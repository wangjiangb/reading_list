<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivlarge language model customization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 18 Aug 2024 13:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v3</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Wed, 10 Jul 2024 11:33:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v3</guid></item><item><title>Review-LLM: Harnessing Large Language Models for Personalized Review Generation</title><link>http://arxiv.org/abs/2407.07487v1</link><description>Product review generation is an important task in recommender systems, whichcould provide explanation and persuasiveness for the recommendation. Recently,Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modelingand generating ability, which could be applied in review generation. However,directly applying the LLMs for generating reviews might be troubled by the``polite'' phenomenon of the LLMs and could not generate personalized reviews(e.g., negative reviews). In this paper, we propose Review-LLM that customizesLLMs for personalized review generation. Firstly, we construct the prompt inputby aggregating user historical behaviors, which include corresponding itemtitles and reviews. This enables the LLMs to capture user interest features andreview writing style. Secondly, we incorporate ratings as indicators ofsatisfaction into the prompt, which could further improve the model'sunderstanding of user preferences and the sentiment tendency control ofgenerated reviews. Finally, we feed the prompt text into LLMs, and useSupervised Fine-Tuning (SFT) to make the model generate personalized reviewsfor the given user and target item. Experimental results on the real-worlddataset show that our fine-tuned model could achieve better review generationperformance than existing close-source LLMs.</description><author>Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang</author><pubDate>Wed, 10 Jul 2024 09:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07487v1</guid></item><item><title>PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games</title><link>http://arxiv.org/abs/2404.19721v3</link><description>This research introduces Procedural Artificial Narrative using Generative AI(PANGeA), a structured approach for leveraging large language models (LLMs),guided by a game designer's high-level criteria, to generate narrative contentfor turn-based role-playing video games (RPGs). Distinct from priorapplications of LLMs used for video game design, PANGeA innovates by not onlygenerating game level data (which includes, but is not limited to, setting, keyitems, and non-playable characters (NPCs)), but by also fostering dynamic,free-form interactions between the player and the environment that align withthe procedural game narrative. The NPCs generated by PANGeA arepersonality-biased and express traits from the Big 5 Personality Model in theirgenerated responses. PANGeA addresses challenges behind ingesting free-formtext input, which can prompt LLM responses beyond the scope of the gamenarrative. A novel validation system that uses the LLM's intelligence evaluatestext input and aligns generated responses with the unfolding narrative. Makingthese interactions possible, PANGeA is supported by a server that hosts acustom memory system that supplies context for augmenting generated responsesthus aligning them with the procedural narrative. For its broad application,the server has a REST interface enabling any game engine to integrate directlywith PANGeA, as well as an LLM interface adaptable with local or private LLMs.PANGeA's ability to foster dynamic narrative generation by aligning responseswith the procedural narrative is demonstrated through an empirical study andablation test of two versions of a demo game. These are, a custom,browser-based GPT and a Unity demo. As the results show, PANGeA holds potentialto assist game designers in using LLMs to generate narrative-consistent contenteven when provided varied and unpredictable, free-form text input.</description><author>Steph Buongiorno, Lawrence Jake Klinkert, Tanishq Chawla, Zixin Zhuang, Corey Clark</author><pubDate>Tue, 09 Jul 2024 23:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19721v3</guid></item><item><title>FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding</title><link>http://arxiv.org/abs/2407.05183v2</link><description>Flowcharts are graphical tools for representing complex concepts in concisevisual representations. This paper introduces the FlowLearn dataset, a resourcetailored to enhance the understanding of flowcharts. FlowLearn contains complexscientific flowcharts and simulated flowcharts. The scientific subset contains3,858 flowcharts sourced from scientific literature and the simulated subsetcontains 10,000 flowcharts created using a customizable script. The dataset isenriched with annotations for visual components, OCR, Mermaid coderepresentation, and VQA question-answer pairs. Despite the proven capabilitiesof Large Vision-Language Models (LVLMs) in various visual understanding tasks,their effectiveness in decoding flowcharts - a crucial element of scientificcommunication - has yet to be thoroughly investigated. The FlowLearn test setis crafted to assess the performance of LVLMs in flowchart comprehension. Ourstudy thoroughly evaluates state-of-the-art LVLMs, identifying existinglimitations and establishing a foundation for future enhancements in thisrelatively underexplored domain. For instance, in tasks involving simulatedflowcharts, GPT-4V achieved the highest accuracy (58%) in counting the numberof nodes, while Claude recorded the highest accuracy (83%) in OCR tasks.Notably, no single model excels in all tasks within the FlowLearn framework,highlighting significant opportunities for further development.</description><author>Huitong Pan, Qi Zhang, Cornelia Caragea, Eduard Dragut, Longin Jan Latecki</author><pubDate>Tue, 09 Jul 2024 21:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05183v2</guid></item><item><title>FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3</title><link>http://arxiv.org/abs/2407.09467v1</link><description>In the diverse world of AI-driven storytelling, there is a unique opportunityto engage young audiences with customized, and personalized narratives. Thispaper introduces FairyLandAI an innovative Large Language Model (LLM) developedthrough OpenAI's API, specifically crafted to create personalized fairytalesfor children. The distinctive feature of FairyLandAI is its dual capability: itnot only generates stories that are engaging, age-appropriate, and reflectiveof various traditions but also autonomously produces imaginative promptssuitable for advanced image generation tools like GenAI and Dalle-3, therebyenriching the storytelling experience. FairyLandAI is expertly tailored toresonate with the imaginative worlds of children, providing narratives that areboth educational and entertaining and in alignment with the moral valuesinherent in different ages. Its unique strength lies in customizing stories tomatch individual children's preferences and cultural backgrounds, heralding anew era in personalized storytelling. Further, its integration with imagegeneration technology offers a comprehensive narrative experience thatstimulates both verbal and visual creativity. Empirical evaluations ofFairyLandAI demonstrate its effectiveness in crafting captivating stories forchildren, which not only entertain but also embody the values and teachings ofdiverse traditions. This model serves as an invaluable tool for parents andeducators, supporting them in imparting meaningful moral lessons throughengaging narratives. FairyLandAI represents a pioneering step in using LLMs,particularly through OpenAI's API, for educational and cultural enrichment,making complex moral narratives accessible and enjoyable for young, imaginativeminds.</description><author>Georgios Makridis, Athanasios Oikonomou, Vasileios Koukos</author><pubDate>Fri, 12 Jul 2024 17:46:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09467v1</guid></item><item><title>Inference Optimization of Foundation Models on AI Accelerators</title><link>http://arxiv.org/abs/2407.09111v1</link><description>Powerful foundation models, including large language models (LLMs), withTransformer architectures have ushered in a new era of Generative AI acrossvarious industries. Industry and research community have witnessed a largenumber of new applications, based on those foundation models. Such applicationsinclude question and answer, customer services, image and video generation, andcode completions, among others. However, as the number of model parametersreaches to hundreds of billions, their deployment incurs prohibitive inferencecosts and high latency in real-world scenarios. As a result, the demand forcost-effective and fast inference using AI accelerators is ever more higher. Tothis end, our tutorial offers a comprehensive discussion on complementaryinference optimization techniques using AI accelerators. Beginning with anoverview of basic Transformer architectures and deep learning systemframeworks, we deep dive into system optimization techniques for fast andmemory-efficient attention computations and discuss how they can be implementedefficiently on AI accelerators. Next, we describe architectural elements thatare key for fast transformer inference. Finally, we examine various modelcompression and fast decoding strategies in the same context.</description><author>Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis</author><pubDate>Fri, 12 Jul 2024 09:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09111v1</guid></item><item><title>Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors</title><link>http://arxiv.org/abs/2407.09136v1</link><description>Large language models (LLMs) present an opportunity to scale high-qualitypersonalized education to all. A promising approach towards this means is tobuild dialog tutoring models that scaffold students' problem-solving. However,even though existing LLMs perform well in solving reasoning questions, theystruggle to precisely detect student's errors and tailor their feedback tothese errors. Inspired by real-world teaching practice where teachers identifystudent errors and customize their response based on them, we focus onverifying student solutions and show how grounding to such verificationimproves the overall quality of tutor response generation. We collect a datasetof 1K stepwise math reasoning chains with the first error step annotated byteachers. We show empirically that finding the mistake in a student solution ischallenging for current models. We propose and evaluate several verifiers fordetecting these errors. Using both automatic and human evaluation we show thatthe student solution verifiers steer the generation model towards highlytargeted responses to student errors which are more often correct with lesshallucinations compared to existing baselines.</description><author>Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan</author><pubDate>Fri, 12 Jul 2024 10:11:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09136v1</guid></item><item><title>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.14608v6</link><description>Large models represent a groundbreaking advancement in multiple applicationfields, enabling remarkable achievements across various tasks. However, theirunprecedented scale comes with significant computational costs. These models,often consisting of billions of parameters, require vast amounts ofcomputational resources for execution. Especially, the expansive scale andcomputational demands pose considerable challenges when customizing them forparticular downstream tasks, particularly over the hardware platformsconstrained by computational capabilities. Parameter Efficient Fine-Tuning(PEFT) provides a practical solution by efficiently adjusting the large modelsover the various downstream tasks. In particular, PEFT refers to the process ofadjusting the parameters of a pre-trained large models to adapt it to aspecific task or domain while minimizing the number of additional parametersintroduced or computational resources required. This approach is particularlyimportant when dealing with large-scale language models with high parametercounts, as fine-tuning these models from scratch can be computationallyexpensive and resource-intensive, posing considerable challenges in thesupporting system platform design. In this survey, we present comprehensivestudies of various PEFT algorithms, examining their performance andcomputational overhead. Moreover, we provide an overview of applicationsdeveloped using different PEFT algorithms and discuss common techniquesemployed to mitigate computation costs for PEFT. In addition to providing anextensive survey from an algorithmic standpoint, we also examine variousreal-world system designs to investigate the implementation costs associatedwith different PEFT approaches. This survey serves as an indispensable resourcefor researchers aiming to understand both the PEFT algorithm and its systemimplementation, offering detailed ......</description><author>Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang</author><pubDate>Fri, 12 Jul 2024 09:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14608v6</guid></item><item><title>Evaluating Nuanced Bias in Large Language Model Free Response Answers</title><link>http://arxiv.org/abs/2407.08842v1</link><description>Pre-trained large language models (LLMs) can now be easily adapted forspecific business purposes using custom prompts or fine tuning. Thesecustomizations are often iteratively re-engineered to improve some aspect ofperformance, but after each change businesses want to ensure that there hasbeen no negative impact on the system's behavior around such critical issues asbias. Prior methods of benchmarking bias use techniques such as word maskingand multiple choice questions to assess bias at scale, but these do not captureall of the nuanced types of bias that can occur in free response answers, thetypes of answers typically generated by LLM systems. In this paper, we identifyseveral kinds of nuanced bias in free text that cannot be similarly identifiedby multiple choice tests. We describe these as: confidence bias, implied bias,inclusion bias and erasure bias. We present a semi-automated pipeline fordetecting these types of bias by first eliminating answers that can beautomatically classified as unbiased and then co-evaluating name reversed pairsusing crowd workers. We believe that the nuanced classifications our methodgenerates can be used to give better feedback to LLMs, especially as LLMreasoning capabilities become more advanced.</description><author>Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Moumita Sinha</author><pubDate>Thu, 11 Jul 2024 19:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08842v1</guid></item><item><title>UrbanWorld: An Urban World Model for 3D City Generation</title><link>http://arxiv.org/abs/2407.11965v1</link><description>Cities, as the most fundamental environment of human life, encompass diversephysical elements such as buildings, roads and vegetation with complexinterconnection. Crafting realistic, interactive 3D urban environments plays acrucial role in constructing AI agents capable of perceiving, decision-making,and acting like humans in real-world environments. However, creatinghigh-fidelity 3D urban environments usually entails extensive manual labor fromdesigners, involving intricate detailing and accurate representation of complexurban features. Therefore, how to accomplish this in an automatical way remainsa longstanding challenge. Toward this problem, we propose UrbanWorld, the firstgenerative urban world model that can automatically create a customized,realistic and interactive 3D urban world with flexible control conditions.UrbanWorld incorporates four key stages in the automatical crafting pipeline:3D layout generation from openly accessible OSM data, urban scene planning anddesigning with a powerful urban multimodal large language model (Urban MLLM),controllable urban asset rendering with advanced 3D diffusion techniques, andfinally the MLLM-assisted scene refinement. The crafted high-fidelity 3D urbanenvironments enable realistic feedback and interactions for general AI andmachine perceptual systems in simulations. We are working on contributingUrbanWorld as an open-source and versatile platform for evaluating andimproving AI abilities in perception, decision-making, and interaction inrealistic urban environments.</description><author>Yu Shang, Jiansheng Chen, Hangyu Fan, Jingtao Ding, Jie Feng, Yong Li</author><pubDate>Tue, 16 Jul 2024 17:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11965v1</guid></item><item><title>How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models</title><link>http://arxiv.org/abs/2407.11549v1</link><description>Psychological evidence reveals the influence of personality traits ondecision-making. For instance, agreeableness is generally associated withpositive outcomes in negotiations, whereas neuroticism is often linked to lessfavorable outcomes. This paper introduces a simulation framework centered onLarge Language Model (LLM) agents endowed with synthesized personality traits.The agents negotiate within bargaining domains and possess customizablepersonalities and objectives. The experimental results show that the behavioraltendencies of LLM-based simulations could reproduce behavioral patternsobserved in human negotiations. The contribution is twofold. First, we proposea simulation methodology that investigates the alignment between the linguisticand economic capabilities of LLM agents. Secondly, we offer empirical insightsinto the strategic impact of Big-Five personality traits on the outcomes ofbilateral negotiations. We also provide a case study based on synthesizedbargaining dialogues to reveal intriguing behaviors, including deceitful andcompromising behaviors.</description><author>Yin Jou Huang, Rafik Hadfi</author><pubDate>Tue, 16 Jul 2024 09:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11549v1</guid></item><item><title>Beyond Mask: Rethinking Guidance Types in Few-shot Segmentation</title><link>http://arxiv.org/abs/2407.11503v1</link><description>Existing few-shot segmentation (FSS) methods mainly focus on prototypefeature generation and the query-support matching mechanism. As a crucialprompt for generating prototype features, the pair of image-mask types in thesupport set has become the default setting. However, various types such asimage, text, box, and mask all can provide valuable information regarding theobjects in context, class, localization, and shape appearance. Existing workfocuses on specific combinations of guidance, leading FSS into differentresearch branches. Rethinking guidance types in FSS is expected to explore theefficient joint representation of the coupling between the support set andquery set, giving rise to research trends in the weakly or strongly annotatedguidance to meet the customized requirements of practical users. In this work,we provide the generalized FSS with seven guidance paradigms and develop auniversal vision-language framework (UniFSS) to integrate prompts from text,mask, box, and image. Leveraging the advantages of large-scale pre-trainingvision-language models in textual and visual embeddings, UniFSS proposeshigh-level spatial correction and embedding interactive units to overcome thesemantic ambiguity drawbacks typically encountered by pure visual matchingmethods when facing intra-class appearance diversities. Extensive experimentsshow that UniFSS significantly outperforms the state-of-the-art methods.Notably, the weakly annotated class-aware box paradigm even surpasses thefinely annotated mask paradigm.</description><author>Shijie Chang, Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu</author><pubDate>Tue, 16 Jul 2024 08:41:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11503v1</guid></item><item><title>Pretraining Data and Tokenizer for Indic LLM</title><link>http://arxiv.org/abs/2407.12481v1</link><description>We present a novel approach to data preparation for developing multilingualIndic large language model. Our meticulous data acquisition spans open-sourceand proprietary sources, including Common Crawl, Indic books, news articles,and Wikipedia, ensuring a diverse and rich linguistic representation. For eachIndic language, we design a custom preprocessing pipeline to effectivelyeliminate redundant and low-quality text content. Additionally, we performdeduplication on Common Crawl data to address the redundancy present in 70% ofthe crawled web pages. This study focuses on developing high-quality data,optimizing tokenization for our multilingual dataset for Indic large languagemodels with 3B and 7B parameters, engineered for superior performance in Indiclanguages. We introduce a novel multilingual tokenizer training strategy,demonstrating our custom-trained Indic tokenizer outperforms thestate-of-the-art OpenAI Tiktoken tokenizer, achieving a superior token-to-wordratio for Indic languages.</description><author>Rahul Kumar, Shubham Kakde, Divyansh Rajput, Daud Ibrahim, Rishabh Nahata, Pidathala Sowjanya, Deepak Kumar</author><pubDate>Wed, 17 Jul 2024 11:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12481v1</guid></item><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v4</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Wed, 17 Jul 2024 07:26:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v4</guid></item><item><title>Building Intelligence Identification System via Large Language Model Watermarking: A Survey and Beyond</title><link>http://arxiv.org/abs/2407.11100v2</link><description>Large Language Models (LLMs) are increasingly integrated into diverseindustries, posing substantial security risks due to unauthorized replicationand misuse. To mitigate these concerns, robust identification mechanisms arewidely acknowledged as an effective strategy. Identification systems for LLMsnow rely heavily on watermarking technology to manage and protect intellectualproperty and ensure data security. However, previous studies have primarilyconcentrated on the basic principles of algorithms and lacked a comprehensiveanalysis of watermarking theory and practice from the perspective ofintelligent identification. To bridge this gap, firstly, we explore how arobust identity recognition system can be effectively implemented and managedwithin LLMs by various participants using watermarking technology. Secondly, wepropose a mathematical framework based on mutual information theory, whichsystematizes the identification process to achieve more precise and customizedwatermarking. Additionally, we present a comprehensive evaluation ofperformance metrics for LLM watermarking, reflecting participant preferencesand advancing discussions on its identification applications. Lastly, weoutline the existing challenges in current watermarking technologies andtheoretical frameworks, and provide directional guidance to address thesechallenges. Our systematic classification and detailed exposition aim toenhance the comparison and evaluation of various methods, fostering furtherresearch and development toward a transparent, secure, and equitable LLMecosystem.</description><author>Xuhong Wang, Haoyu Jiang, Yi Yu, Jingru Yu, Yilun Lin, Ping Yi, Yingchun Wang, Qiao Yu, Li Li, Fei-Yue Wang</author><pubDate>Wed, 17 Jul 2024 03:08:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11100v2</guid></item><item><title>On Pre-training of Multimodal Language Models Customized for Chart Understanding</title><link>http://arxiv.org/abs/2407.14506v1</link><description>Recent studies customizing Multimodal Large Language Models (MLLMs) fordomain-specific tasks have yielded promising results, especially in the fieldof scientific chart comprehension. These studies generally utilize visualinstruction tuning with specialized datasets to enhance question and answer(QA) accuracy within the chart domain. However, they often neglect thefundamental discrepancy between natural image-caption pre-training data anddigital chart image-QA data, particularly in the models' capacity to extractunderlying numeric values from charts. This paper tackles this oversight byexploring the training processes necessary to improve MLLMs' comprehension ofcharts. We present three key findings: (1) Incorporating raw data values inalignment pre-training markedly improves comprehension of chart data. (2)Replacing images with their textual representation randomly during end-to-endfine-tuning transfer the language reasoning capability to chart interpretationskills. (3) Requiring the model to first extract the underlying chart data andthen answer the question in the fine-tuning can further improve the accuracy.Consequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chartcomprehension. CHOPINLLM effectively interprets various types of charts,including unannotated ones, while maintaining robust reasoning abilities.Furthermore, we establish a new benchmark to evaluate MLLMs' understanding ofdifferent chart types across various comprehension levels. Experimental resultsshow that CHOPINLLM exhibits strong performance in understanding both annotatedand unannotated charts across a wide range of types.</description><author>Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Lu Yuan, Leonid Sigal</author><pubDate>Fri, 19 Jul 2024 17:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14506v1</guid></item><item><title>The Art of Refusal: A Survey of Abstention in Large Language Models</title><link>http://arxiv.org/abs/2407.18418v1</link><description>Abstention, the refusal of large language models (LLMs) to provide an answer,is increasingly recognized for its potential to mitigate hallucinations andenhance safety in building LLM systems. In this survey, we introduce aframework to examine abstention behavior from three perspectives: the query,the model, and human values. We review the literature on abstention methods(categorized based on the development stages of LLMs), benchmarks, andevaluation metrics, and discuss the merits and limitations of prior work. Wefurther identify and motivate areas for future research, such as encouragingthe study of abstention as a meta-capability across tasks and customizingabstention abilities based on context. In doing so, we aim to broaden the scopeand impact of abstention methodologies in AI systems.</description><author>Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, Lucy Lu Wang</author><pubDate>Thu, 25 Jul 2024 22:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18418v1</guid></item><item><title>RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent</title><link>http://arxiv.org/abs/2407.16667v1</link><description>Recently, advanced Large Language Models (LLMs) such as GPT-4 have beenintegrated into many real-world applications like Code Copilot. Theseapplications have significantly expanded the attack surface of LLMs, exposingthem to a variety of threats. Among them, jailbreak attacks that induce toxicresponses through jailbreak prompts have raised critical safety concerns. Toidentify these threats, a growing number of red teaming approaches simulatepotential adversarial scenarios by crafting jailbreak prompts to test thetarget LLM. However, existing red teaming methods do not consider the uniquevulnerabilities of LLM in different scenarios, making it difficult to adjustthe jailbreak prompts to find context-specific vulnerabilities. Meanwhile,these methods are limited to refining jailbreak templates using a few mutationoperations, lacking the automation and scalability to adapt to differentscenarios. To enable context-aware and efficient red teaming, we abstract andmodel existing attacks into a coherent concept called "jailbreak strategy" andpropose a multi-agent LLM system named RedAgent that leverages these strategiesto generate context-aware jailbreak prompts. By self-reflecting on contextualfeedback in an additional memory buffer, RedAgent continuously learns how toleverage these strategies to achieve effective jailbreaks in specific contexts.Extensive experiments demonstrate that our system can jailbreak most black-boxLLMs in just five queries, improving the efficiency of existing red teamingmethods by two times. Additionally, RedAgent can jailbreak customized LLMapplications more efficiently. By generating context-aware jailbreak promptstowards applications on GPTs, we discover 60 severe vulnerabilities of thesereal-world applications with only two queries per vulnerability. We havereported all found issues and communicated with OpenAI and Meta for bug fixes.</description><author>Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren</author><pubDate>Tue, 23 Jul 2024 17:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16667v1</guid></item><item><title>ITINERA: Integrating Spatial Optimization with Large Language Models for Open-domain Urban Itinerary Planning</title><link>http://arxiv.org/abs/2402.07204v3</link><description>Citywalk, a recently popular form of urban travel, requires genuinepersonalization and understanding of fine-grained requests compared totraditional itinerary planning. In this paper, we introduce the novel task ofOpen-domain Urban Itinerary Planning (OUIP), which generates personalized urbanitineraries from user requests in natural language. We then present ITINERA, anOUIP system that integrates spatial optimization with large language models toprovide customized urban itineraries based on user needs. This involvesdecomposing user requests, selecting candidate points of interest (POIs),ordering the POIs based on cluster-aware spatial optimization, and generatingthe itinerary. Experiments on real-world datasets and the performance of thedeployed system demonstrate our system's capacity to deliver personalized andspatially coherent itineraries compared to current solutions.</description><author>Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Zhaofeng Wu, Dingyi Zhuang, Jushi Kai, Kebing Hou, Xiaotong Guo, Jinhua Zhao, Zhan Zhao, Wei Ma</author><pubDate>Tue, 23 Jul 2024 11:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07204v3</guid></item><item><title>LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation</title><link>http://arxiv.org/abs/2407.12126v2</link><description>Machine translation is indispensable in healthcare for enabling the globaldissemination of medical knowledge across languages. However, complex medicalterminology poses unique challenges to achieving adequate translation qualityand accuracy. This study introduces a novel "LLMs-in-the-loop" approach todevelop supervised neural machine translation models optimized specifically formedical texts. While large language models (LLMs) have demonstrated powerfulcapabilities, this research shows that small, specialized models trained onhigh-quality in-domain (mostly synthetic) data can outperform even vastlylarger LLMs. Custom parallel corpora in six languages were compiled from scientificarticles, synthetically generated clinical documents, and medical texts. OurLLMs-in-the-loop methodology employs synthetic data generation, rigorousevaluation, and agent orchestration to enhance performance. We developed smallmedical translation models using the MarianMT base model. We introduce a newmedical translation test dataset to standardize evaluation in this domain.Assessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, ourMarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo. Results demonstrate that our LLMs-in-the-loop approach, combined withfine-tuning high-quality, domain-specific data, enables specialized models tooutperform general-purpose and some larger systems. This research, part of abroader series on expert small models, paves the way for futurehealthcare-related AI developments, including deidentification and bio-medicalentity extraction models. Our study underscores the potential of tailoredneural translation models and the LLMs-in-the-loop methodology to advance thefield through improved data generation, evaluation, agent, and modelingtechniques.</description><author>Bunyamin Keles, Murat Gunay, Serdar I. Caglar</author><pubDate>Fri, 26 Jul 2024 12:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12126v2</guid></item><item><title>Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains</title><link>http://arxiv.org/abs/2402.05140v3</link><description>Large Language Models (LLMs) have demonstrated remarkable proficiency inunderstanding and generating natural language. However, their capabilities wanein highly specialized domains underrepresented in the pretraining corpus, suchas physical and biomedical sciences. This work explores how to repurposegeneral LLMs into effective task solvers for specialized domains. We introducea novel, model-agnostic framework for learning custom input tags, which areparameterized as continuous vectors appended to the LLM's embedding layer, tocondition the LLM. We design two types of input tags: domain tags are used todelimit specialized representations (e.g., chemical formulas) and providedomain-relevant context; function tags are used to represent specific functions(e.g., predicting molecular properties) and compress function-solvinginstructions. We develop a three-stage protocol to learn these tags usingauxiliary data and domain knowledge. By explicitly disentangling task domainsfrom task functions, our method enables zero-shot generalization to unseenproblems through diverse combinations of the input tags. It also boosts LLM'sperformance in various specialized domains, such as predicting protein orchemical properties and modeling drug-target interactions, outperforming expertmodels tailored to these tasks.</description><author>Junhong Shen, Neil Tenenholtz, James Brian Hall, David Alvarez-Melis, Nicolo Fusi</author><pubDate>Fri, 26 Jul 2024 01:28:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05140v3</guid></item><item><title>AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes</title><link>http://arxiv.org/abs/2312.06644v3</link><description>Inspired by cognitive theories, we introduce AnyHome, a framework thattranslates any text into well-structured and textured indoor scenes at ahouse-scale. By prompting Large Language Models (LLMs) with designed templates,our approach converts provided textual narratives into amodal structuredrepresentations. These representations guarantee consistent and realisticspatial layouts by directing the synthesis of a geometry mesh within definedconstraints. A Score Distillation Sampling process is then employed to refinethe geometry, followed by an egocentric inpainting process that adds lifeliketextures to it. AnyHome stands out with its editability, customizability,diversity, and realism. The structured representations for scenes allow forextensive editing at varying levels of granularity. Capable of interpretingtexts ranging from simple labels to detailed narratives, AnyHome generatesdetailed geometries and textures that outperform existing methods in bothquantitative and qualitative measures.</description><author>Rao Fu, Zehao Wen, Zichen Liu, Srinath Sridhar</author><pubDate>Mon, 29 Jul 2024 00:09:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06644v3</guid></item><item><title>SOWA: Adapting Hierarchical Frozen Window Self-Attention to Visual-Language Models for Better Anomaly Detection</title><link>http://arxiv.org/abs/2407.03634v2</link><description>Visual anomaly detection is critical in industrial manufacturing, buttraditional methods often rely on extensive normal datasets and custom models,limiting scalability. Recent advancements in large-scale visual-language modelshave significantly improved zero/few-shot anomaly detection. However, theseapproaches may not fully utilize hierarchical features, potentially missingnuanced details. We introduce a window self-attention mechanism based on theCLIP model, combined with learnable prompts to process multi-level featureswithin a Soldier-Offier Window self-Attention (SOWA) framework. Our method hasbeen tested on five benchmark datasets, demonstrating superior performance byleading in 18 out of 20 metrics compared to existing state-of-the-arttechniques.</description><author>Zongxiang Hu, Zhaosheng Zhang</author><pubDate>Tue, 30 Jul 2024 11:02:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03634v2</guid></item><item><title>Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming</title><link>http://arxiv.org/abs/2407.20712v1</link><description>End-user development allows everyday users to tailor service robots orapplications to their needs. One user-friendly approach is natural languageprogramming. However, it encounters challenges such as an expansive userexpression space and limited support for debugging and editing, which restrictits application in end-user programming. The emergence of large language models(LLMs) offers promising avenues for the translation and interpretation betweenhuman language instructions and the code executed by robots, but theirapplication in end-user programming systems requires further study. Weintroduce Cocobo, a natural language programming system with interactivediagrams powered by LLMs. Cocobo employs LLMs to understand users' authoringintentions, generate and explain robot programs, and facilitate the conversionbetween executable code and flowchart representations. Our user study showsthat Cocobo has a low learning curve, enabling even users with zero codingexperience to customize robot programs successfully.</description><author>Yate Ge, Yi Dai, Run Shan, Kechun Li, Yuanda Hu, Xiaohua Sun</author><pubDate>Tue, 30 Jul 2024 10:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20712v1</guid></item><item><title>Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language</title><link>http://arxiv.org/abs/2407.20513v1</link><description>This paper presents a conversational pipeline for crafting domain knowledgefor complex neuro-symbolic models through natural language prompts. Itleverages large language models to generate declarative programs in theDomiKnowS framework. The programs in this framework express concepts and theirrelationships as a graph in addition to logical constraints between them. Thegraph, later, can be connected to trainable neural models according to thosespecifications. Our proposed pipeline utilizes techniques like dynamicin-context demonstration retrieval, model refinement based on feedback from asymbolic parser, visualization, and user interaction to generate the tasks'structure and formal knowledge representation. This approach empowers domainexperts, even those not well-versed in ML/AI, to formally declare theirknowledge to be incorporated in customized neural models in the DomiKnowSframework.</description><author>Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi</author><pubDate>Tue, 30 Jul 2024 03:10:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20513v1</guid></item><item><title>CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment</title><link>http://arxiv.org/abs/2407.21553v1</link><description>This paper presents the Customer Experience (CX) Simulator, a novel frameworkdesigned to assess the effects of untested web-marketing campaigns through userbehavior simulations. The proposed framework leverages large language models(LLMs) to represent various events in a user's behavioral history, such asviewing an item, applying a coupon, or purchasing an item, as semanticembedding vectors. We train a model to predict transitions between events fromtheir LLM embeddings, which can even generalize to unseen events by learningfrom diverse training data. In web-marketing applications, we leverage thistransition prediction model to simulate how users might react differently whennew campaigns or products are presented to them. This allows us to eliminatethe need for costly online testing and enhance the marketers' abilities toreveal insights. Our numerical evaluation and user study, utilizing BigQueryPublic Datasets from the Google Merchandise Store, demonstrate theeffectiveness of our framework.</description><author>Akira Kasuga, Ryo Yonetani</author><pubDate>Wed, 31 Jul 2024 12:22:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21553v1</guid></item><item><title>Building AI Agents for Autonomous Clouds: Challenges and Design Principles</title><link>http://arxiv.org/abs/2407.12165v2</link><description>The rapid growth in the use of Large Language Models (LLMs) and AI Agents aspart of software development and deployment is revolutionizing the informationtechnology landscape. While code generation receives significant attention, ahigher-impact application lies in using AI agents for operational resilience ofcloud services, which currently require significant human effort and domainknowledge. There is a growing interest in AI for IT Operations (AIOps) whichaims to automate complex operational tasks, like fault localization and rootcause analysis, thereby reducing human intervention and customer impact.However, achieving the vision of autonomous and self-healing clouds throughAIOps is hampered by the lack of standardized frameworks for building,evaluating, and improving AIOps agents. This vision paper lays the groundworkfor such a framework by first framing the requirements and then discussingdesign decisions that satisfy them. We also propose AIOpsLab, a prototypeimplementation leveraging agent-cloud-interface that orchestrates anapplication, injects real-time faults using chaos engineering, and interfaceswith an agent to localize and resolve the faults. We report promising resultsand lay the groundwork to build a modular and robust framework for building,evaluating, and improving agents for autonomous clouds.</description><author>Manish Shetty, Yinfang Chen, Gagan Somashekar, Minghua Ma, Yogesh Simmhan, Xuchao Zhang, Jonathan Mace, Dax Vandevoorde, Pedro Las-Casas, Shachee Mishra Gupta, Suman Nath, Chetan Bansal, Saravan Rajmohan</author><pubDate>Wed, 31 Jul 2024 06:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12165v2</guid></item><item><title>On Pre-training of Multimodal Language Models Customized for Chart Understanding</title><link>http://arxiv.org/abs/2407.14506v2</link><description>Recent studies customizing Multimodal Large Language Models (MLLMs) fordomain-specific tasks have yielded promising results, especially in the fieldof scientific chart comprehension. These studies generally utilize visualinstruction tuning with specialized datasets to enhance question and answer(QA) accuracy within the chart domain. However, they often neglect thefundamental discrepancy between natural image-caption pre-training data anddigital chart image-QA data, particularly in the models' capacity to extractunderlying numeric values from charts. This paper tackles this oversight byexploring the training processes necessary to improve MLLMs' comprehension ofcharts. We present three key findings: (1) Incorporating raw data values inalignment pre-training markedly improves comprehension of chart data. (2)Replacing images with their textual representation randomly during end-to-endfine-tuning transfer the language reasoning capability to chart interpretationskills. (3) Requiring the model to first extract the underlying chart data andthen answer the question in the fine-tuning can further improve the accuracy.Consequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chartcomprehension. CHOPINLLM effectively interprets various types of charts,including unannotated ones, while maintaining robust reasoning abilities.Furthermore, we establish a new benchmark to evaluate MLLMs' understanding ofdifferent chart types across various comprehension levels. Experimental resultsshow that CHOPINLLM exhibits strong performance in understanding both annotatedand unannotated charts across a wide range of types.</description><author>Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Lu Yuan, Leonid Sigal</author><pubDate>Wed, 31 Jul 2024 21:01:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14506v2</guid></item><item><title>DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency</title><link>http://arxiv.org/abs/2408.00741v1</link><description>The rapid evolution and widespread adoption of generative large languagemodels (LLMs) have made them a pivotal workload in various applications. Today,LLM inference clusters receive a large number of queries with strict ServiceLevel Objectives (SLOs). To achieve the desired performance, these modelsexecute on power-hungry GPUs causing the inference clusters to consume largeamount of energy and, consequently, result in excessive carbon emissions.Fortunately, we find that there is a great opportunity to exploit theheterogeneity in inference compute properties and fluctuations in inferenceworkloads, to significantly improve energy-efficiency. However, such a diverseand dynamic environment creates a large search-space where different systemconfigurations (e.g., number of instances, model parallelism, and GPUfrequency) translate into different energy-performance trade-offs. To addressthese challenges, we propose DynamoLLM, the first energy-management frameworkfor LLM inference environments. DynamoLLM automatically and dynamicallyreconfigures the inference cluster to optimize for energy and cost of LLMserving under the service's performance SLOs. We show that at a service-level,DynamoLLM conserves 53% energy and 38% operational carbon emissions, andreduces 61% cost to the customer, while meeting the latency SLOs.</description><author>Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Josep Torrellas, Esha Choukse</author><pubDate>Thu, 01 Aug 2024 17:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00741v1</guid></item><item><title>AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models</title><link>http://arxiv.org/abs/2408.00665v1</link><description>Automated Machine Learning (AutoML) offers a promising approach to streamlinethe training of machine learning models. However, existing AutoML frameworksare often limited to unimodal scenarios and require extensive manualconfiguration. Recent advancements in Large Language Models (LLMs) haveshowcased their exceptional abilities in reasoning, interaction, and codegeneration, presenting an opportunity to develop a more automated anduser-friendly framework. To this end, we introduce AutoM3L, an innovativeAutomated Multimodal Machine Learning framework that leverages LLMs ascontrollers to automatically construct multimodal training pipelines. AutoM3Lcomprehends data modalities and selects appropriate models based on userrequirements, providing automation and interactivity. By eliminating the needfor manual feature engineering and hyperparameter optimization, our frameworksimplifies user engagement and enables customization through directives,addressing the limitations of previous rule-based AutoML approaches. Weevaluate the performance of AutoM3L on six diverse multimodal datasets spanningclassification, regression, and retrieval tasks, as well as a comprehensive setof unimodal datasets. The results demonstrate that AutoM3L achieves competitiveor superior performance compared to traditional rule-based AutoML methods.Furthermore, a user study highlights the user-friendliness and usability of ourframework, compared to the rule-based AutoML methods.</description><author>Daqin Luo, Chengjian Feng, Yuxuan Nong, Yiqing Shen</author><pubDate>Thu, 01 Aug 2024 16:01:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00665v1</guid></item><item><title>Chat AI: A Seamless Slurm-Native Solution for HPC-Based Services</title><link>http://arxiv.org/abs/2407.00110v2</link><description>The widespread adoption of large language models (LLMs) has created apressing need for an efficient, secure and private serving infrastructure,which allows researchers to run open source or custom fine-tuned LLMs andensures users that their data remains private and is not stored without theirconsent. While high-performance computing (HPC) systems equipped withstate-of-the-art GPUs are well-suited for training LLMs, their batch schedulingparadigm is not designed to support real-time serving of AI applications. Cloudsystems, on the other hand, are well suited for web services but commonly lackaccess to the computational power of HPC clusters, especially expensive andscarce high-end GPUs, which are required for optimal inference speed. Wepropose an architecture with an implementation consisting of a web service thatruns on a cloud VM with secure access to a scalable backend running a multitudeof LLM models on HPC systems. By offering a web service using our HPCinfrastructure to host LLMs, we leverage the trusted environment of localuniversities and research centers to offer a private and secure alternative tocommercial LLM services. Our solution natively integrates with the HPC batchscheduler Slurm, enabling seamless deployment on HPC clusters, and is able torun side by side with regular Slurm workloads, while utilizing gaps in theschedule created by Slurm. In order to ensure the security of the HPC system,we use the SSH ForceCommand directive to construct a robust circuit breaker,which prevents successful attacks on the web-facing server from affecting thecluster. We have successfully deployed our system as a production service, andmade the source code available at \url{https://github.com/gwdg/chat-ai}</description><author>Ali Doosthosseini, Jonathan Decker, Hendrik Nolte, Julian M. Kunkel</author><pubDate>Fri, 02 Aug 2024 15:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00110v2</guid></item><item><title>Eliciting Informative Text Evaluations with Large Language Models</title><link>http://arxiv.org/abs/2405.15077v3</link><description>Peer prediction mechanisms motivate high-quality feedback with provableguarantees. However, current methods only apply to rather simple reports, likemultiple-choice or scalar numbers. We aim to broaden these techniques to thelarger domain of text-based reports, drawing on the recent developments inlarge language models. This vastly increases the applicability of peerprediction mechanisms as textual feedback is the norm in a large variety offeedback channels: peer reviews, e-commerce customer reviews, and comments onsocial media. We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanismsutilize LLMs as predictors, mapping from one agent's report to a prediction ofher peer's report. Theoretically, we show that when the LLM prediction issufficiently accurate, our mechanisms can incentivize high effort andtruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, weconfirm the efficacy of our mechanisms through experiments conducted on tworeal datasets: the Yelp review dataset and the ICLR OpenReview dataset. Wehighlight the results that on the ICLR dataset, our mechanisms candifferentiate three quality levels -- human-written reviews, GPT-4-generatedreviews, and GPT-3.5-generated reviews in terms of expected scores.Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.</description><author>Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck</author><pubDate>Fri, 02 Aug 2024 03:38:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15077v3</guid></item><item><title>Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models</title><link>http://arxiv.org/abs/2408.02416v1</link><description>The drastic increase of large language models' (LLMs) parameters has led to anew research direction of fine-tuning-free downstream customization by prompts,i.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)play an important role in many businesses, there has emerged growing concernsabout the prompt leakage, which undermines the intellectual properties of theseservices and causes downstream attacks. In this paper, we analyze theunderlying mechanism of prompt leakage, which we refer to as promptmemorization, and develop corresponding defending strategies. By exploring thescaling laws in prompt extraction, we analyze key attributes that influenceprompt extraction, including model sizes, prompt lengths, as well as the typesof prompts. Then we propose two hypotheses that explain how LLMs expose theirprompts. The first is attributed to the perplexity, i.e. the familiarity ofLLMs to texts, whereas the second is based on the straightforward tokentranslation path in attention matrices. To defend against such threats, weinvestigate whether alignments can undermine the extraction of prompts. We findthat current LLMs, even those with safety alignments like GPT-4, are highlyvulnerable to prompt extraction attacks, even under the most straightforwarduser attacks. Therefore, we put forward several defense strategies with theinspiration of our findings, which achieve 83.8\% and 71.0\% drop in the promptextraction rate for Llama2-7B and GPT-3.5, respectively. Source code isavaliable at \url{https://github.com/liangzid/PromptExtractionEval}.</description><author>Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Haoyang Li</author><pubDate>Mon, 05 Aug 2024 12:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02416v1</guid></item><item><title>Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding</title><link>http://arxiv.org/abs/2408.02361v1</link><description>State-of-the-art task-oriented dialogue systems typically rely ontask-specific ontologies for fulfilling user queries. The majority oftask-oriented dialogue data, such as customer service recordings, comes withoutontology and annotation. Such ontologies are normally built manually, limitingthe application of specialised systems. Dialogue ontology construction is anapproach for automating that process and typically consists of two steps: termextraction and relation extraction. In this work, we focus on relationextraction in a transfer learning set-up. To improve the generalisation, wepropose an extension to the decoding mechanism of large language models. Weadapt Chain-of-Thought (CoT) decoding, recently developed for reasoningproblems, to generative relation extraction. Here, we generate multiplebranches in the decoding space and select the relations based on a confidencethreshold. By constraining the decoding to ontology terms and relations, we aimto decrease the risk of hallucination. We conduct extensive experimentation ontwo widely used datasets and find improvements in performance on targetontology for source fine-tuned and one-shot prompted large language models.</description><author>Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias Ruppik, Hsien-Chin Lin, Michael Heck, Milica Gašić</author><pubDate>Mon, 05 Aug 2024 10:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02361v1</guid></item><item><title>ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems</title><link>http://arxiv.org/abs/2408.02248v1</link><description>Recently, there has been increasing interest in using Large Language Models(LLMs) to construct complex multi-agent systems to perform tasks such ascompiling literature reviews, drafting consumer reports, and planningvacations. Many tools and libraries exist for helping create such systems,however none support recursive multi-agent systems -- where the modelsthemselves flexibly decide when to delegate tasks and how to organize theirdelegation structure. In this work, we introduce ReDel: a toolkit for recursivemulti-agent systems that supports custom tool-use, delegation schemes,event-based logging, and interactive replay in an easy-to-use web interface. Weshow that, using ReDel, we are able to achieve significant performance gains onagentic benchmarks and easily identify potential areas of improvements throughthe visualization and debugging tools. Our code, documentation, and PyPIpackage are open-source and free to use under the MIT license.</description><author>Andrew Zhu, Liam Dugan, Chris Callison-Burch</author><pubDate>Mon, 05 Aug 2024 05:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02248v1</guid></item><item><title>Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report)</title><link>http://arxiv.org/abs/2408.02201v1</link><description>The use of large language models (LLMs) is expanding rapidly, and open-sourceversions are becoming available, offering users safer and more adaptableoptions. These models enable users to protect data privacy by eliminating theneed to provide data to third parties and can be customized for specific tasks.In this study, we compare the performance of various language models on theSustainable Development Goal (SDG) mapping task, using the output of GPT-4o asthe baseline. The selected open-source models for comparison include Mixtral,LLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a morespecialized version of GPT-4o, was included to extend the comparison. Given themulti-label nature of the SDG mapping task, we employed metrics such as F1score, precision, and recall with micro-averaging to evaluate different aspectsof the models' performance. These metrics are derived from the confusion matrixto ensure a comprehensive evaluation. We provide a clear observation andanalysis of each model's performance by plotting curves based on F1 score,precision, and recall at different thresholds. According to the results of thisexperiment, LLaMA 2 and Gemma still have significant room for improvement. Theother four models do not exhibit particularly large differences in performance.The outputs from all seven models are available on Zenodo:https://doi.org/10.5281/zenodo.12789375.</description><author>Hui Yin, Amir Aryani, Nakul Nambiar</author><pubDate>Mon, 05 Aug 2024 03:05:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02201v1</guid></item><item><title>LLaSA: Large Language and E-Commerce Shopping Assistant</title><link>http://arxiv.org/abs/2408.02006v1</link><description>The e-commerce platform has evolved rapidly due to its widespread popularityand convenience. Developing an e-commerce shopping assistant for customers iscrucial to aiding them in quickly finding desired products and recommendingprecisely what they need. However, most previous shopping assistants face twomain problems: (1) task-specificity, which necessitates the development ofdifferent models for various tasks, thereby increasing development costs andlimiting effectiveness; and (2) poor generalization, where the trained modelperforms inadequately on up-to-date products. To resolve these issues, weemploy Large Language Models (LLMs) to construct an omnipotent assistant,leveraging their adeptness at handling multiple tasks and their superiorgeneralization capability. Nonetheless, LLMs lack inherent knowledge ofe-commerce concepts. To address this, we create an instruction datasetcomprising 65,000 samples and diverse tasks, termed as EshopInstruct. Throughinstruction tuning on our dataset, the assistant, named LLaSA, demonstrates thepotential to function as an omnipotent assistant. Additionally, we proposevarious inference optimization strategies to enhance performance with limitedinference resources. In the Amazon KDD Cup 2024 Challenge, our proposed method,LLaSA, achieved an overall ranking of 3rd place on ShopBench, including 57tasks and approximately 20,000 questions, and we secured top-5 rankings in eachtrack, especially in track4, where we achieved the best performance resultamong all student teams. Our extensive practices fully demonstrate that LLMspossess the great potential to be competent e-commerce shopping assistants.</description><author>Shuo Zhang, Boci Peng, Xinping Zhao, Boren Hu, Yun Zhu, Yanjia Zeng, Xuming Hu</author><pubDate>Sun, 04 Aug 2024 12:10:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02006v1</guid></item><item><title>VIP: Versatile Image Outpainting Empowered by Multimodal Large Language Model</title><link>http://arxiv.org/abs/2406.01059v2</link><description>In this paper, we focus on resolving the problem of image outpainting, whichaims to extrapolate the surrounding parts given the center contents of animage. Although recent works have achieved promising performance, the lack ofversatility and customization hinders their practical applications in broaderscenarios. Therefore, this work presents a novel image outpainting frameworkthat is capable of customizing the results according to the requirement ofusers. First of all, we take advantage of a Multimodal Large Language Model(MLLM) that automatically extracts and organizes the corresponding textualdescriptions of the masked and unmasked part of a given image. Accordingly, theobtained text prompts are introduced to endow our model with the capacity tocustomize the outpainting results. In addition, a special Cross-Attentionmodule, namely Center-Total-Surrounding (CTS), is elaborately designed toenhance further the the interaction between specific space regions of the imageand corresponding parts of the text prompts. Note that unlike most existingmethods, our approach is very resource-efficient since it is just slightlyfine-tuned on the off-the-shelf stable diffusion (SD) model rather than beingtrained from scratch. Finally, the experimental results on three commonly useddatasets, i.e. Scenery, Building, and WikiArt, demonstrate our modelsignificantly surpasses the SoTA methods. Moreover, versatile outpaintingresults are listed to show its customized ability.</description><author>Jinze Yang, Haoran Wang, Zining Zhu, Chenglong Liu, Meng Wymond Wu, Zeke Xie, Zhong Ji, Jungong Han, Mingming Sun</author><pubDate>Sat, 03 Aug 2024 08:52:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01059v2</guid></item><item><title>Analysis of Argument Structure Constructions in a Deep Recurrent Language Model</title><link>http://arxiv.org/abs/2408.03062v1</link><description>Understanding how language and linguistic constructions are processed in thebrain is a fundamental question in cognitive computational neuroscience. Inthis study, we explore the representation and processing of Argument StructureConstructions (ASCs) in a recurrent neural language model. We trained a LongShort-Term Memory (LSTM) network on a custom-made dataset consisting of 2000sentences, generated using GPT-4, representing four distinct ASCs: transitive,ditransitive, caused-motion, and resultative constructions. We analyzed the internal activations of the LSTM model's hidden layers usingMultidimensional Scaling (MDS) and t-Distributed Stochastic Neighbor Embedding(t-SNE) to visualize the sentence representations. The GeneralizedDiscrimination Value (GDV) was calculated to quantify the degree of clusteringwithin these representations. Our results show that sentence representationsform distinct clusters corresponding to the four ASCs across all hidden layers,with the most pronounced clustering observed in the last hidden layer beforethe output layer. This indicates that even a relatively simple,brain-constrained recurrent neural network can effectively differentiatebetween various construction types. These findings are consistent with previous studies demonstrating theemergence of word class and syntax rule representations in recurrent languagemodels trained on next word prediction tasks. In future work, we aim tovalidate these results using larger language models and compare them withneuroimaging data obtained during continuous speech perception. This studyhighlights the potential of recurrent neural language models to mirrorlinguistic processing in the human brain, providing valuable insights into thecomputational and neural mechanisms underlying language understanding.</description><author>Pegah Ramezani, Achim Schilling, Patrick Krauss</author><pubDate>Tue, 06 Aug 2024 09:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03062v1</guid></item><item><title>OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents</title><link>http://arxiv.org/abs/2408.03047v1</link><description>Multimodal conversational agents are highly desirable because they offernatural and human-like interaction. However, there is a lack of comprehensiveend-to-end solutions to support collaborative development and benchmarking.While proprietary systems like GPT-4o and Gemini demonstrating impressiveintegration of audio, video, and text with response times of 200-250ms,challenges remain in balancing latency, accuracy, cost, and data privacy. Tobetter understand and quantify these issues, we developed OpenOmni, anopen-source, end-to-end pipeline benchmarking tool that integrates advancedtechnologies such as Speech-to-Text, Emotion Detection, Retrieval AugmentedGeneration, Large Language Models, along with the ability to integratecustomized models. OpenOmni supports local and cloud deployment, ensuring dataprivacy and supporting latency and accuracy benchmarking. This flexibleframework allows researchers to customize the pipeline, focusing on realbottlenecks and facilitating rapid proof-of-concept development. OpenOmni cansignificantly enhance applications like indoor assistance for visually impairedindividuals, advancing human-computer interaction. Our demonstration video isavailable https://www.youtube.com/watch?v=zaSiT3clWqY, demo is available viahttps://openomni.ai4wa.com, code is available viahttps://github.com/AI4WA/OpenOmniFramework.</description><author>Qiang Sun, Yuanyi Luo, Sirui Li, Wenxiao Zhang, Wei Liu</author><pubDate>Tue, 06 Aug 2024 09:02:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03047v1</guid></item><item><title>WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models</title><link>http://arxiv.org/abs/2408.03837v1</link><description>WalledEval is a comprehensive AI safety testing toolkit designed to evaluatelarge language models (LLMs). It accommodates a diverse range of models,including both open-weight and API-based ones, and features over 35 safetybenchmarks covering areas such as multilingual safety, exaggerated safety, andprompt injections. The framework supports both LLM and judge benchmarking, andincorporates custom mutators to test safety against various text-stylemutations such as future tense and paraphrasing. Additionally, WalledEvalintroduces WalledGuard, a new, small and performant content moderation tool,and SGXSTest, a benchmark for assessing exaggerated safety in culturalcontexts. We make WalledEval publicly available athttps://github.com/walledai/walledevalA.</description><author>Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria</author><pubDate>Wed, 07 Aug 2024 15:22:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03837v1</guid></item><item><title>Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation</title><link>http://arxiv.org/abs/2408.03533v1</link><description>We primarily focus on the field of large language models (LLMs) forrecommendation, which has been actively explored recently and poses asignificant challenge in effectively enhancing recommender systems with logicalreasoning abilities and open-world knowledge. Current mainstream efforts mainlycenter around injecting personalized information from recommendation modelsinto LLMs by customizing input templates or aligning representations betweensemantic and recommendation spaces at the prediction layer. However, they facethree significant limitations: (1) LoRA is mostly used as a core component inexisting works, but personalization is not well established in LoRA parametersas the LoRA matrix shared by every user may not cater to different users'characteristics, leading to suboptimal performance. (2) Although lifelongpersonalized behavior sequences are ideal for personalization, their use raiseseffectiveness and efficiency issues since LLMs require escalating training andinference time to extend text lengths. (3) Existing approaches aren't scalablefor large datasets due to training efficiency constraints. Thus, LLMs only seea small fraction of the datasets (e.g., less than 10%) instead of the wholedatasets, limiting their exposure to the full training space. To address theseproblems, we propose RecLoRA. This model incorporates a Personalized LoRAmodule that maintains independent LoRAs for different users and a Long-ShortModality Retriever that retrieves different history lengths for differentmodalities, significantly improving performance while adding minimal time cost.Furthermore, we design a Few2Many Learning Strategy, using a conventionalrecommendation model as a lens to magnify small training spaces to full spaces.Extensive experiments on public datasets demonstrate the efficacy of ourRecLoRA compared to existing baseline models.</description><author>Jiachen Zhu, Jianghao Lin, Xinyi Dai, Bo Chen, Rong Shan, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang</author><pubDate>Wed, 07 Aug 2024 04:20:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03533v1</guid></item><item><title>RULER: What's the Real Context Size of Your Long-Context Language Models?</title><link>http://arxiv.org/abs/2404.06654v3</link><description>The needle-in-a-haystack (NIAH) test, which examines the ability to retrievea piece of information (the "needle") from long distractor texts (the"haystack"), has been widely adopted to evaluate long-context language models(LMs). However, this simple retrieval-based test is indicative of only asuperficial form of long-context understanding. To provide a more comprehensiveevaluation of long-context LMs, we create a new synthetic benchmark RULER withflexible configurations for customized sequence length and task complexity.RULER expands upon the vanilla NIAH test to encompass variations with diversetypes and quantities of needles. Moreover, RULER introduces new task categoriesmulti-hop tracing and aggregation to test behaviors beyond searching fromcontext. We evaluate 17 long-context LMs with 13 representative tasks in RULER.Despite achieving nearly perfect accuracy in the vanilla NIAH test, almost allmodels exhibit large performance drops as the context length increases. Whilethese models all claim context sizes of 32K tokens or greater, only half ofthem can maintain satisfactory performance at the length of 32K. Our analysisof Yi-34B, which supports context length of 200K, reveals large room forimprovement as we increase input length and task complexity. We open sourceRULER to spur comprehensive evaluation of long-context LMs.</description><author>Cheng-Ping Hsieh, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, Yang Zhang, Boris Ginsburg</author><pubDate>Tue, 06 Aug 2024 21:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06654v3</guid></item><item><title>Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization</title><link>http://arxiv.org/abs/2408.04112v1</link><description>Large language models (LLMs) can help writers build story worlds bygenerating world elements, such as factions, characters, and locations.However, making sense of many generated elements can be overwhelming. Moreover,if the user wants to precisely control aspects of generated elements that aredifficult to specify verbally, prompting alone may be insufficient. Weintroduce Patchview, a customizable LLM-powered system that visually aidsworldbuilding by allowing users to interact with story concepts and elementsthrough the physical metaphor of magnets and dust. Elements in Patchview arevisually dragged closer to concepts with high relevance, facilitatingsensemaking. The user can also steer the generation with verbally elusiveconcepts by indicating the desired position of the element between concepts.When the user disagrees with the LLM's visualization and generation, they cancorrect those by repositioning the element. These corrections can be used toalign the LLM's future behaviors to the user's perception. With a user study,we show that Patchview supports the sensemaking of world elements and steeringof element generation, facilitating exploration during the worldbuildingprocess. Patchview provides insights on how customizable visual representationcan help sensemake, steer, and align generative AI model behaviors with theuser's intentions.</description><author>John Joon Young Chung, Max Kreminski</author><pubDate>Wed, 07 Aug 2024 22:27:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04112v1</guid></item><item><title>WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models</title><link>http://arxiv.org/abs/2408.03837v2</link><description>WalledEval is a comprehensive AI safety testing toolkit designed to evaluatelarge language models (LLMs). It accommodates a diverse range of models,including both open-weight and API-based ones, and features over 35 safetybenchmarks covering areas such as multilingual safety, exaggerated safety, andprompt injections. The framework supports both LLM and judge benchmarking, andincorporates custom mutators to test safety against various text-stylemutations such as future tense and paraphrasing. Additionally, WalledEvalintroduces WalledGuard, a new, small and performant content moderation tool,and SGXSTest, a benchmark for assessing exaggerated safety in culturalcontexts. We make WalledEval publicly available athttps://github.com/walledai/walledeval</description><author>Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria</author><pubDate>Thu, 08 Aug 2024 18:05:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03837v2</guid></item><item><title>TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning</title><link>http://arxiv.org/abs/2408.05200v1</link><description>Language model continual learning (CL) has recently garnered significantinterest due to its potential to adapt large language models (LLMs) to dynamicreal-world environments without re-training. A key challenge in this field iscatastrophic forgetting, where models lose previously acquired knowledge whenlearning new tasks. Existing methods commonly employ multipleparameter-efficient fine-tuning (PEFT) blocks to acquire task-specificknowledge for each task, but these approaches lack efficiency and overlook thepotential for knowledge transfer through task interaction. In this paper, wepresent a novel CL framework for language models called Task Skill Localizationand Consolidation (TaSL), which enhances knowledge transfer without relying onmemory replay. TaSL first divides the model into `skill units' based onparameter dependencies, enabling more granular control. It then employs a novelgroup-wise skill localization technique to identify the importance distributionof skill units for a new task. By comparing this importance distribution withthose from previous tasks, we implement a fine-grained skill consolidationstrategy that retains task-specific knowledge, thereby preventing forgetting,and updates task-shared knowledge, which facilitates bi-directional knowledgetransfer. As a result, TaSL achieves a superior balance between retainingprevious knowledge and excelling in new tasks. TaSL also shows stronggeneralizability, suitable for general models and customizable for PEFT methodslike LoRA. Additionally, it demonstrates notable extensibility, allowingintegration with memory replay to further enhance performance. Extensiveexperiments on two CL benchmarks, with varying model sizes (from 220M to 7B),demonstrate the effectiveness of TaSL and its variants across differentsettings.</description><author>Yujie Feng, Xu Chu, Yongxin Xu, Zexin Lu, Bo Liu, Philip S. Yu, Xiao-Ming Wu</author><pubDate>Fri, 09 Aug 2024 17:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05200v1</guid></item><item><title>Shifting the Lens: Detecting Malicious npm Packages using Large Language Models</title><link>http://arxiv.org/abs/2403.12196v2</link><description>Existing malicious code detection techniques can aid the manual reviewprocess by predicting which packages are likely to be malicious. However, thesetechniques often suffer from high misclassification rates. Therefore, maliciouscode detection techniques could be enhanced by adopting advanced, moreautomated approaches to achieve high accuracy and a low misclassification rate.The goal of this study is to assist security analysts in detecting maliciouspackages through the empirical study of using Large Language Models (LLMs) todetect malicious code in the npm ecosystem. We present SecurityAI, a maliciouscode review workflow to detect malicious code using ChatGPT. We leverage abenchmark dataset of 5,115 npm packages, of which 2,180 packages have maliciouscode. We conducted a baseline comparison of GPT-3 and GPT- 4 models with thestate-of-the-art CodeQL static analysis tool, using 39 custom CodeQL rulesdeveloped in prior research to detect malicious Javascript code. We compare theeffectiveness of static analysis as a pre-screener with SecurityAI workflow,measuring the number of files that need to be analyzed and the associatedcosts. Additionally, we performed a qualitative study to understand the typesof malicious packages detected or missed by our workflow. Our baselinecomparison demonstrates a 16% and 9% improvement over static analysis inprecision and F1 scores, respectively. We attained precision and F1 scores of91% and 94% for GPT-3, and 99% &amp; 97% for GPT-4, respectively, with GPT-3offering a cost-effective balance. Pre-screening files with a static analyzerreduces the number of files requiring LLM analysis by 77.9% and decreases costsby 60.9% for GPT-3 and 76.1% for GPT-4. Our qualitative analysis identifieddata theft, hidden backdoors, and suspicious domain connection categories asthe top detected malicious packages.</description><author>Nusrat Zahan, Philipp Burckhardt, Mikola Lysenko, Feross Aboukhadijeh, Laurie Williams</author><pubDate>Fri, 09 Aug 2024 16:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12196v2</guid></item><item><title>It's Morphing Time: Unleashing the Potential of Multiple LLMs via Multi-objective Optimization</title><link>http://arxiv.org/abs/2407.00487v2</link><description>In this paper, we introduce a novel approach for large language model mergingvia black-box multi-objective optimization algorithms. The goal of modelmerging is to combine multiple models, each excelling in different tasks, intoa single model that outperforms any of the individual source models. However,model merging faces two significant challenges: First, existing methods relyheavily on human intuition and customized strategies to tackle multiple tasks.Second, it's difficult to search for the great model merging configuration inlimited evaluations. To address these challenges, we propose a multi-objectiveoptimization based model merging method named MM-MO. The proposed method canautomatically search merging configurations for multiple tasks withmulti-objective optimization algorithms. Moreover, to obtain high-quality modelmerging configurations within a limited number of evaluation iterations, wehave made several improvements to multi-objective Bayesian optimizationspecifically for model merging scenarios. First, we introduced a weak-to-strongmethod to improve the acquisition strategy. Second, we employed Fisherinformation to select configurations, further increasing the chances ofdiscovering superior model merging configurations. Third, we designed asparsity metric as an additional optimization objective to enhance the model'sgeneralization performance across different tasks. We conducted comprehensiveexperiments with other mainstream model merging methods, demonstrating that ourmethod consistently outperforms them. Moreover, performance improvements areobserved even on the tasks not explicitly targeted as optimization objectives,indicating that our method enhances the overall potential of the model. ...</description><author>Bingdong Li, Zixiang Di, Yanting Yang, Hong Qian, Peng Yang, Hao Hao, Ke Tang, Aimin Zhou</author><pubDate>Mon, 12 Aug 2024 14:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00487v2</guid></item><item><title>ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers</title><link>http://arxiv.org/abs/2408.06040v1</link><description>In the rapidly evolving fields of natural language processing and computervision, Visual Word Sense Disambiguation (VWSD) stands as a critical, yetchallenging task. The quest for models that can seamlessly integrate andinterpret multimodal data is more pressing than ever. Imagine a system that canunderstand language with the depth and nuance of human cognition, whilesimultaneously interpreting the rich visual context of the world around it. We present ARPA, an architecture that fuses the unparalleled contextualunderstanding of large language models with the advanced feature extractioncapabilities of transformers, which then pass through a custom Graph NeuralNetwork (GNN) layer to learn intricate relationships and subtle nuances withinthe data. This innovative architecture not only sets a new benchmark in visualword disambiguation but also introduces a versatile framework poised totransform how linguistic and visual data interact by harnessing the synergisticstrengths of its components, ensuring robust performance even in the mostcomplex disambiguation scenarios. Through a series of experiments andcomparative analysis, we reveal the substantial advantages of our model,underscoring its potential to redefine standards in the field. Beyond itsarchitectural prowess, our architecture excels through experimentalenrichments, including sophisticated data augmentation and multi-modal trainingtechniques. ARPA's introduction marks a significant milestone in visual worddisambiguation, offering a compelling solution that bridges the gap betweenlinguistic and visual modalities. We invite researchers and practitioners toexplore the capabilities of our model, envisioning a future where such hybridmodels drive unprecedented advancements in artificial intelligence.</description><author>Aristi Papastavrou, Maria Lymperaiou, Giorgos Stamou</author><pubDate>Mon, 12 Aug 2024 10:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06040v1</guid></item><item><title>Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models</title><link>http://arxiv.org/abs/2408.05933v1</link><description>With the growing demand for offline PDF chatbots in automotive industrialproduction environments, optimizing the deployment of large language models(LLMs) in local, low-performance settings has become increasingly important.This study focuses on enhancing Retrieval-Augmented Generation (RAG) techniquesfor processing complex automotive industry documents using locally deployedOllama models. Based on the Langchain framework, we propose a multi-dimensionaloptimization approach for Ollama's local RAG implementation. Our methodaddresses key challenges in automotive document processing, includingmulti-column layouts and technical specifications. We introduce improvements inPDF processing, retrieval mechanisms, and context compression, tailored to theunique characteristics of automotive industry documents. Additionally, wedesign custom classes supporting embedding pipelines and an agent supportingself-RAG based on LangGraph best practices. To evaluate our approach, weconstructed a proprietary dataset comprising typical automotive industrydocuments, including technical reports and corporate regulations. We comparedour optimized RAG model and self-RAG agent against a naive RAG baseline acrossthree datasets: our automotive industry dataset, QReCC, and CoQA. Resultsdemonstrate significant improvements in context precision, context recall,answer relevancy, and faithfulness, with particularly notable performance onthe automotive industry dataset. Our optimization scheme provides an effectivesolution for deploying local RAG systems in the automotive sector, addressingthe specific needs of PDF chatbots in industrial production environments. Thisresearch has important implications for advancing information processing andintelligent production in the automotive industry.</description><author>Fei Liu, Zejun Kang, Xing Han</author><pubDate>Mon, 12 Aug 2024 06:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05933v1</guid></item><item><title>A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning</title><link>http://arxiv.org/abs/2408.05911v1</link><description>With the rapid development of large language models in recent years, therehas been an increasing demand for domain-specific Agents that can cater to theunique needs of enterprises and organizations. Unlike general models, whichstrive for broad coverage, these specialized Agents rely on focused datasetstailored to their intended applications. This research proposes a pipeline thatleverages the power of LLMs and the Retrieval-Augmented Generation relatedframework to construct high-quality instruction datasets for fine-tuning onspecific domains using custom document collections. By ingestingdomain-specific documents, the pipeline generates relevant and contextuallyappropriate instructions, thus effectively creating a comprehensive dataset forfine-tuning LLMs on the target domain. This approach overcomes the limitationsof traditional dataset creation methods, which often rely on manual curation orweb-scraping techniques that may introduce noise and irrelevant data. Notably,our pipeline offers a dynamic solution that can quickly adapt to updates ormodifications in the domain-specific document collection, eliminating the needfor complete retraining. Additionally, it addresses the challenge of datascarcity by enabling the generation of instruction datasets from a limited setof initial documents, rendering it suitable for unpopular or specializeddomains where comprehensive datasets are scarce. As a case study, we apply thisapproach to the domain of psychiatry, a field requiring specialized knowledgeand sensitive handling of patient information. The resulting fine-tuned LLMdemonstrates showcases the viability of the proposed approach and underscoresits potential for widespread adoption across various industries and domainswhere tailored, accurate, and contextually relevant language models areindispensable.</description><author>Chih-Wei Song, Yu-Kai Lee, Yin-Te Tsai</author><pubDate>Mon, 12 Aug 2024 03:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05911v1</guid></item><item><title>Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation</title><link>http://arxiv.org/abs/2408.03533v2</link><description>We primarily focus on the field of large language models (LLMs) forrecommendation, which has been actively explored recently and poses asignificant challenge in effectively enhancing recommender systems with logicalreasoning abilities and open-world knowledge. Current mainstream efforts mainlycenter around injecting personalized information from recommendation modelsinto LLMs by customizing input templates or aligning representations betweensemantic and recommendation spaces at the prediction layer. However, they facethree significant limitations: (1) LoRA is mostly used as a core component inexisting works, but personalization is not well established in LoRA parametersas the LoRA matrix shared by every user may not cater to different users'characteristics, leading to suboptimal performance. (2) Although lifelongpersonalized behavior sequences are ideal for personalization, their use raiseseffectiveness and efficiency issues since LLMs require escalating training andinference time to extend text lengths. (3) Existing approaches aren't scalablefor large datasets due to training efficiency constraints. Thus, LLMs only seea small fraction of the datasets (e.g., less than 10%) instead of the wholedatasets, limiting their exposure to the full training space. To address theseproblems, we propose RecLoRA. This model incorporates a Personalized LoRAmodule that maintains independent LoRAs for different users and a Long-ShortModality Retriever that retrieves different history lengths for differentmodalities, significantly improving performance while adding minimal time cost.Furthermore, we design a Few2Many Learning Strategy, using a conventionalrecommendation model as a lens to magnify small training spaces to full spaces.Extensive experiments on public datasets demonstrate the efficacy of ourRecLoRA compared to existing baseline models.</description><author>Jiachen Zhu, Jianghao Lin, Xinyi Dai, Bo Chen, Rong Shan, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang</author><pubDate>Sun, 11 Aug 2024 09:08:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03533v2</guid></item><item><title>SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning</title><link>http://arxiv.org/abs/2408.05517v1</link><description>Recent development in Large Language Models (LLMs) and Multi-modal LargeLanguage Models (MLLMs) have leverage Attention-based Transformer architecturesand achieved superior performance and generalization capabilities. They havesince covered extensive areas of traditional learning tasks. For instance,text-based tasks such as text-classification and sequence-labeling, as well asmulti-modal tasks like Visual Question Answering (VQA) and Optical CharacterRecognition (OCR), which were previously addressed using different models, cannow be tackled based on one foundation model. Consequently, the training andlightweight fine-tuning of LLMs and MLLMs, especially those based onTransformer architecture, has become particularly important. In recognition ofthese overwhelming needs, we develop SWIFT, a customizable one-stopinfrastructure for large models. With support of over $300+$ LLMs and $50+$MLLMs, SWIFT stands as the open-source framework that provide the \textit{mostcomprehensive support} for fine-tuning large models. In particular, it is thefirst training framework that provides systematic support for MLLMs. Inaddition to the core functionalities of fine-tuning, SWIFT also integratespost-training processes such as inference, evaluation, and model quantization,to facilitate fast adoptions of large models in various application scenarios.With a systematic integration of various training techniques, SWIFT offershelpful utilities such as benchmark comparisons among different trainingtechniques for large models. For fine-tuning models specialized in agentframework, we show that notable improvements on the ToolBench leader-board canbe achieved by training with customized dataset on SWIFT, with an increase of5.2\%-21.8\% in the Act.EM metric over various baseline models, a reduction inhallucination by 1.6\%-14.1\%, and an average performance improvement of8\%-17\%.</description><author>Yuze Zhao, Jintao Huang, Jinghan Hu, Daoze Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen</author><pubDate>Sat, 10 Aug 2024 11:00:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05517v1</guid></item><item><title>SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning</title><link>http://arxiv.org/abs/2408.05517v2</link><description>Recent development in Large Language Models (LLMs) and Multi-modal LargeLanguage Models (MLLMs) have leverage Attention-based Transformer architecturesand achieved superior performance and generalization capabilities. They havesince covered extensive areas of traditional learning tasks. For instance,text-based tasks such as text-classification and sequence-labeling, as well asmulti-modal tasks like Visual Question Answering (VQA) and Optical CharacterRecognition (OCR), which were previously addressed using different models, cannow be tackled based on one foundation model. Consequently, the training andlightweight fine-tuning of LLMs and MLLMs, especially those based onTransformer architecture, has become particularly important. In recognition ofthese overwhelming needs, we develop SWIFT, a customizable one-stopinfrastructure for large models. With support of over $300+$ LLMs and $50+$MLLMs, SWIFT stands as the open-source framework that provide the \textit{mostcomprehensive support} for fine-tuning large models. In particular, it is thefirst training framework that provides systematic support for MLLMs. Inaddition to the core functionalities of fine-tuning, SWIFT also integratespost-training processes such as inference, evaluation, and model quantization,to facilitate fast adoptions of large models in various application scenarios.With a systematic integration of various training techniques, SWIFT offershelpful utilities such as benchmark comparisons among different trainingtechniques for large models. For fine-tuning models specialized in agentframework, we show that notable improvements on the ToolBench leader-board canbe achieved by training with customized dataset on SWIFT, with an increase of5.2%-21.8% in the Act.EM metric over various baseline models, a reduction inhallucination by 1.6%-14.1%, and an average performance improvement of 8%-17%.</description><author>Yuze Zhao, Jintao Huang, Jinghan Hu, Xingjun Wang, Yunlin Mao, Daoze Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen</author><pubDate>Tue, 13 Aug 2024 09:22:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05517v2</guid></item><item><title>Efficient Search for Customized Activation Functions with Gradient Descent</title><link>http://arxiv.org/abs/2408.06820v1</link><description>Different activation functions work best for different deep learning models.To exploit this, we leverage recent advancements in gradient-based searchtechniques for neural architectures to efficiently identify high-performingactivation functions for a given application. We propose a fine-grained searchcell that combines basic mathematical operations to model activation functions,allowing for the exploration of novel activations. Our approach enables theidentification of specialized activations, leading to improved performance inevery model we tried, from image classification to language models. Moreover,the identified activations exhibit strong transferability to larger models ofthe same type, as well as new datasets. Importantly, our automated process forcreating customized activation functions is orders of magnitude more efficientthan previous approaches. It can easily be applied on top of arbitrary deeplearning pipelines and thus offers a promising practical avenue for enhancingdeep learning architectures.</description><author>Lukas Strack, Mahmoud Safari, Frank Hutter</author><pubDate>Tue, 13 Aug 2024 11:27:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06820v1</guid></item><item><title>Seeing and Understanding: Bridging Vision with Chemical Knowledge Via ChemVLM</title><link>http://arxiv.org/abs/2408.07246v1</link><description>In this technical report, we propose ChemVLM, the first open-sourcemultimodal large language model dedicated to the fields of chemistry, designedto address the incompatibility between chemical image understanding and textanalysis. Built upon the VIT-MLP-LLM architecture, we leverage ChemLLM-20B asthe foundational large model, endowing our model with robust capabilities inunderstanding and utilizing chemical text knowledge. Additionally, we employInternVIT-6B as a powerful image encoder. We have curated high-quality datafrom the chemical domain, including molecules, reaction formulas, and chemistryexamination data, and compiled these into a bilingual multimodalquestion-answering dataset. We test the performance of our model on multipleopen-source benchmarks and three custom evaluation sets. Experimental resultsdemonstrate that our model achieves excellent performance, securingstate-of-the-art results in five out of six involved tasks. Our model can befound at https://huggingface.co/AI4Chem/ChemVLM-26B.</description><author>Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu, Weiyun Wang, Zhe Chen, Wenhai Wang, Wei Li, Shufei Zhang, Mao Su, Wanli Ouyang, Yuqiang Li, Dongzhan Zhou</author><pubDate>Wed, 14 Aug 2024 01:16:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07246v1</guid></item><item><title>Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach</title><link>http://arxiv.org/abs/2408.07238v1</link><description>Advanced Large language models (LLMs) like GPT-4 or LlaMa 3 provide superiorperformance in complex human-like interactions. But they are costly, or toolarge for edge devices such as smartphones and harder to self-host, leading tosecurity and privacy concerns. This paper introduces a novel interpretableknowledge distillation approach to enhance the performance of smaller, moreeconomical LLMs that firms can self-host. We study this problem in the contextof building a customer service agent aimed at achieving high customersatisfaction through goal-oriented dialogues. Unlike traditional knowledgedistillation, where the "student" model learns directly from the "teacher"model's responses via fine-tuning, our interpretable "strategy" teachingapproach involves the teacher providing strategies to improve the student'sperformance in various scenarios. This method alternates between a "scenariogeneration" step and a "strategies for improvement" step, creating a customizedlibrary of scenarios and optimized strategies for automated prompting. Themethod requires only black-box access to both student and teacher models; henceit can be used without manipulating model parameters. In our customer serviceapplication, the method improves performance, and the learned strategies aretransferable to other LLMs and scenarios beyond the training set. The method'sinterpretabilty helps safeguard against potential harms through human audit.</description><author>Tong Wang, K. Sudhir, Dat Hong</author><pubDate>Tue, 13 Aug 2024 23:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07238v1</guid></item></channel></rss>