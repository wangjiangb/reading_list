<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivlarge language model customization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 24 Jun 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Rapid Adoption, Hidden Risks: The Dual Impact of Large Language Model Customization</title><link>http://arxiv.org/abs/2402.09179v2</link><description>The increasing demand for customized Large Language Models (LLMs) has led tothe development of solutions like GPTs. These solutions facilitate tailored LLMcreation via natural language prompts without coding. However, thetrustworthiness of third-party custom versions of LLMs remains an essentialconcern. In this paper, we propose the first instruction backdoor attacksagainst applications integrated with untrusted customized LLMs (e.g., GPTs).Specifically, these attacks embed the backdoor into the custom version of LLMsby designing prompts with backdoor instructions, outputting the attacker'sdesired result when inputs contain the pre-defined triggers. Our attackincludes 3 levels of attacks: word-level, syntax-level, and semantic-level,which adopt different types of triggers with progressive stealthiness. Westress that our attacks do not require fine-tuning or any modification to thebackend LLMs, adhering strictly to GPTs development guidelines. We conductextensive experiments on 4 prominent LLMs and 5 benchmark text classificationdatasets. The results show that our instruction backdoor attacks achieve thedesired attack performance without compromising utility. Additionally, wepropose an instruction-ignoring defense mechanism and demonstrate its partialeffectiveness in mitigating such attacks. Our findings highlight thevulnerability and the potential risks of LLM customization such as GPTs.</description><author>Rui Zhang, Hongwei Li, Rui Wen, Wenbo Jiang, Yuan Zhang, Michael Backes, Yun Shen, Yang Zhang</author><pubDate>Thu, 15 Feb 2024 06:15:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09179v2</guid></item><item><title>LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks</title><link>http://arxiv.org/abs/2402.11455v1</link><description>LoRA employs lightweight modules to customize large language models (LLMs)for each downstream task or domain, where different learned additional modulesrepresent diverse skills. Combining existing LoRAs to address new tasks canenhance the reusability of learned LoRAs, particularly beneficial for taskswith limited annotated data. Most prior works on LoRA combination primarilyrely on task-level weights for each involved LoRA, making different examplesand tokens share the same LoRA weights. However, in generative tasks, differenttokens may necessitate diverse skills to manage. Taking the Chinese math taskas an example, understanding the problem description may depend more on theChinese LoRA, while the calculation part may rely more on the math LoRA. Tothis end, we propose LoRA-Flow, which utilizes dynamic weights to adjust theimpact of different LoRAs. The weights at each step are determined by a fusiongate with extremely few parameters, which can be learned with only 200 trainingexamples. Experiments across six generative tasks demonstrate that our methodconsistently outperforms baselines with task-level fusion weights. Thisunderscores the necessity of introducing dynamic fusion weights for LoRAcombination.</description><author>Hanqing Wang, Bowen Ping, Shuo Wang, Xu Han, Yun Chen, Zhiyuan Liu, Maosong Sun</author><pubDate>Sun, 18 Feb 2024 04:41:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11455v1</guid></item><item><title>Nyonic Technical Report</title><link>http://arxiv.org/abs/2404.15702v1</link><description>This report details the development and key achievements of our latestlanguage model designed for custom large language models. The advancementsintroduced include a novel Online Data Scheduler that supports flexibletraining data adjustments and curriculum learning. The model's architecture isfortified with state-of-the-art techniques such as Rotary PositionalEmbeddings, QK-LayerNorm, and a specially crafted multilingual tokenizer toenhance stability and performance. Moreover, our robust training frameworkincorporates advanced monitoring and rapid recovery features to ensure optimalefficiency. Our Wonton 7B model has demonstrated competitive performance on arange of multilingual and English benchmarks. Future developments willprioritize narrowing the performance gap with more extensively trained models,thereby enhancing the model's real-world efficacy and adaptability.GitHub:\url{https://github.com/nyonicai/nyonic-public}</description><author>Junfeng Tian, Rui Wang, Cong Li, Yudong Zhou, Jun Liu, Jun Wang</author><pubDate>Wed, 24 Apr 2024 08:38:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15702v1</guid></item><item><title>Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks</title><link>http://arxiv.org/abs/2403.02238v1</link><description>The integration of Machine Learning and Artificial Intelligence (ML/AI) intofifth-generation (5G) networks has made evident the limitations of networkintelligence with ever-increasing, strenuous requirements for current andnext-generation devices. This transition to ubiquitous intelligence demandshigh connectivity, synchronicity, and end-to-end communication between usersand network operators, and will pave the way towards full network automationwithout human intervention. Intent-based networking is a key factor in thereduction of human actions, roles, and responsibilities while shifting towardsnovel extraction and interpretation of automated network management. This paperpresents the development of a custom Large Language Model (LLM) for 5G andnext-generation intent-based networking and provides insights into future LLMdevelopments and integrations to realize end-to-end intent-based networking forfully automated network intelligence.</description><author>Dimitrios Michael Manias, Ali Chouman, Abdallah Shami</author><pubDate>Mon, 04 Mar 2024 17:29:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02238v1</guid></item><item><title>Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks</title><link>http://arxiv.org/abs/2403.02238v2</link><description>The integration of Machine Learning and Artificial Intelligence (ML/AI) intofifth-generation (5G) networks has made evident the limitations of networkintelligence with ever-increasing, strenuous requirements for current andnext-generation devices. This transition to ubiquitous intelligence demandshigh connectivity, synchronicity, and end-to-end communication between usersand network operators, and will pave the way towards full network automationwithout human intervention. Intent-based networking is a key factor in thereduction of human actions, roles, and responsibilities while shifting towardsnovel extraction and interpretation of automated network management. This paperpresents the development of a custom Large Language Model (LLM) for 5G andnext-generation intent-based networking and provides insights into future LLMdevelopments and integrations to realize end-to-end intent-based networking forfully automated network intelligence.</description><author>Dimitrios Michael Manias, Ali Chouman, Abdallah Shami</author><pubDate>Wed, 22 May 2024 14:34:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02238v2</guid></item><item><title>Instruction Backdoor Attacks Against Customized LLMs</title><link>http://arxiv.org/abs/2402.09179v3</link><description>The increasing demand for customized Large Language Models (LLMs) has led tothe development of solutions like GPTs. These solutions facilitate tailored LLMcreation via natural language prompts without coding. However, thetrustworthiness of third-party custom versions of LLMs remains an essentialconcern. In this paper, we propose the first instruction backdoor attacksagainst applications integrated with untrusted customized LLMs (e.g., GPTs).Specifically, these attacks embed the backdoor into the custom version of LLMsby designing prompts with backdoor instructions, outputting the attacker'sdesired result when inputs contain the pre-defined triggers. Our attackincludes 3 levels of attacks: word-level, syntax-level, and semantic-level,which adopt different types of triggers with progressive stealthiness. Westress that our attacks do not require fine-tuning or any modification to thebackend LLMs, adhering strictly to GPTs development guidelines. We conductextensive experiments on 6 prominent LLMs and 5 benchmark text classificationdatasets. The results show that our instruction backdoor attacks achieve thedesired attack performance without compromising utility. Additionally, wepropose two defense strategies and demonstrate their effectiveness in reducingsuch attacks. Our findings highlight the vulnerability and the potential risksof LLM customization such as GPTs.</description><author>Rui Zhang, Hongwei Li, Rui Wen, Wenbo Jiang, Yuan Zhang, Michael Backes, Yun Shen, Yang Zhang</author><pubDate>Tue, 28 May 2024 12:36:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09179v3</guid></item><item><title>Generative AI in the Construction Industry: A State-of-the-art Analysis</title><link>http://arxiv.org/abs/2402.09939v1</link><description>The construction industry is a vital sector of the global economy, but itfaces many productivity challenges in various processes, such as design,planning, procurement, inspection, and maintenance. Generative artificialintelligence (AI), which can create novel and realistic data or content, suchas text, image, video, or code, based on some input or prior knowledge, offersinnovative and disruptive solutions to address these challenges. However, thereis a gap in the literature on the current state, opportunities, and challengesof generative AI in the construction industry. This study aims to fill this gapby providing a state-of-the-art analysis of generative AI in construction, withthree objectives: (1) to review and categorize the existing and emerginggenerative AI opportunities and challenges in the construction industry; (2) topropose a framework for construction firms to build customized generative AIsolutions using their own data, comprising steps such as data collection,dataset curation, training custom large language model (LLM), model evaluation,and deployment; and (3) to demonstrate the framework via a case study ofdeveloping a generative model for querying contract documents. The results showthat retrieval augmented generation (RAG) improves the baseline LLM by 5.2,9.4, and 4.8% in terms of quality, relevance, and reproducibility. This studyprovides academics and construction professionals with a comprehensive analysisand practical framework to guide the adoption of generative AI techniques toenhance productivity, quality, safety, and sustainability across theconstruction industry.</description><author>Ridwan Taiwo, Idris Temitope Bello, Sulemana Fatoama Abdulai, Abdul-Mugis Yussif, Babatunde Abiodun Salami, Abdullahi Saka, Tarek Zayed</author><pubDate>Thu, 15 Feb 2024 13:39:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09939v1</guid></item><item><title>Prompt Engineering a Prompt Engineer</title><link>http://arxiv.org/abs/2311.05661v2</link><description>Prompt engineering is a challenging yet crucial task for optimizing theperformance of large language models on customized tasks. It requires complexreasoning to examine the model's errors, hypothesize what is missing ormisleading in the current prompt, and communicate the task with clarity. Whilerecent works indicate that large language models can be meta-prompted toperform automatic prompt engineering, we argue that their potential is limiteddue to insufficient guidance for complex reasoning in the meta-prompt. We fillthis gap by infusing into the meta-prompt three key components: detaileddescriptions, context specification, and a step-by-step reasoning template. Theresulting method, named PE2, showcases remarkable versatility across diverselanguage tasks. It finds prompts that outperform "let's think step by step" by6.3% on MultiArith and 3.1% on GSM8K, and outperforms competitive baselines oncounterfactual tasks by 6.9%. Further, we show that PE2 can make targetedprompt edits, rectify erroneous prompts, and induce multi-step plans forcomplex tasks.</description><author>Qinyuan Ye, Maxamed Axmed, Reid Pryzant, Fereshte Khani</author><pubDate>Mon, 19 Feb 2024 19:46:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05661v2</guid></item><item><title>CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models</title><link>http://arxiv.org/abs/2402.15265v1</link><description>Large language models (LLMs) have facilitated significant strides ingenerating conversational agents, enabling seamless, contextually relevantdialogues across diverse topics. However, the existing LLM-drivenconversational agents have fixed personalities and functionalities, limitingtheir adaptability to individual user needs. Creating personalized agentpersonas with distinct expertise or traits can address this issue. Nonetheless,we lack knowledge of how people customize and interact with agent personas. Inthis research, we investigated how users customize agent personas and theirimpact on interaction quality, diversity, and dynamics. To this end, wedeveloped CloChat, an interface supporting easy and accurate customization ofagent personas in LLMs. We conducted a study comparing how participantsinteract with CloChat and ChatGPT. The results indicate that participantsformed emotional bonds with the customized agents, engaged in more dynamicdialogues, and showed interest in sustaining interactions. These findingscontribute to design implications for future systems with conversational agentsusing LLMs.</description><author>Juhye Ha, Hyeon Jeon, DaEun Han, Jinwook Seo, Changhoon Oh</author><pubDate>Fri, 23 Feb 2024 11:25:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15265v1</guid></item><item><title>Automating Customer Needs Analysis: A Comparative Study of Large Language Models in the Travel Industry</title><link>http://arxiv.org/abs/2404.17975v1</link><description>In the rapidly evolving landscape of Natural Language Processing (NLP), LargeLanguage Models (LLMs) have emerged as powerful tools for many tasks, such asextracting valuable insights from vast amounts of textual data. In this study,we conduct a comparative analysis of LLMs for the extraction of travel customerneeds from TripAdvisor posts. Leveraging a diverse range of models, includingboth open-source and proprietary ones such as GPT-4 and Gemini, we aim toelucidate their strengths and weaknesses in this specialized domain. Through anevaluation process involving metrics such as BERTScore, ROUGE, and BLEU, weassess the performance of each model in accurately identifying and summarizingcustomer needs. Our findings highlight the efficacy of opensource LLMs,particularly Mistral 7B, in achieving comparable performance to larger closedmodels while offering affordability and customization benefits. Additionally,we underscore the importance of considering factors such as model size,resource requirements, and performance metrics when selecting the most suitableLLM for customer needs analysis tasks. Overall, this study contributes valuableinsights for businesses seeking to leverage advanced NLP techniques to enhancecustomer experience and drive operational efficiency in the travel industry.</description><author>Simone Barandoni, Filippo Chiarello, Lorenzo Cascone, Emiliano Marrale, Salvatore Puccio</author><pubDate>Sat, 27 Apr 2024 19:28:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17975v1</guid></item><item><title>Concerns on Bias in Large Language Models when Creating Synthetic Personae</title><link>http://arxiv.org/abs/2405.05080v1</link><description>This position paper explores the benefits, drawbacks, and ethicalconsiderations of incorporating synthetic personae in HCI research,particularly focusing on the customization challenges beyond the limitations ofcurrent Large Language Models (LLMs). These perspectives are derived from theinitial results of a sub-study employing vignettes to showcase the existence ofbias within black-box LLMs and explore methods for manipulating them. The studyaims to establish a foundation for understanding the challenges associated withthese models, emphasizing the necessity of thorough testing before utilizingthem to create synthetic personae for HCI research.</description><author>Helena A. Haxvig</author><pubDate>Wed, 08 May 2024 15:24:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05080v1</guid></item><item><title>Customization Assistant for Text-to-image Generation</title><link>http://arxiv.org/abs/2312.03045v2</link><description>Customizing pre-trained text-to-image generation model has attracted massiveresearch interest recently, due to its huge potential in real-worldapplications. Although existing methods are able to generate creative contentfor a novel concept contained in single user-input image, their capability arestill far from perfection. Specifically, most existing methods requirefine-tuning the generative model on testing images. Some existing methods donot require fine-tuning, while their performance are unsatisfactory.Furthermore, the interaction between users and models are still limited todirective and descriptive prompts such as instructions and captions. In thiswork, we build a customization assistant based on pre-trained large languagemodel and diffusion model, which can not only perform customized generation ina tuning-free manner, but also enable more user-friendly interactions: userscan chat with the assistant and input either ambiguous text or clearinstruction. Specifically, we propose a new framework consists of a new modeldesign and a novel training strategy. The resulting assistant can performcustomized generation in 2-5 seconds without any test time fine-tuning.Extensive experiments are conducted, competitive results have been obtainedacross different domains, illustrating the effectiveness of the proposedmethod.</description><author>Yufan Zhou, Ruiyi Zhang, Jiuxiang Gu, Tong Sun</author><pubDate>Wed, 08 May 2024 22:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03045v2</guid></item><item><title>Customizing Language Model Responses with Contrastive In-Context Learning</title><link>http://arxiv.org/abs/2401.17390v2</link><description>Large language models (LLMs) are becoming increasingly important for machinelearning applications. However, it can be challenging to align LLMs with ourintent, particularly when we want to generate content that is preferable overothers or when we want the LLM to respond in a certain style or tone that ishard to describe. To address this challenge, we propose an approach that usescontrastive examples to better describe our intent. This involves providingpositive examples that illustrate the true intent, along with negative examplesthat show what characteristics we want LLMs to avoid. The negative examples canbe retrieved from labeled data, written by a human, or generated by the LLMitself. Before generating an answer, we ask the model to analyze the examplesto teach itself what to avoid. This reasoning step provides the model with theappropriate articulation of the user's need and guides it towards generting abetter answer. We tested our approach on both synthesized and real-worlddatasets, including StackExchange and Reddit, and found that it significantlyimproves performance compared to standard few-shot prompting</description><author>Xiang Gao, Kamalika Das</author><pubDate>Mon, 08 Apr 2024 06:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17390v2</guid></item><item><title>Driving Everywhere with Large Language Model Policy Adaptation</title><link>http://arxiv.org/abs/2402.05932v2</link><description>Adapting driving behavior to new environments, customs, and laws is along-standing problem in autonomous driving, precluding the widespreaddeployment of autonomous vehicles (AVs). In this paper, we present LLaDA, asimple yet powerful tool that enables human drivers and autonomous vehiclesalike to drive everywhere by adapting their tasks and motion plans to trafficrules in new locations. LLaDA achieves this by leveraging the impressivezero-shot generalizability of large language models (LLMs) in interpreting thetraffic rules in the local driver handbook. Through an extensive user study, weshow that LLaDA's instructions are useful in disambiguating in-the-wildunexpected situations. We also demonstrate LLaDA's ability to adapt AV motionplanning policies in real-world datasets; LLaDA outperforms baseline planningapproaches on all our metrics. Please check our website for more details:https://boyiliee.github.io/llada.</description><author>Boyi Li, Yue Wang, Jiageng Mao, Boris Ivanovic, Sushant Veer, Karen Leung, Marco Pavone</author><pubDate>Thu, 11 Apr 2024 00:29:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05932v2</guid></item><item><title>ChipNeMo: Domain-Adapted LLMs for Chip Design</title><link>http://arxiv.org/abs/2311.00176v5</link><description>ChipNeMo aims to explore the applications of large language models (LLMs) forindustrial chip design. Instead of directly deploying off-the-shelf commercialor open-source LLMs, we instead adopt the following domain adaptationtechniques: domain-adaptive tokenization, domain-adaptive continuedpretraining, model alignment with domain-specific instructions, anddomain-adapted retrieval models. We evaluate these methods on three selectedLLM applications for chip design: an engineering assistant chatbot, EDA scriptgeneration, and bug summarization and analysis. Our evaluations demonstratethat domain-adaptive pretraining of language models, can lead to superiorperformance in domain related downstream tasks compared to their base LLaMA2counterparts, without degradations in generic capabilities. In particular, ourlargest model, ChipNeMo-70B, outperforms the highly capable GPT-4 on two of ouruse cases, namely engineering assistant chatbot and EDA scripts generation,while exhibiting competitive performance on bug summarization and analysis.These results underscore the potential of domain-specific customization forenhancing the effectiveness of large language models in specializedapplications.</description><author>Mingjie Liu, Teodor-Dumitru Ene, Robert Kirby, Chris Cheng, Nathaniel Pinckney, Rongjian Liang, Jonah Alben, Himyanshu Anand, Sanmitra Banerjee, Ismet Bayraktaroglu, Bonita Bhaskaran, Bryan Catanzaro, Arjun Chaudhuri, Sharon Clay, Bill Dally, Laura Dang, Parikshit Deshpande, Siddhanth Dhodhi, Sameer Halepete, Eric Hill, Jiashang Hu, Sumit Jain, Ankit Jindal, Brucek Khailany, George Kokai, Kishor Kunal, Xiaowei Li, Charley Lind, Hao Liu, Stuart Oberman, Sujeet Omar, Ghasem Pasandi, Sreedhar Pratty, Jonathan Raiman, Ambar Sarkar, Zhengjiang Shao, Hanfei Sun, Pratik P Suthar, Varun Tej, Walker Turner, Kaizhe Xu, Haoxing Ren</author><pubDate>Thu, 04 Apr 2024 21:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00176v5</guid></item><item><title>ChipNeMo: Domain-Adapted LLMs for Chip Design</title><link>http://arxiv.org/abs/2311.00176v4</link><description>ChipNeMo aims to explore the applications of large language models (LLMs) forindustrial chip design. Instead of directly deploying off-the-shelf commercialor open-source LLMs, we instead adopt the following domain adaptationtechniques: domain-adaptive tokenization, domain-adaptive continuedpretraining, model alignment with domain-specific instructions, anddomain-adapted retrieval models. We evaluate these methods on three selectedLLM applications for chip design: an engineering assistant chatbot, EDA scriptgeneration, and bug summarization and analysis. Our evaluations demonstratethat domain-adaptive pretraining of language models, can lead to superiorperformance in domain related downstream tasks compared to their base LLaMA2counterparts, without degradations in generic capabilities. In particular, ourlargest model, ChipNeMo-70B, outperforms the highly capable GPT-4 on two of ouruse cases, namely engineering assistant chatbot and EDA scripts generation,while exhibiting competitive performance on bug summarization and analysis.These results underscore the potential of domain-specific customization forenhancing the effectiveness of large language models in specializedapplications.</description><author>Mingjie Liu, Teodor-Dumitru Ene, Robert Kirby, Chris Cheng, Nathaniel Pinckney, Rongjian Liang, Jonah Alben, Himyanshu Anand, Sanmitra Banerjee, Ismet Bayraktaroglu, Bonita Bhaskaran, Bryan Catanzaro, Arjun Chaudhuri, Sharon Clay, Bill Dally, Laura Dang, Parikshit Deshpande, Siddhanth Dhodhi, Sameer Halepete, Eric Hill, Jiashang Hu, Sumit Jain, Ankit Jindal, Brucek Khailany, George Kokai, Kishor Kunal, Xiaowei Li, Charley Lind, Hao Liu, Stuart Oberman, Sujeet Omar, Sreedhar Pratty, Jonathan Raiman, Ambar Sarkar, Zhengjiang Shao, Hanfei Sun, Pratik P Suthar, Varun Tej, Walker Turner, Kaizhe Xu, Haoxing Ren</author><pubDate>Thu, 07 Mar 2024 01:10:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00176v4</guid></item><item><title>"Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time</title><link>http://arxiv.org/abs/2405.00801v2</link><description>Customer service is how companies interface with their customers. It cancontribute heavily towards the overall customer satisfaction. However,high-quality service can become expensive, creating an incentive to make it ascost efficient as possible and prompting most companies to utilize AI-poweredassistants, or "chat bots". On the other hand, human-to-human interaction isstill desired by customers, especially when it comes to complex scenarios suchas disputes and sensitive topics like bill payment. This raises the bar for customer service agents. They need to accuratelyunderstand the customer's question or concern, identify a solution that isacceptable yet feasible (and within the company's policy), all while handlingmultiple conversations at once. In this work, we introduce "Ask Me Anything" (AMA) as an add-on feature to anagent-facing customer service interface. AMA allows agents to ask questions toa large language model (LLM) on demand, as they are handling customerconversations -- the LLM provides accurate responses in real-time, reducing theamount of context switching the agent needs. In our internal experiments, wefind that agents using AMA versus a traditional search experience spendapproximately 10% fewer seconds per conversation containing a search,translating to millions of dollars of savings annually. Agents that used theAMA feature provided positive feedback nearly 80% of the time, demonstratingits usefulness as an AI-assisted feature for customer care.</description><author>Scott Rome, Tianwen Chen, Raphael Tang, Luwei Zhou, Ferhan Ture</author><pubDate>Mon, 06 May 2024 17:15:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00801v2</guid></item><item><title>"Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time</title><link>http://arxiv.org/abs/2405.00801v1</link><description>Customer service is how companies interface with their customers. It cancontribute heavily towards the overall customer satisfaction. However,high-quality service can become expensive, creating an incentive to make it ascost efficient as possible and prompting most companies to utilize AI-poweredassistants, or "chat bots". On the other hand, human-to-human interaction isstill desired by customers, especially when it comes to complex scenarios suchas disputes and sensitive topics like bill payment. This raises the bar for customer service agents. They need to accuratelyunderstand the customer's question or concern, identify a solution that isacceptable yet feasible (and within the company's policy), all while handlingmultiple conversations at once. In this work, we introduce "Ask Me Anything" (AMA) as an add-on feature to anagent-facing customer service interface. AMA allows agents to ask questions toa large language model (LLM) on demand, as they are handling customerconversations -- the LLM provides accurate responses in real-time, reducing theamount of context switching the agent needs. In our internal experiments, wefind that agents using AMA versus a traditional search experience spendapproximately 10% fewer seconds per conversation containing a search,translating to millions of dollars of savings annually. Agents that used theAMA feature provided positive feedback nearly 80% of the time, demonstratingits usefulness as an AI-assisted feature for customer care.</description><author>Scott Rome, Tianwen Chen, Raphael Tang, Luwei Zhou, Ferhan Ture</author><pubDate>Wed, 01 May 2024 19:31:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00801v1</guid></item><item><title>Layout Generation Agents with Large Language Models</title><link>http://arxiv.org/abs/2405.08037v1</link><description>In recent years, there has been an increasing demand for customizable 3Dvirtual spaces. Due to the significant human effort required to create thesevirtual spaces, there is a need for efficiency in virtual space creation. Whileexisting studies have proposed methods for automatically generating layoutssuch as floor plans and furniture arrangements, these methods only generatetext indicating the layout structure based on user instructions, withoututilizing the information obtained during the generation process. In thisstudy, we propose an agent-driven layout generation system using the GPT-4Vmultimodal large language model and validate its effectiveness. Specifically,the language model manipulates agents to sequentially place objects in thevirtual space, thus generating layouts that reflect user instructions.Experimental results confirm that our proposed method can generate virtualspaces reflecting user instructions with a high success rate. Additionally, wesuccessfully identified elements contributing to the improvement in behaviorgeneration performance through ablation study.</description><author>Yuichi Sasazawa, Yasuhiro Sogawa</author><pubDate>Mon, 13 May 2024 07:27:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08037v1</guid></item><item><title>ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors</title><link>http://arxiv.org/abs/2402.16444v1</link><description>The safety of Large Language Models (LLMs) has gained increasing attention inrecent years, but there still lacks a comprehensive approach for detectingsafety issues within LLMs' responses in an aligned, customizable andexplainable manner. In this paper, we propose ShieldLM, an LLM-based safetydetector, which aligns with general human safety standards, supportscustomizable detection rules, and provides explanations for its decisions. Totrain ShieldLM, we compile a large bilingual dataset comprising 14,387query-response pairs, annotating the safety of responses based on varioussafety standards. Through extensive experiments, we demonstrate that ShieldLMsurpasses strong baselines across four test sets, showcasing remarkablecustomizability and explainability. Besides performing well on standarddetection datasets, ShieldLM has also been shown to be effective in real-worldsituations as a safety evaluator for advanced LLMs. We release ShieldLM at\url{https://github.com/thu-coai/ShieldLM} to support accurate and explainablesafety detection under various safety standards, contributing to the ongoingefforts to enhance the safety of LLMs.</description><author>Zhexin Zhang, Yida Lu, Jingyuan Ma, Di Zhang, Rui Li, Pei Ke, Hao Sun, Lei Sha, Zhifang Sui, Hongning Wang, Minlie Huang</author><pubDate>Mon, 26 Feb 2024 09:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16444v1</guid></item><item><title>Evaluating Large Language Models in Theory of Mind Tasks</title><link>http://arxiv.org/abs/2302.02083v6</link><description>Eleven Large Language Models (LLMs) were assessed using a custom-made batteryof false-belief tasks, considered a gold standard in testing Theory of Mind(ToM) in humans. The battery included 640 prompts spread across 40 diversetasks, each one including a false-belief scenario, three closely matchedtrue-belief control scenarios, and the reversed versions of all four. To solvea single task, a model needed to correctly answer 16 prompts across all eightscenarios. Smaller and older models solved no tasks; GPT-3-davinci-003 (fromNovember 2022) and ChatGPT-3.5-turbo (from March 2023) solved 20% of the tasks;ChatGPT-4 (from June 2023) solved 75% of the tasks, matching the performance ofsix-year-old children observed in past studies. We explore the potentialinterpretation of these findings, including the intriguing possibility thatToM, previously considered exclusive to humans, may have spontaneously emergedas a byproduct of LLMs' improving language skills.</description><author>Michal Kosinski</author><pubDate>Sat, 17 Feb 2024 02:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02083v6</guid></item><item><title>LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain</title><link>http://arxiv.org/abs/2402.14871v1</link><description>In the last years' digitalization process, the creation and management ofdocuments in various domains, particularly in Public Administration (PA), havebecome increasingly complex and diverse. This complexity arises from the needto handle a wide range of document types, often characterized bysemi-structured forms. Semi-structured documents present a fixed set of datawithout a fixed format. As a consequence, a template-based solution cannot beused, as understanding a document requires the extraction of the datastructure. The recent introduction of Large Language Models (LLMs) has enabledthe creation of customized text output satisfying user requests. In this work,we propose a novel approach that combines the LLMs with prompt engineering andmulti-agent systems for generating new documents compliant with a desiredstructure. The main contribution of this work concerns replacing the commonlyused manual prompting with a task description generated by semantic retrievalfrom an LLM. The potential of this approach is demonstrated through a series ofexperiments and case studies, showcasing its effectiveness in real-world PAscenarios.</description><author>Emanuele Musumeci, Michele Brienza, Vincenzo Suriani, Daniele Nardi, Domenico Daniele Bloisi</author><pubDate>Wed, 21 Feb 2024 13:54:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14871v1</guid></item><item><title>Controlled Text Generation via Language Model Arithmetic</title><link>http://arxiv.org/abs/2311.14479v2</link><description>As Large Language Models (LLMs) are deployed more widely, customization withrespect to vocabulary, style, and character becomes more important. In thiswork, we introduce model arithmetic, a novel inference framework for composingand biasing LLMs without the need for model (re)training or highly specificdatasets. In addition, the framework allows for more precise control ofgenerated text than direct prompting and prior controlled text generation (CTG)techniques. Using model arithmetic, we can express prior CTG techniques assimple formulas and naturally extend them to new and more effectiveformulations. Further, we show that speculative sampling, a technique forefficient LLM sampling, extends to our setting. This enables highly efficienttext generation with multiple composed models with only marginal overhead overa single model. Our empirical evaluation demonstrates that model arithmeticallows fine-grained control of generated text while outperformingstate-of-the-art on the task of toxicity reduction. We release an open sourceeasy-to-use implementation of our framework athttps://github.com/eth-sri/language-model-arithmetic.</description><author>Jasper Dekoninck, Marc Fischer, Luca Beurer-Kellner, Martin Vechev</author><pubDate>Wed, 06 Mar 2024 09:36:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14479v2</guid></item><item><title>A Large Language Model-based multi-agent manufacturing system for intelligent shopfloor</title><link>http://arxiv.org/abs/2405.16887v1</link><description>As productivity advances, the demand of customers for multi-variety andsmall-batch production is increasing, thereby putting forward higherrequirements for manufacturing systems. When production tasks frequent changesdue to this demand, traditional manufacturing systems often cannot responsepromptly. The multi-agent manufacturing system is proposed to address thisproblem. However, because of technical limitations, the negotiation amongagents in this kind of system is realized through predefined heuristic rules,which is not intelligent enough to deal with the multi-variety and small batchproduction. To this end, a Large Language Model-based (LLM-based) multi-agentmanufacturing system for intelligent shopfloor is proposed in the presentstudy. This system delineates the diverse agents and defines theircollaborative methods. The roles of the agents encompass Machine Server Agent(MSA), Bid Inviter Agent (BIA), Bidder Agent (BA), Thinking Agent (TA), andDecision Agent (DA). Due to the support of LLMs, TA and DA acquire the abilityof analyzing the shopfloor condition and choosing the most suitable machine, asopposed to executing a predefined program artificially. The negotiation betweenBAs and BIA is the most crucial step in connecting manufacturing resources.With the support of TA and DA, BIA will finalize the distribution of orders,relying on the information of each machine returned by BA. MSAs bears theresponsibility for connecting the agents with the physical shopfloor. Thissystem aims to distribute and transmit workpieces through the collaboration ofthe agents with these distinct roles, distinguishing it from other schedulingapproaches. Comparative experiments were also conducted to validate theperformance of this system.</description><author>Zhen Zhao, Dunbing Tang, Haihua Zhu, Zequn Zhang, Kai Chen, Changchun Liu, Yuchen Ji</author><pubDate>Mon, 27 May 2024 08:10:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16887v1</guid></item><item><title>Large Language Models meet Network Slicing Management and Orchestration</title><link>http://arxiv.org/abs/2403.13721v1</link><description>Network slicing, a cornerstone technology for future networks, enables thecreation of customized virtual networks on a shared physical infrastructure.This fosters innovation and agility by providing dedicated resources tailoredto specific applications. However, current orchestration and managementapproaches face limitations in handling the complexity of new service demandswithin multi-administrative domain environments. This paper proposes a futurevision for network slicing powered by Large Language Models (LLMs) andmulti-agent systems, offering a framework that can be integrated with existingManagement and Orchestration (MANO) frameworks. This framework leverages LLMsto translate user intent into technical requirements, map network functions toinfrastructure, and manage the entire slice lifecycle, while multi-agentsystems facilitate collaboration across different administrative domains. Wealso discuss the challenges associated with implementing this framework andpotential solutions to mitigate them.</description><author>Abdulhalim Dandoush, Viswanath Kumarskandpriya, Mueen Uddin, Usman Khalil</author><pubDate>Wed, 20 Mar 2024 17:29:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13721v1</guid></item><item><title>Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement</title><link>http://arxiv.org/abs/2403.03188v1</link><description>Real-time flood forecasting plays a crucial role in enabling timely andeffective emergency responses. However, a significant challenge lies inbridging the gap between complex numerical flood models and practicaldecision-making. Decision-makers often rely on experts to interpret thesemodels for optimizing flood mitigation strategies. And the public requirescomplex techniques to inquiry and understand socio-cultural and institutionalfactors, often hinders the public's understanding of flood risks. To overcomethese challenges, our study introduces an innovative solution: a customized AIAssistant powered by the GPT-4 Large Language Model. This AI Assistant isdesigned to facilitate effective communication between decision-makers, thegeneral public, and flood forecasters, without the requirement of specializedknowledge. The new framework utilizes GPT-4's advanced natural languageunderstanding and function calling capabilities to provide immediate floodalerts and respond to various flood-related inquiries. Our developed prototypeintegrates real-time flood warnings with flood maps and social vulnerabilitydata. It also effectively translates complex flood zone information intoactionable risk management advice. To assess its performance, we evaluated theprototype using six criteria within three main categories: relevance, errorresilience, and understanding of context. Our research marks a significant steptowards a more accessible and user-friendly approach in flood risk management.This study highlights the potential of advanced AI tools like GPT-4 indemocratizing information and enhancing public engagement in critical socialand environmental issues.</description><author>Rafaela Martelo, Ruo-Qian Wang</author><pubDate>Tue, 05 Mar 2024 18:24:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03188v1</guid></item><item><title>CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets</title><link>http://arxiv.org/abs/2309.17428v2</link><description>Large language models (LLMs) are often augmented with tools to solve complextasks. By generating code snippets and executing them through task-specificApplication Programming Interfaces (APIs), they can offload certain functionsto dedicated external modules, such as image encoding and performingcalculations. However, most existing approaches to augment LLMs with tools areconstrained by general-purpose APIs and lack the flexibility for tailoring themto specific tasks. In this work, we present CRAFT, a general tool creation andretrieval framework for LLMs. It creates toolsets specifically curated for thetasks and equips LLMs with a component that retrieves tools from these sets toenhance their capability to solve complex tasks. For each task, we collectspecific code solutions by prompting GPT-4 to solve the training examples.Following a validation step ensuring the correctness, these solutions areabstracted into code snippets to enhance reusability, and deduplicated forhigher quality. At inference time, the language model retrieves snippets fromthe toolsets and then executes them or generates the output conditioning on theretrieved snippets. Our method is designed to be flexible and offers aplug-and-play approach to adapt off-the-shelf LLMs to unseen domains andmodalities, without any finetuning. Experiments on vision-language, tabularprocessing, and mathematical reasoning tasks show that our approach achievessubstantial improvements compared to strong baselines. In addition, ourin-depth analysis reveals that: (1) consistent performance improvement can beachieved by scaling up the number of tools and the capability of the backbonemodels; (2) each component of our approach contributes to the performancegains; (3) the created tools are well-structured and reliable with lowcomplexity and atomicity. The code is available athttps://github.com/lifan-yuan/CRAFT.</description><author>Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R. Fung, Hao Peng, Heng Ji</author><pubDate>Wed, 13 Mar 2024 06:39:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17428v2</guid></item><item><title>Self-Improving Customer Review Response Generation Based on LLMs</title><link>http://arxiv.org/abs/2405.03845v1</link><description>Previous studies have demonstrated that proactive interaction with userreviews has a positive impact on the perception of app users and encouragesthem to submit revised ratings. Nevertheless, developers encounter challengesin managing a high volume of reviews, particularly in the case of popular appswith a substantial influx of daily reviews. Consequently, there is a demand forautomated solutions aimed at streamlining the process of responding to userreviews. To address this, we have developed a new system for generatingautomatic responses by leveraging user-contributed documents with the help ofretrieval-augmented generation (RAG) and advanced Large Language Models (LLMs).Our solution, named SCRABLE, represents an adaptive customer review responseautomation that enhances itself with self-optimizing prompts and a judgingmechanism based on LLMs. Additionally, we introduce an automatic scoringmechanism that mimics the role of a human evaluator to assess the quality ofresponses generated in customer review domains. Extensive experiments andanalyses conducted on real-world datasets reveal that our method is effectivein producing high-quality responses, yielding improvement of more than 8.5%compared to the baseline. Further validation through manual examination of thegenerated responses underscores the efficacy our proposed system.</description><author>Guy Azov, Tatiana Pelc, Adi Fledel Alon, Gila Kamhi</author><pubDate>Mon, 06 May 2024 21:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03845v1</guid></item><item><title>RLVF: Learning from Verbal Feedback without Overgeneralization</title><link>http://arxiv.org/abs/2402.10893v1</link><description>The diversity of contexts in which large language models (LLMs) are deployedrequires the ability to modify or customize default model behaviors toincorporate nuanced requirements and preferences. A convenient interface tospecify such model adjustments is high-level verbal feedback, such as "Don'tuse emojis when drafting emails to my boss." However, while writing high-levelfeedback is far simpler than collecting annotations for reinforcement learningfrom human feedback (RLHF), we find that simply prompting a model with suchfeedback leads to overgeneralization of the feedback to contexts where it isnot relevant. We study the problem of incorporating verbal feedback withoutsuch overgeneralization, inspiring a new method Contextualized Critiques withConstrained Preference Optimization (C3PO). C3PO uses a piece of high-levelfeedback to generate a small synthetic preference dataset specifying how thefeedback should (and should not) be applied. It then fine-tunes the model inaccordance with the synthetic preference data while minimizing the divergencefrom the original model for prompts where the feedback does not apply. Ourexperimental results indicate that our approach effectively applies verbalfeedback to relevant scenarios while preserving existing behaviors for othercontexts. For both human- and GPT-4-generated high-level feedback, C3POeffectively adheres to the given feedback comparably to in-context baselineswhile reducing overgeneralization by 30%.</description><author>Moritz Stephan, Alexander Khazatsky, Eric Mitchell, Annie S Chen, Sheryl Hsu, Archit Sharma, Chelsea Finn</author><pubDate>Fri, 16 Feb 2024 18:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10893v1</guid></item><item><title>CleanAgent: Automating Data Standardization with LLM-based Agents</title><link>http://arxiv.org/abs/2403.08291v2</link><description>Data standardization is a crucial part in data science life cycle. Whiletools like Pandas offer robust functionalities, their complexity and the manualeffort required for customizing code to diverse column types pose significantchallenges. Although large language models (LLMs) like ChatGPT have shownpromise in automating this process through natural language understanding andcode generation, it still demands expert-level programming knowledge andcontinuous interaction for prompt refinement. To solve these challenges, ourkey idea is to propose a Python library with declarative, unified APIs forstandardizing column types, simplifying the code generation of LLM with conciseAPI calls. We first propose Dataprep.Clean which is written as a component ofthe Dataprep Library, offers a significant reduction in complexity by enablingthe standardization of specific column types with a single line of code. Thenwe introduce the CleanAgent framework integrating Dataprep.Clean and LLM-basedagents to automate the data standardization process. With CleanAgent, datascientists need only provide their requirements once, allowing for ahands-free, automatic standardization process.</description><author>Danrui Qi, Jiannan Wang</author><pubDate>Thu, 25 Apr 2024 04:47:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08291v2</guid></item><item><title>CleanAgent: Automating Data Standardization with LLM-based Agents</title><link>http://arxiv.org/abs/2403.08291v1</link><description>Data standardization is a crucial part in data science life cycle. Whiletools like Pandas offer robust functionalities, their complexity and the manualeffort required for customizing code to diverse column types pose significantchallenges. Although large language models (LLMs) like ChatGPT have shownpromise in automating this process through natural language understanding andcode generation, it still demands expert-level programming knowledge andcontinuous interaction for prompt refinement. To solve these challenges, ourkey idea is to propose a Python library with declarative, unified APIs forstandardizing column types, simplifying the code generation of LLM with conciseAPI calls. We first propose Dataprep.Clean which is written as a component ofthe Dataprep Library, offers a significant reduction in complexity by enablingthe standardization of specific column types with a single line of code. Thenwe introduce the CleanAgent framework integrating Dataprep.Clean and LLM-basedagents to automate the data standardization process. With CleanAgent, datascientists need only provide their requirements once, allowing for ahands-free, automatic standardization process.</description><author>Danrui Qi, Jiannan Wang</author><pubDate>Wed, 13 Mar 2024 07:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08291v1</guid></item><item><title>Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering</title><link>http://arxiv.org/abs/2404.17723v1</link><description>In customer service technical support, swiftly and accurately retrievingrelevant past issues is critical for efficiently resolving customer inquiries.The conventional retrieval methods in retrieval-augmented generation (RAG) forlarge language models (LLMs) treat a large corpus of past issue trackingtickets as plain text, ignoring the crucial intra-issue structure andinter-issue relations, which limits performance. We introduce a novel customerservice question-answering method that amalgamates RAG with a knowledge graph(KG). Our method constructs a KG from historical issues for use in retrieval,retaining the intra-issue structure and inter-issue relations. During thequestion-answering phase, our method parses consumer queries and retrievesrelated sub-graphs from the KG to generate answers. This integration of a KGnot only improves retrieval accuracy by preserving customer service structureinformation but also enhances answering quality by mitigating the effects oftext segmentation. Empirical assessments on our benchmark datasets, utilizingkey retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR)metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by0.32 in BLEU. Our method has been deployed within LinkedIn's customer serviceteam for approximately six months and has reduced the median per-issueresolution time by 28.6%.</description><author>Zhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang, Zheng Li</author><pubDate>Sat, 27 Apr 2024 00:05:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17723v1</guid></item><item><title>Plum: Prompt Learning using Metaheuristic</title><link>http://arxiv.org/abs/2311.08364v2</link><description>Since the emergence of large language models, prompt learning has become apopular method for optimizing and customizing these models. Special prompts,such as Chain-of-Thought, have even revealed previously unknown reasoningcapabilities within these models. However, the progress of discoveringeffective prompts has been slow, driving a desire for general promptoptimization methods. Unfortunately, few existing prompt learning methodssatisfy the criteria of being truly "general", i.e., automatic, discrete,black-box, gradient-free, and interpretable all at once. In this paper, weintroduce metaheuristics, a branch of discrete non-convex optimization methodswith over 100 options, as a promising approach to prompt learning. Within ourparadigm, we test six typical methods: hill climbing, simulated annealing,genetic algorithms with/without crossover, tabu search, and harmony search,demonstrating their effectiveness in white-box and black-box prompt learning.Furthermore, we show that these methods can be used to discover morehuman-understandable prompts that were previously unknown in both reasoning andimage generation tasks, opening the door to a cornucopia of possibilities inprompt optimization. We release all the codes in\url{https://github.com/research4pan/Plum}.</description><author>Rui Pan, Shuo Xing, Shizhe Diao, Wenhe Sun, Xiang Liu, Kashun Shum, Renjie Pi, Jipeng Zhang, Tong Zhang</author><pubDate>Thu, 14 Mar 2024 14:43:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08364v2</guid></item><item><title>VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks</title><link>http://arxiv.org/abs/2405.15179v1</link><description>As the adoption of large language models increases and the need for per-useror per-task model customization grows, the parameter-efficient fine-tuning(PEFT) methods, such as low-rank adaptation (LoRA) and its variants, incursubstantial storage and transmission costs. To further reduce storedparameters, we introduce a "divide-and-share" paradigm that breaks the barriersof low-rank decomposition across matrix dimensions, modules and layers bysharing parameters globally via a \textit{vector bank}. As an instantiation ofthe paradigm to LoRA, our proposed VB-LoRA composites \textit{all} the low-rankmatrices of LoRA from a shared \textit{vector bank} with a differentiabletop-$k$ admixture module. VB-LoRA achieves extreme parameter efficiency whilemaintaining comparable or better performance compared to state-of-the-art PEFTmethods. Extensive experiments demonstrate the effectiveness of VB-LoRA onnatural language understanding, natural language generation, and instructiontuning tasks. When fine-tuning the Llama2-13B model, VB-LoRA only uses 0.4\% ofLoRA's stored parameters yet attaining superior results. Our source code isavailable at \url{https://github.com/leo-yangli/VB-LoRA}.</description><author>Yang Li, Shaobo Han, Shihao Ji</author><pubDate>Fri, 24 May 2024 04:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15179v1</guid></item><item><title>DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation</title><link>http://arxiv.org/abs/2403.06845v2</link><description>World models have demonstrated superiority in autonomous driving,particularly in the generation of multi-view driving videos. However,significant challenges still exist in generating customized driving videos. Inthis paper, we propose DriveDreamer-2, which builds upon the framework ofDriveDreamer and incorporates a Large Language Model (LLM) to generateuser-defined driving videos. Specifically, an LLM interface is initiallyincorporated to convert a user's query into agent trajectories. Subsequently, aHDMap, adhering to traffic regulations, is generated based on the trajectories.Ultimately, we propose the Unified Multi-View Model to enhance temporal andspatial coherence in the generated driving videos. DriveDreamer-2 is the firstworld model to generate customized driving videos, it can generate uncommondriving videos (e.g., vehicles abruptly cut in) in a user-friendly manner.Besides, experimental results demonstrate that the generated videos enhance thetraining of driving perception methods (e.g., 3D detection and tracking).Furthermore, video generation quality of DriveDreamer-2 surpasses otherstate-of-the-art methods, showcasing FID and FVD scores of 11.2 and 55.7,representing relative improvements of 30% and 50%.</description><author>Guosheng Zhao, Xiaofeng Wang, Zheng Zhu, Xinze Chen, Guan Huang, Xiaoyi Bao, Xingang Wang</author><pubDate>Thu, 11 Apr 2024 05:17:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06845v2</guid></item><item><title>DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation</title><link>http://arxiv.org/abs/2403.06845v1</link><description>World models have demonstrated superiority in autonomous driving,particularly in the generation of multi-view driving videos. However,significant challenges still exist in generating customized driving videos. Inthis paper, we propose DriveDreamer-2, which builds upon the framework ofDriveDreamer and incorporates a Large Language Model (LLM) to generateuser-defined driving videos. Specifically, an LLM interface is initiallyincorporated to convert a user's query into agent trajectories. Subsequently, aHDMap, adhering to traffic regulations, is generated based on the trajectories.Ultimately, we propose the Unified Multi-View Model to enhance temporal andspatial coherence in the generated driving videos. DriveDreamer-2 is the firstworld model to generate customized driving videos, it can generate uncommondriving videos (e.g., vehicles abruptly cut in) in a user-friendly manner.Besides, experimental results demonstrate that the generated videos enhance thetraining of driving perception methods (e.g., 3D detection and tracking).Furthermore, video generation quality of DriveDreamer-2 surpasses otherstate-of-the-art methods, showcasing FID and FVD scores of 11.2 and 55.7,representing relative improvements of 30% and 50%.</description><author>Guosheng Zhao, Xiaofeng Wang, Zheng Zhu, Xinze Chen, Guan Huang, Xiaoyi Bao, Xingang Wang</author><pubDate>Mon, 11 Mar 2024 17:03:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06845v1</guid></item><item><title>GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities</title><link>http://arxiv.org/abs/2406.11768v1</link><description>Perceiving and understanding non-speech sounds and non-verbal speech isessential to making decisions that help us interact with our surroundings. Inthis paper, we propose GAMA, a novel General-purpose Large Audio-Language Model(LALM) with Advanced Audio Understanding and Complex Reasoning Abilities. Webuild GAMA by integrating an LLM with multiple types of audio representations,including features from a custom Audio Q-Former, a multi-layer aggregator thataggregates features from multiple layers of an audio encoder. We fine-tune GAMAon a large-scale audio-language dataset, which augments it with audiounderstanding capabilities. Next, we propose CompA-R (Instruction-Tuning forComplex Audio Reasoning), a synthetically generated instruction-tuning (IT)dataset with instructions that require the model to perform complex reasoningon the input audio. We instruction-tune GAMA with CompA-R to endow it withcomplex reasoning abilities, where we further add a soft prompt as input withhigh-level semantic evidence by leveraging event tags of the input audio.Finally, we also propose CompA-R-test, a human-labeled evaluation dataset forevaluating the capabilities of LALMs on open-ended audio question-answeringthat requires complex reasoning. Through automated and expert humanevaluations, we show that GAMA outperforms all other LALMs in literature ondiverse audio understanding tasks by margins of 1%-84%. Further, GAMA IT-ed onCompA-R proves to be superior in its complex reasoning and instructionfollowing capabilities.</description><author>Sreyan Ghosh, Sonal Kumar, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, S Sakshi, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha</author><pubDate>Mon, 17 Jun 2024 18:31:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11768v1</guid></item><item><title>Machine Unlearning in Large Language Models</title><link>http://arxiv.org/abs/2405.15152v1</link><description>Machine unlearning, a novel area within artificial intelligence, focuses onaddressing the challenge of selectively forgetting or reducing undesirableknowledge or behaviors in machine learning models, particularly in the contextof large language models (LLMs). This paper introduces a methodology to alignLLMs, such as Open Pre-trained Transformer Language Models, with ethical,privacy, and safety standards by leveraging the gradient ascent algorithm forknowledge unlearning. Our approach aims to selectively erase or modify learnedinformation in LLMs, targeting harmful responses and copyrighted content. Thispaper presents a dual-pronged approach to enhance the ethical and safe behaviorof large language models (LLMs) by addressing the issues of harmful responsesand copyrighted content. To mitigate harmful responses, we applied gradientascent on the PKU dataset, achieving a 75\% reduction in harmful responses forOpen Pre-trained Transformer Language Models (OPT1.3b and OPT2.7b)\citet{zhang2022opt} while retaining previous knowledge using the TruthfulQAdataset \citet{DBLP:journals/corr/abs-2109-07958}. For handling copyrightedcontent, we constructed a custom dataset based on the Lord of the Rings corpusand aligned LLMs (OPT1.3b and OPT2.7b) \citet{zhang2022opt} through LoRA:Low-Rank Adaptation of Large Language Models\citet{DBLP:journals/corr/abs-2106-09685} finetuning. Subsequently, we employedgradient ascent to unlearn the Lord of the Rings content, resulting in aremarkable reduction in the presence of copyrighted material. To maintain adiverse knowledge base, we utilized the Book Corpus dataset. Additionally, wepropose a new evaluation technique for assessing the effectiveness of harmfulunlearning.</description><author>Saaketh Koundinya Gundavarapu, Shreya Agarwal, Arushi Arora, Chandana Thimmalapura Jagadeeshaiah</author><pubDate>Fri, 24 May 2024 03:12:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15152v1</guid></item><item><title>Question Suggestion for Conversational Shopping Assistants Using Product Metadata</title><link>http://arxiv.org/abs/2405.01738v1</link><description>Digital assistants have become ubiquitous in e-commerce applications,following the recent advancements in Information Retrieval (IR), NaturalLanguage Processing (NLP) and Generative Artificial Intelligence (AI). However,customers are often unsure or unaware of how to effectively converse with theseassistants to meet their shopping needs. In this work, we emphasize theimportance of providing customers a fast, easy to use, and natural way tointeract with conversational shopping assistants. We propose a framework thatemploys Large Language Models (LLMs) to automatically generate contextual,useful, answerable, fluent and diverse questions about products, via in-contextlearning and supervised fine-tuning. Recommending these questions to customersas helpful suggestions or hints to both start and continue a conversation canresult in a smoother and faster shopping experience with reduced conversationoverhead and friction. We perform extensive offline evaluations, and discuss indetail about potential customer impact, and the type, length and latency of ourgenerated product questions if incorporated into a real-world shoppingassistant.</description><author>Nikhita Vedula, Oleg Rokhlenko, Shervin Malmasi</author><pubDate>Thu, 02 May 2024 22:16:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01738v1</guid></item><item><title>DeepLocalization: Using change point detection for Temporal Action Localization</title><link>http://arxiv.org/abs/2404.12258v1</link><description>In this study, we introduce DeepLocalization, an innovative framework devisedfor the real-time localization of actions tailored explicitly for monitoringdriver behavior. Utilizing the power of advanced deep learning methodologies,our objective is to tackle the critical issue of distracted driving-asignificant factor contributing to road accidents. Our strategy employs a dualapproach: leveraging Graph-Based Change-Point Detection for pinpointing actionsin time alongside a Video Large Language Model (Video-LLM) for preciselycategorizing activities. Through careful prompt engineering, we customize theVideo-LLM to adeptly handle driving activities' nuances, ensuring itsclassification efficacy even with sparse data. Engineered to be lightweight,our framework is optimized for consumer-grade GPUs, making it vastly applicablein practical scenarios. We subjected our method to rigorous testing on theSynDD2 dataset, a complex benchmark for distracted driving behaviors, where itdemonstrated commendable performance-achieving 57.5% accuracy in eventclassification and 51% in event detection. These outcomes underscore thesubstantial promise of DeepLocalization in accurately identifying diversedriver behaviors and their temporal occurrences, all within the bounds oflimited computational resources.</description><author>Mohammed Shaiqur Rahman, Ibne Farabi Shihab, Lynna Chu, Anuj Sharma</author><pubDate>Thu, 18 Apr 2024 16:25:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12258v1</guid></item><item><title>Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph</title><link>http://arxiv.org/abs/2404.14372v1</link><description>Model scaling is becoming the default choice for many language tasks due tothe success of large language models (LLMs). However, it can fall short inspecific scenarios where simple customized methods excel. In this paper, wedelve into the patent approval pre-diction task and unveil that simpledomain-specific graph methods outperform enlarging the model, using theintrinsic dependencies within the patent data. Specifically, we first extendthe embedding-based state-of-the-art (SOTA) by scaling up its backbone modelwith various sizes of open-source LLMs, then explore prompt-based methods toharness proprietary LLMs' potential, but find the best results close to randomguessing, underlining the ineffectiveness of model scaling-up. Hence, wepropose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulouspatent data analyses, capturing the inherent dependencies across segments ofthe patent text. As it is model-agnostic, we apply cost-effective graph modelsto our FLAN Graph to obtain representations for approval prediction. Extensiveexperiments and detailed analyses prove that incorporating FLAN Graph viavarious graph models consistently outperforms all LLM baselines significantly.We hope that our observations and analyses in this paper can bring moreattention to this challenging task and prompt further research into thelimitations of LLMs. Our source code and dataset can be obtained fromhttp://github.com/ShangDataLab/FLAN-Graph.</description><author>Xiaochen Kev Gao, Feng Yao, Kewen Zhao, Beilei He, Animesh Kumar, Vish Krishnan, Jingbo Shang</author><pubDate>Mon, 22 Apr 2024 18:22:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14372v1</guid></item><item><title>Comparative Study of Domain Driven Terms Extraction Using Large Language Models</title><link>http://arxiv.org/abs/2404.02330v1</link><description>Keywords play a crucial role in bridging the gap between human understandingand machine processing of textual data. They are essential to data enrichmentbecause they form the basis for detailed annotations that provide a moreinsightful and in-depth view of the underlying data. Keyword/domain driven termextraction is a pivotal task in natural language processing, facilitatinginformation retrieval, document summarization, and content categorization. Thisreview focuses on keyword extraction methods, emphasizing the use of threemajor Large Language Models(LLMs): Llama2-7B, GPT-3.5, and Falcon-7B. Weemployed a custom Python package to interface with these LLMs, simplifyingkeyword extraction. Our study, utilizing the Inspec and PubMed datasets,evaluates the performance of these models. The Jaccard similarity index wasused for assessment, yielding scores of 0.64 (Inspec) and 0.21 (PubMed) forGPT-3.5, 0.40 and 0.17 for Llama2-7B, and 0.23 and 0.12 for Falcon-7B. Thispaper underlines the role of prompt engineering in LLMs for better keywordextraction and discusses the impact of hallucination in LLMs on resultevaluation. It also sheds light on the challenges in using LLMs for keywordextraction, including model complexity, resource demands, and optimizationtechniques.</description><author>Sandeep Chataut, Tuyen Do, Bichar Dip Shrestha Gurung, Shiva Aryal, Anup Khanal, Carol Lushbough, Etienne Gnimpieba</author><pubDate>Tue, 02 Apr 2024 23:04:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02330v1</guid></item><item><title>Deep Learning and LLM-based Methods Applied to Stellar Lightcurve Classification</title><link>http://arxiv.org/abs/2404.10757v1</link><description>Light curves serve as a valuable source of information on stellar formationand evolution. With the rapid advancement of machine learning techniques, itcan be effectively processed to extract astronomical patterns and information.In this study, we present a comprehensive evaluation of deep-learning and largelanguage model (LLM) based models for the automatic classification of variablestar light curves, based on large datasets from the Kepler and K2 missions.Special emphasis is placed on Cepheids, RR Lyrae, and eclipsing binaries,examining the influence of observational cadence and phase distribution onclassification precision. Employing AutoDL optimization, we achieve strikingperformance with the 1D-Convolution+BiLSTM architecture and the SwinTransformer, hitting accuracies of 94\% and 99\% correspondingly, with thelatter demonstrating a notable 83\% accuracy in discerning the elusive Type IICepheids-comprising merely 0.02\% of the total dataset.We unveil StarWhisperLightCurve (LC), an innovative Series comprising three LLM-based models: LLM,multimodal large language model (MLLM), and Large Audio Language Model (LALM).Each model is fine-tuned with strategic prompt engineering and customizedtraining methods to explore the emergent abilities of these models forastronomical data. Remarkably, StarWhisper LC Series exhibit high accuraciesaround 90\%, significantly reducing the need for explicit feature engineering,thereby paving the way for streamlined parallel data processing and theprogression of multifaceted multimodal models in astronomical applications. Thestudy furnishes two detailed catalogs illustrating the impacts of phase andsampling intervals on deep learning classification accuracy, showing that asubstantial decrease of up to 14\% in observation duration and 21\% in samplingpoints can be realized without compromising accuracy by more than 10\%.</description><author>Yu-Yang Li, Yu Bai, Cunshi Wang, Mengwei Qu, Ziteng Lu, Roberto Soria, Jifeng Liu</author><pubDate>Tue, 16 Apr 2024 18:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10757v1</guid></item><item><title>Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models</title><link>http://arxiv.org/abs/2403.19340v1</link><description>To address the challenges associated with data processing at scale, wepropose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipelinefor large language models (LLMs) with a user-friendly design at its core. Easyaddition of custom processors with block-based interface in Dataverse allowsusers to readily and efficiently use Dataverse to build their own ETL pipeline.We hope that Dataverse will serve as a vital tool for LLM development and opensource the entire library to welcome community contribution. Additionally, weprovide a concise, two-minute video demonstration of our system, illustratingits capabilities and implementation.</description><author>Hyunbyung Park, Sukyung Lee, Gyoungjin Gim, Yungi Kim, Dahyun Kim, Chanjun Park</author><pubDate>Thu, 28 Mar 2024 12:57:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19340v1</guid></item><item><title>Enhancing Zero-Shot Facial Expression Recognition by LLM Knowledge Transfer</title><link>http://arxiv.org/abs/2405.19100v1</link><description>Current facial expression recognition (FER) models are often designed in asupervised learning manner thus are constrained by the lack of large-scalefacial expression images with high-quality annotations. Consequently, thesemodels often fail to generalize well, performing poorly on unseen images intraining. Vision-language-based zero-shot models demonstrate a promisingpotential for addressing such challenges. However, these models lacktask-specific knowledge therefore are not optimized for the nuances ofrecognizing facial expressions. To bridge this gap, this work proposes a novelmethod, Exp-CLIP, to enhance zero-shot FER by transferring the task knowledgefrom large language models (LLMs). Specifically, based on the pre-trainedvision-language encoders, we incorporate a projection head designed to map theinitial joint vision-language space into a space that captures representationsof facial actions. To train this projection head for subsequent zero-shotpredictions, we propose to align the projected visual representations withtask-specific semantic meanings derived from the LLM encoder, and the textinstruction-based strategy is employed to customize the LLM knowledge. Givenunlabelled facial data and efficient training of the projection head, Exp-CLIPachieves superior zero-shot results to the CLIP models and several other largevision-language models (LVLMs) on seven in-the-wild FER datasets. The code andpre-trained models are available at\url{https://github.com/zengqunzhao/Exp-CLIP}.</description><author>Zengqun Zhao, Yu Cao, Shaogang Gong, Ioannis Patras</author><pubDate>Wed, 29 May 2024 15:06:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19100v1</guid></item><item><title>GeoGalactica: A Scientific Large Language Model in Geoscience</title><link>http://arxiv.org/abs/2401.00434v2</link><description>Large language models (LLMs) have achieved huge success for their generalknowledge and ability to solve a wide spectrum of tasks in natural languageprocessing (NLP). Due to their impressive abilities, LLMs have shed light onpotential inter-discipline applications to foster scientific discoveries of aspecific domain by using artificial intelligence (AI for science, AI4S). In themeantime, utilizing NLP techniques in geoscience research and practice is wideand convoluted, contributing from knowledge extraction and documentclassification to question answering and knowledge discovery. In this work, wetake the initial step to leverage LLM for science, through a ratherstraightforward approach. We try to specialize an LLM into geoscience, byfurther pre-training the model with a vast amount of texts in geoscience, aswell as supervised fine-tuning (SFT) the resulting model with our customcollected instruction tuning dataset. These efforts result in a modelGeoGalactica consisting of 30 billion parameters. To our best knowledge, it isthe largest language model for the geoscience domain. More specifically,GeoGalactica is from further pre-training of Galactica. We train GeoGalacticaover a geoscience-related text corpus containing 65 billion tokens, preservingas the largest geoscience-specific text corpus. Then we fine-tune the modelwith 1 million pairs of instruction-tuning data consisting of questions thatdemand professional geoscience knowledge to answer. In this technical report,we will illustrate in detail all aspects of GeoGalactica, including datacollection, data cleaning, base model selection, pre-training, SFT, andevaluation. We open-source our data curation tools and the checkpoints ofGeoGalactica during the first 3/4 of pre-training.</description><author>Zhouhan Lin, Cheng Deng, Le Zhou, Tianhang Zhang, Yi Xu, Yutong Xu, Zhongmou He, Yuanyuan Shi, Beiya Dai, Yunchong Song, Boyi Zeng, Qiyuan Chen, Yuxun Miao, Bo Xue, Shu Wang, Luoyi Fu, Weinan Zhang, Junxian He, Yunqiang Zhu, Xinbing Wang, Chenghu Zhou</author><pubDate>Sat, 13 Apr 2024 18:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00434v2</guid></item><item><title>EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities</title><link>http://arxiv.org/abs/2310.10436v3</link><description>The advent of artificial intelligence has led to a growing emphasis ondata-driven modeling in macroeconomics, with agent-based modeling (ABM)emerging as a prominent bottom-up simulation paradigm. In ABM, agents (e.g.,households, firms) interact within a macroeconomic environment, collectivelygenerating market dynamics. Existing agent modeling typically employspredetermined rules or learning-based neural networks for decision-making.However, customizing each agent presents significant challenges, complicatingthe modeling of agent heterogeneity. Additionally, the influence ofmulti-period market dynamics and multifaceted macroeconomic factors are oftenoverlooked in decision-making processes. In this work, we introduce EconAgent,a large language model-empowered agent with human-like characteristics formacroeconomic simulation. We first construct a simulation environment thatincorporates various market dynamics driven by agents' decisions regarding workand consumption. Through the perception module, we create heterogeneous agentswith distinct decision-making mechanisms. Furthermore, we model the impact ofmacroeconomic trends using a memory module, which allows agents to reflect onpast individual experiences and market dynamics. Simulation experiments showthat EconAgent can make realistic decisions, leading to more reasonablemacroeconomic phenomena compared to existing rule-based or learning-basedagents. Our codes are released athttps://github.com/tsinghua-fib-lab/ACL24-EconAgent.</description><author>Nian Li, Chen Gao, Mingyu Li, Yong Li, Qingmin Liao</author><pubDate>Wed, 22 May 2024 08:20:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10436v3</guid></item><item><title>EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities</title><link>http://arxiv.org/abs/2310.10436v4</link><description>The advent of artificial intelligence has led to a growing emphasis ondata-driven modeling in macroeconomics, with agent-based modeling (ABM)emerging as a prominent bottom-up simulation paradigm. In ABM, agents (e.g.,households, firms) interact within a macroeconomic environment, collectivelygenerating market dynamics. Existing agent modeling typically employspredetermined rules or learning-based neural networks for decision-making.However, customizing each agent presents significant challenges, complicatingthe modeling of agent heterogeneity. Additionally, the influence ofmulti-period market dynamics and multifaceted macroeconomic factors are oftenoverlooked in decision-making processes. In this work, we introduce EconAgent,a large language model-empowered agent with human-like characteristics formacroeconomic simulation. We first construct a simulation environment thatincorporates various market dynamics driven by agents' decisions regarding workand consumption. Through the perception module, we create heterogeneous agentswith distinct decision-making mechanisms. Furthermore, we model the impact ofmacroeconomic trends using a memory module, which allows agents to reflect onpast individual experiences and market dynamics. Simulation experiments showthat EconAgent can make realistic decisions, leading to more reasonablemacroeconomic phenomena compared to existing rule-based or learning-basedagents. Our codes are released athttps://github.com/tsinghua-fib-lab/ACL24-EconAgent.</description><author>Nian Li, Chen Gao, Mingyu Li, Yong Li, Qingmin Liao</author><pubDate>Fri, 24 May 2024 03:53:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10436v4</guid></item><item><title>EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities</title><link>http://arxiv.org/abs/2310.10436v2</link><description>The advent of artificial intelligence has led to a growing emphasis ondata-driven modeling in macroeconomics, with agent-based modeling (ABM)emerging as a prominent bottom-up simulation paradigm. In ABM, agents (e.g.,households, firms) interact within a macroeconomic environment, collectivelygenerating market dynamics. Existing agent modeling typically employspredetermined rules or learning-based neural networks for decision-making.However, customizing each agent presents significant challenges, complicatingthe modeling of agent heterogeneity. Additionally, the influence ofmulti-period market dynamics and multifaceted macroeconomic factors are oftenoverlooked in decision-making processes. In this work, we introduce EconAgent,a large language model-empowered agent with human-like characteristics formacroeconomic simulation. We first construct a simulation environment thatincorporates various market dynamics driven by agents' decisions regarding workand consumption. Through the perception module, we create heterogeneous agentswith distinct decision-making mechanisms. Furthermore, we model the impact ofmacroeconomic trends using a memory module, which allows agents to reflect onpast individual experiences and market dynamics. Simulation experiments showthat EconAgent can make realistic decisions, leading to more reasonablemacroeconomic phenomena compared to existing rule-based or learning-basedagents. Our codes are released athttps://github.com/tsinghua-fib-lab/ACL24-EconAgent.</description><author>Li Nian, Gao Chen, Li Mingyu, Li Yong, Liao Qingmin</author><pubDate>Tue, 21 May 2024 03:49:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10436v2</guid></item><item><title>Manipulating Large Language Models to Increase Product Visibility</title><link>http://arxiv.org/abs/2404.07981v1</link><description>Large language models (LLMs) are increasingly being integrated into searchengines to provide natural language responses tailored to user queries.Customers and end-users are also becoming more dependent on these models forquick and easy purchase decisions. In this work, we investigate whetherrecommendations from LLMs can be manipulated to enhance a product's visibility.We demonstrate that adding a strategic text sequence (STS) -- a carefullycrafted message -- to a product's information page can significantly increaseits likelihood of being listed as the LLM's top recommendation. To understandthe impact of STS, we use a catalog of fictitious coffee machines and analyzeits effect on two target products: one that seldom appears in the LLM'srecommendations and another that usually ranks second. We observe that thestrategic text sequence significantly enhances the visibility of both productsby increasing their chances of appearing as the top recommendation. Thisability to manipulate LLM-generated search responses provides vendors with aconsiderable competitive advantage and has the potential to disrupt fair marketcompetition. Just as search engine optimization (SEO) revolutionized howwebpages are customized to rank higher in search engine results, influencingLLM recommendations could profoundly impact content optimization for AI-drivensearch services. Code for our experiments is available athttps://github.com/aounon/llm-rank-optimizer.</description><author>Aounon Kumar, Himabindu Lakkaraju</author><pubDate>Thu, 11 Apr 2024 18:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07981v1</guid></item><item><title>LoRA Meets Dropout under a Unified Framework</title><link>http://arxiv.org/abs/2403.00812v2</link><description>With the remarkable capabilities, large language models (LLMs) have emergedas essential elements in numerous NLP applications, while parameter-efficientfinetuning, especially LoRA, has gained popularity as a lightweight approachfor model customization. Meanwhile, various dropout methods, initially designedfor full finetuning with all the parameters updated, alleviates overfittingassociated with excessive parameter redundancy. Hence, a possible contradictionarises from negligible trainable parameters of LoRA and the effectiveness ofprevious dropout methods, which has been largely overlooked. To fill this gap,we first confirm that parameter-efficient LoRA is also overfitting-prone. Wethen revisit transformer-specific dropout methods, and establish theirequivalence and distinctions mathematically and empirically. Building upon thiscomparative analysis, we introduce a unified framework for a comprehensiveinvestigation, which instantiates these methods based on dropping position,structural pattern and compensation measure. Through this framework, we revealthe new preferences and performance comparisons of them when involved withlimited trainable parameters. This framework also allows us to amalgamate themost favorable aspects into a novel dropout method named HiddenKey. Extensiveexperiments verify the remarkable superiority and sufficiency of HiddenKeyacross multiple models and tasks, which highlights it as the preferred approachfor high-performance and parameter-efficient finetuning of LLMs.</description><author>Sheng Wang, Liheng Chen, Jiyue Jiang, Boyang Xue, Lingpeng Kong, Chuan Wu</author><pubDate>Mon, 27 May 2024 03:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00812v2</guid></item><item><title>UniDM: A Unified Framework for Data Manipulation with Large Language Models</title><link>http://arxiv.org/abs/2405.06510v1</link><description>Designing effective data manipulation methods is a long standing problem indata lakes. Traditional methods, which rely on rules or machine learningmodels, require extensive human efforts on training data collection and tuningmodels. Recent methods apply Large Language Models (LLMs) to resolve multipledata manipulation tasks. They exhibit bright benefits in terms of performancebut still require customized designs to fit each specific task. This is verycostly and can not catch up with the requirements of big data lake platforms.In this paper, inspired by the cross-task generality of LLMs on NLP tasks, wepave the first step to design an automatic and general solution to tackle withdata manipulation tasks. We propose UniDM, a unified framework whichestablishes a new paradigm to process data manipulation tasks using LLMs. UniDMformalizes a number of data manipulation tasks in a unified form and abstractsthree main general steps to solve each task. We develop an automatic contextretrieval to allow the LLMs to retrieve data from data lakes, potentiallycontaining evidence and factual information. For each step, we design effectiveprompts to guide LLMs to produce high quality results. By our comprehensiveevaluation on a variety of benchmarks, our UniDM exhibits great generality andstate-of-the-art performance on a wide variety of data manipulation tasks.</description><author>Yichen Qian, Yongyi He, Rong Zhu, Jintao Huang, Zhijian Ma, Haibin Wang, Yaohua Wang, Xiuyu Sun, Defu Lian, Bolin Ding, Jingren Zhou</author><pubDate>Fri, 10 May 2024 15:44:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06510v1</guid></item><item><title>Scaffolding Language Learning via Multi-modal Tutoring Systems with Pedagogical Instructions</title><link>http://arxiv.org/abs/2404.03429v1</link><description>Intelligent tutoring systems (ITSs) that imitate human tutors and aim toprovide immediate and customized instructions or feedback to learners haveshown their effectiveness in education. With the emergence of generativeartificial intelligence, large language models (LLMs) further entitle thesystems to complex and coherent conversational interactions. These systemswould be of great help in language education as it involves developing skillsin communication, which, however, drew relatively less attention. Additionally,due to the complicated cognitive development at younger ages, more endeavorsare needed for practical uses. Scaffolding refers to a teaching technique whereteachers provide support and guidance to students for learning and developingnew concepts or skills. It is an effective way to support diverse learningneeds, goals, processes, and outcomes. In this work, we investigate howpedagogical instructions facilitate the scaffolding in ITSs, by conducting acase study on guiding children to describe images for language learning. Weconstruct different types of scaffolding tutoring systems grounded in fourfundamental learning theories: knowledge construction, inquiry-based learning,dialogic teaching, and zone of proximal development. For qualitative andquantitative analyses, we build and refine a seven-dimension rubric to evaluatethe scaffolding process. In our experiment on GPT-4V, we observe that LLMsdemonstrate strong potential to follow pedagogical instructions and achieveself-paced learning in different student groups. Moreover, we extend ourevaluation framework from a manual to an automated approach, paving the way tobenchmark various conversational tutoring systems.</description><author>Zhengyuan Liu, Stella Xin Yin, Carolyn Lee, Nancy F. Chen</author><pubDate>Thu, 04 Apr 2024 14:22:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03429v1</guid></item><item><title>Évaluation des capacités de réponse de larges modèles de langage (LLM) pour des questions d'historiens</title><link>http://arxiv.org/abs/2406.15173v1</link><description>Large Language Models (LLMs) like ChatGPT or Bard have revolutionizedinformation retrieval and captivated the audience with their ability togenerate custom responses in record time, regardless of the topic. In thisarticle, we assess the capabilities of various LLMs in producing reliable,comprehensive, and sufficiently relevant responses about historical facts inFrench. To achieve this, we constructed a testbed comprising numeroushistory-related questions of varying types, themes, and levels of difficulty.Our evaluation of responses from ten selected LLMs reveals numerousshortcomings in both substance and form. Beyond an overall insufficientaccuracy rate, we highlight uneven treatment of the French language, as well asissues related to verbosity and inconsistency in the responses provided byLLMs.</description><author>Mathieu Chartier, Nabil Dakkoune, Guillaume Bourgeois, Stéphane Jean</author><pubDate>Fri, 21 Jun 2024 15:19:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15173v1</guid></item><item><title>Zero- and Few-Shot Prompting with LLMs: A Comparative Study with Fine-tuned Models for Bangla Sentiment Analysis</title><link>http://arxiv.org/abs/2308.10783v2</link><description>The rapid expansion of the digital world has propelled sentiment analysisinto a critical tool across diverse sectors such as marketing, politics,customer service, and healthcare. While there have been significantadvancements in sentiment analysis for widely spoken languages, low-resourcelanguages, such as Bangla, remain largely under-researched due to resourceconstraints. Furthermore, the recent unprecedented performance of LargeLanguage Models (LLMs) in various applications highlights the need to evaluatethem in the context of low-resource languages. In this study, we present asizeable manually annotated dataset encompassing 33,606 Bangla news tweets andFacebook comments. We also investigate zero- and few-shot in-context learningwith several language models, including Flan-T5, GPT-4, and Bloomz, offering acomparative analysis against fine-tuned models. Our findings suggest thatmonolingual transformer-based models consistently outperform other models, evenin zero and few-shot scenarios. To foster continued exploration, we intend tomake this dataset and our research tools publicly available to the broaderresearch community.</description><author>Md. Arid Hasan, Shudipta Das, Afiyat Anjum, Firoj Alam, Anika Anjum, Avijit Sarker, Sheak Rashed Haider Noori</author><pubDate>Fri, 05 Apr 2024 02:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10783v2</guid></item><item><title>Noise-Aware Training of Layout-Aware Language Models</title><link>http://arxiv.org/abs/2404.00488v1</link><description>A visually rich document (VRD) utilizes visual features along with linguisticcues to disseminate information. Training a custom extractor that identifiesnamed entities from a document requires a large number of instances of thetarget document type annotated at textual and visual modalities. This is anexpensive bottleneck in enterprise scenarios, where we want to train customextractors for thousands of different document types in a scalable way.Pre-training an extractor model on unlabeled instances of the target documenttype, followed by a fine-tuning step on human-labeled instances does not workin these scenarios, as it surpasses the maximum allowable training timeallocated for the extractor. We address this scenario by proposing aNoise-Aware Training method or NAT in this paper. Instead of acquiringexpensive human-labeled documents, NAT utilizes weakly labeled documents totrain an extractor in a scalable way. To avoid degradation in the model'squality due to noisy, weakly labeled samples, NAT estimates the confidence ofeach training sample and incorporates it as uncertainty measure duringtraining. We train multiple state-of-the-art extractor models using NAT.Experiments on a number of publicly available and in-house datasets show thatNAT-trained models are not only robust in performance -- it outperforms atransfer-learning baseline by up to 6% in terms of macro-F1 score, but it isalso more label-efficient -- it reduces the amount of human-effort required toobtain comparable performance by up to 73%.</description><author>Ritesh Sarkhel, Xiaoqi Ren, Lauro Beltrao Costa, Guolong Su, Vincent Perot, Yanan Xie, Emmanouil Koukoumidis, Arnab Nandi</author><pubDate>Sun, 31 Mar 2024 00:06:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00488v1</guid></item><item><title>When Dataflow Analysis Meets Large Language Models</title><link>http://arxiv.org/abs/2402.10754v1</link><description>Dataflow analysis is a powerful code analysis technique that reasonsdependencies between program values, offering support for code optimization,program comprehension, and bug detection. Existing approaches require thesuccessful compilation of the subject program and customizations for downstreamapplications. This paper introduces LLMDFA, an LLM-powered dataflow analysisframework that analyzes arbitrary code snippets without requiring a compilationinfrastructure and automatically synthesizes downstream applications. Inspiredby summary-based dataflow analysis, LLMDFA decomposes the problem into threesub-problems, which are effectively resolved by several essential strategies,including few-shot chain-of-thought prompting and tool synthesis. Ourevaluation has shown that the design can mitigate the hallucination and improvethe reasoning ability, obtaining high precision and recall in detectingdataflow-related bugs upon benchmark programs, outperforming state-of-the-art(classic) tools, including a very recent industrial analyzer.</description><author>Chengpeng Wang, Wuqi Zhang, Zian Su, Xiangzhe Xu, Xiaoheng Xie, Xiangyu Zhang</author><pubDate>Fri, 16 Feb 2024 15:21:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10754v1</guid></item><item><title>Coeditor: Leveraging Contextual Changes for Multi-round Code Auto-editing</title><link>http://arxiv.org/abs/2305.18584v2</link><description>Developers often dedicate significant time to maintaining and refactoringexisting code. However, most prior work on generative models for code focusessolely on creating new code, overlooking the distinctive needs of editingexisting code. In this work, we explore a multi-round code auto-editingsetting, aiming to predict edits to a code region based on recent changeswithin the same codebase. Our model, Coeditor, is a fine-tuned language modelspecifically designed for code editing tasks. We represent code changes using aline diff format and employ static analysis to form large customized modelcontexts, ensuring the availability of appropriate information for prediction.We collect a code editing dataset from the commit histories of 1650 open-sourcePython projects for training and evaluation. In a simplified single-round,single-edit task, Coeditor significantly outperforms GPT-3.5 and SOTAopen-source code completion models (bringing exact-match accuracy from 34.7 upto 60.4), demonstrating the benefits of incorporating editing history for codecompletion. In a multi-round, multi-edit setting, we observe substantial gainsby iteratively conditioning on additional user edits. We have open-sourced ourcode, data, and model weights to encourage future research and have released aVSCode extension powered by our model for interactive IDE usage.</description><author>Jiayi Wei, Greg Durrett, Isil Dillig</author><pubDate>Sun, 28 Apr 2024 18:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18584v2</guid></item><item><title>Seventeenth-Century Spanish American Notary Records for Fine-Tuning Spanish Large Language Models</title><link>http://arxiv.org/abs/2406.05812v1</link><description>Large language models have gained tremendous popularity in domains such ase-commerce, finance, healthcare, and education. Fine-tuning is a commonapproach to customize an LLM on a domain-specific dataset for a desireddownstream task. In this paper, we present a valuable resource for fine-tuningLLMs developed for the Spanish language to perform a variety of tasks such asclassification, masked language modeling, clustering, and others. Our resourceis a collection of handwritten notary records from the seventeenth centuryobtained from the National Archives of Argentina. This collection contains acombination of original images and transcribed text (and metadata) of 160+pages that were handwritten by two notaries, namely, Estenban Agreda de Vergaraand Nicolas de Valdivia y Brisuela nearly 400 years ago. Through empiricalevaluation, we demonstrate that our collection can be used to fine-tune SpanishLLMs for tasks such as classification and masked language modeling, and canoutperform pre-trained Spanish models and ChatGPT-3.5/ChatGPT-4o. Our resourcewill be an invaluable resource for historical text analysis and is publiclyavailable on GitHub.</description><author>Shraboni Sarker, Ahmad Tamim Hamad, Hulayyil Alshammari, Viviana Grieco, Praveen Rao</author><pubDate>Sun, 09 Jun 2024 15:54:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05812v1</guid></item><item><title>Does Combining Parameter-efficient Modules Improve Few-shot Transfer Accuracy?</title><link>http://arxiv.org/abs/2402.15414v1</link><description>Parameter-efficient fine-tuning stands as the standard for efficientlyfine-tuning large language and vision models on downstream tasks. Specifically,the efficiency of low-rank adaptation has facilitated the creation and sharingof hundreds of custom LoRA modules, each trained on distinct data from variousdownstream tasks. In this paper, we explore the composability of LoRA modules,examining if combining these pre-trained modules enhances generalization tounseen downstream tasks. Our investigation involves evaluating two approaches:(a) uniform composition, involving averaging upstream LoRA modules with equalweights, and (b) learned composition, where we learn the weights for eachupstream module and perform weighted averaging. Our experimental results onboth vision and language models reveal that in few-shot settings, where only alimited number of samples are available for the downstream task, both uniformand learned composition methods result in better transfer accuracy;outperforming full fine-tuning and training a LoRA from scratch. Moreover, infull-shot settings, learned composition performs comparably to regular LoRAtraining with significantly fewer number of trainable parameters. Our researchunveils the potential of uniform composition for enhancing transferability inlow-shot settings, without introducing additional learnable parameters.</description><author>Nader Asadi, Mahdi Beitollahi, Yasser Khalil, Yinchuan Li, Guojun Zhang, Xi Chen</author><pubDate>Fri, 23 Feb 2024 16:20:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15414v1</guid></item><item><title>GCOF: Self-iterative Text Generation for Copywriting Using Large Language Model</title><link>http://arxiv.org/abs/2402.13667v1</link><description>Large language models(LLM) such as ChatGPT have substantially simplified thegeneration of marketing copy, yet producing content satisfying domain specificrequirements, such as effectively engaging customers, remains a significantchallenge. In this work, we introduce the Genetic Copy Optimization Framework(GCOF) designed to enhance both efficiency and engagememnt of marketing copycreation. We conduct explicit feature engineering within the prompts of LLM.Additionally, we modify the crossover operator in Genetic Algorithm (GA),integrating it into the GCOF to enable automatic feature engineering. Thisintegration facilitates a self-iterative refinement of the marketing copy.Compared to human curated copy, Online results indicate that copy produced byour framework achieves an average increase in click-through rate (CTR) of over$50\%$.</description><author>Jianghui Zhou, Ya Gao, Jie Liu, Xuemin Zhao, Zhaohua Yang, Yue Wu, Lirong Shi</author><pubDate>Wed, 21 Feb 2024 09:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13667v1</guid></item><item><title>PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval</title><link>http://arxiv.org/abs/2402.19273v1</link><description>In the field of urban planning, general-purpose large language models oftenstruggle to meet the specific needs of planners. Tasks like generating urbanplanning texts, retrieving related information, and evaluating planningdocuments pose unique challenges. To enhance the efficiency of urbanprofessionals and overcome these obstacles, we introduce PlanGPT, the firstspecialized Large Language Model tailored for urban and spatial planning.Developed through collaborative efforts with institutions like the ChineseAcademy of Urban Planning, PlanGPT leverages a customized local databaseretrieval framework, domain-specific fine-tuning of base models, and advancedtooling capabilities. Empirical tests demonstrate that PlanGPT has achievedadvanced performance, delivering responses of superior quality preciselytailored to the intricacies of urban planning.</description><author>He Zhu, Wenjia Zhang, Nuoxian Huang, Boyang Li, Luyao Niu, Zipei Fan, Tianle Lun, Yicheng Tao, Junyou Su, Zhaoya Gong, Chenyu Fang, Xing Liu</author><pubDate>Thu, 29 Feb 2024 15:41:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19273v1</guid></item><item><title>Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models</title><link>http://arxiv.org/abs/2405.16833v1</link><description>While large language models (LLMs) such as Llama-2 or GPT-4 have shownimpressive zero-shot performance, fine-tuning is still necessary to enhancetheir performance for customized datasets, domain-specific tasks, or otherprivate needs. However, fine-tuning all parameters of LLMs requires significanthardware resources, which can be impractical for typical users. Therefore,parameter-efficient fine-tuning such as LoRA have emerged, allowing users tofine-tune LLMs without the need for considerable computing resources, withlittle performance degradation compared to fine-tuning all parameters.Unfortunately, recent studies indicate that fine-tuning can increase the riskto the safety of LLMs, even when data does not contain malicious content. Toaddress this challenge, we propose Safe LoRA, a simple one-liner patch to theoriginal LoRA implementation by introducing the projection of LoRA weights fromselected layers to the safety-aligned subspace, effectively reducing the safetyrisks in LLM fine-tuning while maintaining utility. It is worth noting thatSafe LoRA is a training-free and data-free approach, as it only requires theknowledge of the weights from the base and aligned LLMs. Our extensiveexperiments demonstrate that when fine-tuning on purely malicious data, SafeLoRA retains similar safety performance as the original aligned model.Moreover, when the fine-tuning dataset contains a mixture of both benign andmalicious data, Safe LoRA mitigates the negative effect made by malicious datawhile preserving performance on downstream tasks.</description><author>Chia-Yi Hsu, Yu-Lin Tsai, Chih-Hsun Lin, Pin-Yu Chen, Chia-Mu Yu, Chun-Ying Huang</author><pubDate>Mon, 27 May 2024 06:04:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16833v1</guid></item><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v1</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Our codeand dataset will be open-sourced soon.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Sun, 31 Mar 2024 08:11:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v1</guid></item><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v2</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Mon, 15 Apr 2024 07:03:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v2</guid></item><item><title>Student Answer Forecasting: Transformer-Driven Answer Choice Prediction for Language Learning</title><link>http://arxiv.org/abs/2405.20079v1</link><description>Intelligent Tutoring Systems (ITS) enhance personalized learning bypredicting student answers to provide immediate and customized instruction.However, recent research has primarily focused on the correctness of the answerrather than the student's performance on specific answer choices, limitinginsights into students' thought processes and potential misconceptions. Toaddress this gap, we present MCQStudentBert, an answer forecasting model thatleverages the capabilities of Large Language Models (LLMs) to integratecontextual understanding of students' answering history along with the text ofthe questions and answers. By predicting the specific answer choices studentsare likely to make, practitioners can easily extend the model to new answerchoices or remove answer choices for the same multiple-choice question (MCQ)without retraining the model. In particular, we compare MLP, LSTM, BERT, andMistral 7B architectures to generate embeddings from students' pastinteractions, which are then incorporated into a finetuned BERT'sanswer-forecasting mechanism. We apply our pipeline to a dataset of languagelearning MCQ, gathered from an ITS with over 10,000 students to explore thepredictive accuracy of MCQStudentBert, which incorporates student interactionpatterns, in comparison to correct answer prediction and traditionalmastery-learning feature-based approaches. This work opens the door to morepersonalized content, modularization, and granular support.</description><author>Elena Grazia Gado, Tommaso Martorella, Luca Zunino, Paola Mejia-Domenzain, Vinitra Swamy, Jibril Frej, Tanja Käser</author><pubDate>Thu, 30 May 2024 15:09:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20079v1</guid></item><item><title>Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs</title><link>http://arxiv.org/abs/2404.17833v1</link><description>Agents based on large language models (LLMs) have demonstrated effectivenessin solving a wide range of tasks by integrating LLMs with key modules such asplanning, memory, and tool usage. Increasingly, customers are adopting LLMagents across a variety of commercial applications critical to reliability,including support for mental well-being, chemical synthesis, and softwaredevelopment. Nevertheless, our observations and daily use of LLM agentsindicate that they are prone to making erroneous plans, especially when thetasks are complex and require long-term planning. In this paper, we propose PDoctor, a novel and automated approach to testingLLM agents and understanding their erroneous planning. As the first work inthis direction, we formulate the detection of erroneous planning as aconstraint satisfiability problem: an LLM agent's plan is considered erroneousif its execution violates the constraints derived from the user inputs. To thisend, PDoctor first defines a domain-specific language (DSL) for user queriesand synthesizes varying inputs with the assistance of the Z3 constraint solver.These synthesized inputs are natural language paragraphs that specify therequirements for completing a series of tasks. Then, PDoctor derivesconstraints from these requirements to form a testing oracle. We evaluatePDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5and GPT-4). The results show that PDoctor can effectively detect diverse errorsin agent planning and provide insights and error characteristics that arevaluable to both agent developers and users. We conclude by discussingpotential alternative designs and directions to extend PDoctor.</description><author>Zhenlan Ji, Daoyuan Wu, Pingchuan Ma, Zongjie Li, Shuai Wang</author><pubDate>Sat, 27 Apr 2024 09:56:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17833v1</guid></item><item><title>Eliciting Informative Text Evaluations with Large Language Models</title><link>http://arxiv.org/abs/2405.15077v1</link><description>Peer prediction mechanisms motivate high-quality feedback with provableguarantees. However, current methods only apply to rather simple reports, likemultiple-choice or scalar numbers. We aim to broaden these techniques to thelarger domain of text-based reports, drawing on the recent developments inlarge language models. This vastly increases the applicability of peerprediction mechanisms as textual feedback is the norm in a large variety offeedback channels: peer reviews, e-commerce customer reviews, and comments onsocial media. We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanismsutilize LLMs as predictors, mapping from one agent's report to a prediction ofher peer's report. Theoretically, we show that when the LLM prediction issufficiently accurate, our mechanisms can incentivize high effort andtruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, weconfirm the efficacy of our mechanisms through experiments conducted on tworeal datasets: the Yelp review dataset and the ICLR OpenReview dataset. Wehighlight the results that on the ICLR dataset, our mechanisms candifferentiate three quality levels -- human-written reviews, GPT-4-generatedreviews, and GPT-3.5-generated reviews in terms of expected scores.Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.</description><author>Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck</author><pubDate>Thu, 23 May 2024 22:56:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15077v1</guid></item><item><title>Eliciting Informative Text Evaluations with Large Language Models</title><link>http://arxiv.org/abs/2405.15077v2</link><description>Peer prediction mechanisms motivate high-quality feedback with provableguarantees. However, current methods only apply to rather simple reports, likemultiple-choice or scalar numbers. We aim to broaden these techniques to thelarger domain of text-based reports, drawing on the recent developments inlarge language models. This vastly increases the applicability of peerprediction mechanisms as textual feedback is the norm in a large variety offeedback channels: peer reviews, e-commerce customer reviews, and comments onsocial media. We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanismsutilize LLMs as predictors, mapping from one agent's report to a prediction ofher peer's report. Theoretically, we show that when the LLM prediction issufficiently accurate, our mechanisms can incentivize high effort andtruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, weconfirm the efficacy of our mechanisms through experiments conducted on tworeal datasets: the Yelp review dataset and the ICLR OpenReview dataset. Wehighlight the results that on the ICLR dataset, our mechanisms candifferentiate three quality levels -- human-written reviews, GPT-4-generatedreviews, and GPT-3.5-generated reviews in terms of expected scores.Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.</description><author>Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck</author><pubDate>Tue, 28 May 2024 18:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15077v2</guid></item><item><title>ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL</title><link>http://arxiv.org/abs/2402.19446v1</link><description>A broad use case of large language models (LLMs) is in goal-directeddecision-making tasks (or "agent" tasks), where an LLM needs to not justgenerate completions for a given prompt, but rather make intelligent decisionsover a multi-turn interaction to accomplish a task (e.g., when interacting withthe web, using tools, or providing customer support). Reinforcement learning(RL) provides a general paradigm to address such agent tasks, but current RLmethods for LLMs largely focus on optimizing single-turn rewards. Byconstruction, most single-turn RL methods cannot endow LLMs with the ability tointelligently seek information over multiple turns, perform credit assignment,or reason about their past actions -- all of which are critical in agent tasks.This raises the question: how can we design effective and efficient multi-turnRL algorithms for LLMs? In this paper, we develop a framework for buildingmulti-turn RL algorithms for fine-tuning LLMs, that preserves the flexibilityof existing single-turn RL methods for LLMs (e.g., proximal policyoptimization), while accommodating multiple turns, long horizons, and delayedrewards effectively. To do this, our framework adopts a hierarchical RLapproach and runs two RL algorithms in parallel: a high-level off-policyvalue-based RL algorithm to aggregate reward over utterances, and a low-levelRL algorithm that utilizes this high-level value function to train a tokenpolicy within each utterance or turn. Our hierarchical framework, Actor-CriticFramework with a Hierarchical Structure (ArCHer), can also give rise to otherRL methods. Empirically, we find that ArCHer significantly improves efficiencyand performance on agent tasks, attaining a sample efficiency of about 100xover existing methods, while also improving with larger model capacity (uptothe 7 billion scale that we tested on).</description><author>Yifei Zhou, Andrea Zanette, Jiayi Pan, Sergey Levine, Aviral Kumar</author><pubDate>Thu, 29 Feb 2024 18:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19446v1</guid></item><item><title>Comprehensive Lipidomic Automation Workflow using Large Language Models</title><link>http://arxiv.org/abs/2403.15076v1</link><description>Lipidomics generates large data that makes manual annotation andinterpretation challenging. Lipid chemical and structural diversity withstructural isomers further complicates annotation. Although, several commercialand open-source software for targeted lipid identification exists, it lacksautomated method generation workflows and integration with statistical andbioinformatics tools. We have developed the Comprehensive Lipidomic AutomatedWorkflow (CLAW) platform with integrated workflow for parsing, detailedstatistical analysis and lipid annotations based on custom multiple reactionmonitoring (MRM) precursor and product ion pair transitions. CLAW containsseveral modules including identification of carbon-carbon double bondposition(s) in unsaturated lipids when combined with ozone electrosprayionization (OzESI)-MRM methodology. To demonstrate the utility of the automatedworkflow in CLAW, large-scale lipidomics data was collected with traditionaland OzESI-MRM profiling on biological and non-biological samples. Specifically,a total of 1497 transitions organized into 10 MRM-based mass spectrometrymethods were used to profile lipid droplets isolated from different brainregions of 18-24 month-old Alzheimer's disease mice and age-matched wild-typecontrols. Additionally, triacyclglycerols (TGs) profiles with carbon-carbondouble bond specificity were generated from canola oil samples using OzESI-MRMprofiling. We also developed an integrated language user interface with largelanguage models using artificially intelligent (AI) agents that permits usersto interact with the CLAW platform using a chatbot terminal to performstatistical and bioinformatic analyses. We envision CLAW pipeline to be used inhigh-throughput lipid structural identification tasks aiding users to generateautomated lipidomics workflows ranging from data acquisition to AI agent-basedbioinformatic analysis.</description><author>Connor Beveridge, Sanjay Iyer, Caitlin E. Randolph, Matthew Muhoberac, Palak Manchanda, Amy C. Clingenpeel, Shane Tichy, Gaurav Chopra</author><pubDate>Fri, 22 Mar 2024 11:00:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15076v1</guid></item><item><title>LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems</title><link>http://arxiv.org/abs/2403.00982v1</link><description>Retrieval-augmented question-answering systems combine retrieval techniqueswith large language models to provide answers that are more accurate andinformative. Many existing toolkits allow users to quickly build such systemsusing off-the-shelf models, but they fall short in supporting researchers anddevelopers to customize the model training, testing, and deployment process. Wepropose LocalRQA, an open-source toolkit that features a wide selection ofmodel training algorithms, evaluation methods, and deployment tools curatedfrom the latest research. As a showcase, we build QA systems using onlinedocumentation obtained from Databricks and Faire's websites. We find 7B-modelstrained and deployed using LocalRQA reach a similar performance compared tousing OpenAI's text-ada-002 and GPT-4-turbo.</description><author>Xiao Yu, Yunan Lu, Zhou Yu</author><pubDate>Fri, 01 Mar 2024 21:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00982v1</guid></item><item><title>CroissantLLM: A Truly Bilingual French-English Language Model</title><link>http://arxiv.org/abs/2402.00786v4</link><description>We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3TEnglish and French tokens, to bring to the research and industrial community ahigh-performance, fully open-sourced bilingual model that runs swiftly onconsumer-grade local hardware. To that end, we pioneer the approach of trainingan intrinsically bilingual model with a 1:1 English-to-French pretraining dataratio, a custom tokenizer, and bilingual finetuning datasets. We release thetraining dataset, notably containing a French split with manually curated,high-quality, and varied data sources. To assess performance outside ofEnglish, we craft a novel benchmark, FrenchBench, consisting of an array ofclassification and generation tasks, covering various orthogonal aspects ofmodel performance in the French Language. Additionally, rooted in transparencyand to foster further Large Language Model research, we release codebases, anddozens of checkpoints across various model sizes, training data distributions,and training steps, as well as fine-tuned Chat models, and strong translationmodels. We evaluate our model through the FMTI framework, and validate 81 % ofthe transparency criteria, far beyond the scores of even most open initiatives.This work enriches the NLP landscape, breaking away from previousEnglish-centric work in order to strengthen our understanding ofmultilinguality in language models.</description><author>Manuel Faysse, Patrick Fernandes, Nuno M. Guerreiro, António Loison, Duarte M. Alves, Caio Corro, Nicolas Boizard, João Alves, Ricardo Rei, Pedro H. Martins, Antoni Bigata Casademunt, François Yvon, André F. T. Martins, Gautier Viaud, Céline Hudelot, Pierre Colombo</author><pubDate>Fri, 29 Mar 2024 15:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00786v4</guid></item><item><title>Exploring Autonomous Agents through the Lens of Large Language Models: A Review</title><link>http://arxiv.org/abs/2404.04442v1</link><description>Large Language Models (LLMs) are transforming artificial intelligence,enabling autonomous agents to perform diverse tasks across various domains.These agents, proficient in human-like text comprehension and generation, havethe potential to revolutionize sectors from customer service to healthcare.However, they face challenges such as multimodality, human value alignment,hallucinations, and evaluation. Techniques like prompting, reasoning, toolutilization, and in-context learning are being explored to enhance theircapabilities. Evaluation platforms like AgentBench, WebArena, and ToolLLMprovide robust methods for assessing these agents in complex scenarios. Theseadvancements are leading to the development of more resilient and capableautonomous agents, anticipated to become integral in our digital lives,assisting in tasks from email responses to disease diagnosis. The future of AI,with LLMs at the forefront, is promising.</description><author>Saikat Barua</author><pubDate>Fri, 05 Apr 2024 23:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04442v1</guid></item><item><title>Neuro-Vision to Language: Enhancing Visual Reconstruction and Language Interaction through Brain Recordings</title><link>http://arxiv.org/abs/2404.19438v3</link><description>Decoding non-invasive brain recordings is pivotal for advancing ourunderstanding of human cognition but faces challenges due to individualdifferences and complex neural signal representations. Traditional methodsoften require customized models and extensive trials, lacking interpretabilityin visual reconstruction tasks. Our framework integrates 3D brain structureswith visual semantics using a Vision Transformer 3D. This unified featureextractor efficiently aligns fMRI features with multiple levels of visualembeddings, eliminating the need for subject-specific models and allowingextraction from single-trial data. The extractor consolidates multi-levelvisual features into one network, simplifying integration with Large LanguageModels (LLMs). Additionally, we have enhanced the fMRI dataset with diversefMRI-image-related textual data to support multimodal large model development.Integrating with LLMs enhances decoding capabilities, enabling tasks such asbrain captioning, complex reasoning, concept localization, and visualreconstruction. Our approach demonstrates superior performance across thesetasks, precisely identifying language-based concepts within brain signals,enhancing interpretability, and providing deeper insights into neuralprocesses. These advances significantly broaden the applicability ofnon-invasive brain decoding in neuroscience and human-computer interaction,setting the stage for advanced brain-computer interfaces and cognitive models.</description><author>Guobin Shen, Dongcheng Zhao, Xiang He, Linghao Feng, Yiting Dong, Jihang Wang, Qian Zhang, Yi Zeng</author><pubDate>Wed, 22 May 2024 18:21:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19438v3</guid></item><item><title>Scaling Laws for Discriminative Classification in Large Language Models</title><link>http://arxiv.org/abs/2405.15765v1</link><description>Modern large language models (LLMs) represent a paradigm shift in what canplausibly be expected of machine learning models. The fact that LLMs caneffectively generate sensible answers to a diverse range of queries suggeststhat they would be useful in customer support applications. While powerful,LLMs have been observed to be prone to hallucination which unfortunately makestheir near term use in customer support applications challenging. To addressthis issue we present a system that allows us to use an LLM to augment ourcustomer support advocates by re-framing the language modeling task as adiscriminative classification task. In this framing, we seek to present thetop-K best template responses for a customer support advocate to use whenresponding to a customer. We present the result of both offline and onlineexperiments where we observed offline gains and statistically significantonline lifts for our experimental system. Along the way, we present observedscaling curves for validation loss and top-K accuracy, resulted from modelparameter ablation studies. We close by discussing the space of trade-offs withrespect to model size, latency, and accuracy as well as and suggesting futureapplications to explore.</description><author>Dean Wyatte, Fatemeh Tahmasbi, Ming Li, Thomas Markovich</author><pubDate>Fri, 24 May 2024 18:58:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15765v1</guid></item><item><title>LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</title><link>http://arxiv.org/abs/2403.13372v2</link><description>Efficient fine-tuning is vital for adapting large language models (LLMs) todownstream tasks. However, it requires non-trivial efforts to implement thesemethods on different models. We present LlamaFactory, a unified framework thatintegrates a suite of cutting-edge efficient training methods. It allows usersto flexibly customize the fine-tuning of 100+ LLMs without the need for codingthrough the built-in web UI LlamaBoard. We empirically validate the efficiencyand effectiveness of our framework on language modeling and text generationtasks. It has been released at https://github.com/hiyouga/LLaMA-Factory andalready received over 13,000 stars and 1,600 forks.</description><author>Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Yongqiang Ma</author><pubDate>Thu, 21 Mar 2024 09:36:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13372v2</guid></item><item><title>LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</title><link>http://arxiv.org/abs/2403.13372v1</link><description>Efficient fine-tuning is vital for adapting large language models (LLMs) todownstream tasks. However, it requires non-trivial efforts to implement thesemethods on different models. We present LlamaFactory, a unified framework thatintegrates a suite of cutting-edge efficient training methods. It allows usersto flexibly customize the fine-tuning of 100+ LLMs without the need for codingthrough the built-in web UI LlamaBoard. We empirically validate the efficiencyand effectiveness of our framework on language modeling and text generationtasks. It has been released at https://github.com/hiyouga/LLaMA-Factory andalready received over 13,000 stars and 1,600 forks.</description><author>Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo</author><pubDate>Wed, 20 Mar 2024 09:08:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13372v1</guid></item><item><title>Neuro-Vision to Language: Image Reconstruction and Language enabled Interaction via Brain Recordings</title><link>http://arxiv.org/abs/2404.19438v2</link><description>Decoding non-invasive brain recordings is crucial for advancing ourunderstanding of human cognition, yet faces challenges from individualdifferences and complex neural signal representations. Traditional methodsrequire custom models and extensive trials, and lack interpretability in visualreconstruction tasks. Our framework integrating integrates 3D brain structureswith visual semantics by Vision Transformer 3D. The unified feature extractoraligns fMRI features with multiple levels of visual embeddings efficiently,removing the need for individual-specific models and allowing extraction fromsingle-trial data. This extractor consolidates multi-level visual features intoone network, simplifying integration with Large Language Models (LLMs).Additionally, we have enhanced the fMRI dataset with various fMRI-image relatedtextual data to support multimodal large model development. The integrationwith LLMs enhances decoding capabilities, enabling tasks like brain captioning,question-answering, detailed descriptions, complex reasoning, and visualreconstruction. Our approach not only shows superior performance across thesetasks but also precisely identifies and manipulates language-based conceptswithin brain signals, enhancing interpretability and providing deeper neuralprocess insights. These advances significantly broaden non-invasive braindecoding applicability in neuroscience and human-computer interaction, settingthe stage for advanced brain-computer interfaces and cognitive models.</description><author>Guobin Shen, Dongcheng Zhao, Xiang He, Linghao Feng, Yiting Dong, Jihang Wang, Qian Zhang, Yi Zeng</author><pubDate>Wed, 01 May 2024 09:57:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19438v2</guid></item><item><title>Neuro-Vision to Language: Image Reconstruction and Interaction via Non-invasive Brain Recordings</title><link>http://arxiv.org/abs/2404.19438v1</link><description>Decoding non-invasive brain recordings is crucial for advancing ourunderstanding of human cognition, yet faces challenges from individualdifferences and complex neural signal representations. Traditional methodsrequire custom models and extensive trials, and lack interpretability in visualreconstruction tasks. Our framework integrating integrates 3D brain structureswith visual semantics by Vision Transformer 3D. The unified feature extractoraligns fMRI features with multiple levels of visual embeddings efficiently,removing the need for individual-specific models and allowing extraction fromsingle-trial data. This extractor consolidates multi-level visual features intoone network, simplifying integration with Large Language Models (LLMs).Additionally, we have enhanced the fMRI dataset with various fMRI-image relatedtextual data to support multimodal large model development. The integrationwith LLMs enhances decoding capabilities, enabling tasks like brain captioning,question-answering, detailed descriptions, complex reasoning, and visualreconstruction. Our approach not only shows superior performance across thesetasks but also precisely identifies and manipulates language-based conceptswithin brain signals, enhancing interpretability and providing deeper neuralprocess insights. These advances significantly broaden non-invasive braindecoding applicability in neuroscience and human-computer interaction, settingthe stage for advanced brain-computer interfaces and cognitive models.</description><author>Guobin Shen, Dongcheng Zhao, Xiang He, Linghao Feng, Yiting Dong, Jihang Wang, Qian Zhang, Yi Zeng</author><pubDate>Tue, 30 Apr 2024 11:41:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19438v1</guid></item><item><title>Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents</title><link>http://arxiv.org/abs/2403.06872v1</link><description>Legal judgment prediction suffers from the problem of long case documentsexceeding tens of thousands of words, in general, and having a non-uniformstructure. Predicting judgments from such documents becomes a challenging task,more so on documents with no structural annotation. We explore theclassification of these large legal documents and their lack of structuralinformation with a deep-learning-based hierarchical framework which we callMESc; "Multi-stage Encoder-based Supervised with-clustering"; for judgmentprediction. Specifically, we divide a document into parts to extract theirembeddings from the last four layers of a custom fine-tuned Large LanguageModel, and try to approximate their structure through unsupervised clustering.Which we use in another set of transformer encoder layers to learn theinter-chunk representations. We analyze the adaptability of Large LanguageModels (LLMs) with multi-billion parameters (GPT-Neo, and GPT-J) with thehierarchical framework of MESc and compare them with their standaloneperformance on legal texts. We also study their intra-domain(legal) transferlearning capability and the impact of combining embeddings from their lastlayers in MESc. We test these methods and their effectiveness with extensiveexperiments and ablation studies on legal documents from India, the EuropeanUnion, and the United States with the ILDC dataset and a subset of the LexGLUEdataset. Our approach achieves a minimum total performance gain ofapproximately 2 points over previous state-of-the-art methods.</description><author>Nishchal Prasad, Mohand Boughanem, Taoufiq Dkaki</author><pubDate>Mon, 11 Mar 2024 17:24:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06872v1</guid></item><item><title>Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models</title><link>http://arxiv.org/abs/2402.13064v1</link><description>We introduce Generalized Instruction Tuning (called GLAN), a general andscalable method for instruction tuning of Large Language Models (LLMs). Unlikeprior work that relies on seed examples or existing datasets to constructinstruction tuning data, GLAN exclusively utilizes a pre-curated taxonomy ofhuman knowledge and capabilities as input and generates large-scale syntheticinstruction data across all disciplines. Specifically, inspired by thesystematic structure in human education system, we build the taxonomy bydecomposing human knowledge and capabilities to various fields, sub-fields andultimately, distinct disciplines semi-automatically, facilitated by LLMs.Subsequently, we generate a comprehensive list of subjects for every disciplineand proceed to design a syllabus tailored to each subject, again utilizingLLMs. With the fine-grained key concepts detailed in every class session of thesyllabus, we are able to generate diverse instructions with a broad coverageacross the entire spectrum of human knowledge and skills. Extensive experimentson large language models (e.g., Mistral) demonstrate that GLAN excels inmultiple dimensions from mathematical reasoning, coding, academic exams,logical reasoning to general instruction following without using task-specifictraining data of these tasks. In addition, GLAN allows for easy customizationand new fields or skills can be added by simply incorporating a new node intoour taxonomy.</description><author>Haoran Li, Qingxiu Dong, Zhengyang Tang, Chaojun Wang, Xingxing Zhang, Haoyang Huang, Shaohan Huang, Xiaolong Huang, Zeqiang Huang, Dongdong Zhang, Yuxian Gu, Xin Cheng, Xun Wang, Si-Qing Chen, Li Dong, Wei Lu, Zhifang Sui, Benyou Wang, Wai Lam, Furu Wei</author><pubDate>Tue, 20 Feb 2024 15:00:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13064v1</guid></item><item><title>Synergizing Spatial Optimization with Large Language Models for Open-Domain Urban Itinerary Planning</title><link>http://arxiv.org/abs/2402.07204v2</link><description>In this paper, we introduce the novel task of Open-domain Urban ItineraryPlanning (OUIP), a paradigm designed to generate personalized urban itinerariesfrom user requests articulated in natural language. This approach is differentfrom traditional itinerary planning, which often restricts the granularity ofuser inputs, thus hindering genuine personalization. To this end, we presentItiNera, an OUIP system that synergizes spatial optimization with largelanguage models (LLMs) to provide services that customize urban itinerariesbased on users' needs. Upon receiving the user's itinerary request, the LLMfirst decomposes it into detailed components, identifying key requirements,including preferences and dislikes. Then, we use these specifics to selectcandidate POIs from a large-scale collection using embedding-basedPreference-aware POI Retrieval. Finally, a preference score-based Cluster-awareSpatial Optimization module clusters, filters, and orders these POIs, followedby the LLM for detailed POI selection and organization to craft a personalized,spatially coherent itinerary. Moreover, we created an LLM-based pipeline toupdate and personalize a user-owned POI database. This ensures up-to-date POIinformation, supports itinerary planning, pre-trip research, POI collection,recommendations, and more. To the best of our knowledge, this study marks thefirst integration of LLMs to innovate itinerary planning, with potentialextensions for various urban travel and exploration activities. Offline andonline evaluations demonstrate the capacity of our system to deliver moreresponsive, personalized, and spatially coherent itineraries than currentsolutions. Our system, deployed on an online platform, has attracted thousandsof users for their urban travel planning.</description><author>Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Kebing Hou, Dingyi Zhuang, Xiaotong Guo, Jinhua Zhao, Zhan Zhao, Wei Ma</author><pubDate>Thu, 23 May 2024 11:24:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07204v2</guid></item><item><title>ERATTA: Extreme RAG for Table To Answers with Large Language Models</title><link>http://arxiv.org/abs/2405.03963v1</link><description>Large language models (LLMs) with residual augmented-generation (RAG) havebeen the optimal choice for scalable generative AI solutions in the recentpast. However, the choice of use-cases that incorporate RAG with LLMs have beeneither generic or extremely domain specific, thereby questioning thescalability and generalizability of RAG-LLM approaches. In this work, wepropose a unique LLM-based system where multiple LLMs can be invoked to enabledata authentication, user query routing, data retrieval and custom promptingfor question answering capabilities from data tables that are highly varyingand large in size. Our system is tuned to extract information fromEnterprise-level data products and furnish real time responses under 10seconds. One prompt manages user-to-data authentication followed by threeprompts to route, fetch data and generate a customizable prompt naturallanguage responses. Additionally, we propose a five metric scoring module thatdetects and reports hallucinations in the LLM responses. Our proposed systemand scoring metrics achieve &gt;90% confidence scores across hundreds of userqueries in the sustainability, financial health and social media domains.Extensions to the proposed extreme RAG architectures can enable heterogeneoussource querying using LLMs.</description><author>Sohini Roychowdhury, Marko Krema, Anvar Mahammad, Brian Moore, Arijit Mukherjee, Punit Prakashchandra</author><pubDate>Tue, 07 May 2024 03:49:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03963v1</guid></item><item><title>ERATTA: Extreme RAG for Table To Answers with Large Language Models</title><link>http://arxiv.org/abs/2405.03963v2</link><description>Large language models (LLMs) with retrieval augmented-generation (RAG) havebeen the optimal choice for scalable generative AI solutions in the recentpast. However, the choice of use-cases that incorporate RAG with LLMs have beeneither generic or extremely domain specific, thereby questioning thescalability and generalizability of RAG-LLM approaches. In this work, wepropose a unique LLM-based system where multiple LLMs can be invoked to enabledata authentication, user query routing, data retrieval and custom promptingfor question answering capabilities from data tables that are highly varyingand large in size. Our system is tuned to extract information fromEnterprise-level data products and furnish real time responses under 10seconds. One prompt manages user-to-data authentication followed by threeprompts to route, fetch data and generate a customizable prompt naturallanguage responses. Additionally, we propose a five metric scoring module thatdetects and reports hallucinations in the LLM responses. Our proposed systemand scoring metrics achieve &gt;90% confidence scores across hundreds of userqueries in the sustainability, financial health and social media domains.Extensions to the proposed extreme RAG architectures can enable heterogeneoussource querying using LLMs.</description><author>Sohini Roychowdhury, Marko Krema, Anvar Mahammad, Brian Moore, Arijit Mukherjee, Punit Prakashchandra</author><pubDate>Tue, 14 May 2024 16:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03963v2</guid></item><item><title>Generating Illustrated Instructions</title><link>http://arxiv.org/abs/2312.04552v2</link><description>We introduce the new task of generating Illustrated Instructions, i.e.,visual instructions customized to a user's needs. We identify desiderata uniqueto this task, and formalize it through a suite of automatic and humanevaluation metrics, designed to measure the validity, consistency, and efficacyof the generations. We combine the power of large language models (LLMs)together with strong text-to-image generation diffusion models to propose asimple approach called StackedDiffusion, which generates such illustratedinstructions given text as input. The resulting model strongly outperformsbaseline approaches and state-of-the-art multimodal LLMs; and in 30% of cases,users even prefer it to human-generated articles. Most notably, it enablesvarious new and exciting applications far beyond what static articles on theweb can provide, such as personalized instructions complete with intermediatesteps and pictures in response to a user's individual situation.</description><author>Sachit Menon, Ishan Misra, Rohit Girdhar</author><pubDate>Fri, 12 Apr 2024 19:34:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04552v2</guid></item><item><title>Low-Cost Generation and Evaluation of Dictionary Example Sentences</title><link>http://arxiv.org/abs/2404.06224v1</link><description>Dictionary example sentences play an important role in illustrating worddefinitions and usage, but manually creating quality sentences is challenging.Prior works have demonstrated that language models can be trained to generateexample sentences. However, they relied on costly customized models and wordsense datasets for generation and evaluation of their work. Rapid advancementsin foundational models present the opportunity to create low-cost, zero-shotmethods for the generation and evaluation of dictionary example sentences. Weintroduce a new automatic evaluation metric called OxfordEval that measures thewin-rate of generated sentences against existing Oxford Dictionary sentences.OxfordEval shows high alignment with human judgments, enabling large-scaleautomated quality evaluation. We experiment with various LLMs andconfigurations to generate dictionary sentences across word classes. Wecomplement this with a novel approach of using masked language models toidentify and select sentences that best exemplify word meaning. The eventualmodel, FM-MLM, achieves over 85.1% win rate against Oxford baseline sentencesaccording to OxfordEval, compared to 39.8% win rate for prior model-generatedsentences.</description><author>Bill Cai, Clarence Boon Liang Ng, Daniel Tan, Shelvia Hotama</author><pubDate>Tue, 09 Apr 2024 12:26:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06224v1</guid></item><item><title>Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers</title><link>http://arxiv.org/abs/2404.14680v1</link><description>The task of accurate and efficient language translation is an extremelyimportant information processing task. Machine learning enabled and automatedtranslation that is accurate and fast is often a large topic of interest in themachine learning and data science communities. In this study, we examine usinglocal Generative Pretrained Transformer (GPT) models to perform automated zeroshot black-box, sentence wise, multi-natural-language translation into Englishtext. We benchmark 16 different open-source GPT models, with no customfine-tuning, from the Huggingface LLM repository for translating 50 differentnon-English languages into English using translated TED Talk transcripts as thereference dataset. These GPT model inference calls are performed strictlylocally, on single A100 Nvidia GPUs. Benchmark metrics that are reported arelanguage translation accuracy, using BLEU, GLEU, METEOR, and chrF text overlapmeasures, and wall-clock time for each sentence translation. The best overallperforming GPT model for translating into English text for the BLEU metric isReMM-v2-L2-13B with a mean score across all tested languages of $0.152$, forthe GLEU metric is ReMM-v2-L2-13B with a mean score across all tested languagesof $0.256$, for the chrF metric is Llama2-chat-AYT-13B with a mean score acrossall tested languages of $0.448$, and for the METEOR metric is ReMM-v2-L2-13Bwith a mean score across all tested languages of $0.438$.</description><author>Elijah Pelofske, Vincent Urias, Lorie M. Liebrock</author><pubDate>Tue, 23 Apr 2024 03:19:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14680v1</guid></item><item><title>Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries</title><link>http://arxiv.org/abs/2403.20145v2</link><description>Improving mental health support in developing countries is a pressing need.One potential solution is the development of scalable, automated systems toconduct diagnostic screenings, which could help alleviate the burden on mentalhealth professionals. In this work, we evaluate several state-of-the-art LargeLanguage Models (LLMs), with and without fine-tuning, on our custom dataset forgenerating concise summaries from mental state examinations. We rigorouslyevaluate four different models for summary generation using established ROUGEmetrics and input from human evaluators. The results highlight that ourtop-performing fine-tuned model outperforms existing models, achieving ROUGE-1and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessedthe fine-tuned model's generalizability on a publicly available D4 dataset, andthe outcomes were promising, indicating its potential applicability beyond ourcustom dataset.</description><author>Manjeet Yadav, Nilesh Kumar Sahu, Mudita Chaturvedi, Snehil Gupta, Haroon R Lone</author><pubDate>Thu, 04 Apr 2024 11:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20145v2</guid></item><item><title>Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries</title><link>http://arxiv.org/abs/2403.20145v1</link><description>Improving mental health support in developing countries is a pressing need.One potential solution is the development of scalable, automated systems toconduct diagnostic screenings, which could help alleviate the burden on mentalhealth professionals. In this work, we evaluate several state-of-the-art LargeLanguage Models (LLMs), with and without fine-tuning, on our custom dataset forgenerating concise summaries from mental state examinations. We rigorouslyevaluate four different models for summary generation using established ROUGEmetrics and input from human evaluators. The results highlight that ourtop-performing fine-tuned model outperforms existing models, achieving ROUGE-1and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessedthe fine-tuned model's generalizability on a publicly available D4 dataset, andthe outcomes were promising, indicating its potential applicability beyond ourcustom dataset.</description><author>Manjeet Yadav, Nilesh Kumar Sahu, Mudita Chaturvedi, Snehil Gupta, Haroon R Lone</author><pubDate>Fri, 29 Mar 2024 13:25:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20145v1</guid></item><item><title>Text Understanding and Generation Using Transformer Models for Intelligent E-commerce Recommendations</title><link>http://arxiv.org/abs/2402.16035v1</link><description>With the rapid development of artificial intelligence technology, Transformerstructural pre-training model has become an important tool for large languagemodel (LLM) tasks. In the field of e-commerce, these models are especiallywidely used, from text understanding to generating recommendation systems,which provide powerful technical support for improving user experience andoptimizing service processes. This paper reviews the core application scenariosof Transformer pre-training model in e-commerce text understanding andrecommendation generation, including but not limited to automatic generation ofproduct descriptions, sentiment analysis of user comments, construction ofpersonalized recommendation system and automated processing of customer serviceconversations. Through a detailed analysis of the model's working principle,implementation process, and application effects in specific cases, this paperemphasizes the unique advantages of pre-trained models in understanding complexuser intentions and improving the quality of recommendations. In addition, thechallenges and improvement directions for the future are also discussed, suchas how to further improve the generalization ability of the model, the abilityto handle large-scale data sets, and technical strategies to protect userprivacy. Ultimately, the paper points out that the application of Transformerstructural pre-training models in e-commerce has not only driven technologicalinnovation, but also brought substantial benefits to merchants and consumers,and looking forward, these models will continue to play a key role ine-commerce and beyond.</description><author>Yafei Xiang, Hanyi Yu, Yulu Gong, Shuning Huo, Mengran Zhu</author><pubDate>Sun, 25 Feb 2024 09:19:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16035v1</guid></item><item><title>PromptFix: You Prompt and We Fix the Photo</title><link>http://arxiv.org/abs/2405.16785v1</link><description>Diffusion models equipped with language models demonstrate excellentcontrollability in image generation tasks, allowing image processing to adhereto human instructions. However, the lack of diverse instruction-following datahampers the development of models that effectively recognize and executeuser-customized instructions, particularly in low-level tasks. Moreover, thestochastic nature of the diffusion process leads to deficiencies in imagegeneration or editing tasks that require the detailed preservation of thegenerated images. To address these limitations, we propose PromptFix, acomprehensive framework that enables diffusion models to follow humaninstructions to perform a wide variety of image-processing tasks. First, weconstruct a large-scale instruction-following dataset that covers comprehensiveimage-processing tasks, including low-level tasks, image editing, and objectcreation. Next, we propose a high-frequency guidance sampling method toexplicitly control the denoising process and preserve high-frequency details inunprocessed areas. Finally, we design an auxiliary prompting adapter, utilizingVision-Language Models (VLMs) to enhance text prompts and improve the model'stask generalization. Experimental results show that PromptFix outperformsprevious methods in various image-processing tasks. Our proposed model alsoachieves comparable inference efficiency with these baseline models andexhibits superior zero-shot capabilities in blind restoration and combinationtasks. The dataset and code will be aviliable athttps://github.com/yeates/PromptFix.</description><author>Yongsheng Yu, Ziyun Zeng, Hang Hua, Jianlong Fu, Jiebo Luo</author><pubDate>Mon, 27 May 2024 04:13:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16785v1</guid></item><item><title>Automatic Histograms: Leveraging Language Models for Text Dataset Exploration</title><link>http://arxiv.org/abs/2402.14880v1</link><description>Making sense of unstructured text datasets is perennially difficult, yetincreasingly relevant with Large Language Models. Data workers often rely ondataset summaries, especially distributions of various derived features. Somefeatures, like toxicity or topics, are relevant to many datasets, but manyinteresting features are domain specific: instruments and genres for a musicdataset, or diseases and symptoms for a medical dataset. Accordingly, dataworkers often run custom analyses for each dataset, which is cumbersome anddifficult. We present AutoHistograms, a visualization tool leveragingLLMs.AutoHistograms automatically identifies relevant features, visualizes them withhistograms, and allows the user to interactively query the dataset forcategories of entities and create new histograms. In a user study with 10 dataworkers (n=10), we observe that participants can quickly identify insights andexplore the data using AutoHistograms, and conceptualize a broad range ofapplicable use cases. Together, this tool and user study contributeto thegrowing field of LLM-assisted sensemaking tools.</description><author>Emily Reif, Crystal Qian, James Wexler, Minsuk Kahng</author><pubDate>Wed, 21 Feb 2024 22:29:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14880v1</guid></item><item><title>Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2404.18564v1</link><description>Recent research in dialogue systems and corpora has focused on two maincategories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TODsystems help users accomplish specific tasks, while open-domain systems aim tocreate engaging conversations. However, in real-world scenarios, user intentsare often revealed during interactions. A recent study introduced SalesBot,which simulates dialogues transitioning from chit-chat to task-orientedscenarios to train sales agents. Unfortunately, the initial data lacked smoothtransitions and coherent long-turn dialogues, resulting in poor naturalness insales-customer interactions. To address these issues, this paper presentsSalesBot 2.0, an improved dataset. It leverages commonsense knowledge fromlarge language models (LLMs) through strategic prompting. Additionally, weintroduce a novel model called SalesAgent, trained on salesperson'sinteractions, using chain-of-thought (CoT) reasoning. This model excels intransitioning topics, understanding user intents, and selecting appropriatestrategies. Experiments using diverse user simulations validate theeffectiveness of our method in controlling dialogue strategies in LLMs.Furthermore, SalesBot 2.0 enhances coherence and reduces aggression,facilitating better model learning for sales-customer interactions.</description><author>Wen-Yu Chang, Yun-Nung Chen</author><pubDate>Mon, 29 Apr 2024 11:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18564v1</guid></item><item><title>Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains</title><link>http://arxiv.org/abs/2402.05140v2</link><description>Large Language Models (LLMs) have demonstrated remarkable proficiency inunderstanding and generating natural language. However, their capabilities wanein highly specialized domains underrepresented in the pretraining corpus, suchas physical and biomedical sciences. This work explores how to repurposegeneral LLMs into effective task solvers for specialized domains. We introducea novel, model-agnostic framework for learning custom input tags, which areparameterized as continuous vectors appended to the LLM's embedding layer, tocondition the LLM. We design two types of input tags: domain tags are used todelimit specialized representations (e.g., chemical formulas) and providedomain-relevant context; function tags are used to represent specific functions(e.g., predicting molecular properties) and compress function-solvinginstructions. We develop a three-stage protocol to learn these tags usingauxiliary data and domain knowledge. By explicitly disentangling task domainsfrom task functions, our method enables zero-shot generalization to unseenproblems through diverse combinations of the input tags. It also boosts LLM'sperformance in various specialized domains, such as predicting protein orchemical properties and modeling drug-target interactions, outperforming expertmodels tailored to these tasks.</description><author>Junhong Shen, Neil Tenenholtz, James Brian Hall, David Alvarez-Melis, Nicolo Fusi</author><pubDate>Thu, 30 May 2024 18:37:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05140v2</guid></item><item><title>DeAL: Decoding-time Alignment for Large Language Models</title><link>http://arxiv.org/abs/2402.06147v2</link><description>Large Language Models (LLMs) are nowadays expected to generate contentaligned with human preferences. Current work focuses on alignment at modeltraining time, through techniques such as Reinforcement Learning with HumanFeedback (RLHF). However, it is unclear if such methods are an effective choiceto teach alignment objectives to the model. First, the inability to incorporatemultiple, custom rewards and reliance on a model developer's view of universaland static principles are key limitations. Second, the residual gaps in modeltraining and the reliability of such approaches are also questionable (e.g.susceptibility to jail-breaking even after safety training). To address these,we propose DeAL, a framework that allows the user to customize reward functionsand enables Decoding-time Alignment of LLMs (DeAL). At its core, we viewdecoding as a heuristic-guided search process and facilitate the use of a widevariety of alignment objectives. Our experiments with programmatic constraintssuch as keyword and length constraints (studied widely in the pre-LLM era) andabstract objectives such as harmlessness and helpfulness (proposed in thepost-LLM era) show that we can DeAL with fine-grained trade-offs, improveadherence to alignment objectives, and address residual gaps in LLMs. Lastly,while DeAL can be effectively paired with RLHF and prompting techniques, itsgenerality makes decoding slower, an optimization we leave for future work.</description><author>James Y. Huang, Sailik Sengupta, Daniele Bonadiman, Yi-an Lai, Arshit Gupta, Nikolaos Pappas, Saab Mansour, Katrin Kirchhoff, Dan Roth</author><pubDate>Wed, 21 Feb 2024 02:25:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06147v2</guid></item><item><title>Optimizing Machine Translation through Prompt Engineering: An Investigation into ChatGPT's Customizability</title><link>http://arxiv.org/abs/2308.01391v2</link><description>This paper explores the influence of integrating the purpose of thetranslation and the target audience into prompts on the quality of translationsproduced by ChatGPT. Drawing on previous translation studies, industrypractices, and ISO standards, the research underscores the significance of thepre-production phase in the translation process. The study reveals that theinclusion of suitable prompts in large-scale language models like ChatGPT canyield flexible translations, a feat yet to be realized by conventional MachineTranslation (MT). The research scrutinizes the changes in translation qualitywhen prompts are used to generate translations that meet specific conditions.The evaluation is conducted from a practicing translator's viewpoint, bothsubjectively and qualitatively, supplemented by the use of OpenAI's wordembedding API for cosine similarity calculations. The findings suggest that theintegration of the purpose and target audience into prompts can indeed modifythe generated translations, generally enhancing the translation quality byindustry standards. The study also demonstrates the practical application ofthe "good translation" concept, particularly in the context of marketingdocuments and culturally dependent idioms.</description><author>Masaru Yamada</author><pubDate>Wed, 21 Feb 2024 07:24:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01391v2</guid></item><item><title>Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients</title><link>http://arxiv.org/abs/2402.10153v1</link><description>Effective diabetes management is crucial for maintaining health in diabeticpatients. Large Language Models (LLMs) have opened new avenues for diabetesmanagement, facilitating their efficacy. However, current LLM-based approachesare limited by their dependence on general sources and lack of integration withdomain-specific knowledge, leading to inaccurate responses. In this paper, wepropose a knowledge-infused LLM-powered conversational health agent (CHA) fordiabetic patients. We customize and leverage the open-source openCHA framework,enhancing our CHA with external knowledge and analytical capabilities. Thisintegration involves two key components: 1) incorporating the American DiabetesAssociation dietary guidelines and the Nutritionix information and 2) deployinganalytical tools that enable nutritional intake calculation and comparison withthe guidelines. We compare the proposed CHA with GPT4. Our evaluation includes100 diabetes-related questions on daily meal choices and assessing thepotential risks associated with the suggested diet. Our findings show that theproposed agent demonstrates superior performance in generating responses tomanage essential nutrients.</description><author>Mahyar Abbasian, Zhongqi Yang, Elahe Khatibi, Pengfei Zhang, Nitish Nagesh, Iman Azimi, Ramesh Jain, Amir M. Rahmani</author><pubDate>Thu, 15 Feb 2024 18:00:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10153v1</guid></item><item><title>Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients</title><link>http://arxiv.org/abs/2402.10153v2</link><description>Effective diabetes management is crucial for maintaining health in diabeticpatients. Large Language Models (LLMs) have opened new avenues for diabetesmanagement, facilitating their efficacy. However, current LLM-based approachesare limited by their dependence on general sources and lack of integration withdomain-specific knowledge, leading to inaccurate responses. In this paper, wepropose a knowledge-infused LLM-powered conversational health agent (CHA) fordiabetic patients. We customize and leverage the open-source openCHA framework,enhancing our CHA with external knowledge and analytical capabilities. Thisintegration involves two key components: 1) incorporating the American DiabetesAssociation dietary guidelines and the Nutritionix information and 2) deployinganalytical tools that enable nutritional intake calculation and comparison withthe guidelines. We compare the proposed CHA with GPT4. Our evaluation includes100 diabetes-related questions on daily meal choices and assessing thepotential risks associated with the suggested diet. Our findings show that theproposed agent demonstrates superior performance in generating responses tomanage essential nutrients.</description><author>Mahyar Abbasian, Zhongqi Yang, Elahe Khatibi, Pengfei Zhang, Nitish Nagesh, Iman Azimi, Ramesh Jain, Amir M. Rahmani</author><pubDate>Wed, 28 Feb 2024 19:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10153v2</guid></item><item><title>Jellyfish: A Large Language Model for Data Preprocessing</title><link>http://arxiv.org/abs/2312.01678v5</link><description>This paper explores the utilization of LLMs for data preprocessing (DP), acrucial step in the data mining pipeline that transforms raw data into a cleanformat conducive to easy processing. Whereas the use of LLMs has sparkedinterest in devising universal solutions to DP, recent initiatives in thisdomain typically rely on GPT APIs, raising inevitable data breach concerns.Unlike these approaches, we consider instruction-tuning local LLMs (7 -- 13Bmodels) as universal DP task solvers that operate on a local, single, andlow-priced GPU, ensuring data security and enabling further customization. Weselect a collection of datasets across four representative DP tasks andconstruct instruction tuning data using data configuration, knowledgeinjection, and reasoning data distillation techniques tailored to DP. By tuningMistral-7B, Llama 3-8B, and OpenOrca-Platypus2-13B, our models, namely,Jellyfish-7B/8B/13B, deliver competitiveness compared to GPT-3.5/4 models andstrong generalizability to unseen tasks while barely compromising the basemodels' abilities in NLP tasks. Meanwhile, Jellyfish offers enhanced reasoningcapabilities compared to GPT-3.5. Our models are available at: https://huggingface.co/NECOUDBFM/Jellyfish . Our instruction dataset is available at:https://huggingface.co/datasets/NECOUDBFM/Jellyfish-Instruct .</description><author>Haochen Zhang, Yuyang Dong, Chuan Xiao, Masafumi Oyamada</author><pubDate>Fri, 21 Jun 2024 10:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01678v5</guid></item></channel></rss>