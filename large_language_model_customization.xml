<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivlarge language model customization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 28 Apr 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Rapid Adoption, Hidden Risks: The Dual Impact of Large Language Model Customization</title><link>http://arxiv.org/abs/2402.09179v2</link><description>The increasing demand for customized Large Language Models (LLMs) has led tothe development of solutions like GPTs. These solutions facilitate tailored LLMcreation via natural language prompts without coding. However, thetrustworthiness of third-party custom versions of LLMs remains an essentialconcern. In this paper, we propose the first instruction backdoor attacksagainst applications integrated with untrusted customized LLMs (e.g., GPTs).Specifically, these attacks embed the backdoor into the custom version of LLMsby designing prompts with backdoor instructions, outputting the attacker'sdesired result when inputs contain the pre-defined triggers. Our attackincludes 3 levels of attacks: word-level, syntax-level, and semantic-level,which adopt different types of triggers with progressive stealthiness. Westress that our attacks do not require fine-tuning or any modification to thebackend LLMs, adhering strictly to GPTs development guidelines. We conductextensive experiments on 4 prominent LLMs and 5 benchmark text classificationdatasets. The results show that our instruction backdoor attacks achieve thedesired attack performance without compromising utility. Additionally, wepropose an instruction-ignoring defense mechanism and demonstrate its partialeffectiveness in mitigating such attacks. Our findings highlight thevulnerability and the potential risks of LLM customization such as GPTs.</description><author>Rui Zhang, Hongwei Li, Rui Wen, Wenbo Jiang, Yuan Zhang, Michael Backes, Yun Shen, Yang Zhang</author><pubDate>Thu, 15 Feb 2024 06:15:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09179v2</guid></item><item><title>LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks</title><link>http://arxiv.org/abs/2402.11455v1</link><description>LoRA employs lightweight modules to customize large language models (LLMs)for each downstream task or domain, where different learned additional modulesrepresent diverse skills. Combining existing LoRAs to address new tasks canenhance the reusability of learned LoRAs, particularly beneficial for taskswith limited annotated data. Most prior works on LoRA combination primarilyrely on task-level weights for each involved LoRA, making different examplesand tokens share the same LoRA weights. However, in generative tasks, differenttokens may necessitate diverse skills to manage. Taking the Chinese math taskas an example, understanding the problem description may depend more on theChinese LoRA, while the calculation part may rely more on the math LoRA. Tothis end, we propose LoRA-Flow, which utilizes dynamic weights to adjust theimpact of different LoRAs. The weights at each step are determined by a fusiongate with extremely few parameters, which can be learned with only 200 trainingexamples. Experiments across six generative tasks demonstrate that our methodconsistently outperforms baselines with task-level fusion weights. Thisunderscores the necessity of introducing dynamic fusion weights for LoRAcombination.</description><author>Hanqing Wang, Bowen Ping, Shuo Wang, Xu Han, Yun Chen, Zhiyuan Liu, Maosong Sun</author><pubDate>Sun, 18 Feb 2024 04:41:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11455v1</guid></item><item><title>Nyonic Technical Report</title><link>http://arxiv.org/abs/2404.15702v1</link><description>This report details the development and key achievements of our latestlanguage model designed for custom large language models. The advancementsintroduced include a novel Online Data Scheduler that supports flexibletraining data adjustments and curriculum learning. The model's architecture isfortified with state-of-the-art techniques such as Rotary PositionalEmbeddings, QK-LayerNorm, and a specially crafted multilingual tokenizer toenhance stability and performance. Moreover, our robust training frameworkincorporates advanced monitoring and rapid recovery features to ensure optimalefficiency. Our Wonton 7B model has demonstrated competitive performance on arange of multilingual and English benchmarks. Future developments willprioritize narrowing the performance gap with more extensively trained models,thereby enhancing the model's real-world efficacy and adaptability.GitHub:\url{https://github.com/nyonicai/nyonic-public}</description><author>Junfeng Tian, Rui Wang, Cong Li, Yudong Zhou, Jun Liu, Jun Wang</author><pubDate>Wed, 24 Apr 2024 08:38:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15702v1</guid></item><item><title>Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks</title><link>http://arxiv.org/abs/2403.02238v1</link><description>The integration of Machine Learning and Artificial Intelligence (ML/AI) intofifth-generation (5G) networks has made evident the limitations of networkintelligence with ever-increasing, strenuous requirements for current andnext-generation devices. This transition to ubiquitous intelligence demandshigh connectivity, synchronicity, and end-to-end communication between usersand network operators, and will pave the way towards full network automationwithout human intervention. Intent-based networking is a key factor in thereduction of human actions, roles, and responsibilities while shifting towardsnovel extraction and interpretation of automated network management. This paperpresents the development of a custom Large Language Model (LLM) for 5G andnext-generation intent-based networking and provides insights into future LLMdevelopments and integrations to realize end-to-end intent-based networking forfully automated network intelligence.</description><author>Dimitrios Michael Manias, Ali Chouman, Abdallah Shami</author><pubDate>Mon, 04 Mar 2024 17:29:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02238v1</guid></item><item><title>Generative AI in the Construction Industry: A State-of-the-art Analysis</title><link>http://arxiv.org/abs/2402.09939v1</link><description>The construction industry is a vital sector of the global economy, but itfaces many productivity challenges in various processes, such as design,planning, procurement, inspection, and maintenance. Generative artificialintelligence (AI), which can create novel and realistic data or content, suchas text, image, video, or code, based on some input or prior knowledge, offersinnovative and disruptive solutions to address these challenges. However, thereis a gap in the literature on the current state, opportunities, and challengesof generative AI in the construction industry. This study aims to fill this gapby providing a state-of-the-art analysis of generative AI in construction, withthree objectives: (1) to review and categorize the existing and emerginggenerative AI opportunities and challenges in the construction industry; (2) topropose a framework for construction firms to build customized generative AIsolutions using their own data, comprising steps such as data collection,dataset curation, training custom large language model (LLM), model evaluation,and deployment; and (3) to demonstrate the framework via a case study ofdeveloping a generative model for querying contract documents. The results showthat retrieval augmented generation (RAG) improves the baseline LLM by 5.2,9.4, and 4.8% in terms of quality, relevance, and reproducibility. This studyprovides academics and construction professionals with a comprehensive analysisand practical framework to guide the adoption of generative AI techniques toenhance productivity, quality, safety, and sustainability across theconstruction industry.</description><author>Ridwan Taiwo, Idris Temitope Bello, Sulemana Fatoama Abdulai, Abdul-Mugis Yussif, Babatunde Abiodun Salami, Abdullahi Saka, Tarek Zayed</author><pubDate>Thu, 15 Feb 2024 13:39:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09939v1</guid></item><item><title>Prompt Engineering a Prompt Engineer</title><link>http://arxiv.org/abs/2311.05661v2</link><description>Prompt engineering is a challenging yet crucial task for optimizing theperformance of large language models on customized tasks. It requires complexreasoning to examine the model's errors, hypothesize what is missing ormisleading in the current prompt, and communicate the task with clarity. Whilerecent works indicate that large language models can be meta-prompted toperform automatic prompt engineering, we argue that their potential is limiteddue to insufficient guidance for complex reasoning in the meta-prompt. We fillthis gap by infusing into the meta-prompt three key components: detaileddescriptions, context specification, and a step-by-step reasoning template. Theresulting method, named PE2, showcases remarkable versatility across diverselanguage tasks. It finds prompts that outperform "let's think step by step" by6.3% on MultiArith and 3.1% on GSM8K, and outperforms competitive baselines oncounterfactual tasks by 6.9%. Further, we show that PE2 can make targetedprompt edits, rectify erroneous prompts, and induce multi-step plans forcomplex tasks.</description><author>Qinyuan Ye, Maxamed Axmed, Reid Pryzant, Fereshte Khani</author><pubDate>Mon, 19 Feb 2024 19:46:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05661v2</guid></item><item><title>CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models</title><link>http://arxiv.org/abs/2402.15265v1</link><description>Large language models (LLMs) have facilitated significant strides ingenerating conversational agents, enabling seamless, contextually relevantdialogues across diverse topics. However, the existing LLM-drivenconversational agents have fixed personalities and functionalities, limitingtheir adaptability to individual user needs. Creating personalized agentpersonas with distinct expertise or traits can address this issue. Nonetheless,we lack knowledge of how people customize and interact with agent personas. Inthis research, we investigated how users customize agent personas and theirimpact on interaction quality, diversity, and dynamics. To this end, wedeveloped CloChat, an interface supporting easy and accurate customization ofagent personas in LLMs. We conducted a study comparing how participantsinteract with CloChat and ChatGPT. The results indicate that participantsformed emotional bonds with the customized agents, engaged in more dynamicdialogues, and showed interest in sustaining interactions. These findingscontribute to design implications for future systems with conversational agentsusing LLMs.</description><author>Juhye Ha, Hyeon Jeon, DaEun Han, Jinwook Seo, Changhoon Oh</author><pubDate>Fri, 23 Feb 2024 11:25:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15265v1</guid></item><item><title>Customizing Language Model Responses with Contrastive In-Context Learning</title><link>http://arxiv.org/abs/2401.17390v2</link><description>Large language models (LLMs) are becoming increasingly important for machinelearning applications. However, it can be challenging to align LLMs with ourintent, particularly when we want to generate content that is preferable overothers or when we want the LLM to respond in a certain style or tone that ishard to describe. To address this challenge, we propose an approach that usescontrastive examples to better describe our intent. This involves providingpositive examples that illustrate the true intent, along with negative examplesthat show what characteristics we want LLMs to avoid. The negative examples canbe retrieved from labeled data, written by a human, or generated by the LLMitself. Before generating an answer, we ask the model to analyze the examplesto teach itself what to avoid. This reasoning step provides the model with theappropriate articulation of the user's need and guides it towards generting abetter answer. We tested our approach on both synthesized and real-worlddatasets, including StackExchange and Reddit, and found that it significantlyimproves performance compared to standard few-shot prompting</description><author>Xiang Gao, Kamalika Das</author><pubDate>Mon, 08 Apr 2024 06:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17390v2</guid></item><item><title>Driving Everywhere with Large Language Model Policy Adaptation</title><link>http://arxiv.org/abs/2402.05932v2</link><description>Adapting driving behavior to new environments, customs, and laws is along-standing problem in autonomous driving, precluding the widespreaddeployment of autonomous vehicles (AVs). In this paper, we present LLaDA, asimple yet powerful tool that enables human drivers and autonomous vehiclesalike to drive everywhere by adapting their tasks and motion plans to trafficrules in new locations. LLaDA achieves this by leveraging the impressivezero-shot generalizability of large language models (LLMs) in interpreting thetraffic rules in the local driver handbook. Through an extensive user study, weshow that LLaDA's instructions are useful in disambiguating in-the-wildunexpected situations. We also demonstrate LLaDA's ability to adapt AV motionplanning policies in real-world datasets; LLaDA outperforms baseline planningapproaches on all our metrics. Please check our website for more details:https://boyiliee.github.io/llada.</description><author>Boyi Li, Yue Wang, Jiageng Mao, Boris Ivanovic, Sushant Veer, Karen Leung, Marco Pavone</author><pubDate>Thu, 11 Apr 2024 00:29:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05932v2</guid></item><item><title>ChipNeMo: Domain-Adapted LLMs for Chip Design</title><link>http://arxiv.org/abs/2311.00176v4</link><description>ChipNeMo aims to explore the applications of large language models (LLMs) forindustrial chip design. Instead of directly deploying off-the-shelf commercialor open-source LLMs, we instead adopt the following domain adaptationtechniques: domain-adaptive tokenization, domain-adaptive continuedpretraining, model alignment with domain-specific instructions, anddomain-adapted retrieval models. We evaluate these methods on three selectedLLM applications for chip design: an engineering assistant chatbot, EDA scriptgeneration, and bug summarization and analysis. Our evaluations demonstratethat domain-adaptive pretraining of language models, can lead to superiorperformance in domain related downstream tasks compared to their base LLaMA2counterparts, without degradations in generic capabilities. In particular, ourlargest model, ChipNeMo-70B, outperforms the highly capable GPT-4 on two of ouruse cases, namely engineering assistant chatbot and EDA scripts generation,while exhibiting competitive performance on bug summarization and analysis.These results underscore the potential of domain-specific customization forenhancing the effectiveness of large language models in specializedapplications.</description><author>Mingjie Liu, Teodor-Dumitru Ene, Robert Kirby, Chris Cheng, Nathaniel Pinckney, Rongjian Liang, Jonah Alben, Himyanshu Anand, Sanmitra Banerjee, Ismet Bayraktaroglu, Bonita Bhaskaran, Bryan Catanzaro, Arjun Chaudhuri, Sharon Clay, Bill Dally, Laura Dang, Parikshit Deshpande, Siddhanth Dhodhi, Sameer Halepete, Eric Hill, Jiashang Hu, Sumit Jain, Ankit Jindal, Brucek Khailany, George Kokai, Kishor Kunal, Xiaowei Li, Charley Lind, Hao Liu, Stuart Oberman, Sujeet Omar, Sreedhar Pratty, Jonathan Raiman, Ambar Sarkar, Zhengjiang Shao, Hanfei Sun, Pratik P Suthar, Varun Tej, Walker Turner, Kaizhe Xu, Haoxing Ren</author><pubDate>Thu, 07 Mar 2024 01:10:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00176v4</guid></item><item><title>ChipNeMo: Domain-Adapted LLMs for Chip Design</title><link>http://arxiv.org/abs/2311.00176v5</link><description>ChipNeMo aims to explore the applications of large language models (LLMs) forindustrial chip design. Instead of directly deploying off-the-shelf commercialor open-source LLMs, we instead adopt the following domain adaptationtechniques: domain-adaptive tokenization, domain-adaptive continuedpretraining, model alignment with domain-specific instructions, anddomain-adapted retrieval models. We evaluate these methods on three selectedLLM applications for chip design: an engineering assistant chatbot, EDA scriptgeneration, and bug summarization and analysis. Our evaluations demonstratethat domain-adaptive pretraining of language models, can lead to superiorperformance in domain related downstream tasks compared to their base LLaMA2counterparts, without degradations in generic capabilities. In particular, ourlargest model, ChipNeMo-70B, outperforms the highly capable GPT-4 on two of ouruse cases, namely engineering assistant chatbot and EDA scripts generation,while exhibiting competitive performance on bug summarization and analysis.These results underscore the potential of domain-specific customization forenhancing the effectiveness of large language models in specializedapplications.</description><author>Mingjie Liu, Teodor-Dumitru Ene, Robert Kirby, Chris Cheng, Nathaniel Pinckney, Rongjian Liang, Jonah Alben, Himyanshu Anand, Sanmitra Banerjee, Ismet Bayraktaroglu, Bonita Bhaskaran, Bryan Catanzaro, Arjun Chaudhuri, Sharon Clay, Bill Dally, Laura Dang, Parikshit Deshpande, Siddhanth Dhodhi, Sameer Halepete, Eric Hill, Jiashang Hu, Sumit Jain, Ankit Jindal, Brucek Khailany, George Kokai, Kishor Kunal, Xiaowei Li, Charley Lind, Hao Liu, Stuart Oberman, Sujeet Omar, Ghasem Pasandi, Sreedhar Pratty, Jonathan Raiman, Ambar Sarkar, Zhengjiang Shao, Hanfei Sun, Pratik P Suthar, Varun Tej, Walker Turner, Kaizhe Xu, Haoxing Ren</author><pubDate>Thu, 04 Apr 2024 21:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00176v5</guid></item><item><title>ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors</title><link>http://arxiv.org/abs/2402.16444v1</link><description>The safety of Large Language Models (LLMs) has gained increasing attention inrecent years, but there still lacks a comprehensive approach for detectingsafety issues within LLMs' responses in an aligned, customizable andexplainable manner. In this paper, we propose ShieldLM, an LLM-based safetydetector, which aligns with general human safety standards, supportscustomizable detection rules, and provides explanations for its decisions. Totrain ShieldLM, we compile a large bilingual dataset comprising 14,387query-response pairs, annotating the safety of responses based on varioussafety standards. Through extensive experiments, we demonstrate that ShieldLMsurpasses strong baselines across four test sets, showcasing remarkablecustomizability and explainability. Besides performing well on standarddetection datasets, ShieldLM has also been shown to be effective in real-worldsituations as a safety evaluator for advanced LLMs. We release ShieldLM at\url{https://github.com/thu-coai/ShieldLM} to support accurate and explainablesafety detection under various safety standards, contributing to the ongoingefforts to enhance the safety of LLMs.</description><author>Zhexin Zhang, Yida Lu, Jingyuan Ma, Di Zhang, Rui Li, Pei Ke, Hao Sun, Lei Sha, Zhifang Sui, Hongning Wang, Minlie Huang</author><pubDate>Mon, 26 Feb 2024 09:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16444v1</guid></item><item><title>LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain</title><link>http://arxiv.org/abs/2402.14871v1</link><description>In the last years' digitalization process, the creation and management ofdocuments in various domains, particularly in Public Administration (PA), havebecome increasingly complex and diverse. This complexity arises from the needto handle a wide range of document types, often characterized bysemi-structured forms. Semi-structured documents present a fixed set of datawithout a fixed format. As a consequence, a template-based solution cannot beused, as understanding a document requires the extraction of the datastructure. The recent introduction of Large Language Models (LLMs) has enabledthe creation of customized text output satisfying user requests. In this work,we propose a novel approach that combines the LLMs with prompt engineering andmulti-agent systems for generating new documents compliant with a desiredstructure. The main contribution of this work concerns replacing the commonlyused manual prompting with a task description generated by semantic retrievalfrom an LLM. The potential of this approach is demonstrated through a series ofexperiments and case studies, showcasing its effectiveness in real-world PAscenarios.</description><author>Emanuele Musumeci, Michele Brienza, Vincenzo Suriani, Daniele Nardi, Domenico Daniele Bloisi</author><pubDate>Wed, 21 Feb 2024 13:54:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14871v1</guid></item><item><title>Evaluating Large Language Models in Theory of Mind Tasks</title><link>http://arxiv.org/abs/2302.02083v6</link><description>Eleven Large Language Models (LLMs) were assessed using a custom-made batteryof false-belief tasks, considered a gold standard in testing Theory of Mind(ToM) in humans. The battery included 640 prompts spread across 40 diversetasks, each one including a false-belief scenario, three closely matchedtrue-belief control scenarios, and the reversed versions of all four. To solvea single task, a model needed to correctly answer 16 prompts across all eightscenarios. Smaller and older models solved no tasks; GPT-3-davinci-003 (fromNovember 2022) and ChatGPT-3.5-turbo (from March 2023) solved 20% of the tasks;ChatGPT-4 (from June 2023) solved 75% of the tasks, matching the performance ofsix-year-old children observed in past studies. We explore the potentialinterpretation of these findings, including the intriguing possibility thatToM, previously considered exclusive to humans, may have spontaneously emergedas a byproduct of LLMs' improving language skills.</description><author>Michal Kosinski</author><pubDate>Sat, 17 Feb 2024 02:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02083v6</guid></item><item><title>Controlled Text Generation via Language Model Arithmetic</title><link>http://arxiv.org/abs/2311.14479v2</link><description>As Large Language Models (LLMs) are deployed more widely, customization withrespect to vocabulary, style, and character becomes more important. In thiswork, we introduce model arithmetic, a novel inference framework for composingand biasing LLMs without the need for model (re)training or highly specificdatasets. In addition, the framework allows for more precise control ofgenerated text than direct prompting and prior controlled text generation (CTG)techniques. Using model arithmetic, we can express prior CTG techniques assimple formulas and naturally extend them to new and more effectiveformulations. Further, we show that speculative sampling, a technique forefficient LLM sampling, extends to our setting. This enables highly efficienttext generation with multiple composed models with only marginal overhead overa single model. Our empirical evaluation demonstrates that model arithmeticallows fine-grained control of generated text while outperformingstate-of-the-art on the task of toxicity reduction. We release an open sourceeasy-to-use implementation of our framework athttps://github.com/eth-sri/language-model-arithmetic.</description><author>Jasper Dekoninck, Marc Fischer, Luca Beurer-Kellner, Martin Vechev</author><pubDate>Wed, 06 Mar 2024 09:36:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14479v2</guid></item><item><title>Large Language Models meet Network Slicing Management and Orchestration</title><link>http://arxiv.org/abs/2403.13721v1</link><description>Network slicing, a cornerstone technology for future networks, enables thecreation of customized virtual networks on a shared physical infrastructure.This fosters innovation and agility by providing dedicated resources tailoredto specific applications. However, current orchestration and managementapproaches face limitations in handling the complexity of new service demandswithin multi-administrative domain environments. This paper proposes a futurevision for network slicing powered by Large Language Models (LLMs) andmulti-agent systems, offering a framework that can be integrated with existingManagement and Orchestration (MANO) frameworks. This framework leverages LLMsto translate user intent into technical requirements, map network functions toinfrastructure, and manage the entire slice lifecycle, while multi-agentsystems facilitate collaboration across different administrative domains. Wealso discuss the challenges associated with implementing this framework andpotential solutions to mitigate them.</description><author>Abdulhalim Dandoush, Viswanath Kumarskandpriya, Mueen Uddin, Usman Khalil</author><pubDate>Wed, 20 Mar 2024 17:29:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13721v1</guid></item><item><title>Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement</title><link>http://arxiv.org/abs/2403.03188v1</link><description>Real-time flood forecasting plays a crucial role in enabling timely andeffective emergency responses. However, a significant challenge lies inbridging the gap between complex numerical flood models and practicaldecision-making. Decision-makers often rely on experts to interpret thesemodels for optimizing flood mitigation strategies. And the public requirescomplex techniques to inquiry and understand socio-cultural and institutionalfactors, often hinders the public's understanding of flood risks. To overcomethese challenges, our study introduces an innovative solution: a customized AIAssistant powered by the GPT-4 Large Language Model. This AI Assistant isdesigned to facilitate effective communication between decision-makers, thegeneral public, and flood forecasters, without the requirement of specializedknowledge. The new framework utilizes GPT-4's advanced natural languageunderstanding and function calling capabilities to provide immediate floodalerts and respond to various flood-related inquiries. Our developed prototypeintegrates real-time flood warnings with flood maps and social vulnerabilitydata. It also effectively translates complex flood zone information intoactionable risk management advice. To assess its performance, we evaluated theprototype using six criteria within three main categories: relevance, errorresilience, and understanding of context. Our research marks a significant steptowards a more accessible and user-friendly approach in flood risk management.This study highlights the potential of advanced AI tools like GPT-4 indemocratizing information and enhancing public engagement in critical socialand environmental issues.</description><author>Rafaela Martelo, Ruo-Qian Wang</author><pubDate>Tue, 05 Mar 2024 18:24:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03188v1</guid></item><item><title>CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets</title><link>http://arxiv.org/abs/2309.17428v2</link><description>Large language models (LLMs) are often augmented with tools to solve complextasks. By generating code snippets and executing them through task-specificApplication Programming Interfaces (APIs), they can offload certain functionsto dedicated external modules, such as image encoding and performingcalculations. However, most existing approaches to augment LLMs with tools areconstrained by general-purpose APIs and lack the flexibility for tailoring themto specific tasks. In this work, we present CRAFT, a general tool creation andretrieval framework for LLMs. It creates toolsets specifically curated for thetasks and equips LLMs with a component that retrieves tools from these sets toenhance their capability to solve complex tasks. For each task, we collectspecific code solutions by prompting GPT-4 to solve the training examples.Following a validation step ensuring the correctness, these solutions areabstracted into code snippets to enhance reusability, and deduplicated forhigher quality. At inference time, the language model retrieves snippets fromthe toolsets and then executes them or generates the output conditioning on theretrieved snippets. Our method is designed to be flexible and offers aplug-and-play approach to adapt off-the-shelf LLMs to unseen domains andmodalities, without any finetuning. Experiments on vision-language, tabularprocessing, and mathematical reasoning tasks show that our approach achievessubstantial improvements compared to strong baselines. In addition, ourin-depth analysis reveals that: (1) consistent performance improvement can beachieved by scaling up the number of tools and the capability of the backbonemodels; (2) each component of our approach contributes to the performancegains; (3) the created tools are well-structured and reliable with lowcomplexity and atomicity. The code is available athttps://github.com/lifan-yuan/CRAFT.</description><author>Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R. Fung, Hao Peng, Heng Ji</author><pubDate>Wed, 13 Mar 2024 06:39:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17428v2</guid></item><item><title>RLVF: Learning from Verbal Feedback without Overgeneralization</title><link>http://arxiv.org/abs/2402.10893v1</link><description>The diversity of contexts in which large language models (LLMs) are deployedrequires the ability to modify or customize default model behaviors toincorporate nuanced requirements and preferences. A convenient interface tospecify such model adjustments is high-level verbal feedback, such as "Don'tuse emojis when drafting emails to my boss." However, while writing high-levelfeedback is far simpler than collecting annotations for reinforcement learningfrom human feedback (RLHF), we find that simply prompting a model with suchfeedback leads to overgeneralization of the feedback to contexts where it isnot relevant. We study the problem of incorporating verbal feedback withoutsuch overgeneralization, inspiring a new method Contextualized Critiques withConstrained Preference Optimization (C3PO). C3PO uses a piece of high-levelfeedback to generate a small synthetic preference dataset specifying how thefeedback should (and should not) be applied. It then fine-tunes the model inaccordance with the synthetic preference data while minimizing the divergencefrom the original model for prompts where the feedback does not apply. Ourexperimental results indicate that our approach effectively applies verbalfeedback to relevant scenarios while preserving existing behaviors for othercontexts. For both human- and GPT-4-generated high-level feedback, C3POeffectively adheres to the given feedback comparably to in-context baselineswhile reducing overgeneralization by 30%.</description><author>Moritz Stephan, Alexander Khazatsky, Eric Mitchell, Annie S Chen, Sheryl Hsu, Archit Sharma, Chelsea Finn</author><pubDate>Fri, 16 Feb 2024 18:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10893v1</guid></item><item><title>CleanAgent: Automating Data Standardization with LLM-based Agents</title><link>http://arxiv.org/abs/2403.08291v2</link><description>Data standardization is a crucial part in data science life cycle. Whiletools like Pandas offer robust functionalities, their complexity and the manualeffort required for customizing code to diverse column types pose significantchallenges. Although large language models (LLMs) like ChatGPT have shownpromise in automating this process through natural language understanding andcode generation, it still demands expert-level programming knowledge andcontinuous interaction for prompt refinement. To solve these challenges, ourkey idea is to propose a Python library with declarative, unified APIs forstandardizing column types, simplifying the code generation of LLM with conciseAPI calls. We first propose Dataprep.Clean which is written as a component ofthe Dataprep Library, offers a significant reduction in complexity by enablingthe standardization of specific column types with a single line of code. Thenwe introduce the CleanAgent framework integrating Dataprep.Clean and LLM-basedagents to automate the data standardization process. With CleanAgent, datascientists need only provide their requirements once, allowing for ahands-free, automatic standardization process.</description><author>Danrui Qi, Jiannan Wang</author><pubDate>Thu, 25 Apr 2024 04:47:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08291v2</guid></item><item><title>CleanAgent: Automating Data Standardization with LLM-based Agents</title><link>http://arxiv.org/abs/2403.08291v1</link><description>Data standardization is a crucial part in data science life cycle. Whiletools like Pandas offer robust functionalities, their complexity and the manualeffort required for customizing code to diverse column types pose significantchallenges. Although large language models (LLMs) like ChatGPT have shownpromise in automating this process through natural language understanding andcode generation, it still demands expert-level programming knowledge andcontinuous interaction for prompt refinement. To solve these challenges, ourkey idea is to propose a Python library with declarative, unified APIs forstandardizing column types, simplifying the code generation of LLM with conciseAPI calls. We first propose Dataprep.Clean which is written as a component ofthe Dataprep Library, offers a significant reduction in complexity by enablingthe standardization of specific column types with a single line of code. Thenwe introduce the CleanAgent framework integrating Dataprep.Clean and LLM-basedagents to automate the data standardization process. With CleanAgent, datascientists need only provide their requirements once, allowing for ahands-free, automatic standardization process.</description><author>Danrui Qi, Jiannan Wang</author><pubDate>Wed, 13 Mar 2024 07:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08291v1</guid></item><item><title>Plum: Prompt Learning using Metaheuristic</title><link>http://arxiv.org/abs/2311.08364v2</link><description>Since the emergence of large language models, prompt learning has become apopular method for optimizing and customizing these models. Special prompts,such as Chain-of-Thought, have even revealed previously unknown reasoningcapabilities within these models. However, the progress of discoveringeffective prompts has been slow, driving a desire for general promptoptimization methods. Unfortunately, few existing prompt learning methodssatisfy the criteria of being truly "general", i.e., automatic, discrete,black-box, gradient-free, and interpretable all at once. In this paper, weintroduce metaheuristics, a branch of discrete non-convex optimization methodswith over 100 options, as a promising approach to prompt learning. Within ourparadigm, we test six typical methods: hill climbing, simulated annealing,genetic algorithms with/without crossover, tabu search, and harmony search,demonstrating their effectiveness in white-box and black-box prompt learning.Furthermore, we show that these methods can be used to discover morehuman-understandable prompts that were previously unknown in both reasoning andimage generation tasks, opening the door to a cornucopia of possibilities inprompt optimization. We release all the codes in\url{https://github.com/research4pan/Plum}.</description><author>Rui Pan, Shuo Xing, Shizhe Diao, Wenhe Sun, Xiang Liu, Kashun Shum, Renjie Pi, Jipeng Zhang, Tong Zhang</author><pubDate>Thu, 14 Mar 2024 14:43:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08364v2</guid></item><item><title>DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation</title><link>http://arxiv.org/abs/2403.06845v2</link><description>World models have demonstrated superiority in autonomous driving,particularly in the generation of multi-view driving videos. However,significant challenges still exist in generating customized driving videos. Inthis paper, we propose DriveDreamer-2, which builds upon the framework ofDriveDreamer and incorporates a Large Language Model (LLM) to generateuser-defined driving videos. Specifically, an LLM interface is initiallyincorporated to convert a user's query into agent trajectories. Subsequently, aHDMap, adhering to traffic regulations, is generated based on the trajectories.Ultimately, we propose the Unified Multi-View Model to enhance temporal andspatial coherence in the generated driving videos. DriveDreamer-2 is the firstworld model to generate customized driving videos, it can generate uncommondriving videos (e.g., vehicles abruptly cut in) in a user-friendly manner.Besides, experimental results demonstrate that the generated videos enhance thetraining of driving perception methods (e.g., 3D detection and tracking).Furthermore, video generation quality of DriveDreamer-2 surpasses otherstate-of-the-art methods, showcasing FID and FVD scores of 11.2 and 55.7,representing relative improvements of 30% and 50%.</description><author>Guosheng Zhao, Xiaofeng Wang, Zheng Zhu, Xinze Chen, Guan Huang, Xiaoyi Bao, Xingang Wang</author><pubDate>Thu, 11 Apr 2024 05:17:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06845v2</guid></item><item><title>DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation</title><link>http://arxiv.org/abs/2403.06845v1</link><description>World models have demonstrated superiority in autonomous driving,particularly in the generation of multi-view driving videos. However,significant challenges still exist in generating customized driving videos. Inthis paper, we propose DriveDreamer-2, which builds upon the framework ofDriveDreamer and incorporates a Large Language Model (LLM) to generateuser-defined driving videos. Specifically, an LLM interface is initiallyincorporated to convert a user's query into agent trajectories. Subsequently, aHDMap, adhering to traffic regulations, is generated based on the trajectories.Ultimately, we propose the Unified Multi-View Model to enhance temporal andspatial coherence in the generated driving videos. DriveDreamer-2 is the firstworld model to generate customized driving videos, it can generate uncommondriving videos (e.g., vehicles abruptly cut in) in a user-friendly manner.Besides, experimental results demonstrate that the generated videos enhance thetraining of driving perception methods (e.g., 3D detection and tracking).Furthermore, video generation quality of DriveDreamer-2 surpasses otherstate-of-the-art methods, showcasing FID and FVD scores of 11.2 and 55.7,representing relative improvements of 30% and 50%.</description><author>Guosheng Zhao, Xiaofeng Wang, Zheng Zhu, Xinze Chen, Guan Huang, Xiaoyi Bao, Xingang Wang</author><pubDate>Mon, 11 Mar 2024 17:03:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06845v1</guid></item><item><title>DeepLocalization: Using change point detection for Temporal Action Localization</title><link>http://arxiv.org/abs/2404.12258v1</link><description>In this study, we introduce DeepLocalization, an innovative framework devisedfor the real-time localization of actions tailored explicitly for monitoringdriver behavior. Utilizing the power of advanced deep learning methodologies,our objective is to tackle the critical issue of distracted driving-asignificant factor contributing to road accidents. Our strategy employs a dualapproach: leveraging Graph-Based Change-Point Detection for pinpointing actionsin time alongside a Video Large Language Model (Video-LLM) for preciselycategorizing activities. Through careful prompt engineering, we customize theVideo-LLM to adeptly handle driving activities' nuances, ensuring itsclassification efficacy even with sparse data. Engineered to be lightweight,our framework is optimized for consumer-grade GPUs, making it vastly applicablein practical scenarios. We subjected our method to rigorous testing on theSynDD2 dataset, a complex benchmark for distracted driving behaviors, where itdemonstrated commendable performance-achieving 57.5% accuracy in eventclassification and 51% in event detection. These outcomes underscore thesubstantial promise of DeepLocalization in accurately identifying diversedriver behaviors and their temporal occurrences, all within the bounds oflimited computational resources.</description><author>Mohammed Shaiqur Rahman, Ibne Farabi Shihab, Lynna Chu, Anuj Sharma</author><pubDate>Thu, 18 Apr 2024 16:25:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12258v1</guid></item><item><title>Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph</title><link>http://arxiv.org/abs/2404.14372v1</link><description>Model scaling is becoming the default choice for many language tasks due tothe success of large language models (LLMs). However, it can fall short inspecific scenarios where simple customized methods excel. In this paper, wedelve into the patent approval pre-diction task and unveil that simpledomain-specific graph methods outperform enlarging the model, using theintrinsic dependencies within the patent data. Specifically, we first extendthe embedding-based state-of-the-art (SOTA) by scaling up its backbone modelwith various sizes of open-source LLMs, then explore prompt-based methods toharness proprietary LLMs' potential, but find the best results close to randomguessing, underlining the ineffectiveness of model scaling-up. Hence, wepropose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulouspatent data analyses, capturing the inherent dependencies across segments ofthe patent text. As it is model-agnostic, we apply cost-effective graph modelsto our FLAN Graph to obtain representations for approval prediction. Extensiveexperiments and detailed analyses prove that incorporating FLAN Graph viavarious graph models consistently outperforms all LLM baselines significantly.We hope that our observations and analyses in this paper can bring moreattention to this challenging task and prompt further research into thelimitations of LLMs. Our source code and dataset can be obtained fromhttp://github.com/ShangDataLab/FLAN-Graph.</description><author>Xiaochen Kev Gao, Feng Yao, Kewen Zhao, Beilei He, Animesh Kumar, Vish Krishnan, Jingbo Shang</author><pubDate>Mon, 22 Apr 2024 18:22:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14372v1</guid></item><item><title>Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models</title><link>http://arxiv.org/abs/2403.19340v1</link><description>To address the challenges associated with data processing at scale, wepropose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipelinefor large language models (LLMs) with a user-friendly design at its core. Easyaddition of custom processors with block-based interface in Dataverse allowsusers to readily and efficiently use Dataverse to build their own ETL pipeline.We hope that Dataverse will serve as a vital tool for LLM development and opensource the entire library to welcome community contribution. Additionally, weprovide a concise, two-minute video demonstration of our system, illustratingits capabilities and implementation.</description><author>Hyunbyung Park, Sukyung Lee, Gyoungjin Gim, Yungi Kim, Dahyun Kim, Chanjun Park</author><pubDate>Thu, 28 Mar 2024 12:57:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19340v1</guid></item><item><title>Deep Learning and LLM-based Methods Applied to Stellar Lightcurve Classification</title><link>http://arxiv.org/abs/2404.10757v1</link><description>Light curves serve as a valuable source of information on stellar formationand evolution. With the rapid advancement of machine learning techniques, itcan be effectively processed to extract astronomical patterns and information.In this study, we present a comprehensive evaluation of deep-learning and largelanguage model (LLM) based models for the automatic classification of variablestar light curves, based on large datasets from the Kepler and K2 missions.Special emphasis is placed on Cepheids, RR Lyrae, and eclipsing binaries,examining the influence of observational cadence and phase distribution onclassification precision. Employing AutoDL optimization, we achieve strikingperformance with the 1D-Convolution+BiLSTM architecture and the SwinTransformer, hitting accuracies of 94\% and 99\% correspondingly, with thelatter demonstrating a notable 83\% accuracy in discerning the elusive Type IICepheids-comprising merely 0.02\% of the total dataset.We unveil StarWhisperLightCurve (LC), an innovative Series comprising three LLM-based models: LLM,multimodal large language model (MLLM), and Large Audio Language Model (LALM).Each model is fine-tuned with strategic prompt engineering and customizedtraining methods to explore the emergent abilities of these models forastronomical data. Remarkably, StarWhisper LC Series exhibit high accuraciesaround 90\%, significantly reducing the need for explicit feature engineering,thereby paving the way for streamlined parallel data processing and theprogression of multifaceted multimodal models in astronomical applications. Thestudy furnishes two detailed catalogs illustrating the impacts of phase andsampling intervals on deep learning classification accuracy, showing that asubstantial decrease of up to 14\% in observation duration and 21\% in samplingpoints can be realized without compromising accuracy by more than 10\%.</description><author>Yu-Yang Li, Yu Bai, Cunshi Wang, Mengwei Qu, Ziteng Lu, Roberto Soria, Jifeng Liu</author><pubDate>Tue, 16 Apr 2024 18:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10757v1</guid></item><item><title>Comparative Study of Domain Driven Terms Extraction Using Large Language Models</title><link>http://arxiv.org/abs/2404.02330v1</link><description>Keywords play a crucial role in bridging the gap between human understandingand machine processing of textual data. They are essential to data enrichmentbecause they form the basis for detailed annotations that provide a moreinsightful and in-depth view of the underlying data. Keyword/domain driven termextraction is a pivotal task in natural language processing, facilitatinginformation retrieval, document summarization, and content categorization. Thisreview focuses on keyword extraction methods, emphasizing the use of threemajor Large Language Models(LLMs): Llama2-7B, GPT-3.5, and Falcon-7B. Weemployed a custom Python package to interface with these LLMs, simplifyingkeyword extraction. Our study, utilizing the Inspec and PubMed datasets,evaluates the performance of these models. The Jaccard similarity index wasused for assessment, yielding scores of 0.64 (Inspec) and 0.21 (PubMed) forGPT-3.5, 0.40 and 0.17 for Llama2-7B, and 0.23 and 0.12 for Falcon-7B. Thispaper underlines the role of prompt engineering in LLMs for better keywordextraction and discusses the impact of hallucination in LLMs on resultevaluation. It also sheds light on the challenges in using LLMs for keywordextraction, including model complexity, resource demands, and optimizationtechniques.</description><author>Sandeep Chataut, Tuyen Do, Bichar Dip Shrestha Gurung, Shiva Aryal, Anup Khanal, Carol Lushbough, Etienne Gnimpieba</author><pubDate>Tue, 02 Apr 2024 23:04:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02330v1</guid></item><item><title>GeoGalactica: A Scientific Large Language Model in Geoscience</title><link>http://arxiv.org/abs/2401.00434v2</link><description>Large language models (LLMs) have achieved huge success for their generalknowledge and ability to solve a wide spectrum of tasks in natural languageprocessing (NLP). Due to their impressive abilities, LLMs have shed light onpotential inter-discipline applications to foster scientific discoveries of aspecific domain by using artificial intelligence (AI for science, AI4S). In themeantime, utilizing NLP techniques in geoscience research and practice is wideand convoluted, contributing from knowledge extraction and documentclassification to question answering and knowledge discovery. In this work, wetake the initial step to leverage LLM for science, through a ratherstraightforward approach. We try to specialize an LLM into geoscience, byfurther pre-training the model with a vast amount of texts in geoscience, aswell as supervised fine-tuning (SFT) the resulting model with our customcollected instruction tuning dataset. These efforts result in a modelGeoGalactica consisting of 30 billion parameters. To our best knowledge, it isthe largest language model for the geoscience domain. More specifically,GeoGalactica is from further pre-training of Galactica. We train GeoGalacticaover a geoscience-related text corpus containing 65 billion tokens, preservingas the largest geoscience-specific text corpus. Then we fine-tune the modelwith 1 million pairs of instruction-tuning data consisting of questions thatdemand professional geoscience knowledge to answer. In this technical report,we will illustrate in detail all aspects of GeoGalactica, including datacollection, data cleaning, base model selection, pre-training, SFT, andevaluation. We open-source our data curation tools and the checkpoints ofGeoGalactica during the first 3/4 of pre-training.</description><author>Zhouhan Lin, Cheng Deng, Le Zhou, Tianhang Zhang, Yi Xu, Yutong Xu, Zhongmou He, Yuanyuan Shi, Beiya Dai, Yunchong Song, Boyi Zeng, Qiyuan Chen, Yuxun Miao, Bo Xue, Shu Wang, Luoyi Fu, Weinan Zhang, Junxian He, Yunqiang Zhu, Xinbing Wang, Chenghu Zhou</author><pubDate>Sat, 13 Apr 2024 18:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00434v2</guid></item><item><title>Manipulating Large Language Models to Increase Product Visibility</title><link>http://arxiv.org/abs/2404.07981v1</link><description>Large language models (LLMs) are increasingly being integrated into searchengines to provide natural language responses tailored to user queries.Customers and end-users are also becoming more dependent on these models forquick and easy purchase decisions. In this work, we investigate whetherrecommendations from LLMs can be manipulated to enhance a product's visibility.We demonstrate that adding a strategic text sequence (STS) -- a carefullycrafted message -- to a product's information page can significantly increaseits likelihood of being listed as the LLM's top recommendation. To understandthe impact of STS, we use a catalog of fictitious coffee machines and analyzeits effect on two target products: one that seldom appears in the LLM'srecommendations and another that usually ranks second. We observe that thestrategic text sequence significantly enhances the visibility of both productsby increasing their chances of appearing as the top recommendation. Thisability to manipulate LLM-generated search responses provides vendors with aconsiderable competitive advantage and has the potential to disrupt fair marketcompetition. Just as search engine optimization (SEO) revolutionized howwebpages are customized to rank higher in search engine results, influencingLLM recommendations could profoundly impact content optimization for AI-drivensearch services. Code for our experiments is available athttps://github.com/aounon/llm-rank-optimizer.</description><author>Aounon Kumar, Himabindu Lakkaraju</author><pubDate>Thu, 11 Apr 2024 18:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07981v1</guid></item><item><title>Scaffolding Language Learning via Multi-modal Tutoring Systems with Pedagogical Instructions</title><link>http://arxiv.org/abs/2404.03429v1</link><description>Intelligent tutoring systems (ITSs) that imitate human tutors and aim toprovide immediate and customized instructions or feedback to learners haveshown their effectiveness in education. With the emergence of generativeartificial intelligence, large language models (LLMs) further entitle thesystems to complex and coherent conversational interactions. These systemswould be of great help in language education as it involves developing skillsin communication, which, however, drew relatively less attention. Additionally,due to the complicated cognitive development at younger ages, more endeavorsare needed for practical uses. Scaffolding refers to a teaching technique whereteachers provide support and guidance to students for learning and developingnew concepts or skills. It is an effective way to support diverse learningneeds, goals, processes, and outcomes. In this work, we investigate howpedagogical instructions facilitate the scaffolding in ITSs, by conducting acase study on guiding children to describe images for language learning. Weconstruct different types of scaffolding tutoring systems grounded in fourfundamental learning theories: knowledge construction, inquiry-based learning,dialogic teaching, and zone of proximal development. For qualitative andquantitative analyses, we build and refine a seven-dimension rubric to evaluatethe scaffolding process. In our experiment on GPT-4V, we observe that LLMsdemonstrate strong potential to follow pedagogical instructions and achieveself-paced learning in different student groups. Moreover, we extend ourevaluation framework from a manual to an automated approach, paving the way tobenchmark various conversational tutoring systems.</description><author>Zhengyuan Liu, Stella Xin Yin, Carolyn Lee, Nancy F. Chen</author><pubDate>Thu, 04 Apr 2024 14:22:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03429v1</guid></item><item><title>Zero- and Few-Shot Prompting with LLMs: A Comparative Study with Fine-tuned Models for Bangla Sentiment Analysis</title><link>http://arxiv.org/abs/2308.10783v2</link><description>The rapid expansion of the digital world has propelled sentiment analysisinto a critical tool across diverse sectors such as marketing, politics,customer service, and healthcare. While there have been significantadvancements in sentiment analysis for widely spoken languages, low-resourcelanguages, such as Bangla, remain largely under-researched due to resourceconstraints. Furthermore, the recent unprecedented performance of LargeLanguage Models (LLMs) in various applications highlights the need to evaluatethem in the context of low-resource languages. In this study, we present asizeable manually annotated dataset encompassing 33,606 Bangla news tweets andFacebook comments. We also investigate zero- and few-shot in-context learningwith several language models, including Flan-T5, GPT-4, and Bloomz, offering acomparative analysis against fine-tuned models. Our findings suggest thatmonolingual transformer-based models consistently outperform other models, evenin zero and few-shot scenarios. To foster continued exploration, we intend tomake this dataset and our research tools publicly available to the broaderresearch community.</description><author>Md. Arid Hasan, Shudipta Das, Afiyat Anjum, Firoj Alam, Anika Anjum, Avijit Sarker, Sheak Rashed Haider Noori</author><pubDate>Fri, 05 Apr 2024 02:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10783v2</guid></item><item><title>Noise-Aware Training of Layout-Aware Language Models</title><link>http://arxiv.org/abs/2404.00488v1</link><description>A visually rich document (VRD) utilizes visual features along with linguisticcues to disseminate information. Training a custom extractor that identifiesnamed entities from a document requires a large number of instances of thetarget document type annotated at textual and visual modalities. This is anexpensive bottleneck in enterprise scenarios, where we want to train customextractors for thousands of different document types in a scalable way.Pre-training an extractor model on unlabeled instances of the target documenttype, followed by a fine-tuning step on human-labeled instances does not workin these scenarios, as it surpasses the maximum allowable training timeallocated for the extractor. We address this scenario by proposing aNoise-Aware Training method or NAT in this paper. Instead of acquiringexpensive human-labeled documents, NAT utilizes weakly labeled documents totrain an extractor in a scalable way. To avoid degradation in the model'squality due to noisy, weakly labeled samples, NAT estimates the confidence ofeach training sample and incorporates it as uncertainty measure duringtraining. We train multiple state-of-the-art extractor models using NAT.Experiments on a number of publicly available and in-house datasets show thatNAT-trained models are not only robust in performance -- it outperforms atransfer-learning baseline by up to 6% in terms of macro-F1 score, but it isalso more label-efficient -- it reduces the amount of human-effort required toobtain comparable performance by up to 73%.</description><author>Ritesh Sarkhel, Xiaoqi Ren, Lauro Beltrao Costa, Guolong Su, Vincent Perot, Yanan Xie, Emmanouil Koukoumidis, Arnab Nandi</author><pubDate>Sun, 31 Mar 2024 00:06:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00488v1</guid></item><item><title>When Dataflow Analysis Meets Large Language Models</title><link>http://arxiv.org/abs/2402.10754v1</link><description>Dataflow analysis is a powerful code analysis technique that reasonsdependencies between program values, offering support for code optimization,program comprehension, and bug detection. Existing approaches require thesuccessful compilation of the subject program and customizations for downstreamapplications. This paper introduces LLMDFA, an LLM-powered dataflow analysisframework that analyzes arbitrary code snippets without requiring a compilationinfrastructure and automatically synthesizes downstream applications. Inspiredby summary-based dataflow analysis, LLMDFA decomposes the problem into threesub-problems, which are effectively resolved by several essential strategies,including few-shot chain-of-thought prompting and tool synthesis. Ourevaluation has shown that the design can mitigate the hallucination and improvethe reasoning ability, obtaining high precision and recall in detectingdataflow-related bugs upon benchmark programs, outperforming state-of-the-art(classic) tools, including a very recent industrial analyzer.</description><author>Chengpeng Wang, Wuqi Zhang, Zian Su, Xiangzhe Xu, Xiaoheng Xie, Xiangyu Zhang</author><pubDate>Fri, 16 Feb 2024 15:21:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10754v1</guid></item><item><title>Does Combining Parameter-efficient Modules Improve Few-shot Transfer Accuracy?</title><link>http://arxiv.org/abs/2402.15414v1</link><description>Parameter-efficient fine-tuning stands as the standard for efficientlyfine-tuning large language and vision models on downstream tasks. Specifically,the efficiency of low-rank adaptation has facilitated the creation and sharingof hundreds of custom LoRA modules, each trained on distinct data from variousdownstream tasks. In this paper, we explore the composability of LoRA modules,examining if combining these pre-trained modules enhances generalization tounseen downstream tasks. Our investigation involves evaluating two approaches:(a) uniform composition, involving averaging upstream LoRA modules with equalweights, and (b) learned composition, where we learn the weights for eachupstream module and perform weighted averaging. Our experimental results onboth vision and language models reveal that in few-shot settings, where only alimited number of samples are available for the downstream task, both uniformand learned composition methods result in better transfer accuracy;outperforming full fine-tuning and training a LoRA from scratch. Moreover, infull-shot settings, learned composition performs comparably to regular LoRAtraining with significantly fewer number of trainable parameters. Our researchunveils the potential of uniform composition for enhancing transferability inlow-shot settings, without introducing additional learnable parameters.</description><author>Nader Asadi, Mahdi Beitollahi, Yasser Khalil, Yinchuan Li, Guojun Zhang, Xi Chen</author><pubDate>Fri, 23 Feb 2024 16:20:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15414v1</guid></item><item><title>GCOF: Self-iterative Text Generation for Copywriting Using Large Language Model</title><link>http://arxiv.org/abs/2402.13667v1</link><description>Large language models(LLM) such as ChatGPT have substantially simplified thegeneration of marketing copy, yet producing content satisfying domain specificrequirements, such as effectively engaging customers, remains a significantchallenge. In this work, we introduce the Genetic Copy Optimization Framework(GCOF) designed to enhance both efficiency and engagememnt of marketing copycreation. We conduct explicit feature engineering within the prompts of LLM.Additionally, we modify the crossover operator in Genetic Algorithm (GA),integrating it into the GCOF to enable automatic feature engineering. Thisintegration facilitates a self-iterative refinement of the marketing copy.Compared to human curated copy, Online results indicate that copy produced byour framework achieves an average increase in click-through rate (CTR) of over$50\%$.</description><author>Jianghui Zhou, Ya Gao, Jie Liu, Xuemin Zhao, Zhaohua Yang, Yue Wu, Lirong Shi</author><pubDate>Wed, 21 Feb 2024 09:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13667v1</guid></item><item><title>PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval</title><link>http://arxiv.org/abs/2402.19273v1</link><description>In the field of urban planning, general-purpose large language models oftenstruggle to meet the specific needs of planners. Tasks like generating urbanplanning texts, retrieving related information, and evaluating planningdocuments pose unique challenges. To enhance the efficiency of urbanprofessionals and overcome these obstacles, we introduce PlanGPT, the firstspecialized Large Language Model tailored for urban and spatial planning.Developed through collaborative efforts with institutions like the ChineseAcademy of Urban Planning, PlanGPT leverages a customized local databaseretrieval framework, domain-specific fine-tuning of base models, and advancedtooling capabilities. Empirical tests demonstrate that PlanGPT has achievedadvanced performance, delivering responses of superior quality preciselytailored to the intricacies of urban planning.</description><author>He Zhu, Wenjia Zhang, Nuoxian Huang, Boyang Li, Luyao Niu, Zipei Fan, Tianle Lun, Yicheng Tao, Junyou Su, Zhaoya Gong, Chenyu Fang, Xing Liu</author><pubDate>Thu, 29 Feb 2024 15:41:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19273v1</guid></item><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v2</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Mon, 15 Apr 2024 07:03:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v2</guid></item><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v1</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Our codeand dataset will be open-sourced soon.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Sun, 31 Mar 2024 08:11:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v1</guid></item><item><title>ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL</title><link>http://arxiv.org/abs/2402.19446v1</link><description>A broad use case of large language models (LLMs) is in goal-directeddecision-making tasks (or "agent" tasks), where an LLM needs to not justgenerate completions for a given prompt, but rather make intelligent decisionsover a multi-turn interaction to accomplish a task (e.g., when interacting withthe web, using tools, or providing customer support). Reinforcement learning(RL) provides a general paradigm to address such agent tasks, but current RLmethods for LLMs largely focus on optimizing single-turn rewards. Byconstruction, most single-turn RL methods cannot endow LLMs with the ability tointelligently seek information over multiple turns, perform credit assignment,or reason about their past actions -- all of which are critical in agent tasks.This raises the question: how can we design effective and efficient multi-turnRL algorithms for LLMs? In this paper, we develop a framework for buildingmulti-turn RL algorithms for fine-tuning LLMs, that preserves the flexibilityof existing single-turn RL methods for LLMs (e.g., proximal policyoptimization), while accommodating multiple turns, long horizons, and delayedrewards effectively. To do this, our framework adopts a hierarchical RLapproach and runs two RL algorithms in parallel: a high-level off-policyvalue-based RL algorithm to aggregate reward over utterances, and a low-levelRL algorithm that utilizes this high-level value function to train a tokenpolicy within each utterance or turn. Our hierarchical framework, Actor-CriticFramework with a Hierarchical Structure (ArCHer), can also give rise to otherRL methods. Empirically, we find that ArCHer significantly improves efficiencyand performance on agent tasks, attaining a sample efficiency of about 100xover existing methods, while also improving with larger model capacity (uptothe 7 billion scale that we tested on).</description><author>Yifei Zhou, Andrea Zanette, Jiayi Pan, Sergey Levine, Aviral Kumar</author><pubDate>Thu, 29 Feb 2024 18:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19446v1</guid></item><item><title>Comprehensive Lipidomic Automation Workflow using Large Language Models</title><link>http://arxiv.org/abs/2403.15076v1</link><description>Lipidomics generates large data that makes manual annotation andinterpretation challenging. Lipid chemical and structural diversity withstructural isomers further complicates annotation. Although, several commercialand open-source software for targeted lipid identification exists, it lacksautomated method generation workflows and integration with statistical andbioinformatics tools. We have developed the Comprehensive Lipidomic AutomatedWorkflow (CLAW) platform with integrated workflow for parsing, detailedstatistical analysis and lipid annotations based on custom multiple reactionmonitoring (MRM) precursor and product ion pair transitions. CLAW containsseveral modules including identification of carbon-carbon double bondposition(s) in unsaturated lipids when combined with ozone electrosprayionization (OzESI)-MRM methodology. To demonstrate the utility of the automatedworkflow in CLAW, large-scale lipidomics data was collected with traditionaland OzESI-MRM profiling on biological and non-biological samples. Specifically,a total of 1497 transitions organized into 10 MRM-based mass spectrometrymethods were used to profile lipid droplets isolated from different brainregions of 18-24 month-old Alzheimer's disease mice and age-matched wild-typecontrols. Additionally, triacyclglycerols (TGs) profiles with carbon-carbondouble bond specificity were generated from canola oil samples using OzESI-MRMprofiling. We also developed an integrated language user interface with largelanguage models using artificially intelligent (AI) agents that permits usersto interact with the CLAW platform using a chatbot terminal to performstatistical and bioinformatic analyses. We envision CLAW pipeline to be used inhigh-throughput lipid structural identification tasks aiding users to generateautomated lipidomics workflows ranging from data acquisition to AI agent-basedbioinformatic analysis.</description><author>Connor Beveridge, Sanjay Iyer, Caitlin E. Randolph, Matthew Muhoberac, Palak Manchanda, Amy C. Clingenpeel, Shane Tichy, Gaurav Chopra</author><pubDate>Fri, 22 Mar 2024 11:00:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15076v1</guid></item><item><title>LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems</title><link>http://arxiv.org/abs/2403.00982v1</link><description>Retrieval-augmented question-answering systems combine retrieval techniqueswith large language models to provide answers that are more accurate andinformative. Many existing toolkits allow users to quickly build such systemsusing off-the-shelf models, but they fall short in supporting researchers anddevelopers to customize the model training, testing, and deployment process. Wepropose LocalRQA, an open-source toolkit that features a wide selection ofmodel training algorithms, evaluation methods, and deployment tools curatedfrom the latest research. As a showcase, we build QA systems using onlinedocumentation obtained from Databricks and Faire's websites. We find 7B-modelstrained and deployed using LocalRQA reach a similar performance compared tousing OpenAI's text-ada-002 and GPT-4-turbo.</description><author>Xiao Yu, Yunan Lu, Zhou Yu</author><pubDate>Fri, 01 Mar 2024 21:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00982v1</guid></item><item><title>CroissantLLM: A Truly Bilingual French-English Language Model</title><link>http://arxiv.org/abs/2402.00786v4</link><description>We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3TEnglish and French tokens, to bring to the research and industrial community ahigh-performance, fully open-sourced bilingual model that runs swiftly onconsumer-grade local hardware. To that end, we pioneer the approach of trainingan intrinsically bilingual model with a 1:1 English-to-French pretraining dataratio, a custom tokenizer, and bilingual finetuning datasets. We release thetraining dataset, notably containing a French split with manually curated,high-quality, and varied data sources. To assess performance outside ofEnglish, we craft a novel benchmark, FrenchBench, consisting of an array ofclassification and generation tasks, covering various orthogonal aspects ofmodel performance in the French Language. Additionally, rooted in transparencyand to foster further Large Language Model research, we release codebases, anddozens of checkpoints across various model sizes, training data distributions,and training steps, as well as fine-tuned Chat models, and strong translationmodels. We evaluate our model through the FMTI framework, and validate 81 % ofthe transparency criteria, far beyond the scores of even most open initiatives.This work enriches the NLP landscape, breaking away from previousEnglish-centric work in order to strengthen our understanding ofmultilinguality in language models.</description><author>Manuel Faysse, Patrick Fernandes, Nuno M. Guerreiro, António Loison, Duarte M. Alves, Caio Corro, Nicolas Boizard, João Alves, Ricardo Rei, Pedro H. Martins, Antoni Bigata Casademunt, François Yvon, André F. T. Martins, Gautier Viaud, Céline Hudelot, Pierre Colombo</author><pubDate>Fri, 29 Mar 2024 15:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00786v4</guid></item><item><title>Exploring Autonomous Agents through the Lens of Large Language Models: A Review</title><link>http://arxiv.org/abs/2404.04442v1</link><description>Large Language Models (LLMs) are transforming artificial intelligence,enabling autonomous agents to perform diverse tasks across various domains.These agents, proficient in human-like text comprehension and generation, havethe potential to revolutionize sectors from customer service to healthcare.However, they face challenges such as multimodality, human value alignment,hallucinations, and evaluation. Techniques like prompting, reasoning, toolutilization, and in-context learning are being explored to enhance theircapabilities. Evaluation platforms like AgentBench, WebArena, and ToolLLMprovide robust methods for assessing these agents in complex scenarios. Theseadvancements are leading to the development of more resilient and capableautonomous agents, anticipated to become integral in our digital lives,assisting in tasks from email responses to disease diagnosis. The future of AI,with LLMs at the forefront, is promising.</description><author>Saikat Barua</author><pubDate>Fri, 05 Apr 2024 23:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04442v1</guid></item><item><title>LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</title><link>http://arxiv.org/abs/2403.13372v1</link><description>Efficient fine-tuning is vital for adapting large language models (LLMs) todownstream tasks. However, it requires non-trivial efforts to implement thesemethods on different models. We present LlamaFactory, a unified framework thatintegrates a suite of cutting-edge efficient training methods. It allows usersto flexibly customize the fine-tuning of 100+ LLMs without the need for codingthrough the built-in web UI LlamaBoard. We empirically validate the efficiencyand effectiveness of our framework on language modeling and text generationtasks. It has been released at https://github.com/hiyouga/LLaMA-Factory andalready received over 13,000 stars and 1,600 forks.</description><author>Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo</author><pubDate>Wed, 20 Mar 2024 09:08:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13372v1</guid></item><item><title>LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</title><link>http://arxiv.org/abs/2403.13372v2</link><description>Efficient fine-tuning is vital for adapting large language models (LLMs) todownstream tasks. However, it requires non-trivial efforts to implement thesemethods on different models. We present LlamaFactory, a unified framework thatintegrates a suite of cutting-edge efficient training methods. It allows usersto flexibly customize the fine-tuning of 100+ LLMs without the need for codingthrough the built-in web UI LlamaBoard. We empirically validate the efficiencyand effectiveness of our framework on language modeling and text generationtasks. It has been released at https://github.com/hiyouga/LLaMA-Factory andalready received over 13,000 stars and 1,600 forks.</description><author>Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Yongqiang Ma</author><pubDate>Thu, 21 Mar 2024 09:36:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13372v2</guid></item><item><title>Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents</title><link>http://arxiv.org/abs/2403.06872v1</link><description>Legal judgment prediction suffers from the problem of long case documentsexceeding tens of thousands of words, in general, and having a non-uniformstructure. Predicting judgments from such documents becomes a challenging task,more so on documents with no structural annotation. We explore theclassification of these large legal documents and their lack of structuralinformation with a deep-learning-based hierarchical framework which we callMESc; "Multi-stage Encoder-based Supervised with-clustering"; for judgmentprediction. Specifically, we divide a document into parts to extract theirembeddings from the last four layers of a custom fine-tuned Large LanguageModel, and try to approximate their structure through unsupervised clustering.Which we use in another set of transformer encoder layers to learn theinter-chunk representations. We analyze the adaptability of Large LanguageModels (LLMs) with multi-billion parameters (GPT-Neo, and GPT-J) with thehierarchical framework of MESc and compare them with their standaloneperformance on legal texts. We also study their intra-domain(legal) transferlearning capability and the impact of combining embeddings from their lastlayers in MESc. We test these methods and their effectiveness with extensiveexperiments and ablation studies on legal documents from India, the EuropeanUnion, and the United States with the ILDC dataset and a subset of the LexGLUEdataset. Our approach achieves a minimum total performance gain ofapproximately 2 points over previous state-of-the-art methods.</description><author>Nishchal Prasad, Mohand Boughanem, Taoufiq Dkaki</author><pubDate>Mon, 11 Mar 2024 17:24:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06872v1</guid></item><item><title>Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models</title><link>http://arxiv.org/abs/2402.13064v1</link><description>We introduce Generalized Instruction Tuning (called GLAN), a general andscalable method for instruction tuning of Large Language Models (LLMs). Unlikeprior work that relies on seed examples or existing datasets to constructinstruction tuning data, GLAN exclusively utilizes a pre-curated taxonomy ofhuman knowledge and capabilities as input and generates large-scale syntheticinstruction data across all disciplines. Specifically, inspired by thesystematic structure in human education system, we build the taxonomy bydecomposing human knowledge and capabilities to various fields, sub-fields andultimately, distinct disciplines semi-automatically, facilitated by LLMs.Subsequently, we generate a comprehensive list of subjects for every disciplineand proceed to design a syllabus tailored to each subject, again utilizingLLMs. With the fine-grained key concepts detailed in every class session of thesyllabus, we are able to generate diverse instructions with a broad coverageacross the entire spectrum of human knowledge and skills. Extensive experimentson large language models (e.g., Mistral) demonstrate that GLAN excels inmultiple dimensions from mathematical reasoning, coding, academic exams,logical reasoning to general instruction following without using task-specifictraining data of these tasks. In addition, GLAN allows for easy customizationand new fields or skills can be added by simply incorporating a new node intoour taxonomy.</description><author>Haoran Li, Qingxiu Dong, Zhengyang Tang, Chaojun Wang, Xingxing Zhang, Haoyang Huang, Shaohan Huang, Xiaolong Huang, Zeqiang Huang, Dongdong Zhang, Yuxian Gu, Xin Cheng, Xun Wang, Si-Qing Chen, Li Dong, Wei Lu, Zhifang Sui, Benyou Wang, Wai Lam, Furu Wei</author><pubDate>Tue, 20 Feb 2024 15:00:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13064v1</guid></item><item><title>Generating Illustrated Instructions</title><link>http://arxiv.org/abs/2312.04552v2</link><description>We introduce the new task of generating Illustrated Instructions, i.e.,visual instructions customized to a user's needs. We identify desiderata uniqueto this task, and formalize it through a suite of automatic and humanevaluation metrics, designed to measure the validity, consistency, and efficacyof the generations. We combine the power of large language models (LLMs)together with strong text-to-image generation diffusion models to propose asimple approach called StackedDiffusion, which generates such illustratedinstructions given text as input. The resulting model strongly outperformsbaseline approaches and state-of-the-art multimodal LLMs; and in 30% of cases,users even prefer it to human-generated articles. Most notably, it enablesvarious new and exciting applications far beyond what static articles on theweb can provide, such as personalized instructions complete with intermediatesteps and pictures in response to a user's individual situation.</description><author>Sachit Menon, Ishan Misra, Rohit Girdhar</author><pubDate>Fri, 12 Apr 2024 19:34:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04552v2</guid></item><item><title>Low-Cost Generation and Evaluation of Dictionary Example Sentences</title><link>http://arxiv.org/abs/2404.06224v1</link><description>Dictionary example sentences play an important role in illustrating worddefinitions and usage, but manually creating quality sentences is challenging.Prior works have demonstrated that language models can be trained to generateexample sentences. However, they relied on costly customized models and wordsense datasets for generation and evaluation of their work. Rapid advancementsin foundational models present the opportunity to create low-cost, zero-shotmethods for the generation and evaluation of dictionary example sentences. Weintroduce a new automatic evaluation metric called OxfordEval that measures thewin-rate of generated sentences against existing Oxford Dictionary sentences.OxfordEval shows high alignment with human judgments, enabling large-scaleautomated quality evaluation. We experiment with various LLMs andconfigurations to generate dictionary sentences across word classes. Wecomplement this with a novel approach of using masked language models toidentify and select sentences that best exemplify word meaning. The eventualmodel, FM-MLM, achieves over 85.1% win rate against Oxford baseline sentencesaccording to OxfordEval, compared to 39.8% win rate for prior model-generatedsentences.</description><author>Bill Cai, Clarence Boon Liang Ng, Daniel Tan, Shelvia Hotama</author><pubDate>Tue, 09 Apr 2024 12:26:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06224v1</guid></item><item><title>Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers</title><link>http://arxiv.org/abs/2404.14680v1</link><description>The task of accurate and efficient language translation is an extremelyimportant information processing task. Machine learning enabled and automatedtranslation that is accurate and fast is often a large topic of interest in themachine learning and data science communities. In this study, we examine usinglocal Generative Pretrained Transformer (GPT) models to perform automated zeroshot black-box, sentence wise, multi-natural-language translation into Englishtext. We benchmark 16 different open-source GPT models, with no customfine-tuning, from the Huggingface LLM repository for translating 50 differentnon-English languages into English using translated TED Talk transcripts as thereference dataset. These GPT model inference calls are performed strictlylocally, on single A100 Nvidia GPUs. Benchmark metrics that are reported arelanguage translation accuracy, using BLEU, GLEU, METEOR, and chrF text overlapmeasures, and wall-clock time for each sentence translation. The best overallperforming GPT model for translating into English text for the BLEU metric isReMM-v2-L2-13B with a mean score across all tested languages of $0.152$, forthe GLEU metric is ReMM-v2-L2-13B with a mean score across all tested languagesof $0.256$, for the chrF metric is Llama2-chat-AYT-13B with a mean score acrossall tested languages of $0.448$, and for the METEOR metric is ReMM-v2-L2-13Bwith a mean score across all tested languages of $0.438$.</description><author>Elijah Pelofske, Vincent Urias, Lorie M. Liebrock</author><pubDate>Tue, 23 Apr 2024 03:19:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14680v1</guid></item><item><title>Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries</title><link>http://arxiv.org/abs/2403.20145v1</link><description>Improving mental health support in developing countries is a pressing need.One potential solution is the development of scalable, automated systems toconduct diagnostic screenings, which could help alleviate the burden on mentalhealth professionals. In this work, we evaluate several state-of-the-art LargeLanguage Models (LLMs), with and without fine-tuning, on our custom dataset forgenerating concise summaries from mental state examinations. We rigorouslyevaluate four different models for summary generation using established ROUGEmetrics and input from human evaluators. The results highlight that ourtop-performing fine-tuned model outperforms existing models, achieving ROUGE-1and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessedthe fine-tuned model's generalizability on a publicly available D4 dataset, andthe outcomes were promising, indicating its potential applicability beyond ourcustom dataset.</description><author>Manjeet Yadav, Nilesh Kumar Sahu, Mudita Chaturvedi, Snehil Gupta, Haroon R Lone</author><pubDate>Fri, 29 Mar 2024 13:25:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20145v1</guid></item><item><title>Fine-tuning Large Language Models for Automated Diagnostic Screening Summaries</title><link>http://arxiv.org/abs/2403.20145v2</link><description>Improving mental health support in developing countries is a pressing need.One potential solution is the development of scalable, automated systems toconduct diagnostic screenings, which could help alleviate the burden on mentalhealth professionals. In this work, we evaluate several state-of-the-art LargeLanguage Models (LLMs), with and without fine-tuning, on our custom dataset forgenerating concise summaries from mental state examinations. We rigorouslyevaluate four different models for summary generation using established ROUGEmetrics and input from human evaluators. The results highlight that ourtop-performing fine-tuned model outperforms existing models, achieving ROUGE-1and ROUGE-L values of 0.810 and 0.764, respectively. Furthermore, we assessedthe fine-tuned model's generalizability on a publicly available D4 dataset, andthe outcomes were promising, indicating its potential applicability beyond ourcustom dataset.</description><author>Manjeet Yadav, Nilesh Kumar Sahu, Mudita Chaturvedi, Snehil Gupta, Haroon R Lone</author><pubDate>Thu, 04 Apr 2024 11:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20145v2</guid></item><item><title>Text Understanding and Generation Using Transformer Models for Intelligent E-commerce Recommendations</title><link>http://arxiv.org/abs/2402.16035v1</link><description>With the rapid development of artificial intelligence technology, Transformerstructural pre-training model has become an important tool for large languagemodel (LLM) tasks. In the field of e-commerce, these models are especiallywidely used, from text understanding to generating recommendation systems,which provide powerful technical support for improving user experience andoptimizing service processes. This paper reviews the core application scenariosof Transformer pre-training model in e-commerce text understanding andrecommendation generation, including but not limited to automatic generation ofproduct descriptions, sentiment analysis of user comments, construction ofpersonalized recommendation system and automated processing of customer serviceconversations. Through a detailed analysis of the model's working principle,implementation process, and application effects in specific cases, this paperemphasizes the unique advantages of pre-trained models in understanding complexuser intentions and improving the quality of recommendations. In addition, thechallenges and improvement directions for the future are also discussed, suchas how to further improve the generalization ability of the model, the abilityto handle large-scale data sets, and technical strategies to protect userprivacy. Ultimately, the paper points out that the application of Transformerstructural pre-training models in e-commerce has not only driven technologicalinnovation, but also brought substantial benefits to merchants and consumers,and looking forward, these models will continue to play a key role ine-commerce and beyond.</description><author>Yafei Xiang, Hanyi Yu, Yulu Gong, Shuning Huo, Mengran Zhu</author><pubDate>Sun, 25 Feb 2024 09:19:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16035v1</guid></item><item><title>Automatic Histograms: Leveraging Language Models for Text Dataset Exploration</title><link>http://arxiv.org/abs/2402.14880v1</link><description>Making sense of unstructured text datasets is perennially difficult, yetincreasingly relevant with Large Language Models. Data workers often rely ondataset summaries, especially distributions of various derived features. Somefeatures, like toxicity or topics, are relevant to many datasets, but manyinteresting features are domain specific: instruments and genres for a musicdataset, or diseases and symptoms for a medical dataset. Accordingly, dataworkers often run custom analyses for each dataset, which is cumbersome anddifficult. We present AutoHistograms, a visualization tool leveragingLLMs.AutoHistograms automatically identifies relevant features, visualizes them withhistograms, and allows the user to interactively query the dataset forcategories of entities and create new histograms. In a user study with 10 dataworkers (n=10), we observe that participants can quickly identify insights andexplore the data using AutoHistograms, and conceptualize a broad range ofapplicable use cases. Together, this tool and user study contributeto thegrowing field of LLM-assisted sensemaking tools.</description><author>Emily Reif, Crystal Qian, James Wexler, Minsuk Kahng</author><pubDate>Wed, 21 Feb 2024 22:29:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14880v1</guid></item><item><title>DeAL: Decoding-time Alignment for Large Language Models</title><link>http://arxiv.org/abs/2402.06147v2</link><description>Large Language Models (LLMs) are nowadays expected to generate contentaligned with human preferences. Current work focuses on alignment at modeltraining time, through techniques such as Reinforcement Learning with HumanFeedback (RLHF). However, it is unclear if such methods are an effective choiceto teach alignment objectives to the model. First, the inability to incorporatemultiple, custom rewards and reliance on a model developer's view of universaland static principles are key limitations. Second, the residual gaps in modeltraining and the reliability of such approaches are also questionable (e.g.susceptibility to jail-breaking even after safety training). To address these,we propose DeAL, a framework that allows the user to customize reward functionsand enables Decoding-time Alignment of LLMs (DeAL). At its core, we viewdecoding as a heuristic-guided search process and facilitate the use of a widevariety of alignment objectives. Our experiments with programmatic constraintssuch as keyword and length constraints (studied widely in the pre-LLM era) andabstract objectives such as harmlessness and helpfulness (proposed in thepost-LLM era) show that we can DeAL with fine-grained trade-offs, improveadherence to alignment objectives, and address residual gaps in LLMs. Lastly,while DeAL can be effectively paired with RLHF and prompting techniques, itsgenerality makes decoding slower, an optimization we leave for future work.</description><author>James Y. Huang, Sailik Sengupta, Daniele Bonadiman, Yi-an Lai, Arshit Gupta, Nikolaos Pappas, Saab Mansour, Katrin Kirchhoff, Dan Roth</author><pubDate>Wed, 21 Feb 2024 02:25:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06147v2</guid></item><item><title>Optimizing Machine Translation through Prompt Engineering: An Investigation into ChatGPT's Customizability</title><link>http://arxiv.org/abs/2308.01391v2</link><description>This paper explores the influence of integrating the purpose of thetranslation and the target audience into prompts on the quality of translationsproduced by ChatGPT. Drawing on previous translation studies, industrypractices, and ISO standards, the research underscores the significance of thepre-production phase in the translation process. The study reveals that theinclusion of suitable prompts in large-scale language models like ChatGPT canyield flexible translations, a feat yet to be realized by conventional MachineTranslation (MT). The research scrutinizes the changes in translation qualitywhen prompts are used to generate translations that meet specific conditions.The evaluation is conducted from a practicing translator's viewpoint, bothsubjectively and qualitatively, supplemented by the use of OpenAI's wordembedding API for cosine similarity calculations. The findings suggest that theintegration of the purpose and target audience into prompts can indeed modifythe generated translations, generally enhancing the translation quality byindustry standards. The study also demonstrates the practical application ofthe "good translation" concept, particularly in the context of marketingdocuments and culturally dependent idioms.</description><author>Masaru Yamada</author><pubDate>Wed, 21 Feb 2024 07:24:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01391v2</guid></item><item><title>Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients</title><link>http://arxiv.org/abs/2402.10153v1</link><description>Effective diabetes management is crucial for maintaining health in diabeticpatients. Large Language Models (LLMs) have opened new avenues for diabetesmanagement, facilitating their efficacy. However, current LLM-based approachesare limited by their dependence on general sources and lack of integration withdomain-specific knowledge, leading to inaccurate responses. In this paper, wepropose a knowledge-infused LLM-powered conversational health agent (CHA) fordiabetic patients. We customize and leverage the open-source openCHA framework,enhancing our CHA with external knowledge and analytical capabilities. Thisintegration involves two key components: 1) incorporating the American DiabetesAssociation dietary guidelines and the Nutritionix information and 2) deployinganalytical tools that enable nutritional intake calculation and comparison withthe guidelines. We compare the proposed CHA with GPT4. Our evaluation includes100 diabetes-related questions on daily meal choices and assessing thepotential risks associated with the suggested diet. Our findings show that theproposed agent demonstrates superior performance in generating responses tomanage essential nutrients.</description><author>Mahyar Abbasian, Zhongqi Yang, Elahe Khatibi, Pengfei Zhang, Nitish Nagesh, Iman Azimi, Ramesh Jain, Amir M. Rahmani</author><pubDate>Thu, 15 Feb 2024 18:00:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10153v1</guid></item><item><title>Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients</title><link>http://arxiv.org/abs/2402.10153v2</link><description>Effective diabetes management is crucial for maintaining health in diabeticpatients. Large Language Models (LLMs) have opened new avenues for diabetesmanagement, facilitating their efficacy. However, current LLM-based approachesare limited by their dependence on general sources and lack of integration withdomain-specific knowledge, leading to inaccurate responses. In this paper, wepropose a knowledge-infused LLM-powered conversational health agent (CHA) fordiabetic patients. We customize and leverage the open-source openCHA framework,enhancing our CHA with external knowledge and analytical capabilities. Thisintegration involves two key components: 1) incorporating the American DiabetesAssociation dietary guidelines and the Nutritionix information and 2) deployinganalytical tools that enable nutritional intake calculation and comparison withthe guidelines. We compare the proposed CHA with GPT4. Our evaluation includes100 diabetes-related questions on daily meal choices and assessing thepotential risks associated with the suggested diet. Our findings show that theproposed agent demonstrates superior performance in generating responses tomanage essential nutrients.</description><author>Mahyar Abbasian, Zhongqi Yang, Elahe Khatibi, Pengfei Zhang, Nitish Nagesh, Iman Azimi, Ramesh Jain, Amir M. Rahmani</author><pubDate>Wed, 28 Feb 2024 19:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10153v2</guid></item><item><title>Exploring ChatGPT and its Impact on Society</title><link>http://arxiv.org/abs/2403.14643v2</link><description>Artificial intelligence has been around for a while, but suddenly it hasreceived more attention than ever before. Thanks to innovations from companieslike Google, Microsoft, Meta, and other major brands in technology. OpenAI,though, has triggered the button with its ground-breaking invention ChatGPT.ChatGPT is a Large Language Model (LLM) based on Transformer architecture thathas the ability to generate human-like responses in a conversational context.It uses deep learning algorithms to generate natural language responses toinput text. Its large number of parameters, contextual generation, andopen-domain training make it a versatile and effective tool for a wide range ofapplications, from chatbots to customer service to language translation. It hasthe potential to revolutionize various industries and transform the way weinteract with technology. However, the use of ChatGPT has also raised severalconcerns, including ethical, social, and employment challenges, which must becarefully considered to ensure the responsible use of this technology. Thearticle provides an overview of ChatGPT, delving into its architecture andtraining process. It highlights the potential impacts of ChatGPT on thesociety. In this paper, we suggest some approaches involving technology,regulation, education, and ethics in an effort to maximize ChatGPT's benefitswhile minimizing its negative impacts. This study is expected to contribute toa greater understanding of ChatGPT and aid in predicting the potential changesit may bring about.</description><author>Md. Asraful Haque, Shuai Li</author><pubDate>Mon, 25 Mar 2024 06:35:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14643v2</guid></item><item><title>Metric-aware LLM inference</title><link>http://arxiv.org/abs/2403.04182v1</link><description>Large language models (LLMs) have demonstrated strong results on a range ofNLP tasks. Typically, outputs are obtained via autoregressive sampling from theLLM's underlying distribution. We show that this inference strategy can besuboptimal for a range of tasks and associated evaluation metrics. As a remedy,we propose metric aware LLM inference: a decision theoretic approach optimizingfor custom metrics at inference time. We report improvements over baselines onacademic benchmarks and publicly available models.</description><author>Michal Lukasik, Harikrishna Narasimhan, Aditya Krishna Menon, Felix Yu, Sanjiv Kumar</author><pubDate>Thu, 07 Mar 2024 03:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04182v1</guid></item><item><title>InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions</title><link>http://arxiv.org/abs/2403.11435v1</link><description>Instruction tuning effectively optimizes Large Language Models (LLMs) fordownstream tasks. Due to the changing environment in real-life applications,LLMs necessitate continual task-specific adaptation without catastrophicforgetting. Considering the heavy computational cost, replay-based ContinualLearning (CL) methods are the simplest and most widely used for LLMs to addressthe forgetting issue. However, traditional replay-based methods do not fullyutilize instructions to customize the replay strategy. In this work, we proposea novel paradigm called Instruction-based Continual Learning (InsCL). InsCLdynamically replays previous data based on task similarity, calculated byWasserstein Distance with instructions. Moreover, we further introduce anInstruction Information Metric (InsInfo) to quantify the complexity anddiversity of instructions. According to InsInfo, InsCL guides the replayprocess more inclined to high-quality data. We conduct extensive experimentsover 16 tasks with different training orders, observing consistent performanceimprovements of InsCL. When all tasks have been trained, InsCL achievesperformance gains of 3.0 Relative Gain compared with Random Replay, and 27.96Relative Gain compared with No Replay.</description><author>Yifan Wang, Yafei Liu, Chufan Shi, Haoling Li, Chen Chen, Haonan Lu, Yujiu Yang</author><pubDate>Mon, 18 Mar 2024 04:10:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11435v1</guid></item><item><title>ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis</title><link>http://arxiv.org/abs/2404.10141v1</link><description>Text-to-Image (T2I) Synthesis has made tremendous strides in enhancingsynthesized image quality, but current datasets evaluate model performance onlyon descriptive, instruction-based prompts. Real-world news image captions takea more pragmatic approach, providing high-level situational and Named-Entity(NE) information and limited physical object descriptions, making themabstractive. To evaluate the ability of T2I models to capture intended subjectsfrom news captions, we introduce the Abstractive News Captions with High-levelcOntext Representation (ANCHOR) dataset, containing 70K+ samples sourced from 5different news media organizations. With Large Language Models (LLM) achievingsuccess in language and commonsense reasoning tasks, we explore the ability ofdifferent LLMs to identify and understand key subjects from abstractivecaptions. Our proposed method Subject-Aware Finetuning (SAFE), selects andenhances the representation of key subjects in synthesized images by leveragingLLM-generated subject weights. It also adapts to the domain distribution ofnews images and captions through custom Domain Fine-tuning, outperformingcurrent T2I baselines on ANCHOR. By launching the ANCHOR dataset, we hope tomotivate research in furthering the Natural Language Understanding (NLU)capabilities of T2I models.</description><author>Aashish Anantha Ramakrishnan, Sharon X. Huang, Dongwon Lee</author><pubDate>Mon, 15 Apr 2024 22:19:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10141v1</guid></item><item><title>Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents</title><link>http://arxiv.org/abs/2402.05746v2</link><description>Scene simulation in autonomous driving has gained significant attentionbecause of its huge potential for generating customized data. However, existingeditable scene simulation approaches face limitations in terms of userinteraction efficiency, multi-camera photo-realistic rendering and externaldigital assets integration. To address these challenges, this paper introducesChatSim, the first system that enables editable photo-realistic 3D drivingscene simulations via natural language commands with external digital assets.To enable editing with high command flexibility,~ChatSim leverages a largelanguage model (LLM) agent collaboration framework. To generate photo-realisticoutcomes, ChatSim employs a novel multi-camera neural radiance field method.Furthermore, to unleash the potential of extensive high-quality digital assets,ChatSim employs a novel multi-camera lighting estimation method to achievescene-consistent assets' rendering. Our experiments on Waymo Open Datasetdemonstrate that ChatSim can handle complex language commands and generatecorresponding photo-realistic scene videos.</description><author>Yuxi Wei, Zi Wang, Yifan Lu, Chenxin Xu, Changxing Liu, Hao Zhao, Siheng Chen, Yanfeng Wang</author><pubDate>Mon, 11 Mar 2024 14:45:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05746v2</guid></item><item><title>Source-Free Domain Adaptation with Frozen Multimodal Foundation Model</title><link>http://arxiv.org/abs/2311.16510v3</link><description>Source-Free Domain Adaptation (SFDA) aims to adapt a source model for atarget domain, with only access to unlabeled target training data and thesource model pre-trained on a supervised source domain. Relying on pseudolabeling and/or auxiliary supervision, conventional methods are inevitablyerror-prone. To mitigate this limitation, in this work we for the first timeexplore the potentials of off-the-shelf vision-language (ViL) multimodal models(e.g.,CLIP) with rich whilst heterogeneous knowledge. We find that directlyapplying the ViL model to the target domain in a zero-shot fashion isunsatisfactory, as it is not specialized for this particular task but largelygeneric. To make it task specific, we propose a novel Distilling multimodalFoundation model(DIFO)approach. Specifically, DIFO alternates between two stepsduring adaptation: (i) Customizing the ViL model by maximizing the mutualinformation with the target model in a prompt learning manner, (ii) Distillingthe knowledge of this customized ViL model to the target model. For morefine-grained and reliable distillation, we further introduce two effectiveregularization terms, namely most-likely category encouragement and predictiveconsistency. Extensive experiments show that DIFO significantly outperforms thestate-of-the-art alternatives. Code is here</description><author>Song Tang, Wenxin Su, Mao Ye, Xiatian Zhu</author><pubDate>Wed, 13 Mar 2024 06:11:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16510v3</guid></item><item><title>Source-Free Domain Adaptation with Frozen Multimodal Foundation Model</title><link>http://arxiv.org/abs/2311.16510v2</link><description>Source-Free Domain Adaptation (SFDA) aims to adapt a source model for atarget domain, with only access to unlabeled target training data and thesource model pre-trained on a supervised source domain. Relying on pseudolabeling and/or auxiliary supervision, conventional methods are inevitablyerror-prone. To mitigate this limitation, in this work we for the first timeexplore the potentials of off-the-shelf vision-language (ViL) multimodal models(e.g.,CLIP) with rich whilst heterogeneous knowledge. We find that directlyapplying the ViL model to the target domain in a zero-shot fashion isunsatisfactory, as it is not specialized for this particular task but largelygeneric. To make it task specific, we propose a novel Distilling multimodalFoundation model(DIFO)approach. Specifically, DIFO alternates between two stepsduring adaptation: (i) Customizing the ViL model by maximizing the mutualinformation with the target model in a prompt learning manner, (ii) Distillingthe knowledge of this customized ViL model to the target model. For morefine-grained and reliable distillation, we further introduce two effectiveregularization terms, namely most-likely category encouragement and predictiveconsistency. Extensive experiments show that DIFO significantly outperforms thestate-of-the-art alternatives. Code is here</description><author>Song Tang, Wenxin Su, Mao Ye, Xiatian Zhu</author><pubDate>Tue, 12 Mar 2024 15:41:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16510v2</guid></item><item><title>AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes</title><link>http://arxiv.org/abs/2312.06644v2</link><description>Inspired by cognitive theories, we introduce AnyHome, a framework thattranslates any text into well-structured and textured indoor scenes at ahouse-scale. By prompting Large Language Models (LLMs) with designed templates,our approach converts provided textual narratives into amodal structuredrepresentations. These representations guarantee consistent and realisticspatial layouts by directing the synthesis of a geometry mesh within definedconstraints. A Score Distillation Sampling process is then employed to refinethe geometry, followed by an egocentric inpainting process that adds lifeliketextures to it. AnyHome stands out with its editability, customizability,diversity, and realism. The structured representations for scenes allow forextensive editing at varying levels of granularity. Capable of interpretingtexts ranging from simple labels to detailed narratives, AnyHome generatesdetailed geometries and textures that outperform existing methods in bothquantitative and qualitative measures.</description><author>Rao Fu, Zehao Wen, Zichen Liu, Srinath Sridhar</author><pubDate>Wed, 20 Mar 2024 18:58:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06644v2</guid></item><item><title>Fine-tuning Large Language Model (LLM) Artificial Intelligence Chatbots in Ophthalmology and LLM-based evaluation using GPT-4</title><link>http://arxiv.org/abs/2402.10083v1</link><description>Purpose: To assess the alignment of GPT-4-based evaluation to human clinicianexperts, for the evaluation of responses to ophthalmology-related patientqueries generated by fine-tuned LLM chatbots. Methods: 400 ophthalmologyquestions and paired answers were created by ophthalmologists to representcommonly asked patient questions, divided into fine-tuning (368; 92%), andtesting (40; 8%). We find-tuned 5 different LLMs, including LLAMA2-7b,LLAMA2-7b-Chat, LLAMA2-13b, and LLAMA2-13b-Chat. For the testing dataset,additional 8 glaucoma QnA pairs were included. 200 responses to the testingdataset were generated by 5 fine-tuned LLMs for evaluation. A customizedclinical evaluation rubric was used to guide GPT-4 evaluation, grounded onclinical accuracy, relevance, patient safety, and ease of understanding. GPT-4evaluation was then compared against ranking by 5 clinicians for clinicalalignment. Results: Among all fine-tuned LLMs, GPT-3.5 scored the highest(87.1%), followed by LLAMA2-13b (80.9%), LLAMA2-13b-chat (75.5%),LLAMA2-7b-Chat (70%) and LLAMA2-7b (68.8%) based on the GPT-4 evaluation. GPT-4evaluation demonstrated significant agreement with human clinician rankings,with Spearman and Kendall Tau correlation coefficients of 0.90 and 0.80respectively; while correlation based on Cohen Kappa was more modest at 0.50.Notably, qualitative analysis and the glaucoma sub-analysis revealed clinicalinaccuracies in the LLM-generated responses, which were appropriatelyidentified by the GPT-4 evaluation. Conclusion: The notable clinical alignmentof GPT-4 evaluation highlighted its potential to streamline the clinicalevaluation of LLM chatbot responses to healthcare-related queries. Bycomplementing the existing clinician-dependent manual grading, this efficientand automated evaluation could assist the validation of future developments inLLM applications for healthcare.</description><author>Ting Fang Tan, Kabilan Elangovan, Liyuan Jin, Yao Jie, Li Yong, Joshua Lim, Stanley Poh, Wei Yan Ng, Daniel Lim, Yuhe Ke, Nan Liu, Daniel Shu Wei Ting</author><pubDate>Thu, 15 Feb 2024 16:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10083v1</guid></item><item><title>BattleAgent: Multi-modal Dynamic Emulation on Historical Battles to Complement Historical Analysis</title><link>http://arxiv.org/abs/2404.15532v1</link><description>This paper presents BattleAgent, an emulation system that combines the LargeVision-Language Model and Multi-agent System. This novel system aims tosimulate complex dynamic interactions among multiple agents, as well as betweenagents and their environments, over a period of time. It emulates both thedecision-making processes of leaders and the viewpoints of ordinaryparticipants, such as soldiers. The emulation showcases the currentcapabilities of agents, featuring fine-grained multi-modal interactions betweenagents and landscapes. It develops customizable agent structures to meetspecific situational requirements, for example, a variety of battle-relatedactivities like scouting and trench digging. These components collaborate torecreate historical events in a lively and comprehensive manner while offeringinsights into the thoughts and feelings of individuals from diverse viewpoints.The technological foundations of BattleAgent establish detailed and immersivesettings for historical battles, enabling individual agents to partake in,observe, and dynamically respond to evolving battle scenarios. This methodologyholds the potential to substantially deepen our understanding of historicalevents, particularly through individual accounts. Such initiatives can also aidhistorical research, as conventional historical narratives often lackdocumentation and prioritize the perspectives of decision-makers, therebyoverlooking the experiences of ordinary individuals. BattelAgent illustratesAI's potential to revitalize the human aspect in crucial social events, therebyfostering a more nuanced collective understanding and driving the progressivedevelopment of human society.</description><author>Shuhang Lin, Wenyue Hua, Lingyao Li, Che-Jui Chang, Lizhou Fan, Jianchao Ji, Hang Hua, Mingyu Jin, Jiebo Luo, Yongfeng Zhang</author><pubDate>Tue, 23 Apr 2024 22:37:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15532v1</guid></item><item><title>Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru</title><link>http://arxiv.org/abs/2402.11571v1</link><description>Social robots aim to establish long-term bonds with humans through engagingconversation. However, traditional conversational approaches, reliant onscripted interactions, often fall short in maintaining engaging conversations.This paper addresses this limitation by integrating large language models(LLMs) into social robots to achieve more dynamic and expressive conversations.We introduce a fully-automated conversation system that leverages LLMs togenerate robot responses with expressive behaviors, congruent with the robot'spersonality. We incorporate robot behavior with two modalities: 1) atext-to-speech (TTS) engine capable of various delivery styles, and 2) alibrary of physical actions for the robot. We develop a custom,state-of-the-art emotion recognition model to dynamically select the robot'stone of voice and utilize emojis from LLM output as cues for generating robotactions. A demo of our system is available here. To illuminate design andimplementation issues, we conduct a pilot study where volunteers chat with asocial robot using our proposed system, and we analyze their feedback,conducting a rigorous error analysis of chat transcripts. Feedback wasoverwhelmingly positive, with participants commenting on the robot's empathy,helpfulness, naturalness, and entertainment. Most negative feedback was due toautomatic speech recognition (ASR) errors which had limited impact onconversations. However, we observed a small class of errors, such as the LLMrepeating itself or hallucinating fictitious information and human responses,that have the potential to derail conversations, raising important issues forLLM application.</description><author>Zining Wang, Paul Reisert, Eric Nichols, Randy Gomez</author><pubDate>Sun, 18 Feb 2024 12:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11571v1</guid></item><item><title>Metric-aware LLM inference for regression and scoring</title><link>http://arxiv.org/abs/2403.04182v2</link><description>Large language models (LLMs) have demonstrated strong results on a range ofNLP tasks. Typically, outputs are obtained via autoregressive sampling from theLLM's underlying distribution. Building on prior work on Minimum Bayes RiskDecoding, we show that this inference strategy can be suboptimal for a range ofregression and scoring tasks, and associated evaluation metrics. As a remedy,we propose metric aware LLM inference: a decision theoretic approach optimizingfor custom regression and scoring metrics at inference time. We reportimprovements over baselines on academic benchmarks and publicly availablemodels.</description><author>Michal Lukasik, Harikrishna Narasimhan, Aditya Krishna Menon, Felix Yu, Sanjiv Kumar</author><pubDate>Thu, 04 Apr 2024 14:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04182v2</guid></item><item><title>Multi-dimensional Evaluation of Empathetic Dialog Responses</title><link>http://arxiv.org/abs/2402.11409v1</link><description>Empathy is a critical element of effective and satisfactory conversationalcommunication, yet previous studies in measuring conversational empathy mostlyfocus on expressed communicative intents -- in which way empathy is expressed,ignoring the fact that conversation is also a collaborative practice involvingboth speakers and listeners. In contrast, we propose a multi-dimensionalempathy evaluation framework that extends upon existing work to measure bothexpressed intents from the speaker's perspective and perceived empathy from thelistener's perspective. Applying the proposed framework to analyzing ourinternal customer-service dialogue shows that the two dimensions (expressedintent types and perceived empathy) are inter-connected, while perceivedempathy has high correlation with the satisfactory level of dialogue sessions.This proposed framework still requires subjective assessments from trainedannotators, which can be non-trivial to collect. To scale up evaluation withoutexcessive reliance on carefully annotated data, we explore different modelingoptions to automatically measure conversational empathy with (1) promptingfrozen large language models (LLMs) and (2) training language model-basedclassifiers. Extensive experiments on both internal and external dialoguedatasets show that measuring conversational empathy remains a challenging taskfor prompting frozen LLMs, reflected by less satisfying performance of GPT-4and Flan family models. On the other hand, our proposed instruction-finetunedclassifiers based on sequence-to-sequence (Seq2Seq) language models is able toachieve the best performance compared to prior works and competitive baselines.Finally, we perform comprehensive ablation studies on the performance ofproposed instruction-finetuned classifiers and give recommendations onpotentially adopting them as automatic conversational empathy evaluationmetrics.</description><author>Zhichao Xu, Jiepu Jiang</author><pubDate>Sun, 18 Feb 2024 00:32:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11409v1</guid></item><item><title>Self-Selected Attention Span for Accelerating Large Language Model Inference</title><link>http://arxiv.org/abs/2404.09336v1</link><description>Large language models (LLMs) can solve challenging tasks. However, theirinference computation on modern GPUs is highly inefficient due to theincreasing number of tokens they must attend to as they generate new ones. Toaddress this inefficiency, we capitalize on LLMs' problem-solving capabilitiesto optimize their own inference-time efficiency. We demonstrate with twospecific tasks: (a) evaluating complex arithmetic expressions and (b)summarizing news articles. For both tasks, we create custom datasets tofine-tune an LLM. The goal of fine-tuning is twofold: first, to make the LLMlearn to solve the evaluation or summarization task, and second, to train it toidentify the minimal attention spans required for each step of the task. As aresult, the fine-tuned model is able to convert these self-identified minimalattention spans into sparse attention masks on-the-fly during inference. Wedevelop a custom CUDA kernel to take advantage of the reduced context to attendto. We demonstrate that using this custom CUDA kernel improves the throughputof LLM inference by 28%. Our work presents an end-to-end demonstration showingthat training LLMs to self-select their attention spans speeds upautoregressive inference in solving real-world tasks.</description><author>Tian Jin, Wanzin Yazar, Zifei Xu, Sayeh Sharify, Xin Wang</author><pubDate>Sun, 14 Apr 2024 20:36:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09336v1</guid></item><item><title>Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts</title><link>http://arxiv.org/abs/2402.10554v1</link><description>Aspect-based summarization has seen significant advancements, especially instructured text. Yet, summarizing disordered, large-scale texts, like thosefound in social media and customer feedback, remains a significant challenge.Current research largely targets predefined aspects within structured texts,neglecting the complexities of dynamic and disordered environments. Addressingthis gap, we introduce Disordered-DABS, a novel benchmark for dynamicaspect-based summarization tailored to unstructured text. Developed by adaptingexisting datasets for cost-efficiency and scalability, our comprehensiveexperiments and detailed human evaluations reveal that Disordered-DABS posesunique challenges to contemporary summarization models, includingstate-of-the-art language models such as GPT-3.5.</description><author>Xiaobo Guo, Soroush Vosoughi</author><pubDate>Fri, 16 Feb 2024 10:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10554v1</guid></item><item><title>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.14608v2</link><description>Large models represent a groundbreaking advancement in multiple applicationfields, enabling remarkable achievements across various tasks. However, theirunprecedented scale comes with significant computational costs. These models,often consisting of billions of parameters, require vast amounts ofcomputational resources for execution. Especially, the expansive scale andcomputational demands pose considerable challenges when customizing them forparticular downstream tasks, particularly over the hardware platformsconstrained by computational capabilities. Parameter Efficient Fine-Tuning(PEFT) provides a practical solution by efficiently adapt the large models overthe various downstream tasks. In particular, PEFT refers to the process ofadjusting the parameters of a pre-trained large models to adapt it to aspecific task while minimizing the number of additional parameters introducedor computational resources required. This approach is particularly importantwhen dealing with large language models with high parameter counts, asfine-tuning these models from scratch can be computationally expensive andresource-intensive, posing considerable challenges in the supporting systemplatform design. In this survey, we present comprehensive studies of variousPEFT algorithms, examining their performance and computational overhead.Moreover, we provide an overview of applications developed using different PEFTalgorithms and discuss common techniques employed to mitigate computation costsfor PEFT. In addition to the algorithmic perspective, we overview variousreal-world system designs to investigate the implementation costs associatedwith different PEFT algorithms. This survey serves as an indispensable resourcefor researchers aiming to understand both the PEFT algorithm and its systemimplementation, offering detailed insights into recent advancements andpractical applications.</description><author>Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang</author><pubDate>Mon, 01 Apr 2024 16:11:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14608v2</guid></item><item><title>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.14608v1</link><description>Large models represent a groundbreaking advancement in multiple applicationfields, enabling remarkable achievements across various tasks. However, theirunprecedented scale comes with significant computational costs. These models,often consisting of billions of parameters, require vast amounts ofcomputational resources for execution. Especially, the expansive scale andcomputational demands pose considerable challenges when customizing them forparticular downstream tasks, particularly over the hardware platformsconstrained by computational capabilities. Parameter Efficient Fine-Tuning(PEFT) provides a practical solution by efficiently adapt the large models overthe various downstream tasks. In particular, PEFT refers to the process ofadjusting the parameters of a pre-trained large models to adapt it to aspecific task while minimizing the number of additional parameters introducedor computational resources required. This approach is particularly importantwhen dealing with large language models with high parameter counts, asfine-tuning these models from scratch can be computationally expensive andresource-intensive, posing considerable challenges in the supporting systemplatform design. In this survey, we present comprehensive studies of variousPEFT algorithms, examining their performance and computational overhead.Moreover, we provide an overview of applications developed using different PEFTalgorithms and discuss common techniques employed to mitigate computation costsfor PEFT. In addition to the algorithmic perspective, we overview variousreal-world system designs to investigate the implementation costs associatedwith different PEFT algorithms. This survey serves as an indispensable resourcefor researchers aiming to understand both the PEFT algorithm and its systemimplementation, offering detailed insights into recent advancements andpractical applications.</description><author>Zeyu Han, Chao Gao, Jinyang Liu, Jeff, Zhang, Sai Qian Zhang</author><pubDate>Thu, 21 Mar 2024 18:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14608v1</guid></item><item><title>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.14608v3</link><description>Large models represent a groundbreaking advancement in multiple applicationfields, enabling remarkable achievements across various tasks. However, theirunprecedented scale comes with significant computational costs. These models,often consisting of billions of parameters, require vast amounts ofcomputational resources for execution. Especially, the expansive scale andcomputational demands pose considerable challenges when customizing them forparticular downstream tasks, particularly over the hardware platformsconstrained by computational capabilities. Parameter Efficient Fine-Tuning(PEFT) provides a practical solution by efficiently adapt the large models overthe various downstream tasks. In particular, PEFT refers to the process ofadjusting the parameters of a pre-trained large models to adapt it to aspecific task while minimizing the number of additional parameters introducedor computational resources required. This approach is particularly importantwhen dealing with large language models with high parameter counts, asfine-tuning these models from scratch can be computationally expensive andresource-intensive, posing considerable challenges in the supporting systemplatform design. In this survey, we present comprehensive studies of variousPEFT algorithms, examining their performance and computational overhead.Moreover, we provide an overview of applications developed using different PEFTalgorithms and discuss common techniques employed to mitigate computation costsfor PEFT. In addition to the algorithmic perspective, we overview variousreal-world system designs to investigate the implementation costs associatedwith different PEFT algorithms. This survey serves as an indispensable resourcefor researchers aiming to understand both the PEFT algorithm and its systemimplementation, offering detailed insights into recent advancements andpractical applications.</description><author>Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang</author><pubDate>Wed, 17 Apr 2024 17:23:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14608v3</guid></item><item><title>InterGen: Diffusion-based Multi-human Motion Generation under Complex Interactions</title><link>http://arxiv.org/abs/2304.05684v3</link><description>We have recently seen tremendous progress in diffusion advances forgenerating realistic human motions. Yet, they largely disregard the multi-humaninteractions. In this paper, we present InterGen, an effective diffusion-basedapproach that incorporates human-to-human interactions into the motiondiffusion process, which enables layman users to customize high-qualitytwo-person interaction motions, with only text guidance. We first contribute amultimodal dataset, named InterHuman. It consists of about 107M frames fordiverse two-person interactions, with accurate skeletal motions and 23,337natural language descriptions. For the algorithm side, we carefully tailor themotion diffusion model to our two-person interaction setting. To handle thesymmetry of human identities during interactions, we propose two cooperativetransformer-based denoisers that explicitly share weights, with a mutualattention mechanism to further connect the two denoising processes. Then, wepropose a novel representation for motion input in our interaction diffusionmodel, which explicitly formulates the global relations between the twoperformers in the world frame. We further introduce two novel regularizationterms to encode spatial relations, equipped with a corresponding damping schemeduring the training of our interaction diffusion model. Extensive experimentsvalidate the effectiveness and generalizability of InterGen. Notably, it cangenerate more diverse and compelling two-person motions than previous methodsand enables various downstream applications for human interactions.</description><author>Han Liang, Wenqian Zhang, Wenxuan Li, Jingyi Yu, Lan Xu</author><pubDate>Thu, 28 Mar 2024 04:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05684v3</guid></item><item><title>Mixture of Cluster-conditional LoRA Experts for Vision-language Instruction Tuning</title><link>http://arxiv.org/abs/2312.12379v4</link><description>Instruction tuning of Large Vision-language Models (LVLMs) has revolutionizedthe development of versatile models with zero-shot generalization across a widerange of downstream vision-language tasks. However, the diversity of trainingtasks of different sources and formats would lead to inevitable task conflicts,where different tasks conflict for the same set of model parameters, resultingin sub-optimal instructionfollowing abilities. To address that, we propose theMixture of Clusterconditional LoRA Experts (MoCLE), a novel Mixture of Experts(MoE) architecture designed to activate the task-customized model parametersbased on the instruction clusters. A separate universal expert is furtherincorporated to improve generalization capabilities of MoCLE for novelinstructions. Extensive experiments on 11 zero-shot tasks demonstrate theeffectiveness of MoCLE.</description><author>Yunhao Gou, Zhili Liu, Kai Chen, Lanqing Hong, Hang Xu, Aoxue Li, Dit-Yan Yeung, James T. Kwok, Yu Zhang</author><pubDate>Fri, 22 Mar 2024 10:36:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12379v4</guid></item><item><title>Evaluating Large Language Models in Analysing Classroom Dialogue</title><link>http://arxiv.org/abs/2402.02380v3</link><description>This study explores the application of Large Language Models (LLMs),specifically GPT-4, in the analysis of classroom dialogue, a crucial researchtask for both teaching diagnosis and quality improvement. Recognizing theknowledge-intensive and labor-intensive nature of traditional qualitativemethods in educational research, this study investigates the potential of LLMto streamline and enhance the analysis process. The study involves datasetsfrom a middle school, encompassing classroom dialogues across mathematics andChinese classes. These dialogues were manually coded by educational experts andthen analyzed using a customised GPT-4 model. This study focuses on comparingmanual annotations with the outputs of GPT-4 to evaluate its efficacy inanalyzing educational dialogues. Time efficiency, inter-coder agreement, andinter-coder reliability between human coders and GPT-4 are evaluated. Resultsindicate substantial time savings with GPT-4, and a high degree of consistencyin coding between the model and human coders, with some discrepancies inspecific codes. These findings highlight the strong potential of LLM inteaching evaluation and facilitation.</description><author>Yun Long, Haifeng Luo, Yu Zhang</author><pubDate>Fri, 23 Feb 2024 02:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02380v3</guid></item><item><title>Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond</title><link>http://arxiv.org/abs/2403.10667v2</link><description>Developing a universal model that can effectively harness heterogeneousresources and respond to a wide range of personalized needs has been alongstanding community aspiration. Our daily choices, especially in domainslike fashion and retail, are substantially shaped by multi-modal data, such aspictures and textual descriptions. These modalities not only offer intuitiveguidance but also cater to personalized user preferences. However, thepredominant personalization approaches mainly focus on the ID or text-basedrecommendation problem, failing to comprehend the information spanning varioustasks or modalities. In this paper, our goal is to establish a Unified paradigmfor Multi-modal Personalization systems (UniMP), which effectively leveragesmulti-modal data while eliminating the complexities associated with task- andmodality-specific customization. We argue that the advancements in foundationalgenerative modeling have provided the flexibility and effectiveness necessaryto achieve the objective. In light of this, we develop a generic and extensiblepersonalization generative framework, that can handle a wide range ofpersonalized needs including item recommendation, product search, preferenceprediction, explanation generation, and further user-guided image generation.Our methodology enhances the capabilities of foundational language models forpersonalized tasks by seamlessly ingesting interleaved cross-modal user historyinformation, ensuring a more precise and customized experience for users. Totrain and evaluate the proposed multi-modal personalized tasks, we alsointroduce a novel and comprehensive benchmark covering a variety of userrequirements. Our experiments on the real-world benchmark showcase the model'spotential, outperforming competitive methods specialized for each task.</description><author>Tianxin Wei, Bowen Jin, Ruirui Li, Hansi Zeng, Zhengyang Wang, Jianhui Sun, Qingyu Yin, Hanqing Lu, Suhang Wang, Jingrui He, Xianfeng Tang</author><pubDate>Wed, 27 Mar 2024 22:11:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.10667v2</guid></item><item><title>SoK: Reducing the Vulnerability of Fine-tuned Language Models to Membership Inference Attacks</title><link>http://arxiv.org/abs/2403.08481v1</link><description>Natural language processing models have experienced a significant upsurge inrecent years, with numerous applications being built upon them. Many of theseapplications require fine-tuning generic base models on customized, proprietarydatasets. This fine-tuning data is especially likely to contain personal orsensitive information about individuals, resulting in increased privacy risk.Membership inference attacks are the most commonly employed attack to assessthe privacy leakage of a machine learning model. However, limited research isavailable on the factors that affect the vulnerability of language models tothis kind of attack, or on the applicability of different defense strategies inthe language domain. We provide the first systematic review of thevulnerability of fine-tuned large language models to membership inferenceattacks, the various factors that come into play, and the effectiveness ofdifferent defense strategies. We find that some training methods providesignificantly reduced privacy risk, with the combination of differentialprivacy and low-rank adaptors achieving the best privacy protection againstthese attacks.</description><author>Guy Amit, Abigail Goldsteen, Ariel Farkash</author><pubDate>Wed, 13 Mar 2024 13:46:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08481v1</guid></item><item><title>Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge</title><link>http://arxiv.org/abs/2403.01432v2</link><description>Large language models (LLMs) memorize a vast amount of factual knowledge,exhibiting strong performance across diverse tasks and domains. However, it hasbeen observed that the performance diminishes when dealing with less-popular orlow-frequency concepts and entities, for example in domain specificapplications. The two prominent approaches to enhance the performance of LLMson low-frequent topics are: Retrieval Augmented Generation (RAG) andfine-tuning (FT) over synthetic data. This paper explores and evaluates theimpact of RAG and FT on customizing LLMs in handling low-frequency entities onquestion answering task. Our findings indicate that FT significantly boosts theperformance across entities of varying popularity, especially in the most andleast popular groups, while RAG surpasses other methods. Additionally, thesuccess of both RAG and FT approaches is amplified by advancements in retrievaland data augmentation techniques. We release our data and code athttps://github.com/informagi/RAGvsFT.</description><author>Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi</author><pubDate>Thu, 07 Mar 2024 11:24:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01432v2</guid></item><item><title>Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments</title><link>http://arxiv.org/abs/2402.14672v1</link><description>The applications of large language models (LLMs) have expanded well beyondthe confines of text processing, signaling a new era where LLMs are envisionedas generalist language agents capable of operating within complex real-worldenvironments. These environments are often highly expansive, making itimpossible for the LLM to process them within its short-term memory. Motivatedby recent research on extending the capabilities of LLMs with tools, this paperinvestigates the intriguing potential of tools to augment LLMs in handling suchcomplexity. To this end, we design customized tools to aid in the proactiveexploration within these massive environments. Such tools can serve as amiddleware layer shielding the LLM from environmental complexity. In tworepresentative complex environments -- knowledge bases (KBs) and databases --we demonstrate the significant potential of augmenting language agents withtools in complex environments. Notably, equipped with these tools, GPT-4achieves 2.8X the performance of the best baseline in tasks requiring access todatabase content and 2.2X in KB tasks. Our findings illuminate the path foradvancing language agents in complex real-world applications.</description><author>Yu Gu, Yiheng Shu, Hao Yu, Xiao Liu, Yuxiao Dong, Jie Tang, Jayanth Srinivasa, Hugo Latapie, Yu Su</author><pubDate>Thu, 22 Feb 2024 16:18:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14672v1</guid></item><item><title>Can Public Large Language Models Help Private Cross-device Federated Learning?</title><link>http://arxiv.org/abs/2305.12132v2</link><description>We study (differentially) private federated learning (FL) of language models.The language models in cross-device FL are relatively small, which can betrained with meaningful formal user-level differential privacy (DP) guaranteeswhen massive parallelism in training is enabled by the participation of amoderate size of users. Recently, public data has been used to improveprivacy-utility trade-offs for both large and small language models. In thiswork, we provide a systematic study of using large-scale public data and LLMsto help differentially private training of on-device FL models, and furtherimprove the privacy-utility tradeoff by techniques of distillation. Moreover,we propose a novel distribution matching algorithm with theoretical groundingto sample public data close to private data distribution, which significantlyimproves the sample efficiency of (pre-)training on public data. The proposedmethod is efficient and effective for training private models by takingadvantage of public data, especially for customized on-device architecturesthat do not have ready-to-use pre-trained models.</description><author>Boxin Wang, Yibo Jacky Zhang, Yuan Cao, Bo Li, H. Brendan McMahan, Sewoong Oh, Zheng Xu, Manzil Zaheer</author><pubDate>Fri, 12 Apr 2024 22:01:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12132v2</guid></item><item><title>Large Language Models as Financial Data Annotators: A Study on Effectiveness and Efficiency</title><link>http://arxiv.org/abs/2403.18152v1</link><description>Collecting labeled datasets in finance is challenging due to scarcity ofdomain experts and higher cost of employing them. While Large Language Models(LLMs) have demonstrated remarkable performance in data annotation tasks ongeneral domain datasets, their effectiveness on domain specific datasetsremains underexplored. To address this gap, we investigate the potential ofLLMs as efficient data annotators for extracting relations in financialdocuments. We compare the annotations produced by three LLMs (GPT-4, PaLM 2,and MPT Instruct) against expert annotators and crowdworkers. We demonstratethat the current state-of-the-art LLMs can be sufficient alternatives tonon-expert crowdworkers. We analyze models using various prompts and parametersettings and find that customizing the prompts for each relation group byproviding specific examples belonging to those groups is paramount.Furthermore, we introduce a reliability index (LLM-RelIndex) used to identifyoutputs that may require expert attention. Finally, we perform an extensivetime, cost and error analysis and provide recommendations for the collectionand usage of automated annotations in domain-specific settings.</description><author>Toyin Aguda, Suchetha Siddagangappa, Elena Kochkina, Simerjot Kaur, Dongsheng Wang, Charese Smiley, Sameena Shah</author><pubDate>Wed, 27 Mar 2024 00:32:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18152v1</guid></item><item><title>PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models</title><link>http://arxiv.org/abs/2404.15549v1</link><description>Clinical trial matching is the task of identifying trials for which patientsmay be potentially eligible. Typically, this task is labor-intensive andrequires detailed verification of patient electronic health records (EHRs)against the stringent inclusion and exclusion criteria of clinical trials. Thisprocess is manual, time-intensive, and challenging to scale up, resulting inmany patients missing out on potential therapeutic options. Recent advancementsin Large Language Models (LLMs) have made automating patient-trial matchingpossible, as shown in multiple concurrent research studies. However, thecurrent approaches are confined to constrained, often synthetic datasets thatdo not adequately mirror the complexities encountered in real-world medicaldata. In this study, we present the first, end-to-end large-scale empiricalevaluation of clinical trial matching using real-world EHRs. Our studyshowcases the capability of LLMs to accurately match patients with appropriateclinical trials. We perform experiments with proprietary LLMs, including GPT-4and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and showthat OncoLLM, despite its significantly smaller size, not only outperformsGPT-3.5 but also matches the performance of qualified medical doctors. Allexperiments were carried out on real-world EHRs that include clinical notes andavailable clinical trials from a single cancer center in the United States.</description><author>Shashi Kant Gupta, Aditya Basu, Mauro Nievas, Jerrin Thomas, Nathan Wolfrath, Adhitya Ramamurthi, Bradley Taylor, Anai N. Kothari, Therica M. Miller, Sorena Nadaf-Rahrov, Yanshan Wang, Hrituraj Singh</author><pubDate>Tue, 23 Apr 2024 23:33:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15549v1</guid></item><item><title>CacheGen: Fast Context Loading for Language Model Applications via KV Cache Streaming</title><link>http://arxiv.org/abs/2310.07240v2</link><description>As large language models (LLMs) take on complex tasks, their inputs aresupplemented with longer contexts that incorporate domain knowledge oruser-specific information. Yet using long contexts poses a challenge forresponsive LLM systems, as nothing can be generated until the whole context isprocessed by the LLM. While the context-processing delay can be reduced byreusing the KV cache of a context across different inputs, fetching the KVcache, which contains large tensors, over the network can cause extra networkdelays. CacheGen is a fast context-loading module for LLM systems. First, CacheGenuses a custom tensor encoder, which embraces KV cache's distributionalproperties, to encode a KV cache into more compact bitstream representationswith negligible encoding/decoding overhead. This reduces the bandwidth demandto fetch the KV cache. Second, to maintain low context-loading delay and highgeneration quality, CacheGen adapts the streaming strategies to cope withchanges in available bandwidth. When available bandwidth drops, CacheGen mayraise the compression level for a part of the context or choose to recomputeits KV cache on the fly. We test CacheGen on four popular LLMs of various sizesand four datasets (662 contexts in total). Compared to the recent systems thatreuse the KV cache, CacheGen reduces the KV cache size by 3.7-4.3x and thetotal delay in fetching and processing contexts by 2.7-3.2x while havingnegligible impact on the LLM response quality in accuracy or perplexity.</description><author>Yuhan Liu, Hanchen Li, Yihua Cheng, Siddhant Ray, Yuyang Huang, Qizheng Zhang, Kuntai Du, Jiayi Yao, Shan Lu, Ganesh Ananthanarayanan, Michael Maire, Henry Hoffmann, Ari Holtzman, Junchen Jiang</author><pubDate>Wed, 13 Mar 2024 06:55:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07240v2</guid></item><item><title>CacheGen: Fast Context Loading for Language Model Applications via KV Cache Streaming</title><link>http://arxiv.org/abs/2310.07240v3</link><description>As large language models (LLMs) take on complex tasks, their inputs aresupplemented with longer contexts that incorporate domain knowledge oruser-specific information. Yet using long contexts poses a challenge forresponsive LLM systems, as nothing can be generated until the whole context isprocessed by the LLM. While the context-processing delay can be reduced byreusing the KV cache of a context across different inputs, fetching the KVcache, which contains large tensors, over the network can cause extra networkdelays. CacheGen is a fast context-loading module for LLM systems. First, CacheGenuses a custom tensor encoder, which embraces KV cache's distributionalproperties, to encode a KV cache into more compact bitstream representationswith negligible encoding/decoding overhead. This reduces the bandwidth demandto fetch the KV cache. Second, to maintain low context-loading delay and highgeneration quality, CacheGen adapts the streaming strategies to cope withchanges in available bandwidth. When available bandwidth drops, CacheGen mayraise the compression level for a part of the context or choose to recomputeits KV cache on the fly. We test CacheGen on four popular LLMs of various sizesand four datasets (662 contexts in total). Compared to the recent systems thatreuse the KV cache, CacheGen reduces the KV cache size by 3.7-4.3x and thetotal delay in fetching and processing contexts by 2.7-3.2x while havingnegligible impact on the LLM response quality in accuracy or perplexity.</description><author>Yuhan Liu, Hanchen Li, Yihua Cheng, Siddhant Ray, Yuyang Huang, Qizheng Zhang, Kuntai Du, Jiayi Yao, Shan Lu, Ganesh Ananthanarayanan, Michael Maire, Henry Hoffmann, Ari Holtzman, Junchen Jiang</author><pubDate>Thu, 14 Mar 2024 18:58:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07240v3</guid></item><item><title>CheckEval: Robust Evaluation Framework using Large Language Model via Checklist</title><link>http://arxiv.org/abs/2403.18771v1</link><description>We introduce CheckEval, a novel evaluation framework using Large LanguageModels, addressing the challenges of ambiguity and inconsistency in currentevaluation methods. CheckEval addresses these challenges by dividing evaluationcriteria into detailed sub-aspects and constructing a checklist of Booleanquestions for each, simplifying the evaluation. This approach not only rendersthe process more interpretable but also significantly enhances the robustnessand reliability of results by focusing on specific evaluation dimensions.Validated through a focused case study using the SummEval benchmark, CheckEvalindicates a strong correlation with human judgments. Furthermore, itdemonstrates a highly consistent Inter-Annotator Agreement. These findingshighlight the effectiveness of CheckEval for objective, flexible, and preciseevaluations. By offering a customizable and interactive framework, CheckEvalsets a new standard for the use of LLMs in evaluation, responding to theevolving needs of the field and establishing a clear method for futureLLM-based evaluation.</description><author>Yukyung Lee, Joonghoon Kim, Jaehee Kim, Hyowon Cho, Pilsung Kang</author><pubDate>Wed, 27 Mar 2024 18:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18771v1</guid></item><item><title>Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following</title><link>http://arxiv.org/abs/2311.17002v3</link><description>Existing text-to-image (T2I) diffusion models usually struggle ininterpreting complex prompts, especially those with quantity, object-attributebinding, and multi-subject descriptions. In this work, we introduce a semanticpanel as the middleware in decoding texts to images, supporting the generatorto better follow instructions. The panel is obtained through arranging thevisual concepts parsed from the input text by the aid of large language models,and then injected into the denoising network as a detailed control signal tocomplement the text condition. To facilitate text-to-panel learning, we come upwith a carefully designed semantic formatting protocol, accompanied by afully-automatic data preparation pipeline. Thanks to such a design, ourapproach, which we call Ranni, manages to enhance a pre-trained T2I generatorregarding its textual controllability. More importantly, the introduction ofthe generative middleware brings a more convenient form of interaction (i.e.,directly adjusting the elements in the panel or using language instructions)and further allows users to finely customize their generation, based on whichwe develop a practical system and showcase its potential in continuousgeneration and chatting-based editing. Our project page is athttps://ranni-t2i.github.io/Ranni.</description><author>Yutong Feng, Biao Gong, Di Chen, Yujun Shen, Yu Liu, Jingren Zhou</author><pubDate>Tue, 09 Apr 2024 08:46:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17002v3</guid></item><item><title>Evaluating Task-oriented Dialogue Systems: A Systematic Review of Measures, Constructs and their Operationalisations</title><link>http://arxiv.org/abs/2312.13871v2</link><description>This review gives an extensive overview of evaluation methods fortask-oriented dialogue systems, paying special attention to practicalapplications of dialogue systems, for example for customer service. The review(1) provides an overview of the used constructs and metrics in previous work,(2) discusses challenges in the context of dialogue system evaluation and (3)develops a research agenda for the future of dialogue system evaluation. Weconducted a systematic review of four databases (ACL, ACM, IEEE and Web ofScience), which after screening resulted in 122 studies. Those studies werecarefully analysed for the constructs and methods they proposed for evaluation.We found a wide variety in both constructs and methods. Especially theoperationalisation is not always clearly reported. Newer developmentsconcerning large language models are discussed in two contexts: to powerdialogue systems and to use in the evaluation process. We hope that future workwill take a more critical approach to the operationalisation and specificationof the used constructs. To work towards this aim, this review ends withrecommendations for evaluation and suggestions for outstanding questions.</description><author>Anouck Braggaar, Christine Liebrecht, Emiel van Miltenburg, Emiel Krahmer</author><pubDate>Mon, 08 Apr 2024 08:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13871v2</guid></item><item><title>Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement</title><link>http://arxiv.org/abs/2402.11060v1</link><description>The increasing demand for personalized interactions with large languagemodels (LLMs) calls for the development of methodologies capable of accuratelyand efficiently identifying user opinions and preferences. Retrievalaugmentation emerges as an effective strategy, as it can accommodate a vastnumber of users without the costs from fine-tuning. Existing research, however,has largely focused on enhancing the retrieval stage and devoted limitedexploration toward optimizing the representation of the database, a crucialaspect for tasks such as personalization. In this work, we examine the problemfrom a novel angle, focusing on how data can be better represented for moreefficient retrieval in the context of LLM customization. To tackle thischallenge, we introduce Persona-DB, a simple yet effective framework consistingof a hierarchical construction process to improve generalization across taskcontexts and collaborative refinement to effectively bridge knowledge gapsamong users. In the task of response forecasting, Persona-DB demonstratessuperior efficiency in maintaining accuracy with a significantly reducedretrieval size, a critical advantage in scenarios with extensive histories orlimited context windows. Our experiments also indicate a marked improvement ofover 15% under cold-start scenarios, when users have extremely sparse data.Furthermore, our analysis reveals the increasing importance of collaborativeknowledge as the retrieval capacity expands.</description><author>Chenkai Sun, Ke Yang, Revanth Gangi Reddy, Yi R. Fung, Hou Pong Chan, ChengXiang Zhai, Heng Ji</author><pubDate>Fri, 16 Feb 2024 20:20:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11060v1</guid></item><item><title>adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource Languages with Integrated LLM Playgrounds</title><link>http://arxiv.org/abs/2403.02370v1</link><description>The advent of Multilingual Language Models (MLLMs) and Large Language Modelshas spawned innovation in many areas of natural language processing. Despitethe exciting potential of this technology, its impact on developinghigh-quality Machine Translation (MT) outputs for low-resource languagesremains relatively under-explored. Furthermore, an open-source application,dedicated to both fine-tuning MLLMs and managing the complete MT workflow forlow-resources languages, remains unavailable. We aim to address theseimbalances through the development of adaptMLLM, which streamlines allprocesses involved in the fine-tuning of MLLMs for MT. This open-sourceapplication is tailored for developers, translators, and users who are engagedin MT. An intuitive interface allows for easy customisation of hyperparameters,and the application offers a range of metrics for model evaluation and thecapability to deploy models as a translation service directly within theapplication. As a multilingual tool, we used adaptMLLM to fine-tune models fortwo low-resource language pairs: English to Irish (EN$\leftrightarrow$GA) andEnglish to Marathi (EN$\leftrightarrow$MR). Compared with baselines from theLoResMT2021 Shared Task, the adaptMLLM system demonstrated significantimprovements. In the EN$\rightarrow$GA direction, an improvement of 5.2 BLEUpoints was observed and an increase of 40.5 BLEU points was recorded in theGA$\rightarrow$EN direction. Significant improvements in the translationperformance of the EN$\leftrightarrow$MR pair were also observed notably in theMR$\rightarrow$EN direction with an increase of 21.3 BLEU points. Finally, afine-grained human evaluation of the MLLM output on the EN$\rightarrow$GA pairwas conducted using the Multidimensional Quality Metrics and Scalar QualityMetrics error taxonomies. The application and models are freely available.</description><author>Séamus Lankford, Haithem Afli, Andy Way</author><pubDate>Mon, 04 Mar 2024 14:49:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02370v1</guid></item><item><title>Generating consistent PDDL domains with Large Language Models</title><link>http://arxiv.org/abs/2404.07751v1</link><description>Large Language Models (LLMs) are capable of transforming natural languagedomain descriptions into plausibly looking PDDL markup. However, ensuring thatactions are consistent within domains still remains a challenging task. In thispaper we present a novel concept to significantly improve the quality ofLLM-generated PDDL models by performing automated consistency checking duringthe generation process. Although the proposed consistency checking strategiesstill can't guarantee absolute correctness of generated models, they can serveas valuable source of feedback reducing the amount of correction effortsexpected from a human in the loop. We demonstrate the capabilities of our errordetection approach on a number of classical and custom planning domains(logistics, gripper, tyreworld, household, pizza).</description><author>Pavel Smirnov, Frank Joublin, Antonello Ceravola, Michael Gienger</author><pubDate>Thu, 11 Apr 2024 14:48:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07751v1</guid></item><item><title>Training-Free Unsupervised Prompt for Vision-Language Models</title><link>http://arxiv.org/abs/2404.16339v1</link><description>Prompt learning has become the most effective paradigm for adapting largepre-trained vision-language models (VLMs) to downstream tasks. Recently,unsupervised prompt tuning methods, such as UPL and POUF, directly leveragepseudo-labels as supervisory information to fine-tune additional adaptationmodules on unlabeled data. However, inaccurate pseudo labels easily misguidethe tuning process and result in poor representation capabilities. In light ofthis, we propose Training-Free Unsupervised Prompts (TFUP), which maximallypreserves the inherent representation capabilities and enhances them with aresidual connection to similarity-based prediction probabilities in atraining-free and labeling-free manner. Specifically, we integrate bothinstance confidence and prototype scores to select representative samples,which are used to customize a reliable Feature Cache Model (FCM) fortraining-free inference. Then, we design a Multi-level Similarity Measure (MSM)that considers both feature-level and semantic-level similarities to calculatethe distance between each test image and the cached sample as the weight of thecorresponding cached label to generate similarity-based predictionprobabilities. In this way, TFUP achieves surprising performance, evensurpassing the training-base method on multiple classification datasets. Basedon our TFUP, we propose a training-based approach (TFUP-T) to further boost theadaptation performance. In addition to the standard cross-entropy loss, TFUP-Tadopts an additional marginal distribution entropy loss to constrain the modelfrom a global perspective. Our TFUP-T achieves new state-of-the-artclassification performance compared to unsupervised and few-shot adaptationapproaches on multiple benchmarks. In particular, TFUP-T improves theclassification accuracy of POUF by 3.3% on the most challenging Domain-Netdataset.</description><author>Sifan Long, Linbin Wang, Zhen Zhao, Zichang Tan, Yiming Wu, Shengsheng Wang, Jingdong Wang</author><pubDate>Thu, 25 Apr 2024 06:07:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.16339v1</guid></item><item><title>Scalable Model Editing via Customized Expert Networks</title><link>http://arxiv.org/abs/2404.02699v1</link><description>Addressing the issue of hallucinations and outdated knowledge in largelanguage models is critical for their reliable application. Model Editingpresents a promising avenue for mitigating these challenges in a cost-effectivemanner. However, existing methods often suffer from unsatisfactorygeneralization and unintended effects on unrelated samples. To overcome theselimitations, we introduce a novel approach: Scalable Model Editing viaCustomized Expert Networks (SCEN), which is a two-stage continuous trainingparadigm. Specifically, in the first stage, we train lightweight expertnetworks individually for each piece of knowledge that needs to be updated.Subsequently, we train a corresponding neuron for each expert to control theactivation state of that expert. Our experiments on two different sizes ofopen-source large language models, the Llama2 7B and 13B, achievestate-of-the-art results compared to existing mainstream Model Editing methods.Our code is available at https: //github.com/TAL-auroraX/SCEN</description><author>Zihan Yao, Yu He, Tianyu Qi, Ming Li</author><pubDate>Wed, 03 Apr 2024 13:57:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02699v1</guid></item><item><title>CameraCtrl: Enabling Camera Control for Text-to-Video Generation</title><link>http://arxiv.org/abs/2404.02101v1</link><description>Controllability plays a crucial role in video generation since it allowsusers to create desired content. However, existing models largely overlookedthe precise control of camera pose that serves as a cinematic language toexpress deeper narrative nuances. To alleviate this issue, we introduceCameraCtrl, enabling accurate camera pose control for text-to-video(T2V)models. After precisely parameterizing the camera trajectory, a plug-and-playcamera module is then trained on a T2V model, leaving others untouched.Additionally, a comprehensive study on the effect of various datasets is alsoconducted, suggesting that videos with diverse camera distribution and similarappearances indeed enhance controllability and generalization. Experimentalresults demonstrate the effectiveness of CameraCtrl in achieving precise anddomain-adaptive camera control, marking a step forward in the pursuit ofdynamic and customized video storytelling from textual and camera pose inputs.Our project website is at: https://hehao13.github.io/projects-CameraCtrl/.</description><author>Hao He, Yinghao Xu, Yuwei Guo, Gordon Wetzstein, Bo Dai, Hongsheng Li, Ceyuan Yang</author><pubDate>Tue, 02 Apr 2024 17:52:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02101v1</guid></item><item><title>RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models</title><link>http://arxiv.org/abs/2310.00746v2</link><description>The advent of Large Language Models (LLMs) has paved the way for complextasks such as role-playing, which enhances user interactions by enabling modelsto imitate various characters. However, the closed-source nature ofstate-of-the-art LLMs and their general-purpose training limit role-playingoptimization. In this paper, we introduce RoleLLM, a framework to benchmark,elicit, and enhance role-playing abilities in LLMs. RoleLLM comprises fourstages: (1) Role Profile Construction for 100 roles; (2) Context-BasedInstruction Generation (Context-Instruct) for role-specific knowledgeextraction; (3) Role Prompting using GPT (RoleGPT) for speaking styleimitation; and (4) Role-Conditioned Instruction Tuning (RoCIT) for fine-tuningopen-source models along with role customization. By Context-Instruct andRoleGPT, we create RoleBench, the first systematic and fine-grainedcharacter-level benchmark dataset for role-playing with 168,093 samples.Moreover, RoCIT on RoleBench yields RoleLLaMA (English) and RoleGLM (Chinese),significantly enhancing role-playing abilities and even achieving comparableresults with RoleGPT (using GPT-4).</description><author>Zekun Moore Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Jian Yang, Man Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, Stephen W. Huang, Jie Fu, Junran Peng</author><pubDate>Wed, 24 Apr 2024 08:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00746v2</guid></item></channel></rss>