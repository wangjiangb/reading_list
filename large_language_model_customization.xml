<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivlarge language model customization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 18 Jul 2024 13:00:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v3</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Wed, 10 Jul 2024 11:33:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v3</guid></item><item><title>Review-LLM: Harnessing Large Language Models for Personalized Review Generation</title><link>http://arxiv.org/abs/2407.07487v1</link><description>Product review generation is an important task in recommender systems, whichcould provide explanation and persuasiveness for the recommendation. Recently,Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modelingand generating ability, which could be applied in review generation. However,directly applying the LLMs for generating reviews might be troubled by the``polite'' phenomenon of the LLMs and could not generate personalized reviews(e.g., negative reviews). In this paper, we propose Review-LLM that customizesLLMs for personalized review generation. Firstly, we construct the prompt inputby aggregating user historical behaviors, which include corresponding itemtitles and reviews. This enables the LLMs to capture user interest features andreview writing style. Secondly, we incorporate ratings as indicators ofsatisfaction into the prompt, which could further improve the model'sunderstanding of user preferences and the sentiment tendency control ofgenerated reviews. Finally, we feed the prompt text into LLMs, and useSupervised Fine-Tuning (SFT) to make the model generate personalized reviewsfor the given user and target item. Experimental results on the real-worlddataset show that our fine-tuned model could achieve better review generationperformance than existing close-source LLMs.</description><author>Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang</author><pubDate>Wed, 10 Jul 2024 09:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07487v1</guid></item><item><title>PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games</title><link>http://arxiv.org/abs/2404.19721v3</link><description>This research introduces Procedural Artificial Narrative using Generative AI(PANGeA), a structured approach for leveraging large language models (LLMs),guided by a game designer's high-level criteria, to generate narrative contentfor turn-based role-playing video games (RPGs). Distinct from priorapplications of LLMs used for video game design, PANGeA innovates by not onlygenerating game level data (which includes, but is not limited to, setting, keyitems, and non-playable characters (NPCs)), but by also fostering dynamic,free-form interactions between the player and the environment that align withthe procedural game narrative. The NPCs generated by PANGeA arepersonality-biased and express traits from the Big 5 Personality Model in theirgenerated responses. PANGeA addresses challenges behind ingesting free-formtext input, which can prompt LLM responses beyond the scope of the gamenarrative. A novel validation system that uses the LLM's intelligence evaluatestext input and aligns generated responses with the unfolding narrative. Makingthese interactions possible, PANGeA is supported by a server that hosts acustom memory system that supplies context for augmenting generated responsesthus aligning them with the procedural narrative. For its broad application,the server has a REST interface enabling any game engine to integrate directlywith PANGeA, as well as an LLM interface adaptable with local or private LLMs.PANGeA's ability to foster dynamic narrative generation by aligning responseswith the procedural narrative is demonstrated through an empirical study andablation test of two versions of a demo game. These are, a custom,browser-based GPT and a Unity demo. As the results show, PANGeA holds potentialto assist game designers in using LLMs to generate narrative-consistent contenteven when provided varied and unpredictable, free-form text input.</description><author>Steph Buongiorno, Lawrence Jake Klinkert, Tanishq Chawla, Zixin Zhuang, Corey Clark</author><pubDate>Tue, 09 Jul 2024 23:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19721v3</guid></item><item><title>FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding</title><link>http://arxiv.org/abs/2407.05183v2</link><description>Flowcharts are graphical tools for representing complex concepts in concisevisual representations. This paper introduces the FlowLearn dataset, a resourcetailored to enhance the understanding of flowcharts. FlowLearn contains complexscientific flowcharts and simulated flowcharts. The scientific subset contains3,858 flowcharts sourced from scientific literature and the simulated subsetcontains 10,000 flowcharts created using a customizable script. The dataset isenriched with annotations for visual components, OCR, Mermaid coderepresentation, and VQA question-answer pairs. Despite the proven capabilitiesof Large Vision-Language Models (LVLMs) in various visual understanding tasks,their effectiveness in decoding flowcharts - a crucial element of scientificcommunication - has yet to be thoroughly investigated. The FlowLearn test setis crafted to assess the performance of LVLMs in flowchart comprehension. Ourstudy thoroughly evaluates state-of-the-art LVLMs, identifying existinglimitations and establishing a foundation for future enhancements in thisrelatively underexplored domain. For instance, in tasks involving simulatedflowcharts, GPT-4V achieved the highest accuracy (58%) in counting the numberof nodes, while Claude recorded the highest accuracy (83%) in OCR tasks.Notably, no single model excels in all tasks within the FlowLearn framework,highlighting significant opportunities for further development.</description><author>Huitong Pan, Qi Zhang, Cornelia Caragea, Eduard Dragut, Longin Jan Latecki</author><pubDate>Tue, 09 Jul 2024 21:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05183v2</guid></item><item><title>FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3</title><link>http://arxiv.org/abs/2407.09467v1</link><description>In the diverse world of AI-driven storytelling, there is a unique opportunityto engage young audiences with customized, and personalized narratives. Thispaper introduces FairyLandAI an innovative Large Language Model (LLM) developedthrough OpenAI's API, specifically crafted to create personalized fairytalesfor children. The distinctive feature of FairyLandAI is its dual capability: itnot only generates stories that are engaging, age-appropriate, and reflectiveof various traditions but also autonomously produces imaginative promptssuitable for advanced image generation tools like GenAI and Dalle-3, therebyenriching the storytelling experience. FairyLandAI is expertly tailored toresonate with the imaginative worlds of children, providing narratives that areboth educational and entertaining and in alignment with the moral valuesinherent in different ages. Its unique strength lies in customizing stories tomatch individual children's preferences and cultural backgrounds, heralding anew era in personalized storytelling. Further, its integration with imagegeneration technology offers a comprehensive narrative experience thatstimulates both verbal and visual creativity. Empirical evaluations ofFairyLandAI demonstrate its effectiveness in crafting captivating stories forchildren, which not only entertain but also embody the values and teachings ofdiverse traditions. This model serves as an invaluable tool for parents andeducators, supporting them in imparting meaningful moral lessons throughengaging narratives. FairyLandAI represents a pioneering step in using LLMs,particularly through OpenAI's API, for educational and cultural enrichment,making complex moral narratives accessible and enjoyable for young, imaginativeminds.</description><author>Georgios Makridis, Athanasios Oikonomou, Vasileios Koukos</author><pubDate>Fri, 12 Jul 2024 17:46:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09467v1</guid></item><item><title>Inference Optimization of Foundation Models on AI Accelerators</title><link>http://arxiv.org/abs/2407.09111v1</link><description>Powerful foundation models, including large language models (LLMs), withTransformer architectures have ushered in a new era of Generative AI acrossvarious industries. Industry and research community have witnessed a largenumber of new applications, based on those foundation models. Such applicationsinclude question and answer, customer services, image and video generation, andcode completions, among others. However, as the number of model parametersreaches to hundreds of billions, their deployment incurs prohibitive inferencecosts and high latency in real-world scenarios. As a result, the demand forcost-effective and fast inference using AI accelerators is ever more higher. Tothis end, our tutorial offers a comprehensive discussion on complementaryinference optimization techniques using AI accelerators. Beginning with anoverview of basic Transformer architectures and deep learning systemframeworks, we deep dive into system optimization techniques for fast andmemory-efficient attention computations and discuss how they can be implementedefficiently on AI accelerators. Next, we describe architectural elements thatare key for fast transformer inference. Finally, we examine various modelcompression and fast decoding strategies in the same context.</description><author>Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis</author><pubDate>Fri, 12 Jul 2024 09:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09111v1</guid></item><item><title>Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors</title><link>http://arxiv.org/abs/2407.09136v1</link><description>Large language models (LLMs) present an opportunity to scale high-qualitypersonalized education to all. A promising approach towards this means is tobuild dialog tutoring models that scaffold students' problem-solving. However,even though existing LLMs perform well in solving reasoning questions, theystruggle to precisely detect student's errors and tailor their feedback tothese errors. Inspired by real-world teaching practice where teachers identifystudent errors and customize their response based on them, we focus onverifying student solutions and show how grounding to such verificationimproves the overall quality of tutor response generation. We collect a datasetof 1K stepwise math reasoning chains with the first error step annotated byteachers. We show empirically that finding the mistake in a student solution ischallenging for current models. We propose and evaluate several verifiers fordetecting these errors. Using both automatic and human evaluation we show thatthe student solution verifiers steer the generation model towards highlytargeted responses to student errors which are more often correct with lesshallucinations compared to existing baselines.</description><author>Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan</author><pubDate>Fri, 12 Jul 2024 10:11:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09136v1</guid></item><item><title>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.14608v6</link><description>Large models represent a groundbreaking advancement in multiple applicationfields, enabling remarkable achievements across various tasks. However, theirunprecedented scale comes with significant computational costs. These models,often consisting of billions of parameters, require vast amounts ofcomputational resources for execution. Especially, the expansive scale andcomputational demands pose considerable challenges when customizing them forparticular downstream tasks, particularly over the hardware platformsconstrained by computational capabilities. Parameter Efficient Fine-Tuning(PEFT) provides a practical solution by efficiently adjusting the large modelsover the various downstream tasks. In particular, PEFT refers to the process ofadjusting the parameters of a pre-trained large models to adapt it to aspecific task or domain while minimizing the number of additional parametersintroduced or computational resources required. This approach is particularlyimportant when dealing with large-scale language models with high parametercounts, as fine-tuning these models from scratch can be computationallyexpensive and resource-intensive, posing considerable challenges in thesupporting system platform design. In this survey, we present comprehensivestudies of various PEFT algorithms, examining their performance andcomputational overhead. Moreover, we provide an overview of applicationsdeveloped using different PEFT algorithms and discuss common techniquesemployed to mitigate computation costs for PEFT. In addition to providing anextensive survey from an algorithmic standpoint, we also examine variousreal-world system designs to investigate the implementation costs associatedwith different PEFT approaches. This survey serves as an indispensable resourcefor researchers aiming to understand both the PEFT algorithm and its systemimplementation, offering detailed ......</description><author>Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang</author><pubDate>Fri, 12 Jul 2024 09:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14608v6</guid></item><item><title>Evaluating Nuanced Bias in Large Language Model Free Response Answers</title><link>http://arxiv.org/abs/2407.08842v1</link><description>Pre-trained large language models (LLMs) can now be easily adapted forspecific business purposes using custom prompts or fine tuning. Thesecustomizations are often iteratively re-engineered to improve some aspect ofperformance, but after each change businesses want to ensure that there hasbeen no negative impact on the system's behavior around such critical issues asbias. Prior methods of benchmarking bias use techniques such as word maskingand multiple choice questions to assess bias at scale, but these do not captureall of the nuanced types of bias that can occur in free response answers, thetypes of answers typically generated by LLM systems. In this paper, we identifyseveral kinds of nuanced bias in free text that cannot be similarly identifiedby multiple choice tests. We describe these as: confidence bias, implied bias,inclusion bias and erasure bias. We present a semi-automated pipeline fordetecting these types of bias by first eliminating answers that can beautomatically classified as unbiased and then co-evaluating name reversed pairsusing crowd workers. We believe that the nuanced classifications our methodgenerates can be used to give better feedback to LLMs, especially as LLMreasoning capabilities become more advanced.</description><author>Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Moumita Sinha</author><pubDate>Thu, 11 Jul 2024 19:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08842v1</guid></item><item><title>UrbanWorld: An Urban World Model for 3D City Generation</title><link>http://arxiv.org/abs/2407.11965v1</link><description>Cities, as the most fundamental environment of human life, encompass diversephysical elements such as buildings, roads and vegetation with complexinterconnection. Crafting realistic, interactive 3D urban environments plays acrucial role in constructing AI agents capable of perceiving, decision-making,and acting like humans in real-world environments. However, creatinghigh-fidelity 3D urban environments usually entails extensive manual labor fromdesigners, involving intricate detailing and accurate representation of complexurban features. Therefore, how to accomplish this in an automatical way remainsa longstanding challenge. Toward this problem, we propose UrbanWorld, the firstgenerative urban world model that can automatically create a customized,realistic and interactive 3D urban world with flexible control conditions.UrbanWorld incorporates four key stages in the automatical crafting pipeline:3D layout generation from openly accessible OSM data, urban scene planning anddesigning with a powerful urban multimodal large language model (Urban MLLM),controllable urban asset rendering with advanced 3D diffusion techniques, andfinally the MLLM-assisted scene refinement. The crafted high-fidelity 3D urbanenvironments enable realistic feedback and interactions for general AI andmachine perceptual systems in simulations. We are working on contributingUrbanWorld as an open-source and versatile platform for evaluating andimproving AI abilities in perception, decision-making, and interaction inrealistic urban environments.</description><author>Yu Shang, Jiansheng Chen, Hangyu Fan, Jingtao Ding, Jie Feng, Yong Li</author><pubDate>Tue, 16 Jul 2024 17:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11965v1</guid></item><item><title>How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models</title><link>http://arxiv.org/abs/2407.11549v1</link><description>Psychological evidence reveals the influence of personality traits ondecision-making. For instance, agreeableness is generally associated withpositive outcomes in negotiations, whereas neuroticism is often linked to lessfavorable outcomes. This paper introduces a simulation framework centered onLarge Language Model (LLM) agents endowed with synthesized personality traits.The agents negotiate within bargaining domains and possess customizablepersonalities and objectives. The experimental results show that the behavioraltendencies of LLM-based simulations could reproduce behavioral patternsobserved in human negotiations. The contribution is twofold. First, we proposea simulation methodology that investigates the alignment between the linguisticand economic capabilities of LLM agents. Secondly, we offer empirical insightsinto the strategic impact of Big-Five personality traits on the outcomes ofbilateral negotiations. We also provide a case study based on synthesizedbargaining dialogues to reveal intriguing behaviors, including deceitful andcompromising behaviors.</description><author>Yin Jou Huang, Rafik Hadfi</author><pubDate>Tue, 16 Jul 2024 09:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11549v1</guid></item><item><title>Beyond Mask: Rethinking Guidance Types in Few-shot Segmentation</title><link>http://arxiv.org/abs/2407.11503v1</link><description>Existing few-shot segmentation (FSS) methods mainly focus on prototypefeature generation and the query-support matching mechanism. As a crucialprompt for generating prototype features, the pair of image-mask types in thesupport set has become the default setting. However, various types such asimage, text, box, and mask all can provide valuable information regarding theobjects in context, class, localization, and shape appearance. Existing workfocuses on specific combinations of guidance, leading FSS into differentresearch branches. Rethinking guidance types in FSS is expected to explore theefficient joint representation of the coupling between the support set andquery set, giving rise to research trends in the weakly or strongly annotatedguidance to meet the customized requirements of practical users. In this work,we provide the generalized FSS with seven guidance paradigms and develop auniversal vision-language framework (UniFSS) to integrate prompts from text,mask, box, and image. Leveraging the advantages of large-scale pre-trainingvision-language models in textual and visual embeddings, UniFSS proposeshigh-level spatial correction and embedding interactive units to overcome thesemantic ambiguity drawbacks typically encountered by pure visual matchingmethods when facing intra-class appearance diversities. Extensive experimentsshow that UniFSS significantly outperforms the state-of-the-art methods.Notably, the weakly annotated class-aware box paradigm even surpasses thefinely annotated mask paradigm.</description><author>Shijie Chang, Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu</author><pubDate>Tue, 16 Jul 2024 08:41:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11503v1</guid></item><item><title>Pretraining Data and Tokenizer for Indic LLM</title><link>http://arxiv.org/abs/2407.12481v1</link><description>We present a novel approach to data preparation for developing multilingualIndic large language model. Our meticulous data acquisition spans open-sourceand proprietary sources, including Common Crawl, Indic books, news articles,and Wikipedia, ensuring a diverse and rich linguistic representation. For eachIndic language, we design a custom preprocessing pipeline to effectivelyeliminate redundant and low-quality text content. Additionally, we performdeduplication on Common Crawl data to address the redundancy present in 70% ofthe crawled web pages. This study focuses on developing high-quality data,optimizing tokenization for our multilingual dataset for Indic large languagemodels with 3B and 7B parameters, engineered for superior performance in Indiclanguages. We introduce a novel multilingual tokenizer training strategy,demonstrating our custom-trained Indic tokenizer outperforms thestate-of-the-art OpenAI Tiktoken tokenizer, achieving a superior token-to-wordratio for Indic languages.</description><author>Rahul Kumar, Shubham Kakde, Divyansh Rajput, Daud Ibrahim, Rishabh Nahata, Pidathala Sowjanya, Deepak Kumar</author><pubDate>Wed, 17 Jul 2024 11:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12481v1</guid></item></channel></rss>