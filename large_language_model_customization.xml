<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivlarge language model customization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 01 Aug 2024 13:00:21 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v3</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Wed, 10 Jul 2024 11:33:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v3</guid></item><item><title>Review-LLM: Harnessing Large Language Models for Personalized Review Generation</title><link>http://arxiv.org/abs/2407.07487v1</link><description>Product review generation is an important task in recommender systems, whichcould provide explanation and persuasiveness for the recommendation. Recently,Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modelingand generating ability, which could be applied in review generation. However,directly applying the LLMs for generating reviews might be troubled by the``polite'' phenomenon of the LLMs and could not generate personalized reviews(e.g., negative reviews). In this paper, we propose Review-LLM that customizesLLMs for personalized review generation. Firstly, we construct the prompt inputby aggregating user historical behaviors, which include corresponding itemtitles and reviews. This enables the LLMs to capture user interest features andreview writing style. Secondly, we incorporate ratings as indicators ofsatisfaction into the prompt, which could further improve the model'sunderstanding of user preferences and the sentiment tendency control ofgenerated reviews. Finally, we feed the prompt text into LLMs, and useSupervised Fine-Tuning (SFT) to make the model generate personalized reviewsfor the given user and target item. Experimental results on the real-worlddataset show that our fine-tuned model could achieve better review generationperformance than existing close-source LLMs.</description><author>Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang</author><pubDate>Wed, 10 Jul 2024 09:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07487v1</guid></item><item><title>PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games</title><link>http://arxiv.org/abs/2404.19721v3</link><description>This research introduces Procedural Artificial Narrative using Generative AI(PANGeA), a structured approach for leveraging large language models (LLMs),guided by a game designer's high-level criteria, to generate narrative contentfor turn-based role-playing video games (RPGs). Distinct from priorapplications of LLMs used for video game design, PANGeA innovates by not onlygenerating game level data (which includes, but is not limited to, setting, keyitems, and non-playable characters (NPCs)), but by also fostering dynamic,free-form interactions between the player and the environment that align withthe procedural game narrative. The NPCs generated by PANGeA arepersonality-biased and express traits from the Big 5 Personality Model in theirgenerated responses. PANGeA addresses challenges behind ingesting free-formtext input, which can prompt LLM responses beyond the scope of the gamenarrative. A novel validation system that uses the LLM's intelligence evaluatestext input and aligns generated responses with the unfolding narrative. Makingthese interactions possible, PANGeA is supported by a server that hosts acustom memory system that supplies context for augmenting generated responsesthus aligning them with the procedural narrative. For its broad application,the server has a REST interface enabling any game engine to integrate directlywith PANGeA, as well as an LLM interface adaptable with local or private LLMs.PANGeA's ability to foster dynamic narrative generation by aligning responseswith the procedural narrative is demonstrated through an empirical study andablation test of two versions of a demo game. These are, a custom,browser-based GPT and a Unity demo. As the results show, PANGeA holds potentialto assist game designers in using LLMs to generate narrative-consistent contenteven when provided varied and unpredictable, free-form text input.</description><author>Steph Buongiorno, Lawrence Jake Klinkert, Tanishq Chawla, Zixin Zhuang, Corey Clark</author><pubDate>Tue, 09 Jul 2024 23:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19721v3</guid></item><item><title>FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding</title><link>http://arxiv.org/abs/2407.05183v2</link><description>Flowcharts are graphical tools for representing complex concepts in concisevisual representations. This paper introduces the FlowLearn dataset, a resourcetailored to enhance the understanding of flowcharts. FlowLearn contains complexscientific flowcharts and simulated flowcharts. The scientific subset contains3,858 flowcharts sourced from scientific literature and the simulated subsetcontains 10,000 flowcharts created using a customizable script. The dataset isenriched with annotations for visual components, OCR, Mermaid coderepresentation, and VQA question-answer pairs. Despite the proven capabilitiesof Large Vision-Language Models (LVLMs) in various visual understanding tasks,their effectiveness in decoding flowcharts - a crucial element of scientificcommunication - has yet to be thoroughly investigated. The FlowLearn test setis crafted to assess the performance of LVLMs in flowchart comprehension. Ourstudy thoroughly evaluates state-of-the-art LVLMs, identifying existinglimitations and establishing a foundation for future enhancements in thisrelatively underexplored domain. For instance, in tasks involving simulatedflowcharts, GPT-4V achieved the highest accuracy (58%) in counting the numberof nodes, while Claude recorded the highest accuracy (83%) in OCR tasks.Notably, no single model excels in all tasks within the FlowLearn framework,highlighting significant opportunities for further development.</description><author>Huitong Pan, Qi Zhang, Cornelia Caragea, Eduard Dragut, Longin Jan Latecki</author><pubDate>Tue, 09 Jul 2024 21:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05183v2</guid></item><item><title>FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3</title><link>http://arxiv.org/abs/2407.09467v1</link><description>In the diverse world of AI-driven storytelling, there is a unique opportunityto engage young audiences with customized, and personalized narratives. Thispaper introduces FairyLandAI an innovative Large Language Model (LLM) developedthrough OpenAI's API, specifically crafted to create personalized fairytalesfor children. The distinctive feature of FairyLandAI is its dual capability: itnot only generates stories that are engaging, age-appropriate, and reflectiveof various traditions but also autonomously produces imaginative promptssuitable for advanced image generation tools like GenAI and Dalle-3, therebyenriching the storytelling experience. FairyLandAI is expertly tailored toresonate with the imaginative worlds of children, providing narratives that areboth educational and entertaining and in alignment with the moral valuesinherent in different ages. Its unique strength lies in customizing stories tomatch individual children's preferences and cultural backgrounds, heralding anew era in personalized storytelling. Further, its integration with imagegeneration technology offers a comprehensive narrative experience thatstimulates both verbal and visual creativity. Empirical evaluations ofFairyLandAI demonstrate its effectiveness in crafting captivating stories forchildren, which not only entertain but also embody the values and teachings ofdiverse traditions. This model serves as an invaluable tool for parents andeducators, supporting them in imparting meaningful moral lessons throughengaging narratives. FairyLandAI represents a pioneering step in using LLMs,particularly through OpenAI's API, for educational and cultural enrichment,making complex moral narratives accessible and enjoyable for young, imaginativeminds.</description><author>Georgios Makridis, Athanasios Oikonomou, Vasileios Koukos</author><pubDate>Fri, 12 Jul 2024 17:46:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09467v1</guid></item><item><title>Inference Optimization of Foundation Models on AI Accelerators</title><link>http://arxiv.org/abs/2407.09111v1</link><description>Powerful foundation models, including large language models (LLMs), withTransformer architectures have ushered in a new era of Generative AI acrossvarious industries. Industry and research community have witnessed a largenumber of new applications, based on those foundation models. Such applicationsinclude question and answer, customer services, image and video generation, andcode completions, among others. However, as the number of model parametersreaches to hundreds of billions, their deployment incurs prohibitive inferencecosts and high latency in real-world scenarios. As a result, the demand forcost-effective and fast inference using AI accelerators is ever more higher. Tothis end, our tutorial offers a comprehensive discussion on complementaryinference optimization techniques using AI accelerators. Beginning with anoverview of basic Transformer architectures and deep learning systemframeworks, we deep dive into system optimization techniques for fast andmemory-efficient attention computations and discuss how they can be implementedefficiently on AI accelerators. Next, we describe architectural elements thatare key for fast transformer inference. Finally, we examine various modelcompression and fast decoding strategies in the same context.</description><author>Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis</author><pubDate>Fri, 12 Jul 2024 09:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09111v1</guid></item><item><title>Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors</title><link>http://arxiv.org/abs/2407.09136v1</link><description>Large language models (LLMs) present an opportunity to scale high-qualitypersonalized education to all. A promising approach towards this means is tobuild dialog tutoring models that scaffold students' problem-solving. However,even though existing LLMs perform well in solving reasoning questions, theystruggle to precisely detect student's errors and tailor their feedback tothese errors. Inspired by real-world teaching practice where teachers identifystudent errors and customize their response based on them, we focus onverifying student solutions and show how grounding to such verificationimproves the overall quality of tutor response generation. We collect a datasetof 1K stepwise math reasoning chains with the first error step annotated byteachers. We show empirically that finding the mistake in a student solution ischallenging for current models. We propose and evaluate several verifiers fordetecting these errors. Using both automatic and human evaluation we show thatthe student solution verifiers steer the generation model towards highlytargeted responses to student errors which are more often correct with lesshallucinations compared to existing baselines.</description><author>Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan</author><pubDate>Fri, 12 Jul 2024 10:11:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09136v1</guid></item><item><title>Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.14608v6</link><description>Large models represent a groundbreaking advancement in multiple applicationfields, enabling remarkable achievements across various tasks. However, theirunprecedented scale comes with significant computational costs. These models,often consisting of billions of parameters, require vast amounts ofcomputational resources for execution. Especially, the expansive scale andcomputational demands pose considerable challenges when customizing them forparticular downstream tasks, particularly over the hardware platformsconstrained by computational capabilities. Parameter Efficient Fine-Tuning(PEFT) provides a practical solution by efficiently adjusting the large modelsover the various downstream tasks. In particular, PEFT refers to the process ofadjusting the parameters of a pre-trained large models to adapt it to aspecific task or domain while minimizing the number of additional parametersintroduced or computational resources required. This approach is particularlyimportant when dealing with large-scale language models with high parametercounts, as fine-tuning these models from scratch can be computationallyexpensive and resource-intensive, posing considerable challenges in thesupporting system platform design. In this survey, we present comprehensivestudies of various PEFT algorithms, examining their performance andcomputational overhead. Moreover, we provide an overview of applicationsdeveloped using different PEFT algorithms and discuss common techniquesemployed to mitigate computation costs for PEFT. In addition to providing anextensive survey from an algorithmic standpoint, we also examine variousreal-world system designs to investigate the implementation costs associatedwith different PEFT approaches. This survey serves as an indispensable resourcefor researchers aiming to understand both the PEFT algorithm and its systemimplementation, offering detailed ......</description><author>Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, Sai Qian Zhang</author><pubDate>Fri, 12 Jul 2024 09:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14608v6</guid></item><item><title>Evaluating Nuanced Bias in Large Language Model Free Response Answers</title><link>http://arxiv.org/abs/2407.08842v1</link><description>Pre-trained large language models (LLMs) can now be easily adapted forspecific business purposes using custom prompts or fine tuning. Thesecustomizations are often iteratively re-engineered to improve some aspect ofperformance, but after each change businesses want to ensure that there hasbeen no negative impact on the system's behavior around such critical issues asbias. Prior methods of benchmarking bias use techniques such as word maskingand multiple choice questions to assess bias at scale, but these do not captureall of the nuanced types of bias that can occur in free response answers, thetypes of answers typically generated by LLM systems. In this paper, we identifyseveral kinds of nuanced bias in free text that cannot be similarly identifiedby multiple choice tests. We describe these as: confidence bias, implied bias,inclusion bias and erasure bias. We present a semi-automated pipeline fordetecting these types of bias by first eliminating answers that can beautomatically classified as unbiased and then co-evaluating name reversed pairsusing crowd workers. We believe that the nuanced classifications our methodgenerates can be used to give better feedback to LLMs, especially as LLMreasoning capabilities become more advanced.</description><author>Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Moumita Sinha</author><pubDate>Thu, 11 Jul 2024 19:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08842v1</guid></item><item><title>UrbanWorld: An Urban World Model for 3D City Generation</title><link>http://arxiv.org/abs/2407.11965v1</link><description>Cities, as the most fundamental environment of human life, encompass diversephysical elements such as buildings, roads and vegetation with complexinterconnection. Crafting realistic, interactive 3D urban environments plays acrucial role in constructing AI agents capable of perceiving, decision-making,and acting like humans in real-world environments. However, creatinghigh-fidelity 3D urban environments usually entails extensive manual labor fromdesigners, involving intricate detailing and accurate representation of complexurban features. Therefore, how to accomplish this in an automatical way remainsa longstanding challenge. Toward this problem, we propose UrbanWorld, the firstgenerative urban world model that can automatically create a customized,realistic and interactive 3D urban world with flexible control conditions.UrbanWorld incorporates four key stages in the automatical crafting pipeline:3D layout generation from openly accessible OSM data, urban scene planning anddesigning with a powerful urban multimodal large language model (Urban MLLM),controllable urban asset rendering with advanced 3D diffusion techniques, andfinally the MLLM-assisted scene refinement. The crafted high-fidelity 3D urbanenvironments enable realistic feedback and interactions for general AI andmachine perceptual systems in simulations. We are working on contributingUrbanWorld as an open-source and versatile platform for evaluating andimproving AI abilities in perception, decision-making, and interaction inrealistic urban environments.</description><author>Yu Shang, Jiansheng Chen, Hangyu Fan, Jingtao Ding, Jie Feng, Yong Li</author><pubDate>Tue, 16 Jul 2024 17:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11965v1</guid></item><item><title>How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models</title><link>http://arxiv.org/abs/2407.11549v1</link><description>Psychological evidence reveals the influence of personality traits ondecision-making. For instance, agreeableness is generally associated withpositive outcomes in negotiations, whereas neuroticism is often linked to lessfavorable outcomes. This paper introduces a simulation framework centered onLarge Language Model (LLM) agents endowed with synthesized personality traits.The agents negotiate within bargaining domains and possess customizablepersonalities and objectives. The experimental results show that the behavioraltendencies of LLM-based simulations could reproduce behavioral patternsobserved in human negotiations. The contribution is twofold. First, we proposea simulation methodology that investigates the alignment between the linguisticand economic capabilities of LLM agents. Secondly, we offer empirical insightsinto the strategic impact of Big-Five personality traits on the outcomes ofbilateral negotiations. We also provide a case study based on synthesizedbargaining dialogues to reveal intriguing behaviors, including deceitful andcompromising behaviors.</description><author>Yin Jou Huang, Rafik Hadfi</author><pubDate>Tue, 16 Jul 2024 09:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11549v1</guid></item><item><title>Beyond Mask: Rethinking Guidance Types in Few-shot Segmentation</title><link>http://arxiv.org/abs/2407.11503v1</link><description>Existing few-shot segmentation (FSS) methods mainly focus on prototypefeature generation and the query-support matching mechanism. As a crucialprompt for generating prototype features, the pair of image-mask types in thesupport set has become the default setting. However, various types such asimage, text, box, and mask all can provide valuable information regarding theobjects in context, class, localization, and shape appearance. Existing workfocuses on specific combinations of guidance, leading FSS into differentresearch branches. Rethinking guidance types in FSS is expected to explore theefficient joint representation of the coupling between the support set andquery set, giving rise to research trends in the weakly or strongly annotatedguidance to meet the customized requirements of practical users. In this work,we provide the generalized FSS with seven guidance paradigms and develop auniversal vision-language framework (UniFSS) to integrate prompts from text,mask, box, and image. Leveraging the advantages of large-scale pre-trainingvision-language models in textual and visual embeddings, UniFSS proposeshigh-level spatial correction and embedding interactive units to overcome thesemantic ambiguity drawbacks typically encountered by pure visual matchingmethods when facing intra-class appearance diversities. Extensive experimentsshow that UniFSS significantly outperforms the state-of-the-art methods.Notably, the weakly annotated class-aware box paradigm even surpasses thefinely annotated mask paradigm.</description><author>Shijie Chang, Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu</author><pubDate>Tue, 16 Jul 2024 08:41:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11503v1</guid></item><item><title>Pretraining Data and Tokenizer for Indic LLM</title><link>http://arxiv.org/abs/2407.12481v1</link><description>We present a novel approach to data preparation for developing multilingualIndic large language model. Our meticulous data acquisition spans open-sourceand proprietary sources, including Common Crawl, Indic books, news articles,and Wikipedia, ensuring a diverse and rich linguistic representation. For eachIndic language, we design a custom preprocessing pipeline to effectivelyeliminate redundant and low-quality text content. Additionally, we performdeduplication on Common Crawl data to address the redundancy present in 70% ofthe crawled web pages. This study focuses on developing high-quality data,optimizing tokenization for our multilingual dataset for Indic large languagemodels with 3B and 7B parameters, engineered for superior performance in Indiclanguages. We introduce a novel multilingual tokenizer training strategy,demonstrating our custom-trained Indic tokenizer outperforms thestate-of-the-art OpenAI Tiktoken tokenizer, achieving a superior token-to-wordratio for Indic languages.</description><author>Rahul Kumar, Shubham Kakde, Divyansh Rajput, Daud Ibrahim, Rishabh Nahata, Pidathala Sowjanya, Deepak Kumar</author><pubDate>Wed, 17 Jul 2024 11:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12481v1</guid></item><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v4</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Wed, 17 Jul 2024 07:26:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v4</guid></item><item><title>Building Intelligence Identification System via Large Language Model Watermarking: A Survey and Beyond</title><link>http://arxiv.org/abs/2407.11100v2</link><description>Large Language Models (LLMs) are increasingly integrated into diverseindustries, posing substantial security risks due to unauthorized replicationand misuse. To mitigate these concerns, robust identification mechanisms arewidely acknowledged as an effective strategy. Identification systems for LLMsnow rely heavily on watermarking technology to manage and protect intellectualproperty and ensure data security. However, previous studies have primarilyconcentrated on the basic principles of algorithms and lacked a comprehensiveanalysis of watermarking theory and practice from the perspective ofintelligent identification. To bridge this gap, firstly, we explore how arobust identity recognition system can be effectively implemented and managedwithin LLMs by various participants using watermarking technology. Secondly, wepropose a mathematical framework based on mutual information theory, whichsystematizes the identification process to achieve more precise and customizedwatermarking. Additionally, we present a comprehensive evaluation ofperformance metrics for LLM watermarking, reflecting participant preferencesand advancing discussions on its identification applications. Lastly, weoutline the existing challenges in current watermarking technologies andtheoretical frameworks, and provide directional guidance to address thesechallenges. Our systematic classification and detailed exposition aim toenhance the comparison and evaluation of various methods, fostering furtherresearch and development toward a transparent, secure, and equitable LLMecosystem.</description><author>Xuhong Wang, Haoyu Jiang, Yi Yu, Jingru Yu, Yilun Lin, Ping Yi, Yingchun Wang, Qiao Yu, Li Li, Fei-Yue Wang</author><pubDate>Wed, 17 Jul 2024 03:08:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11100v2</guid></item><item><title>On Pre-training of Multimodal Language Models Customized for Chart Understanding</title><link>http://arxiv.org/abs/2407.14506v1</link><description>Recent studies customizing Multimodal Large Language Models (MLLMs) fordomain-specific tasks have yielded promising results, especially in the fieldof scientific chart comprehension. These studies generally utilize visualinstruction tuning with specialized datasets to enhance question and answer(QA) accuracy within the chart domain. However, they often neglect thefundamental discrepancy between natural image-caption pre-training data anddigital chart image-QA data, particularly in the models' capacity to extractunderlying numeric values from charts. This paper tackles this oversight byexploring the training processes necessary to improve MLLMs' comprehension ofcharts. We present three key findings: (1) Incorporating raw data values inalignment pre-training markedly improves comprehension of chart data. (2)Replacing images with their textual representation randomly during end-to-endfine-tuning transfer the language reasoning capability to chart interpretationskills. (3) Requiring the model to first extract the underlying chart data andthen answer the question in the fine-tuning can further improve the accuracy.Consequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chartcomprehension. CHOPINLLM effectively interprets various types of charts,including unannotated ones, while maintaining robust reasoning abilities.Furthermore, we establish a new benchmark to evaluate MLLMs' understanding ofdifferent chart types across various comprehension levels. Experimental resultsshow that CHOPINLLM exhibits strong performance in understanding both annotatedand unannotated charts across a wide range of types.</description><author>Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Lu Yuan, Leonid Sigal</author><pubDate>Fri, 19 Jul 2024 17:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14506v1</guid></item><item><title>The Art of Refusal: A Survey of Abstention in Large Language Models</title><link>http://arxiv.org/abs/2407.18418v1</link><description>Abstention, the refusal of large language models (LLMs) to provide an answer,is increasingly recognized for its potential to mitigate hallucinations andenhance safety in building LLM systems. In this survey, we introduce aframework to examine abstention behavior from three perspectives: the query,the model, and human values. We review the literature on abstention methods(categorized based on the development stages of LLMs), benchmarks, andevaluation metrics, and discuss the merits and limitations of prior work. Wefurther identify and motivate areas for future research, such as encouragingthe study of abstention as a meta-capability across tasks and customizingabstention abilities based on context. In doing so, we aim to broaden the scopeand impact of abstention methodologies in AI systems.</description><author>Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, Lucy Lu Wang</author><pubDate>Thu, 25 Jul 2024 22:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18418v1</guid></item><item><title>RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent</title><link>http://arxiv.org/abs/2407.16667v1</link><description>Recently, advanced Large Language Models (LLMs) such as GPT-4 have beenintegrated into many real-world applications like Code Copilot. Theseapplications have significantly expanded the attack surface of LLMs, exposingthem to a variety of threats. Among them, jailbreak attacks that induce toxicresponses through jailbreak prompts have raised critical safety concerns. Toidentify these threats, a growing number of red teaming approaches simulatepotential adversarial scenarios by crafting jailbreak prompts to test thetarget LLM. However, existing red teaming methods do not consider the uniquevulnerabilities of LLM in different scenarios, making it difficult to adjustthe jailbreak prompts to find context-specific vulnerabilities. Meanwhile,these methods are limited to refining jailbreak templates using a few mutationoperations, lacking the automation and scalability to adapt to differentscenarios. To enable context-aware and efficient red teaming, we abstract andmodel existing attacks into a coherent concept called "jailbreak strategy" andpropose a multi-agent LLM system named RedAgent that leverages these strategiesto generate context-aware jailbreak prompts. By self-reflecting on contextualfeedback in an additional memory buffer, RedAgent continuously learns how toleverage these strategies to achieve effective jailbreaks in specific contexts.Extensive experiments demonstrate that our system can jailbreak most black-boxLLMs in just five queries, improving the efficiency of existing red teamingmethods by two times. Additionally, RedAgent can jailbreak customized LLMapplications more efficiently. By generating context-aware jailbreak promptstowards applications on GPTs, we discover 60 severe vulnerabilities of thesereal-world applications with only two queries per vulnerability. We havereported all found issues and communicated with OpenAI and Meta for bug fixes.</description><author>Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren</author><pubDate>Tue, 23 Jul 2024 17:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16667v1</guid></item><item><title>ITINERA: Integrating Spatial Optimization with Large Language Models for Open-domain Urban Itinerary Planning</title><link>http://arxiv.org/abs/2402.07204v3</link><description>Citywalk, a recently popular form of urban travel, requires genuinepersonalization and understanding of fine-grained requests compared totraditional itinerary planning. In this paper, we introduce the novel task ofOpen-domain Urban Itinerary Planning (OUIP), which generates personalized urbanitineraries from user requests in natural language. We then present ITINERA, anOUIP system that integrates spatial optimization with large language models toprovide customized urban itineraries based on user needs. This involvesdecomposing user requests, selecting candidate points of interest (POIs),ordering the POIs based on cluster-aware spatial optimization, and generatingthe itinerary. Experiments on real-world datasets and the performance of thedeployed system demonstrate our system's capacity to deliver personalized andspatially coherent itineraries compared to current solutions.</description><author>Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Zhaofeng Wu, Dingyi Zhuang, Jushi Kai, Kebing Hou, Xiaotong Guo, Jinhua Zhao, Zhan Zhao, Wei Ma</author><pubDate>Tue, 23 Jul 2024 11:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07204v3</guid></item><item><title>LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation</title><link>http://arxiv.org/abs/2407.12126v2</link><description>Machine translation is indispensable in healthcare for enabling the globaldissemination of medical knowledge across languages. However, complex medicalterminology poses unique challenges to achieving adequate translation qualityand accuracy. This study introduces a novel "LLMs-in-the-loop" approach todevelop supervised neural machine translation models optimized specifically formedical texts. While large language models (LLMs) have demonstrated powerfulcapabilities, this research shows that small, specialized models trained onhigh-quality in-domain (mostly synthetic) data can outperform even vastlylarger LLMs. Custom parallel corpora in six languages were compiled from scientificarticles, synthetically generated clinical documents, and medical texts. OurLLMs-in-the-loop methodology employs synthetic data generation, rigorousevaluation, and agent orchestration to enhance performance. We developed smallmedical translation models using the MarianMT base model. We introduce a newmedical translation test dataset to standardize evaluation in this domain.Assessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, ourMarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo. Results demonstrate that our LLMs-in-the-loop approach, combined withfine-tuning high-quality, domain-specific data, enables specialized models tooutperform general-purpose and some larger systems. This research, part of abroader series on expert small models, paves the way for futurehealthcare-related AI developments, including deidentification and bio-medicalentity extraction models. Our study underscores the potential of tailoredneural translation models and the LLMs-in-the-loop methodology to advance thefield through improved data generation, evaluation, agent, and modelingtechniques.</description><author>Bunyamin Keles, Murat Gunay, Serdar I. Caglar</author><pubDate>Fri, 26 Jul 2024 12:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12126v2</guid></item><item><title>Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains</title><link>http://arxiv.org/abs/2402.05140v3</link><description>Large Language Models (LLMs) have demonstrated remarkable proficiency inunderstanding and generating natural language. However, their capabilities wanein highly specialized domains underrepresented in the pretraining corpus, suchas physical and biomedical sciences. This work explores how to repurposegeneral LLMs into effective task solvers for specialized domains. We introducea novel, model-agnostic framework for learning custom input tags, which areparameterized as continuous vectors appended to the LLM's embedding layer, tocondition the LLM. We design two types of input tags: domain tags are used todelimit specialized representations (e.g., chemical formulas) and providedomain-relevant context; function tags are used to represent specific functions(e.g., predicting molecular properties) and compress function-solvinginstructions. We develop a three-stage protocol to learn these tags usingauxiliary data and domain knowledge. By explicitly disentangling task domainsfrom task functions, our method enables zero-shot generalization to unseenproblems through diverse combinations of the input tags. It also boosts LLM'sperformance in various specialized domains, such as predicting protein orchemical properties and modeling drug-target interactions, outperforming expertmodels tailored to these tasks.</description><author>Junhong Shen, Neil Tenenholtz, James Brian Hall, David Alvarez-Melis, Nicolo Fusi</author><pubDate>Fri, 26 Jul 2024 01:28:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05140v3</guid></item><item><title>AnyHome: Open-Vocabulary Generation of Structured and Textured 3D Homes</title><link>http://arxiv.org/abs/2312.06644v3</link><description>Inspired by cognitive theories, we introduce AnyHome, a framework thattranslates any text into well-structured and textured indoor scenes at ahouse-scale. By prompting Large Language Models (LLMs) with designed templates,our approach converts provided textual narratives into amodal structuredrepresentations. These representations guarantee consistent and realisticspatial layouts by directing the synthesis of a geometry mesh within definedconstraints. A Score Distillation Sampling process is then employed to refinethe geometry, followed by an egocentric inpainting process that adds lifeliketextures to it. AnyHome stands out with its editability, customizability,diversity, and realism. The structured representations for scenes allow forextensive editing at varying levels of granularity. Capable of interpretingtexts ranging from simple labels to detailed narratives, AnyHome generatesdetailed geometries and textures that outperform existing methods in bothquantitative and qualitative measures.</description><author>Rao Fu, Zehao Wen, Zichen Liu, Srinath Sridhar</author><pubDate>Mon, 29 Jul 2024 00:09:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06644v3</guid></item><item><title>SOWA: Adapting Hierarchical Frozen Window Self-Attention to Visual-Language Models for Better Anomaly Detection</title><link>http://arxiv.org/abs/2407.03634v2</link><description>Visual anomaly detection is critical in industrial manufacturing, buttraditional methods often rely on extensive normal datasets and custom models,limiting scalability. Recent advancements in large-scale visual-language modelshave significantly improved zero/few-shot anomaly detection. However, theseapproaches may not fully utilize hierarchical features, potentially missingnuanced details. We introduce a window self-attention mechanism based on theCLIP model, combined with learnable prompts to process multi-level featureswithin a Soldier-Offier Window self-Attention (SOWA) framework. Our method hasbeen tested on five benchmark datasets, demonstrating superior performance byleading in 18 out of 20 metrics compared to existing state-of-the-arttechniques.</description><author>Zongxiang Hu, Zhaosheng Zhang</author><pubDate>Tue, 30 Jul 2024 11:02:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03634v2</guid></item><item><title>Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming</title><link>http://arxiv.org/abs/2407.20712v1</link><description>End-user development allows everyday users to tailor service robots orapplications to their needs. One user-friendly approach is natural languageprogramming. However, it encounters challenges such as an expansive userexpression space and limited support for debugging and editing, which restrictits application in end-user programming. The emergence of large language models(LLMs) offers promising avenues for the translation and interpretation betweenhuman language instructions and the code executed by robots, but theirapplication in end-user programming systems requires further study. Weintroduce Cocobo, a natural language programming system with interactivediagrams powered by LLMs. Cocobo employs LLMs to understand users' authoringintentions, generate and explain robot programs, and facilitate the conversionbetween executable code and flowchart representations. Our user study showsthat Cocobo has a low learning curve, enabling even users with zero codingexperience to customize robot programs successfully.</description><author>Yate Ge, Yi Dai, Run Shan, Kechun Li, Yuanda Hu, Xiaohua Sun</author><pubDate>Tue, 30 Jul 2024 10:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20712v1</guid></item><item><title>Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language</title><link>http://arxiv.org/abs/2407.20513v1</link><description>This paper presents a conversational pipeline for crafting domain knowledgefor complex neuro-symbolic models through natural language prompts. Itleverages large language models to generate declarative programs in theDomiKnowS framework. The programs in this framework express concepts and theirrelationships as a graph in addition to logical constraints between them. Thegraph, later, can be connected to trainable neural models according to thosespecifications. Our proposed pipeline utilizes techniques like dynamicin-context demonstration retrieval, model refinement based on feedback from asymbolic parser, visualization, and user interaction to generate the tasks'structure and formal knowledge representation. This approach empowers domainexperts, even those not well-versed in ML/AI, to formally declare theirknowledge to be incorporated in customized neural models in the DomiKnowSframework.</description><author>Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi</author><pubDate>Tue, 30 Jul 2024 03:10:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20513v1</guid></item><item><title>CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment</title><link>http://arxiv.org/abs/2407.21553v1</link><description>This paper presents the Customer Experience (CX) Simulator, a novel frameworkdesigned to assess the effects of untested web-marketing campaigns through userbehavior simulations. The proposed framework leverages large language models(LLMs) to represent various events in a user's behavioral history, such asviewing an item, applying a coupon, or purchasing an item, as semanticembedding vectors. We train a model to predict transitions between events fromtheir LLM embeddings, which can even generalize to unseen events by learningfrom diverse training data. In web-marketing applications, we leverage thistransition prediction model to simulate how users might react differently whennew campaigns or products are presented to them. This allows us to eliminatethe need for costly online testing and enhance the marketers' abilities toreveal insights. Our numerical evaluation and user study, utilizing BigQueryPublic Datasets from the Google Merchandise Store, demonstrate theeffectiveness of our framework.</description><author>Akira Kasuga, Ryo Yonetani</author><pubDate>Wed, 31 Jul 2024 12:22:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21553v1</guid></item><item><title>Building AI Agents for Autonomous Clouds: Challenges and Design Principles</title><link>http://arxiv.org/abs/2407.12165v2</link><description>The rapid growth in the use of Large Language Models (LLMs) and AI Agents aspart of software development and deployment is revolutionizing the informationtechnology landscape. While code generation receives significant attention, ahigher-impact application lies in using AI agents for operational resilience ofcloud services, which currently require significant human effort and domainknowledge. There is a growing interest in AI for IT Operations (AIOps) whichaims to automate complex operational tasks, like fault localization and rootcause analysis, thereby reducing human intervention and customer impact.However, achieving the vision of autonomous and self-healing clouds throughAIOps is hampered by the lack of standardized frameworks for building,evaluating, and improving AIOps agents. This vision paper lays the groundworkfor such a framework by first framing the requirements and then discussingdesign decisions that satisfy them. We also propose AIOpsLab, a prototypeimplementation leveraging agent-cloud-interface that orchestrates anapplication, injects real-time faults using chaos engineering, and interfaceswith an agent to localize and resolve the faults. We report promising resultsand lay the groundwork to build a modular and robust framework for building,evaluating, and improving agents for autonomous clouds.</description><author>Manish Shetty, Yinfang Chen, Gagan Somashekar, Minghua Ma, Yogesh Simmhan, Xuchao Zhang, Jonathan Mace, Dax Vandevoorde, Pedro Las-Casas, Shachee Mishra Gupta, Suman Nath, Chetan Bansal, Saravan Rajmohan</author><pubDate>Wed, 31 Jul 2024 06:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12165v2</guid></item></channel></rss>