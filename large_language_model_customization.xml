<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivlarge language model customization</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 11 Jul 2024 18:35:02 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs</title><link>http://arxiv.org/abs/2404.01343v3</link><description>Businesses and software platforms are increasingly turning to Large LanguageModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistancewith file access or as reasoning agents for customer service. However, currentLLM-based customer service models have limited integration with customerprofiles and lack the operational capabilities necessary for effective service.Moreover, existing API integrations emphasize diversity over the precision anderror avoidance essential in real-world customer service scenarios. To addressthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profilein existing System), designed to: (1) efficiently utilize existing databases orsystems for accessing user information or interacting with these systemsfollowing existing guidelines; (2) provide accurate and reasonable responses orcarry out required operations in the system while avoiding harmful operations;and (3) leverage a combination of small and large LLMs to achieve satisfyingperformance at a reasonable inference cost. We introduce a practical dataset,the CPHOS-dataset, which includes a database, guiding files, and QA pairscollected from CPHOS, an online platform that facilitates the organization ofsimulated Physics Olympiads for high school teachers and students. We haveconducted extensive experiments to validate the performance of our proposedCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating howLLMs can enhance or serve as alternatives to human customer service. Code forour proposed architecture and dataset can be found at{https://github.com/JingzheShi/CHOPS}.</description><author>Jingzhe Shi, Jialuo Li, Qinwei Ma, Zaiwen Yang, Huan Ma, Lei Li</author><pubDate>Wed, 10 Jul 2024 11:33:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01343v3</guid></item><item><title>Review-LLM: Harnessing Large Language Models for Personalized Review Generation</title><link>http://arxiv.org/abs/2407.07487v1</link><description>Product review generation is an important task in recommender systems, whichcould provide explanation and persuasiveness for the recommendation. Recently,Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modelingand generating ability, which could be applied in review generation. However,directly applying the LLMs for generating reviews might be troubled by the``polite'' phenomenon of the LLMs and could not generate personalized reviews(e.g., negative reviews). In this paper, we propose Review-LLM that customizesLLMs for personalized review generation. Firstly, we construct the prompt inputby aggregating user historical behaviors, which include corresponding itemtitles and reviews. This enables the LLMs to capture user interest features andreview writing style. Secondly, we incorporate ratings as indicators ofsatisfaction into the prompt, which could further improve the model'sunderstanding of user preferences and the sentiment tendency control ofgenerated reviews. Finally, we feed the prompt text into LLMs, and useSupervised Fine-Tuning (SFT) to make the model generate personalized reviewsfor the given user and target item. Experimental results on the real-worlddataset show that our fine-tuned model could achieve better review generationperformance than existing close-source LLMs.</description><author>Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang</author><pubDate>Wed, 10 Jul 2024 09:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07487v1</guid></item></channel></rss>