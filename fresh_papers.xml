<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 24 Dec 2024 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>HoVLE: Unleashing the Power of Monolithic Vision-Language Models with Holistic Vision-Language Embedding</title><link>http://arxiv.org/abs/2412.16158v1</link><description>The rapid advance of Large Language Models (LLMs) has catalyzed thedevelopment of Vision-Language Models (VLMs). Monolithic VLMs, which avoidmodality-specific encoders, offer a promising alternative to the compositionalones but face the challenge of inferior performance. Most existing monolithicVLMs require tuning pre-trained LLMs to acquire vision abilities, which maydegrade their language capabilities. To address this dilemma, this paperpresents a novel high-performance monolithic VLM named HoVLE. We note that LLMshave been shown capable of interpreting images, when image embeddings arealigned with text embeddings. The challenge for current monolithic VLMsactually lies in the lack of a holistic embedding module for both vision andlanguage inputs. Therefore, HoVLE introduces a holistic embedding module thatconverts visual and textual inputs into a shared space, allowing LLMs toprocess images in the same way as texts. Furthermore, a multi-stage trainingstrategy is carefully designed to empower the holistic embedding module. It isfirst trained to distill visual features from a pre-trained vision encoder andtext embeddings from the LLM, enabling large-scale training with unpairedrandom images and text tokens. The whole model further undergoes next-tokenprediction on multi-modal data to align the embeddings. Finally, aninstruction-tuning stage is incorporated. Our experiments show that HoVLEachieves performance close to leading compositional models on variousbenchmarks, outperforming previous monolithic models by a large margin. Modelavailable at https://huggingface.co/OpenGVLab/HoVLE.</description><author>Chenxin Tao, Shiqian Su, Xizhou Zhu, Chenyu Zhang, Zhe Chen, Jiawen Liu, Wenhai Wang, Lewei Lu, Gao Huang, Yu Qiao, Jifeng Dai</author><pubDate>Fri, 20 Dec 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16158v1</guid></item><item><title>Personalized Representation from Personalized Generation</title><link>http://arxiv.org/abs/2412.16156v1</link><description>Modern vision models excel at general purpose downstream tasks. It isunclear, however, how they may be used for personalized vision tasks, which areboth fine-grained and data-scarce. Recent works have successfully appliedsynthetic data to general-purpose representation learning, while advances inT2I diffusion models have enabled the generation of personalized images fromjust a few real examples. Here, we explore a potential connection between theseideas, and formalize the challenge of using personalized synthetic data tolearn personalized representations, which encode knowledge about an object ofinterest and may be flexibly applied to any downstream task relating to thetarget object. We introduce an evaluation suite for this challenge, includingreformulations of two existing datasets and a novel dataset explicitlyconstructed for this purpose, and propose a contrastive learning approach thatmakes creative use of image generators. We show that our method improvespersonalized representation learning for diverse downstream tasks, fromrecognition to segmentation, and analyze characteristics of image generationapproaches that are key to this gain.</description><author>Shobhita Sundaram, Julia Chae, Yonglong Tian, Sara Beery, Phillip Isola</author><pubDate>Fri, 20 Dec 2024 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16156v1</guid></item><item><title>Can Generative Video Models Help Pose Estimation?</title><link>http://arxiv.org/abs/2412.16155v1</link><description>Pairwise pose estimation from images with little or no overlap is an openchallenge in computer vision. Existing methods, even those trained onlarge-scale datasets, struggle in these scenarios due to the lack ofidentifiable correspondences or visual overlap. Inspired by the human abilityto infer spatial relationships from diverse scenes, we propose a novelapproach, InterPose, that leverages the rich priors encoded within pre-trainedgenerative video models. We propose to use a video model to hallucinateintermediate frames between two input images, effectively creating a dense,visual transition, which significantly simplifies the problem of poseestimation. Since current video models can still produce implausible motion orinconsistent geometry, we introduce a self-consistency score that evaluates theconsistency of pose predictions from sampled videos. We demonstrate that ourapproach generalizes among three state-of-the-art video models and showconsistent improvements over the state-of-the-art DUSt3R on four diversedatasets encompassing indoor, outdoor, and object-centric scenes. Our findingssuggest a promising avenue for improving pose estimation models by leveraginglarge generative models trained on vast amounts of video data, which is morereadily available than 3D data. See our project page for results:https://inter-pose.github.io/.</description><author>Ruojin Cai, Jason Y. Zhang, Philipp Henzler, Zhengqi Li, Noah Snavely, Ricardo Martin-Brualla</author><pubDate>Fri, 20 Dec 2024 18:58:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16155v1</guid></item><item><title>MotiF: Making Text Count in Image Animation with Motion Focal Loss</title><link>http://arxiv.org/abs/2412.16153v1</link><description>Text-Image-to-Video (TI2V) generation aims to generate a video from an imagefollowing a text description, which is also referred to as text-guided imageanimation. Most existing methods struggle to generate videos that align wellwith the text prompts, particularly when motion is specified. To overcome thislimitation, we introduce MotiF, a simple yet effective approach that directsthe model's learning to the regions with more motion, thereby improving thetext alignment and motion generation. We use optical flow to generate a motionheatmap and weight the loss according to the intensity of the motion. Thismodified objective leads to noticeable improvements and complements existingmethods that utilize motion priors as model inputs. Additionally, due to thelack of a diverse benchmark for evaluating TI2V generation, we propose TI2VBench, a dataset consists of 320 image-text pairs for robust evaluation. Wepresent a human evaluation protocol that asks the annotators to select anoverall preference between two videos followed by their justifications. Througha comprehensive evaluation on TI2V Bench, MotiF outperforms nine open-sourcedmodels, achieving an average preference of 72%. The TI2V Bench is released inhttps://wang-sj16.github.io/motif/.</description><author>Shijie Wang, Samaneh Azadi, Rohit Girdhar, Saketh Rambhatla, Chen Sun, Xi Yin</author><pubDate>Fri, 20 Dec 2024 18:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16153v1</guid></item><item><title>Frequency Is What You Need: Word-frequency Masking Benefits Vision-Language Model Pre-training</title><link>http://arxiv.org/abs/2412.16148v1</link><description>Vision Language Models (VLMs) can be trained more efficiently if trainingsets can be reduced in size. Recent work has shown the benefits of masking textduring VLM training using a variety of approaches: truncation, random masking,block masking and syntax masking. In this paper, we show that the best maskingstrategy changes over training epochs and that, given sufficient trainingepochs, word frequency information is what you need to achieve the bestperformance. Experiments on a large range of data sets demonstrate theadvantages of our approach, called Contrastive Language-Image Pre-training withword Frequency Masking (CLIPF). The benefits are particularly evident as thenumber of input tokens decreases. We analyze the impact of CLIPF vs. othermasking approaches on word frequency balance and discuss the apparentlycritical contribution of CLIPF in maintaining word frequency balance across POScategories.</description><author>Mingliang Liang, Martha Larson</author><pubDate>Fri, 20 Dec 2024 18:51:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16148v1</guid></item><item><title>SeagrassFinder: Deep Learning for Eelgrass Detection and Coverage Estimation in the Wild</title><link>http://arxiv.org/abs/2412.16147v1</link><description>Seagrass meadows play a crucial role in marine ecosystems, providingimportant services such as carbon sequestration, water quality improvement, andhabitat provision. Monitoring the distribution and abundance of seagrass isessential for environmental impact assessments and conservation efforts.However, the current manual methods of analyzing underwater video transects toassess seagrass coverage are time-consuming and subjective. This work exploresthe use of deep learning models to automate the process of seagrass detectionand coverage estimation from underwater video data. A dataset of over 8,300annotated underwater images was created, and several deep learningarchitectures, including ResNet, InceptionNetV3, DenseNet, and VisionTransformer, were evaluated for the task of binary classification of ``EelgrassPresent'' and ``Eelgrass Absent'' images. The results demonstrate that deeplearning models, particularly the Vision Transformer, can achieve highperformance in predicting eelgrass presence, with AUROC scores exceeding 0.95on the final test dataset. The use of transfer learning and the application ofthe Deep WaveNet underwater image enhancement model further improved themodels' capabilities. The proposed methodology allows for the efficientprocessing of large volumes of video data, enabling the acquisition of muchmore detailed information on seagrass distributions compared to current manualmethods. This information is crucial for environmental impact assessments andmonitoring programs, as seagrasses are important indicators of coastalecosystem health. Overall, this project demonstrates the value that deeplearning can bring to the field of marine ecology and environmental monitoring.</description><author>Jannik Elsäßer, Laura Weihl, Veronika Cheplygina, Lisbeth Tangaa Nielsen</author><pubDate>Fri, 20 Dec 2024 18:50:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16147v1</guid></item><item><title>Mamba2D: A Natively Multi-Dimensional State-Space Model for Vision Tasks</title><link>http://arxiv.org/abs/2412.16146v1</link><description>State-Space Models (SSMs) have recently emerged as a powerful and efficientalternative to the long-standing transformer architecture. However, existingSSM conceptualizations retain deeply rooted biases from their roots in naturallanguage processing. This constrains their ability to appropriately model thespatially-dependent characteristics of visual inputs. In this paper, we addressthese limitations by re-deriving modern selective state-space techniques,starting from a natively multidimensional formulation. Currently, prior worksattempt to apply natively 1D SSMs to 2D data (i.e. images) by relying onarbitrary combinations of 1D scan directions to capture spatial dependencies.In contrast, Mamba2D improves upon this with a single 2D scan direction thatfactors in both dimensions of the input natively, effectively modelling spatialdependencies when constructing hidden states. Mamba2D shows comparableperformance to prior adaptations of SSMs for vision tasks, on standard imageclassification evaluations with the ImageNet-1K dataset.</description><author>Enis Baty, Alejandro Hernández Díaz, Chris Bridges, Rebecca Davidson, Steve Eckersley, Simon Hadfield</author><pubDate>Fri, 20 Dec 2024 18:50:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16146v1</guid></item><item><title>Offline Reinforcement Learning for LLM Multi-Step Reasoning</title><link>http://arxiv.org/abs/2412.16145v1</link><description>Improving the multi-step reasoning ability of large language models (LLMs)with offline reinforcement learning (RL) is essential for quickly adapting themto complex tasks. While Direct Preference Optimization (DPO) has shown promisein aligning LLMs with human preferences, it is less suitable for multi-stepreasoning tasks because (1) DPO relies on paired preference data, which is notreadily available for multi-step reasoning tasks, and (2) it treats all tokensuniformly, making it ineffective for credit assignment in multi-step reasoningtasks, which often come with sparse reward. In this work, we propose OREO(Offline Reasoning Optimization), an offline RL method for enhancing LLMmulti-step reasoning. Building on insights from previous works of maximumentropy reinforcement learning, it jointly learns a policy model and valuefunction by optimizing the soft Bellman Equation. We show in principle that itreduces the need to collect pairwise data and enables better credit assignment.Empirically, OREO surpasses existing offline learning methods on multi-stepreasoning benchmarks, including mathematical reasoning tasks (GSM8K, MATH) andembodied agent control (ALFWorld). The approach can be extended to amulti-iteration framework when additional resources are available. Furthermore,the learned value function can be leveraged to guide the tree search for free,which can further boost performance during test time.</description><author>Huaijie Wang, Shibo Hao, Hanze Dong, Shenao Zhang, Yilin Bao, Ziran Yang, Yi Wu</author><pubDate>Fri, 20 Dec 2024 18:49:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16145v1</guid></item><item><title>FedGAT: A Privacy-Preserving Federated Approximation Algorithm for Graph Attention Networks</title><link>http://arxiv.org/abs/2412.16144v1</link><description>Federated training methods have gained popularity for graph learning withapplications including friendship graphs of social media sites andcustomer-merchant interaction graphs of huge online marketplaces. However,privacy regulations often require locally generated data to be stored on localclients. The graph is then naturally partitioned across clients, with no clientpermitted access to information stored on another. Cross-client edges arisenaturally in such cases and present an interesting challenge to federatedtraining methods, as training a graph model at one client requires featureinformation of nodes on the other end of cross-client edges. Attempting toretain such edges often incurs significant communication overhead, and droppingthem altogether reduces model performance. In simpler models such as GraphConvolutional Networks, this can be fixed by communicating a limited amount offeature information across clients before training, but GATs (Graph AttentionNetworks) require additional information that cannot be pre-communicated, as itchanges from training round to round. We introduce the Federated GraphAttention Network (FedGAT) algorithm for semi-supervised node classification,which approximates the behavior of GATs with provable bounds on theapproximation error. FedGAT requires only one pre-training communication round,significantly reducing the communication overhead for federated GAT training.We then analyze the error in the approximation and examine the communicationoverhead and computational complexity of the algorithm. Experiments show thatFedGAT achieves nearly the same accuracy as a GAT model in a centralisedsetting, and its performance is robust to the number of clients as well as datadistribution.</description><author>Siddharth Ambekar, Yuhang Yao, Ryan Li, Carlee Joe-Wong</author><pubDate>Fri, 20 Dec 2024 18:48:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16144v1</guid></item><item><title>Synthesizing Moving People with 3D Control</title><link>http://arxiv.org/abs/2401.10889v2</link><description>In this paper, we present a diffusion model-based framework for animatingpeople from a single image for a given target 3D motion sequence. Our approachhas two core components: a) learning priors about invisible parts of the humanbody and clothing, and b) rendering novel body poses with proper clothing andtexture. For the first part, we learn an in-filling diffusion model tohallucinate unseen parts of a person given a single image. We train this modelon texture map space, which makes it more sample-efficient since it isinvariant to pose and viewpoint. Second, we develop a diffusion-based renderingpipeline, which is controlled by 3D human poses. This produces realisticrenderings of novel poses of the person, including clothing, hair, andplausible in-filling of unseen regions. This disentangled approach allows ourmethod to generate a sequence of images that are faithful to the target motionin the 3D pose and, to the input image in terms of visual similarity. Inaddition to that, the 3D control allows various synthetic camera trajectoriesto render a person. Our experiments show that our method is resilient ingenerating prolonged motions and varied challenging and complex poses comparedto prior methods. Please check our website for more details:https://boyiliee.github.io/3DHM.github.io/.</description><author>Boyi Li, Junming Chen, Jathushan Rajasegaran, Yossi Gandelsman, Alexei A. Efros, Jitendra Malik</author><pubDate>Fri, 20 Dec 2024 18:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10889v2</guid></item><item><title>NeRF-To-Real Tester: Neural Radiance Fields as Test Image Generators for Vision of Autonomous Systems</title><link>http://arxiv.org/abs/2412.16141v1</link><description>Autonomous inspection of infrastructure on land and in water is a quicklygrowing market, with applications including surveying constructions, monitoringplants, and tracking environmental changes in on- and off-shore wind energyfarms. For Autonomous Underwater Vehicles and Unmanned Aerial Vehiclesoverfitting of controllers to simulation conditions fundamentally leads to poorperformance in the operation environment. There is a pressing need for morediverse and realistic test data that accurately represents the challenges facedby these systems. We address the challenge of generating perception test datafor autonomous systems by leveraging Neural Radiance Fields to generaterealistic and diverse test images, and integrating them into a metamorphictesting framework for vision components such as vSLAM and object detection. Ourtool, N2R-Tester, allows training models of custom scenes and rendering testimages from perturbed positions. An experimental evaluation of N2R-Tester oneight different vision components in AUVs and UAVs demonstrates the efficacyand versatility of the approach.</description><author>Laura Weihl, Bilal Wehbe, Andrzej Wąsowski</author><pubDate>Fri, 20 Dec 2024 18:40:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16141v1</guid></item><item><title>Factored space models: Towards causality between levels of abstraction</title><link>http://arxiv.org/abs/2412.02579v2</link><description>Causality plays an important role in understanding intelligent behavior, andthere is a wealth of literature on mathematical models for causality, most ofwhich is focused on causal graphs. Causal graphs are a powerful tool for a widerange of applications, in particular when the relevant variables are known andat the same level of abstraction. However, the given variables can also beunstructured data, like pixels of an image. Meanwhile, the causal variables,such as the positions of objects in the image, can be arbitrary deterministicfunctions of the given variables. Moreover, the causal variables may form ahierarchy of abstractions, in which the macro-level variables are deterministicfunctions of the micro-level variables. Causal graphs are limited when it comesto modeling this kind of situation. In the presence of deterministicrelationships there is generally no causal graph that satisfies both the Markovcondition and the faithfulness condition. We introduce factored space models asan alternative to causal graphs which naturally represent both probabilisticand deterministic relationships at all levels of abstraction. Moreover, weintroduce structural independence and establish that it is equivalent tostatistical independence in every distribution that factorizes over thefactored space. This theorem generalizes the classical soundness andcompleteness theorem for d-separation.</description><author>Scott Garrabrant, Matthias Georg Mayer, Magdalena Wache, Leon Lang, Sam Eisenstat, Holger Dell</author><pubDate>Fri, 20 Dec 2024 18:38:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.02579v2</guid></item><item><title>Camera-Based Localization and Enhanced Normalized Mutual Information</title><link>http://arxiv.org/abs/2412.16137v1</link><description>Robust and fine localization algorithms are crucial for autonomous driving.For the production of such vehicles as a commodity, affordable sensingsolutions and reliable localization algorithms must be designed. This workconsiders scenarios where the sensor data comes from images captured by aninexpensive camera mounted on the vehicle and where the vehicle contains a fineglobal map. Such localization algorithms typically involve finding the sectionin the global map that best matches the captured image. In harsh environments,both the global map and the captured image can be noisy. Because of physicalconstraints on camera placement, the image captured by the camera can be viewedas a noisy perspective transformed version of the road in the global map. Thus,an optimal algorithm should take into account the unequal noise power invarious regions of the captured image, and the intrinsic uncertainty in theglobal map due to environmental variations. This article briefly reviews twomatching methods: (i) standard inner product (SIP) and (ii) normalized mutualinformation (NMI). It then proposes novel and principled modifications toimprove the performance of these algorithms significantly in noisyenvironments. These enhancements are inspired by the physical constraintsassociated with autonomous vehicles. They are grounded in statistical signalprocessing and, in some context, are provably better. Numerical simulationsdemonstrate the effectiveness of such modifications.</description><author>Vishnu Teja Kunde, Jean-Francois Chamberland, Siddharth Agarwal</author><pubDate>Fri, 20 Dec 2024 18:35:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16137v1</guid></item><item><title>EF-Net: A Deep Learning Approach Combining Word Embeddings and Feature Fusion for Patient Disposition Analysis</title><link>http://arxiv.org/abs/2412.16134v1</link><description>One of the most urgent problems is the overcrowding in emergency departments(EDs), caused by an aging population and rising healthcare costs. Patientdispositions have become more complex as a result of the strain on hospitalinfrastructure and the scarcity of medical resources. Individuals with moredangerous health issues should be prioritized in the emergency room. Thus, ourresearch aims to develop a prediction model for patient disposition usingEF-Net. This model will incorporate categorical features into the neuralnetwork layer and add numerical features with the embedded categoricalfeatures. We combine the EF-Net and XGBoost models to attain higher accuracy inour results. The result is generated using the soft voting technique. InEF-Net, we attained an accuracy of 95.33%, whereas in the Ensemble Model, weachieved an accuracy of 96%. The experiment's analysis shows that EF-Netsurpasses existing works in accuracy, AUROC, and F1-Score on the MIMIC-IV-EDdataset, demonstrating its potential as a scalable solution for patientdisposition assessment. Our code is available athttps://github.com/nafisa67/thesis</description><author>Nafisa Binte Feroz, Chandrima Sarker, Tanzima Ahsan, K M Arefeen Sultan, Raqeebir Rab</author><pubDate>Fri, 20 Dec 2024 18:31:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16134v1</guid></item><item><title>Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation</title><link>http://arxiv.org/abs/2412.16135v1</link><description>Malware authors often employ code obfuscations to make their malware harderto detect. Existing tools for generating obfuscated code often require accessto the original source code (e.g., C++ or Java), and adding new obfuscations isa non-trivial, labor-intensive process. In this study, we ask the followingquestion: Can Large Language Models (LLMs) potentially generate a newobfuscated assembly code? If so, this poses a risk to anti-virus engines andpotentially increases the flexibility of attackers to create new obfuscationpatterns. We answer this in the affirmative by developing the MetamorphASMbenchmark comprising MetamorphASM Dataset (MAD) along with three codeobfuscation techniques: dead code, register substitution, and control flowchange. The MetamorphASM systematically evaluates the ability of LLMs togenerate and analyze obfuscated code using MAD, which contains 328,200obfuscated assembly code samples. We release this dataset and analyze thesuccess rate of various LLMs (e.g., GPT-3.5/4, GPT-4o-mini, Starcoder,CodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assemblycode. The evaluation was performed using established information-theoreticmetrics and manual human review to ensure correctness and provide thefoundation for researchers to study and develop remediations to this risk. Thesource code can be found at the following GitHub link:https://github.com/mohammadi-ali/MetamorphASM.</description><author>Seyedreza Mohseni, Seyedali Mohammadi, Deepa Tilwani, Yash Saxena, Gerald Ndwula, Sriram Vema, Edward Raff, Manas Gaur</author><pubDate>Fri, 20 Dec 2024 18:31:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16135v1</guid></item><item><title>LEDA: Log-Euclidean Diffeomorphic Autoencoder for Efficient Statistical Analysis of Diffeomorphism</title><link>http://arxiv.org/abs/2412.16129v1</link><description>Image registration is a core task in computational anatomy that establishescorrespondences between images. Invertible deformable registration, whichcomputes a deformation field and handles complex, non-linear transformation, isessential for tracking anatomical variations, especially in neuroimagingapplications where inter-subject differences and longitudinal changes are key.Analyzing the deformation fields is challenging due to their non-linearity,limiting statistical analysis. However, traditional approaches for analyzingdeformation fields are computationally expensive, sensitive to initialization,and prone to numerical errors, especially when the deformation is far from theidentity. To address these limitations, we propose the Log-EuclideanDiffeomorphic Autoencoder (LEDA), an innovative framework designed to computethe principal logarithm of deformation fields by efficiently predictingconsecutive square roots. LEDA operates within a linearized latent space thatadheres to the diffeomorphisms group action laws, enhancing our model'srobustness and applicability. We also introduce a loss function to enforceinverse consistency, ensuring accurate latent representations of deformationfields. Extensive experiments with the OASIS-1 dataset demonstrate theeffectiveness of LEDA in accurately modeling and analyzing complex non-lineardeformations while maintaining inverse consistency. Additionally, we evaluateits ability to capture and incorporate clinical variables, enhancing itsrelevance for clinical applications.</description><author>Krithika Iyer, Shireen Elhabian, Sarang Joshi</author><pubDate>Fri, 20 Dec 2024 18:26:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16129v1</guid></item><item><title>Data Quality Matters: Suicide Intention Detection on Social Media Posts Using RoBERTa-CNN</title><link>http://arxiv.org/abs/2402.02262v2</link><description>Suicide remains a pressing global health concern, necessitating innovativeapproaches for early detection and intervention. This paper focuses onidentifying suicidal intentions in posts from the SuicideWatch subreddit byproposing a novel deep-learning approach that utilizes the state-of-the-artRoBERTa-CNN model. The robustly Optimized BERT Pretraining Approach (RoBERTa)excels at capturing textual nuances and forming semantic relationships withinthe text. The remaining Convolutional Neural Network (CNN) head enhancesRoBERTa's capacity to discern critical patterns from extensive datasets. Toevaluate RoBERTa-CNN, we conducted experiments on the Suicide and DepressionDetection dataset, yielding promising results. For instance, RoBERTa-CNNachieves a mean accuracy of 98% with a standard deviation (STD) of 0.0009.Additionally, we found that data quality significantly impacts the training ofa robust model. To improve data quality, we removed noise from the text datawhile preserving its contextual content through either manually cleaning orutilizing the OpenAI API.</description><author>Emily Lin, Jian Sun, Hsingyu Chen, Mohammad H. Mahoor</author><pubDate>Fri, 20 Dec 2024 18:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02262v2</guid></item><item><title>Representation Learning of Daily Movement Data Using Text Encoders</title><link>http://arxiv.org/abs/2405.04494v2</link><description>Time-series representation learning is a key area of research for remotehealthcare monitoring applications. In this work, we focus on a dataset ofrecordings of in-home activity from people living with Dementia. We design arepresentation learning method based on converting activity to text stringsthat can be encoded using a language model fine-tuned to transform data fromthe same participants within a $30$-day window to similar embeddings in thevector space. This allows for clustering and vector searching over participantsand days, and the identification of activity deviations to aid withpersonalised delivery of care.</description><author>Alexander Capstick, Tianyu Cui, Yu Chen, Payam Barnaghi</author><pubDate>Fri, 20 Dec 2024 18:18:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04494v2</guid></item><item><title>Learning ECG Signal Features Without Backpropagation Using Linear Laws</title><link>http://arxiv.org/abs/2307.01930v2</link><description>This paper introduces LLT-ECG, a novel method for electrocardiogram (ECG)signal classification that leverages concepts from theoretical physics toautomatically generate features from time series data. Unlike traditional deeplearning approaches, LLT-ECG operates in a forward manner, eliminating the needfor backpropagation and hyperparameter tuning. By identifying linear laws thatcapture shared patterns within specific classes, the proposed method constructsa compact and verifiable representation, enhancing the effectiveness ofdownstream classifiers. We demonstrate LLT-ECG's state-of-the-art performanceon real-world ECG datasets from PhysioNet, underscoring its potential formedical applications where speed and verifiability are crucial.</description><author>Péter Pósfay, Marcell T. Kurbucz, Péter Kovács, Antal Jakovác</author><pubDate>Fri, 20 Dec 2024 18:18:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01930v2</guid></item><item><title>Residual Multi-Fidelity Neural Network Computing</title><link>http://arxiv.org/abs/2310.03572v3</link><description>In this work, we consider the general problem of constructing a neuralnetwork surrogate model using multi-fidelity information. Motivated byerror-complexity estimates for ReLU neural networks, we formulate thecorrelation between an inexpensive low-fidelity model and an expensivehigh-fidelity model as a possibly non-linear residual function. This functiondefines a mapping between 1) the shared input space of the models along withthe low-fidelity model output, and 2) the discrepancy between the outputs ofthe two models. The computational framework proceeds by training two neuralnetworks to work in concert. The first network learns the residual function ona small set of high- and low-fidelity data. Once trained, this network is usedto generate additional synthetic high-fidelity data, which is used in thetraining of the second network. The trained second network then acts as oursurrogate for the high-fidelity quantity of interest. We present four numericalexamples to demonstrate the power of the proposed framework, showing thatsignificant savings in computational cost may be achieved when the outputpredictions are desired to be accurate within small tolerances.</description><author>Owen Davis, Mohammad Motamed, Raul Tempone</author><pubDate>Fri, 20 Dec 2024 18:17:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03572v3</guid></item><item><title>SHAP zero Explains Genomic Models with Near-zero Marginal Cost for Future Queried Sequences</title><link>http://arxiv.org/abs/2410.19236v2</link><description>With the rapid growth of large-scale machine learning models in genomics,Shapley values have emerged as a popular method for model explanations due totheir theoretical guarantees. While Shapley values explain model predictionslocally for an individual input query sequence, extracting biological knowledgerequires global explanation across thousands of input sequences. This demandsexponential model evaluations per sequence, resulting in significantcomputational cost and carbon footprint. Herein, we develop SHAP zero, a methodthat estimates Shapley values and interactions with a near-zero marginal costfor future queried sequences after paying a one-time fee for model sketching.SHAP zero achieves this by establishing a surprisingly underexplored connectionbetween the Shapley values and interactions and the Fourier transform of themodel. Explaining two genomic models, one trained to predict guide RNA bindingand the other to predict DNA repair outcome, we demonstrate that SHAP zeroachieves orders of magnitude reduction in amortized computational cost comparedto state-of-the-art algorithms, revealing almost all predictive motifs -- afinding previously inaccessible due to the combinatorial space of possibleinteractions.</description><author>Darin Tsui, Aryan Musharaf, Yigit Efe Erginbas, Justin Singh Kang, Amirali Aghazadeh</author><pubDate>Fri, 20 Dec 2024 18:13:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19236v2</guid></item><item><title>What is the Role of Small Models in the LLM Era: A Survey</title><link>http://arxiv.org/abs/2409.06857v4</link><description>Large Language Models (LLMs) have made significant progress in advancingartificial general intelligence (AGI), leading to the development ofincreasingly large models such as GPT-4 and LLaMA-405B. However, scaling upmodel sizes results in exponentially higher computational costs and energyconsumption, making these models impractical for academic researchers andbusinesses with limited resources. At the same time, Small Models (SMs) arefrequently used in practical settings, although their significance is currentlyunderestimated. This raises important questions about the role of small modelsin the era of LLMs, a topic that has received limited attention in priorresearch. In this work, we systematically examine the relationship between LLMsand SMs from two key perspectives: Collaboration and Competition. We hope thissurvey provides valuable insights for practitioners, fostering a deeperunderstanding of the contribution of small models and promoting more efficientuse of computational resources. The code is available athttps://github.com/tigerchen52/role_of_small_models</description><author>Lihu Chen, Gaël Varoquaux</author><pubDate>Fri, 20 Dec 2024 18:11:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06857v4</guid></item><item><title>PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation Metrics</title><link>http://arxiv.org/abs/2412.16120v1</link><description>Evaluating the quality of machine-generated natural language content is achallenging task in Natural Language Processing (NLP). Recently, large languagemodels (LLMs) like GPT-4 have been employed for this purpose, but they arecomputationally expensive due to the extensive token usage required by complexevaluation prompts. In this paper, we propose a prompt optimization approachthat uses a smaller, fine-tuned language model to compress input data forevaluation prompt, thus reducing token usage and computational cost when usinglarger LLMs for downstream evaluation. Our method involves a two-stagefine-tuning process: supervised fine-tuning followed by preference optimizationto refine the model's outputs based on human preferences. We focus on MachineTranslation (MT) evaluation and utilize the GEMBA-MQM metric as a startingpoint. Our results show a $2.37\times$ reduction in token usage without anyloss in evaluation quality. This work makes state-of-the-art LLM-based metricslike GEMBA-MQM more cost-effective and efficient, enhancing their accessibilityfor broader use.</description><author>Daniil Larionov, Steffen Eger</author><pubDate>Fri, 20 Dec 2024 18:08:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16120v1</guid></item><item><title>Deciphering the Underserved: Benchmarking LLM OCR for Low-Resource Scripts</title><link>http://arxiv.org/abs/2412.16119v1</link><description>This study investigates the potential of Large Language Models (LLMs),particularly GPT-4o, for Optical Character Recognition (OCR) in low-resourcescripts such as Urdu, Albanian, and Tajik, with English serving as a benchmark.Using a meticulously curated dataset of 2,520 images incorporating controlledvariations in text length, font size, background color, and blur, the researchsimulates diverse real-world challenges. Results emphasize the limitations ofzero-shot LLM-based OCR, particularly for linguistically complex scripts,highlighting the need for annotated datasets and fine-tuned models. This workunderscores the urgency of addressing accessibility gaps in text digitization,paving the way for inclusive and robust OCR solutions for underservedlanguages.</description><author>Muhammad Abdullah Sohail, Salaar Masood, Hamza Iqbal</author><pubDate>Fri, 20 Dec 2024 18:05:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16119v1</guid></item><item><title>Convolutional Deep Operator Networks for Learning Nonlinear Focused Ultrasound Wave Propagation in Heterogeneous Spinal Cord Anatomy</title><link>http://arxiv.org/abs/2412.16118v1</link><description>Focused ultrasound (FUS) therapy is a promising tool for optimally targetedtreatment of spinal cord injuries (SCI), offering submillimeter precision toenhance blood flow at injury sites while minimizing impact on surroundingtissues. However, its efficacy is highly sensitive to the placement of theultrasound source, as the spinal cord's complex geometry and acousticheterogeneity distort and attenuate the FUS signal. Current approaches rely oncomputer simulations to solve the governing wave propagation equations andcompute patient-specific pressure maps using ultrasound images of the spinalcord anatomy. While accurate, these high-fidelity simulations arecomputationally intensive, taking up to hours to complete parameter sweeps,which is impractical for real-time surgical decision-making. To address thisbottleneck, we propose a convolutional deep operator network (DeepONet) torapidly predict FUS pressure fields in patient spinal cords. Unlikeconventional neural networks, DeepONets are well equipped to approximate thesolution operator of the parametric partial differential equations (PDEs) thatgovern the behavior of FUS waves with varying initial and boundary conditions(i.e., new transducer locations or spinal cord geometries) without requiringextensive simulations. Trained on simulated pressure maps across diversepatient anatomies, this surrogate model achieves real-time predictions withonly a 2% loss on the test set, significantly accelerating the modeling ofnonlinear physical systems in heterogeneous domains. By facilitating rapidparameter sweeps in surgical settings, this work provides a crucial step towardprecise and individualized solutions in neurosurgical treatments.</description><author>Avisha Kumar, Xuzhe Zhi, Zan Ahmad, Minglang Yin, Amir Manbachi</author><pubDate>Fri, 20 Dec 2024 18:03:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16118v1</guid></item><item><title>POPoS: Improving Efficient and Robust Facial Landmark Detection with Parallel Optimal Position Search</title><link>http://arxiv.org/abs/2410.09583v5</link><description>Achieving a balance between accuracy and efficiency is a critical challengein facial landmark detection (FLD). This paper introduces Parallel OptimalPosition Search (POPoS), a high-precision encoding-decoding framework designedto address the limitations of traditional FLD methods. POPoS employs three keycontributions: (1) Pseudo-range multilateration is utilized to correct heatmaperrors, improving landmark localization accuracy. By integrating multipleanchor points, it reduces the impact of individual heatmap inaccuracies,leading to robust overall positioning. (2) To enhance the pseudo-range accuracyof selected anchor points, a new loss function, named multilateration anchorloss, is proposed. This loss function enhances the accuracy of the distancemap, mitigates the risk of local optima, and ensures optimal solutions. (3) Asingle-step parallel computation algorithm is introduced, boostingcomputational efficiency and reducing processing time. Extensive evaluationsacross five benchmark datasets demonstrate that POPoS consistently outperformsexisting methods, particularly excelling in low-resolution heatmaps scenarioswith minimal computational overhead. These advantages make POPoS a highlyefficient and accurate tool for FLD, with broad applicability in real-worldscenarios.</description><author>Chong-Yang Xiang, Jun-Yan He, Zhi-Qi Cheng, Xiao Wu, Xian-Sheng Hua</author><pubDate>Fri, 20 Dec 2024 18:03:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09583v5</guid></item><item><title>PruneVid: Visual Token Pruning for Efficient Video Large Language Models</title><link>http://arxiv.org/abs/2412.16117v1</link><description>In this paper, we introduce PruneVid, a visual token pruning method designedto enhance the efficiency of multi-modal video understanding. Large LanguageModels (LLMs) have shown promising performance in video tasks due to theirextended capabilities in comprehending visual modalities. However, thesubstantial redundancy in video data presents significant computationalchallenges for LLMs. To address this issue, we introduce a training-free methodthat 1) minimizes video redundancy by merging spatial-temporal tokens, and 2)leverages LLMs' reasoning capabilities to selectively prune visual featuresrelevant to question tokens, enhancing model efficiency. We validate our methodacross multiple video benchmarks, which demonstrate that PruneVid can pruneover 80% of tokens while maintaining competitive performance combined withdifferent model networks. This highlights its superior effectiveness andefficiency compared to existing pruning methods. Code:https://github.com/Visual-AI/PruneVid.</description><author>Xiaohu Huang, Hao Zhou, Kai Han</author><pubDate>Fri, 20 Dec 2024 18:01:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16117v1</guid></item><item><title>CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up</title><link>http://arxiv.org/abs/2412.16112v1</link><description>Diffusion Transformers (DiT) have become a leading architecture in imagegeneration. However, the quadratic complexity of attention mechanisms, whichare responsible for modeling token-wise relationships, results in significantlatency when generating high-resolution images. To address this issue, we aimat a linear attention mechanism in this paper that reduces the complexity ofpre-trained DiTs to linear. We begin our exploration with a comprehensivesummary of existing efficient attention mechanisms and identify four keyfactors crucial for successful linearization of pre-trained DiTs: locality,formulation consistency, high-rank attention maps, and feature integrity. Basedon these insights, we introduce a convolution-like local attention strategytermed CLEAR, which limits feature interactions to a local window around eachquery token, and thus achieves linear complexity. Our experiments indicatethat, by fine-tuning the attention layer on merely 10K self-generated samplesfor 10K iterations, we can effectively transfer knowledge from a pre-trainedDiT to a student model with linear complexity, yielding results comparable tothe teacher model. Simultaneously, it reduces attention computations by 99.5%and accelerates generation by 6.3 times for generating 8K-resolution images.Furthermore, we investigate favorable properties in the distilled attentionlayers, such as zero-shot generalization cross various models and plugins, andimproved support for multi-GPU parallel inference. Models and codes areavailable here: https://github.com/Huage001/CLEAR.</description><author>Songhua Liu, Zhenxiong Tan, Xinchao Wang</author><pubDate>Fri, 20 Dec 2024 17:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16112v1</guid></item><item><title>Learning Massive-scale Partial Correlation Networks in Clinical Multi-omics Studies with HP-ACCORD</title><link>http://arxiv.org/abs/2412.11554v2</link><description>Graphical model estimation from modern multi-omics data requires a balancebetween statistical estimation performance and computational scalability. Weintroduce a novel pseudolikelihood-based graphical model framework thatreparameterizes the target precision matrix while preserving sparsity patternand estimates it by minimizing an $\ell_1$-penalized empirical risk based on anew loss function. The proposed estimator maintains estimation and selectionconsistency in various metrics under high-dimensional assumptions. Theassociated optimization problem allows for a provably fast computationalgorithm using a novel operator-splitting approach and communication-avoidingdistributed matrix multiplication. A high-performance computing implementationof our framework was tested in simulated data with up to one million variablesdemonstrating complex dependency structures akin to biological networks.Leveraging this scalability, we estimated partial correlation network from adual-omic liver cancer data set. The co-expression network estimated from theultrahigh-dimensional data showed superior specificity in prioritizing keytranscription factors and co-activators by excluding the impact of epigenomicregulation, demonstrating the value of computational scalability in multi-omicdata analysis. %derived from the gene expression data.</description><author>Sungdong Lee, Joshua Bang, Youngrae Kim, Hyungwon Choi, Sang-Yun Oh, Joong-Ho Won</author><pubDate>Fri, 20 Dec 2024 17:56:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.11554v2</guid></item><item><title>Text Understanding in GPT-4 vs Humans</title><link>http://arxiv.org/abs/2403.17196v3</link><description>We examine whether a leading AI system GPT4 understands text as well ashumans do, first using a well-established standardized test of discoursecomprehension. On this test, GPT4 performs slightly, but not statisticallysignificantly, better than humans given the very high level of humanperformance. Both GPT4 and humans make correct inferences about informationthat is not explicitly stated in the text, a critical test of understanding.Next, we use more difficult passages to determine whether that could allowlarger differences between GPT4 and humans. GPT4 does considerably better onthis more difficult text than do the high school and university students forwhom these the text passages are designed, as admission tests of studentreading comprehension. Deeper exploration of GPT4 performance on material fromone of these admission tests reveals generally accepted signatures of genuineunderstanding, namely generalization and inference.</description><author>Thomas R. Shultz, Jamie M. Wise, Ardavan Salehi Nobandegani</author><pubDate>Fri, 20 Dec 2024 17:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17196v3</guid></item><item><title>Demystifying the Potential of ChatGPT-4 Vision for Construction Progress Monitoring</title><link>http://arxiv.org/abs/2412.16108v1</link><description>The integration of Large Vision-Language Models (LVLMs) such as OpenAI'sGPT-4 Vision into various sectors has marked a significant evolution in thefield of artificial intelligence, particularly in the analysis andinterpretation of visual data. This paper explores the practical application ofGPT-4 Vision in the construction industry, focusing on its capabilities inmonitoring and tracking the progress of construction projects. Utilizinghigh-resolution aerial imagery of construction sites, the study examines howGPT-4 Vision performs detailed scene analysis and tracks developmental changesover time. The findings demonstrate that while GPT-4 Vision is proficient inidentifying construction stages, materials, and machinery, it faces challengeswith precise object localization and segmentation. Despite these limitations,the potential for future advancements in this technology is considerable. Thisresearch not only highlights the current state and opportunities of using LVLMsin construction but also discusses future directions for enhancing the model'sutility through domain-specific training and integration with other computervision techniques and digital twins.</description><author>Ahmet Bahaddin Ersoz</author><pubDate>Fri, 20 Dec 2024 17:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16108v1</guid></item><item><title>Logical Consistency of Large Language Models in Fact-checking</title><link>http://arxiv.org/abs/2412.16100v1</link><description>In recent years, large language models (LLMs) have demonstrated significantsuccess in performing varied natural language tasks such as languagetranslation, question-answering, summarizing, fact-checking, etc. Despite LLMs'impressive ability to generate human-like texts, LLMs are infamous for theirinconsistent responses -- a meaning-preserving change in the input queryresults in an inconsistent response and attributes to vulnerabilities of LLMssuch as hallucination, jailbreaking, etc. Consequently, existing researchfocuses on simple paraphrasing-based consistency assessment of LLMs, andignores complex queries that necessitates an even better understanding oflogical reasoning by an LLM. Our work therefore addresses the logicalinconsistency of LLMs under complex logical queries with primitive logicaloperators, e.g., negation, conjunction, and disjunction. As a test bed, weconsider retrieval-augmented LLMs on a fact-checking task involvingpropositional logic queries from real-world knowledge graphs (KGs). Ourcontributions are three-fold. Benchmark: We introduce three logicalfact-checking datasets over KGs for community development towards logicallyconsistent LLMs. Assessment: We propose consistency measures of LLMs onpropositional logic queries as input and demonstrate that existing LLMs lacklogical consistency, specially on complex queries. Improvement: We employsupervised fine-tuning to improve the logical consistency of LLMs on thecomplex fact-checking task with KG contexts.</description><author>Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, Arijit Khan</author><pubDate>Fri, 20 Dec 2024 17:42:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16100v1</guid></item><item><title>Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Time Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis</title><link>http://arxiv.org/abs/2412.16098v1</link><description>Detecting and analyzing complex patterns in multivariate time-series data iscrucial for decision-making in urban and environmental system operations.However, challenges arise from the high dimensionality, intricate complexity,and interconnected nature of complex patterns, which hinder the understandingof their underlying physical processes. Existing AI methods often facelimitations in interpretability, computational efficiency, and scalability,reducing their applicability in real-world scenarios. This paper proposes anovel visual analytics framework that integrates two generative AI models, TimeFusion Transformer (TFT) and Variational Autoencoders (VAEs), to reduce complexpatterns into lower-dimensional latent spaces and visualize them in 2D usingdimensionality reduction techniques such as PCA, t-SNE, and UMAP with DBSCAN.These visualizations, presented through coordinated and interactive views andtailored glyphs, enable intuitive exploration of complex multivariate temporalpatterns, identifying patterns' similarities and uncover their potentialcorrelations for a better interpretability of the AI outputs. The framework isdemonstrated through a case study on power grid signal data, where itidentifies multi-label grid event signatures, including faults and anomalieswith diverse root causes. Additionally, novel metrics and visualizations areintroduced to validate the models and evaluate the performance, efficiency, andconsistency of latent maps generated by TFT and VAE under differentconfigurations. These analyses provide actionable insights for model parametertuning and reliability improvements. Comparative results highlight that TFTachieves shorter run times and superior scalability to diverse time-series datashapes compared to VAE. This work advances fault diagnosis in multivariate timeseries, fostering explainable AI to support critical system operations.</description><author>Haowen Xu, Ali Boyaci, Jianming Lian, Aaron Wilson</author><pubDate>Fri, 20 Dec 2024 17:41:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16098v1</guid></item><item><title>Memory Layers at Scale</title><link>http://arxiv.org/abs/2412.09764v2</link><description>Memory layers use a trainable key-value lookup mechanism to add extraparameters to a model without increasing FLOPs. Conceptually, sparselyactivated memory layers complement compute-heavy dense feed-forward layers,providing dedicated capacity to store and retrieve information cheaply. Thiswork takes memory layers beyond proof-of-concept, proving their utility atcontemporary scale. On downstream tasks, language models augmented with ourimproved memory layer outperform dense models with more than twice thecomputation budget, as well as mixture-of-expert models when matched for bothcompute and parameters. We find gains are especially pronounced for factualtasks. We provide a fully parallelizable memory layer implementation,demonstrating scaling laws with up to 128B memory parameters, pretrained to 1trillion tokens, comparing to base models with up to 8B parameters.</description><author>Vincent-Pierre Berges, Barlas Oğuz, Daniel Haziza, Wen-tau Yih, Luke Zettlemoyer, Gargi Ghosh</author><pubDate>Fri, 20 Dec 2024 17:36:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.09764v2</guid></item><item><title>The Evolution of LLM Adoption in Industry Data Curation Practices</title><link>http://arxiv.org/abs/2412.16089v1</link><description>As large language models (LLMs) grow increasingly adept at processingunstructured text data, they offer new opportunities to enhance data curationworkflows. This paper explores the evolution of LLM adoption amongpractitioners at a large technology company, evaluating the impact of LLMs indata curation tasks through participants' perceptions, integration strategies,and reported usage scenarios. Through a series of surveys, interviews, and userstudies, we provide a timely snapshot of how organizations are navigating apivotal moment in LLM evolution. In Q2 2023, we conducted a survey to assessLLM adoption in industry for development tasks (N=84), and facilitated expertinterviews to assess evolving data needs (N=10) in Q3 2023. In Q2 2024, weexplored practitioners' current and anticipated LLM usage through a user studyinvolving two LLM-based prototypes (N=12). While each study addressed distinctresearch goals, they revealed a broader narrative about evolving LLM usage inaggregate. We discovered an emerging shift in data understanding fromheuristic-first, bottom-up approaches to insights-first, top-down workflowssupported by LLMs. Furthermore, to respond to a more complex data landscape,data practitioners now supplement traditional subject-expert-created 'goldendatasets' with LLM-generated 'silver' datasets and rigorously validated 'supergolden' datasets curated by diverse experts. This research sheds light on thetransformative role of LLMs in large-scale analysis of unstructured data andhighlights opportunities for further tool development.</description><author>Crystal Qian, Michael Xieyang Liu, Emily Reif, Grady Simon, Nada Hussein, Nathan Clement, James Wexler, Carrie J. Cai, Michael Terry, Minsuk Kahng</author><pubDate>Fri, 20 Dec 2024 17:34:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16089v1</guid></item><item><title>Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG</title><link>http://arxiv.org/abs/2412.16086v1</link><description>Deep learning has advanced medical image classification, but interpretabilitychallenges hinder its clinical adoption. This study enhances interpretabilityin Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)and a multi-agent Retrieval-Augmented Generation (RAG) system for reportgeneration. By modeling relationships between visual features and clinicalconcepts, we create interpretable concept vectors that guide a multi-agent RAGsystem to generate radiology reports, enhancing clinical relevance,explainability, and transparency. Evaluation of the generated reports using anLLM-as-a-judge confirmed the interpretability and clinical utility of ourmodel's outputs. On the COVID-QU dataset, our model achieved 81% classificationaccuracy and demonstrated robust report generation performance, with five keymetrics ranging between 84% and 90%. This interpretable multi-agent frameworkbridges the gap between high-performance AI and the explainability required forreliable AI-driven CXR analysis in clinical settings.</description><author>Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag</author><pubDate>Fri, 20 Dec 2024 17:33:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16086v1</guid></item><item><title>Efficient MedSAMs: Segment Anything in Medical Images on Laptop</title><link>http://arxiv.org/abs/2412.16085v1</link><description>Promptable segmentation foundation models have emerged as a transformativeapproach to addressing the diverse needs in medical images, but most existingmodels require expensive computing, posing a big barrier to their adoption inclinical practice. In this work, we organized the first internationalcompetition dedicated to promptable medical image segmentation, featuring alarge-scale dataset spanning nine common imaging modalities from over 20different institutions. The top teams developed lightweight segmentationfoundation models and implemented an efficient inference pipeline thatsubstantially reduced computational requirements while maintainingstate-of-the-art segmentation accuracy. Moreover, the post-challenge phaseadvanced the algorithms through the design of performance booster andreproducibility tasks, resulting in improved algorithms and validatedreproducibility of the winning solution. Furthermore, the best-performingalgorithms have been incorporated into the open-source software with auser-friendly interface to facilitate clinical adoption. The data and code arepublicly available to foster the further development of medical imagesegmentation foundation models and pave the way for impactful real-worldapplications.</description><author>Jun Ma, Feifei Li, Sumin Kim, Reza Asakereh, Bao-Hiep Le, Dang-Khoa Nguyen-Vu, Alexander Pfefferle, Muxin Wei, Ruochen Gao, Donghang Lyu, Songxiao Yang, Lennart Purucker, Zdravko Marinov, Marius Staring, Haisheng Lu, Thuy Thanh Dao, Xincheng Ye, Zhi Li, Gianluca Brugnara, Philipp Vollmuth, Martha Foltyn-Dumitru, Jaeyoung Cho, Mustafa Ahmed Mahmutoglu, Martin Bendszus, Irada Pflüger, Aditya Rastogi, Dong Ni, Xin Yang, Guang-Quan Zhou, Kaini Wang, Nicholas Heller, Nikolaos Papanikolopoulos, Christopher Weight, Yubing Tong, Jayaram K Udupa, Cahill J. Patrick, Yaqi Wang, Yifan Zhang, Francisco Contijoch, Elliot McVeigh, Xin Ye, Shucheng He, Robert Haase, Thomas Pinetz, Alexander Radbruch, Inga Krause, Erich Kobler, Jian He, Yucheng Tang, Haichun Yang, Yuankai Huo, Gongning Luo, Kaisar Kushibar</author><pubDate>Fri, 20 Dec 2024 17:33:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16085v1</guid></item><item><title>Differentially Private Federated Learning of Diffusion Models for Synthetic Tabular Data Generation</title><link>http://arxiv.org/abs/2412.16083v1</link><description>The increasing demand for privacy-preserving data analytics in financenecessitates solutions for synthetic data generation that rigorously upholdprivacy standards. We introduce DP-Fed-FinDiff framework, a novel integrationof Differential Privacy, Federated Learning and Denoising DiffusionProbabilistic Models designed to generate high-fidelity synthetic tabular data.This framework ensures compliance with stringent privacy regulations whilemaintaining data utility. We demonstrate the effectiveness of DP-Fed-FinDiff onmultiple real-world financial datasets, achieving significant improvements inprivacy guarantees without compromising data quality. Our empirical evaluationsreveal the optimal trade-offs between privacy budgets, client configurations,and federated optimization strategies. The results affirm the potential ofDP-Fed-FinDiff to enable secure data sharing and robust analytics in highlyregulated domains, paving the way for further advances in federated learningand privacy-preserving data synthesis.</description><author>Timur Sattarov, Marco Schreyer, Damian Borth</author><pubDate>Fri, 20 Dec 2024 17:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16083v1</guid></item><item><title>Vision Model Pre-training on Interleaved Image-Text Data via Latent Compression Learning</title><link>http://arxiv.org/abs/2406.07543v2</link><description>Recently, vision model pre-training has evolved from relying on manuallyannotated datasets to leveraging large-scale, web-crawled image-text data.Despite these advances, there is no pre-training method that effectivelyexploits the interleaved image-text data, which is very prevalent on theInternet. Inspired by the recent success of compression learning in naturallanguage processing, we propose a novel vision model pre-training method calledLatent Compression Learning (LCL) for interleaved image-text data. This methodperforms latent compression learning by maximizing the mutual informationbetween the inputs and outputs of a causal attention model. The trainingobjective can be decomposed into two basic tasks: 1) contrastive learningbetween visual representation and preceding context, and 2) generatingsubsequent text based on visual representation. Our experiments demonstratethat our method not only matches the performance of CLIP on paired pre-trainingdatasets (e.g., LAION), but can also leverage interleaved pre-training data(e.g., MMC4) to learn robust visual representation from scratch, showcasing thepotential of vision model pre-training with interleaved image-text data. Codeis released at https://github.com/OpenGVLab/LCL.</description><author>Chenyu Yang, Xizhou Zhu, Jinguo Zhu, Weijie Su, Junjie Wang, Xuan Dong, Wenhai Wang, Lewei Lu, Bin Li, Jie Zhou, Yu Qiao, Jifeng Dai</author><pubDate>Fri, 20 Dec 2024 17:24:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07543v2</guid></item><item><title>Fair Distributed Machine Learning with Imbalanced Data as a Stackelberg Evolutionary Game</title><link>http://arxiv.org/abs/2412.16079v1</link><description>Decentralised learning enables the training of deep learning algorithmswithout centralising data sets, resulting in benefits such as improved dataprivacy, operational efficiency and the fostering of data ownership policies.However, significant data imbalances pose a challenge in this framework.Participants with smaller datasets in distributed learning environments oftenachieve poorer results than participants with larger datasets. Data imbalancesare particularly pronounced in medical fields and are caused by differentpatient populations, technological inequalities and divergent data collectionpractices. In this paper, we consider distributed learning as an Stackelbergevolutionary game. We present two algorithms for setting the weights of eachnode's contribution to the global model in each training round: theDeterministic Stackelberg Weighting Model (DSWM) and the Adaptive StackelbergWeighting Model (ASWM). We use three medical datasets to highlight the impactof dynamic weighting on underrepresented nodes in distributed learning. Ourresults show that the ASWM significantly favours underrepresented nodes byimproving their performance by 2.713% in AUC. Meanwhile, nodes with largerdatasets experience only a modest average performance decrease of 0.441%.</description><author>Sebastian Niehaus, Ingo Roeder, Nico Scherf</author><pubDate>Fri, 20 Dec 2024 17:23:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16079v1</guid></item><item><title>SegCol Challenge: Semantic Segmentation for Tools and Fold Edges in Colonoscopy data</title><link>http://arxiv.org/abs/2412.16078v1</link><description>Colorectal cancer (CRC) remains a leading cause of cancer-related deathsworldwide, with polyp removal being an effective early screening method.However, navigating the colon for thorough polyp detection poses significantchallenges. To advance camera navigation in colonoscopy, we propose theSemantic Segmentation for Tools and Fold Edges in Colonoscopy (SegCol)Challenge. This challenge introduces a dataset from the EndoMapper repository,featuring manually annotated, pixel-level semantic labels for colon folds andendoscopic tools across selected frames from 96 colonoscopy videos. Byproviding fold edges as anatomical landmarks and depth discontinuityinformation from both fold and tool labels, the dataset is aimed to improvedepth perception and localization methods. Hosted as part of the EndovisChallenge at MICCAI 2024, SegCol aims to drive innovation in colonoscopynavigation systems. Details are available athttps://www.synapse.org/Synapse:syn54124209/wiki/626563, and code resources athttps://github.com/surgical-vision/segcol_challenge .</description><author>Xinwei Ju, Rema Daher, Razvan Caramalau, Baoru Huang, Danail Stoyanov, Francisco Vasconcelos</author><pubDate>Fri, 20 Dec 2024 17:21:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16078v1</guid></item><item><title>Formal Mathematical Reasoning: A New Frontier in AI</title><link>http://arxiv.org/abs/2412.16075v1</link><description>AI for Mathematics (AI4Math) is not only intriguing intellectually but alsocrucial for AI-driven discovery in science, engineering, and beyond. Extensiveefforts on AI4Math have mirrored techniques in NLP, in particular, traininglarge language models on carefully curated math datasets in text form. As acomplementary yet less explored avenue, formal mathematical reasoning isgrounded in formal systems such as proof assistants, which can verify thecorrectness of reasoning and provide automatic feedback. In this positionpaper, we advocate for formal mathematical reasoning and argue that it isindispensable for advancing AI4Math to the next level. In recent years, we haveseen steady progress in using AI to perform formal reasoning, including coretasks such as theorem proving and autoformalization, as well as emergingapplications such as verifiable generation of code and hardware designs.However, significant challenges remain to be solved for AI to truly mastermathematics and achieve broader impact. We summarize existing progress, discussopen challenges, and envision critical milestones to measure future success. Atthis inflection point for formal mathematical reasoning, we call on theresearch community to come together to drive transformative advancements inthis field.</description><author>Kaiyu Yang, Gabriel Poesia, Jingxuan He, Wenda Li, Kristin Lauter, Swarat Chaudhuri, Dawn Song</author><pubDate>Fri, 20 Dec 2024 17:19:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16075v1</guid></item><item><title>SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer</title><link>http://arxiv.org/abs/2412.10958v2</link><description>Efficient image tokenization with high compression ratios remains a criticalchallenge for training generative models. We present SoftVQ-VAE, a continuousimage tokenizer that leverages soft categorical posteriors to aggregatemultiple codewords into each latent token, substantially increasing therepresentation capacity of the latent space. When applied to Transformer-basedarchitectures, our approach compresses 256x256 and 512x512 images using as fewas 32 or 64 1-dimensional tokens. Not only does SoftVQ-VAE show consistent andhigh-quality reconstruction, more importantly, it also achievesstate-of-the-art and significantly faster image generation results acrossdifferent denoising-based generative models. Remarkably, SoftVQ-VAE improvesinference throughput by up to 18x for generating 256x256 images and 55x for512x512 images while achieving competitive FID scores of 1.78 and 2.21 forSiT-XL. It also improves the training efficiency of the generative models byreducing the number of training iterations by 2.3x while maintaining comparableperformance. With its fully-differentiable design and semantic-rich latentspace, our experiment demonstrates that SoftVQ-VAE achieves efficienttokenization without compromising generation quality, paving the way for moreefficient generative models. Code and model are released.</description><author>Hao Chen, Ze Wang, Xiang Li, Ximeng Sun, Fangyi Chen, Jiang Liu, Jindong Wang, Bhiksha Raj, Zicheng Liu, Emad Barsoum</author><pubDate>Fri, 20 Dec 2024 16:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10958v2</guid></item><item><title>Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy</title><link>http://arxiv.org/abs/2412.16050v1</link><description>The accurate segmentation of guidewires in interventional cardiac fluoroscopyvideos is crucial for computer-aided navigation tasks. Although deep learningmethods have demonstrated high accuracy and robustness in wire segmentation,they require substantial annotated datasets for generalizability, underscoringthe need for extensive labeled data to enhance model performance. To addressthis challenge, we propose the Segmentation-guided Frame-consistency VideoDiffusion Model (SF-VD) to generate large collections of labeled fluoroscopyvideos, augmenting the training data for wire segmentation networks. SF-VDleverages videos with limited annotations by independently modeling scenedistribution and motion distribution. It first samples the scene distributionby generating 2D fluoroscopy images with wires positioned according to aspecified input mask, and then samples the motion distribution by progressivelygenerating subsequent frames, ensuring frame-to-frame coherence through aframe-consistency strategy. A segmentation-guided mechanism further refines theprocess by adjusting wire contrast, ensuring a diverse range of visibility inthe synthesized image. Evaluation on a fluoroscopy dataset confirms thesuperior quality of the generated videos and shows significant improvements inguidewire segmentation.</description><author>Shaoyan Pan, Yikang Liu, Lin Zhao, Eric Z. Chen, Xiao Chen, Terrence Chen, Shanhui Sun</author><pubDate>Fri, 20 Dec 2024 16:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16050v1</guid></item><item><title>Segmentation of arbitrary features in very high resolution remote sensing imagery</title><link>http://arxiv.org/abs/2412.16046v1</link><description>Very high resolution (VHR) mapping through remote sensing (RS) imagerypresents a new opportunity to inform decision-making and sustainable practicesin countless domains. Efficient processing of big VHR data requires automatedtools applicable to numerous geographic regions and features. Contemporary RSstudies address this challenge by employing deep learning (DL) models forspecific datasets or features, which limits their applicability acrosscontexts. The present research aims to overcome this limitation by introducingEcoMapper, a scalable solution to segment arbitrary features in VHR RS imagery.EcoMapper fully automates processing of geospatial data, DL model training, andinference. Models trained with EcoMapper successfully segmented two distinctfeatures in a real-world UAV dataset, achieving scores competitive with priorstudies which employed context-specific models. To evaluate EcoMapper, many additional models were trained on permutations ofprincipal field survey characteristics (FSCs). A relationship was discoveredallowing derivation of optimal ground sampling distance from feature size,termed Cording Index (CI). A comprehensive methodology for field surveys wasdeveloped to ensure DL methods can be applied effectively to collected data. The EcoMapper code accompanying this work is available athttps://github.com/hcording/ecomapper .</description><author>Henry Cording, Yves Plancherel, Pablo Brito-Parada</author><pubDate>Fri, 20 Dec 2024 16:48:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16046v1</guid></item><item><title>Stealing That Free Lunch: Exposing the Limits of Dyna-Style Reinforcement Learning</title><link>http://arxiv.org/abs/2412.14312v2</link><description>Dyna-style off-policy model-based reinforcement learning (DMBRL) algorithmsare a family of techniques for generating synthetic state transition data andthereby enhancing the sample efficiency of off-policy RL algorithms. This paperidentifies and investigates a surprising performance gap observed when applyingDMBRL algorithms across different benchmark environments with proprioceptiveobservations. We show that, while DMBRL algorithms perform well in OpenAI Gym,their performance can drop significantly in DeepMind Control Suite (DMC), eventhough these settings offer similar tasks and identical physics backends.Modern techniques designed to address several key issues that arise in thesesettings do not provide a consistent improvement across all environments, andoverall our results show that adding synthetic rollouts to the training process-- the backbone of Dyna-style algorithms -- significantly degrades performanceacross most DMC environments. Our findings contribute to a deeper understandingof several fundamental challenges in model-based RL and show that, like manyoptimization fields, there is no free lunch when evaluating performance acrossdiverse benchmarks in RL.</description><author>Brett Barkley, David Fridovich-Keil</author><pubDate>Fri, 20 Dec 2024 16:43:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14312v2</guid></item><item><title>SafeCFG: Redirecting Harmful Classifier-Free Guidance for Safe Generation</title><link>http://arxiv.org/abs/2412.16039v1</link><description>Diffusion models (DMs) have demonstrated exceptional performance intext-to-image (T2I) tasks, leading to their widespread use. With theintroduction of classifier-free guidance (CFG), the quality of images generatedby DMs is improved. However, DMs can generate more harmful images bymaliciously guiding the image generation process through CFG. Some safeguidance methods aim to mitigate the risk of generating harmful images butoften reduce the quality of clean image generation. To address this issue, weintroduce the Harmful Guidance Redirector (HGR), which redirects harmful CFGdirection while preserving clean CFG direction during image generation,transforming CFG into SafeCFG and achieving high safety and quality generation.We train HGR to redirect multiple harmful CFG directions simultaneously,demonstrating its ability to eliminate various harmful elements whilepreserving high-quality generation. Additionally, we find that HGR can detectimage harmfulness, allowing for unsupervised fine-tuning of safe diffusionmodels without pre-defined clean or harmful labels. Experimental results showthat by incorporating HGR, images generated by diffusion models achieve bothhigh quality and strong safety, and safe DMs trained through unsupervisedmethods according to the harmfulness detected by HGR also exhibit good safetyperformance. The codes will be publicly available.</description><author>Jiadong Pan, Hongcheng Gao, Liang Li, Zheng-Jun Zha, Qingming Huang, Jiebo Luo</author><pubDate>Fri, 20 Dec 2024 16:40:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16039v1</guid></item><item><title>Applying Predictive Analytics to Occupational Health and Safety in India</title><link>http://arxiv.org/abs/2412.16038v1</link><description>Predictive analytics is revolutionizing occupational health and safety (OHS).It offers evidence-based insights. These insights enable proactive riskmanagement and informed, data-driven decision-making in organizationalsettings. This paper explores the key components of predictive analytics inOHS, beginning with data collection, management, and preparation, and movingthrough to advanced predictive modelling techniques. We emphasize theimportance of data integrity through processes such as missing valueimputation, anomaly detection, and feature engineering to ensure accurate modelpredictions. Risk prioritization identifies and ranks hazards across variousfactors, including employee behaviours, organizational policies, environmentalconditions, and operational practices. We posit that insights derived frompredictive models must be effectively interpreted and implemented. Theseinsights guide organizations to focus on high-impact areas for accidentprevention and resource optimization. The integration of predictive analyticsin OHS brings notable benefits, including enhanced decision-making, greateroperational efficiency, cost savings, and improved compliance with safetystandards. We examine applications of predictive analytics in OHS in Indiansettings. India has the largest workforce in the world, and the predominance ofit is in the informal sector - a sector largely unprotected by the alreadyinadequate OHS laws. Ethical considerations, data privacy concerns, and therisk of overdependence on predictive models are discussed. We conclude with adiscussion on the potential for predictive analytics to create a data-oriented,adaptive approach to OHS in India. We posit that, using predictive analytics,India can develop high safety standards while traversing the complexities ofits workforce setting.</description><author>Ritwik Raj Saxena</author><pubDate>Fri, 20 Dec 2024 16:39:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16038v1</guid></item><item><title>A Framework for Streaming Event-Log Prediction in Business Processes</title><link>http://arxiv.org/abs/2412.16032v1</link><description>We present a Python-based framework for event-log prediction in streamingmode, enabling predictions while data is being generated by a business process.The framework allows for easy integration of streaming algorithms, includinglanguage models like n-grams and LSTMs, and for combining these predictorsusing ensemble methods. Using our framework, we conducted experiments on various well-knownprocess-mining data sets and compared classical batch with streaming mode.Though, in batch mode, LSTMs generally achieve the best performance, there isoften an n-gram whose accuracy comes very close. Combining basic models inensemble methods can even outperform LSTMs. The value of basic models withrespect to LSTMs becomes even more apparent in streaming mode, where LSTMsgenerally lack accuracy in the early stages of a prediction run, while basicmethods make sensible predictions immediately.</description><author>Benedikt Bollig, Matthias Függer, Thomas Nowak</author><pubDate>Fri, 20 Dec 2024 16:29:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16032v1</guid></item><item><title>Magnetic Preference Optimization: Achieving Last-iterate Convergence for Language Model Alignment</title><link>http://arxiv.org/abs/2410.16714v2</link><description>Self-play methods have demonstrated remarkable success in enhancing modelcapabilities across various domains. In the context of Reinforcement Learningfrom Human Feedback (RLHF), self-play not only boosts Large Language Model(LLM) performance but also overcomes the limitations of traditionalBradley-Terry (BT) model assumptions by finding the Nash equilibrium (NE) of apreference-based, two-player constant-sum game. However, existing methodseither guarantee only average-iterate convergence, incurring high storage andinference costs, or converge to the NE of a regularized game, failing toaccurately reflect true human preferences. In this paper, we introduce MagneticPreference Optimization (MPO), a novel approach capable of achievinglast-iterate convergence to the NE of the original game, effectively overcomingthe limitations of existing methods. Building upon Magnetic Mirror Descent(MMD), MPO attains a linear convergence rate, making it particularly suitablefor fine-tuning LLMs. To ensure our algorithm is both theoretically sound andpractically viable, we present a simple yet effective implementation thatadapts the theoretical insights to the RLHF setting. Empirical resultsdemonstrate that MPO can significantly enhance the performance of LLMs,highlighting the potential of self-play methods in alignment.</description><author>Mingzhi Wang, Chengdong Ma, Qizhi Chen, Linjian Meng, Yang Han, Jiancong Xiao, Zhaowei Zhang, Jing Huo, Weijie J. Su, Yaodong Yang</author><pubDate>Fri, 20 Dec 2024 16:26:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16714v2</guid></item><item><title>Learning sparsity-promoting regularizers for linear inverse problems</title><link>http://arxiv.org/abs/2412.16031v1</link><description>This paper introduces a novel approach to learning sparsity-promotingregularizers for solving linear inverse problems. We develop a bileveloptimization framework to select an optimal synthesis operator, denoted as $B$,which regularizes the inverse problem while promoting sparsity in the solution.The method leverages statistical properties of the underlying data andincorporates prior knowledge through the choice of $B$. We establish thewell-posedness of the optimization problem, provide theoretical guarantees forthe learning process, and present sample complexity bounds. The approach isdemonstrated through examples, including compact perturbations of a knownoperator and the problem of learning the mother wavelet, showcasing itsflexibility in incorporating prior knowledge into the regularization framework.This work extends previous efforts in Tikhonov regularization by addressingnon-differentiable norms and proposing a data-driven approach for sparseregularization in infinite dimensions.</description><author>Giovanni S. Alberti, Ernesto De Vito, Tapio Helin, Matti Lassas, Luca Ratti, Matteo Santacesaria</author><pubDate>Fri, 20 Dec 2024 16:26:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16031v1</guid></item><item><title>CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images</title><link>http://arxiv.org/abs/2412.16028v1</link><description>3D Gaussian Splatting (3DGS) has attracted significant attention for itshigh-quality novel view rendering, inspiring research to address real-worldchallenges. While conventional methods depend on sharp images for accuratescene reconstruction, real-world scenarios are often affected by defocus blurdue to finite depth of field, making it essential to account for realistic 3Dscene representation. In this study, we propose CoCoGaussian, a Circle ofConfusion-aware Gaussian Splatting that enables precise 3D scene representationusing only defocused images. CoCoGaussian addresses the challenge of defocusblur by modeling the Circle of Confusion (CoC) through a physically groundedapproach based on the principles of photographic defocus. Exploiting 3DGaussians, we compute the CoC diameter from depth and learnable apertureinformation, generating multiple Gaussians to precisely capture the CoC shape.Furthermore, we introduce a learnable scaling factor to enhance robustness andprovide more flexibility in handling unreliable depth in scenes with reflectiveor refractive surfaces. Experiments on both synthetic and real-world datasetsdemonstrate that CoCoGaussian achieves state-of-the-art performance acrossmultiple benchmarks.</description><author>Jungho Lee, Suhwan Cho, Taeoh Kim, Ho-Deok Jang, Minhyeok Lee, Geonho Cha, Dongyoon Wee, Dogyoon Lee, Sangyoun Lee</author><pubDate>Fri, 20 Dec 2024 16:25:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16028v1</guid></item><item><title>Language Models Resist Alignment: Evidence From Data Compression</title><link>http://arxiv.org/abs/2406.06144v3</link><description>Large language models (LLMs) may exhibit unintended or undesirable behaviors.Recent works have concentrated on aligning LLMs to mitigate harmful outputs.Despite these efforts, some anomalies indicate that even a well-conductedalignment process can be easily circumvented, whether intentionally oraccidentally. Does alignment fine-tuning yield have robust effects on models,or are its impacts merely superficial? In this work, we make the firstexploration of this phenomenon from both theoretical and empiricalperspectives. Empirically, we demonstrate the elasticity of post-alignmentmodels, i.e., the tendency to revert to the behavior distribution formed duringthe pre-training phase upon further fine-tuning. Leveraging compression theory,we formally deduce that fine-tuning disproportionately undermines alignmentrelative to pre-training, potentially by orders of magnitude. We validate thepresence of elasticity through experiments on models of varying types andscales. Specifically, we find that model performance declines rapidly beforereverting to the pre-training distribution, after which the rate of declinedrops significantly. Furthermore, we further reveal that elasticity positivelycorrelates with the increased model size and the expansion of pre-trainingdata. Our findings underscore the need to address the inherent elasticity ofLLMs to mitigate their resistance to alignment.</description><author>Jiaming Ji, Kaile Wang, Tianyi Qiu, Boyuan Chen, Jiayi Zhou, Changye Li, Hantao Lou, Josef Dai, Yunhuai Liu, Yaodong Yang</author><pubDate>Fri, 20 Dec 2024 16:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06144v3</guid></item><item><title>Learning Temporally Equivariance for Degenerative Disease Progression in OCT by Predicting Future Representations</title><link>http://arxiv.org/abs/2405.09404v3</link><description>Contrastive pretraining provides robust representations by ensuring theirinvariance to different image transformations while simultaneously preventingrepresentational collapse. Equivariant contrastive learning, on the other hand,provides representations sensitive to specific image transformations whileremaining invariant to others. By introducing equivariance to time-inducedtransformations, such as disease-related anatomical changes in longitudinalimaging, the model can effectively capture such changes in the representationspace. In this work, we propose a Time-equivariant Contrastive Learning (TC)method. First, an encoder embeds two unlabeled scans from different time pointsof the same patient into the representation space. Next, a temporalequivariance module is trained to predict the representation of a later visitbased on the representation from one of the previous visits and thecorresponding time interval with a novel regularization loss term whilepreserving the invariance property to irrelevant image transformations. On alarge longitudinal dataset, our model clearly outperforms existing equivariantcontrastive methods in predicting progression from intermediate age-relatedmacular degeneration (AMD) to advanced wet-AMD within a specified time-window.</description><author>Taha Emre, Arunava Chakravarty, Dmitrii Lachinov, Antoine Rivail, Ursula Schmidt-Erfurth, Hrvoje Bogunović</author><pubDate>Fri, 20 Dec 2024 16:19:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09404v3</guid></item><item><title>A Modern Take on Visual Relationship Reasoning for Grasp Planning</title><link>http://arxiv.org/abs/2409.02035v2</link><description>Interacting with real-world cluttered scenes pose several challenges torobotic agents that need to understand complex spatial dependencies among theobserved objects to determine optimal pick sequences or efficient objectretrieval strategies. Existing solutions typically manage simplified scenariosand focus on predicting pairwise object relationships following an initialobject detection phase, but often overlook the global context or struggle withhandling redundant and missing object relations. In this work, we present amodern take on visual relational reasoning for grasp planning. We introduceD3GD, a novel testbed that includes bin picking scenes with up to 35 objectsfrom 97 distinct categories. Additionally, we propose D3G, a new end-to-endtransformer-based dependency graph generation model that simultaneously detectsobjects and produces an adjacency matrix representing their spatialrelationships. Recognizing the limitations of standard metrics, we employ theAverage Precision of Relationships for the first time to evaluate modelperformance, conducting an extensive experimental benchmark. The obtainedresults establish our approach as the new state-of-the-art for this task,laying the foundation for future research in robotic manipulation. We publiclyrelease the code and dataset at https://paolotron.github.io/d3g.github.io.</description><author>Paolo Rabino, Tatiana Tommasi</author><pubDate>Fri, 20 Dec 2024 16:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.02035v2</guid></item><item><title>Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models</title><link>http://arxiv.org/abs/2410.19732v2</link><description>Large Vision-Language Models (LVLMs) excel in cross-model tasks butexperience performance declines in long-context reasoning due to overrelianceon textual information and reduced visual dependency. In this study, weempirically analyze LVLMs in long-context reasoning, revealing that increasedcontext length leads to a higher dependence on language at the expense ofvisual dependency. To address this issue, we propose a novel training-freecontext pruning method that selectively removes less critical textualinformation. Our approach enhances visual dependency and reduces textual noise,thereby improving LVLM performance in long-context reasoning. We validate ourmethod by constructing a long-context dataset, demonstrating its effectivenessacross various LVLMs. Moreover, further analysis confirms the robustness ofdifferent token pruning strategies and preliminary explores scaling lawsbetween pruning rates and context length.</description><author>Yucheng Zhou, Zhi Rao, Jun Wan, Jianbing Shen</author><pubDate>Fri, 20 Dec 2024 16:19:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19732v2</guid></item><item><title>BMRS: Bayesian Model Reduction for Structured Pruning</title><link>http://arxiv.org/abs/2406.01345v2</link><description>Modern neural networks are often massively overparameterized leading to highcompute costs during training and at inference. One effective method to improveboth the compute and energy efficiency of neural networks while maintaininggood performance is structured pruning, where full network structures(e.g.~neurons or convolutional filters) that have limited impact on the modeloutput are removed. In this work, we propose Bayesian Model Reduction forStructured pruning (BMRS), a fully end-to-end Bayesian method of structuredpruning. BMRS is based on two recent methods: Bayesian structured pruning withmultiplicative noise, and Bayesian model reduction (BMR), a method which allowsefficient comparison of Bayesian models under a change in prior. We present tworealizations of BMRS derived from different priors which yield differentstructured pruning characteristics: 1) BMRS_N with the truncated log-normalprior, which offers reliable compression rates and accuracy without the needfor tuning any thresholds and 2) BMRS_U with the truncated log-uniform priorthat can achieve more aggressive compression based on the boundaries oftruncation. Overall, we find that BMRS offers a theoretically grounded approachto structured pruning of neural networks yielding both high compression ratesand accuracy. Experiments on multiple datasets and neural networks of varyingcomplexity showed that the two BMRS methods offer a competitiveperformance-efficiency trade-off compared to other pruning methods.</description><author>Dustin Wright, Christian Igel, Raghavendra Selvan</author><pubDate>Fri, 20 Dec 2024 16:18:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01345v2</guid></item><item><title>Semantic Role Labeling of NomBank Partitives</title><link>http://arxiv.org/abs/2412.14328v2</link><description>This article is about Semantic Role Labeling for English partitive nouns(5%/REL of the price/ARG1; The price/ARG1 rose 5 percent/REL) in the NomBankannotated corpus. Several systems are described using traditional andtransformer-based machine learning, as well as ensembling. Our highest scoringsystem achieves an F1 of 91.74% using "gold" parses from the Penn Treebank and91.12% when using the Berkeley Neural parser. This research includes bothclassroom and experimental settings for system development.</description><author>Adam Meyers, Advait Pravin Savant, John E. Ortega</author><pubDate>Fri, 20 Dec 2024 16:17:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14328v2</guid></item><item><title>The Only Way is Ethics: A Guide to Ethical Research with Large Language Models</title><link>http://arxiv.org/abs/2412.16022v1</link><description>There is a significant body of work looking at the ethical considerations oflarge language models (LLMs): critiquing tools to measure performance andharms; proposing toolkits to aid in ideation; discussing the risks to workers;considering legislation around privacy and security etc. As yet there is nowork that integrates these resources into a single practical guide that focuseson LLMs; we attempt this ambitious goal. We introduce 'LLM Ethics Whitepaper',which we provide as an open and living resource for NLP practitioners, andthose tasked with evaluating the ethical implications of others' work. Our goalis to translate ethics literature into concrete recommendations andprovocations for thinking with clear first steps, aimed at computer scientists.'LLM Ethics Whitepaper' distils a thorough literature review into clear Do'sand Don'ts, which we present also in this paper. We likewise identify usefultoolkits to support ethical work. We refer the interested reader to the fullLLM Ethics Whitepaper, which provides a succinct discussion of ethicalconsiderations at each stage in a project lifecycle, as well as citations forthe hundreds of papers from which we drew our recommendations. The presentpaper can be thought of as a pocket guide to conducting ethical research withLLMs.</description><author>Eddie L. Ungless, Nikolas Vitsakis, Zeerak Talat, James Garforth, Björn Ross, Arno Onken, Atoosa Kasirzadeh, Alexandra Birch</author><pubDate>Fri, 20 Dec 2024 16:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16022v1</guid></item><item><title>Autonomous Driving Small-Scale Cars: A Survey of Recent Development</title><link>http://arxiv.org/abs/2404.06229v2</link><description>While engaging with the unfolding revolution in autonomous driving, achallenge presents itself, how can we effectively raise awareness withinsociety about this transformative trend? While full-scale autonomous drivingvehicles often come with a hefty price tag, the emergence of small-scale carplatforms offers a compelling alternative. These platforms not only serve asvaluable educational tools for the broader public and young generations butalso function as robust research platforms, contributing significantly to theongoing advancements in autonomous driving technology. This survey outlinesvarious small-scale car platforms, categorizing them and detailing the researchadvancements accomplished through their usage. The conclusion providesproposals for promising future directions in the field.</description><author>Dianzhao Li, Paul Auerbach, Ostap Okhrin</author><pubDate>Fri, 20 Dec 2024 16:10:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06229v2</guid></item><item><title>A study on the adequacy of common IQA measures for medical images</title><link>http://arxiv.org/abs/2405.19224v4</link><description>Image quality assessment (IQA) is standard practice in the development stageof novel machine learning algorithms that operate on images. The most commonlyused IQA measures have been developed and tested for natural images, but not inthe medical setting. Reported inconsistencies arising in medical images are notsurprising, as they have different properties than natural images. In thisstudy, we test the applicability of common IQA measures for medical image databy comparing their assessment to manually rated chest X-ray (5 experts) andphotoacoustic image data (2 experts). Moreover, we include supplementarystudies on grayscale natural images and accelerated brain MRI data. The resultsof all experiments show a similar outcome in line with previous findings formedical images: PSNR and SSIM in the default setting are in the lower range ofthe result list and HaarPSI outperforms the other tested measures in theoverall performance. Also among the top performers in our experiments are thefull reference measures FSIM, LPIPS and MS-SSIM. Generally, the results onnatural images yield considerably higher correlations, suggesting thatadditional employment of tailored IQA measures for medical imaging algorithmsis needed.</description><author>Anna Breger, Clemens Karner, Ian Selby, Janek Gröhl, Sören Dittmer, Edward Lilley, Judith Babar, Jake Beckford, Thomas R Else, Timothy J Sadler, Shahab Shahipasand, Arthikkaa Thavakumar, Michael Roberts, Carola-Bibiane Schönlieb</author><pubDate>Fri, 20 Dec 2024 16:04:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19224v4</guid></item><item><title>Experience of Training a 1.7B-Parameter LLaMa Model From Scratch</title><link>http://arxiv.org/abs/2412.13335v2</link><description>Pretraining large language models is a complex endeavor influenced bymultiple factors, including model architecture, data quality, trainingcontinuity, and hardware constraints. In this paper, we share insights gainedfrom the experience of training DMaS-LLaMa-Lite, a fully open source,1.7-billion-parameter, LLaMa-based model, on approximately 20 billion tokens ofcarefully curated data. We chronicle the full training trajectory, documentinghow evolving validation loss levels and downstream benchmarks reflecttransitions from incoherent text to fluent, contextually grounded output.Beyond pretraining, we extend our analysis to include a post-training phasefocused on instruction tuning, where the model was refined to produce morecontextually appropriate, user-aligned responses. We highlight practicalconsiderations such as the importance of restoring optimizer states whenresuming from checkpoints, and the impact of hardware changes on trainingstability and throughput. While qualitative evaluation provides an intuitiveunderstanding of model improvements, our analysis extends to variousperformance benchmarks, demonstrating how high-quality data and thoughtfulscaling enable competitive results with significantly fewer training tokens. Bydetailing these experiences and offering training logs, checkpoints, and sampleoutputs, we aim to guide future researchers and practitioners in refining theirpretraining strategies. The training script is available on Github athttps://github.com/McGill-DMaS/DMaS-LLaMa-Lite-Training-Code. The modelcheckpoints are available on Huggingface athttps://huggingface.co/collections/McGill-DMaS/dmas-llama-lite-6761d97ba903f82341954ceb.</description><author>Miles Q. Li, Benjamin C. M. Fung, Shih-Chia Huang</author><pubDate>Fri, 20 Dec 2024 16:00:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13335v2</guid></item><item><title>Gauss-Newton Dynamics for Neural Networks: A Riemannian Optimization Perspective</title><link>http://arxiv.org/abs/2412.14031v3</link><description>We analyze the convergence of Gauss-Newton dynamics for training neuralnetworks with smooth activation functions. In the underparameterized regime,the Gauss-Newton gradient flow induces a Riemannian gradient flow on alow-dimensional, smooth, embedded submanifold of the Euclidean output space.Using tools from Riemannian optimization, we prove \emph{last-iterate}convergence of the Riemannian gradient flow to the optimal in-class predictorat an \emph{exponential rate} that is independent of the conditioning of theGram matrix, \emph{without} requiring explicit regularization. We furthercharacterize the critical impacts of the neural network scaling factor and theinitialization on the convergence behavior. In the overparameterized regime, weshow that the Levenberg-Marquardt dynamics with an appropriately chosen dampingfactor yields robustness to ill-conditioned kernels, analogous to theunderparameterized regime. These findings demonstrate the potential ofGauss-Newton methods for efficiently optimizing neural networks, particularlyin ill-conditioned problems where kernel and Gram matrices have small singularvalues.</description><author>Semih Cayci</author><pubDate>Fri, 20 Dec 2024 15:58:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14031v3</guid></item><item><title>All-in-One Tuning and Structural Pruning for Domain-Specific LLMs</title><link>http://arxiv.org/abs/2412.14426v2</link><description>Existing pruning techniques for large language models (LLMs) targetingdomain-specific applications typically follow a two-stage process: pruning thepretrained general-purpose LLMs and then fine-tuning the pruned LLMs onspecific domains. However, the pruning decisions, derived from the pretrainedweights, remain unchanged during fine-tuning, even if the weights have beenupdated. Therefore, such a combination of the pruning decisions and thefinetuned weights may be suboptimal, leading to non-negligible performancedegradation. To address these limitations, we propose ATP: All-in-One Tuningand Structural Pruning, a unified one-stage structural pruning and fine-tuningapproach that dynamically identifies the current optimal substructurethroughout the fine-tuning phase via a trainable pruning decision generator.Moreover, given the limited available data for domain-specific applications,Low-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. InATP, we introduce LoRA-aware forward and sparsity regularization to ensure thatthe substructures corresponding to the learned pruning decisions can bedirectly removed after the ATP process. ATP outperforms the state-of-the-arttwo-stage pruning methods on tasks in the legal and healthcare domains. Morespecifically, ATP recovers up to 88% and 91% performance of the dense modelwhen pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.</description><author>Lei Lu, Zhepeng Wang, Runxue Bao, Mengbing Wang, Fangyi Li, Yawen Wu, Weiwen Jiang, Jie Xu, Yanzhi Wang, Shangqian Gao</author><pubDate>Fri, 20 Dec 2024 15:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14426v2</guid></item><item><title>Choose Your Explanation: A Comparison of SHAP and GradCAM in Human Activity Recognition</title><link>http://arxiv.org/abs/2412.16003v1</link><description>Explaining machine learning (ML) models using eXplainable AI (XAI) techniqueshas become essential to make them more transparent and trustworthy. This isespecially important in high-stakes domains like healthcare, whereunderstanding model decisions is critical to ensure ethical, sound, andtrustworthy outcome predictions. However, users are often confused about whichexplanability method to choose for their specific use case. We present acomparative analysis of widely used explainability methods, Shapley AdditiveExplanations (SHAP) and Gradient-weighted Class Activation Mapping (GradCAM),within the domain of human activity recognition (HAR) utilizing graphconvolutional networks (GCNs). By evaluating these methods on skeleton-baseddata from two real-world datasets, including a healthcare-critical cerebralpalsy (CP) case, this study provides vital insights into both approaches'strengths, limitations, and differences, offering a roadmap for selecting themost appropriate explanation method based on specific models and applications.We quantitatively and quantitatively compare these methods, focusing on featureimportance ranking, interpretability, and model sensitivity throughperturbation experiments. While SHAP provides detailed input featureattribution, GradCAM delivers faster, spatially oriented explanations, makingboth methods complementary depending on the application's requirements. Giventhe importance of XAI in enhancing trust and transparency in ML models,particularly in sensitive environments like healthcare, our researchdemonstrates how SHAP and GradCAM could complement each other to provide moreinterpretable and actionable model explanations.</description><author>Felix Tempel, Daniel Groos, Espen Alexander F. Ihlen, Lars Adde, Inga Strümke</author><pubDate>Fri, 20 Dec 2024 15:53:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16003v1</guid></item><item><title>Single Exposure Quantitative Phase Imaging with a Conventional Microscope using Diffusion Models</title><link>http://arxiv.org/abs/2406.04388v2</link><description>Phase imaging is gaining importance due to its applications in fields likebiomedical imaging and material characterization. In biomedical applications,it can provide quantitative information missing in label-free microscopymodalities. One of the most prominent methods in phase quantification is theTransport-of-Intensity Equation (TIE). TIE often requires multiple acquisitionsat different defocus distances, which is not always feasible in a clinicalsetting. To address this issue, we propose to use chromatic aberrations toinduce the required through-focus images with a single exposure, effectivelygenerating a through-focus stack. Since the defocus distance induced by theaberrations is small, conventional TIE solvers are insufficient to address theresulting artifacts. We propose Zero-Mean Diffusion, a modified version ofdiffusion models designed for quantitative image prediction, and train it withsynthetic data to ensure robust phase retrieval. Our contributions offer analternative TIE approach that leverages chromatic aberrations, achievingaccurate single-exposure phase measurement with white light and thus improvingthe efficiency of phase imaging. Moreover, we present a new class of diffusionmodels that are well-suited for quantitative data and have a sound theoreticalbasis. To validate our approach, we employ a widespread brightfield microscopeequipped with a commercially available color camera. We apply our model toclinical microscopy of patients' urine, obtaining accurate phase measurements.</description><author>Gabriel della Maggiora, Luis Alberto Croquevielle, Harry Horsley, Thomas Heinis, Artur Yakimovich</author><pubDate>Fri, 20 Dec 2024 15:49:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04388v2</guid></item><item><title>Sims: An Interactive Tool for Geospatial Matching and Clustering</title><link>http://arxiv.org/abs/2412.10184v2</link><description>Acquiring, processing, and visualizing geospatial data requires significantcomputing resources, especially for large spatio-temporal domains. Thischallenge hinders the rapid discovery of predictive features, which isessential for advancing geospatial modeling. To address this, we developedSimilarity Search (Sims), a no-code web tool that allows users to performclustering and similarity search over defined regions of interest using GoogleEarth Engine as a backend. Sims is designed to complement existing modelingtools by focusing on feature exploration rather than model creation. Wedemonstrate the utility of Sims through a case study analyzing simulated maizeyield data in Rwanda, where we evaluate how different combinations of soil,weather, and agronomic features affect the clustering of yield response zones.Sims is open source and available at https://github.com/microsoft/Sims</description><author>Akram Zaytar, Girmaw Abebe Tadesse, Caleb Robinson, Eduardo G. Bendito, Medha Devare, Meklit Chernet, Gilles Q. Hacheme, Rahul Dodhia, Juan M. Lavista Ferres</author><pubDate>Fri, 20 Dec 2024 15:49:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10184v2</guid></item><item><title>CNN-LSTM Hybrid Deep Learning Model for Remaining Useful Life Estimation</title><link>http://arxiv.org/abs/2412.15998v1</link><description>Remaining Useful Life (RUL) of a component or a system is defined as thelength from the current time to the end of the useful life. Accurate RULestimation plays a crucial role in Predictive Maintenance applications.Traditional regression methods, both linear and non-linear, have struggled toachieve high accuracy in this domain. While Convolutional Neural Networks(CNNs) have shown improved accuracy, they often overlook the sequential natureof the data, relying instead on features derived from sliding windows. SinceRUL prediction inherently involves multivariate time series analysis, robustsequence learning is essential. In this work, we propose a hybrid approachcombining Convolutional Neural Networks with Long Short-Term Memory (LSTM)networks for RUL estimation. Although CNN-based LSTM models have been appliedto sequence prediction tasks in financial forecasting, this is the firstattempt to adopt this approach for RUL estimation in prognostics. In thisapproach, CNN is first employed to efficiently extract features from the data,followed by LSTM, which uses these extracted features to predict RUL. Thismethod effectively leverages sensor sequence information, uncovering hiddenpatterns within the data, even under multiple operating conditions and faultscenarios. Our results demonstrate that the hybrid CNN-LSTM model achieves thehighest accuracy, offering a superior score compared to the other methods.</description><author>Muthukumar G, Jyosna Philip</author><pubDate>Fri, 20 Dec 2024 15:48:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15998v1</guid></item><item><title>Data-Centric Improvements for Enhancing Multi-Modal Understanding in Spoken Conversation Modeling</title><link>http://arxiv.org/abs/2412.15995v1</link><description>Conversational assistants are increasingly popular across diverse real-worldapplications, highlighting the need for advanced multimodal speech modeling.Speech, as a natural mode of communication, encodes rich user-specificcharacteristics such as speaking rate and pitch, making it critical foreffective interaction. Our work introduces a data-centric customizationapproach for efficiently enhancing multimodal understanding in conversationalspeech modeling. Central to our contributions is a novel multi-task learningparadigm that involves designing auxiliary tasks to utilize a small amount ofspeech data. Our approach achieves state-of-the-art performance on theSpoken-SQuAD benchmark, using only 10% of the training data with open-weightmodels, establishing a robust and efficient framework for audio-centricconversational modeling. We also introduce ASK-QA, the first dataset formulti-turn spoken dialogue with ambiguous user requests and dynamic evaluationinputs. Code and data forthcoming.</description><author>Maximillian Chen, Ruoxi Sun, Sercan Ö. Arık</author><pubDate>Fri, 20 Dec 2024 15:43:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15995v1</guid></item><item><title>Fearful Falcons and Angry Llamas: Emotion Category Annotations of Arguments by Humans and LLMs</title><link>http://arxiv.org/abs/2412.15993v1</link><description>Arguments evoke emotions, influencing the effect of the argument itself. Notonly the emotional intensity but also the category influence the argument'seffects, for instance, the willingness to adapt stances. While binaryemotionality has been studied in arguments, there is no work on discreteemotion categories (e.g., "Anger") in such data. To fill this gap, wecrowdsource subjective annotations of emotion categories in a German argumentcorpus and evaluate automatic LLM-based labeling methods. Specifically, wecompare three prompting strategies (zero-shot, one-shot, chain-of-thought) onthree large instruction-tuned language models (Falcon-7b-instruct,Llama-3.1-8B-instruct, GPT-4o-mini). We further vary the definition of theoutput space to be binary (is there emotionality in the argument?),closed-domain (which emotion from a given label set is in the argument?), oropen-domain (which emotion is in the argument?). We find that emotioncategories enhance the prediction of emotionality in arguments, emphasizing theneed for discrete emotion annotations in arguments. Across all prompt settingsand models, automatic predictions show a high recall but low precision forpredicting anger and fear, indicating a strong bias toward negative emotions.</description><author>Lynn Greschner, Roman Klinger</author><pubDate>Fri, 20 Dec 2024 15:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15993v1</guid></item><item><title>APIRL: Deep Reinforcement Learning for REST API Fuzzing</title><link>http://arxiv.org/abs/2412.15991v1</link><description>REST APIs have become key components of web services. However, they oftencontain logic flaws resulting in server side errors or securityvulnerabilities. HTTP requests are used as test cases to find and mitigate suchissues. Existing methods to modify requests, including those using deeplearning, suffer from limited performance and precision, relying on undirectedsearch or making limited usage of the contextual information. In this paper wepropose APIRL, a fully automated deep reinforcement learning tool for testingREST APIs. A key novelty of our approach is the use of feedback from atransformer module pre-trained on JSON-structured data, akin to that used inAPI responses. This allows APIRL to learn the subtleties relating to testoutcomes, and generalise to unseen API endpoints. We show APIRL can findsignificantly more bugs than the state-of-the-art in real world REST APIs whileminimising the number of required test cases. We also study how rewardfunctions, and other key design choices, affect learnt policies in a thoroughablation study.</description><author>Myles Foley, Sergio Maffeis</author><pubDate>Fri, 20 Dec 2024 15:40:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15991v1</guid></item><item><title>The Clear Sky Corridor: Insights Towards Aerosol Formation in Exoplanets Using An AI-based Survey of Exoplanet Atmospheres</title><link>http://arxiv.org/abs/2410.06804v2</link><description>Producing optimized and accurate transmission spectra of exoplanets fromtelescope data has traditionally been a manual and labor-intensive procedure.Here we present the results of the first attempt to improve and standardizethis procedure using artificial intelligence (AI) based processing of lightcurves and spectroscopic data from transiting exoplanets observed with theHubble Space Telescope's (HST) Wide Field Camera 3 (WFC3) instrument. Weimplement an AI-based parameter optimizer that autonomously operates the Eurekapipeline to produce homogeneous transmission spectra of publicly available HSTWFC3 datasets, spanning exoplanet types from hot Jupiters to sub-Neptunes.Surveying 42 exoplanets with temperatures between 280 and 2580 Kelvin, weconfirm modeled relationships between the amplitude of the water band at 1.4umin hot Jupiters and their equilibrium temperatures. We also identify a similar,novel trend in Neptune/sub-Neptune atmospheres, but shifted to coolertemperatures. Excitingly, a planet mass versus equilibrium temperature diagramreveals a "Clear Sky Corridor," where planets between 700 and 1700 Kelvin(depending on the mass) show stronger 1.4um H2O band measurements. This noveltrend points to metallicity as a potentially important driver of aerosolformation. As we unveil and include these new discoveries into ourunderstanding of aerosol formation, we enter a thrilling future for the studyof exoplanet atmospheres. With HST sculpting this foundational understandingfor aerosol formation in various exoplanet types, ranging from Jupiters tosub-Neptunes, we present a compelling platform for the James Webb SpaceTelescope (JWST) to discover similar atmospheric trends for more planets acrossa broader wavelength range.</description><author>Reza Ashtari, Kevin B. Stevenson, David Sing, Mercedes Lopez-Morales, Munazza K. Alam, Nikolay K. Nikolov, Thomas M. Evans-Soma</author><pubDate>Fri, 20 Dec 2024 15:29:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06804v2</guid></item><item><title>Learning Low Degree Hypergraphs</title><link>http://arxiv.org/abs/2202.09989v3</link><description>We study the problem of learning a hypergraph via edge detecting queries. Inthis problem, a learner queries subsets of vertices of a hidden hypergraph andobserves whether these subsets contain an edge or not. In general, learning ahypergraph with $m$ edges of maximum size $d$ requires $\Omega((2m/d)^{d/2})$queries. In this paper, we aim to identify families of hypergraphs that can belearned without suffering from a query complexity that grows exponentially inthe size of the edges. We show that hypermatchings and low-degree near-uniform hypergraphs with $n$vertices are learnable with poly$(n)$ queries. For learning hypermatchings(hypergraphs of maximum degree $ 1$), we give an $O(\log^3 n)$-round algorithmwith $O(n \log^5 n)$ queries. We complement this upper bound by showing thatthere are no algorithms with poly$(n)$ queries that learn hypermatchings in$o(\log \log n)$ adaptive rounds. For hypergraphs with maximum degree $\Delta$and edge size ratio $\rho$, we give a non-adaptive algorithm with $O((2n)^{\rho\Delta+1}\log^2 n)$ queries. To the best of our knowledge, these are the firstalgorithms with poly$(n, m)$ query complexity for learning non-trivial familiesof hypergraphs that have a super-constant number of edges of super-constantsize.</description><author>Eric Balkanski, Oussama Hanguir, Shatian Wang</author><pubDate>Fri, 20 Dec 2024 15:29:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.09989v3</guid></item><item><title>Augment then Smooth: Reconciling Differential Privacy with Certified Robustness</title><link>http://arxiv.org/abs/2306.08656v3</link><description>Machine learning models are susceptible to a variety of attacks that canerode trust, including attacks against the privacy of training data, andadversarial examples that jeopardize model accuracy. Differential privacy andcertified robustness are effective frameworks for combating these two threatsrespectively, as they each provide future-proof guarantees. However, we showthat standard differentially private model training is insufficient forproviding strong certified robustness guarantees. Indeed, combiningdifferential privacy and certified robustness in a single system isnon-trivial, leading previous works to introduce complex training schemes thatlack flexibility. In this work, we present DP-CERT, a simple and effectivemethod that achieves both privacy and robustness guarantees simultaneously byintegrating randomized smoothing into standard differentially private modeltraining. Compared to the leading prior work, DP-CERT gives up to a 2.5%increase in certified accuracy for the same differential privacy guarantee onCIFAR10. Through in-depth per-sample metric analysis, we find that largercertifiable radii correlate with smaller local Lipschitz constants, and showthat DP-CERT effectively reduces Lipschitz constants compared to otherdifferentially private training methods. The code is available atgithub.com/layer6ai-labs/dp-cert.</description><author>Jiapeng Wu, Atiyeh Ashari Ghomi, David Glukhov, Jesse C. Cresswell, Franziska Boenisch, Nicolas Papernot</author><pubDate>Fri, 20 Dec 2024 15:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08656v3</guid></item><item><title>Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators</title><link>http://arxiv.org/abs/2408.12325v4</link><description>Despite their remarkable capabilities, Large Language Models (LLMs) are proneto generate responses that contradict verifiable facts, i.e., unfaithfulhallucination content. Existing efforts generally focus on optimizing modelparameters or editing semantic representations, which compromise the internalfactual knowledge of target LLMs. In addition, hallucinations typically exhibitmultifaceted patterns in downstream tasks, limiting the model's holisticperformance across tasks. In this paper, we propose a Comparator-drivenDecoding-Time (CDT) framework to alleviate the response hallucination. Firstly,we construct hallucinatory and truthful comparators with multi-task fine-tuningsamples. In this case, we present an instruction prototype-guided mixture ofexperts strategy to enhance the ability of the corresponding comparators tocapture different hallucination or truthfulness patterns in distinct taskinstructions. CDT constrains next-token predictions to factuality-robustdistributions by contrasting the logit differences between the target LLMs andthese comparators. Systematic experiments on multiple downstream tasks showthat our framework can significantly improve the model performance and responsefactuality.</description><author>Dingkang Yang, Dongling Xiao, Jinjie Wei, Mingcheng Li, Zhaoyu Chen, Ke Li, Lihua Zhang</author><pubDate>Fri, 20 Dec 2024 15:26:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12325v4</guid></item><item><title>Never Reset Again: A Mathematical Framework for Continual Inference in Recurrent Neural Networks</title><link>http://arxiv.org/abs/2412.15983v1</link><description>Recurrent Neural Networks (RNNs) are widely used for sequential processingbut face fundamental limitations with continual inference due to statesaturation, requiring disruptive hidden state resets. However, reset-basedmethods impose synchronization requirements with input boundaries and increasecomputational costs at inference. To address this, we propose an adaptive lossfunction that eliminates the need for resets during inference while preservinghigh accuracy over extended sequences. By combining cross-entropy andKullback-Leibler divergence, the loss dynamically modulates the gradient basedon input informativeness, allowing the network to differentiate meaningful datafrom noise and maintain stable representations over time. Experimental resultsdemonstrate that our reset-free approach outperforms traditional reset-basedmethods when applied to a variety of RNNs, particularly in continual tasks,enhancing both the theoretical and practical capabilities of RNNs for streamingapplications.</description><author>Bojian Yin, Federico Corradi</author><pubDate>Fri, 20 Dec 2024 15:24:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15983v1</guid></item><item><title>MR-GDINO: Efficient Open-World Continual Object Detection</title><link>http://arxiv.org/abs/2412.15979v1</link><description>Open-world (OW) recognition and detection models show strong zero- andfew-shot adaptation abilities, inspiring their use as initializations incontinual learning methods to improve performance. Despite promising results onseen classes, such OW abilities on unseen classes are largely degenerated dueto catastrophic forgetting. To tackle this challenge, we propose an open-worldcontinual object detection task, requiring detectors to generalize to old, new,and unseen categories in continual learning scenarios. Based on this task, wepresent a challenging yet practical OW-COD benchmark to assess detectionabilities. The goal is to motivate OW detectors to simultaneously preservelearned classes, adapt to new classes, and maintain open-world capabilitiesunder few-shot adaptations. To mitigate forgetting in unseen categories, wepropose MR-GDINO, a strong, efficient and scalable baseline via memory andretrieval mechanisms within a highly scalable memory pool. Experimental resultsshow that existing continual detectors suffer from severe forgetting for bothseen and unseen categories. In contrast, MR-GDINO largely mitigates forgettingwith only 0.1% activated extra parameters, achieving state-of-the-artperformance for old, new, and unseen categories.</description><author>Bowen Dong, Zitong Huang, Guanglei Yang, Lei Zhang, Wangmeng Zuo</author><pubDate>Fri, 20 Dec 2024 15:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15979v1</guid></item><item><title>BabyHGRN: Exploring RNNs for Sample-Efficient Training of Language Models</title><link>http://arxiv.org/abs/2412.15978v1</link><description>This paper explores the potential of recurrent neural networks (RNNs) andother subquadratic architectures as competitive alternatives totransformer-based models in low-resource language modeling scenarios. Weutilize HGRN2 (Qin et al., 2024), a recently proposed RNN-based architecture,and comparatively evaluate its effectiveness against transformer-basedbaselines and other subquadratic architectures (LSTM, xLSTM, Mamba). Ourexperimental results show that BABYHGRN, our HGRN2 language model, outperformstransformer-based models in both the 10M and 100M word tracks of the challenge,as measured by their performance on the BLiMP, EWoK, GLUE and BEAR benchmarks.Further, we show the positive impact of knowledge distillation. Our findingschallenge the prevailing focus on transformer architectures and indicate theviability of RNN-based models, particularly in resource-constrainedenvironments.</description><author>Patrick Haller, Jonas Golde, Alan Akbik</author><pubDate>Fri, 20 Dec 2024 15:21:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15978v1</guid></item><item><title>Towards Projected and Incremental Pseudo-Boolean Model Counting</title><link>http://arxiv.org/abs/2412.14485v2</link><description>Model counting is a fundamental task that involves determining the number ofsatisfying assignments to a logical formula, typically in conjunctive normalform (CNF). While CNF model counting has received extensive attention overrecent decades, interest in Pseudo-Boolean (PB) model counting is just emergingpartly due to the greater flexibility of PB formulas. As such, we observedfeature gaps in existing PB counters such as a lack of support for projectedand incremental settings, which could hinder adoption. In this work, our maincontribution is the introduction of the PB model counter PBCount2, the firstexact PB model counter with support for projected and incremental modelcounting. Our counter, PBCount2, uses our Least Occurrence Weighted Min Degree(LOW-MD) computation ordering heuristic to support projected model counting anda cache mechanism to enable incremental model counting. In our evaluations,PBCount2 completed at least 1.40x the number of benchmarks of competing methodsfor projected model counting and at least 1.18x of competing methods inincremental model counting.</description><author>Suwei Yang, Kuldeep S. Meel</author><pubDate>Fri, 20 Dec 2024 15:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14485v2</guid></item><item><title>Recent Advances in Named Entity Recognition: A Comprehensive Survey and Comparative Study</title><link>http://arxiv.org/abs/2401.10825v3</link><description>Named Entity Recognition seeks to extract substrings within a text that namereal-world objects and to determine their type (for example, whether they referto persons or organizations). In this survey, we first present an overview ofrecent popular approaches, including advancements in Transformer-based methodsand Large Language Models (LLMs) that have not had much coverage in othersurveys. In addition, we discuss reinforcement learning and graph-basedapproaches, highlighting their role in enhancing NER performance. Second, wefocus on methods designed for datasets with scarce annotations. Third, weevaluate the performance of the main NER implementations on a variety ofdatasets with differing characteristics (as regards their domain, their size,and their number of classes). We thus provide a deep comparison of algorithmsthat have never been considered together. Our experiments shed some light onhow the characteristics of datasets affect the behavior of the methods wecompare.</description><author>Imed Keraghel, Stanislas Morbieu, Mohamed Nadif</author><pubDate>Fri, 20 Dec 2024 15:11:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10825v3</guid></item><item><title>ChinaTravel: A Real-World Benchmark for Language Agents in Chinese Travel Planning</title><link>http://arxiv.org/abs/2412.13682v2</link><description>Recent advances in LLMs, particularly in language reasoning and toolintegration, have rapidly sparked the real-world development of LanguageAgents. Among these, travel planning represents a prominent domain, combiningacademic challenges with practical value due to its complexity and marketdemand. However, existing benchmarks fail to reflect the diverse, real-worldrequirements crucial for deployment. To address this gap, we introduceChinaTravel, a benchmark specifically designed for authentic Chinese travelplanning scenarios. We collect the travel requirements from questionnaires andpropose a compositionally generalizable domain-specific language that enables ascalable evaluation process, covering feasibility, constraint satisfaction, andpreference comparison. Empirical studies reveal the potential of neuro-symbolicagents in travel planning, achieving a constraint satisfaction rate of 27.9%,significantly surpassing purely neural models at 2.6%. Moreover, we identifykey challenges in real-world travel planning deployments, including openlanguage reasoning and unseen concept composition. These findings highlight thesignificance of ChinaTravel as a pivotal milestone for advancing languageagents in complex, real-world planning scenarios.</description><author>Jie-Jing Shao, Xiao-Wen Yang, Bo-Wen Zhang, Baizhi Chen, Wen-Da Wei, Guohao Cai, Zhenhua Dong, Lan-Zhe Guo, Yu-feng Li</author><pubDate>Fri, 20 Dec 2024 15:08:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13682v2</guid></item><item><title>Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?</title><link>http://arxiv.org/abs/2412.15967v1</link><description>Modern deep learning-based clinical imaging workflows rely on accurate labelsof the examined anatomical region. Knowing the anatomical region is required toselect applicable downstream models and to effectively generate cohorts of highquality data for future medical and machine learning research efforts. However,this information may not be available in externally sourced data or generallycontain data entry errors. To address this problem, we show the effectivenessof self-supervised methods such as SimCLR and BYOL as well as supervisedcontrastive deep learning methods in assigning one of 14 anatomical regionclasses in our in-house dataset of 48,434 skeletal radiographs. We achieve astrong linear evaluation accuracy of 96.6% with a single model and 97.7% usingan ensemble approach. Furthermore, only a few labeled instances (1% of thetraining set) suffice to achieve an accuracy of 92.2%, enabling usage inlow-label and thus low-resource scenarios. Our model can be used to correctdata entry mistakes: a follow-up analysis of the test set errors of ourbest-performing single model by an expert radiologist identified 35% incorrectlabels and 11% out-of-domain images. When accounted for, the radiographanatomical region labelling performance increased -- without and with anensemble, respectively -- to a theoretical accuracy of 98.0% and 98.8%.</description><author>Simon Langer, Jessica Ritter, Rickmer Braren, Daniel Rueckert, Paul Hager</author><pubDate>Fri, 20 Dec 2024 15:07:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15967v1</guid></item><item><title>Monkey Transfer Learning Can Improve Human Pose Estimation</title><link>http://arxiv.org/abs/2412.15966v1</link><description>In this study, we investigated whether transfer learning from macaque monkeyscould improve human pose estimation. Current state-of-the-art pose estimationtechniques, often employing deep neural networks, can match human annotation innon-clinical datasets. However, they underperform in novel situations, limitingtheir generalisability to clinical populations with pathological movementpatterns. Clinical datasets are not widely available for AI training due toethical challenges and a lack of data collection. We observe that data fromother species may be able to bridge this gap by exposing the network to abroader range of motion cues. We found that utilising data from other speciesand undertaking transfer learning improved human pose estimation in terms ofprecision and recall compared to the benchmark, which was trained on humansonly. Compared to the benchmark, fewer human training examples were needed forthe transfer learning approach (1,000 vs 19,185). These results suggest thatmacaque pose estimation can improve human pose estimation in clinicalsituations. Future work should further explore the utility of pose estimationtrained with monkey data in clinical populations.</description><author>Bradley Scott, Clarisse de Vries, Aiden Durrant, Nir Oren, Edward Chadwick, Dimitra Blana</author><pubDate>Fri, 20 Dec 2024 15:06:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15966v1</guid></item><item><title>Language Repository for Long Video Understanding</title><link>http://arxiv.org/abs/2403.14622v2</link><description>Language has become a prominent modality in computer vision with the rise ofLLMs. Despite supporting long context-lengths, their effectiveness in handlinglong-term information gradually declines with input length. This becomescritical, especially in applications such as long-form video understanding. Inthis paper, we introduce a Language Repository (LangRepo) for LLMs, thatmaintains concise and structured information as an interpretable (i.e.,all-textual) representation. Our repository is updated iteratively based onmulti-scale video chunks. We introduce write and read operations that focus onpruning redundancies in text, and extracting information at various temporalscales. The proposed framework is evaluated on zero-shot visualquestion-answering benchmarks including EgoSchema, NExT-QA, IntentQA andNExT-GQA, showing state-of-the-art performance at its scale. Our code isavailable at https://github.com/kkahatapitiya/LangRepo.</description><author>Kumara Kahatapitiya, Kanchana Ranasinghe, Jongwoo Park, Michael S. Ryoo</author><pubDate>Fri, 20 Dec 2024 15:06:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14622v2</guid></item><item><title>FullStack Bench: Evaluating LLMs as Full Stack Coders</title><link>http://arxiv.org/abs/2412.00535v5</link><description>As the capabilities of code large language models (LLMs) continue to expand,their applications across diverse code intelligence domains are rapidlyincreasing. However, most existing datasets only evaluate limited applicationdomains. To address this gap, we have developed a comprehensive code evaluationdataset FullStack Bench focusing on full-stack programming, which encompasses awide range of application domains (e.g., basic programming, data analysis,software engineering, mathematics, and machine learning). Besides, to assessmultilingual programming capabilities, in FullStack Bench, we design real-worldinstructions and corresponding unit test cases from 16 widely-used programminglanguages to reflect real-world usage scenarios rather than simpletranslations. Moreover, we also release an effective code sandbox executiontool (i.e., SandboxFusion) supporting various programming languages andpackages to evaluate the performance of our FullStack Bench efficiently.Comprehensive experimental results on our FullStack Bench demonstrate thenecessity and effectiveness of our FullStack Bench and SandboxFusion.</description><author>Bytedance-Seed-Foundation-Code-Team, :, Yao Cheng, Jianfeng Chen, Jie Chen, Li Chen, Liyu Chen, Wentao Chen, Zhengyu Chen, Shijie Geng, Aoyan Li, Bo Li, Bowen Li, Linyi Li, Boyi Liu, Jerry Liu, Kaibo Liu, Qi Liu, Shukai Liu, Siyao Liu, Tianyi Liu, Tingkai Liu, Yongfei Liu, Rui Long, Jing Mai, Guanghan Ning, Z. Y. Peng, Kai Shen, Jiahao Su, Jing Su, Tao Sun, Yifan Sun, Yunzhe Tao, Guoyin Wang, Siwei Wang, Xuwu Wang, Yite Wang, Zihan Wang, Jinxiang Xia, Liang Xiang, Xia Xiao, Yongsheng Xiao, Chenguang Xi, Shulin Xin, Jingjing Xu, Shikun Xu, Hongxia Yang, Jack Yang, Yingxiang Yang, Jianbo Yuan, Jun Zhang, Yufeng Zhang, Yuyu Zhang, Shen Zheng, He Zhu, Ming Zhu</author><pubDate>Fri, 20 Dec 2024 14:58:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.00535v5</guid></item><item><title>Scientific Realism vs. Anti-Realism: Toward a Common Ground</title><link>http://arxiv.org/abs/2412.10643v2</link><description>The debate between scientific realism and anti-realism remains at astalemate, making reconciliation seem hopeless. Yet, important work remains:exploring a common ground, even if only to uncover deeper points ofdisagreement and, ideally, to benefit both sides of the debate. I propose sucha common ground. Specifically, many anti-realists, such as instrumentalists,have yet to seriously engage with Sober's call to justify their preferredversion of Ockham's razor through a positive account. Meanwhile, realists facea similar challenge: providing a non-circular explanation of how their versionof Ockham's razor connects to truth. The common ground I propose addressesthese challenges for both sides; the key is to leverage the idea that everyonevalues some truths and to draw on insights from scientific fields that studyscientific inference -- namely, statistics and machine learning. This commonground also isolates a distinctively epistemic root of the irreconcilability inthe realism debate.</description><author>Hanti Lin</author><pubDate>Fri, 20 Dec 2024 14:55:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10643v2</guid></item><item><title>Little is Enough: Boosting Privacy by Sharing Only Hard Labels in Federated Semi-Supervised Learning</title><link>http://arxiv.org/abs/2310.05696v4</link><description>In many critical applications, sensitive data is inherently distributed andcannot be centralized due to privacy concerns. A wide range of federatedlearning approaches have been proposed to train models locally at each clientwithout sharing their sensitive data, typically by exchanging model parameters,or probabilistic predictions (soft labels) on a public dataset or a combinationof both. However, these methods still disclose private information and restrictlocal models to those that can be trained using gradient-based methods. Wepropose a federated co-training (FedCT) approach that improves privacy bysharing only definitive (hard) labels on a public unlabeled dataset. Clientsuse a consensus of these shared labels as pseudo-labels for local training.This federated co-training approach empirically enhances privacy withoutcompromising model quality. In addition, it allows the use of local models thatare not suitable for parameter aggregation in traditional federated learning,such as gradient-boosted decision trees, rule ensembles, and random forests.Furthermore, we observe that FedCT performs effectively in federatedfine-tuning of large language models, where its pseudo-labeling mechanism isparticularly beneficial. Empirical evaluations and theoretical analyses suggestits applicability across a range of federated learning scenarios.</description><author>Amr Abourayya, Jens Kleesiek, Kanishka Rao, Erman Ayday, Bharat Rao, Geoff Webb, Michael Kamp</author><pubDate>Fri, 20 Dec 2024 14:51:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05696v4</guid></item><item><title>From General to Specific: Tailoring Large Language Models for Personalized Healthcare</title><link>http://arxiv.org/abs/2412.15957v1</link><description>The rapid development of large language models (LLMs) has transformed manyindustries, including healthcare. However, previous medical LLMs have largelyfocused on leveraging general medical knowledge to provide responses, withoutaccounting for patient variability and lacking true personalization at theindividual level. To address this, we propose a novel method calledpersonalized medical language model (PMLM), which explores and optimizespersonalized LLMs through recommendation systems and reinforcement learning(RL). Specifically, by utilizing self-informed and peer-informedpersonalization, PMLM captures changes in behaviors and preferences to designinitial personalized prompts tailored to individual needs. We further refinethese initial personalized prompts through RL, ultimately enhancing theprecision of LLM guidance. Notably, the personalized prompt are hard prompt,which grants PMLM high adaptability and reusability, allowing it to directlyleverage high-quality proprietary LLMs. We evaluate PMLM using real-worldobstetrics and gynecology data, and the experimental results demonstrate thatPMLM achieves personalized responses, and it provides more refined andindividualized services, offering a potential way for personalized medicalLLMs.</description><author>Ruize Shi, Hong Huang, Wei Zhou, Kehan Yin, Kai Zhao, Yun Zhao</author><pubDate>Fri, 20 Dec 2024 14:51:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15957v1</guid></item><item><title>Black-Box Uniform Stability for Non-Euclidean Empirical Risk Minimization</title><link>http://arxiv.org/abs/2412.15956v1</link><description>We study first-order algorithms that are uniformly stable for empirical riskminimization (ERM) problems that are convex and smooth with respect to$p$-norms, $p \geq 1$. We propose a black-box reduction method that, byemploying properties of uniformly convex regularizers, turns an optimizationalgorithm for H\"older smooth convex losses into a uniformly stable learningalgorithm with optimal statistical risk bounds on the excess risk, up to aconstant factor depending on $p$. Achieving a black-box reduction for uniformstability was posed as an open question by (Attia and Koren, 2022), which hadsolved the Euclidean case $p=2$. We explore applications that leveragenon-Euclidean geometry in addressing binary classification problems.</description><author>Simon Vary, David Martínez-Rubio, Patrick Rebeschini</author><pubDate>Fri, 20 Dec 2024 14:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15956v1</guid></item><item><title>Trust Calibration in IDEs: Paving the Way for Widespread Adoption of AI Refactoring</title><link>http://arxiv.org/abs/2412.15948v1</link><description>In the software industry, the drive to add new features often overshadows theneed to improve existing code. Large Language Models (LLMs) offer a newapproach to improving codebases at an unprecedented scale through AI-assistedrefactoring. However, LLMs come with inherent risks such as braking changes andthe introduction of security vulnerabilities. We advocate for encapsulating theinteraction with the models in IDEs and validating refactoring attempts usingtrustworthy safeguards. However, equally important for the uptake of AIrefactoring is research on trust development. In this position paper, weposition our future work based on established models from research on humanfactors in automation. We outline action research within CodeScene ondevelopment of 1) novel LLM safeguards and 2) user interaction that conveys anappropriate level of trust. The industry collaboration enables large-scalerepository analysis and A/B testing to continuously guide the design of ourresearch interventions.</description><author>Markus Borg</author><pubDate>Fri, 20 Dec 2024 14:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15948v1</guid></item><item><title>Mamba-based Deep Learning Approaches for Sleep Staging on a Wireless Multimodal Wearable System without Electroencephalography</title><link>http://arxiv.org/abs/2412.15947v1</link><description>Study Objectives: We investigate using Mamba-based deep learning approachesfor sleep staging on signals from ANNE One (Sibel Health, Evanston, IL), aminimally intrusive dual-sensor wireless wearable system measuring chestelectrocardiography (ECG), triaxial accelerometry, and temperature, as well asfinger photoplethysmography (PPG) and temperature. Methods: We obtained wearable sensor recordings from 360 adults undergoingconcurrent clinical polysomnography (PSG) at a tertiary care sleep lab. PSGrecordings were scored according to AASM criteria. PSG and wearable sensor datawere automatically aligned using their ECG channels with manual confirmation byvisual inspection. We trained Mamba-based models with bothconvolutional-recurrent neural network (CRNN) and the recurrent neural network(RNN) architectures on these recordings. Ensembling of model variants withsimilar architectures was performed. Results: Our best approach, after ensembling, attains a 3-class (wake, NREM,REM) balanced accuracy of 83.50%, F1 score of 84.16%, Cohen's $\kappa$ of72.68%, and a MCC score of 72.84%; a 4-class (wake, N1/N2, N3, REM) balancedaccuracy of 74.64%, F1 score of 74.56%, Cohen's $\kappa$ of 61.63%, and MCCscore of 62.04%; a 5-class (wake, N1, N2, N3, REM) balanced accuracy of 64.30%,F1 score of 66.97%, Cohen's $\kappa$ of 53.23%, MCC score of 54.38%. Conclusions: Deep learning models can infer major sleep stages from awearable system without electroencephalography (EEG) and can be successfullyapplied to data from adults attending a tertiary care sleep clinic.</description><author>Andrew H. Zhang, Alex He-Mo, Richard Fei Yin, Chunlin Li, Yuzhi Tang, Dharmendra Gurve, Nasim Montazeri Ghahjaverestan, Maged Goubran, Bo Wang, Andrew S. P. Lim</author><pubDate>Fri, 20 Dec 2024 14:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15947v1</guid></item><item><title>Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning</title><link>http://arxiv.org/abs/2412.12808v2</link><description>This paper focuses on sarcasm detection, which aims to identify whether givenstatements convey criticism, mockery, or other negative sentiment opposite tothe literal meaning. To detect sarcasm, humans often require a comprehensiveunderstanding of the semantics in the statement and even resort to externalcommonsense to infer the fine-grained incongruity. However, existing methodslack commonsense inferential ability when they face complex real-worldscenarios, leading to unsatisfactory performance. To address this problem, wepropose a novel framework for sarcasm detection, which conducts incongruityreasoning based on commonsense augmentation, called EICR. Concretely, we firstemploy retrieval-augmented large language models to supplement the missing butindispensable commonsense background knowledge. To capture complex contextualassociations, we construct a dependency graph and obtain the optimized topologyvia graph refinement. We further introduce an adaptive reasoning skeleton thatintegrates prior rules to extract sentiment-inconsistent subgraphs explicitly.To eliminate the possible spurious relations between words and labels, weemploy adversarial contrastive learning to enhance the robustness of thedetector. Experiments conducted on five datasets demonstrate the effectivenessof EICR.</description><author>Ziqi Qiu, Jianxing Yu, Yufeng Zhang, Hanjiang Lai, Yanghui Rao, Qinliang Su, Jian Yin</author><pubDate>Fri, 20 Dec 2024 14:39:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.12808v2</guid></item><item><title>Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation</title><link>http://arxiv.org/abs/2412.15939v1</link><description>The rise of the generative models quality during the past years enabled thegeneration of edited variations of images at an important scale. To counter theharmful effects of such technology, the Image Difference Captioning (IDC) taskaims to describe the differences between two images. While this task issuccessfully handled for simple 3D rendered images, it struggles on real-worldimages. The reason is twofold: the training data-scarcity, and the difficultyto capture fine-grained differences between complex images. To address thoseissues, we propose in this paper a simple yet effective framework to both adaptexisting image captioning models to the IDC task and augment IDC datasets. Weintroduce BLIP2IDC, an adaptation of BLIP2 to the IDC task at low computationalcost, and show it outperforms two-streams approaches by a significant margin onreal-world IDC datasets. We also propose to use synthetic augmentation toimprove the performance of IDC models in an agnostic fashion. We show that oursynthetic augmentation strategy provides high quality data, leading to achallenging new dataset well-suited for IDC named Syned1.</description><author>Gautier Evennou, Antoine Chaffin, Vivien Chappelier, Ewa Kijak</author><pubDate>Fri, 20 Dec 2024 14:32:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15939v1</guid></item><item><title>The Unreasonable Effectiveness of Guidance for Diffusion Models</title><link>http://arxiv.org/abs/2411.10257v2</link><description>Guidance is an error-correcting technique used to improve the perceptualquality of images generated by diffusion models. Typically, the correction isachieved by linear extrapolation, using an auxiliary diffusion model that haslower performance than the primary model. Using a 2D toy example, we show thatit is highly beneficial when the auxiliary model exhibits similar errors as theprimary one but stronger. We verify this finding in higher dimensions, where weshow that competitive generative performance to state-of-the-art guidancemethods can be achieved when the auxiliary model differs from the primary oneonly by having stronger weight regularization. As an independent contribution,we investigate whether upweighting long-range spatial dependencies improvesvisual fidelity. The result is a novel guidance method, which we call slidingwindow guidance (SWG), that guides the primary model with itself byconstraining its receptive field. Intriguingly, SWG aligns better with humanpreferences than state-of-the-art guidance methods while requiring neithertraining, architectural modifications, nor class conditioning. The code will bereleased.</description><author>Tim Kaiser, Nikolas Adaloglou, Markus Kollmann</author><pubDate>Fri, 20 Dec 2024 14:24:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10257v2</guid></item><item><title>MiniGPT-Pancreas: Multimodal Large Language Model for Pancreas Cancer Classification and Detection</title><link>http://arxiv.org/abs/2412.15925v1</link><description>Problem: Pancreas radiological imaging is challenging due to the small size,blurred boundaries, and variability of shape and position of the organ amongpatients. Goal: In this work we present MiniGPT-Pancreas, a Multimodal LargeLanguage Model (MLLM), as an interactive chatbot to support clinicians inpancreas cancer diagnosis by integrating visual and textual information.Methods: MiniGPT-v2, a general-purpose MLLM, was fine-tuned in a cascaded wayfor pancreas detection, tumor classification, and tumor detection withmultimodal prompts combining questions and computed tomography scans from theNational Institute of Health (NIH), and Medical Segmentation Decathlon (MSD)datasets. The AbdomenCT-1k dataset was used to detect the liver, spleen,kidney, and pancreas. Results: MiniGPT-Pancreas achieved an Intersection overUnion (IoU) of 0.595 and 0.550 for the detection of pancreas on NIH and MSDdatasets, respectively. For the pancreas cancer classification task on the MSDdataset, accuracy, precision, and recall were 0.876, 0.874, and 0.878,respectively. When evaluating MiniGPT-Pancreas on the AbdomenCT-1k dataset formulti-organ detection, the IoU was 0.8399 for the liver, 0.722 for the kidney,0.705 for the spleen, and 0.497 for the pancreas. For the pancreas tumordetection task, the IoU score was 0.168 on the MSD dataset. Conclusions:MiniGPT-Pancreas represents a promising solution to support clinicians in theclassification of pancreas images with pancreas tumors. Future research isneeded to improve the score on the detection task, especially for pancreastumors.</description><author>Andrea Moglia, Elia Clement Nastasio, Luca Mainardi, Pietro Cerveri</author><pubDate>Fri, 20 Dec 2024 14:18:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15925v1</guid></item><item><title>Watertox: The Art of Simplicity in Universal Attacks A Cross-Model Framework for Robust Adversarial Generation</title><link>http://arxiv.org/abs/2412.15924v1</link><description>Contemporary adversarial attack methods face significant limitations incross-model transferability and practical applicability. We present Watertox,an elegant adversarial attack framework achieving remarkable effectivenessthrough architectural diversity and precision-controlled perturbations. Ourtwo-stage Fast Gradient Sign Method combines uniform baseline perturbations($\epsilon_1 = 0.1$) with targeted enhancements ($\epsilon_2 = 0.4$). Theframework leverages an ensemble of complementary architectures, from VGG toConvNeXt, synthesizing diverse perspectives through an innovative votingmechanism. Against state-of-the-art architectures, Watertox reduces modelaccuracy from 70.6% to 16.0%, with zero-shot attacks achieving up to 98.8%accuracy reduction against unseen architectures. These results establishWatertox as a significant advancement in adversarial methodologies, withpromising applications in visual security systems and CAPTCHA generation.</description><author>Zhenghao Gao, Shengjie Xu, Meixi Chen, Fangyao Zhao</author><pubDate>Fri, 20 Dec 2024 14:17:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15924v1</guid></item><item><title>RiTTA: Modeling Event Relations in Text-to-Audio Generation</title><link>http://arxiv.org/abs/2412.15922v1</link><description>Despite significant advancements in Text-to-Audio (TTA) generation modelsachieving high-fidelity audio with fine-grained context understanding, theystruggle to model the relations between audio events described in the inputtext. However, previous TTA methods have not systematically explored audioevent relation modeling, nor have they proposed frameworks to enhance thiscapability. In this work, we systematically study audio event relation modelingin TTA generation models. We first establish a benchmark for this task by: 1.proposing a comprehensive relation corpus covering all potential relations inreal-world scenarios; 2. introducing a new audio event corpus encompassingcommonly heard audios; and 3. proposing new evaluation metrics to assess audioevent relation modeling from various perspectives. Furthermore, we propose afinetuning framework to enhance existing TTA models ability to model audioevents relation. Code is available at: https://github.com/yuhanghe01/RiTTA</description><author>Yuhang He, Yash Jain, Xubo Liu, Andrew Markham, Vibhav Vineet</author><pubDate>Fri, 20 Dec 2024 14:14:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15922v1</guid></item><item><title>Less is More: Towards Green Code Large Language Models via Unified Structural Pruning</title><link>http://arxiv.org/abs/2412.15921v1</link><description>The extensive application of Large Language Models (LLMs) in generativecoding tasks has raised concerns due to their high computational demands andenergy consumption. Unlike previous structural pruning methods designed forclassification models that deal with lowdimensional classification logits,generative Code LLMs produce high-dimensional token logit sequences, makingtraditional pruning objectives inherently limited. Moreover, existing singlecomponent pruning approaches further constrain the effectiveness when appliedto generative Code LLMs. In response, we propose Flab-Pruner, an innovativeunified structural pruning method that combines vocabulary, layer, andFeed-Forward Network (FFN) pruning. This approach effectively reduces modelparameters while maintaining performance. Additionally, we introduce acustomized code instruction data strategy for coding tasks to enhance theperformance recovery efficiency of the pruned model. Through extensiveevaluations on three state-of-the-art Code LLMs across multiple generativecoding tasks, the results demonstrate that Flab-Pruner retains 97% of theoriginal performance after pruning 22% of the parameters and achieves the sameor even better performance after post-training. The pruned models exhibitsignificant improvements in storage, GPU usage, computational efficiency, andenvironmental impact, while maintaining well robustness. Our research providesa sustainable solution for green software engineering and promotes theefficient deployment of LLMs in real-world generative coding intelligenceapplications.</description><author>Guang Yang, Yu Zhou, Xiangyu Zhang, Wei Cheng, Ke Liu, Xiang Chen, Terry Yue Zhuo, Taolue Chen</author><pubDate>Fri, 20 Dec 2024 14:13:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15921v1</guid></item><item><title>Variational measurement-based quantum computation for generative modeling</title><link>http://arxiv.org/abs/2310.13524v2</link><description>Measurement-based quantum computation (MBQC) offers a fundamentally uniqueparadigm to design quantum algorithms. Indeed, due to the inherent randomnessof quantum measurements, the natural operations in MBQC are not deterministicand unitary, but are rather augmented with probabilistic byproducts. Yet, themain algorithmic use of MBQC so far has been to completely counteract thisprobabilistic nature in order to simulate unitary computations expressed in thecircuit model. In this work, we propose designing MBQC algorithms that embracethis inherent randomness and treat the random byproducts in MBQC as a resourcefor computation. As a natural application where randomness can be beneficial,we consider generative modeling, a task in machine learning centered aroundgenerating complex probability distributions. To address this task, we proposea variational MBQC algorithm equipped with control parameters that allow one todirectly adjust the degree of randomness to be admitted in the computation. Ouralgebraic and numerical findings indicate that this additional randomness canlead to significant gains in expressivity and learning performance for certaingenerative modeling tasks, respectively. These results highlight the potentialadvantages in exploiting the inherent randomness of MBQC and motivate furtherresearch into MBQC-based algorithms.</description><author>Arunava Majumder, Marius Krumm, Tina Radkohl, Lukas J. Fiderer, Hendrik Poulsen Nautrup, Sofiene Jerbi, Hans J. Briegel</author><pubDate>Fri, 20 Dec 2024 14:12:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13524v2</guid></item><item><title>Data Preparation for Fairness-Performance Trade-Offs: A Practitioner-Friendly Alternative?</title><link>http://arxiv.org/abs/2412.15920v1</link><description>As machine learning (ML) systems are increasingly adopted across industries,addressing fairness and bias has become essential. While many solutions focuson ethical challenges in ML, recent studies highlight that data itself is amajor source of bias. Pre-processing techniques, which mitigate bias beforetraining, are effective but may impact model performance and pose integrationdifficulties. In contrast, fairness-aware Data Preparation practices are bothfamiliar to practitioners and easier to implement, providing a more accessibleapproach to reducing bias. Objective. This registered report proposes anempirical evaluation of how optimally selected fairness-aware practices,applied in early ML lifecycle stages, can enhance both fairness andperformance, potentially outperforming standard pre-processing bias mitigationmethods. Method. To this end, we will introduce FATE, an optimization techniquefor selecting 'Data Preparation' pipelines that optimize fairness andperformance. Using FATE, we will analyze the fairness-performance trade-off,comparing pipelines selected by FATE with results by pre-processing biasmitigation techniques.</description><author>Gianmario Voria, Rebecca Di Matteo, Giammaria Giordano, Gemma Catolino, Fabio Palomba</author><pubDate>Fri, 20 Dec 2024 14:12:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15920v1</guid></item></channel></rss>