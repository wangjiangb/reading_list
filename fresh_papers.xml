<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 28 Mar 2024 06:00:29 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark</title><link>http://arxiv.org/abs/2403.18821v1</link><description>We present a new dataset called Real Acoustic Fields (RAF) that captures realacoustic room data from multiple modalities. The dataset includes high-qualityand densely captured room impulse response data paired with multi-view images,and precise 6DoF pose tracking data for sound emitters and listeners in therooms. We used this dataset to evaluate existing methods for novel-viewacoustic synthesis and impulse response generation which previously relied onsynthetic data. In our evaluation, we thoroughly assessed existing audio andaudio-visual models against multiple criteria and proposed settings to enhancetheir performance on real-world data. We also conducted experiments toinvestigate the impact of incorporating visual data (i.e., images and depth)into neural acoustic field models. Additionally, we demonstrated theeffectiveness of a simple sim2real approach, where a model is pre-trained withsimulated data and fine-tuned with sparse real-world data, resulting insignificant improvements in the few-shot learning approach. RAF is the firstdataset to provide densely captured room acoustic data, making it an idealresource for researchers working on audio and audio-visual neural acousticfield modeling techniques. Demos and datasets are available on our projectpage: https://facebookresearch.github.io/real-acoustic-fields/</description><author>Ziyang Chen, Israel D. Gebru, Christian Richardt, Anurag Kumar, William Laney, Andrew Owens, Alexander Richard</author><pubDate>Wed, 27 Mar 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18821v1</guid></item><item><title>MetaCap: Meta-learning Priors from Multi-View Imagery for Sparse-view Human Performance Capture and Rendering</title><link>http://arxiv.org/abs/2403.18820v1</link><description>Faithful human performance capture and free-view rendering from sparse RGBobservations is a long-standing problem in Vision and Graphics. The mainchallenges are the lack of observations and the inherent ambiguities of thesetting, e.g. occlusions and depth ambiguity. As a result, radiance fields,which have shown great promise in capturing high-frequency appearance andgeometry details in dense setups, perform poorly when na\"ively supervisingthem on sparse camera views, as the field simply overfits to the sparse-viewinputs. To address this, we propose MetaCap, a method for efficient andhigh-quality geometry recovery and novel view synthesis given very sparse oreven a single view of the human. Our key idea is to meta-learn the radiancefield weights solely from potentially sparse multi-view videos, which can serveas a prior when fine-tuning them on sparse imagery depicting the human. Thisprior provides a good network weight initialization, thereby effectivelyaddressing ambiguities in sparse-view capture. Due to the articulated structureof the human body and motion-induced surface deformations, learning such aprior is non-trivial. Therefore, we propose to meta-learn the field weights ina pose-canonicalized space, which reduces the spatial feature range and makesfeature learning more effective. Consequently, one can fine-tune our fieldparameters to quickly generalize to unseen poses, novel illumination conditionsas well as novel and sparse (even monocular) camera views. For evaluating ourmethod under different scenarios, we collect a new dataset, WildDynaCap, whichcontains subjects captured in, both, a dense camera dome and in-the-wild sparsecamera rigs, and demonstrate superior results compared to recentstate-of-the-art methods on both public and WildDynaCap dataset.</description><author>Guoxing Sun, Rishabh Dabral, Pascal Fua, Christian Theobalt, Marc Habermann</author><pubDate>Wed, 27 Mar 2024 18:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18820v1</guid></item><item><title>Benchmarking Object Detectors with COCO: A New Path Forward</title><link>http://arxiv.org/abs/2403.18819v1</link><description>The Common Objects in Context (COCO) dataset has been instrumental inbenchmarking object detectors over the past decade. Like every dataset, COCOcontains subtle errors and imperfections stemming from its annotationprocedure. With the advent of high-performing models, we ask whether theseerrors of COCO are hindering its utility in reliably benchmarking furtherprogress. In search for an answer, we inspect thousands of masks from COCO(2017 version) and uncover different types of errors such as imprecise maskboundaries, non-exhaustively annotated instances, and mislabeled masks. Due tothe prevalence of COCO, we choose to correct these errors to maintaincontinuity with prior research. We develop COCO-ReM (Refined Masks), a cleanerset of annotations with visibly better mask quality than COCO-2017. We evaluatefifty object detectors and find that models that predict visually sharper masksscore higher on COCO-ReM, affirming that they were being incorrectly penalizeddue to errors in COCO-2017. Moreover, our models trained using COCO-ReMconverge faster and score higher than their larger variants trained usingCOCO-2017, highlighting the importance of data quality in improving objectdetectors. With these findings, we advocate using COCO-ReM for future objectdetection research. Our dataset is available at https://cocorem.xyz</description><author>Shweta Singh, Aayan Yadav, Jitesh Jain, Humphrey Shi, Justin Johnson, Karan Desai</author><pubDate>Wed, 27 Mar 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18819v1</guid></item><item><title>ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion</title><link>http://arxiv.org/abs/2403.18818v1</link><description>Diffusion models have revolutionized image editing but often generate imagesthat violate physical laws, particularly the effects of objects on the scene,e.g., occlusions, shadows, and reflections. By analyzing the limitations ofself-supervised approaches, we propose a practical solution centered on a\q{counterfactual} dataset. Our method involves capturing a scene before andafter removing a single object, while minimizing other changes. By fine-tuninga diffusion model on this dataset, we are able to not only remove objects butalso their effects on the scene. However, we find that applying this approachfor photorealistic object insertion requires an impractically large dataset. Totackle this challenge, we propose bootstrap supervision; leveraging our objectremoval model trained on a small counterfactual dataset, we syntheticallyexpand this dataset considerably. Our approach significantly outperforms priormethods in photorealistic object removal and insertion, particularly atmodeling the effects of objects on the scene.</description><author>Daniel Winter, Matan Cohen, Shlomi Fruchter, Yael Pritch, Alex Rav-Acha, Yedid Hoshen</author><pubDate>Wed, 27 Mar 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18818v1</guid></item><item><title>Garment3DGen: 3D Garment Stylization and Texture Generation</title><link>http://arxiv.org/abs/2403.18816v1</link><description>We introduce Garment3DGen a new method to synthesize 3D garment assets from abase mesh given a single input image as guidance. Our proposed approach allowsusers to generate 3D textured clothes based on both real and synthetic images,such as those generated by text prompts. The generated assets can be directlydraped and simulated on human bodies. First, we leverage the recent progress ofimage to 3D diffusion methods to generate 3D garment geometries. However, sincethese geometries cannot be utilized directly for downstream tasks, we proposeto use them as pseudo ground-truth and set up a mesh deformation optimizationprocedure that deforms a base template mesh to match the generated 3D target.Second, we introduce carefully designed losses that allow the input base meshto freely deform towards the desired target, yet preserve mesh quality andtopology such that they can be simulated. Finally, a texture estimation modulegenerates high-fidelity texture maps that are globally and locally consistentand faithfully capture the input guidance, allowing us to render the generated3D assets. With Garment3DGen users can generate the textured 3D garment oftheir choice without the need of artist intervention. One can provide a textualprompt describing the garment they desire to generate a simulation-ready 3Dasset. We present a plethora of quantitative and qualitative comparisons onvarious assets both real and generated and provide use-cases of how one cangenerate simulation-ready 3D garments.</description><author>Nikolaos Sarafianos, Tuur Stuyck, Xiaoyu Xiang, Yilei Li, Jovan Popovic, Rakesh Ranjan</author><pubDate>Wed, 27 Mar 2024 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18816v1</guid></item><item><title>Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models</title><link>http://arxiv.org/abs/2403.18814v1</link><description>In this work, we introduce Mini-Gemini, a simple and effective frameworkenhancing multi-modality Vision Language Models (VLMs). Despite theadvancements in VLMs facilitating basic visual dialog and reasoning, aperformance gap persists compared to advanced models like GPT-4 and Gemini. Wetry to narrow the gap by mining the potential of VLMs for better performanceand any-to-any workflow from three aspects, i.e., high-resolution visualtokens, high-quality data, and VLM-guided generation. To enhance visual tokens,we propose to utilize an additional visual encoder for high-resolutionrefinement without increasing the visual token count. We further construct ahigh-quality dataset that promotes precise image comprehension andreasoning-based generation, expanding the operational scope of current VLMs. Ingeneral, Mini-Gemini further mines the potential of VLMs and empowers currentframeworks with image understanding, reasoning, and generation simultaneously.Mini-Gemini supports a series of dense and MoE Large Language Models (LLMs)from 2B to 34B. It is demonstrated to achieve leading performance in severalzero-shot benchmarks and even surpasses the developed private models. Code andmodels are available at https://github.com/dvlab-research/MiniGemini.</description><author>Yanwei Li, Yuechen Zhang, Chengyao Wang, Zhisheng Zhong, Yixin Chen, Ruihang Chu, Shaoteng Liu, Jiaya Jia</author><pubDate>Wed, 27 Mar 2024 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18814v1</guid></item><item><title>Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment</title><link>http://arxiv.org/abs/2403.18811v1</link><description>We introduce a novel task within the field of 3D dance generation, termeddance accompaniment, which necessitates the generation of responsive movementsfrom a dance partner, the "follower", synchronized with the lead dancer'smovements and the underlying musical rhythm. Unlike existing solo or groupdance generation tasks, a duet dance scenario entails a heightened degree ofinteraction between the two participants, requiring delicate coordination inboth pose and position. To support this task, we first build a large-scale anddiverse duet interactive dance dataset, DD100, by recording about 117 minutesof professional dancers' performances. To address the challenges inherent inthis task, we propose a GPT-based model, Duolando, which autoregressivelypredicts the subsequent tokenized motion conditioned on the coordinatedinformation of the music, the leader's and the follower's movements. To furtherenhance the GPT's capabilities of generating stable results on unseenconditions (music and leader motions), we devise an off-policy reinforcementlearning strategy that allows the model to explore viable trajectories fromout-of-distribution samplings, guided by human-defined rewards. Based on thecollected dataset and proposed method, we establish a benchmark with severalcarefully designed metrics.</description><author>Li Siyao, Tianpei Gu, Zhitao Yang, Zhengyu Lin, Ziwei Liu, Henghui Ding, Lei Yang, Chen Change Loy</author><pubDate>Wed, 27 Mar 2024 18:57:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18811v1</guid></item><item><title>ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation</title><link>http://arxiv.org/abs/2403.18807v1</link><description>In the absence of parallax cues, a learning-based single image depthestimation (SIDE) model relies heavily on shading and contextual cues in theimage. While this simplicity is attractive, it is necessary to train suchmodels on large and varied datasets, which are difficult to capture. It hasbeen shown that using embeddings from pre-trained foundational models, such asCLIP, improves zero shot transfer in several applications. Taking inspirationfrom this, in our paper we explore the use of global image priors generatedfrom a pre-trained ViT model to provide more detailed contextual information.We argue that the embedding vector from a ViT model, pre-trained on a largedataset, captures greater relevant information for SIDE than the usual route ofgenerating pseudo image captions, followed by CLIP based text embeddings. Basedon this idea, we propose a new SIDE model using a diffusion backbone which isconditioned on ViT embeddings. Our proposed design establishes a newstate-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of0.059(14% improvement) compared to 0.069 by the current SOTA (VPD). And onKITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to0.142 by the current SOTA (GEDepth). For zero-shot transfer with a modeltrained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%)over NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%,18%, 45%, 9%) by ZoeDepth. The code is available athttps://github.com/Aradhye2002/EcoDepth.</description><author>Suraj Patni, Aradhye Agarwal, Chetan Arora</author><pubDate>Wed, 27 Mar 2024 18:53:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18807v1</guid></item><item><title>Is Modularity Transferable? A Case Study through the Lens of Knowledge Distillation</title><link>http://arxiv.org/abs/2403.18804v1</link><description>The rise of Modular Deep Learning showcases its potential in various NaturalLanguage Processing applications. Parameter-efficient fine-tuning (PEFT)modularity has been shown to work for various use cases, from domain adaptationto multilingual setups. However, all this work covers the case where themodular components are trained and deployed within one single Pre-trainedLanguage Model (PLM). This model-specific setup is a substantial limitation onthe very modularity that modular architectures are trying to achieve. We askwhether current modular approaches are transferable between models and whetherwe can transfer the modules from more robust and larger PLMs to smaller ones.In this work, we aim to fill this gap via a lens of Knowledge Distillation,commonly used for model compression, and present an extremely straightforwardapproach to transferring pre-trained, task-specific PEFT modules betweensame-family PLMs. Moreover, we propose a method that allows the transfer ofmodules between incompatible PLMs without any change in the inferencecomplexity. The experiments on Named Entity Recognition, Natural LanguageInference, and Paraphrase Identification tasks over multiple languages and PEFTmethods showcase the initial potential of transferable modularity.</description><author>Mateusz Klimaszewski, Piotr Andruszkiewicz, Alexandra Birch</author><pubDate>Wed, 27 Mar 2024 18:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18804v1</guid></item><item><title>Projective Methods for Mitigating Gender Bias in Pre-trained Language Models</title><link>http://arxiv.org/abs/2403.18803v1</link><description>Mitigation of gender bias in NLP has a long history tied to debiasing staticword embeddings. More recently, attention has shifted to debiasing pre-trainedlanguage models. We study to what extent the simplest projective debiasingmethods, developed for word embeddings, can help when applied to BERT'sinternal representations. Projective methods are fast to implement, use a smallnumber of saved parameters, and make no updates to the existing modelparameters. We evaluate the efficacy of the methods in reducing both intrinsicbias, as measured by BERT's next sentence prediction task, and in mitigatingobserved bias in a downstream setting when fine-tuned. To this end, we alsoprovide a critical analysis of a popular gender-bias assessment test forquantifying intrinsic bias, resulting in an enhanced test set and new biasmeasures. We find that projective methods can be effective at both intrinsicbias and downstream bias mitigation, but that the two outcomes are notnecessarily correlated. This finding serves as a warning that intrinsic biastest sets, based either on language modeling tasks or next sentence prediction,should not be the only benchmark in developing a debiased language model.</description><author>Hillary Dawkins, Isar Nejadgholi, Daniel Gillis, Judi McCuaig</author><pubDate>Wed, 27 Mar 2024 18:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18803v1</guid></item><item><title>Long-form factuality in large language models</title><link>http://arxiv.org/abs/2403.18802v1</link><description>Large language models (LLMs) often generate content that contains factualerrors when responding to fact-seeking prompts on open-ended topics. Tobenchmark a model's long-form factuality in open domains, we first use GPT-4 togenerate LongFact, a prompt set comprising thousands of questions spanning 38topics. We then propose that LLM agents can be used as automated evaluators forlong-form factuality through a method which we call Search-Augmented FactualityEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response intoa set of individual facts and to evaluate the accuracy of each fact using amulti-step reasoning process comprising sending search queries to Google Searchand determining whether a fact is supported by the search results. Furthermore,we propose extending F1 score as an aggregated metric for long-form factuality.To do so, we balance the percentage of supported facts in a response(precision) with the percentage of provided facts relative to a hyperparameterrepresenting a user's preferred response length (recall). Empirically, we demonstrate that LLM agents can achieve superhuman ratingperformance - on a set of ~16k individual facts, SAFE agrees with crowdsourcedhuman annotators 72% of the time, and on a random subset of 100 disagreementcases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 timescheaper than human annotators. We also benchmark thirteen language models onLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), findingthat larger language models generally achieve better long-form factuality.LongFact, SAFE, and all experimental code are available athttps://github.com/google-deepmind/long-form-factuality.</description><author>Jerry Wei, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Dustin Tran, Daiyi Peng, Ruibo Liu, Da Huang, Cosmo Du, Quoc V. Le</author><pubDate>Wed, 27 Mar 2024 18:48:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18802v1</guid></item><item><title>A 4D Hybrid Algorithm to Scale Parallel Training to Thousands of GPUs</title><link>http://arxiv.org/abs/2305.13525v2</link><description>Large communication costs are a critical bottleneck in trainingstate-of-the-art neural networks on distributed systems. This paper introducesAxoNN, a novel four-dimensional (4D) parallelization approach, inspired byAgarwal's algorithm for matrix multiplication, for parallelizing tensorcomputations in deep learning, AxoNN employs two key strategies to minimizecommunication overhead. First, we optimize communication by overlappingexpensive collective operations (reduce-scatter, all-gather, all-reduce) withcomputations. Our experiments with a 20-billion parameter transformer modeldemonstrate that these optimizations deliver nearly 53\% improvement. Second,we present an analytical model to assist users in identifyingcommunication-minimizing configurations within the vast search space defined byour 4D algorithm. This model empowers practitioners by simplifying the tuningprocess for their specific training workloads. When training an 80-billionparameter model on 1024 GPUs of Perlmutter, AxoNN surpasses Megatron-LM, astate-of-the-art framework, by a significant 26%. Additionally, it achieves 57%of the theoretical peak FLOP/s.</description><author>Siddharth Singh, Prajwal Singhania, Aditya K. Ranjan, Zack Sating, Abhinav Bhatele</author><pubDate>Wed, 27 Mar 2024 18:47:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13525v2</guid></item><item><title>Shifting to Machine Supervision: Annotation-Efficient Semi and Self-Supervised Learning for Automatic Medical Image Segmentation and Classification</title><link>http://arxiv.org/abs/2311.10319v4</link><description>Advancements in clinical treatment are increasingly constrained by thelimitations of supervised learning techniques, which depend heavily on largevolumes of annotated data. The annotation process is not only costly but alsodemands substantial time from clinical specialists. Addressing this issue, weintroduce the S4MI (Self-Supervision and Semi-Supervision for Medical Imaging)pipeline, a novel approach that leverages advancements in self-supervised andsemi-supervised learning. These techniques engage in auxiliary tasks that donot require labeling, thus simplifying the scaling of machine supervisioncompared to fully-supervised methods. Our study benchmarks these techniques onthree distinct medical imaging datasets to evaluate their effectiveness inclassification and segmentation tasks. Notably, we observed that selfsupervised learning significantly surpassed the performance of supervisedmethods in the classification of all evaluated datasets. Remarkably, thesemi-supervised approach demonstrated superior outcomes in segmentation,outperforming fully-supervised methods while using 50% fewer labels across alldatasets. In line with our commitment to contributing to the scientificcommunity, we have made the S4MI code openly accessible, allowing for broaderapplication and further development of these methods.</description><author>Pranav Singh, Raviteja Chukkapalli, Shravan Chaudhari, Luoyao Chen, Mei Chen, Jinqian Pan, Craig Smuda, Jacopo Cirrone</author><pubDate>Wed, 27 Mar 2024 18:41:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10319v4</guid></item><item><title>Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction</title><link>http://arxiv.org/abs/2403.18795v1</link><description>We tackle the challenge of efficiently reconstructing a 3D asset from asingle image with growing demands for automated 3D content creation pipelines.Previous methods primarily rely on Score Distillation Sampling (SDS) and NeuralRadiance Fields (NeRF). Despite their significant success, these approachesencounter practical limitations due to lengthy optimization and considerablememory usage. In this report, we introduce Gamba, an end-to-end amortized 3Dreconstruction model from single-view images, emphasizing two main insights:(1) 3D representation: leveraging a large number of 3D Gaussians for anefficient 3D Gaussian splatting process; (2) Backbone design: introducing aMamba-based sequential network that facilitates context-dependent reasoning andlinear scalability with the sequence (token) length, accommodating asubstantial number of Gaussians. Gamba incorporates significant advancements indata preprocessing, regularization design, and training methodologies. Weassessed Gamba against existing optimization-based and feed-forward 3Dgeneration approaches using the real-world scanned OmniObject3D dataset. Here,Gamba demonstrates competitive generation capabilities, both qualitatively andquantitatively, while achieving remarkable speed, approximately 0.6 second on asingle NVIDIA A100 GPU.</description><author>Qiuhong Shen, Xuanyu Yi, Zike Wu, Pan Zhou, Hanwang Zhang, Shuicheng Yan, Xinchao Wang</author><pubDate>Wed, 27 Mar 2024 18:40:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18795v1</guid></item><item><title>CrystalBox: Future-Based Explanations for Input-Driven Deep RL Systems</title><link>http://arxiv.org/abs/2302.13483v4</link><description>We present CrystalBox, a novel, model-agnostic, posthoc explainabilityframework for Deep Reinforcement Learning (DRL) controllers in the large familyof input-driven environments which includes computer systems. We combine thenatural decomposability of reward functions in input-driven environments withthe explanatory power of decomposed returns. We propose an efficient algorithmto generate future-based explanations across both discrete and continuouscontrol environments. Using applications such as adaptive bitrate streaming andcongestion control, we demonstrate CrystalBox's capability to generatehigh-fidelity explanations. We further illustrate its higher utility acrossthree practical use cases: contrastive explanations, network observability, andguided reward design, as opposed to prior explainability techniques thatidentify salient features.</description><author>Sagar Patel, Sangeetha Abdu Jyothi, Nina Narodytska</author><pubDate>Wed, 27 Mar 2024 18:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.13483v4</guid></item><item><title>Object Pose Estimation via the Aggregation of Diffusion Features</title><link>http://arxiv.org/abs/2403.18791v1</link><description>Estimating the pose of objects from images is a crucial task of 3D sceneunderstanding, and recent approaches have shown promising results on very largebenchmarks. However, these methods experience a significant performance dropwhen dealing with unseen objects. We believe that it results from the limitedgeneralizability of image features. To address this problem, we have anin-depth analysis on the features of diffusion models, e.g. Stable Diffusion,which hold substantial potential for modeling unseen objects. Based on thisanalysis, we then innovatively introduce these diffusion features for objectpose estimation. To achieve this, we propose three distinct architectures thatcan effectively capture and aggregate diffusion features of differentgranularity, greatly improving the generalizability of object pose estimation.Our approach outperforms the state-of-the-art methods by a considerable marginon three popular benchmark datasets, LM, O-LM, and T-LESS. In particular, ourmethod achieves higher accuracy than the previous best arts on unseen objects:98.2% vs. 93.5% on Unseen LM, 85.9% vs. 76.3% on Unseen O-LM, showing thestrong generalizability of our method. Our code is released athttps://github.com/Tianfu18/diff-feats-pose.</description><author>Tianfu Wang, Guosheng Hu, Hongguang Wang</author><pubDate>Wed, 27 Mar 2024 18:35:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18791v1</guid></item><item><title>Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization</title><link>http://arxiv.org/abs/2402.17574v2</link><description>Large Language Models exhibit robust problem-solving capabilities for diversetasks. However, most LLM-based agents are designed as specific task solverswith sophisticated prompt engineering, rather than agents capable of learningand evolving through interactions. These task solvers necessitate manuallycrafted prompts to inform task rules and regulate LLM behaviors, inherentlyincapacitating to address complex dynamic scenarios e.g., large interactivegames. In light of this, we propose Agent-Pro: an LLM-based Agent withPolicy-level Reflection and Optimization that can learn a wealth of expertisefrom interactive experiences and progressively elevate its behavioral policy.Specifically, it involves a dynamic belief generation and reflection processfor policy evolution. Rather than action-level reflection, Agent-Proiteratively reflects on past trajectories and beliefs, fine-tuning itsirrational beliefs for a better policy. Moreover, a depth-first search isemployed for policy optimization, ensuring continual enhancement in policypayoffs. Agent-Pro is evaluated across two games: Blackjack and Texas Hold'em,outperforming vanilla LLM and specialized models. Our results show Agent-Procan learn and evolve in complex and dynamic scenes, which also benefitsnumerous LLM-based applications.</description><author>Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, Weiming Lu</author><pubDate>Wed, 27 Mar 2024 18:34:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17574v2</guid></item><item><title>SplatFace: Gaussian Splat Face Reconstruction Leveraging an Optimizable Surface</title><link>http://arxiv.org/abs/2403.18784v1</link><description>We present SplatFace, a novel Gaussian splatting framework designed for 3Dhuman face reconstruction without reliance on accurate pre-determined geometry.Our method is designed to simultaneously deliver both high-quality novel viewrendering and accurate 3D mesh reconstructions. We incorporate a generic 3DMorphable Model (3DMM) to provide a surface geometric structure, making itpossible to reconstruct faces with a limited set of input images. We introducea joint optimization strategy that refines both the Gaussians and the morphablesurface through a synergistic non-rigid alignment process. A novel distancemetric, splat-to-surface, is proposed to improve alignment by considering boththe Gaussian position and covariance. The surface information is also utilizedto incorporate a world-space densification process, resulting in superiorreconstruction quality. Our experimental analysis demonstrates that theproposed method is competitive with both other Gaussian splatting techniques innovel view synthesis and other 3D reconstruction methods in producing 3D facemeshes with high geometric precision.</description><author>Jiahao Luo, Jing Liu, James Davis</author><pubDate>Wed, 27 Mar 2024 18:32:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18784v1</guid></item><item><title>Towards a World-English Language Model for On-Device Virtual Assistants</title><link>http://arxiv.org/abs/2403.18783v1</link><description>Neural Network Language Models (NNLMs) for Virtual Assistants (VAs) aregenerally language-, region-, and in some cases, device-dependent, whichincreases the effort to scale and maintain them. Combining NNLMs for one ormore of the categories is one way to improve scalability. In this work, wecombine regional variants of English to build a ``World English'' NNLM foron-device VAs. In particular, we investigate the application of adapterbottlenecks to model dialect-specific characteristics in our existingproduction NNLMs {and enhance the multi-dialect baselines}. We find thatadapter modules are more effective in modeling dialects than specializingentire sub-networks. Based on this insight and leveraging the design of ourproduction models, we introduce a new architecture for World English NNLM thatmeets the accuracy, latency, and memory constraints of our single-dialectmodels.</description><author>Rricha Jalota, Lyan Verwimp, Markus Nussbaum-Thom, Amr Mousa, Arturo Argueta, Youssef Oualil</author><pubDate>Wed, 27 Mar 2024 18:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18783v1</guid></item><item><title>Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives</title><link>http://arxiv.org/abs/2401.02009v2</link><description>The reflection capacity of Large Language Model (LLM) has garnered extensiveattention. A post-hoc prompting strategy, e.g., reflexion and self-refine,refines LLM's response based on self-evaluated or external feedback. However,recent research indicates without external feedback, LLM's intrinsic reflectionis unstable. Our investigation unveils that the key bottleneck is the qualityof the self-evaluated feedback. We find LLMs often exhibit overconfidence orhigh randomness when self-evaluate, offering stubborn or inconsistent feedback,which causes poor reflection. To remedy this, we advocate Self-Contrast: Itadaptively explores diverse solving perspectives tailored to the request,contrasts the differences, and summarizes these discrepancies into a checklistwhich could be used to re-examine and eliminate discrepancies. Our methodendows LLM with diverse perspectives to alleviate stubborn biases. Moreover,their discrepancies indicate potential errors or inherent uncertainties thatLLM often overlooks. Reflecting upon these can catalyze more accurate andstable reflection. Experiments conducted on a series of reasoning andtranslation tasks with different LLMs serve to underscore the effectiveness andgenerality of our strategy.</description><author>Wenqi Zhang, Yongliang Shen, Linjuan Wu, Qiuying Peng, Jun Wang, Yueting Zhuang, Weiming Lu</author><pubDate>Wed, 27 Mar 2024 18:24:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02009v2</guid></item><item><title>ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object</title><link>http://arxiv.org/abs/2403.18775v1</link><description>We establish rigorous benchmarks for visual perception robustness. Syntheticimages such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specifictype of evaluation over synthetic corruptions, backgrounds, and textures, yetthose robustness benchmarks are restricted in specified variations and have lowsynthetic quality. In this work, we introduce generative model as a data sourcefor synthesizing hard images that benchmark deep models' robustness. Leveragingdiffusion models, we are able to generate images with more diversifiedbackgrounds, textures, and materials than any prior work, where we term thisbenchmark as ImageNet-D. Experimental results show that ImageNet-D results in asignificant accuracy drop to a range of vision models, from the standard ResNetvisual classifier to the latest foundation models like CLIP and MiniGPT-4,significantly reducing their accuracy by up to 60\%. Our work suggests thatdiffusion models can be an effective source to test vision models. The code anddataset are available at https://github.com/chenshuang-zhang/imagenet_d.</description><author>Chenshuang Zhang, Fei Pan, Junmo Kim, In So Kweon, Chengzhi Mao</author><pubDate>Wed, 27 Mar 2024 18:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18775v1</guid></item><item><title>Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation</title><link>http://arxiv.org/abs/2312.01220v2</link><description>Detecting objects in low-light scenarios presents a persistent challenge, asdetectors trained on well-lit data exhibit significant performance degradationon low-light data due to low visibility. Previous methods mitigate this issueby exploring image enhancement or object detection techniques with reallow-light image datasets. However, the progress is impeded by the inherentdifficulties about collecting and annotating low-light images. To address thischallenge, we propose to boost low-light object detection with zero-shotday-night domain adaptation, which aims to generalize a detector from well-litscenarios to low-light ones without requiring real low-light data. RevisitingRetinex theory in the low-level vision, we first design a reflectancerepresentation learning module to learn Retinex-based illumination invariancein images with a carefully designed illumination invariance reinforcementstrategy. Next, an interchange-redecomposition-coherence procedure isintroduced to improve over the vanilla Retinex image decomposition process byperforming two sequential image decompositions and introducing aredecomposition cohering loss. Extensive experiments on ExDark, DARK FACE, andCODaN datasets show strong low-light generalizability of our method. Our codeis available at https://github.com/ZPDu/DAI-Net.</description><author>Zhipeng Du, Miaojing Shi, Jiankang Deng</author><pubDate>Wed, 27 Mar 2024 18:23:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01220v2</guid></item><item><title>CheckEval: Robust Evaluation Framework using Large Language Model via Checklist</title><link>http://arxiv.org/abs/2403.18771v1</link><description>We introduce CheckEval, a novel evaluation framework using Large LanguageModels, addressing the challenges of ambiguity and inconsistency in currentevaluation methods. CheckEval addresses these challenges by dividing evaluationcriteria into detailed sub-aspects and constructing a checklist of Booleanquestions for each, simplifying the evaluation. This approach not only rendersthe process more interpretable but also significantly enhances the robustnessand reliability of results by focusing on specific evaluation dimensions.Validated through a focused case study using the SummEval benchmark, CheckEvalindicates a strong correlation with human judgments. Furthermore, itdemonstrates a highly consistent Inter-Annotator Agreement. These findingshighlight the effectiveness of CheckEval for objective, flexible, and preciseevaluations. By offering a customizable and interactive framework, CheckEvalsets a new standard for the use of LLMs in evaluation, responding to theevolving needs of the field and establishing a clear method for futureLLM-based evaluation.</description><author>Yukyung Lee, Joonghoon Kim, Jaehee Kim, Hyowon Cho, Pilsung Kang</author><pubDate>Wed, 27 Mar 2024 18:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18771v1</guid></item><item><title>Improved Neural Protoform Reconstruction via Reflex Prediction</title><link>http://arxiv.org/abs/2403.18769v1</link><description>Protolanguage reconstruction is central to historical linguistics. Thecomparative method, one of the most influential theoretical and methodologicalframeworks in the history of the language sciences, allows linguists to inferprotoforms (reconstructed ancestral words) from their reflexes (related modernwords) based on the assumption of regular sound change. Not surprisingly,numerous computational linguists have attempted to operationalize comparativereconstruction through various computational models, the most successful ofwhich have been supervised encoder-decoder models, which treat the problem ofpredicting protoforms given sets of reflexes as a sequence-to-sequence problem.We argue that this framework ignores one of the most important aspects of thecomparative method: not only should protoforms be inferable from cognate sets(sets of related reflexes) but the reflexes should also be inferable from theprotoforms. Leveraging another line of research -- reflex prediction -- wepropose a system in which candidate protoforms from a reconstruction model arereranked by a reflex prediction model. We show that this more completeimplementation of the comparative method allows us to surpass state-of-the-artprotoform reconstruction methods on three of four Chinese and Romance datasets.</description><author>Liang Lu, Jingzhi Wang, David R. Mortensen</author><pubDate>Wed, 27 Mar 2024 18:13:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18769v1</guid></item><item><title>Generalization Bounds: Perspectives from Information Theory and PAC-Bayes</title><link>http://arxiv.org/abs/2309.04381v2</link><description>A fundamental question in theoretical machine learning is generalization.Over the past decades, the PAC-Bayesian approach has been established as aflexible framework to address the generalization capabilities of machinelearning algorithms, and design new ones. Recently, it has garnered increasedinterest due to its potential applicability for a variety of learningalgorithms, including deep neural networks. In parallel, aninformation-theoretic view of generalization has developed, wherein therelation between generalization and various information measures has beenestablished. This framework is intimately connected to the PAC-Bayesianapproach, and a number of results have been independently discovered in bothstrands. In this monograph, we highlight this strong connection and present aunified treatment of PAC-Bayesian and information-theoretic generalizationbounds. We present techniques and results that the two perspectives have incommon, and discuss the approaches and interpretations that differ. Inparticular, we demonstrate how many proofs in the area share a modularstructure, through which the underlying ideas can be intuited. We pay specialattention to the conditional mutual information (CMI) framework; analyticalstudies of the information complexity of learning algorithms; and theapplication of the proposed methods to deep learning. This monograph isintended to provide a comprehensive introduction to information-theoreticgeneralization bounds and their connection to PAC-Bayes, serving as afoundation from which the most recent developments are accessible. It is aimedbroadly towards researchers with an interest in generalization and theoreticalmachine learning.</description><author>Fredrik Hellström, Giuseppe Durisi, Benjamin Guedj, Maxim Raginsky</author><pubDate>Wed, 27 Mar 2024 18:07:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04381v2</guid></item><item><title>Decoupled Data Consistency with Diffusion Purification for Image Restoration</title><link>http://arxiv.org/abs/2403.06054v4</link><description>Diffusion models have recently gained traction as a powerful class of deepgenerative priors, excelling in a wide range of image restoration tasks due totheir exceptional ability to model data distributions. To solve imagerestoration problems, many existing techniques achieve data consistency byincorporating additional likelihood gradient steps into the reverse samplingprocess of diffusion models. However, the additional gradient steps pose achallenge for real-world practical applications as they incur a largecomputational overhead, thereby increasing inference time. They also presentadditional difficulties when using accelerated diffusion model samplers, as thenumber of data consistency steps is limited by the number of reverse samplingsteps. In this work, we propose a novel diffusion-based image restorationsolver that addresses these issues by decoupling the reverse process from thedata consistency steps. Our method involves alternating between areconstruction phase to maintain data consistency and a refinement phase thatenforces the prior via diffusion purification. Our approach demonstratesversatility, making it highly adaptable for efficient problem-solving in latentspace. Additionally, it reduces the necessity for numerous sampling stepsthrough the integration of consistency models. The efficacy of our approach isvalidated through comprehensive experiments across various image restorationtasks, including image denoising, deblurring, inpainting, and super-resolution.</description><author>Xiang Li, Soo Min Kwon, Ismail R. Alkhouri, Saiprasad Ravishankar, Qing Qu</author><pubDate>Wed, 27 Mar 2024 18:06:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06054v4</guid></item><item><title>Superior Parallel Big Data Clustering through Competitive Stochastic Sample Size Optimization in Big-means</title><link>http://arxiv.org/abs/2403.18766v1</link><description>This paper introduces a novel K-means clustering algorithm, an advancement onthe conventional Big-means methodology. The proposed method efficientlyintegrates parallel processing, stochastic sampling, and competitiveoptimization to create a scalable variant designed for big data applications.It addresses scalability and computation time challenges typically faced withtraditional techniques. The algorithm adjusts sample sizes dynamically for eachworker during execution, optimizing performance. Data from these sample sizesare continually analyzed, facilitating the identification of the most efficientconfiguration. By incorporating a competitive element among workers usingdifferent sample sizes, efficiency within the Big-means algorithm is furtherstimulated. In essence, the algorithm balances computational time andclustering quality by employing a stochastic, competitive sampling strategy ina parallel computing setting.</description><author>Rustam Mussabayev, Ravil Mussabayev</author><pubDate>Wed, 27 Mar 2024 18:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18766v1</guid></item><item><title>CaT: Constraints as Terminations for Legged Locomotion Reinforcement Learning</title><link>http://arxiv.org/abs/2403.18765v1</link><description>Deep Reinforcement Learning (RL) has demonstrated impressive results insolving complex robotic tasks such as quadruped locomotion. Yet, currentsolvers fail to produce efficient policies respecting hard constraints. In thiswork, we advocate for integrating constraints into robot learning and presentConstraints as Terminations (CaT), a novel constrained RL algorithm. Departingfrom classical constrained RL formulations, we reformulate constraints throughstochastic terminations during policy learning: any violation of a constrainttriggers a probability of terminating potential future rewards the RL agentcould attain. We propose an algorithmic approach to this formulation, byminimally modifying widely used off-the-shelf RL algorithms in robot learning(such as Proximal Policy Optimization). Our approach leads to excellentconstraint adherence without introducing undue complexity and computationaloverhead, thus mitigating barriers to broader adoption. Through empiricalevaluation on the real quadruped robot Solo crossing challenging obstacles, wedemonstrate that CaT provides a compelling solution for incorporatingconstraints into RL frameworks. Videos and code are available athttps://constraints-as-terminations.github.io.</description><author>Elliot Chane-Sane, Pierre-Alexandre Leziart, Thomas Flayols, Olivier Stasse, Philippe Souères, Nicolas Mansard</author><pubDate>Wed, 27 Mar 2024 18:03:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18765v1</guid></item><item><title>ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition</title><link>http://arxiv.org/abs/2403.18762v1</link><description>Place recognition is an important task for robots and autonomous cars tolocalize themselves and close loops in pre-built maps. While single-modalsensor-based methods have shown satisfactory performance, cross-modal placerecognition that retrieving images from a point-cloud database remains achallenging problem. Current cross-modal methods transform images into 3Dpoints using depth estimation for modality conversion, which are usuallycomputationally intensive and need expensive labeled data for depthsupervision. In this work, we introduce a fast and lightweight framework toencode images and point clouds into place-distinctive descriptors. We proposean effective Field of View (FoV) transformation module to convert point cloudsinto an analogous modality as images. This module eliminates the necessity fordepth estimation and helps subsequent modules achieve real-time performance. Wefurther design a non-negative factorization-based encoder to extract mutuallyconsistent semantic features between point clouds and images. This encoderyields more distinctive global descriptors for retrieval. Experimental resultson the KITTI dataset show that our proposed methods achieve state-of-the-artperformance while running in real time. Additional evaluation on the HAOMOdataset covering a 17 km trajectory further shows the practical generalizationcapabilities. We have released the implementation of our methods as open sourceat: https://github.com/haomo-ai/ModaLink.git.</description><author>Weidong Xie, Lun Luo, Nanfei Ye, Yi Ren, Shaoyi Du, Minhang Wang, Jintao Xu, Rui Ai, Weihao Gu, Xieyuanli Chen</author><pubDate>Wed, 27 Mar 2024 18:01:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18762v1</guid></item><item><title>FedSN: A Novel Federated Learning Framework over LEO Satellite Networks</title><link>http://arxiv.org/abs/2311.01483v3</link><description>Recently, a large number of Low Earth Orbit (LEO) satellites have beenlaunched and deployed successfully in space by commercial companies, such asSpaceX. Due to multimodal sensors equipped by the LEO satellites, they servenot only for communication but also for various machine learning applications,such as space modulation recognition, remote sensing image classification, etc.However, the ground station (GS) may be incapable of downloading such a largevolume of raw sensing data for centralized model training due to the limitedcontact time with LEO satellites (e.g. 5 minutes). Therefore, federatedlearning (FL) has emerged as the promising solution to address this problem viaon-device training. Unfortunately, to enable FL on LEO satellites, we stillface three critical challenges that are i) heterogeneous computing and memorycapabilities, ii) limited uplink rate, and iii) model staleness. To this end,we propose FedSN as a general FL framework to tackle the above challenges, andfully explore data diversity on LEO satellites. Specifically, we first presenta novel sub-structure scheme to enable heterogeneous local model trainingconsidering different computing, memory, and communication constraints on LEOsatellites. Additionally, we propose a pseudo-synchronous model aggregationstrategy to dynamically schedule model aggregation for compensating modelstaleness. To further demonstrate the effectiveness of the FedSN, we evaluateit using space modulation recognition and remote sensing image classificationtasks by leveraging the data from real-world satellite networks. Extensiveexperimental results demonstrate that FedSN framework achieves higher accuracy,lower computing, and communication overhead than the state-of-the-artbenchmarks and the effectiveness of each components in FedSN.</description><author>Zheng Lin, Zhe Chen, Zihan Fang, Xianhao Chen, Xiong Wang, Yue Gao</author><pubDate>Wed, 27 Mar 2024 17:56:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01483v3</guid></item><item><title>Detection of subclinical atherosclerosis by image-based deep learning on chest x-ray</title><link>http://arxiv.org/abs/2403.18756v1</link><description>Aims. To develop a deep-learning based system for recognition of subclinicalatherosclerosis on a plain frontal chest x-ray. Methods and Results. Adeep-learning algorithm to predict coronary artery calcium (CAC) score (theAI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20%internal validation cohort) of primary prevention patients (58.4% male, medianage 63 [51-74] years) with available paired chest x-ray and chest computedtomography (CT) indicated for any clinical reason and performed within 3months. The CAC score calculated on chest CT was used as ground truth. Themodel was validated on an temporally-independent cohort of 90 patients from thesame institution (external validation). The diagnostic accuracy of the AI-CACmodel assessed by the area under the curve (AUC) was the primary outcome.Overall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.AUC of the AI-CAC model to identify a CAC&gt;0 was 0.90 in the internal validationcohort and 0.77 in the external validation cohort. Sensitivity was consistentlyabove 92% in both cohorts. In the overall cohort (n=540), among patients withAI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients withAI-CAC&gt;0 had significantly higher Kaplan Meier estimates for ASCVD events(13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems toaccurately detect subclinical atherosclerosis on chest x-ray with elevatedsensitivity, and to predict ASCVD events with elevated negative predictivevalue. Adoption of the AI-CAC model to refine CV risk stratification or as anopportunistic screening tool requires prospective evaluation.</description><author>Guglielmo Gallone, Francesco Iodice, Alberto Presta, Davide Tore, Ovidio de Filippo, Michele Visciano, Carlo Alberto Barbano, Alessandro Serafini, Paola Gorrini, Alessandro Bruno, Walter Grosso Marra, James Hughes, Mario Iannaccone, Paolo Fonio, Attilio Fiandrotti, Alessandro Depaoli, Marco Grangetto, Gaetano Maria de Ferrari, Fabrizio D'Ascenzo</author><pubDate>Wed, 27 Mar 2024 17:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18756v1</guid></item><item><title>Many-Objective Evolutionary Influence Maximization: Balancing Spread, Budget, Fairness, and Time</title><link>http://arxiv.org/abs/2403.18755v1</link><description>The Influence Maximization (IM) problem seeks to discover the set of nodes ina graph that can spread the information propagation at most. This problem isknown to be NP-hard, and it is usually studied by maximizing the influence(spread) and, optionally, optimizing a second objective, such as minimizing theseed set size or maximizing the influence fairness. However, in many practicalscenarios multiple aspects of the IM problem must be optimized at the sametime. In this work, we propose a first case study where several IM-specificobjective functions, namely budget, fairness, communities, and time, areoptimized on top of the maximization of influence and minimization of the seedset size. To this aim, we introduce MOEIM (Many-Objective EvolutionaryAlgorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm(MOEA) based on NSGA-II incorporating graph-aware operators and a smartinitialization. We compare MOEIM in two experimental settings, including atotal of nine graph datasets, two heuristic methods, a related MOEA, and astate-of-the-art Deep Learning approach. The experiments show that MOEIMoverall outperforms the competitors in most of the tested many-objectivesettings. To conclude, we also investigate the correlation between theobjectives, leading to novel insights into the topic. The codebase is availableat https://github.com/eliacunegatti/MOEIM.</description><author>Elia Cunegatti, Leonardo Lucio Custode, Giovanni Iacca</author><pubDate>Wed, 27 Mar 2024 17:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18755v1</guid></item><item><title>Interpretable machine learning for time-to-event prediction in medicine and healthcare</title><link>http://arxiv.org/abs/2303.09817v2</link><description>Time-to-event prediction, e.g. cancer survival analysis or hospital length ofstay, is a highly prominent machine learning task in medical and healthcareapplications. However, only a few interpretable machine learning methods complywith its challenges. To facilitate a comprehensive explanatory analysis ofsurvival models, we formally introduce time-dependent feature effects andglobal feature importance explanations. We show how post-hoc interpretationmethods allow for finding biases in AI systems predicting length of stay usinga novel multi-modal dataset created from 1235 X-ray images with textualradiology reports annotated by human experts. Moreover, we evaluate cancersurvival models beyond predictive performance to include the importance ofmulti-omics feature groups based on a large-scale benchmark comprising 11datasets from The Cancer Genome Atlas (TCGA). Model developers can use theproposed methods to debug and improve machine learning algorithms, whilephysicians can discover disease biomarkers and assess their significance. Wehope the contributed open data and code resources facilitate future work in theemerging research direction of explainable survival analysis.</description><author>Hubert Baniecki, Bartlomiej Sobieski, Patryk Szatkowski, Przemyslaw Bombinski, Przemyslaw Biecek</author><pubDate>Wed, 27 Mar 2024 17:52:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09817v2</guid></item><item><title>Simplified Diffusion Schrödinger Bridge</title><link>http://arxiv.org/abs/2403.14623v2</link><description>This paper introduces a novel theoretical simplification of the DiffusionSchr\"odinger Bridge (DSB) that facilitates its unification with Score-basedGenerative Models (SGMs), addressing the limitations of DSB in complex datageneration and enabling faster convergence and enhanced performance. Byemploying SGMs as an initial solution for DSB, our approach capitalizes on thestrengths of both frameworks, ensuring a more efficient training process andimproving the performance of SGM. We also propose a reparameterizationtechnique that, despite theoretical approximations, practically improves thenetwork's fitting capabilities. Our extensive experimental evaluations confirmthe effectiveness of the simplified DSB, demonstrating its significantimprovements. We believe the contributions of this work pave the way foradvanced generative modeling. The code is available athttps://github.com/checkcrab/SDSB.</description><author>Zhicong Tang, Tiankai Hang, Shuyang Gu, Dong Chen, Baining Guo</author><pubDate>Wed, 27 Mar 2024 17:49:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14623v2</guid></item><item><title>Self-supervised co-salient object detection via feature correspondence at multiple scales</title><link>http://arxiv.org/abs/2403.11107v2</link><description>Our paper introduces a novel two-stage self-supervised approach for detectingco-occurring salient objects (CoSOD) in image groups without requiringsegmentation annotations. Unlike existing unsupervised methods that rely solelyon patch-level information (e.g. clustering patch descriptors) or oncomputation heavy off-the-shelf components for CoSOD, our lightweight modelleverages feature correspondences at both patch and region levels,significantly improving prediction performance. In the first stage, we train aself-supervised network that detects co-salient regions by computing localpatch-level feature correspondences across images. We obtain the segmentationpredictions using confidence-based adaptive thresholding. In the next stage, werefine these intermediate segmentations by eliminating the detected regions(within each image) whose averaged feature representations are dissimilar tothe foreground feature representation averaged across all the cross-attentionmaps (from the previous stage). Extensive experiments on three CoSOD benchmarkdatasets show that our self-supervised model outperforms the correspondingstate-of-the-art models by a huge margin (e.g. on the CoCA dataset, our modelhas a 13.7% F-measure gain over the SOTA unsupervised CoSOD model). Notably,our self-supervised model also outperforms several recent fully supervisedCoSOD models on the three test datasets (e.g., on the CoCA dataset, our modelhas a 4.6% F-measure gain over a recent supervised CoSOD model).</description><author>Souradeep Chakraborty, Dimitris Samaras</author><pubDate>Wed, 27 Mar 2024 17:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11107v2</guid></item><item><title>Nonlinear Control Allocation: A Learning Based Approach</title><link>http://arxiv.org/abs/2201.06180v2</link><description>Modern aircraft are designed with redundant control effectors to cater forfault tolerance and maneuverability requirements. This leads to aircraft beingover-actuated and requires control allocation schemes to distribute the controlcommands among control effectors. Traditionally, optimization-based controlallocation schemes are used; however, for nonlinear allocation problems, thesemethods require large computational resources. In this work, an artificialneural network (ANN) based nonlinear control allocation scheme is proposed. Theproposed scheme is composed of learning the inverse of the controleffectiveness map through ANN, and then implementing it as an allocator insteadof solving an online optimization problem. Stability conditions are presentedfor closed-loop systems incorporating the allocator, and computationalchallenges are explored with piece-wise linear effectiveness functions andANN-based allocators. To demonstrate the efficacy of the proposed scheme, it iscompared with a standard quadratic programming-based method for controlallocation.</description><author>Hafiz Zeeshan Iqbal Khan, Surrayya Mobeen, Jahanzeb Rajput, Jamshed Riaz</author><pubDate>Wed, 27 Mar 2024 17:45:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.06180v2</guid></item><item><title>CYCLE: Learning to Self-Refine the Code Generation</title><link>http://arxiv.org/abs/2403.18746v1</link><description>Pre-trained code language models have achieved promising performance in codegeneration and improved the programming efficiency of human developers.However, their self-refinement capability is typically overlooked by theexisting evaluations of code LMs, which focus only on the accuracy of theone-time prediction. For the cases when code LMs fail to implement the correctprogram, developers actually find it hard to debug and fix the faultyprediction since it is not written by the developers themselves. Unfortunately,our study reveals that code LMs cannot efficiently self-refine their faultygenerations as well. In this paper, we propose CYCLE framework, learning to self-refine the faultygeneration according to the available feedback, such as the execution resultsreported by the test suites. We evaluate CYCLE on three popular code generationbenchmarks, HumanEval, MBPP, and APPS. The results reveal that CYCLEsuccessfully maintains, sometimes improves, the quality of one-time codegeneration, while significantly improving the self-refinement capability ofcode LMs. We implement four variants of CYCLE with varied numbers of parametersacross 350M, 1B, 2B, and 3B, and the experiments show that CYCLE consistentlyboosts the code generation performance, by up to 63.5%, across benchmarks andvaried model sizes. We also notice that CYCLE outperforms code LMs that have3$\times$ more parameters in self-refinement.</description><author>Yangruibo Ding, Marcus J. Min, Gail Kaiser, Baishakhi Ray</author><pubDate>Wed, 27 Mar 2024 17:45:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18746v1</guid></item><item><title>Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks</title><link>http://arxiv.org/abs/2311.03683v2</link><description>Discriminatively trained, deterministic neural networks are the de factochoice for classification problems. However, even though they achievestate-of-the-art results on in-domain test sets, they tend to be overconfidenton out-of-distribution (OOD) data. For instance, ReLU networks - a popularclass of neural network architectures - have been shown to almost always yieldhigh confidence predictions when the test data are far away from the trainingset, even when they are trained with OOD data. We overcome this problem byadding a term to the output of the neural network that corresponds to the logitof an extra class, that we design to dominate the logits of the originalclasses as we move away from the training data.This technique provably preventsarbitrarily high confidence on far-away test data while maintaining a simplediscriminative point-estimate training. Evaluation on various benchmarksdemonstrates strong performance against competitive baselines on both far-awayand realistic OOD data.</description><author>Ahmad Rashid, Serena Hacker, Guojun Zhang, Agustinus Kristiadi, Pascal Poupart</author><pubDate>Wed, 27 Mar 2024 17:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03683v2</guid></item><item><title>Understanding the Learning Dynamics of Alignment with Human Feedback</title><link>http://arxiv.org/abs/2403.18742v1</link><description>Aligning large language models (LLMs) with human intentions has become acritical task for safely deploying models in real-world systems. While existingalignment approaches have seen empirical success, theoretically understandinghow these methods affect model behavior remains an open question. Our workprovides an initial attempt to theoretically analyze the learning dynamics ofhuman preference alignment. We formally show how the distribution of preferencedatasets influences the rate of model updates and provide rigorous guaranteeson the training accuracy. Our theory also reveals an intricate phenomenon wherethe optimization is prone to prioritizing certain behaviors with higherpreference distinguishability. We empirically validate our findings oncontemporary LLMs and alignment tasks, reinforcing our theoretical insights andshedding light on considerations for future alignment approaches. Disclaimer:This paper contains potentially offensive text; reader discretion is advised.</description><author>Shawn Im, Yixuan Li</author><pubDate>Wed, 27 Mar 2024 17:39:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18742v1</guid></item><item><title>Usage-Specific Survival Modeling Based on Operational Data and Neural Networks</title><link>http://arxiv.org/abs/2403.18739v1</link><description>Accurate predictions of when a component will fail are crucial when planningmaintenance, and by modeling the distribution of these failure times, survivalmodels have shown to be particularly useful in this context. The presentedmethodology is based on conventional neural network-based survival models thatare trained using data that is continuously gathered and stored at specifictimes, called snapshots. An important property of this type of training data isthat it can contain more than one snapshot from a specific individual whichresults in that standard maximum likelihood training can not be directlyapplied since the data is not independent. However, the papers show that if thedata is in a specific format where all snapshot times are the same for allindividuals, called homogeneously sampled, maximum likelihood training can beapplied and produce desirable results. In many cases, the data is nothomogeneously sampled and in this case, it is proposed to resample the data tomake it homogeneously sampled. How densely the dataset is sampled turns out tobe an important parameter; it should be chosen large enough to produce goodresults, but this also increases the size of the dataset which makes trainingslow. To reduce the number of samples needed during training, the paper alsoproposes a technique to, instead of resampling the dataset once before thetraining starts, randomly resample the dataset at the start of each epochduring the training. The proposed methodology is evaluated on both a simulateddataset and an experimental dataset of starter battery failures. The resultsshow that if the data is homogeneously sampled the methodology works asintended and produces accurate survival models. The results also show thatrandomly resampling the dataset on each epoch is an effective way to reduce thesize of the training data.</description><author>Olov Holmer, Mattias Krysander, Erik Frisk</author><pubDate>Wed, 27 Mar 2024 17:32:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18739v1</guid></item><item><title>Nonlinear model reduction for operator learning</title><link>http://arxiv.org/abs/2403.18735v1</link><description>Operator learning provides methods to approximate mappings betweeninfinite-dimensional function spaces. Deep operator networks (DeepONets) are anotable architecture in this field. Recently, an extension of DeepONet based onmodel reduction and neural networks, proper orthogonal decomposition(POD)-DeepONet, has been able to outperform other architectures in terms ofaccuracy for several benchmark tests. We extend this idea towards nonlinearmodel order reduction by proposing an efficient framework that combines neuralnetworks with kernel principal component analysis (KPCA) for operator learning.Our results demonstrate the superior performance of KPCA-DeepONet overPOD-DeepONet.</description><author>Hamidreza Eivazi, Stefan Wittek, Andreas Rausch</author><pubDate>Wed, 27 Mar 2024 17:24:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18735v1</guid></item><item><title>A vascular synthetic model for improved aneurysm segmentation and detection via Deep Neural Networks</title><link>http://arxiv.org/abs/2403.18734v1</link><description>We hereby present a full synthetic model, able to mimic the variousconstituents of the cerebral vascular tree: the cerebral arteries, thebifurcations and the intracranial aneurysms. By building this model, our goalwas to provide a substantial dataset of brain arteries which could be used by a3D Convolutional Neural Network (CNN) to either segment or detect/recognizevarious vascular diseases (such as artery dissection/thrombosis) or even someportions of the cerebral vasculature, such as the bifurcations or aneurysms. Inthis study, we will particularly focus on Intra-Cranial Aneurysm (ICA)detection and segmentation. The cerebral aneurysms most often occur on aparticular structure of the vascular tree named the Circle of Willis. Variousstudies have been conducted to detect and monitor the ICAs and those based onDeep Learning (DL) achieve the best performances. Specifically, in this work,we propose a full synthetic 3D model able to mimic the brain vasculature asacquired by Magnetic Resonance Angiography (MRA), and more particularly theTime Of Flight (TOF) principle. Among the various MRI modalities, the MRA-TOFallows to have a relatively good rendering of the blood vessels and isnon-invasive (no contrast liquid injection). Our model has been designed tosimultaneously mimic the arteries geometry, the ICA shape and the backgroundnoise. The geometry of the vascular tree is modeled thanks to an interpolationwith 3D Spline functions, and the statistical properties of the background MRInoise is collected from MRA acquisitions and reproduced within the model. Inthis work, we thoroughly describe the synthetic vasculature model, we build upa neural network designed for ICA segmentation and detection, and finally, wecarry out an in-depth evaluation of the performance gap gained thanks to thesynthetic model data augmentation.</description><author>Rafic Nader, Florent Autrusseau, Vincent L'Allinec, Romain Bourcier</author><pubDate>Wed, 27 Mar 2024 17:22:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18734v1</guid></item><item><title>Enhancing Manufacturing Quality Prediction Models through the Integration of Explainability Methods</title><link>http://arxiv.org/abs/2403.18731v1</link><description>This research presents a method that utilizes explainability techniques toamplify the performance of machine learning (ML) models in forecasting thequality of milling processes, as demonstrated in this paper through amanufacturing use case. The methodology entails the initial training of MLmodels, followed by a fine-tuning phase where irrelevant features identifiedthrough explainability methods are eliminated. This procedural refinementresults in performance enhancements, paving the way for potential reductions inmanufacturing costs and a better understanding of the trained ML models. Thisstudy highlights the usefulness of explainability techniques in both explainingand optimizing predictive models in the manufacturing realm.</description><author>Dennis Gross, Helge Spieker, Arnaud Gotlieb, Ricardo Knoblauch</author><pubDate>Wed, 27 Mar 2024 17:21:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18731v1</guid></item><item><title>Towards Image Ambient Lighting Normalization</title><link>http://arxiv.org/abs/2403.18730v1</link><description>Lighting normalization is a crucial but underexplored restoration task withbroad applications. However, existing works often simplify this task within thecontext of shadow removal, limiting the light sources to one andoversimplifying the scene, thus excluding complex self-shadows and restrictingsurface classes to smooth ones. Although promising, such simplifications hindergeneralizability to more realistic settings encountered in daily use. In thispaper, we propose a new challenging task termed Ambient Lighting Normalization(ALN), which enables the study of interactions between shadows, unifying imagerestoration and shadow removal in a broader context. To address the lack ofappropriate datasets for ALN, we introduce the large-scale high-resolutiondataset Ambient6K, comprising samples obtained from multiple light sources andincluding self-shadows resulting from complex geometries, which is the first ofits kind. For benchmarking, we select various mainstream methods and rigorouslyevaluate them on Ambient6K. Additionally, we propose IFBlend, a novel strongbaseline that maximizes Image-Frequency joint entropy to selectively restorelocal areas under different lighting conditions, without relying on shadowlocalization priors. Experiments show that IFBlend achieves SOTA scores onAmbient6K and exhibits competitive performance on conventional shadow removalbenchmarks compared to shadow-specific models with mask priors. The dataset,benchmark, and code are available at https://github.com/fvasluianu97/IFBlend.</description><author>Florin-Alexandru Vasluianu, Tim Seizinger, Zongwei Wu, Rakesh Ranjan, Radu Timofte</author><pubDate>Wed, 27 Mar 2024 17:20:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18730v1</guid></item><item><title>LION: Implicit Vision Prompt Tuning</title><link>http://arxiv.org/abs/2303.09992v3</link><description>Despite recent competitive performance across a range of vision tasks, visionTransformers still have an issue of heavy computational costs. Recently, visionprompt learning has provided an economic solution to this problem withoutfine-tuning the whole large-scale models. However, the efficiency of existingmodels are still far from satisfactory due to insertion of extensive promptsblocks and trick prompt designs. In this paper, we propose an efficient visionmodel named impLicit vIsion prOmpt tuNing (LION), which is motivated by deepimplicit models with stable memory costs for various complex tasks. Inparticular, we merely insect two equilibrium implicit layers in two ends of thepre-trained main backbone with parameters in the backbone frozen. Moreover, weprune the parameters in these two layers according to lottery hypothesis. Theperformance obtained by our LION are promising on a wide range of datasets. Inparticular, our LION reduces up to 11.5% of training parameter numbers whileobtaining higher performance compared with the state-of-the-art baseline VPT,especially under challenging scenes. Furthermore, we find that our proposedLION had a good generalization performance, making it an easy way to boosttransfer learning in the future.</description><author>Haixin Wang, Jianlong Chang, Xiao Luo, Jinan Sun, Zhouchen Lin, Qi Tian</author><pubDate>Wed, 27 Mar 2024 17:20:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09992v3</guid></item><item><title>Probabilistic Model Checking of Stochastic Reinforcement Learning Policies</title><link>http://arxiv.org/abs/2403.18725v1</link><description>We introduce a method to verify stochastic reinforcement learning (RL)policies. This approach is compatible with any RL algorithm as long as thealgorithm and its corresponding environment collectively adhere to the Markovproperty. In this setting, the future state of the environment should dependsolely on its current state and the action executed, independent of anyprevious states or actions. Our method integrates a verification technique,referred to as model checking, with RL, leveraging a Markov decision process, atrained RL policy, and a probabilistic computation tree logic (PCTL) formula tobuild a formal model that can be subsequently verified via the model checkerStorm. We demonstrate our method's applicability across multiple benchmarks,comparing it to baseline methods called deterministic safety estimates andnaive monolithic model checking. Our results show that our method is suited toverify stochastic RL policies.</description><author>Dennis Gross, Helge Spieker</author><pubDate>Wed, 27 Mar 2024 17:15:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18725v1</guid></item><item><title>NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models</title><link>http://arxiv.org/abs/2403.03100v2</link><description>While recent large-scale text-to-speech (TTS) models have achievedsignificant progress, they still fall short in speech quality, similarity, andprosody. Considering speech intricately encompasses various attributes (e.g.,content, prosody, timbre, and acoustic details) that pose significantchallenges for generation, a natural idea is to factorize speech intoindividual subspaces representing different attributes and generate themindividually. Motivated by it, we propose NaturalSpeech 3, a TTS system withnovel factorized diffusion models to generate natural speech in a zero-shotway. Specifically, 1) we design a neural codec with factorized vectorquantization (FVQ) to disentangle speech waveform into subspaces of content,prosody, timbre, and acoustic details; 2) we propose a factorized diffusionmodel to generate attributes in each subspace following its correspondingprompt. With this factorization design, NaturalSpeech 3 can effectively andefficiently model intricate speech with disentangled subspaces in adivide-and-conquer way. Experiments show that NaturalSpeech 3 outperforms thestate-of-the-art TTS systems on quality, similarity, prosody, andintelligibility, and achieves on-par quality with human recordings.Furthermore, we achieve better performance by scaling to 1B parameters and 200Khours of training data.</description><author>Zeqian Ju, Yuancheng Wang, Kai Shen, Xu Tan, Detai Xin, Dongchao Yang, Yanqing Liu, Yichong Leng, Kaitao Song, Siliang Tang, Zhizheng Wu, Tao Qin, Xiang-Yang Li, Wei Ye, Shikun Zhang, Jiang Bian, Lei He, Jinyu Li, Sheng Zhao</author><pubDate>Wed, 27 Mar 2024 17:14:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03100v2</guid></item><item><title>Nesting Particle Filters for Experimental Design in Dynamical Systems</title><link>http://arxiv.org/abs/2402.07868v2</link><description>In this paper, we propose a novel approach to Bayesian experimental designfor non-exchangeable data that formulates it as risk-sensitive policyoptimization. We develop the Inside-Out SMC$^2$ algorithm, a nested sequentialMonte Carlo technique to infer optimal designs, and embed it into a particleMarkov chain Monte Carlo framework to perform gradient-based policyamortization. Our approach is distinct from other amortized experimental designtechniques, as it does not rely on contrastive estimators. Numerical validationon a set of dynamical systems showcases the efficacy of our method incomparison to other state-of-the-art strategies.</description><author>Sahel Iqbal, Adrien Corenflos, Simo Särkkä, Hany Abdulsamad</author><pubDate>Wed, 27 Mar 2024 17:12:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07868v2</guid></item><item><title>A Comprehensive Review of Community Detection in Graphs</title><link>http://arxiv.org/abs/2309.11798v3</link><description>The study of complex networks has significantly advanced our understanding ofcommunity structures which serves as a crucial feature of real-world graphs.Detecting communities in graphs is a challenging problem with applications insociology, biology, and computer science. Despite the efforts of aninterdisciplinary community of scientists, a satisfactory solution to thisproblem has not yet been achieved. This review article delves into the topic ofcommunity detection in graphs, which serves as a thorough exposition of variouscommunity detection methods from perspectives of modularity-based method,spectral clustering, probabilistic modelling, and deep learning. Along with themethods, a new community detection method designed by us is also presented.Additionally, the performance of these methods on the datasets with and withoutground truth is compared. In conclusion, this comprehensive review provides adeep understanding of community detection in graphs.</description><author>Jiakang Li, Songning Lai, Zhihao Shuai, Yuan Tan, Yifan Jia, Mianyang Yu, Zichen Song, Xiaokang Peng, Ziyang Xu, Yongxin Ni, Haifeng Qiu, Jiayu Yang, Yutong Liu, Yonggang Lu</author><pubDate>Wed, 27 Mar 2024 17:12:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11798v3</guid></item><item><title>Semi-Supervised Learning for Deep Causal Generative Models</title><link>http://arxiv.org/abs/2403.18717v1</link><description>Developing models that can answer questions of the form "How would $x$ changeif $y$ had been $z$?" is fundamental for advancing medical image analysis.Training causal generative models that address such counterfactual questions,though, currently requires that all relevant variables have been observed andthat corresponding labels are available in training data. However, clinicaldata may not have complete records for all patients and state of the art causalgenerative models are unable to take full advantage of this. We thus develop,for the first time, a semi-supervised deep causal generative model thatexploits the causal relationships between variables to maximise the use of allavailable data. We explore this in the setting where each sample is eitherfully labelled or fully unlabelled, as well as the more clinically realisticcase of having different labels missing for each sample. We leverage techniquesfrom causal inference to infer missing values and subsequently generaterealistic counterfactuals, even for samples with incomplete labels.</description><author>Yasin Ibrahim, Hermione Warr, Konstantinos Kamnitsas</author><pubDate>Wed, 27 Mar 2024 17:06:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18717v1</guid></item><item><title>Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering Tasks</title><link>http://arxiv.org/abs/2401.07494v3</link><description>Computational efficiency and non-adversarial robustness are critical factorsin real-world engineering applications. Yet, conventional neural networks oftenfall short in addressing both simultaneously, or even separately. Drawinginsights from natural physical systems and existing literature, it is knownthat an input convex architecture enhances computational efficiency, while aLipschitz-constrained architecture bolsters non-adversarial robustness. Byleveraging the strengths of convexity and Lipschitz continuity, we develop anovel network architecture, termed Input Convex Lipschitz Recurrent NeuralNetworks. This model is explicitly designed for fast and robustoptimization-based tasks and outperforms existing recurrent units across aspectrum of engineering tasks in terms of computational efficiency andnon-adversarial robustness, including real-world solar irradiance predictionfor Solar PV system planning at LHT Holdings in Singapore and real-time ModelPredictive Control optimization for a nonlinear chemical reactor.</description><author>Zihao Wang, P S Pravin, Zhe Wu</author><pubDate>Wed, 27 Mar 2024 17:06:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07494v3</guid></item><item><title>Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding</title><link>http://arxiv.org/abs/2403.18715v1</link><description>Large Vision-Language Models (LVLMs) are increasingly adept at generatingcontextually detailed and coherent responses from visual inputs. However, theirapplication in multimodal decision-making and open-ended generation is hinderedby a notable rate of hallucinations, where generated text inaccuratelyrepresents the visual contents. To address this issue, this paper introducesthe Instruction Contrastive Decoding (ICD) method, a novel approach designed toreduce hallucinations during LVLM inference. Our method is inspired by ourobservation that what we call disturbance instructions significantly exacerbatehallucinations in multimodal fusion modules. ICD contrasts distributions fromstandard and instruction disturbance, thereby increasing alignment uncertaintyand effectively subtracting hallucinated concepts from the originaldistribution. Through comprehensive experiments on discriminative benchmarks(POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate thatICD significantly mitigates both object-level and attribute-levelhallucinations. Moreover, our method not only addresses hallucinations but alsosignificantly enhances the general perception and recognition capabilities ofLVLMs.</description><author>Xintong Wang, Jingheng Pan, Liang Ding, Chris Biemann</author><pubDate>Wed, 27 Mar 2024 17:04:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18715v1</guid></item><item><title>ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review</title><link>http://arxiv.org/abs/2305.03123v3</link><description>ChatGPT is another large language model (LLM) vastly available for theconsumers on their devices but due to its performance and ability to converseeffectively, it has gained a huge popularity amongst research as well asindustrial community. Recently, many studies have been published to show theeffectiveness, efficiency, integration, and sentiments of chatGPT and otherLLMs. In contrast, this study focuses on the important aspects that are mostlyoverlooked, i.e. sustainability, privacy, digital divide, and ethics andsuggests that not only chatGPT but every subsequent entry in the category ofconversational bots should undergo Sustainability, PrivAcy, Digital divide, andEthics (SPADE) evaluation. This paper discusses in detail the issues andconcerns raised over chatGPT in line with aforementioned characteristics. Wealso discuss the recent EU AI Act briefly in accordance with the SPADEevaluation. We support our hypothesis by some preliminary data collection andvisualizations along with hypothesized facts. We also suggest mitigations andrecommendations for each of the concerns. Furthermore, we also suggest somepolicies and recommendations for EU AI policy act concerning ethics, digitaldivide, and sustainability.</description><author>Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Weizheng Wang, Lewis Nkenyereye</author><pubDate>Wed, 27 Mar 2024 17:03:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03123v3</guid></item><item><title>Bringing Textual Prompt to AI-Generated Image Quality Assessment</title><link>http://arxiv.org/abs/2403.18714v1</link><description>AI-Generated Images (AGIs) have inherent multimodal nature. Unliketraditional image quality assessment (IQA) on natural scenarios, AGIs qualityassessment (AGIQA) takes the correspondence of image and its textual promptinto consideration. This is coupled in the ground truth score, which confusesthe unimodal IQA methods. To solve this problem, we introduce IP-IQA (AGIsQuality Assessment via Image and Prompt), a multimodal framework for AGIQA viacorresponding image and prompt incorporation. Specifically, we propose a novelincremental pretraining task named Image2Prompt for better understanding ofAGIs and their corresponding textual prompts. An effective and efficientimage-prompt fusion module, along with a novel special [QA] token, are alsoapplied. Both are plug-and-play and beneficial for the cooperation of image andits corresponding prompt. Experiments demonstrate that our IP-IQA achieves thestate-of-the-art on AGIQA-1k and AGIQA-3k datasets. Code will be available.</description><author>Bowen Qu, Haohui Li, Wei Gao</author><pubDate>Wed, 27 Mar 2024 17:02:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18714v1</guid></item><item><title>Empowering Data Mesh with Federated Learning</title><link>http://arxiv.org/abs/2403.17878v2</link><description>The evolution of data architecture has seen the rise of data lakes, aiming tosolve the bottlenecks of data management and promote intelligentdecision-making. However, this centralized architecture is limited by theproliferation of data sources and the growing demand for timely analysis andprocessing. A new data paradigm, Data Mesh, is proposed to overcome thesechallenges. Data Mesh treats domains as a first-class concern by distributingthe data ownership from the central team to each data domain, while keeping thefederated governance to monitor domains and their data products. Manymulti-million dollar organizations like Paypal, Netflix, and Zalando havealready transformed their data analysis pipelines based on this newarchitecture. In this decentralized architecture where data is locallypreserved by each domain team, traditional centralized machine learning isincapable of conducting effective analysis across multiple domains, especiallyfor security-sensitive organizations. To this end, we introduce a pioneeringapproach that incorporates Federated Learning into Data Mesh. To the best ofour knowledge, this is the first open-source applied work that represents acritical advancement toward the integration of federated learning methods intothe Data Mesh paradigm, underscoring the promising prospects forprivacy-preserving and decentralized data analysis strategies within Data Mesharchitecture.</description><author>Haoyuan Li, Salman Toor</author><pubDate>Wed, 27 Mar 2024 17:01:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17878v2</guid></item><item><title>SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable Transient-Free 3D reconstruction from Satellite Imagery</title><link>http://arxiv.org/abs/2403.18711v1</link><description>Current stereo-vision pipelines produce high accuracy 3D reconstruction whenusing multiple pairs or triplets of satellite images. However, these pipelinesare sensitive to the changes between images that can occur as a result ofmulti-date acquisitions. Such variations are mainly due to variable shadows,reflexions and transient objects (cars, vegetation). To take such changes intoaccount, Neural Radiance Fields (NeRF) have recently been applied to multi-datesatellite imagery. However, Neural methods are very compute-intensive, takingdozens of hours to learn, compared with minutes for standard stereo-visionpipelines. Following the ideas of Instant Neural Graphics Primitives we proposeto use an efficient sampling strategy and multi-resolution hash encoding toaccelerate the learning. Our model, Satellite Neural Graphics Primitives(SAT-NGP) decreases the learning time to 15 minutes while maintaining thequality of the 3D reconstruction.</description><author>Camille Billouard, Dawa Derksen, Emmanuelle Sarrazin, Bruno Vallet</author><pubDate>Wed, 27 Mar 2024 16:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18711v1</guid></item><item><title>Deep Learning for Traffic Flow Prediction using Cellular Automata-based Model and CNN-LSTM architecture</title><link>http://arxiv.org/abs/2403.18710v1</link><description>Recent works have attempted to use deep learning to predict future states oftraffic flow, but have met with mixed results. These approaches face two keychallenges. First, training deep learning neural networks requires largeamounts of training data which are not yet easily available for traffic flowsystems. Second, even when data is available, the neural networks requireaccess to historical data that covers most possible traffic flow dynamics tosuccessfully predict future traffic states. Specifically, these deep learningapproaches do not fully leverage domain-knowledge about traffic flow dynamics,despite a significant existing knowledge-base. In this work, we propose tosolve both issues using a Convolutional Neural Network (CNNs) with Long ShortTerm Memory (LSTM) deep learning architecture to successfully predict trafficflow, while leveraging a cellular automata-based statistical mechanics model oftraffic flow to generate training and test data. Another major contribution ofthis paper is the insight that training data for a large traffic system canactually be sampled from the simulations of a much smaller traffic system. Thisis achieved through observing that the normalized energy distribution of thestatistical mechanics model is scale invariant, which significantly eases theburden of data generation for large scale traffic systems. The resultingsimulations indicate good agreement between the predicted and the true trafficflow dynamics.</description><author>Zhaohui Yang, Kshitij Jerath</author><pubDate>Wed, 27 Mar 2024 16:57:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18710v1</guid></item><item><title>Dense Vision Transformer Compression with Few Samples</title><link>http://arxiv.org/abs/2403.18708v1</link><description>Few-shot model compression aims to compress a large model into a more compactone with only a tiny training set (even without labels). Block-level pruninghas recently emerged as a leading technique in achieving high accuracy and lowlatency in few-shot CNN compression. But, few-shot compression for VisionTransformers (ViT) remains largely unexplored, which presents a new challenge.In particular, the issue of sparse compression exists in traditional CNNfew-shot methods, which can only produce very few compressed models ofdifferent model sizes. This paper proposes a novel framework for few-shot ViTcompression named DC-ViT. Instead of dropping the entire block, DC-ViTselectively eliminates the attention module while retaining and reusingportions of the MLP module. DC-ViT enables dense compression, which outputsnumerous compressed models that densely populate the range of model complexity.DC-ViT outperforms state-of-the-art few-shot compression methods by asignificant margin of 10 percentage points, along with lower latency in thecompression of ViT and its variants.</description><author>Hanxiao Zhang, Yifan Zhou, Guo-Hua Wang, Jianxin Wu</author><pubDate>Wed, 27 Mar 2024 16:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18708v1</guid></item><item><title>Conditional Wasserstein Distances with Applications in Bayesian OT Flow Matching</title><link>http://arxiv.org/abs/2403.18705v1</link><description>In inverse problems, many conditional generative models approximate theposterior measure by minimizing a distance between the joint measure and itslearned approximation. While this approach also controls the distance betweenthe posterior measures in the case of the Kullback--Leibler divergence, this isin general not hold true for the Wasserstein distance. In this paper, weintroduce a conditional Wasserstein distance via a set of restricted couplingsthat equals the expected Wasserstein distance of the posteriors. Interestingly,the dual formulation of the conditional Wasserstein-1 flow resembles losses inthe conditional Wasserstein GAN literature in a quite natural way. We derivetheoretical properties of the conditional Wasserstein distance, characterizethe corresponding geodesics and velocity fields as well as the flow ODEs.Subsequently, we propose to approximate the velocity fields by relaxing theconditional Wasserstein distance. Based on this, we propose an extension of OTFlow Matching for solving Bayesian inverse problems and demonstrate itsnumerical advantages on an inverse problem and class-conditional imagegeneration.</description><author>Jannis Chemseddine, Paul Hagemann, Christian Wald, Gabriele Steidl</author><pubDate>Wed, 27 Mar 2024 16:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18705v1</guid></item><item><title>Fpga-Based Neural Thrust Controller for UAVs</title><link>http://arxiv.org/abs/2403.18703v1</link><description>The advent of unmanned aerial vehicles (UAVs) has improved a variety offields by providing a versatile, cost-effective and accessible platform forimplementing state-of-the-art algorithms. To accomplish a broader range oftasks, there is a growing need for enhanced on-board computing to cope withincreasing complexity and dynamic environmental conditions. Recent advanceshave seen the application of Deep Neural Networks (DNNs), particularly incombination with Reinforcement Learning (RL), to improve the adaptability andperformance of UAVs, especially in unknown environments. However, thecomputational requirements of DNNs pose a challenge to the limited computingresources available on many UAVs. This work explores the use of FieldProgrammable Gate Arrays (FPGAs) as a viable solution to this challenge,offering flexibility, high performance, energy and time efficiency. We proposea novel hardware board equipped with an Artix-7 FPGA for a popular open-sourcemicro-UAV platform. We successfully validate its functionality by implementingan RL-based low-level controller using real-world experiments.</description><author>Sharif Azem, David Scheunert, Mengguang Li, Jonas Gehrunger, Kai Cui, Christian Hochberger, Heinz Koepp</author><pubDate>Wed, 27 Mar 2024 16:52:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18703v1</guid></item><item><title>Incorporating simulated spatial context information improves the effectiveness of contrastive learning models</title><link>http://arxiv.org/abs/2401.15120v2</link><description>Visual learning often occurs in a specific context, where an agent acquiresskills through exploration and tracking of its location in a consistentenvironment. The historical spatial context of the agent provides a similaritysignal for self-supervised contrastive learning. We present a unique approach,termed Environmental Spatial Similarity (ESS), that complements existingcontrastive learning methods. Using images from simulated, photorealisticenvironments as an experimental setting, we demonstrate that ESS outperformstraditional instance discrimination approaches. Moreover, sampling additionaldata from the same environment substantially improves accuracy and provides newaugmentations. ESS allows remarkable proficiency in room classification andspatial prediction tasks, especially in unfamiliar environments. This learningparadigm has the potential to enable rapid visual learning in agents operatingin new environments with unique visual characteristics. Potentiallytransformative applications span from robotics to space exploration. Our proofof concept demonstrates improved efficiency over methods that rely onextensive, disconnected datasets.</description><author>Lizhen Zhu, James Z. Wang, Wonseuk Lee, Brad Wyble</author><pubDate>Wed, 27 Mar 2024 16:49:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15120v2</guid></item><item><title>Stochastic Approximation with Delayed Updates: Finite-Time Rates under Markovian Sampling</title><link>http://arxiv.org/abs/2402.11800v3</link><description>Motivated by applications in large-scale and multi-agent reinforcementlearning, we study the non-asymptotic performance of stochastic approximation(SA) schemes with delayed updates under Markovian sampling. While the effect ofdelays has been extensively studied for optimization, the manner in which theyinteract with the underlying Markov process to shape the finite-timeperformance of SA remains poorly understood. In this context, our first maincontribution is to show that under time-varying bounded delays, the delayed SAupdate rule guarantees exponentially fast convergence of the \emph{lastiterate} to a ball around the SA operator's fixed point. Notably, our bound is\emph{tight} in its dependence on both the maximum delay $\tau_{max}$, and themixing time $\tau_{mix}$. To achieve this tight bound, we develop a novelinductive proof technique that, unlike various existing delayed-optimizationanalyses, relies on establishing uniform boundedness of the iterates. As such,our proof may be of independent interest. Next, to mitigate the impact of themaximum delay on the convergence rate, we provide the first finite-timeanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,we show that the exponent of convergence of this scheme gets scaled down by$\tau_{avg}$, as opposed to $\tau_{max}$ for the vanilla delayed SA rule; here,$\tau_{avg}$ denotes the average delay across all iterations. Moreover, theadaptive scheme requires no prior knowledge of the delay sequence for step-sizetuning. Our theoretical findings shed light on the finite-time effects ofdelays for a broad class of algorithms, including TD learning, Q-learning, andstochastic gradient descent under Markovian sampling.</description><author>Arman Adibi, Nicolo Dal Fabbro, Luca Schenato, Sanjeev Kulkarni, H. Vincent Poor, George J. Pappas, Hamed Hassani, Aritra Mitra</author><pubDate>Wed, 27 Mar 2024 16:48:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11800v3</guid></item><item><title>Contrastive Learning with Orthonormal Anchors (CLOA)</title><link>http://arxiv.org/abs/2403.18699v1</link><description>This study focuses on addressing the instability issues prevalent incontrastive learning, specifically examining the InfoNCE loss function and itsderivatives. We reveal a critical observation that these loss functions exhibita restrictive behavior, leading to a convergence phenomenon where embeddingstend to merge into a singular point. This "over-fusion" effect detrimentallyaffects classification accuracy in subsequent supervised-learning tasks.Through theoretical analysis, we demonstrate that embeddings, when equalized orconfined to a rank-1 linear subspace, represent a local minimum for InfoNCE. Inresponse to this challenge, our research introduces an innovative strategy thatleverages the same or fewer labeled data than typically used in the fine-tuningphase. The loss we proposed, Orthonormal Anchor Regression Loss, is designed todisentangle embedding clusters, significantly enhancing the distinctiveness ofeach embedding while simultaneously ensuring their aggregation into dense,well-defined clusters. Our method demonstrates remarkable improvements withjust a fraction of the conventional label requirements, as evidenced by ourresults on CIFAR10 and CIFAR100 datasets.</description><author>Huanran Li, Daniel Pimentel-Alarcón</author><pubDate>Wed, 27 Mar 2024 16:48:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18699v1</guid></item><item><title>The Invalsi Benchmark: measuring Language Models Mathematical and Language understanding in Italian</title><link>http://arxiv.org/abs/2403.18697v1</link><description>While Italian is by all metrics a high resource language, currently, thereare isn't a Language Model pre-trained exclusively in this language. Thisresults in a lower number of available benchmarks to evaluate the performanceof language models in Italian. This work presents two new benchmarks to evaluate the models performance onmathematical understanding and language understanding in Italian. Thesebenchmarks are based on real tests that are undertaken by students of agebetween 11 and 18 within the Italian school system and have therefore beenvalidated by several experts in didactics and pedagogy. To validate this dataset we evaluate the performance of 9 language modelsthat are the best performing when writing in Italian, including our ownfine-tuned models. We show that this is a challenging benchmark where currentlanguage models are bound by 60\% accuracy. We believe that the release of this dataset paves the way for improvingfuture models mathematical and language understanding in Italian.</description><author>Andrea Esuli, Giovanni Puccetti</author><pubDate>Wed, 27 Mar 2024 16:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18697v1</guid></item><item><title>Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning</title><link>http://arxiv.org/abs/2303.12091v3</link><description>Semi-supervised learning (SSL) methods assume that labeled data, unlabeleddata and test data are from the same distribution. Open-set semi-supervisedlearning (Open-set SSL) considers a more practical scenario, where unlabeleddata and test data contain new categories (outliers) not observed in labeleddata (inliers). Most previous works focused on outlier detection via binaryclassifiers, which suffer from insufficient scalability and inability todistinguish different types of uncertainty. In this paper, we propose a novelframework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle theselimitations. Concretely, we first introduce evidential deep learning (EDL) asan outlier detector to quantify different types of uncertainty, and designdifferent uncertainty metrics for self-training and inference. Furthermore, wepropose a novel adaptive negative optimization strategy, making EDL moretailored to the unlabeled dataset containing both inliers and outliers. Asdemonstrated empirically, our proposed method outperforms existingstate-of-the-art methods across four datasets.</description><author>Yang Yu, Danruo Deng, Furui Liu, Yueming Jin, Qi Dou, Guangyong Chen, Pheng-Ann Heng</author><pubDate>Wed, 27 Mar 2024 16:44:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12091v3</guid></item><item><title>Annolid: Annotate, Segment, and Track Anything You Need</title><link>http://arxiv.org/abs/2403.18690v1</link><description>Annolid is a deep learning-based software package designed for thesegmentation, labeling, and tracking of research targets within video files,focusing primarily on animal behavior analysis. Based on state-of-the-artinstance segmentation methods, Annolid now harnesses the Cutie video objectsegmentation model to achieve resilient, markerless tracking of multipleanimals from single annotated frames, even in environments in which they may bepartially or entirely concealed by environmental features or by one another.Our integration of Segment Anything and Grounding-DINO strategies additionallyenables the automatic masking and segmentation of recognizable animals andobjects by text command, removing the need for manual annotation. Annolid'scomprehensive approach to object segmentation flexibly accommodates a broadspectrum of behavior analysis applications, enabling the classification ofdiverse behavioral states such as freezing, digging, pup huddling, and socialinteractions in addition to the tracking of animals and their body parts.</description><author>Chen Yang, Thomas A. Cleland</author><pubDate>Wed, 27 Mar 2024 16:41:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18690v1</guid></item><item><title>Vision Transformer-Based Deep Learning for Histologic Classification of Endometrial Cancer</title><link>http://arxiv.org/abs/2312.08479v2</link><description>Endometrial cancer, the fourth most common cancer in females in the UnitedStates, with the lifetime risk for developing this disease is approximately2.8% in women. Precise histologic evaluation and molecular classification ofendometrial cancer is important for effective patient management anddetermining the best treatment modalities. This study introduces EndoNet, whichuses convolutional neural networks for extracting histologic features and avision transformer for aggregating these features and classifying slides basedon their visual characteristics into high- and low- grade. The model wastrained on 929 digitized hematoxylin and eosin-stained whole-slide images ofendometrial cancer from hysterectomy cases at Dartmouth-Health. It classifiesthese slides into low-grade (Endometroid Grades 1 and 2) and high-grade(endometroid carcinoma FIGO grade 3, uterine serous carcinoma, carcinosarcoma)categories. EndoNet was evaluated on an internal test set of 110 patients andan external test set of 100 patients from the public TCGA database. The modelachieved a weighted average F1-score of 0.91 (95% CI: 0.86-0.95) and an AUC of0.95 (95% CI: 0.89-0.99) on the internal test, and 0.86 (95% CI: 0.80-0.94) forF1-score and 0.86 (95% CI: 0.75-0.93) for AUC on the external test. Pendingfurther validation, EndoNet has the potential to support pathologists withoutthe need of manual annotations in classifying the grades of gynecologicpathology tumors.</description><author>Manu Goyal, Laura J. Tafe, James X. Feng, Kristen E. Muller, Liesbeth Hondelink, Jessica L. Bentz, Saeed Hassanpour</author><pubDate>Wed, 27 Mar 2024 16:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08479v2</guid></item><item><title>InceptionTime vs. Wavelet -- A comparison for time series classification</title><link>http://arxiv.org/abs/2403.18687v1</link><description>Neural networks were used to classify infrasound data. Two differentapproaches were compared. One based on the direct classification of time seriesdata, using a custom implementation of the InceptionTime network. For the otherapproach, we generated 2D images of the wavelet transformation of the signals,which were subsequently classified using a ResNet implementation. Choosingappropriate hyperparameter settings, both achieve a classification accuracy ofabove 90 %, with the direct approach reaching 95.2 %.</description><author>Daniel Klenkert, Daniel Schaeffer, Julian Stauch</author><pubDate>Wed, 27 Mar 2024 16:34:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18687v1</guid></item><item><title>Representatividad Muestral en la Incertidumbre Simétrica Multivariada para la Selección de Atributos</title><link>http://arxiv.org/abs/2403.18685v1</link><description>In this work, we analyze the behavior of the multivariate symmetricuncertainty (MSU) measure through the use of statistical simulation techniquesunder various mixes of informative and non-informative randomly generatedfeatures. Experiments show how the number of attributes, their cardinalities,and the sample size affect the MSU. In this thesis, through observation ofresults, it is proposed an heuristic condition that preserves good quality inthe MSU under different combinations of these three factors, providing a newuseful criterion to help drive the process of dimension reduction. -- En el presente trabajo hemos analizado el comportamiento de una versi\'onmultivariada de la incertidumbre sim\'etrica a trav\'es de t\'ecnicas desimulaci\'on estad\'isticas sobre varias combinaciones de atributosinformativos y no-informativos generados de forma aleatoria. Los experimentosmuestran como el n\'umero de atributos, sus cardinalidades y el tama\~nomuestral afectan al MSU como medida. En esta tesis, mediante la observaci\'onde resultados hemos propuesto una condici\'on que preserva una buena calidad enel MSU bajo diferentes combinaciones de los tres factores mencionados, lo cualprovee un nuevo y valioso criterio para llevar a cabo el proceso de reducci\'onde dimensionalidad.</description><author>Gustavo Sosa-Cabrera</author><pubDate>Wed, 27 Mar 2024 16:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18685v1</guid></item><item><title>Scaling Laws For Dense Retrieval</title><link>http://arxiv.org/abs/2403.18684v1</link><description>Scaling up neural models has yielded significant advancements in a wide arrayof tasks, particularly in language generation. Previous studies have found thatthe performance of neural models frequently adheres to predictable scalinglaws, correlated with factors such as training set size and model size. Thisinsight is invaluable, especially as large-scale experiments grow increasinglyresource-intensive. Yet, such scaling law has not been fully explored in denseretrieval due to the discrete nature of retrieval metrics and complexrelationships between training data and model sizes in retrieval tasks. In thisstudy, we investigate whether the performance of dense retrieval models followsthe scaling law as other neural models. We propose to use contrastivelog-likelihood as the evaluation metric and conduct extensive experiments withdense retrieval models implemented with different numbers of parameters andtrained with different amounts of annotated data. Results indicate that, underour settings, the performance of dense retrieval models follows a precisepower-law scaling related to the model size and the number of annotations.Additionally, we examine scaling with prevalent data augmentation methods toassess the impact of annotation quality, and apply the scaling law to find thebest resource allocation strategy under a budget constraint. We believe thatthese insights will significantly contribute to understanding the scalingeffect of dense retrieval models and offer meaningful guidance for futureresearch endeavors.</description><author>Yan Fang, Jingtao Zhan, Qingyao Ai, Jiaxin Mao, Weihang Su, Jia Chen, Yiqun Liu</author><pubDate>Wed, 27 Mar 2024 16:27:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18684v1</guid></item><item><title>Automated Construction of Time-Space Diagrams for Traffic Analysis Using Street-View Video Sequence</title><link>http://arxiv.org/abs/2308.06098v2</link><description>Time-space diagrams are essential tools for analyzing traffic patterns andoptimizing transportation infrastructure and traffic management strategies.Traditional data collection methods for these diagrams have limitations interms of temporal and spatial coverage. Recent advancements in cameratechnology have overcome these limitations and provided extensive urban data.In this study, we propose an innovative approach to constructing time-spacediagrams by utilizing street-view video sequences captured by cameras mountedon moving vehicles. Using the state-of-the-art YOLOv5, StrongSORT, andphotogrammetry techniques for distance calculation, we can infer vehicletrajectories from the video data and generate time-space diagrams. To evaluatethe effectiveness of our proposed method, we utilized datasets from the KITTIcomputer vision benchmark suite. The evaluation results demonstrate that ourapproach can generate trajectories from video data, although there are someerrors that can be mitigated by improving the performance of the detector,tracker, and distance calculation components. In conclusion, the utilization ofstreet-view video sequences captured by cameras mounted on moving vehicles,combined with state-of-the-art computer vision techniques, has immensepotential for constructing comprehensive time-space diagrams. These diagramsoffer valuable insights into traffic patterns and contribute to the design oftransportation infrastructure and traffic management strategies.</description><author>Tanay Rastogi, Mårten Björkman</author><pubDate>Wed, 27 Mar 2024 16:26:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06098v2</guid></item><item><title>TransFusion: Contrastive Learning with Transformers</title><link>http://arxiv.org/abs/2403.18681v1</link><description>This paper proposes a novel framework, TransFusion, designed to make theprocess of contrastive learning more analytical and explainable. TransFusionconsists of attention blocks whose softmax being replaced by ReLU, and itsfinal block's weighted-sum operation is truncated to leave the adjacency matrixas the output. The model is trained by minimizing the Jensen-Shannon Divergencebetween its output and the target affinity matrix, which indicates whether eachpair of samples belongs to the same or different classes. The main contributionof TransFusion lies in defining a theoretical limit for answering twofundamental questions in the field: the maximum level of data augmentation andthe minimum batch size required for effective contrastive learning.Furthermore, experimental results indicate that TransFusion successfullyextracts features that isolate clusters from complex real-world data, leadingto improved classification accuracy in downstream tasks.</description><author>Huanran Li, Daniel Pimentel-Alarcón</author><pubDate>Wed, 27 Mar 2024 16:24:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18681v1</guid></item><item><title>Beyond Static Evaluation: A Dynamic Approach to Assessing AI Assistants' API Invocation Capabilities</title><link>http://arxiv.org/abs/2403.11128v2</link><description>With the rise of Large Language Models (LLMs), AI assistants' ability toutilize tools, especially through API calls, has advanced notably. Thisprogress has necessitated more accurate evaluation methods. Many existingstudies adopt static evaluation, where they assess AI assistants' API callbased on pre-defined dialogue histories. However, such evaluation method can bemisleading, as an AI assistant might fail in generating API calls frompreceding human interaction in real cases. Instead of the resource-intensivemethod of direct human-machine interactions, we propose Automated DynamicEvaluation (AutoDE) to assess an assistant's API call capability without humaninvolvement. In our framework, we endeavor to closely mirror genuine humanconversation patterns in human-machine interactions, using a LLM-based useragent, equipped with a user script to ensure human alignment. Experimentalresults highlight that AutoDE uncovers errors overlooked by static evaluations,aligning more closely with human assessment. Testing four AI assistants usingour crafted benchmark, our method further mirrored human evaluation compared toconventional static evaluations.</description><author>Honglin Mu, Yang Xu, Yunlong Feng, Xiaofeng Han, Yitong Li, Yutai Hou, Wanxiang Che</author><pubDate>Wed, 27 Mar 2024 16:22:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11128v2</guid></item><item><title>NL-ITI: Optimizing Probing and Intervention for Improvement of ITI Method</title><link>http://arxiv.org/abs/2403.18680v1</link><description>Large Language Models (LLM) are prone to returning false information. Itconstitutes one of major challenges in the AI field. In our work, we exploreparadigm introduced by Inference-Time-Intervention (ITI). In first stage, itidentifies attention heads, which contain the highest amount of desired type ofknowledge (e.g., truthful). Afterwards, during inference, LLM activations areshifted for chosen subset of attention heads. We further improved the ITIframework by introducing a nonlinear probing and multi-token intervention -Non-Linear ITI (NL-ITI). NL-ITI is tested on diverse multiple-choicebenchmarks, including TruthfulQA, on which we report around 14% MC1 metricimprovement with respect to the baseline ITI results. NL-ITI achieves alsoencouraging results on other testsets - on Business Ethics subdomain of MMLU,around 18% MC1 improvement over baseline LLaMA2-7B. Additionally, NL-ITIperforms better while being less invasive in the behavior of LLM at the sametime (as measured by Kullback-Leibler divergence).</description><author>Jakub Hoscilowicz, Adam Wiacek, Jan Chojnacki, Adam Cieslak, Leszek Michon, Vitalii Urbanevych, Artur Janicki</author><pubDate>Wed, 27 Mar 2024 16:22:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18680v1</guid></item><item><title>Deep Learning for Robust and Explainable Models in Computer Vision</title><link>http://arxiv.org/abs/2403.18674v1</link><description>Recent breakthroughs in machine and deep learning (ML and DL) research haveprovided excellent tools for leveraging enormous amounts of data and optimizinghuge models with millions of parameters to obtain accurate networks for imageprocessing. These developments open up tremendous opportunities for usingartificial intelligence (AI) in the automation and human assisted AI industry.However, as more and more models are deployed and used in practice, manychallenges have emerged. This thesis presents various approaches that addressrobustness and explainability challenges for using ML and DL in practice. Robustness and reliability are the critical components of any model beforecertification and deployment in practice. Deep convolutional neural networks(CNNs) exhibit vulnerability to transformations of their inputs, such asrotation and scaling, or intentional manipulations as described in theadversarial attack literature. In addition, building trust in AI-based modelsrequires a better understanding of current models and developing methods thatare more explainable and interpretable a priori. This thesis presents developments in computer vision models' robustness andexplainability. Furthermore, this thesis offers an example of using visionmodels' feature response visualization (models' interpretations) to improverobustness despite interpretability and robustness being seemingly unrelated inthe related research. Besides methodological developments for robust andexplainable vision models, a key message of this thesis is introducing modelinterpretation techniques as a tool for understanding vision models andimproving their design and robustness. In addition to the theoreticaldevelopments, this thesis demonstrates several applications of ML and DL indifferent contexts, such as medical imaging and affective computing.</description><author>Mohammadreza Amirian</author><pubDate>Wed, 27 Mar 2024 16:17:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18674v1</guid></item><item><title>Guided Distant Supervision for Multilingual Relation Extraction Data: Adapting to a New Language</title><link>http://arxiv.org/abs/2403.17143v2</link><description>Relation extraction is essential for extracting and understandingbiographical information in the context of digital humanities and relatedsubjects. There is a growing interest in the community to build datasetscapable of training machine learning models to extract relationships. However,annotating such datasets can be expensive and time-consuming, in addition tobeing limited to English. This paper applies guided distant supervision tocreate a large biographical relationship extraction dataset for German. Ourdataset, composed of more than 80,000 instances for nine relationship types, isthe largest biographical German relationship extraction dataset. We also createa manually annotated dataset with 2000 instances to evaluate the models andrelease it together with the dataset compiled using guided distant supervision.We train several state-of-the-art machine learning models on the automaticallycreated dataset and release them as well. Furthermore, we experiment withmultilingual and cross-lingual experiments that could benefit many low-resourcelanguages.</description><author>Alistair Plum, Tharindu Ranasinghe, Christoph Purschke</author><pubDate>Wed, 27 Mar 2024 16:15:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17143v2</guid></item><item><title>Fact Checking Beyond Training Set</title><link>http://arxiv.org/abs/2403.18671v1</link><description>Evaluating the veracity of everyday claims is time consuming and in somecases requires domain expertise. We empirically demonstrate that the commonlyused fact checking pipeline, known as the retriever-reader, suffers fromperformance deterioration when it is trained on the labeled data from onedomain and used in another domain. Afterwards, we delve into each component ofthe pipeline and propose novel algorithms to address this problem. We proposean adversarial algorithm to make the retriever component robust againstdistribution shift. Our core idea is to initially train a bi-encoder on thelabeled source data, and then, to adversarially train two separate document andclaim encoders using unlabeled target data. We then focus on the readercomponent and propose to train it such that it is insensitive towards the orderof claims and evidence documents. Our empirical evaluations support thehypothesis that such a reader shows a higher robustness against distributionshift. To our knowledge, there is no publicly available multi-topic factchecking dataset. Thus, we propose a simple automatic method to re-purpose twowell-known fact checking datasets. We then construct eight fact checkingscenarios from these datasets, and compare our model to a set of strongbaseline models, including recent domain adaptation models that use GPT4 forgenerating synthetic data.</description><author>Payam Karisani, Heng Ji</author><pubDate>Wed, 27 Mar 2024 16:15:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18671v1</guid></item><item><title>Aiming for Relevance</title><link>http://arxiv.org/abs/2403.18668v1</link><description>Vital signs are crucial in intensive care units (ICUs). They are used totrack the patient's state and to identify clinically significant changes.Predicting vital sign trajectories is valuable for early detection of adverseevents. However, conventional machine learning metrics like RMSE often fail tocapture the true clinical relevance of such predictions. We introduce novelvital sign prediction performance metrics that align with clinical contexts,focusing on deviations from clinical norms, overall trends, and trenddeviations. These metrics are derived from empirical utility curves obtained ina previous study through interviews with ICU clinicians. We validate themetrics' usefulness using simulated and real clinical datasets (MIMIC andeICU). Furthermore, we employ these metrics as loss functions for neuralnetworks, resulting in models that excel in predicting clinically significantevents. This research paves the way for clinically relevant machine learningmodel evaluation and optimization, promising to improve ICU patient care. 10pages, 9 figures.</description><author>Bar Eini Porat, Danny Eytan, Uri Shalit</author><pubDate>Wed, 27 Mar 2024 16:11:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18668v1</guid></item><item><title>Improving Content Recommendation: Knowledge Graph-Based Semantic Contrastive Learning for Diversity and Cold-Start Users</title><link>http://arxiv.org/abs/2403.18667v1</link><description>Addressing the challenges related to data sparsity, cold-start problems, anddiversity in recommendation systems is both crucial and demanding. Many currentsolutions leverage knowledge graphs to tackle these issues by combining bothitem-based and user-item collaborative signals. A common trend in theseapproaches focuses on improving ranking performance at the cost of escalatingmodel complexity, reducing diversity, and complicating the task. It isessential to provide recommendations that are both personalized and diverse,rather than solely relying on achieving high rank-based performance, such asClick-through Rate, Recall, etc. In this paper, we propose a hybrid multi-tasklearning approach, training on user-item and item-item interactions. We applyitem-based contrastive learning on descriptive text, sampling positive andnegative pairs based on item metadata. Our approach allows the model to betterunderstand the relationships between entities within the knowledge graph byutilizing semantic information from text. It leads to more accurate, relevant,and diverse user recommendations and a benefit that extends even to cold-startusers who have few interactions with items. We perform extensive experiments ontwo widely used datasets to validate the effectiveness of our approach. Ourfindings demonstrate that jointly training user-item interactions anditem-based signals using synopsis text is highly effective. Furthermore, ourresults provide evidence that item-based contrastive learning enhances thequality of entity embeddings, as indicated by metrics such as uniformity andalignment.</description><author>Yejin Kim, Scott Rome, Kevin Foley, Mayur Nankani, Rimon Melamed, Javier Morales, Abhay Yadav, Maria Peifer, Sardar Hamidian, H. Howie Huang</author><pubDate>Wed, 27 Mar 2024 16:11:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18667v1</guid></item><item><title>SeSaMe: A Framework to Simulate Self-Reported Ground Truth for Mental Health Sensing Studies</title><link>http://arxiv.org/abs/2403.17219v2</link><description>Advances in mobile and wearable technologies have enabled the potential topassively monitor a person's mental, behavioral, and affective health. Theseapproaches typically rely on longitudinal collection of self-reported outcomes,e.g., depression, stress, and anxiety, to train machine learning (ML) models.However, the need to continuously self-report adds a significant burden on theparticipants, often resulting in attrition, missing labels, or insincereresponses. In this work, we introduce the Scale Scores Simulation using MentalModels (SeSaMe) framework to alleviate participants' burden in digital mentalhealth studies. By leveraging pre-trained large language models (LLMs), SeSaMeenables the simulation of participants' responses on psychological scales. InSeSaMe, researchers can prompt LLMs with information on participants' internalbehavioral dispositions, enabling LLMs to construct mental models ofparticipants to simulate their responses on psychological scales. Wedemonstrate an application of SeSaMe, where we use GPT-4 to simulate responseson one scale using responses from another as behavioral information. We alsoevaluate the alignment between human and SeSaMe-simulated responses topsychological scales. Then, we present experiments to inspect the utility ofSeSaMe-simulated responses as ground truth in training ML models by replicatingestablished depression and anxiety screening tasks from a previous study. Ourresults indicate SeSaMe to be a promising approach, but its alignment may varyacross scales and specific prediction objectives. We also observed that modelperformance with simulated data was on par with using the real data fortraining in most evaluation scenarios. We conclude by discussing the potentialimplications of SeSaMe in addressing some challenges researchers face withground-truth collection in passive sensing studies.</description><author>Akshat Choube, Vedant Das Swain, Varun Mishra</author><pubDate>Wed, 27 Mar 2024 16:08:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17219v2</guid></item><item><title>Neural Network-Based Piecewise Survival Models</title><link>http://arxiv.org/abs/2403.18664v1</link><description>In this paper, a family of neural network-based survival models is presented.The models are specified based on piecewise definitions of the hazard functionand the density function on a partitioning of the time; both constant andlinear piecewise definitions are presented, resulting in a family of fourmodels. The models can be seen as an extension of the commonly useddiscrete-time and piecewise exponential models and thereby add flexibility tothis set of standard models. Using a simulated dataset the models are shown toperform well compared to the highly expressive, state-of-the-art energy-basedmodel, while only requiring a fraction of the computation time.</description><author>Olov Holmer, Erik Frisk, Mattias Krysander</author><pubDate>Wed, 27 Mar 2024 16:08:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18664v1</guid></item><item><title>SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using Neural Radiance Fields</title><link>http://arxiv.org/abs/2311.15803v3</link><description>In rapidly-evolving domains such as autonomous driving, the use of multiplesensors with different modalities is crucial to ensure high operationalprecision and stability. To correctly exploit the provided information by eachsensor in a single common frame, it is essential for these sensors to beaccurately calibrated. In this paper, we leverage the ability of NeuralRadiance Fields (NeRF) to represent different sensors modalities in a commonvolumetric representation to achieve robust and accurate spatio-temporal sensorcalibration. By designing a partitioning approach based on the visible part ofthe scene for each sensor, we formulate the calibration problem using only theoverlapping areas. This strategy results in a more robust and accuratecalibration that is less prone to failure. We demonstrate that our approachworks on outdoor urban scenes by validating it on multiple established drivingdatasets. Results show that our method is able to get better accuracy androbustness compared to existing methods.</description><author>Quentin Herau, Nathan Piasco, Moussab Bennehar, Luis Roldão, Dzmitry Tsishkou, Cyrille Migniot, Pascal Vasseur, Cédric Demonceaux</author><pubDate>Wed, 27 Mar 2024 16:05:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15803v3</guid></item><item><title>InstructBrush: Learning Attention-based Instruction Optimization for Image Editing</title><link>http://arxiv.org/abs/2403.18660v1</link><description>In recent years, instruction-based image editing methods have garneredsignificant attention in image editing. However, despite encompassing a widerange of editing priors, these methods are helpless when handling editing tasksthat are challenging to accurately describe through language. We proposeInstructBrush, an inversion method for instruction-based image editing methodsto bridge this gap. It extracts editing effects from exemplar image pairs asediting instructions, which are further applied for image editing. Two keytechniques are introduced into InstructBrush, Attention-based InstructionOptimization and Transformation-oriented Instruction Initialization, to addressthe limitations of the previous method in terms of inversion effects andinstruction generalization. To explore the ability of instruction inversionmethods to guide image editing in open scenarios, we establish aTransformationOriented Paired Benchmark (TOP-Bench), which contains a rich setof scenes and editing types. The creation of this benchmark paves the way forfurther exploration of instruction inversion. Quantitatively and qualitatively,our approach achieves superior performance in editing and is more semanticallyconsistent with the target editing effects.</description><author>Ruoyu Zhao, Qingnan Fan, Fei Kou, Shuai Qin, Hong Gu, Wei Wu, Pengcheng Xu, Mingrui Zhu, Nannan Wang, Xinbo Gao</author><pubDate>Wed, 27 Mar 2024 16:03:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18660v1</guid></item><item><title>INEXA: Interactive and Explainable Process Model Abstraction Through Object-Centric Process Mining</title><link>http://arxiv.org/abs/2403.18659v1</link><description>Process events are recorded by multiple information systems at differentgranularity levels. Based on the resulting event logs, process models arediscovered at different granularity levels, as well. Events stored at afine-grained granularity level, for example, may hinder the discovered processmodel to be displayed due the high number of resulting model elements. Thediscovered process model of a real-world manufacturing process, for example,consists of 1,489 model elements and over 2,000 arcs. Existing process modelabstraction techniques could help reducing the size of the model, but woulddisconnect it from the underlying event log. Existing event abstractiontechniques do neither support the analysis of mixed granularity levels, norinteractive exploration of a suitable granularity level. To enable theexploration of discovered process models at different granularity levels, wepropose INEXA, an interactive, explainable process model abstraction methodthat keeps the link to the event log. As a starting point, INEXA aggregateslarge process models to a "displayable" size, e.g., for the manufacturing usecase to a process model with 58 model elements. Then, the process analyst canexplore granularity levels interactively, while applied abstractions areautomatically traced in the event log for explainability.</description><author>Janik-Vasily Benzin, Gyunam Park, Juergen Mangler, Stefanie Rinderle-Ma</author><pubDate>Wed, 27 Mar 2024 16:03:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18659v1</guid></item><item><title>Theoretical Guarantees for the Subspace-Constrained Tyler's Estimator</title><link>http://arxiv.org/abs/2403.18658v1</link><description>This work analyzes the subspace-constrained Tyler's estimator (STE) designedfor recovering a low-dimensional subspace within a dataset that may be highlycorrupted with outliers. It assumes a weak inlier-outlier model and allows thefraction of inliers to be smaller than a fraction that leads to computationalhardness of the robust subspace recovery problem. It shows that in thissetting, if the initialization of STE, which is an iterative algorithm,satisfies a certain condition, then STE can effectively recover the underlyingsubspace. It further shows that under the generalized haystack model, STEinitialized by the Tyler's M-estimator (TME), can recover the subspace when thefraction of iniliers is too small for TME to handle.</description><author>Gilad Lerman, Feng Yu, Teng Zhang</author><pubDate>Wed, 27 Mar 2024 16:03:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18658v1</guid></item><item><title>Point, Segment and Count: A Generalized Framework for Object Counting</title><link>http://arxiv.org/abs/2311.12386v3</link><description>Class-agnostic object counting aims to count all objects in an image withrespect to example boxes or class names, \emph{a.k.a} few-shot and zero-shotcounting. In this paper, we propose a generalized framework for both few-shotand zero-shot object counting based on detection. Our framework combines thesuperior advantages of two foundation models without compromising theirzero-shot capability: (\textbf{i}) SAM to segment all possible objects as maskproposals, and (\textbf{ii}) CLIP to classify proposals to obtain accurateobject counts. However, this strategy meets the obstacles of efficiencyoverhead and the small crowded objects that cannot be localized anddistinguished. To address these issues, our framework, termed PseCo, followsthree steps: point, segment, and count. Specifically, we first propose aclass-agnostic object localization to provide accurate but least point promptsfor SAM, which consequently not only reduces computation costs but also avoidsmissing small objects. Furthermore, we propose a generalized objectclassification that leverages CLIP image/text embeddings as the classifier,following a hierarchical knowledge distillation to obtain discriminativeclassifications among hierarchical mask proposals. Extensive experimentalresults on FSC-147, COCO, and LVIS demonstrate that PseCo achievesstate-of-the-art performance in both few-shot/zero-shot objectcounting/detection. Code: https://github.com/Hzzone/PseCo</description><author>Zhizhong Huang, Mingliang Dai, Yi Zhang, Junping Zhang, Hongming Shan</author><pubDate>Wed, 27 Mar 2024 16:01:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12386v3</guid></item><item><title>Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech Gesture Generation</title><link>http://arxiv.org/abs/2311.17532v3</link><description>Generating vivid and emotional 3D co-speech gestures is crucial for virtualavatar animation in human-machine interaction applications. While the existingmethods enable generating the gestures to follow a single emotion label, theyoverlook that long gesture sequence modeling with emotion transition is morepractical in real scenes. In addition, the lack of large-scale availabledatasets with emotional transition speech and corresponding 3D human gesturesalso limits the addressing of this task. To fulfill this goal, we firstincorporate the ChatGPT-4 and an audio inpainting approach to construct thehigh-fidelity emotion transition human speeches. Considering obtaining therealistic 3D pose annotations corresponding to the dynamically inpaintedemotion transition audio is extremely difficult, we propose a novel weaklysupervised training strategy to encourage authority gesture transitions.Specifically, to enhance the coordination of transition gestures w.r.tdifferent emotional ones, we model the temporal association representationbetween two different emotional gesture sequences as style guidance and infuseit into the transition generation. We further devise an emotion mixturemechanism that provides weak supervision based on a learnable mixed emotionlabel for transition gestures. Last, we present a keyframe sampler to supplyeffective initial posture cues in long sequences, enabling us to generatediverse gestures. Extensive experiments demonstrate that our method outperformsthe state-of-the-art models constructed by adapting single emotion-conditionedcounterparts on our newly defined emotion transition task and datasets. Ourcode and dataset will be released on the project page:https://xingqunqi-lab.github.io/Emo-Transition-Gesture/.</description><author>Xingqun Qi, Jiahao Pan, Peng Li, Ruibin Yuan, Xiaowei Chi, Mengfei Li, Wenhan Luo, Wei Xue, Shanghang Zhang, Qifeng Liu, Yike Guo</author><pubDate>Wed, 27 Mar 2024 16:01:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17532v3</guid></item><item><title>Byzantine-resilient Federated Learning With Adaptivity to Data Heterogeneity</title><link>http://arxiv.org/abs/2403.13374v3</link><description>This paper deals with federated learning (FL) in the presence of maliciousByzantine attacks and data heterogeneity. A novel Robust Average GradientAlgorithm (RAGA) is proposed, which leverages the geometric median foraggregation and can freely select the round number for local updating.Different from most existing resilient approaches, which perform convergenceanalysis based on strongly-convex loss function or homogeneously distributeddataset, we conduct convergence analysis for not only strongly-convex but alsonon-convex loss function over heterogeneous dataset. According to ourtheoretical analysis, as long as the fraction of dataset from malicious usersis less than half, RAGA can achieve convergence at rate$\mathcal{O}({1}/{T^{2/3- \delta}})$ where $T$ is the iteration number and$\delta \in (0, 2/3)$ for non-convex loss function, and at linear rate forstrongly-convex loss function. Moreover, stationary point or global optimalsolution is proved to obtainable as data heterogeneity vanishes. Experimentalresults corroborate the robustness of RAGA to Byzantine attacks and verifiesthe advantage of RAGA over baselines on convergence performance under variousintensity of Byzantine attacks, for heterogeneous dataset.</description><author>Shiyuan Zuo, Xingrun Yan, Rongfei Fan, Han Hu, Hangguan Shan, Tony Q. S. Quek</author><pubDate>Wed, 27 Mar 2024 15:57:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13374v3</guid></item><item><title>GlotScript: A Resource and Tool for Low Resource Writing System Identification</title><link>http://arxiv.org/abs/2309.13320v2</link><description>We present GlotScript, an open resource and tool for low resource writingsystem identification. GlotScript-R is a resource that provides the attestedwriting systems for more than 7,000 languages. It is compiled by aggregatinginformation from existing writing system resources. GlotScript-T is a writingsystem identification tool that covers all 161 Unicode 15.0 scripts. For aninput text, it returns its script distribution where scripts are identified byISO 15924 codes. We also present two use cases for GlotScript. First, wedemonstrate that GlotScript can help cleaning multilingual corpora such as mC4and OSCAR. Second, we analyze the tokenization of a number of language modelssuch as GPT-4 using GlotScript and provide insights on the coverage of lowresource scripts and languages by each language model. We hope that GlotScriptwill become a useful resource for work on low resource languages in the NLPcommunity. GlotScript-R and GlotScript-T are available athttps://github.com/cisnlp/GlotScript.</description><author>Amir Hossein Kargaran, François Yvon, Hinrich Schütze</author><pubDate>Wed, 27 Mar 2024 15:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13320v2</guid></item><item><title>Addressing Data Annotation Challenges in Multiple Sensors: A Solution for Scania Collected Datasets</title><link>http://arxiv.org/abs/2403.18649v1</link><description>Data annotation in autonomous vehicles is a critical step in the developmentof Deep Neural Network (DNN) based models or the performance evaluation of theperception system. This often takes the form of adding 3D bounding boxes ontime-sequential and registered series of point-sets captured from activesensors like Light Detection and Ranging (LiDAR) and Radio Detection andRanging (RADAR). When annotating multiple active sensors, there is a need tomotion compensate and translate the points to a consistent coordinate frame andtimestamp respectively. However, highly dynamic objects pose a uniquechallenge, as they can appear at different timestamps in each sensor's data.Without knowing the speed of the objects, their position appears to bedifferent in different sensor outputs. Thus, even after motion compensation,highly dynamic objects are not matched from multiple sensors in the same frame,and human annotators struggle to add unique bounding boxes that capture allobjects. This article focuses on addressing this challenge, primarily withinthe context of Scania collected datasets. The proposed solution takes a trackof an annotated object as input and uses the Moving Horizon Estimation (MHE) torobustly estimate its speed. The estimated speed profile is utilized to correctthe position of the annotated box and add boxes to object clusters missed bythe original annotation.</description><author>Ajinkya Khoche, Aron Asefaw, Alejandro Gonzalez, Bogdan Timus, Sina Sharif Mansouri, Patric Jensfelt</author><pubDate>Wed, 27 Mar 2024 15:56:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18649v1</guid></item><item><title>SDSAT: Accelerating LLM Inference through Speculative Decoding with Semantic Adaptive Tokens</title><link>http://arxiv.org/abs/2403.18647v1</link><description>We propose an acceleration scheme for large language models (LLMs) throughSpeculative Decoding with Semantic Adaptive Tokens (SDSAT). The primaryobjective of this design is to enhance the LLM model's ability to generatedraft tokens more accurately without compromising the model's accuracy. Thecore strategies involve: 1) Fine-tune the model by incorporating semanticadaptive tokens that possess flexible decoding capabilities without changingits structure, allowing them to generate high-quality draft tokens. 2) Byemploying a training method that does not affect the standard tokens, the modelcan acquire parallel decoding abilities atop its original framework withminimal training overhead. 3) We have designed the "two-step-draft-then-verify"generation strategies using both greedy search and nucleus sampling.Experiments conducted on the CodeLlama-13B and 7B models have yielded speedincreases of over 3.5X and 3.0X, respectively. Please refer tohttps://github.com/hasuoshenyun/SDSAT.</description><author>Chengbo Liu, Yong Zhu</author><pubDate>Wed, 27 Mar 2024 15:54:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18647v1</guid></item><item><title>NLPre: a revised approach towards language-centric benchmarking of Natural Language Preprocessing systems</title><link>http://arxiv.org/abs/2403.04507v2</link><description>With the advancements of transformer-based architectures, we observe the riseof natural language preprocessing (NLPre) tools capable of solving preliminaryNLP tasks (e.g. tokenisation, part-of-speech tagging, dependency parsing, ormorphological analysis) without any external linguistic guidance. It is arduousto compare novel solutions to well-entrenched preprocessing toolkits, relyingon rule-based morphological analysers or dictionaries. Aware of theshortcomings of existing NLPre evaluation approaches, we investigate a novelmethod of reliable and fair evaluation and performance reporting. Inspired bythe GLUE benchmark, the proposed language-centric benchmarking system enablescomprehensive ongoing evaluation of multiple NLPre tools, while crediblytracking their performance. The prototype application is configured for Polishand integrated with the thoroughly assembled NLPre-PL benchmark. Based on thisbenchmark, we conduct an extensive evaluation of a variety of Polish NLPresystems. To facilitate the construction of benchmarking environments for otherlanguages, e.g. NLPre-GA for Irish or NLPre-ZH for Chinese, we ensure fullcustomization of the publicly released source code of the benchmarking system.The links to all the resources (deployed platforms, source code, trainedmodels, datasets etc.) can be found on the project website:https://sites.google.com/view/nlpre-benchmark.</description><author>Martyna Wiącek, Piotr Rybak, Łukasz Pszenny, Alina Wróblewska</author><pubDate>Wed, 27 Mar 2024 15:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04507v2</guid></item><item><title>Demystifying Misconceptions in Social Bots Research</title><link>http://arxiv.org/abs/2303.17251v2</link><description>Research on social bots aims at advancing knowledge and providing solutionsto one of the most debated forms of online manipulation. Yet, social botresearch is plagued by widespread biases, hyped results, and misconceptionsthat set the stage for ambiguities, unrealistic expectations, and seeminglyirreconcilable findings. Overcoming such issues is instrumental towardsensuring reliable solutions and reaffirming the validity of the scientificmethod. In this contribution, we review some recent results in social botsresearch, highlighting and revising factual errors as well as methodologicaland conceptual biases. More importantly, we demystify common misconceptions,addressing fundamental points on how social bots research is discussed. Ouranalysis surfaces the need to discuss research about online disinformation andmanipulation in a rigorous, unbiased, and responsible way. This articlebolsters such effort by identifying and refuting common fallacious argumentsused by both proponents and opponents of social bots research, as well asproviding directions toward sound methodologies for future research in thefield.</description><author>Stefano Cresci, Kai-Cheng Yang, Angelo Spognardi, Roberto Di Pietro, Filippo Menczer, Marinella Petrocchi</author><pubDate>Wed, 27 Mar 2024 15:48:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17251v2</guid></item><item><title>LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition</title><link>http://arxiv.org/abs/2308.12882v2</link><description>Audio classification aims at recognizing audio signals, including speechcommands or sound events. However, current audio classifiers are susceptible toperturbations and adversarial attacks. In addition, real-world audioclassification tasks often suffer from limited labeled data. To help bridgethese gaps, previous work developed neuro-inspired convolutional neuralnetworks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA)in the first layer (i.e., LCANets) for computer vision. LCANets learn in acombination of supervised and unsupervised learning, reducing dependency onlabeled samples. Motivated by the fact that auditory cortex is also sparse, weextend LCANets to audio recognition tasks and introduce LCANets++, which areCNNs that perform sparse coding in multiple layers via LCA. We demonstrate thatLCANets++ are more robust than standard CNNs and LCANets against perturbations,e.g., background noise, as well as black-box and white-box attacks, e.g.,evasion and fast gradient sign (FGSM) attacks.</description><author>Sayanton V. Dibbo, Juston S. Moore, Garrett T. Kenyon, Michael A. Teti</author><pubDate>Wed, 27 Mar 2024 15:47:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12882v2</guid></item><item><title>Transformers-based architectures for stroke segmentation: A review</title><link>http://arxiv.org/abs/2403.18637v1</link><description>Stroke remains a significant global health concern, necessitating precise andefficient diagnostic tools for timely intervention and improved patientoutcomes. The emergence of deep learning methodologies has transformed thelandscape of medical image analysis. Recently, Transformers, initially designedfor natural language processing, have exhibited remarkable capabilities invarious computer vision applications, including medical image analysis. Thiscomprehensive review aims to provide an in-depth exploration of thecutting-edge Transformer-based architectures applied in the context of strokesegmentation. It commences with an exploration of stroke pathology, imagingmodalities, and the challenges associated with accurate diagnosis andsegmentation. Subsequently, the review delves into the fundamental ideas ofTransformers, offering detailed insights into their architectural intricaciesand the underlying mechanisms that empower them to effectively capture complexspatial information within medical images. The existing literature issystematically categorized and analyzed, discussing various approaches thatleverage Transformers for stroke segmentation. A critical assessment isprovided, highlighting the strengths and limitations of these methods,including considerations of performance and computational efficiency.Additionally, this review explores potential avenues for future research anddevelopment</description><author>Yalda Zafari-Ghadim, Essam A. Rashed, Mohamed Mabrok</author><pubDate>Wed, 27 Mar 2024 15:42:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18637v1</guid></item><item><title>Fusion approaches for emotion recognition from speech using acoustic and text-based features</title><link>http://arxiv.org/abs/2403.18635v1</link><description>In this paper, we study different approaches for classifying emotions fromspeech using acoustic and text-based features. We propose to obtaincontextualized word embeddings with BERT to represent the information containedin speech transcriptions and show that this results in better performance thanusing Glove embeddings. We also propose and compare different strategies tocombine the audio and text modalities, evaluating them on IEMOCAP andMSP-PODCAST datasets. We find that fusing acoustic and text-based systems isbeneficial on both datasets, though only subtle differences are observed acrossthe evaluated fusion approaches. Finally, for IEMOCAP, we show the large effectthat the criteria used to define the cross-validation folds have on results. Inparticular, the standard way of creating folds for this dataset results in ahighly optimistic estimation of performance for the text-based system,suggesting that some previous works may overestimate the advantage ofincorporating transcriptions.</description><author>Leonardo Pepino, Pablo Riera, Luciana Ferrer, Agustin Gravano</author><pubDate>Wed, 27 Mar 2024 15:40:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18635v1</guid></item><item><title>First Experiences with the Identification of People at Risk for Diabetes in Argentina using Machine Learning Techniques</title><link>http://arxiv.org/abs/2403.18631v1</link><description>Detecting Type 2 Diabetes (T2D) and Prediabetes (PD) is a real challenge formedicine due to the absence of pathogenic symptoms and the lack of knownassociated risk factors. Even though some proposals for machine learning modelsenable the identification of people at risk, the nature of the condition makesit so that a model suitable for one population may not necessarily be suitablefor another. In this article, the development and assessment of predictivemodels to identify people at risk for T2D and PD specifically in Argentina arediscussed. First, the database was thoroughly preprocessed and three specificdatasets were generated considering a compromise between the number of recordsand the amount of available variables. After applying 5 differentclassification models, the results obtained show that a very good performancewas observed for two datasets with some of these models. In particular, RF, DT,and ANN demonstrated great classification power, with good values for themetrics under consideration. Given the lack of this type of tool in Argentina,this work represents the first step towards the development of moresophisticated models.</description><author>Enzo Rucci, Gonzalo Tittarelli, Franco Ronchetti, Jorge F. Elgart, Laura Lanzarini, Juan José Gagliardino</author><pubDate>Wed, 27 Mar 2024 15:38:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18631v1</guid></item><item><title>DeepMachining: Online Prediction of Machining Errors of Lathe Machines</title><link>http://arxiv.org/abs/2403.16451v3</link><description>We describe DeepMachining, a deep learning-based AI system for onlineprediction of machining errors of lathe machine operations. We have built andevaluated DeepMachining based on manufacturing data from factories.Specifically, we first pretrain a deep learning model for a given lathemachine's operations to learn the salient features of machining states. Then,we fine-tune the pretrained model to adapt to specific machining tasks. Wedemonstrate that DeepMachining achieves high prediction accuracy for multipletasks that involve different workpieces and cutting tools. To the best of ourknowledge, this work is one of the first factory experiments using pre-traineddeep-learning models to predict machining errors of lathe machines.</description><author>Xiang-Li Lu, Hwai-Jung Hsu, Che-Wei Chou, H. T. Kung, Chen-Hsin Lee</author><pubDate>Wed, 27 Mar 2024 15:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16451v3</guid></item><item><title>Vulnerability Detection with Code Language Models: How Far Are We?</title><link>http://arxiv.org/abs/2403.18624v1</link><description>In the context of the rising interest in code language models (code LMs) andvulnerability detection, we study the effectiveness of code LMs for detectingvulnerabilities. Our analysis reveals significant shortcomings in existingvulnerability datasets, including poor data quality, low label accuracy, andhigh duplication rates, leading to unreliable model performance in realisticvulnerability detection scenarios. Additionally, the evaluation methods usedwith these datasets are not representative of real-world vulnerabilitydetection. To address these challenges, we introduce PrimeVul, a new dataset fortraining and evaluating code LMs for vulnerability detection. PrimeVulincorporates a novel set of data labeling techniques that achieve comparablelabel accuracy to human-verified benchmarks while significantly expanding thedataset. It also implements a rigorous data de-duplication and chronologicaldata splitting strategy to mitigate data leakage issues, alongside introducingmore realistic evaluation metrics and settings. This comprehensive approachaims to provide a more accurate assessment of code LMs' performance inreal-world conditions. Evaluating code LMs on PrimeVul reveals that existing benchmarkssignificantly overestimate the performance of these models. For instance, astate-of-the-art 7B model scored 68.26% F1 on BigVul but only 3.09% F1 onPrimeVul. Attempts to improve performance through advanced training techniquesand larger models like GPT-3.5 and GPT-4 were unsuccessful, with results akinto random guessing in the most stringent settings. These findings underscorethe considerable gap between current capabilities and the practicalrequirements for deploying code LMs in security roles, highlighting the needfor more innovative research in this domain.</description><author>Yangruibo Ding, Yanjun Fu, Omniyyah Ibrahim, Chawin Sitawarin, Xinyun Chen, Basel Alomair, David Wagner, Baishakhi Ray, Yizheng Chen</author><pubDate>Wed, 27 Mar 2024 15:34:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18624v1</guid></item><item><title>Structure Guided Large Language Model for SQL Generation</title><link>http://arxiv.org/abs/2402.13284v2</link><description>Generating accurate Structured Querying Language (SQL) is a long-standingproblem, especially in matching users' semantic queries with structureddatabases and then generating structured SQL. Existing models typically inputqueries and database schemas into the LLM and rely on the LLM to performsemantic-structure matching and generate structured SQL. However, suchsolutions overlook the structural information within user queries anddatabases, which can be utilized to enhance the generation of structured SQL.This oversight can lead to inaccurate or unexecutable SQL generation. To fullyexploit the structure, we propose a structure-to-SQL framework, which leveragesthe inherent structure information to improve the SQL generation of LLMs.Specifically, we introduce our Structure Guided SQL~(SGU-SQL) generation model.SGU-SQL first links user queries and databases in a structure-enhanced manner.It then decomposes complicated linked structures with grammar trees to guidethe LLM to generate the SQL step by step. Extensive experiments on twobenchmark datasets illustrate that SGU-SQL can outperform sixteen SQLgeneration baselines.</description><author>Qinggang Zhang, Junnan Dong, Hao Chen, Wentao Li, Feiran Huang, Xiao Huang</author><pubDate>Wed, 27 Mar 2024 15:30:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13284v2</guid></item></channel></rss>