<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 17 May 2023 06:01:40 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Annotating 8,000 Abdominal CT Volumes for Multi-Organ Segmentation in Three Weeks</title><link>http://arxiv.org/abs/2305.09666v1</link><description>Annotating medical images, particularly for organ segmentation, is laboriousand time-consuming. For example, annotating an abdominal organ requires anestimated rate of 30-60 minutes per CT volume based on the expertise of anannotator and the size, visibility, and complexity of the organ. Therefore,publicly available datasets for multi-organ segmentation are often limited indata size and organ diversity. This paper proposes a systematic and efficientmethod to expedite the annotation process for organ segmentation. We havecreated the largest multi-organ dataset (by far) with the spleen, liver,kidneys, stomach, gallbladder, pancreas, aorta, and IVC annotated in 8,448 CTvolumes, equating to 3.2 million slices. The conventional annotation methodswould take an experienced annotator up to 1,600 weeks (or roughly 30.8 years)to complete this task. In contrast, our annotation method has accomplished thistask in three weeks (based on an 8-hour workday, five days a week) whilemaintaining a similar or even better annotation quality. This achievement isattributed to three unique properties of our method: (1) label bias reductionusing multiple pre-trained segmentation models, (2) effective error detectionin the model predictions, and (3) attention guidance for annotators to makecorrections on the most salient errors. Furthermore, we summarize the taxonomyof common errors made by AI algorithms and annotators. This allows forcontinuous refinement of both AI and annotations and significantly reduces theannotation costs required to create large-scale datasets for a wider variety ofmedical imaging tasks.</description><author>Chongyu Qu, Tiezheng Zhang, Hualin Qiao, Jie Liu, Yucheng Tang, Alan Yuille, Zongwei Zhou</author><pubDate>Tue, 16 May 2023 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09666v1</guid></item><item><title>Listen, Denoise, Action! Audio-Driven Motion Synthesis with Diffusion Models</title><link>http://arxiv.org/abs/2211.09707v2</link><description>Diffusion models have experienced a surge of interest as highly expressiveyet efficiently trainable probabilistic models. We show that these models arean excellent fit for synthesising human motion that co-occurs with audio, e.g.,dancing and co-speech gesticulation, since motion is complex and highlyambiguous given audio, calling for a probabilistic description. Specifically,we adapt the DiffWave architecture to model 3D pose sequences, puttingConformers in place of dilated convolutions for improved modelling power. Wealso demonstrate control over motion style, using classifier-free guidance toadjust the strength of the stylistic expression. Experiments on gesture anddance generation confirm that the proposed method achieves top-of-the-linemotion quality, with distinctive styles whose expression can be made more orless pronounced. We also synthesise path-driven locomotion using the same modelarchitecture. Finally, we generalise the guidance procedure to obtainproduct-of-expert ensembles of diffusion models and demonstrate how these maybe used for, e.g., style interpolation, a contribution we believe is ofindependent interest. Seehttps://www.speech.kth.se/research/listen-denoise-action/ for video examples,data, and code.</description><author>Simon Alexanderson, Rajmund Nagy, Jonas Beskow, Gustav Eje Henter</author><pubDate>Tue, 16 May 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.09707v2</guid></item><item><title>Understanding 3D Object Interaction from a Single Image</title><link>http://arxiv.org/abs/2305.09664v1</link><description>Humans can easily understand a single image as depicting multiple potentialobjects permitting interaction. We use this skill to plan our interactions withthe world and accelerate understanding new objects without engaging ininteraction. In this paper, we would like to endow machines with the similarability, so that intelligent agents can better explore the 3D scene ormanipulate objects. Our approach is a transformer-based model that predicts the3D location, physical properties and affordance of objects. To power thismodel, we collect a dataset with Internet videos, egocentric videos and indoorimages to train and validate our approach. Our model yields strong performanceon our data, and generalizes well to robotics data.</description><author>Shengyi Qian, David F. Fouhey</author><pubDate>Tue, 16 May 2023 18:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09664v1</guid></item><item><title>Bot or Human? Detecting ChatGPT Imposters with A Single Question</title><link>http://arxiv.org/abs/2305.06424v2</link><description>Large language models like ChatGPT have recently demonstrated impressivecapabilities in natural language understanding and generation, enabling variousapplications including translation, essay writing, and chit-chatting. However,there is a concern that they can be misused for malicious purposes, such asfraud or denial-of-service attacks. Therefore, it is crucial to develop methodsfor detecting whether the party involved in a conversation is a bot or a human.In this paper, we propose a framework named FLAIR, Finding Large language modelAuthenticity via a single Inquiry and Response, to detect conversational botsin an online manner. Specifically, we target a single question scenario thatcan effectively differentiate human users from bots. The questions are dividedinto two categories: those that are easy for humans but difficult for bots(e.g., counting, substitution, positioning, noise filtering, and ASCII art),and those that are easy for bots but difficult for humans (e.g., memorizationand computation). Our approach shows different strengths of these questions intheir effectiveness, providing a new way for online service providers toprotect themselves against nefarious activities and ensure that they areserving real users. We open-sourced our dataset onhttps://github.com/hongwang600/FLAIR and welcome contributions from thecommunity to enrich such detection datasets.</description><author>Hong Wang, Xuan Luo, Weizhi Wang, Xifeng Yan</author><pubDate>Tue, 16 May 2023 18:59:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06424v2</guid></item><item><title>Make-An-Animation: Large-Scale Text-conditional 3D Human Motion Generation</title><link>http://arxiv.org/abs/2305.09662v1</link><description>Text-guided human motion generation has drawn significant interest because ofits impactful applications spanning animation and robotics. Recently,application of diffusion models for motion generation has enabled improvementsin the quality of generated motions. However, existing approaches are limitedby their reliance on relatively small-scale motion capture data, leading topoor performance on more diverse, in-the-wild prompts. In this paper, weintroduce Make-An-Animation, a text-conditioned human motion generation modelwhich learns more diverse poses and prompts from large-scale image-textdatasets, enabling significant improvement in performance over prior works.Make-An-Animation is trained in two stages. First, we train on a curatedlarge-scale dataset of (text, static pseudo-pose) pairs extracted fromimage-text datasets. Second, we fine-tune on motion capture data, addingadditional layers to model the temporal dimension. Unlike prior diffusionmodels for motion generation, Make-An-Animation uses a U-Net architecturesimilar to recent text-to-video generation models. Human evaluation of motionrealism and alignment with input text shows that our model reachesstate-of-the-art performance on text-to-motion generation.</description><author>Samaneh Azadi, Akbar Shah, Thomas Hayes, Devi Parikh, Sonal Gupta</author><pubDate>Tue, 16 May 2023 18:58:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09662v1</guid></item><item><title>Osteosarcoma Tumor Detection using Transfer Learning Models</title><link>http://arxiv.org/abs/2305.09660v1</link><description>The field of clinical image analysis has been applying transfer learningmodels increasingly due to their less computational complexity, better accuracyetc. These are pre-trained models that don't require to be trained from scratchwhich eliminates the necessity of large datasets. Transfer learning models aremostly used for the analysis of brain, breast, or lung images but other sectorssuch as bone marrow cell detection or bone cancer detection can also benefitfrom using transfer learning models, especially considering the lack ofavailable large datasets for these tasks. This paper studies the performance ofseveral transfer learning models for osteosarcoma tumour detection.Osteosarcoma is a type of bone cancer mostly found in the cells of the longbones of the body. The dataset consists of H&amp;E stained images divided into 4categories- Viable Tumor, Non-viable Tumor, Non-Tumor and Viable Non-viable.Both datasets were randomly divided into train and test sets following an 80-20ratio. 80% was used for training and 20\% for test. 4 models are considered forcomparison- EfficientNetB7, InceptionResNetV2, NasNetLarge and ResNet50. Allthese models are pre-trained on ImageNet. According to the result,InceptionResNetV2 achieved the highest accuracy (93.29%), followed byNasNetLarge (90.91%), ResNet50 (89.83%) and EfficientNetB7 (62.77%). It alsohad the highest precision (0.8658) and recall (0.8658) values among the 4models.</description><author>Raisa Fairooz Meem, Khandaker Tabin Hasan</author><pubDate>Tue, 16 May 2023 18:58:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09660v1</guid></item><item><title>Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage</title><link>http://arxiv.org/abs/2305.09659v1</link><description>We study distributionally robust offline reinforcement learning (robustoffline RL), which seeks to find an optimal robust policy purely from anoffline dataset that can perform well in perturbed environments. We propose ageneric algorithm framework \underline{D}oubly \underline{P}essimistic\underline{M}odel-based \underline{P}olicy \underline{O}ptimization($\texttt{P}^2\texttt{MPO}$) for robust offline RL, which features a novelcombination of a flexible model estimation subroutine and a doubly pessimisticpolicy optimization step. The \emph{double pessimism} principle is crucial toovercome the distributional shift incurred by i) the mismatch between behaviorpolicy and the family of target policies; and ii) the perturbation of thenominal model. Under certain accuracy assumptions on the model estimationsubroutine, we show that $\texttt{P}^2\texttt{MPO}$ is provably efficient with\emph{robust partial coverage data}, which means that the offline dataset hasgood coverage of the distributions induced by the optimal robust policy andperturbed models around the nominal model. By tailoring specific modelestimation subroutines for concrete examples including tabular Robust MarkovDecision Process (RMDP), factored RMDP, and RMDP with kernel and neuralfunction approximations, we show that $\texttt{P}^2\texttt{MPO}$ enjoys a$\tilde{\mathcal{O}}(n^{-1/2})$ convergence rate, where $n$ is the number oftrajectories in the offline dataset. Notably, these models, except for thetabular case, are first identified and proven tractable by this paper. To thebest of our knowledge, we first propose a general learning principle -- doublepessimism -- for robust offline RL and show that it is provably efficient inthe context of general function approximations.</description><author>Jose Blanchet, Miao Lu, Tong Zhang, Han Zhong</author><pubDate>Tue, 16 May 2023 18:58:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09659v1</guid></item><item><title>Classification of Superstatistical Features in High Dimensions</title><link>http://arxiv.org/abs/2304.02912v2</link><description>We characterise the learning of a mixture of two clouds of data points withgeneric centroids via empirical risk minimisation in the high dimensionalregime, under the assumptions of generic convex loss and convex regularisation.Each cloud of data points is obtained by sampling from a possibly uncountablesuperposition of Gaussian distributions, whose variance has a genericprobability density $\varrho$. Our analysis covers therefore a large family ofdata distributions, including the case of power-law-tailed distributions withno covariance. We study the generalisation performance of the obtainedestimator, we analyse the role of regularisation, and the dependence of theseparability transition on the distribution scale parameters.</description><author>Urte Adomaityte, Gabriele Sicuro, Pierpaolo Vivo</author><pubDate>Tue, 16 May 2023 18:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02912v2</guid></item><item><title>Model Fusion via Optimal Transport</title><link>http://arxiv.org/abs/1910.05653v6</link><description>Combining different models is a widely used paradigm in machine learningapplications. While the most common approach is to form an ensemble of modelsand average their individual predictions, this approach is often renderedinfeasible by given resource constraints in terms of memory and computation,which grow linearly with the number of models. We present a layer-wise modelfusion algorithm for neural networks that utilizes optimal transport to (soft-)align neurons across the models before averaging their associated parameters. We show that this can successfully yield "one-shot" knowledge transfer (i.e,without requiring any retraining) between neural networks trained onheterogeneous non-i.i.d. data. In both i.i.d. and non-i.i.d. settings , weillustrate that our approach significantly outperforms vanilla averaging, aswell as how it can serve as an efficient replacement for the ensemble withmoderate fine-tuning, for standard convolutional networks (like VGG11),residual networks (like ResNet18), and multi-layer perceptrons on CIFAR10,CIFAR100, and MNIST. Finally, our approach also provides a principled way tocombine the parameters of neural networks with different widths, and we exploreits application for model compression. The code is available at the followinglink, https://github.com/sidak/otfusion.</description><author>Sidak Pal Singh, Martin Jaggi</author><pubDate>Tue, 16 May 2023 18:57:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1910.05653v6</guid></item><item><title>Satisfiability-Aided Language Models Using Declarative Prompting</title><link>http://arxiv.org/abs/2305.09656v1</link><description>Prior work has combined chain-of-thought prompting in large language models(LLMs) with programmatic representations to perform effective and transparentreasoning. While such an approach works very well for tasks that only requireforward reasoning (e.g., straightforward arithmetic), it is less effective forconstraint solving tasks that require more sophisticated planning and search.In this paper, we propose a new satisfiability-aided language modeling approachfor improving the reasoning capabilities of LLMs. We use an LLM to generate adeclarative task specification rather than an imperative program and leveragean off-the-shelf automated theorem prover to derive the final answer. Thisapproach has two key advantages. The declarative specification is closer to theproblem description than the reasoning steps are, so the LLM can parse it moreaccurately. Furthermore, by offloading the actual reasoning task to anautomated theorem prover, our approach can guarantee the correctness of theanswer with respect to the parsed specification and avoid planning errors inthe reasoning process. We evaluate SATLM on 6 different datasets and show thatit consistently outperforms program-aided LMs in an imperative paradigm(PROGLM). In particular, SATLM outperforms PROGLM by 23% on a challengingsubset of GSM; SATLM also achieves a new SoTA on LSAT, surpassing previousmodels that are trained on the full training set.</description><author>Xi Ye, Qiaochu Chen, Isil Dillig, Greg Durrett</author><pubDate>Tue, 16 May 2023 18:55:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09656v1</guid></item><item><title>RAMario: Experimental Approach to Reptile Algorithm -- Reinforcement Learning for Mario</title><link>http://arxiv.org/abs/2305.09655v1</link><description>This research paper presents an experimental approach to using the Reptilealgorithm for reinforcement learning to train a neural network to play SuperMario Bros. We implement the Reptile algorithm using the Super Mario Bros Gymlibrary and TensorFlow in Python, creating a neural network model with a singleconvolutional layer, a flatten layer, and a dense layer. We define theoptimizer and use the Reptile class to create an instance of the Reptilemeta-learning algorithm. We train the model using multiple tasks and episodes,choosing actions using the current weights of the neural network model, takingthose actions in the environment, and updating the model weights using theReptile algorithm. We evaluate the performance of the algorithm by printing thetotal reward for each episode. In addition, we compare the performance of theReptile algorithm approach to two other popular reinforcement learningalgorithms, Proximal Policy Optimization (PPO) and Deep Q-Network (DQN),applied to the same Super Mario Bros task. Our results demonstrate that theReptile algorithm provides a promising approach to few-shot learning in videogame AI, with comparable or even better performance than the other twoalgorithms, particularly in terms of moves vs distance that agent performs for1M episodes of training. The results shows that best total distance for world1-2 in the game environment were ~1732 (PPO), ~1840 (DQN) and ~2300 (RAMario).Full code is available at https://github.com/s4nyam/RAMario.</description><author>Sanyam Jain</author><pubDate>Tue, 16 May 2023 18:54:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09655v1</guid></item><item><title>The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation</title><link>http://arxiv.org/abs/2305.09652v1</link><description>End-to-end spoken language understanding (SLU) remains elusive even withcurrent large pretrained language models on text and speech, especially inmultilingual cases. Machine translation has been established as a powerfulpretraining objective on text as it enables the model to capture high-levelsemantics of the input utterance and associations between different languages,which is desired for speech models that work on lower-level acoustic frames.Motivated particularly by the task of cross-lingual SLU, we demonstrate thatthe task of speech translation (ST) is a good means of pretraining speechmodels for end-to-end SLU on both monolingual and cross-lingual scenarios. By introducing ST, our models give higher performance over current baselineson monolingual and multilingual intent classification as well as spokenquestion answering using SLURP, MINDS-14, and NMSQA benchmarks. To verify theeffectiveness of our methods, we also release two new benchmark datasets fromboth synthetic and real sources, for the tasks of abstractive summarizationfrom speech and low-resource or zero-shot transfer from English to French. Wefurther show the value of preserving knowledge from the pretraining task, andexplore Bayesian transfer learning on pretrained speech models based oncontinual learning regularizers for that.</description><author>Mutian He, Philip N. Garner</author><pubDate>Tue, 16 May 2023 18:53:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09652v1</guid></item><item><title>Tailoring Instructions to Student's Learning Levels Boosts Knowledge Distillation</title><link>http://arxiv.org/abs/2305.09651v1</link><description>It has been commonly observed that a teacher model with superior performancedoes not necessarily result in a stronger student, highlighting a discrepancybetween current teacher training practices and effective knowledge transfer. Inorder to enhance the guidance of the teacher training process, we introduce theconcept of distillation influence to determine the impact of distillation fromeach training sample on the student's generalization ability. In this paper, wepropose Learning Good Teacher Matters (LGTM), an efficient training techniquefor incorporating distillation influence into the teacher's learning process.By prioritizing samples that are likely to enhance the student's generalizationability, our LGTM outperforms 10 common knowledge distillation baselines on 6text classification tasks in the GLUE benchmark.</description><author>Yuxin Ren, Zihan Zhong, Xingjian Shi, Yi Zhu, Chun Yuan, Mu Li</author><pubDate>Tue, 16 May 2023 18:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09651v1</guid></item><item><title>Prompt-Tuning Decision Transformer with Preference Ranking</title><link>http://arxiv.org/abs/2305.09648v1</link><description>Prompt-tuning has emerged as a promising method for adapting pre-trainedmodels to downstream tasks or aligning with human preferences. Prompt learningis widely used in NLP but has limited applicability to RL due to the complexphysical meaning and environment-specific information contained within RLprompts. These factors require supervised learning to imitate thedemonstrations and may result in a loss of meaning after learning.Additionally, directly extending prompt-tuning approaches to RL is challengingbecause RL prompts guide agent behavior based on environmental modeling andanalysis, rather than filling in missing information, making it unlikely thatadjustments to the prompt format for downstream tasks, as in NLP, can yieldsignificant improvements. In this work, we propose the Prompt-Tuning DTalgorithm to address these challenges by using trajectory segments as promptsto guide RL agents in acquiring environmental information and optimizingprompts via black-box tuning to enhance their ability to contain more relevantinformation, thereby enabling agents to make better decisions. Our approachinvolves randomly sampling a Gaussian distribution to fine-tune the elements ofthe prompt trajectory and using preference ranking function to find theoptimization direction, thereby providing more informative prompts and guidingthe agent towards specific preferences in the target environment. Extensiveexperiments show that with only 0.03% of the parameters learned, Prompt-TuningDT achieves comparable or even better performance than full-model fine-tuningin low-data scenarios. Our work contributes to the advancement of prompt-tuningapproaches in RL, providing a promising direction for optimizing large RLagents for specific preference tasks.</description><author>Shengchao Hu, Li Shen, Ya Zhang, Dacheng Tao</author><pubDate>Tue, 16 May 2023 18:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09648v1</guid></item><item><title>Wavelet-based Unsupervised Label-to-Image Translation</title><link>http://arxiv.org/abs/2305.09647v1</link><description>Semantic Image Synthesis (SIS) is a subclass of image-to-image translationwhere a semantic layout is used to generate a photorealistic image.State-of-the-art conditional Generative Adversarial Networks (GANs) need a hugeamount of paired data to accomplish this task while generic unpairedimage-to-image translation frameworks underperform in comparison, because theycolor-code semantic layouts and learn correspondences in appearance instead ofsemantic content. Starting from the assumption that a high quality generatedimage should be segmented back to its semantic layout, we propose a newUnsupervised paradigm for SIS (USIS) that makes use of a self-supervisedsegmentation loss and whole image wavelet based discrimination. Furthermore, inorder to match the high-frequency distribution of real images, a novelgenerator architecture in the wavelet domain is proposed. We test ourmethodology on 3 challenging datasets and demonstrate its ability to bridge theperformance gap between paired and unpaired models.</description><author>George Eskandar, Mohamed Abdelsamad, Karim Armanious, Shuai Zhang, Bin Yang</author><pubDate>Tue, 16 May 2023 18:48:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09647v1</guid></item><item><title>torchosr -- a PyTorch extension package for Open Set Recognition models evaluation in Python</title><link>http://arxiv.org/abs/2305.09646v1</link><description>The article presents the torchosr package - a Python package compatible withPyTorch library - offering tools and methods dedicated to Open Set Recognitionin Deep Neural Networks. The package offers two state-of-the-art methods in thefield, a set of functions for handling base sets and generation of derived setsfor the Open Set Recognition task (where some classes are considered unknownand used only in the testing process) and additional tools to handle datasetsand methods. The main goal of the package proposal is to simplify and promotethe correct experimental evaluation, where experiments are carried out on alarge number of derivative sets with various Openness and class-to-categoryassignments. The authors hope that state-of-the-art methods available in thepackage will become a source of a correct and open-source implementation of therelevant solutions in the domain.</description><author>Joanna Komorniczak, Pawel Ksieniewicz</author><pubDate>Tue, 16 May 2023 18:45:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09646v1</guid></item><item><title>StructGPT: A General Framework for Large Language Model to Reason over Structured Data</title><link>http://arxiv.org/abs/2305.09645v1</link><description>In this paper, we study how to improve the zero-shot reasoning ability oflarge language models~(LLMs) over structured data in a unified way. Inspired bythe study on tool augmentation for LLMs, we develop an \emph{IterativeReading-then-Reasoning~(IRR)} approach for solving question answering tasksbased on structured data, called \textbf{StructGPT}. In our approach, weconstruct the specialized function to collect relevant evidence from structureddata (\ie \emph{reading}), and let LLMs concentrate the reasoning task based onthe collected information (\ie \emph{reasoning}). Specially, we propose an\emph{invoking-linearization-generation} procedure to support LLMs in reasoningon the structured data with the help of the external interfaces. By iteratingthis procedures with provided interfaces, our approach can gradually approachthe target answer to a given query. Extensive experiments conducted on threetypes of structured data demonstrate the effectiveness of our approach, whichcan significantly boost the performance of ChatGPT and achieve comparableperformance against the full-data supervised-tuning baselines. Our codes anddata are publicly available at~\url{https://github.com/RUCAIBox/StructGPT}.</description><author>Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, Ji-Rong Wen</author><pubDate>Tue, 16 May 2023 18:45:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09645v1</guid></item><item><title>FitMe: Deep Photorealistic 3D Morphable Model Avatars</title><link>http://arxiv.org/abs/2305.09641v1</link><description>In this paper, we introduce FitMe, a facial reflectance model and adifferentiable rendering optimization pipeline, that can be used to acquirehigh-fidelity renderable human avatars from single or multiple images. Themodel consists of a multi-modal style-based generator, that captures facialappearance in terms of diffuse and specular reflectance, and a PCA-based shapemodel. We employ a fast differentiable rendering process that can be used in anoptimization pipeline, while also achieving photorealistic facial shading. Ouroptimization process accurately captures both the facial reflectance and shapein high-detail, by exploiting the expressivity of the style-based latentrepresentation and of our shape model. FitMe achieves state-of-the-artreflectance acquisition and identity preservation on single "in-the-wild"facial images, while it produces impressive scan-like results, when givenmultiple unconstrained facial images pertaining to the same identity. Incontrast with recent implicit avatar reconstructions, FitMe requires only oneminute and produces relightable mesh and texture-based avatars, that can beused by end-user applications.</description><author>Alexandros Lattas, Stylianos Moschoglou, Stylianos Ploumpis, Baris Gecer, Jiankang Deng, Stefanos Zafeiriou</author><pubDate>Tue, 16 May 2023 18:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09641v1</guid></item><item><title>Literature Review of the Recent Trends and Applications in various Fuzzy Rule based systems</title><link>http://arxiv.org/abs/2209.07175v2</link><description>Fuzzy rule based systems (FRBSs) is a rule-based system which uses linguisticfuzzy variables as antecedents and consequent to represent human understandableknowledge. They have been applied to various applications and areas throughoutthe soft computing literature. However, FRBSs suffers from many drawbacks suchas uncertainty representation, high number of rules, interpretability loss,high computational time for learning etc. To overcome these issues with FRBSs,there exists many extensions of FRBSs. This paper presents an overview andliterature review of recent trends on various types and prominent areas offuzzy systems (FRBSs) namely genetic fuzzy system (GFS), hierarchical fuzzysystem (HFS), neuro fuzzy system (NFS), evolving fuzzy system (eFS), FRBSs forbig data, FRBSs for imbalanced data, interpretability in FRBSs and FRBSs whichuse cluster centroids as fuzzy rules. The review is for years 2010-2021. Thispaper also highlights important contributions, publication statistics andcurrent trends in the field. The paper also addresses several open researchareas which need further attention from the FRBSs research community.</description><author>Ayush K. Varshney, Vicenç Torra</author><pubDate>Tue, 16 May 2023 18:42:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.07175v2</guid></item><item><title>SoundStorm: Efficient Parallel Audio Generation</title><link>http://arxiv.org/abs/2305.09636v1</link><description>We present SoundStorm, a model for efficient, non-autoregressive audiogeneration. SoundStorm receives as input the semantic tokens of AudioLM, andrelies on bidirectional attention and confidence-based parallel decoding togenerate the tokens of a neural audio codec. Compared to the autoregressivegeneration approach of AudioLM, our model produces audio of the same qualityand with higher consistency in voice and acoustic conditions, while being twoorders of magnitude faster. SoundStorm generates 30 seconds of audio in 0.5seconds on a TPU-v4. We demonstrate the ability of our model to scale audiogeneration to longer sequences by synthesizing high-quality, natural dialoguesegments, given a transcript annotated with speaker turns and a short promptwith the speakers' voices.</description><author>Zalán Borsos, Matt Sharifi, Damien Vincent, Eugene Kharitonov, Neil Zeghidour, Marco Tagliasacchi</author><pubDate>Tue, 16 May 2023 18:41:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09636v1</guid></item><item><title>Faster Federated Learning with Decaying Number of Local SGD Steps</title><link>http://arxiv.org/abs/2305.09628v1</link><description>In Federated Learning (FL) client devices connected over the internetcollaboratively train a machine learning model without sharing their privatedata with a central server or with other clients. The seminal FederatedAveraging (FedAvg) algorithm trains a single global model by performing roundsof local training on clients followed by model averaging. FedAvg can improvethe communication-efficiency of training by performing more steps of StochasticGradient Descent (SGD) on clients in each round. However, client data inreal-world FL is highly heterogeneous, which has been extensively shown to slowmodel convergence and harm final performance when $K &gt; 1$ steps of SGD areperformed on clients per round. In this work we propose decaying $K$ astraining progresses, which can jointly improve the final performance of the FLmodel whilst reducing the wall-clock time and the total computational cost oftraining compared to using a fixed $K$. We analyse the convergence of FedAvgwith decaying $K$ for strongly-convex objectives, providing novel insights intothe convergence properties, and derive three theoretically-motivated decayschedules for $K$. We then perform thorough experiments on four benchmark FLdatasets (FEMNIST, CIFAR100, Sentiment140, Shakespeare) to show the real-worldbenefit of our approaches in terms of real-world convergence time,computational cost, and generalisation performance.</description><author>Jed Mills, Jia Hu, Geyong Min</author><pubDate>Tue, 16 May 2023 18:36:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09628v1</guid></item><item><title>Addressing computational challenges in physical system simulations with machine learning</title><link>http://arxiv.org/abs/2305.09627v1</link><description>In this paper, we present a machine learning-based data generator frameworktailored to aid researchers who utilize simulations to examine various physicalsystems or processes. High computational costs and the resulting limited dataoften pose significant challenges to gaining insights into these systems orprocesses. Our approach involves a two-step process: initially, we train asupervised predictive model using a limited simulated dataset to predictsimulation outcomes. Subsequently, a reinforcement learning agent is trained togenerate accurate, simulation-like data by leveraging the supervised model.With this framework, researchers can generate more accurate data and know theoutcomes without running high computational simulations, which enables them toexplore the parameter space more efficiently and gain deeper insights intophysical systems or processes. We demonstrate the effectiveness of the proposedframework by applying it to two case studies, one focusing on earthquakerupture physics and the other on new material development.</description><author>Sabber Ahamed, Md Mesbah Uddin</author><pubDate>Tue, 16 May 2023 18:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09627v1</guid></item><item><title>Modeling Moral Choices in Social Dilemmas with Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2301.08491v2</link><description>Practical uses of Artificial Intelligence (AI) in the real world havedemonstrated the importance of embedding moral choices into intelligent agents.They have also highlighted that defining top-down ethical constraints on AIaccording to any one type of morality is extremely challenging and can poserisks. A bottom-up learning approach may be more appropriate for studying anddeveloping ethical behavior in AI agents. In particular, we believe that aninteresting and insightful starting point is the analysis of emergent behaviorof Reinforcement Learning (RL) agents that act according to a predefined set ofmoral rewards in social dilemmas. In this work, we present a systematic analysis of the choices made byintrinsically-motivated RL agents whose rewards are based on moral theories. Weaim to design reward structures that are simplified yet representative of a setof key ethical systems. Therefore, we first define moral reward functions thatdistinguish between consequence- and norm-based agents, between morality basedon societal norms or internal virtues, and between single- and mixed-virtue(e.g., multi-objective) methodologies. Then, we evaluate our approach bymodeling repeated dyadic interactions between learning moral agents in threeiterated social dilemma games (Prisoner's Dilemma, Volunteer's Dilemma and StagHunt). We analyze the impact of different types of morality on the emergence ofcooperation, defection or exploitation, and the corresponding social outcomes.Finally, we discuss the implications of these findings for the development ofmoral agents in artificial and mixed human-AI societies.</description><author>Elizaveta Tennant, Stephen Hailes, Mirco Musolesi</author><pubDate>Tue, 16 May 2023 18:29:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08491v2</guid></item><item><title>Learning quantum symmetries with interactive quantum-classical variational algorithms</title><link>http://arxiv.org/abs/2206.11970v2</link><description>A symmetry of a state $\vert \psi \rangle$ is a unitary operator of which$\vert \psi \rangle$ is an eigenvector. When $\vert \psi \rangle$ is an unknownstate supplied by a black-box oracle, the state's symmetries provide keyphysical insight into the quantum system; symmetries also boost many crucialquantum learning techniques. In this paper, we develop a variational hybridquantum-classical learning scheme to systematically probe for symmetries of$\vert \psi \rangle$ with no a priori assumptions about the state. Thisprocedure can be used to learn various symmetries at the same time. In order toavoid re-learning already known symmetries, we introduce an interactiveprotocol with a classical deep neural net. The classical net therebyregularizes against repetitive findings and allows our algorithm to terminateempirically with all possible symmetries found. Our scheme can be implementedefficiently on average with non-local SWAP gates; we also give a less efficientalgorithm with only local operations, which may be more appropriate for currentnoisy quantum devices. We simulate our algorithm on representative families ofstates, including cluster states and ground states of Rydberg and IsingHamiltonians. We also find that the numerical query complexity scales well withqubit size.</description><author>Jonathan Z. Lu, Rodrigo A. Bravo, Kaiying Hou, Gebremedhin A. Dagnew, Susanne F. Yelin, Khadijeh Najafi</author><pubDate>Tue, 16 May 2023 18:28:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.11970v2</guid></item><item><title>Balancing Risk and Reward: An Automated Phased Release Strategy</title><link>http://arxiv.org/abs/2305.09626v1</link><description>Phased releases are a common strategy in the technology industry forgradually releasing new products or updates through a sequence of A/B tests inwhich the number of treated units gradually grows until full deployment ordeprecation. Performing phased releases in a principled way requires selectingthe proportion of units assigned to the new release in a way that balances therisk of an adverse effect with the need to iterate and learn from theexperiment rapidly. In this paper, we formalize this problem and propose analgorithm that automatically determines the release percentage at each stage inthe schedule, balancing the need to control risk while maximizing ramp-upspeed. Our framework models the challenge as a constrained batched banditproblem that ensures that our pre-specified experimental budget is not depletedwith high probability. Our proposed algorithm leverages an adaptive Bayesianapproach in which the maximal number of units assigned to the treatment isdetermined by the posterior distribution, ensuring that the probability ofdepleting the remaining budget is low. Notably, our approach analyticallysolves the ramp sizes by inverting probability bounds, eliminating the need forchallenging rare-event Monte Carlo simulation. It only requires computing meansand variances of outcome subsets, making it highly efficient andparallelizable.</description><author>Yufan Li, Jialiang Mao, Iavor Bojinov</author><pubDate>Tue, 16 May 2023 18:27:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09626v1</guid></item><item><title>Distributionally Robust Optimization using Cost-Aware Ambiguity Sets</title><link>http://arxiv.org/abs/2303.09408v2</link><description>We present a novel framework for distributionally robust optimization (DRO),called cost-aware DRO (CADRO). The key idea of CADRO is to exploit the coststructure in the design of the ambiguity set to reduce conservatism.Particularly, the set specifically constrains the worst-case distribution alongthe direction in which the expected cost of an approximate solution increasesmost rapidly. We prove that CADRO provides both a high-confidence upper boundand a consistent estimator of the out-of-sample expected cost, and showempirically that it produces solutions that are substantially less conservativethan existing DRO methods, while providing the same guarantees.</description><author>Mathijs Schuurmans, Panagiotis Patrinos</author><pubDate>Tue, 16 May 2023 18:27:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09408v2</guid></item><item><title>A New Aligned Simple German Corpus</title><link>http://arxiv.org/abs/2209.01106v3</link><description>"Leichte Sprache", the German counterpart to Simple English, is a regulatedlanguage aiming to facilitate complex written language that would otherwisestay inaccessible to different groups of people. We present a newsentence-aligned monolingual corpus for Simple German -- German. It containsmultiple document-aligned sources which we have aligned using automaticsentence-alignment methods. We evaluate our alignments based on a manuallylabelled subset of aligned documents. The quality of our sentence alignments,as measured by F1-score, surpasses previous work. We publish the dataset underCC BY-SA and the accompanying code under MIT license.</description><author>Vanessa Toborek, Moritz Busch, Malte Boßert, Christian Bauckhage, Pascal Welke</author><pubDate>Tue, 16 May 2023 18:24:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.01106v3</guid></item><item><title>Conditional variational autoencoder with Gaussian process regression recognition for parametric models</title><link>http://arxiv.org/abs/2305.09625v1</link><description>In this article, we present a data-driven method for parametric models withnoisy observation data. Gaussian process regression based reduced ordermodeling (GPR-based ROM) can realize fast online predictions without usingequations in the offline stage. However, GPR-based ROM does not perform wellfor complex systems since POD projection are naturally linear. Conditionalvariational autoencoder (CVAE) can address this issue via nonlinear neuralnetworks but it has more model complexity, which poses challenges for trainingand tuning hyperparameters. To this end, we propose a framework of CVAE withGaussian process regression recognition (CVAE-GPRR). The proposed methodconsists of a recognition model and a likelihood model. In the recognitionmodel, we first extract low-dimensional features from data by POD to filter theredundant information with high frequency. And then a non-parametric model GPRis used to learn the map from parameters to POD latent variables, which canalso alleviate the impact of noise. CVAE-GPRR can achieve the similar accuracyto CVAE but with fewer parameters. In the likelihood model, neural networks areused to reconstruct data. Besides the samples of POD latent variables and inputparameters, physical variables are also added as the inputs to make predictionsin the whole physical space. This can not be achieved by either GPR-based ROMor CVAE. Moreover, the numerical results show that CVAE-GPRR may alleviate theoverfitting issue in CVAE.</description><author>Xuehan Zhang, Lijian Jiang</author><pubDate>Tue, 16 May 2023 18:24:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09625v1</guid></item><item><title>AI-Augmented Surveys: Leveraging Large Language Models for Opinion Prediction in Nationally Representative Surveys</title><link>http://arxiv.org/abs/2305.09620v1</link><description>How can we use large language models (LLMs) to augment surveys? This paperinvestigates three distinct applications of LLMs fine-tuned by nationallyrepresentative surveys for opinion prediction -- missing data imputation,retrodiction, and zero-shot prediction. We present a new methodologicalframework that incorporates neural embeddings of survey questions, individualbeliefs, and temporal contexts to personalize LLMs in opinion prediction. Among3,110 binarized opinions from 68,846 Americans in the General Social Surveyfrom 1972 to 2021, our best models based on Alpaca-7b excels in missing dataimputation (AUC = 0.87 for personal opinion prediction and $\rho$ = 0.99 forpublic opinion prediction) and retrodiction (AUC = 0.86, $\rho$ = 0.98). Theseremarkable prediction capabilities allow us to fill in missing trends with highconfidence and pinpoint when public attitudes changed, such as the risingsupport for same-sex marriage. However, the models show limited performance ina zero-shot prediction task (AUC = 0.73, $\rho$ = 0.67), highlightingchallenges presented by LLMs without human responses. Further, we find that thebest models' accuracy is lower for individuals with low socioeconomic status,racial minorities, and non-partisan affiliations but higher for ideologicallysorted opinions in contemporary periods. We discuss practical constraints,socio-demographic representation, and ethical concerns regarding individualautonomy and privacy when using LLMs for opinion prediction. This papershowcases a new approach for leveraging LLMs to enhance nationallyrepresentative surveys by predicting missing responses and trends.</description><author>Junsol Kim, Byungkyu Lee</author><pubDate>Tue, 16 May 2023 18:13:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09620v1</guid></item><item><title>The Power of Learned Locally Linear Models for Nonlinear Policy Optimization</title><link>http://arxiv.org/abs/2305.09619v1</link><description>A common pipeline in learning-based control is to iteratively estimate amodel of system dynamics, and apply a trajectory optimization algorithm -e.g.~$\mathtt{iLQR}$ - on the learned model to minimize a target cost. Thispaper conducts a rigorous analysis of a simplified variant of this strategy forgeneral nonlinear systems. We analyze an algorithm which iterates betweenestimating local linear models of nonlinear system dynamics and performing$\mathtt{iLQR}$-like policy updates. We demonstrate that this algorithm attainssample complexity polynomial in relevant problem parameters, and, bysynthesizing locally stabilizing gains, overcomes exponential dependence inproblem horizon. Experimental results validate the performance of ouralgorithm, and compare to natural deep-learning baselines.</description><author>Daniel Pfrommer, Max Simchowitz, Tyler Westenbroek, Nikolai Matni, Stephen Tu</author><pubDate>Tue, 16 May 2023 18:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09619v1</guid></item><item><title>Towards Expert-Level Medical Question Answering with Large Language Models</title><link>http://arxiv.org/abs/2305.09617v1</link><description>Recent artificial intelligence (AI) systems have reached milestones in "grandchallenges" ranging from Go to protein-folding. The capability to retrievemedical knowledge, reason over it, and answer medical questions comparably tophysicians has long been viewed as one such grand challenge. Large language models (LLMs) have catalyzed significant progress in medicalquestion answering; Med-PaLM was the first model to exceed a "passing" score inUS Medical Licensing Examination (USMLE) style questions with a score of 67.2%on the MedQA dataset. However, this and other prior work suggested significantroom for improvement, especially when models' answers were compared toclinicians' answers. Here we present Med-PaLM 2, which bridges these gaps byleveraging a combination of base LLM improvements (PaLM 2), medical domainfinetuning, and prompting strategies including a novel ensemble refinementapproach. Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLMby over 19% and setting a new state-of-the-art. We also observed performanceapproaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLUclinical topics datasets. We performed detailed human evaluations on long-form questions along multipleaxes relevant to clinical applications. In pairwise comparative ranking of 1066consumer medical questions, physicians preferred Med-PaLM 2 answers to thoseproduced by physicians on eight of nine axes pertaining to clinical utility (p&lt; 0.001). We also observed significant improvements compared to Med-PaLM onevery evaluation axis (p &lt; 0.001) on newly introduced datasets of 240 long-form"adversarial" questions to probe LLM limitations. While further studies are necessary to validate the efficacy of these modelsin real-world settings, these results highlight rapid progress towardsphysician-level performance in medical question answering.</description><author>Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, Mike Schaekermann, Amy Wang, Mohamed Amin, Sami Lachgar, Philip Mansfield, Sushant Prakash, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Nenad Tomasev, Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle Barral, Dale Webster, Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan Karthikesalingam, Vivek Natarajan</author><pubDate>Tue, 16 May 2023 18:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09617v1</guid></item><item><title>Planning Multiple Epidemic Interventions with Reinforcement Learning</title><link>http://arxiv.org/abs/2301.12802v2</link><description>Combating an epidemic entails finding a plan that describes when and how toapply different interventions, such as mask-wearing mandates, vaccinations,school or workplace closures. An optimal plan will curb an epidemic withminimal loss of life, disease burden, and economic cost. Finding an optimalplan is an intractable computational problem in realistic settings.Policy-makers, however, would greatly benefit from tools that can efficientlysearch for plans that minimize disease and economic costs especially whenconsidering multiple possible interventions over a continuous and complexaction space given a continuous and equally complex state space. We formulatethis problem as a Markov decision process. Our formulation is unique in itsability to represent multiple continuous interventions over any disease modeldefined by ordinary differential equations. We illustrate how to effectivelyapply state-of-the-art actor-critic reinforcement learning algorithms (PPO andSAC) to search for plans that minimize overall costs. We empirically evaluatethe learning performance of these algorithms and compare their performance tohand-crafted baselines that mimic plans constructed by policy-makers. Ourmethod outperforms baselines. Our work confirms the viability of acomputational approach to support policy-makers</description><author>Anh Mai, Nikunj Gupta, Azza Abouzied, Dennis Shasha</author><pubDate>Tue, 16 May 2023 18:09:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12802v2</guid></item><item><title>Open Korean Corpora: A Practical Report</title><link>http://arxiv.org/abs/2012.15621v2</link><description>Korean is often referred to as a low-resource language in the researchcommunity. While this claim is partially true, it is also because theavailability of resources is inadequately advertised and curated. This workcurates and reviews a list of Korean corpora, first describinginstitution-level resource development, then further iterate through a list ofcurrent open datasets for different types of tasks. We then propose a directionon how open-source dataset construction and releases should be done forless-resourced languages to promote research.</description><author>Won Ik Cho, Sangwhan Moon, Youngsook Song</author><pubDate>Tue, 16 May 2023 18:08:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.15621v2</guid></item><item><title>Large Language Models are Built-in Autoregressive Search Engines</title><link>http://arxiv.org/abs/2305.09612v1</link><description>Document retrieval is a key stage of standard Web search engines. Existingdual-encoder dense retrievers obtain representations for questions anddocuments independently, allowing for only shallow interactions between them.To overcome this limitation, recent autoregressive search engines replace thedual-encoder architecture by directly generating identifiers for relevantdocuments in the candidate pool. However, the training cost of suchautoregressive search engines rises sharply as the number of candidatedocuments increases. In this paper, we find that large language models (LLMs)can follow human instructions to directly generate URLs for document retrieval. Surprisingly, when providing a few {Query-URL} pairs as in-contextdemonstrations, LLMs can generate Web URLs where nearly 90\% of thecorresponding documents contain correct answers to open-domain questions. Inthis way, LLMs can be thought of as built-in search engines, since they havenot been explicitly trained to map questions to document identifiers.Experiments demonstrate that our method can consistently achieve betterretrieval performance than existing retrieval approaches by a significantmargin on three open-domain question answering benchmarks, under both zero andfew-shot settings. The code for this work can be found at\url{https://github.com/Ziems/llm-url}.</description><author>Noah Ziems, Wenhao Yu, Zhihan Zhang, Meng Jiang</author><pubDate>Tue, 16 May 2023 18:04:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09612v1</guid></item><item><title>Concurrent Misclassification and Out-of-Distribution Detection for Semantic Segmentation via Energy-Based Normalizing Flow</title><link>http://arxiv.org/abs/2305.09610v1</link><description>Recent semantic segmentation models accurately classify test-time examplesthat are similar to a training dataset distribution. However, theirdiscriminative closed-set approach is not robust in practical data setups withdistributional shifts and out-of-distribution (OOD) classes. As a result, thepredicted probabilities can be very imprecise when used as confidence scores attest time. To address this, we propose a generative model for concurrentin-distribution misclassification (IDM) and OOD detection that relies on anormalizing flow framework. The proposed flow-based detector with anenergy-based inputs (FlowEneDet) can extend previously deployed segmentationmodels without their time-consuming retraining. Our FlowEneDet results in alow-complexity architecture with marginal increase in the memory footprint.FlowEneDet achieves promising results on Cityscapes, Cityscapes-C, FishyScapesand SegmentMeIfYouCan benchmarks in IDM/OOD detection when applied topretrained DeepLabV3+ and SegFormer semantic segmentation models.</description><author>Denis Gudovskiy, Tomoyuki Okuno, Yohei Nakata</author><pubDate>Tue, 16 May 2023 18:02:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09610v1</guid></item><item><title>Towards Tumour Graph Learning for Survival Prediction in Head &amp; Neck Cancer Patients</title><link>http://arxiv.org/abs/2304.08106v2</link><description>With nearly one million new cases diagnosed worldwide in 2020, head \&amp; neckcancer is a deadly and common malignity. There are challenges to decisionmaking and treatment of such cancer, due to lesions in multiple locations andoutcome variability between patients. Therefore, automated segmentation andprognosis estimation approaches can help ensure each patient gets the mosteffective treatment. This paper presents a framework to perform these functionson arbitrary field of view (FoV) PET and CT registered scans, thus approachingtasks 1 and 2 of the HECKTOR 2022 challenge as team \texttt{VokCow}. The methodconsists of three stages: localization, segmentation and survival prediction.First, the scans with arbitrary FoV are cropped to the head and neck region anda u-shaped convolutional neural network (CNN) is trained to segment the regionof interest. Then, using the obtained regions, another CNN is combined with asupport vector machine classifier to obtain the semantic segmentation of thetumours, which results in an aggregated Dice score of 0.57 in task 1. Finally,survival prediction is approached with an ensemble of Weibull acceleratedfailure times model and deep learning methods. In addition to patient healthrecord data, we explore whether processing graphs of image patches centred atthe tumours via graph convolutions can improve the prognostic predictions. Aconcordance index of 0.64 was achieved in the test set, ranking 6th in thechallenge leaderboard for this task.</description><author>Angel Victor Juanco Muller, Joao F. C. Mota, Keith A. Goatman, Corne Hoogendoorn</author><pubDate>Tue, 16 May 2023 18:02:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08106v2</guid></item><item><title>Data Augmentation for Conflict and Duplicate Detection in Software Engineering Sentence Pairs</title><link>http://arxiv.org/abs/2305.09608v1</link><description>This paper explores the use of text data augmentation techniques to enhanceconflict and duplicate detection in software engineering tasks through sentencepair classification. The study adapts generic augmentation techniques such asshuffling, back translation, and paraphrasing and proposes new dataaugmentation techniques such as Noun-Verb Substitution, target-lemmareplacement and Actor-Action Substitution for software requirement texts. Acomprehensive empirical analysis is conducted on six software text datasets toidentify conflicts and duplicates among sentence pairs. The results demonstratethat data augmentation techniques have a significant impact on the performanceof all software pair text datasets. On the other hand, in cases where thedatasets are relatively balanced, the use of augmentation techniques may resultin a negative effect on the classification performance.</description><author>Garima Malik, Mucahit Cevik, Ayşe Başar</author><pubDate>Tue, 16 May 2023 18:00:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09608v1</guid></item><item><title>Expressiveness Remarks for Denoising Diffusion Models and Samplers</title><link>http://arxiv.org/abs/2305.09605v1</link><description>Denoising diffusion models are a class of generative models which haverecently achieved state-of-the-art results across many domains. Gradual noiseis added to the data using a diffusion process, which transforms the datadistribution into a Gaussian. Samples from the generative model are thenobtained by simulating an approximation of the time reversal of this diffusioninitialized by Gaussian samples. Recent research has explored adaptingdiffusion models for sampling and inference tasks. In this paper, we leverageknown connections to stochastic control akin to the F\"ollmer drift to extendestablished neural network approximation results for the F\"ollmer drift todenoising diffusion models and samplers.</description><author>Francisco Vargas, Teodora Reu, Anna Kerekes</author><pubDate>Tue, 16 May 2023 17:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09605v1</guid></item><item><title>Deep Imputation of Missing Values in Time Series Health Data: A Review with Benchmarking</title><link>http://arxiv.org/abs/2302.10902v2</link><description>The imputation of missing values in multivariate time series (MTS) data iscritical in ensuring data quality and producing reliable data-driven predictivemodels. Apart from many statistical approaches, a few recent studies haveproposed state-of-the-art deep learning methods to impute missing values in MTSdata. However, the evaluation of these deep methods is limited to one or twodata sets, low missing rates, and completely random missing value types. Thissurvey performs six data-centric experiments to benchmark state-of-the-art deepimputation methods on five time series health data sets. Our extensive analysisreveals that no single imputation method outperforms the others on all fivedata sets. The imputation performance depends on data types, individualvariable statistics, missing value rates, and types. Deep learning methods thatjointly perform cross-sectional (across variables) and longitudinal (acrosstime) imputations of missing values in time series data yield statisticallybetter data quality than traditional imputation methods. Althoughcomputationally expensive, deep learning methods are practical given thecurrent availability of high-performance computing resources, especially whendata quality and sample size are highly important in healthcare informatics.Our findings highlight the importance of data-centric selection of imputationmethods to optimize data-driven predictive models.</description><author>Maksims Kazijevs, Manar D. Samad</author><pubDate>Tue, 16 May 2023 17:56:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10902v2</guid></item><item><title>Urban-StyleGAN: Learning to Generate and Manipulate Images of Urban Scenes</title><link>http://arxiv.org/abs/2305.09602v1</link><description>A promise of Generative Adversarial Networks (GANs) is to provide cheapphotorealistic data for training and validating AI models in autonomousdriving. Despite their huge success, their performance on complex imagesfeaturing multiple objects is understudied. While some frameworks producehigh-quality street scenes with little to no control over the image content,others offer more control at the expense of high-quality generation. A commonlimitation of both approaches is the use of global latent codes for the wholeimage, which hinders the learning of independent object distributions.Motivated by SemanticStyleGAN (SSG), a recent work on latent spacedisentanglement in human face generation, we propose a novel framework,Urban-StyleGAN, for urban scene generation and manipulation. We find that astraightforward application of SSG leads to poor results because urban scenesare more complex than human faces. To provide a more compact yet disentangledlatent representation, we develop a class grouping strategy wherein individualclasses are grouped into super-classes. Moreover, we employ an unsupervisedlatent exploration algorithm in the $\mathcal{S}$-space of the generator andshow that it is more efficient than the conventional $\mathcal{W}^{+}$-space incontrolling the image content. Results on the Cityscapes and Mapillary datasetsshow the proposed approach achieves significantly more controllability andimproved image quality than previous approaches on urban scenes and is on parwith general-purpose non-controllable generative models (like StyleGAN2) interms of quality.</description><author>George Eskandar, Youssef Farag, Tarun Yenamandra, Daniel Cremers, Karim Guirguis, Bin Yang</author><pubDate>Tue, 16 May 2023 17:54:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09602v1</guid></item><item><title>Deep Learning Methods for Partial Differential Equations and Related Parameter Identification Problems</title><link>http://arxiv.org/abs/2212.03130v2</link><description>Recent years have witnessed a growth in mathematics for deep learning--whichseeks a deeper understanding of the concepts of deep learning with mathematicsand explores how to make it more robust--and deep learning for mathematics,where deep learning algorithms are used to solve problems in mathematics. Thelatter has popularised the field of scientific machine learning where deeplearning is applied to problems in scientific computing. Specifically, more andmore neural network architectures have been developed to solve specific classesof partial differential equations (PDEs). Such methods exploit properties thatare inherent to PDEs and thus solve the PDEs better than standard feed-forwardneural networks, recurrent neural networks, or convolutional neural networks.This has had a great impact in the area of mathematical modeling whereparametric PDEs are widely used to model most natural and physical processesarising in science and engineering. In this work, we review such methods aswell as their extensions for parametric studies and for solving the relatedinverse problems. We equally proceed to show their relevance in some industrialapplications.</description><author>Derick Nganyu Tanyu, Jianfeng Ning, Tom Freudenberg, Nick Heilenkötter, Andreas Rademacher, Uwe Iben, Peter Maass</author><pubDate>Tue, 16 May 2023 17:53:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.03130v2</guid></item><item><title>Deep Reinforcement Learning to Maximize Arterial Usage during Extreme Congestion</title><link>http://arxiv.org/abs/2305.09600v1</link><description>Collisions, crashes, and other incidents on road networks, if leftunmitigated, can potentially cause cascading failures that can affect largeparts of the system. Timely handling such extreme congestion scenarios isimperative to reduce emissions, enhance productivity, and improve the qualityof urban living. In this work, we propose a Deep Reinforcement Learning (DRL)approach to reduce traffic congestion on multi-lane freeways during extremecongestion. The agent is trained to learn adaptive detouring strategies forcongested freeway traffic such that the freeway lanes along with the localarterial network in proximity are utilized optimally, with rewards beingcongestion reduction and traffic speed improvement. The experimental setup is a2.6-mile-long 4-lane freeway stretch in Shoreline, Washington, USA with twoexits and associated arterial roads simulated on a microscopic and continuousmulti-modal traffic simulator SUMO (Simulation of Urban MObility) while usingparameterized traffic profiles generated using real-world traffic data. Ouranalysis indicates that DRL-based controllers can improve average traffic speedby 21\% when compared to no-action during steep congestion. The study furtherdiscusses the trade-offs involved in the choice of reward functions, the impactof human compliance on agent performance, and the feasibility of knowledgetransfer from one agent to other to address data sparsity and scaling issues.</description><author>Ashutosh Dutta, Milan Jain, Arif Khan, Arun Sathanur</author><pubDate>Tue, 16 May 2023 17:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09600v1</guid></item><item><title>Boosting Event Extraction with Denoised Structure-to-Text Augmentation</title><link>http://arxiv.org/abs/2305.09598v1</link><description>Event extraction aims to recognize pre-defined event triggers and argumentsfrom texts, which suffer from the lack of high-quality annotations. In most NLPapplications, involving a large scale of synthetic training data is a practicaland effective approach to alleviate the problem of data scarcity. However, whenapplying to the task of event extraction, recent data augmentation methodsoften neglect the problem of grammatical incorrectness, structure misalignment,and semantic drifting, leading to unsatisfactory performances. In order tosolve these problems, we propose a denoised structure-to-text augmentationframework for event extraction DAEE, which generates additional training datathrough the knowledge-based structure-to-text generation model and selects theeffective subset from the generated data iteratively with a deep reinforcementlearning agent. Experimental results on several datasets demonstrate that theproposed method generates more diverse text representations for eventextraction and achieves comparable results with the state-of-the-art.</description><author>bo wang, Heyan Huang, Xiaochi Wei, Ge Shi, Xiao Liu, Chong Feng, Tong Zhou, Shuaiqiang Wang, Dawei Yin</author><pubDate>Tue, 16 May 2023 17:52:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09598v1</guid></item><item><title>Identification and Classification of Exoplanets Using Machine Learning Techniques</title><link>http://arxiv.org/abs/2305.09596v1</link><description>NASA's Kepler Space Telescope has been instrumental in the task of findingthe presence of exoplanets in our galaxy. This search has been supported bycomputational data analysis to identify exoplanets from the signals received bythe Kepler telescope. In this paper, we consider building upon some existingwork on exoplanet identification using residual networks for the data of theKepler space telescope and its extended mission K2. This paper aims to explorehow deep learning algorithms can help in classifying the presence of exoplanetswith less amount of data in one case and a more extensive variety of data inanother. In addition to the standard CNN-based method, we propose a Siamesearchitecture that is particularly useful in addressing classification in alow-data scenario. The CNN and ResNet algorithms achieved an average accuracyof 68% for three classes and 86% for two-class classification. However, forboth the three and two classes, the Siamese algorithm achieved 99% accuracy.</description><author>Prithivraj G, Alka Kumari</author><pubDate>Tue, 16 May 2023 17:51:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09596v1</guid></item><item><title>HiNoVa: A Novel Open-Set Detection Method for Automating RF Device Authentication</title><link>http://arxiv.org/abs/2305.09594v1</link><description>New capabilities in wireless network security have been enabled by deeplearning, which leverages patterns in radio frequency (RF) data to identify andauthenticate devices. Open-set detection is an area of deep learning thatidentifies samples captured from new devices during deployment that were notpart of the training set. Past work in open-set detection has mostly beenapplied to independent and identically distributed data such as images. Incontrast, RF signal data present a unique set of challenges as the data forms atime series with non-linear time dependencies among the samples. We introduce anovel open-set detection approach based on the patterns of the hidden statevalues within a Convolutional Neural Network (CNN) Long Short-Term Memory(LSTM) model. Our approach greatly improves the Area Under the Precision-RecallCurve on LoRa, Wireless-WiFi, and Wired-WiFi datasets, and hence, can be usedsuccessfully to monitor and control unauthorized network access of wirelessdevices.</description><author>Luke Puppo, Weng-Keen Wong, Bechir Hamdaoui, Abdurrahman Elmaghbub</author><pubDate>Tue, 16 May 2023 17:47:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09594v1</guid></item><item><title>Leveraging Demonstrations to Improve Online Learning: Quality Matters</title><link>http://arxiv.org/abs/2302.03319v3</link><description>We investigate the extent to which offline demonstration data can improveonline learning. It is natural to expect some improvement, but the question ishow, and by how much? We show that the degree of improvement must depend on thequality of the demonstration data. To generate portable insights, we focus onThompson sampling (TS) applied to a multi-armed bandit as a prototypical onlinelearning algorithm and model. The demonstration data is generated by an expertwith a given competence level, a notion we introduce. We propose an informed TSalgorithm that utilizes the demonstration data in a coherent way through Bayes'rule and derive a prior-dependent Bayesian regret bound. This offers insightinto how pretraining can greatly improve online performance and how the degreeof improvement increases with the expert's competence level. We also develop apractical, approximate informed TS algorithm through Bayesian bootstrapping andshow substantial empirical regret reduction through experiments.</description><author>Botao Hao, Rahul Jain, Tor Lattimore, Benjamin Van Roy, Zheng Wen</author><pubDate>Tue, 16 May 2023 17:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03319v3</guid></item><item><title>In Search of Verifiability: Explanations Rarely Enable Complementary Performance in AI-Advised Decision Making</title><link>http://arxiv.org/abs/2305.07722v2</link><description>The current literature on AI-advised decision making -- involving explainableAI systems advising human decision makers -- presents a series of inconclusiveand confounding results. To synthesize these findings, we propose a simpletheory that elucidates the frequent failure of AI explanations to engenderappropriate reliance and complementary decision making performance. We argueexplanations are only useful to the extent that they allow a human decisionmaker to verify the correctness of an AI's prediction, in contrast to otherdesiderata, e.g., interpretability or spelling out the AI's reasoning process.Prior studies find in many decision making contexts AI explanations do notfacilitate such verification. Moreover, most contexts fundamentally do notallow verification, regardless of explanation method. We conclude with adiscussion of potential approaches for more effective explainable AI-adviseddecision making and human-AI collaboration.</description><author>Raymond Fok, Daniel S. Weld</author><pubDate>Tue, 16 May 2023 17:35:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07722v2</guid></item><item><title>Inductive Graph Neural Networks for Moving Object Segmentation</title><link>http://arxiv.org/abs/2305.09585v1</link><description>Moving Object Segmentation (MOS) is a challenging problem in computer vision,particularly in scenarios with dynamic backgrounds, abrupt lighting changes,shadows, camouflage, and moving cameras. While graph-based methods have shownpromising results in MOS, they have mainly relied on transductive learningwhich assumes access to the entire training and testing data for evaluation.However, this assumption is not realistic in real-world applications where thesystem needs to handle new data during deployment. In this paper, we propose anovel Graph Inductive Moving Object Segmentation (GraphIMOS) algorithm based ona Graph Neural Network (GNN) architecture. Our approach builds a generic modelcapable of performing prediction on newly added data frames using the alreadytrained model. GraphIMOS outperforms previous inductive learning methods and ismore generic than previous transductive techniques. Our proposed algorithmenables the deployment of graph-based MOS models in real-world applications.</description><author>Wieke Prummel, Jhony H. Giraldo, Anastasia Zakharova, Thierry Bouwmans</author><pubDate>Tue, 16 May 2023 17:32:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09585v1</guid></item><item><title>Revisiting Proprioceptive Sensing for Articulated Object Manipulation</title><link>http://arxiv.org/abs/2305.09584v1</link><description>Robots that assist humans will need to interact with articulated objects suchas cabinets or microwaves. Early work on creating systems for doing so usedproprioceptive sensing to estimate joint mechanisms during contact. However,nowadays, almost all systems use only vision and no longer considerproprioceptive information during contact. We believe that proprioceptiveinformation during contact is a valuable source of information and did not findclear motivation for not using it in the literature. Therefore, in this paper,we create a system that, starting from a given grasp, uses proprioceptivesensing to open cabinets with a position-controlled robot and a parallelgripper. We perform a qualitative evaluation of this system, where we find thatslip between the gripper and handle limits the performance. Nonetheless, wefind that the system already performs quite well. This poses the question:should we make more use of proprioceptive information during contact inarticulated object manipulation systems, or is it not worth the addedcomplexity, and can we manage with vision alone? We do not have an answer tothis question, but we hope to spark some discussion on the matter. The codebaseand videos of the system are available athttps://tlpss.github.io/revisiting-proprioception-for-articulated-manipulation/.</description><author>Thomas Lips, Francis wyffels</author><pubDate>Tue, 16 May 2023 17:31:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09584v1</guid></item><item><title>CREPE: Can Vision-Language Foundation Models Reason Compositionally?</title><link>http://arxiv.org/abs/2212.07796v3</link><description>A fundamental characteristic common to both human vision and natural languageis their compositional nature. Yet, despite the performance gains contributedby large vision and language pretraining, we find that: across 7 architecturestrained with 4 algorithms on massive datasets, they struggle atcompositionality. To arrive at this conclusion, we introduce a newcompositionality evaluation benchmark, CREPE, which measures two importantaspects of compositionality identified by cognitive science literature:systematicity and productivity. To measure systematicity, CREPE consists of atest dataset containing over $370K$ image-text pairs and three differentseen-unseen splits. The three splits are designed to test models trained onthree popular training datasets: CC-12M, YFCC-15M, and LAION-400M. We alsogenerate $325K$, $316K$, and $309K$ hard negative captions for a subset of thepairs. To test productivity, CREPE contains $17K$ image-text pairs with ninedifferent complexities plus $183K$ hard negative captions with atomic, swappingand negation foils. The datasets are generated by repurposing the Visual Genomescene graphs and region descriptions and applying handcrafted templates andGPT-3. For systematicity, we find that model performance decreases consistentlywhen novel compositions dominate the retrieval set, with Recall@1 dropping byup to $12\%$. For productivity, models' retrieval success decays as complexityincreases, frequently nearing random chance at high complexity. These resultshold regardless of model and training dataset size.</description><author>Zixian Ma, Jerry Hong, Mustafa Omer Gul, Mona Gandhi, Irena Gao, Ranjay Krishna</author><pubDate>Tue, 16 May 2023 17:27:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07796v3</guid></item><item><title>Private Everlasting Prediction</title><link>http://arxiv.org/abs/2305.09579v1</link><description>A private learner is trained on a sample of labeled points and generates ahypothesis that can be used for predicting the labels of newly sampled pointswhile protecting the privacy of the training set [Kasiviswannathan et al., FOCS2008]. Research uncovered that private learners may need to exhibitsignificantly higher sample complexity than non-private learners as is the casewith, e.g., learning of one-dimensional threshold functions [Bun et al., FOCS2015, Alon et al., STOC 2019]. We explore prediction as an alternative to learning. Instead of puttingforward a hypothesis, a predictor answers a stream of classification queries.Earlier work has considered a private prediction model with just a singleclassification query [Dwork and Feldman, COLT 2018]. We observe that whenanswering a stream of queries, a predictor must modify the hypothesis it usesover time, and, furthermore, that it must use the queries for thismodification, hence introducing potential privacy risks with respect to thequeries themselves. We introduce private everlasting prediction taking into account the privacyof both the training set and the (adaptively chosen) queries made to thepredictor. We then present a generic construction of private everlastingpredictors in the PAC model. The sample complexity of the initial trainingsample in our construction is quadratic (up to polylog factors) in the VCdimension of the concept class. Our construction allows prediction for allconcept classes with finite VC dimension, and in particular threshold functionswith constant size initial training sample, even when considered over infinitedomains, whereas it is known that the sample complexity of privately learningthreshold functions must grow as a function of the domain size and hence isimpossible for infinite domains.</description><author>Moni Naor, Kobbi Nissim, Uri Stemmer, Chao Yan</author><pubDate>Tue, 16 May 2023 17:26:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09579v1</guid></item><item><title>Localizing Model Behavior with Path Patching</title><link>http://arxiv.org/abs/2304.05969v2</link><description>Localizing behaviors of neural networks to a subset of the network'scomponents or a subset of interactions between components is a natural firststep towards analyzing network mechanisms and possible failure modes. Existingwork is often qualitative and ad-hoc, and there is no consensus on theappropriate way to evaluate localization claims. We introduce path patching, atechnique for expressing and quantitatively testing a natural class ofhypotheses expressing that behaviors are localized to a set of paths. We refinean explanation of induction heads, characterize a behavior of GPT-2, and opensource a framework for efficiently running similar experiments.</description><author>Nicholas Goldowsky-Dill, Chris MacLeod, Lucas Sato, Aryaman Arora</author><pubDate>Tue, 16 May 2023 17:24:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05969v2</guid></item><item><title>Partial Mobilization: Tracking Multilingual Information Flows Amongst Russian Media Outlets and Telegram</title><link>http://arxiv.org/abs/2301.10856v2</link><description>In response to disinformation and propaganda from Russian online mediafollowing the Russian invasion of Ukraine, Russian outlets including RussiaToday and Sputnik News were banned throughout Europe. To maintain viewership,many of these Russian outlets began to heavily promote their content onmessaging services like Telegram. In this work, we study how 16 Russian mediaoutlets interacted with and utilized 732 Telegram channels throughout 2022.Leveraging the foundational model MPNet, DP-means clustering, and HawkesProcesses, we trace how narratives spread between news sites and Telegramchannels. We show that news outlets not only propagate existing narrativesthrough Telegram, but that they source material from the messaging platform.Across the sites in our study, between 2.3% (ura.news) and 26.7% (ukraina.ru)of articles discuss content that originated/resulted from activity on Telegram.Finally, tracking the spread of individual topics, we measure the rate at whichnews websites and their Telegram channels disseminate content within theRussian media ecosystem.</description><author>Hans W. A. Hanley, Zakir Durumeric</author><pubDate>Tue, 16 May 2023 17:19:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.10856v2</guid></item><item><title>UOR: Universal Backdoor Attacks on Pre-trained Language Models</title><link>http://arxiv.org/abs/2305.09574v1</link><description>Backdoors implanted in pre-trained language models (PLMs) can be transferredto various downstream tasks, which exposes a severe security threat. However,most existing backdoor attacks against PLMs are un-targeted and task-specific.Few targeted and task-agnostic methods use manually pre-defined triggers andoutput representations, which prevent the attacks from being more effective andgeneral. In this paper, we first summarize the requirements that a morethreatening backdoor attack against PLMs should satisfy, and then propose a newbackdoor attack method called UOR, which breaks the bottleneck of the previousapproach by turning manual selection into automatic optimization. Specifically,we define poisoned supervised contrastive learning which can automaticallylearn the more uniform and universal output representations of triggers forvarious PLMs. Moreover, we use gradient search to select appropriate triggerwords which can be adaptive to different PLMs and vocabularies. Experimentsshow that our method can achieve better attack performance on various textclassification tasks compared to manual methods. Further, we tested our methodon PLMs with different architectures, different usage paradigms, and moredifficult tasks, which demonstrated the universality of our method.</description><author>Wei Du, Peixuan Li, Boqun Li, Haodong Zhao, Gongshen Liu</author><pubDate>Tue, 16 May 2023 17:11:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09574v1</guid></item><item><title>Walking the Walk of AI Ethics: Organizational Challenges and the Individualization of Risk among Ethics Entrepreneurs</title><link>http://arxiv.org/abs/2305.09573v1</link><description>Amidst decline in public trust in technology, computing ethics have takencenter stage, and critics have raised questions about corporate ethics washing.Yet few studies examine the actual implementation of AI ethics values intechnology companies. Based on a qualitative analysis of technology workerstasked with integrating AI ethics into product development, we find thatworkers experience an environment where policies, practices, and outcomes aredecoupled. We analyze AI ethics workers as ethics entrepreneurs who work toinstitutionalize new ethics-related practices within organizations. We showthat ethics entrepreneurs face three major barriers to their work. First, theystruggle to have ethics prioritized in an environment centered around softwareproduct launches. Second, ethics are difficult to quantify in a context wherecompany goals are incentivized by metrics. Third, the frequent reorganizationof teams makes it difficult to access knowledge and maintain relationshipscentral to their work. Consequently, individuals take on great personal riskwhen raising ethics issues, especially when they come from marginalizedbackgrounds. These findings shed light on complex dynamics of institutionalchange at technology companies.</description><author>Sanna J. Ali, Angèle Christin, Andrew Smart, Riitta Katila</author><pubDate>Tue, 16 May 2023 17:11:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09573v1</guid></item><item><title>Fracture Detection in Pediatric Wrist Trauma X-ray Images Using YOLOv8 Algorithm</title><link>http://arxiv.org/abs/2304.05071v3</link><description>Hospital emergency departments frequently receive lots of bone fracturecases, with pediatric wrist trauma fracture accounting for the majority ofthem. Before pediatric surgeons perform surgery, they need to ask patients howthe fracture occurred and analyze the fracture situation by interpreting X-rayimages. The interpretation of X-ray images often requires a combination oftechniques from radiologists and surgeons, which requires time-consumingspecialized training. With the rise of deep learning in the field of computervision, network models applying for fracture detection has become an importantresearch topic. In this paper, we train YOLOv8 (the latest version of You OnlyLook Once) model on the GRAZPEDWRI-DX dataset, and use data augmentation toimprove the model performance. The experimental results show that our modelhave reached the state-of-the-art (SOTA) real-time model performance.Specifically, compared to YOLOv8s models, the mean average precision (mAP 50)of our models improve from 0.604 and 0.625 to 0.612 and 0.631 at the inputimage size of 640 and 1024, respectively. To enable surgeons to use our modelfor fracture detection on pediatric wrist trauma X-ray images, we have designedthe application "Fracture Detection Using YOLOv8 App" to assist surgeons indiagnosing fractures, reducing the probability of error analysis, and providingmore useful information for surgery. Our implementation code is released athttps://github.com/RuiyangJu/Bone_Fracture_Detection_YOLOv8.</description><author>Rui-Yang Ju, Weiming Cai</author><pubDate>Tue, 16 May 2023 17:10:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05071v3</guid></item><item><title>Ray-Patch: An Efficient Decoder for Light Field Transformers</title><link>http://arxiv.org/abs/2305.09566v1</link><description>In this paper we propose the Ray-Patch decoder, a novel model to efficientlyquery transformers to decode implicit representations into target views. OurRay-Patch decoding reduces the computational footprint up to two orders ofmagnitude compared to previous models, without losing global attention, andhence maintaining specific task metrics. The key idea of our novel decoder isto split the target image into a set of patches, then querying the transformerfor each patch to extract a set of feature vectors, which are finally decodedinto the target image using convolutional layers. Our experimental resultsquantify the effectiveness of our method, specifically the notable boost inrendering speed and equal specific task metrics for different baselines anddatasets.</description><author>T. B. Martins, J. Civera</author><pubDate>Tue, 16 May 2023 17:03:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09566v1</guid></item><item><title>Toward Falsifying Causal Graphs Using a Permutation-Based Test</title><link>http://arxiv.org/abs/2305.09565v1</link><description>Understanding the causal relationships among the variables of a system isparamount to explain and control its behaviour. Inferring the causal graph fromobservational data without interventions, however, requires a lot of strongassumptions that are not always realistic. Even for domain experts it can bechallenging to express the causal graph. Therefore, metrics that quantitativelyassess the goodness of a causal graph provide helpful checks before using it indownstream tasks. Existing metrics provide an absolute number ofinconsistencies between the graph and the observed data, and without abaseline, practitioners are left to answer the hard question of how many suchinconsistencies are acceptable or expected. Here, we propose a novelconsistency metric by constructing a surrogate baseline through nodepermutations. By comparing the number of inconsistencies with those on thesurrogate baseline, we derive an interpretable metric that captures whether theDAG fits significantly better than random. Evaluating on both simulated andreal data sets from various domains, including biology and cloud monitoring, wedemonstrate that the true DAG is not falsified by our metric, whereas the wronggraphs given by a hypothetical user are likely to be falsified.</description><author>Elias Eulig, Atalanti A. Mastakouri, Patrick Blöbaum, Michaela Hardt, Dominik Janzing</author><pubDate>Tue, 16 May 2023 17:02:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09565v1</guid></item><item><title>DETRs with Hybrid Matching</title><link>http://arxiv.org/abs/2207.13080v3</link><description>One-to-one set matching is a key design for DETR to establish its end-to-endcapability, so that object detection does not require a hand-crafted NMS(non-maximum suppression) to remove duplicate detections. This end-to-endsignature is important for the versatility of DETR, and it has been generalizedto broader vision tasks. However, we note that there are few queries assignedas positive samples and the one-to-one set matching significantly reduces thetraining efficacy of positive samples. We propose a simple yet effective methodbased on a hybrid matching scheme that combines the original one-to-onematching branch with an auxiliary one-to-many matching branch during training.Our hybrid strategy has been shown to significantly improve accuracy. Ininference, only the original one-to-one match branch is used, thus maintainingthe end-to-end merit and the same inference efficiency of DETR. The method isnamed H-DETR, and it shows that a wide range of representative DETR methods canbe consistently improved across a wide range of visual tasks, includingDeformableDETR, PETRv2, PETR, and TransTrack, among others. The code isavailable at: https://github.com/HDETR</description><author>Ding Jia, Yuhui Yuan, Haodi He, Xiaopei Wu, Haojun Yu, Weihong Lin, Lei Sun, Chao Zhang, Han Hu</author><pubDate>Tue, 16 May 2023 17:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.13080v3</guid></item><item><title>Image Reconstruction using Superpixel Clustering and Tensor Completion</title><link>http://arxiv.org/abs/2305.09564v1</link><description>This paper presents a pixel selection method for compact image representationbased on superpixel segmentation and tensor completion. Our method divides theimage into several regions that capture important textures or semantics andselects a representative pixel from each region to store. We experiment withdifferent criteria for choosing the representative pixel and find that thecentroid pixel performs the best. We also propose two smooth tensor completionalgorithms that can effectively reconstruct different types of images from theselected pixels. Our experiments show that our superpixel-based method achievesbetter results than uniform sampling for various missing ratios.</description><author>Maame G. Asante-Mensah, Anh Huy Phan, Salman Ahmadi-Asl, Zaher Al Aghbari, Andrzej Cichocki</author><pubDate>Tue, 16 May 2023 17:00:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09564v1</guid></item><item><title>Learning from Aggregated Data: Curated Bags versus Random Bags</title><link>http://arxiv.org/abs/2305.09557v1</link><description>Protecting user privacy is a major concern for many machine learning systemsthat are deployed at scale and collect from a diverse set of population. Oneway to address this concern is by collecting and releasing data labels in anaggregated manner so that the information about a single user is potentiallycombined with others. In this paper, we explore the possibility of trainingmachine learning models with aggregated data labels, rather than individuallabels. Specifically, we consider two natural aggregation procedures suggestedby practitioners: curated bags where the data points are grouped based oncommon features and random bags where the data points are grouped randomly inbag of similar sizes. For the curated bag setting and for a broad range of lossfunctions, we show that we can perform gradient-based learning without anydegradation in performance that may result from aggregating data. Our method isbased on the observation that the sum of the gradients of the loss function onindividual data examples in a curated bag can be computed from the aggregatelabel without the need for individual labels. For the random bag setting, weprovide a generalization risk bound based on the Rademacher complexity of thehypothesis class and show how empirical risk minimization can be regularized toachieve the smallest risk bound. In fact, in the random bag setting, there is atrade-off between size of the bag and the achievable error rate as our boundindicates. Finally, we conduct a careful empirical study to confirm ourtheoretical findings. In particular, our results suggest that aggregatelearning can be an effective method for preserving user privacy whilemaintaining model accuracy.</description><author>Lin Chen, Thomas Fu, Amin Karbasi, Vahab Mirrokni</author><pubDate>Tue, 16 May 2023 16:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09557v1</guid></item><item><title>Adapting Sentence Transformers for the Aviation Domain</title><link>http://arxiv.org/abs/2305.09556v1</link><description>Learning effective sentence representations is crucial for many NaturalLanguage Processing (NLP) tasks, including semantic search, semantic textualsimilarity (STS), and clustering. While multiple transformer models have beendeveloped for sentence embedding learning, these models may not performoptimally when dealing with specialized domains like aviation, which has uniquecharacteristics such as technical jargon, abbreviations, and unconventionalgrammar. Furthermore, the absence of labeled datasets makes it difficult totrain models specifically for the aviation domain. To address these challenges,we propose a novel approach for adapting sentence transformers for the aviationdomain. Our method is a two-stage process consisting of pre-training followedby fine-tuning. During pre-training, we use Transformers and SequentialDenoising AutoEncoder (TSDAE) with aviation text data as input to improve theinitial model performance. Subsequently, we fine-tune our models using aNatural Language Inference (NLI) dataset in the Sentence Bidirectional EncoderRepresentations from Transformers (SBERT) architecture to mitigate overfittingissues. Experimental results on several downstream tasks show that our adaptedsentence transformers significantly outperform general-purpose transformers,demonstrating the effectiveness of our approach in capturing the nuances of theaviation domain. Overall, our work highlights the importance of domain-specificadaptation in developing high-quality NLP solutions for specialized industrieslike aviation.</description><author>Liya Wang, Jason Chou, Dave Rouck, Alex Tien, Diane M Baumgartner</author><pubDate>Tue, 16 May 2023 16:53:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09556v1</guid></item><item><title>Life of PII -- A PII Obfuscation Transformer</title><link>http://arxiv.org/abs/2305.09550v1</link><description>Protecting sensitive information is crucial in today's world of LargeLanguage Models (LLMs) and data-driven services. One common method used topreserve privacy is by using data perturbation techniques to reduceoverreaching utility of (sensitive) Personal Identifiable Information (PII)data while maintaining its statistical and semantic properties. Dataperturbation methods often result in significant information loss, making themimpractical for use. In this paper, we propose 'Life of PII', a novelObfuscation Transformer framework for transforming PII into faux-PII whilepreserving the original information, intent, and context as much as possible.Our approach includes an API to interface with the given document, aconfiguration-based obfuscator, and a model based on the Transformerarchitecture, which has shown high context preservation and performance innatural language processing tasks and LLMs. Our Transformer-based approach learns mapping between the original PII andits transformed faux-PII representation, which we call "obfuscated" data. Ourexperiments demonstrate that our method, called Life of PII, outperformstraditional data perturbation techniques in terms of both utility preservationand privacy protection. We show that our approach can effectively reduceutility loss while preserving the original information, offering greaterflexibility in the trade-off between privacy protection and data utility. Ourwork provides a solution for protecting PII in various real-world applications.</description><author>Ajinkya Deshmukh, Saumya Banthia, Anantha Sharma</author><pubDate>Tue, 16 May 2023 16:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09550v1</guid></item><item><title>How to select predictive models for causal inference?</title><link>http://arxiv.org/abs/2302.00370v2</link><description>As predictive models -- e.g., from machine learning -- give likely outcomes,they may be used to reason on the effect of an intervention, a causal-inferencetask. The increasing complexity of health data has opened the door to aplethora of models, but also the Pandora box of model selection: which of thesemodels yield the most valid causal estimates? Here we highlight that classicmachine-learning model selection does not select the best outcome models forcausal inference. Indeed, causal model selection should control both outcomeerrors for each individual, treated or not treated, whereas only one outcome isobserved. Theoretically, simple risks used in machine learning do not controlcausal effects when treated and non-treated population differ too much. Moreelaborate risks build proxies of the causal error using ``nuisance''re-weighting to compute it on the observed data. But does computing thesenuisance adds noise to model selection? Drawing from an extensive empiricalstudy, we outline a good causal model-selection procedure: using the so-called$R\text{-risk}$; using flexible estimators to compute the nuisance models onthe train set; and splitting out 10\% of the data to compute risks.</description><author>Matthieu Doutreligne, Gaël Varoquaux</author><pubDate>Tue, 16 May 2023 16:47:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00370v2</guid></item><item><title>Measuring Stereotypes using Entity-Centric Data</title><link>http://arxiv.org/abs/2305.09548v1</link><description>Stereotypes inform how we present ourselves and others, and in turn how webehave. They are thus important to measure. Recent work has used projections ofembeddings from Distributional Semantic Models (DSMs), such as BERT, to performthese measurements. However, DSMs capture cognitive associations that are notnecessarily relevant to the interpersonal nature of stereotyping. Here, wepropose and evaluate three novel, entity-centric methods for learningstereotypes from Twitter and Wikipedia biographies. Models are trained byleveraging the fact that multiple phrases are applied to the same person,magnifying the person-centric nature of the learned associations. We show thatthese models outperform existing approaches to stereotype measurement withrespect to 1) predicting which identities people apply to themselves andothers, and 2) quantifying stereotypes on salient social dimensions (e.g.gender). Via a case study, we also show the utility of these models for futurequestions in computational social science.</description><author>Navid Madani, Rabiraj Bandyopadhyay, Michael Miller Yoder, Kenneth Joseph</author><pubDate>Tue, 16 May 2023 16:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09548v1</guid></item><item><title>Empowering GNNs via Edge-Aware Weisfeiler-Lehman Algorithm</title><link>http://arxiv.org/abs/2206.02059v2</link><description>Message passing graph neural networks (GNNs) are known to have theirexpressiveness upper-bounded by 1-dimensional Weisfeiler-Lehman (1-WL)algorithm. To achieve more powerful GNNs, existing attempts either require adhoc features, or involve operations that incur high time and spacecomplexities. In this work, we propose a general and provably powerful GNNframework that preserves the scalability of the message passing scheme. Inparticular, we first propose to empower 1-WL for graph isomorphism test byconsidering edges among neighbors, giving rise to NC-1-WL. The expressivenessof NC-1-WL is shown to be strictly above 1-WL and below 3-WL theoretically.Further, we propose the NC-GNN framework as a differentiable neural version ofNC-1-WL. Our simple implementation of NC-GNN is provably as powerful asNC-1-WL. Experiments demonstrate that our NC-GNN performs effectively andefficiently on various benchmarks.</description><author>Meng Liu, Haiyang Yu, Shuiwang Ji</author><pubDate>Tue, 16 May 2023 16:41:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.02059v2</guid></item><item><title>EEG-based Sleep Staging with Hybrid Attention</title><link>http://arxiv.org/abs/2305.09543v1</link><description>Sleep staging is critical for assessing sleep quality and diagnosing sleepdisorders. However, capturing both the spatial and temporal relationshipswithin electroencephalogram (EEG) signals during different sleep stages remainschallenging. In this paper, we propose a novel framework called the HybridAttention EEG Sleep Staging (HASS) Framework. Specifically, we propose awell-designed spatio-temporal attention mechanism to adaptively assign weightsto inter-channels and intra-channel EEG segments based on the spatio-temporalrelationship of the brain during different sleep stages. Experiment results onthe MASS and ISRUC datasets demonstrate that HASS can significantly improvetypical sleep staging networks. Our proposed framework alleviates thedifficulties of capturing the spatial-temporal relationship of EEG signalsduring sleep staging and holds promise for improving the accuracy andreliability of sleep assessment in both clinical and research settings.</description><author>Xinliang Zhou, Chenyu Liu, Jiaping Xiao, Yang Liu</author><pubDate>Tue, 16 May 2023 16:37:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09543v1</guid></item><item><title>Increasing Melanoma Diagnostic Confidence: Forcing the Convolutional Network to Learn from the Lesion</title><link>http://arxiv.org/abs/2305.09542v1</link><description>Deep learning implemented with convolutional network architectures can exceedspecialists' diagnostic accuracy. However, whole-image deep learning trained ona given dataset may not generalize to other datasets. The problem arisesbecause extra-lesional features - ruler marks, ink marks, and other melanomacorrelates - may serve as information leaks. These extra-lesional features,discoverable by heat maps, degrade melanoma diagnostic performance and causetechniques learned on one data set to fail to generalize. We propose a noveltechnique to improve melanoma recognition by an EfficientNet model. The modeltrains the network to detect the lesion and learn features from the detectedlesion. A generalizable elliptical segmentation model for lesions wasdeveloped, with an ellipse enclosing a lesion and the ellipse enclosed by anextended rectangle (bounding box). The minimal bounding box was extended by 20%to allow some background around the lesion. The publicly availableInternational Skin Imaging Collaboration (ISIC) 2020 skin lesion image datasetwas used to evaluate the effectiveness of the proposed method. Our test resultsshow that the proposed method improved diagnostic accuracy by increasing themean area under receiver operating characteristic curve (mean AUC) score from0.9 to 0.922. Additionally, correctly diagnosed scores are also improved,providing better separation of scores, thereby increasing melanoma diagnosticconfidence. The proposed lesion-focused convolutional technique warrantsfurther study.</description><author>Norsang Lama, R. Joe Stanley, Anand Nambisan, Akanksha Maurya, Jason Hagerty, William V. Stoecker</author><pubDate>Tue, 16 May 2023 16:34:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09542v1</guid></item><item><title>Learning Higher-order Object Interactions for Keypoint-based Video Understanding</title><link>http://arxiv.org/abs/2305.09539v1</link><description>Action recognition is an important problem that requires identifying actionsin video by learning complex interactions across scene actors and objects.However, modern deep-learning based networks often require significantcomputation, and may capture scene context using various modalities thatfurther increases compute costs. Efficient methods such as those used for AR/VRoften only use human-keypoint information but suffer from a loss of scenecontext that hurts accuracy. In this paper, we describe an action-localizationmethod, KeyNet, that uses only the keypoint data for tracking and actionrecognition. Specifically, KeyNet introduces the use of object based keypointinformation to capture context in the scene. Our method illustrates how tobuild a structured intermediate representation that allows modelinghigher-order interactions in the scene from object and human keypoints withoutusing any RGB information. We find that KeyNet is able to track and classifyhuman actions at just 5 FPS. More importantly, we demonstrate that objectkeypoints can be modeled to recover any loss in context from using keypointinformation over AVA action and Kinetics datasets.</description><author>Yi Huang, Asim Kadav, Farley Lai, Deep Patel, Hans Peter Graf</author><pubDate>Tue, 16 May 2023 16:30:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09539v1</guid></item><item><title>PiML Toolbox for Interpretable Machine Learning Model Development and Validation</title><link>http://arxiv.org/abs/2305.04214v2</link><description>PiML (read $\pi$-ML, /`pai.`em.`el/) is an integrated and open-access Pythontoolbox for interpretable machine learning model development and modeldiagnostics. It is designed with machine learning workflows in both low-codeand high-code modes, including data pipeline, model training, modelinterpretation and explanation, and model diagnostics and comparison. Thetoolbox supports a growing list of interpretable models (e.g. GAM, GAMI-Net,XGB2) with inherent local and/or global interpretability. It also supportsmodel-agnostic explainability tools (e.g. PFI, PDP, LIME, SHAP) and a powerfulsuite of model-agnostic diagnostics (e.g. weakness, uncertainty, robustness,fairness). Integration of PiML models and tests to existing MLOps platforms forquality assurance are enabled by flexible high-code APIs. Furthermore, PiMLtoolbox comes with a comprehensive user guide and hands-on examples, includingthe applications for model development and validation in banking. The projectis available at https://github.com/SelfExplainML/PiML-Toolbox.</description><author>Agus Sudjianto, Aijun Zhang, Zebin Yang, Yu Su, Ningzhou Zeng</author><pubDate>Tue, 16 May 2023 16:30:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04214v2</guid></item><item><title>A Comparative Study of Methods for Estimating Conditional Shapley Values and When to Use Them</title><link>http://arxiv.org/abs/2305.09536v1</link><description>Shapley values originated in cooperative game theory but are extensively usedtoday as a model-agnostic explanation framework to explain predictions made bycomplex machine learning models in the industry and academia. There are severalalgorithmic approaches for computing different versions of Shapley valueexplanations. Here, we focus on conditional Shapley values for predictivemodels fitted to tabular data. Estimating precise conditional Shapley values isdifficult as they require the estimation of non-trivial conditionalexpectations. In this article, we develop new methods, extend earlier proposedapproaches, and systematize the new refined and existing methods into differentmethod classes for comparison and evaluation. The method classes use eitherMonte Carlo integration or regression to model the conditional expectations. Weconduct extensive simulation studies to evaluate how precisely the differentmethod classes estimate the conditional expectations, and thereby theconditional Shapley values, for different setups. We also apply the methods toseveral real-world data experiments and provide recommendations for when to usethe different method classes and approaches. Roughly speaking, we recommendusing parametric methods when we can specify the data distribution almostcorrectly, as they generally produce the most accurate Shapley valueexplanations. When the distribution is unknown, both generative methods andregression models with a similar form as the underlying predictive model aregood and stable options. Regression-based methods are often slow to train butproduce the Shapley value explanations quickly once trained. The vice versa istrue for Monte Carlo-based methods, making the different methods appropriate indifferent practical situations.</description><author>Lars Henry Berge Olsen, Ingrid Kristine Glad, Martin Jullum, Kjersti Aas</author><pubDate>Tue, 16 May 2023 16:27:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09536v1</guid></item><item><title>What's the Problem, Linda? The Conjunction Fallacy as a Fairness Problem</title><link>http://arxiv.org/abs/2305.09535v1</link><description>The field of Artificial Intelligence (AI) is focusing on creating automateddecision-making (ADM) systems that operate as close as possible to human-likeintelligence. This effort has pushed AI researchers into exploring cognitivefields like psychology. The work of Daniel Kahneman and the late Amos Tverskyon biased human decision-making, including the study of the conjunctionfallacy, has experienced a second revival because of this. Under theconjunction fallacy a human decision-maker will go against basic probabilitylaws and rank as more likely a conjunction over one of its parts. It has beenproven overtime through a set of experiments with the Linda Problem being themost famous one. Although this interdisciplinary effort is welcomed, we fearthat AI researchers ignore the driving force behind the conjunction fallacy ascaptured by the Linda Problem: the fact that Linda must be stereotypicallydescribed as a woman. In this paper we revisit the Linda Problem and formulateit as a fairness problem. In doing so we introduce perception as a parameter ofinterest through the structural causal perception framework. Using anillustrative decision-making example, we showcase the proposed conceptualframework and its potential impact for developing fair ADM systems.</description><author>Jose Alvarez Colmenares</author><pubDate>Tue, 16 May 2023 16:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09535v1</guid></item><item><title>MetaSRL++: A Uniform Scheme for Modelling Deeper Semantics</title><link>http://arxiv.org/abs/2305.09534v1</link><description>Despite enormous progress in Natural Language Processing (NLP), our field isstill lacking a common deep semantic representation scheme. As a result, theproblem of meaning and understanding is typically sidestepped through moresimple, approximative methods. This paper argues that in order to arrive atsuch a scheme, we also need a common modelling scheme. It therefore introducesMetaSRL++, a uniform, language- and modality-independent modelling scheme basedon Semantic Graphs, as a step towards a common representation scheme; as wellas a method for defining the concepts and entities that are used in thesegraphs. Our output is twofold. First, we illustrate MetaSRL++ through concreteexamples. Secondly, we discuss how it relates to existing work in the field.</description><author>Fritz Hohl, Nianheng Wu, Martina Galetti, Remi van Trijp</author><pubDate>Tue, 16 May 2023 16:26:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09534v1</guid></item><item><title>NightHazeFormer: Single Nighttime Haze Removal Using Prior Query Transformer</title><link>http://arxiv.org/abs/2305.09533v1</link><description>Nighttime image dehazing is a challenging task due to the presence ofmultiple types of adverse degrading effects including glow, haze, blurry,noise, color distortion, and so on. However, most previous studies mainly focuson daytime image dehazing or partial degradations presented in nighttime hazyscenes, which may lead to unsatisfactory restoration results. In this paper, wepropose an end-to-end transformer-based framework for nighttime haze removal,called NightHazeFormer. Our proposed approach consists of two stages:supervised pre-training and semi-supervised fine-tuning. During thepre-training stage, we introduce two powerful priors into the transformerdecoder to generate the non-learnable prior queries, which guide the model toextract specific degradations. For the fine-tuning, we combine the generatedpseudo ground truths with input real-world nighttime hazy images as pairedimages and feed into the synthetic domain to fine-tune the pre-trained model.This semi-supervised fine-tuning paradigm helps improve the generalization toreal domain. In addition, we also propose a large-scale synthetic datasetcalled UNREAL-NH, to simulate the real-world nighttime haze scenarioscomprehensively. Extensive experiments on several synthetic and real-worlddatasets demonstrate the superiority of our NightHazeFormer overstate-of-the-art nighttime haze removal methods in terms of both visually andquantitatively.</description><author>Yun Liu, Zhongsheng Yan, Sixiang Chen, Tian Ye, Wenqi Ren, Erkang Chen</author><pubDate>Tue, 16 May 2023 16:26:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09533v1</guid></item><item><title>Learning Correspondence Uncertainty via Differentiable Nonlinear Least Squares</title><link>http://arxiv.org/abs/2305.09527v1</link><description>We propose a differentiable nonlinear least squares framework to account foruncertainty in relative pose estimation from feature correspondences.Specifically, we introduce a symmetric version of the probabilistic normalepipolar constraint, and an approach to estimate the covariance of featurepositions by differentiating through the camera pose estimation procedure. Weevaluate our approach on synthetic, as well as the KITTI and EuRoC real-worlddatasets. On the synthetic dataset, we confirm that our learned covariancesaccurately approximate the true noise distribution. In real world experiments,we find that our approach consistently outperforms state-of-the-artnon-probabilistic and probabilistic approaches, regardless of the featureextraction algorithm of choice.</description><author>Dominik Muhle, Lukas Koestler, Krishna Murthy Jatavallabhula, Daniel Cremers</author><pubDate>Tue, 16 May 2023 16:21:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09527v1</guid></item><item><title>SALSA PICANTE: a machine learning attack on LWE with binary secrets</title><link>http://arxiv.org/abs/2303.04178v3</link><description>Learning with Errors (LWE) is a hard math problem underpinning many proposedpost-quantum cryptographic (PQC) systems. The only PQC Key Exchange Mechanism(KEM) standardized by NIST is based on module~LWE, and current publiclyavailable PQ Homomorphic Encryption (HE) libraries are based on ring LWE. Thesecurity of LWE-based PQ cryptosystems is critical, but certain implementationchoices could weaken them. One such choice is sparse binary secrets, desirablefor PQ HE schemes for efficiency reasons. Prior work, SALSA, demonstrated amachine learning-based attack on LWE with sparse binary secrets in smalldimensions ($n \le 128$) and low Hamming weights ($h \le 4$). However, thisattack assumes access to millions of eavesdropped LWE samples and fails athigher Hamming weights or dimensions. We present PICANTE, an enhanced machine learning attack on LWE with sparsebinary secrets, which recovers secrets in much larger dimensions (up to$n=350$) and with larger Hamming weights (roughly $n/10$, and up to $h=60$ for$n=350$). We achieve this dramatic improvement via a novel preprocessing step,which allows us to generate training data from a linear number of eavesdroppedLWE samples ($4n$) and changes the distribution of the data to improvetransformer training. We also improve the secret recovery methods of SALSA andintroduce a novel cross-attention recovery mechanism allowing us to read offthe secret directly from the trained models. While PICANTE does not threatenNIST's proposed LWE standards, it demonstrates significant improvement overSALSA and could scale further, highlighting the need for future investigationinto machine learning attacks on LWE with sparse binary secrets.</description><author>Cathy Li, Jana Sotáková, Emily Wenger, Mohamed Malhou, Evrard Garcelon, Francois Charton, Kristin Lauter</author><pubDate>Tue, 16 May 2023 16:19:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04178v3</guid></item><item><title>SCTracker: Multi-object tracking with shape and confidence constraints</title><link>http://arxiv.org/abs/2305.09523v1</link><description>Detection-based tracking is one of the main methods of multi-object tracking.It can obtain good tracking results when using excellent detectors but it mayassociate wrong targets when facing overlapping and low-confidence detections.To address this issue, this paper proposes a multi-object tracker based onshape constraint and confidence named SCTracker. In the data association stage,an Intersection of Union distance with shape constraints is applied tocalculate the cost matrix between tracks and detections, which can effectivelyavoid the track tracking to the wrong target with the similar position butinconsistent shape, so as to improve the accuracy of data association.Additionally, the Kalman Filter based on the detection confidence is used toupdate the motion state to improve the tracking performance when the detectionhas low confidence. Experimental results on MOT 17 dataset show that theproposed method can effectively improve the tracking performance ofmulti-object tracking.</description><author>Huan Mao, Yulin Chen, Zongtan Li, Feng Chen, Pingping Chen</author><pubDate>Tue, 16 May 2023 16:18:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09523v1</guid></item><item><title>Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation</title><link>http://arxiv.org/abs/2211.02127v3</link><description>We consider the problem of multi-agent navigation and collision avoidancewhen observations are limited to the local neighborhood of each agent. Wepropose InforMARL, a novel architecture for multi-agent reinforcement learning(MARL) which uses local information intelligently to compute paths for all theagents in a decentralized manner. Specifically, InforMARL aggregatesinformation about the local neighborhood of agents for both the actor and thecritic using a graph neural network and can be used in conjunction with anystandard MARL algorithm. We show that (1) in training, InforMARL has bettersample efficiency and performance than baseline approaches, despite using lessinformation, and (2) in testing, it scales well to environments with arbitrarynumbers of agents and obstacles. We illustrate these results using four taskenvironments, including one with predetermined goals for each agent, and one inwhich the agents collectively try to cover all goals. Code available athttps://github.com/nsidn98/InforMARL.</description><author>Siddharth Nayak, Kenneth Choi, Wenqi Ding, Sydney Dolan, Karthik Gopalakrishnan, Hamsa Balakrishnan</author><pubDate>Tue, 16 May 2023 16:17:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.02127v3</guid></item><item><title>Undercover Deepfakes: Detecting Fake Segments in Videos</title><link>http://arxiv.org/abs/2305.06564v2</link><description>The recent renaissance in generative models, driven primarily by the adventof diffusion models and iterative improvement in GAN methods, has enabled manycreative applications. However, each advancement is also accompanied by a risein the potential for misuse. In the arena of deepfake generation this is a keysocietal issue. In particular, the ability to modify segments of videos usingsuch generative techniques creates a new paradigm of deepfakes which are mostlyreal videos altered slightly to distort the truth. Current deepfake detectionmethods in the academic literature are not evaluated on this paradigm. In thispaper, we present a deepfake detection method able to address this issue byperforming both frame and video level deepfake prediction. To facilitatetesting our method we create a new benchmark dataset where videos have bothreal and fake frame sequences. Our method utilizes the Vision Transformer,Scaling and Shifting pretraining and Timeseries Transformer to temporallysegment videos to help facilitate the interpretation of possible deepfakes.Extensive experiments on a variety of deepfake generation methods showexcellent results on temporal segmentation and classical video levelpredictions as well. In particular, the paradigm we introduce will form apowerful tool for the moderation of deepfakes, where human oversight can bebetter targeted to the parts of videos suspected of being deepfakes. Allexperiments can be reproduced at:https://github.com/sanjaysaha1311/temporal-deepfake-segmentation.</description><author>Sanjay Saha, Rashindrie Perera, Sachith Seneviratne, Tamasha Malepathirana, Sanka Rasnayaka, Deshani Geethika, Terence Sim, Saman Halgamuge</author><pubDate>Tue, 16 May 2023 16:16:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06564v2</guid></item><item><title>DLUE: Benchmarking Document Language Understanding</title><link>http://arxiv.org/abs/2305.09520v1</link><description>Understanding documents is central to many real-world tasks but remains achallenging topic. Unfortunately, there is no well-established consensus on howto comprehensively evaluate document understanding abilities, whichsignificantly hinders the fair comparison and measuring the progress of thefield. To benchmark document understanding researches, this paper summarizesfour representative abilities, i.e., document classification, documentstructural analysis, document information extraction, and documenttranscription. Under the new evaluation framework, we propose \textbf{DocumentLanguage Understanding Evaluation} -- \textbf{DLUE}, a new task suite whichcovers a wide-range of tasks in various forms, domains and document genres. Wealso systematically evaluate six well-established transformer models on DLUE,and find that due to the lengthy content, complicated underlying structure anddispersed knowledge, document understanding is still far from being solved, andcurrently there is no neural architecture that dominates all tasks, raisingrequirements for a universal document understanding architecture.</description><author>Ruoxi Xu, Hongyu Lin, Xinyan Guan, Xianpei Han, Yingfei Sun, Le Sun</author><pubDate>Tue, 16 May 2023 16:16:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09520v1</guid></item><item><title>Learning-enhanced Nonlinear Model Predictive Control using Knowledge-based Neural Ordinary Differential Equations and Deep Ensembles</title><link>http://arxiv.org/abs/2211.13829v2</link><description>Nonlinear model predictive control (MPC) is a flexible and increasinglypopular framework used to synthesize feedback control strategies that cansatisfy both state and control input constraints. In this framework, anoptimization problem, subjected to a set of dynamics constraints characterizedby a nonlinear dynamics model, is solved at each time step. Despite itsversatility, the performance of nonlinear MPC often depends on the accuracy ofthe dynamics model. In this work, we leverage deep learning tools, namelyknowledge-based neural ordinary differential equations (KNODE) and deepensembles, to improve the prediction accuracy of this model. In particular, welearn an ensemble of KNODE models, which we refer to as the KNODE ensemble, toobtain an accurate prediction of the true system dynamics. This learned modelis then integrated into a novel learning-enhanced nonlinear MPC framework. Weprovide sufficient conditions that guarantees asymptotic stability of theclosed-loop system and show that these conditions can be implemented inpractice. We show that the KNODE ensemble provides more accurate predictionsand illustrate the efficacy and closed-loop performance of the proposednonlinear MPC framework using two case studies.</description><author>Kong Yao Chee, M. Ani Hsieh, Nikolai Matni</author><pubDate>Tue, 16 May 2023 16:13:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13829v2</guid></item><item><title>Experiential Explanations for Reinforcement Learning</title><link>http://arxiv.org/abs/2210.04723v3</link><description>Reinforcement Learning (RL) systems can be complex and non-interpretable,making it challenging for non-AI experts to understand or intervene in theirdecisions. This is due, in part, to the sequential nature of RL in whichactions are chosen because of future rewards. However, RL agents discard thequalitative features of their training, making it hard to recoveruser-understandable information for "why" an action is chosen. Proposedsentence chunking: We propose a technique Experiential Explanations to generatecounterfactual explanations by training influence predictors alongside the RLpolicy. Influence predictors are models that learn how sources of reward affectthe agent in different states, thus restoring information about how the policyreflects the environment. A human evaluation study revealed that participantspresented with experiential explanations were better able to correctly guesswhat an agent would do than those presented with other standard types ofexplanations. Participants also found experiential explanations to be moreunderstandable, satisfying, complete, useful, and accurate. The qualitativeanalysis provides insights into the factors of experiential explanations thatfind most useful.</description><author>Amal Alabdulkarim, Gennie Mansi, Kaely Hall, Mark O. Riedl</author><pubDate>Tue, 16 May 2023 16:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04723v3</guid></item><item><title>AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation</title><link>http://arxiv.org/abs/2305.09515v1</link><description>Diffusion models have gained significant attention in the realm of imagegeneration due to their exceptional performance. Their success has beenrecently expanded to text generation via generating all tokens within asequence concurrently. However, natural language exhibits a far more pronouncedsequential dependency in comparison to images, and the majority of existinglanguage models are trained utilizing a left-to-right auto-regressive approach.To account for the inherent sequential characteristic of natural language, weintroduce Auto-Regressive Diffusion (AR-Diffusion). AR-Diffusion ensures thatthe generation of tokens on the right depends on the generated ones on theleft, a mechanism achieved through employing a dynamic number of denoisingsteps that vary based on token position. This results in tokens on the leftundergoing fewer denoising steps than those on the right, thereby enabling themto generate earlier and subsequently influence the generation of tokens on theright. In a series of experiments on various text generation tasks includingtext summarization, machine translation, and common sense generation,AR-Diffusion clearly demonstrated the superiority over existing diffusionlanguage models and that it can be $100\times\sim600\times$ faster whenachieving comparable results. Our code will be publicly released.</description><author>Tong Wu, Zhihao Fan, Xiao Liu, Yeyun Gong, Yelong Shen, Jian Jiao, Hai-Tao Zheng, Juntao Li, Zhongyu Wei, Jian Guo, Nan Duan, Weizhu Chen</author><pubDate>Tue, 16 May 2023 16:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09515v1</guid></item><item><title>Light-VQA: A Multi-Dimensional Quality Assessment Model for Low-Light Video Enhancement</title><link>http://arxiv.org/abs/2305.09512v1</link><description>Recently, Users Generated Content (UGC) videos becomes ubiquitous in ourdaily lives. However, due to the limitations of photographic equipments andtechniques, UGC videos often contain various degradations, in which one of themost visually unfavorable effects is the underexposure. Therefore,corresponding video enhancement algorithms such as Low-Light Video Enhancement(LLVE) have been proposed to deal with the specific degradation. However,different from video enhancement algorithms, almost all existing Video QualityAssessment (VQA) models are built generally rather than specifically, whichmeasure the quality of a video from a comprehensive perspective. To the best ofour knowledge, there is no VQA model specially designed for videos enhanced byLLVE algorithms. To this end, we first construct a Low-Light Video EnhancementQuality Assessment (LLVE-QA) dataset in which 254 original low-light videos arecollected and then enhanced by leveraging 8 LLVE algorithms to obtain 2,060videos in total. Moreover, we propose a quality assessment model specialized inLLVE, named Light-VQA. More concretely, since the brightness and noise have themost impact on low-light enhanced VQA, we handcraft corresponding features andintegrate them with deep-learning-based semantic features as the overallspatial information. As for temporal information, in addition todeep-learning-based motion features, we also investigate the handcraftedbrightness consistency among video frames, and the overall temporal informationis their concatenation. Subsequently, spatial and temporal information is fusedto obtain the quality-aware representation of a video. Extensive experimentalresults show that our Light-VQA achieves the best performance against thecurrent State-Of-The-Art (SOTA) on LLVE-QA and public dataset. Dataset andCodes can be found at https://github.com/wenzhouyidu/Light-VQA.</description><author>Yunlong Dong, Xiaohong Liu, Yixuan Gao, Xunchu Zhou, Tao Tan, Guangtao Zhai</author><pubDate>Tue, 16 May 2023 16:04:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09512v1</guid></item><item><title>Limit-behavior of a hybrid evolutionary algorithm for the Hasofer-Lind reliability index problem</title><link>http://arxiv.org/abs/2305.09511v1</link><description>In probabilistic structural mechanics, the Hasofer-Lind reliability indexproblem is a paradigmatic equality constrained problem of searching for theminimum distance from a point to a surface. In practical engineering problems,such surface is defined implicitly, requiring the solution of a boundary-valueproblem. Recently, it was proposed in the literature a hybrid micro-geneticalgorithm (HmGA), with mixed real-binary genotype and novel deterministicoperators for equality-constraint handling, namely the Genetic Repair andRegion Zooming mechanisms (G. das Neves Carneiro and C. Concei\c{c}\~aoAnt\'onio, "Global optimal reliability index of implicit composite laminatestructures by evolutionary algorithms", Struct Saf, vol. 79, pp. 54-65, 2019).We investigate the limit-behavior of the HmGA and present the convergencetheorems for the algorithm. It is proven that Genetic Repair is a conditionallystable mechanism, and its modes of convergence are discussed. Based on a Markovchain analysis, the conditions for the convergence with probability 1 of theHmGA are given and discussed.</description><author>Gonçalo das Neves Carneiro, Carlos Conceição António</author><pubDate>Tue, 16 May 2023 16:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09511v1</guid></item><item><title>Real-time Simultaneous Multi-Object 3D Shape Reconstruction, 6DoF Pose Estimation and Dense Grasp Prediction</title><link>http://arxiv.org/abs/2305.09510v1</link><description>Robotic manipulation systems operating in complex environments rely onperception systems that provide information about the geometry (pose and 3Dshape) of the objects in the scene along with other semantic information suchas object labels. This information is then used for choosing the feasiblegrasps on relevant objects. In this paper, we present a novel method to providethis geometric and semantic information of all objects in the scene as well asfeasible grasps on those objects simultaneously. The main advantage of ourmethod is its speed as it avoids sequential perception and grasp planningsteps. With detailed quantitative analysis, we show that our method deliverscompetitive performance compared to the state-of-the-art dedicated methods forobject shape, pose, and grasp predictions while providing fast inference at 30frames per second speed.</description><author>Shubham Agrawal, Nikhil Chavan-Dafle, Isaac Kasahara, Selim Engin, Jinwook Huh, Volkan Isler</author><pubDate>Tue, 16 May 2023 16:03:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09510v1</guid></item><item><title>Bidirectional Generative Framework for Cross-domain Aspect-based Sentiment Analysis</title><link>http://arxiv.org/abs/2305.09509v1</link><description>Cross-domain aspect-based sentiment analysis (ABSA) aims to perform variousfine-grained sentiment analysis tasks on a target domain by transferringknowledge from a source domain. Since labeled data only exists in the sourcedomain, a model is expected to bridge the domain gap for tackling cross-domainABSA. Though domain adaptation methods have proven to be effective, most ofthem are based on a discriminative model, which needs to be specificallydesigned for different ABSA tasks. To offer a more general solution, we proposea unified bidirectional generative framework to tackle various cross-domainABSA tasks. Specifically, our framework trains a generative model in bothtext-to-label and label-to-text directions. The former transforms each taskinto a unified format to learn domain-agnostic features, and the lattergenerates natural sentences from noisy labels for data augmentation, with whicha more accurate model can be trained. To investigate the effectiveness andgenerality of our framework, we conduct extensive experiments on fourcross-domain ABSA tasks and present new state-of-the-art results on all tasks.Our data and code are publicly available at\url{https://github.com/DAMO-NLP-SG/BGCA}.</description><author>Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, Lidong Bing</author><pubDate>Tue, 16 May 2023 16:02:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09509v1</guid></item><item><title>BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis</title><link>http://arxiv.org/abs/2302.14859v2</link><description>We present a method for reconstructing high-quality meshes of large unboundedreal-world scenes suitable for photorealistic novel view synthesis. We firstoptimize a hybrid neural volume-surface scene representation designed to havewell-behaved level sets that correspond to surfaces in the scene. We then bakethis representation into a high-quality triangle mesh, which we equip with asimple and fast view-dependent appearance model based on spherical Gaussians.Finally, we optimize this baked representation to best reproduce the capturedviewpoints, resulting in a model that can leverage accelerated polygonrasterization pipelines for real-time view synthesis on commodity hardware. Ourapproach outperforms previous scene representations for real-time rendering interms of accuracy, speed, and power consumption, and produces high qualitymeshes that enable applications such as appearance editing and physicalsimulation.</description><author>Lior Yariv, Peter Hedman, Christian Reiser, Dor Verbin, Pratul P. Srinivasan, Richard Szeliski, Jonathan T. Barron, Ben Mildenhall</author><pubDate>Tue, 16 May 2023 16:01:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14859v2</guid></item><item><title>The Hardness of Reasoning about Probabilities and Causality</title><link>http://arxiv.org/abs/2305.09508v1</link><description>We study formal languages which are capable of fully expressing quantitativeprobabilistic reasoning and do-calculus reasoning for causal effects, from acomputational complexity perspective. We focus on satisfiability problems whoseinstance formulas allow expressing many tasks in probabilistic and causalinference. The main contribution of this work is establishing the exactcomputational complexity of these satisfiability problems. We introduce a newnatural complexity class, named succ$\exists$R, which can be viewed as asuccinct variant of the well-studied class $\exists$R, and show that theproblems we consider are complete for succ$\exists$R. Our results imply evenstronger algorithmic limitations than were proven by Fagin, Halpern, andMegiddo (1990) and Moss\'{e}, Ibeling, and Icard (2022) for some variants ofthe standard languages used commonly in probabilistic and causal inference.</description><author>Benito van der Zander, Markus Bläser, Maciej Liśkiewicz</author><pubDate>Tue, 16 May 2023 16:01:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09508v1</guid></item><item><title>TAToo: Vision-based Joint Tracking of Anatomy and Tool for Skull-base Surgery</title><link>http://arxiv.org/abs/2212.14131v2</link><description>Purpose: Tracking the 3D motion of the surgical tool and the patient anatomyis a fundamental requirement for computer-assisted skull-base surgery. Theestimated motion can be used both for intra-operative guidance and fordownstream skill analysis. Recovering such motion solely from surgical videosis desirable, as it is compliant with current clinical workflows andinstrumentation. Methods: We present Tracker of Anatomy and Tool (TAToo). TAToo jointly tracksthe rigid 3D motion of patient skull and surgical drill from stereo microscopicvideos. TAToo estimates motion via an iterative optimization process in anend-to-end differentiable form. For robust tracking performance, TAToo adopts aprobabilistic formulation and enforces geometric constraints on the objectlevel. Results: We validate TAToo on both simulation data, where ground truth motionis available, as well as on anthropomorphic phantom data, where opticaltracking provides a strong baseline. We report sub-millimeter and millimeterinter-frame tracking accuracy for skull and drill, respectively, with rotationerrors below 1{\deg}. We further illustrate how TAToo may be used in a surgicalnavigation setting. Conclusion: We present TAToo, which simultaneously tracks the surgical tooland the patient anatomy in skull-base surgery. TAToo directly predicts themotion from surgical videos, without the need of any markers. Our results showthat the performance of TAToo compares favorably to competing approaches.Future work will include fine-tuning of our depth network to reach a 1 mmclinical accuracy goal desired for surgical applications in the skull base.</description><author>Zhaoshuo Li, Hongchao Shu, Ruixing Liang, Anna Goodridge, Manish Sahu, Francis X. Creighton, Russell H. Taylor, Mathias Unberath</author><pubDate>Tue, 16 May 2023 15:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.14131v2</guid></item><item><title>Fuzzy Temporal Protoforms for the Quantitative Description of Processes in Natural Language</title><link>http://arxiv.org/abs/2305.09506v1</link><description>In this paper, we propose a series of fuzzy temporal protoforms in theframework of the automatic generation of quantitative and qualitative naturallanguage descriptions of processes. The model includes temporal and causalinformation from processes and attributes, quantifies attributes in time duringthe process life-span and recalls causal relations and temporal distancesbetween events, among other features. Through integrating process miningtechniques and fuzzy sets within the usual Data-to-Text architecture, ourframework is able to extract relevant quantitative temporal as well asstructural information from a process and describe it in natural languageinvolving uncertain terms. A real use-case in the cardiology domain ispresented, showing the potential of our model for providing natural languageexplanations addressed to domain experts.</description><author>Yago Fontenla-Seco, Alberto Bugarín-Diz, Manuel Lama</author><pubDate>Tue, 16 May 2023 15:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09506v1</guid></item><item><title>Content-Adaptive Downsampling in Convolutional Neural Networks</title><link>http://arxiv.org/abs/2305.09504v1</link><description>Many convolutional neural networks (CNNs) rely on progressive downsampling oftheir feature maps to increase the network's receptive field and decreasecomputational cost. However, this comes at the price of losing granularity inthe feature maps, limiting the ability to correctly understand images orrecover fine detail in dense prediction tasks. To address this, common practiceis to replace the last few downsampling operations in a CNN with dilatedconvolutions, allowing to retain the feature map resolution without reducingthe receptive field, albeit increasing the computational cost. This allows totrade off predictive performance against cost, depending on the output featureresolution. By either regularly downsampling or not downsampling the entirefeature map, existing work implicitly treats all regions of the input image andsubsequent feature maps as equally important, which generally does not hold. Wepropose an adaptive downsampling scheme that generalizes the above idea byallowing to process informative regions at a higher resolution than lessinformative ones. In a variety of experiments, we demonstrate the versatilityof our adaptive downsampling strategy and empirically show that it improves thecost-accuracy trade-off of various established CNNs.</description><author>Robin Hesse, Simone Schaub-Meyer, Stefan Roth</author><pubDate>Tue, 16 May 2023 15:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09504v1</guid></item><item><title>Efficient Computation of General Modules for ALC Ontologies (Extended Version)</title><link>http://arxiv.org/abs/2305.09503v1</link><description>We present a method for extracting general modules for ontologies formulatedin the description logic ALC. A module for an ontology is an ideallysubstantially smaller ontology that preserves all entailments for auser-specified set of terms. As such, it has applications such as ontologyreuse and ontology analysis. Different from classical modules, general modulesmay use axioms not explicitly present in the input ontology, which allows foradditional conciseness. So far, general modules have only been investigated forlightweight description logics. We present the first work that considers themore expressive description logic ALC. In particular, our contribution is a newmethod based on uniform interpolation supported by some new theoreticalresults. Our evaluation indicates that our general modules are often smallerthan classical modules and uniform interpolants computed by thestate-of-the-art, and compared with uniform interpolants, can be computed in asignificantly shorter time. Moreover, our method can be used for, and in factimproves, the computation of uniform interpolants and classical modules.</description><author>Hui Yang, Patrick Koopmann, Yue Ma, Nicole Bidoit</author><pubDate>Tue, 16 May 2023 15:58:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09503v1</guid></item><item><title>Applications of Federated Learning in Manufacturing: Identifying the Challenges and Exploring the Future Directions with Industry 4.0 and 5.0 Visions</title><link>http://arxiv.org/abs/2302.13514v2</link><description>In manufacturing settings, data collection and analysis are often atime-consuming, challenging, and costly process. It also hinders the use ofadvanced machine learning and data-driven methods which require a substantialamount of offline training data to generate good results. It is particularlychallenging for small manufacturers who do not share the resources of a largeenterprise. Recently, with the introduction of the Internet of Things (IoT),data can be collected in an integrated manner across the factory in real-time,sent to the cloud for advanced analysis, and used to update the machinelearning model sequentially. Nevertheless, small manufacturers face twoobstacles in reaping the benefits of IoT: they may be unable to afford orgenerate enough data to operate a private cloud, and they may be hesitant toshare their raw data with a public cloud. Federated learning (FL) is anemerging concept of collaborative learning that can help small-scale industriesaddress these issues and learn from each other without sacrificing theirprivacy. It can bring together diverse and geographically dispersedmanufacturers under the same analytics umbrella to create a win-win situation.However, the widespread adoption of FL across multiple manufacturingorganizations remains a significant challenge. This study aims to review thechallenges and future directions of applying federated learning in themanufacturing industry, with a specific emphasis on the perspectives ofIndustry 4.0 and 5.0.</description><author>Farzana Islam, Ahmed Shoyeb Raihan, Imtiaz Ahmed</author><pubDate>Tue, 16 May 2023 15:56:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.13514v2</guid></item><item><title>Interpretable histopathology-based prediction of disease relevant features in Inflammatory Bowel Disease biopsies using weakly-supervised deep learning</title><link>http://arxiv.org/abs/2303.12095v2</link><description>Crohn's Disease (CD) and Ulcerative Colitis (UC) are the two mainInflammatory Bowel Disease (IBD) types. We developed deep learning models toidentify histological disease features for both CD and UC using only endoscopiclabels. We explored fine-tuning and end-to-end training of two state-of-the-artself-supervised models for predicting three different endoscopic categories (i)CD vs UC (AUC=0.87), (ii) normal vs lesional (AUC=0.81), (iii) low vs highdisease severity score (AUC=0.80). We produced visual attention maps tointerpret what the models learned and validated them with the support of apathologist, where we observed a strong association between the models'predictions and histopathological inflammatory features of the disease.Additionally, we identified several cases where the model incorrectly predictednormal samples as lesional but were correct on the microscopic level whenreviewed by the pathologist. This tendency of histological presentation to bemore severe than endoscopic presentation was previously published in theliterature. In parallel, we utilised a model trained on the Colon NucleiIdentification and Counting (CoNIC) dataset to predict and explore 6 cellpopulations. We observed correlation between areas enriched with the predictedimmune cells in biopsies and the pathologist's feedback on the attention maps.Finally, we identified several cell level features indicative of diseaseseverity in CD and UC. These models can enhance our understanding about thepathology behind IBD and can shape our strategies for patient stratification inclinical trials.</description><author>Ricardo Mokhtari, Azam Hamidinekoo, Daniel Sutton, Arthur Lewis, Bastian Angermann, Ulf Gehrmann, Pal Lundin, Hibret Adissu, Junmei Cairns, Jessica Neisen, Emon Khan, Daniel Marks, Nia Khachapuridze, Talha Qaiser, Nikolay Burlutskiy</author><pubDate>Tue, 16 May 2023 15:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12095v2</guid></item><item><title>Contrastive Label Enhancement</title><link>http://arxiv.org/abs/2305.09500v1</link><description>Label distribution learning (LDL) is a new machine learning paradigm forsolving label ambiguity. Since it is difficult to directly obtain labeldistributions, many studies are focusing on how to recover label distributionsfrom logical labels, dubbed label enhancement (LE). Existing LE methodsestimate label distributions by simply building a mapping relationship betweenfeatures and label distributions under the supervision of logical labels. Theytypically overlook the fact that both features and logical labels aredescriptions of the instance from different views. Therefore, we propose anovel method called Contrastive Label Enhancement (ConLE) which integratesfeatures and logical labels into the unified projection space to generatehigh-level features by contrastive learning strategy. In this approach,features and logical labels belonging to the same sample are pulled closer,while those of different samples are projected farther away from each other inthe projection space. Subsequently, we leverage the obtained high-levelfeatures to gain label distributions through a welldesigned training strategythat considers the consistency of label attributes. Extensive experiments onLDL benchmark datasets demonstrate the effectiveness and superiority of ourmethod.</description><author>Yifei Wang, Yiyang Zhou, Jihua Zhu, Xinyuan Liu, Wenbiao Yan, Zhiqiang Tian</author><pubDate>Tue, 16 May 2023 15:53:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09500v1</guid></item><item><title>Hardware Realization of Nonlinear Activation Functions for NN-based Optical Equalizers</title><link>http://arxiv.org/abs/2305.09495v1</link><description>To reduce the complexity of the hardware implementation of neuralnetwork-based optical channel equalizers, we demonstrate that the performanceof the biLSTM equalizer with approximated activation functions is close to thatof the original model.</description><author>Sasipim Srivallapanondh, Pedro J. Freire, Antonio Napoli, Sergei K. Turitsyn, Jaroslaw E. Prilepsky</author><pubDate>Tue, 16 May 2023 15:47:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09495v1</guid></item><item><title>PanFlowNet: A Flow-Based Deep Network for Pan-sharpening</title><link>http://arxiv.org/abs/2305.07774v2</link><description>Pan-sharpening aims to generate a high-resolution multispectral (HRMS) imageby integrating the spectral information of a low-resolution multispectral(LRMS) image with the texture details of a high-resolution panchromatic (PAN)image. It essentially inherits the ill-posed nature of the super-resolution(SR) task that diverse HRMS images can degrade into an LRMS image. However,existing deep learning-based methods recover only one HRMS image from the LRMSimage and PAN image using a deterministic mapping, thus ignoring the diversityof the HRMS image. In this paper, to alleviate this ill-posed issue, we proposea flow-based pan-sharpening network (PanFlowNet) to directly learn theconditional distribution of HRMS image given LRMS image and PAN image insteadof learning a deterministic mapping. Specifically, we first transform thisunknown conditional distribution into a given Gaussian distribution by aninvertible network, and the conditional distribution can thus be explicitlydefined. Then, we design an invertible Conditional Affine Coupling Block (CACB)and further build the architecture of PanFlowNet by stacking a series of CACBs.Finally, the PanFlowNet is trained by maximizing the log-likelihood of theconditional distribution given a training set and can then be used to predictdiverse HRMS images. The experimental results verify that the proposedPanFlowNet can generate various HRMS images given an LRMS image and a PANimage. Additionally, the experimental results on different kinds of satellitedatasets also demonstrate the superiority of our PanFlowNet compared with otherstate-of-the-art methods both visually and quantitatively.</description><author>Gang Yang, Xiangyong Cao, Wenzhe Xiao, Man Zhou, Aiping Liu, Xun chen, Deyu Meng</author><pubDate>Tue, 16 May 2023 15:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07774v2</guid></item><item><title>Solar Active Region Magnetogram Image Dataset for Studies of Space Weather</title><link>http://arxiv.org/abs/2305.09492v1</link><description>In this dataset we provide a comprehensive collection of magnetograms (imagesquantifying the strength of the magnetic field) from the National Aeronauticsand Space Administration's (NASA's) Solar Dynamics Observatory (SDO). Thedataset incorporates data from three sources and provides SDO Helioseismic andMagnetic Imager (HMI) magnetograms of solar active regions (regions of largemagnetic flux, generally the source of eruptive events) as well as labels ofcorresponding flaring activity. This dataset will be useful for image analysisor solar physics research related to magnetic structure, its evolution overtime, and its relation to solar flares. The dataset will be of interest tothose researchers investigating automated solar flare prediction methods,including supervised and unsupervised machine learning (classical and deep),binary and multi-class classification, and regression. This dataset is aminimally processed, user configurable dataset of consistently sized images ofsolar active regions that can serve as a benchmark dataset for solar flareprediction research.</description><author>Laura E. Boucheron, Ty Vincent, Jeremy A. Grajeda, Ellery Wuest</author><pubDate>Tue, 16 May 2023 15:44:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09492v1</guid></item><item><title>Discrete Diffusion Probabilistic Models for Symbolic Music Generation</title><link>http://arxiv.org/abs/2305.09489v1</link><description>Denoising Diffusion Probabilistic Models (DDPMs) have made great strides ingenerating high-quality samples in both discrete and continuous domains.However, Discrete DDPMs (D3PMs) have yet to be applied to the domain ofSymbolic Music. This work presents the direct generation of Polyphonic SymbolicMusic using D3PMs. Our model exhibits state-of-the-art sample quality,according to current quantitative evaluation metrics, and allows for flexibleinfilling at the note level. We further show, that our models are accessible topost-hoc classifier guidance, widening the scope of possible applications.However, we also cast a critical view on quantitative evaluation of musicsample quality via statistical metrics, and present a simple algorithm that canconfound our metrics with completely spurious, non-musical samples.</description><author>Matthias Plasser, Silvan Peter, Gerhard Widmer</author><pubDate>Tue, 16 May 2023 15:43:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09489v1</guid></item></channel></rss>