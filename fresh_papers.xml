<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 28 Jun 2023 06:00:22 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Symphonize 3D Semantic Scene Completion with Contextual Instance Queries</title><link>http://arxiv.org/abs/2306.15670v1</link><description>3D Semantic Scene Completion (SSC) has emerged as a nascent and pivotal taskfor autonomous driving, as it involves predicting per-voxel occupancy within a3D scene from partial LiDAR or image inputs. Existing methods primarily focuson the voxel-wise feature aggregation, while neglecting the instance-centricsemantics and broader context. In this paper, we present a novel paradigmtermed Symphonies (Scene-from-Insts) for SSC, which completes the scene volumefrom a sparse set of instance queries derived from the input with contextawareness. By incorporating the queries as the instance feature representationswithin the scene, Symphonies dynamically encodes the instance-centric semanticsto interact with the image and volume features while avoiding the densevoxel-wise modeling. Simultaneously, it orchestrates a more comprehensiveunderstanding of the scenario by capturing context throughout the entire scene,contributing to alleviating the geometric ambiguity derived from occlusion andperspective errors. Symphonies achieves a state-of-the-art result of 13.02 mIoUon the challenging SemanticKITTI dataset, outperforming existing methods andshowcasing the promising advancements of the paradigm. The code is available at\url{https://github.com/hustvl/Symphonies}.</description><author>Haoyi Jiang, Tianheng Cheng, Naiyu Gao, Haoyang Zhang, Wenyu Liu, Xinggang Wang</author><pubDate>Tue, 27 Jun 2023 18:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15670v1</guid></item><item><title>Detector-Free Structure from Motion</title><link>http://arxiv.org/abs/2306.15669v1</link><description>We propose a new structure-from-motion framework to recover accurate cameraposes and point clouds from unordered images. Traditional SfM systems typicallyrely on the successful detection of repeatable keypoints across multiple viewsas the first step, which is difficult for texture-poor scenes, and poorkeypoint detection may break down the whole SfM system. We propose a newdetector-free SfM framework to draw benefits from the recent success ofdetector-free matchers to avoid the early determination of keypoints, whilesolving the multi-view inconsistency issue of detector-free matchers.Specifically, our framework first reconstructs a coarse SfM model fromquantized detector-free matches. Then, it refines the model by a noveliterative refinement pipeline, which iterates between an attention-basedmulti-view matching module to refine feature tracks and a geometry refinementmodule to improve the reconstruction accuracy. Experiments demonstrate that theproposed framework outperforms existing detector-based SfM systems on commonbenchmark datasets. We also collect a texture-poor SfM dataset to demonstratethe capability of our framework to reconstruct texture-poor scenes. Based onthis framework, we take $\textit{first place}$ in Image Matching Challenge2023.</description><author>Xingyi He, Jiaming Sun, Yifan Wang, Sida Peng, Qixing Huang, Hujun Bao, Xiaowei Zhou</author><pubDate>Tue, 27 Jun 2023 18:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15669v1</guid></item><item><title>Physion++: Evaluating Physical Scene Understanding that Requires Online Inference of Different Physical Properties</title><link>http://arxiv.org/abs/2306.15668v1</link><description>General physical scene understanding requires more than simply localizing andrecognizing objects -- it requires knowledge that objects can have differentlatent properties (e.g., mass or elasticity), and that those properties affectthe outcome of physical events. While there has been great progress in physicaland video prediction models in recent years, benchmarks to test theirperformance typically do not require an understanding that objects haveindividual physical properties, or at best test only those properties that aredirectly observable (e.g., size or color). This work proposes a novel datasetand benchmark, termed Physion++, that rigorously evaluates visual physicalprediction in artificial systems under circumstances where those predictionsrely on accurate estimates of the latent physical properties of objects in thescene. Specifically, we test scenarios where accurate prediction relies onestimates of properties such as mass, friction, elasticity, and deformability,and where the values of those properties can only be inferred by observing howobjects move and interact with other objects or fluids. We evaluate theperformance of a number of state-of-the-art prediction models that span avariety of levels of learning vs. built-in knowledge, and compare thatperformance to a set of human predictions. We find that models that have beentrained using standard regimes and datasets do not spontaneously learn to makeinferences about latent properties, but also that models that encode objectnessand physical states tend to make better predictions. However, there is still ahuge gap between all models and human performance, and all models' predictionscorrelate poorly with those made by humans, suggesting that no state-of-the-artmodel is learning to make physical predictions in a human-like way. Projectpage: https://dingmyu.github.io/physion_v2/</description><author>Hsiao-Yu Tung, Mingyu Ding, Zhenfang Chen, Daniel Bear, Chuang Gan, Joshua B. Tenenbaum, Daniel LK Yamins, Judith E Fan, Kevin A. Smith</author><pubDate>Tue, 27 Jun 2023 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15668v1</guid></item><item><title>PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle Adjustment</title><link>http://arxiv.org/abs/2306.15667v1</link><description>Camera pose estimation is a long-standing computer vision problem that todate often relies on classical methods, such as handcrafted keypoint matching,RANSAC and bundle adjustment. In this paper, we propose to formulate theStructure from Motion (SfM) problem inside a probabilistic diffusion framework,modelling the conditional distribution of camera poses given input images. Thisnovel view of an old problem has several advantages. (i) The nature of thediffusion framework mirrors the iterative procedure of bundle adjustment. (ii)The formulation allows a seamless integration of geometric constraints fromepipolar geometry. (iii) It excels in typically difficult scenarios such assparse views with wide baselines. (iv) The method can predict intrinsics andextrinsics for an arbitrary amount of images. We demonstrate that our methodPoseDiffusion significantly improves over the classic SfM pipelines and thelearned approaches on two real-world datasets. Finally, it is observed that ourmethod can generalize across datasets without further training. Project page:https://posediffusion.github.io/</description><author>Jianyuan Wang, Christian Rupprecht, David Novotny</author><pubDate>Tue, 27 Jun 2023 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15667v1</guid></item><item><title>ShuttleSet22: Benchmarking Stroke Forecasting with Stroke-Level Badminton Dataset</title><link>http://arxiv.org/abs/2306.15664v1</link><description>In recent years, badminton analytics has drawn attention due to theadvancement of artificial intelligence and the efficiency of data collection.While there is a line of effective applications to improve and investigateplayer performance, there are only a few public badminton datasets that can beused for researchers outside the badminton domain. Existing badminton singlesdatasets focus on specific matchups; however, they cannot provide comprehensivestudies on different players and various matchups. In this paper, we provide abadminton singles dataset, ShuttleSet22, which is collected from high-rankingmatches in 2022. ShuttleSet22 consists of 30,172 strokes in 2,888 rallies inthe training set, 1,400 strokes in 450 rallies in the validation set, and 2,040strokes in 654 rallies in the testing set with detailed stroke-level metadatawithin a rally. To benchmark existing work with ShuttleSet22, we test thestate-of-the-art stroke forecasting approach, ShuttleNet, with thecorresponding stroke forecasting task, i.e., predict the future strokes basedon the given strokes of each rally. We also hold a challenge, Track 2:Forecasting Future Turn-Based Strokes in Badminton Rallies, at CoachAIBadminton Challenge 2023 to boost researchers to tackle this problem. Thebaseline codes and the dataset will be made available onhttps://github.com/wywyWang/CoachAI-Projects/tree/main/CoachAI-Challenge-IJCAI2023/Track\%202\%3A\%20Stroke\%20Forecasting.</description><author>Wei-Yao Wang, Wei-Wei Du, Wen-Chih Peng</author><pubDate>Tue, 27 Jun 2023 18:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15664v1</guid></item><item><title>Measured Albedo in the Wild: Filling the Gap in Intrinsics Evaluation</title><link>http://arxiv.org/abs/2306.15662v1</link><description>Intrinsic image decomposition and inverse rendering are long-standingproblems in computer vision. To evaluate albedo recovery, most algorithmsreport their quantitative performance with a mean Weighted Human DisagreementRate (WHDR) metric on the IIW dataset. However, WHDR focuses only on relativealbedo values and often fails to capture overall quality of the albedo. Inorder to comprehensively evaluate albedo, we collect a new dataset, MeasuredAlbedo in the Wild (MAW), and propose three new metrics that complement WHDR:intensity, chromaticity and texture metrics. We show that existing algorithmsoften improve WHDR metric but perform poorly on other metrics. We then finetunedifferent algorithms on our MAW dataset to significantly improve the quality ofthe reconstructed albedo both quantitatively and qualitatively. Since theproposed intensity, chromaticity, and texture metrics and the WHDR are allcomplementary we further introduce a relative performance measure that capturesaverage performance. By analysing existing algorithms we show that there issignificant room for improvement. Our dataset and evaluation metrics willenable researchers to develop algorithms that improve albedo reconstruction.Code and Data available at: https://measuredalbedo.github.io/</description><author>Jiaye Wu, Sanjoy Chowdhury, Hariharmano Shanmugaraja, David Jacobs, Soumyadip Sengupta</author><pubDate>Tue, 27 Jun 2023 18:55:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15662v1</guid></item><item><title>Enhancing Representation Learning on High-Dimensional, Small-Size Tabular Data: A Divide and Conquer Method with Ensembled VAEs</title><link>http://arxiv.org/abs/2306.15661v1</link><description>Variational Autoencoders and their many variants have displayed impressiveability to perform dimensionality reduction, often achieving state-of-the-artperformance. Many current methods however, struggle to learn goodrepresentations in High Dimensional, Low Sample Size (HDLSS) tasks, which is aninherently challenging setting. We address this challenge by using an ensembleof lightweight VAEs to learn posteriors over subsets of the feature-space,which get aggregated into a joint posterior in a novel divide-and-conquerapproach. Specifically, we present an alternative factorisation of the jointposterior that induces a form of implicit data augmentation that yields greatersample efficiency. Through a series of experiments on eight real-worlddatasets, we show that our method learns better latent representations in HDLSSsettings, which leads to higher accuracy in a downstream classification task.Furthermore, we verify that our approach has a positive effect ondisentanglement and achieves a lower estimated Total Correlation on learntrepresentations. Finally, we show that our approach is robust to partialfeatures at inference, exhibiting little performance degradation even with mostfeatures missing.</description><author>Navindu Leelarathna, Andrei Margeloiu, Mateja Jamnik, Nikola Simidjievski</author><pubDate>Tue, 27 Jun 2023 18:55:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15661v1</guid></item><item><title>CLIPA-v2: Scaling CLIP Training with 81.1% Zero-shot ImageNet Accuracy within a \$10,000 Budget; An Extra \$4,000 Unlocks 81.8% Accuracy</title><link>http://arxiv.org/abs/2306.15658v1</link><description>The recent work CLIPA presents an inverse scaling law for CLIP training --whereby the larger the image/text encoders used, the shorter the sequencelength of image/text tokens that can be applied in training. This findingenables us to train high-performance CLIP models with significantly reducedcomputations. Building upon this work, we hereby present CLIPA-v2 with two keycontributions. Technically, we find this inverse scaling law is also applicablein the finetuning stage, enabling further reduction in computational needs.Empirically, we explore CLIPA at scale, extending the experiments up to theH/14 model with ~13B image-text pairs seen during training. Our results are exciting -- by only allocating a budget of \$10,000, our CLIPmodel achieves an impressive zero-shot ImageNet accuracy of 81.1%, surpassingthe prior best CLIP model (from OpenCLIP, 80.1%) by 1.0% and meanwhile reducingthe computational cost by ~39X. Moreover, with an additional investment of$4,000, we can further elevate the zero-shot ImageNet accuracy to 81.8%. Ourcode and models are available at https://github.com/UCSC-VLAA/CLIPA.</description><author>Xianhang Li, Zeyu Wang, Cihang Xie</author><pubDate>Tue, 27 Jun 2023 18:51:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15658v1</guid></item><item><title>The Distortion of Binomial Voting Defies Expectation</title><link>http://arxiv.org/abs/2306.15657v1</link><description>In computational social choice, the distortion of a voting rule quantifiesthe degree to which the rule overcomes limited preference information to selecta socially desirable outcome. This concept has been investigated extensively,but only through a worst-case lens. Instead, we study the expected distortionof voting rules with respect to an underlying distribution over voterutilities. Our main contribution is the design and analysis of a novel andintuitive rule, binomial voting, which provides strong expected distortionguarantees for all distributions.</description><author>Yannai A. Gonczarowski, Gregory Kehne, Ariel D. Procaccia, Ben Schiffer, Shirley Zhang</author><pubDate>Tue, 27 Jun 2023 18:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15657v1</guid></item><item><title>SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design</title><link>http://arxiv.org/abs/2306.15656v1</link><description>This paper introduces SparseOptimizer, a novel deep learning optimizer thatexploits Moreau-Yosida regularization to naturally induce sparsity in largelanguage models such as BERT, ALBERT and GPT. Key to the design ofSparseOptimizer is an embedded shrinkage operator, which imparts sparsitydirectly within the optimization process. This operator, backed by a soundtheoretical framework, includes an analytical solution, thereby reinforcing theoptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-playfunctionality eradicates the need for code modifications, making it auniversally adaptable tool for a wide array of large language models. Empiricalevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2confirm that SparseBERT and SparseALBERT, when sparsified usingSparseOptimizer, achieve performance comparable to their dense counterparts,BERT and ALBERT, while significantly reducing their parameter count. Further,this work proposes an innovative optimizer-compiler co-design strategy,demonstrating the potential of inference acceleration (\textbf{3.37x},\textbf{6.30x}, and \textbf{7.15x} in comparison with Pytorch, TensorFlow, andLLVM generic compile, respectively) in SparseBERT when paired with anappropriately designed compiler. This study represents a significant stepforward in the evolution of efficient, scalable, and high-performing largelanguage models, setting a precedent for future exploration and optimization inthis domain. The SparseOptimizer code and SparseALBERT model will be madeavailable upon paper acceptance.</description><author>Fu-Ming Guo</author><pubDate>Tue, 27 Jun 2023 18:50:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15656v1</guid></item><item><title>Dental CLAIRES: Contrastive LAnguage Image REtrieval Search for Dental Research</title><link>http://arxiv.org/abs/2306.15651v1</link><description>Learning about diagnostic features and related clinical information fromdental radiographs is important for dental research. However, the lack ofexpert-annotated data and convenient search tools poses challenges. Our primaryobjective is to design a search tool that uses a user's query for oral-relatedresearch. The proposed framework, Contrastive LAnguage Image REtrieval Searchfor dental research, Dental CLAIRES, utilizes periapical radiographs andassociated clinical details such as periodontal diagnosis, demographicinformation to retrieve the best-matched images based on the text query. Weapplied a contrastive representation learning method to find images describedby the user's text by maximizing the similarity score of positive pairs (truepairs) and minimizing the score of negative pairs (random pairs). Our modelachieved a hit@3 ratio of 96% and a Mean Reciprocal Rank (MRR) of 0.82. We alsodesigned a graphical user interface that allows researchers to verify themodel's performance with interactions.</description><author>Tanjida Kabir, Luyao Chen, Muhammad F Walji, Luca Giancardo, Xiaoqian Jiang, Shayan Shams</author><pubDate>Tue, 27 Jun 2023 18:47:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15651v1</guid></item><item><title>Effective resistance in metric spaces</title><link>http://arxiv.org/abs/2306.15649v1</link><description>Effective resistance (ER) is an attractive way to interrogate the structureof graphs. It is an alternative to computing the eigenvectors of the graphLaplacian. One attractive application of ER is to point clouds, i.e. graphs whosevertices correspond to IID samples from a distribution over a metric space.Unfortunately, it was shown that the ER between any two points converges to atrivial quantity that holds no information about the graph's structure as thesize of the sample increases to infinity. In this study, we show that this trivial solution can be circumvented byconsidering a region-based ER between pairs of small regions rather than pairsof points and by scaling the edge weights appropriately with respect to theunderlying density in each region. By keeping the regions fixed, we showanalytically that the region-based ER converges to a non-trivial limit as thenumber of points increases to infinity. Namely the ER on a metric space. Wesupport our theoretical findings with numerical experiments.</description><author>Robi Bhattacharjee, Alexander Cloninger, Yoav Freund, Andreas Oslandsbotn</author><pubDate>Tue, 27 Jun 2023 18:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15649v1</guid></item><item><title>Style-transfer based Speech and Audio-visual Scene Understanding for Robot Action Sequence Acquisition from Videos</title><link>http://arxiv.org/abs/2306.15644v1</link><description>To realize human-robot collaboration, robots need to execute actions for newtasks according to human instructions given finite prior knowledge. Humanexperts can share their knowledge of how to perform a task with a robot throughmulti-modal instructions in their demonstrations, showing a sequence ofshort-horizon steps to achieve a long-horizon goal. This paper introduces amethod for robot action sequence generation from instruction videos using (1)an audio-visual Transformer that converts audio-visual features and instructionspeech to a sequence of robot actions called dynamic movement primitives (DMPs)and (2) style-transfer-based training that employs multi-task learning withvideo captioning and weakly-supervised learning with a semantic classifier toexploit unpaired video-action data. We built a system that accomplishes variouscooking actions, where an arm robot executes a DMP sequence acquired from acooking video using the audio-visual Transformer. Experiments withEpic-Kitchen-100, YouCookII, QuerYD, and in-house instruction video datasetsshow that the proposed method improves the quality of DMP sequences by 2.3times the METEOR score obtained with a baseline video-to-action Transformer.The model achieved 32% of the task success rate with the task knowledge of theobject.</description><author>Chiori Hori, Puyuan Peng, David Harwath, Xinyu Liu, Kei Ota, Siddarth Jain, Radu Corcodel, Devesh Jha, Diego Romeres, Jonathan Le Roux</author><pubDate>Tue, 27 Jun 2023 18:37:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15644v1</guid></item><item><title>Likelihood-free neural Bayes estimators for censored peaks-over-threshold models</title><link>http://arxiv.org/abs/2306.15642v1</link><description>Inference for spatial extremal dependence models can be computationallyburdensome in moderate-to-high dimensions due to their reliance on intractableand/or censored likelihoods. Exploiting recent advances in likelihood-freeinference with neural Bayes estimators (that is, neural estimators that targetBayes estimators), we develop a novel approach to construct highly efficientestimators for censored peaks-over-threshold models by encoding censoringinformation in the neural network architecture. Our new method provides aparadigm shift that challenges traditional censored likelihood-based inferencefor spatial extremes. Our simulation studies highlight significant gains inboth computational and statistical efficiency, relative to competinglikelihood-based approaches, when applying our novel estimators for inferenceof popular extremal dependence models, such as max-stable, $r$-Pareto, andrandom scale mixture processes. We also illustrate that it is possible to traina single estimator for a general censoring level, obviating the need to retrainwhen the censoring level is changed. We illustrate the efficacy of ourestimators by making fast inference on hundreds-of-thousands ofhigh-dimensional spatial extremal dependence models to assess particulatematter 2.5 microns or less in diameter (PM2.5) concentration over the whole ofSaudi Arabia.</description><author>Jordan Richards, Matthew Sainsbury-Dale, Andrew Zammit-Mangion, Raphaël Huser</author><pubDate>Tue, 27 Jun 2023 18:36:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15642v1</guid></item><item><title>On the Usefulness of Synthetic Tabular Data Generation</title><link>http://arxiv.org/abs/2306.15636v1</link><description>Despite recent advances in synthetic data generation, the scientificcommunity still lacks a unified consensus on its usefulness. It is commonlybelieved that synthetic data can be used for both data exchange and boostingmachine learning (ML) training. Privacy-preserving synthetic data generationcan accelerate data exchange for downstream tasks, but there is not enoughevidence to show how or why synthetic data can boost ML training. In thisstudy, we benchmarked ML performance using synthetic tabular data for four usecases: data sharing, data augmentation, class balancing, and datasummarization. We observed marginal improvements for the balancing use case onsome datasets. However, we conclude that there is not enough evidence to claimthat synthetic tabular data is useful for ML training.</description><author>Dionysis Manousakas, Sergül Aydöre</author><pubDate>Tue, 27 Jun 2023 18:26:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15636v1</guid></item><item><title>Automatic Annotation of Direct Speech in Written French Narratives</title><link>http://arxiv.org/abs/2306.15634v1</link><description>The automatic annotation of direct speech (AADS) in written text has beenoften used in computational narrative understanding. Methods based on eitherrules or deep neural networks have been explored, in particular for English orGerman languages. Yet, for French, our target language, not many works exist.Our goal is to create a unified framework to design and evaluate AADS models inFrench. For this, we consolidated the largest-to-date French narrative datasetannotated with DS per word; we adapted various baselines for sequence labellingor from AADS in other languages; and we designed and conducted an extensiveevaluation focused on generalisation. Results show that the task still requiressubstantial efforts and emphasise characteristics of each baseline. Althoughthis framework could be improved, it is a step further to encourage moreresearch on the topic.</description><author>Noé Durandard, Viet-Anh Tan, Gaspard Michel, Elena V. Epure</author><pubDate>Tue, 27 Jun 2023 18:21:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15634v1</guid></item><item><title>Latent Graph Inference using Product Manifolds</title><link>http://arxiv.org/abs/2211.16199v3</link><description>Graph Neural Networks usually rely on the assumption that the graph topologyis available to the network as well as optimal for the downstream task. Latentgraph inference allows models to dynamically learn the intrinsic graphstructure of problems where the connectivity patterns of data may not bedirectly accessible. In this work, we generalize the discrete DifferentiableGraph Module (dDGM) for latent graph learning. The original dDGM architectureused the Euclidean plane to encode latent features based on which the latentgraphs were generated. By incorporating Riemannian geometry into the model andgenerating more complex embedding spaces, we can improve the performance of thelatent graph inference system. In particular, we propose a computationallytractable approach to produce product manifolds of constant curvature modelspaces that can encode latent features of varying structure. The latentrepresentations mapped onto the inferred product manifold are used to computericher similarity measures that are leveraged by the latent graph learningmodel to obtain optimized latent graphs. Moreover, the curvature of the productmanifold is learned during training alongside the rest of the networkparameters and based on the downstream task, rather than it being a staticembedding space. Our novel approach is tested on a wide range of datasets, andoutperforms the original dDGM model.</description><author>Haitz Sáez de Ocáriz Borde, Anees Kazi, Federico Barbero, Pietro Liò</author><pubDate>Tue, 27 Jun 2023 18:17:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.16199v3</guid></item><item><title>Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network</title><link>http://arxiv.org/abs/2306.10946v2</link><description>The recommendation algorithm based on knowledge graphs is at a relativelymature stage. However, there are still some problems in the recommendation ofspecific areas. For example, in the tourism field, selecting suitable touristattraction attributes process is complicated as the recommendation basis fortourist attractions. In this paper, we propose the improved Attention KnowledgeGraph Convolution Network model, named (Att-KGCN), which automaticallydiscovers the neighboring entities of the target scenic spot semantically. Theattention layer aggregates relatively similar locations and represents themwith an adjacent vector. Then, according to the tourist's preferred choices,the model predicts the probability of similar spots as a recommendation system.A knowledge graph dataset of tourist attractions used based on tourism data onSocotra Island-Yemen. Through experiments, it is verified that the AttentionKnowledge Graph Convolution Network has a good effect on the recommendation oftourist attractions and can make more recommendations for tourists' choices.</description><author>Ahmad A. Mubarak, Afifa Kahled</author><pubDate>Tue, 27 Jun 2023 18:14:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10946v2</guid></item><item><title>Asynchronous Algorithmic Alignment with Cocycles</title><link>http://arxiv.org/abs/2306.15632v1</link><description>State-of-the-art neural algorithmic reasoners make use of message passing ingraph neural networks (GNNs). But typical GNNs blur the distinction between thedefinition and invocation of the message function, forcing a node to sendmessages to its neighbours at every layer, synchronously. When applying GNNs tolearn to execute dynamic programming algorithms, however, on most steps only ahandful of the nodes would have meaningful updates to send. One, hence, runsthe risk of inefficiencies by sending too much irrelevant data across the graph-- with many intermediate GNN steps having to learn identity functions. In thiswork, we explicitly separate the concepts of node state update and messagefunction invocation. With this separation, we obtain a mathematical formulationthat allows us to reason about asynchronous computation in both algorithms andneural networks.</description><author>Andrew Dudzik, Tamara von Glehn, Razvan Pascanu, Petar Veličković</author><pubDate>Tue, 27 Jun 2023 18:13:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15632v1</guid></item><item><title>Coupling parameter and particle dynamics for adaptive sampling in Neural Galerkin schemes</title><link>http://arxiv.org/abs/2306.15630v1</link><description>Training nonlinear parametrizations such as deep neural networks tonumerically approximate solutions of partial differential equations is oftenbased on minimizing a loss that includes the residual, which is analyticallyavailable in limited settings only. At the same time, empirically estimatingthe training loss is challenging because residuals and related quantities canhave high variance, especially for transport-dominated and high-dimensionalproblems that exhibit local features such as waves and coherent structures.Thus, estimators based on data samples from un-informed, uniform distributionsare inefficient. This work introduces Neural Galerkin schemes that estimate thetraining loss with data from adaptive distributions, which are empiricallyrepresented via ensembles of particles. The ensembles are actively adapted byevolving the particles with dynamics coupled to the nonlinear parametrizationsof the solution fields so that the ensembles remain informative for estimatingthe training loss. Numerical experiments indicate that few dynamic particlesare sufficient for obtaining accurate empirical estimates of the training loss,even for problems with local features and with high-dimensional spatialdomains.</description><author>Yuxiao Wen, Eric Vanden-Eijnden, Benjamin Peherstorfer</author><pubDate>Tue, 27 Jun 2023 18:12:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15630v1</guid></item><item><title>When Does Translation Require Context? A Data-driven, Multilingual Exploration</title><link>http://arxiv.org/abs/2109.07446v2</link><description>Although proper handling of discourse significantly contributes to thequality of machine translation (MT), these improvements are not adequatelymeasured in common translation quality metrics. Recent works in context-awareMT attempt to target a small set of discourse phenomena during evaluation,however not in a fully systematic way. In this paper, we develop theMultilingual Discourse-Aware (MuDA) benchmark, a series of taggers thatidentify and evaluate model performance on discourse phenomena in any givendataset. The choice of phenomena is inspired by a novel methodology tosystematically identify translations requiring context. We confirm thedifficulty of previously studied phenomena while uncovering others that werepreviously unaddressed. We find that common context-aware MT models make onlymarginal improvements over context-agnostic models, which suggests these modelsdo not handle these ambiguities effectively. We release code and data for 14language pairs to encourage the MT community to focus on accurately capturingdiscourse phenomena.</description><author>Patrick Fernandes, Kayo Yin, Emmy Liu, André F. T. Martins, Graham Neubig</author><pubDate>Tue, 27 Jun 2023 18:10:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.07446v2</guid></item><item><title>Machine-learning based noise characterization and correction on neutral atoms NISQ devices</title><link>http://arxiv.org/abs/2306.15628v1</link><description>Neutral atoms devices represent a promising technology that uses opticaltweezers to geometrically arrange atoms and modulated laser pulses to controlthe quantum states. A neutral atoms Noisy Intermediate Scale Quantum (NISQ)device is developed by Pasqal with rubidium atoms that will allow to work withup to 100 qubits. All NISQ devices are affected by noise that have an impact onthe computations results. Therefore it is important to better understand andcharacterize the noise sources and possibly to correct them. Here, twoapproaches are proposed to characterize and correct noise parameters on neutralatoms NISQ devices. In particular the focus is on Pasqal devices and MachineLearning (ML) techniques are adopted to pursue those objectives. Tocharacterize the noise parameters, several ML models are trained, using asinput only the measurements of the final quantum state of the atoms, to predictlaser intensity fluctuation and waist, temperature and false positive andnegative measurement rate. Moreover, an analysis is provided with the scalingon the number of atoms in the system and on the number of measurements used asinput. Also, we compare on real data the values predicted with ML with the apriori estimated parameters. Finally, a Reinforcement Learning (RL) frameworkis employed to design a pulse in order to correct the effect of the noise inthe measurements. It is expected that the analysis performed in this work willbe useful for a better understanding of the quantum dynamic in neutral atomsdevices and for the widespread adoption of this class of NISQ devices.</description><author>Ettore Canonici, Stefano Martina, Riccardo Mengoni, Daniele Ottaviani, Filippo Caruso</author><pubDate>Tue, 27 Jun 2023 18:08:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15628v1</guid></item><item><title>LeanDojo: Theorem Proving with Retrieval-Augmented Language Models</title><link>http://arxiv.org/abs/2306.15626v1</link><description>Large language models (LLMs) have shown promise in proving formal theoremsusing proof assistants such as Lean. However, existing methods are difficult toreproduce or build on, due to private code, data, and large computerequirements. This has created substantial barriers to research on machinelearning methods for theorem proving. This paper removes these barriers byintroducing LeanDojo: an open-source Lean playground consisting of toolkits,data, models, and benchmarks. LeanDojo extracts data from Lean and enablesinteraction with the proof environment programmatically. It containsfine-grained annotations of premises in proofs, providing valuable data forpremise selection: a key bottleneck in theorem proving. Using this data, wedevelop ReProver (Retrieval-Augmented Prover): the first LLM-based prover thatis augmented with retrieval for selecting premises from a vast math library. Itis inexpensive and needs only one GPU week of training. Our retriever leveragesLeanDojo's program analysis capability to identify accessible premises and hardnegative examples, which makes retrieval much more effective. Furthermore, weconstruct a new benchmark consisting of 96,962 theorems and proofs extractedfrom Lean's math library. It features challenging data split requiring theprover to generalize to theorems relying on novel premises that are never usedin training. We use this benchmark for training and evaluation, andexperimental results demonstrate the effectiveness of ReProver overnon-retrieval baselines and GPT-4. We thus provide the first set of open-sourceLLM-based theorem provers without any proprietary datasets and release it undera permissive MIT license to facilitate further research.</description><author>Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, Anima Anandkumar</author><pubDate>Tue, 27 Jun 2023 18:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15626v1</guid></item><item><title>Value-aware Importance Weighting for Off-policy Reinforcement Learning</title><link>http://arxiv.org/abs/2306.15625v1</link><description>Importance sampling is a central idea underlying off-policy prediction inreinforcement learning. It provides a strategy for re-weighting samples from adistribution to obtain unbiased estimates under another distribution. However,importance sampling weights tend to exhibit extreme variance, often leading tostability issues in practice. In this work, we consider a broader class ofimportance weights to correct samples in off-policy learning. We propose theuse of $\textit{value-aware importance weights}$ which take into account thesample space to provide lower variance, but still unbiased, estimates under atarget distribution. We derive how such weights can be computed, and detail keyproperties of the resulting importance weights. We then extend severalreinforcement learning prediction algorithms to the off-policy setting withthese weights, and evaluate them empirically.</description><author>Kristopher De Asis, Eric Graves, Richard S. Sutton</author><pubDate>Tue, 27 Jun 2023 18:05:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15625v1</guid></item><item><title>Tube-Link: A Flexible Cross Tube Baseline for Universal Video Segmentation</title><link>http://arxiv.org/abs/2303.12782v2</link><description>The goal of video segmentation is to accurately segment and track every pixelin diverse scenarios. In this paper, we present Tube-Link, a versatileframework that addresses multiple core tasks of video segmentation with aunified architecture. Our framework is a near-online approach that takes ashort subclip as input and outputs the corresponding spatial-temporal tubemasks. To enhance the modeling of cross-tube relationships, we propose aneffective way to perform tube-level linking via attention along the queries. Inaddition, we introduce temporal contrastive learning to instance-wisediscriminative features for tube-level association. Our approach offersflexibility and efficiency for both short and long video inputs, as the lengthof each subclip can be varied according to the needs of datasets or scenarios.Tube-Link outperforms existing specialized architectures by a significantmargin on five video segmentation datasets. Specifically, it achieves almost13% relative improvements on VIPSeg and 4% improvements on KITTI-STEP over thestrong baseline Video K-Net. When using a ResNet50 backbone on Youtube-VIS-2019and 2021, Tube-Link boosts IDOL by 3% and 4%, respectively. Code will beavailable.</description><author>Xiangtai Li, Haobo Yuan, Wenwei Zhang, Guangliang Cheng, Jiangmiao Pang, Chen Change Loy</author><pubDate>Tue, 27 Jun 2023 18:02:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12782v2</guid></item><item><title>SCENEREPLICA: Benchmarking Real-World Robot Manipulation by Creating Reproducible Scenes</title><link>http://arxiv.org/abs/2306.15620v1</link><description>We present a new reproducible benchmark for evaluating robot manipulation inthe real world, specifically focusing on pick-and-place. Our benchmark uses theYCB objects, a commonly used dataset in the robotics community, to ensure thatour results are comparable to other studies. Additionally, the benchmark isdesigned to be easily reproducible in the real world, making it accessible toresearchers and practitioners. We also provide our experimental results andanalyzes for model-based and model-free 6D robotic grasping on the benchmark,where representative algorithms are evaluated for object perception, graspingplanning, and motion planning. We believe that our benchmark will be a valuabletool for advancing the field of robot manipulation. By providing a standardizedevaluation framework, researchers can more easily compare different techniquesand algorithms, leading to faster progress in developing robot manipulationmethods.</description><author>Ninad Khargonkar, Sai Haneesh Allu, Yangxiao Lu, Jishnu Jaykumar P, Balakrishnan Prabhakaran, Yu Xiang</author><pubDate>Tue, 27 Jun 2023 17:59:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15620v1</guid></item><item><title>DCID: Deep Canonical Information Decomposition</title><link>http://arxiv.org/abs/2306.15619v1</link><description>We consider the problem of identifying the signal shared between twoone-dimensional target variables, in the presence of additional multivariateobservations. Canonical Correlation Analysis (CCA)-based methods havetraditionally been used to identify shared variables, however, they weredesigned for multivariate targets and only offer trivial solutions forunivariate cases. In the context of Multi-Task Learning (MTL), various modelswere postulated to learn features that are sparse and shared across multipletasks. However, these methods were typically evaluated by their predictiveperformance. To the best of our knowledge, no prior studies systematicallyevaluated models in terms of correctly recovering the shared signal. Here, weformalize the setting of univariate shared information retrieval, and proposeICM, an evaluation metric which can be used in the presence of ground-truthlabels, quantifying 3 aspects of the learned shared features. We furtherpropose Deep Canonical Information Decomposition (DCID) - a simple, yeteffective approach for learning the shared variables. We benchmark the modelson a range of scenarios on synthetic data with known ground-truths and observeDCID outperforming the baselines in a wide range of settings. Finally, wedemonstrate a real-life application of DCID on brain Magnetic Resonance Imaging(MRI) data, where we are able to extract more accurate predictors of changes inbrain regions and obesity. The code for our experiments as well as thesupplementary materials are available at https://github.com/alexrakowski/dcid</description><author>Alexander Rakowski, Christoph Lippert</author><pubDate>Tue, 27 Jun 2023 17:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15619v1</guid></item><item><title>Learning Nonautonomous Systems via Dynamic Mode Decomposition</title><link>http://arxiv.org/abs/2306.15618v1</link><description>We present a data-driven learning approach for unknown nonautonomousdynamical systems with time-dependent inputs based on dynamic modedecomposition (DMD). To circumvent the difficulty of approximating thetime-dependent Koopman operators for nonautonomous systems, a modified systemderived from local parameterization of the external time-dependent inputs isemployed as an approximation to the original nonautonomous system. The modifiedsystem comprises a sequence of local parametric systems, which can be wellapproximated by a parametric surrogate model using our previously proposedframework for dimension reduction and interpolation in parameter space (DRIPS).The offline step of DRIPS relies on DMD to build a linear surrogate model,endowed with reduced-order bases (ROBs), for the observables mapped fromtraining data. Then the offline step constructs a sequence of iterativeparametric surrogate models from interpolations on suitable manifolds, wherethe target/test parameter points are specified by the local parameterization ofthe test external time-dependent inputs. We present a number of numericalexamples to demonstrate the robustness of our method and compare itsperformance with deep neural networks in the same settings.</description><author>Hannah Lu, Daniel M. Tartakovsky</author><pubDate>Tue, 27 Jun 2023 17:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15618v1</guid></item><item><title>Rethinking Cross-Entropy Loss for Stereo Matching Networks</title><link>http://arxiv.org/abs/2306.15612v1</link><description>Despite the great success of deep learning in stereo matching, recoveringaccurate and clearly-contoured disparity map is still challenging. Currently,L1 loss and cross-entropy loss are the two most widely used loss functions fortraining the stereo matching networks. Comparing with the former, the lattercan usually achieve better results thanks to its direct constraint to the thecost volume. However, how to generate reasonable ground-truth distribution forthis loss function remains largely under exploited. Existing works assumeuni-modal distributions around the ground-truth for all of the pixels, whichignores the fact that the edge pixels may have multi-modal distributions. Inthis paper, we first experimentally exhibit the importance of correct edgesupervision to the overall disparity accuracy. Then a novel adaptivemulti-modal cross-entropy loss which encourages the network to generatedifferent distribution patterns for edge and non-edge pixels is proposed. Wefurther optimize the disparity estimator in the inference stage to alleviatethe bleeding and misalignment artifacts at the edge. Our method is generic andcan help classic stereo matching models regain competitive performance. GANettrained by our loss ranks 1st on the KITTI 2015 and 2012 benchmarks andoutperforms state-of-the-art methods by a large margin. Meanwhile, our methodalso exhibits superior cross-domain generalization ability and outperformsexisting generalization-specialized methods on four popular real-worlddatasets.</description><author>Peng Xu, Zhiyu Xiang, Chenyu Qiao, Jingyun Fu, Xijun Zhao</author><pubDate>Tue, 27 Jun 2023 17:53:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15612v1</guid></item><item><title>Constructing Multilingual Code Search Dataset Using Neural Machine Translation</title><link>http://arxiv.org/abs/2306.15604v1</link><description>Code search is a task to find programming codes that semantically match thegiven natural language queries. Even though some of the existing datasets forthis task are multilingual on the programming language side, their query dataare only in English. In this research, we create a multilingual code searchdataset in four natural and four programming languages using a neural machinetranslation model. Using our dataset, we pre-train and fine-tune theTransformer-based models and then evaluate them on multiple code search testsets. Our results show that the model pre-trained with all natural andprogramming language data has performed best in most cases. By applyingback-translation data filtering to our dataset, we demonstrate that thetranslation quality affects the model's performance to a certain extent, butthe data size matters more.</description><author>Ryo Sekizawa, Nan Duan, Shuai Lu, Hitomi Yanaka</author><pubDate>Tue, 27 Jun 2023 17:42:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15604v1</guid></item><item><title>Replicable Reinforcement Learning</title><link>http://arxiv.org/abs/2305.15284v3</link><description>The replicability crisis in the social, behavioral, and data sciences has ledto the formulation of algorithm frameworks for replicability -- i.e., arequirement that an algorithm produce identical outputs (with high probability)when run on two different samples from the same underlying distribution. Whilestill in its infancy, provably replicable algorithms have been developed formany fundamental tasks in machine learning and statistics, includingstatistical query learning, the heavy hitters problem, and distributiontesting. In this work we initiate the study of replicable reinforcementlearning, providing a provably replicable algorithm for parallel valueiteration, and a provably replicable version of R-max in the episodic setting.These are the first formal replicability results for control problems, whichpresent different challenges for replication than batch learning settings.</description><author>Eric Eaton, Marcel Hussing, Michael Kearns, Jessica Sorrell</author><pubDate>Tue, 27 Jun 2023 17:41:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15284v3</guid></item><item><title>Recurrent Neural Network-coupled SPAD TCSPC System for Real-time Fluorescence Lifetime Imaging</title><link>http://arxiv.org/abs/2306.15599v1</link><description>Fluorescence lifetime imaging (FLI) has been receiving increased attention inrecent years as a powerful imaging technique in biological and medicalresearch. However, existing FLI systems often suffer from a tradeoff betweenprocessing speed, accuracy, and robustness. In this paper, we propose a SPADTCSPC system coupled to a recurrent neural network (RNN) for FLI thataccurately estimates on the fly fluorescence lifetime directly from rawtimestamps instead of histograms, which drastically reduces the data transferrate and hardware resource utilization. We train two variants of the RNN on asynthetic dataset and compare the results to those obtained using thecenter-of-mass method (CMM) and least squares fitting (LS fitting) methods. Theresults demonstrate that two RNN variants, gated recurrent unit (GRU) and longshort-term memory (LSTM), are comparable to CMM and LS fitting in terms ofaccuracy and outperform CMM and LS fitting by a large margin in the presence ofbackground noise. We also look at the Cramer-Rao lower bound and detailedanalysis showed that the RNN models are close to the theoretical optima. Theanalysis of experimental data shows that our model, which is purely trained onsynthetic datasets, works well on real-world data. We build a FLI microscopesetup for evaluation based on Piccolo, a 32$\times$32 SPAD sensor developed inour lab. Four quantized GRU cores, capable of processing up to 4 millionphotons per second, are deployed on a Xilinx Kintex-7 FPGA. Powered by the GRU,the FLI setup can retrieve real-time fluorescence lifetime images at up to 10frames per second. The proposed FLI system is promising for many importantbiomedical applications, ranging from biological imaging of fast-moving cellsto fluorescence-assisted diagnosis and surgery.</description><author>Yang Lin, Paul Mos, Andrei Ardelean, Claudio Bruschini, Edoardo Charbon</author><pubDate>Tue, 27 Jun 2023 17:37:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15599v1</guid></item><item><title>Extending Context Window of Large Language Models via Positional Interpolation</title><link>http://arxiv.org/abs/2306.15595v1</link><description>We present Position Interpolation (PI) that extends the context window sizesof RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimalfine-tuning (within 1000 steps), while demonstrating strong empirical resultson various tasks that require long context, including passkey retrieval,language modeling, and long document summarization from LLaMA 7B to 65B.Meanwhile, the extended model by Position Interpolation preserve qualityrelatively well on tasks within its original context window. To achieve thisgoal, Position Interpolation linearly down-scales the input position indices tomatch the original context window size, rather than extrapolating beyond thetrained context length which may lead to catastrophically high attention scoresthat completely ruin the self-attention mechanism. Our theoretical study showsthat the upper bound of interpolation is at least $\sim 600 \times$ smallerthan that of extrapolation, further demonstrating its stability. Modelsextended via Position Interpolation retain its original architecture and canreuse most pre-existing optimization and infrastructure.</description><author>Shouyuan Chen, Sherman Wong, Liangjian Chen, Yuandong Tian</author><pubDate>Tue, 27 Jun 2023 17:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15595v1</guid></item><item><title>Low Latency Edge Classification GNN for Particle Trajectory Tracking on FPGAs</title><link>http://arxiv.org/abs/2306.11330v2</link><description>In-time particle trajectory reconstruction in the Large Hadron Collider ischallenging due to the high collision rate and numerous particle hits. UsingGNN (Graph Neural Network) on FPGA has enabled superior accuracy with flexibletrajectory classification. However, existing GNN architectures have inefficientresource usage and insufficient parallelism for edge classification. This paperintroduces a resource-efficient GNN architecture on FPGAs for low latencyparticle tracking. The modular architecture facilitates design scalability tosupport large graphs. Leveraging the geometric properties of hit detectorsfurther reduces graph complexity and resource usage. Our results on XilinxUltraScale+ VU9P demonstrate 1625x and 1574x performance improvement over CPUand GPU respectively.</description><author>Shi-Yu Huang, Yun-Chen Yang, Yu-Ru Su, Bo-Cheng Lai, Javier Duarte, Scott Hauck, Shih-Chieh Hsu, Jin-Xuan Hu, Mark S. Neubauer</author><pubDate>Tue, 27 Jun 2023 17:21:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11330v2</guid></item><item><title>Cardiac CT perfusion imaging of pericoronary adipose tissue (PCAT) highlights potential confounds in coronary CTA</title><link>http://arxiv.org/abs/2306.15593v1</link><description>Features of pericoronary adipose tissue (PCAT) assessed from coronarycomputed tomography angiography (CCTA) are associated with inflammation andcardiovascular risk. As PCAT is vascularly connected with coronary vasculature,the presence of iodine is a potential confounding factor on PCAT HU andtextures that has not been adequately investigated. Use dynamic cardiac CTperfusion (CCTP) to inform contrast determinants of PCAT assessment. From CCTP,we analyzed HU dynamics of territory-specific PCAT, myocardium, and otheradipose depots in patients with coronary artery disease. HU, blood flow, andradiomics were assessed over time. Changes from peak aorta time, Pa, chosen tomodel the time of CCTA, were obtained. HU in PCAT increased more than in otheradipose depots. The estimated blood flow in PCAT was ~23% of that in thecontiguous myocardium. Comparing PCAT distal and proximal to a significantstenosis, we found less enhancement and longer time-to-peak distally.Two-second offsets [before, after] Pa resulted in [ 4-HU, 3-HU] differences inPCAT. Due to changes in HU, the apparent PCAT volume reduced ~15% from thefirst scan (P1) to Pa using a conventional fat window. Comparing radiomicfeatures over time, 78% of features changed &gt;10% relative to P1. CCTPelucidates blood flow in PCAT and enables analysis of PCAT features over time.PCAT assessments (HU, apparent volume, and radiomics) are sensitive toacquisition timing and the presence of obstructive stenosis, which may confoundthe interpretation of PCAT in CCTA images. Data normalization may be in order.</description><author>Hao Wu, Yingnan Song, Ammar Hoori, Ananya Subramaniam, Juhwan Lee, Justin Kim, Tao Hu, Sadeer Al-Kindi, Wei-Ming Huang, Chun-Ho Yun, Chung-Lieh Hung, Sanjay Rajagopalan, David L. Wilson</author><pubDate>Tue, 27 Jun 2023 17:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15593v1</guid></item><item><title>Benchmarking Reinforcement Learning Techniques for Autonomous Navigation</title><link>http://arxiv.org/abs/2210.04839v2</link><description>Deep reinforcement learning (RL) has brought many successes for autonomousrobot navigation. However, there still exists important limitations thatprevent real-world use of RL-based navigation systems. For example, mostlearning approaches lack safety guarantees; and learned navigation systems maynot generalize well to unseen environments. Despite a variety of recentlearning techniques to tackle these challenges in general, a lack of anopen-source benchmark and reproducible learning methods specifically forautonomous navigation makes it difficult for roboticists to choose whatlearning methods to use for their mobile robots and for learning researchers toidentify current shortcomings of general learning methods for autonomousnavigation. In this paper, we identify four major desiderata of applying deepRL approaches for autonomous navigation: (D1) reasoning under uncertainty, (D2)safety, (D3) learning from limited trial-and-error data, and (D4)generalization to diverse and novel environments. Then, we explore four majorclasses of learning techniques with the purpose of achieving one or more of thefour desiderata: memory-based neural network architectures (D1), safe RL (D2),model-based RL (D2, D3), and domain randomization (D4). By deploying theselearning techniques in a new open-source large-scale navigation benchmark andreal-world environments, we perform a comprehensive study aimed at establishingto what extent can these techniques achieve these desiderata for RL-basednavigation systems.</description><author>Zifan Xu, Bo Liu, Xuesu Xiao, Anirudh Nair, Peter Stone</author><pubDate>Tue, 27 Jun 2023 17:17:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04839v2</guid></item><item><title>Learning to Sail Dynamic Networks: The MARLIN Reinforcement Learning Framework for Congestion Control in Tactical Environments</title><link>http://arxiv.org/abs/2306.15591v1</link><description>Conventional Congestion Control (CC) algorithms,such as TCP Cubic, strugglein tactical environments as they misinterpret packet loss and fluctuatingnetwork performance as congestion symptoms. Recent efforts, including our ownMARLIN, have explored the use of Reinforcement Learning (RL) for CC, but theyoften fall short of generalization, particularly in competitive, unstable, andunforeseen scenarios. To address these challenges, this paper proposes an RLframework that leverages an accurate and parallelizable emulation environmentto reenact the conditions of a tactical network. We also introduce refined RLformulation and performance evaluation methods tailored for agents operating insuch intricate scenarios. We evaluate our RL learning framework by training aMARLIN agent in conditions replicating a bottleneck link transition between aSatellite Communication (SATCOM) and an UHF Wide Band (UHF) radio link.Finally, we compared its performance in file transfer tasks againstTransmission Control Protocol (TCP) Cubic and the default strategy implementedin the Mockets tactical communication middleware. The results demonstrate thatthe MARLIN RL agent outperforms both TCP and Mockets under differentperspectives and highlight the effectiveness of specialized RL solutions inoptimizing CC for tactical network environments.</description><author>Raffaele Galliera, Mattia Zaccarini, Alessandro Morelli, Roberto Fronteddu, Filippo Poltronieri, Niranjan Suri, Mauro Tortonesi</author><pubDate>Tue, 27 Jun 2023 17:15:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15591v1</guid></item><item><title>Asynchronous Execution of Heterogeneous Tasks in ML-driven HPC Workflows</title><link>http://arxiv.org/abs/2208.11069v2</link><description>Heterogeneous scientific workflows consist of numerous types of tasks thatrequire executing on heterogeneous resources. Asynchronous execution of thosetasks is crucial to improve resource utilization, task throughput and reduceworkflows' makespan. Therefore, middleware capable of scheduling and executingdifferent task types across heterogeneous resources must enable asynchronousexecution of tasks. In this paper, we investigate the requirements andproperties of the asynchronous task execution of machine learning (ML)-drivenhigh performance computing (HPC) workflows. We model the degree ofasynchronicity permitted for arbitrary workflows and propose key metrics thatcan be used to determine qualitative benefits when employing asynchronousexecution. Our experiments represent relevant scientific drivers, we performthem at scale on Summit, and we show that the performance enhancements due toasynchronous execution are consistent with our model.</description><author>Vincent R. Pascuzzi, Ozgur O. Kilic, Matteo Turilli, Shantenu Jha</author><pubDate>Tue, 27 Jun 2023 17:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.11069v2</guid></item><item><title>Optimizing Credit Limit Adjustments Under Adversarial Goals Using Reinforcement Learning</title><link>http://arxiv.org/abs/2306.15585v1</link><description>Reinforcement learning has been explored for many problems, from video gameswith deterministic environments to portfolio and operations management in whichscenarios are stochastic; however, there have been few attempts to test thesemethods in banking problems. In this study, we sought to find and automatize anoptimal credit card limit adjustment policy by employing reinforcement learningtechniques. In particular, because of the historical data available, weconsidered two possible actions per customer, namely increasing or maintainingan individual's current credit limit. To find this policy, we first formulatedthis decision-making question as an optimization problem in which the expectedprofit was maximized; therefore, we balanced two adversarial goals: maximizingthe portfolio's revenue and minimizing the portfolio's provisions. Second,given the particularities of our problem, we used an offline learning strategyto simulate the impact of the action based on historical data from a super-app(i.e., a mobile application that offers various services from goods deliveriesto financial products) in Latin America to train our reinforcement learningagent. Our results show that a Double Q-learning agent with optimizedhyperparameters can outperform other strategies and generate a non-trivialoptimal policy reflecting the complex nature of this decision. Our research notonly establishes a conceptual structure for applying reinforcement learningframework to credit limit adjustment, presenting an objective technique to makethese decisions primarily based on data-driven methods rather than relying onlyon expert-driven systems but also provides insights into the effect ofalternative data usage for determining these modifications.</description><author>Sherly Alfonso-Sánchez, Jesús Solano, Alejandro Correa-Bahnsen, Kristina P. Sendova, Cristián Bravo</author><pubDate>Tue, 27 Jun 2023 17:10:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15585v1</guid></item><item><title>Effect-Invariant Mechanisms for Policy Generalization</title><link>http://arxiv.org/abs/2306.10983v2</link><description>Policy learning is an important component of many real-world learningsystems. A major challenge in policy learning is how to adapt efficiently tounseen environments or tasks. Recently, it has been suggested to exploitinvariant conditional distributions to learn models that generalize better tounseen environments. However, assuming invariance of entire conditionaldistributions (which we call full invariance) may be too strong of anassumption in practice. In this paper, we introduce a relaxation of fullinvariance called effect-invariance (e-invariance for short) and prove that itis sufficient, under suitable assumptions, for zero-shot policy generalization.We also discuss an extension that exploits e-invariance when we have a smallsample from the test environment, enabling few-shot policy generalization. Ourwork does not assume an underlying causal graph or that the data are generatedby a structural causal model; instead, we develop testing procedures to teste-invariance directly from data. We present empirical results using simulateddata and a mobile health intervention dataset to demonstrate the effectivenessof our approach.</description><author>Sorawit Saengkyongam, Niklas Pfister, Predrag Klasnja, Susan Murphy, Jonas Peters</author><pubDate>Tue, 27 Jun 2023 17:09:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10983v2</guid></item><item><title>Approximate Message Passing for the Matrix Tensor Product Model</title><link>http://arxiv.org/abs/2306.15580v1</link><description>We propose and analyze an approximate message passing (AMP) algorithm for thematrix tensor product model, which is a generalization of the standard spikedmatrix models that allows for multiple types of pairwise observations over acollection of latent variables. A key innovation for this algorithm is a methodfor optimally weighing and combining multiple estimates in each iteration.Building upon an AMP convergence theorem for non-separable functions, we provea state evolution for non-separable functions that provides an asymptoticallyexact description of its performance in the high-dimensional limit. We leveragethis state evolution result to provide necessary and sufficient conditions forrecovery of the signal of interest. Such conditions depend on the singularvalues of a linear operator derived from an appropriate generalization of asignal-to-noise ratio for our model. Our results recover as special cases anumber of recently proposed methods for contextual models (e.g., covariateassisted clustering) as well as inhomogeneous noise models.</description><author>Riccardo Rossetti, Galen Reeves</author><pubDate>Tue, 27 Jun 2023 17:03:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15580v1</guid></item><item><title>PyBADS: Fast and robust black-box optimization in Python</title><link>http://arxiv.org/abs/2306.15576v1</link><description>PyBADS is a Python implementation of the Bayesian Adaptive Direct Search(BADS) algorithm for fast and robust black-box optimization (Acerbi and Ma2017). BADS is an optimization algorithm designed to efficiently solvedifficult optimization problems where the objective function is rough(non-convex, non-smooth), mildly expensive (e.g., the function evaluationrequires more than 0.1 seconds), possibly noisy, and gradient information isunavailable. With BADS, these issues are well addressed, making it an excellentchoice for fitting computational models using methods such asmaximum-likelihood estimation. The algorithm scales efficiently to black-boxfunctions with up to $D \approx 20$ continuous input parameters and supportsbounds or no constraints. PyBADS comes along with an easy-to-use Pythonicinterface for running the algorithm and inspecting its results. PyBADS onlyrequires the user to provide a Python function for evaluating the targetfunction, and optionally other constraints. Extensive benchmarks on both artificial test problems and large realmodel-fitting problems models drawn from cognitive, behavioral andcomputational neuroscience, show that BADS performs on par with or better thanmany other common and state-of-the-art optimizers (Acerbi and Ma 2017), makingit a general model-fitting tool which provides fast and robust solutions.</description><author>Gurjeet Sangra Singh, Luigi Acerbi</author><pubDate>Tue, 27 Jun 2023 16:54:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15576v1</guid></item><item><title>See Through the Fog: Curriculum Learning with Progressive Occlusion in Medical Imaging</title><link>http://arxiv.org/abs/2306.15574v1</link><description>In recent years, deep learning models have revolutionized medical imageinterpretation, offering substantial improvements in diagnostic accuracy.However, these models often struggle with challenging images where criticalfeatures are partially or fully occluded, which is a common scenario inclinical practice. In this paper, we propose a novel curriculum learning-basedapproach to train deep learning models to handle occluded medical imageseffectively. Our method progressively introduces occlusion, starting fromclear, unobstructed images and gradually moving to images with increasingocclusion levels. This ordered learning process, akin to human learning, allowsthe model to first grasp simple, discernable patterns and subsequently buildupon this knowledge to understand more complicated, occluded scenarios.Furthermore, we present three novel occlusion synthesis methods, namelyWasserstein Curriculum Learning (WCL), Information Adaptive Learning (IAL), andGeodesic Curriculum Learning (GCL). Our extensive experiments on diversemedical image datasets demonstrate substantial improvements in model robustnessand diagnostic accuracy over conventional training methodologies.</description><author>Pradeep Singh, Kishore Babu Nampalle, Uppala Vivek Narayan, Balasubramanian Raman</author><pubDate>Tue, 27 Jun 2023 16:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15574v1</guid></item><item><title>Reversible Quantization Index Modulation for Static Deep Neural Network Watermarking</title><link>http://arxiv.org/abs/2305.17879v2</link><description>Static deep neural network (DNN) watermarking techniques typically employirreversible methods to embed watermarks into the DNN model weights. However,this approach causes permanent damage to the watermarked model and fails tomeet the requirements of integrity authentication. Reversible data hiding (RDH)methods offer a potential solution, but existing approaches suffer fromweaknesses in terms of usability, capacity, and fidelity, hindering theirpractical adoption. In this paper, we propose a novel RDH-based static DNNwatermarking scheme using quantization index modulation (QIM). Our schemeincorporates a novel approach based on a one-dimensional quantizer forwatermark embedding. Furthermore, we design two schemes to address thechallenges of integrity protection and legitimate authentication for DNNs.Through simulation results on training loss and classification accuracy, wedemonstrate the feasibility and effectiveness of our proposed schemes,highlighting their superior adaptability compared to existing methods.</description><author>Junren Qin, Shanxiang Lyu, Fan Yang, Jiarui Deng, Zhihua Xia, Xiaochun Cao</author><pubDate>Tue, 27 Jun 2023 16:49:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17879v2</guid></item><item><title>Generating Elementary Integrable Expressions</title><link>http://arxiv.org/abs/2306.15572v1</link><description>There has been an increasing number of applications of machine learning tothe field of Computer Algebra in recent years, including to the prominentsub-field of Symbolic Integration. However, machine learning models require anabundance of data for them to be successful and there exist few benchmarks onthe scale required. While methods to generate new data already exist, they areflawed in several ways which may lead to bias in machine learning modelstrained upon them. In this paper, we describe how to use the Risch Algorithmfor symbolic integration to create a dataset of elementary integrableexpressions. Further, we show that data generated this way alleviates some ofthe flaws found in earlier methods.</description><author>Rashid Barket, Matthew England, Jürgen Gerhard</author><pubDate>Tue, 27 Jun 2023 16:48:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15572v1</guid></item><item><title>A Three-Way Knot: Privacy, Fairness, and Predictive Performance Dynamics</title><link>http://arxiv.org/abs/2306.15567v1</link><description>As the frontier of machine learning applications moves further into humaninteraction, multiple concerns arise regarding automated decision-making. Twoof the most critical issues are fairness and data privacy. On the one hand, onemust guarantee that automated decisions are not biased against certain groups,especially those unprotected or marginalized. On the other hand, one mustensure that the use of personal information fully abides by privacy regulationsand that user identities are kept safe. The balance between privacy, fairness,and predictive performance is complex. However, despite their potentialsocietal impact, we still demonstrate a poor understanding of the dynamicsbetween these optimization vectors. In this paper, we study this three-waytension and how the optimization of each vector impacts others, aiming toinform the future development of safe applications. In light of claims thatpredictive performance and fairness can be jointly optimized, we find this isonly possible at the expense of data privacy. Overall, experimental resultsshow that one of the vectors will be penalized regardless of which of the threewe optimize. Nonetheless, we find promising avenues for future work in jointoptimization solutions, where smaller trade-offs are observed between the threevectors.</description><author>Tânia Carvalho, Nuno Moniz, Luís Antunes</author><pubDate>Tue, 27 Jun 2023 16:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15567v1</guid></item><item><title>Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling</title><link>http://arxiv.org/abs/2305.11543v2</link><description>As the foundation of current natural language processing methods, pre-trainedlanguage model has achieved excellent performance. However, the black-boxstructure of the deep neural network in pre-trained language models seriouslylimits the interpretability of the language modeling process. After revisitingthe coupled requirement of deep neural representation and semantics logic oflanguage modeling, a Word-Context-Coupled Space (W2CSpace) is proposed byintroducing the alignment processing between uninterpretable neuralrepresentation and interpretable statistical logic. Moreover, a clusteringprocess is also designed to connect the word- and context-level semantics.Specifically, an associative knowledge network (AKN), considered interpretablestatistical logic, is introduced in the alignment process for word-levelsemantics. Furthermore, the context-relative distance is employed as thesemantic feature for the downstream classifier, which is greatly different fromthe current uninterpretable semantic representations of pre-trained models. Ourexperiments for performance evaluation and interpretable analysis are executedon several types of datasets, including SIGHAN, Weibo, and ChnSenti. Wherein anovel evaluation strategy for the interpretability of machine learning modelsis first proposed. According to the experimental results, our language modelcan achieve better performance and highly credible interpretable abilitycompared to related state-of-the-art methods.</description><author>Fanyu Wang, Zhenping Xie</author><pubDate>Tue, 27 Jun 2023 16:45:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11543v2</guid></item><item><title>You Can Mask More For Extremely Low-Bitrate Image Compression</title><link>http://arxiv.org/abs/2306.15561v1</link><description>Learned image compression (LIC) methods have experienced significant progressduring recent years. However, these methods are primarily dedicated tooptimizing the rate-distortion (R-D) performance at medium and high bitrates (&gt;0.1 bits per pixel (bpp)), while research on extremely low bitrates is limited.Besides, existing methods fail to explicitly explore the image structure andtexture components crucial for image compression, treating them equallyalongside uninformative components in networks. This can cause severeperceptual quality degradation, especially under low-bitrate scenarios. In thiswork, inspired by the success of pre-trained masked autoencoders (MAE) in manydownstream tasks, we propose to rethink its mask sampling strategy fromstructure and texture perspectives for high redundancy reduction anddiscriminative feature representation, further unleashing the potential of LICmethods. Therefore, we present a dual-adaptive masking approach (DA-Mask) thatsamples visible patches based on the structure and texture distributions oforiginal images. We combine DA-Mask and pre-trained MAE in masked imagemodeling (MIM) as an initial compressor that abstracts informative semanticcontext and texture representations. Such a pipeline can well cooperate withLIC networks to achieve further secondary compression while preservingpromising reconstruction quality. Consequently, we propose a simple yeteffective masked compression model (MCM), the first framework that unifies MIMand LIC end-to-end for extremely low-bitrate image compression. Extensiveexperiments have demonstrated that our approach outperforms recentstate-of-the-art methods in R-D performance, visual quality, and downstreamapplications, at very low bitrates. Our code is available athttps://github.com/lianqi1008/MCM.git.</description><author>Anqi Li, Feng Li, Jiaxin Han, Huihui Bai, Runmin Cong, Chunjie Zhang, Meng Wang, Weisi Lin, Yao Zhao</author><pubDate>Tue, 27 Jun 2023 16:36:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15561v1</guid></item><item><title>RansomAI: AI-powered Ransomware for Stealthy Encryption</title><link>http://arxiv.org/abs/2306.15559v1</link><description>Cybersecurity solutions have shown promising performance when detectingransomware samples that use fixed algorithms and encryption rates. However, dueto the current explosion of Artificial Intelligence (AI), sooner than later,ransomware (and malware in general) will incorporate AI techniques tointelligently and dynamically adapt its encryption behavior to be undetected.It might result in ineffective and obsolete cybersecurity solutions, but theliterature lacks AI-powered ransomware to verify it. Thus, this work proposesRansomAI, a Reinforcement Learning-based framework that can be integrated intoexisting ransomware samples to adapt their encryption behavior and staystealthy while encrypting files. RansomAI presents an agent that learns thebest encryption algorithm, rate, and duration that minimizes its detection(using a reward mechanism and a fingerprinting intelligent detection system)while maximizing its damage function. The proposed framework was validated in aransomware, Ransomware-PoC, that infected a Raspberry Pi 4, acting as acrowdsensor. A pool of experiments with Deep Q-Learning and Isolation Forest(deployed on the agent and detection system, respectively) has demonstratedthat RansomAI evades the detection of Ransomware-PoC affecting the Raspberry Pi4 in a few minutes with &gt;90% accuracy.</description><author>Jan von der Assen, Alberto Huertas Celdrán, Janik Luechinger, Pedro Miguel Sánchez Sánchez, Gérôme Bovet, Gregorio Martínez Pérez, Burkhard Stiller</author><pubDate>Tue, 27 Jun 2023 16:36:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15559v1</guid></item><item><title>Simple Steps to Success: Axiomatics of Distance-Based Algorithmic Recourse</title><link>http://arxiv.org/abs/2306.15557v1</link><description>We propose a novel data-driven framework for algorithmic recourse that offersusers interventions to change their predicted outcome. Existing approaches tocompute recourse find a set of points that satisfy some desiderata -- e.g. anintervention in the underlying causal graph, or minimizing a cost function.Satisfying these criteria, however, requires extensive knowledge of theunderlying model structure, often an unrealistic amount of information inseveral domains. We propose a data-driven, computationally efficient approachto computing algorithmic recourse. We do so by suggesting directions in thedata manifold that users can take to change their predicted outcome. We presentStepwise Explainable Paths (StEP), an axiomatically justified framework tocompute direction-based algorithmic recourse. We offer a thorough empirical andtheoretical investigation of StEP. StEP offers provable privacy and robustnessguarantees, and outperforms the state-of-the-art on several establishedrecourse desiderata.</description><author>Jenny Hamer, Jake Valladares, Vignesh Viswanathan, Yair Zick</author><pubDate>Tue, 27 Jun 2023 16:35:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15557v1</guid></item><item><title>Weakly Supervised Scene Text Generation for Low-resource Languages</title><link>http://arxiv.org/abs/2306.14269v2</link><description>A large number of annotated training images is crucial for trainingsuccessful scene text recognition models. However, collecting sufficientdatasets can be a labor-intensive and costly process, particularly forlow-resource languages. To address this challenge, auto-generating text datahas shown promise in alleviating the problem. Unfortunately, existing scenetext generation methods typically rely on a large amount of paired data, whichis difficult to obtain for low-resource languages. In this paper, we propose anovel weakly supervised scene text generation method that leverages a fewrecognition-level labels as weak supervision. The proposed method is able togenerate a large amount of scene text images with diverse backgrounds and fontstyles through cross-language generation. Our method disentangles the contentand style features of scene text images, with the former representing textualinformation and the latter representing characteristics such as font,alignment, and background. To preserve the complete content structure ofgenerated images, we introduce an integrated attention module. Furthermore, tobridge the style gap in the style of different languages, we incorporate apre-trained font classifier. We evaluate our method using state-of-the-artscene text recognition models. Experiments demonstrate that our generated scenetext significantly improves the scene text recognition accuracy and helpachieve higher accuracy when complemented with other generative methods.</description><author>Yangchen Xie, Xinyuan Chen, Hongjian Zhan, Palaiahankote Shivakum, Bing Yin, Cong Liu, Yue Lu</author><pubDate>Tue, 27 Jun 2023 16:34:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14269v2</guid></item><item><title>A Survey on Deep Learning Hardware Accelerators for Heterogeneous HPC Platforms</title><link>http://arxiv.org/abs/2306.15552v1</link><description>Recent trends in deep learning (DL) imposed hardware accelerators as the mostviable solution for several classes of high-performance computing (HPC)applications such as image classification, computer vision, and speechrecognition. This survey summarizes and classifies the most recent advances indesigning DL accelerators suitable to reach the performance requirements of HPCapplications. In particular, it highlights the most advanced approaches tosupport deep learning accelerations including not only GPU and TPU-basedaccelerators but also design-specific hardware accelerators such as FPGA-basedand ASIC-based accelerators, Neural Processing Units, open hardwareRISC-V-based accelerators and co-processors. The survey also describesaccelerators based on emerging memory technologies and computing paradigms,such as 3D-stacked Processor-In-Memory, non-volatile memories (mainly,Resistive RAM and Phase Change Memories) to implement in-memory computing,Neuromorphic Processing Units, and accelerators based on Multi-Chip Modules.The survey classifies the most influential architectures and technologiesproposed in the last years, with the purpose of offering the reader acomprehensive perspective in the rapidly evolving field of deep learning.Finally, it provides some insights into future challenges in DL acceleratorssuch as quantum accelerators and photonics.</description><author>Cristina Silvano, Daniele Ielmini, Fabrizio Ferrandi, Leandro Fiorin, Serena Curzel, Luca Benini, Francesco Conti, Angelo Garofalo, Cristian Zambelli, Enrico Calore, Sebastiano Fabio Schifano, Maurizio Palesi, Giuseppe Ascia, Davide Patti, Stefania Perri, Nicola Petra, Davide De Caro, Luciano Lavagno, Teodoro Urso, Valeria Cardellini, Gian Carlo Cardarilli, Robert Birke</author><pubDate>Tue, 27 Jun 2023 16:24:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15552v1</guid></item><item><title>CrunchGPT: A chatGPT assisted framework for scientific machine learning</title><link>http://arxiv.org/abs/2306.15551v1</link><description>Scientific Machine Learning (SciML) has advanced recently across manydifferent areas in computational science and engineering. The objective is tointegrate data and physics seamlessly without the need of employing elaborateand computationally taxing data assimilation schemes. However, preprocessing,problem formulation, code generation, postprocessing and analysis are stilltime consuming and may prevent SciML from wide applicability in industrialapplications and in digital twin frameworks. Here, we integrate the variousstages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, whichplays the role of a conductor orchestrating the entire workflow of SciML basedon simple prompts by the user. Specifically, we present two examples thatdemonstrate the potential use of CrunchGPT in optimizing airfoils inaerodynamics, and in obtaining flow fields in various geometries in interactivemode, with emphasis on the validation stage. To demonstrate the flow of theCrunchGPT, and create an infrastructure that can facilitate a broader vision,we built a webapp based guided user interface, that includes options for acomprehensive summary report. The overall objective is to extend CrunchGPT tohandle diverse problems in computational mechanics, design, optimization andcontrols, and general scientific computing tasks involved in SciML, hence usingit as a research assistant tool but also as an educational tool. While here theexamples focus in fluid mechanics, future versions will target solid mechanicsand materials science, geophysics, systems biology and bioinformatics.</description><author>Varun Kumar, Leonard Gleyzer, Adar Kahana, Khemraj Shukla, George Em Karniadakis</author><pubDate>Tue, 27 Jun 2023 16:23:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15551v1</guid></item><item><title>CamemBERT-bio: a Tasty French Language Model Better for your Health</title><link>http://arxiv.org/abs/2306.15550v1</link><description>Clinical data in hospitals are increasingly accessible for research throughclinical data warehouses, however these documents are unstructured. It istherefore necessary to extract information from medical reports to conductclinical studies. Transfer learning with BERT-like models such as CamemBERT hasallowed major advances, especially for named entity recognition. However, thesemodels are trained for plain language and are less efficient on biomedicaldata. This is why we propose a new French public biomedical dataset on which wehave continued the pre-training of CamemBERT. Thus, we introduce a firstversion of CamemBERT-bio, a specialized public model for the French biomedicaldomain that shows 2.54 points of F1 score improvement on average on differentbiomedical named entity recognition tasks.</description><author>Rian Touchent, Laurent Romary, Eric de la Clergerie</author><pubDate>Tue, 27 Jun 2023 16:23:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15550v1</guid></item><item><title>Geometric Ultrasound Localization Microscopy</title><link>http://arxiv.org/abs/2306.15548v1</link><description>Contrast-Enhanced Ultra-Sound (CEUS) has become a viable method fornon-invasive, dynamic visualization in medical diagnostics, yet UltrasoundLocalization Microscopy (ULM) has enabled a revolutionary breakthrough byoffering ten times higher resolution. To date, Delay-And-Sum (DAS) beamformersare used to render ULM frames, ultimately determining the image resolutioncapability. To take full advantage of ULM, this study questions whetherbeamforming is the most effective processing step for ULM, suggesting analternative approach that relies solely on Time-Difference-of-Arrival (TDoA)information. To this end, a novel geometric framework for micro bubblelocalization via ellipse intersections is proposed to overcome existingbeamforming limitations. We present a benchmark comparison based on a publicdataset for which our geometric ULM outperforms existing baseline methods interms of accuracy and reliability while only utilizing a portion of theavailable transducer data.</description><author>Christopher Hahne, Raphael Sznitman</author><pubDate>Tue, 27 Jun 2023 16:18:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15548v1</guid></item><item><title>When Foundation Model Meets Federated Learning: Motivations, Challenges, and Future Directions</title><link>http://arxiv.org/abs/2306.15546v1</link><description>The intersection of the Foundation Model (FM) and Federated Learning (FL)provides mutual benefits, presents a unique opportunity to unlock newpossibilities in AI research, and address critical challenges in AI andreal-world applications. FL expands the availability of data for FMs andenables computation sharing, distributing the training process and reducing theburden on FL participants. It promotes collaborative FM development,democratizing the process and fostering inclusivity and innovation. On theother hand, FM, with its enormous size, pre-trained knowledge, and exceptionalperformance, serves as a robust starting point for FL, facilitating fasterconvergence and better performance under non-iid data. Additionally, leveragingFM to generate synthetic data enriches data diversity, reduces overfitting, andpreserves privacy. By examining the interplay between FL and FM, this paperaims to deepen the understanding of their synergistic relationship,highlighting the motivations, challenges, and future directions. Through anexploration of the challenges faced by FL and FM individually and theirinterconnections, we aim to inspire future research directions that can furtherenhance both fields, driving advancements and propelling the development ofprivacy-preserving and scalable AI systems.</description><author>Weiming Zhuang, Chen Chen, Lingjuan Lyu</author><pubDate>Tue, 27 Jun 2023 16:15:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15546v1</guid></item><item><title>Unleashing the Power of User Reviews: Exploring Airline Choices at Catania Airport, Italy</title><link>http://arxiv.org/abs/2306.15541v1</link><description>This study aims to investigate the possible relationship between themechanisms of social influence and the choice of airline, through the use ofnew tools, with the aim of understanding whether they can contribute to abetter understanding of the factors influencing the decisions of consumers inthe aviation sector. We have chosen to extract user reviews from well-knownplatforms: Trustpilot, Google, and Twitter. By combining web scrapingtechniques, we have been able to collect a comprehensive dataset comprising awide range of user opinions, feedback, and ratings. We then refined the BERTmodel to focus on insightful sentiment in the context of airline reviews.Through our analysis, we observed an intriguing trend of average negativesentiment scores across various airlines, giving us deeper insight into thedynamics between airlines and helping us identify key partnerships, popularroutes, and airlines that play a central role in the aeronautical ecosystem ofCatania airport during the specified period. Our investigation led us to findthat, despite an airline having received prestigious awards as a low-costleader in Europe for two consecutive years 2021 and 2022, the "Catanese" usertends to suffer the dominant position of other companies. Understanding theimpact of positive reviews and leveraging sentiment analysis can help airlinesimprove their reputation, attract more customers, and ultimately gain acompetitive edge in the marketplace.</description><author>Vincenzo Miracula, Antonio Picone</author><pubDate>Tue, 27 Jun 2023 16:10:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15541v1</guid></item><item><title>DataCI: A Platform for Data-Centric AI on Streaming Data</title><link>http://arxiv.org/abs/2306.15538v1</link><description>We introduce DataCI, a comprehensive open-source platform designedspecifically for data-centric AI in dynamic streaming data settings. DataCIprovides 1) an infrastructure with rich APIs for seamless streaming datasetmanagement, data-centric pipeline development and evaluation on streamingscenarios, 2) an carefully designed versioning control function to track thepipeline lineage, and 3) an intuitive graphical interface for a betterinteractive user experience. Preliminary studies and demonstrations attest tothe easy-to-use and effectiveness of DataCI, highlighting its potential torevolutionize the practice of data-centric AI in streaming data contexts.</description><author>Huaizheng Zhang, Yizheng Huang, Yuanming Li</author><pubDate>Tue, 27 Jun 2023 16:07:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15538v1</guid></item><item><title>Higher-order Graph Attention Network for Stock Selection with Joint Analysis</title><link>http://arxiv.org/abs/2306.15526v1</link><description>Stock selection is important for investors to construct profitableportfolios. Graph neural networks (GNNs) are increasingly attractingresearchers for stock prediction due to their strong ability of relationmodelling and generalisation. However, the existing GNN methods only focus onsimple pairwise stock relation and do not capture complex higher-orderstructures modelling relations more than two nodes. In addition, they onlyconsider factors of technical analysis and overlook factors of fundamentalanalysis that can affect the stock trend significantly. Motivated by them, wepropose higher-order graph attention network with joint analysis (H-GAT). H-GATis able to capture higher-order structures and jointly incorporate factors offundamental analysis with factors of technical analysis. Specifically, thesequential layer of H-GAT take both types of factors as the input of along-short term memory model. The relation embedding layer of H-GAT constructsa higher-order graph and learn node embedding with GAT. We then predict theranks of stock return. Extensive experiments demonstrate the superiority of ourH-GAT method on the profitability test and Sharp ratio over both NSDAQ and NYSEdatasets</description><author>Yang Qiao, Yiping Xia, Xiang Li, Zheng Li, Yan Ge</author><pubDate>Tue, 27 Jun 2023 15:54:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15526v1</guid></item><item><title>What a MESS: Multi-Domain Evaluation of Zero-Shot Semantic Segmentation</title><link>http://arxiv.org/abs/2306.15521v1</link><description>While semantic segmentation has seen tremendous improvements in the past,there is still significant labeling efforts necessary and the problem oflimited generalization to classes that have not been present during training.To address this problem, zero-shot semantic segmentation makes use of largeself-supervised vision-language models, allowing zero-shot transfer to unseenclasses. In this work, we build a benchmark for Multi-domain Evaluation ofSemantic Segmentation (MESS), which allows a holistic analysis of performanceacross a wide range of domain-specific datasets such as medicine, engineering,earth monitoring, biology, and agriculture. To do this, we reviewed 120datasets, developed a taxonomy, and classified the datasets according to thedeveloped taxonomy. We select a representative subset consisting of 22 datasetsand propose it as the MESS benchmark. We evaluate eight recently publishedmodels on the proposed MESS benchmark and analyze characteristics for theperformance of zero-shot transfer models. The toolkit is available athttps://github.com/blumenstiel/MESS.</description><author>Benedikt Blumenstiel, Johannes Jakubik, Hilde Kühne, Michael Vössing</author><pubDate>Tue, 27 Jun 2023 15:47:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15521v1</guid></item><item><title>Paradigm Shift in Sustainability Disclosure Analysis: Empowering Stakeholders with CHATREPORT, a Language Model-Based Tool</title><link>http://arxiv.org/abs/2306.15518v1</link><description>This paper introduces a novel approach to enhance Large Language Models(LLMs) with expert knowledge to automate the analysis of corporatesustainability reports by benchmarking them against the Task Force forClimate-Related Financial Disclosures (TCFD) recommendations. Corporatesustainability reports are crucial in assessing organizations' environmentaland social risks and impacts. However, analyzing these reports' vast amounts ofinformation makes human analysis often too costly. As a result, only a fewentities worldwide have the resources to analyze these reports, which couldlead to a lack of transparency. While AI-powered tools can automaticallyanalyze the data, they are prone to inaccuracies as they lack domain-specificexpertise. This paper introduces a novel approach to enhance LLMs with expertknowledge to automate the analysis of corporate sustainability reports. Wechristen our tool CHATREPORT, and apply it in a first use case to assesscorporate climate risk disclosures following the TCFD recommendations.CHATREPORT results from collaborating with experts in climate science, finance,economic policy, and computer science, demonstrating how domain experts can beinvolved in developing AI tools. We make our prompt templates, generated data,and scores available to the public to encourage transparency.</description><author>Jingwei Ni, Julia Bingler, Chiara Colesanti-Senni, Mathias Kraus, Glen Gostlow, Tobias Schimanski, Dominik Stammbach, Saeid Ashraf Vaghefi, Qian Wang, Nicolas Webersinke, Tobias Wekhof, Tingyu Yu, Markus Leippold</author><pubDate>Tue, 27 Jun 2023 15:46:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15518v1</guid></item><item><title>Enhancing Navigation Benchmarking and Perception Data Generation for Row-based Crops in Simulation</title><link>http://arxiv.org/abs/2306.15517v1</link><description>Service robotics is recently enhancing precision agriculture enabling manyautomated processes based on efficient autonomous navigation solutions.However, data generation and infield validation campaigns hinder the progressof large-scale autonomous platforms. Simulated environments and deep visualperception are spreading as successful tools to speed up the development ofrobust navigation with low-cost RGB-D cameras. In this context, thecontribution of this work is twofold: a synthetic dataset to train deepsemantic segmentation networks together with a collection of virtual scenariosfor a fast evaluation of navigation algorithms. Moreover, an automaticparametric approach is developed to explore different field geometries andfeatures. The simulation framework and the dataset have been evaluated bytraining a deep segmentation network on different crops and benchmarking theresulting navigation.</description><author>Mauro Martini, Andrea Eirale, Brenno Tuberga, Marco Ambrosio, Andrea Ostuni, Francesco Messina, Luigi Mazzara, Marcello Chiaberge</author><pubDate>Tue, 27 Jun 2023 15:46:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15517v1</guid></item><item><title>Meshes Meet Voxels: Abdominal Organ Segmentation via Diffeomorphic Deformations</title><link>http://arxiv.org/abs/2306.15515v1</link><description>Abdominal multi-organ segmentation from CT and MRI is an essentialprerequisite for surgical planning and computer-aided navigation systems.Three-dimensional numeric representations of abdominal shapes are furtherimportant for quantitative and statistical analyses thereof. Existing methodsin the field, however, are unable to extract highly accurate 3D representationsthat are smooth, topologically correct, and match points on a template. In thiswork, we present UNetFlow, a novel diffeomorphic shape deformation approach forabdominal organs. UNetFlow combines the advantages of voxel-based andmesh-based approaches for 3D shape extraction. Our results demonstrate highaccuracy with respect to manually annotated CT data and better topologicalcorrectness compared to previous methods. In addition, we show thegeneralization of UNetFlow to MRI.</description><author>Fabian Bongratz, Anne-Marie Rickmann, Christian Wachinger</author><pubDate>Tue, 27 Jun 2023 15:41:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15515v1</guid></item><item><title>FuXi: A cascade machine learning forecasting system for 15-day global weather forecast</title><link>http://arxiv.org/abs/2306.12873v2</link><description>Over the past few years, due to the rapid development of machine learning(ML) models for weather forecasting, state-of-the-art ML models have shownsuperior performance compared to the European Centre for Medium-Range WeatherForecasts (ECMWF)'s high-resolution forecast (HRES) in 10-day forecasts at aspatial resolution of 0.25 degree. However, the challenge remains to performcomparably to the ECMWF ensemble mean (EM) in 15-day forecasts. Previousstudies have demonstrated the importance of mitigating the accumulation offorecast errors for effective long-term forecasts. Despite numerous efforts toreduce accumulation errors, including autoregressive multi-time step loss,using a single model is found to be insufficient to achieve optimal performancein both short and long lead times. Therefore, we present FuXi, a cascaded MLweather forecasting system that provides 15-day global forecasts with atemporal resolution of 6 hours and a spatial resolution of 0.25 degree. FuXi isdeveloped using 39 years of the ECMWF ERA5 reanalysis dataset. The performanceevaluation, based on latitude-weighted root mean square error (RMSE) andanomaly correlation coefficient (ACC), demonstrates that FuXi has comparableforecast performance to ECMWF EM in 15-day forecasts, making FuXi the firstML-based weather forecasting system to accomplish this achievement.</description><author>Lei Chen, Xiaohui Zhong, Feng Zhang, Yuan Cheng, Yinghui Xu, Yuan Qi, Hao Li</author><pubDate>Tue, 27 Jun 2023 15:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12873v2</guid></item><item><title>Event-Triggered Time-Varying Bayesian Optimization</title><link>http://arxiv.org/abs/2208.10790v3</link><description>We consider the problem of sequentially optimizing a time-varying objectivefunction using time-varying Bayesian optimization (TVBO). Here, the keychallenge is the exploration-exploitation trade-off under time variations.Current approaches to TVBO require prior knowledge of a constant rate ofchange. However, in practice, the rate of change is usually unknown. We proposean event-triggered algorithm, ET-GP-UCB, that treats the optimization problemas static until it detects changes in the objective function online and thenresets the dataset. This allows the algorithm to adapt to realized temporalchanges without the need for prior knowledge. The event-trigger is based onprobabilistic uniform error bounds used in Gaussian process regression. Weprovide regret bounds for ET-GP-UCB and show in numerical experiments that itoutperforms state-of-the-art algorithms on synthetic and real-world data.Furthermore, these results demonstrate that ET-GP-UCB is readily applicable tovarious settings without tuning hyperparameters.</description><author>Paul Brunzema, Alexander von Rohr, Friedrich Solowjow, Sebastian Trimpe</author><pubDate>Tue, 27 Jun 2023 15:37:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10790v3</guid></item><item><title>Self-supervised Learning of Event-guided Video Frame Interpolation for Rolling Shutter Frames</title><link>http://arxiv.org/abs/2306.15507v1</link><description>This paper makes the first attempt to tackle the challenging task ofrecovering arbitrary frame rate latent global shutter (GS) frames from twoconsecutive rolling shutter (RS) frames, guided by the novel event camera data.Although events possess high temporal resolution, beneficial for video frameinterpolation (VFI), a hurdle in tackling this task is the lack of paired GSframes. Another challenge is that RS frames are susceptible to distortion whencapturing moving objects. To this end, we propose a novel self-supervisedframework that leverages events to guide RS frame correction and VFI in aunified framework. Our key idea is to estimate the displacement field (DF)non-linear dense 3D spatiotemporal information of all pixels during theexposure time, allowing for the reciprocal reconstruction between RS and GSframes as well as arbitrary frame rate VFI. Specifically, the displacementfield estimation (DFE) module is proposed to estimate the spatiotemporal motionfrom events to correct the RS distortion and interpolate the GS frames in onestep. We then combine the input RS frames and DF to learn a mapping forRS-to-GS frame interpolation. However, as the mapping is highlyunder-constrained, we couple it with an inverse mapping (i.e., GS-to-RS) and RSframe warping (i.e., RS-to-RS) for self-supervision. As there is a lack oflabeled datasets for evaluation, we generate two synthetic datasets and collecta real-world dataset to train and test our method. Experimental results showthat our method yields comparable or better performance with prior supervisedmethods.</description><author>Yunfan Lu, Guoqiang Liang, Lin Wang</author><pubDate>Tue, 27 Jun 2023 15:30:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15507v1</guid></item><item><title>Reaching the Edge of the Edge: Image Analysis in Space</title><link>http://arxiv.org/abs/2301.04954v2</link><description>Satellites have become more widely available due to the reduction in size andcost of their components. As a result, there has been an advent of smallerorganizations having the ability to deploy satellites with a variety ofdata-intensive applications to run on them. One popular application is imageanalysis to detect, for example, land, ice, clouds, etc. for Earth observation.However, the resource-constrained nature of the devices deployed in satellitescreates additional challenges for this resource-intensive application. In this paper, we present our work and lessons-learned on building an ImageProcessing Unit (IPU) for a satellite. We first investigate the performance ofa variety of edge devices (comparing CPU, GPU, TPU, and VPU) fordeep-learning-based image processing on satellites. Our goal is to identifydevices that can achieve accurate results and are flexible when workloadchanges while satisfying the power and latency constraints of satellites. Ourresults demonstrate that hardware accelerators such as ASICs and GPUs areessential for meeting the latency requirements. However, state-of-the-art edgedevices with GPUs may draw too much power for deployment on a satellite. Then,we use the findings gained from the performance analysis to guide thedevelopment of the IPU module for an upcoming satellite mission. We detail howto integrate such a module into an existing satellite architecture and thesoftware necessary to support various missions utilizing this module.</description><author>Robert Bayer, Julian Priest, Pınar Tözün</author><pubDate>Tue, 27 Jun 2023 15:30:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.04954v2</guid></item><item><title>Prioritized Trajectory Replay: A Replay Memory for Data-driven Reinforcement Learning</title><link>http://arxiv.org/abs/2306.15503v1</link><description>In recent years, data-driven reinforcement learning (RL), also known asoffline RL, have gained significant attention. However, the role of datasampling techniques in offline RL has been overlooked despite its potential toenhance online RL performance. Recent research suggests applying samplingtechniques directly to state-transitions does not consistently improveperformance in offline RL. Therefore, in this study, we propose a memorytechnique, (Prioritized) Trajectory Replay (TR/PTR), which extends the samplingperspective to trajectories for more comprehensive information extraction fromlimited data. TR enhances learning efficiency by backward sampling oftrajectories that optimizes the use of subsequent state information. Buildingon TR, we build the weighted critic target to avoid sampling unseen actions inoffline training, and Prioritized Trajectory Replay (PTR) that enables moreefficient trajectory sampling, prioritized by various trajectory prioritymetrics. We demonstrate the benefits of integrating TR and PTR with existingoffline RL algorithms on D4RL. In summary, our research emphasizes thesignificance of trajectory-based data sampling techniques in enhancing theefficiency and performance of offline RL algorithms.</description><author>Jinyi Liu, Yi Ma, Jianye Hao, Yujing Hu, Yan Zheng, Tangjie Lv, Changjie Fan</author><pubDate>Tue, 27 Jun 2023 15:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15503v1</guid></item><item><title>A novel structured argumentation framework for improved explainability of classification tasks</title><link>http://arxiv.org/abs/2306.15500v1</link><description>This paper presents a novel framework for structured argumentation, namedextend argumentative decision graph ($xADG$). It is an extension ofargumentative decision graphs built upon Dung's abstract argumentation graphs.The $xADG$ framework allows for arguments to use boolean logic operators andmultiple premises (supports) within their internal structure, resulting in moreconcise argumentation graphs that may be easier for users to understand. Thestudy presents a methodology for construction of $xADGs$ and evaluates theirsize and predictive capacity for classification tasks of varying magnitudes.Resulting $xADGs$ achieved strong (balanced) accuracy, which was accomplishedthrough an input decision tree, while also reducing the average number ofsupports needed to reach a conclusion. The results further indicated that it ispossible to construct plausibly understandable $xADGs$ that outperform othertechniques for building $ADGs$ in terms of predictive capacity and overallsize. In summary, the study suggests that $xADG$ represents a promisingframework to developing more concise argumentative models that can be used forclassification tasks and knowledge discovery, acquisition, and refinement.</description><author>Lucas Rizzo, Luca Longo</author><pubDate>Tue, 27 Jun 2023 15:24:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15500v1</guid></item><item><title>Conditional expectation using compactification operators</title><link>http://arxiv.org/abs/2306.10592v2</link><description>The separate tasks of denoising, conditional expectation and manifoldlearning can often be posed in a common setting of finding the conditionalexpectations arising from a product of two random variables. This paper focuseson this more general problem and describes an operator theoretic approach toestimating the conditional expectation. Kernel integral operators are used as acompactification tool, to set up the estimation problem as a linear inverseproblem in a reproducing kernel Hilbert space. This equation is shown to havesolutions that are stable to numerical approximation, thus guaranteeing theconvergence of data-driven implementations. The overall technique is easy toimplement, and their successful application to some real-world problems arealso shown.</description><author>Suddhasattwa Das</author><pubDate>Tue, 27 Jun 2023 15:21:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10592v2</guid></item><item><title>Discovering Object-Centric Generalized Value Functions From Pixels</title><link>http://arxiv.org/abs/2304.13892v2</link><description>Deep Reinforcement Learning has shown significant progress in extractinguseful representations from high-dimensional inputs albeit using hand-craftedauxiliary tasks and pseudo rewards. Automatically learning such representationsin an object-centric manner geared towards control and fast adaptation remainsan open research problem. In this paper, we introduce a method that tries todiscover meaningful features from objects, translating them to temporallycoherent "question" functions and leveraging the subsequent learned generalvalue functions for control. We compare our approach with state-of-the-arttechniques alongside other ablations and show competitive performance in bothstationary and non-stationary settings. Finally, we also investigate thediscovered general value functions and through qualitative analysis show thatthe learned representations are not only interpretable but also, centeredaround objects that are invariant to changes across tasks facilitating fastadaptation.</description><author>Somjit Nath, Gopeshh Raaj Subbaraj, Khimya Khetarpal, Samira Ebrahimi Kahou</author><pubDate>Tue, 27 Jun 2023 15:19:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13892v2</guid></item><item><title>Using Large Language Models to Provide Explanatory Feedback to Human Tutors</title><link>http://arxiv.org/abs/2306.15498v1</link><description>Research demonstrates learners engaging in the process of producingexplanations to support their reasoning, can have a positive impact onlearning. However, providing learners real-time explanatory feedback oftenpresents challenges related to classification accuracy, particularly indomain-specific environments, containing situationally complex and nuancedresponses. We present two approaches for supplying tutors real-time feedbackwithin an online lesson on how to give students effective praise. Thiswork-in-progress demonstrates considerable accuracy in binary classificationfor corrective feedback of effective, or effort-based (F1 score = 0.811), andineffective, or outcome-based (F1 score = 0.350), praise responses. Morenotably, we introduce progress towards an enhanced approach of providingexplanatory feedback using large language model-facilitated named entityrecognition, which can provide tutors feedback, not only while engaging inlessons, but can potentially suggest real-time tutor moves. Future workinvolves leveraging large language models for data augmentation to improveaccuracy, while also developing an explanatory feedback interface.</description><author>Jionghao Lin, Danielle R. Thomas, Feifei Han, Shivang Gupta, Wei Tan, Ngoc Dang Nguyen, Kenneth R. Koedinger</author><pubDate>Tue, 27 Jun 2023 15:19:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15498v1</guid></item><item><title>Smart Learning to Find Dumb Contracts (Extended Version)</title><link>http://arxiv.org/abs/2304.10726v2</link><description>We introduce the Deep Learning Vulnerability Analyzer (DLVA) for Ethereumsmart contracts based on neural networks. We train DLVA to judge bytecode eventhough the supervising oracle can only judge source. DLVA's training algorithmis general: we extend a source code analysis to bytecode without any manualfeature engineering, predefined patterns, or expert rules. DLVA's trainingalgorithm is also robust: it overcame a 1.25% error rate mislabeled contracts,and--the student surpassing the teacher--found vulnerable contracts thatSlither mislabeled. DLVA is much faster than other smart contract vulnerabilitydetectors: DLVA checks contracts for 29 vulnerabilities in 0.2 seconds, a10-1,000x speedup. DLVA has three key components. First, Smart Contract toVector (SC2V) uses neural networks to map smart contract bytecode to ahigh-dimensional floating-point vector. We benchmark SC2V against 4state-of-the-art graph neural networks and show that it improves modeldifferentiation by 2.2%. Second, Sibling Detector (SD) classifies contractswhen a target contract's vector is Euclidian-close to a labeled contract'svector in a training set; although only able to judge 55.7% of the contracts inour test set, it has a Slither-predictive accuracy of 97.4% with a falsepositive rate of only 0.1%. Third, Core Classifier (CC) uses neural networks toinfer vulnerable contracts regardless of vector distance. We benchmark DLVA'sCC with 10 ML techniques and show that the CC improves accuracy by 11.3%.Overall, DLVA predicts Slither's labels with an overall accuracy of 92.7% andassociated false positive rate of 7.2%. Lastly, we benchmark DLVA against ninewell-known smart contract analysis tools. Despite using much less analysistime, DLVA completed every query, leading the pack with an average accuracy of99.7%, pleasingly balancing high true positive rates with low false positiverates.</description><author>Tamer Abdelaziz, Aquinas Hobor</author><pubDate>Tue, 27 Jun 2023 15:19:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10726v2</guid></item><item><title>EVD Surgical Guidance with Retro-Reflective Tool Tracking and Spatial Reconstruction using Head-Mounted Augmented Reality Device</title><link>http://arxiv.org/abs/2306.15490v1</link><description>Augmented Reality (AR) has been used to facilitate surgical guidance duringExternal Ventricular Drain (EVD) surgery, reducing the risks of misplacement inmanual operations. During this procedure, the pivotal challenge is the accurateestimation of spatial relationship between pre-operative images and actualpatient anatomy in AR environment. In this research, we propose a novelframework utilizing Time of Flight (ToF) depth sensors integrated incommercially available AR Head Mounted Devices (HMD) for precise EVD surgicalguidance. As previous studies have proven depth errors for ToF sensors, wefirst conducted a comprehensive assessment for the properties of this error onAR-HMDs. Subsequently, a depth error model and patient-specific model parameteridentification method, is introduced for accurate surface information. Afterthat, a tracking procedure combining retro-reflective markers and point cloudsis proposed for accurate head tracking, where head surface is reconstructedusing ToF sensor data for spatial registration, avoiding fixing trackingtargets rigidly on the patient's cranium. Firstly, $7.580\pm 1.488 mm$ ToFsensor depth value error was revealed on human skin, indicating thesignificance of depth correction. Our results showed that the ToF sensor deptherror was reduced by over $85\%$ using proposed depth correction method on headphantoms in different materials. Meanwhile, the head surface reconstructed withcorrected depth data achieved sub-millimeter accuracy. Experiment on a sheephead revealed $0.79 mm$ reconstruction error. Furthermore, a user study wasconducted for the performance of proposed framework in simulated EVD surgery,where 5 surgeons performed 9 k-wire injections on a head phantom with virtualguidance. Results of this study revealed $2.09 \pm 0.16 mm$ translationalaccuracy and $2.97\pm 0.91 ^\circ$ orientational accuracy.</description><author>Haowei Li, Wenqing Yan, Du Liu, Long Qian, Yuxing Yang, Yihao Liu, Zhe Zhao, Hui Ding, Guangzhi Wang</author><pubDate>Tue, 27 Jun 2023 15:11:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15490v1</guid></item><item><title>Precursor-of-Anomaly Detection for Irregular Time Series</title><link>http://arxiv.org/abs/2306.15489v1</link><description>Anomaly detection is an important field that aims to identify unexpectedpatterns or data points, and it is closely related to many real-world problems,particularly to applications in finance, manufacturing, cyber security, and soon. While anomaly detection has been studied extensively in various fields,detecting future anomalies before they occur remains an unexplored territory.In this paper, we present a novel type of anomaly detection, called\emph{\textbf{P}recursor-of-\textbf{A}nomaly} (PoA) detection. Unlikeconventional anomaly detection, which focuses on determining whether a giventime series observation is an anomaly or not, PoA detection aims to detectfuture anomalies before they happen. To solve both problems at the same time,we present a neural controlled differential equation-based neural network andits multi-task learning algorithm. We conduct experiments using 17 baselinesand 3 datasets, including regular and irregular time series, and demonstratethat our presented method outperforms the baselines in almost all cases. Ourablation studies also indicate that the multitasking training methodsignificantly enhances the overall performance for both anomaly and PoAdetection.</description><author>Sheo Yon Jhin, Jaehoon Lee, Noseong Park</author><pubDate>Tue, 27 Jun 2023 15:10:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15489v1</guid></item><item><title>Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets</title><link>http://arxiv.org/abs/2306.15482v1</link><description>Despite incredible advances, deep learning has been shown to be susceptibleto adversarial attacks. Numerous approaches have been proposed to train robustnetworks both empirically and certifiably. However, most of them defend againstonly a single type of attack, while recent work takes steps forward indefending against multiple attacks. In this paper, to understand multi-targetrobustness, we view this problem as a bargaining game in which differentplayers (adversaries) negotiate to reach an agreement on a joint direction ofparameter updating. We identify a phenomenon named player domination in thebargaining game, namely that the existing max-based approaches, such as MAX andMSD, do not converge. Based on our theoretical analysis, we design a novelframework that adjusts the budgets of different adversaries to avoid any playerdominance. Experiments on standard benchmarks show that employing the proposedframework to the existing approaches significantly advances multi-targetrobustness.</description><author>Yimu Wang, Dinghuai Zhang, Yihan Wu, Heng Huang, Hongyang Zhang</author><pubDate>Tue, 27 Jun 2023 15:02:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15482v1</guid></item><item><title>GraphSR: A Data Augmentation Algorithm for Imbalanced Node Classification</title><link>http://arxiv.org/abs/2302.12814v2</link><description>Graph neural networks (GNNs) have achieved great success in nodeclassification tasks. However, existing GNNs naturally bias towards themajority classes with more labelled data and ignore those minority classes withrelatively few labelled ones. The traditional techniques often resortover-sampling methods, but they may cause overfitting problem. More recently,some works propose to synthesize additional nodes for minority classes from thelabelled nodes, however, there is no any guarantee if those generated nodesreally stand for the corresponding minority classes. In fact, improperlysynthesized nodes may result in insufficient generalization of the algorithm.To resolve the problem, in this paper we seek to automatically augment theminority classes from the massive unlabelled nodes of the graph. Specifically,we propose \textit{GraphSR}, a novel self-training strategy to augment theminority classes with significant diversity of unlabelled nodes, which is basedon a Similarity-based selection module and a Reinforcement Learning(RL)selection module. The first module finds a subset of unlabelled nodes which aremost similar to those labelled minority nodes, and the second one furtherdetermines the representative and reliable nodes from the subset via RLtechnique. Furthermore, the RL-based module can adaptively determine thesampling scale according to current training data. This strategy is general andcan be easily combined with different GNNs models. Our experiments demonstratethe proposed approach outperforms the state-of-the-art baselines on variousclass-imbalanced datasets.</description><author>Mengting Zhou, Zhiguo Gong</author><pubDate>Tue, 27 Jun 2023 15:01:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.12814v2</guid></item><item><title>Survey of Federated Learning Models for Spatial-Temporal Mobility Applications</title><link>http://arxiv.org/abs/2305.05257v3</link><description>Federated learning involves training statistical models over edge devicessuch as mobile phones such that the training data is kept local. FederatedLearning (FL) can serve as an ideal candidate for training spatial temporalmodels that rely on heterogeneous and potentially massive numbers ofparticipants while preserving the privacy of highly sensitive location data.However, there are unique challenges involved with transitioning existingspatial temporal models to decentralized learning. In this survey paper, wereview the existing literature that has proposed FL-based models for predictinghuman mobility, traffic prediction, community detection, location-basedrecommendation systems, and other spatial-temporal tasks. We describe themetrics and datasets these works have been using and create a baseline of theseapproaches in comparison to the centralized settings. Finally, we discuss thechallenges of applying spatial-temporal models in a decentralized setting andby highlighting the gaps in the literature we provide a road map andopportunities for the research community.</description><author>Yacine Belal, Sonia Ben Mokhtar, Hamed Haddadi, Jaron Wang, Afra Mashhadi</author><pubDate>Tue, 27 Jun 2023 14:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05257v3</guid></item><item><title>CADet: Fully Self-Supervised Out-Of-Distribution Detection With Contrastive Learning</title><link>http://arxiv.org/abs/2210.01742v3</link><description>Handling out-of-distribution (OOD) samples has become a major stake in thereal-world deployment of machine learning systems. This work explores the useof self-supervised contrastive learning to the simultaneous detection of twotypes of OOD samples: unseen classes and adversarial perturbations. First, wepair self-supervised contrastive learning with the maximum mean discrepancy(MMD) two-sample test. This approach enables us to robustly test whether twoindependent sets of samples originate from the same distribution, and wedemonstrate its effectiveness by discriminating between CIFAR-10 and CIFAR-10.1with higher confidence than previous work. Motivated by this success, weintroduce CADet (Contrastive Anomaly Detection), a novel method for OODdetection of single samples. CADet draws inspiration from MMD, but leveragesthe similarity between contrastive transformations of a same sample. CADetoutperforms existing adversarial detection methods in identifying adversariallyperturbed samples on ImageNet and achieves comparable performance to unseenlabel detection methods on two challenging benchmarks: ImageNet-O andiNaturalist. Significantly, CADet is fully self-supervised and requires neitherlabels for in-distribution samples nor access to OOD examples.</description><author>Charles Guille-Escuret, Pau Rodriguez, David Vazquez, Ioannis Mitliagkas, Joao Monteiro</author><pubDate>Tue, 27 Jun 2023 14:58:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.01742v3</guid></item><item><title>Causal Inference via Predictive Coding</title><link>http://arxiv.org/abs/2306.15479v1</link><description>Bayesian and causal inference are fundamental processes for intelligence.Bayesian inference models observations: what can be inferred about y if weobserve a related variable x? Causal inference models interventions: if wedirectly change x, how will y change? Predictive coding is aneuroscience-inspired method for performing Bayesian inference on continuousstate variables using local information only. In this work, we go beyondBayesian inference, and show how a simple change in the inference process ofpredictive coding enables interventional and counterfactual inference inscenarios where the causal graph is known. We then extend our results, and showhow predictive coding can be generalized to cases where this graph is unknown,and has to be inferred from data, hence performing causal discovery. Whatresults is a novel and straightforward technique that allows us to performend-to-end causal inference on predictive-coding-based structural causalmodels, and demonstrate its utility for potential applications in machinelearning.</description><author>Tommaso Salvatori, Luca Pinchetti, Amine M'Charrak, Beren Millidge, Thomas Lukasiewicz</author><pubDate>Tue, 27 Jun 2023 14:57:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15479v1</guid></item><item><title>Demonstrating Large-Scale Package Manipulation via Learned Metrics of Pick Success</title><link>http://arxiv.org/abs/2305.10272v2</link><description>Automating warehouse operations can reduce logistics overhead costs,ultimately driving down the final price for consumers, increasing the speed ofdelivery, and enhancing the resiliency to workforce fluctuations. The past fewyears have seen increased interest in automating such repeated tasks but mostlyin controlled settings. Tasks such as picking objects from unstructured,cluttered piles have only recently become robust enough for large-scaledeployment with minimal human intervention. This paper demonstrates a large-scale package manipulation from unstructuredpiles in Amazon Robotics' Robot Induction (Robin) fleet, which utilizes a picksuccess predictor trained on real production data. Specifically, the system wastrained on over 394K picks. It is used for singulating up to 5 million packagesper day and has manipulated over 200 million packages during this paper'sevaluation period. The developed learned pick quality measure ranks various pick alternatives inreal-time and prioritizes the most promising ones for execution. The picksuccess predictor aims to estimate from prior experience the successprobability of a desired pick by the deployed industrial robotic arms incluttered scenes containing deformable and rigid objects with partially knownproperties. It is a shallow machine learning model, which allows us to evaluatewhich features are most important for the prediction. An online pick rankerleverages the learned success predictor to prioritize the most promising picksfor the robotic arm, which are then assessed for collision avoidance. Thislearned ranking process is demonstrated to overcome the limitations andoutperform the performance of manually engineered and heuristic alternatives. To the best of the authors' knowledge, this paper presents the firstlarge-scale deployment of learned pick quality estimation methods in a realproduction system.</description><author>Shuai Li, Azarakhsh Keipour, Kevin Jamieson, Nicolas Hudson, Charles Swan, Kostas Bekris</author><pubDate>Tue, 27 Jun 2023 14:55:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10272v2</guid></item><item><title>Iterative autoregression: a novel trick to improve your low-latency speech enhancement model</title><link>http://arxiv.org/abs/2211.01751v3</link><description>Streaming models are an essential component of real-time speech enhancementtools. The streaming regime constrains speech enhancement models to use only atiny context of future information. As a result, the low-latency streamingsetup is generally considered a challenging task and has a significant negativeimpact on the model's quality. However, the sequential nature of streaminggeneration offers a natural possibility for autoregression, that is, utilizingprevious predictions while making current ones. The conventional method fortraining autoregressive models is teacher forcing, but its primary drawbacklies in the training-inference mismatch that can lead to a substantialdegradation in quality. In this study, we propose a straightforward yeteffective alternative technique for training autoregressive low-latency speechenhancement models. We demonstrate that the proposed approach leads to stableimprovement across diverse architectures and training scenarios.</description><author>Pavel Andreev, Nicholas Babaev, Azat Saginbaev, Ivan Shchekotov, Aibek Alanov</author><pubDate>Tue, 27 Jun 2023 14:54:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.01751v3</guid></item><item><title>One-step Multi-view Clustering with Diverse Representation</title><link>http://arxiv.org/abs/2306.05437v2</link><description>Multi-view clustering has attracted broad attention due to its capacity toutilize consistent and complementary information among views. Althoughtremendous progress has been made recently, most existing methods undergo highcomplexity, preventing them from being applied to large-scale tasks. Multi-viewclustering via matrix factorization is a representative to address this issue.However, most of them map the data matrices into a fixed dimension, limitingthe model's expressiveness. Moreover, a range of methods suffers from atwo-step process, i.e., multimodal learning and the subsequent $k$-means,inevitably causing a sub-optimal clustering result. In light of this, wepropose a one-step multi-view clustering with diverse representation method,which incorporates multi-view learning and $k$-means into a unified framework.Specifically, we first project original data matrices into various latentspaces to attain comprehensive information and auto-weight them in aself-supervised manner. Then we directly use the information matrices underdiverse dimensions to obtain consensus discrete clustering labels. The unifiedwork of representation learning and clustering boosts the quality of the finalresults. Furthermore, we develop an efficient optimization algorithm withproven convergence to solve the resultant problem. Comprehensive experiments onvarious datasets demonstrate the promising clustering performance of ourproposed method.</description><author>Xinhang Wan, Jiyuan Liu, Xinwang Liu, Siwei Wang, Yi Wen, Tianjiao Wan, Li Shen, En Zhu</author><pubDate>Tue, 27 Jun 2023 14:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05437v2</guid></item><item><title>Taming Detection Transformers for Medical Object Detection</title><link>http://arxiv.org/abs/2306.15472v1</link><description>The accurate detection of suspicious regions in medical images is anerror-prone and time-consuming process required by many routinely performeddiagnostic procedures. To support clinicians during this difficult task,several automated solutions were proposed relying on complex methods with manyhyperparameters. In this study, we investigate the feasibility of DEtectionTRansformer (DETR) models for volumetric medical object detection. In contrastto previous works, these models directly predict a set of objects withoutrelying on the design of anchors or manual heuristics such asnon-maximum-suppression to detect objects. We show by conducting extensiveexperiments with three models, namely DETR, Conditional DETR, and DINO DETR onfour data sets (CADA, RibFrac, KiTS19, and LIDC) that these set predictionmodels can perform on par with or even better than currently existing methods.DINO DETR, the best-performing model in our experiments demonstrates this byoutperforming a strong anchor-based one-stage detector, Retina U-Net, on threeout of four data sets.</description><author>Marc K. Ickler, Michael Baumgartner, Saikat Roy, Tassilo Wald, Klaus H. Maier-Hein</author><pubDate>Tue, 27 Jun 2023 14:46:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15472v1</guid></item><item><title>Introducing A Novel Method For Adaptive Thresholding In Brain Tumor Medical Image Segmentation</title><link>http://arxiv.org/abs/2306.14250v2</link><description>One of the most significant challenges in the field of deep learning andmedical image segmentation is to determine an appropriate threshold forclassifying each pixel. This threshold is a value above which the model'soutput is considered to belong to a specific class. Manual thresholding basedon personal experience is error-prone and time-consuming, particularly forcomplex problems such as medical images. Traditional methods for thresholdingare not effective for determining the threshold value for such problems. To tackle this challenge, automatic thresholding methods using deep learninghave been proposed. However, the main issue with these methods is that theyoften determine the threshold value statically without considering changes ininput data. Since input data can be dynamic and may change over time, thresholddetermination should be adaptive and consider input data and environmentalconditions.</description><author>Ali Fayzi, Mohammad Fayzi, Mostafa Forotan</author><pubDate>Tue, 27 Jun 2023 14:40:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14250v2</guid></item><item><title>Dark Web Activity Classification Using Deep Learning</title><link>http://arxiv.org/abs/2306.07980v2</link><description>In contemporary times, people rely heavily on the internet and search enginesto obtain information, either directly or indirectly. However, the informationaccessible to users constitutes merely 4% of the overall information present onthe internet, which is commonly known as the surface web. The remaininginformation that eludes search engines is called the deep web. The deep webencompasses deliberately hidden information, such as personal email accounts,social media accounts, online banking accounts, and other confidential data.The deep web contains several critical applications, including databases ofuniversities, banks, and civil records, which are off-limits and illegal toaccess. The dark web is a subset of the deep web that provides an idealplatform for criminals and smugglers to engage in illicit activities, such asdrug trafficking, weapon smuggling, selling stolen bank cards, and moneylaundering. In this article, we propose a search engine that employs deeplearning to detect the titles of activities on the dark web. We focus on fivecategories of activities, including drug trading, weapon trading, sellingstolen bank cards, selling fake IDs, and selling illegal currencies. Our aim isto extract relevant images from websites with a ".onion" extension and identifythe titles of websites without images by extracting keywords from the text ofthe pages. Furthermore, we introduce a dataset of images called Darkoob, whichwe have gathered and used to evaluate our proposed method. Our experimentalresults demonstrate that the proposed method achieves an accuracy rate of 94%on the test dataset.</description><author>Ali Fayzi, Mohammad Fayzi, Kourosh Ahmadi</author><pubDate>Tue, 27 Jun 2023 14:33:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07980v2</guid></item><item><title>Large-scale unsupervised audio pre-training for video-to-speech synthesis</title><link>http://arxiv.org/abs/2306.15464v1</link><description>Video-to-speech synthesis is the task of reconstructing the speech signalfrom a silent video of a speaker. Most established approaches to date involve atwo-step process, whereby an intermediate representation from the video, suchas a spectrogram, is extracted first and then passed to a vocoder to producethe raw audio. Some recent work has focused on end-to-end synthesis, wherebythe generation of raw audio and any intermediate representations is performedjointly. All such approaches involve training on data from almost exclusivelyaudio-visual datasets, i.e. every audio sample has a corresponding videosample. This precludes the use of abundant audio-only datasets which may nothave a corresponding visual modality (e.g. audiobooks, radio podcasts, speechrecognition datasets etc.), as well as audio-only architectures that have beendeveloped by the audio machine learning community over the years. In this paperwe propose to train encoder-decoder models on more than 3,500 hours of audiodata at 24kHz, and then use the pre-trained decoders to initialize the audiodecoders for the video-to-speech synthesis task. The pre-training step usesaudio samples only and does not require labels or corresponding samples fromother modalities (visual, text). We demonstrate that this pre-training stepimproves the reconstructed speech and that it is an unexplored way to improvethe quality of the generator in a cross-modal task while only requiring samplesfrom one of the modalities. We conduct experiments using both raw audio and melspectrograms as target outputs and benchmark our models with existing work.</description><author>Triantafyllos Kefalas, Yannis Panagakis, Maja Pantic</author><pubDate>Tue, 27 Jun 2023 14:31:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15464v1</guid></item><item><title>Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning</title><link>http://arxiv.org/abs/2306.15457v1</link><description>Recently, it has been widely known that deep neural networks are highlyvulnerable and easily broken by adversarial attacks. To mitigate theadversarial vulnerability, many defense algorithms have been proposed.Recently, to improve adversarial robustness, many works try to enhance featurerepresentation by imposing more direct supervision on the discriminativefeature. However, existing approaches lack an understanding of learningadversarially robust feature representation. In this paper, we propose a noveltraining framework called Robust Proxy Learning. In the proposed method, themodel explicitly learns robust feature representations with robust proxies. Tothis end, firstly, we demonstrate that we can generate class-representativerobust features by adding class-wise robust perturbations. Then, we use theclass representative features as robust proxies. With the class-wise robustfeatures, the model explicitly learns adversarially robust features through theproposed robust proxy learning framework. Through extensive experiments, weverify that we can manually generate robust features, and our proposed learningframework could increase the robustness of the DNNs.</description><author>Hong Joo Lee, Yong Man Ro</author><pubDate>Tue, 27 Jun 2023 14:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15457v1</guid></item><item><title>Debiased Automatic Speech Recognition for Dysarthric Speech via Sample Reweighting with Sample Affinity Test</title><link>http://arxiv.org/abs/2305.13108v3</link><description>Automatic speech recognition systems based on deep learning are mainlytrained under empirical risk minimization (ERM). Since ERM utilizes theaveraged performance on the data samples regardless of a group such as healthyor dysarthric speakers, ASR systems are unaware of the performance disparitiesacross the groups. This results in biased ASR systems whose performancedifferences among groups are severe. In this study, we aim to improve the ASRsystem in terms of group robustness for dysarthric speakers. To achieve ourgoal, we present a novel approach, sample reweighting with sample affinity test(Re-SAT). Re-SAT systematically measures the debiasing helpfulness of the givendata sample and then mitigates the bias by debiasing helpfulness-based samplereweighting. Experimental results demonstrate that Re-SAT contributes toimproved ASR performance on dysarthric speech without performance degradationon healthy speech.</description><author>Eungbeom Kim, Yunkee Chae, Jaeheon Sim, Kyogu Lee</author><pubDate>Tue, 27 Jun 2023 14:19:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13108v3</guid></item><item><title>Language Models are Bounded Pragmatic Speakers</title><link>http://arxiv.org/abs/2305.17760v3</link><description>How do language models "think"? This paper formulates a probabilisticcognitive model called the bounded pragmatic speaker, which can characterizethe operation of different variations of language models. Specifically, wedemonstrate that large language models fine-tuned with reinforcement learningfrom human feedback (Ouyang et al., 2022) embody a model of thought thatconceptually resembles a fast-and-slow model (Kahneman, 2011), whichpsychologists have attributed to humans. We discuss the limitations ofreinforcement learning from human feedback as a fast-and-slow model of thoughtand propose avenues for expanding this framework. In essence, our researchhighlights the value of adopting a cognitive probabilistic modeling approach togain insights into the comprehension, evaluation, and advancement of languagemodels.</description><author>Khanh Nguyen</author><pubDate>Tue, 27 Jun 2023 14:16:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17760v3</guid></item><item><title>Advancing Adversarial Training by Injecting Booster Signal</title><link>http://arxiv.org/abs/2306.15451v1</link><description>Recent works have demonstrated that deep neural networks (DNNs) are highlyvulnerable to adversarial attacks. To defend against adversarial attacks, manydefense strategies have been proposed, among which adversarial training hasbeen demonstrated to be the most effective strategy. However, it has been knownthat adversarial training sometimes hurts natural accuracy. Then, many worksfocus on optimizing model parameters to handle the problem. Different from theprevious approaches, in this paper, we propose a new approach to improve theadversarial robustness by using an external signal rather than modelparameters. In the proposed method, a well-optimized universal external signalcalled a booster signal is injected into the outside of the image which doesnot overlap with the original content. Then, it boosts both adversarialrobustness and natural accuracy. The booster signal is optimized in parallel tomodel parameters step by step collaboratively. Experimental results show thatthe booster signal can improve both the natural and robust accuracies over therecent state-of-the-art adversarial training methods. Also, optimizing thebooster signal is general and flexible enough to be adopted on any existingadversarial training methods.</description><author>Hong Joo Lee, Youngjoon Yu, Yong Man Ro</author><pubDate>Tue, 27 Jun 2023 14:12:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15451v1</guid></item><item><title>The Sample Complexity of Approximate Rejection Sampling with Applications to Smoothed Online Learning</title><link>http://arxiv.org/abs/2302.04658v2</link><description>Suppose we are given access to $n$ independent samples from distribution$\mu$ and we wish to output one of them with the goal of making the outputdistributed as close as possible to a target distribution $\nu$. In this workwe show that the optimal total variation distance as a function of $n$ is givenby $\tilde\Theta(\frac{D}{f'(n)})$ over the class of all pairs $\nu,\mu$ with abounded $f$-divergence $D_f(\nu\|\mu)\leq D$. Previously, this question wasstudied only for the case when the Radon-Nikodym derivative of $\nu$ withrespect to $\mu$ is uniformly bounded. We then consider an application in theseemingly very different field of smoothed online learning, where we show thatrecent results on the minimax regret and the regret of oracle-efficientalgorithms still hold even under relaxed constraints on the adversary (to havebounded $f$-divergence, as opposed to bounded Radon-Nikodym derivative).Finally, we also study efficacy of importance sampling for mean estimatesuniform over a function class and compare importance sampling with rejectionsampling.</description><author>Adam Block, Yury Polyanskiy</author><pubDate>Tue, 27 Jun 2023 14:09:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04658v2</guid></item><item><title>UniUD Submission to the EPIC-Kitchens-100 Multi-Instance Retrieval Challenge 2023</title><link>http://arxiv.org/abs/2306.15445v1</link><description>In this report, we present the technical details of our submission to theEPIC-Kitchens-100 Multi-Instance Retrieval Challenge 2023. To participate inthe challenge, we ensembled two models trained with two different lossfunctions on 25% of the training data. Our submission, visible on the publicleaderboard, obtains an average score of 56.81% nDCG and 42.63% mAP.</description><author>Alex Falcon, Giuseppe Serra</author><pubDate>Tue, 27 Jun 2023 14:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15445v1</guid></item><item><title>Minibatch training of neural network ensembles via trajectory sampling</title><link>http://arxiv.org/abs/2306.13442v2</link><description>Most iterative neural network training methods use estimates of the lossfunction over small random subsets (or minibatches) of the data to update theparameters, which aid in decoupling the training time from the (often verylarge) size of the training datasets. Here, we show that a minibatch approachcan also be used to train neural network ensembles (NNEs) via trajectorymethods in a highly efficient manner. We illustrate this approach by trainingNNEs to classify images in the MNIST datasets. This method gives an improvementto the training times, allowing it to scale as the ratio of the size of thedataset to that of the average minibatch size which, in the case of MNIST,gives a computational improvement typically of two orders of magnitude. Wehighlight the advantage of using longer trajectories to represent NNEs, bothfor improved accuracy in inference and reduced update cost in terms of thesamples needed in minibatch updates.</description><author>Jamie F. Mair, Luke Causer, Juan P. Garrahan</author><pubDate>Tue, 27 Jun 2023 14:01:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13442v2</guid></item><item><title>Limited-Memory Greedy Quasi-Newton Method with Non-asymptotic Superlinear Convergence Rate</title><link>http://arxiv.org/abs/2306.15444v1</link><description>Non-asymptotic convergence analysis of quasi-Newton methods has gainedattention with a landmark result establishing an explicit superlinear rate ofO$((1/\sqrt{t})^t)$. The methods that obtain this rate, however, exhibit awell-known drawback: they require the storage of the previous Hessianapproximation matrix or instead storing all past curvature information to formthe current Hessian inverse approximation. Limited-memory variants ofquasi-Newton methods such as the celebrated L-BFGS alleviate this issue byleveraging a limited window of past curvature information to construct theHessian inverse approximation. As a result, their per iteration complexity andstorage requirement is O$(\tau d)$ where $\tau \le d$ is the size of the windowand $d$ is the problem dimension reducing the O$(d^2)$ computational cost andmemory requirement of standard quasi-Newton methods. However, to the best ofour knowledge, there is no result showing a non-asymptotic superlinearconvergence rate for any limited-memory quasi-Newton method. In this work, weclose this gap by presenting a limited-memory greedy BFGS (LG-BFGS) method thatachieves an explicit non-asymptotic superlinear rate. We incorporatedisplacement aggregation, i.e., decorrelating projection, in post-processinggradient variations, together with a basis vector selection scheme on variablevariations, which greedily maximizes a progress measure of the Hessian estimateto the true Hessian. Their combination allows past curvature information toremain in a sparse subspace while yielding a valid representation of the fullhistory. Interestingly, our established non-asymptotic superlinear convergencerate demonstrates a trade-off between the convergence speed and memoryrequirement, which to our knowledge, is the first of its kind. Numericalresults corroborate our theoretical findings and demonstrate the effectivenessof our method.</description><author>Zhan Gao, Aryan Mokhtari, Alec Koppel</author><pubDate>Tue, 27 Jun 2023 13:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15444v1</guid></item><item><title>Learning World Models with Identifiable Factorization</title><link>http://arxiv.org/abs/2306.06561v2</link><description>Extracting a stable and compact representation of the environment is crucialfor efficient reinforcement learning in high-dimensional, noisy, andnon-stationary environments. Different categories of information coexist insuch environments -- how to effectively extract and disentangle theseinformation remains a challenging problem. In this paper, we propose IFactor, ageneral framework to model four distinct categories of latent state variablesthat capture various aspects of information within the RL system, based ontheir interactions with actions and rewards. Our analysis establishesblock-wise identifiability of these latent variables, which not only provides astable and compact representation but also discloses that all reward-relevantfactors are significant for policy learning. We further present a practicalapproach to learning the world model with identifiable blocks, ensuring theremoval of redundants but retaining minimal and sufficient information forpolicy optimization. Experiments in synthetic worlds demonstrate that ourmethod accurately identifies the ground-truth latent variables, substantiatingour theoretical findings. Moreover, experiments in variants of the DeepMindControl Suite and RoboDesk showcase the superior performance of our approachover baselines.</description><author>Yu-Ren Liu, Biwei Huang, Zhengmao Zhu, Honglong Tian, Mingming Gong, Yang Yu, Kun Zhang</author><pubDate>Tue, 27 Jun 2023 13:58:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06561v2</guid></item><item><title>No-Service Rail Surface Defect Segmentation via Normalized Attention and Dual-scale Interaction</title><link>http://arxiv.org/abs/2306.15442v1</link><description>No-service rail surface defect (NRSD) segmentation is an essential way forperceiving the quality of no-service rails. However, due to the complex anddiverse outlines and low-contrast textures of no-service rails, existingnatural image segmentation methods cannot achieve promising performance in NRSDimages, especially in some unique and challenging NRSD scenes. To this end, inthis paper, we propose a novel segmentation network for NRSDs based onNormalized Attention and Dual-scale Interaction, named NaDiNet. Specifically,NaDiNet follows the enhancement-interaction paradigm. The NormalizedChannel-wise Self-Attention Module (NAM) and the Dual-scale Interaction Block(DIB) are two key components of NaDiNet. NAM is a specific extension of thechannel-wise self-attention mechanism (CAM) to enhance features extracted fromlow-contrast NRSD images. The softmax layer in CAM will produce very smallcorrelation coefficients which are not conducive to low-contrast featureenhancement. Instead, in NAM, we directly calculate the normalized correlationcoefficient between channels to enlarge the feature differentiation. DIB isspecifically designed for the feature interaction of the enhanced features. Ithas two interaction branches with dual scales, one for fine-grained clues andthe other for coarse-grained clues. With both branches working together, DIBcan perceive defect regions of different granularities. With these modulesworking together, our NaDiNet can generate accurate segmentation map. Extensiveexperiments on the public NRSD-MN dataset with man-made and natural NRSDsdemonstrate that our proposed NaDiNet with various backbones (i.e., VGG,ResNet, and DenseNet) consistently outperforms 10 state-of-the-art methods. Thecode and results of our method are available athttps://github.com/monxxcn/NaDiNet.</description><author>Gongyang Li, Chengjun Han, Zhi Liu</author><pubDate>Tue, 27 Jun 2023 13:58:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15442v1</guid></item><item><title>Measuring the Driving Forces of Predictive Performance: Application to Credit Scoring</title><link>http://arxiv.org/abs/2212.05866v3</link><description>In credit scoring, machine learning models are known to outperform standardparametric models. As they condition access to credit, banking supervisors andinternal model validation teams need to monitor their predictive performanceand to identify the features with the highest impact on performance. Tofacilitate this, we introduce the XPER methodology to decompose a performancemetric (e.g., AUC, $R^2$) into specific contributions associated with thevarious features of a classification or regression model. XPER is theoreticallygrounded on Shapley values and is both model-agnostic and performancemetric-agnostic. Furthermore, it can be implemented either at the model levelor at the individual level. Using a novel dataset of car loans, we decomposethe AUC of a machine-learning model trained to forecast the default probabilityof loan applicants. We show that a small number of features can explain asurprisingly large part of the model performance. Furthermore, we find that thefeatures that contribute the most to the predictive performance of the modelmay not be the ones that contribute the most to individual forecasts (SHAP). Wealso show how XPER can be used to deal with heterogeneity issues andsignificantly boost out-of-sample performance.</description><author>Hué Sullivan, Hurlin Christophe, Pérignon Christophe, Saurin Sébastien</author><pubDate>Tue, 27 Jun 2023 13:57:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.05866v3</guid></item><item><title>On-device modeling of user's social context and familiar places from smartphone-embedded sensor data</title><link>http://arxiv.org/abs/2306.15437v1</link><description>Context modeling and recognition are crucial for adaptive mobile andubiquitous computing. Context-awareness in mobile environments relies on promptreactions to context changes. However, current solutions focus on limitedcontext information processed on centralized architectures, risking privacyleakage and lacking personalization. On-device context modeling and recognitionare emerging research trends, addressing these concerns. Social interactionsand visited locations play significant roles in characterizing daily lifescenarios. This paper proposes an unsupervised and lightweight approach tomodel the user's social context and locations directly on the mobile device.Leveraging the ego-network model, the system extracts high-level, semantic-richcontext features from smartphone-embedded sensor data. For the social context,the approach utilizes data on physical and cyber social interactions amongusers and their devices. Regarding location, it prioritizes modeling thefamiliarity degree of specific locations over raw location data, such as GPScoordinates and proximity devices. The effectiveness of the proposed approachis demonstrated through three sets of experiments, employing five real-worlddatasets. These experiments evaluate the structure of social and location egonetworks, provide a semantic evaluation of the proposed models, and assessmobile computing performance. Finally, the relevance of the extracted featuresis showcased by the improved performance of three machine learning models inrecognizing daily-life situations. Compared to using only features related tophysical context, the proposed approach achieves a 3% improvement in AUROC, 9%in Precision, and 5% in Recall.</description><author>Mattia Giovanni Campana, Franca Delmastro</author><pubDate>Tue, 27 Jun 2023 13:53:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15437v1</guid></item><item><title>KnowPrefix-Tuning: A Two-Stage Prefix-Tuning Framework for Knowledge-Grounded Dialogue Generation</title><link>http://arxiv.org/abs/2306.15430v1</link><description>Existing knowledge-grounded conversation systems generate responses typicallyin a retrieve-then-generate manner. They require a large knowledge base and astrong knowledge retrieval component, which is time- and resource-consuming. Inthis paper, we address the challenge by leveraging the inherent knowledgeencoded in the pre-trained language models (PLMs). We propose KnowledgeablePrefix Tuning (KnowPrefix-Tuning), a two-stage tuning framework, bypassing theretrieval process in a knowledge-grounded conversation system by injectingprior knowledge into the lightweight knowledge prefix. The knowledge prefix isa sequence of continuous knowledge-specific vectors that can be learned duringtraining. In addition, we propose a novel interactive re-parameterizationmechanism that allows the prefix to interact fully with the PLM during theoptimization of response generation. Experimental results demonstrate thatKnowPrefix-Tuning outperforms fine-tuning and other lightweight tuningapproaches, and performs comparably with strong retrieval-based baselines whilebeing $3\times$ faster during inference.</description><author>Jiaqi Bai, Zhao Yan, Jian Yang, Xinnian Liang, Hongcheng Guo, Zhoujun Li</author><pubDate>Tue, 27 Jun 2023 13:38:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15430v1</guid></item></channel></rss>