<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 14 Jun 2023 06:01:01 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models</title><link>http://arxiv.org/abs/2306.07971v1</link><description>The latest breakthroughs in large vision-language models, such as Bard andGPT-4, have showcased extraordinary abilities in performing a wide range oftasks. Such models are trained on massive datasets comprising billions ofpublic image-text pairs with diverse tasks. However, their performance ontask-specific domains, such as radiology, is still under-investigated andpotentially limited due to a lack of sophistication in understanding biomedicalimages. On the other hand, conversational medical models have exhibitedremarkable success but have mainly focused on text-based analysis. In thispaper, we introduce XrayGPT, a novel conversational medical vision-languagemodel that can analyze and answer open-ended questions about chest radiographs.Specifically, we align both medical visual encoder (MedClip) with a fine-tunedlarge language model (Vicuna), using a simple linear transformation. Thisalignment enables our model to possess exceptional visual conversationabilities, grounded in a deep understanding of radiographs and medical domainknowledge. To enhance the performance of LLMs in the medical context, wegenerate ~217k interactive and high-quality summaries from free-text radiologyreports. These summaries serve to enhance the performance of LLMs through thefine-tuning process. Our approach opens up new avenues the research foradvancing the automated analysis of chest radiographs. Our open-source demos,models, and instruction sets are available at:https://github.com/mbzuai-oryx/XrayGPT.</description><author>Omkar Thawkar, Abdelrahman Shaker, Sahal Shaji Mullappilly, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Jorma Laaksonen, Fahad Shahbaz Khan</author><pubDate>Tue, 13 Jun 2023 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07971v1</guid></item><item><title>GeneCIS: A Benchmark for General Conditional Image Similarity</title><link>http://arxiv.org/abs/2306.07969v1</link><description>We argue that there are many notions of 'similarity' and that models, likehumans, should be able to adapt to these dynamically. This contrasts with mostrepresentation learning methods, supervised or self-supervised, which learn afixed embedding function and hence implicitly assume a single notion ofsimilarity. For instance, models trained on ImageNet are biased towards objectcategories, while a user might prefer the model to focus on colors, textures orspecific elements in the scene. In this paper, we propose the GeneCIS('genesis') benchmark, which measures models' ability to adapt to a range ofsimilarity conditions. Extending prior work, our benchmark is designed forzero-shot evaluation only, and hence considers an open-set of similarityconditions. We find that baselines from powerful CLIP models struggle onGeneCIS and that performance on the benchmark is only weakly correlated withImageNet accuracy, suggesting that simply scaling existing methods is notfruitful. We further propose a simple, scalable solution based on automaticallymining information from existing image-caption datasets. We find our methodoffers a substantial boost over the baselines on GeneCIS, and further improveszero-shot performance on related image retrieval benchmarks. In fact, thoughevaluated zero-shot, our model surpasses state-of-the-art supervised models onMIT-States. Project page at https://sgvaze.github.io/genecis/.</description><author>Sagar Vaze, Nicolas Carion, Ishan Misra</author><pubDate>Tue, 13 Jun 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07969v1</guid></item><item><title>Neural Scene Chronology</title><link>http://arxiv.org/abs/2306.07970v1</link><description>In this work, we aim to reconstruct a time-varying 3D model, capable ofrendering photo-realistic renderings with independent control of viewpoint,illumination, and time, from Internet photos of large-scale landmarks. The corechallenges are twofold. First, different types of temporal changes, such asillumination and changes to the underlying scene itself (such as replacing onegraffiti artwork with another) are entangled together in the imagery. Second,scene-level temporal changes are often discrete and sporadic over time, ratherthan continuous. To tackle these problems, we propose a new scenerepresentation equipped with a novel temporal step function encoding methodthat can model discrete scene-level content changes as piece-wise constantfunctions over time. Specifically, we represent the scene as a space-timeradiance field with a per-image illumination embedding, wheretemporally-varying scene changes are encoded using a set of learned stepfunctions. To facilitate our task of chronology reconstruction from Internetimagery, we also collect a new dataset of four scenes that exhibit variouschanges over time. We demonstrate that our method exhibits state-of-the-artview synthesis results on this dataset, while achieving independent control ofviewpoint, time, and illumination.</description><author>Haotong Lin, Qianqian Wang, Ruojin Cai, Sida Peng, Hadar Averbuch-Elor, Xiaowei Zhou, Noah Snavely</author><pubDate>Tue, 13 Jun 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07970v1</guid></item><item><title>arXiVeri: Automatic table verification with GPT</title><link>http://arxiv.org/abs/2306.07968v1</link><description>Without accurate transcription of numerical data in scientific documents, ascientist cannot draw accurate conclusions. Unfortunately, the process ofcopying numerical data from one paper to another is prone to human error. Inthis paper, we propose to meet this challenge through the novel task ofautomatic table verification (AutoTV), in which the objective is to verify theaccuracy of numerical data in tables by cross-referencing cited sources. Tosupport this task, we propose a new benchmark, arXiVeri, which comprisestabular data drawn from open-access academic papers on arXiv. We introducemetrics to evaluate the performance of a table verifier in two key areas: (i)table matching, which aims to identify the source table in a cited documentthat corresponds to a target table, and (ii) cell matching, which aims tolocate shared cells between a target and source table and identify their rowand column indices accurately. By leveraging the flexible capabilities ofmodern large language models (LLMs), we propose simple baselines for tableverification. Our findings highlight the complexity of this task, even forstate-of-the-art LLMs like OpenAI's GPT-4. The code and benchmark will be madepublicly available.</description><author>Gyungin Shin, Weidi Xie, Samuel Albanie</author><pubDate>Tue, 13 Jun 2023 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07968v1</guid></item><item><title>One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning</title><link>http://arxiv.org/abs/2306.07967v1</link><description>We present Generalized LoRA (GLoRA), an advanced approach for universalparameter-efficient fine-tuning tasks. Enhancing Low-Rank Adaptation (LoRA),GLoRA employs a generalized prompt module to optimize pre-trained model weightsand adjust intermediate activations, providing more flexibility and capabilityacross diverse tasks and datasets. Moreover, GLoRA facilitates efficientparameter adaptation by employing a scalable, modular, layer-wise structuresearch that learns individual adapter of each layer. Originating from a unifiedmathematical formulation, GLoRA exhibits strong transfer learning, few-shotlearning and domain generalization abilities, as it adjusts to new tasksthrough additional dimensions on weights and activations. Comprehensiveexperiments demonstrate that GLoRA outperforms all previous methods in natural,specialized, and structured benchmarks, achieving superior accuracy with fewerparameters and computations on various datasets. Furthermore, our structuralre-parameterization design ensures that GLoRA incurs no extra inference cost,rendering it a practical solution for resource-limited applications. Code isavailable at: https://github.com/Arnav0400/ViT-Slim/tree/master/GLoRA.</description><author>Arnav Chavan, Zhuang Liu, Deepak Gupta, Eric Xing, Zhiqiang Shen</author><pubDate>Tue, 13 Jun 2023 18:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07967v1</guid></item><item><title>Parting with Misconceptions about Learning-based Vehicle Motion Planning</title><link>http://arxiv.org/abs/2306.07962v1</link><description>The release of nuPlan marks a new era in vehicle motion planning research,offering the first large-scale real-world dataset and evaluation schemesrequiring both precise short-term planning and long-horizon ego-forecasting.Existing systems struggle to simultaneously meet both requirements. Indeed, wefind that these tasks are fundamentally misaligned and should be addressedindependently. We further assess the current state of closed-loop planning inthe field, revealing the limitations of learning-based methods in complexreal-world scenarios and the value of simple rule-based priors such ascenterline selection through lane graph search algorithms. More surprisingly,for the open-loop sub-task, we observe that the best results are achieved whenusing only this centerline as scene context (\ie, ignoring all informationregarding the map and other agents). Combining these insights, we propose anextremely simple and efficient planner which outperforms an extensive set ofcompetitors, winning the nuPlan planning challenge 2023.</description><author>Daniel Dauner, Marcel Hallgarten, Andreas Geiger, Kashyap Chitta</author><pubDate>Tue, 13 Jun 2023 18:57:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07962v1</guid></item><item><title>How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition</title><link>http://arxiv.org/abs/2207.07730v2</link><description>A major goal of artificial intelligence (AI) is to create an agent capable ofacquiring a general understanding of the world. Such an agent would require theability to continually accumulate and build upon its knowledge as it encountersnew experiences. Lifelong or continual learning addresses this setting, wherebyan agent faces a continual stream of problems and must strive to capture theknowledge necessary for solving each new task it encounters. If the agent iscapable of accumulating knowledge in some form of compositional representation,it could then selectively reuse and combine relevant pieces of knowledge toconstruct novel solutions. Despite the intuitive appeal of this simple idea,the literatures on lifelong learning and compositional learning have proceededlargely separately. In an effort to promote developments that bridge betweenthe two fields, this article surveys their respective research landscapes anddiscusses existing and future connections between them.</description><author>Jorge A. Mendez, Eric Eaton</author><pubDate>Tue, 13 Jun 2023 18:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.07730v2</guid></item><item><title>Differentiating Metropolis-Hastings to Optimize Intractable Densities</title><link>http://arxiv.org/abs/2306.07961v1</link><description>When performing inference on probabilistic models, target densities oftenbecome intractable, necessitating the use of Monte Carlo samplers. We develop amethodology for unbiased differentiation of the Metropolis-Hastings sampler,allowing us to differentiate through probabilistic inference. By fusing recentadvances in stochastic differentiation with Markov chain coupling schemes, theprocedure can be made unbiased, low-variance, and automatic. This allows us toapply gradient-based optimization to objectives expressed as expectations overintractable target densities. We demonstrate our approach by finding anambiguous observation in a Gaussian mixture model and by maximizing thespecific heat in an Ising model.</description><author>Gaurav Arya, Ruben Seyer, Frank Schäfer, Alex Lew, Mathieu Huot, Vikash K. Mansinghka, Chris Rackauckas, Kartik Chandra, Moritz Schauer</author><pubDate>Tue, 13 Jun 2023 18:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07961v1</guid></item><item><title>Supervised-Contrastive Loss Learns Orthogonal Frames and Batching Matters</title><link>http://arxiv.org/abs/2306.07960v1</link><description>Supervised contrastive loss (SCL) is a competitive and often superioralternative to the cross-entropy (CE) loss for classification. In this paper weask: what differences in the learning process occur when the two different lossfunctions are being optimized? To answer this question, our main finding isthat the geometry of embeddings learned by SCL forms an orthogonal frame (OF)regardless of the number of training examples per class. This is in contrast tothe CE loss, for which previous work has shown that it learns embeddingsgeometries that are highly dependent on the class sizes. We arrive at ourfinding theoretically, by proving that the global minimizers of anunconstrained features model with SCL loss and entry-wise non-negativityconstraints form an OF. We then validate the model's prediction by conductingexperiments with standard deep-learning models on benchmark vision datasets.Finally, our analysis and experiments reveal that the batching scheme chosenduring SCL training plays a critical role in determining the quality ofconvergence to the OF geometry. This finding motivates a simple algorithmwherein the addition of a few binding examples in each batch significantlyspeeds up the occurrence of the OF geometry.</description><author>Ganesh Ramachandra Kini, Vala Vakilian, Tina Behnia, Jaidev Gill, Christos Thrampoulidis</author><pubDate>Tue, 13 Jun 2023 18:55:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07960v1</guid></item><item><title>Privacy Preserving Bayesian Federated Learning in Heterogeneous Settings</title><link>http://arxiv.org/abs/2306.07959v1</link><description>In several practical applications of federated learning (FL), the clients arehighly heterogeneous in terms of both their data and compute resources, andtherefore enforcing the same model architecture for each client is verylimiting. Moreover, the need for uncertainty quantification and data privacyconstraints are often particularly amplified for clients that have limitedlocal data. This paper presents a unified FL framework to simultaneouslyaddress all these constraints and concerns, based on training customized localBayesian models that learn well even in the absence of large local datasets. ABayesian framework provides a natural way of incorporating supervision in theform of prior distributions. We use priors in the functional (output) space ofthe networks to facilitate collaboration across heterogeneous clients.Moreover, formal differential privacy guarantees are provided for thisframework. Experiments on standard FL datasets demonstrate that our approachoutperforms strong baselines in both homogeneous and heterogeneous settings andunder strict privacy constraints, while also providing characterizations ofmodel uncertainties.</description><author>Disha Makhija, Joydeep Ghosh, Nhat Ho</author><pubDate>Tue, 13 Jun 2023 18:55:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07959v1</guid></item><item><title>Hidden Biases of End-to-End Driving Models</title><link>http://arxiv.org/abs/2306.07957v1</link><description>End-to-end driving systems have recently made rapid progress, in particularon CARLA. Independent of their major contribution, they introduce changes tominor system components. Consequently, the source of improvements is unclear.We identify two biases that recur in nearly all state-of-the-art methods andare critical for the observed progress on CARLA: (1) lateral recovery via astrong inductive bias towards target point following, and (2) longitudinalaveraging of multimodal waypoint predictions for slowing down. We investigatethe drawbacks of these biases and identify principled alternatives. Byincorporating our insights, we develop TF++, a simple end-to-end method thatranks first on the Longest6 and LAV benchmarks, gaining 14 driving score overthe best prior work on Longest6.</description><author>Bernhard Jaeger, Kashyap Chitta, Andreas Geiger</author><pubDate>Tue, 13 Jun 2023 18:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07957v1</guid></item><item><title>Adaptive Monte Carlo Search for Conjecture Refutation in Graph Theory</title><link>http://arxiv.org/abs/2306.07956v1</link><description>Graph theory is an interdisciplinary field of study that has variousapplications in mathematical modeling and computer science. Research in graphtheory depends on the creation of not only theorems but also conjectures.Conjecture-refuting algorithms attempt to refute conjectures by searching forcounterexamples to those conjectures, often by maximizing certain scorefunctions on graphs. This study proposes a novel conjecture-refuting algorithm,referred to as the adaptive Monte Carlo search (AMCS) algorithm, obtained bymodifying the Monte Carlo tree search algorithm. Evaluated based on its successin finding counterexamples to several graph theory conjectures, AMCSoutperforms existing conjecture-refuting algorithms. The algorithm is furtherutilized to refute six open conjectures, two of which were chemical graphtheory conjectures formulated by Liu et al. in 2021 and four of which wereformulated by the AutoGraphiX computer system in 2006. Finally, four of theopen conjectures are strongly refuted by generalizing the counterexamplesobtained by AMCS to produce a family of counterexamples. It is expected thatthe algorithm can help researchers test graph-theoretic conjectures moreeffectively.</description><author>Valentino Vito, Lim Yohanes Stefanus</author><pubDate>Tue, 13 Jun 2023 18:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07956v1</guid></item><item><title>detrex: Benchmarking Detection Transformers</title><link>http://arxiv.org/abs/2306.07265v2</link><description>The DEtection TRansformer (DETR) algorithm has received considerableattention in the research community and is gradually emerging as a mainstreamapproach for object detection and other perception tasks. However, the currentfield lacks a unified and comprehensive benchmark specifically tailored forDETR-based models. To address this issue, we develop a unified, highly modular,and lightweight codebase called detrex, which supports a majority of themainstream DETR-based instance recognition algorithms, covering variousfundamental tasks, including object detection, segmentation, and poseestimation. We conduct extensive experiments under detrex and perform acomprehensive benchmark for DETR-based models. Moreover, we enhance theperformance of detection transformers through the refinement of traininghyper-parameters, providing strong baselines for supported algorithms.We hopethat detrex could offer research communities a standardized and unifiedplatform to evaluate and compare different DETR-based models while fostering adeeper understanding and driving advancements in DETR-based instancerecognition. Our code is available at https://github.com/IDEA-Research/detrex.The project is currently being actively developed. We encourage the communityto use detrex codebase for further development and contributions.</description><author>Tianhe Ren, Shilong Liu, Feng Li, Hao Zhang, Ailing Zeng, Jie Yang, Xingyu Liao, Ding Jia, Hongyang Li, He Cao, Jianan Wang, Zhaoyang Zeng, Xianbiao Qi, Yuhui Yuan, Jianwei Yang, Lei Zhang</author><pubDate>Tue, 13 Jun 2023 18:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07265v2</guid></item><item><title>Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation</title><link>http://arxiv.org/abs/2306.07954v1</link><description>Large text-to-image diffusion models have exhibited impressive proficiency ingenerating high-quality images. However, when applying these models to videodomain, ensuring temporal consistency across video frames remains a formidablechallenge. This paper proposes a novel zero-shot text-guided video-to-videotranslation framework to adapt image models to videos. The framework includestwo parts: key frame translation and full video translation. The first partuses an adapted diffusion model to generate key frames, with hierarchicalcross-frame constraints applied to enforce coherence in shapes, textures andcolors. The second part propagates the key frames to other frames withtemporal-aware patch matching and frame blending. Our framework achieves globalstyle and local texture temporal consistency at a low cost (without re-trainingor optimization). The adaptation is compatible with existing image diffusiontechniques, allowing our framework to take advantage of them, such ascustomizing a specific subject with LoRA, and introducing extra spatialguidance with ControlNet. Extensive experimental results demonstrate theeffectiveness of our proposed framework over existing methods in renderinghigh-quality and temporally-coherent videos.</description><author>Shuai Yang, Yifan Zhou, Ziwei Liu, Chen Change Loy</author><pubDate>Tue, 13 Jun 2023 18:52:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07954v1</guid></item><item><title>MOFI: Learning Image Representations from Noisy Entity Annotated Images</title><link>http://arxiv.org/abs/2306.07952v1</link><description>We present MOFI, a new vision foundation model designed to learn imagerepresentations from noisy entity annotated images. MOFI differs from previouswork in two key aspects: ($i$) pre-training data, and ($ii$) training recipe.Regarding data, we introduce a new approach to automatically assign entitylabels to images from noisy image-text pairs. Our approach involves employing anamed entity recognition model to extract entities from the alt-text, and thenusing a CLIP model to select the correct entities as labels of the pairedimage. The approach is simple, does not require costly human annotation, andcan be readily scaled up to billions of image-text pairs mined from the web.Through this method, we have created Image-to-Entities (I2E), a new large-scaledataset with 1 billion images and 2 million distinct entities, covering richvisual concepts in the wild. Building upon the I2E dataset, we study differenttraining recipes, including supervised pre-training, contrastive pre-training,and multi-task learning. For constrastive pre-training, we treat entity namesas free-form text, and further enrich them with entity descriptions.Experiments show that supervised pre-training with large-scale fine-grainedentity labels is highly effective for image retrieval tasks, and multi-tasktraining further improves the performance. The final MOFI model achieves 86.66%mAP on the challenging GPR1200 dataset, surpassing the previousstate-of-the-art performance of 72.19% from OpenAI's CLIP model. Furtherexperiments on zero-shot and linear probe image classification also show thatMOFI outperforms a CLIP model trained on the original image-text data,demonstrating the effectiveness of the I2E dataset in learning strong imagerepresentations.</description><author>Wentao Wu, Aleksei Timofeev, Chen Chen, Bowen Zhang, Kun Duan, Shuangning Liu, Yantao Zheng, Jon Shlens, Xianzhi Du, Zhe Gan, Yinfei Yang</author><pubDate>Tue, 13 Jun 2023 18:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07952v1</guid></item><item><title>Questioning the Survey Responses of Large Language Models</title><link>http://arxiv.org/abs/2306.07951v1</link><description>As large language models increase in capability, researchers have started toconduct surveys of all kinds on these models with varying scientificmotivations. In this work, we examine what we can learn from a model's surveyresponses on the basis of the well-established American Community Survey (ACS)by the U.S. Census Bureau. Evaluating more than a dozen different models,varying in size from a few hundred million to ten billion parameters, hundredsof thousands of times each on questions from the ACS, we systematicallyestablish two dominant patterns. First, smaller models have a significantposition and labeling bias, for example, towards survey responses labeled withthe letter "A". This A-bias diminishes, albeit slowly, as model size increases.Second, when adjusting for this labeling bias through randomized answerordering, models still do not trend toward US population statistics or those ofany cognizable population. Rather, models across the board trend towarduniformly random aggregate statistics over survey responses. This pattern isrobust to various different ways of prompting the model, including what is thede-facto standard. Our findings demonstrate that aggregate statistics of alanguage model's survey responses lack the signals found in human populations.This absence of statistical signal cautions about the use of survey responsesfrom large language models at present time.</description><author>Ricardo Dominguez-Olmedo, Moritz Hardt, Celestine Mendler-Dünner</author><pubDate>Tue, 13 Jun 2023 18:48:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07951v1</guid></item><item><title>Aligning Offline Metrics and Human Judgments of Value for Code Generation Models</title><link>http://arxiv.org/abs/2210.16494v2</link><description>Large language models have demonstrated great potential to assist programmersin generating code. For such human-AI pair programming scenarios, weempirically demonstrate that while generated code is most often evaluated interms of their functional correctness (i.e., whether generations pass availableunit tests), correctness does not fully capture (e.g., may underestimate) theproductivity gains these models may provide. Through a user study with N = 49experienced programmers, we show that while correctness captures high-valuegenerations, programmers still rate code that fails unit tests as valuable ifit reduces the overall effort needed to complete a coding task. Finally, wepropose a hybrid metric that combines functional correctness and syntacticsimilarity and show that it achieves a 14% stronger correlation with value andcan therefore better represent real-world gains when evaluating and comparingmodels.</description><author>Victor Dibia, Adam Fourney, Gagan Bansal, Forough Poursabzi-Sangdeh, Han Liu, Saleema Amershi</author><pubDate>Tue, 13 Jun 2023 18:45:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.16494v2</guid></item><item><title>BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information</title><link>http://arxiv.org/abs/2306.07934v1</link><description>Automated reasoning with unstructured natural text is a key requirement formany potential applications of NLP and for developing robust AI systems.Recently, Language Models (LMs) have demonstrated complex reasoning capacitieseven without any finetuning. However, existing evaluation for automatedreasoning assumes access to a consistent and coherent set of information overwhich models reason. When reasoning in the real-world, the availableinformation is frequently inconsistent or contradictory, and therefore modelsneed to be equipped with a strategy to resolve such conflicts when they arise.One widely-applicable way of resolving conflicts is to impose preferences overinformation sources (e.g., based on source credibility or information recency)and adopt the source with higher preference. In this paper, we formulate theproblem of reasoning with contradictory information guided by preferences oversources as the classical problem of defeasible reasoning, and develop a datasetcalled BoardgameQA for measuring the reasoning capacity of LMs in this setting.BoardgameQA also incorporates reasoning with implicit background knowledge, tobetter reflect reasoning problems in downstream applications. We benchmarkvarious LMs on BoardgameQA and the results reveal a significant gap in thereasoning capacity of state-of-the-art LMs on this problem, showing thatreasoning with conflicting information does not surface out-of-the-box in LMs.While performance can be improved with finetuning, it nevertheless remainspoor.</description><author>Mehran Kazemi, Quan Yuan, Deepti Bhatia, Najoung Kim, Xin Xu, Vaiva Imbrasaite, Deepak Ramachandran</author><pubDate>Tue, 13 Jun 2023 18:39:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07934v1</guid></item><item><title>Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments</title><link>http://arxiv.org/abs/2209.15090v3</link><description>It is quite challenging to ensure the safety of reinforcement learning (RL)agents in an unknown and stochastic environment under hard constraints thatrequire the system state not to reach certain specified unsafe regions. Manypopular safe RL methods such as those based on the Constrained Markov DecisionProcess (CMDP) paradigm formulate safety violations in a cost function and tryto constrain the expectation of cumulative cost under a threshold. However, itis often difficult to effectively capture and enforce hard reachability-basedsafety constraints indirectly with such constraints on safety violation costs.In this work, we leverage the notion of barrier function to explicitly encodethe hard safety constraints, and given that the environment is unknown, relaxthem to our design of \emph{generative-model-based soft barrier functions}.Based on such soft barriers, we propose a safe RL approach that can jointlylearn the environment and optimize the control policy, while effectivelyavoiding unsafe regions with safety probability optimization. Experiments on aset of examples demonstrate that our approach can effectively enforce hardsafety constraints and significantly outperform CMDP-based baseline methods insystem safe rate measured via simulations.</description><author>Yixuan Wang, Simon Sinong Zhan, Ruochen Jiao, Zhilu Wang, Wanxin Jin, Zhuoran Yang, Zhaoran Wang, Chao Huang, Qi Zhu</author><pubDate>Tue, 13 Jun 2023 18:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.15090v3</guid></item><item><title>Collaborative Machine Learning Model Building with Families Using Co-ML</title><link>http://arxiv.org/abs/2304.05444v2</link><description>Existing novice-friendly machine learning (ML) modeling tools center around asolo user experience, where a single user collects only their own data to builda model. However, solo modeling experiences limit valuable opportunities forencountering alternative ideas and approaches that can arise when learners worktogether; consequently, it often precludes encountering critical issues in MLaround data representation and diversity that can surface when differentperspectives are manifested in a group-constructed data set. To address thisissue, we created Co-ML -- a tablet-based app for learners to collaborativelybuild ML image classifiers through an end-to-end, iterative model-buildingprocess. In this paper, we illustrate the feasibility and potential richness ofcollaborative modeling by presenting an in-depth case study of a family (twochildren 11 and 14-years-old working with their parents) using Co-ML in afacilitated introductory ML activity at home. We share the Co-ML system designand contribute a discussion of how using Co-ML in a collaborative activityenabled beginners to collectively engage with dataset design considerationsunderrepresented in prior work such as data diversity, class imbalance, anddata quality. We discuss how a distributed collaborative process, in whichindividuals can take on different model-building responsibilities, provides arich context for children and adults to learn ML dataset design.</description><author>Tiffany Tseng, Jennifer King Chen, Mona Abdelrahman, Mary Beth Kery, Fred Hohman, Adriana Hilliard, R. Benjamin Shapiro</author><pubDate>Tue, 13 Jun 2023 18:37:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05444v2</guid></item><item><title>Thermodynamic AI and the fluctuation frontier</title><link>http://arxiv.org/abs/2302.06584v3</link><description>Many Artificial Intelligence (AI) algorithms are inspired by physics andemploy stochastic fluctuations. We connect these physics-inspired AI algorithmsby unifying them under a single mathematical framework that we callThermodynamic AI. Seemingly disparate algorithmic classes can be described bythis framework, for example, (1) Generative diffusion models, (2) Bayesianneural networks, (3) Monte Carlo sampling and (4) Simulated annealing. SuchThermodynamic AI algorithms are currently run on digital hardware, ultimatelylimiting their scalability and overall potential. Stochastic fluctuationsnaturally occur in physical thermodynamic systems, and such fluctuations can beviewed as a computational resource. Hence, we propose a novel computingparadigm, where software and hardware become inseparable. Our algorithmicunification allows us to identify a single full-stack paradigm, involvingThermodynamic AI hardware, that could accelerate such algorithms. We contrastThermodynamic AI hardware with quantum computing where noise is a roadblockrather than a resource. Thermodynamic AI hardware can be viewed as a novel formof computing, since it uses a novel fundamental building block. We identifystochastic bits (s-bits) and stochastic modes (s-modes) as the respectivebuilding blocks for discrete and continuous Thermodynamic AI hardware. Inaddition to these stochastic units, Thermodynamic AI hardware employs aMaxwell's demon device that guides the system to produce non-trivial states. Weprovide a few simple physical architectures for building these devices and wedevelop a formalism for programming the hardware via gate sequences. We hope tostimulate discussion around this new computing paradigm. Beyond acceleration,we believe it will impact the design of both hardware and algorithms, whilealso deepening our understanding of the connection between physics andintelligence.</description><author>Patrick J. Coles, Collin Szczepanski, Denis Melanson, Kaelan Donatella, Antonio J. Martinez, Faris Sbahi</author><pubDate>Tue, 13 Jun 2023 18:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06584v3</guid></item><item><title>Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach</title><link>http://arxiv.org/abs/2110.04514v2</link><description>We target open-world feature extrapolation problem where the feature space ofinput data goes through expansion and a model trained on partially observedfeatures needs to handle new features in test data without further retraining.The problem is of much significance for dealing with features incrementallycollected from different fields. To this end, we propose a new learningparadigm with graph representation and learning. Our framework contains twomodules: 1) a backbone network (e.g., feedforward neural nets) as a lower modeltakes features as input and outputs predicted labels; 2) a graph neural networkas an upper model learns to extrapolate embeddings for new features via messagepassing over a feature-data graph built from observed data. Based on ourframework, we design two training strategies, a self-supervised approach and aninductive learning approach, to endow the model with extrapolation ability andalleviate feature-level over-fitting. We also provide theoretical analysis onthe generalization error on test data with new features, which dissects theimpact of training features and algorithms on generalization performance. Ourexperiments over several classification datasets and large-scale advertisementclick prediction datasets demonstrate that our model can produce effectiveembeddings for unseen features and significantly outperforms baseline methodsthat adopt KNN and local aggregation.</description><author>Qitian Wu, Chenxiao Yang, Junchi Yan</author><pubDate>Tue, 13 Jun 2023 18:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.04514v2</guid></item><item><title>Oracle-Efficient Pessimism: Offline Policy Optimization in Contextual Bandits</title><link>http://arxiv.org/abs/2306.07923v1</link><description>We consider policy optimization in contextual bandits, where one is given afixed dataset of logged interactions. While pessimistic regularizers aretypically used to mitigate distribution shift, prior implementations thereofare not computationally efficient. We present the first oracle-efficientalgorithm for pessimistic policy optimization: it reduces to supervisedlearning, leading to broad applicability. We also obtain best-effortstatistical guarantees analogous to those for pessimistic approaches in priorwork. We instantiate our approach for both discrete and continuous actions. Weperform extensive experiments in both settings, showing advantage overunregularized policy optimization across a wide range of configurations.</description><author>Lequn Wang, Akshay Krishnamurthy, Aleksandrs Slivkins</author><pubDate>Tue, 13 Jun 2023 18:29:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07923v1</guid></item><item><title>Multi-Task Training with In-Domain Language Models for Diagnostic Reasoning</title><link>http://arxiv.org/abs/2306.04551v2</link><description>Generative artificial intelligence (AI) is a promising direction foraugmenting clinical diagnostic decision support and reducing diagnostic errors,a leading contributor to medical errors. To further the development of clinicalAI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as acomprehensive generative AI framework, comprised of six tasks representing keycomponents in clinical reasoning. We present a comparative analysis ofin-domain versus out-of-domain language models as well as multi-task versussingle task training with a focus on the problem summarization task in DR.BENCH(Gao et al., 2023). We demonstrate that a multi-task, clinically trainedlanguage model outperforms its general domain counterpart by a large margin,establishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.This research underscores the value of domain-specific training for optimizingclinical diagnostic reasoning tasks.</description><author>Brihat Sharma, Yanjun Gao, Timothy Miller, Matthew M. Churpek, Majid Afshar, Dmitriy Dligach</author><pubDate>Tue, 13 Jun 2023 18:28:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04551v2</guid></item><item><title>Continuous Cost Aggregation for Dual-Pixel Disparity Extraction</title><link>http://arxiv.org/abs/2306.07921v1</link><description>Recent works have shown that depth information can be obtained fromDual-Pixel (DP) sensors. A DP arrangement provides two views in a single shot,thus resembling a stereo image pair with a tiny baseline. However, thedifferent point spread function (PSF) per view, as well as the small disparityrange, makes the use of typical stereo matching algorithms problematic. Toaddress the above shortcomings, we propose a Continuous Cost Aggregation (CCA)scheme within a semi-global matching framework that is able to provide accuratecontinuous disparities from DP images. The proposed algorithm fits parabolas tomatching costs and aggregates parabola coefficients along image paths. Theaggregation step is performed subject to a quadratic constraint that not onlyenforces the disparity smoothness but also maintains the quadratic form of thetotal costs. This gives rise to an inherently efficient disparity propagationscheme with a pixel-wise minimization in closed-form. Furthermore, thecontinuous form allows for a robust multi-scale aggregation that bettercompensates for the varying PSF. Experiments on DP data from both DSLR andphone cameras show that the proposed scheme attains state-of-the-artperformance in DP disparity estimation.</description><author>Sagi Monin, Sagi Katz, Georgios Evangelidis</author><pubDate>Tue, 13 Jun 2023 18:26:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07921v1</guid></item><item><title>Skill Disentanglement for Imitation Learning from Suboptimal Demonstrations</title><link>http://arxiv.org/abs/2306.07919v1</link><description>Imitation learning has achieved great success in many sequentialdecision-making tasks, in which a neural agent is learned by imitatingcollected human demonstrations. However, existing algorithms typically requirea large number of high-quality demonstrations that are difficult and expensiveto collect. Usually, a trade-off needs to be made between demonstration qualityand quantity in practice. Targeting this problem, in this work we consider theimitation of sub-optimal demonstrations, with both a small clean demonstrationset and a large noisy set. Some pioneering works have been proposed, but theysuffer from many limitations, e.g., assuming a demonstration to be of the sameoptimality throughout time steps and failing to provide any interpretationw.r.t knowledge learned from the noisy set. Addressing these problems, wepropose {\method} by evaluating and imitating at the sub-demonstration level,encoding action primitives of varying quality into different skills.Concretely, {\method} consists of a high-level controller to discover skillsand a skill-conditioned module to capture action-taking policies, and istrained following a two-phase pipeline by first discovering skills with alldemonstrations and then adapting the controller to only the clean set. Amutual-information-based regularization and a dynamic sub-demonstrationoptimality estimator are designed to promote disentanglement in the skillspace. Extensive experiments are conducted over two gym environments and areal-world healthcare dataset to demonstrate the superiority of {\method} inlearning from sub-optimal demonstrations and its improved interpretability byexamining learned skills.</description><author>Tianxiang Zhao, Wenchao Yu, Suhang Wang, Lu Wang, Xiang Zhang, Yuncong Chen, Yanchi Liu, Wei Cheng, Haifeng Chen</author><pubDate>Tue, 13 Jun 2023 18:24:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07919v1</guid></item><item><title>Causal Mediation Analysis with Multi-dimensional and Indirectly Observed Mediators</title><link>http://arxiv.org/abs/2306.07918v1</link><description>Causal mediation analysis (CMA) is a powerful method to dissect the totaleffect of a treatment into direct and mediated effects within the potentialoutcome framework. This is important in many scientific applications toidentify the underlying mechanisms of a treatment effect. However, in manyscientific applications the mediator is unobserved, but there may exist relatedmeasurements. For example, we may want to identify how changes in brainactivity or structure mediate an antidepressant's effect on behavior, but wemay only have access to electrophysiological or imaging brain measurements. Todate, most CMA methods assume that the mediator is one-dimensional andobservable, which oversimplifies such real-world scenarios. To overcome thislimitation, we introduce a CMA framework that can handle complex and indirectlyobserved mediators based on the identifiable variational autoencoder (iVAE)architecture. We prove that the true joint distribution over observed andlatent variables is identifiable with the proposed method. Additionally, ourframework captures a disentangled representation of the indirectly observedmediator and yields accurate estimation of the direct and mediated effects insynthetic and semi-synthetic experiments, providing evidence of its potentialutility in real-world applications.</description><author>Ziyang Jiang, Yiling Liu, Michael H. Klein, Ahmed Aloui, Yiman Ren, Keyu Li, Vahid Tarokh, David Carlson</author><pubDate>Tue, 13 Jun 2023 18:22:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07918v1</guid></item><item><title>Identification of Nonlinear Latent Hierarchical Models</title><link>http://arxiv.org/abs/2306.07916v1</link><description>Identifying latent variables and causal structures from observational data isessential to many real-world applications involving biological data, medicaldata, and unstructured data such as images and languages. However, this taskcan be highly challenging, especially when observed variables are generated bycausally related latent variables and the relationships are nonlinear. In thiswork, we investigate the identification problem for nonlinear latenthierarchical causal models in which observed variables are generated by a setof causally related latent variables, and some latent variables may not haveobserved children. We show that the identifiability of both causal structureand latent variables can be achieved under mild assumptions: on causalstructures, we allow for the existence of multiple paths between any pair ofvariables in the graph, which relaxes latent tree assumptions in prior work; onstructural functions, we do not make parametric assumptions, thus permittinggeneral nonlinearity and multi-dimensional continuous variables. Specifically,we first develop a basic identification criterion in the form of novelidentifiability guarantees for an elementary latent variable model. Leveragingthis criterion, we show that both causal structures and latent variables of thehierarchical model can be identified asymptotically by explicitly constructingan estimation procedure. To the best of our knowledge, our work is the first toestablish identifiability guarantees for both causal structures and latentvariables in nonlinear latent hierarchical models.</description><author>Lingjing Kong, Biwei Huang, Feng Xie, Eric Xing, Yuejie Chi, Kun Zhang</author><pubDate>Tue, 13 Jun 2023 18:19:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07916v1</guid></item><item><title>Image Captioners Are Scalable Vision Learners Too</title><link>http://arxiv.org/abs/2306.07915v1</link><description>Contrastive pretraining on image-text pairs from the web is one of the mostpopular large-scale pretraining strategies for vision backbones, especially inthe context of large multimodal models. At the same time, image captioning onthis type of data is commonly considered an inferior pretraining strategy. Inthis paper, we perform a fair comparison of these two pretraining strategies,carefully matching training data, compute, and model capacity. Using a standardencoder-decoder transformer, we find that captioning alone is surprisinglyeffective: on classification tasks, captioning produces vision encoderscompetitive with contrastively pretrained encoders, while surpassing them onvision &amp; language tasks. We further analyze the effect of the modelarchitecture and scale, as well as the pretraining data on the representationquality, and find that captioning exhibits the same or better scaling behavioralong these axes. Overall our results show that plain image captioning is amore powerful pretraining strategy than was previously believed.</description><author>Michael Tschannen, Manoj Kumar, Andreas Steiner, Xiaohua Zhai, Neil Houlsby, Lucas Beyer</author><pubDate>Tue, 13 Jun 2023 18:18:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07915v1</guid></item><item><title>DAPPER: Label-Free Performance Estimation after Personalization for Heterogeneous Mobile Sensing</title><link>http://arxiv.org/abs/2111.11053v2</link><description>Many applications utilize sensors in mobile devices and machine learning toprovide novel services. However, various factors such as different users,devices, and environments impact the performance of such applications, thusmaking the domain shift (i.e., distributional shift between the training domainand the target domain) a critical issue in mobile sensing. Despite attempts indomain adaptation to solve this challenging problem, their performance isunreliable due to the complex interplay among diverse factors. In principle,the performance uncertainty can be identified and redeemed by performancevalidation with ground-truth labels. However, it is infeasible for every userto collect high-quality, sufficient labeled data. To address the issue, wepresent DAPPER (Domain AdaPtation Performance EstimatoR) that estimates theadaptation performance in a target domain with only unlabeled target data. Ourkey idea is to approximate the model performance based on the mutualinformation between the model inputs and corresponding outputs. Our evaluationwith four real-world sensing datasets compared against six baselines shows thaton average, DAPPER outperforms the state-of-the-art baseline by 39.8% inestimation accuracy. Moreover, our on-device experiment shows that DAPPERachieves up to 396X less computation overhead compared with the baselines.</description><author>Taesik Gong, Yewon Kim, Adiba Orzikulova, Yunxin Liu, Sung Ju Hwang, Jinwoo Shin, Sung-Ju Lee</author><pubDate>Tue, 13 Jun 2023 18:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.11053v2</guid></item><item><title>WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences</title><link>http://arxiv.org/abs/2306.07906v1</link><description>We present WebGLM, a web-enhanced question-answering system based on theGeneral Language Model (GLM). Its goal is to augment a pre-trained largelanguage model (LLM) with web search and retrieval capabilities while beingefficient for real-world deployments. To achieve this, we develop WebGLM withstrategies for the LLM-augmented retriever, bootstrapped generator, and humanpreference-aware scorer. Specifically, we identify and address the limitationsof WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency,and cost-effectiveness advantages. In addition, we propose systematic criteriafor evaluating web-enhanced QA systems. We conduct multi-dimensional humanevaluation and quantitative ablation studies, which suggest the outperformanceof the proposed WebGLM designs over existing systems. WebGLM with the10-billion-parameter GLM (10B) is shown to perform better than thesimilar-sized WebGPT (13B) and even comparably to WebGPT (175B) in humanevaluation. The code, demo, and data are at\url{https://github.com/THUDM/WebGLM}.</description><author>Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng Zhang, Yuxiao Dong, Jie Tang</author><pubDate>Tue, 13 Jun 2023 17:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07906v1</guid></item><item><title>Omega: Optimistic EMA Gradients</title><link>http://arxiv.org/abs/2306.07905v1</link><description>Stochastic min-max optimization has gained interest in the machine learningcommunity with the advancements in GANs and adversarial training. Although gameoptimization is fairly well understood in the deterministic setting, someissues persist in the stochastic regime. Recent work has shown that stochasticgradient descent-ascent methods such as the optimistic gradient are highlysensitive to noise or can fail to converge. Although alternative strategiesexist, they can be prohibitively expensive. We introduce Omega, a method withoptimistic-like updates that mitigates the impact of noise by incorporating anEMA of historic gradients in its update rule. We also explore a variation ofthis algorithm that incorporates momentum. Although we do not provideconvergence guarantees, our experiments on stochastic games show that Omegaoutperforms the optimistic gradient method when applied to linear players.</description><author>Juan Ramirez, Rohan Sukumaran, Quentin Bertrand, Gauthier Gidel</author><pubDate>Tue, 13 Jun 2023 17:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07905v1</guid></item><item><title>Tight Memory-Regret Lower Bounds for Streaming Bandits</title><link>http://arxiv.org/abs/2306.07903v1</link><description>In this paper, we investigate the streaming bandits problem, wherein thelearner aims to minimize regret by dealing with online arriving arms andsublinear arm memory. We establish the tight worst-case regret lower bound of$\Omega \left( (TB)^{\alpha} K^{1-\alpha}\right), \alpha = 2^{B} / (2^{B+1}-1)$for any algorithm with a time horizon $T$, number of arms $K$, and number ofpasses $B$. The result reveals a separation between the stochastic banditsproblem in the classical centralized setting and the streaming setting withbounded arm memory. Notably, in comparison to the well-known$\Omega(\sqrt{KT})$ lower bound, an additional double logarithmic factor isunavoidable for any streaming bandits algorithm with sublinear memorypermitted. Furthermore, we establish the first instance-dependent lower boundof $\Omega \left(T^{1/(B+1)} \sum_{\Delta_x&gt;0} \frac{\mu^*}{\Delta_x}\right)$for streaming bandits. These lower bounds are derived through a uniquereduction from the regret-minimization setting to the sample complexityanalysis for a sequence of $\epsilon$-optimal arms identification tasks, whichmaybe of independent interest. To complement the lower bound, we also provide amulti-pass algorithm that achieves a regret upper bound of $\tilde{O} \left((TB)^{\alpha} K^{1 - \alpha}\right)$ using constant arm memory.</description><author>Shaoang Li, Lan Zhang, Junhao Wang, Xiang-Yang Li</author><pubDate>Tue, 13 Jun 2023 17:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07903v1</guid></item><item><title>Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark</title><link>http://arxiv.org/abs/2306.07902v1</link><description>Despite impressive advancements in multilingual corpora collection and modeltraining, developing large-scale deployments of multilingual models stillpresents a significant challenge. This is particularly true for language tasksthat are culture-dependent. One such example is the area of multilingualsentiment analysis, where affective markers can be subtle and deeply ensconcedin culture. This work presents the most extensive open massively multilingualcorpus of datasets for training sentiment models. The corpus consists of 79manually selected datasets from over 350 datasets reported in the scientificliterature based on strict quality criteria. The corpus covers 27 languagesrepresenting 6 language families. Datasets can be queried using severallinguistic and functional features. In addition, we present a multi-facetedsentiment classification benchmark summarizing hundreds of experimentsconducted on different base models, training objectives, dataset collections,and fine-tuning strategies.</description><author>Łukasz Augustyniak, Szymon Woźniak, Marcin Gruza, Piotr Gramacki, Krzysztof Rajda, Mikołaj Morzy, Tomasz Kajdanowicz</author><pubDate>Tue, 13 Jun 2023 17:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07902v1</guid></item><item><title>Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks</title><link>http://arxiv.org/abs/2306.07899v1</link><description>Large language models (LLMs) are remarkable data annotators. They can be usedto generate high-fidelity supervised training data, as well as survey andexperimental data. With the widespread adoption of LLMs, human gold--standardannotations are key to understanding the capabilities of LLMs and the validityof their results. However, crowdsourcing, an important, inexpensive way toobtain human annotations, may itself be impacted by LLMs, as crowd workers havefinancial incentives to use LLMs to increase their productivity and income. Toinvestigate this concern, we conducted a case study on the prevalence of LLMusage by crowd workers. We reran an abstract summarization task from theliterature on Amazon Mechanical Turk and, through a combination of keystrokedetection and synthetic text classification, estimate that 33-46% of crowdworkers used LLMs when completing the task. Although generalization to other,less LLM-friendly tasks is unclear, our results call for platforms,researchers, and crowd workers to find new ways to ensure that human dataremain human, perhaps using the methodology proposed here as a stepping stone.Code/data: https://github.com/epfl-dlab/GPTurk</description><author>Veniamin Veselovsky, Manoel Horta Ribeiro, Robert West</author><pubDate>Tue, 13 Jun 2023 17:46:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07899v1</guid></item><item><title>Contextualized Semantic Distance between Highly Overlapped Texts</title><link>http://arxiv.org/abs/2110.01176v3</link><description>Overlapping frequently occurs in paired texts in natural language processingtasks like text editing and semantic similarity evaluation. Better evaluationof the semantic distance between the overlapped sentences benefits the languagesystem's understanding and guides the generation. Since conventional semanticmetrics are based on word representations, they are vulnerable to thedisturbance of overlapped components with similar representations. This paperaims to address the issue with a mask-and-predict strategy. We take the wordsin the longest common sequence (LCS) as neighboring words and use maskedlanguage modeling (MLM) from pre-trained language models (PLMs) to predict thedistributions on their positions. Our metric, Neighboring DistributionDivergence (NDD), represent the semantic distance by calculating the divergencebetween distributions in the overlapped parts. Experiments on Semantic TextualSimilarity show NDD to be more sensitive to various semantic differences,especially on highly overlapped paired texts. Based on the discovery, wefurther implement an unsupervised and training-free method for textcompression, leading to a significant improvement on the previousperplexity-based method. The high scalability of our method even enables NDD tooutperform the supervised state-of-the-art in domain adaption by a huge margin.Further experiments on syntax and semantics analyses verify the awareness ofinternal sentence structures, indicating the high potential of NDD for furtherstudies.</description><author>Letian Peng, Zuchao Li, Hai Zhao</author><pubDate>Tue, 13 Jun 2023 17:46:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.01176v3</guid></item><item><title>Fischer-Schultz Lecture: Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments, with an Application to Immunization in India</title><link>http://arxiv.org/abs/1712.04802v7</link><description>We propose strategies to estimate and make inference on key features ofheterogeneous effects in randomized experiments. These key features includebest linear predictors of the effects using machine learning proxies, averageeffects sorted by impact groups, and average characteristics of most and leastimpacted units. The approach is valid in high dimensional settings, where theeffects are proxied (but not necessarily consistently estimated) by predictiveand causal machine learning methods. We post-process these proxies intoestimates of the key features. Our approach is generic, it can be used inconjunction with penalized methods, neural networks, random forests, boostedtrees, and ensemble methods, both predictive and causal. Estimation andinference are based on repeated data splitting to avoid overfitting and achievevalidity. We use quantile aggregation of the results across many potentialsplits, in particular taking medians of p-values and medians and otherquantiles of confidence intervals. We show that quantile aggregation lowersestimation risks over a single split procedure, and establish its principalinferential properties. Finally, our analysis reveals ways to build provablybetter machine learning proxies through causal learning: we can use theobjective functions that we develop to construct the best linear predictors ofthe effects, to obtain better machine learning proxies in the initial step. Weillustrate the use of both inferential tools and causal learners with arandomized field experiment that evaluates a combination of nudges to stimulatedemand for immunization in India.</description><author>Victor Chernozhukov, Mert Demirer, Esther Duflo, Iván Fernández-Val</author><pubDate>Tue, 13 Jun 2023 17:41:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1712.04802v7</guid></item><item><title>iSLAM: Imperative SLAM</title><link>http://arxiv.org/abs/2306.07894v1</link><description>Simultaneous localization and mapping (SLAM) stands as one of the criticalchallenges in robot navigation. Recent advancements suggest that methods basedon supervised learning deliver impressive performance in front-end odometry,while traditional optimization-based methods still play a vital role in theback-end for minimizing estimation drift. In this paper, we found that suchdecoupled paradigm can lead to only sub-optimal performance, consequentlycurtailing system capabilities and generalization potential. To solve thisproblem, we proposed a novel self-supervised learning framework, imperativeSLAM (iSLAM), which fosters reciprocal correction between the front-end andback-end, thus enhancing performance without necessitating any externalsupervision. Specifically, we formulate a SLAM system as a bi-leveloptimization problem so that the two components are bidirectionally connected.As a result, the front-end model is able to learn global geometric knowledgeobtained through pose graph optimization by back-propagating the residuals fromthe back-end. This significantly improves the generalization ability of theentire system and thus achieves the accuracy improvement up to 45%. To the bestof our knowledge, iSLAM is the first SLAM system showing that the front-end andback-end can learn jointly and mutually contribute to each other in aself-supervised manner.</description><author>Taimeng Fu, Shaoshu Su, Chen Wang</author><pubDate>Tue, 13 Jun 2023 17:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07894v1</guid></item><item><title>Robustly Learning a Single Neuron via Sharpness</title><link>http://arxiv.org/abs/2306.07892v1</link><description>We study the problem of learning a single neuron with respect to the$L_2^2$-loss in the presence of adversarial label noise. We give an efficientalgorithm that, for a broad family of activations including ReLUs, approximatesthe optimal $L_2^2$-error within a constant factor. Our algorithm applies undermuch milder distributional assumptions compared to prior work. The keyingredient enabling our results is a novel connection to local error boundsfrom optimization theory.</description><author>Puqian Wang, Nikos Zarifis, Ilias Diakonikolas, Jelena Diakonikolas</author><pubDate>Tue, 13 Jun 2023 17:34:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07892v1</guid></item><item><title>VISION Datasets: A Benchmark for Vision-based InduStrial InspectiON</title><link>http://arxiv.org/abs/2306.07890v1</link><description>Despite progress in vision-based inspection algorithms, real-world industrialchallenges -- specifically in data availability, quality, and complexproduction requirements -- often remain under-addressed. We introduce theVISION Datasets, a diverse collection of 14 industrial inspection datasets,uniquely poised to meet these challenges. Unlike previous datasets, VISIONbrings versatility to defect detection, offering annotation masks across allsplits and catering to various detection methodologies. Our datasets alsofeature instance-segmentation annotation, enabling precise defectidentification. With a total of 18k images encompassing 44 defect types, VISIONstrives to mirror a wide range of real-world production scenarios. Bysupporting two ongoing challenge competitions on the VISION Datasets, we hopeto foster further advancements in vision-based industrial inspection.</description><author>Haoping Bai, Shancong Mou, Tatiana Likhomanenko, Ramazan Gokberk Cinbis, Oncel Tuzel, Ping Huang, Jiulong Shan, Jianjun Shi, Meng Cao</author><pubDate>Tue, 13 Jun 2023 17:31:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07890v1</guid></item><item><title>Symmetry &amp; Critical Points for Symmetric Tensor Decompositions Problems</title><link>http://arxiv.org/abs/2306.07886v1</link><description>We consider the non-convex optimization problem associated with thedecomposition of a real symmetric tensor into a sum of rank one terms. Use ismade of the rich symmetry structure to derive Puiseux series representations offamilies of critical points, and so obtain precise analytic estimates on thecritical values and the Hessian spectrum. The sharp results make possible ananalytic characterization of various geometric obstructions to localoptimization methods, revealing in particular a complex array of saddles andlocal minima which differ by their symmetry, structure and analytic properties.A desirable phenomenon, occurring for all critical points considered, concernsthe index of a point, i.e., the number of negative Hessian eigenvalues,increasing with the value of the objective function. Lastly, a Newton polytopeargument is used to give a complete enumeration of all critical points of fixedsymmetry, and it is shown that contrarily to the set of global minima whichremains invariant under different choices of tensor norms, certain families ofnon-global minima emerge, others disappear.</description><author>Yossi Arjevani, Gal Vinograd</author><pubDate>Tue, 13 Jun 2023 17:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07886v1</guid></item><item><title>Temporal Gradient Inversion Attacks with Robust Optimization</title><link>http://arxiv.org/abs/2306.07883v1</link><description>Federated Learning (FL) has emerged as a promising approach for collaborativemodel training without sharing private data. However, privacy concernsregarding information exchanged during FL have received significant researchattention. Gradient Inversion Attacks (GIAs) have been proposed to reconstructthe private data retained by local clients from the exchanged gradients. Whilerecovering private data, the data dimensions and the model complexity increase,which thwart data reconstruction by GIAs. Existing methods adopt priorknowledge about private data to overcome those challenges. In this paper, wefirst observe that GIAs with gradients from a single iteration fail toreconstruct private data due to insufficient dimensions of leaked gradients,complex model architectures, and invalid gradient information. We investigate aTemporal Gradient Inversion Attack with a Robust Optimization framework, calledTGIAs-RO, which recovers private data without any prior knowledge by leveragingmultiple temporal gradients. To eliminate the negative impacts of outliers,e.g., invalid gradients for collaborative optimization, robust statistics areproposed. Theoretical guarantees on the recovery performance and robustness ofTGIAs-RO against invalid gradients are also provided. Extensive empiricalresults on MNIST, CIFAR10, ImageNet and Reuters 21578 datasets show that theproposed TGIAs-RO with 10 temporal gradients improves reconstructionperformance compared to state-of-the-art methods, even for large batch sizes(up to 128), complex models like ResNet18, and large datasets like ImageNet(224*224 pixels). Furthermore, the proposed attack method inspires furtherexploration of privacy-preserving methods in the context of FL.</description><author>Bowen Li, Hanlin Gu, Ruoxin Chen, Jie Li, Chentao Wu, Na Ruan, Xueming Si, Lixin Fan</author><pubDate>Tue, 13 Jun 2023 17:21:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07883v1</guid></item><item><title>Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data</title><link>http://arxiv.org/abs/2306.07881v1</link><description>We present Viewset Diffusion: a framework for training image-conditioned 3Dgenerative models from 2D data. Image-conditioned 3D generative models allow usto address the inherent ambiguity in single-view 3D reconstruction. Given oneimage of an object, there is often more than one possible 3D volume thatmatches the input image, because a single image never captures all sides of anobject. Deterministic models are inherently limited to producing one possiblereconstruction and therefore make mistakes in ambiguous settings. Modellingdistributions of 3D shapes is challenging because 3D ground truth data is oftennot available. We propose to solve the issue of data availability by training adiffusion model which jointly denoises a multi-view image set.We constrain theoutput of Viewset Diffusion models to a single 3D volume per image set,guaranteeing consistent geometry. Training is done through reconstructionlosses on renderings, allowing training with only three images per object. Ourdesign of architecture and training scheme allows our model to perform 3Dgeneration and generative, ambiguity-aware single-view reconstruction in afeed-forward manner. Project page: szymanowiczs.github.io/viewset-diffusion.</description><author>Stanislaw Szymanowicz, Christian Rupprecht, Andrea Vedaldi</author><pubDate>Tue, 13 Jun 2023 17:18:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07881v1</guid></item><item><title>MACARONS: Mapping And Coverage Anticipation with RGB Online Self-Supervision</title><link>http://arxiv.org/abs/2303.03315v2</link><description>We introduce a method that simultaneously learns to explore new largeenvironments and to reconstruct them in 3D from color images only. This isclosely related to the Next Best View problem (NBV), where one has to identifywhere to move the camera next to improve the coverage of an unknown scene.However, most of the current NBV methods rely on depth sensors, need 3Dsupervision and/or do not scale to large scenes. Our method requires only acolor camera and no 3D supervision. It simultaneously learns in aself-supervised fashion to predict a "volume occupancy field" from color imagesand, from this field, to predict the NBV. Thanks to this approach, our methodperforms well on new scenes as it is not biased towards any training 3D data.We demonstrate this on a recent dataset made of various 3D scenes and show itperforms even better than recent methods requiring a depth sensor, which is nota realistic assumption for outdoor scenes captured with a flying drone.</description><author>Antoine Guédon, Tom Monnier, Pascal Monasse, Vincent Lepetit</author><pubDate>Tue, 13 Jun 2023 17:16:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03315v2</guid></item><item><title>Rethinking pose estimation in crowds: overcoming the detection information-bottleneck and ambiguity</title><link>http://arxiv.org/abs/2306.07879v1</link><description>Frequent interactions between individuals are a fundamental challenge forpose estimation algorithms. Current pipelines either use an object detectortogether with a pose estimator (top-down approach), or localize all body partsfirst and then link them to predict the pose of individuals (bottom-up). Yet,when individuals closely interact, top-down methods are ill-defined due tooverlapping individuals, and bottom-up methods often falsely infer connectionsto distant body parts. Thus, we propose a novel pipeline called bottom-upconditioned top-down pose estimation (BUCTD) that combines the strengths ofbottom-up and top-down methods. Specifically, we propose to use a bottom-upmodel as the detector, which in addition to an estimated bounding box providesa pose proposal that is fed as condition to an attention-based top-down model.We demonstrate the performance and efficiency of our approach on animal andhuman pose estimation benchmarks. On CrowdPose and OCHuman, we outperformprevious state-of-the-art models by a significant margin. We achieve 78.5 AP onCrowdPose and 47.2 AP on OCHuman, an improvement of 8.6% and 4.9% over theprior art, respectively. Furthermore, we show that our method has excellentperformance on non-crowded datasets such as COCO, and strongly improves theperformance on multi-animal benchmarks involving mice, fish and monkeys.</description><author>Mu Zhou, Lucas Stoffl, Mackenzie Mathis, Alexander Mathis</author><pubDate>Tue, 13 Jun 2023 17:14:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07879v1</guid></item><item><title>ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support Lateral Reading</title><link>http://arxiv.org/abs/2306.07875v1</link><description>With the rapid growth and spread of online misinformation, people need toolsto help them evaluate the credibility and accuracy of online information.Lateral reading, a strategy that involves cross-referencing information withmultiple sources, may be an effective approach to achieving this goal. In thispaper, we present ReadProbe, a tool to support lateral reading, powered bygenerative large language models from OpenAI and the Bing search engine. Ourtool is able to generate useful questions for lateral reading, scour the webfor relevant documents, and generate well-attributed answers to help peoplebetter evaluate online information. We made a web-based application todemonstrate how ReadProbe can help reduce the risk of being misled by falseinformation. The code is available athttps://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool wonthe first prize in a national AI misinformation hackathon.</description><author>Dake Zhang, Ronak Pradeep</author><pubDate>Tue, 13 Jun 2023 17:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07875v1</guid></item><item><title>Nonparametric extensions of randomized response for private confidence sets</title><link>http://arxiv.org/abs/2202.08728v3</link><description>This work derives methods for performing nonparametric, nonasymptoticstatistical inference for population means under the constraint of localdifferential privacy (LDP). Given bounded observations $(X_1, \dots, X_n)$ withmean $\mu^\star$ that are privatized into $(Z_1, \dots, Z_n)$, we presentconfidence intervals (CI) and time-uniform confidence sequences (CS) for$\mu^\star$ when only given access to the privatized data. To achieve this, weintroduce a nonparametric and sequentially interactive generalization ofWarner's famous ``randomized response'' mechanism, satisfying LDP for arbitrarybounded random variables, and then provide CIs and CSs for their means givenaccess to the resulting privatized observations. For example, our results yieldprivate analogues of Hoeffding's inequality in both fixed-time and time-uniformregimes. We extend these Hoeffding-type CSs to capture time-varying(non-stationary) means, and conclude by illustrating how these methods can beused to conduct private online A/B tests.</description><author>Ian Waudby-Smith, Zhiwei Steven Wu, Aaditya Ramdas</author><pubDate>Tue, 13 Jun 2023 17:04:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.08728v3</guid></item><item><title>Taxonomy-Structured Domain Adaptation</title><link>http://arxiv.org/abs/2306.07874v1</link><description>Domain adaptation aims to mitigate distribution shifts among differentdomains. However, traditional formulations are mostly limited to categoricaldomains, greatly simplifying nuanced domain relationships in the real world. Inthis work, we tackle a generalization with taxonomy-structured domains, whichformalizes domains with nested, hierarchical similarity structures such asanimal species and product catalogs. We build on the classic adversarialframework and introduce a novel taxonomist, which competes with the adversarialdiscriminator to preserve the taxonomy information. The equilibrium recoversthe classic adversarial domain adaptation's solution if given a non-informativedomain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the rootnode) while yielding non-trivial results with other taxonomies. Empirically,our method achieves state-of-the-art performance on both synthetic andreal-world datasets with successful adaptation. Code is available athttps://github.com/Wang-ML-Lab/TSDA.</description><author>Tianyi Liu, Zihao Xu, Hao He, Guang-Yuan Hao, Guang-He Lee, Hao Wang</author><pubDate>Tue, 13 Jun 2023 17:04:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07874v1</guid></item><item><title>Hand Gesture Recognition through Reflected Infrared Light Wave Signals</title><link>http://arxiv.org/abs/2301.05955v2</link><description>In this study, we present a wireless (non-contact) gesture recognition methodusing only incoherent light wave signals reflected from a human subject. Incomparison to existing radar, light shadow, sound and camera-based sensingsystems, this technology uses a low-cost ubiquitous light source (e.g.,infrared LED) to send light towards the subject's hand performing gestures andthe reflected light is collected by a light sensor (e.g., photodetector). Thislight wave sensing system recognizes different gestures from the variations ofthe received light intensity within a 20-35cm range. The hand gesturerecognition results demonstrate up to 96% accuracy on average. The developedsystem can be utilized in numerous Human-computer Interaction (HCI)applications as a low-cost and non-contact gesture recognition technology.</description><author>Md Zobaer Islam, Li Yu, Hisham Abuella, John F. O'Hara, Christopher Crick, Sabit Ekin</author><pubDate>Tue, 13 Jun 2023 17:03:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.05955v2</guid></item><item><title>An extended physics informed neural network for preliminary analysis of parametric optimal control problems</title><link>http://arxiv.org/abs/2110.13530v2</link><description>In this work we propose an extension of physics informed supervised learningstrategies to parametric partial differential equations. Indeed, even if thelatter are indisputably useful in many applications, they can becomputationally expensive most of all in a real-time and many-query setting.Thus, our main goal is to provide a physics informed learning paradigm tosimulate parametrized phenomena in a small amount of time. The physicsinformation will be exploited in many ways, in the loss function (standardphysics informed neural networks), as an augmented input (extra featureemployment) and as a guideline to build an effective structure for the neuralnetwork (physics informed architecture). These three aspects, combinedtogether, will lead to a faster training phase and to a more accurateparametric prediction. The methodology has been tested for several equationsand also in an optimal control framework.</description><author>Nicola Demo, Maria Strazzullo, Gianluigi Rozza</author><pubDate>Tue, 13 Jun 2023 17:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.13530v2</guid></item><item><title>Synapse: Leveraging Few-Shot Exemplars for Human-Level Computer Control</title><link>http://arxiv.org/abs/2306.07863v1</link><description>This paper investigates the design of few-shot exemplars for computerautomation through prompting large language models (LLMs). While previousprompting approaches focus on self-correction, we find that well-structuredexemplars alone are sufficient for human-level performance. We present Synapse,an in-context computer control agent demonstrating human-level performance onthe MiniWob++ benchmark. Synapse consists of three main components: 1)state-conditional decomposition, which divides demonstrations into exemplarsets based on the agent's need for new environment states, enabling temporalabstraction; 2) structured prompting, which filters states and reformulatestask descriptions for each set to improve planning correctness; and 3) exemplarretrieval, which associates incoming tasks with corresponding exemplars in anexemplar database for multi-task adaptation and generalization. Synapseovercomes context length limits, reduces errors in multi-step control, andallows for more exemplars within the context. Importantly, Synapse complementsexisting prompting approaches that enhance LLMs' reasoning and planningabilities. Synapse outperforms previous methods, including behavioral cloning,reinforcement learning, finetuning, and prompting, with an average success rateof $98.5\%$ across 63 tasks in MiniWob++. Notably, Synapse relies on exemplarsfrom only 47 tasks, demonstrating effective generalization to novel tasks. Ourresults highlight the potential of in-context learning to advance theintegration of LLMs into practical tool automation.</description><author>Longtao Zheng, Rundong Wang, Bo An</author><pubDate>Tue, 13 Jun 2023 16:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07863v1</guid></item><item><title>Additive Causal Bandits with Unknown Graph</title><link>http://arxiv.org/abs/2306.07858v1</link><description>We explore algorithms to select actions in the causal bandit setting wherethe learner can choose to intervene on a set of random variables related by acausal graph, and the learner sequentially chooses interventions and observes asample from the interventional distribution. The learner's goal is to quicklyfind the intervention, among all interventions on observable variables, thatmaximizes the expectation of an outcome variable. We depart from previousliterature by assuming no knowledge of the causal graph except that latentconfounders between the outcome and its ancestors are not present. We firstshow that the unknown graph problem can be exponentially hard in the parents ofthe outcome. To remedy this, we adopt an additional additive assumption on theoutcome which allows us to solve the problem by casting it as an additivecombinatorial linear bandit problem with full-bandit feedback. We propose anovel action-elimination algorithm for this setting, show how to apply thisalgorithm to the causal bandit problem, provide sample complexity bounds, andempirically validate our findings on a suite of randomly generated causalmodels, effectively showing that one does not need to explicitly learn theparents of the outcome to identify the best intervention.</description><author>Alan Malek, Virginia Aglietti, Silvia Chiappa</author><pubDate>Tue, 13 Jun 2023 16:43:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07858v1</guid></item><item><title>Multimodal Audio-textual Architecture for Robust Spoken Language Understanding</title><link>http://arxiv.org/abs/2306.06819v2</link><description>Recent voice assistants are usually based on the cascade spoken languageunderstanding (SLU) solution, which consists of an automatic speech recognition(ASR) engine and a natural language understanding (NLU) system. Because suchapproach relies on the ASR output, it often suffers from the so-called ASRerror propagation. In this work, we investigate impacts of this ASR errorpropagation on state-of-the-art NLU systems based on pre-trained languagemodels (PLM), such as BERT and RoBERTa. Moreover, a multimodal languageunderstanding (MLU) module is proposed to mitigate SLU performance degradationcaused by errors present in the ASR transcript. The MLU benefits fromself-supervised features learned from both audio and text modalities,specifically Wav2Vec for speech and Bert/RoBERTa for language. Our MLU combinesan encoder network to embed the audio signal and a text encoder to process texttranscripts followed by a late fusion layer to fuse audio and text logits. Wefound that the proposed MLU showed to be robust towards poor quality ASRtranscripts, while the performance of BERT and RoBERTa are severelycompromised. Our model is evaluated on five tasks from three SLU datasets androbustness is tested using ASR transcripts from three ASR engines. Results showthat the proposed approach effectively mitigates the ASR error propagationproblem, surpassing the PLM models' performance across all datasets for theacademic ASR engine.</description><author>Anderson R. Avila, Mehdi Rezagholizadeh, Chao Xing</author><pubDate>Tue, 13 Jun 2023 16:41:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06819v2</guid></item><item><title>Improving the Validity of Decision Trees as Explanations</title><link>http://arxiv.org/abs/2306.06777v2</link><description>In classification and forecasting with tabular data, one often utilizestree-based models. This can be competitive with deep neural networks on tabulardata [cf. Grinsztajn et al., NeurIPS 2022, arXiv:2207.08815] and, under someconditions, explainable. The explainability depends on the depth of the treeand the accuracy in each leaf of the tree. Here, we train a low-depth tree withthe objective of minimising the maximum misclassification error across eachleaf node, and then ``suspend'' further tree-based models (e.g., trees ofunlimited depth) from each leaf of the low-depth tree. The low-depth tree iseasily explainable, while the overall statistical performance of the combinedlow-depth and suspended tree-based models improves upon decision trees ofunlimited depth trained using classical methods (e.g., CART) and is comparableto state-of-the-art methods (e.g., well-tuned XGBoost).</description><author>Jiri Nemecek, Tomas Pevny, Jakub Marecek</author><pubDate>Tue, 13 Jun 2023 16:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06777v2</guid></item><item><title>DreamDecompiler: Improved Bayesian Program Learning by Decompiling Amortised Knowledge</title><link>http://arxiv.org/abs/2306.07856v1</link><description>Solving program induction problems requires searching through an enormousspace of possibilities. DreamCoder is an inductive program synthesis systemthat, whilst solving problems, learns to simplify search in an iterativewake-sleep procedure. The cost of search is amortised by training a neuralsearch policy, reducing search breadth and effectively "compiling" usefulinformation to compose program solutions across tasks. Additionally, a libraryof program components is learnt to express discovered solutions in fewercomponents, reducing search depth. In DreamCoder, the neural search policy hasonly an indirect effect on the library learnt through the program solutions ithelps discover. We present an approach for library learning that directlyleverages the neural search policy, effectively "decompiling" its amortisedknowledge to extract relevant program components. This provides strongeramortised inference: the amortised knowledge learnt to reduce search breadth isnow also used to reduce search depth. We integrate our approach with DreamCoderand demonstrate faster domain proficiency with improved generalisation on arange of domains, particularly when fewer example solutions are available.</description><author>Alessandro B. Palmarini, Christopher G. Lucas, N. Siddharth</author><pubDate>Tue, 13 Jun 2023 16:35:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07856v1</guid></item><item><title>Show me the numbers! -- Student-facing Interventions in Adaptive Learning Environments for German Spelling</title><link>http://arxiv.org/abs/2306.07853v1</link><description>Since adaptive learning comes in many shapes and sizes, it is crucial to findout which adaptations can be meaningful for which areas of learning. Our workpresents the result of an experiment conducted on an online platform for theacquisition of German spelling skills. We compared the traditional onlinelearning platform to three different adaptive versions of the platform thatimplement machine learning-based student-facing interventions that show thepersonalized solution probability. We evaluate the different interventions withregard to the error rate, the number of early dropouts, and the userscompetency. Our results show that the number of mistakes decreased incomparison to the control group. Additionally, an increasing number of dropoutswas found. We did not find any significant effects on the users competency. Weconclude that student-facing adaptive learning environments are effective inimproving a persons error rate and should be chosen wisely to have a motivatingimpact.</description><author>Nathalie Rzepka, Katharina Simbeck, Hans-Georg Mueller, Marlene Bueltemann, Niels Pinkwart</author><pubDate>Tue, 13 Jun 2023 16:33:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07853v1</guid></item><item><title>Exact Mean Square Linear Stability Analysis for SGD</title><link>http://arxiv.org/abs/2306.07850v1</link><description>The dynamical stability of optimization methods at the vicinity of minima ofthe loss has recently attracted significant attention. For gradient descent(GD), stable convergence is possible only to minima that are sufficiently flatw.r.t. the step size, and those have been linked with favorable properties ofthe trained model. However, while the stability threshold of GD is well-known,to date, no explicit expression has been derived for the exact threshold ofstochastic GD (SGD). In this paper, we derive such a closed-form expression.Specifically, we provide an explicit condition on the step size $\eta$ that isboth necessary and sufficient for the stability of SGD in the mean squaresense. Our analysis sheds light on the precise role of the batch size $B$.Particularly, we show that the stability threshold is a monotonicallynon-decreasing function of the batch size, which means that reducing the batchsize can only hurt stability. Furthermore, we show that SGD's stabilitythreshold is equivalent to that of a process which takes in each iteration afull batch gradient step w.p. $1-p$, and a single sample gradient step w.p.$p$, where $p \approx 1/B $. This indicates that even with moderate batchsizes, SGD's stability threshold is very close to that of GD's. Finally, weprove simple necessary conditions for stability, which depend on the batchsize, and are easier to compute than the precise threshold. We demonstrate ourtheoretical findings through experiments on the MNIST dataset.</description><author>Rotem Mulayoff, Tomer Michaeli</author><pubDate>Tue, 13 Jun 2023 16:29:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07850v1</guid></item><item><title>Homophily modulates double descent generalization in graph convolution networks</title><link>http://arxiv.org/abs/2212.13069v2</link><description>Graph neural networks are among the most successful machine learning modelsfor relational datasets like metabolic, transportation, and social networks.Yet the determinants of their strong generalization for diverse interactionsencoded in the data are not well understood. Methods from statistical learningtheory do not explain emergent phenomena such as double descent or thedependence of risk on the nature of interactions. We use analytical tools fromstatistical physics and random matrix theory to precisely characterizegeneralization in simple graph convolution networks on the contextualstochastic block model. The derived curves are phenomenologically rich: theyexplain the distinction between learning on homophilic and heterophilic andthey predict double descent whose existence in GNNs has been questioned byrecent work. We show how risk depends on the interplay between the noise in thegraph, noise in the features, and the proportion of nodes used for training.Our analysis predicts qualitative behavior not only of a stylized graphlearning model but also to complex GNNs on messy real-world datasets. As a casein point, we use these analytic insights about heterophily and self-loop signsto improve performance of state-of-the-art graph convolution networks onseveral heterophilic benchmarks by a simple addition of negative self-loopfilters.</description><author>Cheng Shi, Liming Pan, Hong Hu, Ivan Dokmanić</author><pubDate>Tue, 13 Jun 2023 16:28:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.13069v2</guid></item><item><title>GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition</title><link>http://arxiv.org/abs/2306.07848v1</link><description>Contrastive Language-Audio Pretraining (CLAP) has recently exhibitedimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, akind of efficient gender-attribute-enhanced CLAP model for speech emotionrecognition (SER). Specifically, we first build an effective emotion CLAP modeltermed Emo-CLAP for SER, utilizing various self-supervised learning basedpre-trained models. Then, considering the importance of the gender attribute inspeech emotion modeling, two GEmo-CLAP approaches are further proposed tointegrate the emotion and gender information of speech signals, forming morereasonable objectives. Extensive experiments conducted on the IEMOCAP corpusdemonstrate that our proposed two GEmo-CLAP approaches consistently outperformthe baseline Emo-CLAP with different pre-trained models, while also achievingsuperior recognition performance compared with other state-of-the-art methods.</description><author>Yu Pan, Yanni Hu, Yuguang Yang, Jixun Yao, Wen Fei, Lei Ma, Heng Lu</author><pubDate>Tue, 13 Jun 2023 16:28:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07848v1</guid></item><item><title>Adversarial Capsule Networks for Romanian Satire Detection and Sentiment Analysis</title><link>http://arxiv.org/abs/2306.07845v1</link><description>Satire detection and sentiment analysis are intensively explored naturallanguage processing (NLP) tasks that study the identification of the satiricaltone from texts and extracting sentiments in relationship with their targets.In languages with fewer research resources, an alternative is to produceartificial examples based on character-level adversarial processes to overcomedataset size limitations. Such samples are proven to act as a regularizationmethod, thus improving the robustness of models. In this work, we improve thewell-known NLP models (i.e., Convolutional Neural Networks, Long Short-TermMemory (LSTM), Bidirectional LSTM, Gated Recurrent Units (GRUs), andBidirectional GRUs) with adversarial training and capsule networks. Thefine-tuned models are used for satire detection and sentiment analysis tasks inthe Romanian language. The proposed framework outperforms the existing methodsfor the two tasks, achieving up to 99.08% accuracy, thus confirming theimprovements added by the capsule layers and the adversarial training in NLPapproaches.</description><author>Sebastian-Vasile Echim, Răzvan-Alexandru Smădu, Andrei-Marius Avram, Dumitru-Clementin Cercel, Florin Pop</author><pubDate>Tue, 13 Jun 2023 16:23:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07845v1</guid></item><item><title>Additive interaction modelling using I-priors</title><link>http://arxiv.org/abs/2007.15766v4</link><description>Additive regression models with interactions are widely studied in theliterature, using methods such as splines or Gaussian process regression.However, these methods can pose challenges for estimation and model selection,due to the presence of many smoothing parameters and the lack of suitablecriteria. We propose to address these challenges by extending the I-priormethodology (Bergsma, 2020) to multiple covariates, which may bemultidimensional. The I-prior methodology has some advantages over othermethods, such as Gaussian process regression and Tikhonov regularization, boththeoretically and practically. In particular, the I-prior is a proper prior, isbased on minimal assumptions, yields an admissible posterior mean, andestimation of the scale (or smoothing) parameters can be done using an EMalgorithm with simple E and M steps. Moreover, we introduce a parsimoniousspecification of models with interactions, which has two benefits: (i) itreduces the number of scale parameters and thus facilitates the estimation ofmodels with interactions, and (ii) it enables straightforward model selection(among models with different interactions) based on the marginal likelihood.</description><author>Wicher Bergsma, Haziq Jamil</author><pubDate>Tue, 13 Jun 2023 16:22:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2007.15766v4</guid></item><item><title>Stochastic coordinate transformations with applications to robust machine learning</title><link>http://arxiv.org/abs/2110.01729v3</link><description>In this paper we introduce a set of novel features for identifying underlyingstochastic behavior of input data using the Karhunen-Loeve expansion. Thesenovel features are constructed by applying a coordinate transformation based onthe recent Functional Data Analysis theory for anomaly detection. Theassociated signal decomposition is an exact hierarchical tensor productexpansion with known optimality properties for approximating stochasticprocesses (random fields) with finite dimensional function spaces. In principlethese low dimensional spaces can capture most of the stochastic behavior of`underlying signals' in a given nominal class, and can reject signals inalternative classes as stochastic anomalies. Using a hierarchical finitedimensional expansion of the nominal class, a series of orthogonal nestedsubspaces is constructed for detecting anomalous signal components. Projectioncoefficients of input data in these subspaces are then used to train a MachineLearning (ML) classifier. However, due to the split of the signal into nominaland anomalous projection components, clearer separation surfaces of the classesarise. In fact we show that with a sufficiently accurate estimation of thecovariance structure of the nominal class, a sharp classification can beobtained. This is particularly advantageous for situations with largeunbalanced datasets. We formulate this concept and demonstrate it on a numberof high-dimensional datasets. This approach yields significant increases inaccuracy over ML methods that use the original feature data. Our tests on theAlzheimer's Disease ADNI dataset shows a dramatic increase in accuracy (from48% to 89% accuracy). Furthermore, tests from unbalanced semi-syntheticdatasets created from the GCM data confirmed increased accuracy as the datasetbecomes more unbalanced.</description><author>Julio Enrique Castrillon-Candas, Dingning Liu, Sicheng Yang, Mark Kon</author><pubDate>Tue, 13 Jun 2023 16:22:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.01729v3</guid></item><item><title>PSSTRNet: Progressive Segmentation-guided Scene Text Removal Network</title><link>http://arxiv.org/abs/2306.07842v1</link><description>Scene text removal (STR) is a challenging task due to the complex text fonts,colors, sizes, and background textures in scene images. However, most previousmethods learn both text location and background inpainting implicitly within asingle network, which weakens the text localization mechanism and makes a lossybackground. To tackle these problems, we propose a simple ProgressiveSegmentation-guided Scene Text Removal Network(PSSTRNet) to remove the text inthe image iteratively. It contains two decoder branches, a text segmentationbranch, and a text removal branch, with a shared encoder. The text segmentationbranch generates text mask maps as the guidance for the regional removalbranch. In each iteration, the original image, previous text removal result,and text mask are input to the network to extract the rest part of the textsegments and cleaner text removal result. To get a more accurate text mask map,an update module is developed to merge the mask map in the current and previousstages. The final text removal result is obtained by adaptive fusion of resultsfrom all previous stages. A sufficient number of experiments and ablationstudies conducted on the real and synthetic public datasets demonstrate ourproposed method achieves state-of-the-art performance. The source code of ourwork is available at:\href{https://github.com/GuangtaoLyu/PSSTRNet}{https://github.com/GuangtaoLyu/PSSTRNet.}</description><author>Guangtao Lyu, Anna Zhu</author><pubDate>Tue, 13 Jun 2023 16:20:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07842v1</guid></item><item><title>Gen-IR @ SIGIR 2023: The First Workshop on Generative Information Retrieval</title><link>http://arxiv.org/abs/2306.02887v2</link><description>Generative information retrieval (IR) has experienced substantial growthacross multiple research communities (e.g., information retrieval, computervision, natural language processing, and machine learning), and has been highlyvisible in the popular press. Theoretical, empirical, and actual user-facingproducts have been released that retrieve documents (via generation) ordirectly generate answers given an input request. We would like to investigatewhether end-to-end generative models are just another trend or, as some claim,a paradigm change for IR. This necessitates new metrics, theoretical grounding,evaluation methods, task definitions, models, user interfaces, etc. The goal ofthis workshop (https://coda.io/@sigir/gen-ir) is to focus on previouslyexplored Generative IR techniques like document retrieval and direct GroundedAnswer Generation, while also offering a venue for the discussion andexploration of how Generative IR can be applied to new domains likerecommendation systems, summarization, etc. The format of the workshop isinteractive, including roundtable and keynote sessions and tends to avoid theone-sided dialogue of a mini-conference.</description><author>Gabriel Bénédict, Ruqing Zhang, Donald Metzler</author><pubDate>Tue, 13 Jun 2023 16:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02887v2</guid></item><item><title>Arbitrary Shape Text Detection via Boundary Transformer</title><link>http://arxiv.org/abs/2205.05320v3</link><description>In arbitrary shape text detection, locating accurate text boundaries ischallenging and non-trivial. Existing methods often suffer from indirect textboundary modeling or complex post-processing. In this paper, we systematicallypresent a unified coarse-to-fine framework via boundary learning for arbitraryshape text detection, which can accurately and efficiently locate textboundaries without post-processing.In our method, we explicitly model the textboundary via an innovative iterative boundary transformer in a coarse-to-finemanner. In this way, our method can directly gain accurate text boundaries andabandon complex post-processing to improve efficiency. Specifically, our methodmainly consists of a feature extraction backbone, a boundary proposal module,and an iteratively optimized boundary transformer module. The boundary proposalmodule consisting of multi-layer dilated convolutions will compute importantprior information (including classification map, distance field, and directionfield) for generating coarse boundary proposals while guiding the boundarytransformer's optimization. The boundary transformer module adopts anencoder-decoder structure, in which the encoder is constructed by multi-layertransformer blocks with residual connection while the decoder is a simplemulti-layer perceptron network (MLP). Under the guidance of prior information,the boundary transformer module will gradually refine the coarse boundaryproposals via iterative boundary deformation. Furthermore, we propose a novelboundary energy loss (BEL) which introduces an energy minimization constraintand an energy monotonically decreasing constraint to further optimize andstabilize the learning of boundary refinement. Extensive experiments onpublicly available and challenging datasets demonstrate the state-of-the-artperformance and promising efficiency of our method.</description><author>Shi-Xue Zhang, Chun Yang, Xiaobin Zhu, Xu-Cheng Yin</author><pubDate>Tue, 13 Jun 2023 16:17:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.05320v3</guid></item><item><title>The Dormant Neuron Phenomenon in Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2302.12902v2</link><description>In this work we identify the dormant neuron phenomenon in deep reinforcementlearning, where an agent's network suffers from an increasing number ofinactive neurons, thereby affecting network expressivity. We demonstrate thepresence of this phenomenon across a variety of algorithms and environments,and highlight its effect on learning. To address this issue, we propose asimple and effective method (ReDo) that Recycles Dormant neurons throughouttraining. Our experiments demonstrate that ReDo maintains the expressive powerof networks by reducing the number of dormant neurons and results in improvedperformance.</description><author>Ghada Sokar, Rishabh Agarwal, Pablo Samuel Castro, Utku Evci</author><pubDate>Tue, 13 Jun 2023 16:16:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.12902v2</guid></item><item><title>PolyVoice: Language Models for Speech to Speech Translation</title><link>http://arxiv.org/abs/2306.02982v2</link><description>We propose PolyVoice, a language model-based framework for speech-to-speechtranslation (S2ST) system. Our framework consists of two language models: atranslation language model and a speech synthesis language model. We usediscretized speech units, which are generated in a fully unsupervised way, andthus our framework can be used for unwritten languages. For the speechsynthesis part, we adopt the existing VALL-E X approach and build a unit-basedaudio language model. This grants our framework the ability to preserve thevoice characteristics and the speaking style of the original speech. We examineour system on Chinese $\rightarrow$ English and English $\rightarrow$ Spanishpairs. Experimental results show that our system can generate speech with hightranslation quality and audio quality. Speech samples are available athttps://speechtranslation.github.io/polyvoice.</description><author>Qianqian Dong, Zhiying Huang, Qiao Tian, Chen Xu, Tom Ko, Yunlong Zhao, Siyuan Feng, Tang Li, Kexin Wang, Xuxin Cheng, Fengpeng Yue, Ye Bai, Xi Chen, Lu Lu, Zejun Ma, Yuping Wang, Mingxuan Wang, Yuxuan Wang</author><pubDate>Tue, 13 Jun 2023 16:15:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02982v2</guid></item><item><title>Seeing is not always believing: Benchmarking Human and Model Perception of AI-Generated Images</title><link>http://arxiv.org/abs/2304.13023v2</link><description>Photos serve as a way for humans to record what they experience in theirdaily lives, and they are often regarded as trustworthy sources of information.However, there is a growing concern that the advancement of artificialintelligence (AI) technology may produce fake photos, which can createconfusion and diminish trust in photographs. This study aims to comprehensivelyevaluate agents for distinguishing state-of-the-art AI-generated visualcontent. Our study benchmarks both human capability and cutting-edge fake imagedetection AI algorithms, using a newly collected large-scale fake image datasetFake2M. In our human perception evaluation, titled HPBench, we discovered thathumans struggle significantly to distinguish real photos from AI-generatedones, with a misclassification rate of 38.7%. Along with this, we conduct themodel capability of AI-Generated images detection evaluation MPBench and thetop-performing model from MPBench achieves a 13% failure rate under the samesetting used in the human evaluation. We hope that our study can raiseawareness of the potential risks of AI-generated images and facilitate furtherresearch to prevent the spread of false information. More information can referto https://github.com/Inf-imagine/Sentry.</description><author>Zeyu Lu, Di Huang, Lei Bai, Jingjing Qu, Chengyue Wu, Xihui Liu, Wanli Ouyang</author><pubDate>Tue, 13 Jun 2023 16:14:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13023v2</guid></item><item><title>LMD: Light-weight Prediction Quality Estimation for Object Detection in Lidar Point Clouds</title><link>http://arxiv.org/abs/2306.07835v1</link><description>Object detection on Lidar point cloud data is a promising technology forautonomous driving and robotics which has seen a significant rise inperformance and accuracy during recent years. Particularly uncertaintyestimation is a crucial component for down-stream tasks and deep neuralnetworks remain error-prone even for predictions with high confidence.Previously proposed methods for quantifying prediction uncertainty tend toalter the training scheme of the detector or rely on prediction sampling whichresults in vastly increased inference time. In order to address these twoissues, we propose LidarMetaDetect (LMD), a light-weight post-processing schemefor prediction quality estimation. Our method can easily be added to anypre-trained Lidar object detector without altering anything about the basemodel and is purely based on post-processing, therefore, only leading to anegligible computational overhead. Our experiments show a significant increaseof statistical reliability in separating true from false predictions. Wepropose and evaluate an additional application of our method leading to thedetection of annotation errors. Explicit samples and a conservative count ofannotation error proposals indicates the viability of our method forlarge-scale datasets like KITTI and nuScenes. On the widely-used nuScenes testdataset, 43 out of the top 100 proposals of our method indicate, in fact,erroneous annotations.</description><author>Tobias Riedlinger, Marius Schubert, Sarina Penquitt, Jan-Marcel Kezmann, Pascal Colling, Karsten Kahl, Lutz Roese-Koerner, Michael Arnold, Urs Zimmermann, Matthias Rottmann</author><pubDate>Tue, 13 Jun 2023 16:13:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07835v1</guid></item><item><title>Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts</title><link>http://arxiv.org/abs/2302.06495v2</link><description>Prevalent deterministic deep-learning models suffer from significantover-confidence under distribution shifts. Probabilistic approaches can reducethis problem but struggle with computational efficiency. In this paper, wepropose Density-Softmax, a fast and lightweight deterministic method to improvecalibrated uncertainty estimation via a combination of density function withthe softmax layer. By using the latent representation's likelihood value, ourapproach produces more uncertain predictions when test samples are distant fromthe training samples. Theoretically, we show that Density-Softmax can producehigh-quality uncertainty estimation with neural networks, as it is the solutionof minimax uncertainty risk and is distance-aware, thus reducing theover-confidence of the standard softmax. Empirically, our method enjoys similarcomputational efficiency as a single forward pass deterministic with standardsoftmax on the shifted toy, vision, and language datasets across moderndeep-learning architectures. Notably, Density-Softmax uses 4 times fewerparameters than Deep Ensembles and 6 times lower latency than Rank-1 BayesianNeural Network, while obtaining competitive predictive performance and lowercalibration errors under distribution shifts.</description><author>Ha Manh Bui, Anqi Liu</author><pubDate>Tue, 13 Jun 2023 16:13:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06495v2</guid></item><item><title>Fair Learning to Rank with Distribution-free Risk Control</title><link>http://arxiv.org/abs/2306.07188v2</link><description>Learning to Rank (LTR) methods are vital in online economies, affecting usersand item providers. Fairness in LTR models is crucial to allocate exposureproportionally to item relevance. The deterministic ranking model can lead tounfair exposure distribution when items with the same relevance receiveslightly different scores. Stochastic LTR models, incorporating thePlackett-Luce (PL) model, address fairness issues but have limitations incomputational cost and performance guarantees. To overcome these limitations,we propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RCleverages a pretrained scoring function to create a stochastic LTR model,eliminating the need for expensive training. Furthermore, FairLTR-RC providesfinite-sample guarantees on a user-specified utility using distribution-freerisk control framework. By additionally incorporating the Thresholded PL (TPL)model, we are able to achieve an effective trade-off between utility andfairness. Experimental results on several benchmark datasets demonstrate thatFairLTR-RC significantly improves fairness in widely-used deterministic LTRmodels while guaranteeing a specified level of utility.</description><author>Ruocheng Guo, Jean-François Ton, Yang Liu</author><pubDate>Tue, 13 Jun 2023 16:08:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07188v2</guid></item><item><title>The Nuts and Bolts of Adopting Transformer in GANs</title><link>http://arxiv.org/abs/2110.13107v3</link><description>Transformer becomes prevalent in computer vision, especially for high-levelvision tasks. However, adopting Transformer in the generative adversarialnetwork (GAN) framework is still an open yet challenging problem. In thispaper, we conduct a comprehensive empirical study to investigate the propertiesof Transformer in GAN for high-fidelity image synthesis. Our analysishighlights and reaffirms the importance of feature locality in imagegeneration, although the merits of the locality are well known in theclassification task. Perhaps more interestingly, we find the residualconnections in self-attention layers harmful for learning Transformer-baseddiscriminators and conditional generators. We carefully examine the influenceand propose effective ways to mitigate the negative impacts. Our study leads toa new alternative design of Transformers in GAN, a convolutional neural network(CNN)-free generator termed as STrans-G, which achieves competitive results inboth unconditional and conditional image generations. The Transformer-baseddiscriminator, STrans-D, also significantly reduces its gap against theCNN-based discriminators.</description><author>Rui Xu, Xiangyu Xu, Kai Chen, Bolei Zhou, Chen Change Loy</author><pubDate>Tue, 13 Jun 2023 16:07:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.13107v3</guid></item><item><title>Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images</title><link>http://arxiv.org/abs/2306.07831v1</link><description>Contrastive visual language pretraining has emerged as a powerful method foreither training new language-aware image encoders or augmenting existingpretrained models with zero-shot visual recognition capabilities. However,existing works typically train on large datasets of image-text pairs and havebeen designed to perform downstream tasks involving only small to mediumsized-images, neither of which are applicable to the emerging field ofcomputational pathology where there are limited publicly available pairedimage-text datasets and each image can span up to 100,000 x 100,000 pixels. Inthis paper we present MI-Zero, a simple and intuitive framework for unleashingthe zero-shot transfer capabilities of contrastively aligned image and textmodels on gigapixel histopathology whole slide images, enabling multipledownstream diagnostic tasks to be carried out by pretrained encoders withoutrequiring any additional labels. MI-Zero reformulates zero-shot transfer underthe framework of multiple instance learning to overcome the computationalchallenge of inference on extremely large images. We used over 550k pathologyreports and other available in-domain text corpora to pre-train our textencoder. By effectively leveraging strong pre-trained encoders, our best modelpretrained on over 33k histopathology image-caption pairs achieves an averagemedian zero-shot accuracy of 70.2% across three different real-world cancersubtyping tasks. Our code is available at:https://github.com/mahmoodlab/MI-Zero.</description><author>Ming Y. Lu, Bowen Chen, Andrew Zhang, Drew F. K. Williamson, Richard J. Chen, Tong Ding, Long Phi Le, Yung-Sung Chuang, Faisal Mahmood</author><pubDate>Tue, 13 Jun 2023 16:05:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07831v1</guid></item><item><title>Class Attribute Inference Attacks: Inferring Sensitive Class Information by Diffusion-Based Attribute Manipulations</title><link>http://arxiv.org/abs/2303.09289v2</link><description>Neural network-based image classifiers are powerful tools for computer visiontasks, but they inadvertently reveal sensitive attribute information abouttheir classes, raising concerns about their privacy. To investigate thisprivacy leakage, we introduce the first Class Attribute Inference Attack(CAIA), which leverages recent advances in text-to-image synthesis to infersensitive attributes of individual classes in a black-box setting, whileremaining competitive with related white-box attacks. Our extensive experimentsin the face recognition domain show that CAIA can accurately infer undisclosedsensitive attributes, such as an individual's hair color, gender, and racialappearance, which are not part of the training labels. Interestingly, wedemonstrate that adversarial robust models are even more vulnerable to suchprivacy leakage than standard models, indicating that a trade-off betweenrobustness and privacy exists.</description><author>Lukas Struppek, Dominik Hintersdorf, Felix Friedrich, Manuel Brack, Patrick Schramowski, Kristian Kersting</author><pubDate>Tue, 13 Jun 2023 16:00:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09289v2</guid></item><item><title>Unsupervised speech enhancement with deep dynamical generative speech and noise models</title><link>http://arxiv.org/abs/2306.07820v1</link><description>This work builds on a previous work on unsupervised speech enhancement usinga dynamical variational autoencoder (DVAE) as the clean speech model andnon-negative matrix factorization (NMF) as the noise model. We propose toreplace the NMF noise model with a deep dynamical generative model (DDGM)depending either on the DVAE latent variables, or on the noisy observations, oron both. This DDGM can be trained in three configurations: noise-agnostic,noise-dependent and noise adaptation after noise-dependent training.Experimental results show that the proposed method achieves competitiveperformance compared to state-of-the-art unsupervised speech enhancementmethods, while the noise-dependent training configuration yields a much moretime-efficient inference process.</description><author>Xiaoyu Lin, Simon Leglaive, Laurent Girin, Xavier Alameda-Pineda</author><pubDate>Tue, 13 Jun 2023 15:52:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07820v1</guid></item><item><title>A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning</title><link>http://arxiv.org/abs/2306.07818v1</link><description>Offline constrained reinforcement learning (RL) aims to learn a policy thatmaximizes the expected cumulative reward subject to constraints on expectedvalue of cost functions using an existing dataset. In this paper, we proposePrimal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrainedRL with general function approximation. PDCA runs a primal-dual algorithm onthe Lagrangian function estimated by critics. The primal player employs ano-regret policy optimization oracle to maximize the Lagrangian estimate givenany choices of the critics and the dual player. The dual player employs ano-regret online linear optimization oracle to minimize the Lagrangian estimategiven any choices of the critics and the primal player. We show that PDCA cansuccessfully find a near saddle point of the Lagrangian, which is nearlyoptimal for the constrained RL problem. Unlike previous work that requiresconcentrability and strong Bellman completeness assumptions, PDCA only requiresconcentrability and value function/marginalized importance weight realizabilityassumptions.</description><author>Kihyuk Hong, Yuhang Li, Ambuj Tewari</author><pubDate>Tue, 13 Jun 2023 15:50:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07818v1</guid></item><item><title>Automated 3D Pre-Training for Molecular Property Prediction</title><link>http://arxiv.org/abs/2306.07812v1</link><description>Molecular property prediction is an important problem in drug discovery andmaterials science. As geometric structures have been demonstrated necessary formolecular property prediction, 3D information has been combined with variousgraph learning methods to boost prediction performance. However, obtaining thegeometric structure of molecules is not feasible in many real-worldapplications due to the high computational cost. In this work, we propose anovel 3D pre-training framework (dubbed 3D PGT), which pre-trains a model on 3Dmolecular graphs, and then fine-tunes it on molecular graphs without 3Dstructures. Based on fact that bond length, bond angle, and dihedral angle arethree basic geometric descriptors corresponding to a complete molecular 3Dconformer, we first develop a multi-task generative pre-train framework basedon these three attributes. Next, to automatically fuse these three generativetasks, we design a surrogate metric using the \textit{total energy} to searchfor weight distribution of the three pretext task since total energycorresponding to the quality of 3D conformer.Extensive experiments on 2Dmolecular graphs are conducted to demonstrate the accuracy, efficiency andgeneralization ability of the proposed 3D PGT compared to various pre-trainingbaselines.</description><author>Xu Wang, Huan Zhao, Weiwei Tu, Quanming Yao</author><pubDate>Tue, 13 Jun 2023 15:43:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07812v1</guid></item><item><title>How to Trust Your Diffusion Model: A Convex Optimization Approach to Conformal Risk Control</title><link>http://arxiv.org/abs/2302.03791v2</link><description>Score-based generative modeling, informally referred to as diffusion models,continue to grow in popularity across several important domains and tasks.While they provide high-quality and diverse samples from empiricaldistributions, important questions remain on the reliability andtrustworthiness of these sampling procedures for their responsible use incritical scenarios. Conformal prediction is a modern tool to constructfinite-sample, distribution-free uncertainty guarantees for any black-boxpredictor. In this work, we focus on image-to-image regression tasks and wepresent a generalization of the Risk-Controlling Prediction Sets (RCPS)procedure, that we term $K$-RCPS, which allows to $(i)$ provide entrywisecalibrated intervals for future samples of any diffusion model, and $(ii)$control a certain notion of risk with respect to a ground truth image withminimal mean interval length. Differently from existing conformal risk controlprocedures, ours relies on a novel convex optimization approach that allows formultidimensional risk control while provably minimizing the mean intervallength. We illustrate our approach on two real-world image denoising problems:on natural images of faces as well as on computed tomography (CT) scans of theabdomen, demonstrating state of the art performance.</description><author>Jacopo Teneggi, Matthew Tivnan, J. Webster Stayman, Jeremias Sulam</author><pubDate>Tue, 13 Jun 2023 15:40:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03791v2</guid></item><item><title>Low-Resource White-Box Semantic Segmentation of Supporting Towers on 3D Point Clouds via Signature Shape Identification</title><link>http://arxiv.org/abs/2306.07809v1</link><description>Research in 3D semantic segmentation has been increasing performance metrics,like the IoU, by scaling model complexity and computational resources, leavingbehind researchers and practitioners that (1) cannot access the necessaryresources and (2) do need transparency on the model decision mechanisms. Inthis paper, we propose SCENE-Net, a low-resource white-box model for 3D pointcloud semantic segmentation. SCENE-Net identifies signature shapes on the pointcloud via group equivariant non-expansive operators (GENEOs), providingintrinsic geometric interpretability. Our training time on a laptop is 85~min,and our inference time is 20~ms. SCENE-Net has 11 trainable geometricalparameters and requires fewer data than black-box models. SCENE--Net offersrobustness to noisy labeling and data imbalance and has comparable IoU tostate-of-the-art methods. With this paper, we release a 40~000 Km labeleddataset of rural terrain point clouds and our code implementation.</description><author>Diogo Lavado, Cláudia Soares, Alessandra Micheletti, Giovanni Bocchi, Alex Coronati, Manuel Silva, Patrizio Frosini</author><pubDate>Tue, 13 Jun 2023 15:36:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07809v1</guid></item><item><title>SPARF: Neural Radiance Fields from Sparse and Noisy Poses</title><link>http://arxiv.org/abs/2211.11738v3</link><description>Neural Radiance Field (NeRF) has recently emerged as a powerfulrepresentation to synthesize photorealistic novel views. While showingimpressive performance, it relies on the availability of dense input views withhighly accurate camera poses, thus limiting its application in real-worldscenarios. In this work, we introduce Sparse Pose Adjusting Radiance Field(SPARF), to address the challenge of novel-view synthesis given only fewwide-baseline input images (as low as 3) with noisy camera poses. Our approachexploits multi-view geometry constraints in order to jointly learn the NeRF andrefine the camera poses. By relying on pixel matches extracted between theinput views, our multi-view correspondence objective enforces the optimizedscene and camera poses to converge to a global and geometrically accuratesolution. Our depth consistency loss further encourages the reconstructed sceneto be consistent from any viewpoint. Our approach sets a new state of the artin the sparse-view regime on multiple challenging datasets.</description><author>Prune Truong, Marie-Julie Rakotosaona, Fabian Manhardt, Federico Tombari</author><pubDate>Tue, 13 Jun 2023 15:32:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11738v3</guid></item><item><title>Inferring dynamic regulatory interaction graphs from time series data with perturbations</title><link>http://arxiv.org/abs/2306.07803v1</link><description>Complex systems are characterized by intricate interactions between entitiesthat evolve dynamically over time. Accurate inference of these dynamicrelationships is crucial for understanding and predicting system behavior. Inthis paper, we propose Regulatory Temporal Interaction Network Inference(RiTINI) for inferring time-varying interaction graphs in complex systems usinga novel combination of space-and-time graph attentions and graph neuralordinary differential equations (ODEs). RiTINI leverages time-lapse signals ona graph prior, as well as perturbations of signals at various nodes in order toeffectively capture the dynamics of the underlying system. This approach isdistinct from traditional causal inference networks, which are limited toinferring acyclic and static graphs. In contrast, RiTINI can infer cyclic,directed, and time-varying graphs, providing a more comprehensive and accuraterepresentation of complex systems. The graph attention mechanism in RiTINIallows the model to adaptively focus on the most relevant interactions in timeand space, while the graph neural ODEs enable continuous-time modeling of thesystem's dynamics. We evaluate RiTINI's performance on various simulated andreal-world datasets, demonstrating its state-of-the-art capability in inferringinteraction graphs compared to previous methods.</description><author>Dhananjay Bhaskar, Sumner Magruder, Edward De Brouwer, Aarthi Venkat, Frederik Wenkel, Guy Wolf, Smita Krishnaswamy</author><pubDate>Tue, 13 Jun 2023 15:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07803v1</guid></item><item><title>ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer</title><link>http://arxiv.org/abs/2306.07799v1</link><description>Large-scale language models, like ChatGPT, have garnered significant mediaattention and stunned the public with their remarkable capacity for generatingcoherent text from short natural language prompts. In this paper, we aim toconduct a systematic inspection of ChatGPT's performance in two controllablegeneration tasks, with respect to ChatGPT's ability to adapt its output todifferent target audiences (expert vs. layman) and writing styles (formal vs.informal). Additionally, we evaluate the faithfulness of the generated text,and compare the model's performance with human-authored texts. Our findingsindicate that the stylistic variations produced by humans are considerablylarger than those demonstrated by ChatGPT, and the generated texts diverge fromhuman samples in several characteristics, such as the distribution of wordtypes. Moreover, we observe that ChatGPT sometimes incorporates factual errorsor hallucinations when adapting the text to suit a specific style.</description><author>Dongqi Pu, Vera Demberg</author><pubDate>Tue, 13 Jun 2023 15:21:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07799v1</guid></item><item><title>Does generalization performance of $l^q$ regularization learning depend on $q$? A negative example</title><link>http://arxiv.org/abs/1307.6616v2</link><description>$l^q$-regularization has been demonstrated to be an attractive technique inmachine learning and statistical modeling. It attempts to improve thegeneralization (prediction) capability of a machine (model) throughappropriately shrinking its coefficients. The shape of a $l^q$ estimatordiffers in varying choices of the regularization order $q$. In particular,$l^1$ leads to the LASSO estimate, while $l^{2}$ corresponds to the smoothridge regression. This makes the order $q$ a potential tuning parameter inapplications. To facilitate the use of $l^{q}$-regularization, we intend toseek for a modeling strategy where an elaborative selection on $q$ isavoidable. In this spirit, we place our investigation within a generalframework of $l^{q}$-regularized kernel learning under a sample dependenthypothesis space (SDHS). For a designated class of kernel functions, we showthat all $l^{q}$ estimators for $0&lt; q &lt; \infty$ attain similar generalizationerror bounds. These estimated bounds are almost optimal in the sense that up toa logarithmic factor, the upper and lower bounds are asymptotically identical.This finding tentatively reveals that, in some modeling contexts, the choice of$q$ might not have a strong impact in terms of the generalization capability.From this perspective, $q$ can be arbitrarily specified, or specified merely byother no generalization criteria like smoothness, computational complexity,sparsity, etc..</description><author>Shaobo Lin, Chen Xu, Jingshan Zeng, Jian Fang</author><pubDate>Tue, 13 Jun 2023 15:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1307.6616v2</guid></item><item><title>Model selection of polynomial kernel regression</title><link>http://arxiv.org/abs/1503.02143v2</link><description>Polynomial kernel regression is one of the standard and state-of-the-artlearning strategies. However, as is well known, the choices of the degree ofpolynomial kernel and the regularization parameter are still open in the realmof model selection. The first aim of this paper is to develop a strategy toselect these parameters. On one hand, based on the worst-case learning rateanalysis, we show that the regularization term in polynomial kernel regressionis not necessary. In other words, the regularization parameter can decreasearbitrarily fast when the degree of the polynomial kernel is suitable tuned. Onthe other hand,taking account of the implementation of the algorithm, theregularization term is required. Summarily, the effect of the regularizationterm in polynomial kernel regression is only to circumvent the " ill-condition"of the kernel matrix. Based on this, the second purpose of this paper is topropose a new model selection strategy, and then design an efficient learningalgorithm. Both theoretical and experimental analysis show that the newstrategy outperforms the previous one. Theoretically, we prove that the newlearning strategy is almost optimal if the regression function is smooth.Experimentally, it is shown that the new strategy can significantly reduce thecomputational burden without loss of generalization capability.</description><author>Shaobo Lin, Xingping Sun, Zongben Xu, Jinshan Zeng</author><pubDate>Tue, 13 Jun 2023 15:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1503.02143v2</guid></item><item><title>Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms</title><link>http://arxiv.org/abs/2001.02879v2</link><description>In this paper, we propose an adaptive stopping rule for kernel-based gradientdescent (KGD) algorithms. We introduce the empirical effective dimension toquantify the increments of iterations in KGD and derive an implementable earlystopping strategy. We analyze the performance of the adaptive stopping rule inthe framework of learning theory. Using the recently developed integraloperator approach, we rigorously prove the optimality of the adaptive stoppingrule in terms of showing the optimal learning rates for KGD equipped with thisrule. Furthermore, a sharp bound on the number of iterations in KGD equippedwith the proposed early stopping rule is also given to demonstrate itscomputational advantage.</description><author>Xiangyu Chang, Shao-Bo Lin</author><pubDate>Tue, 13 Jun 2023 15:19:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2001.02879v2</guid></item><item><title>Monolingual and Cross-Lingual Knowledge Transfer for Topic Classification</title><link>http://arxiv.org/abs/2306.07797v1</link><description>This article investigates the knowledge transfer from the RuQTopics dataset.This Russian topical dataset combines a large sample number (361,560single-label, 170,930 multi-label) with extensive class coverage (76 classes).We have prepared this dataset from the "Yandex Que" raw data. By evaluating theRuQTopics - trained models on the six matching classes of the Russian MASSIVEsubset, we have proved that the RuQTopics dataset is suitable for real-worldconversational tasks, as the Russian-only models trained on this datasetconsistently yield an accuracy around 85\% on this subset. We also have figuredout that for the multilingual BERT, trained on the RuQTopics and evaluated onthe same six classes of MASSIVE (for all MASSIVE languages), the language-wiseaccuracy closely correlates (Spearman correlation 0.773 with p-value 2.997e-11)with the approximate size of the pretraining BERT's data for the correspondinglanguage. At the same time, the correlation of the language-wise accuracy withthe linguistical distance from Russian is not statistically significant.</description><author>Dmitry Karpov, Mikhail Burtsev</author><pubDate>Tue, 13 Jun 2023 15:19:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07797v1</guid></item><item><title>Finite Gaussian Neurons: Defending against adversarial attacks by making neural networks say "I don't know"</title><link>http://arxiv.org/abs/2306.07796v1</link><description>Since 2014, artificial neural networks have been known to be vulnerable toadversarial attacks, which can fool the network into producing wrong ornonsensical outputs by making humanly imperceptible alterations to inputs.While defenses against adversarial attacks have been proposed, they usuallyinvolve retraining a new neural network from scratch, a costly task. In thiswork, I introduce the Finite Gaussian Neuron (FGN), a novel neuron architecturefor artificial neural networks. My works aims to: - easily convert existingmodels to Finite Gaussian Neuron architecture, - while preserving the existingmodel's behavior on real data, - and offering resistance against adversarialattacks. I show that converted and retrained Finite Gaussian Neural Networks(FGNN) always have lower confidence (i.e., are not overconfident) in theirpredictions over randomized and Fast Gradient Sign Method adversarial imageswhen compared to classical neural networks, while maintaining high accuracy andconfidence over real MNIST images. To further validate the capacity of FiniteGaussian Neurons to protect from adversarial attacks, I compare the behavior ofFGNs to that of Bayesian Neural Networks against both randomized andadversarial images, and show how the behavior of the two architectures differs.Finally I show some limitations of the FGN models by testing them on the morecomplex SPEECHCOMMANDS task, against the stronger Carlini-Wagner and ProjectedGradient Descent adversarial attacks.</description><author>Felix Grezes</author><pubDate>Tue, 13 Jun 2023 15:17:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07796v1</guid></item><item><title>Rethinking Polyp Segmentation from an Out-of-Distribution Perspective</title><link>http://arxiv.org/abs/2306.07792v1</link><description>Unlike existing fully-supervised approaches, we rethink colorectal polypsegmentation from an out-of-distribution perspective with a simple buteffective self-supervised learning approach. We leverage the ability of maskedautoencoders -- self-supervised vision transformers trained on a reconstructiontask -- to learn in-distribution representations; here, the distribution ofhealthy colon images. We then perform out-of-distribution reconstruction andinference, with feature space standardisation to align the latent distributionof the diverse abnormal samples with the statistics of the healthy samples. Wegenerate per-pixel anomaly scores for each image by calculating the differencebetween the input and reconstructed images and use this signal forout-of-distribution (ie, polyp) segmentation. Experimental results on sixbenchmarks show that our model has excellent segmentation performance andgeneralises across datasets. Our code is publicly available athttps://github.com/GewelsJI/Polyp-OOD.</description><author>Ge-Peng Ji, Jing Zhang, Dylan Campbell, Huan Xiong, Nick Barnes</author><pubDate>Tue, 13 Jun 2023 15:13:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07792v1</guid></item><item><title>NoCoLA: The Norwegian Corpus of Linguistic Acceptability</title><link>http://arxiv.org/abs/2306.07790v1</link><description>While there has been a surge of large language models for Norwegian in recentyears, we lack any tool to evaluate their understanding of grammaticality. Wepresent two new Norwegian datasets for this task. NoCoLA_class is a supervisedbinary classification task where the goal is to discriminate between acceptableand non-acceptable sentences. On the other hand, NoCoLA_zero is a purelydiagnostic task for evaluating the grammatical judgement of a language model ina completely zero-shot manner, i.e. without any further training. In thispaper, we describe both datasets in detail, show how to use them for differentflavors of language models, and conduct a comparative study of the existingNorwegian language models.</description><author>Matias Jentoft, David Samuel</author><pubDate>Tue, 13 Jun 2023 15:11:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07790v1</guid></item><item><title>Exact Solutions of a Deep Linear Network</title><link>http://arxiv.org/abs/2202.04777v7</link><description>This work finds the analytical expression of the global minima of a deeplinear network with weight decay and stochastic neurons, a fundamental modelfor understanding the landscape of neural networks. Our result implies that theorigin is a special point in deep neural network loss landscape where highlynonlinear phenomenon emerges. We show that weight decay strongly interacts withthe model architecture and can create bad minima at zero in a network with morethan $1$ hidden layer, qualitatively different from a network with only $1$hidden layer. Practically, our result implies that common deep learninginitialization methods are insufficient to ease the optimization of neuralnetworks in general.</description><author>Liu Ziyin, Botao Li, Xiangming Meng</author><pubDate>Tue, 13 Jun 2023 15:10:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.04777v7</guid></item><item><title>A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews</title><link>http://arxiv.org/abs/2306.07786v1</link><description>The efficiency of natural language processing has improved dramatically withthe advent of machine learning models, particularly neural network-basedsolutions. However, some tasks are still challenging, especially whenconsidering specific domains. In this paper, we present a cloud-based systemthat can extract insights from customer reviews using machine learning methodsintegrated into a pipeline. For topic modeling, our composite model usestransformer-based neural networks designed for natural language processing,vector embedding-based keyword extraction, and clustering. The elements of ourmodel have been integrated and further developed to meet better therequirements of efficient information extraction, topic modeling of theextracted information, and user needs. Furthermore, our system can achievebetter results than this task's existing topic modeling and keyword extractionsolutions. Our approach is validated and compared with other state-of-the-artmethods using publicly available datasets for benchmarking.</description><author>Robert Lakatos, Gergo Bogacsovics, Balazs Harangi, Istvan Lakatos, Attila Tiba, Janos Toth, Marianna Szabo, Andras Hajdu</author><pubDate>Tue, 13 Jun 2023 15:07:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07786v1</guid></item><item><title>Compositionally Equivariant Representation Learning</title><link>http://arxiv.org/abs/2306.07783v1</link><description>Deep learning models often need sufficient supervision (i.e. labelled data)in order to be trained effectively. By contrast, humans can swiftly learn toidentify important anatomy in medical images like MRI and CT scans, withminimal guidance. This recognition capability easily generalises to new imagesfrom different medical facilities and to new tasks in different settings. Thisrapid and generalisable learning ability is largely due to the compositionalstructure of image patterns in the human brain, which are not well representedin current medical models. In this paper, we study the utilisation ofcompositionality in learning more interpretable and generalisablerepresentations for medical image segmentation. Overall, we propose that theunderlying generative factors that are used to generate the medical imagessatisfy compositional equivariance property, where each factor is compositional(e.g. corresponds to the structures in human anatomy) and also equivariant tothe task. Hence, a good representation that approximates well the ground truthfactor has to be compositionally equivariant. By modelling the compositionalrepresentations with learnable von-Mises-Fisher (vMF) kernels, we explore howdifferent design and learning biases can be used to enforce the representationsto be more compositionally equivariant under un-, weakly-, and semi-supervisedsettings. Extensive results show that our methods achieve the best performanceover several strong baselines on the task of semi-supervised domain-generalisedmedical image segmentation. Code will be made publicly available uponacceptance at https://github.com/vios-s.</description><author>Xiao Liu, Pedro Sanchez, Spyridon Thermos, Alison Q. O'Neil, Sotirios A. Tsaftaris</author><pubDate>Tue, 13 Jun 2023 15:06:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07783v1</guid></item><item><title>A Zero-/Few-Shot Anomaly Classification and Segmentation Method for CVPR 2023 VAND Workshop Challenge Tracks 1&amp;2: 1st Place on Zero-shot AD and 4th Place on Few-shot AD</title><link>http://arxiv.org/abs/2305.17382v2</link><description>In this technical report, we briefly introduce our solution for theZero/Few-shot Track of the Visual Anomaly and Novelty Detection (VAND) 2023Challenge. For industrial visual inspection, building a single model that canbe rapidly adapted to numerous categories without or with only a few normalreference images is a promising research direction. This is primarily becauseof the vast variety of the product types. For the zero-shot track, we propose asolution based on the CLIP model by adding extra linear layers. These layersare used to map the image features to the joint embedding space, so that theycan compare with the text features to generate the anomaly maps. Besides, whenthe reference images are available, we utilize multiple memory banks to storetheir features and compare them with the features of the test images during thetesting phase. In this challenge, our method achieved first place in thezero-shot track, especially excelling in segmentation with an impressive F1score improvement of 0.0489 over the second-ranked participant. Furthermore, inthe few-shot track, we secured the fourth position overall, with ourclassification F1 score of 0.8687 ranking first among all participating teams.</description><author>Xuhai Chen, Yue Han, Jiangning Zhang</author><pubDate>Tue, 13 Jun 2023 15:02:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17382v2</guid></item><item><title>iPDP: On Partial Dependence Plots in Dynamic Modeling Scenarios</title><link>http://arxiv.org/abs/2306.07775v1</link><description>Post-hoc explanation techniques such as the well-established partialdependence plot (PDP), which investigates feature dependencies, are used inexplainable artificial intelligence (XAI) to understand black-box machinelearning models. While many real-world applications require dynamic models thatconstantly adapt over time and react to changes in the underlying distribution,XAI, so far, has primarily considered static learning environments, wheremodels are trained in a batch mode and remain unchanged. We thus propose anovel model-agnostic XAI framework called incremental PDP (iPDP) that extendson the PDP to extract time-dependent feature effects in non-stationary learningenvironments. We formally analyze iPDP and show that it approximates atime-dependent variant of the PDP that properly reacts to real and virtualconcept drift. The time-sensitivity of iPDP is controlled by a single smoothingparameter, which directly corresponds to the variance and the approximationerror of iPDP in a static learning environment. We illustrate the efficacy ofiPDP by showcasing an example application for drift detection and conductingmultiple experiments on real-world and synthetic data sets and streams.</description><author>Maximilian Muschalik, Fabian Fumagalli, Rohit Jagtani, Barbara Hammer, Eyke Hüllermeier</author><pubDate>Tue, 13 Jun 2023 14:56:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07775v1</guid></item><item><title>The Rank-Reduced Kalman Filter: Approximate Dynamical-Low-Rank Filtering In High Dimensions</title><link>http://arxiv.org/abs/2306.07774v1</link><description>Inference and simulation in the context of high-dimensional dynamical systemsremain computationally challenging problems. Some form of dimensionalityreduction is required to make the problem tractable in general. In this paper,we propose a novel approximate Gaussian filtering and smoothing method whichpropagates low-rank approximations of the covariance matrices. This isaccomplished by projecting the Lyapunov equations associated with theprediction step to a manifold of low-rank matrices, which are then solved by arecently developed, numerically stable, dynamical low-rank integrator.Meanwhile, the update steps are made tractable by noting that the covarianceupdate only transforms the column space of the covariance matrix, which islow-rank by construction. The algorithm differentiates itself from existingensemble-based approaches in that the low-rank approximations of the covariancematrices are deterministic, rather than stochastic. Crucially, this enables themethod to reproduce the exact Kalman filter as the low-rank dimensionapproaches the true dimensionality of the problem. Our method reducescomputational complexity from cubic (for the Kalman filter) to \emph{quadratic}in the state-space size in the worst-case, and can achieve \emph{linear}complexity if the state-space model satisfies certain criteria. Through a setof experiments in classical data-assimilation and spatio-temporal regression,we show that the proposed method consistently outperforms the ensemble-basedmethods in terms of error in the mean and covariance with respect to the exactKalman filter. This comes at no additional cost in terms of asymptoticcomputational complexity.</description><author>Jonathan Schmidt, Philipp Hennig, Jörg Nick, Filip Tronarp</author><pubDate>Tue, 13 Jun 2023 14:50:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07774v1</guid></item><item><title>EaSyGuide : ESG Issue Identification Framework leveraging Abilities of Generative Large Language Models</title><link>http://arxiv.org/abs/2306.06662v2</link><description>This paper presents our participation in the FinNLP-2023 shared task onmulti-lingual environmental, social, and corporate governance issueidentification (ML-ESG). The task's objective is to classify news articlesbased on the 35 ESG key issues defined by the MSCI ESG rating guidelines. Ourapproach focuses on the English and French subtasks, employing the CerebrasGPT,OPT, and Pythia models, along with the zero-shot and GPT3Mix Augmentationtechniques. We utilize various encoder models, such as RoBERTa, DeBERTa, andFinBERT, subjecting them to knowledge distillation and additional training. Our approach yielded exceptional results, securing the first position in theEnglish text subtask with F1-score 0.69 and the second position in the Frenchtext subtask with F1-score 0.78. These outcomes underscore the effectiveness ofour methodology in identifying ESG issues in news articles across differentlanguages. Our findings contribute to the exploration of ESG topics andhighlight the potential of leveraging advanced language models for ESG issueidentification.</description><author>Hanwool Lee, Jonghyun Choi, Sohyeon Kwon, Sungbum Jung</author><pubDate>Tue, 13 Jun 2023 14:47:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06662v2</guid></item><item><title>FLEdge: Benchmarking Federated Machine Learning Applications in Edge Computing Systems</title><link>http://arxiv.org/abs/2306.05172v2</link><description>Federated Machine Learning (FL) has received considerable attention in recentyears. FL benchmarks are predominantly explored in either simulated systems ordata center environments, neglecting the setups of real-world systems, whichare often closely linked to edge computing. We close this research gap byintroducing FLEdge, a benchmark targeting FL workloads in edge computingsystems. We systematically study hardware heterogeneity, energy efficiencyduring training, and the effect of various differential privacy levels ontraining in FL systems. To make this benchmark applicable to real-worldscenarios, we evaluate the impact of client dropouts on state-of-the-art FLstrategies with failure rates as high as 50%. FLEdge provides new insights,such as that training state-of-the-art FL workloads on older GPU-acceleratedembedded devices is up to 3x more energy efficient than on modern server-gradeGPUs.</description><author>Herbert Woisetschläger, Alexander Isenko, Ruben Mayer, Hans-Arno Jacobsen</author><pubDate>Tue, 13 Jun 2023 14:41:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05172v2</guid></item><item><title>Simulation-Based Frequentist Inference with Tractable and Intractable Likelihoods</title><link>http://arxiv.org/abs/2306.07769v1</link><description>High-fidelity simulators that connect theoretical models with observationsare indispensable tools in many sciences. When coupled with machine learning, asimulator makes it possible to infer the parameters of a theoretical modeldirectly from real and simulated observations without explicit use of thelikelihood function. This is of particular interest when the latter isintractable. We introduce a simple modification of the recently proposedlikelihood-free frequentist inference (LF2I) approach that has somecomputational advantages. The utility of our algorithm is illustrated byapplying it to three pedagogically interesting examples: the first is fromcosmology, the second from high-energy physics and astronomy, both withtractable likelihoods, while the third, with an intractable likelihood, is fromepidemiology.</description><author>Ali Al Kadhim, Harrison B. Prosper, Olivia F. Prosper</author><pubDate>Tue, 13 Jun 2023 14:39:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07769v1</guid></item><item><title>Area is all you need: repeatable elements make stronger adversarial attacks</title><link>http://arxiv.org/abs/2306.07768v1</link><description>Over the last decade, deep neural networks have achieved state of the art incomputer vision tasks. These models, however, are susceptible to unusualinputs, known as adversarial examples, that cause them to misclassify orotherwise fail to detect objects. Here, we provide evidence that the increasingsuccess of adversarial attacks is primarily due to increasing their size. Wethen demonstrate a method for generating the largest possible adversarial patchby building a adversarial pattern out of repeatable elements. This approachachieves a new state of the art in evading detection by YOLOv2 and YOLOv3.Finally, we present an experiment that fails to replicate the prior success ofseveral attacks published in this field, and end with some comments on testingand reproducibility.</description><author>Dillon Niederhut</author><pubDate>Tue, 13 Jun 2023 14:33:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07768v1</guid></item><item><title>MultiModal-GPT: A Vision and Language Model for Dialogue with Humans</title><link>http://arxiv.org/abs/2305.04790v3</link><description>We present a vision and language model named MultiModal-GPT to conductmulti-round dialogue with humans. MultiModal-GPT can follow variousinstructions from humans, such as generating a detailed caption, counting thenumber of interested objects, and answering general questions from users.MultiModal-GPT is parameter-efficiently fine-tuned from OpenFlamingo, withLow-rank Adapter (LoRA) added both in the cross-attention part and theself-attention part of the language model. We first construct instructiontemplates with vision and language data for multi-modality instruction tuningto make the model understand and follow human instructions. We find the qualityof training data is vital for the dialogue performance, where few datacontaining short answers can lead the model to respond shortly to anyinstructions. To further enhance the ability to chat with humans of theMultiModal-GPT, we utilize language-only instruction-following data to trainthe MultiModal-GPT jointly. The joint training of language-only andvisual-language instructions with the \emph{same} instruction templateeffectively improves dialogue performance. Various demos show the ability ofcontinuous dialogue of MultiModal-GPT with humans. Code, dataset, and demo areat https://github.com/open-mmlab/Multimodal-GPT</description><author>Tao Gong, Chengqi Lyu, Shilong Zhang, Yudong Wang, Miao Zheng, Qian Zhao, Kuikun Liu, Wenwei Zhang, Ping Luo, Kai Chen</author><pubDate>Tue, 13 Jun 2023 14:31:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04790v3</guid></item></channel></rss>