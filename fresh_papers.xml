<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 18 Oct 2024 01:00:07 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Context Matters: Leveraging Contextual Features for Time Series Forecasting</title><link>http://arxiv.org/abs/2410.12672v2</link><description>Time series forecasts are often influenced by exogenous contextual featuresin addition to their corresponding history. For example, in financial settings,it is hard to accurately predict a stock price without considering publicsentiments and policy decisions in the form of news articles, tweets, etc.Though this is common knowledge, the current state-of-the-art (SOTA)forecasting models fail to incorporate such contextual information, owing toits heterogeneity and multimodal nature. To address this, we introduceContextFormer, a novel plug-and-play method to surgically integrate multimodalcontextual information into existing pre-trained forecasting models.ContextFormer effectively distills forecast-specific information from richmultimodal contexts, including categorical, continuous, time-varying, and eventextual information, to significantly enhance the performance of existing baseforecasters. ContextFormer outperforms SOTA forecasting models by up to 30% ona range of real-world datasets spanning energy, traffic, environmental, andfinancial domains.</description><author>Sameep Chattopadhyay, Pulkit Paliwal, Sai Shankar Narasimhan, Shubhankar Agarwal, Sandeep P. Chinchali</author><pubDate>Thu, 17 Oct 2024 04:46:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12672v2</guid></item><item><title>CREAM: Consistency Regularized Self-Rewarding Language Models</title><link>http://arxiv.org/abs/2410.12735v2</link><description>Recent self-rewarding large language models (LLM) have successfully appliedLLM-as-a-Judge to iteratively improve the alignment performance without theneed of human annotations for preference data. These methods commonly utilizethe same LLM to act as both the policy model (which generates responses) andthe reward model (which scores and ranks those responses). The ranked responsesare then used as preference pairs to train the LLM via direct alignmenttechnologies (e.g. DPO). However, it is noteworthy that throughout thisprocess, there is no guarantee of accuracy in the rewarding and ranking, whichis critical for ensuring accurate rewards and high-quality preference data.Empirical results from relatively small LLMs (e.g., 7B parameters) alsoindicate that improvements from self-rewarding may diminish after severaliterations in certain situations, which we hypothesize is due to accumulatedbias in the reward system. This bias can lead to unreliable preference data fortraining the LLM. To address this issue, we first formulate and analyze thegeneralized iterative preference fine-tuning framework for self-rewardinglanguage model. We then introduce the regularization to this generalizedframework to mitigate the overconfident preference labeling in theself-rewarding process. Based on this theoretical insight, we propose aConsistency Regularized sElf-rewarding lAnguage Model (CREAM) that leveragesthe rewarding consistency across different iterations to regularize theself-rewarding training, helping the model to learn from more reliablepreference data. With this explicit regularization, our empirical resultsdemonstrate the superiority of CREAM in improving both reward consistency andalignment performance. The code is publicly available athttps://github.com/Raibows/CREAM.</description><author>Zhaoyang Wang, Weilei He, Zhiyuan Liang, Xuchao Zhang, Chetan Bansal, Ying Wei, Weitong Zhang, Huaxiu Yao</author><pubDate>Thu, 17 Oct 2024 02:47:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12735v2</guid></item><item><title>Local transfer learning Gaussian process modeling, with applications to surrogate modeling of expensive computer simulators</title><link>http://arxiv.org/abs/2410.12690v2</link><description>A critical bottleneck for scientific progress is the costly nature ofcomputer simulations for complex systems. Surrogate models provide an appealingsolution: such models are trained on simulator evaluations, then used toemulate and quantify uncertainty on the expensive simulator at unexploredinputs. In many applications, one often has available data on related systems.For example, in designing a new jet turbine, there may be existing studies onturbines with similar configurations. A key question is how information fromsuch "source" systems can be transferred for effective surrogate training onthe "target" system of interest. We thus propose a new LOcal transfer LearningGaussian Process (LOL-GP) model, which leverages a carefully-designed Gaussianprocess to transfer such information for surrogate modeling. The key novelty ofthe LOL-GP is a latent regularization model, which identifies regions wheretransfer should be performed and regions where it should be avoided. This"local transfer" property is desirable in scientific systems: at certainparameters, such systems may behave similarly and thus transfer is beneficial;at other parameters, they may behave differently and thus transfer isdetrimental. By accounting for local transfer, the LOL-GP can rectify acritical limitation of "negative transfer" in existing transfer learningmodels, where the transfer of information worsens predictive performance. Wederive a Gibbs sampling algorithm for efficient posterior predictive samplingon the LOL-GP, for both the multi-source and multi-fidelity transfer settings.We then show, via a suite of numerical experiments and an application for jetturbine design, the improved surrogate performance of the LOL-GP over existingmethods.</description><author>Xinming Wang, Simon Mak, John Miller, Jianguo Wu</author><pubDate>Thu, 17 Oct 2024 01:53:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12690v2</guid></item><item><title>Nearly Tight Black-Box Auditing of Differentially Private Machine Learning</title><link>http://arxiv.org/abs/2405.14106v3</link><description>This paper presents an auditing procedure for the Differentially PrivateStochastic Gradient Descent (DP-SGD) algorithm in the black-box threat modelthat is substantially tighter than prior work. The main intuition is to craftworst-case initial model parameters, as DP-SGD's privacy analysis is agnosticto the choice of the initial model parameters. For models trained on MNIST andCIFAR-10 at theoretical $\varepsilon=10.0$, our auditing procedure yieldsempirical estimates of $\varepsilon_{emp} = 7.21$ and $6.95$, respectively, ona 1,000-record sample and $\varepsilon_{emp}= 6.48$ and $4.96$ on the fulldatasets. By contrast, previous audits were only (relatively) tight in strongerwhite-box models, where the adversary can access the model's inner parametersand insert arbitrary gradients. Overall, our auditing procedure can offervaluable insight into how the privacy analysis of DP-SGD could be improved anddetect bugs and DP violations in real-world implementations. The source codeneeded to reproduce our experiments is available athttps://github.com/spalabucr/bb-audit-dpsgd.</description><author>Meenatchi Sundaram Muthu Selva Annamalai, Emiliano De Cristofaro</author><pubDate>Thu, 17 Oct 2024 01:15:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14106v3</guid></item><item><title>Context is Key(NMF): Modelling Topical Information Dynamics in Chinese Diaspora Media</title><link>http://arxiv.org/abs/2410.12791v1</link><description>Does the People's Republic of China (PRC) interfere with European electionsthrough ethnic Chinese diaspora media? This question forms the basis of anongoing research project exploring how PRC narratives about European electionsare represented in Chinese diaspora media, and thus the objectives of PRC newsmedia manipulation. In order to study diaspora media efficiently and at scale,it is necessary to use techniques derived from quantitative text analysis, suchas topic modelling. In this paper, we present a pipeline for studyinginformation dynamics in Chinese media. Firstly, we present KeyNMF, a newapproach to static and dynamic topic modelling using transformer-basedcontextual embedding models. We provide benchmark evaluations to demonstratethat our approach is competitive on a number of Chinese datasets and metrics.Secondly, we integrate KeyNMF with existing methods for describing informationdynamics in complex systems. We apply this pipeline to data from five newssites, focusing on the period of time leading up to the 2024 Europeanparliamentary elections. Our methods and results demonstrate the effectivenessof KeyNMF for studying information dynamics in Chinese media and lay groundworkfor further work addressing the broader research questions.</description><author>Ross Deans Kristensen-McLachlan, Rebecca M. M. Hicke, Márton Kardos, Mette Thunø</author><pubDate>Wed, 16 Oct 2024 17:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12791v1</guid></item><item><title>Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models</title><link>http://arxiv.org/abs/2410.12790v1</link><description>Test-time adaptation, which enables models to generalize to diverse data withunlabeled test samples, holds significant value in real-world scenarios.Recently, researchers have applied this setting to advanced pre-trainedvision-language models (VLMs), developing approaches such as test-time prompttuning to further extend their practical applicability. However, these methodstypically focus solely on adapting VLMs from a single modality and fail toaccumulate task-specific knowledge as more samples are processed. To addressthis, we introduce Dual Prototype Evolving (DPE), a novel test-time adaptationapproach for VLMs that effectively accumulates task-specific knowledge frommulti-modalities. Specifically, we create and evolve two sets ofprototypes--textual and visual--to progressively capture more accuratemulti-modal representations for target classes during test time. Moreover, topromote consistent multi-modal representations, we introduce and optimizelearnable residuals for each test sample to align the prototypes from bothmodalities. Extensive experimental results on 15 benchmark datasets demonstratethat our proposed DPE consistently outperforms previous state-of-the-artmethods while also exhibiting competitive computational efficiency. Code isavailable at https://github.com/zhangce01/DPE-CLIP.</description><author>Ce Zhang, Simon Stepputtis, Katia Sycara, Yaqi Xie</author><pubDate>Wed, 16 Oct 2024 17:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12790v1</guid></item><item><title>Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception</title><link>http://arxiv.org/abs/2410.12788v1</link><description>Retrieval-Augmented Generation (RAG), while serving as a viable complement tolarge language models (LLMs), often overlooks the crucial aspect of textchunking within its pipeline, which impacts the quality of knowledge-intensivetasks. This paper introduces the concept of Meta-Chunking, which refers to agranularity between sentences and paragraphs, consisting of a collection ofsentences within a paragraph that have deep linguistic logical connections. Toimplement Meta-Chunking, we designed two strategies based on LLMs: MarginSampling Chunking and Perplexity Chunking. The former employs LLMs to performbinary classification on whether consecutive sentences need to be segmented,making decisions based on the probability difference obtained from marginsampling. The latter precisely identifies text chunk boundaries by analyzingthe characteristics of perplexity distribution. Additionally, considering theinherent complexity of different texts, we propose a strategy that combinesMeta-Chunking with dynamic merging to achieve a balance between fine-grainedand coarse-grained text chunking. Experiments conducted on eleven datasetsdemonstrate that Meta-Chunking can more efficiently improve the performance ofsingle-hop and multi-hop question answering based on RAG. For instance, on the2WikiMultihopQA dataset, it outperforms similarity chunking by 1.32 while onlyconsuming 45.8% of the time. Our code is available athttps://github.com/IAAR-Shanghai/Meta-Chunking.</description><author>Jihao Zhao, Zhiyuan Ji, Pengnian Qi, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li</author><pubDate>Wed, 16 Oct 2024 17:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12788v1</guid></item><item><title>The Curse of Multi-Modalities: Evaluating Hallucinations of Large Multimodal Models across Language, Visual, and Audio</title><link>http://arxiv.org/abs/2410.12787v1</link><description>Recent advancements in large multimodal models (LMMs) have significantlyenhanced performance across diverse tasks, with ongoing efforts to furtherintegrate additional modalities such as video and audio. However, most existingLMMs remain vulnerable to hallucinations, the discrepancy between the factualmultimodal input and the generated textual output, which has limited theirapplicability in various real-world scenarios. This paper presents the firstsystematic investigation of hallucinations in LMMs involving the three mostcommon modalities: language, visual, and audio. Our study reveals two keycontributors to hallucinations: overreliance on unimodal priors and spuriousinter-modality correlations. To address these challenges, we introduce thebenchmark The Curse of Multi-Modalities (CMM), which comprehensively evaluateshallucinations in LMMs, providing a detailed analysis of their underlyingissues. Our findings highlight key vulnerabilities, including imbalances inmodality integration and biases from training data, underscoring the need forbalanced cross-modal learning and enhanced hallucination mitigation strategies.Based on our observations and findings, we suggest potential researchdirections that could enhance the reliability of LMMs.</description><author>Sicong Leng, Yun Xing, Zesen Cheng, Yang Zhou, Hang Zhang, Xin Li, Deli Zhao, Shijian Lu, Chunyan Miao, Lidong Bing</author><pubDate>Wed, 16 Oct 2024 17:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12787v1</guid></item><item><title>Metal Price Spike Prediction via a Neurosymbolic Ensemble Approach</title><link>http://arxiv.org/abs/2410.12785v1</link><description>Predicting price spikes in critical metals such as Cobalt, Copper, Magnesium,and Nickel is crucial for mitigating economic risks associated with globaltrends like the energy transition and reshoring of manufacturing. Whiletraditional models have focused on regression-based approaches, our workintroduces a neurosymbolic ensemble framework that integrates multiple neuralmodels with symbolic error detection and correction rules. This framework isdesigned to enhance predictive accuracy by correcting individual model errorsand offering interpretability through rule-based explanations. We show that ourmethod provides up to 6.42% improvement in precision, 29.41% increase in recallat 13.24% increase in F1 over the best performing neural models. Further, ourmethod, as it is based on logical rules, has the benefit of affording anexplanation as to which combination of neural models directly contribute to agiven prediction.</description><author>Nathaniel Lee, Noel Ngu, Harshdeep Singh Sahdev, Pramod Motaganahall, Al Mehdi Saadat Chowdhury, Bowen Xi, Paulo Shakarian</author><pubDate>Wed, 16 Oct 2024 17:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12785v1</guid></item><item><title>JudgeBench: A Benchmark for Evaluating LLM-based Judges</title><link>http://arxiv.org/abs/2410.12784v1</link><description>LLM-based judges have emerged as a scalable alternative to human evaluationand are increasingly used to assess, compare, and improve models. However, thereliability of LLM-based judges themselves is rarely scrutinized. As LLMsbecome more advanced, their responses grow more sophisticated, requiringstronger judges to evaluate them. Existing benchmarks primarily focus on ajudge's alignment with human preferences, but often fail to account for morechallenging tasks where crowdsourced human preference is a poor indicator offactual and logical correctness. To address this, we propose a novel evaluationframework to objectively evaluate LLM-based judges. Based on this framework, wepropose JudgeBench, a benchmark for evaluating LLM-based judges on challengingresponse pairs spanning knowledge, reasoning, math, and coding. JudgeBenchleverages a novel pipeline for converting existing difficult datasets intochallenging response pairs with preference labels reflecting objectivecorrectness. Our comprehensive evaluation on a collection of prompted judges,fine-tuned judges, multi-agent judges, and reward models shows that JudgeBenchposes a significantly greater challenge than previous benchmarks, with manystrong models (e.g., GPT-4o) performing just slightly better than randomguessing. Overall, JudgeBench offers a reliable platform for assessingincreasingly advanced LLM-based judges. Data and code are available athttps://github.com/ScalerLab/JudgeBench .</description><author>Sijun Tan, Siyuan Zhuang, Kyle Montgomery, William Y. Tang, Alejandro Cuadron, Chenguang Wang, Raluca Ada Popa, Ion Stoica</author><pubDate>Wed, 16 Oct 2024 17:58:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12784v1</guid></item><item><title>Context-Scaling versus Task-Scaling in In-Context Learning</title><link>http://arxiv.org/abs/2410.12783v1</link><description>Transformers exhibit In-Context Learning (ICL), where these models solve newtasks by using examples in the prompt without additional training. In our work,we identify and analyze two key components of ICL: (1) context-scaling, wheremodel performance improves as the number of in-context examples increases and(2) task-scaling, where model performance improves as the number ofpre-training tasks increases. While transformers are capable of bothcontext-scaling and task-scaling, we empirically show that standard Multi-LayerPerceptrons (MLPs) with vectorized input are only capable of task-scaling. Tounderstand how transformers are capable of context-scaling, we first propose asignificantly simplified transformer architecture without key, query, valueweights. We show that it performs ICL comparably to the original GPT-2 model invarious statistical learning tasks including linear regression, teacher-studentsettings. Furthermore, a single block of our simplified transformer can beviewed as data dependent feature map followed by an MLP. This feature map onits own is a powerful predictor that is capable of context-scaling but is notcapable of task-scaling. We show empirically that concatenating the output ofthis feature map with vectorized data as an input to MLPs enables bothcontext-scaling and task-scaling. This finding provides a simple setting tostudy context and task-scaling for ICL.</description><author>Amirhesam Abedsoltan, Adityanarayanan Radhakrishnan, Jingfeng Wu, Mikhail Belkin</author><pubDate>Wed, 16 Oct 2024 17:58:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12783v1</guid></item><item><title>Towards Scalable Exact Machine Unlearning Using Parameter-Efficient Fine-Tuning</title><link>http://arxiv.org/abs/2406.16257v2</link><description>Machine unlearning is the process of efficiently removing the influence of atraining data instance from a trained machine learning model without retrainingit from scratch. A popular subclass of unlearning approaches is exact machineunlearning, which focuses on techniques that explicitly guarantee the removalof the influence of a data instance from a model. Exact unlearning approachesuse a machine learning model in which individual components are trained ondisjoint subsets of the data. During deletion, exact unlearning approaches onlyretrain the affected components rather than the entire model. While existingapproaches reduce retraining costs, it can still be expensive for anorganization to retrain a model component as it requires halting a system inproduction, which leads to service failure and adversely impacts customers. Toaddress these challenges, we introduce an exact unlearning framework --Sequence-aware Sharded Sliced Training (S3T), which is designed to enhance thedeletion capabilities of an exact unlearning system while minimizing the impacton model's performance. At the core of S3T, we utilize a lightweightparameter-efficient fine-tuning approach that enables parameter isolation bysequentially training layers with disjoint data slices. This enables efficientunlearning by simply deactivating the layers affected by data deletion.Furthermore, to reduce the retraining cost and improve model performance, wetrain the model on multiple data sequences, which allows S3T to handle anincreased number of deletion requests. Both theoretically and empirically, wedemonstrate that S3T attains superior deletion capabilities and enhancedperformance compared to baselines across a wide range of settings.</description><author>Somnath Basu Roy Chowdhury, Krzysztof Choromanski, Arijit Sehanobish, Avinava Dubey, Snigdha Chaturvedi</author><pubDate>Wed, 16 Oct 2024 17:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16257v2</guid></item><item><title>In-Context Learning Enables Robot Action Prediction in LLMs</title><link>http://arxiv.org/abs/2410.12782v1</link><description>Recently, Large Language Models (LLMs) have achieved remarkable success usingin-context learning (ICL) in the language domain. However, leveraging the ICLcapabilities within LLMs to directly predict robot actions remains largelyunexplored. In this paper, we introduce RoboPrompt, a framework that enablesoff-the-shelf text-only LLMs to directly predict robot actions through ICLwithout training. Our approach first heuristically identifies keyframes thatcapture important moments from an episode. Next, we extract end-effectoractions from these keyframes as well as the estimated initial object poses, andboth are converted into textual descriptions. Finally, we construct astructured template to form ICL demonstrations from these textual descriptionsand a task instruction. This enables an LLM to directly predict robot actionsat test time. Through extensive experiments and analysis, RoboPrompt showsstronger performance over zero-shot and ICL baselines in simulated andreal-world settings.</description><author>Yida Yin, Zekai Wang, Yuvan Sharma, Dantong Niu, Trevor Darrell, Roei Herzig</author><pubDate>Wed, 16 Oct 2024 17:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12782v1</guid></item><item><title>Neural Algorithmic Reasoning with Multiple Correct Solutions</title><link>http://arxiv.org/abs/2409.06953v2</link><description>Neural Algorithmic Reasoning (NAR) aims to optimize classical algorithms.However, canonical implementations of NAR train neural networks to return onlya single solution, even when there are multiple correct solutions to a problem,such as single-source shortest paths. For some applications, it is desirable torecover more than one correct solution. To that end, we give the first methodfor NAR with multiple solutions. We demonstrate our method on two classicalalgorithms: Bellman-Ford (BF) and Depth-First Search (DFS), favouring deeperinsight into two algorithms over a broader survey of algorithms. This methodinvolves generating appropriate training data as well as sampling andvalidating solutions from model output. Each step of our method, which canserve as a framework for neural algorithmic reasoning beyond the taskspresented in this paper, might be of independent interest to the field and ourresults represent the first attempt at this task in the NAR literature.</description><author>Zeno Kujawa, John Poole, Dobrik Georgiev, Danilo Numeroso, Pietro Liò</author><pubDate>Wed, 16 Oct 2024 17:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06953v2</guid></item><item><title>cedar: Optimized and Unified Machine Learning Input Data Pipelines</title><link>http://arxiv.org/abs/2401.08895v3</link><description>The input data pipeline is an essential component of each machine learning(ML) training job. It is responsible for reading massive amounts of trainingdata, processing batches of samples using complex transformations, and loadingthem onto training nodes at low latency and high throughput. Performant inputdata systems are becoming increasingly critical, driven by skyrocketing datavolumes and training throughput demands. Unfortunately, current input datasystems cannot fully leverage key performance optimizations, resulting inhugely inefficient infrastructures that require significant resources - orworse - underutilize expensive accelerators. To address these demands, we present cedar, an optimized and unifiedprogramming framework for ML input data pipelines. cedar allows users to defineinput data pipelines using composable operators that support arbitrary MLframeworks and libraries. cedar introduces an extensible optimizer thatsystematically applies a complex combination of optimizations (e.g.,offloading, caching, prefetching, fusion, and reordering). It orchestratesprocessing across a customizable set of local and distributed compute resourcesin order to improve processing performance and efficiency, all without userinput. Across eight pipelines, cedar improves performance by up to 1.87x to10.65x compared to state-of-the-art input data systems.</description><author>Mark Zhao, Emanuel Adamiak, Christos Kozyrakis</author><pubDate>Wed, 16 Oct 2024 17:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08895v3</guid></item><item><title>Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats</title><link>http://arxiv.org/abs/2410.12781v1</link><description>We propose Long-LRM, a generalizable 3D Gaussian reconstruction model that iscapable of reconstructing a large scene from a long sequence of input images.Specifically, our model can process 32 source images at 960x540 resolutionwithin only 1.3 seconds on a single A100 80G GPU. Our architecture features amixture of the recent Mamba2 blocks and the classical transformer blocks whichallowed many more tokens to be processed than prior work, enhanced by efficienttoken merging and Gaussian pruning steps that balance between quality andefficiency. Unlike previous feed-forward models that are limited to processing1~4 input images and can only reconstruct a small portion of a large scene,Long-LRM reconstructs the entire scene in a single feed-forward step. Onlarge-scale scene datasets such as DL3DV-140 and Tanks and Temples, our methodachieves performance comparable to optimization-based approaches while beingtwo orders of magnitude more efficient. Project page:https://arthurhero.github.io/projects/llrm</description><author>Chen Ziwen, Hao Tan, Kai Zhang, Sai Bi, Fujun Luan, Yicong Hong, Li Fuxin, Zexiang Xu</author><pubDate>Wed, 16 Oct 2024 17:54:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12781v1</guid></item><item><title>Geometry-Aware Generative Autoencoders for Warped Riemannian Metric Learning and Generative Modeling on Data Manifolds</title><link>http://arxiv.org/abs/2410.12779v1</link><description>Rapid growth of high-dimensional datasets in fields such as single-cell RNAsequencing and spatial genomics has led to unprecedented opportunities forscientific discovery, but it also presents unique computational and statisticalchallenges. Traditional methods struggle with geometry-aware data generation,interpolation along meaningful trajectories, and transporting populations viafeasible paths. To address these issues, we introduce Geometry-Aware GenerativeAutoencoder (GAGA), a novel framework that combines extensible manifoldlearning with generative modeling. GAGA constructs a neural network embeddingspace that respects the intrinsic geometries discovered by manifold learningand learns a novel warped Riemannian metric on the data space. This warpedmetric is derived from both the points on the data manifold and negativesamples off the manifold, allowing it to characterize a meaningful geometryacross the entire latent space. Using this metric, GAGA can uniformly samplepoints on the manifold, generate points along geodesics, and interpolatebetween populations across the learned manifold. GAGA shows competitiveperformance in simulated and real world datasets, including a 30% improvementover the state-of-the-art methods in single-cell population-level trajectoryinference.</description><author>Xingzhi Sun, Danqi Liao, Kincaid MacDonald, Yanlei Zhang, Chen Liu, Guillaume Huguet, Guy Wolf, Ian Adelstein, Tim G. J. Rudner, Smita Krishnaswamy</author><pubDate>Wed, 16 Oct 2024 17:53:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12779v1</guid></item><item><title>Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via Convex Optimization</title><link>http://arxiv.org/abs/2405.14033v2</link><description>Training neural networks which are robust to adversarial attacks remains animportant problem in deep learning, especially as heavily overparameterizedmodels are adopted in safety-critical settings. Drawing from recent work whichreformulates the training problems for two-layer ReLU and polynomial activationnetworks as convex programs, we devise a convex semidefinite program (SDP) foradversarial training of two-layer polynomial activation networks and prove thatthe convex SDP achieves the same globally optimal solution as its nonconvexcounterpart. The convex SDP is observed to improve robust test accuracy against$\ell_\infty$ attacks relative to the original convex training formulation onmultiple datasets. Additionally, we present scalable implementations ofadversarial training for two-layer polynomial and ReLU networks which arecompatible with standard machine learning libraries and GPU acceleration.Leveraging these implementations, we retrain the final two fully connectedlayers of a Pre-Activation ResNet-18 model on the CIFAR-10 dataset with bothpolynomial and ReLU activations. The two `robustified' models achievesignificantly higher robust test accuracies against $\ell_\infty$ attacks thana Pre-Activation ResNet-18 model trained with sharpness-aware minimization,demonstrating the practical utility of convex adversarial training onlarge-scale problems.</description><author>Daniel Kuelbs, Sanjay Lall, Mert Pilanci</author><pubDate>Wed, 16 Oct 2024 17:52:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14033v2</guid></item><item><title>Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts</title><link>http://arxiv.org/abs/2410.12777v1</link><description>With the rapid progress of diffusion-based content generation, significantefforts are being made to unlearn harmful or copyrighted concepts frompretrained diffusion models (DMs) to prevent potential model misuse. However,it is observed that even when DMs are properly unlearned before release,malicious finetuning can compromise this process, causing DMs to relearn theunlearned concepts. This occurs partly because certain benign concepts (e.g.,"skin") retained in DMs are related to the unlearned ones (e.g., "nudity"),facilitating their relearning via finetuning. To address this, we proposemeta-unlearning on DMs. Intuitively, a meta-unlearned DM should behave like anunlearned DM when used as is; moreover, if the meta-unlearned DM undergoesmalicious finetuning on unlearned concepts, the related benign conceptsretained within it will be triggered to self-destruct, hindering the relearningof unlearned concepts. Our meta-unlearning framework is compatible with mostexisting unlearning methods, requiring only the addition of aneasy-to-implement meta objective. We validate our approach through empiricalexperiments on meta-unlearning concepts from Stable Diffusion models (SD-v1-4and SDXL), supported by extensive ablation studies. Our code is available athttps://github.com/sail-sg/Meta-Unlearning.</description><author>Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin</author><pubDate>Wed, 16 Oct 2024 17:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12777v1</guid></item><item><title>Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information</title><link>http://arxiv.org/abs/2410.12774v1</link><description>The success of multi-task learning can depend heavily on which tasks aregrouped together. Naively grouping all tasks or a random set of tasks canresult in negative transfer, with the multi-task models performing worse thansingle-task models. Though many efforts have been made to identify taskgroupings and to measure the relatedness among different tasks, it remains achallenging research topic to define a metric to identify the best taskgrouping out of a pool of many potential task combinations. We propose a metricof task relatedness based on task difficulty measured by pointwise V-usableinformation (PVI). PVI is a recently proposed metric to estimate how muchusable information a dataset contains given a model. We hypothesize that taskswith not statistically different PVI estimates are similar enough to benefitfrom the joint learning process. We conduct comprehensive experiments toevaluate the feasibility of this metric for task grouping on 15 NLP datasets inthe general, biomedical, and clinical domains. We compare the results of thejoint learners against single learners, existing baseline methods, and recentlarge language models, including Llama 2 and GPT-4. The results show that bygrouping tasks with similar PVI estimates, the joint learners yieldedcompetitive results with fewer total parameters, with consistent performanceacross domains.</description><author>Yingya Li, Timothy Miller, Steven Bethard, Guergana Savova</author><pubDate>Wed, 16 Oct 2024 17:49:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12774v1</guid></item><item><title>Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions</title><link>http://arxiv.org/abs/2410.12773v1</link><description>Humanoid robots, with their human-like embodiment, have the potential tointegrate seamlessly into human environments. Critical to their coexistence andcooperation with humans is the ability to understand natural languagecommunications and exhibit human-like behaviors. This work focuses ongenerating diverse whole-body motions for humanoid robots from languagedescriptions. We leverage human motion priors from extensive human motiondatasets to initialize humanoid motions and employ the commonsense reasoningcapabilities of Vision Language Models (VLMs) to edit and refine these motions.Our approach demonstrates the capability to produce natural, expressive, andtext-aligned humanoid motions, validated through both simulated and real-worldexperiments. More videos can be found athttps://ut-austin-rpl.github.io/Harmon/.</description><author>Zhenyu Jiang, Yuqi Xie, Jinhan Li, Ye Yuan, Yifeng Zhu, Yuke Zhu</author><pubDate>Wed, 16 Oct 2024 17:48:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12773v1</guid></item><item><title>Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks</title><link>http://arxiv.org/abs/2410.12772v1</link><description>Automatic modulation classification (AMC) serves a vital role in ensuringefficient and reliable communication services within distributed wirelessnetworks. Recent developments have seen a surge in interest in deep neuralnetwork (DNN)-based AMC models, with Federated Learning (FL) emerging as apromising framework. Despite these advancements, the presence of various noiseswithin the signal exerts significant challenges while optimizing models tocapture salient features. Furthermore, existing FL-based AMC models commonlyrely on linear aggregation strategies, which face notable difficulties inintegrating locally fine-tuned parameters within practical non-IID (Independentand Identically Distributed) environments, thereby hindering optimal learningconvergence. To address these challenges, we propose FedVaccine, a novel FLmodel aimed at improving generalizability across signals with varying noiselevels by deliberately introducing a balanced level of noise. This isaccomplished through our proposed harmonic noise resilience approach, whichidentifies an optimal noise tolerance for DNN models, thereby regulating thetraining process and mitigating overfitting. Additionally, FedVaccine overcomesthe limitations of existing FL-based AMC models' linear aggregation byemploying a split-learning strategy using structural clustering topology andlocal queue data structure, enabling adaptive and cumulative updates to localmodels. Our experimental results, including IID and non-IID datasets as well asablation studies, confirm FedVaccine's robust performance and superiority overexisting FL-based AMC approaches across different noise levels. These findingshighlight FedVaccine's potential to enhance the reliability and performance ofAMC systems in practical wireless network environments.</description><author>Hunmin Lee, Hongju Seong, Wonbin Kim, Hyeokchan Kwon, Daehee Seo</author><pubDate>Wed, 16 Oct 2024 17:48:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12772v1</guid></item><item><title>Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models</title><link>http://arxiv.org/abs/2410.12771v1</link><description>The ability to discover new materials with desirable properties is criticalfor numerous applications from helping mitigate climate change to advances innext generation computing hardware. AI has the potential to acceleratematerials discovery and design by more effectively exploring the chemical spacecompared to other computational methods or by trial-and-error. Whilesubstantial progress has been made on AI for materials data, benchmarks, andmodels, a barrier that has emerged is the lack of publicly available trainingdata and open pre-trained models. To address this, we present a Meta FAIRrelease of the Open Materials 2024 (OMat24) large-scale open dataset and anaccompanying set of pre-trained models. OMat24 contains over 110 milliondensity functional theory (DFT) calculations focused on structural andcompositional diversity. Our EquiformerV2 models achieve state-of-the-artperformance on the Matbench Discovery leaderboard and are capable of predictingground-state stability and formation energies to an F1 score above 0.9 and anaccuracy of 20 meV/atom, respectively. We explore the impact of model size,auxiliary denoising objectives, and fine-tuning on performance across a rangeof datasets including OMat24, MPtraj, and Alexandria. The open release of theOMat24 dataset and models enables the research community to build upon ourefforts and drive further advancements in AI-assisted materials science.</description><author>Luis Barroso-Luque, Muhammed Shuaibi, Xiang Fu, Brandon M. Wood, Misko Dzamba, Meng Gao, Ammar Rizvi, C. Lawrence Zitnick, Zachary W. Ulissi</author><pubDate>Wed, 16 Oct 2024 17:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12771v1</guid></item><item><title>BIRD: A Trustworthy Bayesian Inference Framework for Large Language Models</title><link>http://arxiv.org/abs/2404.12494v2</link><description>Predictive models often need to work with incomplete information inreal-world tasks. Consequently, they must provide reliable probability orconfidence estimation, especially in large-scale decision making and planningtasks. Current large language models (LLM) are insufficient for such accurateestimations, but they can generate relevant factors that may affect theprobabilities, produce coarse-grained probabilities when the information ismore complete, and help determine which factors are relevant to specificdownstream contexts. In this paper, we make use of these capabilities of LLMsto provide a significantly more accurate probabilistic estimation. We proposeBIRD, a novel probabilistic inference framework that aligns a Bayesian networkwith LLM abductions and then estimates more accurate probabilities in adeduction step. We show BIRD provides reliable probability estimations that are30\% better than those provided directly by LLM baselines. These estimates canfurther contribute to better and more trustworthy decision-making.</description><author>Yu Feng, Ben Zhou, Weidong Lin, Dan Roth</author><pubDate>Wed, 16 Oct 2024 17:45:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12494v2</guid></item><item><title>Towards Zero-Shot Camera Trap Image Categorization</title><link>http://arxiv.org/abs/2410.12769v1</link><description>This paper describes the search for an alternative approach to the automaticcategorization of camera trap images. First, we benchmark state-of-the-artclassifiers using a single model for all images. Next, we evaluate methodscombining MegaDetector with one or more classifiers and Segment Anything toassess their impact on reducing location-specific overfitting. Last, we proposeand test two approaches using large language and foundational models, such asDINOv2, BioCLIP, BLIP, and ChatGPT, in a zero-shot scenario. Evaluation carriedout on two publicly available datasets (WCT from New Zealand, CCT20 from theSouthwestern US) and a private dataset (CEF from Central Europe) revealed thatcombining MegaDetector with two separate classifiers achieves the highestaccuracy. This approach reduced the relative error of a single BEiTV2classifier by approximately 42\% on CCT20, 48\% on CEF, and 75\% on WCT.Besides, as the background is removed, the error in terms of accuracy in newlocations is reduced to half. The proposed zero-shot pipeline based on DINOv2and FAISS achieved competitive results (1.0\% and 4.7\% smaller on CCT20, andCEF, respectively), which highlights the potential of zero-shot approaches forcamera trap image categorization.</description><author>Jiří Vyskočil, Lukas Picek</author><pubDate>Wed, 16 Oct 2024 17:44:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12769v1</guid></item><item><title>The Non-Local Model Merging Problem: Permutation Symmetries and Variance Collapse</title><link>http://arxiv.org/abs/2410.12766v1</link><description>Model merging aims to efficiently combine the weights of multiple expertmodels, each trained on a specific task, into a single multi-task model, withstrong performance across all tasks. When applied to all but the last layer ofweights, existing methods -- such as Task Arithmetic, TIES-merging, and TALLmask merging -- work well to combine expert models obtained by fine-tuning acommon foundation model, operating within a "local" neighborhood of thefoundation model. This work explores the more challenging scenario of"non-local" merging, which we find arises when an expert model changessignificantly during pretraining or where the expert models do not even share acommon foundation model. We observe that standard merging techniques often fail to generalizeeffectively in this non-local setting, even when accounting for permutationsymmetries using standard techniques. We identify that this failure is, inpart, due to "variance collapse", a phenomenon identified also in the settingof linear mode connectivity by Jordan et al. (2023). To address this, wepropose a multi-task technique to re-scale and shift the output activations ofthe merged model for each task, aligning its output statistics with those ofthe corresponding task-specific expert models. Our experiments demonstrate thatthis correction significantly improves the performance of various model mergingapproaches in non-local settings, providing a strong baseline for futureresearch on this problem.</description><author>Ekansh Sharma, Daniel M. Roy, Gintare Karolina Dziugaite</author><pubDate>Wed, 16 Oct 2024 17:41:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12766v1</guid></item><item><title>Gravity-aligned Rotation Averaging with Circular Regression</title><link>http://arxiv.org/abs/2410.12763v1</link><description>Reconstructing a 3D scene from unordered images is pivotal in computer visionand robotics, with applications spanning crowd-sourced mapping and beyond.While global Structure-from-Motion (SfM) techniques are scalable and fast, theyoften compromise on accuracy. To address this, we introduce a principledapproach that integrates gravity direction into the rotation averaging phase ofglobal pipelines, enhancing camera orientation accuracy and reducing thedegrees of freedom. This additional information is commonly available in recentconsumer devices, such as smartphones, mixed-reality devices and drones, makingthe proposed method readily accessible. Rooted in circular regression, ouralgorithm has similar convergence guarantees as linear regression. It alsosupports scenarios where only a subset of cameras have known gravity.Additionally, we propose a mechanism to refine error-prone gravity. We achievestate-of-the-art accuracy on four large-scale datasets. Particularly, theproposed method improves upon the SfM baseline by 13 AUC@$1^\circ$ points, onaverage, while running eight times faster. It also outperforms the standardplanar pose graph optimization technique by 23 AUC@$1^\circ$ points. The codeis at https://github.com/colmap/glomap.</description><author>Linfei Pan, Marc Pollefeys, Dániel Baráth</author><pubDate>Wed, 16 Oct 2024 17:37:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12763v1</guid></item><item><title>An exactly solvable model for emergence and scaling laws in the multitask sparse parity problem</title><link>http://arxiv.org/abs/2404.17563v3</link><description>Deep learning models can exhibit what appears to be a sudden ability to solvea new problem as training time, training data, or model size increases, aphenomenon known as emergence. In this paper, we present a framework where eachnew ability (a skill) is represented as a basis function. We solve a simplemulti-linear model in this skill-basis, finding analytic expressions for theemergence of new skills, as well as for scaling laws of the loss with trainingtime, data size, model size, and optimal compute. We compare our detailedcalculations to direct simulations of a two-layer neural network trained onmultitask sparse parity, where the tasks in the dataset are distributedaccording to a power-law. Our simple model captures, using a single fitparameter, the sigmoidal emergence of multiple new skills as training time,data size or model size increases in the neural network.</description><author>Yoonsoo Nam, Nayara Fonseca, Seok Hyeong Lee, Chris Mingard, Ard A. Louis</author><pubDate>Wed, 16 Oct 2024 17:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17563v3</guid></item><item><title>SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation</title><link>http://arxiv.org/abs/2410.12761v1</link><description>Recent advances in diffusion models have significantly enhanced their abilityto generate high-quality images and videos, but they have also increased therisk of producing unsafe content. Existing unlearning/editing-based methods forsafe generation remove harmful concepts from models but face severalchallenges: (1) They cannot instantly remove harmful concepts without training.(2) Their safe generation capabilities depend on collected training data. (3)They alter model weights, risking degradation in quality for content unrelatedto toxic concepts. To address these, we propose SAFREE, a novel, training-freeapproach for safe T2I and T2V, that does not alter the model's weights.Specifically, we detect a subspace corresponding to a set of toxic concepts inthe text embedding space and steer prompt embeddings away from this subspace,thereby filtering out harmful content while preserving intended semantics. Tobalance the trade-off between filtering toxicity and preserving safe concepts,SAFREE incorporates a novel self-validating filtering mechanism thatdynamically adjusts the denoising steps when applying the filtered embeddings.Additionally, we incorporate adaptive re-attention mechanisms within thediffusion latent space to selectively diminish the influence of featuresrelated to toxic concepts at the pixel level. In the end, SAFREE ensurescoherent safety checking, preserving the fidelity, quality, and safety of theoutput. SAFREE achieves SOTA performance in suppressing unsafe content in T2Igeneration compared to training-free baselines and effectively filters targetedconcepts while maintaining high-quality images. It also shows competitiveresults against training-based methods. We extend SAFREE to various T2Ibackbones and T2V tasks, showcasing its flexibility and generalization. SAFREEprovides a robust and adaptable safeguard for ensuring safe visual generation.</description><author>Jaehong Yoon, Shoubin Yu, Vaidehi Patil, Huaxiu Yao, Mohit Bansal</author><pubDate>Wed, 16 Oct 2024 17:32:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12761v1</guid></item><item><title>Unitary Multi-Margin BERT for Robust Natural Language Processing</title><link>http://arxiv.org/abs/2410.12759v1</link><description>Recent developments in adversarial attacks on deep learning leave manymission-critical natural language processing (NLP) systems at risk ofexploitation. To address the lack of computationally efficient adversarialdefense methods, this paper reports a novel, universal technique thatdrastically improves the robustness of Bidirectional Encoder Representationsfrom Transformers (BERT) by combining the unitary weights with the multi-marginloss. We discover that the marriage of these two simple ideas amplifies theprotection against malicious interference. Our model, the unitary multi-marginBERT (UniBERT), boosts post-attack classification accuracies significantly by5.3% to 73.8% while maintaining competitive pre-attack accuracies. Furthermore,the pre-attack and post-attack accuracy tradeoff can be adjusted via a singlescalar parameter to best fit the design requirements for the targetapplications.</description><author>Hao-Yuan Chang, Kang L. Wang</author><pubDate>Wed, 16 Oct 2024 17:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12759v1</guid></item><item><title>StyleDistance: Stronger Content-Independent Style Embeddings with Synthetic Parallel Examples</title><link>http://arxiv.org/abs/2410.12757v1</link><description>Style representations aim to embed texts with similar writing styles closelyand texts with different styles far apart, regardless of content. However, thecontrastive triplets often used for training these representations may vary inboth style and content, leading to potential content leakage in therepresentations. We introduce StyleDistance, a novel approach to trainingstronger content-independent style embeddings. We use a large language model tocreate a synthetic dataset of near-exact paraphrases with controlled stylevariations, and produce positive and negative examples across 40 distinct stylefeatures for precise contrastive learning. We assess the quality of oursynthetic data and embeddings through human and automatic evaluations.StyleDistance enhances the content-independence of style embeddings, whichgeneralize to real-world benchmarks and outperform leading stylerepresentations in downstream applications. Our model can be found athttps://huggingface.co/StyleDistance/styledistance .</description><author>Ajay Patel, Jiacheng Zhu, Justin Qiu, Zachary Horvitz, Marianna Apidianaki, Kathleen McKeown, Chris Callison-Burch</author><pubDate>Wed, 16 Oct 2024 17:25:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12757v1</guid></item><item><title>Energy and Carbon Considerations of Fine-Tuning BERT</title><link>http://arxiv.org/abs/2311.10267v2</link><description>Despite the popularity of the `pre-train then fine-tune' paradigm in the NLPcommunity, existing work quantifying energy costs and associated carbonemissions has largely focused on language model pre-training. Although a singlepre-training run draws substantially more energy than fine-tuning, fine-tuningis performed more frequently by many more individual actors, and thus must beaccounted for when considering the energy and carbon footprint of NLP. In orderto better characterize the role of fine-tuning in the landscape of energy andcarbon emissions in NLP, we perform a careful empirical study of thecomputational costs of fine-tuning across tasks, datasets, hardwareinfrastructure and measurement modalities. Our experimental results allow us toplace fine-tuning energy and carbon costs into perspective with respect topre-training and inference, and outline recommendations to NLP researchers andpractitioners who wish to improve their fine-tuning energy efficiency.</description><author>Xiaorong Wang, Clara Na, Emma Strubell, Sorelle Friedler, Sasha Luccioni</author><pubDate>Wed, 16 Oct 2024 17:22:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10267v2</guid></item><item><title>Comparative Analysis of Extrinsic Factors for NER in French</title><link>http://arxiv.org/abs/2410.12750v1</link><description>Named entity recognition (NER) is a crucial task that aims to identifystructured information, which is often replete with complex, technical termsand a high degree of variability. Accurate and reliable NER can facilitate theextraction and analysis of important information. However, NER for other thanEnglish is challenging due to limited data availability, as the high expertise,time, and expenses are required to annotate its data. In this paper, by usingthe limited data, we explore various factors including model structure, corpusannotation scheme and data augmentation techniques to improve the performanceof a NER model for French. Our experiments demonstrate that these approachescan significantly improve the model's F1 score from original CRF score of 62.41to 79.39. Our findings suggest that considering different extrinsic factors andcombining these techniques is a promising approach for improving NERperformance where the size of data is limited.</description><author>Grace Yang, Zhiyi Li, Yandong Liu, Jungyeul Park</author><pubDate>Wed, 16 Oct 2024 17:12:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12750v1</guid></item><item><title>Initialization Method for Factorization Machine Based on Low-Rank Approximation for Constructing a Corrected Approximate Ising Model</title><link>http://arxiv.org/abs/2410.12747v1</link><description>This paper presents an initialization method that can approximate a givenapproximate Ising model with a high degree of accuracy using the FactorizationMachine (FM), a machine learning model. The construction of Ising models usingFM is applied to the combinatorial optimization problem using the factorizationmachine with quantum annealing. It is anticipated that the optimizationperformance of FMQA will be enhanced through the implementation of thewarm-start method. Nevertheless, the optimal initialization method forleveraging the warm-start approach in FMQA remains undetermined. Consequently,the present study compares a number of initialization methods and identifiesthe most appropriate for use with a warm-start in FMQA through numericalexperimentation. Furthermore, the properties of the proposed FM initializationmethod are analyzed using random matrix theory, demonstrating that theapproximation accuracy of the proposed method is not significantly influencedby the specific Ising model under consideration. The findings of this studywill facilitate the advancement of combinatorial optimization problem-solvingthrough the use of Ising machines.</description><author>Yuya Seki, Hyakka Nakada, Shu Tanaka</author><pubDate>Wed, 16 Oct 2024 17:06:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12747v1</guid></item><item><title>Preferential Normalizing Flows</title><link>http://arxiv.org/abs/2410.08710v2</link><description>Eliciting a high-dimensional probability distribution from an expert vianoisy judgments is notoriously challenging, yet useful for many applications,such as prior elicitation and reward modeling. We introduce a method foreliciting the expert's belief density as a normalizing flow based solely onpreferential questions such as comparing or ranking alternatives. This allowseliciting in principle arbitrarily flexible densities, but flow estimation issusceptible to the challenge of collapsing or diverging probability mass thatmakes it difficult in practice. We tackle this problem by introducing a novelfunctional prior for the flow, motivated by a decision-theoretic argument, andshow empirically that the belief density can be inferred as the function-spacemaximum a posteriori estimate. We demonstrate our method by elicitingmultivariate belief densities of simulated experts, including the prior beliefof a general-purpose large language model over a real-world dataset.</description><author>Petrus Mikkola, Luigi Acerbi, Arto Klami</author><pubDate>Wed, 16 Oct 2024 17:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08710v2</guid></item><item><title>Preserving Cardiac Integrity: A Topology-Infused Approach to Whole Heart Segmentation</title><link>http://arxiv.org/abs/2410.10551v2</link><description>Whole heart segmentation (WHS) supports cardiovascular disease (CVD)diagnosis, disease monitoring, treatment planning, and prognosis. Deep learninghas become the most widely used method for WHS applications in recent years.However, segmentation of whole-heart structures faces numerous challengesincluding heart shape variability during the cardiac cycle, clinical artifactslike motion and poor contrast-to-noise ratio, domain shifts in multi-centerdata, and the distinct modalities of CT and MRI. To address these limitationsand improve segmentation quality, this paper introduces a newtopology-preserving module that is integrated into deep neural networks. Theimplementation achieves anatomically plausible segmentation by using learnedtopology-preserving fields, which are based entirely on 3D convolution and aretherefore very effective for 3D voxel data. We incorporate natural constraintsbetween structures into the end-to-end training and enrich the featurerepresentation of the neural network. The effectiveness of the proposed methodis validated on an open-source medical heart dataset, specifically using theWHS++ data. The results demonstrate that the architecture performsexceptionally well, achieving a Dice coefficient of 0.939 during testing. Thisindicates full topology preservation for individual structures andsignificantly outperforms other baselines in preserving the overall scenetopology.</description><author>Chenyu Zhang, Wenxue Guan, Xiaodan Xing, Guang Yang</author><pubDate>Wed, 16 Oct 2024 17:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10551v2</guid></item><item><title>PND-Net: Plant Nutrition Deficiency and Disease Classification using Graph Convolutional Network</title><link>http://arxiv.org/abs/2410.12742v1</link><description>Crop yield production could be enhanced for agricultural growth if variousplant nutrition deficiencies, and diseases are identified and detected at earlystages. The deep learning methods have proven its superior performances in theautomated detection of plant diseases and nutrition deficiencies from visualsymptoms in leaves. This article proposes a new deep learning method for plantnutrition deficiencies and disease classification using a graph convolutionalnetwork (GNN), added upon a base convolutional neural network (CNN). Sometimes,a global feature descriptor might fail to capture the vital region of adiseased leaf, which causes inaccurate classification of disease. To addressthis issue, regional feature learning is crucial for a holistic featureaggregation. In this work, region-based feature summarization at multi-scalesis explored using spatial pyramidal pooling for discriminative featurerepresentation. A GCN is developed to capacitate learning of finer details forclassifying plant diseases and insufficiency of nutrients. The proposed method,called Plant Nutrition Deficiency and Disease Network (PND-Net), is evaluatedon two public datasets for nutrition deficiency, and two for diseaseclassification using four CNNs. The best classification performances are: (a)90.00% Banana and 90.54% Coffee nutrition deficiency; and (b) 96.18% Potatodiseases and 84.30% on PlantDoc datasets using Xception backbone. Furthermore,additional experiments have been carried out for generalization, and theproposed method has achieved state-of-the-art performances on two publicdatasets, namely the Breast Cancer Histopathology Image Classification(BreakHis 40X: 95.50%, and BreakHis 100X: 96.79% accuracy) and Single cells inPap smear images for cervical cancer classification (SIPaKMeD: 99.18%accuracy). Also, PND-Net achieves improved performances using five-fold crossvalidation.</description><author>Asish Bera, Debotosh Bhattacharjee, Ondrej Krejcar</author><pubDate>Wed, 16 Oct 2024 17:01:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12742v1</guid></item><item><title>ÚFAL CorPipe at CRAC 2023: Larger Context Improves Multilingual Coreference Resolution</title><link>http://arxiv.org/abs/2311.14391v3</link><description>We present CorPipe, the winning entry to the CRAC 2023 Shared Task onMultilingual Coreference Resolution. Our system is an improved version of ourearlier multilingual coreference pipeline, and it surpasses other participantsby a large margin of 4.5 percent points. CorPipe first performs mentiondetection, followed by coreference linking via an antecedent-maximizationapproach on the retrieved spans. Both tasks are trained jointly on allavailable corpora using a shared pretrained language model. Our mainimprovements comprise inputs larger than 512 subwords and changing the mentiondecoding to support ensembling. The source code is available athttps://github.com/ufal/crac2023-corpipe.</description><author>Milan Straka</author><pubDate>Wed, 16 Oct 2024 17:01:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14391v3</guid></item><item><title>On the Effective Horizon of Inverse Reinforcement Learning</title><link>http://arxiv.org/abs/2307.06541v2</link><description>Inverse reinforcement learning (IRL) algorithms often rely on (forward)reinforcement learning or planning over a given time horizon to compute anapproximately optimal policy for a hypothesized reward function and then matchthis policy with expert demonstrations. The time horizon plays a critical rolein determining both the accuracy of reward estimates and the computationalefficiency of IRL algorithms. Interestingly, an \emph{effective time horizon}shorter than the ground-truth value often produces better results faster. Thiswork formally analyzes this phenomenon and provides an explanation: the timehorizon controls the complexity of an induced policy class and mitigatesoverfitting with limited data. This analysis serves as a guide for theprincipled choice of the effective horizon for IRL. It also prompts us tore-examine the classic IRL formulation: it is more natural to learn jointly thereward and the effective horizon rather than the reward alone with a givenhorizon. To validate our findings, we implement a cross-validation extensionand the experimental results confirm the theoretical analysis.</description><author>Yiqing Xu, Finale Doshi-Velez, David Hsu</author><pubDate>Wed, 16 Oct 2024 16:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06541v2</guid></item><item><title>ÚFAL CorPipe at CRAC 2022: Effectivity of Multilingual Models for Coreference Resolution</title><link>http://arxiv.org/abs/2209.07278v3</link><description>We describe the winning submission to the CRAC 2022 Shared Task onMultilingual Coreference Resolution. Our system first solves mention detectionand then coreference linking on the retrieved spans with anantecedent-maximization approach, and both tasks are fine-tuned jointly withshared Transformer weights. We report results of fine-tuning a wide range ofpretrained models. The center of this contribution are fine-tuned multilingualmodels. We found one large multilingual model with sufficiently large encoderto increase performance on all datasets across the board, with the benefit notlimited only to the underrepresented languages or groups of typologicallyrelative languages. The source code is available athttps://github.com/ufal/crac2022-corpipe.</description><author>Milan Straka, Jana Straková</author><pubDate>Wed, 16 Oct 2024 16:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.07278v3</guid></item><item><title>Deep Optimal Experimental Design for Parameter Estimation Problems</title><link>http://arxiv.org/abs/2406.14003v3</link><description>Optimal experimental design is a well studied field in applied science andengineering. Techniques for estimating such a design are commonly used withinthe framework of parameter estimation. Nonetheless, in recent years parameterestimation techniques are changing rapidly with the introduction of deeplearning techniques to replace traditional estimation methods. This in turnrequires the adaptation of optimal experimental design that is associated withthese new techniques. In this paper we investigate a new experimental designmethodology that uses deep learning. We show that the training of a network asa Likelihood Free Estimator can be used to significantly simplify the designprocess and circumvent the need for the computationally expensive bi-leveloptimization problem that is inherent in optimal experimental design fornon-linear systems. Furthermore, deep design improves the quality of therecovery process for parameter estimation problems. As proof of concept weapply our methodology to two different systems of Ordinary DifferentialEquations.</description><author>Md Shahriar Rahim Siddiqui, Arman Rahmim, Eldad Haber</author><pubDate>Wed, 16 Oct 2024 16:51:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14003v3</guid></item><item><title>CREAM: Consistency Regularized Self-Rewarding Language Models</title><link>http://arxiv.org/abs/2410.12735v1</link><description>Recent self-rewarding large language models (LLM) have successfully appliedLLM-as-a-Judge to iteratively improve the alignment performance without theneed of human annotations for preference data. These methods commonly utilizethe same LLM to act as both the policy model (which generates responses) andthe reward model (which scores and ranks those responses). The ranked responsesare then used as preference pairs to train the LLM via direct alignmenttechnologies (e.g. DPO). However, it is noteworthy that throughout thisprocess, there is no guarantee of accuracy in the rewarding and ranking, whichis critical for ensuring accurate rewards and high-quality preference data.Empirical results from relatively small LLMs (e.g., 7B parameters) alsoindicate that improvements from self-rewarding may diminish after severaliterations in certain situations, which we hypothesize is due to accumulatedbias in the reward system. This bias can lead to unreliable preference data fortraining the LLM. To address this issue, we first formulate and analyze thegeneralized iterative preference fine-tuning framework for self-rewardinglanguage model. We then introduce the regularization to this generalizedframework to mitigate the overconfident preference labeling in theself-rewarding process. Based on this theoretical insight, we propose aConsistency Regularized sElf-rewarding lAnguage Model (CREAM) that leveragesthe rewarding consistency across different iterations to regularize theself-rewarding training, helping the model to learn from more reliablepreference data. With this explicit regularization, our empirical resultsdemonstrate the superiority of CREAM in improving both reward consistency andalignment performance. The code is publicly available athttps://github.com/Raibows/CREAM.</description><author>Zhaoyang Wang, Weilei He, Zhiyuan Liang, Xuchao Zhang, Chetan Bansal, Ying Wei, Weitong Zhang, Huaxiu Yao</author><pubDate>Wed, 16 Oct 2024 16:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12735v1</guid></item><item><title>Counterfactual Generative Modeling with Variational Causal Inference</title><link>http://arxiv.org/abs/2410.12730v1</link><description>Estimating an individual's potential outcomes under counterfactual treatmentsis a challenging task for traditional causal inference and supervised learningapproaches when the outcome is high-dimensional (e.g. gene expressions, facialimages) and covariates are relatively limited. In this case, to predict one'soutcomes under counterfactual treatments, it is crucial to leverage individualinformation contained in its high-dimensional observed outcome in addition tothe covariates. Prior works using variational inference in counterfactualgenerative modeling have been focusing on neural adaptations and model variantswithin the conditional variational autoencoder formulation, which we argue isfundamentally ill-suited to the notion of counterfactual in causal inference.In this work, we present a novel variational Bayesian causal inferenceframework and its theoretical backings to properly handle counterfactualgenerative modeling tasks, through which we are able to conduct counterfactualsupervision end-to-end during training without any counterfactual samples, andencourage latent disentanglement that aids the correct identification of causaleffect in counterfactual generations. In experiments, we demonstrate theadvantage of our framework compared to state-of-the-art models incounterfactual generative modeling on multiple benchmarks.</description><author>Yulun Wu, Louie McConnell, Claudia Iriondo</author><pubDate>Wed, 16 Oct 2024 16:44:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12730v1</guid></item><item><title>Transformer based super-resolution downscaling for regional reanalysis: Full domain vs tiling approaches</title><link>http://arxiv.org/abs/2410.12728v1</link><description>Super-resolution (SR) is a promising cost-effective downscaling methodologyfor producing high-resolution climate information from coarser counterparts. Aparticular application is downscaling regional reanalysis outputs (predictand)from the driving global counterparts (predictor). This study conducts anintercomparison of various SR downscaling methods focusing on temperature andusing the CERRA reanalysis (5.5 km resolution, produced with a regionalatmospheric model driven by ERA5) as example. The method proposed in this workis the Swin transformer and two alternative methods are used as benchmark(fully convolutional U-Net and convolutional and dense DeepESD) as well as thesimple bicubic interpolation. We compare two approaches, the standard one usingthe full domain as input and a more scalable tiling approach, dividing the fulldomain into tiles that are used as input. The methods are trained to downscaleCERRA surface temperature, based on temperature information from the drivingERA5; in addition, the tiling approach includes static orographic information.We show that the tiling approach, which requires spatial transferability, comesat the cost of a lower performance (although it outperforms some full-domainbenchmarks), but provides an efficient scalable solution that allows SRreduction on a pan-European scale and is valuable for real-time applications.</description><author>Antonio Pérez, Mario Santa Cruz, Daniel San Martín, José Manuel Gutiérrez</author><pubDate>Wed, 16 Oct 2024 16:42:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12728v1</guid></item><item><title>Likelihood-based Differentiable Structure Learning</title><link>http://arxiv.org/abs/2410.06163v2</link><description>Existing approaches to differentiable structure learning of directed acyclicgraphs (DAGs) rely on strong identifiability assumptions in order to guaranteethat global minimizers of the acyclicity-constrained optimization problemidentifies the true DAG. Moreover, it has been observed empirically that theoptimizer may exploit undesirable artifacts in the loss function. We explainand remedy these issues by studying the behavior of differentiableacyclicity-constrained programs under general likelihoods with multiple globalminimizers. By carefully regularizing the likelihood, it is possible toidentify the sparsest model in the Markov equivalence class, even in theabsence of an identifiable parametrization. We first study the Gaussian case indetail, showing how proper regularization of the likelihood defines a scorethat identifies the sparsest model. Assuming faithfulness, it also recovers theMarkov equivalence class. These results are then generalized to general modelsand likelihoods, where the same claims hold. These theoretical results arevalidated empirically, showing how this can be done using standardgradient-based optimizers, thus paving the way for differentiable structurelearning under general models and losses.</description><author>Chang Deng, Kevin Bello, Pradeep Ravikumar, Bryon Aragam</author><pubDate>Wed, 16 Oct 2024 16:40:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06163v2</guid></item><item><title>Optimizing 3D Geometry Reconstruction from Implicit Neural Representations</title><link>http://arxiv.org/abs/2410.12725v1</link><description>Implicit neural representations have emerged as a powerful tool in learning3D geometry, offering unparalleled advantages over conventional representationslike mesh-based methods. A common type of INR implicitly encodes a shape'sboundary as the zero-level set of the learned continuous function and learns amapping from a low-dimensional latent space to the space of all possible shapesrepresented by its signed distance function. However, most INRs struggle toretain high-frequency details, which are crucial for accurate geometricdepiction, and they are computationally expensive. To address theselimitations, we present a novel approach that both reduces computationalexpenses and enhances the capture of fine details. Our method integratesperiodic activation functions, positional encodings, and normals into theneural network architecture. This integration significantly enhances themodel's ability to learn the entire space of 3D shapes while preservingintricate details and sharp features, areas where conventional representationsoften fall short.</description><author>Shen Fan, Przemyslaw Musialski</author><pubDate>Wed, 16 Oct 2024 16:36:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12725v1</guid></item><item><title>SplitLLM: Collaborative Inference of LLMs for Model Placement and Throughput Optimization</title><link>http://arxiv.org/abs/2410.10759v2</link><description>Large language models (LLMs) have been a disruptive innovation in recentyears, and they play a crucial role in our daily lives due to their ability tounderstand and generate human-like text. Their capabilities include naturallanguage understanding, information retrieval and search, translation,chatbots, virtual assistance, and many more. However, it is well known thatLLMs are massive in terms of the number of parameters. Additionally, theself-attention mechanism in the underlying architecture of LLMs, Transformers,has quadratic complexity in terms of both computation and memory with respectto the input sequence length. For these reasons, LLM inference isresource-intensive, and thus, the throughput of LLM inference is limited,especially for the longer sequences. In this report, we design a collaborativeinference architecture between a server and its clients to alleviate thethroughput limit. In this design, we consider the available resources on bothsides, i.e., the computation and communication costs. We develop a dynamicprogramming-based algorithm to optimally allocate computation between theserver and the client device to increase the server throughput, while notviolating the service level agreement (SLA). We show in the experiments that weare able to efficiently distribute the workload allowing for roughly 1/3reduction in the server workload, while achieving 19 percent improvement over agreedy method. As a result, we are able to demonstrate that, in an environmentwith different types of LLM inference requests, the throughput of the server isimproved.</description><author>Akrit Mudvari, Yuang Jiang, Leandros Tassiulas</author><pubDate>Wed, 16 Oct 2024 16:31:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10759v2</guid></item><item><title>WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation</title><link>http://arxiv.org/abs/2410.12722v1</link><description>Multimodal/vision language models (VLMs) are increasingly being deployed inhealthcare settings worldwide, necessitating robust benchmarks to ensure theirsafety, efficacy, and fairness. Multiple-choice question and answer (QA)datasets derived from national medical examinations have long served asvaluable evaluation tools, but existing datasets are largely text-only andavailable in a limited subset of languages and countries. To address thesechallenges, we present WorldMedQA-V, an updated multilingual, multimodalbenchmarking dataset designed to evaluate VLMs in healthcare. WorldMedQA-Vincludes 568 labeled multiple-choice QAs paired with 568 medical images fromfour countries (Brazil, Israel, Japan, and Spain), covering original languagesand validated English translations by native clinicians, respectively. Baselineperformance for common open- and closed-source models are provided in the locallanguage and English translations, and with and without images provided to themodel. The WorldMedQA-V benchmark aims to better match AI systems to thediverse healthcare environments in which they are deployed, fostering moreequitable, effective, and representative applications.</description><author>João Matos, Shan Chen, Siena Placino, Yingya Li, Juan Carlos Climent Pardo, Daphna Idan, Takeshi Tohyama, David Restrepo, Luis F. Nakayama, Jose M. M. Pascual-Leone, Guergana Savova, Hugo Aerts, Leo A. Celi, A. Ian Wong, Danielle S. Bitterman, Jack Gallifant</author><pubDate>Wed, 16 Oct 2024 16:31:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12722v1</guid></item><item><title>HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts</title><link>http://arxiv.org/abs/2410.12720v1</link><description>This project, named HEnRY, aims to introduce a Multi-Agent System (MAS) intoIntesa Sanpaolo. The name HEnRY summarizes the project's core principles: theHierarchical organization of agents in a layered structure for efficientresource management; Efficient optimization of resources and operations toenhance overall performance; Reactive ability of agents to quickly respond toenvironmental stimuli; and Yielding adaptability and flexibility of agents tohandle unexpected situations. The discussion covers two distinct researchpaths: the first focuses on the system architecture, and the second on thecollaboration between agents. This work is not limited to the specificstructure of the Intesa Sanpaolo context; instead, it leverages existingresearch in MAS to introduce a new solution. Since Intesa Sanpaolo is organizedaccording to a model that aligns with international corporate governance bestpractices, this approach could also be relevant to similar scenarios.</description><author>Emmanuele Lacavalla, Shuyi Yang, Riccardo Crupi, Joseph E. Gonzalez</author><pubDate>Wed, 16 Oct 2024 16:28:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12720v1</guid></item><item><title>RAFA-Net: Region Attention Network For Food Items And Agricultural Stress Recognition</title><link>http://arxiv.org/abs/2410.12718v1</link><description>Deep Convolutional Neural Networks (CNNs) have facilitated remarkable successin recognizing various food items and agricultural stress. A decent performanceboost has been witnessed in solving the agro-food challenges by mining andanalyzing of region-based partial feature descriptors. Also, computationallyexpensive ensemble learning schemes using multiple CNNs have been studied inearlier works. This work proposes a region attention scheme for modellinglong-range dependencies by building a correlation among different regionswithin an input image. The attention method enhances feature representation bylearning the usefulness of context information from complementary regions.Spatial pyramidal pooling and average pooling pair aggregate partialdescriptors into a holistic representation. Both pooling methods establishspatial and channel-wise relationships without incurring extra parameters. Acontext gating scheme is applied to refine the descriptiveness of weightedattentional features, which is relevant for classification. The proposed RegionAttention network for Food items and Agricultural stress recognition method,dubbed RAFA-Net, has been experimented on three public food datasets, and hasachieved state-of-the-art performances with distinct margins. The highest top-1accuracies of RAFA-Net are 91.69%, 91.56%, and 96.97% on the UECFood-100,UECFood-256, and MAFood-121 datasets, respectively. In addition, betteraccuracies have been achieved on two benchmark agricultural stress datasets.The best top-1 accuracies on the Insect Pest (IP-102) and PlantDoc-27 plantdisease datasets are 92.36%, and 85.54%, respectively; implying RAFA-Net'sgeneralization capability.</description><author>Asish Bera, Ondrej Krejcar, Debotosh Bhattacharjee</author><pubDate>Wed, 16 Oct 2024 16:28:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12718v1</guid></item><item><title>Diffusion Language Models Are Versatile Protein Learners</title><link>http://arxiv.org/abs/2402.18567v2</link><description>This paper introduces diffusion protein language model (DPLM), a versatileprotein language model that demonstrates strong generative and predictivecapabilities for protein sequences. We first pre-train scalable DPLMs fromevolutionary-scale protein sequences within a generative self-superviseddiscrete diffusion probabilistic framework, which generalizes language modelingfor proteins in a principled way. After pre-training, DPLM exhibits the abilityto generate structurally plausible, novel, and diverse protein sequences forunconditional generation. We further demonstrate the proposed diffusiongenerative pre-training makes DPLM possess a better understanding of proteins,making it a superior representation learner, which can be fine-tuned forvarious predictive tasks, comparing favorably to ESM2 (Lin et al., 2022).Moreover, DPLM can be tailored for various needs, which showcases its prowessof conditional generation in several ways: (1) conditioning on partial peptidesequences, e.g., generating scaffolds for functional motifs with high successrate; (2) incorporating other modalities as conditioner, e.g.,structure-conditioned generation for inverse folding; and (3) steering sequencegeneration towards desired properties, e.g., satisfying specified secondarystructures, through a plug-and-play classifier guidance. Code is released at\url{https://github.com/bytedance/dplm}.</description><author>Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, Quanquan Gu</author><pubDate>Wed, 16 Oct 2024 16:26:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18567v2</guid></item><item><title>Extreme time extrapolation capabilities and thermodynamic consistency of physics-inspired Neural Networks for the 3D microstructure evolution of materials via Cahn-Hilliard flow</title><link>http://arxiv.org/abs/2407.20126v2</link><description>A Convolutional Recurrent Neural Network (CRNN) is trained to reproduce theevolution of the spinodal decomposition process in three dimensions asdescribed by the Cahn-Hilliard equation. A specialized, physics-inspiredarchitecture is proven to provide close accordance between the predictedevolutions and the ground truth ones obtained via conventional integrationschemes. The method can accurately reproduce the evolution of microstructuresnot represented in the training set at a fraction of the computational costs.Extremely long-time extrapolation capabilities are achieved, up to reaching thetheoretically expected equilibrium state of the system, consisting of alayered, phase-separated morphology, despite the training set containing onlyrelatively-short, initial phases of the evolution. Quantitative accordance withthe decay rate of the Free energy is also demonstrated up to the latecoarsening stages, proving that this class of Machine Learning approaches canbecome a new and powerful tool for the long timescale and high throughputsimulation of materials, while retaining thermodynamic consistency andhigh-accuracy.</description><author>Daniele Lanzoni, Andrea Fantasia, Roberto Bergamaschini, Olivier Pierre-Louis, Francesco Montalenti</author><pubDate>Wed, 16 Oct 2024 16:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20126v2</guid></item><item><title>How Does Variance Shape the Regret in Contextual Bandits?</title><link>http://arxiv.org/abs/2410.12713v1</link><description>We consider realizable contextual bandits with general functionapproximation, investigating how small reward variance can lead tobetter-than-minimax regret bounds. Unlike in minimax bounds, we show that theeluder dimension $d_\text{elu}$$-$a complexity measure of the functionclass$-$plays a crucial role in variance-dependent bounds. We consider twotypes of adversary: (1) Weak adversary: The adversary sets the reward variance before observingthe learner's action. In this setting, we prove that a regret of$\Omega(\sqrt{\min\{A,d_\text{elu}\}\Lambda}+d_\text{elu})$ is unavoidable when$d_{\text{elu}}\leq\sqrt{AT}$, where $A$ is the number of actions, $T$ is thetotal number of rounds, and $\Lambda$ is the total variance over $T$ rounds.For the $A\leq d_\text{elu}$ regime, we derive a nearly matching upper bound$\tilde{O}(\sqrt{A\Lambda}+d_\text{elu})$ for the special case where thevariance is revealed at the beginning of each round. (2) Strong adversary: The adversary sets the reward variance after observingthe learner's action. We show that a regret of$\Omega(\sqrt{d_\text{elu}\Lambda}+d_\text{elu})$ is unavoidable when$\sqrt{d_\text{elu}\Lambda}+d_\text{elu}\leq\sqrt{AT}$. In this setting, weprovide an upper bound of order$\tilde{O}(d_\text{elu}\sqrt{\Lambda}+d_\text{elu})$. Furthermore, we examine the setting where the function class additionallyprovides distributional information of the reward, as studied by Wang et al.(2024). We demonstrate that the regret bound$\tilde{O}(\sqrt{d_\text{elu}\Lambda}+d_\text{elu})$ established in their workis unimprovable when $\sqrt{d_{\text{elu}}\Lambda}+d_\text{elu}\leq\sqrt{AT}$.However, with a slightly different definition of the total variance and withthe assumption that the reward follows a Gaussian distribution, one can achievea regret of $\tilde{O}(\sqrt{A\Lambda}+d_\text{elu})$.</description><author>Zeyu Jia, Jian Qian, Alexander Rakhlin, Chen-Yu Wei</author><pubDate>Wed, 16 Oct 2024 16:20:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12713v1</guid></item><item><title>On the sample complexity of purity and inner product estimation</title><link>http://arxiv.org/abs/2410.12712v1</link><description>We study the sample complexity of the prototypical tasks quantum purityestimation and quantum inner product estimation. In purity estimation, we areto estimate $tr(\rho^2)$ of an unknown quantum state $\rho$ to additive error$\epsilon$. Meanwhile, for quantum inner product estimation, Alice and Bob areto estimate $tr(\rho\sigma)$ to additive error $\epsilon$ given copies ofunknown quantum state $\rho$ and $\sigma$ using classical communication andrestricted quantum communication. In this paper, we show a strong connection between the sample complexity ofpurity estimation with bounded quantum memory and inner product estimation withbounded quantum communication and unentangled measurements. We propose aprotocol that solves quantum inner product estimation with $k$-qubit one-wayquantum communication and unentangled local measurements using$O(median\{1/\epsilon^2,2^{n/2}/\epsilon,2^{n-k}/\epsilon^2\})$ copies of$\rho$ and $\sigma$. Our protocol can be modified to estimate the purity of anunknown quantum state $\rho$ using $k$-qubit quantum memory with the samecomplexity. We prove that arbitrary protocols with $k$-qubit quantum memorythat estimate purity to error $\epsilon$ require$\Omega(median\{1/\epsilon^2,2^{n/2}/\sqrt{\epsilon},2^{n-k}/\epsilon^2\})$copies of $\rho$. This indicates the same lower bound for quantum inner productestimation with one-way $k$-qubit quantum communication and classicalcommunication, and unentangled local measurements. For purity estimation, wefurther improve the lower bound to$\Omega(\max\{1/\epsilon^2,2^{n/2}/\epsilon\})$ for any protocols using anidentical single-copy projection-valued measurement. Additionally, we investigate a decisional variant of quantum distributedinner product estimation without quantum communication for mixed state andprovide a lower bound on the sample complexity.</description><author>Weiyuan Gong, Jonas Haferkamp, Qi Ye, Zhihan Zhang</author><pubDate>Wed, 16 Oct 2024 16:17:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12712v1</guid></item><item><title>Open-Source Conversational AI with SpeechBrain 1.0</title><link>http://arxiv.org/abs/2407.00463v5</link><description>SpeechBrain is an open-source Conversational AI toolkit based on PyTorch,focused particularly on speech processing tasks such as speech recognition,speech enhancement, speaker recognition, text-to-speech, and much more. Itpromotes transparency and replicability by releasing both the pre-trainedmodels and the complete "recipes" of code and algorithms required for trainingthem. This paper presents SpeechBrain 1.0, a significant milestone in theevolution of the toolkit, which now has over 200 recipes for speech, audio, andlanguage processing tasks, and more than 100 models available on Hugging Face.SpeechBrain 1.0 introduces new technologies to support diverse learningmodalities, Large Language Model (LLM) integration, and advanced decodingstrategies, along with novel models, tasks, and modalities. It also includes anew benchmark repository, offering researchers a unified platform forevaluating models across diverse tasks.</description><author>Mirco Ravanelli, Titouan Parcollet, Adel Moumen, Sylvain de Langen, Cem Subakan, Peter Plantinga, Yingzhi Wang, Pooneh Mousavi, Luca Della Libera, Artem Ploujnikov, Francesco Paissan, Davide Borra, Salah Zaiem, Zeyu Zhao, Shucong Zhang, Georgios Karakasidis, Sung-Lin Yeh, Pierre Champion, Aku Rouhe, Rudolf Braun, Florian Mai, Juan Zuluaga-Gomez, Seyed Mahed Mousavi, Andreas Nautsch, Xuechen Liu, Sangeet Sagar, Jarod Duret, Salima Mdhaffar, Gaelle Laperriere, Mickael Rouvier, Renato De Mori, Yannick Esteve</author><pubDate>Wed, 16 Oct 2024 16:13:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00463v5</guid></item><item><title>FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression</title><link>http://arxiv.org/abs/2410.12707v1</link><description>To alleviate hardware scarcity in training large deep neural networks (DNNs),particularly large language models (LLMs), we present FusionLLM, adecentralized training system designed and implemented for training DNNs usinggeo-distributed GPUs across different computing clusters or individual devices.Decentralized training faces significant challenges regarding system design andefficiency, including: 1) the need for remote automatic differentiation (RAD),2) support for flexible model definitions and heterogeneous software, 3)heterogeneous hardware leading to low resource utilization or the stragglerproblem, and 4) slow network communication. To address these challenges, in thesystem design, we represent the model as a directed acyclic graph of operators(OP-DAG). Each node in the DAG represents the operator in the DNNs, while theedge represents the data dependency between operators. Based on this design, 1)users are allowed to customize any DNN without caring low-level operatorimplementation; 2) we enable the task scheduling with the more fine-grainedsub-tasks, offering more optimization space; 3) a DAG runtime executor canimplement RAD withour requiring the consistent low-level ML framework versions. To enhance system efficiency, we implement a workload estimator and design anOP-Fence scheduler to cluster devices with similar bandwidths together andpartition the DAG to increase throughput. Additionally, we propose an AdaTopKcompressor to adaptively compress intermediate activations and gradients at theslowest communication links. To evaluate the convergence and efficiency of oursystem and algorithms, we train ResNet-101 and GPT-2 on three real-worldtestbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimentalresults demonstrate that our system and method can achieve 1.45 - 9.39x speedupcompared to baseline methods while ensuring convergence.</description><author>Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu</author><pubDate>Wed, 16 Oct 2024 16:13:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12707v1</guid></item><item><title>Nearly Tight Black-Box Auditing of Differentially Private Machine Learning</title><link>http://arxiv.org/abs/2405.14106v2</link><description>This paper presents an auditing procedure for the Differentially PrivateStochastic Gradient Descent (DP-SGD) algorithm in the black-box threat modelthat is substantially tighter than prior work. The main intuition is to craftworst-case initial model parameters, as DP-SGD's privacy analysis is agnosticto the choice of the initial model parameters. For models trained on MNIST andCIFAR-10 at theoretical $\varepsilon=10.0$, our auditing procedure yieldsempirical estimates of $\varepsilon_{emp} = 7.21$ and $6.95$, respectively, ona 1,000-record sample and $\varepsilon_{emp}= 6.48$ and $4.96$ on the fulldatasets. By contrast, previous audits were only (relatively) tight in strongerwhite-box models, where the adversary can access the model's inner parametersand insert arbitrary gradients. Overall, our auditing procedure can offervaluable insight into how the privacy analysis of DP-SGD could be improved anddetect bugs and DP violations in real-world implementations. The source codeneeded to reproduce our experiments is available athttps://github.com/spalabucr/bb-audit-dpsgd.</description><author>Meenatchi Sundaram Muthu Selva Annamalai, Emiliano De Cristofaro</author><pubDate>Wed, 16 Oct 2024 16:13:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14106v2</guid></item><item><title>WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines</title><link>http://arxiv.org/abs/2410.12705v1</link><description>Vision Language Models (VLMs) often struggle with culture-specific knowledge,particularly in languages other than English and in underrepresented culturalcontexts. To evaluate their understanding of such knowledge, we introduceWorldCuisines, a massive-scale benchmark for multilingual and multicultural,visually grounded language understanding. This benchmark includes a visualquestion answering (VQA) dataset with text-image pairs across 30 languages anddialects, spanning 9 language families and featuring over 1 million datapoints, making it the largest multicultural VQA benchmark to date. It includestasks for identifying dish names and their origins. We provide evaluationdatasets in two sizes (12k and 60k instances) alongside a training dataset (1million instances). Our findings show that while VLMs perform better withcorrect location context, they struggle with adversarial contexts andpredicting specific regional cuisines and languages. To support futureresearch, we release a knowledge base with annotated food entries and imagesalong with the VQA data.</description><author>Genta Indra Winata, Frederikus Hudi, Patrick Amadeus Irawan, David Anugraha, Rifki Afina Putri, Yutong Wang, Adam Nohejl, Ubaidillah Ariq Prathama, Nedjma Ousidhoum, Afifa Amriani, Anar Rzayev, Anirban Das, Ashmari Pramodya, Aulia Adila, Bryan Wilie, Candy Olivia Mawalim, Ching Lam Cheng, Daud Abolade, Emmanuele Chersoni, Enrico Santus, Fariz Ikhwantri, Garry Kuwanto, Hanyang Zhao, Haryo Akbarianto Wibowo, Holy Lovenia, Jan Christian Blaise Cruz, Jan Wira Gotama Putra, Junho Myung, Lucky Susanto, Maria Angelica Riera Machin, Marina Zhukova, Michael Anugraha, Muhammad Farid Adilazuarda, Natasha Santosa, Peerat Limkonchotiwat, Raj Dabre, Rio Alexander Audino, Samuel Cahyawijaya, Shi-Xiong Zhang, Stephanie Yulia Salim, Yi Zhou, Yinxuan Gui, David Ifeoluwa Adelani, En-Shiun Annie Lee, Shogo Ok</author><pubDate>Wed, 16 Oct 2024 16:11:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12705v1</guid></item><item><title>Sarcasm Detection in a Less-Resourced Language</title><link>http://arxiv.org/abs/2410.12704v1</link><description>The sarcasm detection task in natural language processing tries to classifywhether an utterance is sarcastic or not. It is related to sentiment analysissince it often inverts surface sentiment. Because sarcastic sentences arehighly dependent on context, and they are often accompanied by variousnon-verbal cues, the task is challenging. Most of related work focuses onhigh-resourced languages like English. To build a sarcasm detection dataset fora less-resourced language, such as Slovenian, we leverage two moderntechniques: a machine translation specific medium-size transformer model, and avery large generative language model. We explore the viability of translateddatasets and how the size of a pretrained transformer affects its ability todetect sarcasm. We train ensembles of detection models and evaluate models'performance. The results show that larger models generally outperform smallerones and that ensembling can slightly improve sarcasm detection performance.Our best ensemble approach achieves an $\text{F}_1$-score of 0.765 which isclose to annotators' agreement in the source language.</description><author>Lazar Đoković, Marko Robnik-Šikonja</author><pubDate>Wed, 16 Oct 2024 16:10:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12704v1</guid></item><item><title>Task Aware Modulation using Representation Learning: An Approach for Few Shot Learning in Environmental Systems</title><link>http://arxiv.org/abs/2310.04727v2</link><description>We introduce TAM-RL (Task Aware Modulation using Representation Learning), anovel multimodal meta-learning framework for few-shot learning in heterogeneoussystems, designed for science and engineering problems where entities share acommon underlying forward model but exhibit heterogeneity due toentity-specific characteristics. TAM-RL leverages an amortized training processwith a modulation network and a base network to learn task-specific modulationparameters, enabling efficient adaptation to new tasks with limited data. Weevaluate TAM-RL on two real-world environmental datasets: Gross Primary Product(GPP) prediction and streamflow forecasting, demonstrating significantimprovements over existing meta-learning methods. On the FLUXNET dataset,TAM-RL improves RMSE by 18.9\% over MMAML with just one month of few-shot data,while for streamflow prediction, it achieves an 8.21\% improvement with oneyear of data. Synthetic data experiments further validate TAM-RL's superiorperformance in heterogeneous task distributions, outperforming the baselines inthe most heterogeneous setting. Notably, TAM-RL offers substantialcomputational efficiency, with at least 3x faster training times compared togradient-based meta-learning approaches while being much simpler to train dueto reduced complexity. Ablation studies highlight the importance of pretrainingand adaptation mechanisms in TAM-RL's performance.</description><author>Arvind Renganathan, Rahul Ghosh, Ankush Khandelwal, Vipin Kumar</author><pubDate>Wed, 16 Oct 2024 16:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04727v2</guid></item><item><title>Neural-based Control for CubeSat Docking Maneuvers</title><link>http://arxiv.org/abs/2410.12703v1</link><description>Autonomous Rendezvous and Docking (RVD) have been extensively studied inrecent years, addressing the stringent requirements of spacecraft dynamicsvariations and the limitations of GNC systems. This paper presents aninnovative approach employing Artificial Neural Networks (ANN) trained throughReinforcement Learning (RL) for autonomous spacecraft guidance and controlduring the final phase of the rendezvous maneuver. The proposed strategy iseasily implementable onboard and offers fast adaptability and robustness todisturbances by learning control policies from experience rather than relyingon predefined models. Extensive Monte Carlo simulations within a relevantenvironment are conducted in 6DoF settings to validate our approach, along withhardware tests that demonstrate deployment feasibility. Our findings highlightthe efficacy of RL in assuring the adaptability and efficiency of spacecraftRVD, offering insights into future mission expectations.</description><author>Matteo Stoisa, Federica Paganelli Azza, Luca Romanelli, Mattia Varile</author><pubDate>Wed, 16 Oct 2024 16:05:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12703v1</guid></item><item><title>Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization</title><link>http://arxiv.org/abs/2410.12700v1</link><description>Recent advancements in diffusion models trained on large-scale data haveenabled the generation of indistinguishable human-level images, yet they oftenproduce harmful content misaligned with human values, e.g., social bias, andoffensive content. Despite extensive research on Large Language Models (LLMs),the challenge of Text-to-Image (T2I) model alignment remains largelyunexplored. Addressing this problem, we propose LiVO (Lightweight ValueOptimization), a novel lightweight method for aligning T2I models with humanvalues. LiVO only optimizes a plug-and-play value encoder to integrate aspecified value principle with the input prompt, allowing the control ofgenerated images over both semantics and values. Specifically, we design adiffusion model-tailored preference optimization loss, which theoreticallyapproximates the Bradley-Terry model used in LLM alignment but provides a moreflexible trade-off between image quality and value conformity. To optimize thevalue encoder, we also develop a framework to automatically construct atext-image preference dataset of 86k (prompt, aligned image, violating image,value principle) samples. Without updating most model parameters and throughadaptive value selection from the input prompt, LiVO significantly reducesharmful outputs and achieves faster convergence, surpassing several strongbaselines and taking an initial step towards ethically aligned T2I models.</description><author>Xingqi Wang, Xiaoyuan Yi, Xing Xie, Jia Jia</author><pubDate>Wed, 16 Oct 2024 16:03:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12700v1</guid></item><item><title>Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel</title><link>http://arxiv.org/abs/2404.15219v2</link><description>Training task-oriented dialogue systems typically requires turn-levelannotations for interacting with their APIs: e.g. a dialogue state and thesystem actions taken at each step. These annotations can be costly to produce,error-prone, and require both domain and annotation expertise. With advances inLLMs, we hypothesize that unlabeled data and a schema definition are sufficientfor building a working task-oriented dialogue system, completely unsupervised.We consider a novel unsupervised setting of only (1) a well-defined API schema(2) a set of unlabeled dialogues between a user and agent. We propose aninnovative approach using expectation-maximization (EM) that infers turn-levelannotations as latent variables using a noisy channel model to build anend-to-end dialogue agent. Evaluating our approach on the MultiWOZ benchmark,our method more than doubles the dialogue success rate of a strong GPT-3.5baseline.</description><author>Brendan King, Jeffrey Flanigan</author><pubDate>Wed, 16 Oct 2024 16:01:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15219v2</guid></item><item><title>Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense</title><link>http://arxiv.org/abs/2410.09838v2</link><description>Backdoor attacks pose a significant threat to Deep Neural Networks (DNNs) asthey allow attackers to manipulate model predictions with backdoor triggers. Toaddress these security vulnerabilities, various backdoor purification methodshave been proposed to purify compromised models. Typically, these purifiedmodels exhibit low Attack Success Rates (ASR), rendering them resistant tobackdoored inputs. However, Does achieving a low ASR through current safetypurification methods truly eliminate learned backdoor features from thepretraining phase? In this paper, we provide an affirmative answer to thisquestion by thoroughly investigating the Post-Purification Robustness ofcurrent backdoor purification methods. We find that current safety purificationmethods are vulnerable to the rapid re-learning of backdoor behavior, even whenfurther fine-tuning of purified models is performed using a very small numberof poisoned samples. Based on this, we further propose the practicalQuery-based Reactivation Attack (QRA) which could effectively reactivate thebackdoor by merely querying purified models. We find the failure to achievesatisfactory post-purification robustness stems from the insufficient deviationof purified models from the backdoored model along the backdoor-connected path.To improve the post-purification robustness, we propose a straightforwardtuning defense, Path-Aware Minimization (PAM), which promotes deviation alongbackdoor-connected paths with extra model updates. Extensive experimentsdemonstrate that PAM significantly improves post-purification robustness whilemaintaining a good clean accuracy and low ASR. Our work provides a newperspective on understanding the effectiveness of backdoor safety tuning andhighlights the importance of faithfully assessing the model's safety.</description><author>Rui Min, Zeyu Qin, Nevin L. Zhang, Li Shen, Minhao Cheng</author><pubDate>Wed, 16 Oct 2024 15:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09838v2</guid></item><item><title>AdaptiveDrag: Semantic-Driven Dragging on Diffusion-Based Image Editing</title><link>http://arxiv.org/abs/2410.12696v1</link><description>Recently, several point-based image editing methods (e.g., DragDiffusion,FreeDrag, DragNoise) have emerged, yielding precise and high-quality resultsbased on user instructions. However, these methods often make insufficient useof semantic information, leading to less desirable results. In this paper, weproposed a novel mask-free point-based image editing method, AdaptiveDrag,which provides a more flexible editing approach and generates images thatbetter align with user intent. Specifically, we design an auto mask generationmodule using super-pixel division for user-friendliness. Next, we leverage apre-trained diffusion model to optimize the latent, enabling the dragging offeatures from handle points to target points. To ensure a comprehensiveconnection between the input image and the drag process, we have developed asemantic-driven optimization. We design adaptive steps that are supervised bythe positions of the points and the semantic regions derived from super-pixelsegmentation. This refined optimization process also leads to more realisticand accurate drag results. Furthermore, to address the limitations in thegenerative consistency of the diffusion model, we introduce an innovativecorresponding loss during the sampling process. Building on these effectivedesigns, our method delivers superior generation results using only the singleinput image and the handle-target point pairs. Extensive experiments have beenconducted and demonstrate that the proposed method outperforms others inhandling various drag instructions (e.g., resize, movement, extension) acrossdifferent domains (e.g., animals, human face, land space, clothing).</description><author>DuoSheng Chen, Binghui Chen, Yifeng Geng, Liefeng Bo</author><pubDate>Wed, 16 Oct 2024 15:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12696v1</guid></item><item><title>MultiCamCows2024 -- A Multi-view Image Dataset for AI-driven Holstein-Friesian Cattle Re-Identification on a Working Farm</title><link>http://arxiv.org/abs/2410.12695v1</link><description>We present MultiCamCows2024, a farm-scale image dataset filmed acrossmultiple cameras for the biometric identification of individualHolstein-Friesian cattle exploiting their unique black and white coat-patterns.Captured by three ceiling-mounted visual sensors covering adjacent barn areasover seven days on a working dairy farm, the dataset comprises 101, 329 imagesof 90 cows, plus the underlying original CCTV footage. The dataset is providedalongside full computer vision recognition baselines, that is both a supervisedand self-supervised learning framework for individual cow identificationtrained on cattle tracklets. We report a performance above 96% single imageidentification accuracy from the dataset and demonstrate that combining datafrom multiple cameras during learning enhances self-supervised identification.We show that our framework enables fully automatic cattle identification,barring only the simple human verification of tracklet integrity during datacollection. Crucially, our study highlights that multi-camera, supervised andself-supervised components in tandem not only deliver highly accurateindividual cow identification but also achieve this efficiently with nolabelling of cattle identities by humans at all. We argue that this improvementin efficacy has practical implications for livestock management, behaviouranalysis, and agricultural monitoring. For full reproducibility and practicalease of use, we publish all key software and code including re-identificationcomponents and the species detector with this paper.</description><author>Phoenix Yu, Tilo Burghardt, Andrew W Dowsey, Neill W Campbell</author><pubDate>Wed, 16 Oct 2024 15:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12695v1</guid></item><item><title>Pessimistic Backward Policy for GFlowNets</title><link>http://arxiv.org/abs/2405.16012v2</link><description>This paper studies Generative Flow Networks (GFlowNets), which learn tosample objects proportionally to a given reward function through the trajectoryof state transitions. In this work, we observe that GFlowNets tend tounder-exploit the high-reward objects due to training on insufficient number oftrajectories, which may lead to a large gap between the estimated flow and the(known) reward value. In response to this challenge, we propose a pessimisticbackward policy for GFlowNets (PBP-GFN), which maximizes the observed flow toalign closely with the true reward for the object. We extensively evaluatePBP-GFN across eight benchmarks, including hyper-grid environment, baggeneration, structured set generation, molecular generation, and four RNAsequence generation tasks. In particular, PBP-GFN enhances the discovery ofhigh-reward objects, maintains the diversity of the objects, and consistentlyoutperforms existing methods.</description><author>Hyosoon Jang, Yunhui Jang, Minsu Kim, Jinkyoo Park, Sungsoo Ahn</author><pubDate>Wed, 16 Oct 2024 15:57:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16012v2</guid></item><item><title>VividMed: Vision Language Model with Versatile Visual Grounding for Medicine</title><link>http://arxiv.org/abs/2410.12694v1</link><description>Recent advancements in Vision Language Models (VLMs) have demonstratedremarkable promise in generating visually grounded responses. However, theirapplication in the medical domain is hindered by unique challenges. Forinstance, most VLMs rely on a single method of visual grounding, whereascomplex medical tasks demand more versatile approaches. Additionally, whilemost VLMs process only 2D images, a large portion of medical images are 3D. Thelack of medical data further compounds these obstacles. To address thesechallenges, we present VividMed, a vision language model with versatile visualgrounding for medicine. Our model supports generating both semanticsegmentation masks and instance-level bounding boxes, and accommodates variousimaging modalities, including both 2D and 3D data. We design a three-stagetraining procedure and an automatic data synthesis pipeline based on opendatasets and models. Besides visual grounding tasks, VividMed also excels inother common downstream tasks, including Visual Question Answering (VQA) andreport generation. Ablation studies empirically show that the integration ofvisual grounding ability leads to improved performance on these tasks. Our codeis publicly available at https://github.com/function2-llx/MMMM.</description><author>Lingxiao Luo, Bingda Tang, Xuanzhong Chen, Rong Han, Ting Chen</author><pubDate>Wed, 16 Oct 2024 15:54:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12694v1</guid></item><item><title>AssemAI: Interpretable Image-Based Anomaly Detection for Manufacturing Pipelines</title><link>http://arxiv.org/abs/2408.02181v2</link><description>Anomaly detection in manufacturing pipelines remains a critical challenge,intensified by the complexity and variability of industrial environments. Thispaper introduces AssemAI, an interpretable image-based anomaly detection systemtailored for smart manufacturing pipelines. Utilizing a curated image datasetfrom an industry-focused rocket assembly pipeline, we address the challenge ofimbalanced image data and demonstrate the importance of image-based methods inanomaly detection. Our primary contributions include deriving an image dataset,fine-tuning an object detection model YOLO-FF, and implementing a customanomaly detection model for assembly pipelines. The proposed approach leveragesdomain knowledge in data preparation, model development and reasoning. Weimplement several anomaly detection models on the derived image dataset,including a Convolutional Neural Network, Vision Transformer (ViT), andpre-trained versions of these models. Additionally, we incorporateexplainability techniques at both user and model levels, utilizing ontology foruser-level explanations and SCORE-CAM for in-depth feature and model analysis.Finally, the best-performing anomaly detection model and YOLO-FF are deployedin a real-time setting. Our results include ablation studies on the baselinesand a comprehensive evaluation of the proposed system. This work highlights thebroader impact of advanced image-based anomaly detection in enhancing thereliability and efficiency of smart manufacturing processes. The image dataset,codes to reproduce the results and additional experiments are available athttps://github.com/renjithk4/AssemAI.</description><author>Renjith Prasad, Chathurangi Shyalika, Ramtin Zand, Fadi El Kalach, Revathy Venkataramanan, Ramy Harik, Amit Sheth</author><pubDate>Wed, 16 Oct 2024 15:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02181v2</guid></item><item><title>Machine Learning Approach to Brain Tumor Detection and Classification</title><link>http://arxiv.org/abs/2410.12692v1</link><description>Brain tumor detection and classification are critical tasks in medical imageanalysis, particularly in early-stage diagnosis, where accurate and timelydetection can significantly improve treatment outcomes. In this study, we applyvarious statistical and machine learning models to detect and classify braintumors using brain MRI images. We explore a variety of statistical modelsincluding linear, logistic, and Bayesian regressions, and the machine learningmodels including decision tree, random forest, single-layer perceptron,multi-layer perceptron, convolutional neural network (CNN), recurrent neuralnetwork, and long short-term memory. Our findings show that CNN outperformsother models, achieving the best performance. Additionally, we confirm that theCNN model can also work for multi-class classification, distinguishing betweenfour categories of brain MRI images such as normal, glioma, meningioma, andpituitary tumor images. This study demonstrates that machine learningapproaches are suitable for brain tumor detection and classification,facilitating real-world medical applications in assisting radiologists withearly and accurate diagnosis.</description><author>Alice Oh, Inyoung Noh, Jian Choo, Jihoo Lee, Justin Park, Kate Hwang, Sanghyeon Kim, Soo Min Oh</author><pubDate>Wed, 16 Oct 2024 15:52:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12692v1</guid></item><item><title>Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce</title><link>http://arxiv.org/abs/2410.12691v1</link><description>Language is a symbolic capital that affects people's lives in many ways(Bourdieu, 1977, 1991). It is a powerful tool that accounts for identities,cultures, traditions, and societies in general. Hence, data in a given languageshould be viewed as more than a collection of tokens. Good data collection andlabeling practices are key to building more human-centered and socially awaretechnologies. While there has been a rising interest in mid- to low-resourcelanguages within the NLP community, work in this space has to overcome uniquechallenges such as data scarcity and access to suitable annotators. In thispaper, we collect feedback from those directly involved in and impacted by NLPartefacts for mid- to low-resource languages. We conduct a quantitative andqualitative analysis of the responses and highlight the main issues related to(1) data quality such as linguistic and cultural data suitability; and (2) theethics of common annotation practices such as the misuse of online communityservices. Based on these findings, we make several recommendations for thecreation of high-quality language artefacts that reflect the cultural milieu ofits speakers, while simultaneously respecting the dignity and labor of dataworkers.</description><author>Nedjma Ousidhoum, Meriem Beloucif, Saif M. Mohammad</author><pubDate>Wed, 16 Oct 2024 15:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12691v1</guid></item><item><title>Local transfer learning Gaussian process modeling, with applications to surrogate modeling of expensive computer simulators</title><link>http://arxiv.org/abs/2410.12690v1</link><description>A critical bottleneck for scientific progress is the costly nature ofcomputer simulations for complex systems. Surrogate models provide an appealingsolution: such models are trained on simulator evaluations, then used toemulate and quantify uncertainty on the expensive simulator at unexploredinputs. In many applications, one often has available data on related systems.For example, in designing a new jet turbine, there may be existing studies onturbines with similar configurations. A key question is how information fromsuch "source" systems can be transferred for effective surrogate training onthe "target" system of interest. We thus propose a new LOcal transfer LearningGaussian Process (LOL-GP) model, which leverages a carefully-designed Gaussianprocess to transfer such information for surrogate modeling. The key novelty ofthe LOL-GP is a latent regularization model, which identifies regions wheretransfer should be performed and regions where it should be avoided. This"local transfer" property is desirable in scientific systems: at certainparameters, such systems may behave similarly and thus transfer is beneficial;at other parameters, they may behave differently and thus transfer isdetrimental. By accounting for local transfer, the LOL-GP can rectify acritical limitation of "negative transfer" in existing transfer learningmodels, where the transfer of information worsens predictive performance. Wederive a Gibbs sampling algorithm for efficient posterior predictive samplingon the LOL-GP, for both the multi-source and multi-fidelity transfer settings.We then show, via a suite of numerical experiments and an application for jetturbine design, the improved surrogate performance of the LOL-GP over existingmethods.</description><author>Xinming Wang, Simon Mak, John Miller, Jianguo Wu</author><pubDate>Wed, 16 Oct 2024 15:50:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12690v1</guid></item><item><title>A distance function for stochastic matrices</title><link>http://arxiv.org/abs/2410.12689v1</link><description>Motivated by information geometry, a distance function on the space ofstochastic matrices is advocated. Starting with sequences of Markov chains theBhattacharyya angle is advocated as the natural tool for comparing both shortand long term Markov chain runs. Bounds on the convergence of the distance andmixing times are derived. Guided by the desire to compare different Markovchain models, especially in the setting of healthcare processes, a new distancefunction on the space of stochastic matrices is presented. It is a truedistance measure which has a closed form and is efficient to implement fornumerical evaluation. In the case of ergodic Markov chains, it is shown thatconsidering either the Bhattacharyya angle on Markov sequences or the newstochastic matrix distance leads to the same distance between models.</description><author>Antony Lee, Peter Tino, Iain Bruce Styles</author><pubDate>Wed, 16 Oct 2024 15:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12689v1</guid></item><item><title>Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2</title><link>http://arxiv.org/abs/2410.12686v1</link><description>Anatomical landmarks are vital in medical imaging for navigation and anomalydetection. Modern large language models (LLMs), like Llama-2, offer promise forautomating the mapping of these landmarks in free-text radiology reports tocorresponding positions in image data. Recent studies propose LLMs may developcoherent representations of generative processes. Motivated by these insights,we investigated whether LLMs accurately represent the spatial positions ofanatomical landmarks. Through experiments with Llama-2 models, we found thatthey can linearly represent anatomical landmarks in space with considerablerobustness to different prompts. These results underscore the potential of LLMsto enhance the efficiency and accuracy of medical imaging workflows.</description><author>Mohamad Abdi, Gerardo Hemosillo Valadez, Halid Ziya Yerebakan</author><pubDate>Wed, 16 Oct 2024 15:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12686v1</guid></item><item><title>Generative Neural Reparameterization for Differentiable PDE-constrained Optimization</title><link>http://arxiv.org/abs/2410.12683v1</link><description>Partial-differential-equation (PDE)-constrained optimization is a well-worntechnique for acquiring optimal parameters of systems governed by PDEs.However, this approach is limited to providing a single set of optimalparameters per optimization. Given a differentiable PDE solver, if the freeparameters are reparameterized as the output of a neural network, that neuralnetwork can be trained to learn a map from a probability distribution to thedistribution of optimal parameters. This proves useful in the case where thereare many well performing local minima for the PDE. We apply this technique totrain a neural network that generates optimal parameters that minimizelaser-plasma instabilities relevant to laser fusion and show that the neuralnetwork generates many well performing and diverse minima.</description><author>Archis S. Joglekar</author><pubDate>Wed, 16 Oct 2024 15:46:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12683v1</guid></item><item><title>Understanding Figurative Meaning through Explainable Visual Entailment</title><link>http://arxiv.org/abs/2405.01474v2</link><description>Large Vision-Language Models (VLMs) have demonstrated strong capabilities intasks requiring a fine-grained understanding of literal meaning in images andtext, such as visual question-answering or visual entailment. However, therehas been little exploration of these models' capabilities when presented withimages and captions containing figurative meaning, such as metaphors or humor.To close this gap, we propose a new task framing the figurative meaningunderstanding problem as an explainable visual entailment task, where the modelhas to predict whether the image (premise) entails a caption (hypothesis) andjustify the predicted label with a textual explanation. The figurativephenomena can be present either in the image, the caption, or both. Utilizing ahuman-AI collaboration approach, we build the accompanying expert-verifieddataset V-FLUTE, containing 6,027 {image, caption, label, explanation}instances spanning five diverse figurative phenomena: metaphors, similes,idioms, sarcasm, and humor. Through automatic evaluation, we find that VLMsstruggle to generalize from literal to figurative meaning, particularly when itis present in images. Further, we identify common types of errors in VLMreasoning via human evaluation.</description><author>Arkadiy Saakyan, Shreyas Kulkarni, Tuhin Chakrabarty, Smaranda Muresan</author><pubDate>Wed, 16 Oct 2024 15:45:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01474v2</guid></item><item><title>Optimizing Multi-Task Learning for Accurate Spacecraft Pose Estimation</title><link>http://arxiv.org/abs/2410.12679v1</link><description>Accurate satellite pose estimation is crucial for autonomous guidance,navigation, and control (GNC) systems in in-orbit servicing (IOS) missions.This paper explores the impact of different tasks within a multi-task learning(MTL) framework for satellite pose estimation using monocular images. Byintegrating tasks such as direct pose estimation, keypoint prediction, objectlocalization, and segmentation into a single network, the study aims toevaluate the reciprocal influence between tasks by testing different multi-taskconfigurations thanks to the modularity of the convolutional neural network(CNN) used in this work. The trends of mutual bias between the analyzed tasksare found by employing different weighting strategies to further test therobustness of the findings. A synthetic dataset was developed to train and testthe MTL network. Results indicate that direct pose estimation and heatmap-basedpose estimation positively influence each other in general, while both thebounding box and segmentation tasks do not provide significant contributionsand tend to degrade the overall estimation accuracy.</description><author>Francesco Evangelisti, Francesco Rossi, Tobia Giani, Ilaria Bloise, Mattia Varile</author><pubDate>Wed, 16 Oct 2024 15:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12679v1</guid></item><item><title>Efficient Optimization Algorithms for Linear Adversarial Training</title><link>http://arxiv.org/abs/2410.12677v1</link><description>Adversarial training can be used to learn models that are robust againstperturbations. For linear models, it can be formulated as a convex optimizationproblem. Compared to methods proposed in the context of deep learning,leveraging the optimization structure allows significantly faster convergencerates. Still, the use of generic convex solvers can be inefficient forlarge-scale problems. Here, we propose tailored optimization algorithms for theadversarial training of linear models, which render large-scale regression andclassification problems more tractable. For regression problems, we propose afamily of solvers based on iterative ridge regression and, for classification,a family of solvers based on projected gradient descent. The methods are basedon extended variable reformulations of the original problem. We illustratetheir efficiency in numerical examples.</description><author>Antônio H. RIbeiro, Thomas B. Schön, Dave Zahariah, Francis Bach</author><pubDate>Wed, 16 Oct 2024 15:41:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12677v1</guid></item><item><title>ToBlend: Token-Level Blending With an Ensemble of LLMs to Attack AI-Generated Text Detection</title><link>http://arxiv.org/abs/2402.11167v2</link><description>The robustness of AI-content detection models against sophisticatedadversarial strategies, such as paraphrasing or word switching, is a risingconcern in natural language generation (NLG) applications. This study proposesToBlend, a novel token-level ensemble text generation method to challenge therobustness of current AI-content detection approaches by utilizing multiplesets of candidate generative large language models (LLMs). By randomly samplingtoken(s) from candidate LLMs sets, we find ToBlend significantly drops theperformance of most mainstream AI-content detection methods. We evaluate thetext quality produced under different ToBlend settings based on annotationsfrom experienced human experts. We proposed a fine-tuned Llama3.1 model todistinguish the ToBlend generated text more accurately. Our findings underscoreour proposed text generation approach's great potential in deceiving andimproving detection models. Our datasets, codes, and annotations areopen-sourced.</description><author>Fan Huang, Haewoon Kwak, Jisun An</author><pubDate>Wed, 16 Oct 2024 15:40:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11167v2</guid></item><item><title>MambaBEV: An efficient 3D detection model with Mamba2</title><link>http://arxiv.org/abs/2410.12673v1</link><description>A stable 3D object detection model based on BEV paradigm with temporalinformation is very important for autonomous driving systems. However, currenttemporal fusion model use convolutional layer or deformable self-attention isnot conducive to the exchange of global information of BEV space and has morecomputational cost. Recently, a newly proposed based model specialized inprocessing sequence called mamba has shown great potential in multipledownstream task. In this work, we proposed a mamba2-based BEV 3D objectdetection model named MambaBEV. We also adapt an end to end self drivingparadigm to test the performance of the model. Our work performs pretty goodresults on nucences datasets:Our base version achieves 51.7% NDS. Our code willbe available soon.</description><author>Zihan You, Hao Wang, Qichao Zhao, Jinxiang Wang</author><pubDate>Wed, 16 Oct 2024 15:37:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12673v1</guid></item><item><title>Context Matters: Leveraging Contextual Features for Time Series Forecasting</title><link>http://arxiv.org/abs/2410.12672v1</link><description>Time series forecasts are often influenced by exogenous contextual featuresin addition to their corresponding history. For example, in financial settings,it is hard to accurately predict a stock price without considering publicsentiments and policy decisions in the form of news articles, tweets, etc.Though this is common knowledge, the current state-of-the-art (SOTA)forecasting models fail to incorporate such contextual information, owing toits heterogeneity and multimodal nature. To address this, we introduceContextFormer, a novel plug-and-play method to surgically integrate multimodalcontextual information into existing pre-trained forecasting models.ContextFormer effectively distills forecast-specific information from richmultimodal contexts, including categorical, continuous, time-varying, and eventextual information, to significantly enhance the performance of existing baseforecasters. ContextFormer outperforms SOTA forecasting models by up to 30% ona range of real-world datasets spanning energy, traffic, environmental, andfinancial domains.</description><author>Sameep Chattopadhyay, Pulkit Paliwal, Sai Shankar Narasimhan, Shubhankar Agarwal, Sandeep P. Chinchali</author><pubDate>Wed, 16 Oct 2024 15:36:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12672v1</guid></item><item><title>New Paradigm of Adversarial Training: Breaking Inherent Trade-Off between Accuracy and Robustness via Dummy Classes</title><link>http://arxiv.org/abs/2410.12671v1</link><description>Adversarial Training (AT) is one of the most effective methods to enhance therobustness of DNNs. However, existing AT methods suffer from an inherenttrade-off between adversarial robustness and clean accuracy, which seriouslyhinders their real-world deployment. While this problem has been widely studiedwithin the current AT paradigm, existing AT methods still typically experiencea reduction in clean accuracy by over 10% to date, without significantimprovements in robustness compared with simple baselines like PGD-AT. Thisinherent trade-off raises a question: whether the current AT paradigm, whichassumes to learn the corresponding benign and adversarial samples as the sameclass, inappropriately combines clean and robust objectives that may beessentially inconsistent. In this work, we surprisingly reveal that up to 40%of CIFAR-10 adversarial samples always fail to satisfy such an assumptionacross various AT methods and robust models, explicitly indicating theimprovement room for the current AT paradigm. Accordingly, to relax the tensionbetween clean and robust learning derived from this overstrict assumption, wepropose a new AT paradigm by introducing an additional dummy class for eachoriginal class, aiming to accommodate the hard adversarial samples with shifteddistribution after perturbation. The robustness w.r.t. these adversarialsamples can be achieved by runtime recovery from the predicted dummy classes totheir corresponding original ones, eliminating the compromise with cleanlearning. Building on this new paradigm, we propose a novel plug-and-play ATtechnology named DUmmy Classes-based Adversarial Training (DUCAT). Extensiveexperiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate that theDUCAT concurrently improves clean accuracy and adversarial robustness comparedwith state-of-the-art benchmarks, effectively breaking the existing inherenttrade-off.</description><author>Yanyun Wang, Li Liu, Zi Liang, Qingqing Ye, Haibo Hu</author><pubDate>Wed, 16 Oct 2024 15:36:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12671v1</guid></item><item><title>3DIS: Depth-Driven Decoupled Instance Synthesis for Text-to-Image Generation</title><link>http://arxiv.org/abs/2410.12669v1</link><description>The increasing demand for controllable outputs in text-to-image generationhas spurred advancements in multi-instance generation (MIG), allowing users todefine both instance layouts and attributes. However, unlike image-conditionalgeneration methods such as ControlNet, MIG techniques have not been widelyadopted in state-of-the-art models like SD2 and SDXL, primarily due to thechallenge of building robust renderers that simultaneously handle instancepositioning and attribute rendering. In this paper, we introduce Depth-DrivenDecoupled Instance Synthesis (3DIS), a novel framework that decouples the MIGprocess into two stages: (i) generating a coarse scene depth map for accurateinstance positioning and scene composition, and (ii) rendering fine-grainedattributes using pre-trained ControlNet on any foundational model, withoutadditional training. Our 3DIS framework integrates a custom adapter into LDM3Dfor precise depth-based layouts and employs a finetuning-free method forenhanced instance-level attribute rendering. Extensive experiments onCOCO-Position and COCO-MIG benchmarks demonstrate that 3DIS significantlyoutperforms existing methods in both layout precision and attribute rendering.Notably, 3DIS offers seamless compatibility with diverse foundational models,providing a robust, adaptable solution for advanced multi-instance generation.The code is available at: https://github.com/limuloo/3DIS.</description><author>Dewei Zhou, Ji Xie, Zongxin Yang, Yi Yang</author><pubDate>Wed, 16 Oct 2024 15:34:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12669v1</guid></item><item><title>ITINERA: Integrating Spatial Optimization with Large Language Models for Open-domain Urban Itinerary Planning</title><link>http://arxiv.org/abs/2402.07204v4</link><description>Citywalk, a recently popular form of urban travel, requires genuinepersonalization and understanding of fine-grained requests compared totraditional itinerary planning. In this paper, we introduce the novel task ofOpen-domain Urban Itinerary Planning (OUIP), which generates personalized urbanitineraries from user requests in natural language. We then present ITINERA, anOUIP system that integrates spatial optimization with large language models toprovide customized urban itineraries based on user needs. This involvesdecomposing user requests, selecting candidate points of interest (POIs),ordering the POIs based on cluster-aware spatial optimization, and generatingthe itinerary. Experiments on real-world datasets and the performance of thedeployed system demonstrate our system's capacity to deliver personalized andspatially coherent itineraries compared to current solutions. Source codes ofITINERA are available at https://github.com/YihongT/ITINERA.</description><author>Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Zhaofeng Wu, Dingyi Zhuang, Jushi Kai, Kebing Hou, Xiaotong Guo, Jinhua Zhao, Zhan Zhao, Wei Ma</author><pubDate>Wed, 16 Oct 2024 15:28:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07204v4</guid></item><item><title>Hamiltonian bridge: A physics-driven generative framework for targeted pattern control</title><link>http://arxiv.org/abs/2410.12665v1</link><description>Patterns arise spontaneously in a range of systems spanning the sciences, andtheir study typically focuses on mechanisms to understand their evolution inspace-time. Increasingly, there has been a transition towards controlling thesepatterns in various functional settings, with implications for engineering.Here, we combine our knowledge of a general class of dynamical laws for patternformation in non-equilibrium systems, and the power of stochastic optimalcontrol approaches to present a framework that allows us to control patterns atmultiple scales, which we dub the "Hamiltonian bridge". We use a mappingbetween stochastic many-body Lagrangian physics and deterministic Eulerianpattern forming PDEs to leverage our recent approach utilizing theFeynman-Kac-based adjoint path integral formulation for the control ofinteracting particles and generalize this to the active control of patterningfields. We demonstrate the applicability of our computational framework vianumerical experiments on the control of phase separation with and without aconserved order parameter, self-assembly of fluid droplets, coupledreaction-diffusion equations and finally a phenomenological model forspatio-temporal tissue differentiation. We interpret our numerical experimentsin terms of a theoretical understanding of how the underlying physics shapesthe geometry of the pattern manifold, altering the transport paths of patternsand the nature of pattern interpolation. We finally conclude by showing howoptimal control can be utilized to generate complex patterns via an iterativecontrol protocol over pattern forming pdes which can be casted as gradientflows. All together, our study shows how we can systematically build inphysical priors into a generative framework for pattern control innon-equilibrium systems across multiple length and time scales.</description><author>Vishaal Krishnan, Sumit Sinha, L. Mahadevan</author><pubDate>Wed, 16 Oct 2024 15:24:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12665v1</guid></item><item><title>Learning Smooth Humanoid Locomotion through Lipschitz-Constrained Policies</title><link>http://arxiv.org/abs/2410.11825v2</link><description>Reinforcement learning combined with sim-to-real transfer offers a generalframework for developing locomotion controllers for legged robots. Tofacilitate successful deployment in the real world, smoothing techniques, suchas low-pass filters and smoothness rewards, are often employed to developpolicies with smooth behaviors. However, because these techniques arenon-differentiable and usually require tedious tuning of a large set ofhyperparameters, they tend to require extensive manual tuning for each roboticplatform. To address this challenge and establish a general technique forenforcing smooth behaviors, we propose a simple and effective method thatimposes a Lipschitz constraint on a learned policy, which we refer to asLipschitz-Constrained Policies (LCP). We show that the Lipschitz constraint canbe implemented in the form of a gradient penalty, which provides adifferentiable objective that can be easily incorporated with automaticdifferentiation frameworks. We demonstrate that LCP effectively replaces theneed for smoothing rewards or low-pass filters and can be easily integratedinto training frameworks for many distinct humanoid robots. We extensivelyevaluate LCP in both simulation and real-world humanoid robots, producingsmooth and robust locomotion controllers. All simulation and deployment code,along with complete checkpoints, is available on our project page:https://lipschitz-constrained-policy.github.io.</description><author>Zixuan Chen, Xialin He, Yen-Jen Wang, Qiayuan Liao, Yanjie Ze, Zhongyu Li, S. Shankar Sastry, Jiajun Wu, Koushil Sreenath, Saurabh Gupta, Xue Bin Peng</author><pubDate>Wed, 16 Oct 2024 15:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11825v2</guid></item><item><title>Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models</title><link>http://arxiv.org/abs/2410.12662v1</link><description>Vision-language alignment in Large Vision-Language Models (LVLMs)successfully enables LLMs to understand visual input. However, we find thatexisting vision-language alignment methods fail to transfer the existing safetymechanism for text in LLMs to vision, which leads to vulnerabilities in toxicimage. To explore the cause of this problem, we give the insightful explanationof where and how the safety mechanism of LVLMs operates and conduct comparativeanalysis between text and vision. We find that the hidden states at thespecific transformer layers play a crucial role in the successful activation ofsafety mechanism, while the vision-language alignment at hidden states level incurrent methods is insufficient. This results in a semantic shift for inputimages compared to text in hidden states, therefore misleads the safetymechanism. To address this, we propose a novel Text-Guided vision-languageAlignment method (TGA) for LVLMs. TGA retrieves the texts related to inputvision and uses them to guide the projection of vision into the hidden statesspace in LLMs. Experiments show that TGA not only successfully transfers thesafety mechanism for text in basic LLMs to vision in vision-language alignmentfor LVLMs without any safety fine-tuning on the visual modality but alsomaintains the general performance on various vision tasks (Safe and Good).</description><author>Shicheng Xu, Liang Pang, Yunchang Zhu, Huawei Shen, Xueqi Cheng</author><pubDate>Wed, 16 Oct 2024 15:20:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12662v1</guid></item><item><title>Explanation-Preserving Augmentation for Semi-Supervised Graph Representation Learning</title><link>http://arxiv.org/abs/2410.12657v1</link><description>Graph representation learning (GRL), enhanced by graph augmentation methods,has emerged as an effective technique achieving performance improvements inwide tasks such as node classification and graph classification. Inself-supervised GRL, paired graph augmentations are generated from each graph.Its objective is to infer similar representations for augmentations of the samegraph, but maximally distinguishable representations for augmentations ofdifferent graphs. Analogous to image and language domains, the desiderata of anideal augmentation method include both (1) semantics-preservation; and (2)data-perturbation; i.e., an augmented graph should preserve the semantics ofits original graph while carrying sufficient variance. However, most existing(un-)/self-supervised GRL methods focus on data perturbation but largelyneglect semantics preservation. To address this challenge, in this paper, wepropose a novel method, Explanation-Preserving Augmentation (EPA), thatleverages graph explanation techniques for generating augmented graphs that canbridge the gap between semantics-preservation and data-perturbation. EPA firstuses a small number of labels to train a graph explainer to infer thesub-structures (explanations) that are most relevant to a graph's semantics.These explanations are then used to generate semantics-preserving augmentationsfor self-supervised GRL, namely EPA-GRL. We demonstrate theoretically, using ananalytical example, and through extensive experiments on a variety of benchmarkdatasets that EPA-GRL outperforms the state-of-the-art (SOTA) GRL methods,which are built upon semantics-agnostic data augmentations.</description><author>Zhuomin Chen, Jingchao Ni, Hojat Allah Salehi, Xu Zheng, Esteban Schafir, Farhad Shirani, Dongsheng Luo</author><pubDate>Wed, 16 Oct 2024 15:18:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12657v1</guid></item><item><title>Evaluating Morphological Compositional Generalization in Large Language Models</title><link>http://arxiv.org/abs/2410.12656v1</link><description>Large language models (LLMs) have demonstrated significant progress invarious natural language generation and understanding tasks. However, theirlinguistic generalization capabilities remain questionable, raising doubtsabout whether these models learn language similarly to humans. While humansexhibit compositional generalization and linguistic creativity in language use,the extent to which LLMs replicate these abilities, particularly in morphology,is under-explored. In this work, we systematically investigate themorphological generalization abilities of LLMs through the lens ofcompositionality. We define morphemes as compositional primitives and design anovel suite of generative and discriminative tasks to assess morphologicalproductivity and systematicity. Focusing on agglutinative languages such asTurkish and Finnish, we evaluate several state-of-the-art instruction-finetunedmultilingual models, including GPT-4 and Gemini. Our analysis shows that LLMsstruggle with morphological compositional generalization particularly whenapplied to novel word roots, with performance declining sharply asmorphological complexity increases. While models can identify individualmorphological combinations better than chance, their performance lackssystematicity, leading to significant accuracy gaps compared to humans.</description><author>Mete Ismayilzada, Defne Circi, Jonne Sälevä, Hale Sirin, Abdullatif Köksal, Bhuwan Dhingra, Antoine Bosselut, Lonneke van der Plas, Duygu Ataman</author><pubDate>Wed, 16 Oct 2024 15:17:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12656v1</guid></item><item><title>Position Specific Scoring Is All You Need? Revisiting Protein Sequence Classification Tasks</title><link>http://arxiv.org/abs/2410.12655v1</link><description>Understanding the structural and functional characteristics of proteins arecrucial for developing preventative and curative strategies that impact fieldsfrom drug discovery to policy development. An important and popular techniquefor examining how amino acids make up these characteristics of the proteinsequences with position-specific scoring (PSS). While the string kernel iscrucial in natural language processing (NLP), it is unclear if string kernelscan extract biologically meaningful information from protein sequences, despitethe fact that they have been shown to be effective in the general sequenceanalysis tasks. In this work, we propose a weighted PSS kernel matrix (orW-PSSKM), that combines a PSS representation of protein sequences, whichencodes the frequency information of each amino acid in a sequence, with thenotion of the string kernel. This results in a novel kernel function thatoutperforms many other approaches for protein sequence classification. Weperform extensive experimentation to evaluate the proposed method. Our findingsdemonstrate that the W-PSSKM significantly outperforms existing baselines andstate-of-the-art methods and achieves up to 45.1\% improvement inclassification accuracy.</description><author>Sarwan Ali, Taslim Murad, Prakash Chourasia, Haris Mansoor, Imdad Ullah Khan, Pin-Yu Chen, Murray Patterson</author><pubDate>Wed, 16 Oct 2024 15:16:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12655v1</guid></item><item><title>Latent Inversion with Timestep-aware Sampling for Training-free Non-rigid Editing</title><link>http://arxiv.org/abs/2402.08601v3</link><description>Text-guided non-rigid editing involves complex edits for input images, suchas changing motion or compositions within their surroundings. Since it requiresmanipulating the input structure, existing methods often struggle withpreserving object identity and background, particularly when combined withStable Diffusion. In this work, we propose a training-free approach fornon-rigid editing with Stable Diffusion, aimed at improving the identitypreservation quality without compromising editability. Our approach comprisesthree stages: text optimization, latent inversion, and timestep-aware textinjection sampling. Inspired by the success of Imagic, we employ their textoptimization for smooth editing. Then, we introduce latent inversion topreserve the input image's identity without additional model fine-tuning. Tofully utilize the input reconstruction ability of latent inversion, we suggesttimestep-aware text injection sampling. This effectively retains the structureof the input image by injecting the source text prompt in early sampling stepsand then transitioning to the target prompt in subsequent sampling steps. Thisstrategic approach seamlessly harmonizes with text optimization, facilitatingcomplex non-rigid edits to the input without losing the original identity. Wedemonstrate the effectiveness of our method in terms of identity preservation,editability, and aesthetic quality through extensive experiments.</description><author>Yunji Jung, Seokju Lee, Tair Djanibekov, Hyunjung Shim, Jong Chul Ye</author><pubDate>Wed, 16 Oct 2024 15:16:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08601v3</guid></item><item><title>Constrained Posterior Sampling: Time Series Generation with Hard Constraints</title><link>http://arxiv.org/abs/2410.12652v1</link><description>Generating realistic time series samples is crucial for stress-testing modelsand protecting user privacy by using synthetic data. In engineering andsafety-critical applications, these samples must meet certain hard constraintsthat are domain-specific or naturally imposed by physics or nature. Consider,for example, generating electricity demand patterns with constraints on peakdemand times. This can be used to stress-test the functioning of power gridsduring adverse weather conditions. Existing approaches for generatingconstrained time series are either not scalable or degrade sample quality. Toaddress these challenges, we introduce Constrained Posterior Sampling (CPS), adiffusion-based sampling algorithm that aims to project the posterior meanestimate into the constraint set after each denoising update. Notably, CPSscales to a large number of constraints (~100) without requiring additionaltraining. We provide theoretical justifications highlighting the impact of ourprojection step on sampling. Empirically, CPS outperforms state-of-the-artmethods in sample quality and similarity to real time series by around 10% and42%, respectively, on real-world stocks, traffic, and air quality datasets.</description><author>Sai Shankar Narasimhan, Shubhankar Agarwal, Litu Rout, Sanjay Shakkottai, Sandeep P. Chinchali</author><pubDate>Wed, 16 Oct 2024 15:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12652v1</guid></item><item><title>CELL your Model: Contrastive Explanations for Large Language Models</title><link>http://arxiv.org/abs/2406.11785v2</link><description>The advent of black-box deep neural network classification models has sparkedthe need to explain their decisions. However, in the case of generative AI,such as large language models (LLMs), there is no class prediction to explain.Rather, one can ask why an LLM output a particular response to a given prompt.In this paper, we answer this question by proposing, to the best of ourknowledge, the first contrastive explanation methods requiring simplyblack-box/query access. Our explanations suggest that an LLM outputs a reply toa given prompt because if the prompt was slightly modified, the LLM would havegiven a different response that is either less preferable or contradicts theoriginal response. The key insight is that contrastive explanations simplyrequire a scoring function that has meaning to the user and not necessarily aspecific real valued quantity (viz. class label). We offer two algorithms forfinding contrastive explanations: i) A myopic algorithm, which althougheffective in creating contrasts, requires many model calls and ii) A budgetedalgorithm, our main algorithmic contribution, which intelligently createscontrasts adhering to a query budget, necessary for longer contexts. We showthe efficacy of these methods on diverse natural language tasks such asopen-text generation, automated red teaming, and explaining conversationaldegradation.</description><author>Ronny Luss, Erik Miehling, Amit Dhurandhar</author><pubDate>Wed, 16 Oct 2024 15:15:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11785v2</guid></item><item><title>Light-Weight Fault Tolerant Attention for Large Language Model Training</title><link>http://arxiv.org/abs/2410.11720v2</link><description>Large Language Models (LLMs) have demonstrated remarkable performance invarious natural language processing tasks. However, the training of thesemodels is computationally intensive and susceptible to faults, particularly inthe attention mechanism, which is a critical component of transformer-basedLLMs. In this paper, we investigate the impact of faults on LLM training,focusing on INF, NaN, and near-INF values in the computation results withsystematic fault injection experiments. We observe the propagation patterns ofthese errors, which can trigger non-trainable states in the model and disrupttraining, forcing the procedure to load from checkpoints. To mitigate theimpact of these faults, we propose ATTNChecker, the first Algorithm-Based FaultTolerance (ABFT) technique tailored for the attention mechanism in LLMs.ATTNChecker is designed based on fault propagation patterns of LLM andincorporates performance optimization to adapt to both system reliability andmodel vulnerability while providing lightweight protection for fast LLMtraining. Evaluations on four LLMs show that ATTNChecker on average incurs onaverage 7% overhead on training while detecting and correcting all extremeerrors. Compared with the state-of-the-art checkpoint/restore approach,ATTNChecker reduces recovery overhead by up to 49x.</description><author>Yuhang Liang, Xinyi Li, Jie Ren, Ang Li, Bo Fang, Jieyang Chen</author><pubDate>Wed, 16 Oct 2024 15:10:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11720v2</guid></item><item><title>Disentangling Singlish Discourse Particles with Task-Driven Representation</title><link>http://arxiv.org/abs/2409.20366v4</link><description>Singlish, or formally Colloquial Singapore English, is an English-basedcreole language originating from the SouthEast Asian country Singapore. Thelanguage contains influences from Sinitic languages such as Chinese dialects,Malay, Tamil and so forth. A fundamental task to understanding Singlish is tofirst understand the pragmatic functions of its discourse particles, upon whichSinglish relies heavily to convey meaning. This work offers a preliminaryeffort to disentangle the Singlish discourse particles (lah, meh and hor) withtask-driven representation learning. After disentanglement, we cluster thesediscourse particles to differentiate their pragmatic functions, and performSinglish-to-English machine translation. Our work provides a computationalmethod to understanding Singlish discourse particles, and opens avenues towardsa deeper comprehension of the language and its usage.</description><author>Linus Tze En Foo, Lynnette Hui Xian Ng</author><pubDate>Wed, 16 Oct 2024 15:09:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.20366v4</guid></item><item><title>DOCE: Finding the Sweet Spot for Execution-Based Code Generation</title><link>http://arxiv.org/abs/2408.13745v4</link><description>Recently, a diverse set of decoding and reranking procedures have been showneffective for LLM-based code generation. However, a comprehensive frameworkthat links and experimentally compares these methods is missing. We addressthis by proposing Decoding Objectives for Code Execution, a comprehensiveframework that includes candidate generation, $n$-best reranking, minimum Bayesrisk (MBR) decoding, and self-debugging as the core components. We then studythe contributions of these components through execution-based evaluationmetrics. Our findings highlight the importance of execution-based methods andthe difference gap between execution-based and execution-free methods.Furthermore, we assess the impact of filtering based on trial unit tests, asimple and effective strategy that has been often overlooked in prior works. Wealso propose self-debugging on multiple candidates, obtaining state-of-the-artperformance on reranking for code generation. We expect our framework toprovide a solid guideline for future research on code generation.</description><author>Haau-Sing Li, Patrick Fernandes, Iryna Gurevych, André F. T. Martins</author><pubDate>Wed, 16 Oct 2024 15:07:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13745v4</guid></item><item><title>Optimization and Application of Cloud-based Deep Learning Architecture for Multi-Source Data Prediction</title><link>http://arxiv.org/abs/2410.12642v1</link><description>This study develops a cloud-based deep learning system for early predictionof diabetes, leveraging the distributed computing capabilities of the AWS cloudplatform and deep learning technologies to achieve efficient and accurate riskassessment. The system utilizes EC2 p3.8xlarge GPU instances to acceleratemodel training, reducing training time by 93.2% while maintaining a predictionaccuracy of 94.2%. With an automated data processing and model trainingpipeline built using Apache Airflow, the system can complete end-to-end updateswithin 18.7 hours. In clinical applications, the system demonstrates aprediction accuracy of 89.8%, sensitivity of 92.3%, and specificity of 95.1%.Early interventions based on predictions lead to a 37.5% reduction in diabetesincidence among the target population. The system's high performance andscalability provide strong support for large-scale diabetes prevention andmanagement, showcasing significant public health value.</description><author>Yang Zhang, Fa Wang, Xin Huang, Xintao Li, Sibei Liu, Hansong Zhang</author><pubDate>Wed, 16 Oct 2024 15:03:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12642v1</guid></item><item><title>CECILIA: Comprehensive Secure Machine Learning Framework</title><link>http://arxiv.org/abs/2202.03023v4</link><description>Since ML algorithms have proven their success in many different applications,there is also a big interest in privacy preserving (PP) ML methods for buildingmodels on sensitive data. Moreover, the increase in the number of data sourcesand the high computational power required by those algorithms force individualsto outsource the training and/or the inference of a ML model to the cloudsproviding such services. To address this, we propose a secure 3-partycomputation framework, CECILIA, offering PP building blocks to enable complexoperations privately. In addition to the adapted and common operations likeaddition and multiplication, it offers multiplexer, most significant bit andmodulus conversion. The first two are novel in terms of methodology and thelast one is novel in terms of both functionality and methodology. CECILIA alsohas two complex novel methods, which are the exact exponential of a public baseraised to the power of a secret value and the inverse square root of a secretGram matrix. We use CECILIA to realize the private inference on pre-trainedRKNs, which require more complex operations than most other DNNs, on thestructural classification of proteins as the first study ever accomplishing thePP inference on RKNs. In addition to the successful private computation ofbasic building blocks, the results demonstrate that we perform the exact andfully private exponential computation, which is done by approximation in theliterature so far. Moreover, they also show that we compute the exact inversesquare root of a secret Gram matrix up to a certain privacy level, which hasnot been addressed in the literature at all. We also analyze the scalability ofCECILIA to various settings on a synthetic dataset. The framework shows a greatpromise to make other ML algorithms as well as further computations privatelycomputable by the building blocks of the framework.</description><author>Ali Burak Ünal, Nico Pfeifer, Mete Akgün</author><pubDate>Wed, 16 Oct 2024 15:02:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.03023v4</guid></item><item><title>Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans</title><link>http://arxiv.org/abs/2410.12641v1</link><description>Osteoarthritis is a degenerative condition affecting bones and cartilage,often leading to osteophyte formation, bone density loss, and joint spacenarrowing. Treatment options to restore normal joint function vary depending onthe severity of the condition. This work introduces an innovative deep-learningframework processing shoulder CT scans. It features the semantic segmentationof the proximal humerus and scapula, the 3D reconstruction of bone surfaces,the identification of the glenohumeral (GH) joint region, and the staging ofthree common osteoarthritic-related pathologies: osteophyte formation (OS), GHspace reduction (JS), and humeroscapular alignment (HSA). The pipelinecomprises two cascaded CNN architectures: 3D CEL-UNet for segmentation and 3DArthro-Net for threefold classification. A retrospective dataset of 571 CTscans featuring patients with various degrees of GH osteoarthritic-relatedpathologies was used to train, validate, and test the pipeline. Root meansquared error and Hausdorff distance median values for 3D reconstruction were0.22mm and 1.48mm for the humerus and 0.24mm and 1.48mm for the scapula,outperforming state-of-the-art architectures and making it potentially suitablefor a PSI-based shoulder arthroplasty preoperative plan context. Theclassification accuracy for OS, JS, and HSA consistently reached around 90%across all three categories. The computational time for the inference pipelinewas less than 15s, showcasing the framework's efficiency and compatibility withorthopedic radiology practice. The outcomes represent a promising advancementtoward the medical translation of artificial intelligence tools. This progressaims to streamline the preoperative planning pipeline delivering high-qualitybone surfaces and supporting surgeons in selecting the most suitable surgicalapproach according to the unique patient joint conditions.</description><author>Luca Marsilio, Davide Marzorati, Matteo Rossi, Andrea Moglia, Luca Mainardi, Alfonso Manzotti, Pietro Cerveri</author><pubDate>Wed, 16 Oct 2024 15:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12641v1</guid></item><item><title>Towards aerodynamic surrogate modeling based on $β$-variational autoencoders</title><link>http://arxiv.org/abs/2408.04969v2</link><description>Surrogate models that combine dimensionality reduction and regressiontechniques are essential to reduce the need for costly high-fidelitycomputational fluid dynamics data. New approaches using $\beta$-VariationalAutoencoder ($\beta$-VAE) architectures have shown promise in obtaininghigh-quality low-dimensional representations of high-dimensional flow datawhile enabling physical interpretation of their latent spaces. We propose asurrogate model based on latent space regression to predict pressuredistributions on a transonic wing given the flight conditions: Mach number andangle of attack. The $\beta$-VAE model, enhanced with Principal ComponentAnalysis (PCA), maps high-dimensional data to a low-dimensional latent space,showing a direct correlation with flight conditions. Regularization through$\beta$ requires careful tuning to improve overall performance, while PCApreprocessing helps to construct an effective latent space, improvingautoencoder training and performance. Gaussian Process Regression is used topredict latent space variables from flight conditions, showing robust behaviorindependent of $\beta$, and the decoder reconstructs the high-dimensionalpressure field data. This pipeline provides insight into unexplored flightconditions. Furthermore, a fine-tuning process of the decoder further refinesthe model, reducing the dependence on $\beta$ and enhancing accuracy.Structured latent space, robust regression performance, and significantimprovements in fine-tuning collectively create a highly accurate and efficientsurrogate model. Our methodology demonstrates the effectiveness of $\beta$-VAEsfor aerodynamic surrogate modeling, offering a rapid, cost-effective, andreliable alternative for aerodynamic data prediction.</description><author>Víctor Francés-Belda, Alberto Solera-Rico, Javier Nieto-Centenero, Esther Andrés, Carlos Sanmiguel Vila, Rodrigo Castellanos</author><pubDate>Wed, 16 Oct 2024 14:57:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04969v2</guid></item></channel></rss>