<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 19 Feb 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>The Price of Adaptivity in Stochastic Convex Optimization</title><link>http://arxiv.org/abs/2402.10898v1</link><description>We prove impossibility results for adaptivity in non-smooth stochastic convexoptimization. Given a set of problem parameters we wish to adapt to, we definea "price of adaptivity" (PoA) that, roughly speaking, measures themultiplicative increase in suboptimality due to uncertainty in theseparameters. When the initial distance to the optimum is unknown but a gradientnorm bound is known, we show that the PoA is at least logarithmic for expectedsuboptimality, and double-logarithmic for median suboptimality. When there isuncertainty in both distance and gradient norm, we show that the PoA must bepolynomial in the level of uncertainty. Our lower bounds nearly match existingupper bounds, and establish that there is no parameter-free lunch.</description><author>Yair Carmon, Oliver Hinder</author><pubDate>Fri, 16 Feb 2024 18:56:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10898v1</guid></item><item><title>PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter</title><link>http://arxiv.org/abs/2402.10896v1</link><description>This paper demonstrates that a progressively aligned language model caneffectively bridge frozen vision encoders and large language models (LLMs).While the fundamental architecture and pre-training methods of vision encodersand LLMs have been extensively studied, the architecture and training strategyof vision-language adapters vary significantly across recent works. Ourresearch undertakes a thorough exploration of the state-of-the-art perceiverresampler architecture and builds a strong baseline. However, we observe thatthe vision-language alignment with perceiver resampler exhibits slowconvergence and limited scalability with a lack of direct supervision. Toaddress this issue, we propose PaLM2-VAdapter, employing a progressivelyaligned language model as the vision-language adapter. Compared to the strongbaseline with perceiver resampler, our method empirically shows fasterconvergence, higher performance, and stronger scalability. Extensiveexperiments across various Visual Question Answering (VQA) and captioning taskson both images and videos demonstrate that our model exhibits state-of-the-artvisual understanding and multi-modal reasoning capabilities. Notably, ourmethod achieves these advancements with 30~70% fewer parameters than thestate-of-the-art large vision-language models, marking a significant efficiencyimprovement.</description><author>Junfei Xiao, Zheng Xu, Alan Yuille, Shen Yan, Boyu Wang</author><pubDate>Fri, 16 Feb 2024 18:54:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10896v1</guid></item><item><title>Fusion of Diffusion Weighted MRI and Clinical Data for Predicting Functional Outcome after Acute Ischemic Stroke with Deep Contrastive Learning</title><link>http://arxiv.org/abs/2402.10894v1</link><description>Stroke is a common disabling neurological condition that affects aboutone-quarter of the adult population over age 25; more than half of patientsstill have poor outcomes, such as permanent functional dependence or evendeath, after the onset of acute stroke. The aim of this study is to investigatethe efficacy of diffusion-weighted MRI modalities combining with structuredhealth profile on predicting the functional outcome to facilitate earlyintervention. A deep fusion learning network is proposed with two-stagetraining: the first stage focuses on cross-modality representation learning andthe second stage on classification. Supervised contrastive learning isexploited to learn discriminative features that separate the two classes ofpatients from embeddings of individual modalities and from the fused multimodalembedding. The network takes as the input DWI and ADC images, and structuredhealth profile data. The outcome is the prediction of the patient needinglong-term care at 3 months after the onset of stroke. Trained and evaluatedwith a dataset of 3297 patients, our proposed fusion model achieves 0.87, 0.80and 80.45% for AUC, F1-score and accuracy, respectively, outperforming existingmodels that consolidate both imaging and structured data in the medical domain.If trained with comprehensive clinical variables, including NIHSS andcomorbidities, the gain from images on making accurate prediction is notconsidered substantial, but significant. However, diffusion-weighted MRI canreplace NIHSS to achieve comparable level of accuracy combining with otherreadily available clinical variables for better generalization.</description><author>Chia-Ling Tsai, Hui-Yun Su, Shen-Feng Sung, Wei-Yang Lin, Ying-Ying Su, Tzu-Hsien Yang, Man-Lin Mai</author><pubDate>Fri, 16 Feb 2024 18:51:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10894v1</guid></item><item><title>RLVF: Learning from Verbal Feedback without Overgeneralization</title><link>http://arxiv.org/abs/2402.10893v1</link><description>The diversity of contexts in which large language models (LLMs) are deployedrequires the ability to modify or customize default model behaviors toincorporate nuanced requirements and preferences. A convenient interface tospecify such model adjustments is high-level verbal feedback, such as "Don'tuse emojis when drafting emails to my boss." However, while writing high-levelfeedback is far simpler than collecting annotations for reinforcement learningfrom human feedback (RLHF), we find that simply prompting a model with suchfeedback leads to overgeneralization of the feedback to contexts where it isnot relevant. We study the problem of incorporating verbal feedback withoutsuch overgeneralization, inspiring a new method Contextualized Critiques withConstrained Preference Optimization (C3PO). C3PO uses a piece of high-levelfeedback to generate a small synthetic preference dataset specifying how thefeedback should (and should not) be applied. It then fine-tunes the model inaccordance with the synthetic preference data while minimizing the divergencefrom the original model for prompts where the feedback does not apply. Ourexperimental results indicate that our approach effectively applies verbalfeedback to relevant scenarios while preserving existing behaviors for othercontexts. For both human- and GPT-4-generated high-level feedback, C3POeffectively adheres to the given feedback comparably to in-context baselineswhile reducing overgeneralization by 30%.</description><author>Moritz Stephan, Alexander Khazatsky, Eric Mitchell, Annie S Chen, Sheryl Hsu, Archit Sharma, Chelsea Finn</author><pubDate>Fri, 16 Feb 2024 18:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10893v1</guid></item><item><title>Proving membership in LLM pretraining data via data watermarks</title><link>http://arxiv.org/abs/2402.10892v1</link><description>Detecting whether copyright holders' works were used in LLM pretraining ispoised to be an important problem. This work proposes using data watermarks toenable principled detection with only black-box model access, provided that therightholder contributed multiple training documents and watermarked them beforepublic release. By applying a randomly sampled data watermark, detection can beframed as hypothesis testing, which provides guarantees on the false detectionrate. We study two watermarks: one that inserts random sequences, and anotherthat randomly substitutes characters with Unicode lookalikes. We first show howthree aspects of watermark design -- watermark length, number of duplications,and interference -- affect the power of the hypothesis test. Next, we study howa watermark's detection strength changes under model and dataset scaling: whileincreasing the dataset size decreases the strength of the watermark, watermarksremain strong if the model size also increases. Finally, we view SHA hashes asnatural watermarks and show that we can robustly detect hashes fromBLOOM-176B's training data, as long as they occurred at least 90 times.Together, our results point towards a promising future for data watermarks inreal world use.</description><author>Johnny Tian-Zheng Wei, Ryan Yixiang Wang, Robin Jia</author><pubDate>Fri, 16 Feb 2024 18:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10892v1</guid></item><item><title>Instruction Diversity Drives Generalization To Unseen Tasks</title><link>http://arxiv.org/abs/2402.10891v1</link><description>Instruction tuning -- fine-tuning a large language model (LLM) on pairs ofinstructions and desired outcomes -- is an approach that enables pre-trainedlanguage models to perform real-world tasks and follow human instructions. Itspractical success depends on the model learning a broader set of instructionsthan those it was trained on. Yet the factors that determine modelgeneralization to such \emph{unseen tasks} are not well understood. %Tounderstand the driving factors of generalization, In this paper, we experimentwith string rewrites, a symbolic task that serves as a building block forTuring complete Markov algorithms while allowing experimental control of"inputs" and "instructions". We investigate the trade-off between the number ofinstructions the model is trained on and the number of training samplesprovided for each instruction and observe that the diversity of the instructionset determines generalization. Generalization emerges once a diverse enough setof tasks is provided, even though very few examples are provided for each task.Instruction diversity also ensures robustness with respect to non-uniformdistributions of instructions in the training set.</description><author>Dylan Zhang, Justin Wang, Francois Charton</author><pubDate>Fri, 16 Feb 2024 18:47:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10891v1</guid></item><item><title>When is Tree Search Useful for LLM Planning? It Depends on the Discriminator</title><link>http://arxiv.org/abs/2402.10890v1</link><description>In this paper, we examine how large language models (LLMs) solve multi-stepproblems under a language agent framework with three components: a generator, adiscriminator, and a planning method. We investigate the practical utility oftwo advanced planning methods, iterative correction and tree search. We presenta comprehensive analysis of how discrimination accuracy affects the overallperformance of agents when using these two methods or a simpler method,re-ranking. Experiments on two tasks, text-to-SQL parsing and mathematicalreasoning, show that: (1) advanced planning methods demand discriminators withat least 90% accuracy to achieve significant improvements over re-ranking; (2)current LLMs' discrimination abilities have not met the needs of advancedplanning methods to achieve such improvements; (3) with LLM-baseddiscriminators, advanced planning methods may not adequately balance accuracyand efficiency. For example, compared to the other two methods, tree search isat least 10--20 times slower but leads to negligible performance gains, whichhinders its real-world applications. Code and data will be released athttps://github.com/OSU-NLP-Group/llm-planning-eval.</description><author>Ziru Chen, Michael White, Raymond Mooney, Ali Payani, Yu Su, Huan Sun</author><pubDate>Fri, 16 Feb 2024 18:45:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10890v1</guid></item><item><title>Explainability for Machine Learning Models: From Data Adaptability to User Perception</title><link>http://arxiv.org/abs/2402.10888v1</link><description>This thesis explores the generation of local explanations for alreadydeployed machine learning models, aiming to identify optimal conditions forproducing meaningful explanations considering both data and user requirements.The primary goal is to develop methods for generating explanations for anymodel while ensuring that these explanations remain faithful to the underlyingmodel and comprehensible to the users. The thesis is divided into two parts. The first enhances a widely usedrule-based explanation method. It then introduces a novel approach forevaluating the suitability of linear explanations to approximate a model.Additionally, it conducts a comparative experiment between two families ofcounterfactual explanation methods to analyze the advantages of one over theother. The second part focuses on user experiments to assess the impact ofthree explanation methods and two distinct representations. These experimentsmeasure how users perceive their interaction with the model in terms ofunderstanding and trust, depending on the explanations and representations.This research contributes to a better explanation generation, with potentialimplications for enhancing the transparency, trustworthiness, and usability ofdeployed AI systems.</description><author>julien Delaunay</author><pubDate>Fri, 16 Feb 2024 18:44:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10888v1</guid></item><item><title>Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation</title><link>http://arxiv.org/abs/2402.10887v1</link><description>Medical image segmentation is increasingly reliant on deep learningtechniques, yet the promising performance often come with high annotationcosts. This paper introduces Weak-Mamba-UNet, an innovative weakly-supervisedlearning (WSL) framework that leverages the capabilities of ConvolutionalNeural Network (CNN), Vision Transformer (ViT), and the cutting-edge VisualMamba (VMamba) architecture for medical image segmentation, especially whendealing with scribble-based annotations. The proposed WSL strategy incorporatesthree distinct architecture but same symmetrical encoder-decoder networks: aCNN-based UNet for detailed local feature extraction, a Swin Transformer-basedSwinUNet for comprehensive global context understanding, and a VMamba-basedMamba-UNet for efficient long-range dependency modeling. The key concept ofthis framework is a collaborative and cross-supervisory mechanism that employspseudo labels to facilitate iterative learning and refinement across thenetworks. The effectiveness of Weak-Mamba-UNet is validated on a publiclyavailable MRI cardiac segmentation dataset with processed scribble annotations,where it surpasses the performance of a similar WSL framework utilizing onlyUNet or SwinUNet. This highlights its potential in scenarios with sparse orimprecise annotations. The source code is made publicly accessible.</description><author>Ziyang Wang, Chao Ma</author><pubDate>Fri, 16 Feb 2024 18:43:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10887v1</guid></item><item><title>Reviewer2: Optimizing Review Generation Through Prompt Generation</title><link>http://arxiv.org/abs/2402.10886v1</link><description>Recent developments in LLMs offer new opportunities for assisting authors inimproving their work. In this paper, we envision a use case where authors canreceive LLM-generated reviews that uncover weak points in the current draft.While initial methods for automated review generation already exist, thesemethods tend to produce reviews that lack detail, and they do not cover therange of opinions that human reviewers produce. To address this shortcoming, wepropose an efficient two-stage review generation framework called Reviewer2.Unlike prior work, this approach explicitly models the distribution of possibleaspects that the review may address. We show that this leads to more detailedreviews that better cover the range of aspects that human reviewers identify inthe draft. As part of the research, we generate a large-scale review dataset of27k papers and 99k reviews that we annotate with aspect prompts, which we makeavailable as a resource for future research.</description><author>Zhaolin Gao, Kianté Brantley, Thorsten Joachims</author><pubDate>Fri, 16 Feb 2024 18:43:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10886v1</guid></item><item><title>3D Diffuser Actor: Policy Diffusion with 3D Scene Representations</title><link>http://arxiv.org/abs/2402.10885v1</link><description>We marry diffusion policies and 3D scene representations for robotmanipulation. Diffusion policies learn the action distribution conditioned onthe robot and environment state using conditional diffusion models. They haverecently shown to outperform both deterministic and alternativestate-conditioned action distribution learning methods. 3D robot policies use3D scene feature representations aggregated from a single or multiple cameraviews using sensed depth. They have shown to generalize better than their 2Dcounterparts across camera viewpoints. We unify these two lines of work andpresent 3D Diffuser Actor, a neural policy architecture that, given a languageinstruction, builds a 3D representation of the visual scene and conditions onit to iteratively denoise 3D rotations and translations for the robot'send-effector. At each denoising iteration, our model represents end-effectorpose estimates as 3D scene tokens and predicts the 3D translation and rotationerror for each of them, by featurizing them using 3D relative attention toother 3D visual and language tokens. 3D Diffuser Actor sets a newstate-of-the-art on RLBench with an absolute performance gain of 16.3% over thecurrent SOTA on a multi-view setup and an absolute gain of 13.1% on asingle-view setup. On the CALVIN benchmark, it outperforms the current SOTA inthe setting of zero-shot unseen scene generalization by being able tosuccessfully run 0.2 more tasks, a 7% relative increase. It also works in thereal world from a handful of demonstrations. We ablate our model'sarchitectural design choices, such as 3D scene featurization and 3D relativeattentions, and show they all help generalization. Our results suggest that 3Dscene representations and powerful generative modeling are keys to efficientrobot learning from demonstrations.</description><author>Tsung-Wei Ke, Nikolaos Gkanatsios, Katerina Fragkiadaki</author><pubDate>Fri, 16 Feb 2024 18:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10885v1</guid></item><item><title>Multi-modal preference alignment remedies regression of visual instruction tuning on language model</title><link>http://arxiv.org/abs/2402.10884v1</link><description>In production, multi-modal large language models (MLLMs) are expected tosupport multi-turn queries of interchanging image and text modalities. However,the current MLLMs trained with visual-question-answering (VQA) datasets couldsuffer from degradation, as VQA datasets lack the diversity and complexity ofthe original text instruction datasets which the underlying language model hadbeen trained with. To address this challenging degradation, we first collect alightweight (6k entries) VQA preference dataset where answers were annotated byGemini for 5 quality metrics in a granular fashion, and investigate standardSupervised Fine-tuning, rejection sampling, Direct Preference Optimization(DPO), and SteerLM. Our findings indicate that the with DPO we are able tosurpass instruction-following capabilities of the language model, achieving a6.73 score on MT-Bench, compared to Vicuna's 6.57 and LLaVA's 5.99 despitesmall data scale. This enhancement in textual instruction proficiencycorrelates with boosted visual instruction performance (+4.9\% on MM-Vet, +6\%on LLaVA-Bench), with minimal alignment tax on visual knowledge benchmarkscompared to previous RLHF approach. In conclusion, we propose adistillation-based multi-modal alignment model with fine-grained annotations ona small dataset that reconciles the textual and visual performance of MLLMs,restoring and boosting language capability after visual instruction tuning.</description><author>Shengzhi Li, Rongyu Lin, Shichao Pei</author><pubDate>Fri, 16 Feb 2024 18:42:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10884v1</guid></item><item><title>Do Compressed LLMs Forget Knowledge? An Experimental Study with Practical Implications</title><link>http://arxiv.org/abs/2310.00867v3</link><description>Compressing Large Language Models (LLMs) often leads to reduced performance,especially for knowledge-intensive tasks. In this work, we dive into howcompression damages LLMs' inherent knowledge and the possible remedies. Westart by proposing two conjectures on the nature of the damage: one is certainknowledge being forgotten (or erased) after LLM compression, hencenecessitating the compressed model to (re)learn from data with additionalparameters; the other presumes that knowledge is internally displaced and henceone requires merely "inference re-direction" with input-side augmentation suchas prompting, to recover the knowledge-related performance. Extensiveexperiments are then designed to (in)validate the two conjectures. We observethe promise of prompting in comparison to model tuning; we further unlockprompting's potential by introducing a variant called Inference-time DynamicPrompting (IDP), that can effectively increase prompt diversity withoutincurring any inference overhead. Our experiments consistently suggest thatcompared to the classical re-training alternatives such as LoRA, prompting withIDP leads to better or comparable post-compression performance recovery, whilesaving the extra parameter size by 21x and reducing inference latency by 60%.Our experiments hence strongly endorse the conjecture of "knowledge displaced"over "knowledge forgotten", and shed light on a new efficient mechanism torestore compressed LLM performance. We additionally visualize and analyze thedifferent attention and activation patterns between prompted and re-trainedmodels, demonstrating they achieve performance recovery in two differentregimes.</description><author>Duc N. M Hoang, Minsik Cho, Thomas Merth, Mohammad Rastegari, Zhangyang Wang</author><pubDate>Fri, 16 Feb 2024 18:39:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00867v3</guid></item><item><title>Universal Prompt Optimizer for Safe Text-to-Image Generation</title><link>http://arxiv.org/abs/2402.10882v1</link><description>Text-to-Image (T2I) models have shown great performance in generating imagesbased on textual prompts. However, these models are vulnerable to unsafe inputto generate unsafe content like sexual, harassment and illegal-activity images.Existing studies based on image checker, model fine-tuning and embeddingblocking are impractical in real-world applications. Hence, \textit{we proposethe first universal prompt optimizer for safe T2I generation in black-boxscenario}. We first construct a dataset consisting of toxic-clean prompt pairsby GPT-3.5 Turbo. To guide the optimizer to have the ability of convertingtoxic prompt to clean prompt while preserving semantic information, we design anovel reward function measuring toxicity and text alignment of generated imagesand train the optimizer through Proximal Policy Optimization. Experiments showthat our approach can effectively reduce the likelihood of various T2I modelsin generating inappropriate images, with no significant impact on textalignment. It is also flexible to be combined with methods to achieve betterperformance.</description><author>Zongyu Wu, Hongcheng Gao, Yueze Wang, Xiang Zhang, Suhang Wang</author><pubDate>Fri, 16 Feb 2024 18:36:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10882v1</guid></item><item><title>CodeMind: A Framework to Challenge Large Language Models for Code Reasoning</title><link>http://arxiv.org/abs/2402.09664v2</link><description>Solely relying on test passing to evaluate Large Language Models (LLMs) forcode synthesis may result in unfair assessment or promoting models with dataleakage. As an alternative, we introduce CodeMind, a framework designed togauge the code reasoning abilities of LLMs. CodeMind currently supports threecode reasoning tasks: Independent Execution Reasoning (IER), DependentExecution Reasoning (DER), and Specification Reasoning (SR). The first twoevaluate models to predict the execution output of an arbitrary code or codethe model could correctly synthesize. The third one evaluates the extent towhich LLMs implement the specified expected behavior. Our extensive evaluationof nine LLMs across five benchmarks in two different programming languagesusing CodeMind shows that LLMs fairly understand control flow constructs and,in general, are capable of reasoning how inputs evolve to output, specificallyfor simple programs and the ones they can correctly synthesize. However, theirperformance drops for code with higher complexity, non-trivial logical andarithmetic operators, non-primitive types, and API calls. Furthermore, weobserve that, while correlated, specification reasoning (essential for codesynthesis) does not imply execution reasoning (essential for broaderprogramming tasks such as testing and debugging): ranking LLMs based on testpassing can be different compared to code reasoning.</description><author>Changshu Liu, Shizhuo Dylan Zhang, Reyhaneh Jabbarvand</author><pubDate>Fri, 16 Feb 2024 18:35:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09664v2</guid></item><item><title>Robust agents learn causal world models</title><link>http://arxiv.org/abs/2402.10877v1</link><description>It has long been hypothesised that causal reasoning plays a fundamental rolein robust and general intelligence. However, it is not known if agents mustlearn causal models in order to generalise to new domains, or if otherinductive biases are sufficient. We answer this question, showing that anyagent capable of satisfying a regret bound under a large set of distributionalshifts must have learned an approximate causal model of the data generatingprocess, which converges to the true causal model for optimal agents. Wediscuss the implications of this result for several research areas includingtransfer learning and causal inference.</description><author>Jonathan Richens, Tom Everitt</author><pubDate>Fri, 16 Feb 2024 18:29:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10877v1</guid></item><item><title>Design of 2D Skyrmionic Metamaterial Through Controlled Assembly</title><link>http://arxiv.org/abs/2402.10874v1</link><description>Despite extensive research on magnetic skyrmions and antiskyrmions, asignificant challenge remains in crafting nontrivial high-order skyrmionictextures with varying, or even tailor-made, topologies. We address thischallenge, by focusing on a construction pathway of skyrmionics metamaterialwithin a monolayer thin film and suggest several promising lattice-like,flakes-like, and cell-like skyrmionic metamaterials that are surprisinglystable. Central to our approach is the concept of 'simulated controlledassembly', in short, a protocol inspired by 'click chemistry' that allows forpositioning topological magnetic structures where one likes, and then allowingfor energy minimization to elucidate the stability. Utilizing high-throughputatomistic-spin-dynamic (ASD) simulations alongside state-of-the-art AI-driventools, we have isolated skyrmions (topological charge Q=1), antiskyrmions(Q=-1), and skyrmionium (Q=0). These entities serve as foundational 'skyrmionicbuilding blocks' to forming reported intricate textures. In this work, two keycontributions are introduced to the field of skyrmionic systems. First, wepresent a novel method for integrating control assembly protocols for thestabilization and investigation of topological magnets, which marks asignificant advancement in the ability to explore new skyrmionic textures.Second, we report on the discovery of skyrmionic metamaterials, which shows aplethora of complex topologies that are possible to investigate theoreticallyand experimentally.</description><author>Qichen Xu, Zhuanglin Shen, Alexander Edström, I. P. Miranda, Zhiwei Lu, Anders Bergman, Danny Thonig, Wanjian Yin, Olle Eriksson, Anna Delin</author><pubDate>Fri, 16 Feb 2024 18:20:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10874v1</guid></item><item><title>Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process</title><link>http://arxiv.org/abs/2402.04146v2</link><description>With the advent of artificial intelligence (AI) and machine learning (ML),various domains of science and engineering communites has leveraged data-drivensurrogates to model complex systems from numerous sources of information(data). The proliferation has led to significant reduction in cost and timeinvolved in development of superior systems designed to perform specificfunctionalities. A high proposition of such surrogates are built extensivelyfusing multiple sources of data, may it be published papers, patents, openrepositories, or other resources. However, not much attention has been paid tothe differences in quality and comprehensiveness of the known and unknownunderlying physical parameters of the information sources that could havedownstream implications during system optimization. Towards resolving thisissue, a multi-source data fusion framework based on Latent Variable GaussianProcess (LVGP) is proposed. The individual data sources are tagged as acharacteristic categorical variable that are mapped into a physicallyinterpretable latent space, allowing the development of source-aware datafusion modeling. Additionally, a dissimilarity metric based on the latentvariables of LVGP is introduced to study and understand the differences in thesources of data. The proposed approach is demonstrated on and analyzed throughtwo mathematical (representative parabola problem, 2D Ackley function) and twomaterials science (design of FeCrAl and SmCoFe alloys) case studies. From thecase studies, it is observed that compared to using single-source and sourceunaware ML models, the proposed multi-source data fusion framework can providebetter predictions for sparse-data problems, interpretability regarding thesources, and enhanced modeling capabilities by taking advantage of thecorrelations and relationships among different sources.</description><author>Sandipp Krishnan Ravi, Yigitcan Comlek, Wei Chen, Arjun Pathak, Vipul Gupta, Rajnikant Umretiya, Andrew Hoffman, Ghanshyam Pilania, Piyush Pandita, Sayan Ghosh, Nathaniel Mckeever, Liping Wang</author><pubDate>Fri, 16 Feb 2024 18:17:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04146v2</guid></item><item><title>Best of Three Worlds: Adaptive Experimentation for Digital Marketing in Practice</title><link>http://arxiv.org/abs/2402.10870v1</link><description>Adaptive experimental design (AED) methods are increasingly being used inindustry as a tool to boost testing throughput or reduce experimentation costrelative to traditional A/B/N testing methods. However, the behavior andguarantees of such methods are not well-understood beyond idealized stationarysettings. This paper shares lessons learned regarding the challenges of naivelyusing AED systems in industrial settings where non-stationarity is prevalent,while also providing perspectives on the proper objectives and systemspecifications in such settings. We developed an AED framework forcounterfactual inference based on these experiences, and tested it in acommercial environment.</description><author>Tanner Fiez, Houssam Nassif, Arick Chen, Sergio Gamez, Lalit Jain</author><pubDate>Fri, 16 Feb 2024 18:13:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10870v1</guid></item><item><title>K-space Cold Diffusion: Learning to Reconstruct Accelerated MRI without Noise</title><link>http://arxiv.org/abs/2311.10162v2</link><description>Deep learning-based MRI reconstruction models have achieved superiorperformance these days. Most recently, diffusion models have shown remarkableperformance in image generation, in-painting, super-resolution, image editingand more. As a generalized diffusion model, cold diffusion further broadens thescope and considers models built around arbitrary image transformations such asblurring, down-sampling, etc. In this paper, we propose a k-space colddiffusion model that performs image degradation and restoration in k-spacewithout the need for Gaussian noise. We provide comparisons with multiple deeplearning-based MRI reconstruction models and perform tests on a well-knownlarge open-source MRI dataset. Our results show that this novel way ofperforming degradation can generate high-quality reconstruction images foraccelerated MRI.</description><author>Guoyao Shen, Mengyu Li, Chad W. Farris, Stephan Anderson, Xin Zhang</author><pubDate>Fri, 16 Feb 2024 18:08:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10162v2</guid></item><item><title>Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis with Generative AI through Rapid Prototyping, Iteration and Curation</title><link>http://arxiv.org/abs/2402.08812v2</link><description>Complex data analysis inherently seeks unexpected insights throughexploratory \re{visual analysis} methods, transcending logical, step-by-stepprocessing. However, \re{existing interfaces such as notebooks and dashboardshave limitations in exploration and comparison for visual data analysis}.Addressing these limitations, we introduce a "design-like" intelligent canvasenvironment integrating generative AI into data analysis, offering rapidprototyping, iteration, and comparative visualization management. Our dualcontributions include the integration of generative AI components into a canvasinterface, and empirical findings from a user study (N=10) evaluating theeffectiveness of the canvas interface.</description><author>Zijian Ding, Joel Chan</author><pubDate>Fri, 16 Feb 2024 18:04:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08812v2</guid></item><item><title>EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models</title><link>http://arxiv.org/abs/2402.10866v1</link><description>Large Language Models (LLMs) have achieved state-of-the-art performance intext re-ranking. This process includes queries and candidate passages in theprompts, utilizing pointwise, listwise, and pairwise prompting strategies. Alimitation of these ranking strategies with LLMs is their cost: the process canbecome expensive due to API charges, which are based on the number of input andoutput tokens. We study how to maximize the re-ranking performance given abudget, by navigating the vast search spaces of prompt choices, LLM APIs, andbudget splits. We propose a suite of budget-constrained methods to perform textre-ranking using a set of LLM APIs. Our most efficient method, called EcoRank,is a two-layered pipeline that jointly optimizes decisions regarding budgetallocation across prompt strategies and LLM APIs. Our experimental results onfour popular QA and passage reranking datasets show that EcoRank outperformsother budget-aware supervised and unsupervised baselines.</description><author>Muhammad Shihab Rashid, Jannat Ara Meem, Yue Dong, Vagelis Hristidis</author><pubDate>Fri, 16 Feb 2024 18:03:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10866v1</guid></item><item><title>A Mass-Conserving-Perceptron for Machine Learning-Based Modeling of Geoscientific Systems</title><link>http://arxiv.org/abs/2310.08644v3</link><description>Although decades of effort have been devoted to building Physical-Conceptual(PC) models for predicting the time-series evolution of geoscientific systems,recent work shows that Machine Learning (ML) based Gated Recurrent NeuralNetwork technology can be used to develop models that are much more accurate.However, the difficulty of extracting physical understanding from ML-basedmodels complicates their utility for enhancing scientific knowledge regardingsystem structure and function. Here, we propose a physically-interpretable MassConserving Perceptron (MCP) as a way to bridge the gap between PC-based andML-based modeling approaches. The MCP exploits the inherent isomorphism betweenthe directed graph structures underlying both PC models and GRNNs to explicitlyrepresent the mass-conserving nature of physical processes while enabling thefunctional nature of such processes to be directly learned (in an interpretablemanner) from available data using off-the-shelf ML technology. As a proof ofconcept, we investigate the functional expressivity (capacity) of the MCP,explore its ability to parsimoniously represent the rainfall-runoff (RR)dynamics of the Leaf River Basin, and demonstrate its utility for scientifichypothesis testing. To conclude, we discuss extensions of the concept to enableML-based physical-conceptual representation of the coupled nature ofmass-energy-information flows through geoscientific systems.</description><author>Yuan-Heng Wang, Hoshin V. Gupta</author><pubDate>Fri, 16 Feb 2024 18:02:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08644v3</guid></item><item><title>Multi-Model 3D Registration: Finding Multiple Moving Objects in Cluttered Point Clouds</title><link>http://arxiv.org/abs/2402.10865v1</link><description>We investigate a variation of the 3D registration problem, named multi-model3D registration. In the multi-model registration problem, we are given twopoint clouds picturing a set of objects at different poses (and possiblyincluding points belonging to the background) and we want to simultaneouslyreconstruct how all objects moved between the two point clouds. This setupgeneralizes standard 3D registration where one wants to reconstruct a singlepose, e.g., the motion of the sensor picturing a static scene. Moreover, itprovides a mathematically grounded formulation for relevant roboticsapplications, e.g., where a depth sensor onboard a robot perceives a dynamicscene and has the goal of estimating its own motion (from the static portion ofthe scene) while simultaneously recovering the motion of all dynamic objects.We assume a correspondence-based setup where we have putative matches betweenthe two point clouds and consider the practical case where thesecorrespondences are plagued with outliers. We then propose a simple approachbased on Expectation-Maximization (EM) and establish theoretical conditionsunder which the EM approach converges to the ground truth. We evaluate theapproach in simulated and real datasets ranging from table-top scenes toself-driving scenarios and demonstrate its effectiveness when combined withstate-of-the-art scene flow methods to establish dense correspondences.</description><author>David Jin, Sushrut Karmalkar, Harry Zhang, Luca Carlone</author><pubDate>Fri, 16 Feb 2024 18:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10865v1</guid></item><item><title>Differential Private Federated Transfer Learning for Mental Health Monitoring in Everyday Settings: A Case Study on Stress Detection</title><link>http://arxiv.org/abs/2402.10862v1</link><description>Mental health conditions, prevalent across various demographics, necessitateefficient monitoring to mitigate their adverse impacts on life quality. Thesurge in data-driven methodologies for mental health monitoring has underscoredthe importance of privacy-preserving techniques in handling sensitive healthdata. Despite strides in federated learning for mental health monitoring,existing approaches struggle with vulnerabilities to certain cyber-attacks anddata insufficiency in real-world applications. In this paper, we introduce adifferential private federated transfer learning framework for mental healthmonitoring to enhance data privacy and enrich data sufficiency. To accomplishthis, we integrate federated learning with two pivotal elements: (1)differential privacy, achieved by introducing noise into the updates, and (2)transfer learning, employing a pre-trained universal model to adeptly addressissues of data imbalance and insufficiency. We evaluate the framework by a casestudy on stress detection, employing a dataset of physiological and contextualdata from a longitudinal study. Our finding show that the proposed approach canattain a 10% boost in accuracy and a 21% enhancement in recall, while ensuringprivacy protection.</description><author>Ziyu Wang, Zhongqi Yang, Iman Azimi, Amir M. Rahmani</author><pubDate>Fri, 16 Feb 2024 18:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10862v1</guid></item><item><title>JetTrain: IDE-Native Machine Learning Experiments</title><link>http://arxiv.org/abs/2402.10857v1</link><description>Integrated development environments (IDEs) are prevalent code-writing anddebugging tools. However, they have yet to be widely adopted for launchingmachine learning (ML) experiments. This work aims to fill this gap byintroducing JetTrain, an IDE-integrated tool that delegates specific tasks froman IDE to remote computational resources. A user can write and debug codelocally and then seamlessly run it remotely using on-demand hardware. We arguethat this approach can lower the entry barrier for ML training problems andincrease experiment throughput.</description><author>Artem Trofimov, Mikhail Kostyukov, Sergei Ugdyzhekov, Natalia Ponomareva, Igor Naumov, Maksim Melekhovets</author><pubDate>Fri, 16 Feb 2024 17:53:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10857v1</guid></item><item><title>Control Color: Multimodal Diffusion-based Interactive Image Colorization</title><link>http://arxiv.org/abs/2402.10855v1</link><description>Despite the existence of numerous colorization methods, several limitationsstill exist, such as lack of user interaction, inflexibility in localcolorization, unnatural color rendering, insufficient color variation, andcolor overflow. To solve these issues, we introduce Control Color (CtrlColor),a multi-modal colorization method that leverages the pre-trained StableDiffusion (SD) model, offering promising capabilities in highly controllableinteractive image colorization. While several diffusion-based methods have beenproposed, supporting colorization in multiple modalities remains non-trivial.In this study, we aim to tackle both unconditional and conditional imagecolorization (text prompts, strokes, exemplars) and address color overflow andincorrect color within a unified framework. Specifically, we present aneffective way to encode user strokes to enable precise local color manipulationand employ a practical way to constrain the color distribution similar toexemplars. Apart from accepting text prompts as conditions, these designs addversatility to our approach. We also introduce a novel module based onself-attention and a content-guided deformable autoencoder to address thelong-standing issues of color overflow and inaccurate coloring. Extensivecomparisons show that our model outperforms state-of-the-art image colorizationmethods both qualitatively and quantitatively.</description><author>Zhexin Liang, Zhaochen Li, Shangchen Zhou, Chongyi Li, Chen Change Loy</author><pubDate>Fri, 16 Feb 2024 17:51:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10855v1</guid></item><item><title>HistoSegCap: Capsules for Weakly-Supervised Semantic Segmentation of Histological Tissue Type in Whole Slide Images</title><link>http://arxiv.org/abs/2402.10851v1</link><description>Digital pathology involves converting physical tissue slides intohigh-resolution Whole Slide Images (WSIs), which pathologists analyze fordisease-affected tissues. However, large histology slides with numerousmicroscopic fields pose challenges for visual search. To aid pathologists,Computer Aided Diagnosis (CAD) systems offer visual assistance in efficientlyexamining WSIs and identifying diagnostically relevant regions. This paperpresents a novel histopathological image analysis method employing WeaklySupervised Semantic Segmentation (WSSS) based on Capsule Networks, the firstsuch application. The proposed model is evaluated using the Atlas of DigitalPathology (ADP) dataset and its performance is compared with otherhistopathological semantic segmentation methodologies. The findings underscorethe potential of Capsule Networks in enhancing the precision and efficiency ofhistopathological image analysis. Experimental results show that the proposedmodel outperforms traditional methods in terms of accuracy and the meanIntersection-over-Union (mIoU) metric.</description><author>Mobina Mansoori, Sajjad Shahabodini, Jamshid Abouei, Arash Mohammadi, Konstantinos N. Plataniotis</author><pubDate>Fri, 16 Feb 2024 17:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10851v1</guid></item><item><title>Single Cells Are Spatial Tokens: Transformers for Spatial Transcriptomic Data Imputation</title><link>http://arxiv.org/abs/2302.03038v2</link><description>Spatially resolved transcriptomics brings exciting breakthroughs tosingle-cell analysis by providing physical locations along with geneexpression. However, as a cost of the extremely high spatial resolution, thecellular level spatial transcriptomic data suffer significantly from missingvalues. While a standard solution is to perform imputation on the missingvalues, most existing methods either overlook spatial information or onlyincorporate localized spatial context without the ability to capture long-rangespatial information. Using multi-head self-attention mechanisms and positionalencoding, transformer models can readily grasp the relationship between tokensand encode location information. In this paper, by treating single cells asspatial tokens, we study how to leverage transformers to facilitate spatialtanscriptomics imputation. In particular, investigate the following two keyquestions: (1) $\textit{how to encode spatial information of cells intransformers}$, and (2) $\textit{ how to train a transformer for transcriptomicimputation}$. By answering these two questions, we present a transformer-basedimputation framework, SpaFormer, for cellular-level spatial transcriptomicdata. Extensive experiments demonstrate that SpaFormer outperforms existingstate-of-the-art imputation algorithms on three large-scale datasets whilemaintaining superior computational efficiency.</description><author>Hongzhi Wen, Wenzhuo Tang, Wei Jin, Jiayuan Ding, Renming Liu, Xinnan Dai, Feng Shi, Lulu Shang, Hui Liu, Yuying Xie</author><pubDate>Fri, 16 Feb 2024 17:42:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03038v2</guid></item><item><title>KGLens: A Parameterized Knowledge Graph Solution to Assess What an LLM Does and Doesn't Know</title><link>http://arxiv.org/abs/2312.11539v2</link><description>Measuring the alignment between a Knowledge Graph (KG) and Large LanguageModels (LLMs) is an effective method to assess the factualness and identify theknowledge blind spots of LLMs. However, this approach encounters two primarychallenges including the translation of KGs into natural language and theefficient evaluation of these extensive and complex structures. In this paper,we present KGLens--a novel framework aimed at measuring the alignment betweenKGs and LLMs, and pinpointing the LLMs' knowledge deficiencies relative to KGs.KGLens features a graph-guided question generator for converting KGs intonatural language, along with a carefully designed sampling strategy based onparameterized KG structure to expedite KG traversal. We conducted experimentsusing three domain-specific KGs from Wikidata, which comprise over 19,000edges, 700 relations, and 21,000 entities. Our analysis across eight LLMsreveals that KGLens not only evaluates the factual accuracy of LLMs morerapidly but also delivers in-depth analyses on topics, temporal dynamics, andrelationships. Furthermore, human evaluation results indicate that KGLens canassess LLMs with a level of accuracy nearly equivalent to that of humanannotators, achieving 95.7% of the accuracy rate.</description><author>Shangshang Zheng, He Bai, Yizhe Zhang, Yi Su, Xiaochuan Niu, Navdeep Jaitly</author><pubDate>Fri, 16 Feb 2024 17:41:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11539v2</guid></item><item><title>Multivariate Time-Series Anomaly Detection with Contaminated Data</title><link>http://arxiv.org/abs/2308.12563v2</link><description>Mainstream unsupervised anomaly detection algorithms often excel in academicdatasets, yet their real-world performance is restricted due to the controlledexperimental conditions involving clean training data. Addressing the challengeof training with noise, a prevalent issue in practical anomaly detection, isfrequently overlooked. In a pioneering endeavor, this study delves into therealm of label-level noise within sensory time-series anomaly detection (TSAD).This paper presents a novel and practical end-to-end unsupervised TSAD when thetraining data are contaminated with anomalies. The introduced approach, calledTSAD-C, is devoid of access to abnormality labels during the training phase.TSAD-C encompasses three modules: a Decontaminator to rectify the abnormalities(aka noise) present in the training data, a Long-range Variable DependencyModeling module to capture both long-term intra- and inter-variabledependencies within the decontaminated data that can be considered as asurrogate of the pure normal data, and an Anomaly Scoring module to detectanomalies from all types. Our extensive experiments conducted on three reliabledatasets conclusively demonstrate that our approach surpasses existingmethodologies, thus establishing a new state-of-the-art performance in thefield.</description><author>Thi Kieu Khanh Ho, Narges Armanfard</author><pubDate>Fri, 16 Feb 2024 17:39:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12563v2</guid></item><item><title>Enhancement-Driven Pretraining for Robust Fingerprint Representation Learning</title><link>http://arxiv.org/abs/2402.10847v1</link><description>Fingerprint recognition stands as a pivotal component of biometrictechnology, with diverse applications from identity verification to advancedsearch tools. In this paper, we propose a unique method for deriving robustfingerprint representations by leveraging enhancement-based pre-training.Building on the achievements of U-Net-based fingerprint enhancement, our methodemploys a specialized encoder to derive representations from fingerprint imagesin a self-supervised manner. We further refine these representations, aiming toenhance the verification capabilities. Our experimental results, tested onpublicly available fingerprint datasets, reveal a marked improvement inverification performance against established self-supervised trainingtechniques. Our findings not only highlight the effectiveness of our method butalso pave the way for potential advancements. Crucially, our research indicatesthat it is feasible to extract meaningful fingerprint representations fromdegraded images without relying on enhanced samples.</description><author>Ekta Gavas, Kaustubh Olpadkar, Anoop Namboodiri</author><pubDate>Fri, 16 Feb 2024 17:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10847v1</guid></item><item><title>FedD2S: Personalized Data-Free Federated Knowledge Distillation</title><link>http://arxiv.org/abs/2402.10846v1</link><description>This paper addresses the challenge of mitigating data heterogeneity amongclients within a Federated Learning (FL) framework. The model-drift issue,arising from the noniid nature of client data, often results in suboptimalpersonalization of a global model compared to locally trained models for eachclient. To tackle this challenge, we propose a novel approach named FedD2S forPersonalized Federated Learning (pFL), leveraging knowledge distillation.FedD2S incorporates a deep-to-shallow layer-dropping mechanism in the data-freeknowledge distillation process to enhance local model personalization. Throughextensive simulations on diverse image datasets-FEMNIST, CIFAR10, CINIC0, andCIFAR100-we compare FedD2S with state-of-the-art FL baselines. The proposedapproach demonstrates superior performance, characterized by acceleratedconvergence and improved fairness among clients. The introduced layer-droppingtechnique effectively captures personalized knowledge, resulting in enhancedperformance compared to alternative FL models. Moreover, we investigate theimpact of key hyperparameters, such as the participation ratio andlayer-dropping rate, providing valuable insights into the optimal configurationfor FedD2S. The findings demonstrate the efficacy of adaptive layer-dropping inthe knowledge distillation process to achieve enhanced personalization andperformance across diverse datasets and tasks.</description><author>Kawa Atapour, S. Jamal Seyedmohammadi, Jamshid Abouei, Arash Mohammadi, Konstantinos N. Plataniotis</author><pubDate>Fri, 16 Feb 2024 17:36:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10846v1</guid></item><item><title>BloomVQA: Assessing Hierarchical Multi-modal Comprehension</title><link>http://arxiv.org/abs/2312.12716v2</link><description>We propose a novel VQA dataset, BloomVQA, to facilitate comprehensiveevaluation of large vision-language models on comprehension tasks. Unlikecurrent benchmarks that often focus on fact-based memorization and simplereasoning tasks without theoretical grounding, we collect multiple-choicesamples based on picture stories that reflect different levels ofcomprehension, as laid out in Bloom's Taxonomy, a classic framework forlearning assessment widely adopted in education research. Our data maps to anovel hierarchical graph representation which enables automatic dataaugmentation and novel measures characterizing model consistency. We performgraded evaluation and reliability analysis on recent multi-modal models. Incomparison to low-level tasks, we observe decreased performance on tasksrequiring advanced comprehension and cognitive skills with up to 38.0% drop inVQA accuracy. In comparison to earlier models, GPT-4V demonstrates improvedaccuracy over all comprehension levels while also shows a tendency of bypassingvisual inputs especially for higher-level tasks. Current models also showconsistency patterns misaligned with human comprehension in various scenarios,demonstrating the need of improvement based on theoretically-grounded criteria.</description><author>Yunye Gong, Robik Shrestha, Jared Claypoole, Michael Cogswell, Arijit Ray, Christopher Kanan, Ajay Divakaran</author><pubDate>Fri, 16 Feb 2024 17:33:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12716v2</guid></item><item><title>From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification</title><link>http://arxiv.org/abs/2310.11878v5</link><description>In legal NLP, Case Outcome Classification (COC) must not only be accurate butalso trustworthy and explainable. Existing work in explainable COC has beenlimited to annotations by a single expert. However, it is well-known thatlawyers may disagree in their assessment of case facts. We hence collect anovel dataset RAVE: Rationale Variation in ECHR1, which is obtained from twoexperts in the domain of international human rights law, for whom we observeweak agreement. We study their disagreements and build a two-leveltask-independent taxonomy, supplemented with COC-specific subcategories. To ourknowledge, this is the first work in the legal NLP that focuses on human labelvariation. We quantitatively assess different taxonomy categories and find thatdisagreements mainly stem from underspecification of the legal context, whichposes challenges given the typically limited granularity and noise in COCmetadata. We further assess the explainablility of SOTA COC models on RAVE andobserve limited agreement between models and experts. Overall, our case studyreveals hitherto underappreciated complexities in creating benchmark datasetsin legal NLP that revolve around identifying aspects of a case's factssupposedly relevant to its outcome.</description><author>Shanshan Xu, T. Y. S. S Santosh, Oana Ichim, Isabella Risini, Barbara Plank, Matthias Grabmair</author><pubDate>Fri, 16 Feb 2024 17:31:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11878v5</guid></item><item><title>Examining LLMs' Uncertainty Expression Towards Questions Outside Parametric Knowledge</title><link>http://arxiv.org/abs/2311.09731v2</link><description>Can large language models (LLMs) express their uncertainty in situationswhere they lack sufficient parametric knowledge to generate reasonableresponses? This work aims to systematically investigate LLMs' behaviors in suchsituations, emphasizing the trade-off between honesty and helpfulness. Totackle the challenge of precisely determining LLMs' knowledge gaps, wediagnostically create unanswerable questions containing non-existent conceptsor false premises, ensuring that they are outside the LLMs' vast training data.By compiling a benchmark, UnknownBench, which consists of both unanswerable andanswerable questions, we quantitatively evaluate the LLMs' performance inmaintaining honesty while being helpful. Using a model-agnostic unifiedconfidence elicitation approach, we observe that most LLMs fail to consistentlyrefuse or express uncertainty towards questions outside their parametricknowledge, although instruction fine-tuning and alignment techniques canprovide marginal enhancements. Moreover, LLMs' uncertainty expression does notalways stay consistent with the perceived confidence of their textual outputs.</description><author>Genglin Liu, Xingyao Wang, Lifan Yuan, Yangyi Chen, Hao Peng</author><pubDate>Fri, 16 Feb 2024 17:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09731v2</guid></item><item><title>Through the Lens of Split Vote: Exploring Disagreement, Difficulty and Calibration in Legal Case Outcome Classification</title><link>http://arxiv.org/abs/2402.07214v2</link><description>In legal decisions, split votes (SV) occur when judges cannot reach aunanimous decision, posing a difficulty for lawyers who must navigate diverselegal arguments and opinions. In high-stakes domains, understanding thealignment of perceived difficulty between humans and AI systems is crucial tobuild trust. However, existing NLP calibration methods focus on a classifier'sawareness of predictive performance, measured against the human majority class,overlooking inherent human label variation (HLV). This paper explores splitvotes as naturally observable human disagreement and value pluralism. Wecollect judges' vote distributions from the European Court of Human Rights(ECHR), and present SV-ECHR, a case outcome classification (COC) dataset withSV information. We build a taxonomy of disagreement with SV-specificsubcategories. We further assess the alignment of perceived difficulty betweenmodels and humans, as well as confidence- and human-calibration of COC models.We observe limited alignment with the judge vote distribution. To ourknowledge, this is the first systematic exploration of calibration to humanjudgements in legal NLP. Our study underscores the necessity for furtherresearch on measuring and enhancing model calibration considering HLV in legaldecision tasks.</description><author>Shanshan Xu, T. Y. S. S Santosh, Oana Ichim, Barbara Plank, Matthias Grabmair</author><pubDate>Fri, 16 Feb 2024 17:29:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07214v2</guid></item><item><title>GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding</title><link>http://arxiv.org/abs/2402.06764v2</link><description>Integrating large language models (LLMs) with knowledge graphs derived fromdomain-specific data represents an important advancement towards more powerfuland factual reasoning. As these models grow more capable, it is crucial toenable them to perform multi-step inferences over real-world knowledge graphswhile minimizing hallucination. While large language models excel atconversation and text generation, their ability to reason overdomain-specialized graphs of interconnected entities remains limited. Forexample, can we query a LLM to identify the optimal contact in a professionalnetwork for a specific goal, based on relationships and attributes in a privatedatabase? The answer is no--such capabilities lie beyond current methods.However, this question underscores a critical technical gap that must beaddressed. Many high-value applications in areas such as science, security, ande-commerce rely on proprietary knowledge graphs encoding unique structures,relationships, and logical constraints. We introduce a fine-tuning frameworkfor developing Graph-aligned LAnguage Models (GLaM) that transforms a knowledgegraph into an alternate text representation with labeled question-answer pairs.We demonstrate that grounding the models in specific graph-based knowledgeexpands the models' capacity for structure-based reasoning. Our methodologyleverages the large-language model's generative capabilities to create thedataset and proposes an efficient alternate to retrieval-augmented generationstyled methods.</description><author>Stefan Dernbach, Khushbu Agarwal, Alejandro Zuniga, Michael Henry, Sutanay Choudhury</author><pubDate>Fri, 16 Feb 2024 17:23:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06764v2</guid></item><item><title>Pedipulate: Enabling Manipulation Skills using a Quadruped Robot's Leg</title><link>http://arxiv.org/abs/2402.10837v1</link><description>Legged robots have the potential to become vital in maintenance, homesupport, and exploration scenarios. In order to interact with and manipulatetheir environments, most legged robots are equipped with a dedicated robot arm,which means additional mass and mechanical complexity compared to standardlegged robots. In this work, we explore pedipulation - using the legs of alegged robot for manipulation. By training a reinforcement learning policy thattracks position targets for one foot, we enable a dedicated pedipulationcontroller that is robust to disturbances, has a large workspace throughwhole-body behaviors, and can reach far-away targets with gait emergence,enabling loco-pedipulation. By deploying our controller on a quadrupedal robotusing teleoperation, we demonstrate various real-world tasks such as dooropening, sample collection, and pushing obstacles. We demonstrate load carryingof more than 2.0 kg at the foot. Additionally, the controller is robust tointeraction forces at the foot, disturbances at the base, and slippery contactsurfaces. Videos of the experiments are available athttps://sites.google.com/leggedrobotics.com/pedipulate.</description><author>Philip Arm, Mayank Mittal, Hendrik Kolvenbach, Marco Hutter</author><pubDate>Fri, 16 Feb 2024 17:20:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10837v1</guid></item><item><title>Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities</title><link>http://arxiv.org/abs/2402.10835v1</link><description>Large language models (LLMs) have been applied in many fields with rapiddevelopment in recent years. As a classic machine learning task, time seriesforecasting has recently received a boost from LLMs. However, there is aresearch gap in the LLMs' preferences in this field. In this paper, bycomparing LLMs with traditional models, many properties of LLMs in time seriesprediction are found. For example, our study shows that LLMs excel inpredicting time series with clear patterns and trends but face challenges withdatasets lacking periodicity. We explain our findings through designing promptsto require LLMs to tell the period of the datasets. In addition, the inputstrategy is investigated, and it is found that incorporating external knowledgeand adopting natural language paraphrases positively affects the predictiveperformance of LLMs for time series. Overall, this study contributes to insightinto the advantages and limitations of LLMs in time series forecasting underdifferent conditions.</description><author>Mingyu Jin, Hua Tang, Chong Zhang, Qinkai Yu, Chengzhi Liu, Suiyuan Zhu, Yongfeng Zhang, Mengnan Du</author><pubDate>Fri, 16 Feb 2024 17:15:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10835v1</guid></item><item><title>Decorrelative Network Architecture for Robust Electrocardiogram Classification</title><link>http://arxiv.org/abs/2207.09031v4</link><description>Artificial intelligence has made great progress in medical data analysis, butthe lack of robustness and trustworthiness has kept these methods from beingwidely deployed. As it is not possible to train networks that are accurate inall scenarios, models must recognize situations where they cannot operateconfidently. Bayesian deep learning methods sample the model parameter space toestimate uncertainty, but these parameters are often subject to the samevulnerabilities, which can be exploited by adversarial attacks. We propose anovel ensemble approach based on feature decorrelation and Fourier partitioningfor teaching networks diverse complementary features, reducing the chance ofperturbation-based fooling. We test our approach on single and multi-channelelectrocardiogram classification, and adapt adversarial training and DVERGEinto the Bayesian ensemble framework for comparison. Our results indicate thatthe combination of decorrelation and Fourier partitioning generally maintainsperformance on unperturbed data while demonstrating superior robustness anduncertainty estimation on projected gradient descent and smooth adversarialattacks of various magnitudes. Furthermore, our approach does not requireexpensive optimization with adversarial samples, adding much less compute tothe training process than adversarial training or DVERGE. These methods can beapplied to other tasks for more robust and trustworthy models.</description><author>Christopher Wiedeman, Ge Wang</author><pubDate>Fri, 16 Feb 2024 17:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.09031v4</guid></item><item><title>Compositional Generative Modeling: A Single Model is Not All You Need</title><link>http://arxiv.org/abs/2402.01103v2</link><description>Large monolithic generative models trained on massive amounts of data havebecome an increasingly dominant approach in AI research. In this paper, weargue that we should instead construct large generative systems by composingsmaller generative models together. We show how such a compositional generativeapproach enables us to learn distributions in a more data-efficient manner,enabling generalization to parts of the data distribution unseen at trainingtime. We further show how this enables us to program and construct newgenerative models for tasks completely unseen at training. Finally, we showthat in many cases, we can discover separate compositional components fromdata.</description><author>Yilun Du, Leslie Kaelbling</author><pubDate>Fri, 16 Feb 2024 17:11:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01103v2</guid></item><item><title>Learning Representations on the Unit Sphere: Investigating Angular Gaussian and von Mises-Fisher Distributions for Online Continual Learning</title><link>http://arxiv.org/abs/2306.03364v4</link><description>We use the maximum a posteriori estimation principle for learningrepresentations distributed on the unit sphere. We propose to use the angularGaussian distribution, which corresponds to a Gaussian projected on theunit-sphere and derive the associated loss function. We also consider the vonMises-Fisher distribution, which is the conditional of a Gaussian in theunit-sphere. The learned representations are pushed toward fixed directions,which are the prior means of the Gaussians; allowing for a learning strategythat is resilient to data drift. This makes it suitable for online continuallearning, which is the problem of training neural networks on a continuous datastream, where multiple classification tasks are presented sequentially so thatdata from past tasks are no longer accessible, and data from the current taskcan be seen only once. To address this challenging scenario, we propose amemory-based representation learning technique equipped with our new lossfunctions. Our approach does not require negative data or knowledge of taskboundaries and performs well with smaller batch sizes while beingcomputationally efficient. We demonstrate with extensive experiments that theproposed method outperforms the current state-of-the-art methods on bothstandard evaluation scenarios and realistic scenarios with blurry taskboundaries. For reproducibility, we use the same training pipeline for everycompared method and share the code at https://github.com/Nicolas1203/ocl-fd.</description><author>Nicolas Michel, Giovanni Chierchia, Romain Negrel, Jean-François Bercher</author><pubDate>Fri, 16 Feb 2024 17:08:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03364v4</guid></item><item><title>Simple and Asymmetric Graph Contrastive Learning without Augmentations</title><link>http://arxiv.org/abs/2310.18884v2</link><description>Graph Contrastive Learning (GCL) has shown superior performance inrepresentation learning in graph-structured data. Despite their success, mostexisting GCL methods rely on prefabricated graph augmentation and homophilyassumptions. Thus, they fail to generalize well to heterophilic graphs whereconnected nodes may have different class labels and dissimilar features. Inthis paper, we study the problem of conducting contrastive learning onhomophilic and heterophilic graphs. We find that we can achieve promisingperformance simply by considering an asymmetric view of the neighboring nodes.The resulting simple algorithm, Asymmetric Contrastive Learning for Graphs(GraphACL), is easy to implement and does not rely on graph augmentations andhomophily assumptions. We provide theoretical and empirical evidence thatGraphACL can capture one-hop local neighborhood information and two-hopmonophily similarity, which are both important for modeling heterophilicgraphs. Experimental results show that the simple GraphACL significantlyoutperforms state-of-the-art graph contrastive learning and self-supervisedlearning methods on homophilic and heterophilic graphs. The code of GraphACL isavailable at https://github.com/tengxiao1/GraphACL.</description><author>Teng Xiao, Huaisheng Zhu, Zhengyu Chen, Suhang Wang</author><pubDate>Fri, 16 Feb 2024 17:08:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18884v2</guid></item><item><title>GAN-driven Electromagnetic Imaging of 2-D Dielectric Scatterers</title><link>http://arxiv.org/abs/2402.10831v1</link><description>Inverse scattering problems are inherently challenging, given the fact theyare ill-posed and nonlinear. This paper presents a powerful deep learning-basedapproach that relies on generative adversarial networks to accurately andefficiently reconstruct randomly-shaped two-dimensional dielectric objects fromamplitudes of multi-frequency scattered electric fields. An adversarialautoencoder (AAE) is trained to learn to generate the scatterer's geometry froma lower-dimensional latent representation constrained to adhere to the Gaussiandistribution. A cohesive inverse neural network (INN) framework is set upcomprising a sequence of appropriately designed dense layers, thealready-trained generator as well as a separately trained forward neuralnetwork. The images reconstructed at the output of the inverse network arevalidated through comparison with outputs from the forward neural network,addressing the non-uniqueness challenge inherent to electromagnetic (EM)imaging problems. The trained INN demonstrates an enhanced robustness,evidenced by a mean binary cross-entropy (BCE) loss of $0.13$ and a structuresimilarity index (SSI) of $0.90$. The study not only demonstrates a significantreduction in computational load, but also marks a substantial improvement overtraditional objective-function-based methods. It contributes both to the fieldsof machine learning and EM imaging by offering a real-time quantitative imagingapproach. The results obtained with the simulated data, for both training andtesting, yield promising results and may open new avenues for radio-frequencyinverse imaging.</description><author>Ehtasham Naseer, Ali Imran Sandhu, Muhammad Adnan Siddique, Waqas W. Ahmed, Mohamed Farhat, Ying Wu</author><pubDate>Fri, 16 Feb 2024 17:03:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10831v1</guid></item><item><title>Developing a Framework for Auditing Large Language Models Using Human-in-the-Loop</title><link>http://arxiv.org/abs/2402.09346v2</link><description>As LLMs become more pervasive across various users and scenarios, identifyingpotential issues when using these models becomes essential. Examples includebias, inconsistencies, and hallucination. Although auditing the LLM for theseproblems is desirable, it is far from being easy or solved. An effective methodis to probe the LLM using different versions of the same question. This couldexpose inconsistencies in its knowledge or operation, indicating potential forbias or hallucination. However, to operationalize this auditing method atscale, we need an approach to create those probes reliably and automatically.In this paper we propose an automatic and scalable solution, where one uses adifferent LLM along with human-in-the-loop. This approach offers verifiabilityand transparency, while avoiding circular reliance on the same LLMs, andincreasing scientific rigor and generalizability. Specifically, we present anovel methodology with two phases of verification using humans: standardizedevaluation criteria to verify responses, and a structured prompt template togenerate desired probes. Experiments on a set of questions from TruthfulQAdataset show that we can generate a reliable set of probes from one LLM thatcan be used to audit inconsistencies in a different LLM. The criteria forgenerating and applying auditing probes is generalizable to various LLMsregardless of the underlying structure or training mechanism.</description><author>Maryam Amirizaniani, Jihan Yao, Adrian Lavergne, Elizabeth Snell Okada, Aman Chadha, Tanya Roosta, Chirag Shah</author><pubDate>Fri, 16 Feb 2024 16:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09346v2</guid></item><item><title>Anchor-based Large Language Models</title><link>http://arxiv.org/abs/2402.07616v2</link><description>Large language models (LLMs) predominantly employ decoder-only transformerarchitectures, necessitating the retention of keys/values information forhistorical tokens to provide contextual information and avoid redundantcomputation. However, the substantial size and parameter volume of these LLMsrequire massive GPU memory. This memory demand increases with the length of theinput text, leading to an urgent need for more efficient methods of informationstorage and processing. This study introduces Anchor-based LLMs (AnLLMs), whichutilize an innovative anchor-based self-attention network (AnSAN) and also ananchor-based inference strategy. This approach enables LLMs to compresssequence information into an anchor token, reducing the keys/values cache andenhancing inference efficiency. Experiments on question-answering benchmarksreveal that AnLLMs maintain similar accuracy levels while achieving up to 99%keys/values cache reduction and up to 3.5 times faster inference. Despite aminor compromise in accuracy, the substantial enhancements of AnLLMs employingthe AnSAN technique in resource utilization and computational efficiencyunderscore their potential for practical LLM applications.</description><author>Jianhui Pang, Fanghua Ye, Derek F. Wong, Longyue Wang</author><pubDate>Fri, 16 Feb 2024 16:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07616v2</guid></item><item><title>RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model</title><link>http://arxiv.org/abs/2402.10828v1</link><description>Robots powered by 'blackbox' models need to provide human-understandableexplanations which we can trust. Hence, explainability plays a critical role intrustworthy autonomous decision-making to foster transparency and acceptanceamong end users, especially in complex autonomous driving. Recent advancementsin Multi-Modal Large Language models (MLLMs) have shown promising potential inenhancing the explainability as a driving agent by producing controlpredictions along with natural language explanations. However, severe datascarcity due to expensive annotation costs and significant domain gaps betweendifferent datasets makes the development of a robust and generalisable systeman extremely challenging task. Moreover, the prohibitively expensive trainingrequirements of MLLM and the unsolved problem of catastrophic forgettingfurther limit their generalisability post-deployment. To address thesechallenges, we present RAG-Driver, a novel retrieval-augmented multi-modallarge language model that leverages in-context learning for high-performance,explainable, and generalisable autonomous driving. By grounding in retrievedexpert demonstration, we empirically validate that RAG-Driver achievesstate-of-the-art performance in producing driving action explanations,justifications, and control signal prediction. More importantly, it exhibitsexceptional zero-shot generalisation capabilities to unseen environmentswithout further training endeavours.</description><author>Jianhao Yuan, Shuyang Sun, Daniel Omeiza, Bo Zhao, Paul Newman, Lars Kunze, Matthew Gadd</author><pubDate>Fri, 16 Feb 2024 16:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10828v1</guid></item><item><title>History-Aware Conversational Dense Retrieval</title><link>http://arxiv.org/abs/2401.16659v2</link><description>Conversational search facilitates complex information retrieval by enablingmulti-turn interactions between users and the system. Supporting suchinteractions requires a comprehensive understanding of the conversationalinputs to formulate a good search query based on historical information. Inparticular, the search query should include the relevant information from theprevious conversation turns. However, current approaches for conversationaldense retrieval primarily rely on fine-tuning a pre-trained ad-hoc retrieverusing the whole conversational search session, which can be lengthy and noisy.Moreover, existing approaches are limited by the amount of manual supervisionsignals in the existing datasets. To address the aforementioned issues, wepropose a History-Aware Conversational Dense Retrieval (HAConvDR) system, whichincorporates two ideas: context-denoised query reformulation and automaticmining of supervision signals based on the actual impact of historical turns.Experiments on two public conversational search datasets demonstrate theimproved history modeling capability of HAConvDR, in particular for longconversations with topic shifts.</description><author>Fengran Mo, Chen Qu, Kelong Mao, Tianyu Zhu, Zhan Su, Kaiyu Huang, Jian-Yun Nie</author><pubDate>Fri, 16 Feb 2024 16:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16659v2</guid></item><item><title>NorMatch: Matching Normalizing Flows with Discriminative Classifiers for Semi-Supervised Learning</title><link>http://arxiv.org/abs/2211.09593v2</link><description>Semi-Supervised Learning (SSL) aims to learn a model using a tiny labeled setand massive amounts of unlabeled data. To better exploit the unlabeled data thelatest SSL methods use pseudo-labels predicted from a single discriminativeclassifier. However, the generated pseudo-labels are inevitably linked toinherent confirmation bias and noise which greatly affects the modelperformance. In this work we introduce a new framework for SSL named NorMatch.Firstly, we introduce a new uncertainty estimation scheme based on normalizingflows, as an auxiliary classifier, to enforce highly certain pseudo-labelsyielding a boost of the discriminative classifiers. Secondly, we introduce athreshold-free sample weighting strategy to exploit better both high and lowconfidence pseudo-labels. Furthermore, we utilize normalizing flows to model,in an unsupervised fashion, the distribution of unlabeled data. This modellingassumption can further improve the performance of generative classifiers viaunlabeled data, and thus, implicitly contributing to training a betterdiscriminative classifier. We demonstrate, through numerical and visualresults, that NorMatch achieves state-of-the-art performance on severaldatasets.</description><author>Zhongying Deng, Rihuan Ke, Carola-Bibiane Schonlieb, Angelica I Aviles-Rivero</author><pubDate>Fri, 16 Feb 2024 16:50:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.09593v2</guid></item><item><title>Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation</title><link>http://arxiv.org/abs/2310.00796v2</link><description>Strong inductive biases enable learning from little data and helpgeneralization outside of the training distribution. Popular neuralarchitectures such as Transformers lack strong structural inductive biases forseq2seq NLP tasks on their own. Consequently, they struggle with systematicgeneralization beyond the training distribution, e.g. with extrapolating tolonger inputs, even when pre-trained on large amounts of text. We show how astructural inductive bias can be efficiently injected into a seq2seq model bypre-training it to simulate structural transformations on synthetic data.Specifically, we inject an inductive bias towards Finite State Transducers(FSTs) into a Transformer by pre-training it to simulate FSTs given theirdescriptions. Our experiments show that our method imparts the desiredinductive bias, resulting in improved systematic generalization and betterfew-shot learning for FST-like tasks. Our analysis shows that fine-tuned modelsaccurately capture the state dynamics of the unseen underlying FSTs, suggestingthat the simulation process is internalized by the fine-tuned model.</description><author>Matthias Lindemann, Alexander Koller, Ivan Titov</author><pubDate>Fri, 16 Feb 2024 16:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00796v2</guid></item><item><title>Training Class-Imbalanced Diffusion Model Via Overlap Optimization</title><link>http://arxiv.org/abs/2402.10821v1</link><description>Diffusion models have made significant advances recently in high-qualityimage synthesis and related tasks. However, diffusion models trained onreal-world datasets, which often follow long-tailed distributions, yieldinferior fidelity for tail classes. Deep generative models, including diffusionmodels, are biased towards classes with abundant training images. To addressthe observed appearance overlap between synthesized images of rare classes andtail classes, we propose a method based on contrastive learning to minimize theoverlap between distributions of synthetic images for different classes. Weshow variants of our probabilistic contrastive learning method can be appliedto any class conditional diffusion model. We show significant improvement inimage synthesis using our loss for multiple datasets with long-taileddistribution. Extensive experimental results demonstrate that the proposedmethod can effectively handle imbalanced data for diffusion-based generationand classification models. Our code and datasets will be publicly available athttps://github.com/yanliang3612/DiffROP.</description><author>Divin Yan, Lu Qi, Vincent Tao Hu, Ming-Hsuan Yang, Meng Tang</author><pubDate>Fri, 16 Feb 2024 16:47:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10821v1</guid></item><item><title>Goal-Conditioned Offline Reinforcement Learning via Metric Learning</title><link>http://arxiv.org/abs/2402.10820v1</link><description>In this work, we address the problem of learning optimal behavior fromsub-optimal datasets in the context of goal-conditioned offline reinforcementlearning. To do so, we propose a novel way of approximating the optimal valuefunction for goal-conditioned offline RL problems under sparse rewards,symmetric and deterministic actions. We study a property for representations torecover optimality and propose a new optimization objective that leads to suchproperty. We use the learned value function to guide the learning of a policyin an actor-critic fashion, a method we name MetricRL. Experimentally, we showhow our method consistently outperforms other offline RL baselines in learningfrom sub-optimal offline datasets. Moreover, we show the effectiveness of ourmethod in dealing with high-dimensional observations and in multi-goal tasks.</description><author>Alfredo Reichlin, Miguel Vasco, Hang Yin, Danica Kragic</author><pubDate>Fri, 16 Feb 2024 16:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10820v1</guid></item><item><title>The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents</title><link>http://arxiv.org/abs/2311.09665v2</link><description>Human groups are able to converge on more accurate beliefs throughdeliberation, even in the presence of polarization and partisan bias -- aphenomenon known as the "wisdom of partisan crowds." Generated agents poweredby Large Language Models (LLMs) are increasingly used to simulate humancollective behavior, yet few benchmarks exist for evaluating their dynamicsagainst the behavior of human groups. In this paper, we examine the extent towhich the wisdom of partisan crowds emerges in groups of LLM-based agents thatare prompted to role-play as partisan personas (e.g., Democrat or Republican).We find that they not only display human-like partisan biases, but alsoconverge to more accurate beliefs through deliberation as humans do. We thenidentify several factors that interfere with convergence, including the use ofchain-of-thought prompt and lack of details in personas. Conversely,fine-tuning on human data appears to enhance convergence. These findings showthe potential and limitations of LLM-based agents as a model of humancollective intelligence.</description><author>Yun-Shiuan Chuang, Siddharth Suresh, Nikunj Harlalka, Agam Goyal, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers</author><pubDate>Fri, 16 Feb 2024 16:43:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09665v2</guid></item><item><title>Identifying and Analyzing Task-Encoding Tokens in Large Language Models</title><link>http://arxiv.org/abs/2401.11323v2</link><description>In-context learning (ICL) has become an effective solution for few-shotlearning in natural language processing. However, our understanding of ICL'sworking mechanisms is limited, specifically regarding how models learn toperform tasks from ICL demonstrations. For example, unexpectedly large changesin performance can arise from small changes in the prompt, leaving promptdesign a largely empirical endeavour. In this paper, we investigate thisproblem by identifying and analyzing task-encoding tokens on whoserepresentations the task performance depends. Using experiments that ablate therepresentations of different token types, we find that template and stopwordtokens are the most prone to be task-encoding. In addition, we demonstrateexperimentally that lexical meaning, repetition, and text formatting are themain distinguishing characteristics of these tokens. Our work sheds light onhow large language models (LLMs) learn to perform a task from demonstrations,deepens our understanding of the varied roles different types of tokens play inLLMs, and provides insights for avoiding instability from improperly utilizingtask-encoding tokens.</description><author>Yu Bai, Heyan Huang, Cesare Spinoso-Di Piano, Marc-Antoine Rondeau, Sanxing Chen, Yang Gao, Jackie Chi Kit Cheung</author><pubDate>Fri, 16 Feb 2024 16:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11323v2</guid></item><item><title>Trading off Consistency and Dimensionality of Convex Surrogates for the Mode</title><link>http://arxiv.org/abs/2402.10818v1</link><description>In multiclass classification over $n$ outcomes, the outcomes must be embeddedinto the reals with dimension at least $n-1$ in order to design a consistentsurrogate loss that leads to the "correct" classification, regardless of thedata distribution. For large $n$, such as in information retrieval andstructured prediction tasks, optimizing a surrogate in $n-1$ dimensions isoften intractable. We investigate ways to trade off surrogate loss dimension,the number of problem instances, and restricting the region of consistency inthe simplex for multiclass classification. Following past work, we examine anintuitive embedding procedure that maps outcomes into the vertices of convexpolytopes in a low-dimensional surrogate space. We show that full-dimensionalsubsets of the simplex exist around each point mass distribution for whichconsistency holds, but also, with less than $n-1$ dimensions, there existdistributions for which a phenomenon called hallucination occurs, which is whenthe optimal report under the surrogate loss is an outcome with zeroprobability. Looking towards application, we derive a result to check ifconsistency holds under a given polytope embedding and low-noise assumption,providing insight into when to use a particular embedding. We provide examplesof embedding $n = 2^{d}$ outcomes into the $d$-dimensional unit cube and $n =d!$ outcomes into the $d$-dimensional permutahedron under low-noiseassumptions. Finally, we demonstrate that with multiple problem instances, wecan learn the mode with $\frac{n}{2}$ dimensions over the whole simplex.</description><author>Enrique Nueve, Bo Waggoner, Dhamma Kimpara, Jessie Finocchiaro</author><pubDate>Fri, 16 Feb 2024 16:42:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10818v1</guid></item><item><title>TernaryVote: Differentially Private, Communication Efficient, and Byzantine Resilient Distributed Optimization on Heterogeneous Data</title><link>http://arxiv.org/abs/2402.10816v1</link><description>Distributed training of deep neural networks faces three critical challenges:privacy preservation, communication efficiency, and robustness to fault andadversarial behaviors. Although significant research efforts have been devotedto addressing these challenges independently, their synthesis remains lessexplored. In this paper, we propose TernaryVote, which combines a ternarycompressor and the majority vote mechanism to realize differential privacy,gradient compression, and Byzantine resilience simultaneously. We theoreticallyquantify the privacy guarantee through the lens of the emerging f-differentialprivacy (DP) and the Byzantine resilience of the proposed algorithm.Particularly, in terms of privacy guarantees, compared to the existingsign-based approach StoSign, the proposed method improves the dimensiondependence on the gradient size and enjoys privacy amplification by mini-batchsampling while ensuring a comparable convergence rate. We also prove thatTernaryVote is robust when less than 50% of workers are blind attackers, whichmatches that of SIGNSGD with majority vote. Extensive experimental resultsvalidate the effectiveness of the proposed algorithm.</description><author>Richeng Jin, Yujie Gu, Kai Yue, Xiaofan He, Zhaoyang Zhang, Huaiyu Dai</author><pubDate>Fri, 16 Feb 2024 16:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10816v1</guid></item><item><title>Generative quantum machine learning via denoising diffusion probabilistic models</title><link>http://arxiv.org/abs/2310.05866v4</link><description>Deep generative models are key-enabling technology to computer vision, textgeneration, and large language models. Denoising diffusion probabilistic models(DDPMs) have recently gained much attention due to their ability to generatediverse and high-quality samples in many computer vision tasks, as well as toincorporate flexible model architectures and a relatively simple trainingscheme. Quantum generative models, empowered by entanglement and superposition,have brought new insight to learning classical and quantum data. Inspired bythe classical counterpart, we propose the quantum denoising diffusionprobabilistic model (QuDDPM) to enable efficiently trainable generativelearning of quantum data. QuDDPM adopts sufficient layers of circuits toguarantee expressivity, while it introduces multiple intermediate trainingtasks as interpolation between the target distribution and noise to avoidbarren plateau and guarantee efficient training. We provide bounds on thelearning error and demonstrate QuDDPM's capability in learning correlatedquantum noise model, quantum many-body phases, and topological structure ofquantum data. The results provide a paradigm for versatile and efficientquantum generative learning.</description><author>Bingzhi Zhang, Peng Xu, Xiaohui Chen, Quntao Zhuang</author><pubDate>Fri, 16 Feb 2024 16:39:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05866v4</guid></item><item><title>Associative Memories in the Feature Space</title><link>http://arxiv.org/abs/2402.10814v1</link><description>An autoassociative memory model is a function that, given a set of datapoints, takes as input an arbitrary vector and outputs the most similar datapoint from the memorized set. However, popular memory models fail to retrieveimages even when the corruption is mild and easy to detect for a humanevaluator. This is because similarities are evaluated in the raw pixel space,which does not contain any semantic information about the images. This problemcan be easily solved by computing \emph{similarities} in an embedding spaceinstead of the pixel space. We show that an effective way of computing suchembeddings is via a network pretrained with a contrastive loss. As thedimension of embedding spaces is often significantly smaller than the pixelspace, we also have a faster computation of similarity scores. We test thismethod on complex datasets such as CIFAR10 and STL10. An additional drawback ofcurrent models is the need of storing the whole dataset in the pixel space,which is often extremely large. We relax this condition and propose a class ofmemory models that only stores low-dimensional semantic embeddings, and usesthem to retrieve similar, but not identical, memories. We demonstrate a proofof concept of this method on a simple task on the MNIST dataset.</description><author>Tommaso Salvatori, Beren Millidge, Yuhang Song, Rafal Bogacz, Thomas Lukasiewicz</author><pubDate>Fri, 16 Feb 2024 16:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10814v1</guid></item><item><title>MultiMedEval: A Benchmark and a Toolkit for Evaluating Medical Vision-Language Models</title><link>http://arxiv.org/abs/2402.09262v2</link><description>We introduce MultiMedEval, an open-source toolkit for fair and reproducibleevaluation of large, medical vision-language models (VLM). MultiMedEvalcomprehensively assesses the models' performance on a broad array of sixmulti-modal tasks, conducted over 23 datasets, and spanning over 11 medicaldomains. The chosen tasks and performance metrics are based on their widespreadadoption in the community and their diversity, ensuring a thorough evaluationof the model's overall generalizability. We open-source a Python toolkit(github.com/corentin-ryr/MultiMedEval) with a simple interface and setupprocess, enabling the evaluation of any VLM in just a few lines of code. Ourgoal is to simplify the intricate landscape of VLM evaluation, thus promotingfair and uniform benchmarking of future models.</description><author>Corentin Royer, Bjoern Menze, Anjany Sekuboyina</author><pubDate>Fri, 16 Feb 2024 16:36:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09262v2</guid></item><item><title>Exploring Hybrid Question Answering via Program-based Prompting</title><link>http://arxiv.org/abs/2402.10812v1</link><description>Question answering over heterogeneous data requires reasoning over diversesources of data, which is challenging due to the large scale of information andorganic coupling of heterogeneous data. Various approaches have been proposedto address these challenges. One approach involves training specializedretrievers to select relevant information, thereby reducing the input length.Another approach is to transform diverse modalities of data into a singlemodality, simplifying the task difficulty and enabling more straightforwardprocessing. In this paper, we propose HProPro, a novel program-based promptingframework for the hybrid question answering task. HProPro follows the codegeneration and execution paradigm. In addition, HProPro integrates variousfunctions to tackle the hybrid reasoning scenario. Specifically, HProProcontains function declaration and function implementation to perform hybridinformation-seeking over data from various sources and modalities, whichenables reasoning over such data without training specialized retrievers orperforming modal transformations. Experimental results on two typical hybridquestion answering benchmarks HybridQA and MultiModalQA demonstrate theeffectiveness of HProPro: it surpasses all baseline systems and achieves thebest performances in the few-shot settings on both datasets.</description><author>Qi Shi, Han Cui, Haofeng Wang, Qingfu Zhu, Wanxiang Che, Ting Liu</author><pubDate>Fri, 16 Feb 2024 16:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10812v1</guid></item><item><title>Quantifying the Persona Effect in LLM Simulations</title><link>http://arxiv.org/abs/2402.10811v1</link><description>Large language models (LLMs) have shown remarkable promise in simulatinghuman language use and behavior. In this study, we delve into the intersectionof persona variables and the capability of LLMs to simulate differentperspectives. We find that persona variables can explain &lt;10\% variance inannotations in existing subjective NLP datasets. Nonetheless, incorporatingthem via prompting in LLMs provides modest improvement. Persona prompting ismost effective on data samples where disagreements among annotators arefrequent yet confined to a limited range. A linear correlation exists: the morepersona variables influence human annotations, the better LLMs predictions areusing persona prompting. However, when the utility of persona variables is low(i.e., explaining &lt;10\% of human annotations), persona prompting has littleeffect. Most subjective NLP datasets fall into this category, casting doubt onsimulating diverse perspectives in the current NLP landscape.</description><author>Tiancheng Hu, Nigel Collier</author><pubDate>Fri, 16 Feb 2024 16:35:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10811v1</guid></item><item><title>Optimal Transport with Tempered Exponential Measures</title><link>http://arxiv.org/abs/2309.04015v3</link><description>In the field of optimal transport, two prominent subfields face each other:(i) unregularized optimal transport, "\`a-la-Kantorovich", which leads toextremely sparse plans but with algorithms that scale poorly, and (ii)entropic-regularized optimal transport, "\`a-la-Sinkhorn-Cuturi", which getsnear-linear approximation algorithms but leads to maximally un-sparse plans. Inthis paper, we show that an extension of the latter to tempered exponentialmeasures, a generalization of exponential families with indirect measurenormalization, gets to a very convenient middle ground, with both very fastapproximation algorithms and sparsity, which is under control up to sparsitypatterns. In addition, our formulation fits naturally in the unbalanced optimaltransport problem setting.</description><author>Ehsan Amid, Frank Nielsen, Richard Nock, Manfred K. Warmuth</author><pubDate>Fri, 16 Feb 2024 16:35:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04015v3</guid></item><item><title>Double Duality: Variational Primal-Dual Policy Optimization for Constrained Reinforcement Learning</title><link>http://arxiv.org/abs/2402.10810v1</link><description>We study the Constrained Convex Markov Decision Process (MDP), where the goalis to minimize a convex functional of the visitation measure, subject to aconvex constraint. Designing algorithms for a constrained convex MDP facesseveral challenges, including (1) handling the large state space, (2) managingthe exploration/exploitation tradeoff, and (3) solving the constrainedoptimization where the objective and the constraint are both nonlinearfunctions of the visitation measure. In this work, we present a model-basedalgorithm, Variational Primal-Dual Policy Optimization (VPDPO), in whichLagrangian and Fenchel duality are implemented to reformulate the originalconstrained problem into an unconstrained primal-dual optimization. Moreover,the primal variables are updated by model-based value iteration following theprinciple of Optimism in the Face of Uncertainty (OFU), while the dualvariables are updated by gradient ascent. Moreover, by embedding the visitationmeasure into a finite-dimensional space, we can handle large state spaces byincorporating function approximation. Two notable examples are (1) KernelizedNonlinear Regulators and (2) Low-rank MDPs. We prove that with an optimisticplanning oracle, our algorithm achieves sublinear regret and constraintviolation in both cases and can attain the globally optimal policy of theoriginal constrained problem.</description><author>Zihao Li, Boyi Liu, Zhuoran Yang, Zhaoran Wang, Mengdi Wang</author><pubDate>Fri, 16 Feb 2024 16:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10810v1</guid></item><item><title>Generative Cross-Modal Retrieval: Memorizing Images in Multimodal Language Models for Retrieval and Beyond</title><link>http://arxiv.org/abs/2402.10805v1</link><description>The recent advancements in generative language models have demonstrated theirability to memorize knowledge from documents and recall knowledge to respond touser queries effectively. Building upon this capability, we propose to enablemultimodal large language models (MLLMs) to memorize and recall images withintheir parameters. Given a user query for visual content, the MLLM isanticipated to "recall" the relevant image from its parameters as the response.Achieving this target presents notable challenges, including inbuilt visualmemory and visual recall schemes within MLLMs. To address these challenges, weintroduce a generative cross-modal retrieval framework, which assigns uniqueidentifier strings to represent images and involves two training steps:learning to memorize and learning to retrieve. The first step focuses ontraining the MLLM to memorize the association between images and theirrespective identifiers. The latter step teaches the MLLM to generate thecorresponding identifier of the target image, given the textual query input. Bymemorizing images in MLLMs, we introduce a new paradigm to cross-modalretrieval, distinct from previous discriminative approaches. The experimentsdemonstrate that the generative paradigm performs effectively and efficientlyeven with large-scale image candidate sets.</description><author>Yongqi Li, Wenjie Wang, Leigang Qu, Liqiang Nie, Wenjie Li, Tat-Seng Chua</author><pubDate>Fri, 16 Feb 2024 16:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10805v1</guid></item><item><title>Modelling crypto markets by multi-agent reinforcement learning</title><link>http://arxiv.org/abs/2402.10803v1</link><description>Building on a previous foundation work (Lussange et al. 2020), this studyintroduces a multi-agent reinforcement learning (MARL) model simulating cryptomarkets, which is calibrated to the Binance's daily closing prices of $153$cryptocurrencies that were continuously traded between 2018 and 2022. Unlikeprevious agent-based models (ABM) or multi-agent systems (MAS) which relied onzero-intelligence agents or single autonomous agent methodologies, our approachrelies on endowing agents with reinforcement learning (RL) techniques in orderto model crypto markets. This integration is designed to emulate, with abottom-up approach to complexity inference, both individual and collectiveagents, ensuring robustness in the recent volatile conditions of such marketsand during the COVID-19 era. A key feature of our model also lies in the factthat its autonomous agents perform asset price valuation based on two sourcesof information: the market prices themselves, and the approximation of thecrypto assets fundamental values beyond what those market prices are. Our MAScalibration against real market data allows for an accurate emulation of cryptomarkets microstructure and probing key market behaviors, in both the bearishand bullish regimes of that particular time period.</description><author>Johann Lussange, Stefano Vrizzi, Stefano Palminteri, Boris Gutkin</author><pubDate>Fri, 16 Feb 2024 16:28:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10803v1</guid></item><item><title>An Extensible Framework for Open Heterogeneous Collaborative Perception</title><link>http://arxiv.org/abs/2401.13964v2</link><description>Collaborative perception aims to mitigate the limitations of single-agentperception, such as occlusions, by facilitating data exchange among multipleagents. However, most current works consider a homogeneous scenario where allagents use identity sensors and perception models. In reality, heterogeneousagent types may continually emerge and inevitably face a domain gap whencollaborating with existing agents. In this paper, we introduce a new openheterogeneous problem: how to accommodate continually emerging newheterogeneous agent types into collaborative perception, while ensuring highperception performance and low integration cost? To address this problem, wepropose HEterogeneous ALliance (HEAL), a novel extensible collaborativeperception framework. HEAL first establishes a unified feature space withinitial agents via a novel multi-scale foreground-aware Pyramid Fusion network.When heterogeneous new agents emerge with previously unseen modalities ormodels, we align them to the established unified space with an innovativebackward alignment. This step only involves individual training on the newagent type, thus presenting extremely low training costs and highextensibility. To enrich agents' data heterogeneity, we bring OPV2V-H, a newlarge-scale dataset with more diverse sensor types. Extensive experiments onOPV2V-H and DAIR-V2X datasets show that HEAL surpasses SOTA methods inperformance while reducing the training parameters by 91.5% when integrating 3new agent types. We further implement a comprehensive codebase at:https://github.com/yifanlu0227/HEAL</description><author>Yifan Lu, Yue Hu, Yiqi Zhong, Dequan Wang, Siheng Chen, Yanfeng Wang</author><pubDate>Fri, 16 Feb 2024 16:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13964v2</guid></item><item><title>Simulating Opinion Dynamics with Networks of LLM-based Agents</title><link>http://arxiv.org/abs/2311.09618v2</link><description>Accurately simulating human opinion dynamics is crucial for understanding avariety of societal phenomena, including polarization and the spread ofmisinformation. However, the agent-based models (ABMs) commonly used for suchsimulations often over-simplify human behavior. We propose a new approach tosimulating opinion dynamics based on populations of Large Language Models(LLMs). Our findings reveal a strong inherent bias in LLM agents towardsproducing accurate information, leading simulated agents to consensus in linewith scientific reality. This bias limits their utility for understandingresistance to consensus views on issues like climate change. After inducingconfirmation bias through prompt engineering, however, we observed opinionfragmentation in line with existing agent-based modeling and opinion dynamicsresearch. These insights highlight the promise and limitations of LLM agents inthis domain and suggest a path forward: refining LLMs with real-world discourseto better simulate the evolution of human beliefs.</description><author>Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers</author><pubDate>Fri, 16 Feb 2024 16:25:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09618v2</guid></item><item><title>TimeSeriesBench: An Industrial-Grade Benchmark for Time Series Anomaly Detection Models</title><link>http://arxiv.org/abs/2402.10802v1</link><description>Driven by the proliferation of real-world application scenarios and scales,time series anomaly detection (TSAD) has attracted considerable scholarly andindustrial interest. However, existing algorithms exhibit a gap in terms oftraining paradigm, online detection paradigm, and evaluation criteria whencompared to the actual needs of real-world industrial systems. Firstly, currentalgorithms typically train a specific model for each individual time series. Ina large-scale online system with tens of thousands of curves, maintaining sucha multitude of models is impractical. The performance of using merely onesingle unified model to detect anomalies remains unknown. Secondly, most TSADmodels are trained on the historical part of a time series and are tested onits future segment. In distributed systems, however, there are frequent systemdeployments and upgrades, with new, previously unseen time series emergingdaily. The performance of testing newly incoming unseen time series on currentTSAD algorithms remains unknown. Lastly, although some papers have conducteddetailed surveys, the absence of an online evaluation platform preventsanswering questions like "Who is the best at anomaly detection at the currentstage?" In this paper, we propose TimeSeriesBench, an industrial-gradebenchmark that we continuously maintain as a leaderboard. On this leaderboard,we assess the performance of existing algorithms across more than 168evaluation settings combining different training and testing paradigms,evaluation metrics and datasets. Through our comprehensive analysis of theresults, we provide recommendations for the future design of anomaly detectionalgorithms. To address known issues with existing public datasets, we releasean industrial dataset to the public together with TimeSeriesBench. All code,data, and the online leaderboard have been made publicly available.</description><author>Haotian Si, Changhua Pei, Hang Cui, Jingwen Yang, Yongqian Sun, Shenglin Zhang, Jingjing Li, Haiming Zhang, Jing Han, Dan Pei, Jianhui Li, Gaogang Xie</author><pubDate>Fri, 16 Feb 2024 16:25:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10802v1</guid></item><item><title>VATr++: Choose Your Words Wisely for Handwritten Text Generation</title><link>http://arxiv.org/abs/2402.10798v1</link><description>Styled Handwritten Text Generation (HTG) has received significant attentionin recent years, propelled by the success of learning-based solutions employingGANs, Transformers, and, preliminarily, Diffusion Models. Despite this surge ininterest, there remains a critical yet understudied aspect - the impact of theinput, both visual and textual, on the HTG model training and its subsequentinfluence on performance. This study delves deeper into a cutting-edgeStyled-HTG approach, proposing strategies for input preparation and trainingregularization that allow the model to achieve better performance andgeneralize better. These aspects are validated through extensive analysis onseveral different settings and datasets. Moreover, in this work, we go beyondperformance optimization and address a significant hurdle in HTG research - thelack of a standardized evaluation protocol. In particular, we propose astandardization of the evaluation protocol for HTG and conduct a comprehensivebenchmarking of existing approaches. By doing so, we aim to establish afoundation for fair and meaningful comparisons between HTG strategies,fostering progress in the field.</description><author>Bram Vanherle, Vittorio Pippi, Silvia Cascianelli, Nick Michiels, Frank Van Reeth, Rita Cucchiara</author><pubDate>Fri, 16 Feb 2024 16:21:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10798v1</guid></item><item><title>BlackJAX: Composable Bayesian inference in JAX</title><link>http://arxiv.org/abs/2402.10797v1</link><description>BlackJAX is a library implementing sampling and variational inferencealgorithms commonly used in Bayesian computation. It is designed for ease ofuse, speed, and modularity by taking a functional approach to the algorithms'implementation. BlackJAX is written in Python, using JAX to compile and runNumpPy-like samplers and variational methods on CPUs, GPUs, and TPUs. Thelibrary integrates well with probabilistic programming languages by workingdirectly with the (un-normalized) target log density function. BlackJAX isintended as a collection of low-level, composable implementations of basicstatistical 'atoms' that can be combined to perform well-defined Bayesianinference, but also provides high-level routines for ease of use. It isdesigned for users who need cutting-edge methods, researchers who want tocreate complex sampling methods, and people who want to learn how these work.</description><author>Alberto Cabezas, Adrien Corenflos, Junpeng Lao, Rémi Louf</author><pubDate>Fri, 16 Feb 2024 16:21:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10797v1</guid></item><item><title>Diversified Ensembling: An Experiment in Crowdsourced Machine Learning</title><link>http://arxiv.org/abs/2402.10795v1</link><description>Crowdsourced machine learning on competition platforms such as Kaggle is apopular and often effective method for generating accurate models. Typically,teams vie for the most accurate model, as measured by overall error on aholdout set, and it is common towards the end of such competitions for teams atthe top of the leaderboard to ensemble or average their models outside theplatform mechanism to get the final, best global model. In arXiv:2201.10408,the authors developed an alternative crowdsourcing framework in the context offair machine learning, in order to integrate community feedback into modelswhen subgroup unfairness is present and identifiable. There, unlike inclassical crowdsourced ML, participants deliberately specialize their effortsby working on subproblems, such as demographic subgroups in the service offairness. Here, we take a broader perspective on this work: we note that withinthis framework, participants may both specialize in the service of fairness andsimply to cater to their particular expertise (e.g., focusing on identifyingbird species in an image classification task). Unlike traditionalcrowdsourcing, this allows for the diversification of participants' efforts andmay provide a participation mechanism to a larger range of individuals (e.g. amachine learning novice who has insight into a specific fairness concern). Wepresent the first medium-scale experimental evaluation of this framework, with46 participating teams attempting to generate models to predict income fromAmerican Community Survey data. We provide an empirical analysis of teams'approaches, and discuss the novel system architecture we developed. From here,we give concrete guidance for how best to deploy such a framework.</description><author>Ira Globus-Harris, Declan Harrison, Michael Kearns, Pietro Perona, Aaron Roth</author><pubDate>Fri, 16 Feb 2024 16:20:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10795v1</guid></item><item><title>Unsupervised ASR via Cross-Lingual Pseudo-Labeling</title><link>http://arxiv.org/abs/2305.13330v3</link><description>Recent work has shown that it is possible to train an $\textit{unsupervised}$automatic speech recognition (ASR) system using only unpaired audio and text.Existing unsupervised ASR methods assume that no labeled data can be used fortraining. We argue that even if one does not have any labeled audio for a givenlanguage, there is $\textit{always}$ labeled data available for otherlanguages. We show that it is possible to use character-level acoustic models(AMs) from other languages to bootstrap an $\textit{unsupervised}$ AM in a newlanguage. Here, "unsupervised" means no labeled audio is available for the$\textit{target}$ language. Our approach is based on two key ingredients: (i)generating pseudo-labels (PLs) of the $\textit{target}$ language using some$\textit{other}$ language AM and (ii) constraining these PLs with a$\textit{target language model}$. Our approach is effective on Common Voice:e.g. transfer of English AM to Swahili achieves 18% WER. It also outperformscharacter-based wav2vec-U 2.0 by 15% absolute WER on LJSpeech with 800h oflabeled German data instead of 60k hours of unlabeled English data.</description><author>Tatiana Likhomanenko, Loren Lugosch, Ronan Collobert</author><pubDate>Fri, 16 Feb 2024 16:20:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13330v3</guid></item><item><title>Masked Attention is All You Need for Graphs</title><link>http://arxiv.org/abs/2402.10793v1</link><description>Graph neural networks (GNNs) and variations of the message passing algorithmare the predominant means for learning on graphs, largely due to theirflexibility, speed, and satisfactory performance. The design of powerful andgeneral purpose GNNs, however, requires significant research efforts and oftenrelies on handcrafted, carefully-chosen message passing operators. Motivated bythis, we propose a remarkably simple alternative for learning on graphs thatrelies exclusively on attention. Graphs are represented as node or edge setsand their connectivity is enforced by masking the attention weight matrix,effectively creating custom attention patterns for each graph. Despite itssimplicity, masked attention for graphs (MAG) has state-of-the-art performanceon long-range tasks and outperforms strong message passing baselines and muchmore involved attention-based methods on over 55 node and graph-level tasks. Wealso show significantly better transfer learning capabilities compared to GNNsand comparable or better time and memory scaling. MAG has sub-linear memoryscaling in the number of nodes or edges, enabling learning on dense graphs andfuture-proofing the approach.</description><author>David Buterez, Jon Paul Janet, Dino Oglic, Pietro Lio</author><pubDate>Fri, 16 Feb 2024 16:20:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10793v1</guid></item><item><title>AUTOACT: Automatic Agent Learning from Scratch via Self-Planning</title><link>http://arxiv.org/abs/2401.05268v3</link><description>Language agents have achieved considerable performance on various complexquestion-answering tasks. Despite the incessant exploration in this field,existing language agent systems still struggle with costly, non-reproducibledata reliance and face the challenge of compelling a single model for multiplefunctions. To this end, we introduce AutoAct, an automatic agent learningframework that does not rely on large-scale annotated data and synthetictrajectories from closed-source models (e.g., GPT-4). Given limited data with atool library, AutoAct first automatically synthesizes planning trajectorieswithout any assistance from humans or strong closed-source models. Then,AutoAct leverages a division-of-labor strategy to automatically differentiatebased on the target task information and synthesized trajectories, producing asub-agent group to complete the task. We conduct comprehensive experiments withdifferent LLMs, which demonstrates that AutoAct yields better or parallelperformance compared to various strong baselines. Further analysis demonstratesthe effectiveness of the division-of-labor strategy, with the trajectoryquality generated by AutoAct significantly outperforming that of others. Codewill be available at https://github.com/zjunlp/AutoAct.</description><author>Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen</author><pubDate>Fri, 16 Feb 2024 16:19:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05268v3</guid></item><item><title>In Search of Needles in a 10M Haystack: Recurrent Memory Finds What LLMs Miss</title><link>http://arxiv.org/abs/2402.10790v1</link><description>This paper addresses the challenge of processing long documents usinggenerative transformer models. To evaluate different approaches, we introduceBABILong, a new benchmark designed to assess model capabilities in extractingand processing distributed facts within extensive texts. Our evaluation, whichincludes benchmarks for GPT-4 and RAG, reveals that common methods areeffective only for sequences up to $10^4$ elements. In contrast, fine-tuningGPT-2 with recurrent memory augmentations enables it to handle tasks involvingup to $10^7$ elements. This achievement marks a substantial leap, as it is byfar the longest input processed by any open neural network model to date,demonstrating a significant improvement in the processing capabilities for longsequences.</description><author>Yuri Kuratov, Aydar Bulatov, Petr Anokhin, Dmitry Sorokin, Artyom Sorokin, Mikhail Burtsev</author><pubDate>Fri, 16 Feb 2024 16:15:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10790v1</guid></item><item><title>Optimizing Credit Limit Adjustments Under Adversarial Goals Using Reinforcement Learning</title><link>http://arxiv.org/abs/2306.15585v2</link><description>Reinforcement learning has been explored for many problems, from video gameswith deterministic environments to portfolio and operations management in whichscenarios are stochastic; however, there have been few attempts to test thesemethods in banking problems. In this study, we sought to find and automatize anoptimal credit card limit adjustment policy by employing reinforcement learningtechniques. Because of the historical data available, we considered twopossible actions per customer, namely increasing or maintaining an individual'scurrent credit limit. To find this policy, we first formulated thisdecision-making question as an optimization problem in which the expectedprofit was maximized; therefore, we balanced two adversarial goals: maximizingthe portfolio's revenue and minimizing the portfolio's provisions. Second,given the particularities of our problem, we used an offline learning strategyto simulate the impact of the action based on historical data from a super-appin Latin America to train our reinforcement learning agent. Our results, basedon the proposed methodology involving synthetic experimentation, show that aDouble Q-learning agent with optimized hyperparameters can outperform otherstrategies and generate a non-trivial optimal policy not only reflecting thecomplex nature of this decision but offering an incentive to explorereinforcement learning in real-world banking scenarios. Our researchestablishes a conceptual structure for applying reinforcement learningframework to credit limit adjustment, presenting an objective technique to makethese decisions primarily based on data-driven methods rather than relying onlyon expert-driven systems. We also study the use of alternative data for theproblem of balance prediction, as the latter is a requirement of our proposedmodel. We find the use of such data does not always bring prediction gains.</description><author>Sherly Alfonso-Sánchez, Jesús Solano, Alejandro Correa-Bahnsen, Kristina P. Sendova, Cristián Bravo</author><pubDate>Fri, 16 Feb 2024 16:12:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15585v2</guid></item><item><title>EdgeQAT: Entropy and Distribution Guided Quantization-Aware Training for the Acceleration of Lightweight LLMs on the Edge</title><link>http://arxiv.org/abs/2402.10787v1</link><description>Despite the remarkable strides of Large Language Models (LLMs) in variousfields, the wide applications of LLMs on edge devices are limited due to theirmassive parameters and computations. To address this, quantization is commonlyadopted to generate lightweight LLMs with efficient computations and fastinference. However, Post-Training Quantization (PTQ) methods dramaticallydegrade in quality when quantizing weights, activations, and KV cache togetherto below 8 bits. Besides, many Quantization-Aware Training (QAT) works quantizemodel weights, leaving the activations untouched, which do not fully exploitthe potential of quantization for inference acceleration on the edge. In thispaper, we propose EdgeQAT, the Entropy and Distribution Guided QAT for theoptimization of lightweight LLMs to achieve inference acceleration on Edgedevices. We first identify that the performance drop of quantization primarilystems from the information distortion in quantized attention maps, demonstratedby the different distributions in quantized query and key of the self-attentionmechanism. Then, the entropy and distribution guided QAT is proposed tomitigate the information distortion. Moreover, we design a tokenimportance-aware adaptive method to dynamically quantize the tokens withdifferent bit widths for further optimization and acceleration. Our extensiveexperiments verify the substantial improvements with our framework acrossvarious datasets. Furthermore, we achieve an on-device speedup of up to 2.37xcompared with its FP16 counterparts across multiple edge devices, signaling agroundbreaking advancement.</description><author>Xuan Shen, Zhenglun Kong, Changdi Yang, Zhaoyang Han, Lei Lu, Peiyan Dong, Cheng Lyu, Chih-hsiang Li, Xuehang Guo, Zhihao Shu, Wei Niu, Miriam Leeser, Pu Zhao, Yanzhi Wang</author><pubDate>Fri, 16 Feb 2024 16:10:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10787v1</guid></item><item><title>A Condensed Transition Graph Framework for Zero-shot Link Prediction with Large Language Models</title><link>http://arxiv.org/abs/2402.10779v1</link><description>Zero-shot link prediction (ZSLP) on knowledge graphs aims at automaticallyidentifying relations between given entities. Existing methods primarily employauxiliary information to predict tail entity given head entity and itsrelation, yet face challenges due to the occasional unavailability of suchdetailed information and the inherent simplicity of predicting tail entitiesbased on semantic similarities. Even though Large Language Models (LLMs) offera promising solution to predict unobserved relations between the head and tailentity in a zero-shot manner, their performance is still restricted due to theinability to leverage all the (exponentially many) paths' information betweentwo entities, which are critical in collectively indicating their relationtypes. To address this, in this work, we introduce a Condensed Transition GraphFramework for Zero-Shot Link Prediction (CTLP), which encodes all the paths'information in linear time complexity to predict unseen relations betweenentities, attaining both efficiency and information preservation. Specifically,we design a condensed transition graph encoder with theoretical guarantees onits coverage, expressiveness, and efficiency. It is learned by a transitiongraph contrastive learning strategy. Subsequently, we design a soft instructiontuning to learn and map the all-path embedding to the input of LLMs.Experimental results show that our proposed CTLP method achievesstate-of-the-art performance on three standard ZSLP datasets</description><author>Mingchen Li, Chen Ling, Rui Zhang, Liang Zhao</author><pubDate>Fri, 16 Feb 2024 16:02:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10779v1</guid></item><item><title>AutoGPT+P: Affordance-based Task Planning with Large Language Models</title><link>http://arxiv.org/abs/2402.10778v1</link><description>Recent advances in task planning leverage Large Language Models (LLMs) toimprove generalizability by combining such models with classical planningalgorithms to address their inherent limitations in reasoning capabilities.However, these approaches face the challenge of dynamically capturing theinitial state of the task planning problem. To alleviate this issue, we proposeAutoGPT+P, a system that combines an affordance-based scene representation witha planning system. Affordances encompass the action possibilities of an agenton the environment and objects present in it. Thus, deriving the planningdomain from an affordance-based scene representation allows symbolic planningwith arbitrary objects. AutoGPT+P leverages this representation to derive andexecute a plan for a task specified by the user in natural language. Inaddition to solving planning tasks under a closed-world assumption, AutoGPT+Pcan also handle planning with incomplete information, e. g., tasks with missingobjects by exploring the scene, suggesting alternatives, or providing a partialplan. The affordance-based scene representation combines object detection withan automatically generated object-affordance-mapping using ChatGPT. The coreplanning tool extends existing work by automatically correcting semantic andsyntactic errors. Our approach achieves a success rate of 98%, surpassing thecurrent 81% success rate of the current state-of-the-art LLM-based planningmethod SayCan on the SayCan instruction set. Furthermore, we evaluated ourapproach on our newly created dataset with 150 scenarios covering a wide rangeof complex tasks with missing objects, achieving a success rate of 79% on ourdataset. The dataset and the code are publicly available athttps://git.h2t.iar.kit.edu/birr/autogpt-p-standalone.</description><author>Timo Birr, Christoph Pohl, Abdelrahman Younes, Tamim Asfour</author><pubDate>Fri, 16 Feb 2024 16:00:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10778v1</guid></item><item><title>Pushing The Limit of LLM Capacity for Text Classification</title><link>http://arxiv.org/abs/2402.07470v2</link><description>The value of text classification's future research has encountered challengesand uncertainties, due to the extraordinary efficacy demonstrated by largelanguage models (LLMs) across numerous downstream NLP tasks. In this era ofopen-ended language modeling, where task boundaries are gradually fading, anurgent question emerges: have we made significant advances in textclassification under the full benefit of LLMs? To answer this question, wepropose RGPT, an adaptive boosting framework tailored to produce a specializedtext classification LLM by recurrently ensembling a pool of strong baselearners. The base learners are constructed by adaptively adjusting thedistribution of training samples and iteratively fine-tuning LLMs with them.Such base learners are then ensembled to be a specialized text classificationLLM, by recurrently incorporating the historical predictions from the previouslearners. Through a comprehensive empirical comparison, we show that RGPTsignificantly outperforms 8 SOTA PLMs and 7 SOTA LLMs on four benchmarks by1.36% on average. Further evaluation experiments show a clear surpassing ofRGPT over human classification.</description><author>Yazhou Zhang, Mengyao Wang, Chenyu Ren, Qiuchi Li, Prayag Tiwari, Benyou Wang, Jing Qin</author><pubDate>Fri, 16 Feb 2024 15:59:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07470v2</guid></item><item><title>In-Vivo Hyperspectral Human Brain Image Database for Brain Cancer Detection</title><link>http://arxiv.org/abs/2402.10776v1</link><description>The use of hyperspectral imaging for medical applications is becoming morecommon in recent years. One of the main obstacles that researchers find whendeveloping hyperspectral algorithms for medical applications is the lack ofspecific, publicly available, and hyperspectral medical data. The workdescribed in this paper was developed within the framework of the Europeanproject HELICoiD (HypErspectraL Imaging Cancer Detection), which had as a maingoal the application of hyperspectral imaging to the delineation of braintumors in real-time during neurosurgical operations. In this paper, themethodology followed to generate the first hyperspectral database of in-vivohuman brain tissues is presented. Data was acquired employing a customizedhyperspectral acquisition system capable of capturing information in the Visualand Near InfraRed (VNIR) range from 400 to 1000 nm. Repeatability was assessedfor the cases where two images of the same scene were captured consecutively.The analysis reveals that the system works more efficiently in the spectralrange between 450 and 900 nm. A total of 36 hyperspectral images from 22different patients were obtained. From these data, more than 300 000 spectralsignatures were labeled employing a semi-automatic methodology based on thespectral angle mapper algorithm. Four different classes were defined: normaltissue, tumor tissue, blood vessel, and background elements. All thehyperspectral data has been made available in a public repository.</description><author>H. Fabelo, S. Ortega, A. Szolna, D. Bulters, J. F. Pineiro, S. Kabwama, A. Shanahan, H. Bulstrode, S. Bisshopp, B. R. Kiran, D. Ravi, R. Lazcano, D. Madronal, C. Sosa, C. Espino, M. Marquez, M. De la Luz Plaza, R. Camacho, D. Carrera, M. Hernandez, G. M. Callico, J. Morera, B. Stanciulescu, G. Z. Yang, R. Salvador, E. Juarez, C. Sanz, R. Sarmiento</author><pubDate>Fri, 16 Feb 2024 15:58:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10776v1</guid></item><item><title>Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants</title><link>http://arxiv.org/abs/2402.10774v1</link><description>Error Feedback (EF) is a highly popular and immensely effective mechanism forfixing convergence issues which arise in distributed training methods (such asdistributed GD or SGD) when these are enhanced with greedy communicationcompression techniques such as TopK. While EF was proposed almost a decade ago(Seide et al., 2014), and despite concentrated effort by the community toadvance the theoretical understanding of this mechanism, there is still a lotto explore. In this work we study a modern form of error feedback called EF21(Richtarik et al., 2021) which offers the currently best-known theoreticalguarantees, under the weakest assumptions, and also works well in practice. Inparticular, while the theoretical communication complexity of EF21 depends onthe quadratic mean of certain smoothness parameters, we improve this dependenceto their arithmetic mean, which is always smaller, and can be substantiallysmaller, especially in heterogeneous data regimes. We take the reader on ajourney of our discovery process. Starting with the idea of applying EF21 to anequivalent reformulation of the underlying problem which (unfortunately)requires (often impractical) machine cloning, we continue to the discovery of anew weighted version of EF21 which can (fortunately) be executed without anycloning, and finally circle back to an improved analysis of the original EF21method. While this development applies to the simplest form of EF21, ourapproach naturally extends to more elaborate variants involving stochasticgradients and partial participation. Further, our technique improves thebest-known theory of EF21 in the rare features regime (Richtarik et al., 2023).Finally, we validate our theoretical findings with suitable experiments.</description><author>Peter Richtárik, Elnur Gasanov, Konstantin Burlachenko</author><pubDate>Fri, 16 Feb 2024 15:55:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10774v1</guid></item><item><title>Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios</title><link>http://arxiv.org/abs/2401.17167v2</link><description>The recent trend of using Large Language Models (LLMs) as tool agents inreal-world applications underscores the necessity for comprehensive evaluationsof their capabilities, particularly in complex scenarios involving planning,creating, and using tools. However, existing benchmarks typically focus onsimple synthesized queries that do not reflect real-world complexity, therebyoffering limited perspectives in evaluating tool utilization. To address thisissue, we present UltraTool, a novel benchmark designed to improve and evaluateLLMs' ability in tool utilization within real-world scenarios. UltraToolfocuses on the entire process of using tools - from planning and creating toapplying them in complex tasks. It emphasizes real-world complexities,demanding accurate, multi-step planning for effective problem-solving. A keyfeature of UltraTool is its independent evaluation of planning with naturallanguage, which happens before tool usage and simplifies the task solving bymapping out the intermediate steps. Thus, unlike previous work, it eliminatesthe restriction of pre-defined toolset. Through extensive experiments onvarious LLMs, we offer novel insights into the evaluation of capabilities ofLLMs in tool utilization, thereby contributing a fresh perspective to thisrapidly evolving field. The benchmark is publicly available athttps://github.com/JoeYing1019/UltraTool.</description><author>Shijue Huang, Wanjun Zhong, Jianqiao Lu, Qi Zhu, Jiahui Gao, Weiwen Liu, Yutai Hou, Xingshan Zeng, Yasheng Wang, Lifeng Shang, Xin Jiang, Ruifeng Xu, Qun Liu</author><pubDate>Fri, 16 Feb 2024 15:55:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17167v2</guid></item><item><title>Enhancing ESG Impact Type Identification through Early Fusion and Multilingual Models</title><link>http://arxiv.org/abs/2402.10772v1</link><description>In the evolving landscape of Environmental, Social, and Corporate Governance(ESG) impact assessment, the ML-ESG-2 shared task proposes identifying ESGimpact types. To address this challenge, we present a comprehensive systemleveraging ensemble learning techniques, capitalizing on early and late fusionapproaches. Our approach employs four distinct models: mBERT, FlauBERT-base,ALBERT-base-v2, and a Multi-Layer Perceptron (MLP) incorporating LatentSemantic Analysis (LSA) and Term Frequency-Inverse Document Frequency (TF-IDF)features. Through extensive experimentation, we find that our early fusionensemble approach, featuring the integration of LSA, TF-IDF, mBERT,FlauBERT-base, and ALBERT-base-v2, delivers the best performance. Our systemoffers a comprehensive ESG impact type identification solution, contributing tothe responsible and sustainable decision-making processes vital in today'sfinancial and corporate governance landscape.</description><author>Hariram Veeramani, Surendrabikram Thapa, Usman Naseem</author><pubDate>Fri, 16 Feb 2024 15:54:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10772v1</guid></item><item><title>From Peptides to Nanostructures: A Euclidean Transformer for Fast and Stable Machine Learned Force Fields</title><link>http://arxiv.org/abs/2309.15126v2</link><description>Recent years have seen vast progress in the development of machine learnedforce fields (MLFFs) based on ab-initio reference calculations. Despiteachieving low test errors, the reliability of MLFFs in molecular dynamics (MD)simulations is facing growing scrutiny due to concerns about instability overextended simulation timescales. Our findings suggest a potential connectionbetween robustness to cumulative inaccuracies and the use of equivariantrepresentations in MLFFs, but the computational cost associated with theserepresentations can limit this advantage in practice. To address this, wepropose a transformer architecture called SO3krates that combines sparseequivariant representations (Euclidean variables) with a self-attentionmechanism that separates invariant and equivariant information, eliminating theneed for expensive tensor products. SO3krates achieves a unique combination ofaccuracy, stability, and speed that enables insightful analysis of quantumproperties of matter on extended time and system size scales. To showcase thiscapability, we generate stable MD trajectories for flexible peptides andsupra-molecular structures with hundreds of atoms. Furthermore, we investigatethe PES topology for medium-sized chainlike molecules (e.g., small peptides) byexploring thousands of minima. Remarkably, SO3krates demonstrates the abilityto strike a balance between the conflicting demands of stability and theemergence of new minimum-energy conformations beyond the training data, whichis crucial for realistic exploration tasks in the field of biochemistry.</description><author>J. Thorben Frank, Oliver T. Unke, Klaus-Robert Müller, Stefan Chmiela</author><pubDate>Fri, 16 Feb 2024 15:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15126v2</guid></item><item><title>Medical Image Segmentation with InTEnt: Integrated Entropy Weighting for Single Image Test-Time Adaptation</title><link>http://arxiv.org/abs/2402.09604v2</link><description>Test-time adaptation (TTA) refers to adapting a trained model to a new domainduring testing. Existing TTA techniques rely on having multiple test imagesfrom the same domain, yet this may be impractical in real-world applicationssuch as medical imaging, where data acquisition is expensive and imagingconditions vary frequently. Here, we approach such a task, of adapting amedical image segmentation model with only a single unlabeled test image. MostTTA approaches, which directly minimize the entropy of predictions, fail toimprove performance significantly in this setting, in which we also observe thechoice of batch normalization (BN) layer statistics to be a highly importantyet unstable factor due to only having a single test domain example. Toovercome this, we propose to instead integrate over predictions made withvarious estimates of target domain statistics between the training and teststatistics, weighted based on their entropy statistics. Our method, validatedon 24 source/target domain splits across 3 medical image datasets surpasses theleading method by 2.9% Dice coefficient on average.</description><author>Haoyu Dong, Nicholas Konz, Hanxue Gu, Maciej A. Mazurowski</author><pubDate>Fri, 16 Feb 2024 15:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09604v2</guid></item><item><title>Semi-Supervised Health Index Monitoring with Feature Generation and Fusion</title><link>http://arxiv.org/abs/2312.02867v2</link><description>The Health Index (HI) is crucial for evaluating system health, aiding taskslike anomaly detection and predicting remaining useful life for systemsdemanding high safety and reliability. Tight monitoring is crucial forachieving high precision at a lower cost. Obtaining HI labels in real-worldapplications is often cost-prohibitive, requiring continuous, precise healthmeasurements. Therefore, it is more convenient to leverage run-to failuredatasets that may provide potential indications of machine wear condition,making it necessary to apply semi-supervised tools for HI construction. In thisstudy, we adapt the Deep Semi-supervised Anomaly Detection (DeepSAD) method forHI construction. We use the DeepSAD embedding as a condition indicators toaddress interpretability challenges and sensitivity to system-specific factors.Then, we introduce a diversity loss to enrich condition indicators. We employan alternating projection algorithm with isotonic constraints to transform theDeepSAD embedding into a normalized HI with an increasing trend. Validation onthe PHME 2010 milling dataset, a recognized benchmark with ground truth HIsdemonstrates meaningful HIs estimations. Our contributions create opportunitiesfor more accessible and reliable HI estimation, particularly in cases whereobtaining ground truth HI labels is unfeasible.</description><author>Gaëtan Frusque, Ismail Nejjar, Majid Nabavi, Olga Fink</author><pubDate>Fri, 16 Feb 2024 15:52:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02867v2</guid></item><item><title>Dual Box Embeddings for the Description Logic EL++</title><link>http://arxiv.org/abs/2301.11118v4</link><description>OWL ontologies, whose formal semantics are rooted in Description Logic (DL),have been widely used for knowledge representation. Similar to Knowledge Graphs(KGs), ontologies are often incomplete, and maintaining and constructing themhas proved challenging. While classical deductive reasoning algorithms use theprecise formal semantics of an ontology to predict missing facts, recent yearshave witnessed growing interest in inductive reasoning techniques that canderive probable facts from an ontology. Similar to KGs, a promising approach isto learn ontology embeddings in a latent vector space, while additionallyensuring they adhere to the semantics of the underlying DL. While a variety ofapproaches have been proposed, current ontology embedding methods suffer fromseveral shortcomings, especially that they all fail to faithfully modelone-to-many, many-to-one, and many-to-many relations and role inclusion axioms.To address this problem and improve ontology completion performance, we proposea novel ontology embedding method named Box$^2$EL for the DL EL++, whichrepresents both concepts and roles as boxes (i.e., axis-alignedhyperrectangles), and models inter-concept relationships using a bumpingmechanism. We theoretically prove the soundness of Box$^2$EL and conduct anextensive experimental evaluation, achieving state-of-the-art results across avariety of datasets on the tasks of subsumption prediction, role assertionprediction, and approximating deductive reasoning.</description><author>Mathias Jackermeier, Jiaoyan Chen, Ian Horrocks</author><pubDate>Fri, 16 Feb 2024 15:50:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11118v4</guid></item><item><title>Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models</title><link>http://arxiv.org/abs/2311.08011v2</link><description>Recent advancements in Large Language Models (LLMs) have showcased theirremarkable capabilities in text understanding and generation. However, evenstronger LLMs are susceptible to acquiring erroneous or obsolete informationfrom the training corpus. Direct secondary fine-tuning with data containing newknowledge may be ineffective in updating knowledge due to the conflict betweenold and new knowledge. In this paper, we propose a new paradigm for fine-tuningcalled F-Learning (Forgetting before Learning), which employs parametricarithmetic to facilitate the forgetting of old knowledge and learning of newknowledge. Experimental results on two publicly available datasets demonstratethat our proposed F-Learning can obviously improve the knowledge updatingperformance of both full fine-tuning and LoRA fine-tuning, simultaneouslyoutperforming the existing baselines in most cases. Moreover, we have alsodiscovered that forgetting old knowledge by subtracting the parameters of LoRAcan yield a similar effect to subtracting the parameters of full fine-tuning,and occasionally even surpass it significantly.</description><author>Shiwen Ni, Dingwei Chen, Chengming Li, Xiping Hu, Ruifeng Xu, Min Yang</author><pubDate>Fri, 16 Feb 2024 15:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08011v2</guid></item><item><title>CADICA: a new dataset for coronary artery disease detection by using invasive coronary angiography</title><link>http://arxiv.org/abs/2402.00570v2</link><description>Coronary artery disease (CAD) remains the leading cause of death globally andinvasive coronary angiography (ICA) is considered the gold standard ofanatomical imaging evaluation when CAD is suspected. However, risk evaluationbased on ICA has several limitations, such as visual assessment of stenosisseverity, which has significant interobserver variability. This motivates todevelopment of a lesion classification system that can support specialists intheir clinical procedures. Although deep learning classification methods arewell-developed in other areas of medical imaging, ICA image classification isstill at an early stage. One of the most important reasons is the lack ofavailable and high-quality open-access datasets. In this paper, we reported anew annotated ICA images dataset, CADICA, to provide the research communitywith a comprehensive and rigorous dataset of coronary angiography consisting ofa set of acquired patient videos and associated disease-related metadata. Thisdataset can be used by clinicians to train their skills in angiographicassessment of CAD severity and by computer scientists to create computer-aideddiagnostic systems to help in such assessment. In addition, baselineclassification methods are proposed and analyzed, validating the functionalityof CADICA and giving the scientific community a starting point to improve CADdetection.</description><author>Ariadna Jiménez-Partinen, Miguel A. Molina-Cabello, Karl Thurnhofer-Hemsi, Esteban J. Palomo, Jorge Rodríguez-Capitán, Ana I. Molina-Ramos, Manuel Jiménez-Navarro</author><pubDate>Fri, 16 Feb 2024 15:48:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00570v2</guid></item><item><title>How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?</title><link>http://arxiv.org/abs/2402.10770v1</link><description>Work on instruction-tuned Large Language Models (LLMs) has used automaticmethods based on text overlap and LLM judgments as cost-effective alternativesto human evaluation. In this paper, we study the reliability of such methodsacross a broad range of tasks and in a cross-lingual setting. In contrast toprevious findings, we observe considerable variability in correlations betweenautomatic methods and human evaluators when scores are differentiated by tasktype. Specifically, the widely-used ROUGE-L metric strongly correlates withhuman judgments for short-answer English tasks but is unreliable in free-formgeneration tasks and cross-lingual transfer. The effectiveness of GPT-4 as anevaluator depends on including reference answers when prompting forassessments, which can lead to overly strict evaluations in free-formgeneration tasks. In summary, we find that, while automatic evaluation methodscan approximate human judgements under specific conditions, their reliabilityis highly context-dependent. Our findings enhance the understanding of howautomatic methods should be applied and interpreted when developing andevaluating instruction-tuned LLMs.</description><author>Ehsan Doostmohammadi, Oskar Holmström, Marco Kuhlmann</author><pubDate>Fri, 16 Feb 2024 15:48:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10770v1</guid></item><item><title>Distillation Enhanced Generative Retrieval</title><link>http://arxiv.org/abs/2402.10769v1</link><description>Generative retrieval is a promising new paradigm in text retrieval thatgenerates identifier strings of relevant passages as the retrieval target. Thisparadigm leverages powerful generative language models, distinct fromtraditional sparse or dense retrieval methods. In this work, we identify aviable direction to further enhance generative retrieval via distillation andpropose a feasible framework, named DGR. DGR utilizes sophisticated rankingmodels, such as the cross-encoder, in a teacher role to supply a passage ranklist, which captures the varying relevance degrees of passages instead ofbinary hard labels; subsequently, DGR employs a specially designed distilledRankNet loss to optimize the generative retrieval model, considering thepassage rank order provided by the teacher model as labels. This framework onlyrequires an additional distillation step to enhance current generativeretrieval systems and does not add any burden to the inference stage. Weconduct experiments on four public datasets, and the results indicate that DGRachieves state-of-the-art performance among the generative retrieval methods.Additionally, DGR demonstrates exceptional robustness and generalizability withvarious teacher models and distillation losses.</description><author>Yongqi Li, Zhen Zhang, Wenjie Wang, Liqiang Nie, Wenjie Li, Tat-Seng Chua</author><pubDate>Fri, 16 Feb 2024 15:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10769v1</guid></item><item><title>Confident Naturalness Explanation (CNE): A Framework to Explain and Assess Patterns Forming Naturalness</title><link>http://arxiv.org/abs/2311.08936v4</link><description>Protected natural areas are regions that have been minimally affected byhuman activities such as urbanization, agriculture, and other humaninterventions. To better understand and map the naturalness of these areas,machine learning models can be used to analyze satellite imagery. Specifically,explainable machine learning methods show promise in uncovering patterns thatcontribute to the concept of naturalness within these protected environments.Additionally, addressing the uncertainty inherent in machine learning models iscrucial for a comprehensive understanding of this concept. However, existingapproaches have limitations. They either fail to provide explanations that areboth valid and objective or struggle to offer a quantitative metric thataccurately measures the contribution of specific patterns to naturalness, alongwith the associated confidence. In this paper, we propose a novel frameworkcalled the Confident Naturalness Explanation (CNE) framework. This frameworkcombines explainable machine learning and uncertainty quantification to assessand explain naturalness. We introduce a new quantitative metric that describesthe confident contribution of patterns to the concept of naturalness.Furthermore, we generate an uncertainty-aware segmentation mask for each inputsample, highlighting areas where the model lacks knowledge. To demonstrate theeffectiveness of our framework, we apply it to a study site in Fennoscandiausing two open-source satellite datasets.</description><author>Ahmed Emam, Mohamed Farag, Ribana Roscher</author><pubDate>Fri, 16 Feb 2024 15:47:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08936v4</guid></item><item><title>Coronary Artery Disease Classification with Different Lesion Degree Ranges based on Deep Learning</title><link>http://arxiv.org/abs/2402.00593v2</link><description>Invasive Coronary Angiography (ICA) images are considered the gold standardfor assessing the state of the coronary arteries. Deep learning classificationmethods are widely used and well-developed in different areas where medicalimaging evaluation has an essential impact due to the development ofcomputer-aided diagnosis systems that can support physicians in their clinicalprocedures. In this paper, a new performance analysis of deep learning methodsfor binary ICA classification with different lesion degrees is reported. Toreach this goal, an annotated dataset of ICA images that contains the groundtruth, the location of lesions and seven possible severity degrees rangingbetween 0% and 100% was employed. The ICA images were divided into 'lesion' or'non-lesion' patches. We aim to study how binary classification performance isaffected by the different lesion degrees considered in the positive class.Therefore, five known convolutional neural network architectures were trainedwith different input images where different lesion degree ranges were graduallyincorporated until considering the seven lesion degrees. Besides, four types ofexperiments with and without data augmentation were designed, whose F-measureand Area Under Curve (AUC) were computed. Reported results achieved anF-measure and AUC of 92.7% and 98.1%, respectively. However, lesionclassification is highly affected by the degree of the lesion intended toclassify, with 15% less accuracy when &lt;99% lesion patches are present.</description><author>Ariadna Jiménez-Partinen, Karl Thurnhofer-Hemsi, Esteban J. Palomo, Jorge Rodríguez-Capitán, Ana I. Molina-Ramos</author><pubDate>Fri, 16 Feb 2024 15:45:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00593v2</guid></item><item><title>Inference to the Best Explanation in Large Language Models</title><link>http://arxiv.org/abs/2402.10767v1</link><description>While Large Language Models (LLMs) have found success in real-worldapplications, their underlying explanatory process is still poorly understood.This paper proposes IBE-Eval, a framework inspired by philosophical accounts onInference to the Best Explanation (IBE) to advance the interpretation andevaluation of LLMs' explanations. IBE-Eval estimates the plausibility ofnatural language explanations through a combination of explicit logical andlinguistic features including: consistency, parsimony, coherence, anduncertainty. Extensive experiments are conducted on Causal Question Answering(CQA), where \textit{IBE-Eval} is tasked to select the most plausible causalexplanation amongst competing ones generated by LLMs (i.e., GPT 3.5 and Llama2). The experiments reveal that IBE-Eval can successfully identify the bestexplanation with up to 77\% accuracy ($\approx 27\%$ above random), improvingupon a GPT 3.5-as-a-Judge baseline ($\approx+17\%$) while being intrinsicallymore efficient and interpretable. Additional analyses suggest that, despitemodel-specific variances, LLM-generated explanations tend to conform to IBEcriteria and that IBE-Eval is significantly correlated with human judgment,opening up opportunities for future development of automated explanationverification tools.</description><author>Dhairya Dalal, Marco Valentino, André Freitas, Paul Buitelaar</author><pubDate>Fri, 16 Feb 2024 15:41:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10767v1</guid></item><item><title>Unified Hallucination Detection for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2402.03190v2</link><description>Despite significant strides in multimodal tasks, Multimodal Large LanguageModels (MLLMs) are plagued by the critical issue of hallucination. The reliabledetection of such hallucinations in MLLMs has, therefore, become a vital aspectof model evaluation and the safeguarding of practical application deployment.Prior research in this domain has been constrained by a narrow focus onsingular tasks, an inadequate range of hallucination categories addressed, anda lack of detailed granularity. In response to these challenges, our workexpands the investigative horizons of hallucination detection. We present anovel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitatethe evaluation of advancements in hallucination detection methods.Additionally, we unveil a novel unified multimodal hallucination detectionframework, UNIHD, which leverages a suite of auxiliary tools to validate theoccurrence of hallucinations robustly. We demonstrate the effectiveness ofUNIHD through meticulous evaluation and comprehensive analysis. We also providestrategic insights on the application of specific tools for addressing variouscategories of hallucinations.</description><author>Xiang Chen, Chenxi Wang, Yida Xue, Ningyu Zhang, Xiaoyan Yang, Qiang Li, Yue Shen, Lei Liang, Jinjie Gu, Huajun Chen</author><pubDate>Fri, 16 Feb 2024 15:40:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03190v2</guid></item><item><title>Policy Learning for Off-Dynamics RL with Deficient Support</title><link>http://arxiv.org/abs/2402.10765v1</link><description>Reinforcement Learning (RL) can effectively learn complex policies. However,learning these policies often demands extensive trial-and-error interactionswith the environment. In many real-world scenarios, this approach is notpractical due to the high costs of data collection and safety concerns. As aresult, a common strategy is to transfer a policy trained in a low-cost, rapidsource simulator to a real-world target environment. However, this processposes challenges. Simulators, no matter how advanced, cannot perfectlyreplicate the intricacies of the real world, leading to dynamics discrepanciesbetween the source and target environments. Past research posited that thesource domain must encompass all possible target transitions, a condition weterm full support. However, expecting full support is often unrealistic,especially in scenarios where significant dynamics discrepancies arise. In thispaper, our emphasis shifts to addressing large dynamics mismatch adaptation. Wemove away from the stringent full support condition of earlier research,focusing instead on crafting an effective policy for the target domain. Ourproposed approach is simple but effective. It is anchored in the centralconcepts of the skewing and extension of source support towards target supportto mitigate support deficiencies. Through comprehensive testing on a varied setof benchmarks, our method's efficacy stands out, showcasing notableimprovements over previous techniques.</description><author>Linh Le Pham Van, Hung The Tran, Sunil Gupta</author><pubDate>Fri, 16 Feb 2024 15:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10765v1</guid></item><item><title>On Explaining Unfairness: An Overview</title><link>http://arxiv.org/abs/2402.10762v1</link><description>Algorithmic fairness and explainability are foundational elements forachieving responsible AI. In this paper, we focus on their interplay, aresearch area that is recently receiving increasing attention. To this end, wefirst present two comprehensive taxonomies, each representing one of the twocomplementary fields of study: fairness and explanations. Then, we categorizeexplanations for fairness into three types: (a) Explanations to enhancefairness metrics, (b) Explanations to help us understand the causes of(un)fairness, and (c) Explanations to assist us in designing methods formitigating unfairness. Finally, based on our fairness and explanationtaxonomies, we present undiscovered literature paths revealing gaps that canserve as valuable insights for future research.</description><author>Christos Fragkathoulas, Vasiliki Papanikou, Danae Pla Karidi, Evaggelia Pitoura</author><pubDate>Fri, 16 Feb 2024 15:38:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10762v1</guid></item><item><title>Federated Unlearning: A Survey on Methods, Design Guidelines, and Evaluation Metrics</title><link>http://arxiv.org/abs/2401.05146v2</link><description>Federated Learning (FL) enables collaborative training of a Machine Learning(ML) model across multiple parties, facilitating the preservation of users' andinstitutions' privacy by keeping data stored locally. Instead of centralizingraw data, FL exchanges locally refined model parameters to build a global modelincrementally. While FL is more compliant with emerging regulations such as theEuropean General Data Protection Regulation (GDPR), ensuring the right to beforgotten in this context - allowing FL participants to remove their datacontributions from the learned model - remains unclear. In addition, it isrecognized that malicious clients may inject backdoors into the global modelthrough updates, e.g. to generate mispredictions on specially crafted dataexamples. Consequently, there is the need for mechanisms that can guaranteeindividuals the possibility to remove their data and erase maliciouscontributions even after aggregation, without compromising the already acquired"good" knowledge. This highlights the necessity for novel Federated Unlearning(FU) algorithms, which can efficiently remove specific clients' contributionswithout full model retraining. This survey provides background concepts,empirical evidence, and practical guidelines to design/implement efficient FUschemes. Our study includes a detailed analysis of the metrics for evaluatingunlearning in FL and presents an in-depth literature review categorizingstate-of-the-art FU contributions under a novel taxonomy. Finally, we outlinethe most relevant and still open technical challenges, by identifying the mostpromising research directions in the field.</description><author>Nicolò Romandini, Alessio Mora, Carlo Mazzocca, Rebecca Montanari, Paolo Bellavista</author><pubDate>Fri, 16 Feb 2024 15:34:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05146v2</guid></item></channel></rss>