<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 12 Feb 2024 06:00:35 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Feedback Loops With Language Models Drive In-Context Reward Hacking</title><link>http://arxiv.org/abs/2402.06627v1</link><description>Language models influence the external world: they query APIs that read andwrite to web pages, generate content that shapes human behavior, and run systemcommands as autonomous agents. These interactions form feedback loops: LLMoutputs affect the world, which in turn affect subsequent LLM outputs. In thiswork, we show that feedback loops can cause in-context reward hacking (ICRH),where the LLM at test-time optimizes a (potentially implicit) objective butcreates negative side effects in the process. For example, consider an LLMagent deployed to increase Twitter engagement; the LLM may retrieve itsprevious tweets into the context window and make them more controversial,increasing engagement but also toxicity. We identify and study two processesthat lead to ICRH: output-refinement and policy-refinement. For theseprocesses, evaluations on static datasets are insufficient -- they miss thefeedback effects and thus cannot capture the most harmful behavior. Inresponse, we provide three recommendations for evaluation to capture moreinstances of ICRH. As AI development accelerates, the effects of feedback loopswill proliferate, increasing the need to understand their role in shaping LLMbehavior.</description><author>Alexander Pan, Erik Jones, Meena Jagadeesan, Jacob Steinhardt</author><pubDate>Fri, 09 Feb 2024 18:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06627v1</guid></item><item><title>Understanding the Effects of Iterative Prompting on Truthfulness</title><link>http://arxiv.org/abs/2402.06625v1</link><description>The development of Large Language Models (LLMs) has notably transformednumerous sectors, offering impressive text generation capabilities. Yet, thereliability and truthfulness of these models remain pressing concerns. To thisend, we investigate iterative prompting, a strategy hypothesized to refine LLMresponses, assessing its impact on LLM truthfulness, an area which has not beenthoroughly explored. Our extensive experiments delve into the intricacies ofiterative prompting variants, examining their influence on the accuracy andcalibration of model responses. Our findings reveal that naive promptingmethods significantly undermine truthfulness, leading to exacerbatedcalibration errors. In response to these challenges, we introduce severalprompting variants designed to address the identified issues. These variantsdemonstrate marked improvements over existing baselines, signaling a promisingdirection for future research. Our work provides a nuanced understanding ofiterative prompting and introduces novel approaches to enhance the truthfulnessof LLMs, thereby contributing to the development of more accurate andtrustworthy AI systems.</description><author>Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju</author><pubDate>Fri, 09 Feb 2024 18:57:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06625v1</guid></item><item><title>A two-stage algorithm in evolutionary product unit neural networks for classification</title><link>http://arxiv.org/abs/2402.06622v1</link><description>This paper presents a procedure to add broader diversity at the beginning ofthe evolutionary process. It consists of creating two initial populations withdifferent parameter settings, evolving them for a small number of generations,selecting the best individuals from each population in the same proportion andcombining them to constitute a new initial population. At this point the mainloop of an evolutionary algorithm is applied to the new population. The resultsshow that our proposal considerably improves both the efficiency of previousmethodologies and also, significantly, their efficacy in most of the data sets.We have carried out our experimentation on twelve data sets from the UCIrepository and two complex real-world problems which differ in their number ofinstances, features and classes.</description><author>Antonio J. Tallón-Ballesteros, César Hervás-Martínez</author><pubDate>Fri, 09 Feb 2024 18:56:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06622v1</guid></item><item><title>Spacetime-Efficient Low-Depth Quantum State Preparation with Applications</title><link>http://arxiv.org/abs/2303.02131v3</link><description>We propose a novel deterministic method for preparing arbitrary quantumstates. When our protocol is compiled into CNOT and arbitrary single-qubitgates, it prepares an $N$-dimensional state in depth $O(\log(N))$ and spacetimeallocation (a metric that accounts for the fact that oftentimes some ancillaqubits need not be active for the entire circuit) $O(N)$, which are bothoptimal. When compiled into the $\{\mathrm{H,S,T,CNOT}\}$ gate set, we showthat it requires asymptotically fewer quantum resources than previous methods.Specifically, it prepares an arbitrary state up to error $\epsilon$ withoptimal depth of $O(\log(N) + \log (1/\epsilon))$ and spacetime allocation$O(N\log(\log(N)/\epsilon))$, improving over $O(\log(N)\log(\log(N)/\epsilon))$ and $O(N\log(N/\epsilon))$, respectively. We illustrate how thereduced spacetime allocation of our protocol enables rapid preparation of manydisjoint states with only constant-factor ancilla overhead -- $O(N)$ ancillaqubits are reused efficiently to prepare a product state of $w$ $N$-dimensionalstates in depth $O(w + \log(N))$ rather than $O(w\log(N))$, achievingeffectively constant depth per state. We highlight several applications wherethis ability would be useful, including quantum machine learning, Hamiltoniansimulation, and solving linear systems of equations. We provide quantum circuitdescriptions of our protocol, detailed pseudocode, and gate-levelimplementation examples using Braket.</description><author>Kaiwen Gui, Alexander M. Dalzell, Alessandro Achille, Martin Suchara, Frederic T. Chong</author><pubDate>Fri, 09 Feb 2024 18:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02131v3</guid></item><item><title>Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning</title><link>http://arxiv.org/abs/2402.06619v1</link><description>Datasets are foundational to many breakthroughs in modern artificialintelligence. Many recent achievements in the space of natural languageprocessing (NLP) can be attributed to the finetuning of pre-trained models on adiverse set of tasks that enables a large language model (LLM) to respond toinstructions. Instruction fine-tuning (IFT) requires specifically constructedand annotated datasets. However, existing datasets are almost all in theEnglish language. In this work, our primary goal is to bridge the language gapby building a human-curated instruction-following dataset spanning 65languages. We worked with fluent speakers of languages from around the world tocollect natural instances of instructions and completions. Furthermore, wecreate the most extensive multilingual collection to date, comprising 513million instances through templating and translating existing datasets across114 languages. In total, we contribute four key resources: we develop andopen-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection,and the Aya Evaluation Suite. The Aya initiative also serves as a valuable casestudy in participatory research, involving collaborators from 119 countries. Wesee this as a valuable framework for future research collaborations that aim tobridge gaps in resources.</description><author>Shivalika Singh, Freddie Vargus, Daniel Dsouza, Börje F. Karlsson, Abinaya Mahendiran, Wei-Yin Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura OMahony, Mike Zhang, Ramith Hettiarachchi, Joseph Wilson, Marina Machado, Luisa Souza Moura, Dominik Krzemiński, Hakimeh Fadaei, Irem Ergün, Ifeoma Okoh, Aisha Alaagib, Oshan Mudannayake, Zaid Alyafeai, Vu Minh Chien, Sebastian Ruder, Surya Guthikonda, Emad A. Alghamdi, Sebastian Gehrmann, Niklas Muennighoff, Max Bartolo, Julia Kreutzer, Ahmet Üstün, Marzieh Fadaee, Sara Hooker</author><pubDate>Fri, 09 Feb 2024 18:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06619v1</guid></item><item><title>FaBERT: Pre-training BERT on Persian Blogs</title><link>http://arxiv.org/abs/2402.06617v1</link><description>We introduce FaBERT, a Persian BERT-base model pre-trained on the HmBlogscorpus, encompassing both informal and formal Persian texts. FaBERT is designedto excel in traditional Natural Language Understanding (NLU) tasks, addressingthe intricacies of diverse sentence structures and linguistic styles prevalentin the Persian language. In our comprehensive evaluation of FaBERT on 12datasets in various downstream tasks, encompassing Sentiment Analysis (SA),Named Entity Recognition (NER), Natural Language Inference (NLI), QuestionAnswering (QA), and Question Paraphrasing (QP), it consistently demonstratedimproved performance, all achieved within a compact model size. The findingshighlight the importance of utilizing diverse and cleaned corpora, such asHmBlogs, to enhance the performance of language models like BERT in PersianNatural Language Processing (NLP) applications. FaBERT is openly accessible athttps://huggingface.co/sbunlp/fabert</description><author>Mostafa Masumi, Seyed Soroush Majd, Mehrnoush Shamsfard, Hamid Beigy</author><pubDate>Fri, 09 Feb 2024 18:50:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06617v1</guid></item><item><title>The Complexity of Sequential Prediction in Dynamical Systems</title><link>http://arxiv.org/abs/2402.06614v1</link><description>We study the problem of learning to predict the next state of a dynamicalsystem when the underlying evolution function is unknown. Unlike previous work,we place no parametric assumptions on the dynamical system, and study theproblem from a learning theory perspective. We define new combinatorialmeasures and dimensions and show that they quantify the optimal mistake andregret bounds in the realizable and agnostic setting respectively.</description><author>Vinod Raman, Unique Subedi, Ambuj Tewari</author><pubDate>Fri, 09 Feb 2024 18:45:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06614v1</guid></item><item><title>Image-based Deep Learning for the time-dependent prediction of fresh concrete properties</title><link>http://arxiv.org/abs/2402.06611v1</link><description>Increasing the degree of digitisation and automation in the concreteproduction process can play a crucial role in reducing the CO$_2$ emissionsthat are associated with the production of concrete. In this paper, a method ispresented that makes it possible to predict the properties of fresh concreteduring the mixing process based on stereoscopic image sequences of theconcretes flow behaviour. A Convolutional Neural Network (CNN) is used for theprediction, which receives the images supported by information on the mixdesign as input. In addition, the network receives temporal information in theform of the time difference between the time at which the images are taken andthe time at which the reference values of the concretes are carried out. Withthis temporal information, the network implicitly learns the time-dependentbehaviour of the concretes properties. The network predicts the slump flowdiameter, the yield stress and the plastic viscosity. The time-dependentprediction potentially opens up the pathway to determine the temporaldevelopment of the fresh concrete properties already during mixing. Thisprovides a huge advantage for the concrete industry. As a result,countermeasures can be taken in a timely manner. It is shown that an approachbased on depth and optical flow images, supported by information of the mixdesign, achieves the best results.</description><author>Max Meyer, Amadeus Langer, Max Mehltretter, Dries Beyer, Max Coenen, Tobias Schack, Michael Haist, Christian Heipke</author><pubDate>Fri, 09 Feb 2024 18:42:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06611v1</guid></item><item><title>TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations</title><link>http://arxiv.org/abs/2402.06608v1</link><description>We study the problem of generating plans for given natural language planningtask requests. On one hand, LLMs excel at natural language processing but donot perform well on planning. On the other hand, classical planning tools excelat planning tasks but require input in a structured language such as thePlanning Domain Definition Language (PDDL). We leverage the strengths of boththe techniques by using an LLM for generating the PDDL representation (taskPDDL) of planning task requests followed by using a classical planner forcomputing a plan. Unlike previous approaches that use LLMs for generating taskPDDLs directly, our approach comprises of (a) translate: using an LLM only forgenerating a logically interpretable intermediate representation of naturallanguage task descriptions, (b) infer: deriving additional logically dependentinformation from the intermediate representation using a logic reasoner(currently, Answer Set Programming solver), and (c) compile: generating thetarget task PDDL from the base and inferred information. We observe that usingan LLM to only output the intermediate representation significantly reduces LLMerrors. Consequently, TIC approach achieves, for at least one LLM, highaccuracy on task PDDL generation for all seven domains of our evaluationdataset.</description><author>Sudhir Agarwal, Anu Sreepathy</author><pubDate>Fri, 09 Feb 2024 18:39:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06608v1</guid></item><item><title>LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model</title><link>http://arxiv.org/abs/2401.02330v3</link><description>In this paper, we introduce LLaVA-$\phi$ (LLaVA-Phi), an efficientmulti-modal assistant that harnesses the power of the recently advanced smalllanguage model, Phi-2, to facilitate multi-modal dialogues. LLaVA-Phi marks anotable advancement in the realm of compact multi-modal models. It demonstratesthat even smaller language models, with as few as 2.7B parameters, caneffectively engage in intricate dialogues that integrate both textual andvisual elements, provided they are trained with high-quality corpora. Our modeldelivers commendable performance on publicly available benchmarks thatencompass visual comprehension, reasoning, and knowledge-based perception.Beyond its remarkable performance in multi-modal dialogue tasks, our modelopens new avenues for applications in time-sensitive environments and systemsthat require real-time interaction, such as embodied agents. It highlights thepotential of smaller language models to achieve sophisticated levels ofunderstanding and interaction, while maintaining greater resourceefficiency.The project is available at {https://github.com/zhuyiche/llava-phi}.</description><author>Yichen Zhu, Minjie Zhu, Ning Liu, Zhicai Ou, Xiaofeng Mou, Jian Tang</author><pubDate>Fri, 09 Feb 2024 18:38:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02330v3</guid></item><item><title>Apple Tasting: Combinatorial Dimensions and Minimax Rates</title><link>http://arxiv.org/abs/2310.19064v2</link><description>In online binary classification under \emph{apple tasting} feedback, thelearner only observes the true label if it predicts ``1". First studied by\cite{helmbold2000apple}, we revisit this classical partial-feedback settingand study online learnability from a combinatorial perspective. We show thatthe Littlestone dimension continues to provide a tight quantitativecharacterization of apple tasting in the agnostic setting, closing an openquestion posed by \cite{helmbold2000apple}. In addition, we give a newcombinatorial parameter, called the Effective width, that tightly quantifiesthe minimax expected mistakes in the realizable setting. As a corollary, we usethe Effective width to establish a \emph{trichotomy} of the minimax expectednumber of mistakes in the realizable setting. In particular, we show that inthe realizable setting, the expected number of mistakes of any learner, underapple tasting feedback, can be $\Theta(1), \Theta(\sqrt{T})$, or $\Theta(T)$.This is in contrast to the full-information realizable setting where only$\Theta(1)$ and $\Theta(T)$ are possible.</description><author>Vinod Raman, Unique Subedi, Ananth Raman, Ambuj Tewari</author><pubDate>Fri, 09 Feb 2024 18:35:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19064v2</guid></item><item><title>RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization</title><link>http://arxiv.org/abs/2402.06606v1</link><description>The rise of IoT devices has prompted the demand for deploying machinelearning at-the-edge with real-time, efficient, and secure data processing. Inthis context, implementing machine learning (ML) models with real-valued weightparameters can prove to be impractical particularly for large models, and thereis a need to train models with quantized discrete weights. At the same time,these low-dimensional models also need to preserve privacy of the underlyingdataset. In this work, we present RQP-SGD, a new approach forprivacy-preserving quantization to train machine learning models for low-memoryML-at-the-edge. This approach combines differentially private stochasticgradient descent (DP-SGD) with randomized quantization, providing a measurableprivacy guarantee in machine learning. In particular, we study the utilityconvergence of implementing RQP-SGD on ML tasks with convex objectives andquantization constraints and demonstrate its efficacy over deterministicquantization. Through experiments conducted on two datasets, we show thepractical effectiveness of RQP-SGD.</description><author>Ce Feng, Parv Venkitasubramaniam</author><pubDate>Fri, 09 Feb 2024 18:34:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06606v1</guid></item><item><title>A Combinatorial Characterization of Supervised Online Learnability</title><link>http://arxiv.org/abs/2307.03816v2</link><description>We study the online learnability of hypothesis classes with respect toarbitrary, but bounded loss functions. No characterization of onlinelearnability is known at this level of generality. We give a newscale-sensitive combinatorial dimension, named the sequential minimaxdimension, and show that it gives a tight quantitative characterization ofonline learnability. In addition, we show that the sequential minimax dimensionsubsumes most existing combinatorial dimensions in online learning theory.</description><author>Vinod Raman, Unique Subedi, Ambuj Tewari</author><pubDate>Fri, 09 Feb 2024 18:27:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03816v2</guid></item><item><title>On the Out-Of-Distribution Generalization of Multimodal Large Language Models</title><link>http://arxiv.org/abs/2402.06599v1</link><description>We investigate the generalization boundaries of current Multimodal LargeLanguage Models (MLLMs) via comprehensive evaluation under out-of-distributionscenarios and domain-specific tasks. We evaluate their zero-shot generalizationacross synthetic images, real-world distributional shifts, and specializeddatasets like medical and molecular imagery. Empirical results indicate thatMLLMs struggle with generalization beyond common training domains, limitingtheir direct application without adaptation. To understand the cause ofunreliable performance, we analyze three hypotheses: semanticmisinterpretation, visual feature extraction insufficiency, and mappingdeficiency. Results identify mapping deficiency as the primary hurdle. Toaddress this problem, we show that in-context learning (ICL) can significantlyenhance MLLMs' generalization, opening new avenues for overcominggeneralization barriers. We further explore the robustness of ICL underdistribution shifts and show its vulnerability to domain shifts, label shifts,and spurious correlation shifts between in-context examples and test data.</description><author>Xingxuan Zhang, Jiansheng Li, Wenjing Chu, Junjia Hai, Renzhe Xu, Yuqing Yang, Shikai Guan, Jiazheng Xu, Peng Cui</author><pubDate>Fri, 09 Feb 2024 18:21:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06599v1</guid></item><item><title>A Primal-Dual Algorithm for Hybrid Federated Learning</title><link>http://arxiv.org/abs/2210.08106v3</link><description>Very few methods for hybrid federated learning, where clients only holdsubsets of both features and samples, exist. Yet, this scenario is extremelyimportant in practical settings. We provide a fast, robust algorithm for hybridfederated learning that hinges on Fenchel Duality. We prove the convergence ofthe algorithm to the same solution as if the model is trained centrally in avariety of practical regimes. Furthermore, we provide experimental results thatdemonstrate the performance improvements of the algorithm over a commonly usedmethod in federated learning, FedAvg, and an existing hybrid FL algorithm,HyFEM. We also provide privacy considerations and necessary steps to protectclient data.</description><author>Tom Overman, Garrett Blum, Diego Klabjan</author><pubDate>Fri, 09 Feb 2024 18:21:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.08106v3</guid></item><item><title>Understanding the Weakness of Large Language Model Agents within a Complex Android Environment</title><link>http://arxiv.org/abs/2402.06596v1</link><description>Large language models (LLMs) have empowered intelligent agents to executeintricate tasks within domain-specific software such as browsers and games.However, when applied to general-purpose software systems like operatingsystems, LLM agents face three primary challenges. Firstly, the action space isvast and dynamic, posing difficulties for LLM agents to maintain an up-to-dateunderstanding and deliver accurate responses. Secondly, real-world tasks oftenrequire inter-application cooperation}, demanding farsighted planning from LLMagents. Thirdly, agents need to identify optimal solutions aligning with userconstraints, such as security concerns and preferences. These challengesmotivate AndroidArena, an environment and benchmark designed to evaluate LLMagents on a modern operating system. To address high-cost of manpower, wedesign a scalable and semi-automated method to construct the benchmark. In thetask evaluation, AndroidArena incorporates accurate and adaptive metrics toaddress the issue of non-unique solutions. Our findings reveal that evenstate-of-the-art LLM agents struggle in cross-APP scenarios and adhering tospecific constraints. Additionally, we identify a lack of four keycapabilities, i.e., understanding, reasoning, exploration, and reflection, asprimary reasons for the failure of LLM agents. Furthermore, we provideempirical analysis on the failure of reflection, and improve the success rateby 27% with our proposed exploration strategy. This work is the first topresent valuable insights in understanding fine-grained weakness of LLM agents,and offers a path forward for future research in this area. Environment,benchmark, and evaluation code for AndroidArena are released athttps://github.com/AndroidArenaAgent/AndroidArena.</description><author>Mingzhe Xing, Rongkai Zhang, Hui Xue, Qi Chen, Fan Yang, Zhen Xiao</author><pubDate>Fri, 09 Feb 2024 18:19:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06596v1</guid></item><item><title>MAIRA-1: A specialised large multimodal model for radiology report generation</title><link>http://arxiv.org/abs/2311.13668v2</link><description>We present a radiology-specific multimodal model for the task for generatingradiological reports from chest X-rays (CXRs). Our work builds on the idea thatlarge language model(s) can be equipped with multimodal capabilities throughalignment with pre-trained vision encoders. On natural images, this has beenshown to allow multimodal models to gain image understanding and descriptioncapabilities. Our proposed model (MAIRA-1) leverages a CXR-specific imageencoder in conjunction with a fine-tuned large language model based onVicuna-7B, and text-based data augmentation, to produce reports withstate-of-the-art quality. In particular, MAIRA-1 significantly improves on theradiologist-aligned RadCliQ metric and across all lexical metrics considered.Manual review of model outputs demonstrates promising fluency and accuracy ofgenerated reports while uncovering failure modes not captured by existingevaluation practices. More information and resources can be found on theproject website: https://aka.ms/maira.</description><author>Stephanie L. Hyland, Shruthi Bannur, Kenza Bouzid, Daniel C. Castro, Mercy Ranjit, Anton Schwaighofer, Fernando Pérez-García, Valentina Salvatelli, Shaury Srivastav, Anja Thieme, Noel Codella, Matthew P. Lungren, Maria Teodora Wetscherek, Ozan Oktay, Javier Alvarez-Valle</author><pubDate>Fri, 09 Feb 2024 18:16:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13668v2</guid></item><item><title>Self-consistent context aware conformer transducer for speech recognition</title><link>http://arxiv.org/abs/2402.06592v1</link><description>We propose a novel neural network architecture based on conformer transducerthat adds contextual information flow to the ASR systems. Our method improvesthe accuracy of recognizing uncommon words while not harming the word errorrate of regular words. We explore the uncommon words accuracy improvement whenwe use the new model and/or shallow fusion with context language model. Wefound that combination of both provides cumulative gain in uncommon wordsrecognition accuracy.</description><author>Konstantin Kolokolov, Pavel Pekichev, Karthik Raghunathan</author><pubDate>Fri, 09 Feb 2024 18:12:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06592v1</guid></item><item><title>Predictive representations: building blocks of intelligence</title><link>http://arxiv.org/abs/2402.06590v1</link><description>Adaptive behavior often requires predicting future events. The theory ofreinforcement learning prescribes what kinds of predictive representations areuseful and how to compute them. This paper integrates these theoretical ideaswith work on cognition and neuroscience. We pay special attention to thesuccessor representation (SR) and its generalizations, which have been widelyapplied both as engineering tools and models of brain function. Thisconvergence suggests that particular kinds of predictive representations mayfunction as versatile building blocks of intelligence.</description><author>Wilka Carvalho, Momchil S. Tomov, William de Cothi, Caswell Barry, Samuel J. Gershman</author><pubDate>Fri, 09 Feb 2024 18:10:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06590v1</guid></item><item><title>Adaptive Experiment Design with Synthetic Controls</title><link>http://arxiv.org/abs/2401.17205v2</link><description>Clinical trials are typically run in order to understand the effects of a newtreatment on a given population of patients. However, patients in largepopulations rarely respond the same way to the same treatment. Thisheterogeneity in patient responses necessitates trials that investigate effectson multiple subpopulations - especially when a treatment has marginal or nobenefit for the overall population but might have significant benefit for aparticular subpopulation. Motivated by this need, we propose Syntax, anexploratory trial design that identifies subpopulations with positive treatmenteffect among many subpopulations. Syntax is sample efficient as it (i) recruitsand allocates patients adaptively and (ii) estimates treatment effects byforming synthetic controls for each subpopulation that combines control samplesfrom other subpopulations. We validate the performance of Syntax and provideinsights into when it might have an advantage over conventional trial designsthrough experiments.</description><author>Alihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar</author><pubDate>Fri, 09 Feb 2024 18:08:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17205v2</guid></item><item><title>G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German</title><link>http://arxiv.org/abs/2402.06584v1</link><description>The advancement of natural language processing has paved the way forautomated scoring systems in various languages, such as German (e.g., GermanBERT [G-BERT]). Automatically scoring written responses to science questions inGerman is a complex task and challenging for standard G-BERT as they lackcontextual knowledge in the science domain and may be unaligned with studentwriting styles. This paper developed a contextualized German Science EducationBERT (G-SciEdBERT), an innovative large language model tailored for scoringGerman-written responses to science tasks. Using G-BERT, we pre-trainedG-SciEdBERT on a corpus of 50K German written science responses with 5M tokensto the Programme for International Student Assessment (PISA) 2015. Wefine-tuned G-SciEdBERT on 59 assessment items and examined the scoringaccuracy. We then compared its performance with G-BERT. Our findings reveal asubstantial improvement in scoring accuracy with G-SciEdBERT, demonstrating a10% increase of quadratic weighted kappa compared to G-BERT (mean accuracydifference = 0.096, SD = 0.024). These insights underline the significance ofspecialized language models like G-SciEdBERT, which is trained to enhance theaccuracy of automated scoring, offering a substantial contribution to the fieldof AI in education.</description><author>Ehsan Latif, Gyeong-Geon Lee, Knut Neuman, Tamara Kastorff, Xiaoming Zhai</author><pubDate>Fri, 09 Feb 2024 18:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06584v1</guid></item><item><title>More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation</title><link>http://arxiv.org/abs/2402.06581v1</link><description>Semantic segmentation is a key prerequisite to robust image understanding forapplications in \acrlong{ai} and Robotics. \acrlong{fss}, in particular,concerns the extension and optimization of traditional segmentation methods inchallenging conditions where limited training examples are available. Apredominant approach in \acrlong{fss} is to rely on a single backbone forvisual feature extraction. Choosing which backbone to leverage is a decidingfactor contributing to the overall performance. In this work, we interrogate onwhether fusing features from different backbones can improve the ability of\acrlong{fss} models to capture richer visual features. To tackle thisquestion, we propose and compare two ensembling techniques-Independent Votingand Feature Fusion. Among the available \acrlong{fss} methods, we implement theproposed ensembling techniques on PANet. The module dedicated to predictingsegmentation masks from the backbone embeddings in PANet avoids trainableparameters, creating a controlled `in vitro' setting for isolating the impactof different ensembling strategies. Leveraging the complementary strengths ofdifferent backbones, our approach outperforms the original single-backbonePANet across standard benchmarks even in challenging one-shot learningscenarios. Specifically, it achieved a performance improvement of +7.37\% onPASCAL-5\textsuperscript{i} and of +10.68\% on COCO-20\textsuperscript{i} inthe top-performing scenario where three backbones are combined. These results,together with the qualitative inspection of the predicted subject masks,suggest that relying on multiple backbones in PANet leads to a morecomprehensive feature representation, thus expediting the successfulapplication of \acrlong{fss} methods in challenging, data-scarce environments.</description><author>Nico Catalano, Alessandro Maranelli, Agnese Chiatti, Matteo Matteucci</author><pubDate>Fri, 09 Feb 2024 18:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06581v1</guid></item><item><title>SliceGPT: Compress Large Language Models by Deleting Rows and Columns</title><link>http://arxiv.org/abs/2401.15024v2</link><description>Large language models have become the cornerstone of natural languageprocessing, but their use comes with substantial costs in terms of compute andmemory resources. Sparsification provides a solution to alleviate theseresource constraints, and recent works have shown that trained models can besparsified post-hoc. Existing sparsification techniques face challenges as theyneed additional data structures and offer constrained speedup with currenthardware. In this paper we present SliceGPT, a new post-training sparsificationscheme which replaces each weight matrix with a smaller (dense) matrix,reducing the embedding dimension of the network. Through extensiveexperimentation, we show that SliceGPT can remove up to 25% of the modelparameters (including embeddings) for LLAMA2-70B, OPT 66B and Phi-2 modelswhile maintaining 99%, 99% and 90% zero-shot task performance of the densemodel respectively. Our sliced models run on fewer GPUs and run faster withoutany additional code optimization: on 24GB consumer GPUs we reduce the totalcompute for inference on LLAMA2-70B to 64% of that of the dense model; on 40GBA100 GPUs we reduce it to 66%. We offer a new insight, computational invariancein transformer networks, which enables SliceGPT and we hope it will inspire andenable future avenues to reduce memory and computation demands for pre-trainedmodels. Code is available at:https://github.com/microsoft/TransformerCompression</description><author>Saleh Ashkboos, Maximilian L. Croci, Marcelo Gennari do Nascimento, Torsten Hoefler, James Hensman</author><pubDate>Fri, 09 Feb 2024 17:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15024v2</guid></item><item><title>Knowledge Distillation of LLM for Automatic Scoring of Science Education Assessments</title><link>http://arxiv.org/abs/2312.15842v2</link><description>This study proposes a method for knowledge distillation (KD) of fine-tunedLarge Language Models (LLMs) into smaller, more efficient, and accurate neuralnetworks. We specifically target the challenge of deploying these models onresource-constrained devices. Our methodology involves training the smallerstudent model (Neural Network) using the prediction probabilities (as softlabels) of the LLM, which serves as a teacher model. This is achieved through aspecialized loss function tailored to learn from the LLM's outputprobabilities, ensuring that the student model closely mimics the teacher'sperformance. To validate the performance of the KD approach, we utilized alarge dataset, 7T, containing 6,684 student-written responses to sciencequestions and three mathematical reasoning datasets with student-writtenresponses graded by human experts. We compared accuracy with state-of-the-art(SOTA) distilled models, TinyBERT, and artificial neural network (ANN) models.Results have shown that the KD approach has 1% and 4% higher scoring accuracythan ANN and TinyBERT and comparable accuracy to the teacher model.Furthermore, the student model size is 0.02M, 10,000 times smaller inparameters and x10 faster in inferencing than the teacher model and TinyBERT,respectively. The significance of this research lies in its potential to makeadvanced AI technologies accessible in typical educational settings,particularly for automatic scoring.</description><author>Ehsan Latif, Luyang Fang, Ping Ma, Xiaoming Zhai</author><pubDate>Fri, 09 Feb 2024 17:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15842v2</guid></item><item><title>SAE: Single Architecture Ensemble Neural Networks</title><link>http://arxiv.org/abs/2402.06580v1</link><description>Ensembles of separate neural networks (NNs) have shown superior accuracy andconfidence calibration over single NN across tasks. Recent methods compressensembles within a single network via early exits or multi-input multi-outputframeworks. However, the landscape of these methods is fragmented thus far,making it difficult to choose the right approach for a given task. Furthermore,the algorithmic performance of these methods is behind the ensemble of separateNNs and requires extensive architecture tuning. We propose a novel methodologyunifying these approaches into a Single Architecture Ensemble (SAE). Our methodlearns the optimal number and depth of exits per ensemble input in a single NN.This enables the SAE framework to flexibly tailor its configuration for a givenarchitecture or application. We evaluate SAEs on image classification andregression across various network architecture types and sizes. We demonstratecompetitive accuracy or confidence calibration to baselines while reducing thecompute operations or parameter count by up to $1.5{\sim}3.7\times$.</description><author>Martin Ferianc, Hongxiang Fan, Miguel Rodrigues</author><pubDate>Fri, 09 Feb 2024 17:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06580v1</guid></item><item><title>On the Universality of Coupling-based Normalizing Flows</title><link>http://arxiv.org/abs/2402.06578v1</link><description>We present a novel theoretical framework for understanding the expressivepower of coupling-based normalizing flows such as RealNVP. Despite theirprevalence in scientific applications, a comprehensive understanding ofcoupling flows remains elusive due to their restricted architectures. Existingtheorems fall short as they require the use of arbitrarily ill-conditionedneural networks, limiting practical applicability. Additionally, we demonstratethat these constructions inherently lead to volume-preserving flows, a propertywhich we show to be a fundamental constraint for expressivity. We propose a newdistributional universality theorem for coupling-based normalizing flows, whichovercomes several limitations of prior work. Our results support the generalwisdom that the coupling architecture is expressive and provide a nuanced viewfor choosing the expressivity of coupling functions, bridging a gap betweenempirical results and theoretical understanding.</description><author>Felix Draxler, Stefan Wahl, Christoph Schnörr, Ullrich Köthe</author><pubDate>Fri, 09 Feb 2024 17:51:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06578v1</guid></item><item><title>Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet</title><link>http://arxiv.org/abs/2401.03630v2</link><description>With the explosive influence caused by the success of large language models(LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent workshowing that foundation models can be used to solve a large variety of tasks.However, there is very limited work that shares insights on multi-agentplanning. Multi-agent planning is different from other domains by combining thedifficulty of multi-agent coordination and planning, and making it hard toleverage external tools to facilitate the reasoning needed. In this paper, wefocus on the problem of multi-agent path finding (MAPF), which is also known asmulti-robot route planning, and study the performance of solving MAPF withLLMs. We first show the motivating success on an empty room map withoutobstacles, then the failure to plan on the harder room map and maze map of thestandard MAPF benchmark. We present our position on why directly solving MAPFwith LLMs has not been successful yet, and we use various experiments tosupport our hypothesis. Based on our results, we discussed how researchers withdifferent backgrounds could help with this problem from different perspectives.</description><author>Weizhe Chen, Sven Koenig, Bistra Dilkina</author><pubDate>Fri, 09 Feb 2024 17:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03630v2</guid></item><item><title>Optimizing Floors in First Price Auctions: an Empirical Study of Yahoo Advertising</title><link>http://arxiv.org/abs/2302.06018v2</link><description>Floors (also known as reserve prices) help publishers to increase theexpected revenue of their ad space, which is usually sold via auctions. Floorsare defined as the minimum bid that a seller (it can be a publisher or an adexchange) is willing to accept for the inventory opportunity. In this paper, wepresent a model to set floors in first price auctions, and discuss the impactof its implementation on Yahoo sites. The model captures importantcharacteristics of the online advertising industry. For instance, some biddersimpose restrictions on how ad exchanges can handle data from bidders,conditioning the model choice to set reserve prices. Our solution inducesbidders to change their bidding behavior as a response to the floors enclosedin the bid request, helping online publishers to increase their ad revenue. The outlined methodology has been implemented at Yahoo with remarkableresults. The annualized incremental revenue is estimated at +1.3% on Yahoodisplay inventory, and +2.5% on video ad inventory. These are non-negligiblenumbers in the multi-million Yahoo ad business.</description><author>Miguel Alcobendas, Jonathan Ji, Hemakumar Gokulakannan, Dawit Wami, Boris Kapchits, Emilien Pouradier Duteil, Korby Satow, Maria Rosario Levy Roman, Oriol Diaz, Amado A. Diaz Jr., Rabi Kavoori</author><pubDate>Fri, 09 Feb 2024 17:44:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06018v2</guid></item><item><title>Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control</title><link>http://arxiv.org/abs/2402.06570v1</link><description>Learning a universal policy across different robot morphologies cansignificantly improve learning efficiency and enable zero-shot generalizationto unseen morphologies. However, learning a highly performant universal policyrequires sophisticated architectures like transformers (TF) that have largermemory and computational cost than simpler multi-layer perceptrons (MLP). Toachieve both good performance like TF and high efficiency like MLP at inferencetime, we propose HyperDistill, which consists of: (1) A morphology-conditionedhypernetwork (HN) that generates robot-wise MLP policies, and (2) A policydistillation approach that is essential for successful training. We show thaton UNIMAL, a benchmark with hundreds of diverse morphologies, HyperDistillperforms as well as a universal TF teacher policy on both training and unseentest robots, but reduces model size by 6-14 times, and computational cost by67-160 times in different environments. Our analysis attributes the efficiencyadvantage of HyperDistill at inference time to knowledge decoupling, i.e., theability to decouple inter-task and intra-task knowledge, a general principlethat could also be applied to improve inference efficiency in other domains.</description><author>Zheng Xiong, Risto Vuorio, Jacob Beck, Matthieu Zimmer, Kun Shao, Shimon Whiteson</author><pubDate>Fri, 09 Feb 2024 17:40:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06570v1</guid></item><item><title>Constrained multi-objective optimization for multi-UAV planning</title><link>http://arxiv.org/abs/2402.06568v1</link><description>Over the last decade, developments in unmanned aerial vehicles (UAVs) hasgreatly increased, and they are being used in many fields includingsurveillance, crisis management or automated mission planning. This last fieldimplies the search of plans for missions with multiple tasks, UAVs and groundcontrol stations; and the optimization of several objectives, includingmakespan, fuel consumption or cost, among others. In this work, this problemhas been solved using a multi-objective evolutionary algorithm combined with aconstraint satisfaction problem model, which is used in the fitness function ofthe algorithm. The algorithm has been tested on several missions of increasingcomplexity, and the computational complexity of the different elementconsidered in the missions has been studied.</description><author>Cristian Ramirez-Atencia, David Camacho</author><pubDate>Fri, 09 Feb 2024 17:39:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06568v1</guid></item><item><title>Teaching Probabilistic Logical Reasoning to Transformers</title><link>http://arxiv.org/abs/2305.13179v2</link><description>In this paper, we evaluate the capability of transformer-based languagemodels in making inferences over uncertain text that includes uncertain rulesof reasoning. We cover both Pre-trained Language Models (PLMs) and generativeLarge Language Models (LLMs). Our evaluation results show that both generationsof language models struggle with reasoning over uncertain text. We propose anovel end-to-end fine-tuning approach, Probabilistic Constraint Training (PCT),that utilizes probabilistic logical rules as constraints in the fine-tuningphase without relying on these rules in the inference stage. To assess theeffectiveness of PCT, we utilize the related corpora and, additionally, createa new and more challenging benchmark that, unlike the previous ones, usesinstance-specific rules. Our study demonstrates that PCT improves thetransformer-based language model's intrinsic reasoning and makes theirprobabilistic logical reasoning process more explicit and explainable.Furthermore, PCT equips these models to effectively handle novel situations,including higher reasoning depth, new domains, and complex probabilisticstructures.</description><author>Aliakbar Nafar, Kristen Brent Venable, Parisa Kordjamshidi</author><pubDate>Fri, 09 Feb 2024 17:29:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13179v2</guid></item><item><title>What is Hiding in Medicine's Dark Matter? Learning with Missing Data in Medical Practices</title><link>http://arxiv.org/abs/2402.06563v1</link><description>Electronic patient records (EPRs) produce a wealth of data but containsignificant missing information. Understanding and handling this missing datais an important part of clinical data analysis and if left unaddressed couldresult in bias in analysis and distortion in critical conclusions. Missing datamay be linked to health care professional practice patterns and imputation ofmissing data can increase the validity of clinical decisions. This studyfocuses on statistical approaches for understanding and interpreting themissing data and machine learning based clinical data imputation using a singlecentre's paediatric emergency data and the data from UK's largest clinicalaudit for traumatic injury database (TARN). In the study of 56,961 data pointsrelated to initial vital signs and observations taken on children presenting toan Emergency Department, we have shown that missing data are likely to benon-random and how these are linked to health care professional practicepatterns. We have then examined 79 TARN fields with missing values for 5,791trauma cases. Singular Value Decomposition (SVD) and k-Nearest Neighbour (kNN)based missing data imputation methods are used and imputation results againstthe original dataset are compared and statistically tested. We have concludedthat the 1NN imputer is the best imputation which indicates a usual pattern ofclinical decision making: find the most similar patients and take theirattributes as imputation.</description><author>Neslihan Suzen, Evgeny M. Mirkes, Damian Roland, Jeremy Levesley, Alexander N. Gorban, Tim J. Coats</author><pubDate>Fri, 09 Feb 2024 17:27:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06563v1</guid></item><item><title>Safe Guaranteed Exploration for Non-linear Systems</title><link>http://arxiv.org/abs/2402.06562v1</link><description>Safely exploring environments with a-priori unknown constraints is afundamental challenge that restricts the autonomy of robots. While safety isparamount, guarantees on sufficient exploration are also crucial for ensuringautonomous task completion. To address these challenges, we propose a novelsafe guaranteed exploration framework using optimal control, which achievesfirst-of-its-kind results: guaranteed exploration for non-linear systems withfinite time sample complexity bounds, while being provably safe witharbitrarily high probability. The framework is general and applicable to manyreal-world scenarios with complex non-linear dynamics and unknown domains.Based on this framework we propose an efficient algorithm, SageMPC, SAfeGuaranteed Exploration using Model Predictive Control. SageMPC improvesefficiency by incorporating three techniques: i) exploiting a Lipschitz bound,ii) goal-directed exploration, and iii) receding horizon style re-planning, allwhile maintaining the desired sample complexity, safety and explorationguarantees of the framework. Lastly, we demonstrate safe efficient explorationin challenging unknown environments using SageMPC with a car model.</description><author>Manish Prajapat, Johannes Köhler, Matteo Turchetta, Andreas Krause, Melanie N. Zeilinger</author><pubDate>Fri, 09 Feb 2024 17:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06562v1</guid></item><item><title>Toward More Generalized Malicious URL Detection Models</title><link>http://arxiv.org/abs/2202.10027v2</link><description>This paper reveals a data bias issue that can severely affect the performancewhile conducting a machine learning model for malicious URL detection. Wedescribe how such bias can be identified using interpretable machine learningtechniques, and further argue that such biases naturally exist in the realworld security data for training a classification model. We then propose adebiased training strategy that can be applied to most deep-learning basedmodels to alleviate the negative effects from the biased features. The solutionis based on the technique of self-supervised adversarial training to train deepneural networks learning invariant embedding from biased data. We conduct awide range of experiments to demonstrate that the proposed strategy can lead tosignificantly better generalization capability for both CNN-based and RNN-baseddetection models.</description><author>YunDa Tsai, Cayon Liow, Yin Sheng Siang, Shou-De Lin</author><pubDate>Fri, 09 Feb 2024 17:20:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.10027v2</guid></item><item><title>Video Annotator: A framework for efficiently building video classifiers using vision-language models and active learning</title><link>http://arxiv.org/abs/2402.06560v1</link><description>High-quality and consistent annotations are fundamental to the successfuldevelopment of robust machine learning models. Traditional data annotationmethods are resource-intensive and inefficient, often leading to a reliance onthird-party annotators who are not the domain experts. Hard samples, which areusually the most informative for model training, tend to be difficult to labelaccurately and consistently without business context. These can ariseunpredictably during the annotation process, requiring a variable number ofiterations and rounds of feedback, leading to unforeseen expenses and timecommitments to guarantee quality. We posit that more direct involvement of domain experts, using ahuman-in-the-loop system, can resolve many of these practical challenges. Wepropose a novel framework we call Video Annotator (VA) for annotating,managing, and iterating on video classification datasets. Our approach offers anew paradigm for an end-user-centered model development process, enhancing theefficiency, usability, and effectiveness of video classifiers. Uniquely, VAallows for a continuous annotation process, seamlessly integrating datacollection and model training. We leverage the zero-shot capabilities of vision-language foundation modelscombined with active learning techniques, and demonstrate that VA enables theefficient creation of high-quality models. VA achieves a median 6.8 pointimprovement in Average Precision relative to the most competitive baselineacross a wide-ranging assortment of tasks. We release a dataset with 153klabels across 56 video understanding tasks annotated by three professionalvideo editors using VA, and also release code to replicate our experiments at:http://github.com/netflix/videoannotator.</description><author>Amir Ziai, Aneesh Vartakavi</author><pubDate>Fri, 09 Feb 2024 17:19:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06560v1</guid></item><item><title>Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following</title><link>http://arxiv.org/abs/2402.06559v1</link><description>Diffusion models excel at modeling complex and multimodal trajectorydistributions for decision-making and control. Reward-gradient guided denoisinghas been recently proposed to generate trajectories that maximize both adifferentiable reward function and the likelihood under the data distributioncaptured by a diffusion model. Reward-gradient guided denoising requires adifferentiable reward function fitted to both clean and noised samples,limiting its applicability as a general trajectory optimizer. In this paper, wepropose DiffusionES, a method that combines gradient-free optimization withtrajectory denoising to optimize black-box non-differentiable objectives whilestaying in the data manifold. Diffusion-ES samples trajectories duringevolutionary search from a diffusion model and scores them using a black-boxreward function. It mutates high-scoring trajectories using a truncateddiffusion process that applies a small number of noising and denoising steps,allowing for much more efficient exploration of the solution space. We showthat DiffusionES achieves state-of-the-art performance on nuPlan, anestablished closed-loop planning benchmark for autonomous driving. Diffusion-ESoutperforms existing sampling-based planners, reactive deterministic ordiffusion-based policies, and reward-gradient guidance. Additionally, we showthat unlike prior guidance methods, our method can optimize non-differentiablelanguage-shaped reward functions generated by few-shot LLM prompting. Whenguided by a human teacher that issues instructions to follow, our method cangenerate novel, highly complex behaviors, such as aggressive lane weaving,which are not present in the training data. This allows us to solve the hardestnuPlan scenarios which are beyond the capabilities of existing trajectoryoptimization methods and driving policies.</description><author>Brian Yang, Huangyuan Su, Nikolaos Gkanatsios, Tsung-Wei Ke, Ayush Jain, Jeff Schneider, Katerina Fragkiadaki</author><pubDate>Fri, 09 Feb 2024 17:18:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06559v1</guid></item><item><title>The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model</title><link>http://arxiv.org/abs/2402.06557v1</link><description>This paper introduces the Quantified Boolean Bayesian Network (QBBN), whichprovides a unified view of logical and probabilistic reasoning. The QBBN ismeant to address a central problem with the Large Language Model (LLM), whichhas become extremely popular in Information Retrieval, which is that the LLMhallucinates. A Bayesian Network, by construction, cannot hallucinate, becauseit can only return answers that it can explain. We show how a Bayesian Networkover an unbounded number of boolean variables can be configured to representthe logical reasoning underlying human language. We do this by creating akey-value version of the First-Order Calculus, for which we can proveconsistency and completeness. We show that the model is trivially trained overfully observed data, but that inference is non-trivial. Exact inference in aBayesian Network is intractable (i.e. $\Omega(2^N)$ for $N$ variables). Forinference, we investigate the use of Loopy Belief Propagation (LBP), which isnot guaranteed to converge, but which has been shown to often converge inpractice. Our experiments show that LBP indeed does converge very reliably, andour analysis shows that a round of LBP takes time $O(N2^n)$, where $N$ boundsthe number of variables considered, and $n$ bounds the number of incomingconnections to any factor, and further improvements may be possible. Ournetwork is specifically designed to alternate between AND and OR gates in aBoolean Algebra, which connects more closely to logical reasoning, allowing acompleteness proof for an expanded version of our network, and also allowsinference to follow specific but adequate pathways, that turn out to be fast.</description><author>Gregory Coppola</author><pubDate>Fri, 09 Feb 2024 17:15:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06557v1</guid></item><item><title>Lens: A Foundation Model for Network Traffic in Cybersecurity</title><link>http://arxiv.org/abs/2402.03646v2</link><description>Network traffic refers to the amount of data being sent and received over theinternet or any system that connects computers. Analyzing and understandingnetwork traffic is vital for improving network security and management.However, the analysis of network traffic is challenging due to the diversenature of data packets, which often feature heterogeneous headers and encryptedpayloads lacking semantics. To capture the latent semantics of traffic, a fewstudies have adopted pre-training techniques based on the Transformer encoderor decoder to learn the representations from massive traffic data. However,these methods typically excel in traffic understanding (classification) ortraffic generation tasks. To address this issue, we develop Lens, a foundationmodel for network traffic that leverages the T5 architecture to learn thepre-trained representations from large-scale unlabeled data. Harnessing thestrength of the encoder-decoder framework, which captures the globalinformation while preserving the generative ability, our model can better learnthe representations from raw data. To further enhance pre-trainingeffectiveness, we design a novel loss that combines three distinct tasks:Masked Span Prediction (MSP), Packet Order Prediction (POP), and HomologousTraffic Prediction (HTP). Evaluation results across various benchmark datasetsdemonstrate that the proposed Lens outperforms the baselines in most downstreamtasks related to both traffic understanding and generation. Notably, it alsorequires much less labeled data for fine-tuning compared to current methods.</description><author>Qineng Wang, Chen Qian, Xiaochang Li, Ziyu Yao, Huajie Shao</author><pubDate>Fri, 09 Feb 2024 17:15:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03646v2</guid></item><item><title>LLMLight: Large Language Models as Traffic Signal Control Agents</title><link>http://arxiv.org/abs/2312.16044v2</link><description>Traffic Signal Control (TSC) is a crucial component in urban trafficmanagement, aiming to optimize road network efficiency and reduce congestion.Traditional methods in TSC, primarily based on transportation engineering andreinforcement learning (RL), often exhibit limitations in generalization acrossvaried traffic scenarios and lack interpretability. This paper presentsLLMLight, a novel framework employing Large Language Models (LLMs) asdecision-making agents for TSC. Specifically, the framework begins byinstructing the LLM with a knowledgeable prompt detailing real-time trafficconditions. Leveraging the advanced generalization capabilities of LLMs,LLMLight engages a reasoning and decision-making process akin to humanintuition for effective traffic control. Moreover, we build LightGPT, aspecialized backbone LLM tailored for TSC tasks. By learning nuanced trafficpatterns and control strategies, LightGPT enhances the LLMLight frameworkcost-effectively. Extensive experiments on nine real-world and syntheticdatasets showcase the remarkable effectiveness, generalization ability, andinterpretability of LLMLight against nine transportation-based and RL-basedbaselines.</description><author>Siqi Lai, Zhao Xu, Weijia Zhang, Hao Liu, Hui Xiong</author><pubDate>Fri, 09 Feb 2024 17:11:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16044v2</guid></item><item><title>Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks</title><link>http://arxiv.org/abs/2402.06552v1</link><description>Deceptive path planning (DPP) is the problem of designing a path that hidesits true goal from an outside observer. Existing methods for DPP rely onunrealistic assumptions, such as global state observability and perfect modelknowledge, and are typically problem-specific, meaning that even minor changesto a previously solved problem can force expensive computation of an entirelynew solution. Given these drawbacks, such methods do not generalize to unseenproblem instances, lack scalability to realistic problem sizes, and precludeboth on-the-fly tunability of deception levels and real-time adaptivity tochanging environments. In this paper, we propose a reinforcement learning(RL)-based scheme for training policies to perform DPP over arbitrary weightedgraphs that overcomes these issues. The core of our approach is theintroduction of a local perception model for the agent, a new state spacerepresentation distilling the key components of the DPP problem, the use ofgraph neural network-based policies to facilitate generalization and scaling,and the introduction of new deception bonuses that translate the deceptionobjectives of classical methods to the RL setting. Through extensiveexperimentation we show that, without additional fine-tuning, at test time theresulting policies successfully generalize, scale, enjoy tunable levels ofdeception, and adapt in real-time to changes in the environment.</description><author>Michael Y. Fatemi, Wesley A. Suttle, Brian M. Sadler</author><pubDate>Fri, 09 Feb 2024 17:07:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06552v1</guid></item><item><title>Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA</title><link>http://arxiv.org/abs/2402.06549v1</link><description>This study details our approach for the CASE 2024 Shared Task on ClimateActivism Stance and Hate Event Detection, focusing on Hate Speech Detection,Hate Speech Target Identification, and Stance Detection as classificationchallenges. We explored the capability of Large Language Models (LLMs),particularly GPT-4, in zero- or few-shot settings enhanced by retrievalaugmentation and re-ranking for Tweet classification. Our goal was to determineif LLMs could match or surpass traditional methods in this context. We conducted an ablation study with LLaMA for comparison, and our resultsindicate that our models significantly outperformed the baselines, securingsecond place in the Target Detection task. The code for our submission isavailable at https://github.com/NaiveNeuron/bryndza-case-2024</description><author>Marek Šuppa, Daniel Skala, Daniela Jašš, Samuel Sučík, Andrej Švec, Peter Hraška</author><pubDate>Fri, 09 Feb 2024 17:02:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06549v1</guid></item><item><title>Calibrating Long-form Generations from Large Language Models</title><link>http://arxiv.org/abs/2402.06544v1</link><description>To enhance Large Language Models' (LLMs) reliability, calibration isessential -- the model's assessed confidence scores should align with theactual likelihood of its responses being correct. However, current confidenceelicitation methods and calibration metrics typically rely on a binarytrue/false assessment of response correctness. This approach does not apply tolong-form generation, where an answer can be partially correct. Addressing thisgap, we introduce a unified calibration framework, in which both thecorrectness of the LLMs' responses and their associated confidence levels aretreated as distributions across a range of scores. Within this framework, wedevelop three metrics to precisely evaluate LLM calibration and further proposetwo confidence elicitation methods based on self-consistency andself-evaluation. Our experiments, which include long-form QA and summarizationtasks, demonstrate that larger models don't necessarily guarantee bettercalibration, that calibration performance is found to be metric-dependent, andthat self-consistency methods excel in factoid datasets. We also find thatcalibration can be enhanced through techniques such as fine-tuning, integratingrelevant source documents, scaling the temperature, and combiningself-consistency with self-evaluation. Lastly, we showcase a practicalapplication of our system: selecting and cascading open-source models andChatGPT to optimize correctness given a limited API budget. This research notonly challenges existing notions of LLM calibration but also offers practicalmethodologies for improving trustworthiness in long-form generation.</description><author>Yukun Huang, Yixin Liu, Raghuveer Thirukovalluru, Arman Cohan, Bhuwan Dhingra</author><pubDate>Fri, 09 Feb 2024 17:00:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06544v1</guid></item><item><title>Model Selection of Zero-shot Anomaly Detectors in the Absence of Labeled Validation Data</title><link>http://arxiv.org/abs/2310.10461v2</link><description>Anomaly detection requires detecting abnormal samples in large unlabeleddatasets. While progress in deep learning and the advent of foundation modelshas produced powerful zero-shot anomaly detection methods, their deployment inpractice is often hindered by the lack of labeled data -- without it, theirdetection performance cannot be evaluated reliably. In this work, we proposeSWSA (Selection With Synthetic Anomalies): a general-purpose framework toselect image-based anomaly detectors with a generated synthetic validation set.Our proposed anomaly generation method assumes access to only a small supportset of normal images and requires no training or fine-tuning. Once generated,our synthetic validation set is used to create detection tasks that compose avalidation framework for model selection. In an empirical study, we find thatSWSA often selects models that match selections made with a ground-truthvalidation set, resulting in higher AUROCs than baseline methods. We also findthat SWSA selects prompts for CLIP-based anomaly detection that outperformbaseline prompt selection strategies on all datasets, including the challengingMVTec-AD and VisA datasets.</description><author>Clement Fung, Chen Qiu, Aodong Li, Maja Rudolph</author><pubDate>Fri, 09 Feb 2024 16:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10461v2</guid></item><item><title>Hybridnet for depth estimation and semantic segmentation</title><link>http://arxiv.org/abs/2402.06539v1</link><description>Semantic segmentation and depth estimation are two important tasks in thearea of image processing. Traditionally, these two tasks are addressed in anindependent manner. However, for those applications where geometric andsemantic information is required, such as robotics or autonomousnavigation,depth or semantic segmentation alone are not sufficient. In thispaper, depth estimation and semantic segmentation are addressed together from asingle input image through a hybrid convolutional network. Different from thestate of the art methods where features are extracted by a sole featureextraction network for both tasks, the proposed HybridNet improves the featuresextraction by separating the relevant features for one task from those whichare relevant for both. Experimental results demonstrate that HybridNet resultsare comparable with the state of the art methods, as well as the single taskmethods that HybridNet is based on.</description><author>Dalila Sánchez-Escobedo, Xiao Lin, Josep R. Casas, Montse Pardàs</author><pubDate>Fri, 09 Feb 2024 16:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06539v1</guid></item><item><title>Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows</title><link>http://arxiv.org/abs/2402.06537v1</link><description>Out-of-distribution (OOD) detection is a critical task for safe deployment oflearning systems in the open world setting. In this work, we investigate theuse of feature density estimation via normalizing flows for OOD detection andpresent a fully unsupervised approach which requires no exposure to OOD data,avoiding researcher bias in OOD sample selection. This is a post-hoc methodwhich can be applied to any pretrained model, and involves training alightweight auxiliary normalizing flow model to perform the out-of-distributiondetection via density thresholding. Experiments on OOD detection in imageclassification show strong results for far-OOD data detection with only asingle epoch of flow training, including 98.2% AUROC for ImageNet-1k vs.Textures, which exceeds the state of the art by 7.8%. We additionally explorethe connection between the feature space distribution of the pretrained modeland the performance of our method. Finally, we provide insights into trainingpitfalls that have plagued normalizing flows for use in OOD detection.</description><author>Evan D. Cook, Marc-Antoine Lavoie, Steven L. Waslander</author><pubDate>Fri, 09 Feb 2024 16:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06537v1</guid></item><item><title>Bandit Convex Optimisation</title><link>http://arxiv.org/abs/2402.06535v1</link><description>Bandit convex optimisation is a fundamental framework for studyingzeroth-order convex optimisation. These notes cover the many tools used forthis problem, including cutting plane methods, interior point methods,continuous exponential weights, gradient descent and online Newton step. Thenuances between the many assumptions and setups are explained. Although thereis not much truly new here, some existing tools are applied in novel ways toobtain new algorithms. A few bounds are improved in minor ways.</description><author>Tor Lattimore</author><pubDate>Fri, 09 Feb 2024 16:49:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06535v1</guid></item><item><title>Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier</title><link>http://arxiv.org/abs/2212.04382v2</link><description>Whether based on models, training data or a combination, classifiers place(possibly complex) input data into one of a relatively small number of outputcategories. In this paper, we study the structure of the boundary--those pointsfor which a neighbor is classified differently--in the context of an inputspace that is a graph, so that there is a concept of neighboring inputs, Thescientific setting is a model-based naive Bayes classifier for DNA readsproduced by Next Generation Sequencers. We show that the boundary is both largeand complicated in structure. We create a new measure of uncertainty, calledNeighbor Similarity, that compares the result for a point to the distributionof results for its neighbors. This measure not only tracks two inherentuncertainty measures for the Bayes classifier, but also can be implemented, ata computational cost, for classifiers without inherent measures of uncertainty.</description><author>Alan F. Karr, Zac Bowen, Adam A. Porter</author><pubDate>Fri, 09 Feb 2024 16:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.04382v2</guid></item><item><title>TDSTF: Transformer-based Diffusion probabilistic model for Sparse Time series Forecasting</title><link>http://arxiv.org/abs/2301.06625v4</link><description>Background and Objective: Vital sign monitoring in the Intensive Care Unit(ICU) is crucial for enabling prompt interventions for patients. Thisunderscores the need for an accurate predictive system. Therefore, this studyproposes a novel deep learning approach for forecasting Heart Rate (HR),Systolic Blood Pressure (SBP), and Diastolic Blood Pressure (DBP) in the ICU.Methods: We extracted $24,886$ ICU stays from the MIMIC-III database whichcontains data from over $46$ thousand patients, to train and test the model.The model proposed in this study, Transformer-based Diffusion ProbabilisticModel for Sparse Time Series Forecasting (TDSTF), merges Transformer anddiffusion models to forecast vital signs. The TDSTF model showedstate-of-the-art performance in predicting vital signs in the ICU,outperforming other models' ability to predict distributions of vital signs andbeing more computationally efficient. The code is available athttps://github.com/PingChang818/TDSTF. Results: The results of the study showedthat TDSTF achieved a Standardized Average Continuous Ranked Probability Score(SACRPS) of $0.4438$ and a Mean Squared Error (MSE) of $0.4168$, an improvementof $18.9\%$ and $34.3\%$ over the best baseline model, respectively. Theinference speed of TDSTF is more than $17$ times faster than the best baselinemodel. Conclusion: TDSTF is an effective and efficient solution for forecastingvital signs in the ICU, and it shows a significant improvement compared toother models in the field.</description><author>Ping Chang, Huayu Li, Stuart F. Quan, Shuyang Lu, Shu-Fen Wung, Janet Roveda, Ao Li</author><pubDate>Fri, 09 Feb 2024 16:47:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06625v4</guid></item><item><title>Bellman Conformal Inference: Calibrating Prediction Intervals For Time Series</title><link>http://arxiv.org/abs/2402.05203v2</link><description>We introduce Bellman Conformal Inference (BCI), a framework that wraps aroundany time series forecasting models and provides approximately calibratedprediction intervals. Unlike existing methods, BCI is able to leveragemulti-step ahead forecasts and explicitly optimize the average interval lengthsby solving a one-dimensional stochastic control problem (SCP) at each timestep. In particular, we use the dynamic programming algorithm to find theoptimal policy for the SCP. We prove that BCI achieves long-term coverage underarbitrary distribution shifts and temporal dependence, even with poormulti-step ahead forecasts. We find empirically that BCI avoids uninformativeintervals that have infinite lengths and generates substantially shorterprediction intervals in multiple applications when compared with existingmethods.</description><author>Zitong Yang, Emmanuel Candès, Lihua Lei</author><pubDate>Fri, 09 Feb 2024 16:47:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05203v2</guid></item><item><title>Generative Adversarial Bayesian Optimization for Surrogate Objectives</title><link>http://arxiv.org/abs/2402.06532v1</link><description>Offline model-based policy optimization seeks to optimize a learned surrogateobjective function without querying the true oracle objective duringoptimization. However, inaccurate surrogate model predictions are frequentlyencountered along the optimization trajectory. To address this limitation, wepropose generative adversarial Bayesian optimization (GABO) using adaptivesource critic regularization, a task-agnostic framework for Bayesianoptimization that employs a Lipschitz-bounded source critic model to constrainthe optimization trajectory to regions where the surrogate function isreliable. We show that under certain assumptions for the continuous input spaceprior, our algorithm dynamically adjusts the strength of the source criticregularization. GABO outperforms existing baselines on a number of differentoffline optimization tasks across a variety of scientific domains. Our code isavailable at https://github.com/michael-s-yao/gabo</description><author>Michael S. Yao, Yimeng Zeng, Hamsa Bastani, Jacob Gardner, James C. Gee, Osbert Bastani</author><pubDate>Fri, 09 Feb 2024 16:43:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06532v1</guid></item><item><title>Transferring facade labels between point clouds with semantic octrees while considering change detection</title><link>http://arxiv.org/abs/2402.06531v1</link><description>Point clouds and high-resolution 3D data have become increasingly importantin various fields, including surveying, construction, and virtual reality.However, simply having this data is not enough; to extract useful information,semantic labeling is crucial. In this context, we propose a method to transferannotations from a labeled to an unlabeled point cloud using an octreestructure. The structure also analyses changes between the point clouds. Ourexperiments confirm that our method effectively transfers annotations whileaddressing changes. The primary contribution of this project is the developmentof the method for automatic label transfer between two different point cloudsthat represent the same real-world object. The proposed method can be of greatimportance for data-driven deep learning algorithms as it can also allowcircumventing stochastic transfer learning by deterministic label transferbetween datasets depicting the same objects.</description><author>Sophia Schwarz, Tanja Pilz, Olaf Wysocki, Ludwig Hoegner, Uwe Stilla</author><pubDate>Fri, 09 Feb 2024 16:43:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06531v1</guid></item><item><title>Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification</title><link>http://arxiv.org/abs/2402.06530v1</link><description>Early detection of myocardial infarction (MI), a critical condition arisingfrom coronary artery disease (CAD), is vital to prevent further myocardialdamage. This study introduces a novel method for early MI detection using aone-class classification (OCC) algorithm in echocardiography. Our studyovercomes the challenge of limited echocardiography data availability byadopting a novel approach based on Multi-modal Subspace Support Vector DataDescription. The proposed technique involves a specialized MI detectionframework employing multi-view echocardiography incorporating a compositekernel in the non-linear projection trick, fusing Gaussian and Laplaciansigmoid functions. Additionally, we enhance the update strategy of theprojection matrices by adapting maximization for both or one of the modalitiesin the optimization process. Our method boosts MI detection capability byefficiently transforming features extracted from echocardiography data into anoptimized lower-dimensional subspace. The OCC model trained specifically ontarget class instances from the comprehensive HMC-QU dataset that includesmultiple echocardiography views indicates a marked improvement in MI detectionaccuracy. Our findings reveal that our proposed multi-view approach achieves ageometric mean of 71.24\%, signifying a substantial advancement inechocardiography-based MI diagnosis and offering more precise and efficientdiagnostic tools.</description><author>Muhammad Uzair Zahid, Aysen Degerli, Fahad Sohrab, Serkan Kiranyaz, Moncef Gabbouj</author><pubDate>Fri, 09 Feb 2024 16:41:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06530v1</guid></item><item><title>Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty</title><link>http://arxiv.org/abs/2402.06529v1</link><description>Large language models (LLMs) exhibit advanced reasoning skills, enablingrobots to comprehend natural language instructions and strategically planhigh-level actions through proper grounding. However, LLM hallucination mayresult in robots confidently executing plans that are misaligned with usergoals or, in extreme cases, unsafe. Additionally, inherent ambiguity in naturallanguage instructions can induce task uncertainty, particularly in situationswhere multiple valid options exist. To address this issue, LLMs must identifysuch uncertainty and proactively seek clarification. This paper explores theconcept of introspective planning as a systematic method for guiding LLMs informing uncertainty--aware plans for robotic task execution without the needfor fine-tuning. We investigate uncertainty quantification in task-level robotplanning and demonstrate that introspection significantly improves both successrates and safety compared to state-of-the-art LLM-based planning approaches.Furthermore, we assess the effectiveness of introspective planning inconjunction with conformal prediction, revealing that this combination yieldstighter confidence bounds, thereby maintaining statistical success guaranteeswith fewer superfluous user clarification queries.</description><author>Kaiqu Liang, Zixu Zhang, Jaime Fernández Fisac</author><pubDate>Fri, 09 Feb 2024 16:40:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06529v1</guid></item><item><title>Knowledge Distillation Under Ideal Joint Classifier Assumption</title><link>http://arxiv.org/abs/2304.11004v3</link><description>Knowledge distillation constitutes a potent methodology for condensingsubstantial neural networks into more compact and efficient counterparts.Within this context, softmax regression representation learning serves as awidely embraced approach, leveraging a pre-established teacher network to guidethe learning process of a diminutive student network. Notably, despite theextensive inquiry into the efficacy of softmax regression representationlearning, the intricate underpinnings governing the knowledge transfermechanism remain inadequately elucidated. This study introduces the 'IdealJoint Classifier Knowledge Distillation' (IJCKD) framework, an overarchingparadigm that not only furnishes a lucid and exhaustive comprehension ofprevailing knowledge distillation techniques but also establishes a theoreticalunderpinning for prospective investigations. Employing mathematicalmethodologies derived from domain adaptation theory, this investigationconducts a comprehensive examination of the error boundary of the studentnetwork contingent upon the teacher network. Consequently, our frameworkfacilitates efficient knowledge transference between teacher and studentnetworks, thereby accommodating a diverse spectrum of applications.</description><author>Huayu Li, Xiwen Chen, Gregory Ditzler, Janet Roveda, Ao Li</author><pubDate>Fri, 09 Feb 2024 16:40:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11004v3</guid></item><item><title>Synthesizing Forestry Images Conditioned on Plant Phenotype Using a Generative Adversarial Network</title><link>http://arxiv.org/abs/2307.03789v2</link><description>Plant phenology and phenotype prediction using remote sensing data isincreasingly gaining the attention of the plant science community to improveagricultural productivity. This work aims to generate synthetic forestry imagesthat satisfy certain phenotypic attributes, viz. canopy greenness. We harness aGenerative Adversarial Network (GAN) to synthesize biologically plausible andphenotypically stable forestry images conditioned on the greenness ofvegetation (a continuous attribute) over a specific region of interest(describing a particular vegetation type in a mixed forest). The training datais based on the automated digital camera imagery provided by the NationalEcological Observatory Network (NEON) and processed by the PhenoCam Network.Our method helps render the appearance of forest sites specific to a greennessvalue. The synthetic images are utilized to predict another phenotypicattribute, viz., redness of plants. The Structural SIMilarity (SSIM) index isused to assess the quality of the synthetic images. The greenness and rednessindices of the generated synthetic images are compared against that of theoriginal images using Root Mean Squared Percentage Error (RMSPE) to evaluatetheir accuracy and integrity. The generalizability and scalability of ourproposed GAN model is determined by effectively transforming it to generatesynthetic images for other forest sites and vegetation types.</description><author>Debasmita Pal, Arun Ross</author><pubDate>Fri, 09 Feb 2024 16:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03789v2</guid></item><item><title>Flexible infinite-width graph convolutional networks and the importance of representation learning</title><link>http://arxiv.org/abs/2402.06525v1</link><description>A common theoretical approach to understanding neural networks is to take aninfinite-width limit, at which point the outputs become Gaussian process (GP)distributed. This is known as a neural network Gaussian process (NNGP).However, the NNGP kernel is fixed, and tunable only through a small number ofhyperparameters, eliminating any possibility of representation learning. Thiscontrasts with finite-width NNs, which are often believed to perform wellprecisely because they are able to learn representations. Thus in simplifyingNNs to make them theoretically tractable, NNGPs may eliminate precisely whatmakes them work well (representation learning). This motivated us to understandwhether representation learning is necessary in a range of graph classificationtasks. We develop a precise tool for this task, the graph convolutional deepkernel machine. This is very similar to an NNGP, in that it is an infinitewidth limit and uses kernels, but comes with a `knob' to control the amount ofrepresentation learning. We found that representation learning is necessary (inthe sense that it gives dramatic performance improvements) in graphclassification tasks and heterophilous node classification tasks, but not inhomophilous node classification tasks.</description><author>Ben Anson, Edward Milsom, Laurence Aitchison</author><pubDate>Fri, 09 Feb 2024 16:37:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06525v1</guid></item><item><title>Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs with Recurrent Message Passing</title><link>http://arxiv.org/abs/2402.05027v2</link><description>Graph-based environments pose unique challenges to multi-agent reinforcementlearning. In decentralized approaches, agents operate within a given graph andmake decisions based on partial or outdated observations. The size of theobserved neighborhood limits the generalizability to different graphs andaffects the reactivity of agents, the quality of the selected actions, and thecommunication overhead. This work focuses on generalizability and resolves thetrade-off in observed neighborhood size with a continuous information flow inthe whole graph. We propose a recurrent message-passing model that iterateswith the environment's steps and allows nodes to create a global representationof the graph by exchanging messages with their neighbors. Agents receive theresulting learned graph observations based on their location in the graph. Ourapproach can be used in a decentralized manner at runtime and in combinationwith a reinforcement learning algorithm of choice. We evaluate our methodacross 1000 diverse graphs in the context of routing in communication networksand find that it enables agents to generalize and adapt to changes in thegraph.</description><author>Jannis Weil, Zhenghua Bao, Osama Abboud, Tobias Meuser</author><pubDate>Fri, 09 Feb 2024 16:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05027v2</guid></item><item><title>Structured Chemistry Reasoning with Large Language Models</title><link>http://arxiv.org/abs/2311.09656v2</link><description>Large Language Models (LLMs) excel in diverse areas, yet struggle withcomplex scientific reasoning, especially in the field of chemistry. Differentfrom the simple chemistry tasks (e.g., molecule classification) addressed inprevious studies, complex chemistry problems require not only vast knowledgeand precise calculation, but also compositional reasoning about rich dynamicinteractions of different concepts (e.g., temperature changes). Our study showsthat even advanced LLMs, like GPT-4, can fail easily in different ways.Interestingly, the errors often stem not from a lack of domain knowledge withinthe LLMs, but rather from the absence of an effective reasoning structure thatguides the LLMs to elicit the right knowledge, incorporate the knowledge instep-by-step reasoning, and iteratively refine results for further improvedquality. On this basis, we introduce StructChem, a simple yet effectiveprompting strategy that offers the desired guidance and substantially booststhe LLMs' chemical reasoning capability. Testing across four chemistry areas --quantum chemistry, mechanics, physical chemistry, and kinetics -- StructChemsubstantially enhances GPT-4's performance, with up to 30\% peak improvement.Our analysis also underscores the unique difficulties of precise groundedreasoning in science with LLMs, highlighting a need for more research in thisarea. Code is available at \url{https://github.com/ozyyshr/StructChem}.</description><author>Siru Ouyang, Zhuosheng Zhang, Bing Yan, Xuan Liu, Yejin Choi, Jiawei Han, Lianhui Qin</author><pubDate>Fri, 09 Feb 2024 16:35:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09656v2</guid></item><item><title>Reconstructing facade details using MLS point clouds and Bag-of-Words approach</title><link>http://arxiv.org/abs/2402.06521v1</link><description>In the reconstruction of fa\c{c}ade elements, the identification of specificobject types remains challenging and is often circumvented by rectangularityassumptions or the use of bounding boxes. We propose a new approach for thereconstruction of 3D fa\c{c}ade details. We combine MLS point clouds and apre-defined 3D model library using a BoW concept, which we augment byincorporating semi-global features. We conduct experiments on the modelssuperimposed with random noise and on the TUM-FA\c{C}ADE dataset. Our methoddemonstrates promising results, improving the conventional BoW approach. Itholds the potential to be utilized for more realistic facade reconstructionwithout rectangularity assumptions, which can be used in applications such astesting automated driving functions or estimating fa\c{c}ade solar potential.</description><author>Thomas Froech, Olaf Wysocki, Ludwig Hoegner, Uwe Stilla</author><pubDate>Fri, 09 Feb 2024 16:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06521v1</guid></item><item><title>Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks</title><link>http://arxiv.org/abs/2308.04451v3</link><description>AI-based code generators have become pivotal in assisting developers inwriting software starting from natural language (NL). However, they are trainedon large amounts of data, often collected from unsanitized online sources(e.g., GitHub, HuggingFace). As a consequence, AI models become an easy targetfor data poisoning, i.e., an attack that injects malicious samples into thetraining data to generate vulnerable code. To address this threat, this work investigates the security of AI codegenerators by devising a targeted data poisoning strategy. We poison thetraining data by injecting increasing amounts of code containing securityvulnerabilities and assess the attack's success on different state-of-the-artmodels for code generation. Our study shows that AI code generators arevulnerable to even a small amount of poison. Notably, the attack successstrongly depends on the model architecture and poisoning rate, whereas it isnot influenced by the type of vulnerabilities. Moreover, since the attack doesnot impact the correctness of code generated by pre-trained models, it is hardto detect. Lastly, our work offers practical insights into understanding andpotentially mitigating this threat.</description><author>Domenico Cotroneo, Cristina Improta, Pietro Liguori, Roberto Natella</author><pubDate>Fri, 09 Feb 2024 16:28:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04451v3</guid></item><item><title>Multimodal Clinical Trial Outcome Prediction with Large Language Models</title><link>http://arxiv.org/abs/2402.06512v1</link><description>The clinical trial is a pivotal and costly process, often spanning multipleyears and requiring substantial financial resources. Therefore, the developmentof clinical trial outcome prediction models aims to exclude drugs likely tofail and holds the potential for significant cost savings. Recent data-drivenattempts leverage deep learning methods to integrate multimodal data forpredicting clinical trial outcomes. However, these approaches rely on manuallydesigned modal-specific encoders, which limits both the extensibility to adaptnew modalities and the ability to discern similar information patterns acrossdifferent modalities. To address these issues, we propose a multimodalmixture-of-experts (LIFTED) approach for clinical trial outcome prediction.Specifically, LIFTED unifies different modality data by transforming them intonatural language descriptions. Then, LIFTED constructs unified noise-resilientencoders to extract information from modal-specific language descriptions.Subsequently, a sparse Mixture-of-Experts framework is employed to furtherrefine the representations, enabling LIFTED to identify similar informationpatterns across different modalities and extract more consistentrepresentations from those patterns using the same expert model. Finally, amixture-of-experts module is further employed to dynamically integratedifferent modality representations for prediction, which gives LIFTED theability to automatically weigh different modalities and pay more attention tocritical information. The experiments demonstrate that LIFTED significantlyenhances performance in predicting clinical trial outcomes across all threephases compared to the best baseline, showcasing the effectiveness of ourproposed key components.</description><author>Wenhao Zheng, Dongsheng Peng, Hongxia Xu, Hongtu Zhu, Tianfan Fu, Huaxiu Yao</author><pubDate>Fri, 09 Feb 2024 16:18:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06512v1</guid></item><item><title>Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions</title><link>http://arxiv.org/abs/2402.06509v1</link><description>Clarification questions are an essential dialogue tool to signalmisunderstanding, ambiguities, and under-specification in language use. Whilehumans are able to resolve uncertainty by asking questions since childhood,modern dialogue systems struggle to generate effective questions. To makeprogress in this direction, in this work we take a collaborative dialogue taskas a testbed and study how model uncertainty relates to human uncertainty -- anas yet under-explored problem. We show that model uncertainty does not mirrorhuman clarification-seeking behavior, which suggests that using humanclarification questions as supervision for deciding when to ask may not be themost effective way to resolve model uncertainty. To address this issue, wepropose an approach to generating clarification questions based on modeluncertainty estimation, compare it to several alternatives, and show that itleads to significant improvements in terms of task success. Our findingshighlight the importance of equipping dialogue systems with the ability toassess their own uncertainty and exploit in interaction.</description><author>Alberto Testoni, Raquel Fernández</author><pubDate>Fri, 09 Feb 2024 16:15:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06509v1</guid></item><item><title>Classifying point clouds at the facade-level using geometric features and deep learning networks</title><link>http://arxiv.org/abs/2402.06506v1</link><description>3D building models with facade details are playing an important role in manyapplications now. Classifying point clouds at facade-level is key to createsuch digital replicas of the real world. However, few studies have focused onsuch detailed classification with deep neural networks. We propose a methodfusing geometric features with deep learning networks for point cloudclassification at facade-level. Our experiments conclude that such early-fusedfeatures improve deep learning methods' performance. This method can be appliedfor compensating deep learning networks' ability in capturing local geometricinformation and promoting the advancement of semantic segmentation.</description><author>Yue Tan, Olaf Wysocki, Ludwig Hoegner, Uwe Stilla</author><pubDate>Fri, 09 Feb 2024 16:14:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06506v1</guid></item><item><title>Solving Complex Multi-UAV Mission Planning Problems using Multi-objective Genetic Algorithms</title><link>http://arxiv.org/abs/2402.06504v1</link><description>Due to recent booming of UAVs technologies, these are being used in manyfields involving complex tasks. Some of them involve a high risk to the vehicledriver, such as fire monitoring and rescue tasks, which make UAVs excellent foravoiding human risks. Mission Planning for UAVs is the process of planning thelocations and actions (loading/dropping a load, taking videos/pictures,acquiring information) for the vehicles, typically over a time period. Thesevehicles are controlled from Ground Control Stations (GCSs) where humanoperators use rudimentary systems. This paper presents a new Multi-ObjectiveGenetic Algorithm for solving complex Mission Planning Problems (MPP) involvinga team of UAVs and a set of GCSs. A hybrid fitness function has been designedusing a Constraint Satisfaction Problem (CSP) to check if solutions are validand Pareto-based measures to look for optimal solutions. The algorithm has beentested on several datasets optimizing different variables of the mission, suchas the makespan, the fuel consumption, distance, etc. Experimental results showthat the new algorithm is able to obtain good solutions, however as the problembecomes more complex, the optimal solutions also become harder to find.</description><author>Cristian Ramirez-Atencia, Gema Bello-Orgaz, Maria D R-Moreno, David Camacho</author><pubDate>Fri, 09 Feb 2024 16:13:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06504v1</guid></item><item><title>Universal Approximation Power of Deep Residual Neural Networks via Nonlinear Control Theory</title><link>http://arxiv.org/abs/2007.06007v4</link><description>In this paper, we explain the universal approximation capabilities of deepresidual neural networks through geometric nonlinear control. Inspired byrecent work establishing links between residual networks and control systems,we provide a general sufficient condition for a residual network to have thepower of universal approximation by asking the activation function, or one ofits derivatives, to satisfy a quadratic differential equation. Many activationfunctions used in practice satisfy this assumption, exactly or approximately,and we show this property to be sufficient for an adequately deep neuralnetwork with $n+1$ neurons per layer to approximate arbitrarily well, on acompact set and with respect to the supremum norm, any continuous function from$\mathbb{R}^n$ to $\mathbb{R}^n$. We further show this result to hold for verysimple architectures for which the weights only need to assume two values. Thefirst key technical contribution consists of relating the universalapproximation problem to controllability of an ensemble of control systemscorresponding to a residual network and to leverage classical Lie algebraictechniques to characterize controllability. The second technical contributionis to identify monotonicity as the bridge between controllability of finiteensembles and uniform approximability on compact sets.</description><author>Paulo Tabuada, Bahman Gharesifard</author><pubDate>Fri, 09 Feb 2024 16:13:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2007.06007v4</guid></item><item><title>ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies</title><link>http://arxiv.org/abs/2402.06503v1</link><description>Understanding how failure occurs and how it can be prevented in reinforcementlearning (RL) is necessary to enable debugging, maintain user trust, anddevelop personalized policies. Counterfactual reasoning has often been used toassign blame and understand failure by searching for the closest possible worldin which the failure is avoided. However, current counterfactual stateexplanations in RL can only explain an outcome using just the current statefeatures and offer no actionable recourse on how a negative outcome could havebeen prevented. In this work, we propose ACTER (Actionable CounterfactualSequences for Explaining Reinforcement Learning Outcomes), an algorithm forgenerating counterfactual sequences that provides actionable advice on howfailure can be avoided. ACTER investigates actions leading to a failure anduses the evolutionary algorithm NSGA-II to generate counterfactual sequences ofactions that prevent it with minimal changes and high certainty even instochastic environments. Additionally, ACTER generates a set of multiplediverse counterfactual sequences that enable users to correct failure in theway that best fits their preferences. We also introduce three diversity metricsthat can be used for evaluating the diversity of counterfactual sequences. Weevaluate ACTER in two RL environments, with both discrete and continuousactions, and show that it can generate actionable and diverse counterfactualsequences. We conduct a user study to explore how explanations generated byACTER help users identify and correct failure.</description><author>Jasmina Gajcin, Ivana Dusparic</author><pubDate>Fri, 09 Feb 2024 16:12:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06503v1</guid></item><item><title>Scalable Interactive Machine Learning for Future Command and Control</title><link>http://arxiv.org/abs/2402.06501v1</link><description>Future warfare will require Command and Control (C2) personnel to makedecisions at shrinking timescales in complex and potentially ill-definedsituations. Given the need for robust decision-making processes anddecision-support tools, integration of artificial and human intelligence holdsthe potential to revolutionize the C2 operations process to ensure adaptabilityand efficiency in rapidly changing operational environments. We propose toleverage recent promising breakthroughs in interactive machine learning, inwhich humans can cooperate with machine learning algorithms to guide machinelearning algorithm behavior. This paper identifies several gaps instate-of-the-art science and technology that future work should address toextend these approaches to function in complex C2 contexts. In particular, wedescribe three research focus areas that together, aim to enable scalableinteractive machine learning (SIML): 1) developing human-AI interactionalgorithms to enable planning in complex, dynamic situations; 2) fosteringresilient human-AI teams through optimizing roles, configurations, and trust;and 3) scaling algorithms and human-AI teams for flexibility across a range ofpotential contexts and situations.</description><author>Anna Madison, Ellen Novoseller, Vinicius G. Goecks, Benjamin T. Files, Nicholas Waytowich, Alfred Yu, Vernon J. Lawhern, Steven Thurman, Christopher Kelshaw, Kaleb McDowell</author><pubDate>Fri, 09 Feb 2024 16:11:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06501v1</guid></item><item><title>On the Fly Detection of Root Causes from Observed Data with Application to IT Systems</title><link>http://arxiv.org/abs/2402.06500v1</link><description>This paper introduces a new structural causal model tailored for representingthreshold-based IT systems and presents a new algorithm designed to rapidlydetect root causes of anomalies in such systems. When root causes are notcausally related, the method is proven to be correct; while an extension isproposed based on the intervention of an agent to relax this assumption. Ouralgorithm and its agent-based extension leverage causal discovery from offlinedata and engage in subgraph traversal when encountering new anomalies in onlinedata. Our extensive experiments demonstrate the superior performance of ourmethods, even when applied to data generated from alternative structural causalmodels or real IT monitoring data.</description><author>Lei Zan, Charles K. Assaad, Emilie Devijver, Eric Gaussier</author><pubDate>Fri, 09 Feb 2024 16:10:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06500v1</guid></item><item><title>BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning</title><link>http://arxiv.org/abs/2402.06499v1</link><description>Background: Chest X-ray imaging-based abnormality localization, essential indiagnosing various diseases, faces significant clinical challenges due tocomplex interpretations and the growing workload of radiologists. While recentadvances in deep learning offer promising solutions, there is still a criticalissue of domain inconsistency in cross-domain transfer learning, which hampersthe efficiency and accuracy of diagnostic processes. This study aims to addressthe domain inconsistency problem and improve autonomic abnormality localizationperformance of heterogeneous chest X-ray image analysis, by developing aself-supervised learning strategy called "BarlwoTwins-CXR". Methods: Weutilized two publicly available datasets: the NIH Chest X-ray Dataset and theVinDr-CXR. The BarlowTwins-CXR approach was conducted in a two-stage trainingprocess. Initially, self-supervised pre-training was performed using anadjusted Barlow Twins algorithm on the NIH dataset with a Resnet50 backbonepre-trained on ImageNet. This was followed by supervised fine-tuning on theVinDr-CXR dataset using Faster R-CNN with Feature Pyramid Network (FPN).Results: Our experiments showed a significant improvement in model performancewith BarlowTwins-CXR. The approach achieved a 3% increase in mAP50 accuracycompared to traditional ImageNet pre-trained models. In addition, the AblationCAM method revealed enhanced precision in localizing chest abnormalities.Conclusion: BarlowTwins-CXR significantly enhances the efficiency and accuracyof chest X-ray image-based abnormality localization, outperforming traditionaltransfer learning methods and effectively overcoming domain inconsistency incross-domain scenarios. Our experiment results demonstrate the potential ofusing self-supervised learning to improve the generalizability of models inmedical settings with limited amounts of heterogeneous data.</description><author>Haoyue Sheng, Linrui Ma, Jean-Francois Samson, Dianbo Liu</author><pubDate>Fri, 09 Feb 2024 16:10:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06499v1</guid></item><item><title>Statistical exploration of the Manifold Hypothesis</title><link>http://arxiv.org/abs/2208.11665v4</link><description>The Manifold Hypothesis is a widely accepted tenet of Machine Learning whichasserts that nominally high-dimensional data are in fact concentrated near alow-dimensional manifold, embedded in high-dimensional space. This phenomenonis observed empirically in many real world situations, has led to developmentof a wide range of statistical methods in the last few decades, and has beensuggested as a key factor in the success of modern AI technologies. We showthat rich and sometimes intricate manifold structure in data can emerge from ageneric and remarkably simple statistical model -- the Latent Metric Model --via elementary concepts such as latent variables, correlation and stationarity.This establishes a general statistical explanation for why the ManifoldHypothesis seems to hold in so many situations. Informed by the Latent MetricModel we derive procedures to discover and interpret the geometry ofhigh-dimensional data, and explore hypotheses about the data generatingmechanism. These procedures operate under minimal assumptions and make use ofwell known, scaleable graph-analytic algorithms.</description><author>Nick Whiteley, Annie Gray, Patrick Rubin-Delanchy</author><pubDate>Fri, 09 Feb 2024 16:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.11665v4</guid></item><item><title>Iris-SAM: Iris Segmentation Using a Foundational Model</title><link>http://arxiv.org/abs/2402.06497v1</link><description>Iris segmentation is a critical component of an iris biometric system and itinvolves extracting the annular iris region from an ocular image. In this work,we develop a pixel-level iris segmentation model from a foundational model,viz., Segment Anything Model (SAM), that has been successfully used forsegmenting arbitrary objects. The primary contribution of this work lies in theintegration of different loss functions during the fine-tuning of SAM on ocularimages. In particular, the importance of Focal Loss is borne out in thefine-tuning process since it strategically addresses the class imbalanceproblem (i.e., iris versus non-iris pixels). Experiments on ND-IRIS-0405,CASIA-Iris-Interval-v3, and IIT-Delhi-Iris datasets convey the efficacy of thetrained model for the task of iris segmentation. For instance, on theND-IRIS-0405 dataset, an average segmentation accuracy of 99.58% was achieved,compared to the best baseline performance of 89.75%.</description><author>Parisa Farmanifard, Arun Ross</author><pubDate>Fri, 09 Feb 2024 16:08:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06497v1</guid></item><item><title>Mimicking Better by Matching the Approximate Action Distribution</title><link>http://arxiv.org/abs/2306.09805v2</link><description>In this paper, we introduce MAAD, a novel, sample-efficient on-policyalgorithm for Imitation Learning from Observations. MAAD utilizes a surrogatereward signal, which can be derived from various sources such as adversarialgames, trajectory matching objectives, or optimal transport criteria. Tocompensate for the non-availability of expert actions, we rely on an inversedynamics model that infers plausible actions distribution given the expert'sstate-state transitions; we regularize the imitator's policy by aligning it tothe inferred action distribution. MAAD leads to significantly improved sampleefficiency and stability. We demonstrate its effectiveness in a number ofMuJoCo environments, both int the OpenAI Gym and the DeepMind Control Suite. Weshow that it requires considerable fewer interactions to achieve expertperformance, outperforming current state-of-the-art on-policy methods.Remarkably, MAAD often stands out as the sole method capable of attainingexpert performance levels, underscoring its simplicity and efficacy.</description><author>João A. Cândido Ramos, Lionel Blondé, Naoya Takeishi, Alexandros Kalousis</author><pubDate>Fri, 09 Feb 2024 16:04:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09805v2</guid></item><item><title>Deep Learning-Based Auto-Segmentation of Planning Target Volume for Total Marrow and Lymph Node Irradiation</title><link>http://arxiv.org/abs/2402.06494v1</link><description>In order to optimize the radiotherapy delivery for cancer treatment,especially when dealing with complex treatments such as Total Marrow and LymphNode Irradiation (TMLI), the accurate contouring of the Planning Target Volume(PTV) is crucial. Unfortunately, relying on manual contouring for suchtreatments is time-consuming and prone to errors. In this paper, we investigatethe application of Deep Learning (DL) to automate the segmentation of the PTVin TMLI treatment, building upon previous work that introduced a solution tothis problem based on a 2D U-Net model. We extend the previous research (i) byemploying the nnU-Net framework to develop both 2D and 3D U-Net models and (ii)by evaluating the trained models on the PTV with the exclusion of bones, whichconsist mainly of lymp-nodes and represent the most challenging region of thetarget volume to segment. Our result show that the introduction of nnU-NETframework led to statistically significant improvement in the segmentationperformance. In addition, the analysis on the PTV after the exclusion of bonesshowed that the models are quite robust also on the most challenging areas ofthe target volume. Overall, our study is a significant step forward in theapplication of DL in a complex radiotherapy treatment such as TMLI, offering aviable and scalable solution to increase the number of patients who can benefitfrom this treatment.</description><author>Ricardo Coimbra Brioso, Damiano Dei, Nicola Lambri, Daniele Loiacono, Pietro Mancosu, Marta Scorsetti</author><pubDate>Fri, 09 Feb 2024 15:56:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06494v1</guid></item><item><title>Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings</title><link>http://arxiv.org/abs/2402.06492v1</link><description>Transformers generalize to novel compositions of structures and entitiesafter being trained on a complex dataset, but easily overfit on datasets ofinsufficient complexity. We observe that when the training set is sufficientlycomplex, the model encodes sentences that have a common syntactic structureusing a systematic attention pattern. Inspired by this observation, we proposeSQ-Transformer (Structurally Quantized) that explicitly encouragessystematicity in the embeddings and attention layers, even with a training setof low complexity. At the embedding level, we introduce Structure-orientedVector Quantization (SoVQ) to cluster word embeddings into several classes ofstructurally equivalent entities. At the attention level, we devise theSystematic Attention Layer (SAL) and an alternative, Systematically RegularizedLayer (SRL) that operate on the quantized word embeddings so that sentences ofthe same structure are encoded with invariant or similar attention patterns.Empirically, we show that SQ-Transformer achieves stronger compositionalgeneralization than the vanilla Transformer on multiple low-complexity semanticparsing and machine translation datasets. In our analysis, we show that SoVQindeed learns a syntactically clustered embedding space and SAL/SRL inducesgeneralizable attention patterns, which lead to improved systematicity.</description><author>Yichen Jiang, Xiang Zhou, Mohit Bansal</author><pubDate>Fri, 09 Feb 2024 15:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06492v1</guid></item><item><title>Fault-Tolerant Neural Networks from Biological Error Correction Codes</title><link>http://arxiv.org/abs/2202.12887v3</link><description>It has been an open question in deep learning if fault-tolerant computationis possible: can arbitrarily reliable computation be achieved using onlyunreliable neurons? In the grid cells of the mammalian cortex, analog errorcorrection codes have been observed to protect states against neural spikingnoise, but their role in information processing is unclear. Here, we use thesebiological error correction codes to develop a universal fault-tolerant neuralnetwork that achieves reliable computation if the faultiness of each neuronlies below a sharp threshold; remarkably, we find that noisy biological neuronsfall below this threshold. The discovery of a phase transition from faulty tofault-tolerant neural computation suggests a mechanism for reliable computationin the cortex and opens a path towards understanding noisy analog systemsrelevant to artificial intelligence and neuromorphic computing.</description><author>Alexander Zlokapa, Andrew K. Tan, John M. Martyn, Ila R. Fiete, Max Tegmark, Isaac L. Chuang</author><pubDate>Fri, 09 Feb 2024 15:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.12887v3</guid></item><item><title>Multimodal Attention Merging for Improved Speech Recognition and Audio Event Classification</title><link>http://arxiv.org/abs/2312.14378v2</link><description>Training large foundation models using self-supervised objectives onunlabeled data, followed by fine-tuning on downstream tasks, has emerged as astandard procedure. Unfortunately, the efficacy of this approach is oftenconstrained by both limited fine-tuning compute and scarcity in labeleddownstream data. We introduce Multimodal Attention Merging (MAM), an attemptthat facilitates direct knowledge transfer from attention matrices of modelsrooted in high resource modalities, text and images, to those inresource-constrained domains, speech and audio, employing a zero-shot paradigm.MAM reduces the relative Word Error Rate (WER) of an Automatic SpeechRecognition (ASR) model by up to 6.70%, and relative classification error of anAudio Event Classification (AEC) model by 10.63%. In cases where somedata/compute is available, we present Learnable-MAM, a data-driven approach tomerging attention matrices, resulting in a further 2.90% relative reduction inWER for ASR and 18.42% relative reduction in AEC compared to fine-tuning.</description><author>Anirudh S. Sundar, Chao-Han Huck Yang, David M. Chan, Shalini Ghosh, Venkatesh Ravichandran, Phani Sankar Nidadavolu</author><pubDate>Fri, 09 Feb 2024 15:48:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14378v2</guid></item><item><title>Le Nozze di Giustizia. Interactions between Artificial Intelligence, Law, Logic, Language and Computation with some case studies in Traffic Regulations and Health Care</title><link>http://arxiv.org/abs/2402.06487v1</link><description>An important aim of this paper is to convey some basics of mathematical logicto the legal community working with Artificial Intelligence. After analysingwhat AI is, we decide to delimit ourselves to rule-based AI leaving NeuralNetworks and Machine Learning aside. Rule based AI allows for Formal methodswhich are described in a rudimentary form. We will then see how mathematicallogic interacts with legal rule-based AI practice. We shall see howmathematical logic imposes limitations and complications to AI applications. Weclassify the limitations and interactions between mathematical logic and legalAI in three categories: logical, computational and mathematical. The examplesto showcase the interactions will largely come from European trafficregulations. The paper closes off with some reflections on how and where AIcould be used and on basic mechanisms that shape society.</description><author>Joost J. Joosten, Manuela Montoya García</author><pubDate>Fri, 09 Feb 2024 15:43:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06487v1</guid></item><item><title>Real-Time Bus Arrival Prediction: A Deep Learning Approach for Enhanced Urban Mobility</title><link>http://arxiv.org/abs/2303.15495v2</link><description>In urban settings, bus transit stands as a significant mode of publictransportation, yet faces hurdles in delivering accurate and reliable arrivaltimes. This discrepancy often culminates in delays and a decline in ridership,particularly in areas with a heavy reliance on bus transit. A prevalentchallenge is the mismatch between actual bus arrival times and their scheduledcounterparts, leading to disruptions in fixed schedules. Our study, utilizingNew York City bus data, reveals an average delay of approximately eight minutesbetween scheduled and actual bus arrival times. This research introduces aninnovative, AI-based, data-driven methodology for predicting bus arrival timesat various transit points (stations), offering a collective prediction for allbus lines within large metropolitan areas. Through the deployment of a fullyconnected neural network, our method elevates the accuracy and efficiency ofpublic bus transit systems. Our comprehensive evaluation encompasses over 200bus lines and 2 million data points, showcasing an error margin of under 40seconds for arrival time estimates. Additionally, the inference time for eachdata point in the validation set is recorded at below 0.006 ms, demonstratingthe potential of our Neural-Net-based approach in substantially enhancing thepunctuality and reliability of bus transit systems.</description><author>Narges Rashvand, Sanaz Sadat Hosseini, Mona Azarbayjani, Hamed Tabkhi</author><pubDate>Fri, 09 Feb 2024 15:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15495v2</guid></item><item><title>SpikingBERT: Distilling BERT to Train Spiking Language Models Using Implicit Differentiation</title><link>http://arxiv.org/abs/2308.10873v2</link><description>Large language Models (LLMs), though growing exceedingly powerful, comprisesof orders of magnitude less neurons and synapses than the human brain. However,it requires significantly more power/energy to operate. In this work, wepropose a novel bio-inspired spiking language model (LM) which aims to reducethe computational cost of conventional LMs by drawing motivation from thesynaptic information flow in the brain. In this paper, we demonstrate aframework that leverages the average spiking rate of neurons at equilibrium totrain a neuromorphic spiking LM using implicit differentiation technique,thereby overcoming the non-differentiability problem of spiking neural network(SNN) based algorithms without using any type of surrogate gradient. Thesteady-state convergence of the spiking neurons also allows us to design aspiking attention mechanism, which is critical in developing a scalable spikingLM. Moreover, the convergence of average spiking rate of neurons at equilibriumis utilized to develop a novel ANN-SNN knowledge distillation based techniquewherein we use a pre-trained BERT model as "teacher" to train our "student"spiking architecture. While the primary architecture proposed in this paper ismotivated by BERT, the technique can be potentially extended to different kindsof LLMs. Our work is the first one to demonstrate the performance of anoperational spiking LM architecture on multiple different tasks in the GLUEbenchmark.</description><author>Malyaban Bal, Abhronil Sengupta</author><pubDate>Fri, 09 Feb 2024 15:31:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10873v2</guid></item><item><title>Large Language Models for Captioning and Retrieving Remote Sensing Images</title><link>http://arxiv.org/abs/2402.06475v1</link><description>Image captioning and cross-modal retrieval are examples of tasks that involvethe joint analysis of visual and linguistic information. In connection toremote sensing imagery, these tasks can help non-expert users in extractingrelevant Earth observation information for a variety of applications. Still,despite some previous efforts, the development and application of vision andlanguage models to the remote sensing domain have been hindered by therelatively small size of the available datasets and models used in previousstudies. In this work, we propose RS-CapRet, a Vision and Language method forremote sensing tasks, in particular image captioning and text-image retrieval.We specifically propose to use a highly capable large decoder language modeltogether with image encoders adapted to remote sensing imagery throughcontrastive language-image pre-training. To bridge together the image encoderand language decoder, we propose training simple linear layers with examplesfrom combining different remote sensing image captioning datasets, keeping theother parameters frozen. RS-CapRet can then generate descriptions for remotesensing images and retrieve images from textual descriptions, achieving SOTA orcompetitive performance with existing methods. Qualitative results illustratethat RS-CapRet can effectively leverage the pre-trained large language model todescribe remote sensing images, retrieve them based on different types ofqueries, and also show the ability to process interleaved sequences of imagesand text in a dialogue manner.</description><author>João Daniel Silva, João Magalhães, Devis Tuia, Bruno Martins</author><pubDate>Fri, 09 Feb 2024 15:31:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06475v1</guid></item><item><title>ALEXSIS-PT: A New Resource for Portuguese Lexical Simplification</title><link>http://arxiv.org/abs/2209.09034v2</link><description>Lexical simplification (LS) is the task of automatically replacing complexwords for easier ones making texts more accessible to various targetpopulations (e.g. individuals with low literacy, individuals with learningdisabilities, second language learners). To train and test models, LS systemsusually require corpora that feature complex words in context along with theircandidate substitutions. To continue improving the performance of LS systems weintroduce ALEXSIS-PT, a novel multi-candidate dataset for Brazilian PortugueseLS containing 9,605 candidate substitutions for 387 complex words. ALEXSIS-PThas been compiled following the ALEXSIS protocol for Spanish opening excitingnew avenues for cross-lingual models. ALEXSIS-PT is the first LSmulti-candidate dataset that contains Brazilian newspaper articles. Weevaluated four models for substitute generation on this dataset, namelymDistilBERT, mBERT, XLM-R, and BERTimbau. BERTimbau achieved the highestperformance across all evaluation metrics.</description><author>Kai North, Marcos Zampieri, Tharindu Ranasinghe</author><pubDate>Fri, 09 Feb 2024 15:30:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.09034v2</guid></item><item><title>Redefining Counterfactual Explanations for Reinforcement Learning: Overview, Challenges and Opportunities</title><link>http://arxiv.org/abs/2210.11846v2</link><description>While AI algorithms have shown remarkable success in various fields, theirlack of transparency hinders their application to real-life tasks. Althoughexplanations targeted at non-experts are necessary for user trust and human-AIcollaboration, the majority of explanation methods for AI are focused ondevelopers and expert users. Counterfactual explanations are local explanationsthat offer users advice on what can be changed in the input for the output ofthe black-box model to change. Counterfactuals are user-friendly and provideactionable advice for achieving the desired output from the AI system. Whileextensively researched in supervised learning, there are few methods applyingthem to reinforcement learning (RL). In this work, we explore the reasons forthe underrepresentation of a powerful explanation method in RL. We start byreviewing the current work in counterfactual explanations in supervisedlearning. Additionally, we explore the differences between counterfactualexplanations in supervised learning and RL and identify the main challengesthat prevent the adoption of methods from supervised in reinforcement learning.Finally, we redefine counterfactuals for RL and propose research directions forimplementing counterfactuals in RL.</description><author>Jasmina Gajcin, Ivana Dusparic</author><pubDate>Fri, 09 Feb 2024 15:28:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.11846v2</guid></item><item><title>"When He Feels Cold, He Goes to the Seahorse"-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy</title><link>http://arxiv.org/abs/2402.06472v1</link><description>Storymaking, as an integrative form of expressive arts therapy, is aneffective means to foster family communication. Yet, the integration ofgenerative AI as expressive materials in therapeutic storymaking remainsunderexplored. And there is a lack of HCI implications on how to supportfamilies and therapists in this context. Addressing this, our study involvedfive weeks of storymaking sessions with seven families guided by a professionaltherapist. In these sessions, the families used both traditional art-makingmaterials and image-based generative AI to create and evolve their familystories. Via the rich empirical data and commentaries from four experttherapists, we contextualize how families creatively melded AI and traditionalexpressive materials to externalize their ideas and feelings. Through the lensof Expressive Therapies Continuum (ETC), we characterize the therapeuticimplications of AI as expressive materials. Desirable interaction qualities tosupport children, parents, and therapists are distilled for future HCIresearch.</description><author>Di Liu, Hanqing Zhou, Pengcheng An</author><pubDate>Fri, 09 Feb 2024 15:25:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06472v1</guid></item><item><title>How Graph Structure and Label Dependencies Contribute to Node Classification in a Large Network of Documents</title><link>http://arxiv.org/abs/2304.01235v2</link><description>We introduce a new dataset named WikiVitals which contains a large graph of48k mutually referred Wikipedia articles classified into 32 categories andconnected by 2.3M edges. Our aim is to rigorously evaluate the contributions ofthree distinct sources of information to the label prediction in asemi-supervised node classification setting, namely the content of thearticles, their connections with each other and the correlations among theirlabels. We perform this evaluation using a Graph Markov Neural Network whichprovides a theoretically principled model for this task and we conduct adetailed evaluation of the contributions of each sources of information using aclear separation of model selection and model assessment. One interestingobservation is that including the effect of label dependencies is more relevantfor sparse train sets than it is for dense train sets.</description><author>Pirmin Lemberger, Antoine Saillenfest</author><pubDate>Fri, 09 Feb 2024 15:22:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.01235v2</guid></item><item><title>On Differentially Private Subspace Estimation Without Distributional Assumptions</title><link>http://arxiv.org/abs/2402.06465v1</link><description>Private data analysis faces a significant challenge known as the curse ofdimensionality, leading to increased costs. However, many datasets possess aninherent low-dimensional structure. For instance, during optimization viagradient descent, the gradients frequently reside near a low-dimensionalsubspace. If the low-dimensional structure could be privately identified usinga small amount of points, we could avoid paying (in terms of privacy andaccuracy) for the high ambient dimension. On the negative side, Dwork, Talwar, Thakurta, and Zhang (STOC 2014) provedthat privately estimating subspaces, in general, requires an amount of pointsthat depends on the dimension. But Singhal and Steinke (NeurIPS 2021) bypassedthis limitation by considering points that are i.i.d. samples from a Gaussiandistribution whose covariance matrix has a certain eigenvalue gap. Yet, it wasstill left unclear whether we could provide similar upper bounds withoutdistributional assumptions and whether we could prove lower bounds that dependon similar eigenvalue gaps. In this work, we make progress in both directions. We formulate the problemof private subspace estimation under two different types of singular value gapsof the input data and prove new upper and lower bounds for both types. Inparticular, our results determine what type of gap is sufficient and necessaryfor estimating a subspace with an amount of points that is independent of thedimension.</description><author>Eliad Tsfadia</author><pubDate>Fri, 09 Feb 2024 15:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06465v1</guid></item><item><title>Cardiac ultrasound simulation for autonomous ultrasound navigation</title><link>http://arxiv.org/abs/2402.06463v1</link><description>Ultrasound is well-established as an imaging modality for diagnostic andinterventional purposes. However, the image quality varies with operator skillsas acquiring and interpreting ultrasound images requires extensive training dueto the imaging artefacts, the range of acquisition parameters and thevariability of patient anatomies. Automating the image acquisition task couldimprove acquisition reproducibility and quality but training such an algorithmrequires large amounts of navigation data, not saved in routine examinations.Thus, we propose a method to generate large amounts of ultrasound images fromother modalities and from arbitrary positions, such that this pipeline canlater be used by learning algorithms for navigation. We present a novelsimulation pipeline which uses segmentations from other modalities, anoptimized volumetric data representation and GPU-accelerated Monte Carlo pathtracing to generate view-dependent and patient-specific ultrasound images. Weextensively validate the correctness of our pipeline with a phantom experiment,where structures' sizes, contrast and speckle noise properties are assessed.Furthermore, we demonstrate its usability to train neural networks fornavigation in an echocardiography view classification experiment by generatingsynthetic images from more than 1000 patients. Networks pre-trained with oursimulations achieve significantly superior performance in settings where largereal datasets are not available, especially for under-represented classes. Theproposed approach allows for fast and accurate patient-specific ultrasoundimage generation, and its usability for training networks fornavigation-related tasks is demonstrated.</description><author>Abdoul Aziz Amadou, Laura Peralta, Paul Dryburgh, Paul Klein, Kaloian Petkov, Richard James Housden, Vivek Singh, Rui Liao, Young-Ho Kim, Florin Christian Ghesu, Tommaso Mansi, Ronak Rajani, Alistair Young, Kawal Rhode</author><pubDate>Fri, 09 Feb 2024 15:14:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06463v1</guid></item><item><title>Moco: A Learnable Meta Optimizer for Combinatorial Optimization</title><link>http://arxiv.org/abs/2402.04915v2</link><description>Relevant combinatorial optimization problems (COPs) are often NP-hard. Whilethey have been tackled mainly via handcrafted heuristics in the past, advancesin neural networks have motivated the development of general methods to learnheuristics from data. Many approaches utilize a neural network to directlyconstruct a solution, but are limited in further improving based on alreadyconstructed solutions at inference time. Our approach, Moco, learns a graphneural network that updates the solution construction procedure based onfeatures extracted from the current search state. This meta training proceduretargets the overall best solution found during the search procedure giveninformation such as the search budget. This allows Moco to adapt to varyingcircumstances such as different computational budgets. Moco is a fullylearnable meta optimizer that does not utilize any problem specific localsearch or decomposition. We test Moco on the Traveling Salesman Problem (TSP)and Maximum Independent Set (MIS) and show that it outperforms other approacheson MIS and is overall competitive on the TSP, especially outperforming relatedapproaches, partially even if they use additional local search.</description><author>Tim Dernedde, Daniela Thyssens, Sören Dittrich, Maximilian Stubbemann, Lars Schmidt-Thieme</author><pubDate>Fri, 09 Feb 2024 15:12:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04915v2</guid></item><item><title>Autoregressive with Slack Time Series Model for Forecasting a Partially-Observed Dynamical Time Series</title><link>http://arxiv.org/abs/2306.16593v2</link><description>This study delves into the domain of dynamical systems, specifically theforecasting of dynamical time series defined through an evolution function.Traditional approaches in this area predict the future behavior of dynamicalsystems by inferring the evolution function. However, these methods mayconfront obstacles due to the presence of missing variables, which are usuallyattributed to challenges in measurement and a partial understanding of thesystem of interest. To overcome this obstacle, we introduce the autoregressivewith slack time series (ARS) model, that simultaneously estimates the evolutionfunction and imputes missing variables as a slack time series. Assumingtime-invariance and linearity in the (underlying) entire dynamical time series,our experiments demonstrate the ARS model's capability to forecast future timeseries. From a theoretical perspective, we prove that a 2-dimensionaltime-invariant and linear system can be reconstructed by utilizing observationsfrom a single, partially observed dimension of the system.</description><author>Akifumi Okuno, Yuya Morishita, Yoh-ichi Mototake</author><pubDate>Fri, 09 Feb 2024 15:11:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16593v2</guid></item><item><title>Learning Coverage Paths in Unknown Environments with Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2306.16978v3</link><description>Coverage path planning (CPP) is the problem of finding a path that covers theentire free space of a confined area, with applications ranging from roboticlawn mowing to search-and-rescue. When the environment is unknown, the pathneeds to be planned online while mapping the environment, which cannot beaddressed by offline planning methods that do not allow for a flexible pathspace. We investigate how suitable reinforcement learning is for thischallenging problem, and analyze the involved components required toefficiently learn coverage paths, such as action space, input featurerepresentation, neural network architecture, and reward function. We propose acomputationally feasible egocentric map representation based on frontiers, anda novel reward term based on total variation to promote complete coverage.Through extensive experiments, we show that our approach surpasses theperformance of both previous RL-based approaches and highly specialized methodsacross multiple CPP variations.</description><author>Arvi Jonnarth, Jie Zhao, Michael Felsberg</author><pubDate>Fri, 09 Feb 2024 15:09:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16978v3</guid></item><item><title>Sequential Flow Matching for Generative Modeling</title><link>http://arxiv.org/abs/2402.06461v1</link><description>Straightening the probability flow of the continuous-time generative models,such as diffusion models or flow-based models, is the key to fast samplingthrough the numerical solvers, existing methods learn a linear path by directlygenerating the probability path the joint distribution between the noise anddata distribution. One key reason for the slow sampling speed of the ODE-basedsolvers that simulate these generative models is the global truncation error ofthe ODE solver, caused by the high curvature of the ODE trajectory, whichexplodes the truncation error of the numerical solvers in the low-NFE regime.To address this challenge, We propose a novel method called SeqRF, a learningtechnique that straightens the probability flow to reduce the global truncationerror and hence enable acceleration of sampling and improve the synthesisquality. In both theoretical and empirical studies, we first observe thestraightening property of our SeqRF. Through empirical evaluations via SeqRFover flow-based generative models, We achieve surpassing results on CIFAR-10,CelebA-$64 \times 64$, and LSUN-Church datasets.</description><author>Jongmin Yoon, Juho Lee</author><pubDate>Fri, 09 Feb 2024 15:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06461v1</guid></item><item><title>V-STaR: Training Verifiers for Self-Taught Reasoners</title><link>http://arxiv.org/abs/2402.06457v1</link><description>Common self-improvement approaches for large language models (LLMs), such asSTaR (Zelikman et al., 2022), iteratively fine-tune LLMs on self-generatedsolutions to improve their problem-solving ability. However, these approachesdiscard the large amounts of incorrect solutions generated during this process,potentially neglecting valuable information in such solutions. To address thisshortcoming, we propose V-STaR that utilizes both the correct and incorrectsolutions generated during the self-improvement process to train a verifierusing DPO that judges correctness of model-generated solutions. This verifieris used at inference time to select one solution among many candidatesolutions. Running V-STaR for multiple iterations results in progressivelybetter reasoners and verifiers, delivering a 4% to 17% test accuracyimprovement over existing self-improvement and verification approaches oncommon code generation and math reasoning benchmarks with LLaMA2 models.</description><author>Arian Hosseini, Xingdi Yuan, Nikolay Malkin, Aaron Courville, Alessandro Sordoni, Rishabh Agarwal</author><pubDate>Fri, 09 Feb 2024 15:02:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06457v1</guid></item><item><title>An Algorithmic Framework for Constructing Multiple Decision Trees by Evaluating Their Combination Performance Throughout the Construction Process</title><link>http://arxiv.org/abs/2402.06452v1</link><description>Predictions using a combination of decision trees are known to be effectivein machine learning. Typical ideas for constructing a combination of decisiontrees for prediction are bagging and boosting. Bagging independently constructsdecision trees without evaluating their combination performance and averagesthem afterward. Boosting constructs decision trees sequentially, onlyevaluating a combination performance of a new decision tree and the fixed pastdecision trees at each step. Therefore, neither method directly constructs norevaluates a combination of decision trees for the final prediction. When thefinal prediction is based on a combination of decision trees, it is natural toevaluate the appropriateness of the combination when constructing them. In thisstudy, we propose a new algorithmic framework that constructs decision treessimultaneously and evaluates their combination performance throughout theconstruction process. Our framework repeats two procedures. In the firstprocedure, we construct new candidates of combinations of decision trees tofind a proper combination of decision trees. In the second procedure, weevaluate each combination performance of decision trees under some criteria andselect a better combination. To confirm the performance of the proposedframework, we perform experiments on synthetic and benchmark data.</description><author>Keito Tajima, Naoki Ichijo, Yuta Nakahara, Toshiyasu Matsushima</author><pubDate>Fri, 09 Feb 2024 14:58:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06452v1</guid></item><item><title>Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts</title><link>http://arxiv.org/abs/2305.07572v2</link><description>Originally introduced as a neural network for ensemble learning, mixture ofexperts (MoE) has recently become a fundamental building block of highlysuccessful modern deep neural networks for heterogeneous data analysis inseveral applications of machine learning and statistics. Despite its popularityin practice, a satisfactory level of theoretical understanding of the MoE modelis far from complete. To shed new light on this problem, we provide aconvergence analysis for maximum likelihood estimation (MLE) in theGaussian-gated MoE model. The main challenge of that analysis comes from theinclusion of covariates in the Gaussian gating functions and expert networks,which leads to their intrinsic interaction via some partial differentialequations with respect to their parameters. We tackle these issues by designingnovel Voronoi loss functions among parameters to accurately capture theheterogeneity of parameter estimation rates. Our findings reveal that the MLEhas distinct behaviors under two complement settings of location parameters ofthe Gaussian gating functions, namely when all these parameters are non-zeroversus when at least one among them vanishes. Notably, these behaviors can becharacterized by the solvability of two different systems of polynomialequations. Finally, we conduct a simulation study to empirically verify ourtheoretical results.</description><author>Huy Nguyen, TrungTin Nguyen, Khai Nguyen, Nhat Ho</author><pubDate>Fri, 09 Feb 2024 14:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07572v2</guid></item><item><title>ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation</title><link>http://arxiv.org/abs/2402.06446v1</link><description>Data generation is recognized as a potent strategy for unsupervised domainadaptation (UDA) pertaining semantic segmentation in adverse weathers.Nevertheless, these adverse weather scenarios encompass multiple possibilities,and high-fidelity data synthesis with controllable weather is under-researchedin previous UDA works. The recent strides in large-scale text-to-imagediffusion models (DM) have ushered in a novel avenue for research, enabling thegeneration of realistic images conditioned on semantic labels. This capabilityproves instrumental for cross-domain data synthesis from source to targetdomain owing to their shared label space. Thus, source domain labels can bepaired with those generated pseudo target data for training UDA. However, fromthe UDA perspective, there exists several challenges for DM training: (i)ground-truth labels from target domain are missing; (ii) the prompt generatormay produce vague or noisy descriptions of images from adverse weathers; (iii)existing arts often struggle to well handle the complex scene structure andgeometry of urban scenes when conditioned only on semantic labels. To tacklethe above issues, we propose ControlUDA, a diffusion-assisted frameworktailored for UDA segmentation under adverse weather conditions. It firstleverages target prior from a pre-trained segmentor for tuning the DM,compensating the missing target domain labels; It also contains UDAControlNet,a condition-fused multi-scale and prompt-enhanced network targeted athigh-fidelity data generation in adverse weathers. Training UDA with ourgenerated data brings the model performances to a new milestone (72.0 mIoU) onthe popular Cityscapes-to-ACDC benchmark for adverse weathers. Furthermore,ControlUDA helps to achieve good model generalizability on unseen data.</description><author>Fengyi Shen, Li Zhou, Kagan Kucukaytekin, Ziyuan Liu, He Wang, Alois Knoll</author><pubDate>Fri, 09 Feb 2024 14:48:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06446v1</guid></item><item><title>The Deep Equilibrium Algorithmic Reasoner</title><link>http://arxiv.org/abs/2402.06445v1</link><description>Recent work on neural algorithmic reasoning has demonstrated that graphneural networks (GNNs) could learn to execute classical algorithms. Doing so,however, has always used a recurrent architecture, where each iteration of theGNN aligns with an algorithm's iteration. Since an algorithm's solution isoften an equilibrium, we conjecture and empirically validate that one can traina network to solve algorithmic problems by directly finding the equilibrium.Note that this does not require matching each GNN iteration with a step of thealgorithm.</description><author>Dobrik Georgiev, Pietro Liò, Davide Buffelli</author><pubDate>Fri, 09 Feb 2024 14:46:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06445v1</guid></item><item><title>Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach</title><link>http://arxiv.org/abs/2402.06443v1</link><description>The rapid dissemination of misinformation through social media increased theimportance of automated fact-checking. Furthermore, studies on what deep neuralmodels pay attention to when making predictions have increased in recent years.While significant progress has been made in this field, it has not yet reacheda level of reasoning comparable to human reasoning. To address these gaps, wepropose a multi-task explainable neural model for misinformation detection.Specifically, this work formulates an explanation generation process of themodel's veracity prediction as a text summarization problem. Additionally, theperformance of the proposed model is discussed on publicly available datasetsand the findings are evaluated with related studies.</description><author>Recep Firat Cekinel, Pinar Karagoz</author><pubDate>Fri, 09 Feb 2024 14:39:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06443v1</guid></item><item><title>Incorporating Taylor Series and Recursive Structure in Neural Networks for Time Series Prediction</title><link>http://arxiv.org/abs/2402.06441v1</link><description>Time series analysis is relevant in various disciplines such as physics,biology, chemistry, and finance. In this paper, we present a novel neuralnetwork architecture that integrates elements from ResNet structures, whileintroducing the innovative incorporation of the Taylor series framework. Thisapproach demonstrates notable enhancements in test accuracy across many of thebaseline datasets investigated. Furthermore, we extend our method toincorporate a recursive step, which leads to even further improvements in testaccuracy. Our findings underscore the potential of our proposed model tosignificantly advance time series analysis methodologies, offering promisingavenues for future research and application.</description><author>Jarrod Mau, Kevin Moon</author><pubDate>Fri, 09 Feb 2024 14:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06441v1</guid></item><item><title>Improving 2D-3D Dense Correspondences with Diffusion Models for 6D Object Pose Estimation</title><link>http://arxiv.org/abs/2402.06436v1</link><description>Estimating 2D-3D correspondences between RGB images and 3D space is afundamental problem in 6D object pose estimation. Recent pose estimators usedense correspondence maps and Point-to-Point algorithms to estimate objectposes. The accuracy of pose estimation depends heavily on the quality of thedense correspondence maps and their ability to withstand occlusion, clutter,and challenging material properties. Currently, dense correspondence maps areestimated using image-to-image translation models based on GANs, Autoencoders,or direct regression models. However, recent advancements in image-to-imagetranslation have led to diffusion models being the superior choice whenevaluated on benchmarking datasets. In this study, we compare image-to-imagetranslation networks based on GANs and diffusion models for the downstream taskof 6D object pose estimation. Our results demonstrate that the diffusion-basedimage-to-image translation model outperforms the GAN, revealing potential forfurther improvements in 6D object pose estimation models.</description><author>Peter Hönig, Stefan Thalhammer, Markus Vincze</author><pubDate>Fri, 09 Feb 2024 14:27:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06436v1</guid></item><item><title>Where is the Truth? The Risk of Getting Confounded in a Continual World</title><link>http://arxiv.org/abs/2402.06434v1</link><description>A dataset is confounded if it is most easily solved via a spuriouscorrelation which fails to generalize to new data. We will show that, in acontinual learning setting where confounders may vary in time across tasks, theresulting challenge far exceeds the standard forgetting problem normallyconsidered. In particular, we derive mathematically the effect of suchconfounders on the space of valid joint solutions to sets of confounded tasks.Interestingly, our theory predicts that for many such continual datasets,spurious correlations are easily ignored when the tasks are trained on jointly,but it is far harder to avoid confounding when they are consideredsequentially. We construct such a dataset and demonstrate empirically thatstandard continual learning methods fail to ignore confounders, while trainingjointly on all tasks is successful. Our continually confounded dataset, ConCon,is based on CLEVR images and demonstrates the need for continual learningmethods with more robust behavior with respect to confounding.</description><author>Florian Peter Busch, Roshni Kamath, Rupert Mitchell, Wolfgang Stammer, Kristian Kersting, Martin Mundt</author><pubDate>Fri, 09 Feb 2024 14:24:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06434v1</guid></item><item><title>CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention</title><link>http://arxiv.org/abs/2402.06423v1</link><description>In autonomous driving, 3D lane detection using monocular cameras is animportant task for various downstream planning and control tasks. Recent CNNand Transformer approaches usually apply a two-stage scheme in the modeldesign. The first stage transforms the image feature from a front image into abird's-eye-view (BEV) representation. Subsequently, a sub-network processes theBEV feature map to generate the 3D detection results. However, these approachesheavily rely on a challenging image feature transformation module from aperspective view to a BEV representation. In our work, we presentCurveFormer++, a single-stage Transformer-based method that does not requirethe image feature view transform module and directly infers 3D lane detectionresults from the perspective image features. Specifically, our approach modelsthe 3D detection task as a curve propagation problem, where each lane isrepresented by a curve query with a dynamic and ordered anchor point set. Byemploying a Transformer decoder, the model can iteratively refine the 3D lanedetection results. A curve cross-attention module is introduced in theTransformer decoder to calculate similarities between image features and curvequeries of lanes. To handle varying lane lengths, we employ context samplingand anchor point restriction techniques to compute more relevant image featuresfor a curve query. Furthermore, we apply a temporal fusion module thatincorporates selected informative sparse curve queries and their correspondinganchor point sets to leverage historical lane information. In the experiments,we evaluate our approach for the 3D lane detection task on two publiclyavailable real-world datasets. The results demonstrate that our method providesoutstanding performance compared with both CNN and Transformer based methods.We also conduct ablation studies to analyze the impact of each component in ourapproach.</description><author>Yifeng Bai, Zhirong Chen, Pengpeng Liang, Erkang Cheng</author><pubDate>Fri, 09 Feb 2024 14:13:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06423v1</guid></item></channel></rss>