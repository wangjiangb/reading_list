<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 28 May 2024 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Matryoshka Multimodal Models</title><link>http://arxiv.org/abs/2405.17430v1</link><description>Large Multimodal Models (LMMs) such as LLaVA have shown strong performance invisual-linguistic reasoning. These models first embed images into a fixed largenumber of visual tokens and then feed them into a Large Language Model (LLM).However, this design causes an excessive number of tokens for dense visualscenarios such as high-resolution images and videos, leading to greatinefficiency. While token pruning/merging methods do exist, they produce asingle length output for each image and do not afford flexibility in tradingoff information density v.s. efficiency. Inspired by the concept of MatryoshkaDolls, we propose M3: Matryoshka Multimodal Models, which learns to representvisual content as nested sets of visual tokens that capture information acrossmultiple coarse-to-fine granularities. Our approach offers several uniquebenefits for LMMs: (1) One can explicitly control the visual granularity pertest instance during inference, e.g. , adjusting the number of tokens used torepresent an image based on the anticipated complexity or simplicity of thecontent; (2) M3 provides a framework for analyzing the granularity needed forexisting datasets, where we find that COCO-style benchmarks only need around ~9visual tokens to obtain accuracy similar to that of using all 576 tokens; (3)Our approach provides a foundation to explore the best trade-off betweenperformance and visual token length at sample level, where our investigationreveals that a large gap exists between the oracle upper bound and currentfixed-scale representations.</description><author>Mu Cai, Jianwei Yang, Jianfeng Gao, Yong Jae Lee</author><pubDate>Mon, 27 May 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17430v1</guid></item><item><title>GaussianFormer: Scene as Gaussians for Vision-Based 3D Semantic Occupancy Prediction</title><link>http://arxiv.org/abs/2405.17429v1</link><description>3D semantic occupancy prediction aims to obtain 3D fine-grained geometry andsemantics of the surrounding scene and is an important task for the robustnessof vision-centric autonomous driving. Most existing methods employ dense gridssuch as voxels as scene representations, which ignore the sparsity of occupancyand the diversity of object scales and thus lead to unbalanced allocation ofresources. To address this, we propose an object-centric representation todescribe 3D scenes with sparse 3D semantic Gaussians where each Gaussianrepresents a flexible region of interest and its semantic features. Weaggregate information from images through the attention mechanism anditeratively refine the properties of 3D Gaussians including position,covariance, and semantics. We then propose an efficient Gaussian-to-voxelsplatting method to generate 3D occupancy predictions, which only aggregatesthe neighboring Gaussians for a certain position. We conduct extensiveexperiments on the widely adopted nuScenes and KITTI-360 datasets. Experimentalresults demonstrate that GaussianFormer achieves comparable performance withstate-of-the-art methods with only 17.8% - 24.8% of their memory consumption.Code is available at: https://github.com/huang-yh/GaussianFormer.</description><author>Yuanhui Huang, Wenzhao Zheng, Yunpeng Zhang, Jie Zhou, Jiwen Lu</author><pubDate>Mon, 27 May 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17429v1</guid></item><item><title>NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models</title><link>http://arxiv.org/abs/2405.17428v1</link><description>Decoder-only large language model (LLM)-based embedding models are beginningto outperform BERT or T5-based embedding models in general-purpose textembedding tasks, including dense vector-based retrieval. In this work, weintroduce the NV-Embed model with a variety of architectural designs andtraining procedures to significantly enhance the performance of LLM as aversatile embedding model, while maintaining its simplicity andreproducibility. For model architecture, we propose a latent attention layer toobtain pooled embeddings, which consistently improves retrieval and downstreamtask accuracy compared to mean pooling or using the last &lt;EOS&gt; token embeddingfrom LLMs. To enhance representation learning, we remove the causal attentionmask of LLMs during contrastive training. For model training, we introduce atwo-stage contrastive instruction-tuning method. It first applies contrastivetraining with instructions on retrieval datasets, utilizing in-batch negativesand curated hard negative examples. At stage-2, it blends various non-retrievaldatasets into instruction tuning, which not only enhances non-retrieval taskaccuracy but also improves retrieval performance. Combining these techniques,our NV-Embed model, using only publicly available data, has achieved arecord-high score of 69.32, ranking No. 1 on the Massive Text EmbeddingBenchmark (MTEB) (as of May 24, 2024), with 56 tasks, encompassing retrieval,reranking, classification, clustering, and semantic textual similarity tasks.Notably, our model also attains the highest score of 59.36 on 15 retrievaltasks in the MTEB benchmark (also known as BEIR). We will open-source the modelat: https://huggingface.co/nvidia/NV-Embed-v1.</description><author>Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping</author><pubDate>Mon, 27 May 2024 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17428v1</guid></item><item><title>Reason3D: Searching and Reasoning 3D Segmentation via Large Language Model</title><link>http://arxiv.org/abs/2405.17427v1</link><description>Recent advancements in multimodal large language models (LLMs) have showntheir potential in various domains, especially concept reasoning. Despite thesedevelopments, applications in understanding 3D environments remain limited.This paper introduces Reason3D, a novel LLM designed for comprehensive 3Dunderstanding. Reason3D takes point cloud data and text prompts as input toproduce textual responses and segmentation masks, facilitating advanced taskslike 3D reasoning segmentation, hierarchical searching, express referring, andquestion answering with detailed mask outputs. Specifically, we propose ahierarchical mask decoder to locate small objects within expansive scenes. Thisdecoder initially generates a coarse location estimate covering the object'sgeneral area. This foundational estimation facilitates a detailed,coarse-to-fine segmentation strategy that significantly enhances the precisionof object identification and segmentation. Experiments validate that Reason3Dachieves remarkable results on large-scale ScanNet and Matterport3D datasetsfor 3D express referring, 3D question answering, and 3D reasoning segmentationtasks. Code and models are available at:https://github.com/KuanchihHuang/Reason3D.</description><author>Kuan-Chih Huang, Xiangtai Li, Lu Qi, Shuicheng Yan, Ming-Hsuan Yang</author><pubDate>Mon, 27 May 2024 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17427v1</guid></item><item><title>Benchmarking and Improving Bird's Eye View Perception Robustness in Autonomous Driving</title><link>http://arxiv.org/abs/2405.17426v1</link><description>Recent advancements in bird's eye view (BEV) representations have shownremarkable promise for in-vehicle 3D perception. However, while these methodshave achieved impressive results on standard benchmarks, their robustness invaried conditions remains insufficiently assessed. In this study, we presentRoboBEV, an extensive benchmark suite designed to evaluate the resilience ofBEV algorithms. This suite incorporates a diverse set of camera corruptiontypes, each examined over three severity levels. Our benchmarks also considerthe impact of complete sensor failures that occur when using multi-modalmodels. Through RoboBEV, we assess 33 state-of-the-art BEV-based perceptionmodels spanning tasks like detection, map segmentation, depth estimation, andoccupancy prediction. Our analyses reveal a noticeable correlation between themodel's performance on in-distribution datasets and its resilience toout-of-distribution challenges. Our experimental results also underline theefficacy of strategies like pre-training and depth-free BEV transformations inenhancing robustness against out-of-distribution data. Furthermore, we observethat leveraging extensive temporal information significantly improves themodel's robustness. Based on our observations, we design an effectiverobustness enhancement strategy based on the CLIP model. The insights from thisstudy pave the way for the development of future BEV models that seamlesslycombine accuracy with real-world robustness.</description><author>Shaoyuan Xie, Lingdong Kong, Wenwei Zhang, Jiawei Ren, Liang Pan, Kai Chen, Ziwei Liu</author><pubDate>Mon, 27 May 2024 18:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17426v1</guid></item><item><title>From Neurons to Neutrons: A Case Study in Interpretability</title><link>http://arxiv.org/abs/2405.17425v1</link><description>Mechanistic Interpretability (MI) promises a path toward fully understandinghow neural networks make their predictions. Prior work demonstrates that evenwhen trained to perform simple arithmetic, models can implement a variety ofalgorithms (sometimes concurrently) depending on initialization andhyperparameters. Does this mean neuron-level interpretability techniques havelimited applicability? We argue that high-dimensional neural networks can learnlow-dimensional representations of their training data that are useful beyondsimply making good predictions. Such representations can be understood throughthe mechanistic interpretability lens and provide insights that aresurprisingly faithful to human-derived domain knowledge. This indicates thatsuch approaches to interpretability can be useful for deriving a newunderstanding of a problem from models trained to solve it. As a case study, weextract nuclear physics concepts by studying models trained to reproducenuclear data.</description><author>Ouail Kitouni, Niklas Nolte, Víctor Samuel Pérez-Díaz, Sokratis Trifinopoulos, Mike Williams</author><pubDate>Mon, 27 May 2024 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17425v1</guid></item><item><title>LARM: Large Auto-Regressive Model for Long-Horizon Embodied Intelligence</title><link>http://arxiv.org/abs/2405.17424v1</link><description>Due to the need to interact with the real world, embodied agents are requiredto possess comprehensive prior knowledge, long-horizon planning capability, anda swift response speed. Despite recent large language model (LLM) based agentsachieving promising performance, they still exhibit several limitations. Forinstance, the output of LLMs is a descriptive sentence, which is ambiguous whendetermining specific actions. To address these limitations, we introduce thelarge auto-regressive model (LARM). LARM leverages both text and multi-viewimages as input and predicts subsequent actions in an auto-regressive manner.To train LARM, we develop a novel data format named auto-regressive nodetransmission structure and assemble a corresponding dataset. Adopting atwo-phase training regimen, LARM successfully harvests enchanted equipment inMinecraft, which demands significantly more complex decision-making chains thanthe highest achievements of prior best methods. Besides, the speed of LARM is6.8x faster.</description><author>Zhuoling Li, Xiaogang Xu, Zhenhua Xu, SerNam Lim, Hengshuang Zhao</author><pubDate>Mon, 27 May 2024 18:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17424v1</guid></item><item><title>Privacy-Aware Visual Language Models</title><link>http://arxiv.org/abs/2405.17423v1</link><description>This paper aims to advance our understanding of how Visual Language Models(VLMs) handle privacy-sensitive information, a crucial concern as thesetechnologies become integral to everyday life. To this end, we introduce a newbenchmark PrivBench, which contains images from 8 sensitive categories such aspassports, or fingerprints. We evaluate 10 state-of-the-art VLMs on thisbenchmark and observe a generally limited understanding of privacy,highlighting a significant area for model improvement. Based on this weintroduce PrivTune, a new instruction-tuning dataset aimed at equipping VLMswith knowledge about visual privacy. By tuning two pretrained VLMs, TinyLLaVaand MiniGPT-v2, on this small dataset, we achieve strong gains in their abilityto recognize sensitive content, outperforming even GPT4-V. At the same time, weshow that privacy-tuning only minimally affects the VLMs performance onstandard benchmarks such as VQA. Overall, this paper lays out a crucialchallenge for making VLMs effective in handling real-world data safely andprovides a simple recipe that takes the first step towards buildingprivacy-aware VLMs.</description><author>Laurens Samson, Nimrod Barazani, Sennay Ghebreab, Yuki M. Asano</author><pubDate>Mon, 27 May 2024 18:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17423v1</guid></item><item><title>Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection</title><link>http://arxiv.org/abs/2405.17422v1</link><description>3D object detection aims to recover the 3D information of concerning objectsand serves as the fundamental task of autonomous driving perception. Itsperformance greatly depends on the scale of labeled training data, yet it iscostly to obtain high-quality annotations for point cloud data. Whileconventional methods focus on generating pseudo-labels for unlabeled samples assupplements for training, the structural nature of 3D point cloud datafacilitates the composition of objects and backgrounds to synthesize realisticscenes. Motivated by this, we propose a hardness-aware scene synthesis (HASS)method to generate adaptive synthetic scenes to improve the generalization ofthe detection models. We obtain pseudo-labels for unlabeled objects andgenerate diverse scenes with different compositions of objects and backgrounds.As the scene synthesis is sensitive to the quality of pseudo-labels, we furtherpropose a hardness-aware strategy to reduce the effect of low-qualitypseudo-labels and maintain a dynamic pseudo-database to ensure the diversityand quality of synthetic scenes. Extensive experimental results on the widelyused KITTI and Waymo datasets demonstrate the superiority of the proposed HASSmethod, which outperforms existing semi-supervised learning methods on 3Dobject detection. Code: https://github.com/wzzheng/HASS.</description><author>Shuai Zeng, Wenzhao Zheng, Jiwen Lu, Haibin Yan</author><pubDate>Mon, 27 May 2024 18:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17422v1</guid></item><item><title>Towards Calibrated Robust Fine-Tuning of Vision-Language Models</title><link>http://arxiv.org/abs/2311.01723v5</link><description>Improving out-of-distribution (OOD) generalization through in-distribution(ID) adaptation is a primary goal of robust fine-tuning methods beyond thenaive fine-tuning approach. However, despite decent OOD generalizationperformance from recent robust fine-tuning methods, OOD confidence calibrationfor reliable machine learning has not been fully addressed. This work proposesa robust fine-tuning method that improves both OOD accuracy and calibrationerror in Vision Language Models (VLMs). Firstly, we show that both types oferrors have a shared upper bound consisting of two terms of ID data: 1)calibration error and 2) the smallest singular value of the input covariancematrix. Based on this insight, we design a novel framework that conductsfine-tuning with a constrained multimodal contrastive loss enforcing a largersmallest singular value, which is further aided by the self-distillation of amoving averaged model to achieve well-calibrated prediction. Starting from anempirical validation of our theoretical statements, we provide extensiveexperimental results on ImageNet distribution shift benchmarks that demonstratethe effectiveness of our method.</description><author>Changdae Oh, Hyesu Lim, Mijoo Kim, Dongyoon Han, Sangdoo Yun, Jaegul Choo, Alexander Hauptmann, Zhi-Qi Cheng, Kyungwoo Song</author><pubDate>Mon, 27 May 2024 18:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01723v5</guid></item><item><title>MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds</title><link>http://arxiv.org/abs/2405.17421v1</link><description>We introduce 4D Motion Scaffolds (MoSca), a neural information processingsystem designed to reconstruct and synthesize novel views of dynamic scenesfrom monocular videos captured casually in the wild. To address such achallenging and ill-posed inverse problem, we leverage prior knowledge fromfoundational vision models, lift the video data to a novel Motion Scaffold(MoSca) representation, which compactly and smoothly encodes the underlyingmotions / deformations. The scene geometry and appearance are then disentangledfrom the deformation field, and are encoded by globally fusing the Gaussiansanchored onto the MoSca and optimized via Gaussian Splatting. Additionally,camera poses can be seamlessly initialized and refined during the dynamicrendering process, without the need for other pose estimation tools.Experiments demonstrate state-of-the-art performance on dynamic renderingbenchmarks.</description><author>Jiahui Lei, Yijia Weng, Adam Harley, Leonidas Guibas, Kostas Daniilidis</author><pubDate>Mon, 27 May 2024 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17421v1</guid></item><item><title>Survival of the Fittest Representation: A Case Study with Modular Addition</title><link>http://arxiv.org/abs/2405.17420v1</link><description>When a neural network can learn multiple distinct algorithms to solve a task,how does it "choose" between them during training? To approach this question,we take inspiration from ecology: when multiple species coexist, theyeventually reach an equilibrium where some survive while others die out.Analogously, we suggest that a neural network at initialization contains manysolutions (representations and algorithms), which compete with each other underpressure from resource constraints, with the "fittest" ultimately prevailing.To investigate this Survival of the Fittest hypothesis, we conduct a case studyon neural networks performing modular addition, and find that these networks'multiple circular representations at different Fourier frequencies undergo suchcompetitive dynamics, with only a few circles surviving at the end. We findthat the frequencies with high initial signals and gradients, the "fittest,"are more likely to survive. By increasing the embedding dimension, we alsoobserve more surviving frequencies. Inspired by the Lotka-Volterra equationsdescribing the dynamics between species, we find that the dynamics of thecircles can be nicely characterized by a set of linear differential equations.Our results with modular addition show that it is possible to decomposecomplicated representations into simpler components, along with their basicinteractions, to offer insight on the training dynamics of representations.</description><author>Xiaoman Delores Ding, Zifan Carl Guo, Eric J. Michaud, Ziming Liu, Max Tegmark</author><pubDate>Mon, 27 May 2024 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17420v1</guid></item><item><title>MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities</title><link>http://arxiv.org/abs/2405.17419v1</link><description>Detecting out-of-distribution (OOD) samples is important for deployingmachine learning models in safety-critical applications such as autonomousdriving and robot-assisted surgery. Existing research has mainly focused onunimodal scenarios on image data. However, real-world applications areinherently multimodal, which makes it essential to leverage information frommultiple modalities to enhance the efficacy of OOD detection. To establish afoundation for more realistic Multimodal OOD Detection, we introduce thefirst-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizesand varying modality combinations. We first evaluate existing unimodal OODdetection algorithms on MultiOOD, observing that the mere inclusion ofadditional modalities yields substantial improvements. This underscores theimportance of utilizing multiple modalities for OOD detection. Based on theobservation of Modality Prediction Discrepancy between in-distribution (ID) andOOD data, and its strong correlation with OOD performance, we propose theAgree-to-Disagree (A2D) algorithm to encourage such discrepancy duringtraining. Moreover, we introduce a novel outlier synthesis method, NP-Mix,which explores broader feature spaces by leveraging the information fromnearest neighbor classes and complements A2D to strengthen OOD detectionperformance. Extensive experiments on MultiOOD demonstrate that training withA2D and NP-Mix improves existing OOD detection algorithms by a large margin.Our source code and MultiOOD benchmark are available athttps://github.com/donghao51/MultiOOD.</description><author>Hao Dong, Yue Zhao, Eleni Chatzi, Olga Fink</author><pubDate>Mon, 27 May 2024 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17419v1</guid></item><item><title>Self-Corrected Multimodal Large Language Model for End-to-End Robot Manipulation</title><link>http://arxiv.org/abs/2405.17418v1</link><description>Robot manipulation policies have shown unsatisfactory action performance whenconfronted with novel task or object instances. Hence, the capability toautomatically detect and self-correct failure action is essential for apractical robotic system. Recently, Multimodal Large Language Models (MLLMs)have shown promise in visual instruction following and demonstrated strongreasoning abilities in various tasks. To unleash general MLLMs as an end-to-endrobotic agent, we introduce a Self-Corrected (SC)-MLLM, equipping our model notonly to predict end-effector poses but also to autonomously recognize andcorrect failure actions. Specifically, we first conduct parameter-efficientfine-tuning to empower MLLM with pose prediction ability, which is reframed asa language modeling problem. When facing execution failures, our model learnsto identify low-level action error causes (i.e., position and rotation errors)and adaptively seeks prompt feedback from experts. Based on the feedback,SC-MLLM rethinks the current failure scene and generates the corrected actions.Furthermore, we design a continuous policy learning method for successfullycorrected samples, enhancing the model's adaptability to the current sceneconfiguration and reducing the frequency of expert intervention. To evaluateour SC-MLLM, we conduct extensive experiments in both simulation and real-worldsettings. SC-MLLM agent significantly improve manipulation accuracy compared toprevious state-of-the-art robotic MLLM (ManipLLM), increasing from 57\% to 79\%on seen object categories and from 47\% to 69\% on unseen novel categories.</description><author>Jiaming Liu, Chenxuan Li, Guanqun Wang, Lily Lee, Kaichen Zhou, Sixiang Chen, Chuyan Xiong, Jiaxin Ge, Renrui Zhang, Shanghang Zhang</author><pubDate>Mon, 27 May 2024 18:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17418v1</guid></item><item><title>A Recipe for Unbounded Data Augmentation in Visual Reinforcement Learning</title><link>http://arxiv.org/abs/2405.17416v1</link><description>$Q$-learning algorithms are appealing for real-world applications due totheir data-efficiency, but they are very prone to overfitting and traininginstabilities when trained from visual observations. Prior work, namely SVEA,finds that selective application of data augmentation can improve the visualgeneralization of RL agents without destabilizing training. We revisit itsrecipe for data augmentation, and find an assumption that limits itseffectiveness to augmentations of a photometric nature. Addressing theselimitations, we propose a generalized recipe, SADA, that works with widervarieties of augmentations. We benchmark its effectiveness on DMC-GB2 -- ourproposed extension of the popular DMControl Generalization Benchmark -- as wellas tasks from Meta-World and the Distracting Control Suite, and find that ourmethod, SADA, greatly improves training stability and generalization of RLagents across a diverse set of augmentations. Visualizations, code, andbenchmark: see https://aalmuzairee.github.io/SADA/</description><author>Abdulaziz Almuzairee, Nicklas Hansen, Henrik I. Christensen</author><pubDate>Mon, 27 May 2024 18:58:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17416v1</guid></item><item><title>Collaborative Video Diffusion: Consistent Multi-video Generation with Camera Control</title><link>http://arxiv.org/abs/2405.17414v1</link><description>Research on video generation has recently made tremendous progress, enablinghigh-quality videos to be generated from text prompts or images. Adding controlto the video generation process is an important goal moving forward and recentapproaches that condition video generation models on camera trajectories makestrides towards it. Yet, it remains challenging to generate a video of the samescene from multiple different camera trajectories. Solutions to thismulti-video generation problem could enable large-scale 3D scene generationwith editable camera trajectories, among other applications. We introducecollaborative video diffusion (CVD) as an important step towards this vision.The CVD framework includes a novel cross-video synchronization module thatpromotes consistency between corresponding frames of the same video renderedfrom different camera poses using an epipolar attention mechanism. Trained ontop of a state-of-the-art camera-control module for video generation, CVDgenerates multiple videos rendered from different camera trajectories withsignificantly better consistency than baselines, as shown in extensiveexperiments. Project page: https://collaborativevideodiffusion.github.io/.</description><author>Zhengfei Kuang, Shengqu Cai, Hao He, Yinghao Xu, Hongsheng Li, Leonidas Guibas, Gordon Wetzstein</author><pubDate>Mon, 27 May 2024 18:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17414v1</guid></item><item><title>Enhancing Music Genre Classification through Multi-Algorithm Analysis and User-Friendly Visualization</title><link>http://arxiv.org/abs/2405.17413v1</link><description>The aim of this study is to teach an algorithm how to recognize differenttypes of music. Users will submit songs for analysis. Since the algorithmhasn't heard these songs before, it needs to figure out what makes each songunique. It does this by breaking down the songs into different parts andstudying things like rhythm, melody, and tone via supervised learning becausethe program learns from examples that are already labelled. One important thingto consider when classifying music is its genre, which can be quite complex. Toensure accuracy, we use five different algorithms, each working independently,to analyze the songs. This helps us get a more complete understanding of eachsong's characteristics. Therefore, our goal is to correctly identify the genreof each submitted song. Once the analysis is done, the results are presentedusing a graphing tool, making it easy for users to understand and providefeedback.</description><author>Navin Kamuni, Dheerendra Panwar</author><pubDate>Mon, 27 May 2024 18:57:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17413v1</guid></item><item><title>Towards One Model for Classical Dimensionality Reduction: A Probabilistic Perspective on UMAP and t-SNE</title><link>http://arxiv.org/abs/2405.17412v1</link><description>This paper shows that the dimensionality reduction methods, UMAP and t-SNE,can be approximately recast as MAP inference methods corresponding to ageneralized Wishart-based model introduced in ProbDR. This interpretationoffers deeper theoretical insights into these algorithms, while introducingtools with which similar dimensionality reduction methods can be studied.</description><author>Aditya Ravuri, Neil D. Lawrence</author><pubDate>Mon, 27 May 2024 18:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17412v1</guid></item><item><title>SQLformer: Deep Auto-Regressive Query Graph Generation for Text-to-SQL Translation</title><link>http://arxiv.org/abs/2310.18376v4</link><description>In recent years, the task of text-to-SQL translation, which converts naturallanguage questions into executable SQL queries, has gained significantattention for its potential to democratize data access. Despite its promise,challenges such as adapting to unseen databases and aligning natural languagewith SQL syntax have hindered widespread adoption. To overcome these issues, weintroduce SQLformer, a novel Transformer architecture specifically crafted toperform text-to-SQL translation tasks. Our model predicts SQL queries asabstract syntax trees (ASTs) in an autoregressive way, incorporating structuralinductive bias in the encoder and decoder layers. This bias, guided by databasetable and column selection, aids the decoder in generating SQL query ASTsrepresented as graphs in a Breadth-First Search canonical order. Ourexperiments demonstrate that SQLformer achieves state-of-the-art performanceacross six prominent text-to-SQL benchmarks.</description><author>Adrián Bazaga, Pietro Liò, Gos Micklem</author><pubDate>Mon, 27 May 2024 18:55:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18376v4</guid></item><item><title>Deep Learning Calabi-Yau four folds with hybrid and recurrent neural network architectures</title><link>http://arxiv.org/abs/2405.17406v1</link><description>In this work, we report the results of applying deep learning based on hybridconvolutional-recurrent and purely recurrent neural network architectures tothe dataset of almost one million complete intersection Calabi-Yau four-folds(CICY4) to machine-learn their four Hodge numbers $h^{1,1}, h^{2,1}, h^{3,1},h^{2,2}$. In particular, we explored and experimented with twelve differentneural network models, nine of which are convolutional-recurrent (CNN-RNN)hybrids with the RNN unit being either GRU (Gated Recurrent Unit) or Long ShortTerm Memory (LSTM). The remaining four models are purely recurrent neuralnetworks based on LSTM. In terms of the $h^{1,1}, h^{2,1}, h^{3,1}, h^{2,2}$prediction accuracies, at 72% training ratio, our best performing individualmodel is CNN-LSTM-400, a hybrid CNN-LSTM with the LSTM hidden size of 400,which obtained 99.74%, 98.07%, 95.19%, 81.01%, our second best performingindividual model is LSTM-448, an LSTM-based model with the hidden size of 448,which obtained 99.74%, 97.51%, 94.24%, and 78.63%. These results were improvedby forming ensembles of the top two, three or even four models. Our bestensemble, consisting of the top three models, achieved the accuracies of99.80%, 98.40%, 95.80%, 83.02%. At 80% training ratio, the top two performingmodels LSTM-448 and LSTM-424 are both LSTM-based with the hidden sizes of 448and 424. Compared with the 72% training ratio, there is a significantimprovement of accuracies, which reached 99.85%, 98.66%, 96.26%, 84.77% for thebest individual model and 99.88%, 98.91%, 96.96%, 86.78% for the best ensemble.</description><author>H. L. Dao</author><pubDate>Mon, 27 May 2024 18:55:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17406v1</guid></item><item><title>Human4DiT: Free-view Human Video Generation with 4D Diffusion Transformer</title><link>http://arxiv.org/abs/2405.17405v1</link><description>We present a novel approach for generating high-quality, spatio-temporallycoherent human videos from a single image under arbitrary viewpoints. Ourframework combines the strengths of U-Nets for accurate condition injection anddiffusion transformers for capturing global correlations across viewpoints andtime. The core is a cascaded 4D transformer architecture that factorizesattention across views, time, and spatial dimensions, enabling efficientmodeling of the 4D space. Precise conditioning is achieved by injecting humanidentity, camera parameters, and temporal signals into the respectivetransformers. To train this model, we curate a multi-dimensional datasetspanning images, videos, multi-view data and 3D/4D scans, along with amulti-dimensional training strategy. Our approach overcomes the limitations ofprevious methods based on GAN or UNet-based diffusion models, which strugglewith complex motions and viewpoint changes. Through extensive experiments, wedemonstrate our method's ability to synthesize realistic, coherent andfree-view human videos, paving the way for advanced multimedia applications inareas such as virtual reality and animation. Our project website ishttps://human4dit.github.io.</description><author>Ruizhi Shao, Youxin Pang, Zerong Zheng, Jingxiang Sun, Yebin Liu</author><pubDate>Mon, 27 May 2024 18:53:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17405v1</guid></item><item><title>Spectral Greedy Coresets for Graph Neural Networks</title><link>http://arxiv.org/abs/2405.17404v1</link><description>The ubiquity of large-scale graphs in node-classification tasks significantlyhinders the real-world applications of Graph Neural Networks (GNNs). Nodesampling, graph coarsening, and dataset condensation are effective strategiesfor enhancing data efficiency. However, owing to the interdependence of graphnodes, coreset selection, which selects subsets of the data examples, has notbeen successfully applied to speed up GNN training on large graphs, warrantingspecial treatment. This paper studies graph coresets for GNNs and avoids theinterdependence issue by selecting ego-graphs (i.e., neighborhood subgraphsaround a node) based on their spectral embeddings. We decompose the coresetselection problem for GNNs into two phases: a coarse selection of widely spreadego graphs and a refined selection to diversify their topologies. We design agreedy algorithm that approximately optimizes both objectives. Our spectralgreedy graph coreset (SGGC) scales to graphs with millions of nodes, obviatesthe need for model pre-training, and applies to low-homophily graphs. Extensiveexperiments on ten datasets demonstrate that SGGC outperforms other coresetmethods by a wide margin, generalizes well across GNN architectures, and ismuch faster than graph condensation.</description><author>Mucong Ding, Yinhan He, Jundong Li, Furong Huang</author><pubDate>Mon, 27 May 2024 18:52:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17404v1</guid></item><item><title>Learning the mechanisms of network growth</title><link>http://arxiv.org/abs/2404.00793v3</link><description>We propose a novel model-selection method for dynamic networks. Our approachinvolves training a classifier on a large body of synthetic network data. Thedata is generated by simulating nine state-of-the-art random graph models fordynamic networks, with parameter range chosen to ensure exponential growth ofthe network size in time. We design a conceptually novel type of dynamicfeatures that count new links received by a group of vertices in a particulartime interval. The proposed features are easy to compute, analyticallytractable, and interpretable. Our approach achieves a near-perfectclassification of synthetic networks, exceeding the state-of-the-art by a largemargin. Applying our classification method to real-world citation networksgives credibility to the claims in the literature that models with preferentialattachment, fitness and aging fit real-world citation networks best, althoughsometimes, the predicted model does not involve vertex fitness.</description><author>Lourens Touwen, Doina Bucur, Remco van der Hofstad, Alessandro Garavaglia, Nelly Litvak</author><pubDate>Mon, 27 May 2024 18:52:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00793v3</guid></item><item><title>A Closer Look at Time Steps is Worthy of Triple Speed-Up for Diffusion Model Training</title><link>http://arxiv.org/abs/2405.17403v1</link><description>Training diffusion models is always a computation-intensive task. In thispaper, we introduce a novel speed-up method for diffusion model training,called, which is based on a closer look at time steps. Our key findings are: i)Time steps can be empirically divided into acceleration, deceleration, andconvergence areas based on the process increment. ii) These time steps areimbalanced, with many concentrated in the convergence area. iii) Theconcentrated steps provide limited benefits for diffusion training. To addressthis, we design an asymmetric sampling strategy that reduces the frequency ofsteps from the convergence area while increasing the sampling probability forsteps from other areas. Additionally, we propose a weighting strategy toemphasize the importance of time steps with rapid-change process increments. Asa plug-and-play and architecture-agnostic approach, SpeeD consistently achieves3-times acceleration across various diffusion architectures, datasets, andtasks. Notably, due to its simple design, our approach significantly reducesthe cost of diffusion model training with minimal overhead. Our researchenables more researchers to train diffusion models at a lower cost.</description><author>Kai Wang, Yukun Zhou, Mingjia Shi, Zhihang Yuan, Yuzhang Shang, Xiaojiang Peng, Hanwang Zhang, Yang You</author><pubDate>Mon, 27 May 2024 18:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17403v1</guid></item><item><title>THREAD: Thinking Deeper with Recursive Spawning</title><link>http://arxiv.org/abs/2405.17402v1</link><description>Large language models (LLMs) have shown impressive capabilities acrossdiverse settings, but still struggle as the length and complexity of thecontext increases. To address this challenge, we propose Thinking Recursivelyand Dynamically (ThReaD). THREAD frames model generation as a thread ofexecution that, based on the context, can run to completion or dynamicallyspawn new threads. By spawning, threads can offload work (e.g., thinking,retrieving information) to child threads, which only return tokens needed forthe parent thread to do its work. In effect, this enables the model to adapt,as needed, the amount of intermediate work used to produce tokens. We applyTHREAD in the settings of LLM task solving and question answering, where thedynamic threading allows the model to recursively decompose the given task orquestion into progressively simpler sub-problems that can be solved by separatechild threads. We test THREAD, implemented using a few-shot learning approach,on diverse benchmarks for agent tasks and data-grounded question answering.THREAD achieves state-of-the-art performance with GPT-4 and GPT-3.5 on thesebenchmarks, including ALFWorld, TextCraft, and WebShop, along with two newbenchmarks, DataCommons QA and MIMIC-III ICU QA. In addition, THREADoutperforms existing frameworks by 10% to 50% absolute points with smallermodels, including Llama-3-8b and CodeLlama-7b.</description><author>Philip Schroeder, Nathaniel Morgan, Hongyin Luo, James Glass</author><pubDate>Mon, 27 May 2024 18:51:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17402v1</guid></item><item><title>RB-Modulation: Training-Free Personalization of Diffusion Models using Stochastic Optimal Control</title><link>http://arxiv.org/abs/2405.17401v1</link><description>We propose Reference-Based Modulation (RB-Modulation), a new plug-and-playsolution for training-free personalization of diffusion models. Existingtraining-free approaches exhibit difficulties in (a) style extraction fromreference images in the absence of additional style or content textdescriptions, (b) unwanted content leakage from reference style images, and (c)effective composition of style and content. RB-Modulation is built on a novelstochastic optimal controller where a style descriptor encodes the desiredattributes through a terminal cost. The resulting drift not only overcomes thedifficulties above, but also ensures high fidelity to the reference style andadheres to the given text prompt. We also introduce a cross-attention-basedfeature aggregation scheme that allows RB-Modulation to decouple content andstyle from the reference image. With theoretical justification and empiricalevidence, our framework demonstrates precise extraction and control of contentand style in a training-free manner. Further, our method allows a seamlesscomposition of content and style, which marks a departure from the dependencyon external adapters or ControlNets.</description><author>Litu Rout, Yujia Chen, Nataniel Ruiz, Abhishek Kumar, Constantine Caramanis, Sanjay Shakkottai, Wen-Sheng Chu</author><pubDate>Mon, 27 May 2024 18:51:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17401v1</guid></item><item><title>Transformers Can Do Arithmetic with the Right Embeddings</title><link>http://arxiv.org/abs/2405.17399v1</link><description>The poor performance of transformers on arithmetic tasks seems to stem inlarge part from their inability to keep track of the exact position of eachdigit inside of a large span of digits. We mend this problem by adding anembedding to each digit that encodes its position relative to the start of thenumber. In addition to the boost these embeddings provide on their own, we showthat this fix enables architectural modifications such as input injection andrecurrent layers to improve performance even further. With positions resolved, we can study the logical extrapolation ability oftransformers. Can they solve arithmetic problems that are larger and morecomplex than those in their training data? We find that training on only 20digit numbers with a single GPU for one day, we can reach state-of-the-artperformance, achieving up to 99% accuracy on 100 digit addition problems.Finally, we show that these gains in numeracy also unlock improvements on othermulti-step reasoning tasks including sorting and multiplication.</description><author>Sean McLeish, Arpit Bansal, Alex Stein, Neel Jain, John Kirchenbauer, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, Jonas Geiping, Avi Schwarzschild, Tom Goldstein</author><pubDate>Mon, 27 May 2024 18:49:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17399v1</guid></item><item><title>Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability</title><link>http://arxiv.org/abs/2405.17398v1</link><description>World models can foresee the outcomes of different actions, which is ofparamount importance for autonomous driving. Nevertheless, existing drivingworld models still have limitations in generalization to unseen environments,prediction fidelity of critical details, and action controllability forflexible application. In this paper, we present Vista, a generalizable drivingworld model with high fidelity and versatile controllability. Based on asystematic diagnosis of existing methods, we introduce several key ingredientsto address these limitations. To accurately predict real-world dynamics at highresolution, we propose two novel losses to promote the learning of movinginstances and structural information. We also devise an effective latentreplacement approach to inject historical frames as priors for coherentlong-horizon rollouts. For action controllability, we incorporate a versatileset of controls from high-level intentions (command, goal point) to low-levelmaneuvers (trajectory, angle, and speed) through an efficient learningstrategy. After large-scale training, the capabilities of Vista can seamlesslygeneralize to different scenarios. Extensive experiments on multiple datasetsshow that Vista outperforms the most advanced general-purpose video generatorin over 70% of comparisons and surpasses the best-performing driving worldmodel by 55% in FID and 27% in FVD. Moreover, for the first time, we utilizethe capacity of Vista itself to establish a generalizable reward for real-worldaction evaluation without accessing the ground truth actions.</description><author>Shenyuan Gao, Jiazhi Yang, Li Chen, Kashyap Chitta, Yihang Qiu, Andreas Geiger, Jun Zhang, Hongyang Li</author><pubDate>Mon, 27 May 2024 18:49:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17398v1</guid></item><item><title>Occlusion Handling in 3D Human Pose Estimation with Perturbed Positional Encoding</title><link>http://arxiv.org/abs/2405.17397v1</link><description>Understanding human behavior fundamentally relies on accurate 3D human poseestimation. Graph Convolutional Networks (GCNs) have recently shown promisingadvancements, delivering state-of-the-art performance with rather lightweightarchitectures. In the context of graph-structured data, leveraging theeigenvectors of the graph Laplacian matrix for positional encoding iseffective. Yet, the approach does not specify how to handle scenarios whereedges in the input graph are missing. To this end, we propose a novelpositional encoding technique, PerturbPE, that extracts consistent and regularcomponents from the eigenbasis. Our method involves applying multipleperturbations and taking their average to extract the consistent and regularcomponent from the eigenbasis. PerturbPE leverages the Rayleigh-SchrodingerPerturbation Theorem (RSPT) for calculating the perturbed eigenvectors.Employing this labeling technique enhances the robustness and generalizabilityof the model. Our results support our theoretical findings, e.g. ourexperimental analysis observed a performance enhancement of up to $12\%$ on theHuman3.6M dataset in instances where occlusion resulted in the absence of oneedge. Furthermore, our novel approach significantly enhances performance inscenarios where two edges are missing, setting a new benchmark forstate-of-the-art.</description><author>Niloofar Azizi, Mohsen Fayyaz, Horst Bischof</author><pubDate>Mon, 27 May 2024 18:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17397v1</guid></item><item><title>The Expressive Capacity of State Space Models: A Formal Language Perspective</title><link>http://arxiv.org/abs/2405.17394v1</link><description>Recently, recurrent models based on linear state space models (SSMs) haveshown promising performance in language modeling (LM), competititve withtransformers. However, there is little understanding of the in-principleabilities of such models, which could provide useful guidance to the search forbetter LM architectures. We present a comprehensive theoretical study of thecapacity of such SSMs as it compares to that of transformers and traditionalRNNs. We find that SSMs and transformers have overlapping but distinctstrengths. In star-free state tracking, SSMs implement straightforward andexact solutions to problems that transformers struggle to represent exactly.They can also model bounded hierarchical structure with optimal memory evenwithout simulating a stack. On the other hand, we identify a design choice incurrent SSMs that limits their expressive power. We discuss implications forSSM and LM research, and verify results empirically on a recent SSM, Mamba.</description><author>Yash Sarrof, Yana Veitsman, Michael Hahn</author><pubDate>Mon, 27 May 2024 18:46:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17394v1</guid></item><item><title>EASI-Tex: Edge-Aware Mesh Texturing from Single Image</title><link>http://arxiv.org/abs/2405.17393v1</link><description>We present a novel approach for single-image mesh texturing, which employs adiffusion model with judicious conditioning to seamlessly transfer an object'stexture from a single RGB image to a given 3D mesh object. We do not assumethat the two objects belong to the same category, and even if they do, therecan be significant discrepancies in their geometry and part proportions. Ourmethod aims to rectify the discrepancies by conditioning a pre-trained StableDiffusion generator with edges describing the mesh through ControlNet, andfeatures extracted from the input image using IP-Adapter to generate texturesthat respect the underlying geometry of the mesh and the input texture withoutany optimization or training. We also introduce Image Inversion, a noveltechnique to quickly personalize the diffusion model for a single concept usinga single image, for cases where the pre-trained IP-Adapter falls short incapturing all the details from the input image faithfully. Experimental resultsdemonstrate the efficiency and effectiveness of our edge-aware single-imagemesh texturing approach, coined EASI-Tex, in preserving the details of theinput texture on diverse 3D objects, while respecting their geometry.</description><author>Sai Raj Kishore Perla, Yizhi Wang, Ali Mahdavi-Amiri, Hao Zhang</author><pubDate>Mon, 27 May 2024 18:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17393v1</guid></item><item><title>Dataset-learning duality and emergent criticality</title><link>http://arxiv.org/abs/2405.17391v1</link><description>In artificial neural networks, the activation dynamics of non-trainablevariables is strongly coupled to the learning dynamics of trainable variables.During the activation pass, the boundary neurons (e.g., input neurons) aremapped to the bulk neurons (e.g., hidden neurons), and during the learningpass, both bulk and boundary neurons are mapped to changes in trainablevariables (e.g., weights and biases). For example, in feed-forward neuralnetworks, forward propagation is the activation pass and backward propagationis the learning pass. We show that a composition of the two maps establishes aduality map between a subspace of non-trainable boundary variables (e.g.,dataset) and a tangent subspace of trainable variables (i.e., learning). Ingeneral, the dataset-learning duality is a complex non-linear map betweenhigh-dimensional spaces, but in a learning equilibrium, the problem can belinearized and reduced to many weakly coupled one-dimensional problems. We usethe duality to study the emergence of criticality, or the power-lawdistributions of fluctuations of the trainable variables. In particular, weshow that criticality can emerge in the learning system even from the datasetin a non-critical state, and that the power-law distribution can be modified bychanging either the activation function or the loss function.</description><author>Ekaterina Kukleva, Vitaly Vanchurin</author><pubDate>Mon, 27 May 2024 18:44:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17391v1</guid></item><item><title>KSW: Khmer Stop Word based Dictionary for Keyword Extraction</title><link>http://arxiv.org/abs/2405.17390v1</link><description>This paper introduces KSW, a Khmer-specific approach to keyword extractionthat leverages a specialized stop word dictionary. Due to the limitedavailability of natural language processing resources for the Khmer language,effective keyword extraction has been a significant challenge. KSW addressesthis by developing a tailored stop word dictionary and implementing apreprocessing methodology to remove stop words, thereby enhancing theextraction of meaningful keywords. Our experiments demonstrate that KSWachieves substantial improvements in accuracy and relevance compared toprevious methods, highlighting its potential to advance Khmer text processingand information retrieval. The KSW resources, including the stop worddictionary, are available at the following GitHub repository:(https://github.com/back-kh/KSWv2-Khmer-Stop-Word-based-Dictionary-for-Keyword-Extraction.git).</description><author>Nimol Thuon, Wangrui Zhang, Sada Thuon</author><pubDate>Mon, 27 May 2024 18:42:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17390v1</guid></item><item><title>MindMerger: Efficient Boosting LLM Reasoning in non-English Languages</title><link>http://arxiv.org/abs/2405.17386v1</link><description>Reasoning capabilities are crucial for Large Language Models (LLMs), yet anotable gap exists between English and non-English languages. To bridge thisdisparity, some works fine-tune LLMs to relearn reasoning capabilities innon-English languages, while others replace non-English inputs with an externalmodel's outputs such as English translation text to circumvent the challenge ofLLM understanding non-English. Unfortunately, these methods often underutilizethe built-in skilled reasoning and useful language understanding capabilitiesof LLMs. In order to better utilize the minds of reasoning and languageunderstanding in LLMs, we propose a new method, namely MindMerger, which mergesLLMs with the external language understanding capabilities from multilingualmodels to boost the multilingual reasoning performance. Furthermore, a two-steptraining scheme is introduced to first train to embeded the externalcapabilities into LLMs and then train the collaborative utilization of theexternal capabilities and the built-in capabilities in LLMs. Experiments onthree multilingual reasoning datasets and a language understanding datasetdemonstrate that MindMerger consistently outperforms all baselines, especiallyin low-resource languages. Without updating the parameters of LLMs, the averageaccuracy improved by 6.7% and 8.0% across all languages and low-resourcelanguages on the MGSM dataset, respectively.</description><author>Zixian Huang, Wenhao Zhu, Gong Cheng, Lei Li, Fei Yuan</author><pubDate>Mon, 27 May 2024 18:41:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17386v1</guid></item><item><title>Cutting through buggy adversarial example defenses: fixing 1 line of code breaks Sabre</title><link>http://arxiv.org/abs/2405.03672v2</link><description>Sabre is a defense to adversarial examples that was accepted at IEEE S&amp;P2024. We first reveal significant flaws in the evaluation that point to clearsigns of gradient masking. We then show the cause of this gradient masking: abug in the original evaluation code. By fixing a single line of code in theoriginal repository, we reduce Sabre's robust accuracy to 0%. In response tothis, the authors modify the defense and introduce a new defense component notdescribed in the original paper. But this fix contains a second bug; modifyingone more line of code reduces robust accuracy to below baseline levels. Afterwe released the first version of our paper online, the authors introducedanother change to the defense; by commenting out one line of code during attackwe reduce the robust accuracy to 0% again.</description><author>Nicholas Carlini</author><pubDate>Mon, 27 May 2024 18:41:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03672v2</guid></item><item><title>Unlocking the Secrets of Linear Complexity Sequence Model from A Unified Perspective</title><link>http://arxiv.org/abs/2405.17383v1</link><description>We present the Linear Complexity Sequence Model (LCSM), a comprehensivesolution that unites various sequence modeling techniques with linearcomplexity, including linear attention, state space model, long convolution,and linear RNN, within a single framework. The goal is to enhance comprehensionof these models by analyzing the impact of each component from a cohesive andstreamlined viewpoint. Specifically, we segment the modeling processes of thesemodels into three distinct stages: Expand, Oscillation, and Shrink (EOS), witheach model having its own specific settings. The Expand stage involvesprojecting the input signal onto a high-dimensional memory state. This isfollowed by recursive operations performed on the memory state in theOscillation stage. Finally, the memory state is projected back to alow-dimensional space in the Shrink stage. We perform comprehensive experimentsto analyze the impact of different stage settings on language modeling andretrieval tasks. Our results show that data-driven methods are crucial for theeffectiveness of the three stages in language modeling, whereas hand-craftedmethods yield better performance in retrieval tasks.</description><author>Zhen Qin, Xuyang Shen, Weigao Sun, Dong Li, Stan Birchfield, Richard Hartley, Yiran Zhong</author><pubDate>Mon, 27 May 2024 18:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17383v1</guid></item><item><title>ReMoDetect: Reward Models Recognize Aligned LLM's Generations</title><link>http://arxiv.org/abs/2405.17382v1</link><description>The remarkable capabilities and easy accessibility of large language models(LLMs) have significantly increased societal risks (e.g., fake newsgeneration), necessitating the development of LLM-generated text (LGT)detection methods for safe usage. However, detecting LGTs is challenging due tothe vast number of LLMs, making it impractical to account for each LLMindividually; hence, it is crucial to identify the common characteristicsshared by these models. In this paper, we draw attention to a common feature ofrecent powerful LLMs, namely the alignment training, i.e., training LLMs togenerate human-preferable texts. Our key finding is that as these aligned LLMsare trained to maximize the human preferences, they generate texts with higherestimated preferences even than human-written texts; thus, such texts areeasily detected by using the reward model (i.e., an LLM trained to model humanpreference distribution). Based on this finding, we propose two trainingschemes to further improve the detection ability of the reward model, namely(i) continual preference fine-tuning to make the reward model prefer alignedLGTs even further and (ii) reward modeling of Human/LLM mixed texts (arephrased texts from human-written texts using aligned LLMs), which serves as amedian preference text corpus between LGTs and human-written texts to learn thedecision boundary better. We provide an extensive evaluation by considering sixtext domains across twelve aligned LLMs, where our method demonstratesstate-of-the-art results. Code is available athttps://github.com/hyunseoklee-ai/reward_llm_detect.</description><author>Hyunseok Lee, Jihoon Tack, Jinwoo Shin</author><pubDate>Mon, 27 May 2024 18:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17382v1</guid></item><item><title>Various Lengths, Constant Speed: Efficient Language Modeling with Lightning Attention</title><link>http://arxiv.org/abs/2405.17381v1</link><description>We present Lightning Attention, the first linear attention implementationthat maintains a constant training speed for various sequence lengths underfixed memory consumption. Due to the issue with cumulative summation operations(cumsum), previous linear attention implementations cannot achieve theirtheoretical advantage in a casual setting. However, this issue can beeffectively solved by utilizing different attention calculation strategies tocompute the different parts of attention. Specifically, we split the attentioncalculation into intra-blocks and inter-blocks and use conventional attentioncomputation for intra-blocks and linear attention kernel tricks forinter-blocks. This eliminates the need for cumsum in the linear attentioncalculation. Furthermore, a tiling technique is adopted through both forwardand backward procedures to take full advantage of the GPU hardware. To enhanceaccuracy while preserving efficacy, we introduce TransNormerLLM (TNL), a newarchitecture that is tailored to our lightning attention. We conduct rigoroustesting on standard and self-collected datasets with varying model sizes andsequence lengths. TNL is notably more efficient than other language models. Inaddition, benchmark results indicate that TNL performs on par withstate-of-the-art LLMs utilizing conventional transformer structures. The sourcecode is released at github.com/OpenNLPLab/TransnormerLLM.</description><author>Zhen Qin, Weigao Sun, Dong Li, Xuyang Shen, Weixuan Sun, Yiran Zhong</author><pubDate>Mon, 27 May 2024 18:38:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17381v1</guid></item><item><title>Controllable Text Summarization: Unraveling Challenges, Approaches, and Prospects -- A Survey</title><link>http://arxiv.org/abs/2311.09212v2</link><description>Generic text summarization approaches often fail to address the specificintent and needs of individual users. Recently, scholarly attention has turnedto the development of summarization methods that are more closely tailored andcontrolled to align with specific objectives and user needs. Despite a growingcorpus of controllable summarization research, there is no comprehensive surveyavailable that thoroughly explores the diverse controllable attributes employedin this context, delves into the associated challenges, and investigates theexisting solutions. In this survey, we formalize the Controllable TextSummarization (CTS) task, categorize controllable attributes according to theirshared characteristics and objectives, and present a thorough examination ofexisting datasets and methods within each category. Moreover, based on ourfindings, we uncover limitations and research gaps, while also exploringpotential solutions and future directions for CTS. We release our detailedanalysis of CTS papers at\url{https://github.com/ashokurlana/controllable\_text\_summarization\_survey}.</description><author>Ashok Urlana, Pruthwik Mishra, Tathagato Roy, Rahul Mishra</author><pubDate>Mon, 27 May 2024 18:36:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09212v2</guid></item><item><title>RTL-Repo: A Benchmark for Evaluating LLMs on Large-Scale RTL Design Projects</title><link>http://arxiv.org/abs/2405.17378v1</link><description>Large Language Models (LLMs) have demonstrated potential in assisting withRegister Transfer Level (RTL) design tasks. Nevertheless, there remains to be asignificant gap in benchmarks that accurately reflect the complexity ofreal-world RTL projects. To address this, this paper presents RTL-Repo, abenchmark specifically designed to evaluate LLMs on large-scale RTL designprojects. RTL-Repo includes a comprehensive dataset of more than 4000 Verilogcode samples extracted from public GitHub repositories, with each sampleproviding the full context of the corresponding repository. We evaluate severalstate-of-the-art models on the RTL-Repo benchmark, including GPT-4, GPT-3.5,Starcoder2, alongside Verilog-specific models like VeriGen and RTLCoder, andcompare their performance in generating Verilog code for complex projects. TheRTL-Repo benchmark provides a valuable resource for the hardware designcommunity to assess and compare LLMs' performance in real-world RTL designscenarios and train LLMs specifically for Verilog code generation in complex,multi-file RTL projects. RTL-Repo is open-source and publicly available onGithub.</description><author>Ahmed Allam, Mohamed Shalan</author><pubDate>Mon, 27 May 2024 18:36:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17378v1</guid></item><item><title>How Does Perfect Fitting Affect Representation Learning? On the Training Dynamics of Representations in Deep Neural Networks</title><link>http://arxiv.org/abs/2405.17377v1</link><description>In this paper, we elucidate how representations in deep neural networks(DNNs) evolve during training. We focus on overparameterized learning settingswhere the training continues much after the trained DNN starts to perfectly fitits training data. We examine the evolution of learned representations alongthe entire training process, including its perfect fitting regime, and withrespect to the epoch-wise double descent phenomenon. We explore therepresentational similarity of DNN layers, each layer with respect to its ownrepresentations throughout the training process. For this, we use twosimilarity metrics: (1) The centered kernel alignment (CKA) similarity; (2)Similarity of decision regions of linear classifier probes that we train forthe DNN layers. Our extensive experiments discover training dynamics patternsthat can emerge in layers depending on the relative layer-depth, DNN width, andarchitecture. We show that representations at the deeper layers evolve muchmore in the training when an epoch-wise double descent occurs. For VisionTransformer, we show that the perfect fitting threshold creates a transition inthe evolution of representations across all the encoder blocks.</description><author>Yuval Sharon, Yehuda Dar</author><pubDate>Mon, 27 May 2024 18:33:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17377v1</guid></item><item><title>Federating Dynamic Models using Early-Exit Architectures for Automatic Speech Recognition on Heterogeneous Clients</title><link>http://arxiv.org/abs/2405.17376v1</link><description>Automatic speech recognition models require large amounts of speechrecordings for training. However, the collection of such data often iscumbersome and leads to privacy concerns. Federated learning has been widelyused as an effective decentralized technique that collaboratively learns ashared prediction model while keeping the data local on different clients.Unfortunately, client devices often feature limited computation andcommunication resources leading to practical difficulties for large models. Inaddition, the heterogeneity that characterizes edge devices makes itsub-optimal to generate a single model that fits all of them. Differently fromthe recent literature, where multiple models with different architectures areused, in this work, we propose using dynamical architectures which, employingearly-exit solutions, can adapt their processing (i.e. traversed layers)depending on the input and on the operation conditions. This solution falls inthe realm of partial training methods and brings two benefits: a single modelis used on a variety of devices; federating the models after local training isstraightforward. Experiments on public datasets show that our proposed approachis effective and can be combined with basic federated learning strategies.</description><author>Mohamed Nabih Ali, Alessio Brutti, Daniele Falavigna</author><pubDate>Mon, 27 May 2024 18:32:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17376v1</guid></item><item><title>Navigating the Safety Landscape: Measuring Risks in Finetuning Large Language Models</title><link>http://arxiv.org/abs/2405.17374v1</link><description>Safety alignment is the key to guiding the behaviors of large language models(LLMs) that are in line with human preferences and restrict harmful behaviorsat inference time, but recent studies show that it can be easily compromised byfinetuning with only a few adversarially designed training examples. We aim tomeasure the risks in finetuning LLMs through navigating the LLM safetylandscape. We discover a new phenomenon observed universally in the modelparameter space of popular open-source LLMs, termed as "safety basin": randomlyperturbing model weights maintains the safety level of the original alignedmodel in its local neighborhood. Our discovery inspires us to propose the newVISAGE safety metric that measures the safety in LLM finetuning by probing itssafety landscape. Visualizing the safety landscape of the aligned model enablesus to understand how finetuning compromises safety by dragging the model awayfrom the safety basin. LLM safety landscape also highlights the system prompt'scritical role in protecting a model, and that such protection transfers to itsperturbed variants within the safety basin. These observations from our safetylandscape research provide new insights for future work on LLM safetycommunity.</description><author>ShengYun Peng, Pin-Yu Chen, Matthew Hull, Duen Horng Chau</author><pubDate>Mon, 27 May 2024 18:31:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17374v1</guid></item><item><title>AI-based analysis of super-resolution microscopy: Biological discovery in the absence of ground truth</title><link>http://arxiv.org/abs/2305.17193v2</link><description>Super-resolution microscopy, or nanoscopy, enables the use offluorescent-based molecular localization tools to study molecular structure atthe nanoscale level in the intact cell, bridging the mesoscale gap to classicalstructural biology methodologies. Analysis of super-resolution data byartificial intelligence (AI), such as machine learning, offers tremendouspotential for discovery of new biology, that, by definition, is not known andlacks ground truth. Herein, we describe the application of weakly supervisedparadigms to super-resolution microscopy and its potential to enable theaccelerated exploration of the nanoscale architecture of subcellularmacromolecules and organelles.</description><author>Ivan R. Nabi, Ben Cardoen, Ismail M. Khater, Guang Gao, Timothy H. Wong, Ghassan Hamarneh</author><pubDate>Mon, 27 May 2024 18:31:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17193v2</guid></item><item><title>BehaviorGPT: Smart Agent Simulation for Autonomous Driving with Next-Patch Prediction</title><link>http://arxiv.org/abs/2405.17372v1</link><description>Simulating realistic interactions among traffic agents is crucial forefficiently validating the safety of autonomous driving systems. Existingleading simulators primarily use an encoder-decoder structure to encode thehistorical trajectories for future simulation. However, such a paradigmcomplicates the model architecture, and the manual separation of history andfuture trajectories leads to low data utilization. To address these challenges,we propose Behavior Generative Pre-trained Transformers (BehaviorGPT), adecoder-only, autoregressive architecture designed to simulate the sequentialmotion of multiple agents. Crucially, our approach discards the traditionalseparation between "history" and "future," treating each time step as the"current" one, resulting in a simpler, more parameter- and data-efficientdesign that scales seamlessly with data and computation. Additionally, weintroduce the Next-Patch Prediction Paradigm (NP3), which enables models toreason at the patch level of trajectories and capture long-rangespatial-temporal interactions. BehaviorGPT ranks first across several metricson the Waymo Sim Agents Benchmark, demonstrating its exceptional performance inmulti-agent and agent-map interactions. We outperformed state-of-the-art modelswith a realism score of 0.741 and improved the minADE metric to 1.540, with anapproximately 91.6% reduction in model parameters.</description><author>Zikang Zhou, Haibo Hu, Xinhong Chen, Jianping Wang, Nan Guan, Kui Wu, Yung-Hui Li, Yu-Kai Huang, Chun Jason Xue</author><pubDate>Mon, 27 May 2024 18:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17372v1</guid></item><item><title>Model-Agnostic Zeroth-Order Policy Optimization for Meta-Learning of Ergodic Linear Quadratic Regulators</title><link>http://arxiv.org/abs/2405.17370v1</link><description>Meta-learning has been proposed as a promising machine learning topic inrecent years, with important applications to image classification, robotics,computer games, and control systems. In this paper, we study the problem ofusing meta-learning to deal with uncertainty and heterogeneity in ergodiclinear quadratic regulators. We integrate the zeroth-order optimizationtechnique with a typical meta-learning method, proposing an algorithm thatomits the estimation of policy Hessian, which applies to tasks of learning aset of heterogeneous but similar linear dynamic systems. The inducedmeta-objective function inherits important properties of the original costfunction when the set of linear dynamic systems are meta-learnable, allowingthe algorithm to optimize over a learnable landscape without projection ontothe feasible set. We provide a convergence result for the exact gradientdescent process by analyzing the boundedness and smoothness of the gradient forthe meta-objective, which justify the proposed algorithm with gradientestimation error being small. We also provide a numerical example tocorroborate this perspective.</description><author>Yunian Pan, Quanyan Zhu</author><pubDate>Mon, 27 May 2024 18:26:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17370v1</guid></item><item><title>Predict joint angle of body parts based on sequence pattern recognition</title><link>http://arxiv.org/abs/2405.17369v1</link><description>The way organs are positioned and moved in the workplace can cause pain andphysical harm. Therefore, ergonomists use ergonomic risk assessments based onvisual observation of the workplace, or review pictures and videos taken in theworkplace. Sometimes the workers in the photos are not in perfect condition.Some parts of the workers' bodies may not be in the camera's field of view,could be obscured by objects, or by self-occlusion, this is the main problem in2D human posture recognition. It is difficult to predict the position of bodyparts when they are not visible in the image, and geometric mathematicalmethods are not entirely suitable for this purpose. Therefore, we created adataset with artificial images of a 3D human model, specifically for painfulpostures, and real human photos from different viewpoints. Each image wecaptured was based on a predefined joint angle for each 3D model or humanmodel. We created various images, including images where some body parts arenot visible. Nevertheless, the joint angle is estimated beforehand, so we couldstudy the case by converting the input images into the sequence of jointconnections between predefined body parts and extracting the desired jointangle with a convolutional neural network. In the end, we obtained root meansquare error (RMSE) of 12.89 and mean absolute error (MAE) of 4.7 on the testdataset.</description><author>Amin Ahmadi Kasani, Hedieh Sajedi</author><pubDate>Mon, 27 May 2024 18:24:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17369v1</guid></item><item><title>Fusing uncalibrated IMUs and handheld smartphone video to reconstruct knee kinematics</title><link>http://arxiv.org/abs/2405.17368v1</link><description>Video and wearable sensor data provide complementary information about humanmovement. Video provides a holistic understanding of the entire body in theworld while wearable sensors provide high-resolution measurements of specificbody segments. A robust method to fuse these modalities and obtainbiomechanically accurate kinematics would have substantial utility for clinicalassessment and monitoring. While multiple video-sensor fusion methods exist,most assume that a time-intensive, and often brittle, sensor-body calibrationprocess has already been performed. In this work, we present a method tocombine handheld smartphone video and uncalibrated wearable sensor data attheir full temporal resolution. Our monocular, video-only, biomechanicalreconstruction already performs well, with only several degrees of error at theknee during walking compared to markerless motion capture. Reconstructing froma fusion of video and wearable sensor data further reduces this error. Wevalidate this in a mixture of people with no gait impairments, lower limbprosthesis users, and individuals with a history of stroke. We also show thatsensor data allows tracking through periods of visual occlusion.</description><author>J. D. Peiffer, Kunal Shah, Shawana Anarwala, Kayan Abdou, R. James Cotton</author><pubDate>Mon, 27 May 2024 18:23:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17368v1</guid></item><item><title>A Theoretical Framework for Partially Observed Reward-States in RLHF</title><link>http://arxiv.org/abs/2402.03282v2</link><description>The growing deployment of reinforcement learning from human feedback (RLHF)calls for a deeper theoretical investigation of its underlying models. Theprevalent models of RLHF do not account for neuroscience-backed,partially-observed "internal states" that can affect human feedback, nor dothey accommodate intermediate feedback during an interaction. Both of these canbe instrumental in speeding up learning and improving alignment. To addressthese limitations, we model RLHF as reinforcement learning with partiallyobserved reward-states (PORRL). We accommodate two kinds of feedback $-$cardinal and dueling feedback. We first demonstrate that PORRL subsumes a wideclass of RL problems, including traditional RL, RLHF, and reward machines. Forcardinal feedback, we present two model-based methods (POR-UCRL, POR-UCBVI). Wegive both cardinal regret and sample complexity guarantees for the methods,showing that they improve over naive history-summarization. We then discuss thebenefits of a model-free method like GOLF with naive history-summarization insettings with recursive internal states and dense intermediate feedback. Forthis purpose, we define a new history aware version of the Bellman-eluderdimension and give a new guarantee for GOLF in our setting, which can beexponentially sharper in illustrative examples. For dueling feedback, we showthat a naive reduction to cardinal feedback fails to achieve sublinear duelingregret. We then present the first explicit reduction that converts guaranteesfor cardinal regret to dueling regret. In both feedback settings, we show thatour models and guarantees generalize and extend existing ones.</description><author>Chinmaya Kausik, Mirco Mutti, Aldo Pacchiano, Ambuj Tewari</author><pubDate>Mon, 27 May 2024 18:20:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03282v2</guid></item><item><title>EM-GANSim: Real-time and Accurate EM Simulation Using Conditional GANs for 3D Indoor Scenes</title><link>http://arxiv.org/abs/2405.17366v1</link><description>We present a novel machine-learning (ML) approach (EM-GANSim) for real-timeelectromagnetic (EM) propagation that is used for wireless communicationsimulation in 3D indoor environments. Our approach uses a modified conditionalGenerative Adversarial Network (GAN) that incorporates encoded geometry andtransmitter location while adhering to the electromagnetic propagation theory.The overall physically-inspired learning is able to predict the powerdistribution in 3D scenes, which is represented using heatmaps. Our overallaccuracy is comparable to ray tracing-based EM simulation, as evidenced bylower mean squared error values. Furthermore, our GAN-based method drasticallyreduces the computation time, achieving a 5X speedup on complex benchmarks. Inpractice, it can compute the signal strength in a few milliseconds on anylocation in 3D indoor environments. We also present a large dataset of 3Dmodels and EM ray tracing-simulated heatmaps. To the best of our knowledge,EM-GANSim is the first real-time algorithm for EM simulation in complex 3Dindoor environments. We plan to release the code and the dataset.</description><author>Ruichen Wang, Dinesh Manocha</author><pubDate>Mon, 27 May 2024 18:19:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17366v1</guid></item><item><title>Generating Likely Counterfactuals Using Sum-Product Networks</title><link>http://arxiv.org/abs/2401.14086v2</link><description>Explainability of decisions made by AI systems is driven by both recentregulation and user demand. These decisions are often explainable only\emph{post hoc}, after the fact. In counterfactual explanations, one may askwhat constitutes the best counterfactual explanation. Clearly, multiplecriteria must be taken into account, although "distance from the sample" is akey criterion. Recent methods that consider the plausibility of acounterfactual seem to sacrifice this original objective. Here, we present asystem that provides high-likelihood explanations that are, at the same time,close and sparse. We show that the search for the most likely explanationssatisfying many common desiderata for counterfactual explanations can bemodeled using mixed-integer optimization (MIO). In the process, we propose anMIO formulation of a Sum-Product Network (SPN) and use the SPN to estimate thelikelihood of a counterfactual, which can be of independent interest.</description><author>Jiri Nemecek, Tomas Pevny, Jakub Marecek</author><pubDate>Mon, 27 May 2024 18:17:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14086v2</guid></item><item><title>Pre-training with Synthetic Data Helps Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2310.00771v4</link><description>Recently, it has been shown that for offline deep reinforcement learning(DRL), pre-training Decision Transformer with a large language corpus canimprove downstream performance (Reid et al., 2022). A natural question to askis whether this performance gain can only be achieved with languagepre-training, or can be achieved with simpler pre-training schemes which do notinvolve language. In this paper, we first show that language is not essentialfor improved performance, and indeed pre-training with synthetic IID data for asmall number of updates can match the performance gains from pre-training witha large language corpus; moreover, pre-training with data generated by aone-step Markov chain can further improve the performance. Inspired by theseexperimental results, we then consider pre-training Conservative Q-Learning(CQL), a popular offline DRL algorithm, which is Q-learning-based and typicallyemploys a Multi-Layer Perceptron (MLP) backbone. Surprisingly, pre-trainingwith simple synthetic data for a small number of updates can also improve CQL,providing consistent performance improvement on D4RL Gym locomotion datasets.The results of this paper not only illustrate the importance of pre-trainingfor offline DRL but also show that the pre-training data can be synthetic andgenerated with remarkably simple mechanisms.</description><author>Zecheng Wang, Che Wang, Zixuan Dong, Keith Ross</author><pubDate>Mon, 27 May 2024 18:16:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00771v4</guid></item><item><title>A One-Layer Decoder-Only Transformer is a Two-Layer RNN: With an Application to Certified Robustness</title><link>http://arxiv.org/abs/2405.17361v1</link><description>This paper reveals a key insight that a one-layer decoder-only Transformer isequivalent to a two-layer Recurrent Neural Network (RNN). Building on thisinsight, we propose ARC-Tran, a novel approach for verifying the robustness ofdecoder-only Transformers against arbitrary perturbation spaces. Compared toARC-Tran, current robustness verification techniques are limited either tospecific and length-preserving perturbations like word substitutions or torecursive models like LSTMs. ARC-Tran addresses these limitations bymeticulously managing position encoding to prevent mismatches and by utilizingour key insight to achieve precise and scalable verification. Our evaluationshows that ARC-Tran (1) trains models more robust to arbitrary perturbationspaces than those produced by existing techniques and (2) shows highcertification accuracy of the resulting models.</description><author>Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni</author><pubDate>Mon, 27 May 2024 18:10:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17361v1</guid></item><item><title>Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle Escaping, and Network Embedding</title><link>http://arxiv.org/abs/2402.05626v3</link><description>In this paper, we investigate the loss landscape of one-hidden-layer neuralnetworks with ReLU-like activation functions trained with the empirical squaredloss. As the activation function is non-differentiable, it is so far unclearhow to completely characterize the stationary points. We propose the conditionsfor stationarity that apply to both non-differentiable and differentiablecases. Additionally, we show that, if a stationary point does not contain"escape neurons", which are defined with first-order conditions, then it mustbe a local minimum. Moreover, for the scalar-output case, the presence of anescape neuron guarantees that the stationary point is not a local minimum. Ourresults refine the description of the saddle-to-saddle training processstarting from infinitesimally small (vanishing) initialization for shallowReLU-like networks, linking saddle escaping directly with the parameter changesof escape neurons. Moreover, we are also able to fully discuss how networkembedding, which is to instantiate a narrower network within a wider network,reshapes the stationary points.</description><author>Zhengqing Wu, Berfin Simsek, Francois Ged</author><pubDate>Mon, 27 May 2024 18:08:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05626v3</guid></item><item><title>Memory Efficient Neural Processes via Constant Memory Attention Block</title><link>http://arxiv.org/abs/2305.14567v3</link><description>Neural Processes (NPs) are popular meta-learning methods for efficientlymodelling predictive uncertainty. Recent state-of-the-art methods, however,leverage expensive attention mechanisms, limiting their applications,particularly in low-resource settings. In this work, we propose Constant MemoryAttentive Neural Processes (CMANPs), an NP variant that only requires constantmemory. To do so, we first propose an efficient update operation for CrossAttention. Leveraging the update operation, we propose Constant MemoryAttention Block (CMAB), a novel attention block that (i) is permutationinvariant, (ii) computes its output in constant memory, and (iii) performsconstant computation updates. Finally, building on CMAB, we detail ConstantMemory Attentive Neural Processes. Empirically, we show CMANPs achievestate-of-the-art results on popular NP benchmarks while being significantlymore memory efficient than prior methods.</description><author>Leo Feng, Frederick Tung, Hossein Hajimirsadeghi, Yoshua Bengio, Mohamed Osama Ahmed</author><pubDate>Mon, 27 May 2024 18:06:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14567v3</guid></item><item><title>Rethinking Transformers in Solving POMDPs</title><link>http://arxiv.org/abs/2405.17358v1</link><description>Sequential decision-making algorithms such as reinforcement learning (RL) inreal-world scenarios inevitably face environments with partial observability.This paper scrutinizes the effectiveness of a popular architecture, namelyTransformers, in Partially Observable Markov Decision Processes (POMDPs) andreveals its theoretical limitations. We establish that regular languages, whichTransformers struggle to model, are reducible to POMDPs. This poses asignificant challenge for Transformers in learning POMDP-specific inductivebiases, due to their lack of inherent recurrence found in other models likeRNNs. This paper casts doubt on the prevalent belief in Transformers assequence models for RL and proposes to introduce a point-wise recurrentstructure. The Deep Linear Recurrent Unit (LRU) emerges as a well-suitedalternative for Partially Observable RL, with empirical results highlightingthe sub-optimal performance of the Transformer and considerable strength ofLRU.</description><author>Chenhao Lu, Ruizhe Shi, Yuyao Liu, Kaizhe Hu, Simon S. Du, Huazhe Xu</author><pubDate>Mon, 27 May 2024 18:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17358v1</guid></item><item><title>DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution</title><link>http://arxiv.org/abs/2405.17357v1</link><description>Fine-tuning large-scale pre-trained models is inherently a resource-intensivetask. While it can enhance the capabilities of the model, it also incurssubstantial computational costs, posing challenges to the practical applicationof downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methodssuch as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores thedifferential parameter budget requirements across weight matrices, which maylead to suboptimal fine-tuning outcomes. To address this issue, we introducethe Dynamic Low-Rank Adaptation (DoRA) method. DoRA decomposes high-rank LoRAlayers into structured single-rank components, allowing for dynamic pruning ofparameter budget based on their importance to specific tasks during training,which makes the most of the limited parameter budget. Experimental resultsdemonstrate that DoRA can achieve competitive performance compared with LoRAand full model fine-tuning, and outperform various strong baselines with thesame storage parameter budget. Our code is available athttps://github.com/Yulongmao1/DoRA/</description><author>Yulong Mao, Kaiyu Huang, Changhao Guan, Ganglin Bao, Fengran Mo, Jinan Xu</author><pubDate>Mon, 27 May 2024 18:02:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17357v1</guid></item><item><title>Why are Sensitive Functions Hard for Transformers?</title><link>http://arxiv.org/abs/2402.09963v4</link><description>Empirical studies have identified a range of learnability biases andlimitations of transformers, such as a persistent difficulty in learning tocompute simple formal languages such as PARITY, and a bias towards low-degreefunctions. However, theoretical understanding remains limited, with existingexpressiveness theory either overpredicting or underpredicting realisticlearning abilities. We prove that, under the transformer architecture, the losslandscape is constrained by the input-space sensitivity: Transformers whoseoutput is sensitive to many parts of the input string inhabit isolated pointsin parameter space, leading to a low-sensitivity bias in generalization. Weshow theoretically and empirically that this theory unifies a broad array ofempirical observations about the learning abilities and biases of transformers,such as their generalization bias towards low sensitivity and low degree, anddifficulty in length generalization for PARITY. This shows that understandingtransformers' inductive biases requires studying not just their in-principleexpressivity, but also their loss landscape.</description><author>Michael Hahn, Mark Rofin</author><pubDate>Mon, 27 May 2024 18:01:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09963v4</guid></item><item><title>For Better or For Worse? Learning Minimum Variance Features With Label Augmentation</title><link>http://arxiv.org/abs/2402.06855v2</link><description>Data augmentation has been pivotal in successfully training deep learningmodels on classification tasks over the past decade. An important subclass ofdata augmentation techniques - which includes both label smoothing and Mixup -involves modifying not only the input data but also the input label duringmodel training. In this work, we analyze the role played by the labelaugmentation aspect of such methods. We first prove that linear models onbinary classification data trained with label augmentation learn only theminimum variance features in the data, while standard training (which includesweight decay) can learn higher variance features. We then use our techniques toshow that even for nonlinear models and general data distributions, the labelsmoothing and Mixup losses are lower bounded by a function of the model outputvariance. An important consequence of our results is negative: label smoothingand Mixup can be less robust to spurious correlations in the data. We verifythat our theory reflects practice via experiments on image classificationbenchmarks modified to have spurious correlations.</description><author>Muthu Chidambaram, Rong Ge</author><pubDate>Mon, 27 May 2024 17:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06855v2</guid></item><item><title>Assessing the significance of longitudinal data in Alzheimer's Disease forecasting</title><link>http://arxiv.org/abs/2405.17352v1</link><description>In this study, we employ a transformer encoder model to characterize thesignificance of longitudinal patient data for forecasting the progression ofAlzheimer's Disease (AD). Our model, Longitudinal Forecasting Model forAlzheimer's Disease (LongForMAD), harnesses the comprehensive temporalinformation embedded in sequences of patient visits that incorporate multimodaldata, providing a deeper understanding of disease progression than can be drawnfrom single-visit data alone. We present an empirical analysis across twopatient groups-Cognitively Normal (CN) and Mild Cognitive Impairment (MCI)-overa span of five follow-up years. Our findings reveal that models incorporatingmore extended patient histories can outperform those relying solely on presentinformation, suggesting a deeper historical context is critical in enhancingpredictive accuracy for future AD progression. Our results support theincorporation of longitudinal data in clinical settings to enhance the earlydetection and monitoring of AD. Our code is available at\url{https://github.com/batuhankmkaraman/LongForMAD}.</description><author>Batuhan K. Karaman, Mert R. Sabuncu</author><pubDate>Mon, 27 May 2024 17:55:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17352v1</guid></item><item><title>DOF-GS: Adjustable Depth-of-Field 3D Gaussian Splatting for Refocusing,Defocus Rendering and Blur Removal</title><link>http://arxiv.org/abs/2405.17351v1</link><description>3D Gaussian Splatting-based techniques have recently advanced 3D scenereconstruction and novel view synthesis, achieving high-quality real-timerendering. However, these approaches are inherently limited by the underlyingpinhole camera assumption in modeling the images and hence only work forAll-in-Focus (AiF) sharp image inputs. This severely affects theirapplicability in real-world scenarios where images often exhibit defocus blurdue to the limited depth-of-field (DOF) of imaging devices. Additionally,existing 3D Gaussian Splatting (3DGS) methods also do not support rendering ofDOF effects. To address these challenges, we introduce DOF-GS that allows for renderingadjustable DOF effects, removing defocus blur as well as refocusing of 3Dscenes, all from multi-view images degraded by defocus blur. To this end, were-imagine the traditional Gaussian Splatting pipeline by employing a finiteaperture camera model coupled with explicit, differentiable defocus renderingguided by the Circle-of-Confusion (CoC). The proposed framework provides fordynamic adjustment of DOF effects by changing the aperture and focal distanceof the underlying camera model on-demand. It also enables rendering varying DOFeffects of 3D scenes post-optimization, and generating AiF images fromdefocused training images. Furthermore, we devise a joint optimization strategyto further enhance details in the reconstructed scenes by jointly optimizingrendered defocused and AiF images. Our experimental results indicate thatDOF-GS produces high-quality sharp all-in-focus renderings conditioned oninputs compromised by defocus blur, with the training process incurring only amodest increase in GPU memory consumption. We further demonstrate theapplications of the proposed method for adjustable defocus rendering andrefocusing of the 3D scene from input images degraded by defocus blur.</description><author>Yujie Wang, Praneeth Chakravarthula, Baoquan Chen</author><pubDate>Mon, 27 May 2024 17:54:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17351v1</guid></item><item><title>Why Transformers Need Adam: A Hessian Perspective</title><link>http://arxiv.org/abs/2402.16788v2</link><description>SGD performs worse than Adam by a significant margin on Transformers, but thereason remains unclear. In this work, we provide an explanation of SGD's badperformance on Transformers through the lens of Hessian: (i) Transformers are"heterogeneous": the Hessian spectrum across parameter blocks varydramatically, a phenomenon we call "block heterogeneity"; (ii) Heterogeneityhampers SGD: SGD performs badly on problems with block heterogeneity. Tovalidate that heterogeneity hampers SGD, we check various Transformers, CNNs,MLPs, and quadratic problems, and find that SGD works well on problems withoutblock heterogeneity but performs badly when the heterogeneity exists. Ourinitial theoretical analysis indicates that SGD performs poorly because itapplies one single learning rate to all blocks, which cannot handle theheterogeneity among blocks. This limitation could be ameliorated if we usecoordinate-wise learning rates, as designed in Adam.</description><author>Yushun Zhang, Congliang Chen, Tian Ding, Ziniu Li, Ruoyu Sun, Zhi-Quan Luo</author><pubDate>Mon, 27 May 2024 17:53:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16788v2</guid></item><item><title>Prompt Optimization with Human Feedback</title><link>http://arxiv.org/abs/2405.17346v1</link><description>Large language models (LLMs) have demonstrated remarkable performances invarious tasks. However, the performance of LLMs heavily depends on the inputprompt, which has given rise to a number of recent works on promptoptimization. However, previous works often require the availability of anumeric score to assess the quality of every prompt. Unfortunately, when ahuman user interacts with a black-box LLM, attaining such a score is ofteninfeasible and unreliable. Instead, it is usually significantly easier and morereliable to obtain preference feedback from a human user, i.e., showing theuser the responses generated from a pair of prompts and asking the user whichone is preferred. Therefore, in this paper, we study the problem of promptoptimization with human feedback (POHF), in which we aim to optimize the promptfor a black-box LLM using only human preference feedback. Drawing inspirationfrom dueling bandits, we design a theoretically principled strategy to select apair of prompts to query for preference feedback in every iteration, and henceintroduce our algorithm named automated POHF (APOHF). We apply our APOHFalgorithm to various tasks, including optimizing user instructions, promptoptimization for text-to-image generative models, and response optimizationwith human feedback (i.e., further refining the response using a variant of ourAPOHF). The results demonstrate that our APOHF can efficiently find a goodprompt using a small number of preference feedback instances. Our code can befound at \url{https://github.com/xqlin98/APOHF}.</description><author>Xiaoqiang Lin, Zhongxiang Dai, Arun Verma, See-Kiong Ng, Patrick Jaillet, Bryan Kian Hsiang Low</author><pubDate>Mon, 27 May 2024 17:49:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17346v1</guid></item><item><title>Exploring and steering the moral compass of Large Language Models</title><link>http://arxiv.org/abs/2405.17345v1</link><description>Large Language Models (LLMs) have become central to advancing automation anddecision-making across various sectors, raising significant ethical questions.This study proposes a comprehensive comparative analysis of the most advancedLLMs to assess their moral profiles. We subjected several state-of-the-artmodels to a selection of ethical dilemmas and found that all the proprietaryones are mostly utilitarian and all of the open-weights ones align mostly withvalues-based ethics. Furthermore, when using the Moral FoundationsQuestionnaire, all models we probed - except for Llama 2- displayed a strongliberal bias. Lastly, in order to causally intervene in one of the studiedmodels, we propose a novel similarity-specific activation steering technique.Using this method, we were able to reliably steer the model's moral compass todifferent ethical schools. All of these results showcase that there is anethical dimension in already deployed LLMs, an aspect that is generallyoverlooked.</description><author>Alejandro Tlaie</author><pubDate>Mon, 27 May 2024 17:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17345v1</guid></item><item><title>Policy Space Response Oracles: A Survey</title><link>http://arxiv.org/abs/2403.02227v2</link><description>Game theory provides a mathematical way to study the interaction betweenmultiple decision makers. However, classical game-theoretic analysis is limitedin scalability due to the large number of strategies, precluding directapplication to more complex scenarios. This survey provides a comprehensiveoverview of a framework for large games, known as Policy Space Response Oracles(PSRO), which holds promise to improve scalability by focusing attention onsufficient subsets of strategies. We first motivate PSRO and provide historicalcontext. We then focus on the strategy exploration problem for PSRO: thechallenge of assembling effective subsets of strategies that still representthe original game well with minimum computational cost. We survey currentresearch directions for enhancing the efficiency of PSRO, and explore theapplications of PSRO across various domains. We conclude by discussing openquestions and future research.</description><author>Ariyan Bighashdel, Yongzhao Wang, Stephen McAleer, Rahul Savani, Frans A. Oliehoek</author><pubDate>Mon, 27 May 2024 17:49:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02227v2</guid></item><item><title>Open Ad Hoc Teamwork with Cooperative Game Theory</title><link>http://arxiv.org/abs/2402.15259v2</link><description>Ad hoc teamwork poses a challenging problem, requiring the design of an agentto collaborate with teammates without prior coordination or joint training.Open ad hoc teamwork further complicates this challenge by consideringenvironments with a changing number of teammates, referred to as open teams.One promising solution to this problem is leveraging the generalizability ofgraph neural networks to handle an unrestricted number of agents andeffectively address open teams, named graph-based policy learning (GPL).However, its joint Q-value representation over a coordination graph lacksconvincing explanations. In this paper, we establish a new theory to understandthe joint Q-value representation from the perspective of cooperative gametheory, and validate its learning paradigm in open team settings. Building onour theory, we propose a novel algorithm named CIAO compatible with GPLframework, with additional provable implementation tricks that can facilitatelearning. The demo of experiments is available onhttps://sites.google.com/view/ciao2024, and the code of experiments ispublished on https://github.com/hsvgbkhgbv/CIAO.</description><author>Jianhong Wang, Yang Li, Yuan Zhang, Wei Pan, Samuel Kaski</author><pubDate>Mon, 27 May 2024 17:48:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15259v2</guid></item><item><title>Physics-Informed Real NVP for Satellite Power System Fault Detection</title><link>http://arxiv.org/abs/2405.17339v1</link><description>The unique challenges posed by the space environment, characterized byextreme conditions and limited accessibility, raise the need for robust andreliable techniques to identify and prevent satellite faults. Fault detectionmethods in the space sector are required to ensure mission success and toprotect valuable assets. In this context, this paper proposes an ArtificialIntelligence (AI) based fault detection methodology and evaluates itsperformance on ADAPT (Advanced Diagnostics and Prognostics Testbed), anElectrical Power System (EPS) dataset, crafted in laboratory by NASA. Our study focuses on the application of a physics-informed (PI) real-valuednon-volume preserving (Real NVP) model for fault detection in space systems.The efficacy of this method is systematically compared against other AIapproaches such as Gated Recurrent Unit (GRU) and Autoencoder-based techniques. Results show that our physics-informed approach outperforms existing methodsof fault detection, demonstrating its suitability for addressing the uniquechallenges of satellite EPS sub-system faults. Furthermore, we unveil thecompetitive advantage of physics-informed loss in AI models to address specificspace needs, namely robustness, reliability, and power constraints, crucial forspace exploration and satellite missions.</description><author>Carlo Cena, Umberto Albertin, Mauro Martini, Silvia Bucci, Marcello Chiaberge</author><pubDate>Mon, 27 May 2024 17:42:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17339v1</guid></item><item><title>Test-Time Adaptation for Depth Completion</title><link>http://arxiv.org/abs/2402.03312v4</link><description>It is common to observe performance degradation when transferring modelstrained on some (source) datasets to target testing data due to a domain gapbetween them. Existing methods for bridging this gap, such as domain adaptation(DA), may require the source data on which the model was trained (often notavailable), while others, i.e., source-free DA, require many passes through thetesting data. We propose an online test-time adaptation method for depthcompletion, the task of inferring a dense depth map from a single image andassociated sparse depth map, that closes the performance gap in a single pass.We first present a study on how the domain shift in each data modality affectsmodel performance. Based on our observations that the sparse depth modalityexhibits a much smaller covariate shift than the image, we design an embeddingmodule trained in the source domain that preserves a mapping from featuresencoding only sparse depth to those encoding image and sparse depth. Duringtest time, sparse depth features are projected using this map as a proxy forsource domain features and are used as guidance to train a set of auxiliaryparameters (i.e., adaptation layer) to align image and sparse depth featuresfrom the target test domain to that of the source domain. We evaluate ourmethod on indoor and outdoor scenarios and show that it improves over baselinesby an average of 21.1%.</description><author>Hyoungseob Park, Anjali Gupta, Alex Wong</author><pubDate>Mon, 27 May 2024 17:39:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03312v4</guid></item><item><title>Cost-efficient Knowledge-based Question Answering with Large Language Models</title><link>http://arxiv.org/abs/2405.17337v1</link><description>Knowledge-based question answering (KBQA) is widely used in many scenariosthat necessitate domain knowledge. Large language models (LLMs) bringopportunities to KBQA, while their costs are significantly higher and absenceof domain-specific knowledge during pre-training. We are motivated to combineLLMs and prior small models on knowledge graphs (KGMs) for both inferentialaccuracy and cost saving. However, it remains challenging since accuracy andcost are not readily combined in the optimization as two distinct metrics. Itis also laborious for model selection since different models excel in diverseknowledge. To this end, we propose Coke, a novel cost-efficient strategy forKBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimizecalls to LLMs within limited budgets. We first formulate the accuracyexpectation with a cluster-level Thompson Sampling for either KGMs or LLMs. Acontext-aware policy is optimized to further distinguish the expert modelsubject to the question semantics. The overall decision is bounded by the costregret according to historical expenditure on failures. Extensive experimentsshowcase the superior performance of Coke, which moves the Pareto frontier withup to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy onthe benchmark datasets.</description><author>Junnan Dong, Qinggang Zhang, Chuang Zhou, Hao Chen, Daochen Zha, Xiao Huang</author><pubDate>Mon, 27 May 2024 17:37:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17337v1</guid></item><item><title>XFormParser: A Simple and Effective Multimodal Multilingual Semi-structured Form Parser</title><link>http://arxiv.org/abs/2405.17336v1</link><description>In the domain of document AI, semi-structured form parsing plays a crucialrole. This task leverages techniques from key information extraction (KIE),dealing with inputs that range from plain text to intricate modal datacomprising images and structural layouts. The advent of pre-trained multimodalmodels has driven the extraction of key information from form documents indifferent formats such as PDFs and images. Nonetheless, the endeavor of formparsing is still encumbered by notable challenges like subpar capabilities inmulti-lingual parsing and diminished recall in contexts rich in text andvisuals. In this work, we introduce a simple but effective \textbf{M}ultimodaland \textbf{M}ultilingual semi-structured \textbf{FORM} \textbf{PARSER}(\textbf{XFormParser}), which is anchored on a comprehensive pre-trainedlanguage model and innovatively amalgamates semantic entity recognition (SER)and relation extraction (RE) into a unified framework, enhanced by a novelstaged warm-up training approach that employs soft labels to significantlyrefine form parsing accuracy without amplifying inference overhead.Furthermore, we have developed a groundbreaking benchmark dataset, namedInDFormBench, catering specifically to the parsing requirements of multilingualforms in various industrial contexts. Through rigorous testing on establishedmultilingual benchmarks and InDFormBench, XFormParser has demonstrated itsunparalleled efficacy, notably surpassing the state-of-the-art (SOTA) models inRE tasks within language-specific setups by achieving an F1 score improvementof up to 1.79\%. Our framework exhibits exceptionally improved performanceacross tasks in both multi-language and zero-shot contexts when compared toexisting SOTA benchmarks. The code is publicly available athttps://github.com/zhbuaa0/layoutlmft.</description><author>Xianfu Cheng, Hang Zhang, Jian Yang, Xiang Li, Weixiao Zhou, Kui Wu, Fei Liu, Wei Zhang, Tao Sun, Tongliang Li, Zhoujun Li</author><pubDate>Mon, 27 May 2024 17:37:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17336v1</guid></item><item><title>LoRA Training in the NTK Regime has No Spurious Local Minima</title><link>http://arxiv.org/abs/2402.11867v2</link><description>Low-rank adaptation (LoRA) has become the standard approach forparameter-efficient fine-tuning of large language models (LLM), but ourtheoretical understanding of LoRA has been limited. In this work, wetheoretically analyze LoRA fine-tuning in the neural tangent kernel (NTK)regime with $N$ data points, showing: (i) full fine-tuning (without LoRA)admits a low-rank solution of rank $r\lesssim \sqrt{N}$; (ii) using LoRA withrank $r\gtrsim \sqrt{N}$ eliminates spurious local minima, allowing gradientdescent to find the low-rank solutions; (iii) the low-rank solution found usingLoRA generalizes well.</description><author>Uijeong Jang, Jason D. Lee, Ernest K. Ryu</author><pubDate>Mon, 27 May 2024 17:35:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11867v2</guid></item><item><title>Conditioning on Time is All You Need for Synthetic Survival Data Generation</title><link>http://arxiv.org/abs/2405.17333v1</link><description>Synthetic data generation holds considerable promise, offering avenues toenhance privacy, fairness, and data accessibility. Despite the availability ofvarious methods for generating synthetic tabular data, challenges persist,particularly in specialized applications such as survival analysis. Onesignificant obstacle in survival data generation is censoring, which manifestsas not knowing the precise timing of observed (target) events for certaininstances. Existing methods face difficulties in accurately reproducing thereal distribution of event times for both observed (uncensored) events andcensored events, i.e., the generated event-time distributions do not accuratelymatch the underlying distributions of the real data. So motivated, we propose asimple paradigm to produce synthetic survival data by generating covariatesconditioned on event times (and censoring indicators), thus allowing one toreuse existing conditional generative models for tabular data withoutsignificant computational overhead, and without making assumptions about the(usually unknown) generation mechanism underlying censoring. We evaluate thismethod via extensive experiments on real-world datasets. Our methodologyoutperforms multiple competitive baselines at generating survival data, whileimproving the performance of downstream survival models trained on it andtested on real data.</description><author>Mohd Ashhad, Ricardo Henao</author><pubDate>Mon, 27 May 2024 17:34:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17333v1</guid></item><item><title>PlatoLM: Teaching LLMs in Multi-Round Dialogue via a User Simulator</title><link>http://arxiv.org/abs/2308.11534v5</link><description>The unparalleled performance of closed-sourced ChatGPT has sparked effortstowards its democratization, with notable strides made by leveraging real userand ChatGPT dialogues, as evidenced by Vicuna. However, due to challenges ingathering dialogues involving human participation, current endeavors like Baizeand UltraChat rely on ChatGPT conducting roleplay to simulate humans based oninstructions, resulting in overdependence on seeds, diminished human-likeness,limited topic diversity, and an absence of genuine multi-round conversationaldynamics. To address the above issues, we propose a paradigm to simulate humanbehavior better and explore the benefits of incorporating more human-likequestions in multi-turn conversations. Specifically, we directly target humanquestions extracted from genuine human-machine conversations as a learning goaland provide a novel user simulator called `Socratic'. The experimental resultsshow our response model, `PlatoLM', achieves SoTA performance among LLaMA-based7B models in MT-Bench. Our findings further demonstrate that our methodintroduces highly human-like questioning patterns and rich topic structures,which can teach the response model better than previous works in multi-roundconversations.</description><author>Chuyi Kong, Yaxin Fan, Xiang Wan, Feng Jiang, Benyou Wang</author><pubDate>Mon, 27 May 2024 17:32:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11534v5</guid></item><item><title>Double Correction Framework for Denoising Recommendation</title><link>http://arxiv.org/abs/2405.11272v2</link><description>As its availability and generality in online services, implicit feedback ismore commonly used in recommender systems. However, implicit feedback usuallypresents noisy samples in real-world recommendation scenarios (such asmisclicks or non-preferential behaviors), which will affect precise userpreference learning. To overcome the noisy samples problem, a popular solutionis based on dropping noisy samples in the model training phase, which followsthe observation that noisy samples have higher training losses than cleansamples. Despite the effectiveness, we argue that this solution still haslimits. (1) High training losses can result from model optimization instabilityor hard samples, not just noisy samples. (2) Completely dropping of noisysamples will aggravate the data sparsity, which lacks full data exploitation.To tackle the above limitations, we propose a Double Correction Framework forDenoising Recommendation (DCF), which contains two correction components fromviews of more precise sample dropping and avoiding more sparse data. In thesample dropping correction component, we use the loss value of the samples overtime to determine whether it is noise or not, increasing dropping stability.Instead of averaging directly, we use the damping function to reduce the biaseffect of outliers. Furthermore, due to the higher variance exhibited by hardsamples, we derive a lower bound for the loss through concentration inequalityto identify and reuse hard samples. In progressive label correction, weiteratively re-label highly deterministic noisy samples and retrain them tofurther improve performance. Finally, extensive experimental results on threedatasets and four backbones demonstrate the effectiveness and generalization ofour proposed framework.</description><author>Zhuangzhuang He, Yifan Wang, Yonghui Yang, Peijie Sun, Le Wu, Haoyue Bai, Jinqi Gong, Richang Hong, Min Zhang</author><pubDate>Mon, 27 May 2024 17:29:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11272v2</guid></item><item><title>Novel Approaches for ML-Assisted Particle Track Reconstruction and Hit Clustering</title><link>http://arxiv.org/abs/2405.17325v1</link><description>Track reconstruction is a vital aspect of High-Energy Physics (HEP) and playsa critical role in major experiments. In this study, we delve into unexploredavenues for particle track reconstruction and hit clustering. Firstly, weenhance the algorithmic design effort by utilising a simplified simulator(REDVID) to generate training data that is specifically composed forsimplicity. We demonstrate the effectiveness of this data in guiding thedevelopment of optimal network architectures. Additionally, we investigate theapplication of image segmentation networks for this task, exploring theirpotential for accurate track reconstruction. Moreover, we approach the taskfrom a different perspective by treating it as a hit sequence to track sequencetranslation problem. Specifically, we explore the utilisation of Transformerarchitectures for tracking purposes. Our preliminary findings are covered indetail. By considering this novel approach, we aim to uncover new insights andpotential advancements in track reconstruction. This research sheds light onpreviously unexplored methods and provides valuable insights for the field ofparticle track reconstruction and hit clustering in HEP.</description><author>Uraz Odyurt, Nadezhda Dobreva, Zef Wolffs, Yue Zhao, Antonio Ferrer Sánchez, Roberto Ruiz de Austri Bazan, José D. Martín-Guerrero, Ana-Lucia Varbanescu, Sascha Caron</author><pubDate>Mon, 27 May 2024 17:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17325v1</guid></item><item><title>Leveraging Offline Data in Linear Latent Bandits</title><link>http://arxiv.org/abs/2405.17324v1</link><description>Sequential decision-making domains such as recommender systems, healthcareand education often have unobserved heterogeneity in the population that can bemodeled using latent bandits $-$ a framework where an unobserved latent statedetermines the model for a trajectory. While the latent bandit framework iscompelling, the extent of its generality is unclear. We first address this byestablishing a de Finetti theorem for decision processes, and show that$\textit{every}$ exchangeable and coherent stateless decision process is alatent bandit. The latent bandit framework lends itself particularly well toonline learning with offline datasets, a problem of growing interest insequential decision-making. One can leverage offline latent bandit data tolearn a complex model for each latent state, so that an agent can simply learnthe latent state online to act optimally. We focus on a linear model for alatent bandit with $d_A$-dimensional actions, where the latent states lie in anunknown $d_K$-dimensional subspace for $d_K \ll d_A$. We present SOLD, a novelprincipled method to learn this subspace from short offline trajectories withguarantees. We then provide two methods to leverage this subspace online:LOCAL-UCB and ProBALL-UCB. We demonstrate that LOCAL-UCB enjoys $\tildeO(\min(d_A\sqrt{T}, d_K\sqrt{T}(1+\sqrt{d_AT/d_KN})))$ regret guarantees, wherethe effective dimension is lower when the size $N$ of the offline dataset islarger. ProBALL-UCB enjoys a slightly weaker guarantee, but is more practicaland computationally efficient. Finally, we establish the efficacy of ourmethods using experiments on both synthetic data and real-life movierecommendation data from MovieLens.</description><author>Chinmaya Kausik, Kevin Tan, Ambuj Tewari</author><pubDate>Mon, 27 May 2024 17:23:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17324v1</guid></item><item><title>Sharp Generalization of Transductive Learning: A Transductive Local Rademacher Complexity Approach</title><link>http://arxiv.org/abs/2309.16858v2</link><description>We introduce a new tool, Transductive Local Complexity (TLC), designed toanalyze the generalization performance of transductive learning methods andinspire the development of new algorithms in this domain. Our work extends theconcept of the popular Local Rademacher Complexity (LRC) to the transductivesetting, incorporating significant and novel modifications compared to thetypical analysis of LRC methods in the inductive setting. While LRC has beenwidely used as a powerful tool for analyzing inductive models, providing sharpgeneralization bounds for classification and minimax rates for nonparametricregression, it remains an open question whether a localized Rademachercomplexity-based tool can be developed for transductive learning. Our goal isto achieve sharp bounds for transductive learning that align with the inductiveexcess risk bounds established by LRC. We provide a definitive answer to thisopen problem with the introduction of TLC. We construct TLC by firstestablishing a novel and sharp concentration inequality for the supremum of atest-train empirical processes. Using a peeling strategy and a new surrogatevariance operator, we derive the a novel excess risk bound in the transductivesetting which is consistent with the classical LRC-based excess risk bound inthe inductive setting. As an application of TLC, we employ this new tool toanalyze the Transductive Kernel Learning (TKL) model, deriving sharper excessrisk bounds than those provided by the current state-of-the-art under the sameassumptions. Additionally, the concentration inequality for the test-trainprocess is employed to derive a sharp concentration inequality for the generalsupremum of empirical processes involving random variables in the setting ofuniform sampling without replacement. The sharpness of our derived bound iscompared to existing concentration inequalities under the same conditions.</description><author>Yingzhen Yang</author><pubDate>Mon, 27 May 2024 17:23:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16858v2</guid></item><item><title>Tracking Small Birds by Detection Candidate Region Filtering and Detection History-aware Association</title><link>http://arxiv.org/abs/2405.17323v1</link><description>This paper focuses on tracking birds that appear small in a panoramic video.When the size of the tracked object is small in the image (small objecttracking) and move quickly, object detection and association suffers. Toaddress these problems, we propose Adaptive Slicing Aided Hyper Inference(Adaptive SAHI), which reduces the candidate regions to apply detection, andDetection History-aware Similarity Criterion (DHSC), which accuratelyassociates objects in consecutive frames based on the detection history.Experiments on the NUBird2022 dataset verifies the effectiveness of theproposed method by showing improvements in both accuracy and speed.</description><author>Tingwei Liu, Yasutomo Kawanishi, Takahiro Komamizu, Ichiro Ide</author><pubDate>Mon, 27 May 2024 17:22:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17323v1</guid></item><item><title>All-day Depth Completion</title><link>http://arxiv.org/abs/2405.17315v1</link><description>We propose a method for depth estimation under different illuminationconditions, i.e., day and night time. As photometry is uninformative in regionsunder low-illumination, we tackle the problem through a multi-sensor fusionapproach, where we take as input an additional synchronized sparse point cloud(i.e., from a LiDAR) projected onto the image plane as a sparse depth map,along with a camera image. The crux of our method lies in the use of theabundantly available synthetic data to first approximate the 3D scene structureby learning a mapping from sparse to (coarse) dense depth maps along with theirpredictive uncertainty - we term this, SpaDe. In poorly illuminated regionswhere photometric intensities do not afford the inference of local shape, thecoarse approximation of scene depth serves as a prior; the uncertainty map isthen used with the image to guide refinement through an uncertainty-drivenresidual learning (URL) scheme. The resulting depth completion networkleverages complementary strengths from both modalities - depth is sparse butinsensitive to illumination and in metric scale, and image is dense butsensitive with scale ambiguity. SpaDe can be used in a plug-and-play fashion,which allows for 25% improvement when augmented onto existing methods topreprocess sparse depth. We demonstrate URL on the nuScenes dataset where weimprove over all baselines by an average 11.65% in all-day scenarios, 11.23%when tested specifically for daytime, and 13.12% for nighttime scenes.</description><author>Vadim Ezhov, Hyoungseob Park, Zhaoyang Zhang, Rishi Upadhyay, Howard Zhang, Chethan Chinder Chandrappa, Achuta Kadambi, Yunhao Ba, Julie Dorsey, Alex Wong</author><pubDate>Mon, 27 May 2024 17:16:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17315v1</guid></item><item><title>Geometry-Informed Neural Networks</title><link>http://arxiv.org/abs/2402.14009v2</link><description>Geometry is a ubiquitous language of computer graphics, design, andengineering. However, the lack of large shape datasets limits the applicationof state-of-the-art supervised learning methods and motivates the explorationof alternative learning strategies. To this end, we introduce geometry-informedneural networks (GINNs) to train shape generative models \emph{without anydata}. GINNs combine (i) learning under constraints, (ii) neural fields as asuitable representation, and (iii) generating diverse solutions tounder-determined problems. We apply GINNs to several two and three-dimensionalproblems of increasing levels of complexity. Our results demonstrate thefeasibility of training shape generative models in a data-free setting. Thisnew paradigm opens several exciting research directions, expanding theapplication of generative models into domains where data is sparse.</description><author>Arturs Berzins, Andreas Radler, Sebastian Sanokowski, Sepp Hochreiter, Johannes Brandstetter</author><pubDate>Mon, 27 May 2024 17:12:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14009v2</guid></item><item><title>Probabilistic Graph Rewiring via Virtual Nodes</title><link>http://arxiv.org/abs/2405.17311v1</link><description>Message-passing graph neural networks (MPNNs) have emerged as a powerfulparadigm for graph-based machine learning. Despite their effectiveness, MPNNsface challenges such as under-reaching and over-squashing, where limitedreceptive fields and structural bottlenecks hinder information flow in thegraph. While graph transformers hold promise in addressing these issues, theirscalability is limited due to quadratic complexity regarding the number ofnodes, rendering them impractical for larger graphs. Here, we propose\emph{implicitly rewired message-passing neural networks} (IPR-MPNNs), a novelapproach that integrates \emph{implicit} probabilistic graph rewiring intoMPNNs. By introducing a small number of virtual nodes, i.e., adding additionalnodes to a given graph and connecting them to existing nodes, in adifferentiable, end-to-end manner, IPR-MPNNs enable long-distance messagepropagation, circumventing quadratic complexity. Theoretically, we demonstratethat IPR-MPNNs surpass the expressiveness of traditional MPNNs. Empirically, wevalidate our approach by showcasing its ability to mitigate under-reaching andover-squashing effects, achieving state-of-the-art performance across multiplegraph datasets. Notably, IPR-MPNNs outperform graph transformers whilemaintaining significantly faster computational efficiency.</description><author>Chendi Qian, Andrei Manolache, Christopher Morris, Mathias Niepert</author><pubDate>Mon, 27 May 2024 17:11:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17311v1</guid></item><item><title>Recurrent Early Exits for Federated Learning with Heterogeneous Clients</title><link>http://arxiv.org/abs/2405.14791v2</link><description>Federated learning (FL) has enabled distributed learning of a model acrossmultiple clients in a privacy-preserving manner. One of the main challenges ofFL is to accommodate clients with varying hardware capacities; clients havediffering compute and memory requirements. To tackle this challenge, recentstate-of-the-art approaches leverage the use of early exits. Nonetheless, theseapproaches fall short of mitigating the challenges of joint learning multipleexit classifiers, often relying on hand-picked heuristic solutions forknowledge distillation among classifiers and/or utilizing additional layers forweaker classifiers. In this work, instead of utilizing multiple classifiers, wepropose a recurrent early exit approach named ReeFL that fuses features fromdifferent sub-models into a single shared classifier. Specifically, we use atransformer-based early-exit module shared among sub-models to i) betterexploit multi-layer feature representations for task-specific prediction andii) modulate the feature representation of the backbone model for subsequentpredictions. We additionally present a per-client self-distillation approachwhere the best sub-model is automatically selected as the teacher of the othersub-models at each client. Our experiments on standard image and speechclassification benchmarks across various emerging federated fine-tuningbaselines demonstrate ReeFL's effectiveness over previous works.</description><author>Royson Lee, Javier Fernandez-Marques, Shell Xu Hu, Da Li, Stefanos Laskaridis, Łukasz Dudziak, Timothy Hospedales, Ferenc Huszár, Nicholas D. Lane</author><pubDate>Mon, 27 May 2024 17:11:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14791v2</guid></item><item><title>Convolutional Neural Networks Rarely Learn Shape for Semantic Segmentation</title><link>http://arxiv.org/abs/2305.06568v3</link><description>Shape learning, or the ability to leverage shape information, could be adesirable property of convolutional neural networks (CNNs) when target objectshave specific shapes. While some research on the topic is emerging, there is nosystematic study to conclusively determine whether and under what circumstancesCNNs learn shape. Here, we present such a study in the context of segmentationnetworks where shapes are particularly important. We define shape and propose anew behavioral metric to measure the extent to which a CNN utilizes shapeinformation. We then execute a set of experiments with synthetic and real-worlddata to progressively uncover under which circumstances CNNs learn shape andwhat can be done to encourage such behavior. We conclude that (i) CNNs do notlearn shape in typical settings but rather rely on other features available toidentify the objects of interest, (ii) CNNs can learn shape, but only if theshape is the only feature available to identify the object, (iii) sufficientlylarge receptive field size relative to the size of target objects is necessaryfor shape learning; (iv) a limited set of augmentations can encourage shapelearning; (v) learning shape is indeed useful in the presence ofout-of-distribution data.</description><author>Yixin Zhang, Maciej A. Mazurowski</author><pubDate>Mon, 27 May 2024 17:11:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06568v3</guid></item><item><title>Survey of Graph Neural Network for Internet of Things and NextG Networks</title><link>http://arxiv.org/abs/2405.17309v1</link><description>The exponential increase in Internet of Things (IoT) devices coupled with 6Gpushing towards higher data rates and connected devices has sparked a surge indata. Consequently, harnessing the full potential of data-driven machinelearning has become one of the important thrusts. In addition to theadvancement in wireless technology, it is important to efficiently use theresources available and meet the users' requirements. Graph Neural Networks(GNNs) have emerged as a promising paradigm for effectively modeling andextracting insights which inherently exhibit complex network structures due toits high performance and accuracy, scalability, adaptability, and resourceefficiency. There is a lack of a comprehensive survey that focuses on theapplications and advances GNN has made in the context of IoT and NextGeneration (NextG) networks. To bridge that gap, this survey starts byproviding a detailed description of GNN's terminologies, architecture, and thedifferent types of GNNs. Then we provide a comprehensive survey of theadvancements in applying GNNs for IoT from the perspective of data fusion andintrusion detection. Thereafter, we survey the impact GNN has made in improvingspectrum awareness. Next, we provide a detailed account of how GNN has beenleveraged for networking and tactical systems. Through this survey, we aim toprovide a comprehensive resource for researchers to learn more about GNN in thecontext of wireless networks, and understand its state-of-the-art use caseswhile contrasting to other machine learning approaches. Finally, we alsodiscussed the challenges and wide range of future research directions tofurther motivate the use of GNN for IoT and NextG Networks.</description><author>Sabarish Krishna Moorthy, Jithin Jagannath</author><pubDate>Mon, 27 May 2024 17:10:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17309v1</guid></item><item><title>Multi-Task Dense Prediction via Mixture of Low-Rank Experts</title><link>http://arxiv.org/abs/2403.17749v2</link><description>Previous multi-task dense prediction methods based on the Mixture of Experts(MoE) have received great performance but they neglect the importance ofexplicitly modeling the global relations among all tasks. In this paper, wepresent a novel decoder-focused method for multi-task dense prediction, calledMixture-of-Low-Rank-Experts (MLoRE). To model the global task relationships,MLoRE adds a generic convolution path to the original MoE structure, where eachtask feature can go through this path for explicit parameter sharing.Furthermore, to control the parameters and computational cost brought by theincrease in the number of experts, we take inspiration from LoRA and propose toleverage the low-rank format of a vanilla convolution in the expert network.Since the low-rank experts have fewer parameters and can be dynamicallyparameterized into the generic convolution, the parameters and computationalcost do not change much with the increase of experts. Benefiting from thisdesign, we increase the number of experts and its reception field to enlargethe representation capacity, facilitating multiple dense tasks learning in aunified network. Extensive experiments on the PASCAL-Context and NYUD-v2benchmarks show that our MLoRE achieves superior performance compared toprevious state-of-the-art methods on all metrics. Our code is available athttps://github.com/YuqiYang213/MLoRE.</description><author>Yuqi Yang, Peng-Tao Jiang, Qibin Hou, Hao Zhang, Jinwei Chen, Bo Li</author><pubDate>Mon, 27 May 2024 17:09:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17749v2</guid></item><item><title>Controllable Longer Image Animation with Diffusion Models</title><link>http://arxiv.org/abs/2405.17306v1</link><description>Generating realistic animated videos from static images is an important areaof research in computer vision. Methods based on physical simulation and motionprediction have achieved notable advances, but they are often limited tospecific object textures and motion trajectories, failing to exhibit highlycomplex environments and physical dynamics. In this paper, we introduce anopen-domain controllable image animation method using motion priors with videodiffusion models. Our method achieves precise control over the direction andspeed of motion in the movable region by extracting the motion fieldinformation from videos and learning moving trajectories and strengths. Currentpretrained video generation models are typically limited to producing veryshort videos, typically less than 30 frames. In contrast, we propose anefficient long-duration video generation method based on noise reschedulespecifically tailored for image animation tasks, facilitating the creation ofvideos over 100 frames in length while maintaining consistency in contentscenery and motion coordination. Specifically, we decompose the denoise processinto two distinct phases: the shaping of scene contours and the refining ofmotion details. Then we reschedule the noise to control the generated framesequences maintaining long-distance noise correlation. We conducted extensiveexperiments with 10 baselines, encompassing both commercial tools and academicmethodologies, which demonstrate the superiority of our method. Our projectpage: \url{https://wangqiang9.github.io/Controllable.github.io/}</description><author>Qiang Wang, Minghua Liu, Junjun Hu, Fan Jiang, Mu Xu</author><pubDate>Mon, 27 May 2024 17:08:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17306v1</guid></item><item><title>NuwaTS: a Foundation Model Mending Every Incomplete Time Series</title><link>http://arxiv.org/abs/2405.15317v2</link><description>Time series imputation plays a crucial role in various real-world systems andhas been extensively explored. Models for time series imputation often requirespecialization, necessitating distinct designs for different domains andmissing patterns. In this study, we introduce NuwaTS, a framework to repurposePre-trained Language Model (PLM) for general time series imputation. Oncetrained, this model can be applied to imputation tasks on incomplete timeseries from any domain with any missing patterns. We begin by devising specificembeddings for each sub-series patch of the incomplete time series. Theseembeddings encapsulate information about the patch itself, the missing datapatterns within the patch, and the patch's statistical characteristics. Toenhance the model's adaptability to different missing patterns, we propose acontrastive learning approach to make representations of the same patch moresimilar across different missing patterns. By combining this contrastive losswith the missing data imputation task, we train PLMs to obtain a one-for-allimputation model. Furthermore, we utilize a plug-and-play layer-wisefine-tuning approach to train domain-specific models. Experimental resultsdemonstrate that leveraging a dataset of over seventeen million time seriesfrom diverse domains, we obtain a one-for-all imputation model whichoutperforms existing domain-specific models across various datasets and missingpatterns. Additionally, we find that NuwaTS can be generalized to other timeseries tasks such as forecasting. Our codes are available athttps://github.com/Chengyui/NuwaTS.</description><author>Jinguo Cheng, Chunwei Yang, Wanlin Cai, Yuxuan Liang, Yuankai Wu</author><pubDate>Mon, 27 May 2024 17:01:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15317v2</guid></item><item><title>Simplicity Bias of Two-Layer Networks beyond Linearly Separable Data</title><link>http://arxiv.org/abs/2405.17299v1</link><description>Simplicity bias, the propensity of deep models to over-rely on simplefeatures, has been identified as a potential reason for limitedout-of-distribution generalization of neural networks (Shah et al., 2020).Despite the important implications, this phenomenon has been theoreticallyconfirmed and characterized only under strong dataset assumptions, such aslinear separability (Lyu et al., 2021). In this work, we characterizesimplicity bias for general datasets in the context of two-layer neuralnetworks initialized with small weights and trained with gradient flow.Specifically, we prove that in the early training phases, network featurescluster around a few directions that do not depend on the size of the hiddenlayer. Furthermore, for datasets with an XOR-like pattern, we preciselyidentify the learned features and demonstrate that simplicity bias intensifiesduring later training stages. These results indicate that features learned inthe middle stages of training may be more useful for OOD transfer. We supportthis hypothesis with experiments on image data.</description><author>Nikita Tsoy, Nikola Konstantinov</author><pubDate>Mon, 27 May 2024 17:00:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17299v1</guid></item><item><title>Think Before You Act: Decision Transformers with Working Memory</title><link>http://arxiv.org/abs/2305.16338v2</link><description>Decision Transformer-based decision-making agents have shown the ability togeneralize across multiple tasks. However, their performance relies on massivedata and computation. We argue that this inefficiency stems from the forgettingphenomenon, in which a model memorizes its behaviors in parameters throughouttraining. As a result, training on a new task may deteriorate the model'sperformance on previous tasks. In contrast to LLMs' implicit memory mechanism,the human brain utilizes distributed memory storage, which helps manage andorganize multiple skills efficiently, mitigating the forgetting phenomenon.Inspired by this, we propose a working memory module to store, blend, andretrieve information for different downstream tasks. Evaluation results showthat the proposed method improves training efficiency and generalization inAtari games and Meta-World object manipulation tasks. Moreover, we demonstratethat memory fine-tuning further enhances the adaptability of the proposedarchitecture.</description><author>Jikun Kang, Romain Laroche, Xingdi Yuan, Adam Trischler, Xue Liu, Jie Fu</author><pubDate>Mon, 27 May 2024 17:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16338v2</guid></item><item><title>Efficient Ensembles Improve Training Data Attribution</title><link>http://arxiv.org/abs/2405.17293v1</link><description>Training data attribution (TDA) methods aim to quantify the influence ofindividual training data points on the model predictions, with broadapplications in data-centric AI, such as mislabel detection, data selection,and copyright compensation. However, existing methods in this field, which canbe categorized as retraining-based and gradient-based, have struggled with thetrade-off between computational efficiency and attribution efficacy.Retraining-based methods can accurately attribute complex non-convex models butare computationally prohibitive, while gradient-based methods are efficient butoften fail for non-convex models. Recent research has shown that augmentinggradient-based methods with ensembles of multiple independently trained modelscan achieve significantly better attribution efficacy. However, this approachremains impractical for very large-scale applications. In this work, we discover that expensive, fully independent training isunnecessary for ensembling the gradient-based methods, and we propose twoefficient ensemble strategies, DROPOUT ENSEMBLE and LORA ENSEMBLE, alternativeto naive independent ensemble. These strategies significantly reduce trainingtime (up to 80%), serving time (up to 60%), and space cost (up to 80%) whilemaintaining similar attribution efficacy to the naive independent ensemble. Ourextensive experimental results demonstrate that the proposed strategies areeffective across multiple TDA methods on diverse datasets and models, includinggenerative settings, significantly advancing the Pareto frontier of TDA methodswith better computational efficiency and attribution efficacy.</description><author>Junwei Deng, Ting-Wei Li, Shichang Zhang, Jiaqi Ma</author><pubDate>Mon, 27 May 2024 16:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17293v1</guid></item><item><title>Opinion-Guided Reinforcement Learning</title><link>http://arxiv.org/abs/2405.17287v1</link><description>Human guidance is often desired in reinforcement learning to improve theperformance of the learning agent. However, human insights are often mereopinions and educated guesses rather than well-formulated arguments. Whileopinions are subject to uncertainty, e.g., due to partial informedness orignorance about a problem, they also emerge earlier than hard evidence could beproduced. Thus, guiding reinforcement learning agents through opinions offersthe potential for more performant learning processes, but comes with thechallenge of modeling and managing opinions in a formal way. In this article,we present a method to guide reinforcement learning agents through opinions. Tothis end, we provide an end-to-end method to model and manage advisors'opinions. To assess the utility of the approach, we evaluate it with syntheticand human advisors, at different levels of uncertainty, and under multipleadvise strategies. Our results indicate that opinions, even if uncertain,improve the performance of reinforcement learning agents, resulting in higherrewards, more efficient exploration, and a better reinforced policy. Althoughwe demonstrate our approach in a simplified topological running example, ourapproach is applicable to complex problems with higher dimensions as well.</description><author>Kyanna Dagenais, Istvan David</author><pubDate>Mon, 27 May 2024 16:52:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17287v1</guid></item><item><title>ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models</title><link>http://arxiv.org/abs/2402.13516v3</link><description>Activation sparsity refers to the existence of considerableweakly-contributed elements among activation outputs. As a prevalent propertyof the models using the ReLU activation function, activation sparsity has beenproven a promising paradigm to boost model inference efficiency. Nevertheless,most large language models (LLMs) adopt activation functions without intrinsicactivation sparsity (e.g., GELU and Swish). Some recent efforts have exploredintroducing ReLU or its variants as the substitutive activation function tohelp LLMs achieve activation sparsity and inference acceleration, but few cansimultaneously obtain high sparsity and comparable model performance. Thispaper introduces a simple and effective sparsification method named "ProSparse"to push LLMs for higher activation sparsity while maintaining comparableperformance. Specifically, after substituting the activation function of LLMswith ReLU, ProSparse adopts progressive sparsity regularization with a factorsmoothly increasing along the multi-stage sine curves. This can enhanceactivation sparsity and mitigate performance degradation by avoiding radicalshifts in activation distributions. With ProSparse, we obtain high sparsity of89.32% for LLaMA2-7B, 88.80% for LLaMA2-13B, and 87.89% for end-sizeMiniCPM-1B, respectively, achieving comparable performance to their originalSwish-activated versions. These present the most sparsely activated modelsamong open-source LLaMA versions and competitive end-size models, considerablysurpassing ReluLLaMA-7B (66.98%) and ReluLLaMA-13B (71.56%). Our inferenceacceleration experiments further demonstrate the significant practicalacceleration potential of LLMs with higher activation sparsity, obtaining up to4.52$\times$ inference speedup.</description><author>Chenyang Song, Xu Han, Zhengyan Zhang, Shengding Hu, Xiyu Shi, Kuai Li, Chen Chen, Zhiyuan Liu, Guangli Li, Tao Yang, Maosong Sun</author><pubDate>Mon, 27 May 2024 16:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13516v3</guid></item><item><title>An NLP Crosswalk Between the Common Core State Standards and NAEP Item Specifications</title><link>http://arxiv.org/abs/2405.17284v1</link><description>Natural language processing (NLP) is rapidly developing for applications ineducational assessment. In this paper, I describe an NLP-based procedure thatcan be used to support subject matter experts in establishing a crosswalkbetween item specifications and content standards. This paper extends recentwork by proposing and demonstrating the use of multivariate similarity based onembedding vectors for sentences or texts. In particular, a hybrid regressionprocedure is demonstrated for establishing the match of each content standardto multiple item specifications. The procedure is used to evaluate the match ofthe Common Core State Standards (CCSS) for mathematics at grade 4 to thecorresponding item specifications for the 2026 National Assessment ofEducational Progress (NAEP).</description><author>Gregory Camilli</author><pubDate>Mon, 27 May 2024 16:47:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17284v1</guid></item><item><title>Recurrent Complex-Weighted Autoencoders for Unsupervised Object Discovery</title><link>http://arxiv.org/abs/2405.17283v1</link><description>Current state-of-the-art synchrony-based models encode object bindings withcomplex-valued activations and compute with real-valued weights in feedforwardarchitectures. We argue for the computational advantages of a recurrentarchitecture with complex-valued weights. We propose a fully convolutionalautoencoder, SynCx, that performs iterative constraint satisfaction: at eachiteration, a hidden layer bottleneck encodes statistically regularconfigurations of features in particular phase relationships; over iterations,local constraints propagate and the model converges to a globally consistentconfiguration of phase assignments. Binding is achieved simply by thematrix-vector product operation between complex-valued weights and activations,without the need for additional mechanisms that have been incorporated intocurrent synchrony-based models. SynCx outperforms or is strongly competitivewith current models for unsupervised object discovery. SynCx also avoidscertain systematic grouping errors of current models, such as the inability toseparate similarly colored objects without additional supervision.</description><author>Anand Gopalakrishnan, Aleksandar Stanić, Jürgen Schmidhuber, Michael Curtis Mozer</author><pubDate>Mon, 27 May 2024 16:47:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17283v1</guid></item><item><title>R-ODE: Ricci Curvature Tells When You Will be Informed</title><link>http://arxiv.org/abs/2405.17282v1</link><description>Information diffusion prediction is fundamental to understand the structureand organization of the online social networks, and plays a crucial role toblocking rumor spread, influence maximization, political propaganda, etc. Sofar, most existing solutions primarily predict the next user who will beinformed with historical cascades, but ignore an important factor in thediffusion process - the time. Such limitation motivates us to pose the problemof the time-aware personalized information diffusion prediction for the firsttime, telling the time when the target user will be informed. In this paper, weaddress this problem from a fresh geometric perspective of Ricci curvature, andpropose a novel Ricci-curvature regulated Ordinary Differential Equation(R-ODE). In the diffusion process, R-ODE considers that the inter-correlatedusers are organized in a dynamic system in the representation space, and thecascades give the observations sampled from the continuous realm. At eachinfection time, the message diffuses along the largest Ricci curvature,signifying less transportation effort. In the continuous realm, the messagetriggers users' movement, whose trajectory in the space is parameterized by anODE with graph neural network. Consequently, R-ODE predicts the infection timeof a target user by the movement trajectory learnt from the observations.Extensive experiments evaluate the personalized time prediction ability ofR-ODE, and show R-ODE outperforms the state-of-the-art baselines.</description><author>Li Sun, Jingbin Hu, Mengjie Li, Hao Peng</author><pubDate>Mon, 27 May 2024 16:46:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17282v1</guid></item><item><title>A Library for Automatic Natural Language Generation of Spanish Texts</title><link>http://arxiv.org/abs/2405.17280v1</link><description>In this article we present a novel system for natural language generation(NLG) of Spanish sentences from a minimum set of meaningful words (such asnouns, verbs and adjectives) which, unlike other state-of-the-art solutions,performs the NLG task in a fully automatic way, exploiting both knowledge-basedand statistical approaches. Relying on its linguistic knowledge of vocabularyand grammar, the system is able to generate complete, coherent and correctlyspelled sentences from the main word sets presented by the user. The system,which was designed to be integrable, portable and efficient, can be easilyadapted to other languages by design and can feasibly be integrated in a widerange of digital devices. During its development we also created asupplementary lexicon for Spanish, aLexiS, with wide coverage and highprecision, as well as syntactic trees from a freely available definite-clausegrammar. The resulting NLG library has been evaluated both automatically andmanually (annotation). The system can potentially be used in differentapplication domains such as augmentative communication and automatic generationof administrative reports or news.</description><author>Silvia García-Méndez, Milagros Fernández-Gavilanes, Enrique Costa-Montenegro, Jonathan Juncal-Martínez, F. Javier González-Castaño</author><pubDate>Mon, 27 May 2024 16:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17280v1</guid></item><item><title>Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis</title><link>http://arxiv.org/abs/2308.00404v2</link><description>The success of graph neural network-based models (GNNs) has significantlyadvanced recommender systems by effectively modeling users and items as abipartite, undirected graph. However, many original graph-based works oftenadopt results from baseline papers without verifying their validity for thespecific configuration under analysis. Our work addresses this issue byfocusing on the replicability of results. We present a code that successfullyreplicates results from six popular and recent graph recommendation models(NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmarkdatasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare thesegraph models with traditional collaborative filtering models that historicallyperformed well in offline evaluations. Furthermore, we extend our study to twonew datasets (Allrecipes and BookCrossing) that lack established setups inexisting literature. As the performance on these datasets differs from theprevious benchmarks, we analyze the impact of specific dataset characteristicson recommendation accuracy. By investigating the information flow from users'neighborhoods, we aim to identify which models are influenced by intrinsicfeatures in the dataset structure. The code to reproduce our experiments isavailable at: https://github.com/sisinflab/Graph-RSs-Reproducibility.</description><author>Vito Walter Anelli, Daniele Malitesta, Claudio Pomo, Alejandro Bellogín, Tommaso Di Noia, Eugenio Di Sciascio</author><pubDate>Mon, 27 May 2024 16:42:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00404v2</guid></item><item><title>Socially-Aware Shared Control Navigation for Assistive Mobile Robots in the Built Environment</title><link>http://arxiv.org/abs/2405.17279v1</link><description>As the number of Persons with Disabilities (PWD), particularly those with oneor more physical impairments, increases, there is an increasing demand forassistive robotic technologies that can support independent mobility in thebuilt environment and reduce the burden on caregivers. Current assistivemobility platforms (e.g., robotic wheelchairs) often fail to incorporate userpreferences and control, leading to reduced trust and efficiency. Existingshared control algorithms do not allow the incorporation of the user controlpreferences inside the navigation framework or the path planning algorithm. Inaddition, existing dynamic local planner algorithms for robotic wheelchairs donot take into account the social spaces of people, potentially leading suchplatforms to infringe upon these areas and cause discomfort. To address theseconcerns, this work introduces a novel socially-aware shared autonomy-basednavigation system for assistive mobile robotic platforms. Our navigation framework comprises a Global Planner and a Local Planner. Toimplement the Global Planner, the proposed approach introduces a novel UserPreference Field (UPF) theory within its global planning framework, explicitlyacknowledging user preferences to adeptly navigate away from congested areas.For the Local Planner, we propose a Socially-aware Shared Control-based ModelPredictive Control with Dynamic Control Barrier Function (SS-MPC-DCBF) toadjust movements in real-time, integrating user preferences for safer, moreautonomous navigation. Evaluation results show that our Global Planner alignsclosely with user preferences compared to baselines, and our Local Plannerdemonstrates enhanced safety and efficiency in dynamic and static scenarios.This integrated approach fosters trust and autonomy, crucial for the acceptanceof assistive mobility technologies in the built environment.</description><author>Yifan Xu, Qianwei Wang, Vineet Kamat, Carol Menassa</author><pubDate>Mon, 27 May 2024 16:40:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17279v1</guid></item><item><title>EF-Calib: Spatiotemporal Calibration of Event- and Frame-Based Cameras Using Continuous-Time Trajectories</title><link>http://arxiv.org/abs/2405.17278v1</link><description>Event camera, a bio-inspired asynchronous triggered camera, offers promisingprospects for fusion with frame-based cameras owing to its low latency and highdynamic range. However, calibrating stereo vision systems that incorporate bothevent and frame-based cameras remains a significant challenge. In this letter,we present EF-Calib, a spatiotemporal calibration framework for event- andframe-based cameras using continuous-time trajectories. A novel calibrationpattern applicable to both camera types and the corresponding event recognitionalgorithm is proposed. Leveraging the asynchronous nature of events, aderivable piece-wise B-spline to represent camera pose continuously isintroduced, enabling calibration for intrinsic parameters, extrinsicparameters, and time offset, with analytical Jacobians provided. Variousexperiments are carried out to evaluate the calibration performance ofEF-Calib, including calibration experiments for intrinsic parameters, extrinsicparameters, and time offset. Experimental results show that EF-Calib achievesthe most accurate intrinsic parameters compared to current SOTA, the closeaccuracy of the extrinsic parameters compared to the frame-based results, andaccurate time offset estimation. EF-Calib provides a convenient and accuratetoolbox for calibrating the system that fuses events and frames. The code ofthis paper will also be open-sourced at: https://github.com/wsakobe/EF-Calib.</description><author>Shaoan Wang, Zhanhua Xin, Yaoqing Hu, Dongyue Li, Mingzhu Zhu, Junzhi Yu</author><pubDate>Mon, 27 May 2024 16:40:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17278v1</guid></item><item><title>UniTable: Towards a Unified Framework for Table Recognition via Self-Supervised Pretraining</title><link>http://arxiv.org/abs/2403.04822v2</link><description>Tables convey factual and quantitative data with implicit conventions createdby humans that are often challenging for machines to parse. Prior work on tablerecognition (TR) has mainly centered around complex task-specific combinationsof available inputs and tools. We present UniTable, a training framework thatunifies both the training paradigm and training objective of TR. Its trainingparadigm combines the simplicity of purely pixel-level inputs with theeffectiveness and scalability empowered by self-supervised pretraining fromdiverse unannotated tabular images. Our framework unifies the trainingobjectives of all three TR tasks - extracting table structure, cell content,and cell bounding box - into a unified task-agnostic training objective:language modeling. Extensive quantitative and qualitative analyses highlightUniTable's state-of-the-art (SOTA) performance on four of the largest TRdatasets. UniTable's table parsing capability has surpassed both existing TRmethods and general large vision-language models, e.g., GPT-4o, GPT-4-turbowith vision, and LLaVA. Our code is publicly available athttps://github.com/poloclub/unitable, featuring a Jupyter Notebook thatincludes the complete inference pipeline, fine-tuned across multiple TRdatasets, supporting all three TR tasks.</description><author>ShengYun Peng, Aishwarya Chakravarthy, Seongmin Lee, Xiaojing Wang, Rajarajeswari Balasubramaniyan, Duen Horng Chau</author><pubDate>Mon, 27 May 2024 16:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04822v2</guid></item></channel></rss>