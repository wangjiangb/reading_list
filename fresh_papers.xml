<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 21 Aug 2024 13:00:07 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Prompt-Guided Image-Adaptive Neural Implicit Lookup Tables for Interpretable Image Enhancement</title><link>http://arxiv.org/abs/2408.11055v1</link><description>In this paper, we delve into the concept of interpretable image enhancement,a technique that enhances image quality by adjusting filter parameters witheasily understandable names such as "Exposure" and "Contrast". Unlike usingpredefined image editing filters, our framework utilizes learnable filters thatacquire interpretable names through training. Our contribution is two-fold.Firstly, we introduce a novel filter architecture called an image-adaptiveneural implicit lookup table, which uses a multilayer perceptron to implicitlydefine the transformation from input feature space to output color space. Byincorporating image-adaptive parameters directly into the input features, weachieve highly expressive filters. Secondly, we introduce a prompt guidanceloss to assign interpretable names to each filter. We evaluate visualimpressions of enhancement results, such as exposure and contrast, using avision and language model along with guiding prompts. We define a constraint toensure that each filter affects only the targeted visual impression withoutinfluencing other attributes, which allows us to obtain the desired filtereffects. Experimental results show that our method outperforms existingpredefined filter-based methods, thanks to the filters optimized to predicttarget results. Our source code is available athttps://github.com/satoshi-kosugi/PG-IA-NILUT.</description><author>Satoshi Kosugi</author><pubDate>Tue, 20 Aug 2024 17:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11055v1</guid></item><item><title>NeCo: Improving DINOv2's spatial representations in 19 GPU hours with Patch Neighbor Consistency</title><link>http://arxiv.org/abs/2408.11054v1</link><description>We propose sorting patch representations across views as a novelself-supervised learning signal to improve pretrained representations. To thisend, we introduce NeCo: Patch Neighbor Consistency, a novel training loss thatenforces patch-level nearest neighbor consistency across a student and teachermodel, relative to reference batches. Our method leverages a differentiablesorting method applied on top of pretrained representations, such asDINOv2-registers to bootstrap the learning signal and further improve uponthem. This dense post-pretraining leads to superior performance across variousmodels and datasets, despite requiring only 19 hours on a single GPU. Wedemonstrate that this method generates high-quality dense feature encoders andestablish several new state-of-the-art results: +5.5% and + 6% fornon-parametric in-context semantic segmentation on ADE20k and Pascal VOC, and+7.2% and +5.7% for linear segmentation evaluations on COCO-Things and -Stuff.</description><author>Valentinos Pariza, Mohammadreza Salehi, Gertjan Burghouts, Francesco Locatello, Yuki M. Asano</author><pubDate>Tue, 20 Aug 2024 17:58:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11054v1</guid></item><item><title>Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks</title><link>http://arxiv.org/abs/2408.11053v1</link><description>The application of large-language models (LLMs) to digital hardware codegeneration is an emerging field. Most LLMs are primarily trained on naturallanguage and software code. Hardware code, such as Verilog, represents only asmall portion of the training data and few hardware benchmarks exist. Toaddress this gap, the open-source VerilogEval benchmark was released in 2023,providing a consistent evaluation framework for LLMs on code completion tasks.It was tested on state-of-the-art models at the time including GPT-4. However,VerilogEval and other Verilog generation benchmarks lack failure analysis and,in present form, are not conducive to exploring prompting techniques. Also,since VerilogEval's release, both commercial and open-source models have seencontinued development. In this work, we evaluate new commercial and open-source models of varyingsizes against an improved VerilogEval benchmark suite. We enhance VerilogEval'sinfrastructure and dataset by automatically classifying failures, introduce newprompts for supporting in-context learning (ICL) examples, and extend thesupported tasks to specification-to-RTL translation. We find a measurableimprovement in commercial state-of-the-art models, with GPT-4 Turbo achieving a59% pass rate on spec-to-RTL tasks. We also study the performance ofopen-source and domain-specific models that have emerged, and demonstrate thatmodels can benefit substantially from ICL. We find that recently-released Llama3.1 405B achieves a pass rate of 58%, effectively matching that of GPT-4 Turbo,and that the much smaller domain-specific RTL-Coder 6.7B models achieve animpressive 37% pass rate. However, prompt engineering is key to achieving goodpass rates, and varies widely with model and task. A benchmark infrastructurethat allows for prompt engineering and failure analysis is key to continuedmodel development and deployment.</description><author>Nathaniel Pinckney, Christopher Batten, Mingjie Liu, Haoxing Ren, Brucek Khailany</author><pubDate>Tue, 20 Aug 2024 17:58:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11053v1</guid></item><item><title>Accelerating Goal-Conditioned RL Algorithms and Research</title><link>http://arxiv.org/abs/2408.11052v1</link><description>Self-supervision has the potential to transform reinforcement learning (RL),paralleling the breakthroughs it has enabled in other areas of machinelearning. While self-supervised learning in other domains aims to find patternsin a fixed dataset, self-supervised goal-conditioned reinforcement learning(GCRL) agents discover new behaviors by learning from the goals achieved duringunstructured interaction with the environment. However, these methods havefailed to see similar success, both due to a lack of data from slowenvironments as well as a lack of stable algorithms. We take a step towardaddressing both of these issues by releasing a high-performance codebase andbenchmark JaxGCRL for self-supervised GCRL, enabling researchers to trainagents for millions of environment steps in minutes on a single GPU. The key tothis performance is a combination of GPU-accelerated environments and a stable,batched version of the contrastive reinforcement learning algorithm, based onan infoNCE objective, that effectively makes use of this increased datathroughput. With this approach, we provide a foundation for future research inself-supervised GCRL, enabling researchers to quickly iterate on new ideas andevaluate them in a diverse set of challenging environments. Website + Code:https://github.com/MichalBortkiewicz/JaxGCRL</description><author>Michał Bortkiewicz, Władek Pałucki, Vivek Myers, Tadeusz Dziarmaga, Tomasz Arczewski, Łukasz Kuciński, Benjamin Eysenbach</author><pubDate>Tue, 20 Aug 2024 17:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11052v1</guid></item><item><title>FLAME: Learning to Navigate with Multimodal LLM in Urban Environments</title><link>http://arxiv.org/abs/2408.11051v1</link><description>Large Language Models (LLMs) have demonstrated potential inVision-and-Language Navigation (VLN) tasks, yet current applications facechallenges. While LLMs excel in general conversation scenarios, they strugglewith specialized navigation tasks, yielding suboptimal performance compared tospecialized VLN models. We introduce FLAME (FLAMingo-Architected EmbodiedAgent), a novel Multimodal LLM-based agent and architecture designed for urbanVLN tasks that efficiently handles multiple observations. Our approachimplements a three-phase tuning technique for effective adaptation tonavigation tasks, including single perception tuning for street viewdescription, multiple perception tuning for trajectory summarization, andend-to-end training on VLN datasets. The augmented datasets are synthesizedautomatically. Experimental results demonstrate FLAME's superiority overexisting methods, surpassing state-of-the-art methods by a 7.3% increase intask completion rate on Touchdown dataset. This work showcases the potential ofMultimodal LLMs (MLLMs) in complex navigation tasks, representing anadvancement towards practical applications of MLLMs in embodied AI. Projectpage: https://flame-sjtu.github.io</description><author>Yunzhe Xu, Yiyuan Pan, Zhe Liu, Hesheng Wang</author><pubDate>Tue, 20 Aug 2024 17:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11051v1</guid></item><item><title>MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding</title><link>http://arxiv.org/abs/2408.11049v1</link><description>Large Language Models (LLMs) have become more prevalent in long-contextapplications such as interactive chatbots, document analysis, and agentworkflows, but it is challenging to serve long-context requests with lowlatency and high throughput. Speculative decoding (SD) is a widely usedtechnique to reduce latency without sacrificing performance but theconventional wisdom suggests that its efficacy is limited to small batch sizes.In MagicDec, we show that surprisingly SD can achieve speedup even for a highthroughput inference regime for moderate to long sequences. More interestingly,an intelligent drafting strategy can achieve better speedup with increasingbatch size based on our rigorous analysis. MagicDec first identifies thebottleneck shifts with increasing batch size and sequence length, and usesthese insights to deploy speculative decoding more effectively for highthroughput inference. Then, it leverages draft models with sparse KV cache toaddress the KV bottleneck that scales with both sequence length and batch size.</description><author>Jian Chen, Vashisth Tiwari, Ranajoy Sadhukhan, Zhuoming Chen, Jinyuan Shi, Ian En-Hsu Yen, Beidi Chen</author><pubDate>Tue, 20 Aug 2024 17:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11049v1</guid></item><item><title>RP1M: A Large-Scale Motion Dataset for Piano Playing with Bi-Manual Dexterous Robot Hands</title><link>http://arxiv.org/abs/2408.11048v1</link><description>It has been a long-standing research goal to endow robot hands withhuman-level dexterity. Bi-manual robot piano playing constitutes a task thatcombines challenges from dynamic tasks, such as generating fast while precisemotions, with slower but contact-rich manipulation problems. Althoughreinforcement learning based approaches have shown promising results insingle-task performance, these methods struggle in a multi-song setting. Ourwork aims to close this gap and, thereby, enable imitation learning approachesfor robot piano playing at scale. To this end, we introduce the Robot Piano 1Million (RP1M) dataset, containing bi-manual robot piano playing motion data ofmore than one million trajectories. We formulate finger placements as anoptimal transport problem, thus, enabling automatic annotation of vast amountsof unlabeled songs. Benchmarking existing imitation learning approaches showsthat such approaches reach state-of-the-art robot piano playing performance byleveraging RP1M.</description><author>Yi Zhao, Le Chen, Jan Schneider, Quankai Gao, Juho Kannala, Bernhard Schölkopf, Joni Pajarinen, Dieter Büchler</author><pubDate>Tue, 20 Aug 2024 17:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11048v1</guid></item><item><title>LongVILA: Scaling Long-Context Visual Language Models for Long Videos</title><link>http://arxiv.org/abs/2408.10188v2</link><description>Long-context capability is critical for multi-modal foundation models. Weintroduce LongVILA, a full-stack solution for long-context vision-languagemodels, including system, model training, and dataset development. On thesystem side, we introduce the first long-context Multi-Modal SequenceParallelism (MM-SP) system that enables long training and inference, enabling2M context length training on 256 GPUs without any gradient checkpointing.MM-SP is 2.1x - 5.7x faster than ring sequence parallelism and 1.1x - 1.4xfaster than Megatron context parallelism + tensor parallelism in text-onlysettings. Moreover, it seamlessly integrates with Hugging Face Transformers.For model training, we propose a five-stage pipeline comprising alignment,pre-training, short supervised fine-tuning, context extension, and longsupervised fine-tuning. On datasets, we construct large-scale visual languagepre-training datasets and long video instruction-following datasets to supportour multi-stage training process. LongVILA extends the number of frames of VILAfrom 8 to 1024, and improves the long video captioning score from 2.00 to 3.26(1.6x), achieving 99.5% accuracy in 1400-frames video (274k context length)needle-in-a-haystack. LongVILA-8B demonstrates consistent accuracy improvementson long videos in the VideoMME benchmark as the number of frames increases.</description><author>Fuzhao Xue, Yukang Chen, Dacheng Li, Qinghao Hu, Ligeng Zhu, Xiuyu Li, Yunhao Fang, Haotian Tang, Shang Yang, Zhijian Liu, Ethan He, Hongxu Yin, Pavlo Molchanov, Jan Kautz, Linxi Fan, Yuke Zhu, Yao Lu, Song Han</author><pubDate>Tue, 20 Aug 2024 17:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10188v2</guid></item><item><title>Inside the Black Box: Detecting Data Leakage in Pre-trained Language Encoders</title><link>http://arxiv.org/abs/2408.11046v1</link><description>Despite being prevalent in the general field of Natural Language Processing(NLP), pre-trained language models inherently carry privacy and copyrightconcerns due to their nature of training on large-scale web-scraped data. Inthis paper, we pioneer a systematic exploration of such risks associated withpre-trained language encoders, specifically focusing on the membership leakageof pre-training data exposed through downstream models adapted from pre-trainedlanguage encoders-an aspect largely overlooked in existing literature. Ourstudy encompasses comprehensive experiments across four types of pre-trainedencoder architectures, three representative downstream tasks, and fivebenchmark datasets. Intriguingly, our evaluations reveal, for the first time,the existence of membership leakage even when only the black-box output of thedownstream model is exposed, highlighting a privacy risk far greater thanpreviously assumed. Alongside, we present in-depth analysis and insights towardguiding future researchers and practitioners in addressing the privacyconsiderations in developing pre-trained language models.</description><author>Yuan Xin, Zheng Li, Ning Yu, Dingfan Chen, Mario Fritz, Michael Backes, Yang Zhang</author><pubDate>Tue, 20 Aug 2024 17:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11046v1</guid></item><item><title>What is in Your Safe Data? Identifying Benign Data that Breaks Safety</title><link>http://arxiv.org/abs/2404.01099v2</link><description>Current Large Language Models (LLMs), even those tuned for safety andalignment, are susceptible to jailbreaking. Some have found that just furtherfine-tuning an aligned model with benign data (i.e., data without harmfulcontent) surprisingly leads to substantial degradation in safety. We delve intothe data-centric aspects of why benign fine-tuning inadvertently contributes tojailbreaking. First, we represent fine-tuning data through two lenses:representation and gradient spaces. Additionally, we propose a bi-directionalanchoring method that, during the selection process, prioritizes data pointsthat are close to harmful examples and far from benign ones. Our approacheffectively identifies subsets of benign data that are more likely to degradethe model's safety after fine-tuning. Training on just 100 of these seeminglybenign datapoints surprisingly leads to the fine-tuned model affirmativelyresponding to &gt;70% of tested harmful requests, compared to &lt;20% afterfine-tuning on randomly selected data. We also observe that the selected datafrequently appear as lists, bullet points, or math questions, indicating asystematic pattern in fine-tuning data that contributes to jailbreaking.</description><author>Luxi He, Mengzhou Xia, Peter Henderson</author><pubDate>Tue, 20 Aug 2024 17:54:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01099v2</guid></item><item><title>Unified Domain Adaptive Semantic Segmentation</title><link>http://arxiv.org/abs/2311.13254v2</link><description>Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS) aims to transferthe supervision from a labeled source domain to an unlabeled target domain. Themajority of existing UDA-SS works typically consider images whilst recentattempts have extended further to tackle videos by modeling the temporaldimension. Although the two lines of research share the major challenges --overcoming the underlying domain distribution shift, their studies are largelyindependent, resulting in fragmented insights, a lack of holisticunderstanding, and missed opportunities for cross-pollination of ideas. Thisfragmentation prevents the unification of methods, leading to redundant effortsand suboptimal knowledge transfer across image and video domains. Under thisobservation, we advocate unifying the study of UDA-SS across video and imagescenarios, enabling a more comprehensive understanding, synergisticadvancements, and efficient knowledge sharing. To that end, we explore theunified UDA-SS from a general data augmentation perspective, serving as aunifying conceptual framework, enabling improved generalization, and potentialfor cross-pollination of ideas, ultimately contributing to the overall progressand practical impact of this field of research. Specifically, we propose aQuad-directional Mixup (QuadMix) method, characterized by tackling distinctpoint attributes and feature inconsistencies through four-directional paths forintra- and inter-domain mixing in a feature space. To deal with temporal shiftswith videos, we incorporate optical flow-guided feature aggregation acrossspatial and temporal dimensions for fine-grained domain alignment. Extensiveexperiments show that our method outperforms the state-of-the-art works bylarge margins on four challenging UDA-SS benchmarks. Our source code and modelswill be released at \url{https://github.com/ZHE-SAPI/UDASS}.</description><author>Zhe Zhang, Gaochang Wu, Jing Zhang, Xiatian Zhu, Dacheng Tao, Tianyou Chai</author><pubDate>Tue, 20 Aug 2024 17:53:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13254v2</guid></item><item><title>Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research</title><link>http://arxiv.org/abs/2408.11043v1</link><description>Qualitative data collection and analysis approaches, such as those employinginterviews and focus groups, provide rich insights into customer attitudes,sentiment, and behavior. However, manually analyzing qualitative data requiresextensive time and effort to identify relevant topics and thematic insights.This study proposes a novel approach to address this challenge by leveragingRetrieval Augmented Generation (RAG) based Large Language Models (LLMs) foranalyzing interview transcripts. The novelty of this work lies in strategizingthe research inquiry as one that is augmented by an LLM that serves as a noviceresearch assistant. This research explores the mental model of LLMs to serve asnovice qualitative research assistants for researchers in the talent managementspace. A RAG-based LLM approach is extended to enable topic modeling ofsemi-structured interview data, showcasing the versatility of these modelsbeyond their traditional use in information retrieval and search. Our findingsdemonstrate that the LLM-augmented RAG approach can successfully extract topicsof interest, with significant coverage compared to manually generated topicsfrom the same dataset. This establishes the viability of employing LLMs asnovice qualitative research assistants. Additionally, the study recommends thatresearchers leveraging such models lean heavily on quality criteria used intraditional qualitative research to ensure rigor and trustworthiness of theirapproach. Finally, the paper presents key recommendations for industrypractitioners seeking to reconcile the use of LLMs with established qualitativeresearch paradigms, providing a roadmap for the effective integration of thesepowerful, albeit novice, AI tools in the analysis of qualitative datasetswithin talent</description><author>Sreyoshi Bhaduri, Satya Kapoor, Alex Gil, Anshul Mittal, Rutu Mulkar</author><pubDate>Tue, 20 Aug 2024 17:49:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11043v1</guid></item><item><title>GraphFSA: A Finite State Automaton Framework for Algorithmic Learning on Graphs</title><link>http://arxiv.org/abs/2408.11042v1</link><description>Many graph algorithms can be viewed as sets of rules that are iterativelyapplied, with the number of iterations dependent on the size and complexity ofthe input graph. Existing machine learning architectures often struggle torepresent these algorithmic decisions as discrete state transitions. Therefore,we propose a novel framework: GraphFSA (Graph Finite State Automaton). GraphFSAis designed to learn a finite state automaton that runs on each node of a givengraph. We test GraphFSA on cellular automata problems, showcasing its abilitiesin a straightforward algorithmic setting. For a comprehensive empiricalevaluation of our framework, we create a diverse range of synthetic problems.As our main application, we then focus on learning more elaborate graphalgorithms. Our findings suggest that GraphFSA exhibits strong generalizationand extrapolation abilities, presenting an alternative approach to representthese algorithms.</description><author>Florian Grötschla, Joël Mathys, Christoffer Raun, Roger Wattenhofer</author><pubDate>Tue, 20 Aug 2024 17:49:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11042v1</guid></item><item><title>Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model</title><link>http://arxiv.org/abs/2408.11039v1</link><description>We introduce Transfusion, a recipe for training a multi-modal model overdiscrete and continuous data. Transfusion combines the language modeling lossfunction (next token prediction) with diffusion to train a single transformerover mixed-modality sequences. We pretrain multiple Transfusion models up to 7Bparameters from scratch on a mixture of text and image data, establishingscaling laws with respect to a variety of uni- and cross-modal benchmarks. Ourexperiments show that Transfusion scales significantly better than quantizingimages and training a language model over discrete image tokens. By introducingmodality-specific encoding and decoding layers, we can further improve theperformance of Transfusion models, and even compress each image to just 16patches. We further demonstrate that scaling our Transfusion recipe to 7Bparameters and 2T multi-modal tokens produces a model that can generate imagesand text on a par with similar scale diffusion models and language models,reaping the benefits of both worlds.</description><author>Chunting Zhou, Lili Yu, Arun Babu, Kushal Tirumala, Michihiro Yasunaga, Leonid Shamis, Jacob Kahn, Xuezhe Ma, Luke Zettlemoyer, Omer Levy</author><pubDate>Tue, 20 Aug 2024 17:48:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11039v1</guid></item><item><title>Atmospheric Transport Modeling of CO$_2$ with Neural Networks</title><link>http://arxiv.org/abs/2408.11032v1</link><description>Accurately describing the distribution of CO$_2$ in the atmosphere withatmospheric tracer transport models is essential for greenhouse gas monitoringand verification support systems to aid implementation of international climateagreements. Large deep neural networks are poised to revolutionize weatherprediction, which requires 3D modeling of the atmosphere. While similar in thisregard, atmospheric transport modeling is subject to new challenges. Both,stable predictions for longer time horizons and mass conservation throughoutneed to be achieved, while IO plays a larger role compared to computationalcosts. In this study we explore four different deep neural networks (UNet,GraphCast, Spherical Fourier Neural Operator and SwinTransformer) which haveproven as state-of-the-art in weather prediction to assess their usefulness foratmospheric tracer transport modeling. For this, we assemble the CarbonBenchdataset, a systematic benchmark tailored for machine learning emulators ofEulerian atmospheric transport. Through architectural adjustments, we decouplethe performance of our emulators from the distribution shift caused by a steadyrise in atmospheric CO$_2$. More specifically, we center CO$_2$ input fields tozero mean and then use an explicit flux scheme and a mass fixer to assure massbalance. This design enables stable and mass conserving transport for over 6months with all four neural network architectures. In our study, theSwinTransformer displays particularly strong emulation skill (90-day $R^2 &gt;0.99$), with physically plausible emulation even for forward runs of multipleyears. This work paves the way forward towards high resolution forward andinverse modeling of inert trace gases with neural networks.</description><author>Vitus Benson, Ana Bastos, Christian Reimers, Alexander J. Winkler, Fanny Yang, Markus Reichstein</author><pubDate>Tue, 20 Aug 2024 17:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11032v1</guid></item><item><title>OpenScan: A Benchmark for Generalized Open-Vocabulary 3D Scene Understanding</title><link>http://arxiv.org/abs/2408.11030v1</link><description>Open-vocabulary 3D scene understanding (OV-3D) aims to localize and classifynovel objects beyond the closed object classes. However, existing approachesand benchmarks primarily focus on the open vocabulary problem within thecontext of object classes, which is insufficient to provide a holisticevaluation to what extent a model understands the 3D scene. In this paper, weintroduce a more challenging task called Generalized Open-Vocabulary 3D SceneUnderstanding (GOV-3D) to explore the open vocabulary problem beyond objectclasses. It encompasses an open and diverse set of generalized knowledge,expressed as linguistic queries of fine-grained and object-specific attributes.To this end, we contribute a new benchmark named OpenScan, which consists of 3Dobject attributes across eight representative linguistic aspects, includingaffordance, property, material, and more. We further evaluate state-of-the-artOV-3D methods on our OpenScan benchmark, and discover that these methodsstruggle to comprehend the abstract vocabularies of the GOV-3D task, achallenge that cannot be addressed by simply scaling up object classes duringtraining. We highlight the limitations of existing methodologies and explore apromising direction to overcome the identified shortcomings. Data and code areavailable at https://github.com/YoujunZhao/OpenScan</description><author>Youjun Zhao, Jiaying Lin, Shuquan Ye, Qianshi Pang, Rynson W. H. Lau</author><pubDate>Tue, 20 Aug 2024 17:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11030v1</guid></item><item><title>Scaling Law with Learning Rate Annealing</title><link>http://arxiv.org/abs/2408.11029v1</link><description>We find that the cross-entropy loss curves of neural language modelsempirically adhere to a scaling law with learning rate (LR) annealing overtraining steps ($s$): $$L(s) = L_0 + A\cdot S_1^{-\alpha} - C\cdot S_2$$ Where$S_1$ is forward area and $S_2$ is learning rate annealing area. Thisformulation takes into account two factors: (1) The forward scaling defined astypical scaling law, and (2) the additional loss drop brought by LR annealing.Therefore, this formulation can describe the full loss curve at each step,rather than the single loss point at the end of training. Applying the scalinglaw with LR annealing and fitting only one or two training curves, we canaccurately predict the loss of language model training at any given step andacross any learning rate scheduler (LRS). Furthermore, this equation accuratelydescribes the dynamics during training process, and provides a theoreticalverification and explanation for numerous experimental findings of previousstudies, particularly those focusing on LR schedule and LR annealing. Theresulting insights, also serve as a guide for researchers to select criticalLRS in advance by prediction using our equation. Most significantly, since allthe points in a full training curve follow the equation, we can achieveaccurate loss prediction at any given step across any learning rate scheduler,while expending less than 1\% of the computational cost required by thechinchilla scaling law to fit language modeling loss. This approach extremelydemocratizes scaling law fitting and predicting in developing large languagemodels.</description><author>Howe Tissue, Venus Wang, Lu Wang</author><pubDate>Tue, 20 Aug 2024 17:30:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11029v1</guid></item><item><title>Fake News in Sheep's Clothing: Robust Fake News Detection Against LLM-Empowered Style Attacks</title><link>http://arxiv.org/abs/2310.10830v2</link><description>It is commonly perceived that fake news and real news exhibit distinctwriting styles, such as the use of sensationalist versus objective language.However, we emphasize that style-related features can also be exploited forstyle-based attacks. Notably, the advent of powerful Large Language Models(LLMs) has empowered malicious actors to mimic the style of trustworthy newssources, doing so swiftly, cost-effectively, and at scale. Our analysis revealsthat LLM-camouflaged fake news content significantly undermines theeffectiveness of state-of-the-art text-based detectors (up to 38% decrease inF1 Score), implying a severe vulnerability to stylistic variations. To addressthis, we introduce SheepDog, a style-robust fake news detector that prioritizescontent over style in determining news veracity. SheepDog achieves thisresilience through (1) LLM-empowered news reframings that inject stylediversity into the training process by customizing articles to match differentstyles; (2) a style-agnostic training scheme that ensures consistent veracitypredictions across style-diverse reframings; and (3) content-focused veracityattributions that distill content-centric guidelines from LLMs for debunkingfake news, offering supplementary cues and potential intepretability thatassist veracity prediction. Extensive experiments on three real-worldbenchmarks demonstrate SheepDog's style robustness and adaptability to variousbackbones.</description><author>Jiaying Wu, Jiafeng Guo, Bryan Hooi</author><pubDate>Tue, 20 Aug 2024 17:28:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10830v2</guid></item><item><title>Learning Realistic Joint Space Boundaries for Range of Motion Analysis of Healthy and Impaired Human Arms</title><link>http://arxiv.org/abs/2311.10653v2</link><description>A realistic human kinematic model that satisfies anatomical constraints isessential for human-robot interaction, biomechanics and robot-assistedrehabilitation. Modeling realistic joint constraints, however, is challengingas human arm motion is constrained by joint limits, inter- and intra-jointdependencies, self-collisions, individual capabilities and muscular orneurological constraints which are difficult to represent. Hence, physiciansand researchers have relied on simple box-constraints, ignoring importantanatomical factors. In this paper, we propose a data-driven method to learnrealistic anatomically constrained upper-limb range of motion (RoM) boundariesfrom motion capture data. This is achieved by fitting a one-class supportvector machine to a dataset of upper-limb joint space exploration motions withan efficient hyper-parameter tuning scheme. Our approach outperforms similarworks focused on valid RoM learning. Further, we propose an impairment index(II) metric that offers a quantitative assessment of capability/impairment whencomparing healthy and impaired arms. We validate the metric on healthy subjectsphysically constrained to emulate hemiplegia and different disability levels asstroke patients.</description><author>Shafagh Keyvanian, Michelle J. Johnson, Nadia Figueroa</author><pubDate>Tue, 20 Aug 2024 17:21:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10653v2</guid></item><item><title>Athena: Safe Autonomous Agents with Verbal Contrastive Learning</title><link>http://arxiv.org/abs/2408.11021v1</link><description>Due to emergent capabilities, large language models (LLMs) have been utilizedas language-based agents to perform a variety of tasks and make decisions withan increasing degree of autonomy. These autonomous agents can understandhigh-level instructions, interact with their environments, and execute complextasks using a selection of tools available to them. As the capabilities of theagents expand, ensuring their safety and trustworthiness becomes moreimperative. In this study, we introduce the Athena framework which leveragesthe concept of verbal contrastive learning where past safe and unsafetrajectories are used as in-context (contrastive) examples to guide the agenttowards safety while fulfilling a given task. The framework also incorporates acritiquing mechanism to guide the agent to prevent risky actions at every step.Furthermore, due to the lack of existing benchmarks on the safety reasoningability of LLM-based agents, we curate a set of 80 toolkits across 8 categorieswith 180 scenarios to provide a safety evaluation benchmark. Our experimentalevaluation, with both closed- and open-source LLMs, indicates verbalcontrastive learning and interaction-level critiquing improve the safety ratesignificantly.</description><author>Tanmana Sadhu, Ali Pesaranghader, Yanan Chen, Dong Hoon Yi</author><pubDate>Tue, 20 Aug 2024 17:21:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11021v1</guid></item><item><title>An Overlooked Role of Context-Sensitive Dendrites</title><link>http://arxiv.org/abs/2408.11019v1</link><description>To date, most dendritic studies have predominantly focused on the apical zoneof pyramidal two-point neurons (TPNs) receiving only feedback (FB) connectionsfrom higher perceptual layers and using them for learning. Recent cellularneurophysiology and computational neuroscience studies suggests that the apicalinput (context), coming from feedback and lateral connections, is multifacetedand far more diverse, with greater implications for ongoing learning andprocessing in the brain than previously realized. In addition to the FB, theapical tuft receives signals from neighboring cells of the same network asproximal (P) context, other parts of the brain as distal (D) context, andoverall coherent information across the network as universal (U) context. Theintegrated context (C) amplifies and suppresses the transmission of coherentand conflicting feedforward (FF) signals, respectively. Specifically, we showthat complex context-sensitive (CS)-TPNs flexibly integrate C moment-by-momentwith the FF somatic current at the soma such that the somatic current isamplified when both feedforward (FF) and C are coherent; otherwise, it isattenuated. This generates the event only when the FF and C currents arecoherent, which is then translated into a singlet or a burst based on the FBinformation. Spiking simulation results show that this flexible integration ofsomatic and contextual currents enables the propagation of more coherentsignals (bursts), making learning faster with fewer neurons. Similar behavioris observed when this functioning is used in conventional artificial networks,where orders of magnitude fewer neurons are required to process vast amounts ofheterogeneous real-world audio-visual (AV) data trained using backpropagation(BP). The computational findings presented here demonstrate the universality ofCS-TPNs, suggesting a dendritic narrative that was previously overlooked.</description><author>Mohsin Raza, Ahsan Adeel</author><pubDate>Tue, 20 Aug 2024 17:18:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11019v1</guid></item><item><title>Multiwinner Temporal Voting with Aversion to Change</title><link>http://arxiv.org/abs/2408.11017v1</link><description>We study two-stage committee elections where voters have dynamic preferencesover candidates; at each stage, a committee is chosen under a given votingrule. We are interested in identifying a winning committee for the second stagethat overlaps as much as possible with the first-stage committee. We show afull complexity dichotomy for the class of Thiele rules: this problem istractable for Approval Voting (AV) and hard for all other Thiele rules(including, in particular, Proportional Approval Voting and theChamberlin-Courant rule). We extend this dichotomy to the greedy variants ofThiele rules. We also explore this problem from a parameterized complexityperspective for several natural parameters. We complement the theory withexperimental analysis: e.g., we investigate the average number of changes inthe committee as a function of changes in voters' preferences and the role ofties.</description><author>Valentin Zech, Niclas Boehmer, Edith Elkind, Nicholas Teh</author><pubDate>Tue, 20 Aug 2024 17:16:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11017v1</guid></item><item><title>Causal Reasoning and Large Language Models: Opening a New Frontier for Causality</title><link>http://arxiv.org/abs/2305.00050v3</link><description>The causal capabilities of large language models (LLMs) are a matter ofsignificant debate, with critical implications for the use of LLMs insocietally impactful domains such as medicine, science, law, and policy. Weconduct a "behavorial" study of LLMs to benchmark their capability ingenerating causal arguments. Across a wide range of tasks, we find that LLMscan generate text corresponding to correct causal arguments with highprobability, surpassing the best-performing existing methods. Algorithms basedon GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discoverytask (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain)and event causality (86% accuracy in determining necessary and sufficientcauses in vignettes). We perform robustness checks across tasks and show thatthe capabilities cannot be explained by dataset memorization alone, especiallysince LLMs generalize to novel datasets that were created after the trainingcutoff date. That said, LLMs exhibit unpredictable failure modes, and we discuss the kindsof errors that may be improved and what are the fundamental limits of LLM-basedanswers. Overall, by operating on the text metadata, LLMs bring capabilities sofar understood to be restricted to humans, such as using collected knowledge togenerate causal graphs or identifying background causal context from naturallanguage. As a result, LLMs may be used by human domain experts to save effortin setting up a causal analysis, one of the biggest impediments to thewidespread adoption of causal methods. Given that LLMs ignore the actual data,our results also point to a fruitful research direction of developingalgorithms that combine LLMs with existing causal techniques. Code and datasetsare available at https://github.com/py-why/pywhy-llm.</description><author>Emre Kıcıman, Robert Ness, Amit Sharma, Chenhao Tan</author><pubDate>Tue, 20 Aug 2024 17:16:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00050v3</guid></item><item><title>Disparate Impact on Group Accuracy of Linearization for Private Inference</title><link>http://arxiv.org/abs/2402.03629v3</link><description>Ensuring privacy-preserving inference on cryptographically secure data is awell-known computational challenge. To alleviate the bottleneck of costlycryptographic computations in non-linear activations, recent methods havesuggested linearizing a targeted portion of these activations in neuralnetworks. This technique results in significantly reduced runtimes with oftennegligible impacts on accuracy. In this paper, we demonstrate that suchcomputational benefits may lead to increased fairness costs. Specifically, wefind that reducing the number of ReLU activations disproportionately decreasesthe accuracy for minority groups compared to majority groups. To explain theseobservations, we provide a mathematical interpretation under restrictedassumptions about the nature of the decision boundary, while also showing theprevalence of this problem across widely used datasets and architectures.Finally, we show how a simple procedure altering the fine-tuning step forlinearized models can serve as an effective mitigation strategy.</description><author>Saswat Das, Marco Romanelli, Ferdinando Fioretto</author><pubDate>Tue, 20 Aug 2024 17:08:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03629v3</guid></item><item><title>Does GPT Really Get It? A Hierarchical Scale to Quantify Human vs AI's Understanding of Algorithms</title><link>http://arxiv.org/abs/2406.14722v2</link><description>As Large Language Models (LLMs) perform (and sometimes excel at) more andmore complex cognitive tasks, a natural question is whether AI reallyunderstands. The study of understanding in LLMs is in its infancy, and thecommunity has yet to incorporate well-trodden research in philosophy,psychology, and education. We initiate this, specifically focusing onunderstanding algorithms, and propose a hierarchy of levels of understanding.We use the hierarchy to design and conduct a study with human subjects(undergraduate and graduate students) as well as large language models(generations of GPT), revealing interesting similarities and differences. Weexpect that our rigorous criteria will be useful to keep track of AI's progressin such cognitive domains.</description><author>Mirabel Reid, Santosh S. Vempala</author><pubDate>Tue, 20 Aug 2024 17:08:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14722v2</guid></item><item><title>Self-supervised Photographic Image Layout Representation Learning</title><link>http://arxiv.org/abs/2403.03740v2</link><description>In the domain of image layout representation learning, the critical processof translating image layouts into succinct vector forms is increasinglysignificant across diverse applications, such as image retrieval, manipulation,and generation. Most approaches in this area heavily rely on costly labeleddatasets and notably lack in adapting their modeling and learning methods tothe specific nuances of photographic image layouts. This shortfall makes thelearning process for photographic image layouts suboptimal. In our research, wedirectly address these challenges. We innovate by defining basic layoutprimitives that encapsulate various levels of layout information and by mappingthese, along with their interconnections, onto a heterogeneous graph structure.This graph is meticulously engineered to capture the intricate layoutinformation within the pixel domain explicitly. Advancing further, we introducenovel pretext tasks coupled with customized loss functions, strategicallydesigned for effective self-supervised learning of these layout graphs.Building on this foundation, we develop an autoencoder-based networkarchitecture skilled in compressing these heterogeneous layout graphs intoprecise, dimensionally-reduced layout representations. Additionally, weintroduce the LODB dataset, which features a broader range of layout categoriesand richer semantics, serving as a comprehensive benchmark for evaluating theeffectiveness of layout representation learning methods. Our extensiveexperimentation on this dataset demonstrates the superior performance of ourapproach in the realm of photographic image layout representation learning.</description><author>Zhaoran Zhao, Peng Lu, Xujun Peng, Wenhao Guo</author><pubDate>Tue, 20 Aug 2024 17:05:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03740v2</guid></item><item><title>While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?</title><link>http://arxiv.org/abs/2408.11006v1</link><description>The rapid development of large language models (LLMs) has significantlyadvanced code completion capabilities, giving rise to a new generation ofLLM-based Code Completion Tools (LCCTs). Unlike general-purpose LLMs, thesetools possess unique workflows, integrating multiple information sources asinput and prioritizing code suggestions over natural language interaction,which introduces distinct security challenges. Additionally, LCCTs often relyon proprietary code datasets for training, raising concerns about the potentialexposure of sensitive data. This paper exploits these distinct characteristicsof LCCTs to develop targeted attack methodologies on two critical securityrisks: jailbreaking and training data extraction attacks. Our experimentalresults expose significant vulnerabilities within LCCTs, including a 99.4%success rate in jailbreaking attacks on GitHub Copilot and a 46.3% success rateon Amazon Q. Furthermore, We successfully extracted sensitive user data fromGitHub Copilot, including 54 real email addresses and 314 physical addressesassociated with GitHub usernames. Our study also demonstrates that thesecode-based attack methods are effective against general-purpose LLMs, such asthe GPT series, highlighting a broader security misalignment in the handling ofcode by modern LLMs. These findings underscore critical security challengesassociated with LCCTs and suggest essential directions for strengthening theirsecurity frameworks. The example code and attack samples from our research areprovided at https://github.com/Sensente/Security-Attacks-on-LCCTs.</description><author>Wen Cheng, Ke Sun, Xinyu Zhang, Wei Wang</author><pubDate>Tue, 20 Aug 2024 17:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11006v1</guid></item><item><title>MegaFusion: Extend Diffusion Models towards Higher-resolution Image Generation without Further Tuning</title><link>http://arxiv.org/abs/2408.11001v1</link><description>Diffusion models have emerged as frontrunners in text-to-image generation fortheir impressive capabilities. Nonetheless, their fixed image resolution duringtraining often leads to challenges in high-resolution image generation, such assemantic inaccuracies and object replication. This paper introduces MegaFusion,a novel approach that extends existing diffusion-based text-to-image generationmodels towards efficient higher-resolution generation without additionalfine-tuning or extra adaptation. Specifically, we employ an innovative truncateand relay strategy to bridge the denoising processes across differentresolutions, allowing for high-resolution image generation in a coarse-to-finemanner. Moreover, by integrating dilated convolutions and noise re-scheduling,we further adapt the model's priors for higher resolution. The versatility andefficacy of MegaFusion make it universally applicable to both latent-space andpixel-space diffusion models, along with other derivative models. Extensiveexperiments confirm that MegaFusion significantly boosts the capability ofexisting models to produce images of megapixels and various aspect ratios,while only requiring about 40% of the original computational cost.</description><author>Haoning Wu, Shaocheng Shen, Qiang Hu, Xiaoyun Zhang, Ya Zhang, Yanfeng Wang</author><pubDate>Tue, 20 Aug 2024 16:53:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11001v1</guid></item><item><title>SenPa-MAE: Sensor Parameter Aware Masked Autoencoder for Multi-Satellite Self-Supervised Pretraining</title><link>http://arxiv.org/abs/2408.11000v1</link><description>This paper introduces SenPa-MAE, a transformer architecture that encodes thesensor parameters of an observed multispectral signal into the imageembeddings. SenPa-MAE can be pre-trained on imagery of different satelliteswith non-matching spectral or geometrical sensor characteristics. Toincorporate sensor parameters, we propose a versatile sensor parameter encodingmodule as well as a data augmentation strategy for the diversification of thepre-training dataset. This enables the model to effectively differentiatebetween various sensors and gain an understanding of sensor parameters and thecorrelation to the observed signal. Given the rising number of Earthobservation satellite missions and the diversity in their sensorspecifications, our approach paves the way towards a sensor-independent Earthobservation foundation model. This opens up possibilities such as cross-sensortraining and sensor-independent inference.</description><author>Jonathan Prexl, Michael Schmitt</author><pubDate>Tue, 20 Aug 2024 16:53:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11000v1</guid></item><item><title>Representation Matters for Mastering Chess: Improved Feature Representation in AlphaZero Outperforms Switching to Transformers</title><link>http://arxiv.org/abs/2304.14918v2</link><description>While transformers have gained recognition as a versatile tool for artificialintelligence (AI), an unexplored challenge arises in the context of chess - aclassical AI benchmark. Here, incorporating Vision Transformers (ViTs) intoAlphaZero is insufficient for chess mastery, mainly due to ViTs' computationallimitations. The attempt to optimize their efficiency by combining MobileNetand NextViT outperformed AlphaZero by about 30 Elo. However, we propose apractical improvement that involves a simple change in the input representationand value loss functions. As a result, we achieve a significant performanceboost of up to 180 Elo points beyond what is currently achievable withAlphaZero in chess. In addition to these improvements, our experimental resultsusing the Integrated Gradient technique confirm the effectiveness of the newlyintroduced features.</description><author>Johannes Czech, Jannis Blüml, Kristian Kersting, Hedinn Steingrimsson</author><pubDate>Tue, 20 Aug 2024 16:49:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14918v2</guid></item><item><title>Audio Match Cutting: Finding and Creating Matching Audio Transitions in Movies and Videos</title><link>http://arxiv.org/abs/2408.10998v1</link><description>A "match cut" is a common video editing technique where a pair of shots thathave a similar composition transition fluidly from one to another. Althoughmatch cuts are often visual, certain match cuts involve the fluid transition ofaudio, where sounds from different sources merge into one indistinguishabletransition between two shots. In this paper, we explore the ability toautomatically find and create "audio match cuts" within videos and movies. Wecreate a self-supervised audio representation for audio match cutting anddevelop a coarse-to-fine audio match pipeline that recommends matching shotsand creates the blended audio. We further annotate a dataset for the proposedaudio match cut task and compare the ability of multiple audio representationsto find audio match cut candidates. Finally, we evaluate multiple methods toblend two matching audio candidates with the goal of creating a smoothtransition. Project page and examples are available at:https://denfed.github.io/audiomatchcut/</description><author>Dennis Fedorishin, Lie Lu, Srirangaraj Setlur, Venu Govindaraju</author><pubDate>Tue, 20 Aug 2024 16:46:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10998v1</guid></item><item><title>Two-Timescale Optimization Framework for Decentralized Linear-Quadratic Optimal Control</title><link>http://arxiv.org/abs/2406.11168v2</link><description>This study investigates a decentralized linear-quadratic optimal controlproblem, and several approximate separable constrained optimization problemsare formulated for the first time based on the selection of sparsity promotingfunctions. First, for the optimization problem with weighted $\ell_1$ sparsitypromoting function, a two-timescale algorithm is adopted that is based on theBSUM (Block Successive Upper-bound Minimization) framework and a differentialequation solver. Second, a piecewise quadratic sparsity promoting function isintroduced, and the induced optimization problem demonstrates an acceleratedconvergence rate by performing the same two-timescale algorithm. Finally, theoptimization problem with $\ell_0$ sparsity promoting function is consideredthat is nonconvex and discontinuous, and can be approximated by successivecoordinatewise convex optimization problems.</description><author>Lechen Feng, Yuan-Hua Ni, Xuebo Zhang</author><pubDate>Tue, 20 Aug 2024 16:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11168v2</guid></item><item><title>Disentangling segmental and prosodic factors to non-native speech comprehensibility</title><link>http://arxiv.org/abs/2408.10997v1</link><description>Current accent conversion (AC) systems do not disentangle the two mainsources of non-native accent: segmental and prosodic characteristics. Beingable to manipulate a non-native speaker's segmental and/or prosodic channelsindependently is critical to quantify how these two channels contribute tospeech comprehensibility and social attitudes. We present an AC system that notonly decouples voice quality from accent, but also disentangles the latter intoits segmental and prosodic characteristics. The system is able to generateaccent conversions that combine (1) the segmental characteristics from a sourceutterance, (2) the voice characteristics from a target utterance, and (3) theprosody of a reference utterance. We show that vector quantization of acousticembeddings and removal of consecutive duplicated codewords allows the system totransfer prosody and improve voice similarity. We conduct perceptual listeningtests to quantify the individual contributions of segmental features andprosody on the perceived comprehensibility of non-native speech. Our resultsindicate that, contrary to prior research in non-native speech, segmentalfeatures have a larger impact on comprehensibility than prosody. The proposedAC system may also be used to study how segmental and prosody cues affectsocial attitudes towards non-native speech.</description><author>Waris Quamer, Ricardo Gutierrez-Osuna</author><pubDate>Tue, 20 Aug 2024 16:43:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10997v1</guid></item><item><title>Approximation Rates for Shallow ReLU$^k$ Neural Networks on Sobolev Spaces via the Radon Transform</title><link>http://arxiv.org/abs/2408.10996v1</link><description>Let $\Omega\subset \mathbb{R}^d$ be a bounded domain. We consider the problemof how efficiently shallow neural networks with the ReLU$^k$ activationfunction can approximate functions from Sobolev spaces $W^s(L_p(\Omega))$ witherror measured in the $L_q(\Omega)$-norm. Utilizing the Radon transform andrecent results from discrepancy theory, we provide a simple proof of nearlyoptimal approximation rates in a variety of cases, including when $q\leq p$,$p\geq 2$, and $s \leq k + (d+1)/2$. The rates we derive are optimal up tologarithmic factors, and significantly generalize existing results. Aninteresting consequence is that the adaptivity of shallow ReLU$^k$ neuralnetworks enables them to obtain optimal approximation rates for smoothness upto order $s = k + (d+1)/2$, even though they represent piecewise polynomials offixed degree $k$.</description><author>Tong Mao, Jonathan W. Siegel, Jinchao Xu</author><pubDate>Tue, 20 Aug 2024 16:43:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10996v1</guid></item><item><title>CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models</title><link>http://arxiv.org/abs/2408.10995v1</link><description>New medical treatment development requires multiple phases of clinicaltrials. Despite the significant human and financial costs of bringing a drug tomarket, less than 20% of drugs in testing will make it from the first phase tofinal approval. Recent literature indicates that the design of the trialprotocols significantly contributes to trial performance. We investigatedClinical Trial Outcome Prediction (CTOP) using trial design documents topredict phase transitions automatically. We propose CTP-LLM, the first LargeLanguage Model (LLM) based model for CTOP. We also introduce thePhaseTransition (PT) Dataset; which labels trials based on their progressionthrough the regulatory process and serves as a benchmark for CTOP evaluation.Our fine-tuned GPT-3.5-based model (CTP-LLM) predicts clinical trial phasetransition by analyzing the trial's original protocol texts without requiringhuman-selected features. CTP-LLM achieves a 67% accuracy rate in predictingtrial phase transitions across all phases and a 75% accuracy rate specificallyin predicting the transition from Phase~III to final approval. Our experimentalperformance highlights the potential of LLM-powered applications in forecastingclinical trial outcomes and assessing trial design.</description><author>Michael Reinisch, Jianfeng He, Chenxi Liao, Sauleh Ahmad Siddiqui, Bei Xiao</author><pubDate>Tue, 20 Aug 2024 16:43:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10995v1</guid></item><item><title>Facial Demorphing via Identity Preserving Image Decomposition</title><link>http://arxiv.org/abs/2408.10993v1</link><description>A face morph is created by combining the face images usually pertaining totwo distinct identities. The goal is to generate an image that can be matchedwith two identities thereby undermining the security of a face recognitionsystem. To deal with this problem, several morph attack detection techniqueshave been developed. But these methods do not extract any information about theunderlying bonafides used to create them. Demorphing addresses this limitation.However, current demorphing techniques are mostly reference-based, i.e, theyneed an image of one of the identities to recover the other. In this work, wetreat demorphing as an ill-posed decomposition problem. We propose a novelmethod that is reference-free and recovers the bonafides with high accuracy.Our method decomposes the morph into several identity-preserving featurecomponents. A merger network then weighs and combines these components torecover the bonafides. Our method is observed to reconstruct high-qualitybonafides in terms of definition and fidelity. Experiments on theCASIA-WebFace, SMDD and AMSL datasets demonstrate the effectiveness of ourmethod.</description><author>Nitish Shukla, Arun Ross</author><pubDate>Tue, 20 Aug 2024 16:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10993v1</guid></item><item><title>Efficient and Robust Quantization-aware Training via Adaptive Coreset Selection</title><link>http://arxiv.org/abs/2306.07215v3</link><description>Quantization-aware training (QAT) is a representative model compressionmethod to reduce redundancy in weights and activations. However, most existingQAT methods require end-to-end training on the entire dataset, which suffersfrom long training time and high energy costs. In addition, the potential labelnoise in the training data undermines the robustness of QAT. We propose twometrics based on analysis of loss and gradient of quantized weights: errorvector score and disagreement score, to quantify the importance of each sampleduring training. Guided by these two metrics, we proposed a quantization-awareAdaptive Coreset Selection (ACS) method to select the data for the currenttraining epoch. We evaluate our method on various networks (ResNet-18,MobileNetV2, RetinaNet), datasets(CIFAR-10, CIFAR-100, ImageNet-1K, COCO), andunder different quantization settings. Specifically, our method can achieve anaccuracy of 68.39\% of 4-bit quantized ResNet-18 on the ImageNet-1K datasetwith only a 10\% subset, which has an absolute gain of 4.24\% compared to thebaseline. Our method can also improve the robustness of QAT by removing noisysamples in the training set.</description><author>Xijie Huang, Zechun Liu, Shih-Yang Liu, Kwang-Ting Cheng</author><pubDate>Tue, 20 Aug 2024 16:37:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07215v3</guid></item><item><title>Denoising Plane Wave Ultrasound Images Using Diffusion Probabilistic Models</title><link>http://arxiv.org/abs/2408.10987v1</link><description>Ultrasound plane wave imaging is a cutting-edge technique that enables highframe-rate imaging. However, one challenge associated with high frame-rateultrasound imaging is the high noise associated with them, hindering theirwider adoption. Therefore, the development of a denoising method becomesimperative to augment the quality of plane wave images. Drawing inspirationfrom Denoising Diffusion Probabilistic Models (DDPMs), our proposed solutionaims to enhance plane wave image quality. Specifically, the method considersthe distinction between low-angle and high-angle compounding plane waves asnoise and effectively eliminates it by adapting a DDPM to beamformedradiofrequency (RF) data. The method underwent training using only 400simulated images. In addition, our approach employs natural image segmentationmasks as intensity maps for the generated images, resulting in accuratedenoising for various anatomy shapes. The proposed method was assessed acrosssimulation, phantom, and in vivo images. The results of the evaluationsindicate that our approach not only enhances image quality on simulated databut also demonstrates effectiveness on phantom and in vivo data in terms ofimage quality. Comparative analysis with other methods underscores thesuperiority of our proposed method across various evaluation metrics. Thesource code and trained model will be released along with the dataset at:http://code.sonography.ai</description><author>Hojat Asgariandehkordi, Sobhan Goudarzi, Mostafa Sharifzadeh, Adrian Basarab, Hassan Rivaz</author><pubDate>Tue, 20 Aug 2024 16:31:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10987v1</guid></item><item><title>The fusion of phonography and ideographic characters into virtual Chinese characters -- Based on Chinese and English</title><link>http://arxiv.org/abs/2408.10979v1</link><description>The characters used in modern countries are mainly divided into ideographiccharacters and phonetic characters, both of which have their advantages anddisadvantages. Chinese is difficult to learn and easy to master, while Englishis easy to learn but has a large vocabulary. There is still no language thatcombines the advantages of both languages and has less memory capacity, canform words, and is easy to learn. Therefore, inventing new characters that canbe combined and the popularization of deep knowledge, and reduce disputesthrough communication. Firstly, observe the advantages and disadvantages ofChinese and English, such as their vocabulary, information content, and ease oflearning in deep scientific knowledge, and create a new writing system. Then,use comparative analysis to observe the total score of the new language.Through this article, it can be concluded that the new text combines theadvantages of both pictographic and alphabetical writing: new characters thatcan be combined into words reduces the vocabulary that needs to be learned;Special prefixes allow beginners to quickly guess the approximate category andmeaning of unseen words; New characters can enable humans to quickly learn moreadvanced knowledge.</description><author>Hongfa Zi, Zhen Liu</author><pubDate>Tue, 20 Aug 2024 16:13:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10979v1</guid></item><item><title>Kernel-Based Differentiable Learning of Non-Parametric Directed Acyclic Graphical Models</title><link>http://arxiv.org/abs/2408.10976v1</link><description>Causal discovery amounts to learning a directed acyclic graph (DAG) thatencodes a causal model. This model selection problem can be challenging due toits large combinatorial search space, particularly when dealing withnon-parametric causal models. Recent research has sought to bypass thecombinatorial search by reformulating causal discovery as a continuousoptimization problem, employing constraints that ensure the acyclicity of thegraph. In non-parametric settings, existing approaches typically rely onfinite-dimensional approximations of the relationships between nodes, resultingin a score-based continuous optimization problem with a smooth acyclicityconstraint. In this work, we develop an alternative approximation method byutilizing reproducing kernel Hilbert spaces (RKHS) and applying generalsparsity-inducing regularization terms based on partial derivatives. Withinthis framework, we introduce an extended RKHS representer theorem. To enforceacyclicity, we advocate the log-determinant formulation of the acyclicityconstraint and show its stability. Finally, we assess the performance of ourproposed RKHS-DAGMA procedure through simulations and illustrative dataanalyses.</description><author>Yurou Liang, Oleksandr Zadorozhnyi, Mathias Drton</author><pubDate>Tue, 20 Aug 2024 16:09:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10976v1</guid></item><item><title>Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation</title><link>http://arxiv.org/abs/2408.09698v2</link><description>Recent advances in Large Language Models (LLMs) have demonstrated significantpotential in the field of Recommendation Systems (RSs). Most existing studieshave focused on converting user behavior logs into textual prompts andleveraging techniques such as prompt tuning to enable LLMs for recommendationtasks. Meanwhile, research interest has recently grown in multimodalrecommendation systems that integrate data from images, text, and other sourcesusing modality fusion techniques. This introduces new challenges to theexisting LLM-based recommendation paradigm which relies solely on text modalityinformation. Moreover, although Multimodal Large Language Models (MLLMs)capable of processing multi-modal inputs have emerged, how to equip MLLMs withmulti-modal recommendation capabilities remains largely unexplored. To thisend, in this paper, we propose the Multimodal Large Language Model-enhancedMultimodaln Sequential Recommendation (MLLM-MSR) model. To capture the dynamicuser preference, we design a two-stage user preference summarization method.Specifically, we first utilize an MLLM-based item-summarizer to extract imagefeature given an item and convert the image into text. Then, we employ arecurrent user preference summarization generation paradigm to capture thedynamic changes in user preferences based on an LLM-based user-summarizer.Finally, to enable the MLLM for multi-modal recommendation task, we propose tofine-tune a MLLM-based recommender using Supervised Fine-Tuning (SFT)techniques. Extensive evaluations across various datasets validate theeffectiveness of MLLM-MSR, showcasing its superior ability to capture and adaptto the evolving dynamics of user preferences.</description><author>Yuyang Ye, Zhi Zheng, Yishan Shen, Tianshu Wang, Hengruo Zhang, Peijun Zhu, Runlong Yu, Kai Zhang, Hui Xiong</author><pubDate>Tue, 20 Aug 2024 16:09:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09698v2</guid></item><item><title>Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control</title><link>http://arxiv.org/abs/2408.10970v1</link><description>An open problem in artificial intelligence is how systems can flexibly learndiscrete abstractions that are useful for solving inherently continuousproblems. Previous work has demonstrated that a class of hybrid state-spacemodel known as recurrent switching linear dynamical systems (rSLDS) discovermeaningful behavioural units via the piecewise linear decomposition of complexcontinuous dynamics (Linderman et al., 2016). Furthermore, they model how theunderlying continuous states drive these discrete mode switches. We proposethat the rich representations formed by an rSLDS can provide usefulabstractions for planning and control. We present a novel hierarchicalmodel-based algorithm inspired by Active Inference in which a discrete MDP sitsabove a low-level linear-quadratic controller. The recurrent transitiondynamics learned by the rSLDS allow us to (1) specify temporally-abstractedsub-goals in a method reminiscent of the options framework, (2) lift theexploration into discrete space allowing us to exploit information-theoreticexploration bonuses and (3) `cache' the approximate solutions to low-levelproblems in the discrete planner. We successfully apply our model to the sparseContinuous Mountain Car task, demonstrating fast system identification viaenhanced exploration and non-trivial planning through the delineation ofabstract sub-goals.</description><author>Poppy Collis, Ryan Singh, Paul F Kinghorn, Christopher L Buckley</author><pubDate>Tue, 20 Aug 2024 16:02:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10970v1</guid></item><item><title>ISLES'24: Improving final infarct prediction in ischemic stroke using multimodal imaging and clinical data</title><link>http://arxiv.org/abs/2408.10966v1</link><description>Accurate estimation of core (irreversibly damaged tissue) and penumbra(salvageable tissue) volumes is essential for ischemic stroke treatmentdecisions. Perfusion CT, the clinical standard, estimates these volumes but isaffected by variations in deconvolution algorithms, implementations, andthresholds. Core tissue expands over time, with growth rates influenced bythrombus location, collateral circulation, and inherent patient-specificfactors. Understanding this tissue growth is crucial for determining the needto transfer patients to comprehensive stroke centers, predicting the benefitsof additional reperfusion attempts during mechanical thrombectomy, andforecasting final clinical outcomes. This work presents the ISLES'24 challenge,which addresses final post-treatment stroke infarct prediction frompre-interventional acute stroke imaging and clinical data. ISLES'24 establishesa unique 360-degree setting where all feasibly accessible clinical data areavailable for participants, including full CT acute stroke imaging, sub-acutefollow-up MRI, and clinical tabular data. The contributions of this work aretwo-fold: first, we introduce a standardized benchmarking of final strokeinfarct segmentation algorithms through the ISLES'24 challenge; second, weprovide insights into infarct segmentation using multimodal imaging andclinical data strategies by identifying outperforming methods on a finelycurated dataset. The outputs of this challenge are anticipated to enhanceclinical decision-making and improve patient outcome predictions. All ISLES'24materials, including data, performance evaluation scripts, and leadingalgorithmic strategies, are available to the research community following\url{https://isles-24.grand-challenge.org/}.</description><author>Ezequiel de la Rosa, Ruisheng Su, Mauricio Reyes, Roland Wiest, Evamaria O. Riedel, Florian Kofler, Kaiyuan Yang, Hakim Baazaoui, David Robben, Susanne Wegener, Jan S. Kirschke, Benedikt Wiestler, Bjoern Menze</author><pubDate>Tue, 20 Aug 2024 16:01:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10966v1</guid></item><item><title>NLP for The Greek Language: A Longer Survey</title><link>http://arxiv.org/abs/2408.10962v1</link><description>English language is in the spotlight of the Natural Language Processing (NLP)community with other languages, like Greek, lagging behind in terms of offeredmethods, tools and resources. Due to the increasing interest in NLP, in thispaper we try to condense research efforts for the automatic processing of Greeklanguage covering the last three decades. In particular, we list and brieflydiscuss related works, resources and tools, categorized according to variousprocessing layers and contexts. We are not restricted to the modern form ofGreek language but also cover Ancient Greek and various Greek dialects. Thissurvey can be useful for researchers and students interested in NLP tasks,Information Retrieval and Knowledge Management for the Greek language.</description><author>Katerina Papantoniou, Yannis Tzitzikas</author><pubDate>Tue, 20 Aug 2024 15:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10962v1</guid></item><item><title>SR+Codec: a Benchmark of Super-Resolution for Video Compression Bitrate Reduction</title><link>http://arxiv.org/abs/2305.04844v2</link><description>In recent years, there has been significant interest in Super-Resolution(SR), which focuses on generating a high-resolution image from a low-resolutioninput. Deep learning-based methods for super-resolution have been particularlypopular and have shown impressive results on various benchmarks. However,research indicates that these methods may not perform as well on stronglycompressed videos. We developed a super-resolution benchmark to analyze SR'scapacity to upscale compressed videos. Our dataset employed video codecs basedon five widely-used compression standards: H.264, H.265, H.266, AV1, and AVS3.We assessed 19 popular SR models using our benchmark and evaluated theirability to restore details and their susceptibility to compression artifacts.To get an accurate perceptual ranking of SR models, we conducted acrowd-sourced side-by-side comparison of their outputs. We found that some SRmodels, combined with compression, allow us to reduce the video bitrate withoutsignificant loss of quality. We also compared a range of image and videoquality metrics with subjective scores to evaluate their accuracy onsuper-resolved compressed videos. The benchmark is publicly available athttps://videoprocessing.ai/benchmarks/super-resolution-for-video-compression.html</description><author>Evgeney Bogatyrev, Ivan Molodetskikh, Dmitriy Vatolin</author><pubDate>Tue, 20 Aug 2024 15:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04844v2</guid></item><item><title>Kilometer-Scale Convection Allowing Model Emulation using Generative Diffusion Modeling</title><link>http://arxiv.org/abs/2408.10958v1</link><description>Storm-scale convection-allowing models (CAMs) are an important tool forpredicting the evolution of thunderstorms and mesoscale convective systems thatresult in damaging extreme weather. By explicitly resolving convective dynamicswithin the atmosphere they afford meteorologists the nuance needed to provideoutlook on hazard. Deep learning models have thus far not proven skilful atkm-scale atmospheric simulation, despite being competitive at coarserresolution with state-of-the-art global, medium-range weather forecasting. Wepresent a generative diffusion model called StormCast, which emulates thehigh-resolution rapid refresh (HRRR) model-NOAA's state-of-the-art 3kmoperational CAM. StormCast autoregressively predicts 99 state variables at kmscale using a 1-hour time step, with dense vertical resolution in theatmospheric boundary layer, conditioned on 26 synoptic variables. We presentevidence of successfully learnt km-scale dynamics including competitive 1-6hour forecast skill for composite radar reflectivity alongside physicallyrealistic convective cluster evolution, moist updrafts, and cold poolmorphology. StormCast predictions maintain realistic power spectra for multiplepredicted variables across multi-hour forecasts. Together, these resultsestablish the potential for autoregressive ML to emulate CAMs -- opening up newkm-scale frontiers for regional ML weather prediction and future climate hazarddynamical downscaling.</description><author>Jaideep Pathak, Yair Cohen, Piyush Garg, Peter Harrington, Noah Brenowitz, Dale Durran, Morteza Mardani, Arash Vahdat, Shaoming Xu, Karthik Kashinath, Michael Pritchard</author><pubDate>Tue, 20 Aug 2024 15:56:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10958v1</guid></item><item><title>Unc-TTP: A Method for Classifying LLM Uncertainty to Improve In-Context Example Selection</title><link>http://arxiv.org/abs/2408.09172v2</link><description>Nowadays, Large Language Models (LLMs) have demonstrated exceptionalperformance across various downstream tasks. However, it is challenging forusers to discern whether the responses are generated with certainty or arefabricated to meet user expectations. Estimating the uncertainty of LLMs isparticularly challenging due to their vast scale and the lack of white-boxaccess. In this work, we propose a novel Uncertainty Tripartite TestingParadigm (Unc-TTP) to classify LLM uncertainty, via evaluating the consistencyof LLM outputs when incorporating label interference into the sampling-basedapproach. Based on Unc-TTP outputs, we aggregate instances into certain anduncertain categories. Further, we conduct a detailed analysis of theuncertainty properties of LLMs and show Unc-TTP's superiority over the existingsampling-based methods. In addition, we leverage the obtained uncertaintyinformation to guide in-context example selection, demonstrating that Unc-TTPobviously outperforms retrieval-based and sampling-based approaches inselecting more informative examples. Our work paves a new way to classify theuncertainty of both open- and closed-source LLMs, and introduces a practicalapproach to exploit this uncertainty to improve LLMs performance.</description><author>Hsiu-Yuan Huang, Zichen Wu, Yutong Yang, Junzhao Zhang, Yunfang Wu</author><pubDate>Tue, 20 Aug 2024 15:51:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09172v2</guid></item><item><title>Multichannel Attention Networks with Ensembled Transfer Learning to Recognize Bangla Handwritten Charecter</title><link>http://arxiv.org/abs/2408.10955v1</link><description>The Bengali language is the 5th most spoken native and 7th most spokenlanguage in the world, and Bengali handwritten character recognition hasattracted researchers for decades. However, other languages such as English,Arabic, Turkey, and Chinese character recognition have contributedsignificantly to developing handwriting recognition systems. Still, littleresearch has been done on Bengali character recognition because of thesimilarity of the character, curvature and other complexities. However, manyresearchers have used traditional machine learning and deep learning models toconduct Bengali hand-written recognition. The study employed a convolutionalneural network (CNN) with ensemble transfer learning and a multichannelattention network. We generated the feature from the two branches of the CNN,including Inception Net and ResNet and then produced an ensemble feature fusionby concatenating them. After that, we applied the attention module to producethe contextual information from the ensemble features. Finally, we applied aclassification module to refine the features and classification. We evaluatedthe proposed model using the CAMTERdb 3.1.2 data set and achieved 92\% accuracyfor the raw dataset and 98.00\% for the preprocessed dataset. We believe thatour contribution to the Bengali handwritten character recognition domain willbe considered a great development.</description><author>Farhanul Haque, Md. Al-Hasan, Sumaiya Tabssum Mou, Abu Saleh Musa Miah, Jungpil Shin, Md Abdur Rahim</author><pubDate>Tue, 20 Aug 2024 15:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10955v1</guid></item><item><title>InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales</title><link>http://arxiv.org/abs/2406.13629v2</link><description>Retrieval-augmented generation (RAG) has shown promising potential to enhancethe accuracy and factuality of language models (LMs). However, imperfectretrievers or noisy corpora can introduce misleading or even erroneousinformation to the retrieved contents, posing a significant challenge to thegeneration quality. Existing RAG methods typically address this challenge bydirectly predicting final answers despite potentially noisy inputs, resultingin an implicit denoising process that is difficult to interpret and verify. Onthe other hand, the acquisition of explicit denoising supervision is oftencostly, involving significant human efforts. In this work, we proposeInstructRAG, where LMs explicitly learn the denoising process throughself-synthesized rationales -- First, we instruct the LM to explain how theground-truth answer is derived from retrieved documents. Then, these rationalescan be used either as demonstrations for in-context learning of explicitdenoising or as supervised fine-tuning data to train the model. Compared tostandard RAG approaches, InstructRAG requires no additional supervision, allowsfor easier verification of the predicted answers, and effectively improvesgeneration accuracy. Experiments show InstructRAG consistently outperformsexisting RAG methods in both training-free and trainable scenarios, achieving arelative improvement of 8.3% over the best baseline method on average acrossfive knowledge-intensive benchmarks. Extensive analysis indicates thatInstructRAG scales well with increased numbers of retrieved documents andconsistently exhibits robust denoising ability even in out-of-domain datasets,demonstrating strong generalizability.</description><author>Zhepei Wei, Wei-Lin Chen, Yu Meng</author><pubDate>Tue, 20 Aug 2024 15:48:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13629v2</guid></item><item><title>Wave-Mask/Mix: Exploring Wavelet-Based Augmentations for Time Series Forecasting</title><link>http://arxiv.org/abs/2408.10951v1</link><description>Data augmentation is important for improving machine learning modelperformance when faced with limited real-world data. In time series forecasting(TSF), where accurate predictions are crucial in fields like finance,healthcare, and manufacturing, traditional augmentation methods forclassification tasks are insufficient to maintain temporal coherence. Thisresearch introduces two augmentation approaches using the discrete wavelettransform (DWT) to adjust frequency elements while preserving temporaldependencies in time series data. Our methods, Wavelet Masking (WaveMask) andWavelet Mixing (WaveMix), are evaluated against established baselines acrossvarious forecasting horizons. To the best of our knowledge, this is the firststudy to conduct extensive experiments on multivariate time series usingDiscrete Wavelet Transform as an augmentation technique. Experimental resultsdemonstrate that our techniques achieve competitive results with previousmethods. We also explore cold-start forecasting using downsampled trainingdatasets, comparing outcomes to baseline methods.</description><author>Dona Arabi, Jafar Bakhshaliyev, Ayse Coskuner, Kiran Madhusudhanan, Kami Serdar Uckardes</author><pubDate>Tue, 20 Aug 2024 15:42:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10951v1</guid></item><item><title>Which Side Are You On? A Multi-task Dataset for End-to-End Argument Summarisation and Evaluation</title><link>http://arxiv.org/abs/2406.03151v3</link><description>With the recent advances of large language models (LLMs), it is no longerinfeasible to build an automated debate system that helps people to synthesisepersuasive arguments. Previous work attempted this task by integrating multiplecomponents. In our work, we introduce an argument mining dataset that capturesthe end-to-end process of preparing an argumentative essay for a debate, whichcovers the tasks of claim and evidence identification (Task 1 ED), evidenceconvincingness ranking (Task 2 ECR), argumentative essay summarisation andhuman preference ranking (Task 3 ASR) and metric learning for automatedevaluation of resulting essays, based on human feedback along argument qualitydimensions (Task 4 SQE). Our dataset contains 14k examples of claims that arefully annotated with the various properties supporting the aforementionedtasks. We evaluate multiple generative baselines for each of these tasks,including representative LLMs. We find, that while they show promising resultson individual tasks in our benchmark, their end-to-end performance on all fourtasks in succession deteriorates significantly, both in automated measures aswell as in human-centred evaluation. This challenge presented by our proposeddataset motivates future research on end-to-end argument mining andsummarisation. The repository of this project is available athttps://github.com/HaoBytes/ArgSum-Datatset</description><author>Hao Li, Yuping Wu, Viktor Schlegel, Riza Batista-Navarro, Tharindu Madusanka, Iqra Zahid, Jiayan Zeng, Xiaochi Wang, Xinran He, Yizhi Li, Goran Nenadic</author><pubDate>Tue, 20 Aug 2024 15:41:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03151v3</guid></item><item><title>GAIM: Attacking Graph Neural Networks via Adversarial Influence Maximization</title><link>http://arxiv.org/abs/2408.10948v1</link><description>Recent studies show that well-devised perturbations on graph structures ornode features can mislead trained Graph Neural Network (GNN) models. However,these methods often overlook practical assumptions, over-rely on heuristics, orseparate vital attack components. In response, we present GAIM, an integratedadversarial attack method conducted on a node feature basis while consideringthe strict black-box setting. Specifically, we define an adversarial influencefunction to theoretically assess the adversarial impact of node perturbations,thereby reframing the GNN attack problem into the adversarial influencemaximization problem. In our approach, we unify the selection of the targetnode and the construction of feature perturbations into a single optimizationproblem, ensuring a unique and consistent feature perturbation for each targetnode. We leverage a surrogate model to transform this problem into a solvablelinear programming task, streamlining the optimization process. Moreover, weextend our method to accommodate label-oriented attacks, broadening itsapplicability. Thorough evaluations on five benchmark datasets across threepopular models underscore the effectiveness of our method in both untargetedand label-oriented targeted attacks. Through comprehensive analysis andablation studies, we demonstrate the practical value and efficacy inherent toour design choices.</description><author>Xiaodong Yang, Xiaoting Li, Huiyuan Chen, Yiwei Cai</author><pubDate>Tue, 20 Aug 2024 15:41:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10948v1</guid></item><item><title>Model Stealing Attack against Graph Classification with Authenticity, Uncertainty and Diversity</title><link>http://arxiv.org/abs/2312.10943v3</link><description>Recent research demonstrates that GNNs are vulnerable to the model stealingattack, a nefarious endeavor geared towards duplicating the target model viaquery permissions. However, they mainly focus on node classification tasks,neglecting the potential threats entailed within the domain of graphclassification tasks. Furthermore, their practicality is questionable due tounreasonable assumptions, specifically concerning the large data requirementsand extensive model knowledge. To this end, we advocate following strictsettings with limited real data and hard-label awareness to generate syntheticdata, thereby facilitating the stealing of the target model. Specifically,following important data generation principles, we introduce three modelstealing attacks to adapt to different actual scenarios: MSA-AU is inspired byactive learning and emphasizes the uncertainty to enhance query value ofgenerated samples; MSA-AD introduces diversity based on Mixup augmentationstrategy to alleviate the query inefficiency issue caused by over-similarsamples generated by MSA-AU; MSA-AUD combines the above two strategies toseamlessly integrate the authenticity, uncertainty, and diversity of thegenerated samples. Finally, extensive experiments consistently demonstrate thesuperiority of the proposed methods in terms of concealment, query efficiency,and stealing performance.</description><author>Zhihao Zhu, Chenwang Wu, Rui Fan, Yi Yang, Zhen Wang, Defu Lian, Enhong Chen</author><pubDate>Tue, 20 Aug 2024 15:41:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10943v3</guid></item><item><title>Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models</title><link>http://arxiv.org/abs/2408.10947v1</link><description>Teachers are important to imparting knowledge and guiding learners, and therole of large language models (LLMs) as potential educators is emerging as animportant area of study. Recognizing LLMs' capability to generate educationalcontent can lead to advances in automated and personalized learning. While LLMshave been tested for their comprehension and problem-solving skills, theircapability in teaching remains largely unexplored. In teaching, questioning isa key skill that guides students to analyze, evaluate, and synthesize coreconcepts and principles. Therefore, our research introduces a benchmark toevaluate the questioning capability in education as a teacher of LLMs throughevaluating their generated educational questions, utilizing Anderson andKrathwohl's taxonomy across general, monodisciplinary, and interdisciplinarydomains. We shift the focus from LLMs as learners to LLMs as educators,assessing their teaching capability through guiding them to generate questions.We apply four metrics, including relevance, coverage, representativeness, andconsistency, to evaluate the educational quality of LLMs' outputs. Our resultsindicate that GPT-4 demonstrates significant potential in teaching general,humanities, and science courses; Claude2 appears more apt as aninterdisciplinary teacher. Furthermore, the automatic scores align with humanperspectives.</description><author>Yuyan Chen, Chenwei Wu, Songzhou Yan, Panjun Liu, Haoyu Zhou, Yanghua Xiao</author><pubDate>Tue, 20 Aug 2024 15:36:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10947v1</guid></item><item><title>Large Language Model Driven Recommendation</title><link>http://arxiv.org/abs/2408.10946v1</link><description>While previous chapters focused on recommendation systems (RSs) based onstandardized, non-verbal user feedback such as purchases, views, and clicks --the advent of LLMs has unlocked the use of natural language (NL) interactionsfor recommendation. This chapter discusses how LLMs' abilities for general NLreasoning present novel opportunities to build highly personalized RSs -- whichcan effectively connect nuanced and diverse user preferences to items,potentially via interactive dialogues. To begin this discussion, we firstpresent a taxonomy of the key data sources for language-driven recommendation,covering item descriptions, user-system interactions, and user profiles. Wethen proceed to fundamental techniques for LLM recommendation, reviewing theuse of encoder-only and autoregressive LLM recommendation in both tuned anduntuned settings. Afterwards, we move to multi-module recommendationarchitectures in which LLMs interact with components such as retrievers and RSsin multi-stage pipelines. This brings us to architectures for conversationalrecommender systems (CRSs), in which LLMs facilitate multi-turn dialogues whereeach turn presents an opportunity not only to make recommendations, but also toengage with the user in interactive preference elicitation, critiquing, andquestion-answering.</description><author>Anton Korikov, Scott Sanner, Yashar Deldjoo, Zhankui He, Julian McAuley, Arnau Ramisa, Rene Vidal, Mahesh Sathiamoorthy, Atoosa Kasrizadeh, Silvia Milano, Francesco Ricci</author><pubDate>Tue, 20 Aug 2024 15:36:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10946v1</guid></item><item><title>HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models in Resource-Constrained Environments</title><link>http://arxiv.org/abs/2408.10945v1</link><description>High-resolution Vision-Language Models (VLMs) have been widely used inmultimodal tasks to enhance accuracy by preserving detailed image information.However, these models often generate excessive visual tokens due to encodingmultiple partitions of the input image. Processing these excessive visualtokens is computationally challenging, especially in resource-constrainedenvironments with commodity GPUs. To support high-resolution images whilemeeting resource constraints, we propose High-Resolution Early Dropping(HiRED), a token-dropping scheme that operates within a fixed token budgetbefore the Large Language Model (LLM) stage. HiRED can be integrated withexisting high-resolution VLMs in a plug-and-play manner, as it requires noadditional training while still maintaining superior accuracy. We strategicallyuse the vision encoder's attention in the initial layers to assess the visualcontent of each image partition and allocate the token budget accordingly.Then, using the attention in the final layer, we select the most importantvisual tokens from each partition within the allocated budget, dropping therest. Empirically, when applied to LLaVA-Next-7B on NVIDIA TESLA P40 GPU, HiREDwith a 20% token budget increases token generation throughput by 4.7, reducesfirst-token generation latency by 15 seconds, and saves 2.3 GB of GPU memoryfor a single inference.</description><author>Kazi Hasan Ibn Arif, JinYi Yoon, Dimitrios S. Nikolopoulos, Hans Vandierendonck, Deepu John, Bo Ji</author><pubDate>Tue, 20 Aug 2024 15:34:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10945v1</guid></item><item><title>SysBench: Can Large Language Models Follow System Messages?</title><link>http://arxiv.org/abs/2408.10943v1</link><description>Large Language Models (LLMs) have become instrumental across variousapplications, with the customization of these models to specific scenariosbecoming increasingly critical. System message, a fundamental component ofLLMs, is consist of carefully crafted instructions that guide the behavior ofmodel to meet intended goals. Despite the recognized potential of systemmessages to optimize AI-driven solutions, there is a notable absence of acomprehensive benchmark for evaluating how well different LLMs follow thesesystem messages. To fill this gap, we introduce SysBench, a benchmark thatsystematically analyzes system message following ability in terms of threechallenging aspects: constraint complexity, instruction misalignment andmulti-turn stability. In order to enable effective evaluation, SysBenchconstructs multi-turn user conversations covering various interactionrelationships, based on six common types of constraints from system messages inreal-world scenarios. Our dataset contains 500 system messages from variousdomains, each paired with 5 turns of user conversations, which have beenmanually formulated and checked to guarantee high quality. SysBench providesextensive evaluation across various LLMs, measuring their ability to followspecified constraints given in system messages. The results highlight both thestrengths and weaknesses of existing models, offering key insights anddirections for future research. The open source library SysBench is availableat https://github.com/PKU-Baichuan-MLSystemLab/SysBench.</description><author>Yanzhao Qin, Tao Zhang, Tao Zhang, Yanjun Shen, Wenjing Luo, Haoze Sun, Yan Zhang, Yujing Qiao, Weipeng Chen, Zenan Zhou, Wentao Zhang, Bin Cui</author><pubDate>Tue, 20 Aug 2024 15:33:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10943v1</guid></item><item><title>Self-Supervised Disentanglement by Leveraging Structure in Data Augmentations</title><link>http://arxiv.org/abs/2311.08815v2</link><description>Self-supervised representation learning often uses data augmentations toinduce some invariance to "style" attributes of the data. However, withdownstream tasks generally unknown at training time, it is difficult to deducea priori which attributes of the data are indeed "style" and can be safelydiscarded. To deal with this, current approaches try to retain some styleinformation by tuning the degree of invariance to some particular task, such asImageNet object classification. However, prior work has shown that suchtask-specific tuning can lead to significant performance degradation on othertasks that rely on the discarded style. To address this, we introduce a moreprincipled approach that seeks to disentangle style features rather thandiscard them. The key idea is to add multiple style embedding spaces where: (i)each is invariant to all-but-one augmentation; and (ii) joint entropy ismaximized. We formalize our structured data-augmentation procedure from acausal latent-variable-model perspective, and prove identifiability of bothcontent and individual style variables. We empirically demonstrate the benefitsof our approach on both synthetic and real-world data.</description><author>Cian Eastwood, Julius von Kügelgen, Linus Ericsson, Diane Bouchacourt, Pascal Vincent, Bernhard Schölkopf, Mark Ibrahim</author><pubDate>Tue, 20 Aug 2024 15:33:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08815v2</guid></item><item><title>Robust Regression with Ensembles Communicating over Noisy Channels</title><link>http://arxiv.org/abs/2408.10942v1</link><description>As machine-learning models grow in size, their implementation requirementscannot be met by a single computer system. This observation motivatesdistributed settings, in which intermediate computations are performed across anetwork of processing units, while the central node only aggregates theiroutputs. However, distributing inference tasks across low-precision or faultyedge devices, operating over a network of noisy communication channels, givesrise to serious reliability challenges. We study the problem of an ensemble ofdevices, implementing regression algorithms, that communicate through additivenoisy channels in order to collaboratively perform a joint regression task. Wedefine the problem formally, and develop methods for optimizing the aggregationcoefficients for the parameters of the noise in the channels, which canpotentially be correlated. Our results apply to the leading state-of-the-artensemble regression methods: bagging and gradient boosting. We demonstrate theeffectiveness of our algorithms on both synthetic and real-world datasets.</description><author>Yuval Ben-Hur, Yuval Cassuto</author><pubDate>Tue, 20 Aug 2024 15:32:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10942v1</guid></item><item><title>Normalise for Fairness: A Simple Normalisation Technique for Fairness in Regression Machine Learning Problems</title><link>http://arxiv.org/abs/2202.00993v2</link><description>Algorithms and Machine Learning (ML) are increasingly affecting everyday lifeand several decision-making processes, where ML has an advantage due toscalability or superior performance. Fairness in such applications is crucial,where models should not discriminate their results based on race, gender, orother protected groups. This is especially crucial for models affecting verysensitive topics, like interview invitation or recidivism prediction. Fairnessis not commonly studied for regression problems compared to binaryclassification problems; hence, we present a simple, yet effective method basedon normalisation (FaiReg), which minimises the impact of unfairness inregression problems, especially due to labelling bias. We present a theoreticalanalysis of the method, in addition to an empirical comparison against twostandard methods for fairness, namely data balancing and adversarial training.We also include a hybrid formulation (FaiRegH), merging the presented methodwith data balancing, in an attempt to face labelling and sampling biasessimultaneously. The experiments are conducted on the multimodal dataset FirstImpressions (FI) with various labels, namely Big-Five personality predictionand interview screening score. The results show the superior performance ofdiminishing the effects of unfairness better than data balancing, also withoutdeteriorating the performance of the original problem as much as adversarialtraining. Fairness is evaluated based on the Equal Accuracy (EA) andStatistical Parity (SP) constraints. The experiments present a setup thatenhances the fairness for several protected variables simultaneously.</description><author>Mostafa M. Amin, Björn W. Schuller</author><pubDate>Tue, 20 Aug 2024 15:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.00993v2</guid></item><item><title>A Closer Look at Data Augmentation Strategies for Finetuning-Based Low/Few-Shot Object Detection</title><link>http://arxiv.org/abs/2408.10940v1</link><description>Current methods for low- and few-shot object detection have primarily focusedon enhancing model performance for detecting objects. One common approach toachieve this is by combining model finetuning with data augmentationstrategies. However, little attention has been given to the energy efficiencyof these approaches in data-scarce regimes. This paper seeks to conduct acomprehensive empirical study that examines both model performance and energyefficiency of custom data augmentations and automated data augmentationselection strategies when combined with a lightweight object detector. Themethods are evaluated in three different benchmark datasets in terms of theirperformance and energy consumption, and the Efficiency Factor is employed togain insights into their effectiveness considering both performance andefficiency. Consequently, it is shown that in many cases, the performance gainsof data augmentation strategies are overshadowed by their increased energyusage, necessitating the development of more energy efficient data augmentationstrategies to address data scarcity.</description><author>Vladislav Li, Georgios Tsoumplekas, Ilias Siniosoglou, Vasileios Argyriou, Anastasios Lytos, Eleftherios Fountoukidis, Panagiotis Sarigiannidis</author><pubDate>Tue, 20 Aug 2024 15:29:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10940v1</guid></item><item><title>Conformalized Interval Arithmetic with Symmetric Calibration</title><link>http://arxiv.org/abs/2408.10939v1</link><description>Uncertainty quantification is essential in decision-making, especially whenjoint distributions of random variables are involved. While conformalprediction provides distribution-free prediction sets with valid coverageguarantees, it traditionally focuses on single predictions. This paperintroduces novel conformal prediction methods for estimating the sum or averageof unknown labels over specific index sets. We develop conformal predictionintervals for single target to the prediction interval for sum of multipletargets. Under permutation invariant assumptions, we prove the validity of ourproposed method. We also apply our algorithms on class average estimation andpath cost prediction tasks, and we show that our method outperforms existingconformalized approaches as well as non-conformal approaches.</description><author>Rui Luo, Zhixin Zhou</author><pubDate>Tue, 20 Aug 2024 15:27:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10939v1</guid></item><item><title>Large Point-to-Gaussian Model for Image-to-3D Generation</title><link>http://arxiv.org/abs/2408.10935v1</link><description>Recently, image-to-3D approaches have significantly advanced the generationquality and speed of 3D assets based on large reconstruction models,particularly 3D Gaussian reconstruction models. Existing large 3D Gaussianmodels directly map 2D image to 3D Gaussian parameters, while regressing 2Dimage to 3D Gaussian representations is challenging without 3D priors. In thispaper, we propose a large Point-to-Gaussian model, that inputs the initialpoint cloud produced from large 3D diffusion model conditional on 2D image togenerate the Gaussian parameters, for image-to-3D generation. The point cloudprovides initial 3D geometry prior for Gaussian generation, thus significantlyfacilitating image-to-3D Generation. Moreover, we present the\textbf{A}ttention mechanism, \textbf{P}rojection mechanism, and \textbf{P}ointfeature extractor, dubbed as \textbf{APP} block, for fusing the image featureswith point cloud features. The qualitative and quantitative experimentsextensively demonstrate the effectiveness of the proposed approach on GSO andObjaverse datasets, and show the proposed method achieves state-of-the-artperformance.</description><author>Longfei Lu, Huachen Gao, Tao Dai, Yaohua Zha, Zhi Hou, Junta Wu, Shu-Tao Xia</author><pubDate>Tue, 20 Aug 2024 15:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10935v1</guid></item><item><title>SDI-Net: Toward Sufficient Dual-View Interaction for Low-light Stereo Image Enhancement</title><link>http://arxiv.org/abs/2408.10934v1</link><description>Currently, most low-light image enhancement methods only consider informationfrom a single view, neglecting the correlation between cross-view information.Therefore, the enhancement results produced by these methods are oftenunsatisfactory. In this context, there have been efforts to develop methodsspecifically for low-light stereo image enhancement. These methods take intoaccount the cross-view disparities and enable interaction between the left andright views, leading to improved performance. However, these methods still donot fully exploit the interaction between left and right view information. Toaddress this issue, we propose a model called Toward Sufficient Dual-ViewInteraction for Low-light Stereo Image Enhancement (SDI-Net). The backbonestructure of SDI-Net is two encoder-decoder pairs, which are used to learn themapping function from low-light images to normal-light images. Among theencoders and the decoders, we design a module named Cross-View SufficientInteraction Module (CSIM), aiming to fully exploit the correlations between thebinocular views via the attention mechanism. The quantitative and visualresults on public datasets validate the superiority of our method over otherrelated methods. Ablation studies also demonstrate the effectiveness of the keyelements in our model.</description><author>Linlin Hu, Ao Sun, Shijie Hao, Richang Hong, Meng Wang</author><pubDate>Tue, 20 Aug 2024 15:17:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10934v1</guid></item><item><title>The Evolution of Reinforcement Learning in Quantitative Finance</title><link>http://arxiv.org/abs/2408.10932v1</link><description>Reinforcement Learning (RL) has experienced significant advancement over thepast decade, prompting a growing interest in applications within finance. Thissurvey critically evaluates 167 publications, exploring diverse RL applicationsand frameworks in finance. Financial markets, marked by their complexity,multi-agent nature, information asymmetry, and inherent randomness, serve as anintriguing test-bed for RL. Traditional finance offers certain solutions, andRL advances these with a more dynamic approach, incorporating machine learningmethods, including transfer learning, meta-learning, and multi-agent solutions.This survey dissects key RL components through the lens of QuantitativeFinance. We uncover emerging themes, propose areas for future research, andcritique the strengths and weaknesses of existing methods.</description><author>Nikolaos Pippas, Cagatay Turkay, Elliot A. Ludvig</author><pubDate>Tue, 20 Aug 2024 15:15:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10932v1</guid></item><item><title>Reference-Guided Verdict: LLMs-as-Judges in Automatic Evaluation of Free-Form Text</title><link>http://arxiv.org/abs/2408.09235v2</link><description>The emergence of Large Language Models (LLMs) as chat assistants capable ofgenerating human-like conversations has amplified the need for robustevaluation methods, particularly for open-ended tasks. Conventional metricslike BLEU and ROUGE, while useful, are increasingly inadequate for capturingthe subtle semantics and contextual richness of such generative outputs. Wepropose a reference-guided verdict method that automates the evaluation processby leveraging multiple LLMs-as-judges. Through experiments on three open-endedquestion-answering tasks, we demonstrate that combining multiple LLMs-as-judgessignificantly improves the reliability and accuracy of evaluations,particularly in complex tasks where a single model might struggle. Our findingsreveal a strong correlation with human evaluations, establishing our method asa viable and effective alternative to traditional metrics and human judgments,particularly in the context of LLM-based chat assistants where the complexityand diversity of responses challenge existing benchmarks.</description><author>Sher Badshah, Hassan Sajjad</author><pubDate>Tue, 20 Aug 2024 15:12:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09235v2</guid></item><item><title>LBC: Language-Based-Classifier for Out-Of-Variable Generalization</title><link>http://arxiv.org/abs/2408.10923v1</link><description>Large Language Models (LLMs) have great success in natural languageprocessing tasks such as response generation. However, their use in tabulardata has been limited due to their inferior performance compared to traditionalmachine learning models (TMLs) such as XGBoost. We find that the pre-trainedknowledge of LLMs enables them to interpret new variables that appear in a testwithout additional training, a capability central to the concept ofOut-of-Variable (OOV). From the findings, we propose aLanguage-Based-Classifier (LBC), a classifier that maximizes the benefits ofLLMs to outperform TMLs on OOV tasks. LBC employs three key methodologicalstrategies: 1) Categorical changes to adjust data to better fit the model'sunderstanding, 2) Advanced order and indicator to enhance data representationto the model, and 3) Using verbalizer to map logit scores to classes duringinference to generate model predictions. These strategies, combined with thepre-trained knowledge of LBC, emphasize the model's ability to effectivelyhandle OOV tasks. We empirically and theoretically validate the superiority ofLBC. LBC is the first study to apply an LLM-based model to OOV tasks. Thesource code is athttps://github.com/ASDASDanonymous/Language-Based-Classifier-forOOVtasks.</description><author>Kangjun Noh, Baekryun Seong, Hoyoon Byun, Sungjin Song, Kyungwoo Song</author><pubDate>Tue, 20 Aug 2024 15:05:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10923v1</guid></item><item><title>MTFinEval:A Multi-domain Chinese Financial Benchmark with Eurypalynous questions</title><link>http://arxiv.org/abs/2408.10921v1</link><description>With the emergence of more and more economy-specific LLMS, how to measurewhether they can be safely invested in production becomes a problem. Previousresearch has primarily focused on evaluating the performance of LLMs withinspecific application scenarios. However, these benchmarks cannot reflect thetheoretical level and generalization ability, and the backward datasets areincreasingly unsuitable for problems in real scenarios. In this paper, we havecompiled a new benchmark, MTFinEval, focusing on the LLMs' basic knowledge ofeconomics, which can always be used as a basis for judgment. To examine onlytheoretical knowledge as much as possible, MTFinEval is build with foundationalquestions from university textbooks,and exam papers in economics and managementmajor. Aware of the overall performance of LLMs do not depend solely on onesubdiscipline of economics, MTFinEval comprise 360 questions refined from sixmajor disciplines of economics, and reflect capabilities more comprehensively.Experiment result shows all LLMs perform poorly on MTFinEval, which proves thatour benchmark built on basic knowledge is very successful. Our research notonly offers guidance for selecting the appropriate LLM for specific use cases,but also put forward increase the rigor reliability of LLMs from the basics.</description><author>Xinyu Liu, Ke Jin</author><pubDate>Tue, 20 Aug 2024 15:04:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10921v1</guid></item><item><title>Recurrent Neural Networks Learn to Store and Generate Sequences using Non-Linear Representations</title><link>http://arxiv.org/abs/2408.10920v1</link><description>The Linear Representation Hypothesis (LRH) states that neural networks learnto encode concepts as directions in activation space, and a strong version ofthe LRH states that models learn only such encodings. In this paper, we presenta counterexample to this strong LRH: when trained to repeat an input tokensequence, gated recurrent neural networks (RNNs) learn to represent the tokenat each position with a particular order of magnitude, rather than a direction.These representations have layered features that are impossible to locate indistinct linear subspaces. To show this, we train interventions to predict andmanipulate tokens by learning the scaling factor corresponding to each sequenceposition. These interventions indicate that the smallest RNNs find only thismagnitude-based solution, while larger RNNs have linear representations. Thesefindings strongly indicate that interpretability research should not beconfined by the LRH.</description><author>Róbert Csordás, Christopher Potts, Christopher D. Manning, Atticus Geiger</author><pubDate>Tue, 20 Aug 2024 15:04:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10920v1</guid></item><item><title>CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network</title><link>http://arxiv.org/abs/2408.10919v1</link><description>In recent years, Wi-Fi sensing has garnered significant attention due to itsnumerous benefits, such as privacy protection, low cost, and penetrationability. Extensive research has been conducted in this field, focusing on areassuch as gesture recognition, people identification, and fall detection.However, many data-driven methods encounter challenges related to domain shift,where the model fails to perform well in environments different from thetraining data. One major factor contributing to this issue is the limitedavailability of Wi-Fi sensing datasets, which makes models learn excessiveirrelevant information and over-fit to the training set. Unfortunately,collecting large-scale Wi-Fi sensing datasets across diverse scenarios is achallenging task. To address this problem, we propose CrossFi, a siamesenetwork-based approach that excels in both in-domain scenario and cross-domainscenario, including few-shot, zero-shot scenarios, and even works in few-shotnew-class scenario where testing set contains new categories. The corecomponent of CrossFi is a sample-similarity calculation network called CSi-Net,which improves the structure of the siamese network by using an attentionmechanism to capture similarity information, instead of simply calculating thedistance or cosine similarity. Based on it, we develop an extra Weight-Net thatcan generate a template for each class, so that our CrossFi can work indifferent scenarios. Experimental results demonstrate that our CrossFi achievesstate-of-the-art performance across various scenarios. In gesture recognitiontask, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72%in one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario,and 84.75% in one-shot new-class scenario. To facilitate future research, wewill release the code for our model upon publication.</description><author>Zijian Zhao, Tingwei Chen, Zhijie Cai, Hang Li, Xiaoyang Li, Qimei Chen, Guangxu Zhu</author><pubDate>Tue, 20 Aug 2024 15:04:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10919v1</guid></item><item><title>CHECKWHY: Causal Fact Verification via Argument Structure</title><link>http://arxiv.org/abs/2408.10918v1</link><description>With the growing complexity of fact verification tasks, the concern with"thoughtful" reasoning capabilities is increasing. However, recent factverification benchmarks mainly focus on checking a narrow scope of semanticfactoids within claims and lack an explicit logical reasoning process. In thispaper, we introduce CheckWhy, a challenging dataset tailored to a novel causalfact verification task: checking the truthfulness of the causal relation withinclaims through rigorous reasoning steps. CheckWhy consists of over 19K "why"claim-evidence-argument structure triplets with supports, refutes, and notenough info labels. Each argument structure is composed of connected evidence,representing the reasoning process that begins with foundational evidence andprogresses toward claim establishment. Through extensive experiments onstate-of-the-art models, we validate the importance of incorporating theargument structure for causal fact verification. Moreover, the automated andhuman evaluation of argument structure generation reveals the difficulty inproducing satisfying argument structure by fine-tuned models orChain-of-Thought prompted LLMs, leaving considerable room for futureimprovements.</description><author>Jiasheng Si, Yibo Zhao, Yingjie Zhu, Haiyang Zhu, Wenpeng Lu, Deyu Zhou</author><pubDate>Tue, 20 Aug 2024 15:03:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10918v1</guid></item><item><title>Vision-Language Dataset Distillation</title><link>http://arxiv.org/abs/2308.07545v4</link><description>Dataset distillation methods reduce large-scale datasets to smaller sets ofsynthetic data, preserving sufficient information to quickly train a new modelfrom scratch. However, prior work on dataset distillation has focusedexclusively on image classification datasets, whereas modern large-scaledatasets are primarily vision-language datasets. In this work, we design thefirst vision-language dataset distillation method, building on the idea oftrajectory matching. A key challenge is that vision-language datasets do nothave a set of discrete classes. To overcome this, our proposed method jointlydistills image-text pairs in a contrastive formulation. Further, we leverageLow-Rank Adaptation (LoRA) matching to enable more efficient and effectivetrajectory matching in complex modern vision-language models. Since there areno existing baselines, we compare our distillation approach with three adaptedvision-language coreset selection methods. We demonstrate significantimprovements on the challenging Flickr30K and COCO retrieval benchmarks: forexample, on Flickr30K, the best coreset selection method selecting 1000image-text pairs for training achieves only 5.6% image-to-text retrievalaccuracy (i.e., recall@1); in contrast, our dataset distillation almost doublesthat to 9.9% with just 100 training pairs, an order of magnitude fewer.</description><author>Xindi Wu, Byron Zhang, Zhiwei Deng, Olga Russakovsky</author><pubDate>Tue, 20 Aug 2024 14:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07545v4</guid></item><item><title>To Code, or Not To Code? Exploring Impact of Code in Pre-training</title><link>http://arxiv.org/abs/2408.10914v1</link><description>Including code in the pre-training data mixture, even for models notspecifically designed for code, has become a common practice in LLMspre-training. While there has been anecdotal consensus among practitioners thatcode data plays a vital role in general LLMs' performance, there is onlylimited work analyzing the precise impact of code on non-code tasks. In thiswork, we systematically investigate the impact of code data on generalperformance. We ask "what is the impact of code data used in pre-training on alarge variety of downstream tasks beyond code generation". We conduct extensiveablations and evaluate across a broad range of natural language reasoningtasks, world knowledge tasks, code benchmarks, and LLM-as-a-judge win-rates formodels with sizes ranging from 470M to 2.8B parameters. Across settings, wefind a consistent results that code is a critical building block forgeneralization far beyond coding tasks and improvements to code quality have anoutsized impact across all tasks. In particular, compared to text-onlypre-training, the addition of code results in up to relative increase of 8.2%in natural language (NL) reasoning, 4.2% in world knowledge, 6.6% improvementin generative win-rates, and a 12x boost in code performance respectively. Ourwork suggests investments in code quality and preserving code duringpre-training have positive impacts.</description><author>Viraat Aryabumi, Yixuan Su, Raymond Ma, Adrien Morisot, Ivan Zhang, Acyr Locatelli, Marzieh Fadaee, Ahmet Üstün, Sara Hooker</author><pubDate>Tue, 20 Aug 2024 14:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10914v1</guid></item><item><title>Hybrid Semantic Search: Unveiling User Intent Beyond Keywords</title><link>http://arxiv.org/abs/2408.09236v2</link><description>This paper addresses the limitations of traditional keyword-based search inunderstanding user intent and introduces a novel hybrid search approach thatleverages the strengths of non-semantic search engines, Large Language Models(LLMs), and embedding models. The proposed system integrates keyword matching,semantic vector embeddings, and LLM-generated structured queries to deliverhighly relevant and contextually appropriate search results. By combining thesecomplementary methods, the hybrid approach effectively captures both explicitand implicit user intent.The paper further explores techniques to optimizequery execution for faster response times and demonstrates the effectiveness ofthis hybrid search model in producing comprehensive and accurate searchoutcomes.</description><author>Aman Ahluwalia, Bishwajit Sutradhar, Karishma Ghosh, Indrapal Yadav, Arpan Sheetal, Prashant Patil</author><pubDate>Tue, 20 Aug 2024 14:57:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09236v2</guid></item><item><title>Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation</title><link>http://arxiv.org/abs/2407.05890v2</link><description>LLM-based agents have demonstrated impressive zero-shot performance invision-language navigation (VLN) task. However, existing LLM-based methodsoften focus only on solving high-level task planning by selecting nodes inpredefined navigation graphs for movements, overlooking low-level control innavigation scenarios. To bridge this gap, we propose AO-Planner, a novelAffordances-Oriented Planner for continuous VLN task. Our AO-Planner integratesvarious foundation models to achieve affordances-oriented low-level motionplanning and high-level decision-making, both performed in a zero-shot setting.Specifically, we employ a Visual Affordances Prompting (VAP) approach, wherethe visible ground is segmented by SAM to provide navigational affordances,based on which the LLM selects potential candidate waypoints and planslow-level paths towards selected waypoints. We further propose a high-levelPathAgent which marks planned paths into the image input and reasons the mostprobable path by comprehending all environmental information. Finally, weconvert the selected path into 3D coordinates using camera intrinsic parametersand depth information, avoiding challenging 3D predictions for LLMs.Experiments on the challenging R2R-CE and RxR-CE datasets show that AO-Plannerachieves state-of-the-art zero-shot performance (8.8% improvement on SPL). Ourmethod can also serve as a data annotator to obtain pseudo-labels, distillingits waypoint prediction ability into a learning-based predictor. This newpredictor does not require any waypoint data from the simulator and achieves47% SR competing with supervised methods. We establish an effective connectionbetween LLM and 3D world, presenting novel prospects for employing foundationmodels in low-level motion control.</description><author>Jiaqi Chen, Bingqian Lin, Xinmin Liu, Lin Ma, Xiaodan Liang, Kwan-Yee K. Wong</author><pubDate>Tue, 20 Aug 2024 14:51:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05890v2</guid></item><item><title>ShapeSplat: A Large-scale Dataset of Gaussian Splats and Their Self-Supervised Pretraining</title><link>http://arxiv.org/abs/2408.10906v1</link><description>3D Gaussian Splatting (3DGS) has become the de facto method of 3Drepresentation in many vision tasks. This calls for the 3D understandingdirectly in this representation space. To facilitate the research in thisdirection, we first build a large-scale dataset of 3DGS using the commonly usedShapeNet and ModelNet datasets. Our dataset ShapeSplat consists of 65K objectsfrom 87 unique categories, whose labels are in accordance with the respectivedatasets. The creation of this dataset utilized the compute equivalent of 2 GPUyears on a TITAN XP GPU. We utilize our dataset for unsupervised pretraining and supervised finetuningfor classification and segmentation tasks. To this end, we introduce\textbf{\textit{Gaussian-MAE}}, which highlights the unique benefits ofrepresentation learning from Gaussian parameters. Through exhaustiveexperiments, we provide several valuable insights. In particular, we show that(1) the distribution of the optimized GS centroids significantly differs fromthe uniformly sampled point cloud (used for initialization) counterpart; (2)this change in distribution results in degradation in classification butimprovement in segmentation tasks when using only the centroids; (3) toleverage additional Gaussian parameters, we propose Gaussian feature groupingin a normalized feature space, along with splats pooling layer, offering atailored solution to effectively group and embed similar Gaussians, which leadsto notable improvement in finetuning tasks.</description><author>Qi Ma, Yue Li, Bin Ren, Nicu Sebe, Ender Konukoglu, Theo Gevers, Luc Van Gool, Danda Pani Paudel</author><pubDate>Tue, 20 Aug 2024 14:49:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10906v1</guid></item><item><title>The impact of labeling automotive AI as "trustworthy" or "reliable" on user evaluation and technology acceptance</title><link>http://arxiv.org/abs/2408.10905v1</link><description>This study explores whether labeling AI as "trustworthy" or "reliable"influences user perceptions and acceptance of automotive AI technologies. Usinga one-way between-subjects design, the research involved 478 onlineparticipants who were presented with guidelines for either trustworthy orreliable AI. Participants then evaluated three vignette scenarios and completeda modified version of the Technology Acceptance Model, which included variablessuch as perceived ease of use, human-like trust, and overall attitude. Althoughlabeling AI as "trustworthy" did not significantly influence judgments onspecific scenarios, it increased perceived ease of use and human-like trust,particularly benevolence. This suggests a positive impact on usability and ananthropomorphic effect on user perceptions. The study provides insights intohow specific labels can influence attitudes toward AI technology.</description><author>John Dorsch, Ophelia Deroy</author><pubDate>Tue, 20 Aug 2024 14:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10905v1</guid></item><item><title>BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model</title><link>http://arxiv.org/abs/2408.10903v1</link><description>The rapid advancement of large language models (LLMs) has revolutionizedrole-playing, enabling the development of general role-playing models. However,current role-playing training has two significant issues: (I) Using apredefined role profile to prompt dialogue training for specific scenariosusually leads to inconsistencies and even conflicts between the dialogue andthe profile, resulting in training biases. (II) The model learns to imitate therole based solely on the profile, neglecting profile-dialogue alignment at thesentence level. In this work, we propose a simple yet effective frameworkcalled BEYOND DIALOGUE, designed to overcome these hurdles. This frameworkinnovatively introduces "beyond dialogue" tasks to align dialogue with profiletraits based on each specific scenario, thereby eliminating biases duringtraining. Furthermore, by adopting an innovative prompting mechanism thatgenerates reasoning outcomes for training, the framework allows the model toachieve fine-grained alignment between profile and dialogue at the sentencelevel. The aforementioned methods are fully automated and low-cost.Additionally, the integration of automated dialogue and objective evaluationmethods forms a comprehensive framework, paving the way for generalrole-playing. Experimental results demonstrate that our model excels inadhering to and reflecting various dimensions of role profiles, outperformingmost proprietary general and specialized role-playing baselines. All code anddatasets are available at https://github.com/yuyouyu32/BeyondDialogue.</description><author>Yeyong Yu, Rusheng Yu, Haojie Wei, Zhanqiu Zhang, Quan Qian</author><pubDate>Tue, 20 Aug 2024 14:47:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10903v1</guid></item><item><title>Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs</title><link>http://arxiv.org/abs/2408.10902v1</link><description>Although human evaluation remains the gold standard for open-domain dialogueevaluation, the growing popularity of automated evaluation using Large LanguageModels (LLMs) has also extended to dialogue. However, most frameworks leveragebenchmarks that assess older chatbots on aspects such as fluency and relevance,which are not reflective of the challenges associated with contemporary models.In fact, a qualitative analysis on Soda, a GPT-3.5 generated dialogue dataset,suggests that current chatbots may exhibit several recurring issues related tocoherence and commonsense knowledge, but generally produce highly fluent andrelevant responses. Noting the aforementioned limitations, this paper introduces Soda-Eval, anannotated dataset based on Soda that covers over 120K turn-level assessmentsacross 10K dialogues, where the annotations were generated by GPT-4. UsingSoda-Eval as a benchmark, we then study the performance of several open-accessinstruction-tuned LLMs, finding that dialogue evaluation remains challenging.Fine-tuning these models improves performance over few-shot inferences, both interms of correlation and explanation.</description><author>John Mendonça, Isabel Trancoso, Alon Lavie</author><pubDate>Tue, 20 Aug 2024 14:45:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10902v1</guid></item><item><title>A Grey-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse</title><link>http://arxiv.org/abs/2408.10901v1</link><description>Recent advancements in generative AI, particularly Latent Diffusion Models(LDMs), have revolutionized image synthesis and manipulation. However, thesegenerative techniques raises concerns about data misappropriation andintellectual property infringement. Adversarial attacks on machine learningmodels have been extensively studied, and a well-established body of researchhas extended these techniques as a benign metric to prevent the underlyingmisuse of generative AI. Current approaches to safeguarding images frommanipulation by LDMs are limited by their reliance on model-specific knowledgeand their inability to significantly degrade semantic quality of generatedimages. In response to these shortcomings, we propose the Posterior CollapseAttack (PCA) based on the observation that VAEs suffer from posterior collapseduring training. Our method minimizes dependence on the white-box informationof target models to get rid of the implicit reliance on model-specificknowledge. By accessing merely a small amount of LDM parameters, in specificmerely the VAE encoder of LDMs, our method causes a substantial semanticcollapse in generation quality, particularly in perceptual consistency, anddemonstrates strong transferability across various model architectures.Experimental results show that PCA achieves superior perturbation effects onimage generation of LDMs with lower runtime and VRAM. Our method outperformsexisting techniques, offering a more robust and generalizable solution that ishelpful in alleviating the socio-technical challenges posed by the rapidlyevolving landscape of generative AI.</description><author>Zhongliang Guo, Lei Fang, Jingyu Lin, Yifei Qian, Shuai Zhao, Zeyu Wang, Junhao Dong, Cunjian Chen, Ognjen Arandjelović, Chun Pong Lau</author><pubDate>Tue, 20 Aug 2024 14:43:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10901v1</guid></item><item><title>Towards Efficient Formal Verification of Spiking Neural Network</title><link>http://arxiv.org/abs/2408.10900v1</link><description>Recently, AI research has primarily focused on large language models (LLMs),and increasing accuracy often involves scaling up and consuming more power. Thepower consumption of AI has become a significant societal issue; in thiscontext, spiking neural networks (SNNs) offer a promising solution. SNNsoperate event-driven, like the human brain, and compress informationtemporally. These characteristics allow SNNs to significantly reduce powerconsumption compared to perceptron-based artificial neural networks (ANNs),highlighting them as a next-generation neural network technology. However,societal concerns regarding AI go beyond power consumption, with thereliability of AI models being a global issue. For instance, adversarialattacks on AI models are a well-studied problem in the context of traditionalneural networks. Despite their importance, the stability and propertyverification of SNNs remains in the early stages of research. Most SNNverification methods are time-consuming and barely scalable, making practicalapplications challenging. In this paper, we introduce temporal encoding toachieve practical performance in verifying the adversarial robustness of SNNs.We conduct a theoretical analysis of this approach and demonstrate its successin verifying SNNs at previously unmanageable scales. Our contribution advancesSNN verification to a practical level, facilitating the safer application ofSNNs.</description><author>Baekryun Seong, Jieung Kim, Sang-Ki Ko</author><pubDate>Tue, 20 Aug 2024 14:43:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10900v1</guid></item><item><title>Learning material synthesis-process-structure-property relationship by data fusion: Bayesian Coregionalization N-Dimensional Piecewise Function Learning</title><link>http://arxiv.org/abs/2311.06228v3</link><description>Autonomous materials research labs require the ability to combine and learnfrom diverse data streams. This is especially true for learning materialsynthesis-process-structure-property relationships, key to acceleratingmaterials optimization and discovery as well as accelerating mechanisticunderstanding. We present the Synthesis-process-structure-property relAtionshipcoreGionalized lEarner (SAGE) algorithm. A fully Bayesian algorithm that usesmultimodal coregionalization to merge knowledge across data sources to learnsynthesis-process-structure-property relationships. SAGE outputs aprobabilistic posterior for the relationships including the most likelyrelationships given the data.</description><author>A. Gilad Kusne, Austin McDannald, Brian DeCost</author><pubDate>Tue, 20 Aug 2024 14:42:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06228v3</guid></item><item><title>MagicID: Flexible ID Fidelity Generation System</title><link>http://arxiv.org/abs/2408.09248v2</link><description>Portrait Fidelity Generation is a prominent research area in generativemodels, with a primary focus on enhancing both controllability and fidelity.Current methods face challenges in generating high-fidelity portrait resultswhen faces occupy a small portion of the image with a low resolution,especially in multi-person group photo settings. To tackle these issues, wepropose a systematic solution called MagicID, based on a self-constructedmillion-level multi-modal dataset named IDZoom. MagicID consists of Multi-ModeFusion training strategy (MMF) and DDIM Inversion based ID Restorationinference framework (DIIR). During training, MMF iteratively uses the skeletonand landmark modalities from IDZoom as conditional guidance. By introducing theClone Face Tuning in training stage and Mask Guided Multi-ID Cross Attention(MGMICA) in inference stage, explicit constraints on face positional featuresare achieved for multi-ID group photo generation. The DIIR aims to address theissue of artifacts. The DDIM Inversion is used in conjunction with facelandmarks, global and local face features to achieve face restoration whilekeeping the background unchanged. Additionally, DIIR is plug-and-play and canbe applied to any diffusion-based portrait generation method. To validate theeffectiveness of MagicID, we conducted extensive comparative and ablationexperiments. The experimental results demonstrate that MagicID has significantadvantages in both subjective and objective metrics, and achieves controllablegeneration in multi-person scenarios.</description><author>Zhaoli Deng, Wen Liu, Fanyi Wang, Junkang Zhang, Fan Chen, Meng Zhang, Wendong Zhang, Zhenpeng Mi</author><pubDate>Tue, 20 Aug 2024 14:39:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09248v2</guid></item><item><title>Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models</title><link>http://arxiv.org/abs/2404.06209v2</link><description>While many have shown how Large Language Models (LLMs) can be applied to adiverse set of tasks, the critical issues of data contamination andmemorization are often glossed over. In this work, we address this concern fortabular data. Specifically, we introduce a variety of different techniques toassess whether a language model has seen a tabular dataset during training.This investigation reveals that LLMs have memorized many popular tabulardatasets verbatim. We then compare the few-shot learning performance of LLMs ondatasets that were seen during training to the performance on datasets releasedafter training. We find that LLMs perform better on datasets seen duringtraining, indicating that memorization leads to overfitting. At the same time,LLMs show non-trivial performance on novel datasets and are surprisingly robustto data transformations. We then investigate the in-context statisticallearning abilities of LLMs. While LLMs are significantly better than random atsolving statistical classification problems, the sample efficiency of few-shotlearning lags behind traditional statistical learning algorithms, especially asthe dimension of the problem increases. This suggests that much of the observedfew-shot performance on novel real-world datasets is due to the LLM's worldknowledge. Overall, our results highlight the importance of testing whether anLLM has seen an evaluation dataset during pre-training. We release thehttps://github.com/interpretml/LLM-Tabular-Memorization-Checker Python packageto test LLMs for memorization of tabular datasets.</description><author>Sebastian Bordt, Harsha Nori, Vanessa Rodrigues, Besmira Nushi, Rich Caruana</author><pubDate>Tue, 20 Aug 2024 14:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06209v2</guid></item><item><title>Using Unreliable Pseudo-Labels for Label-Efficient Semantic Segmentation</title><link>http://arxiv.org/abs/2306.02314v2</link><description>The crux of label-efficient semantic segmentation is to produce high-qualitypseudo-labels to leverage a large amount of unlabeled or weakly labeled data. Acommon practice is to select the highly confident predictions as thepseudo-ground-truths for each pixel, but it leads to a problem that most pixelsmay be left unused due to their unreliability. However, we argue that everypixel matters to the model training, even those unreliable and ambiguouspixels. Intuitively, an unreliable prediction may get confused among the topclasses, however, it should be confident about the pixel not belonging to theremaining classes. Hence, such a pixel can be convincingly treated as anegative key to those most unlikely categories. Therefore, we develop aneffective pipeline to make sufficient use of unlabeled data. Concretely, weseparate reliable and unreliable pixels via the entropy of predictions, pusheach unreliable pixel to a category-wise queue that consists of negative keys,and manage to train the model with all candidate pixels. Considering thetraining evolution, we adaptively adjust the threshold for thereliable-unreliable partition. Experimental results on various benchmarks andtraining settings demonstrate the superiority of our approach over thestate-of-the-art alternatives.</description><author>Haochen Wang, Yuchao Wang, Yujun Shen, Junsong Fan, Yuxi Wang, Zhaoxiang Zhang</author><pubDate>Tue, 20 Aug 2024 14:30:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02314v2</guid></item><item><title>Analytical and Empirical Study of Herding Effects in Recommendation Systems</title><link>http://arxiv.org/abs/2408.10895v1</link><description>Online rating systems are often used in numerous web or mobile applications,e.g., Amazon and TripAdvisor, to assess the ground-truth quality of products.Due to herding effects, the aggregation of historical ratings (or historicalcollective opinion) can significantly influence subsequent ratings, leading tomisleading and erroneous assessments. We study how to manage product ratingsvia rating aggregation rules and shortlisted representative reviews, for thepurpose of correcting the assessment error. We first develop a mathematicalmodel to characterize important factors of herding effects in product ratings.We then identify sufficient conditions (via the stochastic approximationtheory), under which the historical collective opinion converges to theground-truth collective opinion of the whole user population. These conditionsidentify a class of rating aggregation rules and review selection mechanismsthat can reveal the ground-truth product quality. We also quantify the speed ofconvergence (via the martingale theory), which reflects the efficiency ofrating aggregation rules and review selection mechanisms. We prove that theherding effects slow down the speed of convergence while an accurate reviewselection mechanism can speed it up. We also study the speed of convergencenumerically and reveal trade-offs in selecting rating aggregation rules andreview selection mechanisms. To show the utility of our framework, we design amaximum likelihood algorithm to infer model parameters from ratings, andconduct experiments on rating datasets from Amazon and TripAdvisor. We showthat proper recency aware rating aggregation rules can improve the speed ofconvergence in Amazon and TripAdvisor by 41% and 62% respectively.</description><author>Hong Xie, Mingze Zhong, Defu Lian, Zhen Wang, Enhong Chen</author><pubDate>Tue, 20 Aug 2024 14:29:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10895v1</guid></item><item><title>ViLReF: A Chinese Vision-Language Retinal Foundation Model</title><link>http://arxiv.org/abs/2408.10894v1</link><description>Subtle semantic differences in retinal image and text data present greatchallenges for pre-training visual-language models. Moreover, false negativesamples, i.e., image-text pairs having the same semantics but incorrectlyregarded as negatives, disrupt the visual-language pre-training process andaffect the model's learning ability. This work aims to develop a retinalfoundation model, called ViLReF, by pre-training on a paired dataset comprising451,956 retinal images and corresponding diagnostic text reports. In ourvision-language pre-training strategy, we leverage expert knowledge tofacilitate the extraction of labels and propose a novel constraint, theWeighted Similarity Coupling Loss, to adjust the speed of pushing sample pairsfurther apart dynamically within the feature space. Furthermore, we employ abatch expansion module with dynamic memory queues, maintained by momentumencoders, to supply extra samples and compensate for the vacancies caused byeliminating false negatives. Extensive experiments are conducted on multipledatasets for downstream classification and segmentation tasks. The experimentalresults demonstrate the powerful zero-shot and transfer learning capabilitiesof ViLReF, verifying the effectiveness of our pre-training strategy. Our ViLReFmodel is available at: https://github.com/T6Yang/ViLReF.</description><author>Shengzhu Yang, Jiawei Du, Jia Guo, Weihang Zhang, Hanruo Liu, Huiqi Li, Ningli Wang</author><pubDate>Tue, 20 Aug 2024 14:27:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10894v1</guid></item><item><title>On Learning Action Costs from Input Plans</title><link>http://arxiv.org/abs/2408.10889v1</link><description>Most of the work on learning action models focus on learning the actions'dynamics from input plans. This allows us to specify the valid plans of aplanning task. However, very little work focuses on learning action costs,which in turn allows us to rank the different plans. In this paper we introducea new problem: that of learning the costs of a set of actions such that a setof input plans are optimal under the resulting planning model. To solve thisproblem we present $LACFIP^k$, an algorithm to learn action's costs fromunlabeled input plans. We provide theoretical and empirical results showing how$LACFIP^k$ can successfully solve this task.</description><author>Marianela Morales, Alberto Pozanco, Giuseppe Canonaco, Sriram Gopalakrishnan, Daniel Borrajo, Manuela Veloso</author><pubDate>Tue, 20 Aug 2024 14:20:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10889v1</guid></item><item><title>Language-Guided Self-Supervised Video Summarization Using Text Semantic Matching Considering the Diversity of the Video</title><link>http://arxiv.org/abs/2405.08890v2</link><description>Current video summarization methods rely heavily on supervised computervision techniques, which demands time-consuming and subjective manualannotations. To overcome these limitations, we investigated self-supervisedvideo summarization. Inspired by the success of Large Language Models (LLMs),we explored the feasibility in transforming the video summarization task into aNatural Language Processing (NLP) task. By leveraging the advantages of LLMs incontext understanding, we aim to enhance the effectiveness of self-supervisedvideo summarization. Our method begins by generating captions for individualvideo frames, which are then synthesized into text summaries by LLMs.Subsequently, we measure semantic distance between the captions and the textsummary. Notably, we propose a novel loss function to optimize our modelaccording to the diversity of the video. Finally, the summarized video can begenerated by selecting the frames with captions similar to the text summary.Our method achieves state-of-the-art performance on the SumMe dataset in rankcorrelation coefficients. In addition, our method has a novel feature of beingable to achieve personalized summarization.</description><author>Tomoya Sugihara, Shuntaro Masuda, Ling Xiao, Toshihiko Yamasaki</author><pubDate>Tue, 20 Aug 2024 14:19:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08890v2</guid></item><item><title>Low-Quality Image Detection by Hierarchical VAE</title><link>http://arxiv.org/abs/2408.10885v1</link><description>To make an employee roster, photo album, or training dataset of generativemodels, one needs to collect high-quality images while dismissing low-qualityones. This study addresses a new task of unsupervised detection of low-qualityimages. We propose a method that not only detects low-quality images withvarious types of degradation but also provides visual clues of them based on anobservation that partial reconstruction by hierarchical variationalautoencoders fails for low-quality images. The experiments show that our methodoutperforms several unsupervised out-of-distribution detection methods and alsogives visual clues for low-quality images that help humans recognize them evenin thumbnail view.</description><author>Tomoyasu Nanaumi, Kazuhiko Kawamoto, Hiroshi Kera</author><pubDate>Tue, 20 Aug 2024 14:14:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10885v1</guid></item><item><title>DAAD: Dynamic Analysis and Adaptive Discriminator for Fake News Detection</title><link>http://arxiv.org/abs/2408.10883v1</link><description>In current web environment, fake news spreads rapidly across online socialnetworks, posing serious threats to society. Existing multimodal fake newsdetection (MFND) methods can be classified into knowledge-based andsemantic-based approaches. However, these methods are overly dependent on humanexpertise and feedback, lacking flexibility. To address this challenge, wepropose a Dynamic Analysis and Adaptive Discriminator (DAAD) approach for fakenews detection. For knowledge-based methods, we introduce the Monte Carlo TreeSearch (MCTS) algorithm to leverage the self-reflective capabilities of largelanguage models (LLMs) for prompt optimization, providing richer,domain-specific details and guidance to the LLMs, while enabling more flexibleintegration of LLM comment on news content. For semantic-based methods, wedefine four typical deceit patterns: emotional exaggeration, logicalinconsistency, image manipulation, and semantic inconsistency, to reveal themechanisms behind fake news creation. To detect these patterns, we carefullydesign four discriminators and expand them in depth and breadth, using thesoft-routing mechanism to explore optimal detection models. Experimentalresults on three real-world datasets demonstrate the superiority of ourapproach. The code will be available at: https://github.com/SuXinqi/DAAD.</description><author>Xinqi Su, Yawen Cui, Ajian Liu, Xun Lin, Yuhao Wang, Haochen Liang, Wenhui Li, Zitong Yu</author><pubDate>Tue, 20 Aug 2024 14:13:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10883v1</guid></item><item><title>Exploiting Defenses against GAN-Based Feature Inference Attacks in Federated Learning</title><link>http://arxiv.org/abs/2004.12571v3</link><description>Federated learning (FL) is a decentralized model training framework that aimsto merge isolated data islands while maintaining data privacy. However, recentstudies have revealed that Generative Adversarial Network (GAN) based attackscan be employed in FL to learn the distribution of private datasets andreconstruct recognizable images. In this paper, we exploit defenses againstGAN-based attacks in FL and propose a framework, Anti-GAN, to prevent attackersfrom learning the real distribution of the victim's data. The core idea ofAnti-GAN is to manipulate the visual features of private training images tomake them indistinguishable to human eyes even restored by attackers.Specifically, Anti-GAN projects the private dataset onto a GAN's generator andcombines the generated fake images with the actual images to create thetraining dataset, which is then used for federated model training. Theexperimental results demonstrate that Anti-GAN is effective in preventingattackers from learning the distribution of private images while causingminimal harm to the accuracy of the federated model.</description><author>Xinjian Luo, Xianglong Zhang</author><pubDate>Tue, 20 Aug 2024 14:11:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2004.12571v3</guid></item><item><title>Open 3D World in Autonomous Driving</title><link>http://arxiv.org/abs/2408.10880v1</link><description>The capability for open vocabulary perception represents a significantadvancement in autonomous driving systems, facilitating the comprehension andinterpretation of a wide array of textual inputs in real-time. Despiteextensive research in open vocabulary tasks within 2D computer vision, theapplication of such methodologies to 3D environments, particularly withinlarge-scale outdoor contexts, remains relatively underdeveloped. This paperpresents a novel approach that integrates 3D point cloud data, acquired fromLIDAR sensors, with textual information. The primary focus is on theutilization of textual data to directly localize and identify objects withinthe autonomous driving context. We introduce an efficient framework for thefusion of bird's-eye view (BEV) region features with textual features, therebyenabling the system to seamlessly adapt to novel textual inputs and enhancingthe robustness of open vocabulary detection tasks. The effectiveness of theproposed methodology is rigorously evaluated through extensive experimentationon the newly introduced NuScenes-T dataset, with additional validation of itszero-shot performance on the Lyft Level 5 dataset. This research makes asubstantive contribution to the advancement of autonomous driving technologiesby leveraging multimodal data to enhance open vocabulary perception in 3Denvironments, thereby pushing the boundaries of what is achievable inautonomous navigation and perception.</description><author>Xinlong Cheng, Lei Li</author><pubDate>Tue, 20 Aug 2024 14:10:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10880v1</guid></item><item><title>DBHP: Trajectory Imputation in Multi-Agent Sports Using Derivative-Based Hybrid Prediction</title><link>http://arxiv.org/abs/2408.10878v1</link><description>Many spatiotemporal domains handle multi-agent trajectory data, but inreal-world scenarios, collected trajectory data are often partially missing dueto various reasons. While existing approaches demonstrate good performance intrajectory imputation, they face challenges in capturing the complex dynamicsand interactions between agents due to a lack of physical constraints thatgovern realistic trajectories, leading to suboptimal results. To address thisissue, the paper proposes a Derivative-Based Hybrid Prediction (DBHP) frameworkthat can effectively impute multiple agents' missing trajectories. First, aneural network equipped with Set Transformers produces a naive prediction ofmissing trajectories while satisfying the permutation-equivariance in terms ofthe order of input agents. Then, the framework makes alternative predictionsleveraging velocity and acceleration information and combines all thepredictions with properly determined weights to provide final imputedtrajectories. In this way, our proposed framework not only accurately predictsposition, velocity, and acceleration values but also enforces the physicalrelationship between them, eventually improving both the accuracy andnaturalness of the predicted trajectories. Accordingly, the experiment resultsabout imputing player trajectories in team sports show that our frameworksignificantly outperforms existing imputation baselines.</description><author>Hanjun Choi, Hyunsung Kim, Minho Lee, Chang-Jo Kim, Jinsung Yoon, Sang-Ki Ko</author><pubDate>Tue, 20 Aug 2024 14:08:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10878v1</guid></item><item><title>BrainVis: Exploring the Bridge between Brain and Visual Signals via Image Reconstruction</title><link>http://arxiv.org/abs/2312.14871v2</link><description>Analyzing and reconstructing visual stimuli from brain signals effectivelyadvances the understanding of human visual system. However, the EEG signals arecomplex and contain significant noise. This leads to substantial limitations inexisting works of visual stimuli reconstruction from EEG, such as difficultiesin aligning EEG embeddings with the fine-grained semantic information and aheavy reliance on additional large self-collected dataset for training. Toaddress these challenges, we propose a novel approach called BrainVis. Firstly,we divide the EEG signals into various units and apply a self-supervisedapproach on them to obtain EEG time-domain features, in an attempt to ease thetraining difficulty. Additionally, we also propose to utilize thefrequency-domain features to enhance the EEG representations. Then, wesimultaneously align EEG time-frequency embeddings with the interpolation ofthe coarse and fine-grained semantics in the CLIP space, to highlight theprimary visual components and reduce the cross-modal alignment difficulty.Finally, we adopt the cascaded diffusion models to reconstruct images. Usingonly 10\% training data of the previous work, our proposed BrainVis outperformsstate of the arts in both semantic fidelity reconstruction and generationquality. The code is available at https://github.com/RomGai/BrainVis.</description><author>Honghao Fu, Zhiqi Shen, Jing Jih Chin, Hao Wang</author><pubDate>Tue, 20 Aug 2024 14:06:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14871v2</guid></item><item><title>More Options for Prelabor Rupture of Membranes, A Bayesian Analysis</title><link>http://arxiv.org/abs/2408.10876v1</link><description>An obstetric goal for a laboring mother is to achieve a vaginal delivery asit reduces the risks inherent in major abdominal surgery (i.e., a Cesareansection). Various medical interventions may be used by a physician to increasethe likelihood of this occurring while minimizing maternal and fetal morbidity.However, patients with prelabor rupture of membranes (PROM) have only twocommonly used options for cervical ripening, Pitocin and misoprostol. Littleresearch exists on the benefits/risks for these two key drugs for PROMpatients. A major limitation with most induction-of-labor related research isthe inability to account for differences in \textit{Bishop scores} that arecommonly used in obstetrical practice to determine the next induction agentoffered to the patient. This creates a confounding factor, which biases theresults, but has not been realized in the literature. In this work, we use aBayesian model of the relationships between the relevant factors, informed byexpert physicians, to separate the confounding variable from its actual impact.In doing so, we provide strong evidence that pitocin and buccal misoprostol areequally effective and safe; thus, physicians have more choice in clinical carethan previously realized. This is particularly important for developingcountries where neither medication may be readily available, and priorguidelines may create an artificial barrier to needed medication.</description><author>Ashley Klein, Edward Raff, Elisabeth Seamon, Lily Foley, Timothy Bussert</author><pubDate>Tue, 20 Aug 2024 14:05:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10876v1</guid></item><item><title>V-RoAst: A New Dataset for Visual Road Assessment</title><link>http://arxiv.org/abs/2408.10872v1</link><description>Road traffic crashes cause millions of deaths annually and have a significanteconomic impact, particularly in low- and middle-income countries (LMICs). Thispaper presents an approach using Vision Language Models (VLMs) for road safetyassessment, overcoming the limitations of traditional Convolutional NeuralNetworks (CNNs). We introduce a new task ,V-RoAst (Visual question answeringfor Road Assessment), with a real-world dataset. Our approach optimizes promptengineering and evaluates advanced VLMs, including Gemini-1.5-flash andGPT-4o-mini. The models effectively examine attributes for road assessment.Using crowdsourced imagery from Mapillary, our scalable solution influentiallyestimates road safety levels. In addition, this approach is designed for localstakeholders who lack resources, as it does not require training data. Itoffers a cost-effective and automated methods for global road safetyassessments, potentially saving lives and reducing economic burdens.</description><author>Natchapon Jongwiriyanurak, Zichao Zeng, June Moh Goo, Xinglei Wang, Ilya Ilyankou, Kerkritt Srirrongvikrai, Meihui Wang, James Haworth</author><pubDate>Tue, 20 Aug 2024 14:03:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10872v1</guid></item><item><title>Radio U-Net: a convolutional neural network to detect diffuse radio sources in galaxy clusters and beyond</title><link>http://arxiv.org/abs/2408.10871v1</link><description>The forthcoming generation of radio telescope arrays promises significantadvancements in sensitivity and resolution, enabling the identification andcharacterization of many new faint and diffuse radio sources. Conventionalmanual cataloging methodologies are anticipated to be insufficient to exploitthe capabilities of new radio surveys. Radio interferometric images of diffusesources present a challenge for image segmentation tasks due to noise,artifacts, and embedded radio sources. In response to these challenges, weintroduce Radio U-Net, a fully convolutional neural network based on the U-Netarchitecture. Radio U-Net is designed to detect faint and extended sources inradio surveys, such as radio halos, relics, and cosmic web filaments. RadioU-Net was trained on synthetic radio observations built upon cosmologicalsimulations and then tested on a sample of galaxy clusters, where the detectionof cluster diffuse radio sources relied on customized data reduction and visualinspection of LOFAR Two Metre Sky Survey (LoTSS) data. The 83% of clustersexhibiting diffuse radio emission were accurately identified, and thesegmentation successfully recovered the morphology of the sources even inlow-quality images. In a test sample comprising 246 galaxy clusters, weachieved a 73% accuracy rate in distinguishing between clusters with andwithout diffuse radio emission. Our results establish the applicability ofRadio U-Net to extensive radio survey datasets, probing its efficiency oncutting-edge high-performance computing systems. This approach represents anadvancement in optimizing the exploitation of forthcoming large radio surveysfor scientific exploration.</description><author>Chiara Stuardi, Claudio Gheller, Franco Vazza, Andrea Botteon</author><pubDate>Tue, 20 Aug 2024 14:03:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10871v1</guid></item><item><title>Multi-agent Multi-armed Bandits with Stochastic Sharable Arm Capacities</title><link>http://arxiv.org/abs/2408.10865v1</link><description>Motivated by distributed selection problems, we formulate a new variant ofmulti-player multi-armed bandit (MAB) model, which captures stochastic arrivalof requests to each arm, as well as the policy of allocating requests toplayers. The challenge is how to design a distributed learning algorithm suchthat players select arms according to the optimal arm pulling profile (an armpulling profile prescribes the number of players at each arm) withoutcommunicating to each other. We first design a greedy algorithm, which locatesone of the optimal arm pulling profiles with a polynomial computationalcomplexity. We also design an iterative distributed algorithm for players tocommit to an optimal arm pulling profile with a constant number of rounds inexpectation. We apply the explore then commit (ETC) framework to address theonline setting when model parameters are unknown. We design an explorationstrategy for players to estimate the optimal arm pulling profile. Since suchestimates can be different across different players, it is challenging forplayers to commit. We then design an iterative distributed algorithm, whichguarantees that players can arrive at a consensus on the optimal arm pullingprofile in only M rounds. We conduct experiments to validate our algorithm.</description><author>Hong Xie, Jinyu Mo, Defu Lian, Jie Wang, Enhong Chen</author><pubDate>Tue, 20 Aug 2024 13:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10865v1</guid></item><item><title>SUBER: An RL Environment with Simulated Human Behavior for Recommender Systems</title><link>http://arxiv.org/abs/2406.01631v2</link><description>Reinforcement learning (RL) has gained popularity in the realm of recommendersystems due to its ability to optimize long-term rewards and guide users indiscovering relevant content. However, the successful implementation of RL inrecommender systems is challenging because of several factors, including thelimited availability of online data for training on-policy methods. Thisscarcity requires expensive human interaction for online model training.Furthermore, the development of effective evaluation frameworks that accuratelyreflect the quality of models remains a fundamental challenge in recommendersystems. To address these challenges, we propose a comprehensive framework forsynthetic environments that simulate human behavior by harnessing thecapabilities of large language models (LLMs). We complement our framework within-depth ablation studies and demonstrate its effectiveness with experiments onmovie and book recommendations. Using LLMs as synthetic users, this workintroduces a modular and novel framework to train RL-based recommender systems.The software, including the RL environment, is publicly available on GitHub.</description><author>Nathan Corecco, Giorgio Piatti, Luca A. Lanzendörfer, Flint Xiaofeng Fan, Roger Wattenhofer</author><pubDate>Tue, 20 Aug 2024 13:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01631v2</guid></item></channel></rss>