<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 17 Mar 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>GroupContrast: Semantic-aware Self-supervised Representation Learning for 3D Understanding</title><link>http://arxiv.org/abs/2403.09639v1</link><description>Self-supervised 3D representation learning aims to learn effectiverepresentations from large-scale unlabeled point clouds. Most existingapproaches adopt point discrimination as the pretext task, which assignsmatched points in two distinct views as positive pairs and unmatched points asnegative pairs. However, this approach often results in semantically identicalpoints having dissimilar representations, leading to a high number of falsenegatives and introducing a "semantic conflict" problem. To address this issue,we propose GroupContrast, a novel approach that combines segment grouping andsemantic-aware contrastive learning. Segment grouping partitions points intosemantically meaningful regions, which enhances semantic coherence and providessemantic guidance for the subsequent contrastive representation learning.Semantic-aware contrastive learning augments the semantic information extractedfrom segment grouping and helps to alleviate the issue of "semantic conflict".We conducted extensive experiments on multiple 3D scene understanding tasks.The results demonstrate that GroupContrast learns semantically meaningfulrepresentations and achieves promising transfer learning performance.</description><author>Chengyao Wang, Li Jiang, Xiaoyang Wu, Zhuotao Tian, Bohao Peng, Hengshuang Zhao, Jiaya Jia</author><pubDate>Thu, 14 Mar 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09639v1</guid></item><item><title>SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior</title><link>http://arxiv.org/abs/2403.09638v1</link><description>Semantic image synthesis (SIS) shows good promises for sensor simulation.However, current best practices in this field, based on GANs, have not yetreached the desired level of quality. As latent diffusion models makesignificant strides in image generation, we are prompted to evaluateControlNet, a notable method for its dense control capabilities. Ourinvestigation uncovered two primary issues with its results: the presence ofweird sub-structures within large semantic areas and the misalignment ofcontent with the semantic mask. Through empirical study, we pinpointed thecause of these problems as a mismatch between the noised training datadistribution and the standard normal prior applied at the inference stage. Toaddress this challenge, we developed specific noise priors for SIS,encompassing spatial, categorical, and a novel spatial-categorical joint priorfor inference. This approach, which we have named SCP-Diff, has yieldedexceptional results, achieving an FID of 10.53 on Cityscapes and 12.66 onADE20K.The code and models can be accessed via the project page.</description><author>Huan-ang Gao, Mingju Gao, Jiaju Li, Wenyi Li, Rong Zhi, Hao Tang, Hao Zhao</author><pubDate>Thu, 14 Mar 2024 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09638v1</guid></item><item><title>GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping</title><link>http://arxiv.org/abs/2403.09637v1</link><description>Constructing a 3D scene capable of accommodating open-ended language queries,is a pivotal pursuit, particularly within the domain of robotics. Suchtechnology facilitates robots in executing object manipulations based on humanlanguage directives. To tackle this challenge, some research efforts have beendedicated to the development of language-embedded implicit fields. However,implicit fields (e.g. NeRF) encounter limitations due to the necessity ofprocessing a large number of input views for reconstruction, coupled with theirinherent inefficiencies in inference. Thus, we present the GaussianGrasper,which utilizes 3D Gaussian Splatting to explicitly represent the scene as acollection of Gaussian primitives. Our approach takes a limited set of RGB-Dviews and employs a tile-based splatting technique to create a feature field.In particular, we propose an Efficient Feature Distillation (EFD) module thatemploys contrastive learning to efficiently and accurately distill languageembeddings derived from foundational models. With the reconstructed geometry ofthe Gaussian field, our method enables the pre-trained grasping model togenerate collision-free grasp pose candidates. Furthermore, we propose anormal-guided grasp module to select the best grasp pose. Through comprehensivereal-world experiments, we demonstrate that GaussianGrasper enables robots toaccurately query and grasp objects with language instructions, providing a newsolution for language-guided manipulation tasks. Data and codes can beavailable at https://github.com/MrSecant/GaussianGrasper.</description><author>Yuhang Zheng, Xiangyu Chen, Yupeng Zheng, Songen Gu, Runyi Yang, Bu Jin, Pengfei Li, Chengliang Zhong, Zengmao Wang, Lina Liu, Chao Yang, Dawei Wang, Zhen Chen, Xiaoxiao Long, Meiqing Wang</author><pubDate>Thu, 14 Mar 2024 18:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09637v1</guid></item><item><title>A Data Perspective on Enhanced Identity Preservation for Diffusion Personalization</title><link>http://arxiv.org/abs/2311.04315v3</link><description>Large text-to-image models have revolutionized the ability to generateimagery using natural language. However, particularly unique or personal visualconcepts, such as pets and furniture, will not be captured by the originalmodel. This has led to interest in how to personalize a text-to-image model.Despite significant progress, this task remains a formidable challenge,particularly in preserving the subject's identity. Most researchers attempt toaddress this issue by modifying model architectures. These methods are capableof keeping the subject structure and color but fail to preserve identitydetails. Towards this issue, our approach takes a data-centric perspective. Weintroduce a novel regularization dataset generation strategy on both the textand image level. This strategy enables the model to preserve fine details ofthe desired subjects, such as text and logos. Our method isarchitecture-agnostic and can be flexibly applied on various text-to-imagemodels. We show on established benchmarks that our data-centric approach formsthe new state of the art in terms of identity preservation and text alignment.</description><author>Xingzhe He, Zhiwen Cao, Nicholas Kolkin, Lantao Yu, Kun Wan, Helge Rhodin, Ratheesh Kalarot</author><pubDate>Thu, 14 Mar 2024 18:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04315v3</guid></item><item><title>Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference</title><link>http://arxiv.org/abs/2403.09636v1</link><description>Transformers have emerged as the backbone of large language models (LLMs).However, generation remains inefficient due to the need to store in memory acache of key-value representations for past tokens, whose size scales linearlywith the input sequence length and batch size. As a solution, we proposeDynamic Memory Compression (DMC), a method for on-line key-value cachecompression at inference time. Most importantly, the model learns to applydifferent compression rates in different heads and layers. We retrofitpre-trained LLMs such as Llama 2 (7B, 13B and 70B) into DMC Transformers,achieving up to ~3.7x throughput increase in auto-regressive inference on aNVIDIA H100 GPU. DMC is applied via continued pre-training on a negligiblepercentage of the original data without adding any extra parameters. We findthat DMC preserves the original downstream performance with up to 4x cachecompression, outperforming up-trained grouped-query attention (GQA). GQA andDMC can be even combined to obtain compounded gains. As a result DMC fitslonger contexts and larger batches within any given memory budget.</description><author>Piotr Nawrot, Adrian Łańcucki, Marcin Chochowski, David Tarjan, Edoardo M. Ponti</author><pubDate>Thu, 14 Mar 2024 18:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09636v1</guid></item><item><title>Transformers Get Stable: An End-to-End Signal Propagation Theory for Language Models</title><link>http://arxiv.org/abs/2403.09635v1</link><description>In spite of their huge success, transformer models remain difficult to scalein depth. In this work, we develop a unified signal propagation theory andprovide formulae that govern the moments of the forward and backward signalthrough the transformer model. Our framework can be used to understand andmitigate vanishing/exploding gradients, rank collapse, and instabilityassociated with high attention scores. We also propose DeepScaleLM, aninitialization and scaling scheme that conserves unit output/gradient momentsthroughout the model, enabling the training of very deep models with 100s oflayers. We find that transformer models could be much deeper - our deep modelswith fewer parameters outperform shallow models in Language Modeling, SpeechTranslation, and Image Classification, across Encoder-only, Decoder-only andEncoder-Decoder variants, for both Pre-LN and Post-LN transformers, formultiple datasets and model sizes. These improvements also translate intoimproved performance on downstream Question Answering tasks and improvedrobustness for image classification.</description><author>Akhil Kedia, Mohd Abbas Zaidi, Sushil Khyalia, Jungho Jung, Harshith Goka, Haejun Lee</author><pubDate>Thu, 14 Mar 2024 18:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09635v1</guid></item><item><title>OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning</title><link>http://arxiv.org/abs/2403.09634v1</link><description>Visual object tracking aims to localize the target object of each frame basedon its initial appearance in the first frame. Depending on the input modility,tracking tasks can be divided into RGB tracking and RGB+X (e.g. RGB+N, andRGB+D) tracking. Despite the different input modalities, the core aspect oftracking is the temporal matching. Based on this common ground, we present ageneral framework to unify various tracking tasks, termed as OneTracker.OneTracker first performs a large-scale pre-training on a RGB tracker calledFoundation Tracker. This pretraining phase equips the Foundation Tracker with astable ability to estimate the location of the target object. Then we regardother modality information as prompt and build Prompt Tracker upon FoundationTracker. Through freezing the Foundation Tracker and only adjusting someadditional trainable parameters, Prompt Tracker inhibits the stronglocalization ability from Foundation Tracker and achieves parameter-efficientfinetuning on downstream RGB+X tracking tasks. To evaluate the effectiveness ofour general framework OneTracker, which is consisted of Foundation Tracker andPrompt Tracker, we conduct extensive experiments on 6 popular tracking tasksacross 11 benchmarks and our OneTracker outperforms other models and achievesstate-of-the-art performance.</description><author>Lingyi Hong, Shilin Yan, Renrui Zhang, Wanyun Li, Xinyu Zhou, Pinxue Guo, Kaixun Jiang, Yiting Chen, Jinglun Li, Zhaoyu Chen, Wenqiang Zhang</author><pubDate>Thu, 14 Mar 2024 18:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09634v1</guid></item><item><title>Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image</title><link>http://arxiv.org/abs/2403.09632v1</link><description>At the core of portrait photography is the search for ideal lighting andviewpoint. The process often requires advanced knowledge in photography and anelaborate studio setup. In this work, we propose Holo-Relighting, a volumetricrelighting method that is capable of synthesizing novel viewpoints, and novellighting from a single image. Holo-Relighting leverages the pretrained 3D GAN(EG3D) to reconstruct geometry and appearance from an input portrait as a setof 3D-aware features. We design a relighting module conditioned on a givenlighting to process these features, and predict a relit 3D representation inthe form of a tri-plane, which can render to an arbitrary viewpoint throughvolume rendering. Besides viewpoint and lighting control, Holo-Relighting alsotakes the head pose as a condition to enable head-pose-dependent lightingeffects. With these novel designs, Holo-Relighting can generate complexnon-Lambertian lighting effects (e.g., specular highlights and cast shadows)without using any explicit physical lighting priors. We train Holo-Relightingwith data captured with a light stage, and propose two data-renderingtechniques to improve the data quality for training the volumetric relightingsystem. Through quantitative and qualitative experiments, we demonstrateHolo-Relighting can achieve state-of-the-arts relighting quality with betterphotorealism, 3D consistency and controllability.</description><author>Yiqun Mei, Yu Zeng, He Zhang, Zhixin Shu, Xuaner Zhang, Sai Bi, Jianming Zhang, HyunJoon Jung, Vishal M. Patel</author><pubDate>Thu, 14 Mar 2024 18:58:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09632v1</guid></item><item><title>CacheGen: Fast Context Loading for Language Model Applications via KV Cache Streaming</title><link>http://arxiv.org/abs/2310.07240v3</link><description>As large language models (LLMs) take on complex tasks, their inputs aresupplemented with longer contexts that incorporate domain knowledge oruser-specific information. Yet using long contexts poses a challenge forresponsive LLM systems, as nothing can be generated until the whole context isprocessed by the LLM. While the context-processing delay can be reduced byreusing the KV cache of a context across different inputs, fetching the KVcache, which contains large tensors, over the network can cause extra networkdelays. CacheGen is a fast context-loading module for LLM systems. First, CacheGenuses a custom tensor encoder, which embraces KV cache's distributionalproperties, to encode a KV cache into more compact bitstream representationswith negligible encoding/decoding overhead. This reduces the bandwidth demandto fetch the KV cache. Second, to maintain low context-loading delay and highgeneration quality, CacheGen adapts the streaming strategies to cope withchanges in available bandwidth. When available bandwidth drops, CacheGen mayraise the compression level for a part of the context or choose to recomputeits KV cache on the fly. We test CacheGen on four popular LLMs of various sizesand four datasets (662 contexts in total). Compared to the recent systems thatreuse the KV cache, CacheGen reduces the KV cache size by 3.7-4.3x and thetotal delay in fetching and processing contexts by 2.7-3.2x while havingnegligible impact on the LLM response quality in accuracy or perplexity.</description><author>Yuhan Liu, Hanchen Li, Yihua Cheng, Siddhant Ray, Yuyang Huang, Qizheng Zhang, Kuntai Du, Jiayi Yao, Shan Lu, Ganesh Ananthanarayanan, Michael Maire, Henry Hoffmann, Ari Holtzman, Junchen Jiang</author><pubDate>Thu, 14 Mar 2024 18:58:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07240v3</guid></item><item><title>3D-VLA: A 3D Vision-Language-Action Generative World Model</title><link>http://arxiv.org/abs/2403.09631v1</link><description>Recent vision-language-action (VLA) models rely on 2D inputs, lackingintegration with the broader realm of the 3D physical world. Furthermore, theyperform action prediction by learning a direct mapping from perception toaction, neglecting the vast dynamics of the world and the relations betweenactions and dynamics. In contrast, human beings are endowed with world modelsthat depict imagination about future scenarios to plan actions accordingly. Tothis end, we propose 3D-VLA by introducing a new family of embodied foundationmodels that seamlessly link 3D perception, reasoning, and action through agenerative world model. Specifically, 3D-VLA is built on top of a 3D-basedlarge language model (LLM), and a set of interaction tokens is introduced toengage with the embodied environment. Furthermore, to inject generationabilities into the model, we train a series of embodied diffusion models andalign them into the LLM for predicting the goal images and point clouds. Totrain our 3D-VLA, we curate a large-scale 3D embodied instruction dataset byextracting vast 3D-related information from existing robotics datasets. Ourexperiments on held-in datasets demonstrate that 3D-VLA significantly improvesthe reasoning, multimodal generation, and planning capabilities in embodiedenvironments, showcasing its potential in real-world applications.</description><author>Haoyu Zhen, Xiaowen Qiu, Peihao Chen, Jincheng Yang, Xin Yan, Yilun Du, Yining Hong, Chuang Gan</author><pubDate>Thu, 14 Mar 2024 18:58:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09631v1</guid></item><item><title>Sharp bounds for max-sliced Wasserstein distances</title><link>http://arxiv.org/abs/2403.00666v2</link><description>We obtain essentially matching upper and lower bounds for the expectedmax-sliced 1-Wasserstein distance between a probability measure on a separableHilbert space and its empirical distribution from $n$ samples. By proving aBanach space version of this result, we also obtain an upper bound, that issharp up to a log factor, for the expected max-sliced 2-Wasserstein distancebetween a symmetric probability measure $\mu$ on a Euclidean space and itssymmetrized empirical distribution in terms of the norm of the covariancematrix of $\mu$ and the diameter of the support of $\mu$.</description><author>March T. Boedihardjo</author><pubDate>Thu, 14 Mar 2024 18:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00666v2</guid></item><item><title>Generalized Predictive Model for Autonomous Driving</title><link>http://arxiv.org/abs/2403.09630v1</link><description>In this paper, we introduce the first large-scale video prediction model inthe autonomous driving discipline. To eliminate the restriction of high-costdata collection and empower the generalization ability of our model, we acquiremassive data from the web and pair it with diverse and high-quality textdescriptions. The resultant dataset accumulates over 2000 hours of drivingvideos, spanning areas all over the world with diverse weather conditions andtraffic scenarios. Inheriting the merits from recent latent diffusion models,our model, dubbed GenAD, handles the challenging dynamics in driving sceneswith novel temporal reasoning blocks. We showcase that it can generalize tovarious unseen driving datasets in a zero-shot manner, surpassing general ordriving-specific video prediction counterparts. Furthermore, GenAD can beadapted into an action-conditioned prediction model or a motion planner,holding great potential for real-world driving applications.</description><author>Jiazhi Yang, Shenyuan Gao, Yihang Qiu, Li Chen, Tianyu Li, Bo Dai, Kashyap Chitta, Penghao Wu, Jia Zeng, Ping Luo, Jun Zhang, Andreas Geiger, Yu Qiao, Hongyang Li</author><pubDate>Thu, 14 Mar 2024 18:58:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09630v1</guid></item><item><title>Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking</title><link>http://arxiv.org/abs/2403.09629v1</link><description>When writing and talking, people sometimes pause to think. Althoughreasoning-focused works have often framed reasoning as a method of answeringquestions or completing agentic tasks, reasoning is implicit in almost allwritten text. For example, this applies to the steps not stated between thelines of a proof or to the theory of mind underlying a conversation. In theSelf-Taught Reasoner (STaR, Zelikman et al. 2022), useful thinking is learnedby inferring rationales from few-shot examples in question-answering andlearning from those that lead to a correct answer. This is a highly constrainedsetting -- ideally, a language model could instead learn to infer unstatedrationales in arbitrary text. We present Quiet-STaR, a generalization of STaRin which LMs learn to generate rationales at each token to explain future text,improving their predictions. We address key challenges, including 1) thecomputational cost of generating continuations, 2) the fact that the LM doesnot initially know how to generate or use internal thoughts, and 3) the need topredict beyond individual next tokens. To resolve these, we propose a tokenwiseparallel sampling algorithm, using learnable tokens indicating a thought'sstart and end, and an extended teacher-forcing technique. Encouragingly,generated rationales disproportionately help model difficult-to-predict tokensand improve the LM's ability to directly answer difficult questions. Inparticular, after continued pretraining of an LM on a corpus of internet textwith Quiet-STaR, we find zero-shot improvements on GSM8K(5.9%$\rightarrow$10.9%) and CommonsenseQA (36.3%$\rightarrow$47.2%) andobserve a perplexity improvement of difficult tokens in natural text.Crucially, these improvements require no fine-tuning on these tasks. Quiet-STaRmarks a step towards LMs that can learn to reason in a more general andscalable way.</description><author>Eric Zelikman, Georges Harik, Yijia Shao, Varuna Jayasiri, Nick Haber, Noah D. Goodman</author><pubDate>Thu, 14 Mar 2024 18:58:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09629v1</guid></item><item><title>HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting</title><link>http://arxiv.org/abs/2311.17061v2</link><description>Realistic 3D human generation from text prompts is a desirable yetchallenging task. Existing methods optimize 3D representations like mesh orneural fields via score distillation sampling (SDS), which suffers frominadequate fine details or excessive training time. In this paper, we proposean efficient yet effective framework, HumanGaussian, that generateshigh-quality 3D humans with fine-grained geometry and realistic appearance. Ourkey insight is that 3D Gaussian Splatting is an efficient renderer withperiodic Gaussian shrinkage or growing, where such adaptive density control canbe naturally guided by intrinsic human structures. Specifically, 1) we firstpropose a Structure-Aware SDS that simultaneously optimizes human appearanceand geometry. The multi-modal score function from both RGB and depth space isleveraged to distill the Gaussian densification and pruning process. 2)Moreover, we devise an Annealed Negative Prompt Guidance by decomposing SDSinto a noisier generative score and a cleaner classifier score, which welladdresses the over-saturation issue. The floating artifacts are furthereliminated based on Gaussian size in a prune-only phase to enhance generationsmoothness. Extensive experiments demonstrate the superior efficiency andcompetitive quality of our framework, rendering vivid 3D humans under diversescenarios. Project Page: https://alvinliu0.github.io/projects/HumanGaussian</description><author>Xian Liu, Xiaohang Zhan, Jiaxiang Tang, Ying Shan, Gang Zeng, Dahua Lin, Xihui Liu, Ziwei Liu</author><pubDate>Thu, 14 Mar 2024 18:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17061v2</guid></item><item><title>Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding</title><link>http://arxiv.org/abs/2403.09626v1</link><description>Understanding videos is one of the fundamental directions in computer visionresearch, with extensive efforts dedicated to exploring various architecturessuch as RNN, 3D CNN, and Transformers. The newly proposed architecture of statespace model, e.g., Mamba, shows promising traits to extend its success in longsequence modeling to video modeling. To assess whether Mamba can be a viablealternative to Transformers in the video understanding domain, in this work, weconduct a comprehensive set of studies, probing different roles Mamba can playin modeling videos, while investigating diverse tasks where Mamba could exhibitsuperiority. We categorize Mamba into four roles for modeling videos, derivinga Video Mamba Suite composed of 14 models/modules, and evaluating them on 12video understanding tasks. Our extensive experiments reveal the strongpotential of Mamba on both video-only and video-language tasks while showingpromising efficiency-performance trade-offs. We hope this work could providevaluable data points and insights for future research on video understanding.Code is public: https://github.com/OpenGVLab/video-mamba-suite.</description><author>Guo Chen, Yifei Huang, Jilan Xu, Baoqi Pei, Zhe Chen, Zhiqi Li, Jiahao Wang, Kunchang Li, Tong Lu, Limin Wang</author><pubDate>Thu, 14 Mar 2024 18:57:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09626v1</guid></item><item><title>Make-Your-3D: Fast and Consistent Subject-Driven 3D Content Generation</title><link>http://arxiv.org/abs/2403.09625v1</link><description>Recent years have witnessed the strong power of 3D generation models, whichoffer a new level of creative flexibility by allowing users to guide the 3Dcontent generation process through a single image or natural language. However,it remains challenging for existing 3D generation methods to createsubject-driven 3D content across diverse prompts. In this paper, we introduce anovel 3D customization method, dubbed Make-Your-3D that can personalizehigh-fidelity and consistent 3D content from only a single image of a subjectwith text description within 5 minutes. Our key insight is to harmonize thedistributions of a multi-view diffusion model and an identity-specific 2Dgenerative model, aligning them with the distribution of the desired 3Dsubject. Specifically, we design a co-evolution framework to reduce thevariance of distributions, where each model undergoes a process of learningfrom the other through identity-aware optimization and subject-prioroptimization, respectively. Extensive experiments demonstrate that our methodcan produce high-quality, consistent, and subject-specific 3D content withtext-driven modifications that are unseen in subject image.</description><author>Fangfu Liu, Hanyang Wang, Weiliang Chen, Haowen Sun, Yueqi Duan</author><pubDate>Thu, 14 Mar 2024 18:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09625v1</guid></item><item><title>Score-Guided Diffusion for 3D Human Recovery</title><link>http://arxiv.org/abs/2403.09623v1</link><description>We present Score-Guided Human Mesh Recovery (ScoreHMR), an approach forsolving inverse problems for 3D human pose and shape reconstruction. Theseinverse problems involve fitting a human body model to image observations,traditionally solved through optimization techniques. ScoreHMR mimics modelfitting approaches, but alignment with the image observation is achievedthrough score guidance in the latent space of a diffusion model. The diffusionmodel is trained to capture the conditional distribution of the human modelparameters given an input image. By guiding its denoising process with atask-specific score, ScoreHMR effectively solves inverse problems for variousapplications without the need for retraining the task-agnostic diffusion model.We evaluate our approach on three settings/applications. These are: (i)single-frame model fitting; (ii) reconstruction from multiple uncalibratedviews; (iii) reconstructing humans in video sequences. ScoreHMR consistentlyoutperforms all optimization baselines on popular benchmarks across allsettings. We make our code and models available at thehttps://statho.github.io/ScoreHMR.</description><author>Anastasis Stathopoulos, Ligong Han, Dimitris Metaxas</author><pubDate>Thu, 14 Mar 2024 18:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09623v1</guid></item><item><title>Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering</title><link>http://arxiv.org/abs/2403.09622v1</link><description>Visual text rendering poses a fundamental challenge for contemporarytext-to-image generation models, with the core problem lying in text encoderdeficiencies. To achieve accurate text rendering, we identify two crucialrequirements for text encoders: character awareness and alignment with glyphs.Our solution involves crafting a series of customized text encoder, Glyph-ByT5,by fine-tuning the character-aware ByT5 encoder using a meticulously curatedpaired glyph-text dataset. We present an effective method for integratingGlyph-ByT5 with SDXL, resulting in the creation of the Glyph-SDXL model fordesign image generation. This significantly enhances text rendering accuracy,improving it from less than $20\%$ to nearly $90\%$ on our design imagebenchmark. Noteworthy is Glyph-SDXL's newfound ability for text paragraphrendering, achieving high spelling accuracy for tens to hundreds of characterswith automated multi-line layouts. Finally, through fine-tuning Glyph-SDXL witha small set of high-quality, photorealistic images featuring visual text, weshowcase a substantial improvement in scene text rendering capabilities inopen-domain real images. These compelling outcomes aim to encourage furtherexploration in designing customized text encoders for diverse and challengingtasks.</description><author>Zeyu Liu, Weicong Liang, Zhanhao Liang, Chong Luo, Ji Li, Gao Huang, Yuhui Yuan</author><pubDate>Thu, 14 Mar 2024 18:55:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09622v1</guid></item><item><title>Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2403.09621v1</link><description>Distributionally robust offline reinforcement learning (RL), which seeksrobust policy training against environment perturbation by modeling dynamicsuncertainty, calls for function approximations when facing large state-actionspaces. However, the consideration of dynamics uncertainty introduces essentialnonlinearity and computational burden, posing unique challenges for analyzingand practically employing function approximation. Focusing on a basic settingwhere the nominal model and perturbed models are linearly parameterized, wepropose minimax optimal and computationally efficient algorithms realizingfunction approximation and initiate the study on instance-dependentsuboptimality analysis in the context of robust offline RL. Our results uncoverthat function approximation in robust offline RL is essentially distinct fromand probably harder than that in standard offline RL. Our algorithms andtheoretical results crucially depend on a variety of new techniques, involvinga novel function approximation mechanism incorporating variance information, anew procedure of suboptimality and estimation uncertainty decomposition, aquantification of the robust value function shrinkage, and a meticulouslydesigned family of hard instances, which might be of independent interest.</description><author>Zhishuai Liu, Pan Xu</author><pubDate>Thu, 14 Mar 2024 18:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09621v1</guid></item><item><title>PosSAM: Panoptic Open-vocabulary Segment Anything</title><link>http://arxiv.org/abs/2403.09620v1</link><description>In this paper, we introduce an open-vocabulary panoptic segmentation modelthat effectively unifies the strengths of the Segment Anything Model (SAM) withthe vision-language CLIP model in an end-to-end framework. While SAM excels ingenerating spatially-aware masks, it's decoder falls short in recognizingobject class information and tends to oversegment without additional guidance.Existing approaches address this limitation by using multi-stage techniques andemploying separate models to generate class-aware prompts, such as boundingboxes or segmentation masks. Our proposed method, PosSAM is an end-to-end modelwhich leverages SAM's spatially rich features to produce instance-aware masksand harnesses CLIP's semantically discriminative features for effectiveinstance classification. Specifically, we address the limitations of SAM andpropose a novel Local Discriminative Pooling (LDP) module leveragingclass-agnostic SAM and class-aware CLIP features for unbiased open-vocabularyclassification. Furthermore, we introduce a Mask-Aware Selective Ensembling(MASE) algorithm that adaptively enhances the quality of generated masks andboosts the performance of open-vocabulary classification during inference foreach image. We conducted extensive experiments to demonstrate our methodsstrong generalization properties across multiple datasets, achievingstate-of-the-art performance with substantial improvements over SOTAopen-vocabulary panoptic segmentation methods. In both COCO to ADE20K andADE20K to COCO settings, PosSAM outperforms the previous state-of-the-artmethods by a large margin, 2.4 PQ and 4.6 PQ, respectively. Project Website:https://vibashan.github.io/possam-web/.</description><author>Vibashan VS, Shubhankar Borse, Hyojin Park, Debasmit Das, Vishal Patel, Munawar Hayat, Fatih Porikli</author><pubDate>Thu, 14 Mar 2024 18:55:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09620v1</guid></item><item><title>Explore In-Context Segmentation via Latent Diffusion Models</title><link>http://arxiv.org/abs/2403.09616v1</link><description>In-context segmentation has drawn more attention with the introduction ofvision foundation models. Most existing approaches adopt metric learning ormasked image modeling to build the correlation between visual prompts and inputimage queries. In this work, we explore this problem from a new perspective,using one representative generation model, the latent diffusion model (LDM). Weobserve a task gap between generation and segmentation in diffusion models, butLDM is still an effective minimalist for in-context segmentation. Inparticular, we propose two meta-architectures and correspondingly designseveral output alignment and optimization strategies. We have conductedcomprehensive ablation studies and empirically found that the segmentationquality counts on output alignment and in-context instructions. Moreover, webuild a new and fair in-context segmentation benchmark that includes both imageand video datasets. Experiments validate the efficiency of our approach,demonstrating comparable or even stronger results than previous specialistmodels or visual foundation models. Our study shows that LDMs can also achievegood enough results for challenging in-context segmentation tasks.</description><author>Chaoyang Wang, Xiangtai Li, Henghui Ding, Lu Qi, Jiangning Zhang, Yunhai Tong, Chen Change Loy, Shuicheng Yan</author><pubDate>Thu, 14 Mar 2024 18:52:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09616v1</guid></item><item><title>The statistical thermodynamics of generative diffusion models: Phase transitions, symmetry breaking and critical instability</title><link>http://arxiv.org/abs/2310.17467v2</link><description>Generative diffusion models have achieved spectacular performance in manyareas of generative modeling. While the fundamental ideas behind these modelscome from non-equilibrium physics, variational inference and stochasticcalculus, in this paper we show that many aspects of these models can beunderstood using the tools of equilibrium statistical mechanics. Using thisreformulation, we show that generative diffusion models undergo second-orderphase transitions corresponding to symmetry breaking phenomena. We show thatthese phase-transitions are always in a mean-field universality class, as theyare the result of a self-consistency condition in the generative dynamics. Weargue that the critical instability that arises from the phase transitions liesat the heart of their generative capabilities, which are characterized by a setof mean field critical exponents. Furthermore, using the statistical physics ofdisordered systems, we show that memorization can be understood as a form ofcritical condensation corresponding to a disordered phase transition. Finally,we show that the dynamic equation of the generative process can be interpretedas a stochastic adiabatic transformation that minimizes the free energy whilekeeping the system in thermal equilibrium.</description><author>Luca Ambrogioni</author><pubDate>Thu, 14 Mar 2024 18:51:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17467v2</guid></item><item><title>Reawakening knowledge: Anticipatory recovery from catastrophic interference via structured training</title><link>http://arxiv.org/abs/2403.09613v1</link><description>We explore the training dynamics of neural networks in a structured non-IIDsetting where documents are presented cyclically in a fixed, repeated sequence.Typically, networks suffer from catastrophic interference when training on asequence of documents; however, we discover a curious and remarkable propertyof LLMs fine-tuned sequentially in this setting: they exhibit anticipatorybehavior, recovering from the forgetting on documents before encountering themagain. The behavior emerges and becomes more robust as the architecture scalesup its number of parameters. Through comprehensive experiments andvisualizations, we uncover new insights into training over-parameterizednetworks in structured environments.</description><author>Yanlai Yang, Matt Jones, Michael C. Mozer, Mengye Ren</author><pubDate>Thu, 14 Mar 2024 18:51:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09613v1</guid></item><item><title>Compute-first optical detection for noise-resilient visual perception</title><link>http://arxiv.org/abs/2403.09612v1</link><description>In the context of visual perception, the optical signal from a scene istransferred into the electronic domain by detectors in the form of image data,which are then processed for the extraction of visual information. In noisy andweak-signal environments such as thermal imaging for night vision applications,however, the performance of neural computing tasks faces a significantbottleneck due to the inherent degradation of data quality upon noisydetection. Here, we propose a concept of optical signal processing beforedetection to address this issue. We demonstrate that spatially redistributingoptical signals through a properly designed linear transformer can enhance thedetection noise resilience of visual perception tasks, as benchmarked with theMNIST classification. Our idea is supported by a quantitative analysisdetailing the relationship between signal concentration and noise robustness,as well as its practical implementation in an incoherent imaging system. Thiscompute-first detection scheme can pave the way for advancing infrared machinevision technologies widely used for industrial and defense applications.</description><author>Jungmin Kim, Nanfang Yu, Zongfu Yu</author><pubDate>Thu, 14 Mar 2024 18:51:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09612v1</guid></item><item><title>MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training</title><link>http://arxiv.org/abs/2403.09611v1</link><description>In this work, we discuss building performant Multimodal Large Language Models(MLLMs). In particular, we study the importance of various architecturecomponents and data choices. Through careful and comprehensive ablations of theimage encoder, the vision language connector, and various pre-training datachoices, we identified several crucial design lessons. For example, wedemonstrate that for large-scale multimodal pre-training using a careful mix ofimage-caption, interleaved image-text, and text-only data is crucial forachieving state-of-the-art (SOTA) few-shot results across multiple benchmarks,compared to other published pre-training results. Further, we show that theimage encoder together with image resolution and the image token count hassubstantial impact, while the vision-language connector design is ofcomparatively negligible importance. By scaling up the presented recipe, webuild MM1, a family of multimodal models up to 30B parameters, consisting ofboth dense models and mixture-of-experts (MoE) variants, that are SOTA inpre-training metrics and achieve competitive performance after supervisedfine-tuning on a range of established multimodal benchmarks. Thanks tolarge-scale pre-training, MM1 enjoys appealing properties such as enhancedin-context learning, and multi-image reasoning, enabling few-shotchain-of-thought prompting.</description><author>Brandon McKinzie, Zhe Gan, Jean-Philippe Fauconnier, Sam Dodge, Bowen Zhang, Philipp Dufter, Dhruti Shah, Xianzhi Du, Futang Peng, Floris Weers, Anton Belyi, Haotian Zhang, Karanjeet Singh, Doug Kang, Hongyu Hè, Max Schwarzer, Tom Gunter, Xiang Kong, Aonan Zhang, Jianyu Wang, Chong Wang, Nan Du, Tao Lei, Sam Wiseman, Mark Lee, Zirui Wang, Ruoming Pang, Peter Grasch, Alexander Toshev, Yinfei Yang</author><pubDate>Thu, 14 Mar 2024 18:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09611v1</guid></item><item><title>Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey</title><link>http://arxiv.org/abs/2403.09606v1</link><description>Causal inference has shown potential in enhancing the predictive accuracy,fairness, robustness, and explainability of Natural Language Processing (NLP)models by capturing causal relationships among variables. The emergence ofgenerative Large Language Models (LLMs) has significantly impacted various NLPdomains, particularly through their advanced reasoning capabilities. Thissurvey focuses on evaluating and improving LLMs from a causal view in thefollowing areas: understanding and improving the LLMs' reasoning capacity,addressing fairness and safety issues in LLMs, complementing LLMs withexplanations, and handling multimodality. Meanwhile, LLMs' strong reasoningcapacities can in turn contribute to the field of causal inference by aidingcausal relationship discovery and causal effect estimations. This reviewexplores the interplay between causal inference frameworks and LLMs from bothperspectives, emphasizing their collective potential to further the developmentof more advanced and equitable artificial intelligence systems.</description><author>Xiaoyu Liu, Paiheng Xu, Junda Wu, Jiaxin Yuan, Yifan Yang, Yuhang Zhou, Fuxiao Liu, Tianrui Guan, Haoliang Wang, Tong Yu, Julian McAuley, Wei Ai, Furong Huang</author><pubDate>Thu, 14 Mar 2024 18:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09606v1</guid></item><item><title>Counterfactual contrastive learning: robust representations via causal image synthesis</title><link>http://arxiv.org/abs/2403.09605v1</link><description>Contrastive pretraining is well-known to improve downstream task performanceand model generalisation, especially in limited label settings. However, it issensitive to the choice of augmentation pipeline. Positive pairs shouldpreserve semantic information while destroying domain-specific information.Standard augmentation pipelines emulate domain-specific changes withpre-defined photometric transformations, but what if we could simulaterealistic domain changes instead? In this work, we show how to utilise recentprogress in counterfactual image generation to this effect. We proposeCF-SimCLR, a counterfactual contrastive learning approach which leveragesapproximate counterfactual inference for positive pair creation. Comprehensiveevaluation across five datasets, on chest radiography and mammography,demonstrates that CF-SimCLR substantially improves robustness to acquisitionshift with higher downstream performance on both in- and out-of-distributiondata, particularly for domains which are under-represented during training.</description><author>Melanie Roschewitz, Fabio De Sousa Ribeiro, Tian Xia, Galvin Khara, Ben Glocker</author><pubDate>Thu, 14 Mar 2024 18:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09605v1</guid></item><item><title>Extremal graphical modeling with latent variables</title><link>http://arxiv.org/abs/2403.09604v1</link><description>Extremal graphical models encode the conditional independence structure ofmultivariate extremes and provide a powerful tool for quantifying the risk ofrare events. Prior work on learning these graphs from data has focused on thesetting where all relevant variables are observed. For the popular class ofH\"usler-Reiss models, we propose the \texttt{eglatent} method, a tractableconvex program for learning extremal graphical models in the presence of latentvariables. Our approach decomposes the H\"usler-Reiss precision matrix into asparse component encoding the graphical structure among the observed variablesafter conditioning on the latent variables, and a low-rank component encodingthe effect of a few latent variables on the observed variables. We providefinite-sample guarantees of \texttt{eglatent} and show that it consistentlyrecovers the conditional graph as well as the number of latent variables. Wehighlight the improved performances of our approach on synthetic and real data.</description><author>Sebastian Engelke, Armeen Taeb</author><pubDate>Thu, 14 Mar 2024 18:45:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09604v1</guid></item><item><title>Optimistic Verifiable Training by Controlling Hardware Nondeterminism</title><link>http://arxiv.org/abs/2403.09603v1</link><description>The increasing compute demands of AI systems has led to the emergence ofservices that train models on behalf of clients lacking necessary resources.However, ensuring correctness of training and guarding against potentialtraining-time attacks, such as data poisoning, poses challenges. Existing workson verifiable training largely fall into two classes: proof-based systems,which struggle to scale due to requiring cryptographic techniques, and"optimistic" methods that consider a trusted third-party auditor who replicatesthe training process. A key challenge with the latter is that hardwarenondeterminism between GPU types during training prevents an auditor fromreplicating the training process exactly, and such schemes are thereforenon-robust. We propose a method that combines training in a higher precisionthan the target model, rounding after intermediate computation steps, andstoring rounding decisions based on an adaptive thresholding procedure, tosuccessfully control for nondeterminism. Across three different NVIDIA GPUs(A40, Titan XP, RTX 2080 Ti), we achieve exact training replication at FP32precision for both full-training and fine-tuning of ResNet-50 (23M) and GPT-2(117M) models. Our verifiable training scheme significantly decreases thestorage and time costs compared to proof-based systems.</description><author>Megha Srivastava, Simran Arora, Dan Boneh</author><pubDate>Thu, 14 Mar 2024 18:44:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09603v1</guid></item><item><title>Mixture of Mixups for Multi-label Classification of Rare Anuran Sounds</title><link>http://arxiv.org/abs/2403.09598v1</link><description>Multi-label imbalanced classification poses a significant challenge inmachine learning, particularly evident in bioacoustics where animal soundsoften co-occur, and certain sounds are much less frequent than others. Thispaper focuses on the specific case of classifying anuran species sounds usingthe dataset AnuraSet, that contains both class imbalance and multi-labelexamples. To address these challenges, we introduce Mixture of Mixups (Mix2), aframework that leverages mixing regularization methods Mixup, Manifold Mixup,and MultiMix. Experimental results show that these methods, individually, maylead to suboptimal results; however, when applied randomly, with one selectedat each training iteration, they prove effective in addressing the mentionedchallenges, particularly for rare classes with few occurrences. Furtheranalysis reveals that Mix2 is also proficient in classifying sounds acrossvarious levels of class co-occurrences.</description><author>Ilyass Moummad, Nicolas Farrugia, Romain Serizel, Jeremy Froidevaux, Vincent Lostanlen</author><pubDate>Thu, 14 Mar 2024 18:39:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09598v1</guid></item><item><title>Renovating Names in Open-Vocabulary Segmentation Benchmarks</title><link>http://arxiv.org/abs/2403.09593v1</link><description>Names are essential to both human cognition and vision-language models.Open-vocabulary models utilize class names as text prompts to generalize tocategories unseen during training. However, name qualities are often overlookedand lack sufficient precision in existing datasets. In this paper, we addressthis underexplored problem by presenting a framework for "renovating" names inopen-vocabulary segmentation benchmarks (RENOVATE). Through human study, wedemonstrate that the names generated by our model are more precise descriptionsof the visual segments and hence enhance the quality of existing datasets bymeans of simple renaming. We further demonstrate that using our renovated namesenables training of stronger open-vocabulary segmentation models. Usingopen-vocabulary segmentation for name quality evaluation, we show that ourrenovated names lead to up to 16% relative improvement from the original nameson various benchmarks across various state-of-the-art models. We provide ourcode and relabelings for several popular segmentation datasets (ADE20K,Cityscapes, PASCAL Context) to the research community.</description><author>Haiwen Huang, Songyou Peng, Dan Zhang, Andreas Geiger</author><pubDate>Thu, 14 Mar 2024 18:35:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09593v1</guid></item><item><title>Era Splitting -- Invariant Learning for Decision Trees</title><link>http://arxiv.org/abs/2309.14496v4</link><description>Real-life machine learning problems exhibit distributional shifts in the datafrom one time to another or from one place to another. This behavior is beyondthe scope of the traditional empirical risk minimization paradigm, whichassumes i.i.d. distribution of data over time and across locations. Theemerging field of out-of-distribution (OOD) generalization addresses thisreality with new theory and algorithms which incorporate environmental, orera-wise information into the algorithms. So far, most research has beenfocused on linear models and/or neural networks. In this research we developtwo new splitting criteria for decision trees, which allow us to apply ideasfrom OOD generalization research to decision tree models, namely, gradientboosting decision trees (GBDT). The new splitting criteria use era-wiseinformation associated with the data to grow tree-based models that are optimalacross all disjoint eras in the data, instead of optimal over the entire dataset pooled together, which is the default setting. In this paper, two newsplitting criteria are defined and analyzed theoretically. Effectiveness istested on four experiments, ranging from simple, synthetic to complex,real-world applications. In particular we cast the OOD domain-adaptationproblem in the context of financial markets, where the new models out-performstate-of-the-art GBDT models on the Numerai data set. The new criteria areincorporated into the Scikit-Learn code base and made freely available online.</description><author>Timothy DeLise</author><pubDate>Thu, 14 Mar 2024 18:31:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14496v4</guid></item><item><title>Iterative Forgetting: Online Data Stream Regression Using Database-Inspired Adaptive Granulation</title><link>http://arxiv.org/abs/2403.09588v1</link><description>Many modern systems, such as financial, transportation, andtelecommunications systems, are time-sensitive in the sense that they demandlow-latency predictions for real-time decision-making. Such systems often haveto contend with continuous unbounded data streams as well as concept drift,which are challenging requirements that traditional regression techniques areunable to cater to. There exists a need to create novel data stream regressionmethods that can handle these scenarios. We present a database-inspireddatastream regression model that (a) uses inspiration from R*-trees to creategranules from incoming datastreams such that relevant information is retained,(b) iteratively forgets granules whose information is deemed to be outdated,thus maintaining a list of only recent, relevant granules, and (c) uses therecent data and granules to provide low-latency predictions. TheR*-tree-inspired approach also makes the algorithm amenable to integration withdatabase systems. Our experiments demonstrate that the ability of this methodto discard data produces a significant order-of-magnitude improvement inlatency and training time when evaluated against the most accuratestate-of-the-art algorithms, while the R*-tree-inspired granulation techniqueprovides competitively accurate predictions</description><author>Niket Kathiriya, Hossein Haeri, Cindy Chen, Kshitij Jerath</author><pubDate>Thu, 14 Mar 2024 18:26:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09588v1</guid></item><item><title>SNAP: Semantic Stories for Next Activity Prediction</title><link>http://arxiv.org/abs/2401.15621v2</link><description>Predicting the next activity in an ongoing process is one of the most commonclassification tasks in the business process management (BPM) domain. It allowsbusinesses to optimize resource allocation, enhance operational efficiency, andaids in risk mitigation and strategic decision-making. This provides acompetitive edge in the rapidly evolving confluence of BPM and AI. Existingstate-of-the-art AI models for business process prediction do not fullycapitalize on available semantic information within process event logs. Ascurrent advanced AI-BPM systems provide semantically-richer textual data, theneed for novel adequate models grows. To address this gap, we propose the novelSNAP method that leverages language foundation models by constructing semanticcontextual stories from the process historical event logs and using them forthe next activity prediction. We compared the SNAP algorithm with ninestate-of-the-art models on six benchmark datasets and show that SNAPsignificantly outperforms them, especially for datasets with high levels ofsemantic content.</description><author>Alon Oved, Segev Shlomov, Sergey Zeltyn, Nir Mashkif, Avi Yaeli</author><pubDate>Thu, 14 Mar 2024 18:22:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15621v2</guid></item><item><title>Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning</title><link>http://arxiv.org/abs/2311.00860v3</link><description>Automatic differentiation (AD) is a critical step in physics-informed machinelearning, required for computing the high-order derivatives of network outputw.r.t. coordinates of collocation points. In this paper, we present a novel andlightweight algorithm to conduct AD for physics-informed operator learning,which we call the trick of Zero Coordinate Shift (ZCS). Instead of making allsampled coordinates as leaf variables, ZCS introduces only one scalar-valuedleaf variable for each spatial or temporal dimension, simplifying the wantedderivatives from "many-roots-many-leaves" to "one-root-many-leaves" wherebyreverse-mode AD becomes directly utilisable. It has led to an outstandingperformance leap by avoiding the duplication of the computational graph alongthe dimension of functions (physical parameters). ZCS is easy to implement withcurrent deep learning libraries; our own implementation is achieved byextending the DeepXDE package. We carry out a comprehensive benchmark analysisand several case studies, training physics-informed DeepONets to solve partialdifferential equations (PDEs) without data. The results show that ZCS haspersistently reduced GPU memory consumption and wall time for training by anorder of magnitude, and such reduction factor scales with the number offunctions. As a low-level optimisation technique, ZCS imposes no restrictionson data, physics (PDE) or network architecture and does not compromise trainingresults from any aspect.</description><author>Kuangdai Leng, Mallikarjun Shankar, Jeyan Thiyagalingam</author><pubDate>Thu, 14 Mar 2024 18:21:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00860v3</guid></item><item><title>Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations</title><link>http://arxiv.org/abs/2403.07769v2</link><description>This article explores the dynamic influence of computational entities basedon multi-agent systems theory (SMA) combined with large language models (LLM),which are characterized by their ability to simulate complex humaninteractions, as a possibility to revolutionize human user interaction from theuse of specialized artificial agents to support everything from operationalorganizational processes to strategic decision making based on appliedknowledge and human orchestration. Previous investigations reveal that thereare limitations, particularly in the autonomous approach of artificial agents,especially when dealing with new challenges and pragmatic tasks such asinducing logical reasoning and problem solving. It is also considered thattraditional techniques, such as the stimulation of chains of thoughts, requireexplicit human guidance. In our approach we employ agents developed from largelanguage models (LLM), each with distinct prototyping that considers behavioralelements, driven by strategies that stimulate the generation of knowledge basedon the use case proposed in the scenario (role-play) business, using adiscussion approach between agents (guided conversation). We demonstrate thepotential of developing agents useful for organizational strategies, based onmulti-agent system theories (SMA) and innovative uses based on large languagemodels (LLM based), offering a differentiated and adaptable experiment todifferent applications, complexities, domains, and capabilities from LLM.</description><author>Carlos Jose Xavier Cruz</author><pubDate>Thu, 14 Mar 2024 18:16:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07769v2</guid></item><item><title>Algorithmic syntactic causal identification</title><link>http://arxiv.org/abs/2403.09580v1</link><description>Causal identification in causal Bayes nets (CBNs) is an important tool incausal inference allowing the derivation of interventional distributions fromobservational distributions where this is possible in principle. However, mostexisting formulations of causal identification using techniques such asd-separation and do-calculus are expressed within the mathematical language ofclassical probability theory on CBNs. However, there are many causal settingswhere probability theory and hence current causal identification techniques areinapplicable such as relational databases, dataflow programs such as hardwaredescription languages, distributed systems and most modern machine learningalgorithms. We show that this restriction can be lifted by replacing the use ofclassical probability theory with the alternative axiomatic foundation ofsymmetric monoidal categories. In this alternative axiomatization, we show howan unambiguous and clean distinction can be drawn between the general syntax ofcausal models and any specific semantic implementation of that causal model.This allows a purely syntactic algorithmic description of general causalidentification by a translation of recent formulations of the general IDalgorithm through fixing. Our description is given entirely in terms of thenon-parametric ADMG structure specifying a causal model and the algebraicsignature of the corresponding monoidal category, to which a sequence ofmanipulations is then applied so as to arrive at a modified monoidal categoryin which the desired, purely syntactic interventional causal model, isobtained. We use this idea to derive purely syntactic analogues of classicalback-door and front-door causal adjustment, and illustrate an application to amore complex causal model.</description><author>Dhurim Cakiqi, Max A. Little</author><pubDate>Thu, 14 Mar 2024 18:14:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09580v1</guid></item><item><title>uaMix-MAE: Efficient Tuning of Pretrained Audio Transformers with Unsupervised Audio Mixtures</title><link>http://arxiv.org/abs/2403.09579v1</link><description>Masked Autoencoders (MAEs) learn rich low-level representations fromunlabeled data but require substantial labeled data to effectively adapt todownstream tasks. Conversely, Instance Discrimination (ID) emphasizeshigh-level semantics, offering a potential solution to alleviate annotationrequirements in MAEs. Although combining these two approaches can addressdownstream tasks with limited labeled data, naively integrating ID into MAEsleads to extended training times and high computational costs. To address thischallenge, we introduce uaMix-MAE, an efficient ID tuning strategy thatleverages unsupervised audio mixtures. Utilizing contrastive tuning, uaMix-MAEaligns the representations of pretrained MAEs, thereby facilitating effectiveadaptation to task-specific semantics. To optimize the model with small amountsof unlabeled data, we propose an audio mixing technique that manipulates audiosamples in both input and virtual label spaces. Experiments in low/few-shotsettings demonstrate that \modelname achieves 4-6% accuracy improvements overvarious benchmarks when tuned with limited unlabeled data, such asAudioSet-20K. Code is available at https://github.com/PLAN-Lab/uamix-MAE</description><author>Afrina Tabassum, Dung Tran, Trung Dang, Ismini Lourentzou, Kazuhito Koishida</author><pubDate>Thu, 14 Mar 2024 18:13:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09579v1</guid></item><item><title>The Impact of Explanations on Fairness in Human-AI Decision-Making: Protected vs Proxy Features</title><link>http://arxiv.org/abs/2310.08617v2</link><description>AI systems have been known to amplify biases in real-world data. Explanationsmay help human-AI teams address these biases for fairer decision-making.Typically, explanations focus on salient input features. If a model is biasedagainst some protected group, explanations may include features thatdemonstrate this bias, but when biases are realized through proxy features, therelationship between this proxy feature and the protected one may be less clearto a human. In this work, we study the effect of the presence of protected andproxy features on participants' perception of model fairness and their abilityto improve demographic parity over an AI alone. Further, we examine howdifferent treatments -- explanations, model bias disclosure and proxycorrelation disclosure -- affect fairness perception and parity. We find thatexplanations help people detect direct but not indirect biases. Additionally,regardless of bias type, explanations tend to increase agreement with modelbiases. Disclosures can help mitigate this effect for indirect biases,improving both unfairness recognition and decision-making fairness. We hopethat our findings can help guide further research into advancing explanationsin support of fair human-AI decision-making.</description><author>Navita Goyal, Connor Baumler, Tin Nguyen, Hal Daumé III</author><pubDate>Thu, 14 Mar 2024 18:12:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08617v2</guid></item><item><title>The NeRFect Match: Exploring NeRF Features for Visual Localization</title><link>http://arxiv.org/abs/2403.09577v1</link><description>In this work, we propose the use of Neural Radiance Fields (NeRF) as a scenerepresentation for visual localization. Recently, NeRF has been employed toenhance pose regression and scene coordinate regression models by augmentingthe training database, providing auxiliary supervision through rendered images,or serving as an iterative refinement module. We extend its recognizedadvantages -- its ability to provide a compact scene representation withrealistic appearances and accurate geometry -- by exploring the potential ofNeRF's internal features in establishing precise 2D-3D matches forlocalization. To this end, we conduct a comprehensive examination of NeRF'simplicit knowledge, acquired through view synthesis, for matching under variousconditions. This includes exploring different matching network architectures,extracting encoder features at multiple layers, and varying trainingconfigurations. Significantly, we introduce NeRFMatch, an advanced 2D-3Dmatching function that capitalizes on the internal knowledge of NeRF learnedvia view synthesis. Our evaluation of NeRFMatch on standard localizationbenchmarks, within a structure-based pipeline, sets a new state-of-the-art forlocalization performance on Cambridge Landmarks.</description><author>Qunjie Zhou, Maxim Maximov, Or Litany, Laura Leal-Taixé</author><pubDate>Thu, 14 Mar 2024 18:11:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09577v1</guid></item><item><title>DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model</title><link>http://arxiv.org/abs/2310.01412v4</link><description>Multimodal large language models (MLLMs) have emerged as a prominent area ofinterest within the research community, given their proficiency in handling andreasoning with non-textual data, including images and videos. This study seeksto extend the application of MLLMs to the realm of autonomous driving byintroducing DriveGPT4, a novel interpretable end-to-end autonomous drivingsystem based on LLMs. Capable of processing multi-frame video inputs andtextual queries, DriveGPT4 facilitates the interpretation of vehicle actions,offers pertinent reasoning, and effectively addresses a diverse range ofquestions posed by users. Furthermore, DriveGPT4 predicts low-level vehiclecontrol signals in an end-to-end fashion. These advanced capabilities areachieved through the utilization of a bespoke visual instruction tuningdataset, specifically tailored for autonomous driving applications, inconjunction with a mix-finetuning training strategy. DriveGPT4 represents thepioneering effort to leverage LLMs for the development of an interpretableend-to-end autonomous driving solution. Evaluations conducted on the BDD-Xdataset showcase the superior qualitative and quantitative performance ofDriveGPT4. Additionally, the fine-tuning of domain-specific data enablesDriveGPT4 to yield close or even improved results in terms of autonomousdriving grounding when contrasted with GPT4-V. The code and dataset will bepublicly available.</description><author>Zhenhua Xu, Yujia Zhang, Enze Xie, Zhen Zhao, Yong Guo, Kwan-Yee. K. Wong, Zhenguo Li, Hengshuang Zhao</author><pubDate>Thu, 14 Mar 2024 18:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01412v4</guid></item><item><title>Koopman operators with intrinsic observables in rigged reproducing kernel Hilbert spaces</title><link>http://arxiv.org/abs/2403.02524v2</link><description>This paper presents a novel approach for estimating the Koopman operatordefined on a reproducing kernel Hilbert space (RKHS) and its spectra. Wepropose an estimation method, what we call Jet Dynamic Mode Decomposition(JetDMD), leveraging the intrinsic structure of RKHS and the geometric notionknown as jets to enhance the estimation of the Koopman operator. This methodrefines the traditional Extended Dynamic Mode Decomposition (EDMD) in accuracy,especially in the numerical estimation of eigenvalues. This paper provesJetDMD's superiority through explicit error bounds and convergence rate forspecial positive definite kernels, offering a solid theoretical foundation forits performance. We also delve into the spectral analysis of the Koopmanoperator, proposing the notion of extended Koopman operator within a frameworkof rigged Hilbert space. This notion leads to a deeper understanding ofestimated Koopman eigenfunctions and capturing them outside the originalfunction space. Through the theory of rigged Hilbert space, our study providesa principled methodology to analyze the estimated spectrum and eigenfunctionsof Koopman operators, and enables eigendecomposition within a rigged RKHS. Wealso propose a new effective method for reconstructing the dynamical systemfrom temporally-sampled trajectory data of the dynamical system with solidtheoretical guarantee. We conduct several numerical simulations using the vander Pol oscillator, the Duffing oscillator, the H\'enon map, and the Lorenzattractor, and illustrate the performance of JetDMD with clear numericalcomputations of eigenvalues and accurate predictions of the dynamical systems.</description><author>Isao Ishikawa, Yuka Hashimoto, Masahiro Ikeda, Yoshinobu Kawahara</author><pubDate>Thu, 14 Mar 2024 18:04:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02524v2</guid></item><item><title>Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation</title><link>http://arxiv.org/abs/2403.09572v1</link><description>Multimodal large language models (MLLMs) have shown impressive reasoningabilities, which, however, are also more vulnerable to jailbreak attacks thantheir LLM predecessors. Although still capable of detecting unsafe responses,we observe that safety mechanisms of the pre-aligned LLMs in MLLMs can beeasily bypassed due to the introduction of image features. To construct robustMLLMs, we propose ECSO(Eyes Closed, Safety On), a novel training-freeprotecting approach that exploits the inherent safety awareness of MLLMs, andgenerates safer responses via adaptively transforming unsafe images into textsto activate intrinsic safety mechanism of pre-aligned LLMs in MLLMs.Experiments on five state-of-the-art (SoTA) MLLMs demonstrate that our ECSOenhances model safety significantly (e.g., a 37.6% improvement on theMM-SafetyBench (SD+OCR), and 71.3% on VLSafe for the LLaVA-1.5-7B), whileconsistently maintaining utility results on common MLLM benchmarks.Furthermore, we show that ECSO can be used as a data engine to generatesupervised-finetuning (SFT) data for MLLM alignment without extra humanintervention.</description><author>Yunhao Gou, Kai Chen, Zhili Liu, Lanqing Hong, Hang Xu, Zhenguo Li, Dit-Yan Yeung, James T. Kwok, Yu Zhang</author><pubDate>Thu, 14 Mar 2024 18:03:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09572v1</guid></item><item><title>Are you a robot? Detecting Autonomous Vehicles from Behavior Analysis</title><link>http://arxiv.org/abs/2403.09571v1</link><description>The tremendous hype around autonomous driving is eagerly calling for emergingand novel technologies to support advanced mobility use cases. As carmanufactures keep developing SAE level 3+ systems to improve the safety andcomfort of passengers, traffic authorities need to establish new procedures tomanage the transition from human-driven to fully-autonomous vehicles whileproviding a feedback-loop mechanism to fine-tune envisioned autonomous systems.Thus, a way to automatically profile autonomous vehicles and differentiatethose from human-driven ones is a must. In this paper, we present afully-fledged framework that monitors active vehicles using camera images andstate information in order to determine whether vehicles are autonomous,without requiring any active notification from the vehicles themselves.Essentially, it builds on the cooperation among vehicles, which share theirdata acquired on the road feeding a machine learning model to identifyautonomous cars. We extensively tested our solution and created the NexusStreetdataset, by means of the CARLA simulator, employing an autonomous drivingcontrol agent and a steering wheel maneuvered by licensed drivers. Experimentsshow it is possible to discriminate the two behaviors by analyzing video clipswith an accuracy of 80%, which improves up to 93% when the target stateinformation is available. Lastly, we deliberately degraded the state to observehow the framework performs under non-ideal data collection conditions.</description><author>Fabio Maresca, Filippo Grazioli, Antonio Albanese, Vincenzo Sciancalepore, Gianpiero Negri, Xavier Costa-Perez</author><pubDate>Thu, 14 Mar 2024 18:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09571v1</guid></item><item><title>Multi-Fidelity Bayesian Optimization With Across-Task Transferable Max-Value Entropy Search</title><link>http://arxiv.org/abs/2403.09570v1</link><description>In many applications, ranging from logistics to engineering, a designer isfaced with a sequence of optimization tasks for which the objectives are in theform of black-box functions that are costly to evaluate. For example, thedesigner may need to tune the hyperparameters of neural network models fordifferent learning tasks over time. Rather than evaluating the objectivefunction for each candidate solution, the designer may have access toapproximations of the objective functions, for which higher-fidelityevaluations entail a larger cost. Existing multi-fidelity black-boxoptimization strategies select candidate solutions and fidelity levels with thegoal of maximizing the information accrued about the optimal value or solutionfor the current task. Assuming that successive optimization tasks are related,this paper introduces a novel information-theoretic acquisition function thatbalances the need to acquire information about the current task with the goalof collecting information transferable to future tasks. The proposed methodincludes shared inter-task latent variables, which are transferred across tasksby implementing particle-based variational Bayesian updates. Experimentalresults across synthetic and real-world examples reveal that the proposedprovident acquisition strategy that caters to future tasks can significantlyimprove the optimization efficiency as soon as a sufficient number of tasks isprocessed.</description><author>Yunchuan Zhang, Sangwoo Park, Osvaldo Simeone</author><pubDate>Thu, 14 Mar 2024 18:00:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09570v1</guid></item><item><title>Exploring Safety Generalization Challenges of Large Language Models via Code</title><link>http://arxiv.org/abs/2403.07865v2</link><description>The rapid advancement of Large Language Models (LLMs) has brought aboutremarkable capabilities in natural language processing but also raised concernsabout their potential misuse. While strategies like supervised fine-tuning andreinforcement learning from human feedback have enhanced their safety, thesemethods primarily focus on natural languages, which may not generalize to otherdomains. This paper introduces CodeAttack, a framework that transforms naturallanguage inputs into code inputs, presenting a novel environment for testingthe safety generalization of LLMs. Our comprehensive studies onstate-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal acommon safety vulnerability of these models against code input: CodeAttackconsistently bypasses the safety guardrails of all models more than 80% of thetime. Furthermore, we find that a larger distribution gap between CodeAttackand natural language leads to weaker safety generalization, such as encodingnatural language input with data structures or using less popular programminglanguages. These findings highlight new safety risks in the code domain and theneed for more robust safety alignment algorithms to match the code capabilitiesof LLMs.</description><author>Qibing Ren, Chang Gao, Jing Shao, Junchi Yan, Xin Tan, Yu Qiao, Wai Lam, Lizhuang Ma</author><pubDate>Thu, 14 Mar 2024 17:57:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07865v2</guid></item><item><title>Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models</title><link>http://arxiv.org/abs/2403.09567v1</link><description>The deployment of autonomous agents in environments involving humaninteraction has increasingly raised security concerns. Consequently,understanding the circumstances behind an event becomes critical, requiring thedevelopment of capabilities to justify their behaviors to non-expert users.Such explanations are essential in enhancing trustworthiness and safety, actingas a preventive measure against failures, errors, and misunderstandings.Additionally, they contribute to improving communication, bridging the gapbetween the agent and the user, thereby improving the effectiveness of theirinteractions. This work presents an accountability and explainabilityarchitecture implemented for ROS-based mobile robots. The proposed solutionconsists of two main components. Firstly, a black box-like element to provideaccountability, featuring anti-tampering properties achieved through blockchaintechnology. Secondly, a component in charge of generating natural languageexplanations by harnessing the capabilities of Large Language Models (LLMs)over the data contained within the previously mentioned black box. The studyevaluates the performance of our solution in three different scenarios, eachinvolving autonomous agent navigation functionalities. This evaluation includesa thorough examination of accountability and explainability metrics,demonstrating the effectiveness of our approach in using accountable data fromrobot actions to obtain coherent, accurate and understandable explanations,even when facing challenges inherent in the use of autonomous agents inreal-world scenarios.</description><author>Laura Fernández-Becerra, Miguel Ángel González-Santamarta, Ángel Manuel Guerrero-Higueras, Francisco Javier Rodríguez-Lera, Vicente Matellán Olivera</author><pubDate>Thu, 14 Mar 2024 17:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09567v1</guid></item><item><title>Welcome Your New AI Teammate: On Safety Analysis by Leashing Large Language Models</title><link>http://arxiv.org/abs/2403.09565v1</link><description>DevOps is a necessity in many industries, including the development ofAutonomous Vehicles. In those settings, there are iterative activities thatreduce the speed of SafetyOps cycles. One of these activities is "HazardAnalysis &amp; Risk Assessment" (HARA), which is an essential step to start thesafety requirements specification. As a potential approach to increase thespeed of this step in SafetyOps, we have delved into the capabilities of LargeLanguage Models (LLMs). Our objective is to systematically assess their potential for application inthe field of safety engineering. To that end, we propose a framework to supporta higher degree of automation of HARA with LLMs. Despite our endeavors toautomate as much of the process as possible, expert review remains crucial toensure the validity and correctness of the analysis results, with necessarymodifications made accordingly.</description><author>Ali Nouri, Beatriz Cabrero-Daniel, Fredrik Törner, Hȧkan Sivencrona, Christian Berger</author><pubDate>Thu, 14 Mar 2024 17:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09565v1</guid></item><item><title>Self-Consistency Training for Hamiltonian Prediction</title><link>http://arxiv.org/abs/2403.09560v1</link><description>Hamiltonian prediction is a versatile formulation to leverage machinelearning for solving molecular science problems. Yet, its applicability islimited by insufficient labeled data for training. In this work, we highlightthat Hamiltonian prediction possesses a self-consistency principle, based onwhich we propose an exact training method that does not require labeled data.This merit addresses the data scarcity difficulty, and distinguishes the taskfrom other property prediction formulations with unique benefits: (1)self-consistency training enables the model to be trained on a large amount ofunlabeled data, hence substantially enhances generalization; (2)self-consistency training is more efficient than labeling data with DFT forsupervised training, since it is an amortization of DFT calculation over a setof molecular structures. We empirically demonstrate the better generalizationin data-scarce and out-of-distribution scenarios, and the better efficiencyfrom the amortization. These benefits push forward the applicability ofHamiltonian prediction to an ever larger scale.</description><author>He Zhang, Chang Liu, Zun Wang, Xinran Wei, Siyuan Liu, Nanning Zheng, Bin Shao, Tie-Yan Liu</author><pubDate>Thu, 14 Mar 2024 17:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09560v1</guid></item><item><title>Assessing the Impact of Sequence Length Learning on Classification Tasks for Transformer Encoder Models</title><link>http://arxiv.org/abs/2212.08399v2</link><description>Classification algorithms using Transformer architectures can be affected bythe sequence length learning problem whenever observations from differentclasses have a different length distribution. This problem causes models to usesequence length as a predictive feature instead of relying on important textualinformation. Although most public datasets are not affected by this problem,privately owned corpora for fields such as medicine and insurance may carrythis data bias. The exploitation of this sequence length feature poseschallenges throughout the value chain as these machine learning models can beused in critical applications. In this paper, we empirically expose thisproblem and present approaches to minimize its impacts.</description><author>Jean-Thomas Baillargeon, Luc Lamontagne</author><pubDate>Thu, 14 Mar 2024 17:49:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08399v2</guid></item><item><title>Less is More: Data Value Estimation for Visual Instruction Tuning</title><link>http://arxiv.org/abs/2403.09559v1</link><description>Visual instruction tuning is the key to building multimodal large languagemodels (MLLMs), which greatly improves the reasoning capabilities of largelanguage models (LLMs) in vision scenario. However, existing MLLMs mostly relyon a mixture of multiple highly diverse visual instruction datasets fortraining (even more than a million instructions), which may introduce dataredundancy. To investigate this issue, we conduct a series of empiricalstudies, which reveal a significant redundancy within the visual instructiondatasets, and show that greatly reducing the amount of several instructiondataset even do not affect the performance. Based on the findings, we propose anew data selection approach TIVE, to eliminate redundancy within visualinstruction data. TIVE first estimates the task-level and instance-level valueof the visual instructions based on computed gradients. Then, according to theestimated values, TIVE determines the task proportion within the visualinstructions, and selects representative instances to compose a smaller visualinstruction subset for training. Experiments on LLaVA-1.5 show that ourapproach using only about 7.5% data can achieve comparable performance as thefull-data fine-tuned model across seven benchmarks, even surpassing it on fourof the benchmarks. Our code and data will be publicly released.</description><author>Zikang Liu, Kun Zhou, Wayne Xin Zhao, Dawei Gao, Yaliang Li, Ji-Rong Wen</author><pubDate>Thu, 14 Mar 2024 17:47:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09559v1</guid></item><item><title>CURSOR: Scalable Mixed-Order Hypergraph Matching with CUR Decomposition</title><link>http://arxiv.org/abs/2402.16594v2</link><description>To achieve greater accuracy, hypergraph matching algorithms requireexponential increases in computational resources. Recent kd-tree-basedapproximate nearest neighbor (ANN) methods, despite the sparsity of theircompatibility tensor, still require exhaustive calculations for large-scalegraph matching. This work utilizes CUR tensor decomposition and introduces anovel cascaded second and third-order hypergraph matching framework (CURSOR)for efficient hypergraph matching. A CUR-based second-order graph matchingalgorithm is used to provide a rough match, and then the core of CURSOR, afiber-CUR-based tensor generation method, directly calculates entries of thecompatibility tensor by leveraging the initial second-order match result. Thissignificantly decreases the time complexity and tensor density. A probabilityrelaxation labeling (PRL)-based matching algorithm, specifically suitable forsparse tensors, is developed. Experiment results on large-scale syntheticdatasets and widely-adopted benchmark sets demonstrate the superiority ofCURSOR over existing methods. The tensor generation method in CURSOR can beintegrated seamlessly into existing hypergraph matching methods to improvetheir performance and lower their computational costs.</description><author>Qixuan Zheng, Ming Zhang, Hong Yan</author><pubDate>Thu, 14 Mar 2024 17:45:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16594v2</guid></item><item><title>Cloud gap-filling with deep learning for improved grassland monitoring</title><link>http://arxiv.org/abs/2403.09554v1</link><description>Uninterrupted optical image time series are crucial for the timely monitoringof agricultural land changes. However, the continuity of such time series isoften disrupted by clouds. In response to this challenge, we propose a deeplearning method that integrates cloud-free optical (Sentinel-2) observationsand weather-independent (Sentinel-1) Synthetic Aperture Radar (SAR) data, usinga combined Convolutional Neural Network (CNN)-Recurrent Neural Network (RNN)architecture to generate continuous Normalized Difference Vegetation Index(NDVI) time series. We emphasize the significance of observation continuity byassessing the impact of the generated time series on the detection of grasslandmowing events. We focus on Lithuania, a country characterized by extensivecloud coverage, and compare our approach with alternative interpolationtechniques (i.e., linear, Akima, quadratic). Our method surpasses thesetechniques, with an average MAE of 0.024 and R^2 of 0.92. It not only improvesthe accuracy of event detection tasks by employing a continuous time series,but also effectively filters out sudden shifts and noise originating fromcloudy observations that cloud masks often fail to detect.</description><author>Iason Tsardanidis, Alkiviadis Koukos, Vasileios Sitokonstantinou, Thanassis Drivas, Charalampos Kontoes</author><pubDate>Thu, 14 Mar 2024 17:41:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09554v1</guid></item><item><title>Efficient Combinatorial Optimization via Heat Diffusion</title><link>http://arxiv.org/abs/2403.08757v2</link><description>Combinatorial optimization problems are widespread but inherently challengingdue to their discrete nature.The primary limitation of existing methods is thatthey can only access a small fraction of the solution space at each iteration,resulting in limited efficiency for searching the global optimal. To overcomethis challenge, diverging from conventional efforts of expanding the solver'ssearch scope, we focus on enabling information to actively propagate to thesolver through heat diffusion. By transforming the target function whilepreserving its optima, heat diffusion facilitates information flow from distantregions to the solver, providing more efficient navigation. Utilizing heatdiffusion, we propose a framework for solving general combinatorialoptimization problems. The proposed methodology demonstrates superiorperformance across a range of the most challenging and widely encounteredcombinatorial optimizations. Echoing recent advancements in harnessingthermodynamics for generative artificial intelligence, our study furtherreveals its significant potential in advancing combinatorial optimization.</description><author>Hengyuan Ma, Wenlian Lu, Jianfeng Feng</author><pubDate>Thu, 14 Mar 2024 17:40:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08757v2</guid></item><item><title>WeakSurg: Weakly supervised surgical instrument segmentation using temporal equivariance and semantic continuity</title><link>http://arxiv.org/abs/2403.09551v1</link><description>Weakly supervised surgical instrument segmentation with only instrumentpresence labels has been rarely explored in surgical domain. To mitigate thehighly under-constrained challenges, we extend a two-stage weakly supervisedsegmentation paradigm with temporal attributes from two perspectives. From atemporal equivariance perspective, we propose a prototype-based temporalequivariance regulation loss to enhance pixel-wise consistency between adjacentfeatures. From a semantic continuity perspective, we propose a class-awaretemporal semantic continuity loss to constrain the semantic consistency betweena global view of target frame and local non-discriminative regions of adjacentreference frame. To the best of our knowledge, WeakSurg is the firstinstrument-presence-only weakly supervised segmentation architecture to taketemporal information into account for surgical scenarios. Extensive experimentsare validated on Cholec80, an open benchmark for phase and instrumentrecognition. We annotate instance-wise instrument labels with fixed time-stepswhich are double checked by a clinician with 3-years experience. Our resultsshow that WeakSurg compares favorably with state-of-the-art methods not only onsemantic segmentation metrics but also on instance segmentation metrics.</description><author>Qiyuan Wang, Yanzhe Liu, Shang Zhao, Rong Liu, S. Kevin Zhou</author><pubDate>Thu, 14 Mar 2024 17:39:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09551v1</guid></item><item><title>ZeroFlow: Scalable Scene Flow via Distillation</title><link>http://arxiv.org/abs/2305.10424v8</link><description>Scene flow estimation is the task of describing the 3D motion field betweentemporally successive point clouds. State-of-the-art methods use strong priorsand test-time optimization techniques, but require on the order of tens ofseconds to process full-size point clouds, making them unusable as computervision primitives for real-time applications such as open world objectdetection. Feedforward methods are considerably faster, running on the order oftens to hundreds of milliseconds for full-size point clouds, but requireexpensive human supervision. To address both limitations, we propose Scene Flowvia Distillation, a simple, scalable distillation framework that uses alabel-free optimization method to produce pseudo-labels to supervise afeedforward model. Our instantiation of this framework, ZeroFlow, achievesstate-of-the-art performance on the Argoverse 2 Self-Supervised Scene FlowChallenge while using zero human labels by simply training on large-scale,diverse unlabeled data. At test-time, ZeroFlow is over 1000x faster thanlabel-free state-of-the-art optimization-based methods on full-size pointclouds (34 FPS vs 0.028 FPS) and over 1000x cheaper to train on unlabeled datacompared to the cost of human annotation (\$394 vs ~\$750,000). To facilitatefurther research, we release our code, trained model weights, and high qualitypseudo-labels for the Argoverse 2 and Waymo Open datasets athttps://vedder.io/zeroflow.html</description><author>Kyle Vedder, Neehar Peri, Nathaniel Chodosh, Ishan Khatri, Eric Eaton, Dinesh Jayaraman, Yang Liu, Deva Ramanan, James Hays</author><pubDate>Thu, 14 Mar 2024 17:38:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10424v8</guid></item><item><title>Generalizing Denoising to Non-Equilibrium Structures Improves Equivariant Force Fields</title><link>http://arxiv.org/abs/2403.09549v1</link><description>Understanding the interactions of atoms such as forces in 3D atomisticsystems is fundamental to many applications like molecular dynamics andcatalyst design. However, simulating these interactions requirescompute-intensive ab initio calculations and thus results in limited data fortraining neural networks. In this paper, we propose to use denoisingnon-equilibrium structures (DeNS) as an auxiliary task to better leveragetraining data and improve performance. For training with DeNS, we first corrupta 3D structure by adding noise to its 3D coordinates and then predict thenoise. Different from previous works on denoising, which are limited toequilibrium structures, the proposed method generalizes denoising to a muchlarger set of non-equilibrium structures. The main difference is that anon-equilibrium structure does not correspond to local energy minima and hasnon-zero forces, and therefore it can have many possible atomic positionscompared to an equilibrium structure. This makes denoising non-equilibriumstructures an ill-posed problem since the target of denoising is not uniquelydefined. Our key insight is to additionally encode the forces of the originalnon-equilibrium structure to specify which non-equilibrium structure we aredenoising. Concretely, given a corrupted non-equilibrium structure and theforces of the original one, we predict the non-equilibrium structure satisfyingthe input forces instead of any arbitrary structures. Since DeNS requiresencoding forces, DeNS favors equivariant networks, which can easily incorporateforces and other higher-order tensors in node embeddings. We study theeffectiveness of training equivariant networks with DeNS on OC20, OC22 and MD17datasets and demonstrate that DeNS can achieve new state-of-the-art results onOC20 and OC22 and significantly improve training efficiency on MD17.</description><author>Yi-Lun Liao, Tess Smidt, Abhishek Das</author><pubDate>Thu, 14 Mar 2024 17:38:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09549v1</guid></item><item><title>VBART: The Turkish LLM</title><link>http://arxiv.org/abs/2403.01308v2</link><description>We present VBART, the first Turkish sequence-to-sequence Large LanguageModels (LLMs) pre-trained on a large corpus from scratch. VBART are compactLLMs based on good ideas leveraged from BART and mBART models and come in twosizes, Large and XLarge. Fine-tuned VBART models surpass the priorstate-of-the-art results in abstractive text summarization, title generation,text paraphrasing, question answering and question generation tasks. They allowfine-tuning for future text generation tasks and datasets, carving a new pathfor Turkish Natural Language Processing (NLP) research. Our work shows thathaving a pre-trained LLM for Turkish outperforms up to 3x multilingual models,improving existing results and providing efficient models for training andinference. Moreover, we show that our monolingual tokenizer is up to 11x moreefficient than multilingual tokenizers. Last but not least, we introduce amethod to enlarge an existing pre-trained LLM and question the relevancy ofChinchilla Scaling Law to sequence-to-sequence masked language models. Ourfine-tuned models, tokenizer and cleaned vngrs-web-corpus of 135 GB arepublicly available at huggingface.co/vngrs-ai.</description><author>Meliksah Turker, Mehmet Erdi Ari, Aydin Han</author><pubDate>Thu, 14 Mar 2024 17:37:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01308v2</guid></item><item><title>Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability</title><link>http://arxiv.org/abs/2403.09548v1</link><description>Cancer is one of the diseases that kill the most women in the world, withbreast cancer being responsible for the highest number of cancer cases andconsequently deaths. However, it can be prevented by early detection and,consequently, early treatment. Any development for detection or perdition thiskind of cancer is important for a better healthy life. Many studies focus on amodel with high accuracy in cancer prediction, but sometimes accuracy alone maynot always be a reliable metric. This study implies an investigative approachto studying the performance of different machine learning algorithms based onboosting to predict breast cancer focusing on the recall metric. Boostingmachine learning algorithms has been proven to be an effective tool fordetecting medical diseases. The dataset of the University of California, Irvine(UCI) repository has been utilized to train and test the model classifier thatcontains their attributes. The main objective of this study is to usestate-of-the-art boosting algorithms such as AdaBoost, XGBoost, CatBoost andLightGBM to predict and diagnose breast cancer and to find the most effectivemetric regarding recall, ROC-AUC, and confusion matrix. Furthermore, our studyis the first to use these four boosting algorithms with Optuna, a library forhyperparameter optimization, and the SHAP method to improve theinterpretability of our model, which can be used as a support to identify andpredict breast cancer. We were able to improve AUC or recall for all the modelsand reduce the False Negative for AdaBoost and LigthGBM the final AUC were morethan 99.41\% for all models.</description><author>João Manoel Herrera Pinheiro, Marcelo Becker</author><pubDate>Thu, 14 Mar 2024 17:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09548v1</guid></item><item><title>Probabilistic Contrastive Learning for Long-Tailed Visual Recognition</title><link>http://arxiv.org/abs/2403.06726v2</link><description>Long-tailed distributions frequently emerge in real-world data, where a largenumber of minority categories contain a limited number of samples. Suchimbalance issue considerably impairs the performance of standard supervisedlearning algorithms, which are mainly designed for balanced training sets.Recent investigations have revealed that supervised contrastive learningexhibits promising potential in alleviating the data imbalance. However, theperformance of supervised contrastive learning is plagued by an inherentchallenge: it necessitates sufficiently large batches of training data toconstruct contrastive pairs that cover all categories, yet this requirement isdifficult to meet in the context of class-imbalanced data. To overcome thisobstacle, we propose a novel probabilistic contrastive (ProCo) learningalgorithm that estimates the data distribution of the samples from each classin the feature space, and samples contrastive pairs accordingly. In fact,estimating the distributions of all classes using features in a small batch,particularly for imbalanced data, is not feasible. Our key idea is to introducea reasonable and simple assumption that the normalized features in contrastivelearning follow a mixture of von Mises-Fisher (vMF) distributions on unitspace, which brings two-fold benefits. First, the distribution parameters canbe estimated using only the first sample moment, which can be efficientlycomputed in an online manner across different batches. Second, based on theestimated distribution, the vMF distribution allows us to sample an infinitenumber of contrastive pairs and derive a closed form of the expectedcontrastive loss for efficient optimization. Our code is available athttps://github.com/LeapLabTHU/ProCo.</description><author>Chaoqun Du, Yulin Wang, Shiji Song, Gao Huang</author><pubDate>Thu, 14 Mar 2024 17:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06726v2</guid></item><item><title>How do Machine Learning Projects use Continuous Integration Practices? An Empirical Study on GitHub Actions</title><link>http://arxiv.org/abs/2403.09547v1</link><description>Continuous Integration (CI) is a well-established practice in traditionalsoftware development, but its nuances in the domain of Machine Learning (ML)projects remain relatively unexplored. Given the distinctive nature of MLdevelopment, understanding how CI practices are adopted in this context iscrucial for tailoring effective approaches. In this study, we conduct acomprehensive analysis of 185 open-source projects on GitHub (93 ML and 92non-ML projects). Our investigation comprises both quantitative and qualitativedimensions, aiming to uncover differences in CI adoption between ML and non-MLprojects. Our findings indicate that ML projects often require longer builddurations, and medium-sized ML projects exhibit lower test coverage compared tonon-ML projects. Moreover, small and medium-sized ML projects show a higherprevalence of increasing build duration trends compared to their non-MLcounterparts. Additionally, our qualitative analysis illuminates thediscussions around CI in both ML and non-ML projects, encompassing themes likeCI Build Execution and Status, CI Testing, and CI Infrastructure. Theseinsights shed light on the unique challenges faced by ML projects in adoptingCI practices effectively.</description><author>João Helis Bernardo, Daniel Alencar da Costa, Sérgio Queiroz de Medeiros, Uirá Kulesza</author><pubDate>Thu, 14 Mar 2024 17:35:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09547v1</guid></item><item><title>Explorations in Texture Learning</title><link>http://arxiv.org/abs/2403.09543v1</link><description>In this work, we investigate \textit{texture learning}: the identification oftextures learned by object classification models, and the extent to which theyrely on these textures. We build texture-object associations that uncover newinsights about the relationships between texture and object classes in CNNs andfind three classes of results: associations that are strong and expected,strong and not expected, and expected but not present. Our analysisdemonstrates that investigations in texture learning enable new methods forinterpretability and have the potential to uncover unexpected biases.</description><author>Blaine Hoak, Patrick McDaniel</author><pubDate>Thu, 14 Mar 2024 17:30:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09543v1</guid></item><item><title>TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions</title><link>http://arxiv.org/abs/2403.01977v2</link><description>Robot navigation under visual corruption presents a formidable challenge. Toaddress this, we propose a Test-time Adaptation (TTA) method, named as TTA-Nav,for point-goal navigation under visual corruptions. Our "plug-and-play" methodincorporates a top-down decoder to a pre-trained navigation model. Firstly, thepre-trained navigation model gets a corrupted image and extracts features.Secondly, the top-down decoder produces the reconstruction given the high-levelfeatures extracted by the pre-trained model. Then, it feeds the reconstructionof a corrupted image back to the pre-trained model. Finally, the pre-trainedmodel does forward pass again to output action. Despite being trained solely onclean images, the top-down decoder can reconstruct cleaner images fromcorrupted ones without the need for gradient-based adaptation. The pre-trainednavigation model with our top-down decoder significantly enhances navigationperformance across almost all visual corruptions in our benchmarks. Our methodimproves the success rate of point-goal navigation from the state-of-the-artresult of 46% to 94% on the most severe corruption. This suggests its potentialfor broader application in robotic visual navigation. Project page:https://sites.google.com/view/tta-nav</description><author>Maytus Piriyajitakonkij, Mingfei Sun, Mengmi Zhang, Wei Pan</author><pubDate>Thu, 14 Mar 2024 17:30:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01977v2</guid></item><item><title>Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers</title><link>http://arxiv.org/abs/2309.10639v4</link><description>In this paper, we explicitly determine local and global minimizers of the$\mathcal{L}^2$ cost function in underparametrized Deep Learning (DL) networks;our main goal is to shed light on their geometric structure and properties. Weaccomplish this by a direct construction, without invoking the gradient descentflow at any point of this work. We specifically consider $L$ hidden layers, aReLU ramp activation function, an $\mathcal{L}^2$ Schatten class (orHilbert-Schmidt) cost function, input and output spaces $\mathbb{R}^Q$ withequal dimension $Q\geq1$, and hidden layers also defined on $\mathbb{R}^{Q}$;the training inputs are assumed to be sufficiently clustered. The traininginput size $N$ can be arbitrarily large - thus, we are considering theunderparametrized regime. More general settings are left to future work. Weconstruct an explicit family of minimizers for the global minimum of the costfunction in the case $L\geq Q$, which we show to be degenerate. Moreover, wedetermine a set of $2^Q-1$ distinct degenerate local minima of the costfunction. In the context presented here, the concatenation of hidden layers ofthe DL network is reinterpreted as a recursive application of a {\em truncationmap} which "curates" the training inputs by minimizing their noise to signalratio.</description><author>Thomas Chen, Patricia Muñoz Ewald</author><pubDate>Thu, 14 Mar 2024 17:29:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10639v4</guid></item><item><title>Logits of API-Protected LLMs Leak Proprietary Information</title><link>http://arxiv.org/abs/2403.09539v1</link><description>The commercialization of large language models (LLMs) has led to the commonpractice of high-level API-only access to proprietary models. In this work, weshow that even with a conservative assumption about the model architecture, itis possible to learn a surprisingly large amount of non-public informationabout an API-protected LLM from a relatively small number of API queries (e.g.,costing under $1,000 for OpenAI's gpt-3.5-turbo). Our findings are centered onone key observation: most modern LLMs suffer from a softmax bottleneck, whichrestricts the model outputs to a linear subspace of the full output space. Weshow that this lends itself to a model image or a model signature which unlocksseveral capabilities with affordable cost: efficiently discovering the LLM'shidden size, obtaining full-vocabulary outputs, detecting and disambiguatingdifferent model updates, identifying the source LLM given a single full LLMoutput, and even estimating the output layer parameters. Our empiricalinvestigations show the effectiveness of our methods, which allow us toestimate the embedding size of OpenAI's gpt-3.5-turbo to be about 4,096.Lastly, we discuss ways that LLM providers can guard against these attacks, aswell as how these capabilities can be viewed as a feature (rather than a bug)by allowing for greater transparency and accountability.</description><author>Matthew Finlayson, Swabha Swayamdipta, Xiang Ren</author><pubDate>Thu, 14 Mar 2024 17:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09539v1</guid></item><item><title>Expressive Losses for Verified Robustness via Convex Combinations</title><link>http://arxiv.org/abs/2305.13991v2</link><description>In order to train networks for verified adversarial robustness, it is commonto over-approximate the worst-case loss over perturbation regions, resulting innetworks that attain verifiability at the expense of standard performance. Asshown in recent work, better trade-offs between accuracy and robustness can beobtained by carefully coupling adversarial training with over-approximations.We hypothesize that the expressivity of a loss function, which we formalize asthe ability to span a range of trade-offs between lower and upper bounds to theworst-case loss through a single parameter (the over-approximationcoefficient), is key to attaining state-of-the-art performance. To support ourhypothesis, we show that trivial expressive losses, obtained via convexcombinations between adversarial attacks and IBP bounds, yield state-of-the-artresults across a variety of settings in spite of their conceptual simplicity.We provide a detailed analysis of the relationship between theover-approximation coefficient and performance profiles across differentexpressive losses, showing that, while expressivity is essential, betterapproximations of the worst-case loss are not necessarily linked to superiorrobustness-accuracy trade-offs.</description><author>Alessandro De Palma, Rudy Bunel, Krishnamurthy Dvijotham, M. Pawan Kumar, Robert Stanforth, Alessio Lomuscio</author><pubDate>Thu, 14 Mar 2024 17:20:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13991v2</guid></item><item><title>Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data</title><link>http://arxiv.org/abs/2402.05892v3</link><description>In recent years, Transformers have become the de-facto architecture forsequence modeling on text and a variety of multi-dimensional data, such asimages and video. However, the use of self-attention layers in a Transformerincurs prohibitive compute and memory complexity that scales quadraticallyw.r.t. the sequence length. A recent architecture, Mamba, based on state spacemodels has been shown to achieve comparable performance for modeling textsequences, while scaling linearly with the sequence length. In this work, wepresent Mamba-ND, a generalized design extending the Mamba architecture toarbitrary multi-dimensional data. Our design alternatively unravels the inputdata across different dimensions following row-major orderings. We provide asystematic comparison of Mamba-ND with several other alternatives, based onprior multi-dimensional extensions such as Bi-directional LSTMs and S4ND.Empirically, we show that Mamba-ND demonstrates performance competitive withthe state-of-the-art on a variety of multi-dimensional benchmarks, includingImageNet-1K classification, HMDB-51 action recognition, and ERA5 weatherforecasting.</description><author>Shufan Li, Harkanwar Singh, Aditya Grover</author><pubDate>Thu, 14 Mar 2024 17:16:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05892v3</guid></item><item><title>Me LLaMA: Foundation Large Language Models for Medical Applications</title><link>http://arxiv.org/abs/2402.12749v3</link><description>Recent large language models (LLMs) such as ChatGPT and LLaMA have showngreat promise in many AI applications. However, their performance on medicaltasks is suboptimal and can be improved by training on extensivedomain-specific datasets. This study introduces Me LLaMA, a medical LLM familythat includes foundation models - Me LLaMA 13/70B, along with theirchat-enhanced versions - Me LLaMA 13/70B-chat, developed through continualpre-training and instruction tuning of LLaMA2 using large medical datasets. Ourdomain-specific data suite for training and evaluation includes a large-scale,continual pre-training dataset with 129B tokens, an instruction tuning datasetwith 214k samples, and a new medical evaluation benchmark (MIBE) across sixtasks with 12 datasets. Our extensive evaluation using the MIBE shows that MeLLaMA models achieve overall better performance than existing open-sourcemedical LLMs in zero-shot, few-shot and supervised learning abilities. Theirzero-shot performance is comparable with ChatGPT across 7 out of 8 datasets,with a slight variance of within 3%, and yet falls short when compared toGPT-4. In addition, we investigated the catastrophic forgetting problem, andour results show that Me LLaMA models outperform other open-source medical LLMsin mitigating this issue. Me LLaMA is one of the largest open-source medicalfoundation LLMs that use both biomedical and clinical data. It exhibitssuperior performance across both general and medical tasks compared to otheropen-source medical LLMs, rendering it an attractive choice for medical AIapplications. We release our models, datasets, and evaluation scripts at:https://github.com/BIDS-Xu-Lab/Me-LLaMA.</description><author>Qianqian Xie, Qingyu Chen, Aokun Chen, Cheng Peng, Yan Hu, Fongci Lin, Xueqing Peng, Jimin Huang, Jeffrey Zhang, Vipina Keloth, Xingyu Zhou, Huan He, Lucila Ohno-Machado, Yonghui Wu, Hua Xu, Jiang Bian</author><pubDate>Thu, 14 Mar 2024 17:13:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12749v3</guid></item><item><title>VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding</title><link>http://arxiv.org/abs/2403.09530v1</link><description>The evolution of text to visual components facilitates people's daily lives,such as generating image, videos from text and identifying the desired elementswithin the images. Computer vision models involving the multimodal abilities inthe previous days are focused on image detection, classification based onwell-defined objects. Large language models (LLMs) introduces thetransformation from nature language to visual objects, which present the visuallayout for text contexts. OpenAI GPT-4 has emerged as the pinnacle in LLMs,while the computer vision (CV) domain boasts a plethora of state-of-the-art(SOTA) models and algorithms to convert 2D images to their 3D representations.However, the mismatching between the algorithms with the problem could lead toundesired results. In response to this challenge, we propose an unifiedVisionGPT-3D framework to consolidate the state-of-the-art vision models,thereby facilitating the development of vision-oriented AI. VisionGPT-3Dprovides a versatile multimodal framework building upon the strengths ofmultimodal foundation models. It seamlessly integrates various SOTA visionmodels and brings the automation in the selection of SOTA vision models,identifies the suitable 3D mesh creation algorithms corresponding to 2D depthmaps analysis, generates optimal results based on diverse multimodal inputssuch as text prompts. Keywords: VisionGPT-3D, 3D vision understanding, Multimodal agent</description><author>Chris Kelly, Luhui Hu, Jiayin Hu, Yu Tian, Deshun Yang, Bang Yang, Cindy Yang, Zihao Li, Zaoshan Huang, Yuexian Zou</author><pubDate>Thu, 14 Mar 2024 17:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09530v1</guid></item><item><title>MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation</title><link>http://arxiv.org/abs/2403.09522v1</link><description>Large Language Models (LLM) have demonstrated their strong ability in thefield of machine translation (MT), yet they suffer from high computational costand latency. Therefore, transferring translation knowledge from giant LLMs tomedium-sized machine translation models is a promising research direction.However, traditional knowledge distillation methods do not take the capabilityof student and teacher models into consideration, therefore repeatedly teachingstudent models on the knowledge they have learned, and failing to extend tonovel contexts and knowledge. In this paper, we propose a framework calledMT-Patcher, which transfers knowledge from LLMs to existing MT models in aselective, comprehensive and proactive manner. Considering the currenttranslation ability of student MT models, we only identify and correct theirtranslation errors, instead of distilling the whole translation from theteacher. Leveraging the strong language abilities of LLMs, we instruct LLMteachers to synthesize diverse contexts and anticipate more potential errorsfor the student. Experiment results on translating both specific languagephenomena and general MT benchmarks demonstrate that finetuning the student MTmodel on about 10% examples can achieve comparable results to the traditionalknowledge distillation method, and synthesized potential errors and diversecontexts further improve translation performances on unseen contexts and words.</description><author>Jiahuan Li, Shanbo Cheng, Shujian Huang, Jiajun Chen</author><pubDate>Thu, 14 Mar 2024 17:07:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09522v1</guid></item><item><title>You Only Learn One Query: Learning Unified Human Query for Single-Stage Multi-Person Multi-Task Human-Centric Perception</title><link>http://arxiv.org/abs/2312.05525v2</link><description>Human-centric perception (e.g. pedetrian detection, segmentation, poseestimation, and attribute analysis) is a long-standing problem for computervision. This paper introduces a unified and versatile framework (HQNet) forsingle-stage multi-person multi-task human-centric perception (HCP). Ourapproach centers on learning a unified human query representation, denoted asHuman Query, which captures intricate instance-level features for individualpersons and disentangles complex multi-person scenarios. Although different HCPtasks have been well-studied individually, single-stage multi-task learning ofHCP tasks has not been fully exploited in the literature due to the absence ofa comprehensive benchmark dataset. To address this gap, we proposeCOCO-UniHuman benchmark dataset to enable model development and comprehensiveevaluation. Experimental results demonstrate the proposed method'sstate-of-the-art performance among multi-task HCP models and its competitiveperformance compared to task-specific HCP models. Moreover, our experimentsunderscore Human Query's adaptability to new HCP tasks, thus demonstrating itsrobust generalization capability. Codes and data will be publicly accessible.</description><author>Sheng Jin, Shuhuai Li, Tong Li, Wentao Liu, Chen Qian, Ping Luo</author><pubDate>Thu, 14 Mar 2024 16:59:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05525v2</guid></item><item><title>Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information</title><link>http://arxiv.org/abs/2403.09516v1</link><description>Mitigating social biases typically requires identifying the social groupsassociated with each data sample. In this paper, we present DAFair, a novelapproach to address social bias in language models. Unlike traditional methodsthat rely on explicit demographic labels, our approach does not require anysuch information. Instead, we leverage predefined prototypical demographictexts and incorporate a regularization term during the fine-tuning process tomitigate bias in the model's representations. Our empirical results across twotasks and two models demonstrate the effectiveness of our method compared toprevious approaches that do not rely on labeled data. Moreover, with limiteddemographic-annotated data, our approach outperforms common debiasingapproaches.</description><author>Shadi Iskander, Kira Radinsky, Yonatan Belinkov</author><pubDate>Thu, 14 Mar 2024 16:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09516v1</guid></item><item><title>Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records</title><link>http://arxiv.org/abs/2403.08664v2</link><description>The challenge of accessing historical patient data for clinical research,while adhering to privacy regulations, is a significant obstacle in medicalscience. An innovative approach to circumvent this issue involves utilisingsynthetic medical records that mirror real patient data without compromisingindividual privacy. The creation of these synthetic datasets, particularlywithout using actual patient data to train Large Language Models (LLMs),presents a novel solution as gaining access to sensitive patient information totrain models is also a challenge. This study assesses the capability of theLlama 2 LLM to create synthetic medical records that accurately reflect realpatient information, employing zero-shot and few-shot prompting strategies forcomparison against fine-tuned methodologies that do require sensitive patientdata during training. We focus on generating synthetic narratives for theHistory of Present Illness section, utilising data from the MIMIC-IV datasetfor comparison. In this work introduce a novel prompting technique thatleverages a chain-of-thought approach, enhancing the model's ability togenerate more accurate and contextually relevant medical narratives withoutprior fine-tuning. Our findings suggest that this chain-of-thought promptedapproach allows the zero-shot model to achieve results on par with those offine-tuned models, based on Rouge metrics evaluation.</description><author>Erlend Frayling, Jake Lever, Graham McDonald</author><pubDate>Thu, 14 Mar 2024 16:57:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08664v2</guid></item><item><title>AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting</title><link>http://arxiv.org/abs/2403.09513v1</link><description>With the advent and widespread deployment of Multimodal Large Language Models(MLLMs), the imperative to ensure their safety has become increasinglypronounced. However, with the integration of additional modalities, MLLMs areexposed to new vulnerabilities, rendering them prone to structured-basedjailbreak attacks, where semantic content (e.g., "harmful text") has beeninjected into the images to mislead MLLMs. In this work, we aim to defendagainst such threats. Specifically, we propose \textbf{Ada}ptive\textbf{Shield} Prompting (\textbf{AdaShield}), which prepends inputs withdefense prompts to defend MLLMs against structure-based jailbreak attackswithout fine-tuning MLLMs or training additional modules (e.g., post-stagecontent detector). Initially, we present a manually designed static defenseprompt, which thoroughly examines the image and instruction content step bystep and specifies response methods to malicious queries. Furthermore, weintroduce an adaptive auto-refinement framework, consisting of a target MLLMand a LLM-based defense prompt generator (Defender). These componentscollaboratively and iteratively communicate to generate a defense prompt.Extensive experiments on the popular structure-based jailbreak attacks andbenign datasets show that our methods can consistently improve MLLMs'robustness against structure-based jailbreak attacks without compromising themodel's general capabilities evaluated on standard benign tasks. Our code isavailable at https://github.com/rain305f/AdaShield.</description><author>Yu Wang, Xiaogeng Liu, Yu Li, Muhao Chen, Chaowei Xiao</author><pubDate>Thu, 14 Mar 2024 16:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09513v1</guid></item><item><title>Trust AI Regulation? Discerning users are vital to build trust and effective AI regulation</title><link>http://arxiv.org/abs/2403.09510v1</link><description>There is general agreement that some form of regulation is necessary both forAI creators to be incentivised to develop trustworthy systems, and for users toactually trust those systems. But there is much debate about what form theseregulations should take and how they should be implemented. Most work in thisarea has been qualitative, and has not been able to make formal predictions.Here, we propose that evolutionary game theory can be used to quantitativelymodel the dilemmas faced by users, AI creators, and regulators, and provideinsights into the possible effects of different regulatory regimes. We showthat creating trustworthy AI and user trust requires regulators to beincentivised to regulate effectively. We demonstrate the effectiveness of twomechanisms that can achieve this. The first is where governments can recogniseand reward regulators that do a good job. In that case, if the AI system is nottoo risky for users then some level of trustworthy development and user trustevolves. We then consider an alternative solution, where users can conditiontheir trust decision on the effectiveness of the regulators. This leads toeffective regulation, and consequently the development of trustworthy AI anduser trust, provided that the cost of implementing regulations is not too high.Our findings highlight the importance of considering the effect of differentregulatory regimes from an evolutionary game theoretic perspective.</description><author>Zainab Alalawi, Paolo Bova, Theodor Cimpeanu, Alessandro Di Stefano, Manh Hong Duong, Elias Fernandez Domingos, The Anh Han, Marcus Krellner, Bianca Ogbo, Simon T. Powers, Filippo Zimmaro</author><pubDate>Thu, 14 Mar 2024 16:56:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09510v1</guid></item><item><title>On STPA for Distributed Development of Safe Autonomous Driving: An Interview Study</title><link>http://arxiv.org/abs/2403.09509v1</link><description>Safety analysis is used to identify hazards and build knowledge during thedesign phase of safety-relevant functions. This is especially true for complexAI-enabled and software intensive systems such as Autonomous Drive (AD).System-Theoretic Process Analysis (STPA) is a novel method applied insafety-related fields like defense and aerospace, which is also becomingpopular in the automotive industry. However, STPA assumes prerequisites thatare not fully valid in the automotive system engineering with distributedsystem development and multi-abstraction design levels. This would inhibitsoftware developers from using STPA to analyze their software as part of abigger system, resulting in a lack of traceability. This can be seen as amaintainability challenge in continuous development and deployment (DevOps). Inthis paper, STPA's different guidelines for the automotive industry, e.g.J31887/ISO21448/STPA handbook, are firstly compared to assess theirapplicability to the distributed development of complex AI-enabled systems likeAD. Further, an approach to overcome the challenges of using STPA in amulti-level design context is proposed. By conducting an interview study withautomotive industry experts for the development of AD, the challenges arevalidated and the effectiveness of the proposed approach is evaluated.</description><author>Ali Nouri, Christian Berger, Fredrik Törner</author><pubDate>Thu, 14 Mar 2024 16:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09509v1</guid></item><item><title>SkateFormer: Skeletal-Temporal Transformer for Human Action Recognition</title><link>http://arxiv.org/abs/2403.09508v1</link><description>Skeleton-based action recognition, which classifies human actions based onthe coordinates of joints and their connectivity within skeleton data, iswidely utilized in various scenarios. While Graph Convolutional Networks (GCNs)have been proposed for skeleton data represented as graphs, they suffer fromlimited receptive fields constrained by joint connectivity. To address thislimitation, recent advancements have introduced transformer-based methods.However, capturing correlations between all joints in all frames requiressubstantial memory resources. To alleviate this, we propose a novel approachcalled Skeletal-Temporal Transformer (SkateFormer) that partitions joints andframes based on different types of skeletal-temporal relation (Skate-Type) andperforms skeletal-temporal self-attention (Skate-MSA) within each partition. Wecategorize the key skeletal-temporal relations for action recognition into atotal of four distinct types. These types combine (i) two skeletal relationtypes based on physically neighboring and distant joints, and (ii) two temporalrelation types based on neighboring and distant frames. Through thispartition-specific attention strategy, our SkateFormer can selectively focus onkey joints and frames crucial for action recognition in an action-adaptivemanner with efficient computation. Extensive experiments on various benchmarkdatasets validate that our SkateFormer outperforms recent state-of-the-artmethods.</description><author>Jeonghyeok Do, Munchurl Kim</author><pubDate>Thu, 14 Mar 2024 16:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09508v1</guid></item><item><title>Model-free Reinforcement Learning of Semantic Communication by Stochastic Policy Gradient</title><link>http://arxiv.org/abs/2305.03571v2</link><description>Following the recent success of Machine Learning tools in wirelesscommunications, the idea of semantic communication by Weaver from 1949 hasgained attention. It breaks with Shannon's classic design paradigm by aiming totransmit the meaning, i.e., semantics, of a message instead of its exactversion, allowing for information rate savings. In this work, we apply theStochastic Policy Gradient (SPG) to design a semantic communication system byreinforcement learning, separating transmitter and receiver, and not requiringa known or differentiable channel model -- a crucial step towards deployment inpractice. Further, we derive the use of SPG for both classic and semanticcommunication from the maximization of the mutual information between receivedand target variables. Numerical results show that our approach achievescomparable performance to a model-aware approach based on the reparametrizationtrick, albeit with a decreased convergence rate.</description><author>Edgar Beck, Carsten Bockelmann, Armin Dekorsy</author><pubDate>Thu, 14 Mar 2024 16:54:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03571v2</guid></item><item><title>Don't Judge by the Look: A Motion Coherent Augmentation for Video Recognition</title><link>http://arxiv.org/abs/2403.09506v1</link><description>Current training pipelines in object recognition neglect Hue Jittering whendoing data augmentation as it not only brings appearance changes that aredetrimental to classification, but also the implementation is inefficient inpractice. In this study, we investigate the effect of hue variance in thecontext of video recognition and find this variance to be beneficial sincestatic appearances are less important in videos that contain motioninformation. Based on this observation, we propose a data augmentation methodfor video recognition, named Motion Coherent Augmentation (MCA), thatintroduces appearance variation in videos and implicitly encourages the modelto prioritize motion patterns, rather than static appearances. Concretely, wepropose an operation SwapMix to efficiently modify the appearance of videosamples, and introduce Variation Alignment (VA) to resolve the distributionshift caused by SwapMix, enforcing the model to learn appearance invariantrepresentations. Comprehensive empirical evaluation across variousarchitectures and different datasets solidly validates the effectiveness andgeneralization ability of MCA, and the application of VA in other augmentationmethods. Code is available at https://github.com/BeSpontaneous/MCA-pytorch.</description><author>Yitian Zhang, Yue Bai, Huan Wang, Yizhou Wang, Yun Fu</author><pubDate>Thu, 14 Mar 2024 16:53:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09506v1</guid></item><item><title>Stable Nonconvex-Nonconcave Training via Linear Interpolation</title><link>http://arxiv.org/abs/2310.13459v4</link><description>This paper presents a theoretical analysis of linear interpolation as aprincipled method for stabilizing (large-scale) neural network training. Weargue that instabilities in the optimization process are often caused by thenonmonotonicity of the loss landscape and show how linear interpolation canhelp by leveraging the theory of nonexpansive operators. We construct a newoptimization scheme called relaxed approximate proximal point (RAPP), which isthe first explicit method without anchoring to achieve last iterate convergencerates for $\rho$-comonotone problems while only requiring $\rho &gt;-\tfrac{1}{2L}$. The construction extends to constrained and regularizedsettings. By replacing the inner optimizer in RAPP we rediscover the family ofLookahead algorithms for which we establish convergence in cohypomonotoneproblems even when the base optimizer is taken to be gradient descent ascent.The range of cohypomonotone problems in which Lookahead converges is furtherexpanded by exploiting that Lookahead inherits the properties of the baseoptimizer. We corroborate the results with experiments on generativeadversarial networks which demonstrates the benefits of the linearinterpolation present in both RAPP and Lookahead.</description><author>Thomas Pethick, Wanyun Xie, Volkan Cevher</author><pubDate>Thu, 14 Mar 2024 16:52:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13459v4</guid></item><item><title>Osprey: Pixel Understanding with Visual Instruction Tuning</title><link>http://arxiv.org/abs/2312.10032v3</link><description>Multimodal large language models (MLLMs) have recently achieved impressivegeneral-purpose vision-language capabilities through visual instruction tuning.However, current MLLMs primarily focus on image-level or box-levelunderstanding, falling short in achieving fine-grained vision-languagealignment at pixel level. Besides, the lack of mask-based instruction datalimits their advancements. In this paper, we propose Osprey, a mask-textinstruction tuning approach, to extend MLLMs by incorporating fine-grained maskregions into language instruction, aiming at achieving pixel-wise visualunderstanding. To achieve this goal, we first meticulously curate a mask-basedregion-text dataset with 724K samples, and then design a vision-language modelby injecting pixel-level representation into LLM. Specifically, Osprey adopts aconvolutional CLIP backbone as the vision encoder and employs a mask-awarevisual extractor to extract precise visual mask features from high resolutioninput. Experimental results demonstrate Osprey's superiority in various regionunderstanding tasks, showcasing its new capability for pixel-level instructiontuning. In particular, Osprey can be integrated with Segment Anything Model(SAM) seamlessly to obtain multi-granularity semantics. The source code,dataset and demo can be found at https://github.com/CircleRadon/Osprey.</description><author>Yuqian Yuan, Wentong Li, Jian Liu, Dongqi Tang, Xinjie Luo, Chi Qin, Lei Zhang, Jianke Zhu</author><pubDate>Thu, 14 Mar 2024 16:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10032v3</guid></item><item><title>DiffSF: Diffusion Models for Scene Flow Estimation</title><link>http://arxiv.org/abs/2403.05327v2</link><description>Scene flow estimation is an essential ingredient for a variety of real-worldapplications, especially for autonomous agents, such as self-driving cars androbots. While recent scene flow estimation approaches achieve a reasonableaccuracy, their applicability to real-world systems additionally benefits froma reliability measure. Aiming at improving accuracy while additionallyproviding an estimate for uncertainty, we propose DiffSF that combinestransformer-based scene flow estimation with denoising diffusion models. In thediffusion process, the ground truth scene flow vector field is graduallyperturbed by adding Gaussian noise. In the reverse process, starting fromrandomly sampled Gaussian noise, the scene flow vector field prediction isrecovered by conditioning on a source and a target point cloud. We show thatthe diffusion process greatly increases the robustness of predictions comparedto prior approaches resulting in state-of-the-art performance on standard sceneflow estimation benchmarks. Moreover, by sampling multiple times with differentinitial states, the denoising process predicts multiple hypotheses, whichenables measuring the output uncertainty, allowing our approach to detect amajority of the inaccurate predictions. The code is available athttps://github.com/ZhangYushan3/DiffSF.</description><author>Yushan Zhang, Bastian Wandt, Maria Magnusson, Michael Felsberg</author><pubDate>Thu, 14 Mar 2024 16:48:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05327v2</guid></item><item><title>FedImpro: Measuring and Improving Client Update in Federated Learning</title><link>http://arxiv.org/abs/2402.07011v2</link><description>Federated Learning (FL) models often experience client drift caused byheterogeneous data, where the distribution of data differs across clients. Toaddress this issue, advanced research primarily focuses on manipulating theexisting gradients to achieve more consistent client models. In this paper, wepresent an alternative perspective on client drift and aim to mitigate it bygenerating improved local models. First, we analyze the generalizationcontribution of local training and conclude that this generalizationcontribution is bounded by the conditional Wasserstein distance between thedata distribution of different clients. Then, we propose FedImpro, to constructsimilar conditional distributions for local training. Specifically, FedImprodecouples the model into high-level and low-level components, and trains thehigh-level portion on reconstructed feature distributions. This approachenhances the generalization contribution and reduces the dissimilarity ofgradients in FL. Experimental results show that FedImpro can help FL defendagainst data heterogeneity and enhance the generalization performance of themodel.</description><author>Zhenheng Tang, Yonggang Zhang, Shaohuai Shi, Xinmei Tian, Tongliang Liu, Bo Han, Xiaowen Chu</author><pubDate>Thu, 14 Mar 2024 16:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07011v2</guid></item><item><title>EquiAV: Leveraging Equivariance for Audio-Visual Contrastive Learning</title><link>http://arxiv.org/abs/2403.09502v1</link><description>Recent advancements in self-supervised audio-visual representation learninghave demonstrated its potential to capture rich and comprehensiverepresentations. However, despite the advantages of data augmentation verifiedin many learning methods, audio-visual learning has struggled to fully harnessthese benefits, as augmentations can easily disrupt the correspondence betweeninput pairs. To address this limitation, we introduce EquiAV, a novel frameworkthat leverages equivariance for audio-visual contrastive learning. Our approachbegins with extending equivariance to audio-visual learning, facilitated by ashared attention-based transformation predictor. It enables the aggregation offeatures from diverse augmentations into a representative embedding, providingrobust supervision. Notably, this is achieved with minimal computationaloverhead. Extensive ablation studies and qualitative results verify theeffectiveness of our method. EquiAV outperforms previous works across variousaudio-visual benchmarks.</description><author>Jongsuk Kim, Hyeongkeun Lee, Kyeongha Rho, Junmo Kim, Joon Son Chung</author><pubDate>Thu, 14 Mar 2024 16:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09502v1</guid></item><item><title>Faceptor: A Generalist Model for Face Perception</title><link>http://arxiv.org/abs/2403.09500v1</link><description>With the comprehensive research conducted on various face analysis tasks,there is a growing interest among researchers to develop a unified approach toface perception. Existing methods mainly discuss unified representation andtraining, which lack task extensibility and application efficiency. To tacklethis issue, we focus on the unified model structure, exploring a facegeneralist model. As an intuitive design, Naive Faceptor enables tasks with thesame output shape and granularity to share the structural design of thestandardized output head, achieving improved task extensibility. Furthermore,Faceptor is proposed to adopt a well-designed single-encoder dual-decoderarchitecture, allowing task-specific queries to represent new-coming semantics.This design enhances the unification of model structure while improvingapplication efficiency in terms of storage overhead. Additionally, we introduceLayer-Attention into Faceptor, enabling the model to adaptively select featuresfrom optimal layers to perform the desired tasks. Through joint training on 13face perception datasets, Faceptor achieves exceptional performance in faciallandmark localization, face parsing, age estimation, expression recognition,binary attribute classification, and face recognition, achieving or surpassingspecialized methods in most tasks. Our training framework can also be appliedto auxiliary supervised learning, significantly improving performance indata-sparse tasks such as age estimation and expression recognition. The codeand models will be made publicly available athttps://github.com/lxq1000/Faceptor.</description><author>Lixiong Qin, Mei Wang, Xuannan Liu, Yuhang Zhang, Wei Deng, Xiaoshuai Song, Weiran Xu, Weihong Deng</author><pubDate>Thu, 14 Mar 2024 16:42:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09500v1</guid></item><item><title>A Reinforcement Learning Approach to Dairy Farm Battery Management using Q Learning</title><link>http://arxiv.org/abs/2403.09499v1</link><description>Dairy farming consumes a significant amount of energy, making it anenergy-intensive sector within agriculture. Integrating renewable energygeneration into dairy farming could help address this challenge. Effectivebattery management is important for integrating renewable energy generation.Managing battery charging and discharging poses significant challenges becauseof fluctuations in electrical consumption, the intermittent nature of renewableenergy generation, and fluctuations in energy prices. Artificial Intelligence(AI) has the potential to significantly improve the use of renewable energy indairy farming, however, there is limited research conducted in this particulardomain. This research considers Ireland as a case study as it works towardsattaining its 2030 energy strategy centered on the utilization of renewablesources. This study proposes a Q-learning-based algorithm for schedulingbattery charging and discharging in a dairy farm setting. This research alsoexplores the effect of the proposed algorithm by adding wind generation dataand considering additional case studies. The proposed algorithm reduces thecost of imported electricity from the grid by 13.41\%, peak demand by 2\%, and24.49\% when utilizing wind generation. These results underline howreinforcement learning is highly effective in managing batteries in the dairyfarming sector.</description><author>Nawazish Ali, Abdul Wahid, Rachael Shaw, Karl Mason</author><pubDate>Thu, 14 Mar 2024 16:42:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09499v1</guid></item><item><title>From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News</title><link>http://arxiv.org/abs/2403.09498v1</link><description>In the digital era, the rapid propagation of fake news and rumors via socialnetworks brings notable societal challenges and impacts public opinionregulation. Traditional fake news modeling typically forecasts the generalpopularity trends of different groups or numerically represents opinions shift.However, these methods often oversimplify real-world complexities and overlookthe rich semantic information of news text. The advent of large language models(LLMs) provides the possibility of modeling subtle dynamics of opinion.Consequently, in this work, we introduce a Fake news Propagation Simulationframework (FPS) based on LLM, which studies the trends and control of fake newspropagation in detail. Specifically, each agent in the simulation represents anindividual with a distinct personality. They are equipped with both short-termand long-term memory, as well as a reflective mechanism to mimic human-likethinking. Every day, they engage in random opinion exchanges, reflect on theirthinking, and update their opinions. Our simulation results uncover patterns infake news propagation related to topic relevance, and individual traits,aligning with real-world observations. Additionally, we evaluate variousintervention strategies and demonstrate that early and appropriately frequentinterventions strike a balance between governance cost and effectiveness,offering valuable insights for practical applications. Our study underscoresthe significant utility and potential of LLMs in combating fake news.</description><author>Yuhan Liu, Xiuying Chen, Xiaoqing Zhang, Xing Gao, Ji Zhang, Rui Yan</author><pubDate>Thu, 14 Mar 2024 16:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09498v1</guid></item><item><title>Most discriminative stimuli for functional cell type clustering</title><link>http://arxiv.org/abs/2401.05342v2</link><description>Identifying cell types and understanding their functional properties iscrucial for unraveling the mechanisms underlying perception and cognition. Inthe retina, functional types can be identified by carefully selected stimuli,but this requires expert domain knowledge and biases the procedure towardspreviously known cell types. In the visual cortex, it is still unknown whatfunctional types exist and how to identify them. Thus, for unbiasedidentification of the functional cell types in retina and visual cortex, newapproaches are needed. Here we propose an optimization-based clusteringapproach using deep predictive models to obtain functional clusters of neuronsusing Most Discriminative Stimuli (MDS). Our approach alternates betweenstimulus optimization with cluster reassignment akin to anexpectation-maximization algorithm. The algorithm recovers functional clustersin mouse retina, marmoset retina and macaque visual area V4. This demonstratesthat our approach can successfully find discriminative stimuli across species,stages of the visual system and recording techniques. The resulting mostdiscriminative stimuli can be used to assign functional cell types fast and onthe fly, without the need to train complex predictive models or show a largenatural scene dataset, paving the way for experiments that were previouslylimited by experimental time. Crucially, MDS are interpretable: they visualizethe distinctive stimulus patterns that most unambiguously identify a specifictype of neuron.</description><author>Max F. Burg, Thomas Zenkel, Michaela Vystrčilová, Jonathan Oesterle, Larissa Höfling, Konstantin F. Willeke, Jan Lause, Sarah Müller, Paul G. Fahey, Zhiwei Ding, Kelli Restivo, Shashwat Sridhar, Tim Gollisch, Philipp Berens, Andreas S. Tolias, Thomas Euler, Matthias Bethge, Alexander S. Ecker</author><pubDate>Thu, 14 Mar 2024 16:40:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05342v2</guid></item><item><title>A Comprehensive Dataset and Automated Pipeline for Nailfold Capillary Analysis</title><link>http://arxiv.org/abs/2312.05930v2</link><description>Nailfold capillaroscopy is widely used in assessing health conditions,highlighting the pressing need for an automated nailfold capillary analysissystem. In this study, we present a pioneering effort in constructing acomprehensive nailfold capillary dataset-321 images, 219 videos from 68subjects, with clinic reports and expert annotations-that serves as a crucialresource for training deep-learning models. Leveraging this dataset, wefinetuned three deep learning models with expert annotations as supervisedlabels and integrated them into a novel end-to-end nailfold capillary analysispipeline. This pipeline excels in automatically detecting and measuring a widerange of size factors, morphological features, and dynamic aspects of nailfoldcapillaries. We compared our outcomes with clinical reports. Experiment resultsshowed that our automated pipeline achieves an average of sub-pixel levelprecision in measurements and 89.9% accuracy in identifying morphologicalabnormalities. These results underscore its potential for advancingquantitative medical research and enabling pervasive computing in healthcare.Our data and code are available athttps://github.com/THU-CS-PI-LAB/ANFC-Automated-Nailfold-Capillary.</description><author>Linxi Zhao, Jiankai Tang, Dongyu Chen, Xiaohong Liu, Yong Zhou, Yuanchun Shi, Guangyu Wang, Yuntao Wang</author><pubDate>Thu, 14 Mar 2024 16:39:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05930v2</guid></item><item><title>AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation</title><link>http://arxiv.org/abs/2403.01818v3</link><description>Semi-supervised semantic segmentation (SSSS) has been proposed to alleviatethe burden of time-consuming pixel-level manual labeling, which leverageslimited labeled data along with larger amounts of unlabeled data. Currentstate-of-the-art methods train the labeled data with ground truths andunlabeled data with pseudo labels. However, the two training flows areseparate, which allows labeled data to dominate the training process, resultingin low-quality pseudo labels and, consequently, sub-optimal results. Toalleviate this issue, we present AllSpark, which reborns the labeled featuresfrom unlabeled ones with the channel-wise cross-attention mechanism. We furtherintroduce a Semantic Memory along with a Channel Semantic Grouping strategy toensure that unlabeled features adequately represent labeled features. TheAllSpark shed new light on the architecture level designs of SSSS rather thanframework level, which avoids increasingly complicated training pipelinedesigns. It can also be regarded as a flexible bottleneck module that can beseamlessly integrated into a general transformer-based segmentation model. Theproposed AllSpark outperforms existing methods across all evaluation protocolson Pascal, Cityscapes and COCO benchmarks without bells-and-whistles. Code andmodel weights are available at: https://github.com/xmed-lab/AllSpark.</description><author>Haonan Wang, Qixiang Zhang, Yi Li, Xiaomeng Li</author><pubDate>Thu, 14 Mar 2024 16:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01818v3</guid></item><item><title>K-pop Lyric Translation: Dataset, Analysis, and Neural-Modelling</title><link>http://arxiv.org/abs/2309.11093v2</link><description>Lyric translation, a field studied for over a century, is now attractingcomputational linguistics researchers. We identified two limitations inprevious studies. Firstly, lyric translation studies have predominantly focusedon Western genres and languages, with no previous study centering on K-popdespite its popularity. Second, the field of lyric translation suffers from alack of publicly available datasets; to the best of our knowledge, no suchdataset exists. To broaden the scope of genres and languages in lyrictranslation studies, we introduce a novel singable lyric translation dataset,approximately 89\% of which consists of K-pop song lyrics. This dataset alignsKorean and English lyrics line-by-line and section-by-section. We leveragedthis dataset to unveil unique characteristics of K-pop lyric translation,distinguishing it from other extensively studied genres, and to construct aneural lyric translation model, thereby underscoring the importance of adedicated dataset for singable lyric translations.</description><author>Haven Kim, Jongmin Jung, Dasaem Jeong, Juhan Nam</author><pubDate>Thu, 14 Mar 2024 16:36:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11093v2</guid></item><item><title>Plug and Play Active Learning for Object Detection</title><link>http://arxiv.org/abs/2211.11612v2</link><description>Annotating datasets for object detection is an expensive and time-consumingendeavor. To minimize this burden, active learning (AL) techniques are employedto select the most informative samples for annotation within a constrained"annotation budget". Traditional AL strategies typically rely on modeluncertainty or sample diversity for query sampling, while more advanced methodshave focused on developing AL-specific object detector architectures to enhanceperformance. However, these specialized approaches are not readily adaptable todifferent object detectors due to the significant engineering effort requiredfor integration. To overcome this challenge, we introduce Plug and Play ActiveLearning (PPAL), a simple and effective AL strategy for object detection. PPALis a two-stage method comprising uncertainty-based and diversity-based samplingphases. In the first stage, our Difficulty Calibrated Uncertainty Samplingleverage a category-wise difficulty coefficient that combines bothclassification and localisation difficulties to re-weight instanceuncertainties, from which we sample a candidate pool for the subsequentdiversity-based sampling. In the second stage, we propose Category ConditionedMatching Similarity to better compute the similarities of multi-instance imagesas ensembles of their instance similarities, which is used by the k-Means++algorithm to sample the final AL queries. PPAL makes no change to modelarchitectures or detector training pipelines; hence it can be easilygeneralized to different object detectors. We benchmark PPAL on the MS-COCO andPascal VOC datasets using different detector architectures and show that ourmethod outperforms prior work by a large margin. Code is available athttps://github.com/ChenhongyiYang/PPAL</description><author>Chenhongyi Yang, Lichao Huang, Elliot J. Crowley</author><pubDate>Thu, 14 Mar 2024 16:35:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11612v2</guid></item><item><title>Anomaly Detection by Adapting a pre-trained Vision Language Model</title><link>http://arxiv.org/abs/2403.09493v1</link><description>Recently, large vision and language models have shown their success whenadapting them to many downstream tasks. In this paper, we present a unifiedframework named CLIP-ADA for Anomaly Detection by Adapting a pre-trained CLIPmodel. To this end, we make two important improvements: 1) To acquire unifiedanomaly detection across industrial images of multiple categories, we introducethe learnable prompt and propose to associate it with abnormal patterns throughself-supervised learning. 2) To fully exploit the representation power of CLIP,we introduce an anomaly region refinement strategy to refine the localizationquality. During testing, the anomalies are localized by directly calculatingthe similarity between the representation of the learnable prompt and theimage. Comprehensive experiments demonstrate the superiority of our framework,e.g., we achieve the state-of-the-art 97.5/55.6 and 89.3/33.1 on MVTec-AD andVisA for anomaly detection and localization. In addition, the proposed methodalso achieves encouraging performance with marginal training data, which ismore challenging.</description><author>Yuxuan Cai, Xinwei He, Dingkang Liang, Ao Tong, Xiang Bai</author><pubDate>Thu, 14 Mar 2024 16:35:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09493v1</guid></item><item><title>On using Machine Learning Algorithms for Motorcycle Collision Detection</title><link>http://arxiv.org/abs/2403.09491v1</link><description>Globally, motorcycles attract vast and varied users. However, since the rateof severe injury and fatality in motorcycle accidents far exceeds passenger caraccidents, efforts have been directed toward increasing passive safety systems.Impact simulations show that the risk of severe injury or death in the event ofa motorcycle-to-car impact can be greatly reduced if the motorcycle is equippedwith passive safety measures such as airbags and seat belts. For the passivesafety systems to be activated, a collision must be detected withinmilliseconds for a wide variety of impact configurations, but under nocircumstances may it be falsely triggered. For the challenge of reliablydetecting impending collisions, this paper presents an investigation towardsthe applicability of machine learning algorithms. First, a series ofsimulations of accidents and driving operation is introduced to collect data totrain machine learning classification models. Their performance is henceforthassessed and compared via multiple representative and application-orientedcriteria.</description><author>Philipp Rodegast, Steffen Maier, Jonas Kneifl, Jörg Fehr</author><pubDate>Thu, 14 Mar 2024 16:32:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09491v1</guid></item><item><title>SOCIALITE-LLAMA: An Instruction-Tuned Model for Social Scientific Tasks</title><link>http://arxiv.org/abs/2402.01980v2</link><description>Social science NLP tasks, such as emotion or humor detection, are required tocapture the semantics along with the implicit pragmatics from text, often withlimited amounts of training data. Instruction tuning has been shown to improvethe many capabilities of large language models (LLMs) such as commonsensereasoning, reading comprehension, and computer programming. However, little isknown about the effectiveness of instruction tuning on the social domain whereimplicit pragmatic cues are often needed to be captured. We explore the use ofinstruction tuning for social science NLP tasks and introduce Socialite-Llama-- an open-source, instruction-tuned Llama. On a suite of 20 social sciencetasks, Socialite-Llama improves upon the performance of Llama as well asmatches or improves upon the performance of a state-of-the-art, multi-taskfinetuned model on a majority of them. Further, Socialite-Llama also leads toimprovement on 5 out of 6 related social tasks as compared to Llama, suggestinginstruction tuning can lead to generalized social understanding. All resourcesincluding our code, model and dataset can be found throughbit.ly/socialitellama.</description><author>Gourab Dey, Adithya V Ganesan, Yash Kumar Lal, Manal Shah, Shreyashee Sinha, Matthew Matero, Salvatore Giorgi, Vivek Kulkarni, H. Andrew Schwartz</author><pubDate>Thu, 14 Mar 2024 16:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01980v2</guid></item><item><title>Hyper-CL: Conditioning Sentence Representations with Hypernetworks</title><link>http://arxiv.org/abs/2403.09490v1</link><description>While the introduction of contrastive learning frameworks in sentencerepresentation learning has significantly contributed to advancements in thefield, it still remains unclear whether state-of-the-art sentence embeddingscan capture the fine-grained semantics of sentences, particularly whenconditioned on specific perspectives. In this paper, we introduce Hyper-CL, anefficient methodology that integrates hypernetworks with contrastive learningto compute conditioned sentence representations. In our proposed approach, thehypernetwork is responsible for transforming pre-computed condition embeddingsinto corresponding projection layers. This enables the same sentence embeddingsto be projected differently according to various conditions. Evaluation on tworepresentative conditioning benchmarks, namely conditional semantic textsimilarity and knowledge graph completion, demonstrates that Hyper-CL iseffective in flexibly conditioning sentence representations, showcasing itscomputational efficiency at the same time. We also provide a comprehensiveanalysis of the inner workings of our approach, leading to a betterinterpretation of its mechanisms.</description><author>Young Hyun Yoo, Jii Cha, Changhyeon Kim, Taeuk Kim</author><pubDate>Thu, 14 Mar 2024 16:30:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09490v1</guid></item><item><title>Rectifying Demonstration Shortcut in In-Context Learning</title><link>http://arxiv.org/abs/2403.09488v1</link><description>Large language models (LLMs) are able to solve various tasks with only a fewdemonstrations utilizing their in-context learning (ICL) abilities. However,LLMs often rely on their pre-trained semantic priors of demonstrations ratherthan on the input-label relationships to proceed with ICL prediction. In thiswork, we term this phenomenon as the `Demonstration Shortcut'. While previousworks have primarily focused on improving ICL prediction results for predefinedtasks, we aim to rectify the Demonstration Shortcut, thereby enabling the LLMto effectively learn new input-label relationships from demonstrations. Toachieve this, we introduce In-Context Calibration, a demonstration-awarecalibration method. We evaluate the effectiveness of the proposed method in twosettings: (1) the Original ICL Task using the standard label space and (2) theTask Learning setting, where the label space is replaced with semanticallyunrelated tokens. In both settings, In-Context Calibration demonstratessubstantial improvements, with results generalized across three LLM families(OPT, GPT, and Llama2) under various configurations.</description><author>Joonwon Jang, Sanghwan Jang, Wonbin Kweon, Minjin Jeon, Hwanjo Yu</author><pubDate>Thu, 14 Mar 2024 16:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09488v1</guid></item><item><title>SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams</title><link>http://arxiv.org/abs/2403.09486v1</link><description>Reconstructing a sequence of sharp images from the blurry input is crucialfor enhancing our insights into the captured scene and poses a significantchallenge due to the limited temporal features embedded in the image. Spikecameras, sampling at rates up to 40,000 Hz, have proven effective in capturingmotion features and beneficial for solving this ill-posed problem. Nonetheless,existing methods fall into the supervised learning paradigm, which suffers fromnotable performance degradation when applied to real-world scenarios thatdiverge from the synthetic training data domain. Moreover, the quality ofreconstructed images is capped by the generated images based on motion analysisinterpolation, which inherently differs from the actual scene, affecting thegeneralization ability of these methods in real high-speed scenarios. Toaddress these challenges, we propose the first self-supervised framework forthe task of spike-guided motion deblurring. Our approach begins with theformulation of a spike-guided deblurring model that explores the theoreticalrelationships among spike streams, blurry images, and their corresponding sharpsequences. We subsequently develop a self-supervised cascaded framework toalleviate the issues of spike noise and spatial-resolution mismatchingencountered in the deblurring model. With knowledge distillation andre-blurring loss, we further design a lightweight deblur network to generatehigh-quality sequences with brightness and texture consistency with theoriginal input. Quantitative and qualitative experiments conducted on ourreal-world and synthetic datasets with spikes validate the superiorgeneralization of the proposed framework. Our code, data and trained modelswill be available at \url{https://github.com/chenkang455/S-SDM}.</description><author>Kang Chen, Shiyan Chen, Jiyuan Zhang, Baoyue Zhang, Yajing Zheng, Tiejun Huang, Zhaofei Yu</author><pubDate>Thu, 14 Mar 2024 16:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09486v1</guid></item><item><title>Clinical Reasoning over Tabular Data and Text with Bayesian Networks</title><link>http://arxiv.org/abs/2403.09481v1</link><description>Bayesian networks are well-suited for clinical reasoning on tabular data, butare less compatible with natural language data, for which neural networksprovide a successful framework. This paper compares and discusses strategies toaugment Bayesian networks with neural text representations, both in agenerative and discriminative manner. This is illustrated with simulationresults for a primary care use case (diagnosis of pneumonia) and discussed in abroader clinical context.</description><author>Paloma Rabaey, Johannes Deleu, Stefan Heytens, Thomas Demeester</author><pubDate>Thu, 14 Mar 2024 16:25:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09481v1</guid></item><item><title>A Typology for Exploring the Mitigation of Shortcut Behavior</title><link>http://arxiv.org/abs/2203.03668v6</link><description>As machine learning models become increasingly larger, trained weaklysupervised on large, possibly uncurated data sets, it becomes increasinglyimportant to establish mechanisms for inspecting, interacting, and revisingmodels to mitigate learning shortcuts and guarantee their learned knowledge isaligned with human knowledge. The recently proposed XIL framework was developedfor this purpose, and several such methods have been introduced, each withindividual motivations and methodological details. In this work, we provide aunification of various XIL methods into a single typology by establishing acommon set of basic modules. In doing so, we pave the way for a principledcomparison of existing, but, importantly, also future XIL approaches. Inaddition, we discuss existing and introduce novel measures and benchmarks forevaluating the overall abilities of a XIL method. Given this extensive toolbox,including our typology, measures, and benchmarks, we finally compare severalrecent XIL methods methodologically and quantitatively. In our evaluations, allmethods prove to revise a model successfully. However, we found remarkabledifferences in individual benchmark tasks, revealing valuableapplication-relevant aspects for integrating these benchmarks in developingfuture methods.</description><author>Felix Friedrich, Wolfgang Stammer, Patrick Schramowski, Kristian Kersting</author><pubDate>Thu, 14 Mar 2024 16:25:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.03668v6</guid></item></channel></rss>