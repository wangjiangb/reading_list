<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 29 Feb 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>UniMODE: Unified Monocular 3D Object Detection</title><link>http://arxiv.org/abs/2402.18573v1</link><description>Realizing unified monocular 3D object detection, including both indoor andoutdoor scenes, holds great importance in applications like robot navigation.However, involving various scenarios of data to train models poses challengesdue to their significantly different characteristics, e.g., diverse geometryproperties and heterogeneous domain distributions. To address these challenges,we build a detector based on the bird's-eye-view (BEV) detection paradigm,where the explicit feature projection is beneficial to addressing the geometrylearning ambiguity when employing multiple scenarios of data to traindetectors. Then, we split the classical BEV detection architecture into twostages and propose an uneven BEV grid design to handle the convergenceinstability caused by the aforementioned challenges. Moreover, we develop asparse BEV feature projection strategy to reduce computational cost and aunified domain alignment method to handle heterogeneous domains. Combiningthese techniques, a unified detector UniMODE is derived, which surpasses theprevious state-of-the-art on the challenging Omni3D dataset (a large-scaledataset including both indoor and outdoor scenes) by 4.9% AP_3D, revealing thefirst successful generalization of a BEV detector to unified 3D objectdetection.</description><author>Zhuoling Li, Xiaogang Xu, SerNam Lim, Hengshuang Zhao</author><pubDate>Wed, 28 Feb 2024 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18573v1</guid></item><item><title>Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards</title><link>http://arxiv.org/abs/2402.18571v1</link><description>Fine-grained control over large language models (LLMs) remains a significantchallenge, hindering their adaptability to diverse user needs. WhileReinforcement Learning from Human Feedback (RLHF) shows promise in aligningLLMs, its reliance on scalar rewards often limits its ability to capturediverse user preferences in real-world applications. To address thislimitation, we introduce the Directional Preference Alignment (DPA) framework.Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modelingto represent diverse preference profiles. Additionally, DPA models userpreferences as directions (i.e., unit vectors) in the reward space to achieveuser-dependent preference control. Our method involves training amulti-objective reward model and then fine-tuning the LLM with apreference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHFmethod adopted by Llama 2. This method enjoys a better performance trade-offacross various reward objectives. In comparison with the scalar-reward RLHF,DPA offers users intuitive control over LLM generation: they can arithmeticallyspecify their desired trade-offs (e.g., more helpfulness with less verbosity).We also validate the effectiveness of DPA with real-world alignment experimentson Mistral-7B. Our method provides straightforward arithmetic control over thetrade-off between helpfulness and verbosity while maintaining competitiveperformance with strong baselines such as Direct Preference Optimization (DPO).</description><author>Haoxiang Wang, Yong Lin, Wei Xiong, Rui Yang, Shizhe Diao, Shuang Qiu, Han Zhao, Tong Zhang</author><pubDate>Wed, 28 Feb 2024 18:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18571v1</guid></item><item><title>Diffusion Language Models Are Versatile Protein Learners</title><link>http://arxiv.org/abs/2402.18567v1</link><description>This paper introduces diffusion protein language model (DPLM), a versatileprotein language model that demonstrates strong generative and predictivecapabilities for protein sequences. We first pre-train scalable DPLMs fromevolutionary-scale protein sequences within a generative self-superviseddiscrete diffusion probabilistic framework, which generalizes language modelingfor proteins in a principled way. After pre-training, DPLM exhibits the abilityto generate structurally plausible, novel, and diverse protein sequences forunconditional generation. We further demonstrate the proposed diffusiongenerative pre-training makes DPLM possess a better understanding of proteins,making it a superior representation learner, which can be fine-tuned forvarious predictive tasks, comparing favorably to ESM2 (Lin et al., 2022).Moreover, DPLM can be tailored for various needs, which showcases its prowessof conditional generation in several ways: (1) conditioning on partial peptidesequences, e.g., generating scaffolds for functional motifs with high successrate; (2) incorporating other modalities as conditioner, e.g.,structure-conditioned generation for inverse folding; and (3) steering sequencegeneration towards desired properties, e.g., satisfying specified secondarystructures, through a plug-and-play classifier guidance.</description><author>Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, Quanquan Gu</author><pubDate>Wed, 28 Feb 2024 18:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18567v1</guid></item><item><title>Bayesian Prognostic Covariate Adjustment With Additive Mixture Priors</title><link>http://arxiv.org/abs/2310.18027v4</link><description>Effective and rapid decision-making from randomized controlled trials (RCTs)requires unbiased and precise treatment effect inferences. Two strategies toaddress this requirement are to adjust for covariates that are highlycorrelated with the outcome, and to leverage historical control information viaBayes' theorem. We propose a new Bayesian prognostic covariate adjustmentmethodology, referred to as Bayesian PROCOVA, that combines these twostrategies. Covariate adjustment in Bayesian PROCOVA is based on generativeartificial intelligence (AI) algorithms that construct a digital twin generator(DTG) for RCT participants. The DTG is trained on historical control data andyields a digital twin (DT) probability distribution for each RCT participant'soutcome under the control treatment. The expectation of the DT distribution,referred to as the prognostic score, defines the covariate for adjustment.Historical control information is leveraged via an additive mixture prior withtwo components: an informative prior probability distribution specified basedon historical control data, and a weakly informative prior distribution. Themixture weight determines the extent to which posterior inferences are drawnfrom the informative component, versus the weakly informative component. Thisweight has a prior distribution as well, and so the entire additive mixtureprior is completely pre-specifiable without involving any RCT information. Weestablish an efficient Gibbs algorithm for sampling from the posteriordistribution, and derive closed-form expressions for the posterior mean andvariance of the treatment effect parameter conditional on the weight, inBayesian PROCOVA. We evaluate efficiency gains of Bayesian PROCOVA via its biascontrol and variance reduction compared to frequentist PROCOVA in simulationstudies that encompass different discrepancies. These gains translate tosmaller RCTs.</description><author>Alyssa M. Vanderbeek, Arman Sabbaghi, Jon R. Walsh, Charles K. Fisher</author><pubDate>Wed, 28 Feb 2024 18:57:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18027v4</guid></item><item><title>Approaching Human-Level Forecasting with Language Models</title><link>http://arxiv.org/abs/2402.18563v1</link><description>Forecasting future events is important for policy and decision making. Inthis work, we study whether language models (LMs) can forecast at the level ofcompetitive human forecasters. Towards this goal, we develop aretrieval-augmented LM system designed to automatically search for relevantinformation, generate forecasts, and aggregate predictions. To facilitate ourstudy, we collect a large dataset of questions from competitive forecastingplatforms. Under a test set published after the knowledge cut-offs of our LMs,we evaluate the end-to-end performance of our system against the aggregates ofhuman forecasts. On average, the system nears the crowd aggregate ofcompetitive forecasters, and in some settings surpasses it. Our work suggeststhat using LMs to forecast the future could provide accurate predictions atscale and help to inform institutional decision making.</description><author>Danny Halawi, Fred Zhang, Chen Yueh-Han, Jacob Steinhardt</author><pubDate>Wed, 28 Feb 2024 18:54:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18563v1</guid></item><item><title>Evaluating the Utility of Conformal Prediction Sets for AI-Advised Image Labeling</title><link>http://arxiv.org/abs/2401.08876v4</link><description>As deep neural networks are more commonly deployed in high-stakes domains,their black-box nature makes uncertainty quantification challenging. Weinvestigate the effects of presenting conformal prediction sets -- adistribution-free class of methods for generating prediction sets withspecified coverage -- to express uncertainty in AI-advised decision-making.Through a large online experiment, we compare the utility of conformalprediction sets to displays of Top-$1$ and Top-$k$ predictions for AI-advisedimage labeling. In a pre-registered analysis, we find that the utility ofprediction sets for accuracy varies with the difficulty of the task: while theyresult in accuracy on par with or less than Top-$1$ and Top-$k$ displays foreasy images, prediction sets excel at assisting humans in labelingout-of-distribution (OOD) images, especially when the set size is small. Ourresults empirically pinpoint practical challenges of conformal prediction setsand provide implications on how to incorporate them for real-worlddecision-making.</description><author>Dongping Zhang, Angelos Chatzimparmpas, Negar Kamali, Jessica Hullman</author><pubDate>Wed, 28 Feb 2024 18:47:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08876v4</guid></item><item><title>Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes</title><link>http://arxiv.org/abs/2310.01840v2</link><description>Merging multi-exposure images is a common approach for obtaining high dynamicrange (HDR) images, with the primary challenge being the avoidance of ghostingartifacts in dynamic scenes. Recent methods have proposed using deep neuralnetworks for deghosting. However, the methods typically rely on sufficient datawith HDR ground-truths, which are difficult and costly to collect. In thiswork, to eliminate the need for labeled data, we propose SelfHDR, aself-supervised HDR reconstruction method that only requires dynamicmulti-exposure images during training. Specifically, SelfHDR learns areconstruction network under the supervision of two complementary components,which can be constructed from multi-exposure images and focus on HDR color aswell as structure, respectively. The color component is estimated from alignedmulti-exposure images, while the structure one is generated through astructure-focused network that is supervised by the color component and aninput reference (\eg, medium-exposure) image. During testing, the learnedreconstruction network is directly deployed to predict an HDR image.Experiments on real-world images demonstrate our SelfHDR achieves superiorresults against the state-of-the-art self-supervised methods, and comparableperformance to supervised ones. Codes are available athttps://github.com/cszhilu1998/SelfHDR</description><author>Zhilu Zhang, Haoyu Wang, Shuai Liu, Xiaotao Wang, Lei Lei, Wangmeng Zuo</author><pubDate>Wed, 28 Feb 2024 18:45:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01840v2</guid></item><item><title>Numerical Stability of DeepGOPlus Inference</title><link>http://arxiv.org/abs/2212.06361v4</link><description>Convolutional neural networks (CNNs) are currently among the most widely-useddeep neural network (DNN) architectures available and achieve state-of-the-artperformance for many problems. Originally applied to computer vision tasks,CNNs work well with any data with a spatial relationship, besides images, andhave been applied to different fields. However, recent works have highlightednumerical stability challenges in DNNs, which also relates to their knownsensitivity to noise injection. These challenges can jeopardise theirperformance and reliability. This paper investigates DeepGOPlus, a CNN thatpredicts protein function. DeepGOPlus has achieved state-of-the-art performanceand can successfully take advantage and annotate the abounding proteinsequences emerging in proteomics. We determine the numerical stability of themodel's inference stage by quantifying the numerical uncertainty resulting fromperturbations of the underlying floating-point data. In addition, we explorethe opportunity to use reduced-precision floating point formats for DeepGOPlusinference, to reduce memory consumption and latency. This is achieved byinstrumenting DeepGOPlus' execution using Monte Carlo Arithmetic, a techniquethat experimentally quantifies floating point operation errors and VPREC, atool that emulates results with customizable floating point precision formats.Focus is placed on the inference stage as it is the primary deliverable of theDeepGOPlus model, widely applicable across different environments. All in all,our results show that although the DeepGOPlus CNN is very stable numerically,it can only be selectively implemented with lower-precision floating-pointformats. We conclude that predictions obtained from the pre-trained DeepGOPlusmodel are very reliable numerically, and use existing floating-point formatsefficiently.</description><author>Inés Gonzalez Pepe, Yohan Chatelain, Gregory Kiar, Tristan Glatard</author><pubDate>Wed, 28 Feb 2024 18:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.06361v4</guid></item><item><title>Identification and Estimation for Nonignorable Missing Data: A Data Fusion Approach</title><link>http://arxiv.org/abs/2311.09015v2</link><description>We consider the task of identifying and estimating a parameter of interest insettings where data is missing not at random (MNAR). In general, suchparameters are not identified without strong assumptions on the missing datamodel. In this paper, we take an alternative approach and introduce a methodinspired by data fusion, where information in an MNAR dataset is augmented byinformation in an auxiliary dataset subject to missingness at random (MAR). Weshow that even if the parameter of interest cannot be identified given eitherdataset alone, it can be identified given pooled data, under two complementarysets of assumptions. We derive an inverse probability weighted (IPW) estimatorfor identified parameters, and evaluate the performance of our estimationstrategies via simulation studies, and a data application.</description><author>Zixiao Wang, AmirEmad Ghassami, Ilya Shpitser</author><pubDate>Wed, 28 Feb 2024 18:36:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09015v2</guid></item><item><title>Selection of appropriate multispectral camera exposure settings and radiometric calibration methods for applications in phenotyping and precision agriculture</title><link>http://arxiv.org/abs/2402.18553v1</link><description>Radiometric accuracy of data is crucial in quantitative precisionagriculture, to produce reliable and repeatable data for modeling and decisionmaking. The effect of exposure time and gain settings on the radiometricaccuracy of multispectral images was not explored enough. The goal of thisstudy was to determine if having a fixed exposure (FE) time during imageacquisition improved radiometric accuracy of images, compared to the defaultauto-exposure (AE) settings. This involved quantifying the errors fromauto-exposure and determining ideal exposure values within which radiometricmean absolute percentage error (MAPE) were minimal (&lt; 5%). The results showedthat FE orthomosaic was closer to ground-truth (higher R2 and lower MAPE) thanAE orthomosaic. An ideal exposure range was determined for capturing canopy andsoil objects, without loss of information from under-exposure or saturationfrom over-exposure. A simulation of errors from AE showed that MAPE &lt; 5% forthe blue, green, red, and NIR bands and &lt; 7% for the red edge band for exposuresettings within the determined ideal ranges and increased exponentially beyondthe ideal exposure upper limit. Further, prediction of total plant nitrogenuptake (g/plant) using vegetation indices (VIs) from two different growingseasons were closer to the ground truth (mostly, R2 &gt; 0.40, and MAPE = 12 to14%, p &lt; 0.05) when FE was used, compared to the prediction from AE images(mostly, R2 &lt; 0.13, MAPE = 15 to 18%, p &gt;= 0.05).</description><author>Vaishali Swaminathan, J. Alex Thomasson, Robert G. Hardin, Nithya Rajan</author><pubDate>Wed, 28 Feb 2024 18:35:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18553v1</guid></item><item><title>Implicit Bias of Next-Token Prediction</title><link>http://arxiv.org/abs/2402.18551v1</link><description>Next-token prediction (NTP), the go-to training paradigm in training largelanguage models, involves predicting the next token in a sequence. Departingfrom traditional one-hot classification, in NTP, multiple tokens with varyingfrequencies follow each given context. This work frames NTP training ascross-entropy minimization over distinct contexts, each associated with asparse empirical probability vector across a finite vocabulary. It thenaddresses the following question: do gradient-based optimizers exhibit a biastowards solutions with specific structure as the NTP training loss reaches itslower bound (entropy)? Specifically, for linear NTP models trained usinggradient descent (GD), we make the following contributions: Firstly, wedetermine NTP-separability conditions on the data, under which GD can attainits lower bound. We also demonstrate that these conditions hold underoverparameterization. Secondly, we establish that the parameters of GDprojected onto an appropriate data subspace converge to the unique solution ofa system of linear equations, which requires the logits' difference ofin-support tokens to be equal to the log-ratio of their respectiveprobabilities. Meanwhile, on the orthogonal subspace, the parameters divergeand converge in the direction of the solution of a max-margin quadraticprogram, minimizing the Euclidean norm of parameters satisfying the\NTP-separability conditions. Akin to prior research on implicit bias ofone-hot classification, our work opens exciting avenues for future researchthat can lead to better understanding optimization, generalization androbustness principles of models trained with NTP.</description><author>Christos Thrampoulidis</author><pubDate>Wed, 28 Feb 2024 18:34:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18551v1</guid></item><item><title>ToDo: Token Downsampling for Efficient Generation of High-Resolution Images</title><link>http://arxiv.org/abs/2402.13573v2</link><description>Attention mechanism has been crucial for image diffusion models, however,their quadratic computational complexity limits the sizes of images we canprocess within reasonable time and memory constraints. This paper investigatesthe importance of dense attention in generative image models, which oftencontain redundant features, making them suitable for sparser attentionmechanisms. We propose a novel training-free method ToDo that relies on tokendownsampling of key and value tokens to accelerate Stable Diffusion inferenceby up to 2x for common sizes and up to 4.5x or more for high resolutions like2048x2048. We demonstrate that our approach outperforms previous methods inbalancing efficient throughput and fidelity.</description><author>Ethan Smith, Nayan Saxena, Aninda Saha</author><pubDate>Wed, 28 Feb 2024 18:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13573v2</guid></item><item><title>Generalizability Under Sensor Failure: Tokenization + Transformers Enable More Robust Latent Spaces</title><link>http://arxiv.org/abs/2402.18546v1</link><description>A major goal in neuroscience is to discover neural data representations thatgeneralize. This goal is challenged by variability along recording sessions(e.g. environment), subjects (e.g. varying neural structures), and sensors(e.g. sensor noise), among others. Recent work has begun to addressgeneralization across sessions and subjects, but few study robustness to sensorfailure which is highly prevalent in neuroscience experiments. In order toaddress these generalizability dimensions we first collect our ownelectroencephalography dataset with numerous sessions, subjects, and sensors,then study two time series models: EEGNet (Lawhern et al., 2018) and TOTEM(Talukder et al., 2024). EEGNet is a widely used convolutional neural network,while TOTEM is a discrete time series tokenizer and transformer model. We findthat TOTEM outperforms or matches EEGNet across all generalizability cases.Finally through analysis of TOTEM's latent codebook we observe thattokenization enables generalization.</description><author>Geeling Chau, Yujin An, Ahamed Raffey Iqbal, Soon-Jo Chung, Yisong Yue, Sabera Talukder</author><pubDate>Wed, 28 Feb 2024 18:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18546v1</guid></item><item><title>Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates</title><link>http://arxiv.org/abs/2402.18540v1</link><description>Public LLMs such as the Llama 2-Chat have driven huge activity in LLMresearch. These models underwent alignment training and were considered safe.Recently Qi et al. (2023) reported that even benign fine-tuning (e.g., onseemingly safe datasets) can give rise to unsafe behaviors in the models. Thecurrent paper is about methods and best practices to mitigate such loss ofalignment. Through extensive experiments on several chat models (Meta's Llama2-Chat, Mistral AI's Mistral 7B Instruct v0.2, and OpenAI's GPT-3.5 Turbo),this paper uncovers that the prompt templates used during fine-tuning andinference play a crucial role in preserving safety alignment, and proposes the"Pure Tuning, Safe Testing" (PTST) principle -- fine-tune models without asafety prompt, but include it at test time. Fine-tuning experiments on GSM8K,ChatDoctor, and OpenOrca show that PTST significantly reduces the rise ofunsafe behaviors, and even almost eliminates them in some cases.</description><author>Kaifeng Lyu, Haoyu Zhao, Xinran Gu, Dingli Yu, Anirudh Goyal, Sanjeev Arora</author><pubDate>Wed, 28 Feb 2024 18:23:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18540v1</guid></item><item><title>Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models</title><link>http://arxiv.org/abs/2402.17177v2</link><description>Sora is a text-to-video generative AI model, released by OpenAI in February2024. The model is trained to generate videos of realistic or imaginativescenes from text instructions and show potential in simulating the physicalworld. Based on public technical reports and reverse engineering, this paperpresents a comprehensive review of the model's background, relatedtechnologies, applications, remaining challenges, and future directions oftext-to-video AI models. We first trace Sora's development and investigate theunderlying technologies used to build this "world simulator". Then, we describein detail the applications and potential impact of Sora in multiple industriesranging from film-making and education to marketing. We discuss the mainchallenges and limitations that need to be addressed to widely deploy Sora,such as ensuring safe and unbiased video generation. Lastly, we discuss thefuture development of Sora and video generation models in general, and howadvancements in the field could enable new ways of human-AI interaction,boosting productivity and creativity of video generation.</description><author>Yixin Liu, Kai Zhang, Yuan Li, Zhiling Yan, Chujie Gao, Ruoxi Chen, Zhengqing Yuan, Yue Huang, Hanchi Sun, Jianfeng Gao, Lifang He, Lichao Sun</author><pubDate>Wed, 28 Feb 2024 18:20:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17177v2</guid></item><item><title>Looping in the Human Collaborative and Explainable Bayesian Optimization</title><link>http://arxiv.org/abs/2310.17273v4</link><description>Like many optimizers, Bayesian optimization often falls short of gaining usertrust due to opacity. While attempts have been made to develop human-centricoptimizers, they typically assume user knowledge is well-specified anderror-free, employing users mainly as supervisors of the optimization process.We relax these assumptions and propose a more balanced human-AI partnershipwith our Collaborative and Explainable Bayesian Optimization (CoExBO)framework. Instead of explicitly requiring a user to provide a knowledge model,CoExBO employs preference learning to seamlessly integrate human insights intothe optimization, resulting in algorithmic suggestions that resonate with userpreference. CoExBO explains its candidate selection every iteration to fostertrust, empowering users with a clearer grasp of the optimization. Furthermore,CoExBO offers a no-harm guarantee, allowing users to make mistakes; even withextreme adversarial interventions, the algorithm converges asymptotically to avanilla Bayesian optimization. We validate CoExBO's efficacy through human-AIteaming experiments in lithium-ion battery design, highlighting substantialimprovements over conventional methods. Code is availablehttps://github.com/ma921/CoExBO.</description><author>Masaki Adachi, Brady Planden, David A. Howey, Michael A. Osborne, Sebastian Orbell, Natalia Ares, Krikamol Muandet, Siu Lun Chau</author><pubDate>Wed, 28 Feb 2024 18:12:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17273v4</guid></item><item><title>Gradient Reweighting: Towards Imbalanced Class-Incremental Learning</title><link>http://arxiv.org/abs/2402.18528v1</link><description>Class-Incremental Learning (CIL) trains a model to continually recognize newclasses from non-stationary data while retaining learned knowledge. A majorchallenge of CIL arises when applying to real-world data characterized bynon-uniform distribution, which introduces a dual imbalance problem involving(i) disparities between stored exemplars of old tasks and new class data(inter-phase imbalance), and (ii) severe class imbalances within eachindividual task (intra-phase imbalance). We show that this dual imbalance issuecauses skewed gradient updates with biased weights in FC layers, thus inducingover/under-fitting and catastrophic forgetting in CIL. Our method addresses itby reweighting the gradients towards balanced optimization and unbiasedclassifier learning. Additionally, we observe imbalanced forgetting whereparadoxically the instance-rich classes suffer higher performance degradationduring CIL due to a larger amount of training data becoming unavailable insubsequent learning phases. To tackle this, we further introduce adistribution-aware knowledge distillation loss to mitigate forgetting byaligning output logits proportionally with the distribution of lost trainingdata. We validate our method on CIFAR-100, ImageNetSubset, and Food101 acrossvarious evaluation protocols and demonstrate consistent improvements comparedto existing works, showing great potential to apply CIL in real-world scenarioswith enhanced robustness and effectiveness.</description><author>Jiangpeng He, Fengqing Zhu</author><pubDate>Wed, 28 Feb 2024 18:08:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18528v1</guid></item><item><title>Defect Detection in Tire X-Ray Images: Conventional Methods Meet Deep Structures</title><link>http://arxiv.org/abs/2402.18527v1</link><description>This paper introduces a robust approach for automated defect detection intire X-ray images by harnessing traditional feature extraction methods such asLocal Binary Pattern (LBP) and Gray Level Co-Occurrence Matrix (GLCM) features,as well as Fourier and Wavelet-based features, complemented by advanced machinelearning techniques. Recognizing the challenges inherent in the complexpatterns and textures of tire X-ray images, the study emphasizes thesignificance of feature engineering to enhance the performance of defectdetection systems. By meticulously integrating combinations of these featureswith a Random Forest (RF) classifier and comparing them against advanced modelslike YOLOv8, the research not only benchmarks the performance of traditionalfeatures in defect detection but also explores the synergy between classicaland modern approaches. The experimental results demonstrate that thesetraditional features, when fine-tuned and combined with machine learningmodels, can significantly improve the accuracy and reliability of tire defectdetection, aiming to set a new standard in automated quality assurance in tiremanufacturing.</description><author>Andrei Cozma, Landon Harris, Hairong Qi, Ping Ji, Wenpeng Guo, Song Yuan</author><pubDate>Wed, 28 Feb 2024 18:07:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18527v1</guid></item><item><title>Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology</title><link>http://arxiv.org/abs/2310.05227v3</link><description>Accurate hydrological understanding and water cycle prediction are crucialfor addressing scientific and societal challenges associated with themanagement of water resources, particularly under the dynamic influence ofanthropogenic climate change. Existing reviews predominantly concentrate on thedevelopment of machine learning (ML) in this field, yet there is a cleardistinction between hydrology and ML as separate paradigms. Here, we introducephysics-aware ML as a transformative approach to overcome the perceived barrierand revolutionize both fields. Specifically, we present a comprehensive reviewof the physics-aware ML methods, building a structured community (PaML) ofexisting methodologies that integrate prior physical knowledge or physics-basedmodeling into ML. We systematically analyze these PaML methodologies withrespect to four aspects: physical data-guided ML, physics-informed ML,physics-embedded ML, and physics-aware hybrid learning. PaML facilitatesML-aided hypotheses, accelerating insights from big data and fosteringscientific discoveries. We first conduct a systematic review of hydrology inPaML, including rainfall-runoff hydrological processes and hydrodynamicprocesses, and highlight the most promising and challenging directions fordifferent objectives and PaML methods. Finally, a new PaML-based hydrologyplatform, termed HydroPML, is released as a foundation for hydrologicalapplications. HydroPML enhances the explainability and causality of ML and laysthe groundwork for the digital water cycle's realization. The HydroPML platformis publicly available at https://hydropml.github.io/.</description><author>Qingsong Xu, Yilei Shi, Jonathan Bamber, Ye Tuo, Ralf Ludwig, Xiao Xiang Zhu</author><pubDate>Wed, 28 Feb 2024 18:04:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05227v3</guid></item><item><title>Detecting algorithmic bias in medical AI-models</title><link>http://arxiv.org/abs/2312.02959v3</link><description>With the growing prevalence of machine learning and artificialintelligence-based medical decision support systems, it is equally important toensure that these systems provide patient outcomes in a fair and equitablefashion. This paper presents an innovative framework for detecting areas ofalgorithmic bias in medical-AI decision support systems. Our approachefficiently identifies potential biases in medical-AI models, specifically inthe context of sepsis prediction, by employing the Classification andRegression Trees (CART) algorithm. We verify our methodology by conducting aseries of synthetic data experiments, showcasing its ability to estimate areasof bias in controlled settings precisely. The effectiveness of the concept isfurther validated by experiments using electronic medical records from GradyMemorial Hospital in Atlanta, Georgia. These tests demonstrate the practicalimplementation of our strategy in a clinical environment, where it can functionas a vital instrument for guaranteeing fairness and equity in AI-based medicaldecisions.</description><author>Jeffrey Smith, Andre Holder, Rishikesan Kamaleswaran, Yao Xie</author><pubDate>Wed, 28 Feb 2024 17:40:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02959v3</guid></item><item><title>Log Neural Controlled Differential Equations: The Lie Brackets Make a Difference</title><link>http://arxiv.org/abs/2402.18512v1</link><description>The vector field of a controlled differential equation (CDE) describes therelationship between a control path and the evolution of a solution path.Neural CDEs (NCDEs) treat time series data as observations from a control path,parameterise a CDE's vector field using a neural network, and use the solutionpath as a continuously evolving hidden state. As their formulation makes themrobust to irregular sampling rates, NCDEs are a powerful approach for modellingreal-world data. Building on neural rough differential equations (NRDEs), weintroduce Log-NCDEs, a novel and effective method for training NCDEs. The corecomponent of Log-NCDEs is the Log-ODE method, a tool from the study of roughpaths for approximating a CDE's solution. On a range of multivariate timeseries classification benchmarks, Log-NCDEs are shown to achieve a higheraverage test set accuracy than NCDEs, NRDEs, and two state-of-the-art models,S5 and the linear recurrent unit.</description><author>Benjamin Walker, Andrew D. McLeod, Tiexin Qin, Yichuan Cheng, Haoliang Li, Terry Lyons</author><pubDate>Wed, 28 Feb 2024 17:40:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18512v1</guid></item><item><title>RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval</title><link>http://arxiv.org/abs/2402.18510v1</link><description>This paper investigates the gap in representation powers of Recurrent NeuralNetworks (RNNs) and Transformers in the context of solving algorithmicproblems. We focus on understanding whether RNNs, known for their memoryefficiency in handling long sequences, can match the performance ofTransformers, particularly when enhanced with Chain-of-Thought (CoT) prompting.Our theoretical analysis reveals that CoT improves RNNs but is insufficient toclose the gap with Transformers. A key bottleneck lies in the inability of RNNsto perfectly retrieve information from the context, even with CoT: for severaltasks that explicitly or implicitly require this capability, such asassociative recall and determining if a graph is a tree, we prove that RNNs arenot expressive enough to solve the tasks while Transformers can solve them withease. Conversely, we prove that adopting techniques to enhance the in-contextretrieval capability of RNNs, including Retrieval-Augmented Generation (RAG)and adding a single Transformer layer, can elevate RNNs to be capable ofsolving all polynomial-time solvable problems with CoT, hence closing therepresentation gap with Transformers.</description><author>Kaiyue Wen, Xingyu Dang, Kaifeng Lyu</author><pubDate>Wed, 28 Feb 2024 17:38:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18510v1</guid></item><item><title>Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling</title><link>http://arxiv.org/abs/2402.18508v1</link><description>In the rapidly evolving landscape of deep learning, the quest for models thatbalance expressivity with computational efficiency has never been morecritical. This paper introduces Orchid, a novel architecture that reimaginessequence modeling by incorporating a new data-dependent convolution mechanism.Orchid is designed to address the inherent limitations of traditional attentionmechanisms, particularly their quadratic complexity, without compromising theability to capture long-range dependencies and in-context learning. At the coreof Orchid lies the data-dependent convolution layer, which dynamically adjustsits kernel conditioned on input data using a dedicated conditioning neuralnetwork. We design two simple conditioning networks that maintain shiftequivariance in the adaptive convolution operation. The dynamic nature ofdata-dependent convolution kernel, coupled with gating operations, grantsOrchid high expressivity while maintaining efficiency and quasilinearscalability for long sequences. We rigorously evaluate Orchid across multipledomains, including language modeling and image classification, to showcase itsperformance and generality. Our experiments demonstrate that Orchidarchitecture not only outperforms traditional attention-based architecturessuch as BERT and Vision Transformers with smaller model sizes, but also extendsthe feasible sequence length beyond the limitations of the dense attentionlayers. This achievement represents a significant step towards more efficientand scalable deep learning models for sequence modeling.</description><author>Mahdi Karami, Ali Ghodsi</author><pubDate>Wed, 28 Feb 2024 17:36:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18508v1</guid></item><item><title>Multimodal Learning To Improve Cardiac Late Mechanical Activation Detection From Cine MR Images</title><link>http://arxiv.org/abs/2402.18507v1</link><description>This paper presents a multimodal deep learning framework that utilizesadvanced image techniques to improve the performance of clinical analysisheavily dependent on routinely acquired standard images. More specifically, wedevelop a joint learning network that for the first time leverages the accuracyand reproducibility of myocardial strains obtained from Displacement Encodingwith Stimulated Echo (DENSE) to guide the analysis of cine cardiac magneticresonance (CMR) imaging in late mechanical activation (LMA) detection. An imageregistration network is utilized to acquire the knowledge of cardiac motions,an important feature estimator of strain values, from standard cine CMRs. Ourframework consists of two major components: (i) a DENSE-supervised strainnetwork leveraging latent motion features learned from a registration networkto predict myocardial strains; and (ii) a LMA network taking advantage of thepredicted strain for effective LMA detection. Experimental results show thatour proposed work substantially improves the performance of strain analysis andLMA detection from cine CMR images, aligning more closely with the achievementsof DENSE.</description><author>Jiarui Xing, Nian Wu, Kenneth Bilchick, Frederick Epstein, Miaomiao Zhang</author><pubDate>Wed, 28 Feb 2024 17:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18507v1</guid></item><item><title>Evolving machine learning workflows through interactive AutoML</title><link>http://arxiv.org/abs/2402.18505v1</link><description>Automatic workflow composition (AWC) is a relevant problem in automatedmachine learning (AutoML) that allows finding suitable sequences ofpreprocessing and prediction models together with their optimalhyperparameters. This problem can be solved using evolutionary algorithms and,in particular, grammar-guided genetic programming (G3P). Current G3P approachesto AWC define a fixed grammar that formally specifies how workflow elements canbe combined and which algorithms can be included. In this paper we present\ourmethod, an interactive G3P algorithm that allows users to dynamicallymodify the grammar to prune the search space and focus on their regions ofinterest. Our proposal is the first to combine the advantages of a G3P methodwith ideas from interactive optimisation and human-guided machine learning, anarea little explored in the context of AutoML. To evaluate our approach, wepresent an experimental study in which 20 participants interact with \ourmethodto evolve workflows according to their preferences. Our results confirm thatthe collaboration between \ourmethod and humans allows us to findhigh-performance workflows in terms of accuracy that require less tuning timethan those found without human intervention.</description><author>Rafael Barbudo, Aurora Ramírez, José Raúl Romero</author><pubDate>Wed, 28 Feb 2024 17:34:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18505v1</guid></item><item><title>Detection of Micromobility Vehicles in Urban Traffic Videos</title><link>http://arxiv.org/abs/2402.18503v1</link><description>Urban traffic environments present unique challenges for object detection,particularly with the increasing presence of micromobility vehicles likee-scooters and bikes. To address this object detection problem, this workintroduces an adapted detection model that combines the accuracy and speed ofsingle-frame object detection with the richer features offered by video objectdetection frameworks. This is done by applying aggregated feature maps fromconsecutive frames processed through motion flow to the YOLOX architecture.This fusion brings a temporal perspective to YOLOX detection abilities,allowing for a better understanding of urban mobility patterns andsubstantially improving detection reliability. Tested on a custom datasetcurated for urban micromobility scenarios, our model showcases substantialimprovement over existing state-of-the-art methods, demonstrating the need toconsider spatio-temporal information for detecting such small and thin objects.Our approach enhances detection in challenging conditions, includingocclusions, ensuring temporal consistency, and effectively mitigating motionblur.</description><author>Khalil Sabri, Célia Djilali, Guillaume-Alexandre Bilodeau, Nicolas Saunier, Wassim Bouachir</author><pubDate>Wed, 28 Feb 2024 17:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18503v1</guid></item><item><title>Few-Shot Fairness: Unveiling LLM's Potential for Fairness-Aware Classification</title><link>http://arxiv.org/abs/2402.18502v1</link><description>Employing Large Language Models (LLM) in various downstream applications suchas classification is crucial, especially for smaller companies lacking theexpertise and resources required for fine-tuning a model. Fairness in LLMshelps ensure inclusivity, equal representation based on factors such as race,gender and promotes responsible AI deployment. As the use of LLMs has becomeincreasingly prevalent, it is essential to assess whether LLMs can generatefair outcomes when subjected to considerations of fairness. In this study, weintroduce a framework outlining fairness regulations aligned with variousfairness definitions, with each definition being modulated by varying degreesof abstraction. We explore the configuration for in-context learning and theprocedure for selecting in-context demonstrations using RAG, whileincorporating fairness rules into the process. Experiments conducted withdifferent LLMs indicate that GPT-4 delivers superior results in terms of bothaccuracy and fairness compared to other models. This work is one of the earlyattempts to achieve fairness in prediction tasks by utilizing LLMs throughin-context learning.</description><author>Garima Chhikara, Anurag Sharma, Kripabandhu Ghosh, Abhijnan Chakraborty</author><pubDate>Wed, 28 Feb 2024 17:29:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18502v1</guid></item><item><title>Compass: A Decentralized Scheduler for Latency-Sensitive ML Workflows</title><link>http://arxiv.org/abs/2402.17652v2</link><description>We consider ML query processing in distributed systems where GPU-enabledworkers coordinate to execute complex queries: a computing style often seen inapplications that interact with users in support of image processing andnatural language processing. In such systems, coscheduling of GPU memorymanagement and task placement represents a promising opportunity. We proposeCompass, a novel framework that unifies these functions to reduce job latencywhile using resources efficiently, placing tasks where data dependencies willbe satisfied, collocating tasks from the same job (when this will not overloadthe host or its GPU), and efficiently managing GPU memory. Comparison withother state of the art schedulers shows a significant reduction in completiontimes while requiring the same amount or even fewer resources. In one case,just half the servers were needed for processing the same workload.</description><author>Yuting Yang, Andrea Merlina, Weijia Song, Tiancheng Yuan, Ken Birman, Roman Vitenberg</author><pubDate>Wed, 28 Feb 2024 17:27:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17652v2</guid></item><item><title>OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web</title><link>http://arxiv.org/abs/2402.17553v2</link><description>For decades, human-computer interaction has fundamentally been manual. Eventoday, almost all productive work done on the computer necessitates human inputat every step. Autonomous virtual agents represent an exciting step inautomating many of these menial tasks. Virtual agents would empower users withlimited technical proficiency to harness the full possibilities of computersystems. They could also enable the efficient streamlining of numerous computertasks, ranging from calendar management to complex travel bookings, withminimal human intervention. In this paper, we introduce OmniACT, thefirst-of-a-kind dataset and benchmark for assessing an agent's capability togenerate executable programs to accomplish computer tasks. Our scope extendsbeyond traditional web automation, covering a diverse range of desktopapplications. The dataset consists of fundamental tasks such as "Play the nextsong", as well as longer horizon tasks such as "Send an email to John Doementioning the time and place to meet". Specifically, given a pair of screenimage and a visually-grounded natural language task, the goal is to generate ascript capable of fully executing the task. We run several strong baselinelanguage model agents on our benchmark. The strongest baseline, GPT-4, performsthe best on our benchmark However, its performance level still reaches only 15%of the human proficiency in generating executable scripts capable of completingthe task, demonstrating the challenge of our task for conventional web agents.Our benchmark provides a platform to measure and evaluate the progress oflanguage model agents in automating computer tasks and motivates future worktowards building multimodal models that bridge large language models and thevisual grounding of computer screens.</description><author>Raghav Kapoor, Yash Parag Butala, Melisa Russak, Jing Yu Koh, Kiran Kamble, Waseem Alshikh, Ruslan Salakhutdinov</author><pubDate>Wed, 28 Feb 2024 17:27:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17553v2</guid></item><item><title>Language Models Represent Beliefs of Self and Others</title><link>http://arxiv.org/abs/2402.18496v1</link><description>Understanding and attributing mental states, known as Theory of Mind (ToM),emerges as a fundamental capability for human social reasoning. While LargeLanguage Models (LLMs) appear to possess certain ToM abilities, the mechanismsunderlying these capabilities remain elusive. In this study, we discover thatit is possible to linearly decode the belief status from the perspectives ofvarious agents through neural activations of language models, indicating theexistence of internal representations of self and others' beliefs. Bymanipulating these representations, we observe dramatic changes in the models'ToM performance, underscoring their pivotal role in the social reasoningprocess. Additionally, our findings extend to diverse social reasoning tasksthat involve different causal inference patterns, suggesting the potentialgeneralizability of these representations.</description><author>Wentao Zhu, Zhining Zhang, Yizhou Wang</author><pubDate>Wed, 28 Feb 2024 17:25:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18496v1</guid></item><item><title>ROG$_{PL}$: Robust Open-Set Graph Learning via Region-Based Prototype Learning</title><link>http://arxiv.org/abs/2402.18495v1</link><description>Open-set graph learning is a practical task that aims to classify the knownclass nodes and to identify unknown class samples as unknowns. Conventionalnode classification methods usually perform unsatisfactorily in open-setscenarios due to the complex data they encounter, such as out-of-distribution(OOD) data and in-distribution (IND) noise. OOD data are samples that do notbelong to any known classes. They are outliers if they occur in training (OODnoise), and open-set samples if they occur in testing. IND noise are trainingsamples which are assigned incorrect labels. The existence of IND noise and OODnoise is prevalent, which usually cause the ambiguity problem, including theintra-class variety problem and the inter-class confusion problem. Thus, toexplore robust open-set learning methods is necessary and difficult, and itbecomes even more difficult for non-IID graph data.To this end, we propose aunified framework named ROG$_{PL}$ to achieve robust open-set learning oncomplex noisy graph data, by introducing prototype learning. In specific,ROG$_{PL}$ consists of two modules, i.e., denoising via label propagation andopen-set prototype learning via regions. The first module corrects noisy labelsthrough similarity-based label propagation and removes low-confidence samples,to solve the intra-class variety problem caused by noise. The second modulelearns open-set prototypes for each known class via non-overlapped regions andremains both interior and border prototypes to remedy the inter-class confusionproblem.The two modules are iteratively updated under the constraints ofclassification loss and prototype diversity loss. To the best of our knowledge,the proposed ROG$_{PL}$ is the first robust open-set node classification methodfor graph data with complex noise.</description><author>Qin Zhang, Xiaowei Li, Jiexin Lu, Liping Qiu, Shirui Pan, Xiaojun Chen, Junyang Chen</author><pubDate>Wed, 28 Feb 2024 17:25:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18495v1</guid></item><item><title>Inference for Heteroskedastic PCA with Missing Data</title><link>http://arxiv.org/abs/2107.12365v2</link><description>This paper studies how to construct confidence regions for principalcomponent analysis (PCA) in high dimension, a problem that has been vastlyunder-explored. While computing measures of uncertainty for nonlinear/nonconvexestimators is in general difficult in high dimension, the challenge is furthercompounded by the prevalent presence of missing data and heteroskedastic noise.We propose a novel approach to performing valid inference on the principalsubspace under a spiked covariance model with missing data, on the basis of anestimator called HeteroPCA (Zhang et al., 2022). We develop non-asymptoticdistributional guarantees for HeteroPCA, and demonstrate how these can beinvoked to compute both confidence regions for the principal subspace andentrywise confidence intervals for the spiked covariance matrix. Our inferenceprocedures are fully data-driven and adaptive to heteroskedastic random noise,without requiring prior knowledge about the noise levels.</description><author>Yuling Yan, Yuxin Chen, Jianqing Fan</author><pubDate>Wed, 28 Feb 2024 17:22:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.12365v2</guid></item><item><title>Sunshine to Rainstorm: Cross-Weather Knowledge Distillation for Robust 3D Object Detection</title><link>http://arxiv.org/abs/2402.18493v1</link><description>LiDAR-based 3D object detection models have traditionally struggled underrainy conditions due to the degraded and noisy scanning signals. Previousresearch has attempted to address this by simulating the noise from rain toimprove the robustness of detection models. However, significant disparitiesexist between simulated and actual rain-impacted data points. In this work, wepropose a novel rain simulation method, termed DRET, that unifies Dynamics andRainy Environment Theory to provide a cost-effective means of expanding theavailable realistic rain data for 3D detection training. Furthermore, wepresent a Sunny-to-Rainy Knowledge Distillation (SRKD) approach to enhance 3Ddetection under rainy conditions. Extensive experiments on the WaymoOpenDatasetlarge-scale dataset show that, when combined with the state-of-the-art DSVTmodel and other classical 3D detectors, our proposed framework demonstratessignificant detection accuracy improvements, without losing efficiency.Remarkably, our framework also improves detection capabilities under sunnyconditions, therefore offering a robust solution for 3D detection regardless ofwhether the weather is rainy or sunny</description><author>Xun Huang, Hai Wu, Xin Li, Xiaoliang Fan, Chenglu Wen, Cheng Wang</author><pubDate>Wed, 28 Feb 2024 17:21:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18493v1</guid></item><item><title>Dynamical Regimes of Diffusion Models</title><link>http://arxiv.org/abs/2402.18491v1</link><description>Using statistical physics methods, we study generative diffusion models inthe regime where the dimension of space and the number of data are large, andthe score function has been trained optimally. Our analysis reveals threedistinct dynamical regimes during the backward generative diffusion process.The generative dynamics, starting from pure noise, encounters first a'speciation' transition where the gross structure of data is unraveled, througha mechanism similar to symmetry breaking in phase transitions. It is followedat later time by a 'collapse' transition where the trajectories of the dynamicsbecome attracted to one of the memorized data points, through a mechanism whichis similar to the condensation in a glass phase. For any dataset, thespeciation time can be found from a spectral analysis of the correlationmatrix, and the collapse time can be found from the estimation of an 'excessentropy' in the data. The dependence of the collapse time on the dimension andnumber of data provides a thorough characterization of the curse ofdimensionality for diffusion models. Analytical solutions for simple modelslike high-dimensional Gaussian mixtures substantiate these findings and providea theoretical framework, while extensions to more complex scenarios andnumerical validations with real datasets confirm the theoretical predictions.</description><author>Giulio Biroli, Tony Bonnaire, Valentin de Bortoli, Marc Mézard</author><pubDate>Wed, 28 Feb 2024 17:19:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18491v1</guid></item><item><title>TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding</title><link>http://arxiv.org/abs/2402.18490v1</link><description>The limited scale of current 3D shape datasets hinders the advancements in 3Dshape understanding, and motivates multi-modal learning approaches whichtransfer learned knowledge from data-abundant 2D image and language modalitiesto 3D shapes. However, even though the image and language representations havebeen aligned by cross-modal models like CLIP, we find that the image modalityfails to contribute as much as the language in existing multi-modal 3Drepresentation learning methods. This is attributed to the domain shift in the2D images and the distinct focus of each modality. To more effectively leverageboth modalities in the pre-training, we introduce TriAdapter Multi-ModalLearning (TAMM) -- a novel two-stage learning approach based on threesynergetic adapters. First, our CLIP Image Adapter mitigates the domain gapbetween 3D-rendered images and natural images, by adapting the visualrepresentations of CLIP for synthetic image-text pairs. Subsequently, our DualAdapters decouple the 3D shape representation space into two complementarysub-spaces: one focusing on visual attributes and the other for semanticunderstanding, which ensure a more comprehensive and effective multi-modalpre-training. Extensive experiments demonstrate that TAMM consistently enhances3D representations for a wide range of 3D encoder architectures, pre-trainingdatasets, and downstream tasks. Notably, we boost the zero-shot classificationaccuracy on Objaverse-LVIS from 46.8 to 50.7, and improve the 5-way 10-shotlinear probing classification accuracy on ModelNet40 from 96.1 to 99.0. Projectpage: \url{https://alanzhangcs.github.io/tamm-page}.</description><author>Zhihao Zhang, Shengcao Cao, Yu-Xiong Wang</author><pubDate>Wed, 28 Feb 2024 17:18:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18490v1</guid></item><item><title>Human-Centric Aware UAV Trajectory Planning in Search and Rescue Missions Employing Multi-Objective Reinforcement Learning with AHP and Similarity-Based Experience Replay</title><link>http://arxiv.org/abs/2402.18487v1</link><description>The integration of Unmanned Aerial Vehicles (UAVs) into Search and Rescue(SAR) missions presents a promising avenue for enhancing operational efficiencyand effectiveness. However, the success of these missions is not solelydependent on the technical capabilities of the drones but also on theiracceptance and interaction with humans on the ground. This paper explores theeffect of human-centric factor in UAV trajectory planning for SAR missions. Weintroduce a novel approach based on the reinforcement learning augmented withAnalytic Hierarchy Process and novel similarity-based experience replay tooptimize UAV trajectories, balancing operational objectives with human comfortand safety considerations. Additionally, through a comprehensive survey, weinvestigate the impact of gender cues and anthropomorphism in UAV design onpublic acceptance and trust, revealing significant implications for droneinteraction strategies in SAR. Our contributions include (1) a reinforcementlearning framework for UAV trajectory planning that dynamically integratesmulti-objective considerations, (2) an analysis of human perceptions towardsgendered and anthropomorphized drones in SAR contexts, and (3) the applicationof similarity-based experience replay for enhanced learning efficiency incomplex SAR scenarios. The findings offer valuable insights into designing UAVsystems that are not only technically proficient but also aligned withhuman-centric values.</description><author>Mahya Ramezani, Jose Luis Sanchez-Lopez</author><pubDate>Wed, 28 Feb 2024 17:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18487v1</guid></item><item><title>FinAgent: A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist</title><link>http://arxiv.org/abs/2402.18485v1</link><description>Financial trading is a crucial component of the markets, informed by amultimodal information landscape encompassing news, prices, and Kline charts,and encompasses diverse tasks such as quantitative trading and high-frequencytrading with various assets. While advanced AI techniques like deep learningand reinforcement learning are extensively utilized in finance, theirapplication in financial trading tasks often faces challenges due to inadequatehandling of multimodal data and limited generalizability across various tasks.To address these challenges, we present FinAgent, a multimodal foundationalagent with tool augmentation for financial trading. FinAgent's marketintelligence module processes a diverse range of data-numerical, textual, andvisual-to accurately analyze the financial market. Its unique dual-levelreflection module not only enables rapid adaptation to market dynamics but alsoincorporates a diversified memory retrieval system, enhancing the agent'sability to learn from historical data and improve decision-making processes.The agent's emphasis on reasoning for actions fosters trust in its financialdecisions. Moreover, FinAgent integrates established trading strategies andexpert insights, ensuring that its trading approaches are both data-driven androoted in sound financial principles. With comprehensive experiments on 6financial datasets, including stocks and Crypto, FinAgent significantlyoutperforms 9 state-of-the-art baselines in terms of 6 financial metrics withover 36% average improvement on profit. Specifically, a 92.27% return (a 84.39%relative improvement) is achieved on one dataset. Notably, FinAgent is thefirst advanced multimodal foundation agent designed for financial tradingtasks.</description><author>Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze Sun, Molei Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, Longtao Zheng, Xinrun Wang, Bo An</author><pubDate>Wed, 28 Feb 2024 17:06:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18485v1</guid></item><item><title>A non-intrusive machine learning framework for debiasing long-time coarse resolution climate simulations and quantifying rare events statistics</title><link>http://arxiv.org/abs/2402.18484v1</link><description>Due to the rapidly changing climate, the frequency and severity of extremeweather is expected to increase over the coming decades. As fully-resolvedclimate simulations remain computationally intractable, policy makers must relyon coarse-models to quantify risk for extremes. However, coarse models sufferfrom inherent bias due to the ignored "sub-grid" scales. We propose a frameworkto non-intrusively debias coarse-resolution climate predictions usingneural-network (NN) correction operators. Previous efforts have attempted totrain such operators using loss functions that match statistics. However, thisapproach falls short with events that have longer return period than that ofthe training data, since the reference statistics have not converged. Here, thescope is to formulate a learning method that allows for correction of dynamicsand quantification of extreme events with longer return period than thetraining data. The key obstacle is the chaotic nature of the underlyingdynamics. To overcome this challenge, we introduce a dynamical systems approachwhere the correction operator is trained using reference data and a coarsemodel simulation nudged towards that reference. The method is demonstrated ondebiasing an under-resolved quasi-geostrophic model and the Energy ExascaleEarth System Model (E3SM). For the former, our method enables thequantification of events that have return period two orders longer than thetraining data. For the latter, when trained on 8 years of ERA5 data, ourapproach is able to correct the coarse E3SM output to closely reflect the36-year ERA5 statistics for all prognostic variables and significantly reducetheir spatial biases.</description><author>Benedikt Barthel Sorensen, Alexis Charalampopoulos, Shixuan Zhang, Bryce Harrop, Ruby Leung, Themistoklis Sapsis</author><pubDate>Wed, 28 Feb 2024 17:06:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18484v1</guid></item><item><title>Errors are Robustly Tamed in Cumulative Knowledge Processes</title><link>http://arxiv.org/abs/2309.05638v2</link><description>We study processes of societal knowledge accumulation, where the validity ofa new unit of knowledge depends both on the correctness of its derivation andon the validity of the units it depends on. A fundamental question in thissetting is: If a constant fraction of the new derivations is wrong, caninvesting a constant fraction, bounded away from one, of effort ensure that aconstant fraction of knowledge in society is valid? Ben-Eliezer, Mikulincer,Mossel, and Sudan (ITCS 2023) introduced a concrete probabilistic model toanalyze such questions and showed an affirmative answer to this question. Theirstudy, however, focuses on the simple case where each new unit depends on justone existing unit, and units attach according to a $\textit{preferentialattachment rule}$. In this work, we consider much more general families of cumulative knowledgeprocesses, where new units may attach according to varied attachment mechanismsand depend on multiple existing units. We also allow a (random) fraction ofinsertions of adversarial nodes. We give a robust affirmative answer to the above question by showing that for$\textit{all}$ of these models, as long as many of the units follow simpleheuristics for checking a bounded number of units they depend on, all errorswill be eventually eliminated. Our results indicate that preserving the qualityof large interdependent collections of units of knowledge is feasible, as longas careful but not too costly checks are performed when new units arederived/deposited.</description><author>Anna Brandenberger, Cassandra Marcussen, Elchanan Mossel, Madhu Sudan</author><pubDate>Wed, 28 Feb 2024 17:02:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05638v2</guid></item><item><title>NewsQs: Multi-Source Question Generation for the Inquiring Mind</title><link>http://arxiv.org/abs/2402.18479v1</link><description>We present NewsQs (news-cues), a dataset that provides question-answer pairsfor multiple news documents. To create NewsQs, we augment a traditionalmulti-document summarization dataset with questions automatically generated bya T5-Large model fine-tuned on FAQ-style news articles from the News On the Webcorpus. We show that fine-tuning a model with control codes produces questionsthat are judged acceptable more often than the same model without them asmeasured through human evaluation. We use a QNLI model with high correlationwith human annotations to filter our data. We release our final dataset ofhigh-quality questions, answers, and document clusters as a resource for futurework in query-based multi-document summarization.</description><author>Alyssa Hwang, Kalpit Dixit, Miguel Ballesteros, Yassine Benajiba, Vittorio Castelli, Markus Dreyer, Mohit Bansal, Kathleen McKeown</author><pubDate>Wed, 28 Feb 2024 16:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18479v1</guid></item><item><title>Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes</title><link>http://arxiv.org/abs/2402.18477v1</link><description>Inferring the causal structure underlying stochastic dynamical systems fromobservational data holds great promise in domains ranging from science andhealth to finance. Such processes can often be accurately modeled viastochastic differential equations (SDEs), which naturally imply causalrelationships via "which variables enter the differential of which othervariables". In this paper, we develop a kernel-based test of conditionalindependence (CI) on "path-space" -- solutions to SDEs -- by leveraging recentadvances in signature kernels. We demonstrate strictly superior performance ofour proposed CI test compared to existing approaches on path-space. Then, wedevelop constraint-based causal discovery algorithms for acyclic stochasticdynamical systems (allowing for loops) that leverage temporal information torecover the entire directed graph. Assuming faithfulness and a CI oracle, ouralgorithm is sound and complete. We empirically verify that our developed CItest in conjunction with the causal discovery algorithm reliably outperformsbaselines across a range of settings.</description><author>Georg Manten, Cecilia Casolo, Emilio Ferrucci, Søren Wengel Mogensen, Cristopher Salvi, Niki Kilbertus</author><pubDate>Wed, 28 Feb 2024 16:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18477v1</guid></item><item><title>TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models</title><link>http://arxiv.org/abs/2311.16503v2</link><description>The Diffusion model, a prevalent framework for image generation, encounterssignificant challenges in terms of broad applicability due to its extendedinference times and substantial memory requirements. Efficient Post-trainingQuantization (PTQ) is pivotal for addressing these issues in traditionalmodels. Different from traditional models, diffusion models heavily depend onthe time-step $t$ to achieve satisfactory multi-round denoising. Usually, $t$from the finite set $\{1, \ldots, T\}$ is encoded to a temporal feature by afew modules totally irrespective of the sampling data. However, existing PTQmethods do not optimize these modules separately. They adopt inappropriatereconstruction targets and complex calibration methods, resulting in a severedisturbance of the temporal feature and denoising trajectory, as well as a lowcompression efficiency. To solve these, we propose a Temporal FeatureMaintenance Quantization (TFMQ) framework building upon a Temporal InformationBlock which is just related to the time-step $t$ and unrelated to the samplingdata. Powered by the pioneering block design, we devise temporal informationaware reconstruction (TIAR) and finite set calibration (FSC) to align thefull-precision temporal features in a limited time. Equipped with theframework, we can maintain the most temporal information and ensure theend-to-end generation quality. Extensive experiments on various datasets anddiffusion models prove our state-of-the-art results. Remarkably, ourquantization approach, for the first time, achieves model performance nearly onpar with the full-precision model under 4-bit weight quantization.Additionally, our method incurs almost no extra computational cost andaccelerates quantization time by $2.0 \times$ on LSUN-Bedrooms $256 \times 256$compared to previous works.</description><author>Yushi Huang, Ruihao Gong, Jing Liu, Tianlong Chen, Xianglong Liu</author><pubDate>Wed, 28 Feb 2024 16:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16503v2</guid></item><item><title>IBD: Alleviating Hallucinations in Large Vision-Language Models via Image-Biased Decoding</title><link>http://arxiv.org/abs/2402.18476v1</link><description>Despite achieving rapid developments and with widespread applications, LargeVision-Language Models (LVLMs) confront a serious challenge of being prone togenerating hallucinations. An over-reliance on linguistic priors has beenidentified as a key factor leading to these hallucinations. In this paper, wepropose to alleviate this problem by introducing a novel image-biased decoding(IBD) technique. Our method derives the next-token probability distribution bycontrasting predictions from a conventional LVLM with those of an image-biasedLVLM, thereby amplifying the correct information highly correlated with imagecontent while mitigating the hallucinatory errors caused by excessivedependence on text. We further conduct a comprehensive statistical analysis tovalidate the reliability of our method, and design an adaptive adjustmentstrategy to achieve robust and flexible handling under varying conditions.Experimental results across multiple evaluation metrics verify that our method,despite not requiring additional training data and only with a minimal increasein model parameters, can significantly reduce hallucinations in LVLMs andenhance the truthfulness of the generated response.</description><author>Lanyun Zhu, Deyi Ji, Tianrun Chen, Peng Xu, Jieping Ye, Jun Liu</author><pubDate>Wed, 28 Feb 2024 16:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18476v1</guid></item><item><title>Implementing Online Reinforcement Learning with Clustering Neural Networks</title><link>http://arxiv.org/abs/2402.18472v1</link><description>An agent employing reinforcement learning takes inputs (state variables) froman environment and performs actions that affect the environment in order toachieve some objective. Rewards (positive or negative) guide the agent towardimproved future actions. This paper builds on prior clustering neural networkresearch by constructing an agent with biologically plausible neo-Hebbianthree-factor synaptic learning rules, with a reward signal as the third factor(in addition to pre- and post-synaptic spikes). The classic cart-pole problem(balancing an inverted pendulum) is used as a running example throughout theexposition. Simulation results demonstrate the efficacy of the approach, andthe proposed method may eventually serve as a low-level component of a moregeneral method.</description><author>James E. Smith</author><pubDate>Wed, 28 Feb 2024 16:50:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18472v1</guid></item><item><title>Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries</title><link>http://arxiv.org/abs/2402.15276v2</link><description>Text-to-image retrieval plays a crucial role across various applications,including digital libraries, e-commerce platforms, and multimedia databases, byenabling the search for images using text queries. Despite the advancements inMultimodal Large Language Models (MLLMs), which offer leading-edge performance,their applicability in large-scale, varied, and ambiguous retrieval scenariosis constrained by significant computational demands and the generation ofinjective embeddings. This paper introduces the Text2Pic Swift framework,tailored for efficient and robust retrieval of images corresponding toextensive textual descriptions in sizable datasets. The framework employs atwo-tier approach: the initial Entity-based Ranking (ER) stage addresses theambiguity inherent in lengthy text queries through amultiple-queries-to-multiple-targets strategy, effectively narrowing downpotential candidates for subsequent analysis. Following this, the Summary-basedRe-ranking (SR) stage further refines these selections based on concise querysummaries. Additionally, we present a novel Decoupling-BEiT-3 encoder,specifically designed to tackle the challenges of ambiguous queries and tofacilitate both stages of the retrieval process, thereby significantlyimproving computational efficiency via vector-based similarity assessments. Ourevaluation, conducted on the AToMiC dataset, demonstrates that Text2Pic Swiftoutperforms current MLLMs by achieving up to an 11.06% increase in Recall@1000,alongside reductions in training and retrieval durations by 68.75% and 99.79%,respectively.</description><author>Zijun Long, Xuri Ge, Richard Mccreadie, Joemon Jose</author><pubDate>Wed, 28 Feb 2024 16:49:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15276v2</guid></item><item><title>Separate and Conquer: Decoupling Co-occurrence via Decomposition and Representation for Weakly Supervised Semantic Segmentation</title><link>http://arxiv.org/abs/2402.18467v1</link><description>Attributed to the frequent coupling of co-occurring objects and the limitedsupervision from image-level labels, the challenging co-occurrence problem iswidely present and leads to false activation of objects in weakly supervisedsemantic segmentation (WSSS). In this work, we devise a 'Separate and Conquer'scheme SeCo to tackle this issue from dimensions of image space and featurespace. In the image space, we propose to 'separate' the co-occurring objectswith image decomposition by subdividing images into patches. Importantly, weassign each patch a category tag from Class Activation Maps (CAMs), whichspatially helps remove the co-context bias and guide the subsequentrepresentation. In the feature space, we propose to 'conquer' the falseactivation by enhancing semantic representation with multi-granularityknowledge contrast. To this end, a dual-teacher-single-student architecture isdesigned and tag-guided contrast is conducted to guarantee the correctness ofknowledge and further facilitate the discrepancy among co-occurring objects. Westreamline the multi-staged WSSS pipeline end-to-end and tackle co-occurrencewithout external supervision. Extensive experiments are conducted, validatingthe efficiency of our method tackling co-occurrence and the superiority overprevious single-staged and even multi-staged competitors on PASCAL VOC and MSCOCO. Code will be available.</description><author>Zhiwei Yang, Kexue Fu, Minghong Duan, Linhao Qu, Shuo Wang, Zhijian Song</author><pubDate>Wed, 28 Feb 2024 16:43:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18467v1</guid></item><item><title>Are you Struggling? Dataset and Baselines for Struggle Determination in Assembly Videos</title><link>http://arxiv.org/abs/2402.11057v2</link><description>Determining when people are struggling from video enables a finer-grainedunderstanding of actions and opens opportunities for building intelligentsupport visual interfaces. In this paper, we present a new dataset with threeassembly activities and corresponding performance baselines for thedetermination of struggle from video. Three real-world problem-solvingactivities including assembling plumbing pipes (Pipes-Struggle), pitchingcamping tents (Tent-Struggle) and solving the Tower of Hanoi puzzle(Tower-Struggle) are introduced. Video segments were scored w.r.t. the level ofstruggle as perceived by annotators using a forced choice 4-point scale. Eachvideo segment was annotated by a single expert annotator in addition tocrowd-sourced annotations. The dataset is the first struggle annotation datasetand contains 5.1 hours of video and 725,100 frames from 73 participants intotal. We evaluate three decision-making tasks: struggle classification,struggle level regression, and struggle label distribution learning. We providebaseline results for each of the tasks utilising several mainstream deep neuralnetworks, along with an ablation study and visualisation of results. Our workis motivated toward assistive systems that analyze struggle, support usersduring manual activities and encourage learning, as well as other videounderstanding competencies.</description><author>Shijia Feng, Michael Wray, Brian Sullivan, Youngkyoon Jang, Casimir Ludwig, Iain Gilchrist, Walterio Mayol-Cuevas</author><pubDate>Wed, 28 Feb 2024 16:42:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11057v2</guid></item><item><title>Exploring the Promise and Limits of Real-Time Recurrent Learning</title><link>http://arxiv.org/abs/2305.19044v3</link><description>Real-time recurrent learning (RTRL) for sequence-processing recurrent neuralnetworks (RNNs) offers certain conceptual advantages over backpropagationthrough time (BPTT). RTRL requires neither caching past activations nortruncating context, and enables online learning. However, RTRL's time and spacecomplexity make it impractical. To overcome this problem, most recent work onRTRL focuses on approximation theories, while experiments are often limited todiagnostic settings. Here we explore the practical promise of RTRL in morerealistic settings. We study actor-critic methods that combine RTRL and policygradients, and test them in several subsets of DMLab-30, ProcGen, andAtari-2600 environments. On DMLab memory tasks, our system trained on fewerthan 1.2 B environmental frames is competitive with or outperforms well-knownIMPALA and R2D2 baselines trained on 10 B frames. To scale to such challengingtasks, we focus on certain well-known neural architectures with element-wiserecurrence, allowing for tractable RTRL without approximation. Importantly, wealso discuss rarely addressed limitations of RTRL in real-world applications,such as its complexity in the multi-layer case.</description><author>Kazuki Irie, Anand Gopalakrishnan, Jürgen Schmidhuber</author><pubDate>Wed, 28 Feb 2024 16:40:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19044v3</guid></item><item><title>Efficient local linearity regularization to overcome catastrophic overfitting</title><link>http://arxiv.org/abs/2401.11618v2</link><description>Catastrophic overfitting (CO) in single-step adversarial training (AT)results in abrupt drops in the adversarial test accuracy (even down to 0%). Formodels trained with multi-step AT, it has been observed that the loss functionbehaves locally linearly with respect to the input, this is however lost insingle-step AT. To address CO in single-step AT, several methods have beenproposed to enforce local linearity of the loss via regularization. However,these regularization terms considerably slow down training due to DoubleBackpropagation. Instead, in this work, we introduce a regularization term,called ELLE, to mitigate CO effectively and efficiently in classical ATevaluations, as well as some more difficult regimes, e.g., large adversarialperturbations and long training schedules. Our regularization term can betheoretically linked to curvature of the loss function and is computationallycheaper than previous methods by avoiding Double Backpropagation. Our thoroughexperimental validation demonstrates that our work does not suffer from CO,even in challenging settings where previous works suffer from it. We alsonotice that adapting our regularization parameter during training (ELLE-A)greatly improves the performance, specially in large $\epsilon$ setups. Ourimplementation is available in https://github.com/LIONS-EPFL/ELLE .</description><author>Elias Abad Rocamora, Fanghui Liu, Grigorios G. Chrysos, Pablo M. Olmos, Volkan Cevher</author><pubDate>Wed, 28 Feb 2024 16:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11618v2</guid></item><item><title>Meta-Task Prompting Elicits Embedding from Large Language Models</title><link>http://arxiv.org/abs/2402.18458v1</link><description>In this work, we introduce a new unsupervised embedding method, Meta-TaskPrompting with Explicit One-Word Limitation (MetaEOL), for generatinghigh-quality sentence embeddings from Large Language Models (LLMs) without theneed for model fine-tuning or task-specific engineering. Leveraging meta-taskprompting, MetaEOL guides LLMs to produce embeddings through a series ofcarefully designed prompts that address multiple representational aspects. Ourcomprehensive experiments demonstrate that embeddings averaged from variousmeta-tasks yield competitive performance on Semantic Textual Similarity (STS)benchmarks and excel in downstream tasks, surpassing contrastive-trainedmodels. Our findings suggest a new scaling law for embedding generation,offering a versatile, resource-efficient approach for embedding extractionacross diverse sentence-centric scenarios.</description><author>Yibin Lei, Di Wu, Tianyi Zhou, Tao Shen, Yu Cao, Chongyang Tao, Andrew Yates</author><pubDate>Wed, 28 Feb 2024 16:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18458v1</guid></item><item><title>MambaMIR: An Arbitrary-Masked Mamba for Joint Medical Image Reconstruction and Uncertainty Estimation</title><link>http://arxiv.org/abs/2402.18451v1</link><description>The recent Mamba model has shown remarkable adaptability for visualrepresentation learning, including in medical imaging tasks. This studyintroduces MambaMIR, a Mamba-based model for medical image reconstruction, aswell as its Generative Adversarial Network-based variant, MambaMIR-GAN. Ourproposed MambaMIR inherits several advantages, such as linear complexity,global receptive fields, and dynamic weights, from the original Mamba model.The innovated arbitrary-mask mechanism effectively adapt Mamba to our imagereconstruction task, providing randomness for subsequent Monte Carlo-baseduncertainty estimation. Experiments conducted on various medical imagereconstruction tasks, including fast MRI and SVCT, which cover anatomicalregions such as the knee, chest, and abdomen, have demonstrated that MambaMIRand MambaMIR-GAN achieve comparable or superior reconstruction results relativeto state-of-the-art methods. Additionally, the estimated uncertainty maps offerfurther insights into the reliability of the reconstruction quality. The codeis publicly available at https://github.com/ayanglab/MambaMIR.</description><author>Jiahao Huang, Liutao Yang, Fanwen Wang, Yinzhe Wu, Yang Nan, Angelica I. Aviles-Rivero, Carola-Bibiane Schönlieb, Daoqiang Zhang, Guang Yang</author><pubDate>Wed, 28 Feb 2024 16:24:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18451v1</guid></item><item><title>HOP to the Next Tasks and Domains for Continual Learning in NLP</title><link>http://arxiv.org/abs/2402.18449v1</link><description>Continual Learning (CL) aims to learn a sequence of problems (i.e., tasks anddomains) by transferring knowledge acquired on previous problems, whilstavoiding forgetting of past ones. Different from previous approaches whichfocused on CL for one NLP task or domain in a specific use-case, in this paper,we address a more general CL setting to learn from a sequence of problems in aunique framework. Our method, HOP, permits to hop across tasks and domains byaddressing the CL problem along three directions: (i) we employ a set ofadapters to generalize a large pre-trained model to unseen problems, (ii) wecompute high-order moments over the distribution of embedded representations todistinguish independent and correlated statistics across different tasks anddomains, (iii) we process this enriched information with auxiliary headsspecialized for each end problem. Extensive experimental campaign on 4 NLPapplications, 5 benchmarks and 2 CL setups demonstrates the effectiveness ofour HOP.</description><author>Umberto Michieli, Mete Ozay</author><pubDate>Wed, 28 Feb 2024 16:21:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18449v1</guid></item><item><title>NCART: Neural Classification and Regression Tree for Tabular Data</title><link>http://arxiv.org/abs/2307.12198v2</link><description>Deep learning models have become popular in the analysis of tabular data, asthey address the limitations of decision trees and enable valuable applicationslike semi-supervised learning, online learning, and transfer learning. However,these deep-learning approaches often encounter a trade-off. On one hand, theycan be computationally expensive when dealing with large-scale orhigh-dimensional datasets. On the other hand, they may lack interpretabilityand may not be suitable for small-scale datasets. In this study, we propose anovel interpretable neural network called Neural Classification and RegressionTree (NCART) to overcome these challenges. NCART is a modified version ofResidual Networks that replaces fully-connected layers with multipledifferentiable oblivious decision trees. By integrating decision trees into thearchitecture, NCART maintains its interpretability while benefiting from theend-to-end capabilities of neural networks. The simplicity of the NCARTarchitecture makes it well-suited for datasets of varying sizes and reducescomputational costs compared to state-of-the-art deep learning models.Extensive numerical experiments demonstrate the superior performance of NCARTcompared to existing deep learning models, establishing it as a strongcompetitor to tree-based models.</description><author>Jiaqi Luo, Shixin Xu</author><pubDate>Wed, 28 Feb 2024 16:18:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12198v2</guid></item><item><title>Prompt-Driven Dynamic Object-Centric Learning for Single Domain Generalization</title><link>http://arxiv.org/abs/2402.18447v1</link><description>Single-domain generalization aims to learn a model from single source domaindata to achieve generalized performance on other unseen target domains.Existing works primarily focus on improving the generalization ability ofstatic networks. However, static networks are unable to dynamically adapt tothe diverse variations in different image scenes, leading to limitedgeneralization capability. Different scenes exhibit varying levels ofcomplexity, and the complexity of images further varies significantly incross-domain scenarios. In this paper, we propose a dynamic object-centricperception network based on prompt learning, aiming to adapt to the variationsin image complexity. Specifically, we propose an object-centric gating modulebased on prompt learning to focus attention on the object-centric featuresguided by the various scene prompts. Then, with the object-centric gatingmasks, the dynamic selective module dynamically selects highly correlatedfeature regions in both spatial and channel dimensions enabling the model toadaptively perceive object-centric relevant features, thereby enhancing thegeneralization capability. Extensive experiments were conducted onsingle-domain generalization tasks in image classification and objectdetection. The experimental results demonstrate that our approach outperformsstate-of-the-art methods, which validates the effectiveness and generally ofour proposed method.</description><author>Deng Li, Aming Wu, Yaowei Wang, Yahong Han</author><pubDate>Wed, 28 Feb 2024 16:16:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18447v1</guid></item><item><title>LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs</title><link>http://arxiv.org/abs/2402.18443v1</link><description>Building efficient neural network architectures can be a time-consuming taskrequiring extensive expert knowledge. This task becomes particularlychallenging for edge devices because one has to consider parameters such aspower consumption during inferencing, model size, inferencing speed, and CO2emissions. In this article, we introduce a novel framework designed toautomatically discover new neural network architectures based on user-definedparameters, an expert system, and an LLM trained on a large amount ofopen-domain knowledge. The introduced framework (LeMo-NADe) is tailored to beused by non-AI experts, does not require a predetermined neural architecturesearch space, and considers a large set of edge device-specific parameters. Weimplement and validate this proposed neural architecture discovery frameworkusing CIFAR-10, CIFAR-100, and ImageNet16-120 datasets while using GPT-4 Turboand Gemini as the LLM component. We observe that the proposed framework canrapidly (within hours) discover intricate neural network models that performextremely well across a diverse set of application settings defined by theuser.</description><author>Md Hafizur Rahman, Prabuddha Chakraborty</author><pubDate>Wed, 28 Feb 2024 16:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18443v1</guid></item><item><title>Partial Label Supervision for Agnostic Generative Noisy Label Learning</title><link>http://arxiv.org/abs/2308.01184v2</link><description>Noisy label learning has been tackled with both discriminative and generativeapproaches. Despite the simplicity and efficiency of discriminative methods,generative models offer a more principled way of disentangling clean and noisylabels and estimating the label transition matrix. However, existing generativemethods often require inferring additional latent variables through costlygenerative modules or heuristic assumptions, which hinder adaptive optimisationfor different causal directions. They also assume a uniform clean label prior,which does not reflect the sample-wise clean label distribution anduncertainty. In this paper, we propose a novel framework for generative noisylabel learning that addresses these challenges. First, we propose a newsingle-stage optimisation that directly approximates image generation by adiscriminative classifier output. This approximation significantly reduces thecomputation cost of image generation, preserves the generative modellingbenefits, and enables our framework to be agnostic in regards to differentcausality scenarios (i.e., image generate label or vice-versa). Second, weintroduce a new Partial Label Supervision (PLS) for noisy label learning thataccounts for both clean label coverage and uncertainty. The supervision of PLSdoes not merely aim at minimising loss, but seeks to capture the underlyingsample-wise clean label distribution and uncertainty. Extensive experiments oncomputer vision and natural language processing (NLP) benchmarks demonstratethat our generative modelling achieves state-of-the-art results whilesignificantly reducing the computation cost. Our code is available athttps://github.com/lfb-1/GNL.</description><author>Fengbei Liu, Chong Wang, Yuanhong Chen, Yuyuan Liu, Gustavo Carneiro</author><pubDate>Wed, 28 Feb 2024 16:09:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01184v2</guid></item><item><title>Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication</title><link>http://arxiv.org/abs/2402.18439v1</link><description>Natural language (NL) has long been the predominant format for humancognition and communication, and by extension, has been similarly pivotal inthe development and application of Large Language Models (LLMs). Yet, besidesNL, LLMs have seen various non-NL formats during pre-training, such as code andlogical expression. NL's status as the optimal format for LLMs, particularly insingle-LLM reasoning and multi-agent communication, has not been thoroughlyexamined. In this work, we challenge the default use of NL by exploring theutility of non-NL formats in these contexts. We show that allowing LLMs toautonomously select the most suitable format before reasoning or communicatingleads to a 3.3 to 5.7\% improvement in reasoning efficiency for different LLMs,and up to a 72.7\% reduction in token usage in multi-agent communication, allwhile maintaining communicative effectiveness. Our comprehensive analysisfurther reveals that LLMs can devise a format from limited task instructionsand that the devised format is effectively transferable across different LLMs.Intriguingly, the structured communication format decided by LLMs exhibitsnotable parallels with established agent communication languages, suggesting anatural evolution towards efficient, structured communication in agentcommunication. Our code is released at\url{https://github.com/thunlp/AutoForm}.</description><author>Weize Chen, Chenfei Yuan, Jiarui Yuan, Yusheng Su, Chen Qian, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun</author><pubDate>Wed, 28 Feb 2024 16:07:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18439v1</guid></item><item><title>Graph Regularized Encoder Training for Extreme Classification</title><link>http://arxiv.org/abs/2402.18434v1</link><description>Deep extreme classification (XC) aims to train an encoder architecture and anaccompanying classifier architecture to tag a data point with the most relevantsubset of labels from a very large universe of labels. XC applications inranking, recommendation and tagging routinely encounter tail labels for whichthe amount of training data is exceedingly small. Graph convolutional networks(GCN) present a convenient but computationally expensive way to leverage taskmetadata and enhance model accuracies in these settings. This paper formallyestablishes that in several use cases, the steep computational cost of GCNs isentirely avoidable by replacing GCNs with non-GCN architectures. The papernotices that in these settings, it is much more effective to use graph data toregularize encoder training than to implement a GCN. Based on these insights,an alternative paradigm RAMEN is presented to utilize graph metadata in XCsettings that offers significant performance boosts with zero increase ininference computational costs. RAMEN scales to datasets with up to 1M labelsand offers prediction accuracy up to 15% higher on benchmark datasets thanstate of the art methods, including those that use graph metadata to trainGCNs. RAMEN also offers 10% higher accuracy over the best baseline on aproprietary recommendation dataset sourced from click logs of a popular searchengine. Code for RAMEN will be released publicly.</description><author>Anshul Mittal, Shikhar Mohan, Deepak Saini, Suchith C. Prabhu, Jain jiao, Sumeet Agarwal, Soumen Chakrabarti, Purushottam Kar, Manik Varma</author><pubDate>Wed, 28 Feb 2024 16:00:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18434v1</guid></item><item><title>Fully Convolutional Slice-to-Volume Reconstruction for Single-Stack MRI</title><link>http://arxiv.org/abs/2312.03102v2</link><description>In magnetic resonance imaging (MRI), slice-to-volume reconstruction (SVR)refers to computational reconstruction of an unknown 3D magnetic resonancevolume from stacks of 2D slices corrupted by motion. While promising, currentSVR methods require multiple slice stacks for accurate 3D reconstruction,leading to long scans and limiting their use in time-sensitive applicationssuch as fetal fMRI. Here, we propose a SVR method that overcomes theshortcomings of previous work and produces state-of-the-art reconstructions inthe presence of extreme inter-slice motion. Inspired by the recent success ofsingle-view depth estimation methods, we formulate SVR as a single-stack motionestimation task and train a fully convolutional network to predict a motionstack for a given slice stack, producing a 3D reconstruction as a byproduct ofthe predicted motion. Extensive experiments on the SVR of adult and fetalbrains demonstrate that our fully convolutional method is twice as accurate asprevious SVR methods. Our code is available at github.com/seannz/svr.</description><author>Sean I. Young, Yaël Balbastre, Bruce Fischl, Polina Golland, Juan Eugenio Iglesias</author><pubDate>Wed, 28 Feb 2024 15:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03102v2</guid></item><item><title>Learning in Deep Factor Graphs with Gaussian Belief Propagation</title><link>http://arxiv.org/abs/2311.14649v2</link><description>We propose an approach to do learning in Gaussian factor graphs. We treat allrelevant quantities (inputs, outputs, parameters, latents) as random variablesin a graphical model, and view both training and prediction as inferenceproblems with different observed nodes. Our experiments show that theseproblems can be efficiently solved with belief propagation (BP), whose updatesare inherently local, presenting exciting opportunities for distributed andasynchronous training. Our approach can be scaled to deep networks and providesa natural means to do continual learning: use the BP-estimated parametermarginals of the current task as parameter priors for the next. On a videodenoising task we demonstrate the benefit of learnable parameters over aclassical factor graph approach and we show encouraging performance of deepfactor graphs for continual image classification.</description><author>Seth Nabarro, Mark van der Wilk, Andrew J Davison</author><pubDate>Wed, 28 Feb 2024 15:56:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14649v2</guid></item><item><title>Leveraging Diverse Modeling Contexts with Collaborating Learning for Neural Machine Translation</title><link>http://arxiv.org/abs/2402.18428v1</link><description>Autoregressive (AR) and Non-autoregressive (NAR) models are two types ofgenerative models for Neural Machine Translation (NMT). AR models predicttokens in a word-by-word manner and can effectively capture the distribution ofreal translations. NAR models predict tokens by extracting bidirectionalcontextual information which can improve the inference speed but they sufferfrom performance degradation. Previous works utilized AR models to enhance NARmodels by reducing the training data's complexity or incorporating the globalinformation into AR models by virtue of NAR models. However, those investigatedmethods only take advantage of the contextual information of a single type ofmodel while neglecting the diversity in the contextual information that can beprovided by different types of models. In this paper, we propose a novelgeneric collaborative learning method, DCMCL, where AR and NAR models aretreated as collaborators instead of teachers and students. To hierarchicallyleverage the bilateral contextual information, token-level mutual learning andsequence-level contrastive learning are adopted between AR and NAR models.Extensive experiments on four widely used benchmarks show that the proposedDCMCL method can simultaneously improve both AR and NAR models with up to 1.38and 2.98 BLEU scores respectively, and can also outperform the currentbest-unified model with up to 0.97 BLEU scores for both AR and NAR decoding.</description><author>Yusheng Liao, Yanfeng Wang, Yu Wang</author><pubDate>Wed, 28 Feb 2024 15:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18428v1</guid></item><item><title>Autonomous Vehicles: Evolution of Artificial Intelligence and Learning Algorithms</title><link>http://arxiv.org/abs/2402.17690v2</link><description>The advent of autonomous vehicles has heralded a transformative era intransportation, reshaping the landscape of mobility through cutting-edgetechnologies. Central to this evolution is the integration of ArtificialIntelligence (AI) and learning algorithms, propelling vehicles into realms ofunprecedented autonomy. This paper provides a comprehensive exploration of theevolutionary trajectory of AI within autonomous vehicles, tracing the journeyfrom foundational principles to the most recent advancements. Commencing with acurrent landscape overview, the paper delves into the fundamental role of AI inshaping the autonomous decision-making capabilities of vehicles. It elucidatesthe steps involved in the AI-powered development life cycle in vehicles,addressing ethical considerations and bias in AI-driven software developmentfor autonomous vehicles. The study presents statistical insights into the usageand types of AI/learning algorithms over the years, showcasing the evolvingresearch landscape within the automotive industry. Furthermore, the paperhighlights the pivotal role of parameters in refining algorithms for bothtrucks and cars, facilitating vehicles to adapt, learn, and improve performanceover time. It concludes by outlining different levels of autonomy, elucidatingthe nuanced usage of AI and learning algorithms, and automating key tasks ateach level. Additionally, the document discusses the variation in softwarepackage sizes across different autonomy levels</description><author>Divya Garikapati, Sneha Sudhir Shetiya</author><pubDate>Wed, 28 Feb 2024 15:53:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17690v2</guid></item><item><title>A Relational Inductive Bias for Dimensional Abstraction in Neural Networks</title><link>http://arxiv.org/abs/2402.18426v1</link><description>The human cognitive system exhibits remarkable flexibility and generalizationcapabilities, partly due to its ability to form low-dimensional, compositionalrepresentations of the environment. In contrast, standard neural networkarchitectures often struggle with abstract reasoning tasks, overfitting, andrequiring extensive data for training. This paper investigates the impact ofthe relational bottleneck -- a mechanism that focuses processing on relationsamong inputs -- on the learning of factorized representations conducive tocompositional coding and the attendant flexibility of processing. Wedemonstrate that such a bottleneck not only improves generalization andlearning efficiency, but also aligns network performance with human-likebehavioral biases. Networks trained with the relational bottleneck developedorthogonal representations of feature dimensions latent in the dataset,reflecting the factorized structure thought to underlie human cognitiveflexibility. Moreover, the relational network mimics human biases towardsregularity without pre-specified symbolic primitives, suggesting that thebottleneck fosters the emergence of abstract representations that conferflexibility akin to symbols.</description><author>Declan Campbell, Jonathan D. Cohen</author><pubDate>Wed, 28 Feb 2024 15:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18426v1</guid></item><item><title>Training normalizing flows with computationally intensive target probability distributions</title><link>http://arxiv.org/abs/2308.13294v2</link><description>Machine learning techniques, in particular the so-called normalizing flows,are becoming increasingly popular in the context of Monte Carlo simulations asthey can effectively approximate target probability distributions. In the caseof lattice field theories (LFT) the target distribution is given by theexponential of the action. The common loss function's gradient estimator basedon the "reparametrization trick" requires the calculation of the derivative ofthe action with respect to the fields. This can present a significantcomputational cost for complicated, non-local actions like e.g. fermionicaction in QCD. In this contribution, we propose an estimator for normalizingflows based on the REINFORCE algorithm that avoids this issue. We apply it totwo dimensional Schwinger model with Wilson fermions at criticality and showthat it is up to ten times faster in terms of the wall-clock time as well asrequiring up to $30\%$ less memory than the reparameterization trick estimator.It is also more numerically stable allowing for single precision calculationsand the use of half-float tensor cores. We present an in-depth analysis of theorigins of those improvements. We believe that these benefits will appear alsooutside the realm of the LFT, in each case where the target probabilitydistribution is computationally intensive.</description><author>Piotr Bialas, Piotr Korcyl, Tomasz Stebel</author><pubDate>Wed, 28 Feb 2024 15:48:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13294v2</guid></item><item><title>InstructCoder: Instruction Tuning Large Language Models for Code Editing</title><link>http://arxiv.org/abs/2310.20329v3</link><description>Code editing encompasses a variety of pragmatic tasks that developers dealwith daily. Despite its relevance and practical usefulness, automatic codeediting remains an underexplored area in the evolution of deep learning models,partly due to data scarcity. In this work, we explore the use of Large LanguageModels (LLMs) to edit code based on user instructions. Evaluated on a novelhuman-written execution-based benchmark dubbed EditEval, we found currentmodels often struggle to fulfill the instructions. In light of this, wecontribute InstructCoder, the first instruction-tuning dataset designed toadapt LLMs for general-purpose code editing, containing high-diversitycode-editing tasks such as comment insertion, code optimization, and coderefactoring. It consists of over 114,000 instruction-input-output triplets andcovers multiple distinct code editing scenarios. The collection process startswith filtered commit data sourced from GitHub Python repositories as seeds.Subsequently, the dataset is systematically expanded through an iterativeprocess, where both seed and generated tasks are used to prompt ChatGPT formore data. Our findings reveal that open-source LLMs fine-tuned onInstructCoder can significantly enhance the accuracy of code edits, exhibitingsuperior code-editing performance matching advanced proprietary LLMs. Thedatasets and the source code are publicly available athttps://github.com/qishenghu/CodeInstruct.</description><author>Kaixin Li, Qisheng Hu, Xu Zhao, Hui Chen, Yuxi Xie, Tiedong Liu, Qizhe Xie, Junxian He</author><pubDate>Wed, 28 Feb 2024 15:47:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20329v3</guid></item><item><title>KVN: Keypoints Voting Network with Differentiable RANSAC for Stereo Pose Estimation</title><link>http://arxiv.org/abs/2307.11543v2</link><description>Object pose estimation is a fundamental computer vision task exploited inseveral robotics and augmented reality applications. Many establishedapproaches rely on predicting 2D-3D keypoint correspondences using RANSAC(Random sample consensus) and estimating the object pose using the PnP(Perspective-n-Point) algorithm. Being RANSAC non-differentiable,correspondences cannot be directly learned in an end-to-end fashion. In thispaper, we address the stereo image-based object pose estimation problem by i)introducing a differentiable RANSAC layer into a well-known monocular poseestimation network; ii) exploiting an uncertainty-driven multi-view PnP solverwhich can fuse information from multiple views. We evaluate our approach on achallenging public stereo object pose estimation dataset and a custom-builtdataset we call Transparent Tableware Dataset (TTD), yielding state-of-the-artresults against other recent approaches. Furthermore, in our ablation study, weshow that the differentiable RANSAC layer plays a significant role in theaccuracy of the proposed method. We release with this paper the code of ourmethod and the TTD dataset.</description><author>Ivano Donadi, Alberto Pretto</author><pubDate>Wed, 28 Feb 2024 15:46:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11543v2</guid></item><item><title>Emotion Classification in Low and Moderate Resource Languages</title><link>http://arxiv.org/abs/2402.18424v1</link><description>It is important to be able to analyze the emotional state of people aroundthe globe. There are 7100+ active languages spoken around the world andbuilding emotion classification for each language is labor intensive.Particularly for low-resource and endangered languages, building emotionclassification can be quite challenging. We present a cross-lingual emotionclassifier, where we train an emotion classifier with resource-rich languages(i.e. \textit{English} in our work) and transfer the learning to low andmoderate resource languages. We compare and contrast two approaches of transferlearning from a high-resource language to a low or moderate-resource language.One approach projects the annotation from a high-resource language to low andmoderate-resource language in parallel corpora and the other one uses directtransfer from high-resource language to the other languages. We show theefficacy of our approaches on 6 languages: Farsi, Arabic, Spanish, Ilocano,Odia, and Azerbaijani. Our results indicate that our approaches outperformrandom baselines and transfer emotions across languages successfully. For alllanguages, the direct cross-lingual transfer of emotion yields better results.We also create annotated emotion-labeled resources for four languages: Farsi,Azerbaijani, Ilocano and Odia.</description><author>Shabnam Tafreshi, Shubham Vatsal, Mona Diab</author><pubDate>Wed, 28 Feb 2024 15:46:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18424v1</guid></item><item><title>Memory GAPS: Would LLMs pass the Tulving Test?</title><link>http://arxiv.org/abs/2402.16505v2</link><description>The Tulving Test was designed to investigate memory performance inrecognition and recall tasks. Its results help assess the relevance of the"Synergistic Ecphory Model" of memory and similar RK paradigms in humanperformance. This paper starts investigating whether the more thanforty-year-old framework sheds some light on LLMs' acts of remembering.</description><author>Jean-Marie Chauvet</author><pubDate>Wed, 28 Feb 2024 15:40:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16505v2</guid></item><item><title>Can GPT Improve the State of Prior Authorization via Guideline Based Automated Question Answering?</title><link>http://arxiv.org/abs/2402.18419v1</link><description>Health insurance companies have a defined process called prior authorization(PA) which is a health plan cost-control process that requires doctors andother healthcare professionals to get clearance in advance from a health planbefore performing a particular procedure on a patient in order to be eligiblefor payment coverage. For health insurance companies, approving PA requests forpatients in the medical domain is a time-consuming and challenging task. One ofthose key challenges is validating if a request matches up to certain criteriasuch as age, gender, etc. In this work, we evaluate whether GPT can validatenumerous key factors, in turn helping health plans reach a decision drasticallyfaster. We frame it as a question answering task, prompting GPT to answer aquestion from patient electronic health record. We experiment with differentconventional prompting techniques as well as introduce our own novel promptingtechnique. Moreover, we report qualitative assessment by humans on the naturallanguage generation outputs from our approach. Results show that our methodachieves superior performance with the mean weighted F1 score of 0.61 ascompared to its standard counterparts.</description><author>Shubham Vatsal, Ayush Singh, Shabnam Tafreshi</author><pubDate>Wed, 28 Feb 2024 15:39:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18419v1</guid></item><item><title>Prediction of recurrence free survival of head and neck cancer using PET/CT radiomics and clinical information</title><link>http://arxiv.org/abs/2402.18417v1</link><description>The 5-year survival rate of Head and Neck Cancer (HNC) has not improved overthe past decade and one common cause of treatment failure is recurrence. Inthis paper, we built Cox proportional hazard (CoxPH) models that predict therecurrence free survival (RFS) of oropharyngeal HNC patients. Our modelsutilise both clinical information and multimodal radiomics features extractedfrom tumour regions in Computed Tomography (CT) and Positron EmissionTomography (PET). Furthermore, we were one of the first studies to explore theimpact of segmentation accuracy on the predictive power of the extractedradiomics features, through under- and over-segmentation study. Our models weretrained using the HEad and neCK TumOR (HECKTOR) challenge data, and the bestperforming model achieved a concordance index (C-index) of 0.74 for the modelutilising clinical information and multimodal CT and PET radiomics features,which compares favourably with the model that only used clinical information(C-index of 0.67). Our under- and over-segmentation study confirms thatsegmentation accuracy affects radiomics extraction, however, it affects PET andCT differently.</description><author>Mona Furukawa, Daniel R. McGowan, Bartłomiej W. Papież</author><pubDate>Wed, 28 Feb 2024 15:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18417v1</guid></item><item><title>Unsupervised Cross-Domain Image Retrieval via Prototypical Optimal Transport</title><link>http://arxiv.org/abs/2402.18411v1</link><description>Unsupervised cross-domain image retrieval (UCIR) aims to retrieve imagessharing the same category across diverse domains without relying on labeleddata. Prior approaches have typically decomposed the UCIR problem into twodistinct tasks: intra-domain representation learning and cross-domain featurealignment. However, these segregated strategies overlook the potentialsynergies between these tasks. This paper introduces ProtoOT, a novel OptimalTransport formulation explicitly tailored for UCIR, which integratesintra-domain feature representation learning and cross-domain alignment into aunified framework. ProtoOT leverages the strengths of the K-means clusteringmethod to effectively manage distribution imbalances inherent in UCIR. Byutilizing K-means for generating initial prototypes and approximating classmarginal distributions, we modify the constraints in Optimal Transportaccordingly, significantly enhancing its performance in UCIR scenarios.Furthermore, we incorporate contrastive learning into the ProtoOT framework tofurther improve representation learning. This encourages local semanticconsistency among features with similar semantics, while also explicitlyenforcing separation between features and unmatched prototypes, therebyenhancing global discriminativeness. ProtoOT surpasses existingstate-of-the-art methods by a notable margin across benchmark datasets.Notably, on DomainNet, ProtoOT achieves an average P@200 enhancement of 24.44%,and on Office-Home, it demonstrates a P@15 improvement of 12.12%. Code isavailable at https://github.com/HCVLAB/ProtoOT.</description><author>Bin Li, Ye Shi, Qian Yu, Jingya Wang</author><pubDate>Wed, 28 Feb 2024 15:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18411v1</guid></item><item><title>A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision Language Models</title><link>http://arxiv.org/abs/2402.18409v1</link><description>Large Vision Language Models (LVLMs), despite their recent success, arehardly comprehensively tested for their cognitive abilities. Inspired by theprevalent use of the "Cookie Theft" task in human cognition test, we propose anovel evaluation benchmark to evaluate high-level cognitive ability of LVLMsusing images with rich semantics. It defines eight reasoning capabilities andconsists of an image description task and a visual question answering task. Ourevaluation on well-known LVLMs shows that there is still a large gap incognitive ability between LVLMs and humans.</description><author>Xiujie Song, Mengyue Wu, Kenny Q. Zhu, Chunhao Zhang, Yanyi Chen</author><pubDate>Wed, 28 Feb 2024 15:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18409v1</guid></item><item><title>A Modular System for Enhanced Robustness of Multimedia Understanding Networks via Deep Parametric Estimation</title><link>http://arxiv.org/abs/2402.18402v1</link><description>In multimedia understanding tasks, corrupted samples pose a criticalchallenge, because when fed to machine learning models they lead to performancedegradation. In the past, three groups of approaches have been proposed tohandle noisy data: i) enhancer and denoiser modules to improve the quality ofthe noisy data, ii) data augmentation approaches, and iii) domain adaptationstrategies. All the aforementioned approaches come with drawbacks that limittheir applicability; the first has high computational costs and requires pairsof clean-corrupted data for training, while the others only allow deployment ofthe same task/network they were trained on (\ie, when upstream and downstreamtask/network are the same). In this paper, we propose SyMPIE to solve theseshortcomings. To this end, we design a small, modular, and efficient (just2GFLOPs to process a Full HD image) system to enhance input data for robustdownstream multimedia understanding with minimal computational cost. Our SyMPIEis pre-trained on an upstream task/network that should not match the downstreamones and does not need paired clean-corrupted samples. Our key insight is thatmost input corruptions found in real-world tasks can be modeled through globaloperations on color channels of images or spatial filters with small kernels.We validate our approach on multiple datasets and tasks, such as imageclassification (on ImageNetC, ImageNetC-Bar, VizWiz, and a newly proposed mixedcorruption benchmark named ImageNetC-mixed) and semantic segmentation (onCityscapes, ACDC, and DarkZurich) with consistent improvements of about 5\%relative accuracy gain across the board. The code of our approach and the newImageNetC-mixed benchmark will be made available upon publication.</description><author>Francesco Barbato, Umberto Michieli, Mehmet Karim Yucel, Pietro Zanuttigh, Mete Ozay</author><pubDate>Wed, 28 Feb 2024 15:24:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18402v1</guid></item><item><title>MATHWELL: Generating Educational Math Word Problems at Scale</title><link>http://arxiv.org/abs/2402.15861v2</link><description>Math word problems are critical K-8 educational tools, but writing them istime-consuming and requires domain expertise. We suggest that language modelscan support K-8 math education by automatically generating problems at scale.To be educational, generated problems must be 1) solvable, 2) accurate, and 3)appropriate. Existing datasets are unlabeled for these criteria, making themill-suited for training problem generators. We introduce MATHWELL, a Llama-2(70B) model iteratively finetuned to generate K-8 math word problems using datafrom expert annotation. Using MATHWELL, we generate the largest English wordproblem dataset with Program of Thought (PoT) rationales to date, containing20,490 problems. 3,484 are scored by domain experts who find MATHWELL has a 40%higher share of problems that have executable solutions and meet all criteriathan alternatives, with 74% of its problems with executable solutions beingsolvable, accurate, and appropriate. We release our model, data, andannotations.</description><author>Bryan R Christ, Jonathan Kropko, Thomas Hartvigsen</author><pubDate>Wed, 28 Feb 2024 15:19:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15861v2</guid></item><item><title>Rethinking Centered Kernel Alignment in Knowledge Distillation</title><link>http://arxiv.org/abs/2401.11824v2</link><description>Knowledge distillation has emerged as a highly effective method for bridgingthe representation discrepancy between large-scale models and lightweightmodels. Prevalent approaches involve leveraging appropriate metrics to minimizethe divergence or distance between the knowledge extracted from the teachermodel and the knowledge learned by the student model. Centered Kernel Alignment(CKA) is widely used to measure representation similarity and has been appliedin several knowledge distillation methods. However, these methods are complexand fail to uncover the essence of CKA, thus not answering the question of howto use CKA to achieve simple and effective distillation properly. This paperfirst provides a theoretical perspective to illustrate the effectiveness ofCKA, which decouples CKA to the upper bound of Maximum Mean Discrepancy~(MMD)and a constant term. Drawing from this, we propose a novel Relation-CenteredKernel Alignment~(RCKA) framework, which practically establishes a connectionbetween CKA and MMD. Furthermore, we dynamically customize the application ofCKA based on the characteristics of each task, with less computational sourceyet comparable performance than the previous methods. The extensive experimentson the CIFAR-100, ImageNet-1k, and MS-COCO demonstrate that our method achievesstate-of-the-art performance on almost all teacher-student pairs for imageclassification and object detection, validating the effectiveness of ourapproaches.</description><author>Zikai Zhou, Yunhang Shen, Shitong Shao, Linrui Gong, Shaohui Lin</author><pubDate>Wed, 28 Feb 2024 15:19:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11824v2</guid></item><item><title>Decomposed Prompting: Unveiling Multilingual Linguistic Structure Knowledge in English-Centric Large Language Models</title><link>http://arxiv.org/abs/2402.18397v1</link><description>Despite the predominance of English in their training data, English-centricLarge Language Models (LLMs) like GPT-3 and LLaMA display a remarkable abilityto perform multilingual tasks, raising questions about the depth and nature oftheir cross-lingual capabilities. This paper introduces the decomposedprompting approach to probe the linguistic structure understanding of theseLLMs in sequence labeling tasks. Diverging from the single text-to-text prompt,our method generates for each token of the input sentence an individual promptwhich asks for its linguistic label. We assess our method on the UniversalDependencies part-of-speech tagging dataset for 38 languages, utilizing bothEnglish-centric and multilingual LLMs. Our findings show that decomposedprompting surpasses the iterative prompting baseline in efficacy and efficiencyunder zero- and few-shot settings. Further analysis reveals the influence ofevaluation methods and the use of instructions in prompts. Our multilingualinvestigation shows that English-centric language models perform better onaverage than multilingual models. Our study offers insights into themultilingual transferability of English-centric LLMs, contributing to theunderstanding of their multilingual linguistic knowledge.</description><author>Ercong Nie, Shuzhou Yuan, Bolei Ma, Helmut Schmid, Michael Färber, Frauke Kreuter, Hinrich Schütze</author><pubDate>Wed, 28 Feb 2024 15:15:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18397v1</guid></item><item><title>Deep Confident Steps to New Pockets: Strategies for Docking Generalization</title><link>http://arxiv.org/abs/2402.18396v1</link><description>Accurate blind docking has the potential to lead to new biologicalbreakthroughs, but for this promise to be realized, docking methods mustgeneralize well across the proteome. Existing benchmarks, however, fail torigorously assess generalizability. Therefore, we develop DockGen, a newbenchmark based on the ligand-binding domains of proteins, and we show thatexisting machine learning-based docking models have very weak generalizationabilities. We carefully analyze the scaling laws of ML-based docking and showthat, by scaling data and model size, as well as integrating synthetic datastrategies, we are able to significantly increase the generalization capacityand set new state-of-the-art performance across benchmarks. Further, we proposeConfidence Bootstrapping, a new training paradigm that solely relies on theinteraction between diffusion and confidence models and exploits themulti-resolution generation process of diffusion models. We demonstrate thatConfidence Bootstrapping significantly improves the ability of ML-based dockingmethods to dock to unseen protein classes, edging closer to accurate andgeneralizable blind docking methods.</description><author>Gabriele Corso, Arthur Deng, Benjamin Fry, Nicholas Polizzi, Regina Barzilay, Tommi Jaakkola</author><pubDate>Wed, 28 Feb 2024 15:15:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18396v1</guid></item><item><title>Evaluating Decision Optimality of Autonomous Driving via Metamorphic Testing</title><link>http://arxiv.org/abs/2402.18393v1</link><description>Autonomous Driving System (ADS) testing is crucial in ADS development, withthe current primary focus being on safety. However, the evaluation ofnon-safety-critical performance, particularly the ADS's ability to make optimaldecisions and produce optimal paths for autonomous vehicles (AVs), is equallyvital to ensure the intelligence and reduce risks of AVs. Currently, there islittle work dedicated to assessing ADSs' optimal decision-making performancedue to the lack of corresponding oracles and the difficulty in generatingscenarios with non-optimal decisions. In this paper, we focus on evaluating thedecision-making quality of an ADS and propose the first method for detectingnon-optimal decision scenarios (NoDSs), where the ADS does not compute optimalpaths for AVs. Firstly, to deal with the oracle problem, we propose a novelmetamorphic relation (MR) aimed at exposing violations of optimal decisions.The MR identifies the property that the ADS should retain optimal decisionswhen the optimal path remains unaffected by non-invasive changes. Subsequently,we develop a new framework, Decictor, designed to generate NoDSs efficiently.Decictor comprises three main components: Non-invasive Mutation, MR Check, andFeedback. The Non-invasive Mutation ensures that the original optimal path inthe mutated scenarios is not affected, while the MR Check is responsible fordetermining whether non-optimal decisions are made. To enhance theeffectiveness of identifying NoDSs, we design a feedback metric that combinesboth spatial and temporal aspects of the AV's movement. We evaluate Decictor onBaidu Apollo, an open-source and production-grade ADS. The experimental resultsvalidate the effectiveness of Decictor in detecting non-optimal decisions ofADSs. Our work provides valuable and original insights into evaluating thenon-safety-critical performance of ADSs.</description><author>Mingfei Cheng, Yuan Zhou, Xiaofei Xie, Junjie Wang, Guozhu Meng, Kairui Yang</author><pubDate>Wed, 28 Feb 2024 15:13:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18393v1</guid></item><item><title>Unveiling the Potential of Robustness in Evaluating Causal Inference Models</title><link>http://arxiv.org/abs/2402.18392v1</link><description>The growing demand for personalized decision-making has led to a surge ofinterest in estimating the Conditional Average Treatment Effect (CATE). Theintersection of machine learning and causal inference has yielded variouseffective CATE estimators. However, deploying these estimators in practice isoften hindered by the absence of counterfactual labels, making it challengingto select the desirable CATE estimator using conventional model selectionprocedures like cross-validation. Existing approaches for CATE estimatorselection, such as plug-in and pseudo-outcome metrics, face two inherentchallenges. Firstly, they are required to determine the metric form and theunderlying machine learning models for fitting nuisance parameters or plug-inlearners. Secondly, they lack a specific focus on selecting a robust estimator.To address these challenges, this paper introduces a novel approach, theDistributionally Robust Metric (DRM), for CATE estimator selection. Theproposed DRM not only eliminates the need to fit additional models but alsoexcels at selecting a robust CATE estimator. Experimental studies demonstratethe efficacy of the DRM method, showcasing its consistent effectiveness inidentifying superior estimators while mitigating the risk of selecting inferiorones.</description><author>Yiyan Huang, Cheuk Hang Leung, Siyi Wang, Yijun Li, Qi Wu</author><pubDate>Wed, 28 Feb 2024 15:12:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18392v1</guid></item><item><title>Neuromorphic Event-Driven Semantic Communication in Microgrids</title><link>http://arxiv.org/abs/2402.18390v1</link><description>Synergies between advanced communications, computing and artificialintelligence are unraveling new directions of coordinated operation andresiliency in microgrids. On one hand, coordination among sources isfacilitated by distributed, privacy-minded processing at multiple locations,whereas on the other hand, it also creates exogenous data arrival paths foradversaries that can lead to cyber-physical attacks amongst other reliabilityissues in the communication layer. This long-standing problem necessitates newintrinsic ways of exchanging information between converters through power linesto optimize the system's control performance. Going beyond the existing powerand data co-transfer technologies that are limited by efficiency andscalability concerns, this paper proposes neuromorphic learning to implantcommunicative features using spiking neural networks (SNNs) at each node, whichis trained collaboratively in an online manner simply using the power exchangesbetween the nodes. As opposed to the conventional neuromorphic sensors thatoperate with spiking signals, we employ an event-driven selective process tocollect sparse data for training of SNNs. Finally, its multi-fold effectivenessand reliable performance is validated under simulation conditions withdifferent microgrid topologies and components to establish a new direction inthe sense-actuate-compute cycle for power electronic dominated grids andmicrogrids.</description><author>Xiaoguang Diao, Yubo Song, Subham Sahoo, Yuan Li</author><pubDate>Wed, 28 Feb 2024 15:11:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18390v1</guid></item><item><title>HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments</title><link>http://arxiv.org/abs/2402.10228v2</link><description>To solve complex tasks under resource constraints, reinforcement learning(RL) agents need to be simple, efficient, and scalable, addressing (1) largestate spaces and (2) the continuous accumulation of interaction data. Wepropose HyperAgent, an RL framework featuring the hypermodel and index samplingschemes that enable computation-efficient incremental approximation for theposteriors associated with general value functions without the need forconjugacy, and data-efficient action selection. Implementing HyperAgent isstraightforward, requiring only one additional module beyond what is necessaryfor Double-DQN. HyperAgent stands out as the first method to offer robustperformance in large-scale deep RL benchmarks while achieving provably scalableper-step computational complexity and attaining sublinear regret under tabularassumptions. HyperAgent can solve Deep Sea hard exploration problems withepisodes that optimally scale with problem size and exhibits significantefficiency gains in both data and computation under the Atari benchmark. Thecore of our theoretical analysis is the sequential posterior approximationargument, enabled by the first analytical tool for sequential random projection-- a non-trivial martingale extension of the Johnson-Lindenstrauss. This workbridges the theoretical and practical realms of RL, establishing a newbenchmark for RL algorithm design.</description><author>Yingru Li, Jiawei Xu, Lei Han, Zhi-Quan Luo</author><pubDate>Wed, 28 Feb 2024 15:08:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10228v2</guid></item><item><title>The First Place Solution of WSDM Cup 2024: Leveraging Large Language Models for Conversational Multi-Doc QA</title><link>http://arxiv.org/abs/2402.18385v1</link><description>Conversational multi-doc question answering aims to answer specific questionsbased on the retrieved documents as well as the contextual conversations. Inthis paper, we introduce our winning approach for the "Conversational Multi-DocQA" challenge in WSDM Cup 2024, which exploits the superior natural languageunderstanding and generation capability of Large Language Models (LLMs). Wefirst adapt LLMs to the task, then devise a hybrid training strategy to makethe most of in-domain unlabeled data. Moreover, an advanced text embeddingmodel is adopted to filter out potentially irrelevant documents and severalapproaches are designed and compared for the model ensemble. Equipped with allthese techniques, our solution finally ranked 1st place in WSDM Cup 2024,surpassing its rivals to a large extent. The source codes have been released athttps://github.com/zhangzhao219/WSDM-Cup-2024.</description><author>Yiming Li, Zhao Zhang</author><pubDate>Wed, 28 Feb 2024 15:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18385v1</guid></item><item><title>Robust Quantification of Percent Emphysema on CT via Domain Attention: the Multi-Ethnic Study of Atherosclerosis (MESA) Lung Study</title><link>http://arxiv.org/abs/2402.18383v1</link><description>Robust quantification of pulmonary emphysema on computed tomography (CT)remains challenging for large-scale research studies that involve scans fromdifferent scanner types and for translation to clinical scans. Existing studieshave explored several directions to tackle this challenge, including densitycorrection, noise filtering, regression, hidden Markov measure field (HMMF)model-based segmentation, and volume-adjusted lung density. Despite somepromising results, previous studies either required a tedious workflow orlimited opportunities for downstream emphysema subtyping, limiting efficientadaptation on a large-scale study. To alleviate this dilemma, we developed anend-to-end deep learning framework based on an existing HMMF segmentationframework. We first demonstrate that a regular UNet cannot replicate theexisting HMMF results because of the lack of scanner priors. We then design anovel domain attention block to fuse image feature with quantitative scannerpriors which significantly improves the results.</description><author>Xuzhe Zhang, Elsa D. Angelini, Eric A. Hoffman, Karol E. Watson, Benjamin M. Smith, R. Graham Barr, Andrew F. Laine</author><pubDate>Wed, 28 Feb 2024 15:04:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18383v1</guid></item><item><title>Large Language Models As Evolution Strategies</title><link>http://arxiv.org/abs/2402.18381v1</link><description>Large Transformer models are capable of implementing a plethora of so-calledin-context learning algorithms. These include gradient descent, classification,sequence completion, transformation, and improvement. In this work, weinvestigate whether large language models (LLMs), which never explicitlyencountered the task of black-box optimization, are in principle capable ofimplementing evolutionary optimization algorithms. While previous works havesolely focused on language-based task specification, we move forward and focuson the zero-shot application of LLMs to black-box optimization. We introduce anovel prompting strategy, consisting of least-to-most sorting of discretizedpopulation members and querying the LLM to propose an improvement to the meanstatistic, i.e. perform a type of black-box recombination operation.Empirically, we find that our setup allows the user to obtain an LLM-basedevolution strategy, which we call `EvoLLM', that robustly outperforms baselinealgorithms such as random search and Gaussian Hill Climbing on synthetic BBOBfunctions as well as small neuroevolution tasks. Hence, LLMs can act as`plug-in' in-context recombination operators. We provide several comparativestudies of the LLM's model size, prompt strategy, and context construction.Finally, we show that one can flexibly improve EvoLLM's performance byproviding teacher algorithm information via instruction fine-tuning onpreviously collected teacher optimization trajectories.</description><author>Robert Tjarko Lange, Yingtao Tian, Yujin Tang</author><pubDate>Wed, 28 Feb 2024 15:02:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18381v1</guid></item><item><title>Online Signal Estimation on the Graph Edges via Line Graph Transformation</title><link>http://arxiv.org/abs/2311.00656v2</link><description>The processing of signals on graph edges is challenging considering thatGraph Signal Processing techniques are defined only on the graph nodes.Leveraging the Line Graph to transform a graph edge signal onto the node of itsedge-to-vertex dual, we propose the Line Graph Least Mean Square (LGLMS)algorithm for online time-varying graph edge signal prediction. By setting upan $l_2$-norm optimization problem, LGLMS forms an adaptive algorithm as thegraph edge analogy of the classical adaptive LMS algorithm. Additionally, theLGLMS inherits all the GSP concepts and techniques that can previously bedeployed on the graph nodes, but without the need to redefine them on the graphedges. Experimenting with transportation graphs and meteorological graphs, withthe signal observations having noisy and missing values, we confirmed thatLGLMS is suitable for the online prediction of time-varying edge signals.</description><author>Yi Yan, Ercan Engin Kuruoglu</author><pubDate>Wed, 28 Feb 2024 14:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00656v2</guid></item><item><title>SegForestNet: Spatial-Partitioning-Based Aerial Image Segmentation</title><link>http://arxiv.org/abs/2302.01585v2</link><description>Aerial image segmentation is the basis for applications such as automaticallycreating maps or tracking deforestation. In true orthophotos, which are oftenused in these applications, many objects and regions can be approximated wellby polygons. However, this fact is rarely exploited by state-of-the-artsemantic segmentation models. Instead, most models allow unnecessary degrees offreedom in their predictions by allowing arbitrary region shapes. We thereforepresent a refinement of our deep learning model which predicts binary spacepartitioning trees, an efficient polygon representation. The refinementsinclude a new feature decoder architecture and a new differentiable BSP treerenderer which both avoid vanishing gradients. Additionally, we designed anovel loss function specifically designed to improve the spatial partitioningdefined by the predicted trees. Furthermore, our expanded model can predictmultiple trees at once and thus can predict class-specific segmentations. As anadditional contribution, we investigate the impact of a non-optimal trainingprocess in comparison to an optimized training process. While modelarchitectures optimized for aerial images, such as PFNet or our own model, showan advantage under non-optimal conditions, this advantage disappears underoptimal training conditions. Despite this observation, our model still makesbetter predictions for small rectangular objects, e.g., cars.</description><author>Daniel Gritzner, Jörn Ostermann</author><pubDate>Wed, 28 Feb 2024 14:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01585v2</guid></item><item><title>Out-of-Domain Generalization in Dynamical Systems Reconstruction</title><link>http://arxiv.org/abs/2402.18377v1</link><description>In science we are interested in finding the governing equations, thedynamical rules, underlying empirical phenomena. While traditionally scientificmodels are derived through cycles of human insight and experimentation,recently deep learning (DL) techniques have been advanced to reconstructdynamical systems (DS) directly from time series data. State-of-the-artdynamical systems reconstruction (DSR) methods show promise in capturinginvariant and long-term properties of observed DS, but their ability togeneralize to unobserved domains remains an open challenge. Yet, this is acrucial property we would expect from any viable scientific theory. In thiswork, we provide a formal framework that addresses generalization in DSR. Weexplain why and how out-of-domain (OOD) generalization (OODG) in DSR profoundlydiffers from OODG considered elsewhere in machine learning. We introducemathematical notions based on topological concepts and ergodic theory toformalize the idea of learnability of a DSR model. We formally prove thatblack-box DL techniques, without adequate structural priors, generally will notbe able to learn a generalizing DSR model. We also show this empirically,considering major classes of DSR algorithms proposed so far, and illustratewhere and why they fail to generalize across the whole phase space. Our studyprovides the first comprehensive mathematical treatment of OODG in DSR, andgives a deeper conceptual understanding of where the fundamental problems inOODG lie and how they could possibly be addressed in practice.</description><author>Niclas Göring, Florian Hess, Manuel Brenner, Zahra Monfared, Daniel Durstewitz</author><pubDate>Wed, 28 Feb 2024 14:52:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18377v1</guid></item><item><title>Tokenization Is More Than Compression</title><link>http://arxiv.org/abs/2402.18376v1</link><description>Tokenization is a foundational step in Natural Language Processing (NLP)tasks, bridging raw text and language models. Existing tokenization approacheslike Byte-Pair Encoding (BPE) originate from the field of data compression, andit has been suggested that the effectiveness of BPE stems from its ability tocondense text into a relatively small number of tokens. We test the hypothesisthat fewer tokens lead to better downstream performance by introducingPathPiece, a new tokenizer that segments a document's text into the minimumnumber of tokens for a given vocabulary. Through extensive experimentation wefind this hypothesis not to be the case, casting doubt on the understanding ofthe reasons for effective tokenization. To examine which other factors play arole, we evaluate design decisions across all three phases of tokenization:pre-tokenization, vocabulary construction, and segmentation, offering newinsights into the design of effective tokenizers. Specifically, we illustratethe importance of pre-tokenization and the benefits of using BPE to initializevocabulary construction. We train 64 language models with varying tokenization,ranging in size from 350M to 2.4B parameters, all of which are made publiclyavailable.</description><author>Craig W. Schmidt, Varshini Reddy, Haoran Zhang, Alec Alameddine, Omri Uzan, Yuval Pinter, Chris Tanner</author><pubDate>Wed, 28 Feb 2024 14:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18376v1</guid></item><item><title>VerifiNER: Verification-augmented NER via Knowledge-grounded Reasoning with Large Language Models</title><link>http://arxiv.org/abs/2402.18374v1</link><description>Recent approaches in domain-specific named entity recognition (NER), such asbiomedical NER, have shown remarkable advances. However, they still lack offaithfulness, producing erroneous predictions. We assume that knowledge ofentities can be useful in verifying the correctness of the predictions. Despitethe usefulness of knowledge, resolving such errors with knowledge isnontrivial, since the knowledge itself does not directly indicate theground-truth label. To this end, we propose VerifiNER, a post-hoc verificationframework that identifies errors from existing NER methods using knowledge andrevises them into more faithful predictions. Our framework leverages thereasoning abilities of large language models to adequately ground on knowledgeand the contextual information in the verification process. We validateeffectiveness of VerifiNER through extensive experiments on biomedicaldatasets. The results suggest that VerifiNER can successfully verify errorsfrom existing models as a model-agnostic approach. Further analyses onout-of-domain and low-resource settings show the usefulness of VerifiNER onreal-world applications.</description><author>Seoyeon Kim, Kwangwook Seo, Hyungjoo Chae, Jinyoung Yeo, Dongha Lee</author><pubDate>Wed, 28 Feb 2024 14:49:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18374v1</guid></item><item><title>StructLM: Towards Building Generalist Models for Structured Knowledge Grounding</title><link>http://arxiv.org/abs/2402.16671v2</link><description>Structured data sources, such as tables, graphs, and databases, areubiquitous knowledge sources. Despite the demonstrated capabilities of largelanguage models (LLMs) on plain text, their proficiency in interpreting andutilizing structured data remains limited. Our investigation reveals a notabledeficiency in LLMs' ability to process structured data, e.g., ChatGPT lagsbehind state-of-the-art (SoTA) model by an average of 35%. To augment theStructured Knowledge Grounding (SKG) capabilities in LLMs, we have developed acomprehensive instruction tuning dataset comprising 1.1 million examples.Utilizing this dataset, we train a series of models, referred to as StructLM,based on the Code-LLaMA architecture, ranging from 7B to 34B parameters. OurStructLM series surpasses task-specific models on 14 out of 18 evaluateddatasets and establishes new SoTA achievements on 7 SKG tasks. Furthermore,StructLM demonstrates exceptional generalization across 6 novel SKG tasks.Contrary to expectations, we observe that scaling model size offers marginalbenefits, with StructLM-34B showing only slight improvements over StructLM-7B.This suggests that structured knowledge grounding is still a challenging taskand requires more innovative design to push to a new level.</description><author>Alex Zhuang, Ge Zhang, Tianyu Zheng, Xinrun Du, Junjie Wang, Weiming Ren, Stephen W. Huang, Jie Fu, Xiang Yue, Wenhu Chen</author><pubDate>Wed, 28 Feb 2024 14:49:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16671v2</guid></item><item><title>MiniLLM: Knowledge Distillation of Large Language Models</title><link>http://arxiv.org/abs/2306.08543v2</link><description>Knowledge Distillation (KD) is a promising technique for reducing the highcomputational demand of large language models (LLMs). However, previous KDmethods are primarily applied to white-box classification models or trainingsmall models to imitate black-box model APIs like ChatGPT. How to effectivelydistill the knowledge of white-box LLMs into small models is stillunder-explored, which becomes more important with the prosperity of open-sourceLLMs. In this work, we propose a KD approach that distills LLMs into smallerlanguage models. We first replace the forward Kullback-Leibler divergence (KLD)objective in the standard KD approaches with reverse KLD, which is moresuitable for KD on generative language models, to prevent the student modelfrom overestimating the low-probability regions of the teacher distribution.Then, we derive an effective optimization approach to learn this objective. Thestudent models are named MiniLLM. Extensive experiments in theinstruction-following setting show that MiniLLM generates more preciseresponses with higher overall quality, lower exposure bias, better calibration,and higher long-text generation performance than the baselines. Our method isscalable for different model families with 120M to 13B parameters. Our code,data, and model checkpoints can be found in\url{https://github.com/microsoft/LMOps/tree/main/minillm}.</description><author>Yuxian Gu, Li Dong, Furu Wei, Minlie Huang</author><pubDate>Wed, 28 Feb 2024 14:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08543v2</guid></item><item><title>A Closer Look at the Limitations of Instruction Tuning</title><link>http://arxiv.org/abs/2402.05119v3</link><description>Instruction Tuning (IT), the process of training large language models (LLMs)using instruction-response pairs, has emerged as the predominant method fortransforming base pre-trained LLMs into open-domain conversational agents.While IT has achieved notable success and widespread adoption, its limitationsand shortcomings remain underexplored. In this paper, through rigorousexperiments and an in-depth analysis of the changes LLMs undergo through IT, wereveal various limitations of IT. In particular, we show that (1) IT fails toenhance knowledge or skills in LLMs. LoRA fine-tuning is limited to learningresponse initiation and style tokens, and full-parameter fine-tuning leads toknowledge degradation. (2) Copying response patterns from IT datasets derivedfrom knowledgeable sources leads to a decline in response quality. (3)Full-parameter fine-tuning increases hallucination by inaccurately borrowingtokens from conceptually similar instances in the IT dataset for generatingresponses. (4) Popular methods to improve IT do not lead to performanceimprovements over a simple LoRA fine-tuned model. Our findings reveal thatresponses generated solely from pre-trained knowledge consistently outperformresponses by models that learn any form of new knowledge from IT on open-sourcedatasets. We hope the insights and challenges revealed inspire future work.</description><author>Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Ramaneswaran S, Deepali Aneja, Zeyu Jin, Ramani Duraiswami, Dinesh Manocha</author><pubDate>Wed, 28 Feb 2024 14:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05119v3</guid></item><item><title>BLT: Can Large Language Models Handle Basic Legal Text?</title><link>http://arxiv.org/abs/2311.09693v2</link><description>We find that the best publicly available LLMs like GPT-4, Claude, and {PaLM2} currently perform poorly at basic legal text handling. We introduce abenchmark consisting of tasks that lawyers and paralegals would expect LLMs tohandle zero-shot, such as looking up the text at a line of a witness depositionor at a subsection of a contract. LLMs' poor performance on this benchmarkcasts into doubt their reliability as-is for legal practice. However,fine-tuning for these tasks brings even a smaller model to near-perfectperformance on our test set and also raises performance on a related legaltask. These results suggest that many simple behaviors needed for a domain maynot be present in foundational LLMs, without additional engagement from subjectmatter experts.</description><author>Andrew Blair-Stanek, Nils Holzenberger, Benjamin Van Durme</author><pubDate>Wed, 28 Feb 2024 14:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09693v2</guid></item><item><title>Right on Time: Revising Time Series Models by Constraining their Explanations</title><link>http://arxiv.org/abs/2402.12921v2</link><description>The reliability of deep time series models is often compromised by theirtendency to rely on confounding factors, which may lead to misleading results.Our newly recorded, naturally confounded dataset named P2S from a realmechanical production line emphasizes this. To tackle the challenging problemof mitigating confounders in time series data, we introduce Right on Time(RioT). Our method enables interactions with model explanations across both thetime and frequency domain. Feedback on explanations in both domains is thenused to constrain the model, steering it away from the annotated confoundingfactors. The dual-domain interaction strategy is crucial for effectivelyaddressing confounders in time series datasets. We empirically demonstrate thatRioT can effectively guide models away from the wrong reasons in P2S as well aspopular time series classification and forecasting datasets.</description><author>Maurice Kraus, David Steinmann, Antonia Wüst, Andre Kokozinski, Kristian Kersting</author><pubDate>Wed, 28 Feb 2024 14:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12921v2</guid></item><item><title>Efficient ConvBN Blocks for Transfer Learning and Beyond</title><link>http://arxiv.org/abs/2305.11624v2</link><description>Convolution-BatchNorm (ConvBN) blocks are integral components in variouscomputer vision tasks and other domains. A ConvBN block can operate in threemodes: Train, Eval, and Deploy. While the Train mode is indispensable fortraining models from scratch, the Eval mode is suitable for transfer learningand beyond, and the Deploy mode is designed for the deployment of models. Thispaper focuses on the trade-off between stability and efficiency in ConvBNblocks: Deploy mode is efficient but suffers from training instability; Evalmode is widely used in transfer learning but lacks efficiency. To solve thedilemma, we theoretically reveal the reason behind the diminished trainingstability observed in the Deploy mode. Subsequently, we propose a novel Tunemode to bridge the gap between Eval mode and Deploy mode. The proposed Tunemode is as stable as Eval mode for transfer learning, and its computationalefficiency closely matches that of the Deploy mode. Through extensiveexperiments in object detection, classification, and adversarial examplegeneration across $5$ datasets and $12$ model architectures, we demonstratethat the proposed Tune mode retains the performance while significantlyreducing GPU memory footprint and training time, thereby contributing efficientConvBN blocks for transfer learning and beyond. Our method has been integratedinto both PyTorch (general machine learning framework) and MMCV/MMEngine(computer vision framework). Practitioners just need one line of code to enjoyour efficient ConvBN blocks thanks to PyTorch's builtin machine learningcompilers.</description><author>Kaichao You, Guo Qin, Anchang Bao, Meng Cao, Ping Huang, Jiulong Shan, Mingsheng Long</author><pubDate>Wed, 28 Feb 2024 14:34:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11624v2</guid></item><item><title>Objective and Interpretable Breast Cosmesis Evaluation with Attention Guided Denoising Diffusion Anomaly Detection Model</title><link>http://arxiv.org/abs/2402.18362v1</link><description>As advancements in the field of breast cancer treatment continue to progress,the assessment of post-surgical cosmetic outcomes has gained increasingsignificance due to its substantial impact on patients' quality of life.However, evaluating breast cosmesis presents challenges due to the inherentlysubjective nature of expert labeling. In this study, we present a novelautomated approach, Attention-Guided Denoising Diffusion Anomaly Detection(AG-DDAD), designed to assess breast cosmesis following surgery, addressing thelimitations of conventional supervised learning and existing anomaly detectionmodels. Our approach leverages the attention mechanism of the distillation withno label (DINO) self-supervised Vision Transformer (ViT) in combination with adiffusion model to achieve high-quality image reconstruction and precisetransformation of discriminative regions. By training the diffusion model onunlabeled data predominantly with normal cosmesis, we adopt an unsupervisedanomaly detection perspective to automatically score the cosmesis. Real-worlddata experiments demonstrate the effectiveness of our method, providingvisually appealing representations and quantifiable scores for cosmesisevaluation. Compared to commonly used rule-based programs, our fully automatedapproach eliminates the need for manual annotations and offers objectiveevaluation. Moreover, our anomaly detection model exhibits state-of-the-artperformance, surpassing existing models in accuracy. Going beyond the scope ofbreast cosmesis, our research represents a significant advancement inunsupervised anomaly detection within the medical domain, thereby paving theway for future investigations.</description><author>Sangjoon Park, Yong Bae Kim, Jee Suk Chang, Seo Hee Choi, Hyungjin Chung, Ik Jae Lee, Hwa Kyung Byun</author><pubDate>Wed, 28 Feb 2024 14:33:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18362v1</guid></item><item><title>Similarity-based analogical proportions</title><link>http://arxiv.org/abs/2402.18360v1</link><description>The author has recently introduced abstract algebraic frameworks ofanalogical proportions and similarity within the general setting of universalalgebra. The purpose of this paper is to build a bridge from similarity toanalogical proportions by formulating the latter in terms of the former. Thebenefit of this similarity-based approach is that the connection betweenproportions and similarity is built into the framework and therefore evidentwhich is appealing since proportions and similarity are both at the center ofanalogy; moreover, future results on similarity can directly be applied toanalogical proportions.</description><author>Christian Antić</author><pubDate>Wed, 28 Feb 2024 14:31:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18360v1</guid></item><item><title>Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel</title><link>http://arxiv.org/abs/2205.07384v8</link><description>It is challenging to guide neural network (NN) learning with prior knowledge.In contrast, many known properties, such as spatial smoothness or seasonality,are straightforward to model by choosing an appropriate kernel in a Gaussianprocess (GP). Many deep learning applications could be enhanced by modelingsuch known properties. For example, convolutional neural networks (CNNs) arefrequently used in remote sensing, which is subject to strong seasonal effects.We propose to blend the strengths of deep learning and the clear modelingcapabilities of GPs by using a composite kernel that combines a kernelimplicitly defined by a neural network with a second kernel function chosen tomodel known properties (e.g., seasonality). We implement this idea by combininga deep network and an efficient mapping based on the Nystrom approximation,which we call Implicit Composite Kernel (ICK). We then adopt asample-then-optimize approach to approximate the full GP posteriordistribution. We demonstrate that ICK has superior performance and flexibilityon both synthetic and real-world data sets. We believe that ICK framework canbe used to include prior information into neural networks in many applications.</description><author>Ziyang Jiang, Tongshu Zheng, Yiling Liu, David Carlson</author><pubDate>Wed, 28 Feb 2024 14:30:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.07384v8</guid></item><item><title>Controlling Vision-Language Models for Multi-Task Image Restoration</title><link>http://arxiv.org/abs/2310.01018v2</link><description>Vision-language models such as CLIP have shown great impact on diversedownstream tasks for zero-shot or label-free predictions. However, when itcomes to low-level vision such as image restoration their performancedeteriorates dramatically due to corrupted inputs. In this paper, we present adegradation-aware vision-language model (DA-CLIP) to better transfer pretrainedvision-language models to low-level vision tasks as a multi-task framework forimage restoration. More specifically, DA-CLIP trains an additional controllerthat adapts the fixed CLIP image encoder to predict high-quality featureembeddings. By integrating the embedding into an image restoration network viacross-attention, we are able to pilot the model to learn a high-fidelity imagereconstruction. The controller itself will also output a degradation featurethat matches the real corruptions of the input, yielding a natural classifierfor different degradation types. In addition, we construct a mixed degradationdataset with synthetic captions for DA-CLIP training. Our approach advancesstate-of-the-art performance on both \emph{degradation-specific} and\emph{unified} image restoration tasks, showing a promising direction ofprompting image restoration with large-scale pretrained vision-language models.Our code is available at https://github.com/Algolzw/daclip-uir.</description><author>Ziwei Luo, Fredrik K. Gustafsson, Zheng Zhao, Jens Sjölund, Thomas B. Schön</author><pubDate>Wed, 28 Feb 2024 14:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01018v2</guid></item><item><title>Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education</title><link>http://arxiv.org/abs/2402.15027v2</link><description>This study investigates the acceptability of different artificialintelligence (AI) applications in education from a multi-stakeholderperspective, including students, teachers, and parents. Acknowledging thetransformative potential of AI in education, it addresses concerns related todata privacy, AI agency, transparency, explainability and the ethicaldeployment of AI. Through a vignette methodology, participants were presentedwith four scenarios where AI's agency, transparency, explainability, andprivacy were manipulated. After each scenario, participants completed a surveythat captured their perceptions of AI's global utility, individual usefulness,justice, confidence, risk, and intention to use each scenario's AI ifavailable. The data collection comprising a final sample of 1198multi-stakeholder participants was distributed through a partner institutionand social media campaigns and focused on individual responses to four AI usecases. A mediation analysis of the data indicated that acceptance and trust inAI varies significantly across stakeholder groups. We found that the keymediators between high and low levels of AI's agency, transparency, andexplainability, as well as the intention to use the different educational AI,included perceived global utility, justice, and confidence. The studyhighlights that the acceptance of AI in education is a nuanced and multifacetedissue that requires careful consideration of specific AI applications and theircharacteristics, in addition to the diverse stakeholders' perceptions.</description><author>A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger</author><pubDate>Wed, 28 Feb 2024 14:21:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15027v2</guid></item></channel></rss>