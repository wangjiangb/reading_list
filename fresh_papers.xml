<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 07 Mar 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Backtracing: Retrieving the Cause of the Query</title><link>http://arxiv.org/abs/2403.03956v1</link><description>Many online content portals allow users to ask questions to supplement theirunderstanding (e.g., of lectures). While information retrieval (IR) systems mayprovide answers for such user queries, they do not directly assist contentcreators -- such as lecturers who want to improve their content -- identifysegments that _caused_ a user to ask those questions. We introduce the task ofbacktracing, in which systems retrieve the text segment that most likely causeda user query. We formalize three real-world domains for which backtracing isimportant in improving content delivery and communication: understanding thecause of (a) student confusion in the Lecture domain, (b) reader curiosity inthe News Article domain, and (c) user emotion in the Conversation domain. Weevaluate the zero-shot performance of popular information retrieval methods andlanguage modeling methods, including bi-encoder, re-ranking andlikelihood-based methods and ChatGPT. While traditional IR systems retrievesemantically relevant information (e.g., details on "projection matrices" for aquery "does projecting multiple times still lead to the same point?"), theyoften miss the causally relevant context (e.g., the lecturer states "projectingtwice gets me the same answer as one projection"). Our results show that thereis room for improvement on backtracing and it requires new retrievalapproaches. We hope our benchmark serves to improve future retrieval systemsfor backtracing, spawning systems that refine content generation and identifylinguistic triggers influencing user queries. Our code and data areopen-sourced: https://github.com/rosewang2008/backtracing.</description><author>Rose E. Wang, Pawan Wirawarn, Omar Khattab, Noah Goodman, Dorottya Demszky</author><pubDate>Wed, 06 Mar 2024 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03956v1</guid></item><item><title>3D Diffusion Policy</title><link>http://arxiv.org/abs/2403.03954v1</link><description>Imitation learning provides an efficient way to teach robots dexterousskills; however, learning complex skills robustly and generalizablely usuallyconsumes large amounts of human demonstrations. To tackle this challengingproblem, we present 3D Diffusion Policy (DP3), a novel visual imitationlearning approach that incorporates the power of 3D visual representations intodiffusion policies, a class of conditional action generative models. The coredesign of DP3 is the utilization of a compact 3D visual representation,extracted from sparse point clouds with an efficient point encoder. In ourexperiments involving 72 simulation tasks, DP3 successfully handles most taskswith just 10 demonstrations and surpasses baselines with a 55.3% relativeimprovement. In 4 real robot tasks, DP3 demonstrates precise control with ahigh success rate of 85%, given only 40 demonstrations of each task, and showsexcellent generalization abilities in diverse aspects, including space,viewpoint, appearance, and instance. Interestingly, in real robot experiments,DP3 rarely violates safety requirements, in contrast to baseline methods whichfrequently do, necessitating human intervention. Our extensive evaluationhighlights the critical importance of 3D representations in real-world robotlearning. Videos, code, and data are available onhttps://3d-diffusion-policy.github.io .</description><author>Yanjie Ze, Gu Zhang, Kangning Zhang, Chenyuan Hu, Muhan Wang, Huazhe Xu</author><pubDate>Wed, 06 Mar 2024 18:58:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03954v1</guid></item><item><title>Stop Regressing: Training Value Functions via Classification for Scalable Deep RL</title><link>http://arxiv.org/abs/2403.03950v1</link><description>Value functions are a central component of deep reinforcement learning (RL).These functions, parameterized by neural networks, are trained using a meansquared error regression objective to match bootstrapped target values.However, scaling value-based RL methods that use regression to large networks,such as high-capacity Transformers, has proven challenging. This difficulty isin stark contrast to supervised learning: by leveraging a cross-entropyclassification loss, supervised methods have scaled reliably to massivenetworks. Observing this discrepancy, in this paper, we investigate whether thescalability of deep RL can also be improved simply by using classification inplace of regression for training value functions. We demonstrate that valuefunctions trained with categorical cross-entropy significantly improvesperformance and scalability in a variety of domains. These include: single-taskRL on Atari 2600 games with SoftMoEs, multi-task RL on Atari with large-scaleResNets, robotic manipulation with Q-transformers, playing Chess withoutsearch, and a language-agent Wordle task with high-capacity Transformers,achieving state-of-the-art results on these domains. Through careful analysis,we show that the benefits of categorical cross-entropy primarily stem from itsability to mitigate issues inherent to value-based RL, such as noisy targetsand non-stationarity. Overall, we argue that a simple shift to training valuefunctions with categorical cross-entropy can yield substantial improvements inthe scalability of deep RL at little-to-no cost.</description><author>Jesse Farebrother, Jordi Orbay, Quan Vuong, Adrien Ali Taïga, Yevgen Chebotar, Ted Xiao, Alex Irpan, Sergey Levine, Pablo Samuel Castro, Aleksandra Faust, Aviral Kumar, Rishabh Agarwal</author><pubDate>Wed, 06 Mar 2024 18:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03950v1</guid></item><item><title>Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach for Robust Manipulation</title><link>http://arxiv.org/abs/2403.03949v1</link><description>Imitation learning methods need significant human supervision to learnpolicies robust to changes in object poses, physical disturbances, and visualdistractors. Reinforcement learning, on the other hand, can explore theenvironment autonomously to learn robust behaviors but may require impracticalamounts of unsafe real-world data collection. To learn performant, robustpolicies without the burden of unsafe real-world data collection or extensivehuman supervision, we propose RialTo, a system for robustifying real-worldimitation learning policies via reinforcement learning in "digital twin"simulation environments constructed on the fly from small amounts of real-worlddata. To enable this real-to-sim-to-real pipeline, RialTo proposes aneasy-to-use interface for quickly scanning and constructing digital twins ofreal-world environments. We also introduce a novel "inverse distillation"procedure for bringing real-world demonstrations into simulated environmentsfor efficient fine-tuning, with minimal human intervention and engineeringrequired. We evaluate RialTo across a variety of robotic manipulation problemsin the real world, such as robustly stacking dishes on a rack, placing books ona shelf, and six other tasks. RialTo increases (over 67%) in policy robustnesswithout requiring extensive human data collection. Project website and videosat https://real-to-sim-to-real.github.io/RialTo/</description><author>Marcel Torne, Anthony Simeonov, Zechu Li, April Chan, Tao Chen, Abhishek Gupta, Pulkit Agrawal</author><pubDate>Wed, 06 Mar 2024 18:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03949v1</guid></item><item><title>SPEAR:Exact Gradient Inversion of Batches in Federated Learning</title><link>http://arxiv.org/abs/2403.03945v1</link><description>Federated learning is a popular framework for collaborative machine learningwhere multiple clients only share gradient updates on their local data with theserver and not the actual data. Unfortunately, it was recently shown thatgradient inversion attacks can reconstruct this data from these sharedgradients. Existing attacks enable exact reconstruction only for a batch sizeof $b=1$ in the important honest-but-curious setting, with larger batchespermitting only approximate reconstruction. In this work, we propose \emph{thefirst algorithm reconstructing whole batches with $b &gt;1$ exactly}. Thisapproach combines mathematical insights into the explicit low-rank structure ofgradients with a sampling-based algorithm. Crucially, we leverage ReLU-inducedgradient sparsity to precisely filter out large numbers of incorrect samples,making a final reconstruction step tractable. We provide an efficient GPUimplementation for fully connected networks and show that it recovers batchesof $b \lesssim 25$ elements exactly while being tractable for large networkwidths and depths.</description><author>Dimitar I. Dimitrov, Maximilian Baader, Mark Niklas Müller, Martin Vechev</author><pubDate>Wed, 06 Mar 2024 18:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03945v1</guid></item><item><title>Projected Task-Specific Layers for Multi-Task Reinforcement Learning</title><link>http://arxiv.org/abs/2309.08776v2</link><description>Multi-task reinforcement learning could enable robots to scale across a widevariety of manipulation tasks in homes and workplaces. However, generalizingfrom one task to another and mitigating negative task interference stillremains a challenge. Addressing this challenge by successfully sharinginformation across tasks will depend on how well the structure underlying thetasks is captured. In this work, we introduce our new architecture, ProjectedTask-Specific Layers (PTSL), that leverages a common policy with densetask-specific corrections through task-specific layers to better express sharedand variable task information. We then show that our model outperforms thestate of the art on the MT10 and MT50 benchmarks of Meta-World consisting of 10and 50 goal-conditioned tasks for a Sawyer arm.</description><author>Josselin Somerville Roberts, Julia Di</author><pubDate>Wed, 06 Mar 2024 18:51:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08776v2</guid></item><item><title>The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models</title><link>http://arxiv.org/abs/2403.03942v1</link><description>Prior work has found that pretrained language models (LMs) fine-tuned withdifferent random seeds can achieve similar in-domain performance but generalizedifferently on tests of syntactic generalization. In this work, we show that,even within a single model, we can find multiple subnetworks that performsimilarly in-domain, but generalize vastly differently. To better understandthese phenomena, we investigate if they can be understood in terms of"competing subnetworks": the model initially represents a variety of distinctalgorithms, corresponding to different subnetworks, and generalization occurswhen it ultimately converges to one. This explanation has been used to accountfor generalization in simple algorithmic tasks. Instead of finding competingsubnetworks, we find that all subnetworks -- whether they generalize or not --share a set of attention heads, which we refer to as the heuristic core.Further analysis suggests that these attention heads emerge early in trainingand compute shallow, non-generalizing features. The model learns to generalizeby incorporating additional attention heads, which depend on the outputs of the"heuristic" heads to compute higher-level features. Overall, our results offera more detailed picture of the mechanisms for syntactic generalization inpretrained LMs.</description><author>Adithya Bhaskar, Dan Friedman, Danqi Chen</author><pubDate>Wed, 06 Mar 2024 18:50:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03942v1</guid></item><item><title>Interpretable Stereotype Identification through Reasoning</title><link>http://arxiv.org/abs/2308.00071v2</link><description>Given that language models are trained on vast datasets that may containinherent biases, there is a potential danger of inadvertently perpetuatingsystemic discrimination. Consequently, it becomes essential to examine andaddress biases in language models, integrating fairness into their developmentto ensure these models are equitable and free from bias. In this work, wedemonstrate the importance of reasoning in zero-shot stereotype identificationbased on Vicuna-13B-v1.3. While we do observe improved accuracy by scaling from13B to 33B, we show that the performance gain from reasoning significantlyexceeds the gain from scaling up. Our findings suggest that reasoning could bea key factor that enables LLMs to trescend the scaling law on out-of-domaintasks such as stereotype identification. Additionally, through a qualitativeanalysis of select reasoning traces, we highlight how reasoning enhances notjust accuracy but also the interpretability of the decision.</description><author>Jacob-Junqi Tian, Omkar Dige, David Emerson, Faiza Khan Khattak</author><pubDate>Wed, 06 Mar 2024 18:49:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00071v2</guid></item><item><title>GUIDE: Guidance-based Incremental Learning with Diffusion Models</title><link>http://arxiv.org/abs/2403.03938v1</link><description>We introduce GUIDE, a novel continual learning approach that directsdiffusion models to rehearse samples at risk of being forgotten. Existinggenerative strategies combat catastrophic forgetting by randomly samplingrehearsal examples from a generative model. Such an approach contradictsbuffer-based approaches where sampling strategy plays an important role. Wepropose to bridge this gap by integrating diffusion models with classifierguidance techniques to produce rehearsal examples specifically targetinginformation forgotten by a continuously trained model. This approach enablesthe generation of samples from preceding task distributions, which are morelikely to be misclassified in the context of recently encountered classes. Ourexperimental results show that GUIDE significantly reduces catastrophicforgetting, outperforming conventional random sampling approaches andsurpassing recent state-of-the-art methods in continual learning withgenerative replay.</description><author>Bartosz Cywiński, Kamil Deja, Tomasz Trzciński, Bartłomiej Twardowski, Łukasz Kuciński</author><pubDate>Wed, 06 Mar 2024 18:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03938v1</guid></item><item><title>Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Rival Human Crowd Accuracy</title><link>http://arxiv.org/abs/2402.19379v2</link><description>Human forecasting accuracy in practice relies on the 'wisdom of the crowd'effect, in which predictions about future events are significantly improved byaggregating across a crowd of individual forecasters. Past work on theforecasting ability of large language models (LLMs) suggests that frontierLLMs, as individual forecasters, underperform compared to the gold standard ofa human crowd forecasting tournament aggregate. In Study 1, we expand thisresearch by using an LLM ensemble approach consisting of a crowd of twelveLLMs. We compare the aggregated LLM predictions on 31 binary questions to thatof a crowd of 925 human forecasters from a three-month forecasting tournament.Our preregistered main analysis shows that the LLM crowd outperforms a simpleno-information benchmark and is not statistically different from the humancrowd. In exploratory analyses, we find that these two approaches areequivalent with respect to medium-effect-size equivalence bounds. We alsoobserve an acquiescence effect, with mean model predictions being significantlyabove 50%, despite an almost even split of positive and negative resolutions.Moreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2)can be improved by drawing on human cognitive output. We find that both models'forecasting accuracy benefits from exposure to the median human prediction asinformation, improving accuracy by between 17% and 28%: though this leads toless accurate predictions than simply averaging human and machine forecasts.Our results suggest that LLMs can achieve forecasting accuracy rivaling that ofhuman crowd forecasting tournaments: via the simple, practically applicablemethod of forecast aggregation. This replicates the 'wisdom of the crowd'effect for LLMs, and opens up their use for a variety of applicationsthroughout society.</description><author>Philipp Schoenegger, Indre Tuminauskaite, Peter S. Park, Philip E. Tetlock</author><pubDate>Wed, 06 Mar 2024 18:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19379v2</guid></item><item><title>Extreme Precipitation Nowcasting using Transformer-based Generative Models</title><link>http://arxiv.org/abs/2403.03929v1</link><description>This paper presents an innovative approach to extreme precipitationnowcasting by employing Transformer-based generative models, namelyNowcastingGPT with Extreme Value Loss (EVL) regularization. Leveraging acomprehensive dataset from the Royal Netherlands Meteorological Institute(KNMI), our study focuses on predicting short-term precipitation with highaccuracy. We introduce a novel method for computing EVL without assuming fixedextreme representations, addressing the limitations of current models incapturing extreme weather events. We present both qualitative and quantitativeanalyses, demonstrating the superior performance of the proposedNowcastingGPT-EVL in generating accurate precipitation forecasts, especiallywhen dealing with extreme precipitation events. The code is available at\url{https://github.com/Cmeo97/NowcastingGPT}.</description><author>Cristian Meo, Ankush Roy, Mircea Lică, Junzhe Yin, Zeineb Bou Che, Yanbo Wang, Ruben Imhoff, Remko Uijlenhoet, Justin Dauwels</author><pubDate>Wed, 06 Mar 2024 18:39:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03929v1</guid></item><item><title>Consciousness qua Mortal Computation</title><link>http://arxiv.org/abs/2403.03925v1</link><description>Computational functionalism posits that consciousness is a computation. Herewe show, perhaps surprisingly, that it cannot be a Turing computation. Rather,computational functionalism implies that consciousness is a novel type ofcomputation that has recently been proposed by Geoffrey Hinton, called mortalcomputation.</description><author>Johannes Kleiner</author><pubDate>Wed, 06 Mar 2024 18:37:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03925v1</guid></item><item><title>Did Translation Models Get More Robust Without Anyone Even Noticing?</title><link>http://arxiv.org/abs/2403.03923v1</link><description>Neural machine translation (MT) models achieve strong results across avariety of settings, but it is widely believed that they are highly sensitiveto "noisy" inputs, such as spelling errors, abbreviations, and other formattingissues. In this paper, we revisit this insight in light of recent multilingualMT models and large language models (LLMs) applied to machine translation.Somewhat surprisingly, we show through controlled experiments that these modelsare far more robust to many kinds of noise than previous models, even when theyperform similarly on clean data. This is notable because, even though LLMs havemore parameters and more complex training processes than past models, none ofthe open ones we consider use any techniques specifically designed to encouragerobustness. Next, we show that similar trends hold for social media translationexperiments -- LLMs are more robust to social media text. We include ananalysis of the circumstances in which source correction techniques can be usedto mitigate the effects of noise. Altogether, we show that robustness to manytypes of noise has increased.</description><author>Ben Peters, André F. T. Martins</author><pubDate>Wed, 06 Mar 2024 18:33:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03923v1</guid></item><item><title>Enhancing Instructional Quality: Leveraging Computer-Assisted Textual Analysis to Generate In-Depth Insights from Educational Artifacts</title><link>http://arxiv.org/abs/2403.03920v1</link><description>This paper explores the transformative potential of computer-assisted textualanalysis in enhancing instructional quality through in-depth insights fromeducational artifacts. We integrate Richard Elmore's Instructional CoreFramework to examine how artificial intelligence (AI) and machine learning (ML)methods, particularly natural language processing (NLP), can analyzeeducational content, teacher discourse, and student responses to fosterinstructional improvement. Through a comprehensive review and case studieswithin the Instructional Core Framework, we identify key areas where AI/MLintegration offers significant advantages, including teacher coaching, studentsupport, and content development. We unveil patterns that indicate AI/ML notonly streamlines administrative tasks but also introduces novel pathways forpersonalized learning, providing actionable feedback for educators andcontributing to a richer understanding of instructional dynamics. This paperemphasizes the importance of aligning AI/ML technologies with pedagogical goalsto realize their full potential in educational settings, advocating for abalanced approach that considers ethical considerations, data quality, and theintegration of human expertise.</description><author>Zewei Tian, Min Sun, Alex Liu, Shawon Sarkar, Jing Liu</author><pubDate>Wed, 06 Mar 2024 18:29:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03920v1</guid></item><item><title>High-Fidelity Image Compression with Score-based Generative Models</title><link>http://arxiv.org/abs/2305.18231v2</link><description>Despite the tremendous success of diffusion generative models intext-to-image generation, replicating this success in the domain of imagecompression has proven difficult. In this paper, we demonstrate that diffusioncan significantly improve perceptual quality at a given bit-rate, outperformingstate-of-the-art approaches PO-ELIC and HiFiC as measured by FID score. This isachieved using a simple but theoretically motivated two-stage approachcombining an autoencoder targeting MSE followed by a further score-baseddecoder. However, as we will show, implementation details matter and theoptimal design decisions can differ greatly from typical text-to-image models.</description><author>Emiel Hoogeboom, Eirikur Agustsson, Fabian Mentzer, Luca Versari, George Toderici, Lucas Theis</author><pubDate>Wed, 06 Mar 2024 18:27:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18231v2</guid></item><item><title>FIMP: Foundation Model-Informed Message Passing for Graph Neural Networks</title><link>http://arxiv.org/abs/2210.09475v4</link><description>Foundation models have revolutionized the landscape of Deep Learning (DL),serving as a versatile platform which can be adapted to a wide range ofdownstream tasks. Despite their adaptability, applications of foundation modelsto downstream graph-based tasks have been limited, and there remains noconvenient way to leverage large-scale non-graph pretrained models ingraph-structured settings. In this work, we present a new framework which weterm Foundation-Informed Message Passing (FIMP) to bridge the fields offoundational models and GNNs through a simple concept: constructingmessage-passing operators from pretrained foundation model weights. We showthat this approach results in improved performance for graph-based tasks in anumber of data domains, allowing graph neural networks to leverage theknowledge of foundation models.</description><author>Syed Asad Rizvi, Nhi Nguyen, Haoran Lyu, Benjamin Christensen, Josue Ortega Caro, Antonio H. O. Fonseca, Emanuele Zappala, Maryam Bagherian, Christopher Averill, Chadi G. Abdallah, Amin Karbasi, Rex Ying, Maria Brbic, Rahul Madhav Dhodapkar, David van Dijk</author><pubDate>Wed, 06 Mar 2024 18:25:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.09475v4</guid></item><item><title>Large-scale Training of Foundation Models for Wearable Biosignals</title><link>http://arxiv.org/abs/2312.05409v2</link><description>Tracking biosignals is crucial for monitoring wellness and preempting thedevelopment of severe medical conditions. Today, wearable devices canconveniently record various biosignals, creating the opportunity to monitorhealth status without disruption to one's daily routine. Despite widespread useof wearable devices and existing digital biomarkers, the absence of curateddata with annotated medical labels hinders the development of new biomarkers tomeasure common health conditions. In fact, medical datasets are usually smallin comparison to other domains, which is an obstacle for developing neuralnetwork models for biosignals. To address this challenge, we have employedself-supervised learning using the unlabeled sensor data collected underinformed consent from the large longitudinal Apple Heart and Movement Study(AHMS) to train foundation models for two common biosignals:photoplethysmography (PPG) and electrocardiogram (ECG) recorded on Apple Watch.We curated PPG and ECG datasets from AHMS that include data from ~141Kparticipants spanning ~3 years. Our self-supervised learning framework includesparticipant level positive pair selection, stochastic augmentation module and aregularized contrastive loss optimized with momentum training, and generalizeswell to both PPG and ECG modalities. We show that the pre-trained foundationmodels readily encode information regarding participants' demographics andhealth conditions. To the best of our knowledge, this is the first study thatbuilds foundation models using large-scale PPG and ECG data collected viawearable consumer devices $\unicode{x2013}$ prior works have commonly usedsmaller-size datasets collected in clinical and experimental settings. Webelieve PPG and ECG foundation models can enhance future wearable devices byreducing the reliance on labeled data and hold the potential to help the usersimprove their health.</description><author>Salar Abbaspourazad, Oussama Elachqar, Andrew C. Miller, Saba Emrani, Udhyakumar Nallasamy, Ian Shapiro</author><pubDate>Wed, 06 Mar 2024 18:18:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05409v2</guid></item><item><title>Improving Adversarial Attacks on Latent Diffusion Model</title><link>http://arxiv.org/abs/2310.04687v3</link><description>Adversarial attacks on Latent Diffusion Model (LDM), the state-of-the-artimage generative model, have been adopted as effective protection againstmalicious finetuning of LDM on unauthorized images. We show that these attacksadd an extra error to the score function of adversarial examples predicted byLDM. LDM finetuned on these adversarial examples learns to lower the error by abias, from which the model is attacked and predicts the score function withbiases. Based on the dynamics, we propose to improve the adversarial attack on LDM byAttacking with Consistent score-function Errors (ACE). ACE unifies the patternof the extra error added to the predicted score function. This induces thefinetuned LDM to learn the same pattern as a bias in predicting the scorefunction. We then introduce a well-crafted pattern to improve the attack. Ourmethod outperforms state-of-the-art methods in adversarial attacks on LDM.</description><author>Boyang Zheng, Chumeng Liang, Xiaoyu Wu, Yan Liu</author><pubDate>Wed, 06 Mar 2024 18:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04687v3</guid></item><item><title>A Measure for Transparent Comparison of Linguistic Diversity in Multilingual NLP Data Sets</title><link>http://arxiv.org/abs/2403.03909v1</link><description>Typologically diverse benchmarks are increasingly created to track theprogress achieved in multilingual NLP. Linguistic diversity of these data setsis typically measured as the number of languages or language families includedin the sample, but such measures do not consider structural properties of theincluded languages. In this paper, we propose assessing linguistic diversity ofa data set against a reference language sample as a means of maximisinglinguistic diversity in the long run. We represent languages as sets offeatures and apply a version of the Jaccard index suitable for comparing setsof measures. In addition to the features extracted from typological data bases,we propose an automatic text-based measure, which can be used as a means ofovercoming the well-known problem of data sparsity in manually collectedfeatures. Our diversity score is interpretable in terms of linguistic featuresand can identify the types of languages that are not represented in a data set.Using our method, we analyse a range of popular multilingual data sets (UD,Bible100, mBERT, XTREME, XGLUE, XNLI, XCOPA, TyDiQA, XQuAD). In addition toranking these data sets, we find, for example, that (poly)synthetic languagesare missing in almost all of them.</description><author>Tanja Samardzic, Ximena Gutierrez, Christian Bentz, Steven Moran, Olga Pelloni</author><pubDate>Wed, 06 Mar 2024 18:14:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03909v1</guid></item><item><title>Black-Box $k$-to-$1$-PCA Reductions: Theory and Applications</title><link>http://arxiv.org/abs/2403.03905v1</link><description>The $k$-principal component analysis ($k$-PCA) problem is a fundamentalalgorithmic primitive that is widely-used in data analysis and dimensionalityreduction applications. In statistical settings, the goal of $k$-PCA is toidentify a top eigenspace of the covariance matrix of a distribution, which weonly have implicit access to via samples. Motivated by these implicit settings,we analyze black-box deflation methods as a framework for designing $k$-PCAalgorithms, where we model access to the unknown target matrix via a black-box$1$-PCA oracle which returns an approximate top eigenvector, under two popularnotions of approximation. Despite being arguably the most naturalreduction-based approach to $k$-PCA algorithm design, such black-box methods,which recursively call a $1$-PCA oracle $k$ times, were previouslypoorly-understood. Our main contribution is significantly sharper bounds on the approximationparameter degradation of deflation methods for $k$-PCA. For a quadratic formnotion of approximation we term ePCA (energy PCA), we show deflation methodssuffer no parameter loss. For an alternative well-studied approximation notionwe term cPCA (correlation PCA), we tightly characterize the parameter regimeswhere deflation methods are feasible. Moreover, we show that in all feasibleregimes, $k$-cPCA deflation algorithms suffer no asymptotic parameter loss forany constant $k$. We apply our framework to obtain state-of-the-art $k$-PCAalgorithms robust to dataset contamination, improving prior work both in samplecomplexity and approximation quality.</description><author>Arun Jambulapati, Syamantak Kumar, Jerry Li, Shourya Pandey, Ankit Pensia, Kevin Tian</author><pubDate>Wed, 06 Mar 2024 18:07:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03905v1</guid></item><item><title>DART: Implicit Doppler Tomography for Radar Novel View Synthesis</title><link>http://arxiv.org/abs/2403.03896v1</link><description>Simulation is an invaluable tool for radio-frequency system designers thatenables rapid prototyping of various algorithms for imaging, target detection,classification, and tracking. However, simulating realistic radar scans is achallenging task that requires an accurate model of the scene, radio frequencymaterial properties, and a corresponding radar synthesis function. Rather thanspecifying these models explicitly, we propose DART - Doppler Aided RadarTomography, a Neural Radiance Field-inspired method which uses radar-specificphysics to create a reflectance and transmittance-based rendering pipeline forrange-Doppler images. We then evaluate DART by constructing a custom datacollection platform and collecting a novel radar dataset together with accurateposition and instantaneous velocity measurements from lidar-based localization.In comparison to state-of-the-art baselines, DART synthesizes superior radarrange-Doppler images from novel views across all datasets and additionally canbe used to generate high quality tomographic images.</description><author>Tianshu Huang, John Miller, Akarsh Prabhakara, Tao Jin, Tarana Laroia, Zico Kolter, Anthony Rowe</author><pubDate>Wed, 06 Mar 2024 17:54:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03896v1</guid></item><item><title>IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators</title><link>http://arxiv.org/abs/2403.03894v1</link><description>Code understanding and generation have fast become some of the most popularapplications of language models (LMs). Nonetheless, research on multilingualaspects of Code-LMs (i.e., LMs for code generation) such as cross-lingualtransfer between different programming languages, language-specific dataaugmentation, and post-hoc LM adaptation, alongside exploitation of datasources other than the original textual content, has been much sparser than fortheir natural language counterparts. In particular, most mainstream Code-LMshave been pre-trained on source code files alone. In this work, we investigatethe prospect of leveraging readily available compiler intermediaterepresentations - shared across programming languages - to improve themultilingual capabilities of Code-LMs and facilitate cross-lingual transfer. To this end, we first compile SLTrans, a parallel dataset consisting ofnearly 4M self-contained source code files coupled with respective intermediaterepresentations. Next, starting from various base Code-LMs (ranging in sizefrom 1.1B to 7.3B parameters), we carry out continued causal language modellingtraining on SLTrans, forcing the Code-LMs to (1) learn the IR language and (2)align the IR constructs with respective constructs of various programminglanguages. Our resulting models, dubbed IRCoder, display sizeable andconsistent gains across a wide variety of code generation tasks and metrics,including prompt robustness, multilingual code completion, code understanding,and instruction following.</description><author>Indraneil Paul, Jun Luo, Goran Glavaš, Iryna Gurevych</author><pubDate>Wed, 06 Mar 2024 17:52:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03894v1</guid></item><item><title>From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models</title><link>http://arxiv.org/abs/2403.03893v1</link><description>To date, toxicity mitigation in language models has almost entirely beenfocused on single-language settings. As language models embrace multilingualcapabilities, it's crucial our safety measures keep pace. Recognizing thisresearch gap, our approach expands the scope of conventional toxicitymitigation to address the complexities presented by multiple languages. In theabsence of sufficient annotated datasets across languages, we employ translateddata to evaluate and enhance our mitigation techniques. We also comparefinetuning mitigation approaches against retrieval-augmented techniques underboth static and continual toxicity mitigation scenarios. This allows us toexamine the effects of translation quality and the cross-lingual transfer ontoxicity mitigation. We also explore how model size and data quantity affectthe success of these mitigation efforts. Covering nine languages, our studyrepresents a broad array of linguistic families and levels of resourceavailability, ranging from high to mid-resource languages. Throughcomprehensive experiments, we provide insights into the complexities ofmultilingual toxicity mitigation, offering valuable insights and paving the wayfor future research in this increasingly important field. Code and data areavailable at https://github.com/for-ai/goodtriever.</description><author>Luiza Pozzobon, Patrick Lewis, Sara Hooker, Beyza Ermis</author><pubDate>Wed, 06 Mar 2024 17:51:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03893v1</guid></item><item><title>Joint multi-task learning improves weakly-supervised biomarker prediction in computational pathology</title><link>http://arxiv.org/abs/2403.03891v1</link><description>Deep Learning (DL) can predict biomarkers directly from digitized cancerhistology in a weakly-supervised setting. Recently, the prediction ofcontinuous biomarkers through regression-based DL has seen an increasinginterest. Nonetheless, clinical decision making often requires a categoricaloutcome. Consequently, we developed a weakly-supervised joint multi-taskTransformer architecture which has been trained and evaluated on four publicpatient cohorts for the prediction of two key predictive biomarkers,microsatellite instability (MSI) and homologous recombination deficiency (HRD),trained with auxiliary regression tasks related to the tumor microenvironment.Moreover, we perform a comprehensive benchmark of 16 approaches of taskbalancing for weakly-supervised joint multi-task learning in computationalpathology. Using our novel approach, we improve over the state-of-the-art areaunder the receiver operating characteristic by +7.7% and +4.1%, as well asyielding better clustering of latent embeddings by +8% and +5% for theprediction of MSI and HRD in external cohorts, respectively.</description><author>Omar S. M. El Nahhas, Georg Wölflein, Marta Ligero, Tim Lenz, Marko van Treeck, Firas Khader, Daniel Truhn, Jakob Nikolas Kather</author><pubDate>Wed, 06 Mar 2024 17:51:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03891v1</guid></item><item><title>Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation</title><link>http://arxiv.org/abs/2403.03890v1</link><description>This paper introduces Hierarchical Diffusion Policy (HDP), a hierarchicalagent for multi-task robotic manipulation. HDP factorises a manipulation policyinto a hierarchical structure: a high-level task-planning agent which predictsa distant next-best end-effector pose (NBP), and a low-level goal-conditioneddiffusion policy which generates optimal motion trajectories. The factorisedpolicy representation allows HDP to tackle both long-horizon task planningwhile generating fine-grained low-level actions. To generate context-awaremotion trajectories while satisfying robot kinematics constraints, we present anovel kinematics-aware goal-conditioned control agent, Robot KinematicsDiffuser (RK-Diffuser). Specifically, RK-Diffuser learns to generate both theend-effector pose and joint position trajectories, and distill the accurate butkinematics-unaware end-effector pose diffuser to the kinematics-aware but lessaccurate joint position diffuser via differentiable kinematics. Empirically, weshow that HDP achieves a significantly higher success rate than thestate-of-the-art methods in both simulation and real-world.</description><author>Xiao Ma, Sumit Patidar, Iain Haughton, Stephen James</author><pubDate>Wed, 06 Mar 2024 17:50:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03890v1</guid></item><item><title>Toward Neuromic Computing: Neurons as Autoencoders</title><link>http://arxiv.org/abs/2403.02331v2</link><description>The computational capabilities of dendrites have become increasingly clear.This letter presents the idea that neural backpropagation is using dendriticprocessing to enable individual neurons to perform autoencoding. Using a verysimple connection weight search heuristic and artificial neural network model,the effects of interleaving autoencoding for each neuron in a hidden layer of afeedforward network are explored. This is contrasted to the standard layeredapproach to autoencoding. It is shown that such individualised processing isnot detrimental and can improve network learning.</description><author>Larry Bull</author><pubDate>Wed, 06 Mar 2024 17:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02331v2</guid></item><item><title>FaaF: Facts as a Function for the evaluation of RAG systems</title><link>http://arxiv.org/abs/2403.03888v1</link><description>Factual recall from a reference source is crucial for evaluating theperformance of Retrieval Augmented Generation (RAG) systems, as it directlyprobes into the quality of both retrieval and generation. However, it stillremains a challenge to perform this evaluation reliably and efficiently. Recentwork has focused on fact verification via prompting language model (LM)evaluators, however we demonstrate that these methods are unreliable in thepresence of incomplete or inaccurate information. We introduce Facts as aFunction (FaaF), a new approach to fact verification that utilizes the functioncalling abilities of LMs and a framework for RAG factual recall evaluation.FaaF substantially improves the ability of LMs to identify unsupported facts intext with incomplete information whilst improving efficiency and lowering costby several times, compared to prompt-based approaches.</description><author>Vasileios Katranidis, Gabor Barany</author><pubDate>Wed, 06 Mar 2024 17:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03888v1</guid></item><item><title>AdaCCD: Adaptive Semantic Contrasts Discovery Based Cross Lingual Adaptation for Code Clone Detection</title><link>http://arxiv.org/abs/2311.07277v2</link><description>Code Clone Detection, which aims to retrieve functionally similar programsfrom large code bases, has been attracting increasing attention. Modernsoftware often involves a diverse range of programming languages. However,current code clone detection methods are generally limited to only a fewpopular programming languages due to insufficient annotated data as well astheir own model design constraints. To address these issues, we present AdaCCD,a novel cross-lingual adaptation method that can detect cloned codes in a newlanguage without annotations in that language. AdaCCD leverageslanguage-agnostic code representations from pre-trained programming languagemodels and propose an Adaptively Refined Contrastive Learning framework totransfer knowledge from resource-rich languages to resource-poor languages. Weevaluate the cross-lingual adaptation results of AdaCCD by constructing amultilingual code clone detection benchmark consisting of 5 programminglanguages. AdaCCD achieves significant improvements over other baselines, andachieve comparable performance to supervised fine-tuning.</description><author>Yangkai Du, Tengfei Ma, Lingfei Wu, Xuhong Zhang, Shouling Ji</author><pubDate>Wed, 06 Mar 2024 17:46:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07277v2</guid></item><item><title>SaulLM-7B: A pioneering Large Language Model for Law</title><link>http://arxiv.org/abs/2403.03883v1</link><description>In this paper, we introduce SaulLM-7B, a large language model (LLM) tailoredfor the legal domain. With 7 billion parameters, SaulLM-7B is the first LLMdesigned explicitly for legal text comprehension and generation. Leveraging theMistral 7B architecture as its foundation, SaulLM-7B is trained on an Englishlegal corpus of over 30 billion tokens. SaulLM-7B exhibits state-of-the-artproficiency in understanding and processing legal documents. Additionally, wepresent a novel instructional fine-tuning method that leverages legal datasetsto further enhance SaulLM-7B's performance in legal tasks. SaulLM-7B isreleased under the CC-BY-SA-4.0 License.</description><author>Pierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic Culver, Rui Melo, Caio Corro, Andre F. T. Martins, Fabrizio Esposito, Vera Lúcia Raposo, Sofia Morgado, Michael Desa</author><pubDate>Wed, 06 Mar 2024 17:42:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03883v1</guid></item><item><title>Self and Mixed Supervision to Improve Training Labels for Multi-Class Medical Image Segmentation</title><link>http://arxiv.org/abs/2403.03882v1</link><description>Accurate training labels are a key component for multi-class medical imagesegmentation. Their annotation is costly and time-consuming because it requiresdomain expertise. This work aims to develop a dual-branch network andautomatically improve training labels for multi-class image segmentation.Transfer learning is used to train the network and improve inaccurate weaklabels sequentially. The dual-branch network is first trained by weak labelsalone to initialize model parameters. After the network is stabilized, theshared encoder is frozen, and strong and weak decoders are fine-tuned by strongand weak labels together. The accuracy of weak labels is iteratively improvedin the fine-tuning process. The proposed method was applied to a three-classsegmentation of muscle, subcutaneous and visceral adipose tissue on abdominalCT scans. Validation results on 11 patients showed that the accuracy oftraining labels was statistically significantly improved, with the Dicesimilarity coefficient of muscle, subcutaneous and visceral adipose tissueincreased from 74.2% to 91.5%, 91.2% to 95.6%, and 77.6% to 88.5%, respectively(p&lt;0.05). In comparison with our earlier method, the label accuracy was alsosignificantly improved (p&lt;0.05). These experimental results suggested that thecombination of the dual-branch network and transfer learning is an efficientmeans to improve training labels for multi-class segmentation.</description><author>Jianfei Liu, Christopher Parnell, Ronald M. Summers</author><pubDate>Wed, 06 Mar 2024 17:42:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03882v1</guid></item><item><title>Latent Dataset Distillation with Diffusion Models</title><link>http://arxiv.org/abs/2403.03881v1</link><description>The efficacy of machine learning has traditionally relied on the availabilityof increasingly larger datasets. However, large datasets pose storagechallenges and contain non-influential samples, which could be ignored duringtraining without impacting the final accuracy of the model. In response tothese limitations, the concept of distilling the information on a dataset intoa condensed set of (synthetic) samples, namely a distilled dataset, emerged.One crucial aspect is the selected architecture (usually ConvNet) for linkingthe original and synthetic datasets. However, the final accuracy is lower ifthe employed model architecture differs from the model used duringdistillation. Another challenge is the generation of high-resolution images,e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillationwith Diffusion Models (LD3M) that combine diffusion in latent space withdataset distillation to tackle both challenges. LD3M incorporates a noveldiffusion process tailored for dataset distillation, which improves thegradient norms for learning synthetic images. By adjusting the number ofdiffusion steps, LD3M also offers a straightforward way of controlling thetrade-off between speed and accuracy. We evaluate our approach in severalImageNet subsets and for high-resolution images (128x128 and 256x256). As aresult, LD3M consistently outperforms state-of-the-art distillation techniquesby up to 4.8 p.p. and 4.2 p.p. for 1 and 10 images per class, respectively.</description><author>Brian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel</author><pubDate>Wed, 06 Mar 2024 17:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03881v1</guid></item><item><title>Graph neural network outputs are almost surely asymptotically constant</title><link>http://arxiv.org/abs/2403.03880v1</link><description>Graph neural networks (GNNs) are the predominant architectures for a varietyof learning tasks on graphs. We present a new angle on the expressive power ofGNNs by studying how the predictions of a GNN probabilistic classifier evolveas we apply it on larger graphs drawn from some random graph model. We showthat the output converges to a constant function, which upper-bounds what theseclassifiers can express uniformly. This convergence phenomenon applies to avery wide class of GNNs, including state of the art models, with aggregatesincluding mean and the attention-based mechanism of graph transformers. Ourresults apply to a broad class of random graph models, including the (sparse)Erd\H{o}s-R\'enyi model and the stochastic block model. We empirically validatethese findings, observing that the convergence phenomenon already manifestsitself on graphs of relatively modest size.</description><author>Sam Adam-Day, Michael Benedikt, İsmail İlkan Ceylan, Ben Finkelshtein</author><pubDate>Wed, 06 Mar 2024 17:40:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03880v1</guid></item><item><title>Redefining cystoscopy with ai: bladder cancer diagnosis using an efficient hybrid cnn-transformer model</title><link>http://arxiv.org/abs/2403.03879v1</link><description>Bladder cancer ranks within the top 10 most diagnosed cancers worldwide andis among the most expensive cancers to treat due to the high recurrence rateswhich require lifetime follow-ups. The primary tool for diagnosis iscystoscopy, which heavily relies on doctors' expertise and interpretation.Therefore, annually, numerous cases are either undiagnosed or misdiagnosed andtreated as urinary infections. To address this, we suggest a deep learningapproach for bladder cancer detection and segmentation which combines CNNs witha lightweight positional-encoding-free transformer and dual attention gatesthat fuse self and spatial attention for feature enhancement. The architecturesuggested in this paper is efficient making it suitable for medical scenariosthat require real time inference. Experiments have proven that this modeladdresses the critical need for a balance between computational efficiency anddiagnostic accuracy in cystoscopic imaging as despite its small size it rivalslarge models in performance.</description><author>Meryem Amaouche, Ouassim Karrakchou, Mounir Ghogho, Anouar El Ghazzaly, Mohamed Alami, Ahmed Ameur</author><pubDate>Wed, 06 Mar 2024 17:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03879v1</guid></item><item><title>Impoverished Language Technology: The Lack of (Social) Class in NLP</title><link>http://arxiv.org/abs/2403.03874v1</link><description>Since Labov's (1964) foundational work on the social stratification oflanguage, linguistics has dedicated concerted efforts towards understanding therelationships between socio-demographic factors and language production andperception. Despite the large body of evidence identifying significantrelationships between socio-demographic factors and language production,relatively few of these factors have been investigated in the context of NLPtechnology. While age and gender are well covered, Labov's initial target,socio-economic class, is largely absent. We survey the existing NaturalLanguage Processing (NLP) literature and find that only 20 papers even mentionsocio-economic status. However, the majority of those papers do not engage withclass beyond collecting information of annotator-demographics. Given thisresearch lacuna, we provide a definition of class that can be operationalisedby NLP researchers, and argue for including socio-economic class in futurelanguage technologies.</description><author>Amanda Cercas Curry, Zeerak Talat, Dirk Hovy</author><pubDate>Wed, 06 Mar 2024 17:35:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03874v1</guid></item><item><title>Decoupled Vertical Federated Learning for Practical Training on Vertically Partitioned Data</title><link>http://arxiv.org/abs/2403.03871v1</link><description>Vertical Federated Learning (VFL) is an emergent distributed machine learningparadigm wherein owners of disjoint features of a common set of entitiescollaborate to learn a global model without sharing data. In VFL, a host clientowns data labels for each entity and learns a final representation based onintermediate local representations from all guest clients. Therefore, the hostis a single point of failure and label feedback can be used by malicious guestclients to infer private features. Requiring all participants to remain activeand trustworthy throughout the entire training process is generally impracticaland altogether infeasible outside of controlled environments. We proposeDecoupled VFL (DVFL), a blockwise learning approach to VFL. By training eachmodel on its own objective, DVFL allows for decentralized aggregation andisolation between feature learning and label supervision. With theseproperties, DVFL is fault tolerant and secure. We implement DVFL to train splitneural networks and show that model performance is comparable to VFL on avariety of classification datasets.</description><author>Avi Amalanshu, Yash Sirvi, David I. Inouye</author><pubDate>Wed, 06 Mar 2024 17:23:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03871v1</guid></item><item><title>Learning to Decode Collaboratively with Multiple Language Models</title><link>http://arxiv.org/abs/2403.03870v1</link><description>We propose a method to teach multiple large language models (LLM) tocollaborate by interleaving their generations at the token level. We model thedecision of which LLM generates the next token as a latent variable. Byoptimizing the marginal likelihood of a training set under our latent variablemodel, the base LLM automatically learns when to generate itself and when tocall on one of the ``assistant'' language models to generate, all withoutdirect supervision. Token-level collaboration during decoding allows for afusion of each model's expertise in a manner tailored to the specific task athand. Our collaborative decoding is especially useful in cross-domain settingswhere a generalist base LLM learns to invoke domain expert models. Oninstruction-following, domain-specific QA, and reasoning tasks, we show thatthe performance of the joint system exceeds that of the individual models.Through qualitative analysis of the learned latent decisions, we show modelstrained with our method exhibit several interesting collaboration patterns,e.g., template-filling. Our code is available athttps://github.com/clinicalml/co-llm.</description><author>Shannon Zejiang Shen, Hunter Lang, Bailin Wang, Yoon Kim, David Sontag</author><pubDate>Wed, 06 Mar 2024 17:23:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03870v1</guid></item><item><title>Differentially Private Generalized Linear Models Revisited</title><link>http://arxiv.org/abs/2205.03014v2</link><description>We study the problem of $(\epsilon,\delta)$-differentially private learningof linear predictors with convex losses. We provide results for two subclassesof loss functions. The first case is when the loss is smooth and non-negativebut not necessarily Lipschitz (such as the squared loss). For this case, weestablish an upper bound on the excess population risk of$\tilde{O}\left(\frac{\Vert w^*\Vert}{\sqrt{n}} + \min\left\{\frac{\Vert w^*\Vert^2}{(n\epsilon)^{2/3}},\frac{\sqrt{d}\Vertw^*\Vert^2}{n\epsilon}\right\}\right)$, where $n$ is the number of samples, $d$is the dimension of the problem, and $w^*$ is the minimizer of the populationrisk. Apart from the dependence on $\Vert w^\ast\Vert$, our bound isessentially tight in all parameters. In particular, we show a lower bound of$\tilde{\Omega}\left(\frac{1}{\sqrt{n}} + {\min\left\{\frac{\Vertw^*\Vert^{4/3}}{(n\epsilon)^{2/3}}, \frac{\sqrt{d}\Vertw^*\Vert}{n\epsilon}\right\}}\right)$. We also revisit the previously studiedcase of Lipschitz losses [SSTT20]. For this case, we close the gap in theexisting work and show that the optimal rate is (up to log factors)$\Theta\left(\frac{\Vert w^*\Vert}{\sqrt{n}} + \min\left\{\frac{\Vertw^*\Vert}{\sqrt{n\epsilon}},\frac{\sqrt{\text{rank}}\Vertw^*\Vert}{n\epsilon}\right\}\right)$, where $\text{rank}$ is the rank of thedesign matrix. This improves over existing work in the high privacy regime.Finally, our algorithms involve a private model selection approach that wedevelop to enable attaining the stated rates without a-priori knowledge of$\Vert w^*\Vert$.</description><author>Raman Arora, Raef Bassily, Cristóbal Guzmán, Michael Menart, Enayat Ullah</author><pubDate>Wed, 06 Mar 2024 17:22:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.03014v2</guid></item><item><title>Multigrid-Augmented Deep Learning Preconditioners for the Helmholtz Equation using Compact Implicit Layers</title><link>http://arxiv.org/abs/2306.17486v3</link><description>We present a deep learning-based iterative approach to solve the discreteheterogeneous Helmholtz equation for high wavenumbers. Combining classicaliterative multigrid solvers and convolutional neural networks (CNNs) viapreconditioning, we obtain a learned neural solver that is faster and scalesbetter than a standard multigrid solver. Our approach offers three maincontributions over previous neural methods of this kind. First, we construct amultilevel U-Net-like encoder-solver CNN with an implicit layer on the coarsestgrid of the U-Net, where convolution kernels are inverted. This alleviates thefield of view problem in CNNs and allows better scalability. Second, we improveupon the previous CNN preconditioner in terms of the number of parameters,computation time, and convergence rates. Third, we propose a multiscaletraining approach that enables the network to scale to problems of previouslyunseen dimensions while still maintaining a reasonable training procedure. Ourencoder-solver architecture can be used to generalize over different slownessmodels of various difficulties and is efficient at solving for many right-handsides per slowness model. We demonstrate the benefits of our novel architecturewith numerical experiments on a variety of heterogeneous two-dimensionalproblems at high wavenumbers.</description><author>Bar Lerer, Ido Ben-Yair, Eran Treister</author><pubDate>Wed, 06 Mar 2024 17:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17486v3</guid></item><item><title>Confidence on the Focal: Conformal Prediction with Selection-Conditional Coverage</title><link>http://arxiv.org/abs/2403.03868v1</link><description>Conformal prediction builds marginally valid prediction intervals which coverthe unknown outcome of a randomly drawn new test point with a prescribedprobability. In practice, a common scenario is that, after seeing the testunit(s), practitioners decide which test unit(s) to focus on in a data-drivenmanner, and wish to quantify the uncertainty for the focal unit(s). In suchcases, marginally valid prediction intervals for these focal units can bemisleading due to selection bias. This paper presents a general framework forconstructing a prediction set with finite-sample exact coverage conditional onthe unit being selected. Its general form works for arbitrary selection rules,and generalizes Mondrian Conformal Prediction to multiple test units andnon-equivariant classifiers. We then work out computationally efficientimplementation of our framework for a number of realistic selection rules,including top-K selection, optimization-based selection, selection based onconformal p-values, and selection based on properties of preliminary conformalprediction sets. The performance of our methods is demonstrated viaapplications in drug discovery and health risk prediction.</description><author>Ying Jin, Zhimei Ren</author><pubDate>Wed, 06 Mar 2024 17:18:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03868v1</guid></item><item><title>On the Origins of Linear Representations in Large Language Models</title><link>http://arxiv.org/abs/2403.03867v1</link><description>Recent works have argued that high-level semantic concepts are encoded"linearly" in the representation space of large language models. In this work,we study the origins of such linear representations. To that end, we introducea simple latent variable model to abstract and formalize the concept dynamicsof the next token prediction. We use this formalism to show that the next tokenprediction objective (softmax with cross-entropy) and the implicit bias ofgradient descent together promote the linear representation of concepts.Experiments show that linear representations emerge when learning from datamatching the latent variable model, confirming that this simple structurealready suffices to yield linear representations. We additionally confirm somepredictions of the theory using the LLaMA-2 large language model, givingevidence that the simplified model yields generalizable insights.</description><author>Yibo Jiang, Goutham Rajendran, Pradeep Ravikumar, Bryon Aragam, Victor Veitch</author><pubDate>Wed, 06 Mar 2024 17:17:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03867v1</guid></item><item><title>KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions</title><link>http://arxiv.org/abs/2403.03866v1</link><description>Large language models (LLMs) adapted to follow user instructions are nowwidely deployed as conversational agents. In this work, we examine oneincreasingly common instruction-following task: providing writing assistance tocompose a long-form answer. To evaluate the capabilities of current LLMs onthis task, we construct KIWI, a dataset of knowledge-intensive writinginstructions in the scientific domain. Given a research question, an initialmodel-generated answer and a set of relevant papers, an expert annotatoriteratively issues instructions for the model to revise and improve its answer.We collect 1,260 interaction turns from 234 interaction sessions with threestate-of-the-art LLMs. Each turn includes a user instruction, a model response,and a human evaluation of the model response. Through a detailed analysis ofthe collected responses, we find that all models struggle to incorporate newinformation into an existing answer, and to perform precise and unambiguousedits. Further, we find that models struggle to judge whether their outputssuccessfully followed user instructions, with accuracy at least 10 points shortof human agreement. Our findings indicate that KIWI will be a valuable resourceto measure progress and improve LLMs' instruction-following capabilities forknowledge intensive writing tasks.</description><author>Fangyuan Xu, Kyle Lo, Luca Soldaini, Bailey Kuehl, Eunsol Choi, David Wadden</author><pubDate>Wed, 06 Mar 2024 17:16:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03866v1</guid></item><item><title>l1-norm regularized l1-norm best-fit lines</title><link>http://arxiv.org/abs/2402.16712v2</link><description>In this work, we propose an optimization framework for estimating a sparserobust one-dimensional subspace. Our objective is to minimize both therepresentation error and the penalty, in terms of the l1-norm criterion. Giventhat the problem is NP-hard, we introduce a linear relaxation-based approach.Additionally, we present a novel fitting procedure, utilizing simple ratios andsorting techniques. The proposed algorithm demonstrates a worst-case timecomplexity of $O(n^2 m \log n)$ and, in certain instances, achieves globaloptimality for the sparse robust subspace, thereby exhibiting polynomial timeefficiency. Compared to extant methodologies, the proposed algorithm finds thesubspace with the lowest discordance, offering a smoother trade-off betweensparsity and fit. Its architecture affords scalability, evidenced by a 16-foldimprovement in computational speeds for matrices of 2000x2000 over CPU version.Furthermore, this method is distinguished by several advantages, including itsindependence from initialization and deterministic and replicable procedures.Furthermore, this method is distinguished by several advantages, including itsindependence from initialization and deterministic and replicable procedures.The real-world example demonstrates the effectiveness of algorithm in achievingmeaningful sparsity, underscoring its precise and useful application acrossvarious domains.</description><author>Xiao Ling, Paul Brooks</author><pubDate>Wed, 06 Mar 2024 17:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16712v2</guid></item><item><title>AbDiffuser: Full-Atom Generation of in vitro Functioning Antibodies</title><link>http://arxiv.org/abs/2308.05027v2</link><description>We introduce AbDiffuser, an equivariant and physics-informed diffusion modelfor the joint generation of antibody 3D structures and sequences. AbDiffuser isbuilt on top of a new representation of protein structure, relies on a novelarchitecture for aligned proteins, and utilizes strong diffusion priors toimprove the denoising process. Our approach improves protein diffusion bytaking advantage of domain knowledge and physics-based constraints; handlessequence-length changes; and reduces memory complexity by an order ofmagnitude, enabling backbone and side chain generation. We validate AbDiffuserin silico and in vitro. Numerical experiments showcase the ability ofAbDiffuser to generate antibodies that closely track the sequence andstructural properties of a reference set. Laboratory experiments confirm thatall 16 HER2 antibodies discovered were expressed at high levels and that 57.1%of the selected designs were tight binders.</description><author>Karolis Martinkus, Jan Ludwiczak, Kyunghyun Cho, Wei-Ching Liang, Julien Lafrance-Vanasse, Isidro Hotzel, Arvind Rajpal, Yan Wu, Richard Bonneau, Vladimir Gligorijevic, Andreas Loukas</author><pubDate>Wed, 06 Mar 2024 17:15:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05027v2</guid></item><item><title>Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning</title><link>http://arxiv.org/abs/2403.03864v1</link><description>This paper introduces the novel task of multimodal puzzle solving, framedwithin the context of visual question-answering. We present a new dataset,AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodallanguage models in solving algorithmic puzzles that necessitate both visualunderstanding, language understanding, and complex algorithmic reasoning. Wecreate the puzzles to encompass a diverse array of mathematical and algorithmictopics such as boolean logic, combinatorics, graph theory, optimization,search, etc., aiming to evaluate the gap between visual data interpretation andalgorithmic problem-solving skills. The dataset is generated automatically fromcode authored by humans. All our puzzles have exact solutions that can be foundfrom the algorithm without tedious human calculations. It ensures that ourdataset can be scaled up arbitrarily in terms of reasoning complexity anddataset size. Our investigation reveals that large language models (LLMs) suchas GPT4V and Gemini exhibit limited performance in puzzle-solving tasks. Wefind that their performance is near random in a multi-choice question-answeringsetup for a significant number of puzzles. The findings emphasize thechallenges of integrating visual, language, and algorithmic knowledge forsolving complex reasoning problems.</description><author>Deepanway Ghosal, Vernon Toh Yan Han, Chia Yew Ken, Soujanya Poria</author><pubDate>Wed, 06 Mar 2024 17:15:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03864v1</guid></item><item><title>X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification</title><link>http://arxiv.org/abs/2403.03863v1</link><description>In recent years, few-shot and zero-shot learning, which learn to predictlabels with limited annotated instances, have garnered significant attention.Traditional approaches often treat frequent-shot (freq-shot; labels withabundant instances), few-shot, and zero-shot learning as distinct challenges,optimizing systems for just one of these scenarios. Yet, in real-worldsettings, label occurrences vary greatly. Some of them might appear thousandsof times, while others might only appear sporadically or not at all. Forpractical deployment, it is crucial that a system can adapt to any labeloccurrence. We introduce a novel classification challenge: X-shot, reflecting areal-world context where freq-shot, few-shot, and zero-shot labels co-occurwithout predefined limits. Here, X can span from 0 to positive infinity. Thecrux of X-shot centers on open-domain generalization and devising a systemversatile enough to manage various label scenarios. To solve X-shot, we proposeBinBin (Binary INference Based on INstruction following) that leverages theIndirect Supervision from a large collection of NLP tasks via instructionfollowing, bolstered by Weak Supervision provided by large language models.BinBin surpasses previous state-of-the-art techniques on three benchmarkdatasets across multiple domains. To our knowledge, this is the first workaddressing X-shot learning, where X remains variable.</description><author>Hanzi Xu, Muhao Chen, Lifu Huang, Slobodan Vucetic, Wenpeng Yin</author><pubDate>Wed, 06 Mar 2024 17:13:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03863v1</guid></item><item><title>Designing Informative Metrics for Few-Shot Example Selection</title><link>http://arxiv.org/abs/2403.03861v1</link><description>Pretrained language models (PLMs) have shown remarkable few-shot learningcapabilities when provided with properly formatted examples. However, selectingthe "best" examples remains an open challenge. We propose a complexity-basedprompt selection approach for sequence tagging tasks. This approach avoids thetraining of a dedicated model for selection of examples, and instead usescertain metrics to align the syntactico-semantic complexity of test sentencesand examples. We use both sentence- and word-level metrics to match thecomplexity of examples to the (test) sentence being considered. Our resultsdemonstrate that our approach extracts greater performance from PLMs: itachieves state-of-the-art performance on few-shot NER, achieving a 5% absoluteimprovement in F1 score on the CoNLL2003 dataset for GPT-4. We also see largegains of upto 28.85 points (F1/Acc.) in smaller models like GPT-j-6B.</description><author>Rishabh Adiga, Lakshminarayanan Subramanian, Varun Chandrasekaran</author><pubDate>Wed, 06 Mar 2024 17:11:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03861v1</guid></item><item><title>Emojinize : Enriching Any Text with Emoji Translations</title><link>http://arxiv.org/abs/2403.03857v1</link><description>Emoji have become ubiquitous in written communication, on the Web and beyond.They can emphasize or clarify emotions, add details to conversations, or simplyserve decorative purposes. This casual use, however, barely scratches thesurface of the expressive power of emoji. To further unleash this power, wepresent Emojinize, a method for translating arbitrary text phrases intosequences of one or more emoji without requiring human input. By leveraging thepower of large language models, Emojinize can choose appropriate emoji bydisambiguating based on context (eg, cricket-bat vs bat) and can expresscomplex concepts compositionally by combining multiple emoji (eq, ''Emojinize''is translated to input-latin-letters right-arrow grinning-face). In a clozetest--based user study, we show that Emojinize's emoji translations increasethe human guessability of masked words by 55%, whereas human-picked emojitranslations do so by only 29%. These results suggest that emoji provide asufficiently rich vocabulary to accurately translate a wide variety of words.Moreover, annotating words and phrases with Emojinize's emoji translationsopens the door to numerous downstream applications, including children learninghow to read, adults learning foreign languages, and text understanding forpeople with learning disabilities.</description><author>Lars Henning Klein, Roland Aydin, Robert West</author><pubDate>Wed, 06 Mar 2024 17:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03857v1</guid></item><item><title>Public-data Assisted Private Stochastic Optimization: Power and Limitations</title><link>http://arxiv.org/abs/2403.03856v1</link><description>We study the limits and capability of public-data assisted differentiallyprivate (PA-DP) algorithms. Specifically, we focus on the problem of stochasticconvex optimization (SCO) with either labeled or unlabeled public data. Forcomplete/labeled public data, we show that any $(\epsilon,\delta)$-PA-DP hasexcess risk$\tilde{\Omega}\big(\min\big\{\frac{1}{\sqrt{n_{\text{pub}}}},\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\epsilon}\big\} \big)$, where $d$ is the dimension, ${n_{\text{pub}}}$ is the number ofpublic samples, ${n_{\text{priv}}}$ is the number of private samples, and$n={n_{\text{pub}}}+{n_{\text{priv}}}$. These lower bounds are established viaour new lower bounds for PA-DP mean estimation, which are of a similar form. Upto constant factors, these lower bounds show that the simple strategy of eithertreating all data as private or discarding the private data, is optimal. Wealso study PA-DP supervised learning with \textit{unlabeled} public samples. Incontrast to our previous result, we here show novel methods for leveragingpublic data in private supervised learning. For generalized linear models (GLM)with unlabeled public data, we show an efficient algorithm which, given$\tilde{O}({n_{\text{priv}}}\epsilon)$ unlabeled public samples, achieves thedimension independent rate $\tilde{O}\big(\frac{1}{\sqrt{{n_{\text{priv}}}}} +\frac{1}{\sqrt{{n_{\text{priv}}}\epsilon}}\big)$. We develop new lower boundsfor this setting which shows that this rate cannot be improved with more publicsamples, and any fewer public samples leads to a worse rate. Finally, weprovide extensions of this result to general hypothesis classes with finitefat-shattering dimension with applications to neural networks and non-Euclideangeometries.</description><author>Enayat Ullah, Michael Menart, Raef Bassily, Cristóbal Guzmán, Raman Arora</author><pubDate>Wed, 06 Mar 2024 17:06:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03856v1</guid></item><item><title>ECAP: Extensive Cut-and-Paste Augmentation for Unsupervised Domain Adaptive Semantic Segmentation</title><link>http://arxiv.org/abs/2403.03854v1</link><description>We consider unsupervised domain adaptation (UDA) for semantic segmentation inwhich the model is trained on a labeled source dataset and adapted to anunlabeled target dataset. Unfortunately, current self-training methods aresusceptible to misclassified pseudo-labels resulting from erroneouspredictions. Since certain classes are typically associated with less reliablepredictions in UDA, reducing the impact of such pseudo-labels without skewingthe training towards some classes is notoriously difficult. To this end, wepropose an extensive cut-and-paste strategy (ECAP) to leverage reliablepseudo-labels through data augmentation. Specifically, ECAP maintains a memorybank of pseudo-labeled target samples throughout training and cut-and-pastesthe most confident ones onto the current training batch. We implement ECAP ontop of the recent method MIC and boost its performance on two synthetic-to-realdomain adaptation benchmarks. Notably, MIC+ECAP reaches an unprecedentedperformance of 69.1 mIoU on the Synthia-&gt;Cityscapes benchmark. Our code isavailable at https://github.com/ErikBrorsson/ECAP.</description><author>Erik Brorsson, Knut Åkesson, Lennart Svensson, Kristofer Bengtsson</author><pubDate>Wed, 06 Mar 2024 17:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03854v1</guid></item><item><title>ShortGPT: Layers in Large Language Models are More Redundant Than You Expect</title><link>http://arxiv.org/abs/2403.03853v1</link><description>As Large Language Models (LLMs) continue to advance in performance, theirsize has escalated significantly, with current LLMs containing billions or eventrillions of parameters. However, in this study, we discovered that many layersof LLMs exhibit high similarity, and some layers play a negligible role innetwork functionality. Based on this observation, we define a metric calledBlock Influence (BI) to gauge the significance of each layer in LLMs. We thenpropose a straightforward pruning approach: layer removal, in which we directlydelete the redundant layers in LLMs based on their BI scores. Experimentsdemonstrate that our method, which we call ShortGPT, significantly outperformsprevious state-of-the-art (SOTA) methods in model pruning. Moreover, ShortGPTis orthogonal to quantization-like methods, enabling further reduction inparameters and computation. The ability to achieve better results throughsimple layer removal, as opposed to more complex pruning techniques, suggests ahigh degree of redundancy in the model architecture.</description><author>Xin Men, Mingyu Xu, Qingyu Zhang, Bingning Wang, Hongyu Lin, Yaojie Lu, Xianpei Han, Weipeng Chen</author><pubDate>Wed, 06 Mar 2024 17:04:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03853v1</guid></item><item><title>Accelerating Convergence of Score-Based Diffusion Models, Provably</title><link>http://arxiv.org/abs/2403.03852v1</link><description>Score-based diffusion models, while achieving remarkable empiricalperformance, often suffer from low sampling speed, due to extensive functionevaluations needed during the sampling phase. Despite a flurry of recentactivities towards speeding up diffusion generative modeling in practice,theoretical underpinnings for acceleration techniques remain severely limited.In this paper, we design novel training-free algorithms to accelerate populardeterministic (i.e., DDIM) and stochastic (i.e., DDPM) samplers. Ouraccelerated deterministic sampler converges at a rate $O(1/{T}^2)$ with $T$ thenumber of steps, improving upon the $O(1/T)$ rate for the DDIM sampler; and ouraccelerated stochastic sampler converges at a rate $O(1/T)$, outperforming therate $O(1/\sqrt{T})$ for the DDPM sampler. The design of our algorithmsleverages insights from higher-order approximation, and shares similarintuitions as popular high-order ODE solvers like the DPM-Solver-2. Our theoryaccommodates $\ell_2$-accurate score estimates, and does not requirelog-concavity or smoothness on the target distribution.</description><author>Gen Li, Yu Huang, Timofey Efimov, Yuting Wei, Yuejie Chi, Yuxin Chen</author><pubDate>Wed, 06 Mar 2024 17:02:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03852v1</guid></item><item><title>Conformal prediction for multi-dimensional time series by ellipsoidal sets</title><link>http://arxiv.org/abs/2403.03850v1</link><description>Conformal prediction (CP) has been a popular method for uncertaintyquantification because it is distribution-free, model-agnostic, andtheoretically sound. For forecasting problems in supervised learning, most CPmethods focus on building prediction intervals for univariate responses. Inthis work, we develop a sequential CP method called $\texttt{MultiDimSPCI}$that builds prediction regions for a multivariate response, especially in thecontext of multivariate time series, which are not exchangeable. Theoretically,we estimate finite-sample high-probability bounds on the conditional coveragegap. Empirically, we demonstrate that $\texttt{MultiDimSPCI}$ maintains validcoverage on a wide range of multivariate time series while producing smallerprediction regions than CP and non-CP baselines.</description><author>Chen Xu, Hanyang Jiang, Yao Xie</author><pubDate>Wed, 06 Mar 2024 16:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03850v1</guid></item><item><title>MedMamba: Vision Mamba for Medical Image Classification</title><link>http://arxiv.org/abs/2403.03849v1</link><description>Medical image classification is a very fundamental and crucial task in thefield of computer vision. These years, CNN-based and Transformer-based modelsare widely used in classifying various medical images. Unfortunately, Thelimitation of CNNs in long-range modeling capabilities prevent them fromeffectively extracting fine-grained features in medical images , whileTransformers are hampered by their quadratic computational complexity. Recentresearch has shown that the state space model (SSM) represented by Mamba canefficiently model long-range interactions while maintaining linearcomputational complexity. Inspired by this, we propose Vision Mamba for medicalimage classification (MedMamba). More specifically, we introduce a novelConv-SSM module, which combines the local feature extraction ability ofconvolutional layers with the ability of SSM to capture long-range dependency.To demonstrate the potential of MedMamba, we conduct extensive experimentsusing three publicly available medical datasets with different imagingtechniques (i.e., Kvasir (endoscopic images), FETAL_PLANES_DB (ultrasoundimages) and Covid19-Pneumonia-Normal Chest X-Ray (X-ray images)) and twoprivate datasets built by ourselves. Experimental results show that theproposed MedMamba performs well in detecting lesions in various medical images.To the best of our knowledge, this is the first Vision Mamba tailored formedical image classification. The purpose of this work is to establish a newbaseline for medical image classification tasks and provide valuable insightsfor the future development of more efficient and effective SSM-based artificialintelligence algorithms and application systems in the medical. Source code hasbeen available at https://github.com/YubiaoYue/MedMamba.</description><author>Yubiao Yue, Zhenzhang Li</author><pubDate>Wed, 06 Mar 2024 16:49:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03849v1</guid></item><item><title>Dexterous Legged Locomotion in Confined 3D Spaces with Reinforcement Learning</title><link>http://arxiv.org/abs/2403.03848v1</link><description>Recent advances of locomotion controllers utilizing deep reinforcementlearning (RL) have yielded impressive results in terms of achieving rapid androbust locomotion across challenging terrain, such as rugged rocks, non-rigidground, and slippery surfaces. However, while these controllers primarilyaddress challenges underneath the robot, relatively little research hasinvestigated legged mobility through confined 3D spaces, such as narrow tunnelsor irregular voids, which impose all-around constraints. The cyclic gaitpatterns resulted from existing RL-based methods to learn parameterizedlocomotion skills characterized by motion parameters, such as velocity and bodyheight, may not be adequate to navigate robots through challenging confined 3Dspaces, requiring both agile 3D obstacle avoidance and robust leggedlocomotion. Instead, we propose to learn locomotion skills end-to-end fromgoal-oriented navigation in confined 3D spaces. To address the inefficiency oftracking distant navigation goals, we introduce a hierarchical locomotioncontroller that combines a classical planner tasked with planning waypoints toreach a faraway global goal location, and an RL-based policy trained to followthese waypoints by generating low-level motion commands. This approach allowsthe policy to explore its own locomotion skills within the entire solutionspace and facilitates smooth transitions between local goals, enablinglong-term navigation towards distant goals. In simulation, our hierarchicalapproach succeeds at navigating through demanding confined 3D environments,outperforming both pure end-to-end learning approaches and parameterizedlocomotion skills. We further demonstrate the successful real-world deploymentof our simulation-trained controller on a real robot.</description><author>Zifan Xu, Amir Hossain Raj, Xuesu Xiao, Peter Stone</author><pubDate>Wed, 06 Mar 2024 16:49:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03848v1</guid></item><item><title>On the Effectiveness of Distillation in Mitigating Backdoors in Pre-trained Encoder</title><link>http://arxiv.org/abs/2403.03846v1</link><description>In this paper, we study a defense against poisoned encoders in SSL calleddistillation, which is a defense used in supervised learning originally.Distillation aims to distill knowledge from a given model (a.k.a the teachernet) and transfer it to another (a.k.a the student net). Now, we use it todistill benign knowledge from poisoned pre-trained encoders and transfer it toa new encoder, resulting in a clean pre-trained encoder. In particular, weconduct an empirical study on the effectiveness and performance of distillationagainst poisoned encoders. Using two state-of-the-art backdoor attacks againstpre-trained image encoders and four commonly used image classificationdatasets, our experimental results show that distillation can reduce attacksuccess rate from 80.87% to 27.51% while suffering a 6.35% loss in accuracy.Moreover, we investigate the impact of three core components of distillation onperformance: teacher net, student net, and distillation loss. By comparing 4different teacher nets, 3 student nets, and 6 distillation losses, we find thatfine-tuned teacher nets, warm-up-training-based student nets, andattention-based distillation loss perform best, respectively.</description><author>Tingxu Han, Shenghan Huang, Ziqi Ding, Weisong Sun, Yebo Feng, Chunrong Fang, Jun Li, Hanwei Qian, Cong Wu, Quanjun Zhang, Yang Liu, Zhenyu Chen</author><pubDate>Wed, 06 Mar 2024 16:42:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03846v1</guid></item><item><title>GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction</title><link>http://arxiv.org/abs/2310.03668v5</link><description>Large Language Models (LLMs) combined with instruction tuning have madesignificant progress when generalizing to unseen tasks. However, they have beenless successful in Information Extraction (IE), lagging behind task-specificmodels. Typically, IE tasks are characterized by complex annotation guidelinesthat describe the task and give examples to humans. Previous attempts toleverage such information have failed, even with the largest models, as theyare not able to follow the guidelines out of the box. In this paper, we proposeGoLLIE (Guideline-following Large Language Model for IE), a model able toimprove zero-shot results on unseen IE tasks by virtue of being fine-tuned tocomply with annotation guidelines. Comprehensive evaluation empiricallydemonstrates that GoLLIE is able to generalize to and follow unseen guidelines,outperforming previous attempts at zero-shot information extraction. Theablation study shows that detailed guidelines are key for good results.</description><author>Oscar Sainz, Iker García-Ferrero, Rodrigo Agerri, Oier Lopez de Lacalle, German Rigau, Eneko Agirre</author><pubDate>Wed, 06 Mar 2024 16:38:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03668v5</guid></item><item><title>OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis</title><link>http://arxiv.org/abs/2309.13297v2</link><description>Aspect-based sentiment analysis (ABSA) delves into understanding sentimentsspecific to distinct elements within a user-generated review. It aims toanalyze user-generated reviews to determine a) the target entity beingreviewed, b) the high-level aspect to which it belongs, c) the sentiment wordsused to express the opinion, and d) the sentiment expressed toward the targetsand the aspects. While various benchmark datasets have fostered advancements inABSA, they often come with domain limitations and data granularity challenges.Addressing these, we introduce the OATS dataset, which encompasses three freshdomains and consists of 27,470 sentence-level quadruples and 17,092review-level tuples. Our initiative seeks to bridge specific observed gaps: therecurrent focus on familiar domains like restaurants and laptops, limited datafor intricate quadruple extraction tasks, and an occasional oversight of thesynergy between sentence and review-level sentiments. Moreover, to elucidateOATS's potential and shed light on various ABSA subtasks that OATS can solve,we conducted experiments, establishing initial baselines. We hope the OATSdataset augments current resources, paving the way for an encompassingexploration of ABSA (https://github.com/RiTUAL-UH/OATS-ABSA).</description><author>Siva Uday Sampreeth Chebolu, Franck Dernoncourt, Nedim Lipka, Thamar Solorio</author><pubDate>Wed, 06 Mar 2024 16:33:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13297v2</guid></item><item><title>Feature Selection as Deep Sequential Generative Learning</title><link>http://arxiv.org/abs/2403.03838v1</link><description>Feature selection aims to identify the most pattern-discriminative featuresubset. In prior literature, filter (e.g., backward elimination) and embedded(e.g., Lasso) methods have hyperparameters (e.g., top-K, score thresholding)and tie to specific models, thus, hard to generalize; wrapper methods search afeature subset in a huge discrete space and is computationally costly. Totransform the way of feature selection, we regard a selected feature subset asa selection decision token sequence and reformulate feature selection as a deepsequential generative learning task that distills feature knowledge andgenerates decision sequences. Our method includes three steps: (1) We develop adeep variational transformer model over a joint of sequential reconstruction,variational, and performance evaluator losses. Our model can distill featureselection knowledge and learn a continuous embedding space to map featureselection decision sequences into embedding vectors associated with utilityscores. (2) We leverage the trained feature subset utility evaluator as agradient provider to guide the identification of the optimal feature subsetembedding;(3) We decode the optimal feature subset embedding toautoregressively generate the best feature selection decision sequence withautostop. Extensive experimental results show this generative perspective iseffective and generic, without large discrete search space and expert-specifichyperparameters.</description><author>Wangyang Ying, Dongjie Wang, Haifeng Chen, Yanjie Fu</author><pubDate>Wed, 06 Mar 2024 16:31:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03838v1</guid></item><item><title>Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning</title><link>http://arxiv.org/abs/2403.03835v1</link><description>Cobweb, a human like category learning system, differs from other incrementalcategorization models in constructing hierarchically organized cognitivetree-like structures using the category utility measure. Prior studies haveshown that Cobweb can capture psychological effects such as the basic level,typicality, and fan effects. However, a broader evaluation of Cobweb as a modelof human categorization remains lacking. The current study addresses this gap.It establishes Cobweb's alignment with classical human category learningeffects. It also explores Cobweb's flexibility to exhibit both exemplar andprototype like learning within a single model. These findings set the stage forfuture research on Cobweb as a comprehensive model of human category learning.</description><author>Xin Lian, Sashank Varma, Christopher J. MacLellan</author><pubDate>Wed, 06 Mar 2024 16:26:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03835v1</guid></item><item><title>Your device may know you better than you know yourself -- continuous authentication on novel dataset using machine learning</title><link>http://arxiv.org/abs/2403.03832v1</link><description>This research aims to further understanding in the field of continuousauthentication using behavioral biometrics. We are contributing a novel datasetthat encompasses the gesture data of 15 users playing Minecraft with a SamsungTablet, each for a duration of 15 minutes. Utilizing this dataset, we employedmachine learning (ML) binary classifiers, being Random Forest (RF), K-NearestNeighbors (KNN), and Support Vector Classifier (SVC), to determine theauthenticity of specific user actions. Our most robust model was SVC, whichachieved an average accuracy of approximately 90%, demonstrating that touchdynamics can effectively distinguish users. However, further studies are neededto make it viable option for authentication systems</description><author>Pedro Gomes do Nascimento, Pidge Witiak, Tucker MacCallum, Zachary Winterfeldt, Rushit Dave</author><pubDate>Wed, 06 Mar 2024 16:22:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03832v1</guid></item><item><title>From Clicks to Security: Investigating Continuous Authentication via Mouse Dynamics</title><link>http://arxiv.org/abs/2403.03828v1</link><description>In the realm of computer security, the importance of efficient and reliableuser authentication methods has become increasingly critical. This paperexamines the potential of mouse movement dynamics as a consistent metric forcontinuous authentication. By analyzing user mouse movement patterns in twocontrasting gaming scenarios, "Team Fortress" and Poly Bridge we investigatethe distinctive behavioral patterns inherent in high-intensity andlow-intensity UI interactions. The study extends beyond conventionalmethodologies by employing a range of machine learning models. These models arecarefully selected to assess their effectiveness in capturing and interpretingthe subtleties of user behavior as reflected in their mouse movements. Thismultifaceted approach allows for a more nuanced and comprehensive understandingof user interaction patterns. Our findings reveal that mouse movement dynamicscan serve as a reliable indicator for continuous user authentication. Thediverse machine learning models employed in this study demonstrate competentperformance in user verification, marking an improvement over previous methodsused in this field. This research contributes to the ongoing efforts to enhancecomputer security and highlights the potential of leveraging user behavior,specifically mouse dynamics, in developing robust authentication systems.</description><author>Rushit Dave, Marcho Handoko, Ali Rashid, Cole Schoenbauer</author><pubDate>Wed, 06 Mar 2024 16:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03828v1</guid></item><item><title>Linear and nonlinear system identification under $\ell_1$- and group-Lasso regularization via L-BFGS-B</title><link>http://arxiv.org/abs/2403.03827v1</link><description>In this paper, we propose an approach for identifying linear and nonlineardiscrete-time state-space models, possibly under $\ell_1$- and group-Lassoregularization, based on the L-BFGS-B algorithm. For the identification oflinear models, we show that, compared to classical linear subspace methods, theapproach often provides better results, is much more general in terms of theloss and regularization terms used, and is also more stable from a numericalpoint of view. The proposed method not only enriches the existing set of linearsystem identification tools but can be also applied to identifying a very broadclass of parametric nonlinear state-space models, including recurrent neuralnetworks. We illustrate the approach on synthetic and experimental datasets andapply it to solve the challenging industrial robot benchmark for nonlinearmulti-input/multi-output system identification proposed by Weigand et al.(2022). A Python implementation of the proposed identification method isavailable in the package \texttt{jax-sysid}, available at\url{https://github.com/bemporad/jax-sysid}.</description><author>Alberto Bemporad</author><pubDate>Wed, 06 Mar 2024 16:17:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03827v1</guid></item><item><title>Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning For Visual Story Synthesis</title><link>http://arxiv.org/abs/2309.09553v4</link><description>The excellent text-to-image synthesis capability of diffusion models hasdriven progress in synthesizing coherent visual stories. The currentstate-of-the-art method combines the features of historical captions,historical frames, and the current captions as conditions for generating thecurrent frame. However, this method treats each historical frame and caption asthe same contribution. It connects them in order with equal weights, ignoringthat not all historical conditions are associated with the generation of thecurrent frame. To address this issue, we propose Causal-Story. This modelincorporates a local causal attention mechanism that considers the causalrelationship between previous captions, frames, and current captions. Byassigning weights based on this relationship, Causal-Story generates thecurrent frame, thereby improving the global consistency of story generation. Weevaluated our model on the PororoSV and FlintstonesSV datasets and obtainedstate-of-the-art FID scores, and the generated frames also demonstrate betterstorytelling in visuals.</description><author>Tianyi Song, Jiuxin Cao, Kun Wang, Bo Liu, Xiaofeng Zhang</author><pubDate>Wed, 06 Mar 2024 16:16:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09553v4</guid></item><item><title>Temporal Enhanced Floating Car Observers</title><link>http://arxiv.org/abs/2403.03825v1</link><description>Floating Car Observers (FCOs) are an innovative method to collect trafficdata by deploying sensor-equipped vehicles to detect and locate other vehicles.We demonstrate that even a small penetration rate of FCOs can identify asignificant amount of vehicles at a given intersection. This is achievedthrough the emulation of detection within a microscopic traffic simulation.Additionally, leveraging data from previous moments can enhance the detectionof vehicles in the current frame. Our findings indicate that, with a 20-secondobservation window, it is possible to recover up to 20\% of vehicles that arenot visible by FCOs in the current timestep. To exploit this, we developed adata-driven strategy, utilizing sequences of Bird's Eye View (BEV)representations of detected vehicles and deep learning models. This approachaims to bring currently undetected vehicles into view in the present moment,enhancing the currently detected vehicles. Results of different spatiotemporalarchitectures show that up to 41\% of the vehicles can be recovered into thecurrent timestep at their current position. This enhancement enriches theinformation initially available by the FCO, allowing an improved estimation oftraffic states and metrics (e.g. density and queue length) for improvedimplementation of traffic management strategies.</description><author>Jeremias Gerner, Klaus Bogenberger, Stefanie Schmidtner</author><pubDate>Wed, 06 Mar 2024 16:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03825v1</guid></item><item><title>A Modular Approach for Multimodal Summarization of TV Shows</title><link>http://arxiv.org/abs/2403.03823v1</link><description>In this paper we address the task of summarizing television shows, whichtouches key areas in AI research: complex reasoning, multiple modalities, andlong narratives. We present a modular approach where separate componentsperform specialized sub-tasks which we argue affords greater flexibilitycompared to end-to-end methods. Our modules involve detecting scene boundaries,reordering scenes so as to minimize the number of cuts between differentevents, converting visual information to text, summarizing the dialogue in eachscene, and fusing the scene summaries into a final summary for the entireepisode. We also present a new metric, PREFS (\textbf{P}recision and\textbf{R}ecall \textbf{E}valuation of Summary \textbf{F}act\textbf{s}), tomeasure both precision and recall of generated summaries, which we decomposeinto atomic facts. Tested on the recently released SummScreen3D datasetPapalampidi and Lapata (2023), our method produces higher quality summariesthan comparison models, as measured with ROUGE and our new fact-based metric.</description><author>Louis Mahon, Mirella Lapata</author><pubDate>Wed, 06 Mar 2024 16:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03823v1</guid></item><item><title>Targeted Variance Reduction: Robust Bayesian Optimization of Black-Box Simulators with Noise Parameters</title><link>http://arxiv.org/abs/2403.03816v1</link><description>The optimization of a black-box simulator over control parameters$\mathbf{x}$ arises in a myriad of scientific applications. In suchapplications, the simulator often takes the form$f(\mathbf{x},\boldsymbol{\theta})$, where $\boldsymbol{\theta}$ are parametersthat are uncertain in practice. Robust optimization aims to optimize theobjective $\mathbb{E}[f(\mathbf{x},\boldsymbol{\Theta})]$, where$\boldsymbol{\Theta} \sim \mathcal{P}$ is a random variable that modelsuncertainty on $\boldsymbol{\theta}$. For this, existing black-box methodstypically employ a two-stage approach for selecting the next point$(\mathbf{x},\boldsymbol{\theta})$, where $\mathbf{x}$ and$\boldsymbol{\theta}$ are optimized separately via different acquisitionfunctions. As such, these approaches do not employ a joint acquisition over$(\mathbf{x},\boldsymbol{\theta})$, and thus may fail to fully exploitcontrol-to-noise interactions for effective robust optimization. To addressthis, we propose a new Bayesian optimization method called Targeted VarianceReduction (TVR). The TVR leverages a novel joint acquisition function over$(\mathbf{x},\boldsymbol{\theta})$, which targets variance reduction on theobjective within the desired region of improvement. Under a Gaussian processsurrogate on $f$, the TVR acquisition can be evaluated in closed form, andreveals an insightful exploration-exploitation-precision trade-off for robustblack-box optimization. The TVR can further accommodate a broad class ofnon-Gaussian distributions on $\mathcal{P}$ via a careful integration ofnormalizing flows. We demonstrate the improved performance of TVR over thestate-of-the-art in a suite of numerical experiments and an application to therobust design of automobile brake discs under operational uncertainty.</description><author>John Joshua Miller, Simon Mak</author><pubDate>Wed, 06 Mar 2024 16:03:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03816v1</guid></item><item><title>Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ</title><link>http://arxiv.org/abs/2403.03814v1</link><description>Large language models (LLMs) need to serve everyone, including a globalmajority of non-English speakers. However, most LLMs today, and open LLMs inparticular, are often intended for use in just English (e.g. Llama2, Mistral)or a small handful of high-resource languages (e.g. Mixtral, Qwen). Recentresearch shows that, despite limits in their intended use, people prompt LLMsin many different languages. Therefore, in this paper, we investigate the basicmultilingual capabilities of state-of-the-art open LLMs beyond their intendeduse. For this purpose, we introduce MultiQ, a new silver standard benchmark forbasic open-ended question answering with 27.4k test questions across atypologically diverse set of 137 languages. With MultiQ, we evaluate languagefidelity, i.e.\ whether models respond in the prompted language, and questionanswering accuracy. All LLMs we test respond faithfully and/or accurately forat least some languages beyond their intended use. Most models are moreaccurate when they respond faithfully. However, differences across models arelarge, and there is a long tail of languages where models are neither accuratenor faithful. We explore differences in tokenization as a potential explanationfor our findings, identifying possible correlations that warrant furtherinvestigation.</description><author>Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher</author><pubDate>Wed, 06 Mar 2024 16:01:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03814v1</guid></item><item><title>ProbSAINT: Probabilistic Tabular Regression for Used Car Pricing</title><link>http://arxiv.org/abs/2403.03812v1</link><description>Used car pricing is a critical aspect of the automotive industry, influencedby many economic factors and market dynamics. With the recent surge in onlinemarketplaces and increased demand for used cars, accurate pricing would benefitboth buyers and sellers by ensuring fair transactions. However, the transitiontowards automated pricing algorithms using machine learning necessitates thecomprehension of model uncertainties, specifically the ability to flagpredictions that the model is unsure about. Although recent literature proposesthe use of boosting algorithms or nearest neighbor-based approaches for swiftand precise price predictions, encapsulating model uncertainties with suchalgorithms presents a complex challenge. We introduce ProbSAINT, a model thatoffers a principled approach for uncertainty quantification of its pricepredictions, along with accurate point predictions that are comparable tostate-of-the-art boosting techniques. Furthermore, acknowledging that thebusiness prefers pricing used cars based on the number of days the vehicle waslisted for sale, we show how ProbSAINT can be used as a dynamic forecastingmodel for predicting price probabilities for different expected offer duration.Our experiments further indicate that ProbSAINT is especially accurate oninstances where it is highly certain. This proves the applicability of itsprobabilistic predictions in real-world scenarios where trustworthiness iscrucial.</description><author>Kiran Madhusudhanan, Gunnar Behrens, Maximilian Stubbemann, Lars Schmidt-Thieme</author><pubDate>Wed, 06 Mar 2024 16:00:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03812v1</guid></item><item><title>Incentivized Learning in Principal-Agent Bandit Games</title><link>http://arxiv.org/abs/2403.03811v1</link><description>This work considers a repeated principal-agent bandit game, where theprincipal can only interact with her environment through the agent. Theprincipal and the agent have misaligned objectives and the choice of action isonly left to the agent. However, the principal can influence the agent'sdecisions by offering incentives which add up to his rewards. The principalaims to iteratively learn an incentive policy to maximize her own totalutility. This framework extends usual bandit problems and is motivated byseveral practical applications, such as healthcare or ecological taxation,where traditionally used mechanism design theories often overlook the learningaspect of the problem. We present nearly optimal (with respect to a horizon$T$) learning algorithms for the principal's regret in both multi-armed andlinear contextual settings. Finally, we support our theoretical guaranteesthrough numerical experiments.</description><author>Antoine Scheid, Daniil Tiapkin, Etienne Boursier, Aymeric Capitaine, El Mahdi El Mhamdi, Eric Moulines, Michael I. Jordan, Alain Durmus</author><pubDate>Wed, 06 Mar 2024 16:00:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03811v1</guid></item><item><title>Confidence-Aware Decision-Making and Control for Tool Selection</title><link>http://arxiv.org/abs/2403.03808v1</link><description>Self-reflecting about our performance (e.g., how confident we are) beforedoing a task is essential for decision making, such as selecting the mostsuitable tool or choosing the best route to drive. While this form of awareness-- thinking about our performance or metacognitive performance -- is well-knownin humans, robots still lack this cognitive ability. This reflective monitoringcan enhance their embodied decision power, robustness and safety. Here, we takea step in this direction by introducing a mathematical framework that allowsrobots to use their control self-confidence to make better-informed decisions.We derive a mathematical closed-form expression for control confidence fordynamic systems (i.e., the posterior inverse covariance of the control action).This control confidence seamlessly integrates within an objective function fordecision making, that balances the: i) performance for task completion, ii)control effort, and iii) self-confidence. To evaluate our theoretical account,we framed the decision-making within the tool selection problem, where theagent has to select the best robot arm for a particular control task. Thestatistical analysis of the numerical simulations with randomized 2DOF armsshows that using control confidence during tool selection improves both realtask performance, and the reliability of the tool for performance underunmodelled perturbations (e.g., external forces). Furthermore, our resultsindicate that control confidence is an early indicator of performance and thus,it can be used as a heuristic for making decisions when computation power isrestricted or decision-making is intractable. Overall, we show the advantagesof using confidence-aware decision-making and control scheme for dynamicsystems.</description><author>Ajith Anil Meera, Pablo Lanillos</author><pubDate>Wed, 06 Mar 2024 15:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03808v1</guid></item><item><title>A Precision Drone Landing System using Visual and IR Fiducial Markers and a Multi-Payload Camera</title><link>http://arxiv.org/abs/2403.03806v1</link><description>We propose a method for autonomous precision drone landing with fiducialmarkers and a gimbal-mounted, multi-payload camera with wide-angle, zoom, andIR sensors. The method has minimal data requirements; it depends primarily onthe direction from the drone to the landing pad, enabling it to switchdynamically between the camera's different sensors and zoom factors, andminimizing auxiliary sensor requirements. It eliminates the need for data suchas altitude above ground level, straight-line distance to the landing pad,fiducial marker size, and 6 DoF marker pose (of which the orientation isproblematic). We leverage the zoom and wide-angle cameras, as well as visualApril Tag fiducial markers to conduct successful precision landings from muchlonger distances than in previous work (168m horizontal distance, 102maltitude). We use two types of April Tags in the IR spectrum - active andpassive - for precision landing both at daytime and nighttime, instead ofsimple IR beacons used in most previous work. The active IR landing pad isheated; the novel, passive one is unpowered, at ambient temperature, anddepends on its high reflectivity and an IR differential between the ground andthe sky. Finally, we propose a high-level control policy to manage initialsearch for the landing pad and subsequent searches if it is lost - notaddressed in previous work. The method demonstrates successful landings withthe landing skids at least touching the landing pad, achieving an average errorof 0.19m. It also demonstrates successful recovery and landing when the landingpad is temporarily obscured.</description><author>Joshua Springer, Gylfi Þór Guðmundsson, Marcel Kyas</author><pubDate>Wed, 06 Mar 2024 15:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03806v1</guid></item><item><title>Learning with Language-Guided State Abstractions</title><link>http://arxiv.org/abs/2402.18759v2</link><description>We describe a framework for using natural language to design stateabstractions for imitation learning. Generalizable policy learning inhigh-dimensional observation spaces is facilitated by well-designed staterepresentations, which can surface important features of an environment andhide irrelevant ones. These state representations are typically manuallyspecified, or derived from other labor-intensive labeling procedures. Ourmethod, LGA (language-guided abstraction), uses a combination of naturallanguage supervision and background knowledge from language models (LMs) toautomatically build state representations tailored to unseen tasks. In LGA, auser first provides a (possibly incomplete) description of a target task innatural language; next, a pre-trained LM translates this task description intoa state abstraction function that masks out irrelevant features; finally, animitation policy is trained using a small number of demonstrations andLGA-generated abstract states. Experiments on simulated robotic tasks show thatLGA yields state abstractions similar to those designed by humans, but in afraction of the time, and that these abstractions improve generalization androbustness in the presence of spurious correlations and ambiguousspecifications. We illustrate the utility of the learned abstractions on mobilemanipulation tasks with a Spot robot.</description><author>Andi Peng, Ilia Sucholutsky, Belinda Z. Li, Theodore R. Sumers, Thomas L. Griffiths, Jacob Andreas, Julie A. Shah</author><pubDate>Wed, 06 Mar 2024 15:53:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18759v2</guid></item><item><title>Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages</title><link>http://arxiv.org/abs/2310.04799v2</link><description>Recently, the development of open-source large language models (LLMs) hasadvanced rapidly. Nevertheless, due to data constraints, the capabilities ofmost open-source LLMs are primarily focused on English. To address this issue,we introduce the concept of chat vector to equip pre-trained language modelswith instruction following and human value alignment via simple modelarithmetic. The chat vector is derived by subtracting the weights of apre-trained base model (e.g. LLaMA2) from those of its corresponding chat model(e.g. LLaMA2-chat). By simply adding the chat vector to a continual pre-trainedmodel's weights, we can endow the model with chat capabilities in new languageswithout the need for further training. Our empirical studies demonstrate thesuperior efficacy of the chat vector from three different aspects: instructionfollowing, toxicity mitigation, and multi-turn dialogue. Moreover, to showcasethe adaptability of our approach, we extend our experiments to encompassvarious languages, base models, and chat vectors. The results underscore thechat vector's simplicity, effectiveness, and wide applicability, making it acompelling solution for efficiently enabling conversational capabilities inpre-trained language models.</description><author>Shih-Cheng Huang, Pin-Zu Li, Yu-Chi Hsu, Kuang-Ming Chen, Yu Tung Lin, Shih-Kai Hsiao, Richard Tzong-Han Tsai, Hung-yi Lee</author><pubDate>Wed, 06 Mar 2024 15:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04799v2</guid></item><item><title>Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks</title><link>http://arxiv.org/abs/2403.03792v1</link><description>We introduce a new family of prompt injection attacks, termed Neural Exec.Unlike known attacks that rely on handcrafted strings (e.g., "Ignore previousinstructions and..."), we show that it is possible to conceptualize thecreation of execution triggers as a differentiable search problem and uselearning-based methods to autonomously generate them. Our results demonstrate that a motivated adversary can forge triggers thatare not only drastically more effective than current handcrafted ones but alsoexhibit inherent flexibility in shape, properties, and functionality. In thisdirection, we show that an attacker can design and generate Neural Execscapable of persisting through multi-stage preprocessing pipelines, such as inthe case of Retrieval-Augmented Generation (RAG)-based applications. Morecritically, our findings show that attackers can produce triggers that deviatemarkedly in form and shape from any known attack, sidestepping existingblacklist-based detection and sanitation approaches.</description><author>Dario Pasquini, Martin Strohmeier, Carmela Troncoso</author><pubDate>Wed, 06 Mar 2024 15:40:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03792v1</guid></item><item><title>KG-TREAT: Pre-training for Treatment Effect Estimation by Synergizing Patient Data with Knowledge Graphs</title><link>http://arxiv.org/abs/2403.03791v1</link><description>Treatment effect estimation (TEE) is the task of determining the impact ofvarious treatments on patient outcomes. Current TEE methods fall short due toreliance on limited labeled data and challenges posed by sparse andhigh-dimensional observational patient data. To address the challenges, weintroduce a novel pre-training and fine-tuning framework, KG-TREAT, whichsynergizes large-scale observational patient data with biomedical knowledgegraphs (KGs) to enhance TEE. Unlike previous approaches, KG-TREAT constructsdual-focus KGs and integrates a deep bi-level attention synergy method forin-depth information fusion, enabling distinct encoding of treatment-covariateand outcome-covariate relationships. KG-TREAT also incorporates twopre-training tasks to ensure a thorough grounding and contextualization ofpatient data and KGs. Evaluation on four downstream TEE tasks shows KG-TREAT'ssuperiority over existing methods, with an average improvement of 7% in Areaunder the ROC Curve (AUC) and 9% in Influence Function-based Precision ofEstimating Heterogeneous Effects (IF-PEHE). The effectiveness of our estimatedtreatment effects is further affirmed by alignment with established randomizedclinical trial findings.</description><author>Ruoqi Liu, Lingfei Wu, Ping Zhang</author><pubDate>Wed, 06 Mar 2024 15:37:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03791v1</guid></item><item><title>Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection from Remote Sensing Imagery</title><link>http://arxiv.org/abs/2403.03790v1</link><description>Ship detection needs to identify ship locations from remote sensing (RS)scenes. However, due to different imaging payloads, various appearances ofships, and complicated background interference from the bird's eye view, it isdifficult to set up a unified paradigm for achieving multi-source shipdetection. Therefore, in this article, considering that the large languagemodels (LLMs) emerge the powerful generalization ability, a novel unifiedvisual-language model called Popeye is proposed for multi-source ship detectionfrom RS imagery. First, to bridge the interpretation gap between multi-sourceimages for ship detection, a novel image-instruction-answer way is designed tointegrate the various ship detection ways (e.g., horizontal bounding box (HBB),oriented bounding box (OBB)) into a unified labeling paradigm. Then, in view ofthis, a cross-modal image interpretation method is developed for the proposedPopeye to enhance interactive comprehension ability between visual and languagecontent, which can be easily migrated into any multi-source ship detectiontask. Subsequently, owing to objective domain differences, a knowledge adaptionmechanism is designed to adapt the pre-trained visual-language knowledge fromthe nature scene into the RS domain for multi-source ship detection. Inaddition, the segment anything model (SAM) is also seamlessly integrated intothe proposed Popeye to achieve pixel-level ship segmentation without additionaltraining costs. Finally, extensive experiments are conducted on the newlyconstructed instruction dataset named MMShip, and the results indicate that theproposed Popeye outperforms current specialist, open-vocabulary, and othervisual-language models for zero-shot multi-source ship detection.</description><author>Wei Zhang, Miaoxin Cai, Tong Zhang, Guoqiang Lei, Yin Zhuang, Xuerui Mao</author><pubDate>Wed, 06 Mar 2024 15:35:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03790v1</guid></item><item><title>PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion</title><link>http://arxiv.org/abs/2403.03788v1</link><description>The growing dependence on Large Language Models (LLMs) for finishing userinstructions necessitates a comprehensive understanding of their robustness tocomplex task completion in real-world situations. To address this criticalneed, we propose the PowerPoint Task Completion Robustness benchmark (PPTC-R)to measure LLMs' robustness to the user PPT task instruction and softwareversion. Specifically, we construct adversarial user instructions by attackinguser instructions at sentence, semantic, and multi-language levels. To assessthe robustness of Language Models to software versions, we vary the number ofprovided APIs to simulate both the newest version and earlier version settings.Subsequently, we test 3 closed-source and 4 open-source LLMs using a benchmarkthat incorporates these robustness settings, aiming to evaluate how deviationsimpact LLMs' API calls for task completion. We find that GPT-4 exhibits thehighest performance and strong robustness in our benchmark, particularly in theversion update and the multilingual settings. However, we find that all LLMslose their robustness when confronted with multiple challenges (e.g.,multi-turn) simultaneously, leading to significant performance drops. Wefurther analyze the robustness behavior and error reasons of LLMs in ourbenchmark, which provide valuable insights for researchers to understand theLLM's robustness in task completion and develop more robust LLMs and agents. Werelease the code and data at \url{https://github.com/ZekaiGalaxy/PPTCR}.</description><author>Zekai Zhang, Yiduo Guo, Yaobo Liang, Dongyan Zhao, Nan Duan</author><pubDate>Wed, 06 Mar 2024 15:33:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03788v1</guid></item><item><title>A machine learning workflow to address credit default prediction</title><link>http://arxiv.org/abs/2403.03785v1</link><description>Due to the recent increase in interest in Financial Technology (FinTech),applications like credit default prediction (CDP) are gaining significantindustrial and academic attention. In this regard, CDP plays a crucial role inassessing the creditworthiness of individuals and businesses, enabling lendersto make informed decisions regarding loan approvals and risk management. Inthis paper, we propose a workflow-based approach to improve CDP, which refersto the task of assessing the probability that a borrower will default on his orher credit obligations. The workflow consists of multiple steps, each designedto leverage the strengths of different techniques featured in machine learningpipelines and, thus best solve the CDP task. We employ a comprehensive andsystematic approach starting with data preprocessing using Weight of Evidenceencoding, a technique that ensures in a single-shot data scaling by removingoutliers, handling missing values, and making data uniform for models workingwith different data types. Next, we train several families of learning models,introducing ensemble techniques to build more robust models and hyperparameteroptimization via multi-objective genetic algorithms to consider both predictiveaccuracy and financial aspects. Our research aims at contributing to theFinTech industry in providing a tool to move toward more accurate and reliablecredit risk assessment, benefiting both lenders and borrowers.</description><author>Rambod Rahmani, Marco Parola, Mario G. C. A. Cimino</author><pubDate>Wed, 06 Mar 2024 15:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03785v1</guid></item><item><title>Out-of-Distribution Detection using Neural Activation Prior</title><link>http://arxiv.org/abs/2402.18162v3</link><description>Out-of-distribution detection (OOD) is a crucial technique for deployingmachine learning models in the real world to handle the unseen scenarios. Inthis paper, we first propose a simple yet effective Neural Activation Prior(NAP) for OOD detection. Our neural activation prior is based on a keyobservation that, for a channel before the global pooling layer of a fullytrained neural network, the probability of a few neurons being activated with alarge response by an in-distribution (ID) sample is significantly higher thanthat by an OOD sample. An intuitive explanation is that for a model fullytrained on ID dataset, each channel would play a role in detecting a certainpattern in the ID dataset, and a few neurons can be activated with a largeresponse when the pattern is detected in an input sample. Then, a new scoringfunction based on this prior is proposed to highlight the role of thesestrongly activated neurons in OOD detection. Our approach is plug-and-play anddoes not lead to any performance degradation on ID data classification andrequires no extra training or statistics from training or external datasets.Notice that previous methods primarily rely on post-global-pooling features ofthe neural networks, while the within-channel distribution information weleverage would be discarded by the global pooling operator. Consequently, ourmethod is orthogonal to existing approaches and can be effectively combinedwith them in various applications. Experimental results show that our methodachieves the state-of-the-art performance on CIFAR benchmark and ImageNetdataset, which demonstrates the power of the proposed prior. Finally, we extendour method to Transformers and the experimental findings indicate that NAP canalso significantly enhance the performance of OOD detection on Transformers,thereby demonstrating the broad applicability of this prior knowledge.</description><author>Weilin Wan, Weizhong Zhang, Cheng Jin</author><pubDate>Wed, 06 Mar 2024 15:26:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18162v3</guid></item><item><title>Exact Fractional Inference via Re-Parametrization &amp; Interpolation between Tree-Re-Weighted- and Belief Propagation- Algorithms</title><link>http://arxiv.org/abs/2301.10369v2</link><description>Inference efforts -- required to compute partition function, $Z$, of an Isingmodel over a graph of $N$ ``spins" -- are most likely exponential in $N$.Efficient variational methods, such as Belief Propagation (BP) and TreeRe-Weighted (TRW) algorithms, compute $Z$ approximately minimizing respective(BP- or TRW-) free energy. We generalize the variational scheme building a$\lambda$-fractional-homotopy, $Z^{(\lambda)}$, where $\lambda=0$ and$\lambda=1$ correspond to TRW- and BP-approximations, respectively, and$Z^{(\lambda)}$ decreases with $\lambda$ monotonically. Moreover, thisfractional scheme guarantees that in the attractive (ferromagnetic) case$Z^{(TRW)}\geq Z^{(\lambda)}\geq Z^{(BP)}$, and there exists a unique(``exact") $\lambda_*$ such that, $Z=Z^{(\lambda_*)}$. Generalizing there-parametrization approach of \citep{wainwright_tree-based_2002} and the loopseries approach of \citep{chertkov_loop_2006}, we show how to express $Z$ as aproduct, $\forall \lambda:\ Z=Z^{(\lambda)}{\cal Z}^{(\lambda)}$, where themultiplicative correction, ${\cal Z}^{(\lambda)}$, is an expectation over anode-independent probability distribution built from node-wise fractionalmarginals. Our theoretical analysis is complemented by extensive experimentswith models from Ising ensembles over planar and random graphs of medium- andlarge- sizes. The empirical study yields a number of interesting observations,such as (a) ability to estimate ${\cal Z}^{(\lambda)}$ with $O(N^4)$ fractionalsamples; (b) suppression of $\lambda_*$ fluctuations with increase in $N$ forinstances from a particular random Ising ensemble.</description><author>Hamidreza Behjoo, Michael Chertkov</author><pubDate>Wed, 06 Mar 2024 15:25:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.10369v2</guid></item><item><title>Neural Architecture Search using Particle Swarm and Ant Colony Optimization</title><link>http://arxiv.org/abs/2403.03781v1</link><description>Neural network models have a number of hyperparameters that must be chosenalong with their architecture. This can be a heavy burden on a novice user,choosing which architecture and what values to assign to parameters. In mostcases, default hyperparameters and architectures are used. Significantimprovements to model accuracy can be achieved through the evaluation ofmultiple architectures. A process known as Neural Architecture Search (NAS) maybe applied to automatically evaluate a large number of such architectures. Asystem integrating open source tools for Neural Architecture Search (OpenNAS),in the classification of images, has been developed as part of this research.OpenNAS takes any dataset of grayscale, or RBG images, and generatesConvolutional Neural Network (CNN) architectures based on a range ofmetaheuristics using either an AutoKeras, a transfer learning or a SwarmIntelligence (SI) approach. Particle Swarm Optimization (PSO) and Ant ColonyOptimization (ACO) are used as the SI algorithms. Furthermore, models developedthrough such metaheuristics may be combined using stacking ensembles. In thecontext of this paper, we focus on training and optimizing CNNs using the SwarmIntelligence (SI) components of OpenNAS. Two major types of SI algorithms,namely PSO and ACO, are compared to see which is more effective in generatinghigher model accuracies. It is shown, with our experimental design, that thePSO algorithm performs better than ACO. The performance improvement of PSO ismost notable with a more complex dataset. As a baseline, the performance offine-tuned pre-trained models is also evaluated.</description><author>Séamus Lankford, Diarmuid Grimes</author><pubDate>Wed, 06 Mar 2024 15:23:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03781v1</guid></item><item><title>ENOT: Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport</title><link>http://arxiv.org/abs/2403.03777v1</link><description>We present a new extension for Neural Optimal Transport (NOT) trainingprocedure, capable of accurately and efficiently estimating optimaltransportation plan via specific regularisation on conjugate potentials. Themain bottleneck of existing NOT solvers is associated with the procedure offinding a near-exact approximation of the conjugate operator (i.e., thec-transform), which is done either by optimizing over maximin objectives or bythe computationally-intensive fine-tuning of the initial approximatedprediction. We resolve both issues by proposing a new, theoretically justifiedloss in the form of expectile regularization that enforces binding conditionson the learning dual potentials. Such a regularization provides the upper boundestimation over the distribution of possible conjugate potentials and makes thelearning stable, eliminating the need for additional extensive finetuning. Weformally justify the efficiency of our method, called Expectile-RegularisedNeural Optimal Transport (ENOT). ENOT outperforms previous state-of-the-artapproaches on the Wasserstein-2 benchmark tasks by a large margin (up to a3-fold improvement in quality and up to a 10-fold improvement in runtime).</description><author>Nazar Buzun, Maksim Bobrin, Dmitry V. Dylov</author><pubDate>Wed, 06 Mar 2024 15:15:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03777v1</guid></item><item><title>Parameterized Projected Bellman Operator</title><link>http://arxiv.org/abs/2312.12869v3</link><description>Approximate value iteration (AVI) is a family of algorithms for reinforcementlearning (RL) that aims to obtain an approximation of the optimal valuefunction. Generally, AVI algorithms implement an iterated procedure where eachstep consists of (i) an application of the Bellman operator and (ii) aprojection step into a considered function space. Notoriously, the Bellmanoperator leverages transition samples, which strongly determine its behavior,as uninformative samples can result in negligible updates or long detours,whose detrimental effects are further exacerbated by the computationallyintensive projection step. To address these issues, we propose a novelalternative approach based on learning an approximate version of the Bellmanoperator rather than estimating it through samples as in AVI approaches. Thisway, we are able to (i) generalize across transition samples and (ii) avoid thecomputationally intensive projection step. For this reason, we call our noveloperator projected Bellman operator (PBO). We formulate an optimization problemto learn PBO for generic sequential decision-making problems, and wetheoretically analyze its properties in two representative classes of RLproblems. Furthermore, we theoretically study our approach under the lens ofAVI and devise algorithmic implementations to learn PBO in offline and onlinesettings by leveraging neural network parameterizations. Finally, weempirically showcase the benefits of PBO w.r.t. the regular Bellman operator onseveral RL problems.</description><author>Théo Vincent, Alberto Maria Metelli, Boris Belousov, Jan Peters, Marcello Restelli, Carlo D'Eramo</author><pubDate>Wed, 06 Mar 2024 15:14:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12869v3</guid></item><item><title>ShapeLLM: Universal 3D Object Understanding for Embodied Interaction</title><link>http://arxiv.org/abs/2402.17766v2</link><description>This paper presents ShapeLLM, the first 3D Multimodal Large Language Model(LLM) designed for embodied interaction, exploring a universal 3D objectunderstanding with 3D point clouds and languages. ShapeLLM is built upon animproved 3D encoder by extending ReCon to ReCon++ that benefits from multi-viewimage distillation for enhanced geometry understanding. By utilizing ReCon++ asthe 3D point cloud input encoder for LLMs, ShapeLLM is trained on constructedinstruction-following data and tested on our newly human-curated evaluationbenchmark, 3D MM-Vet. ReCon++ and ShapeLLM achieve state-of-the-art performancein 3D geometry understanding and language-unified 3D interaction tasks, such asembodied visual grounding.</description><author>Zekun Qi, Runpei Dong, Shaochen Zhang, Haoran Geng, Chunrui Han, Zheng Ge, He Wang, Li Yi, Kaisheng Ma</author><pubDate>Wed, 06 Mar 2024 15:11:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17766v2</guid></item><item><title>Deep Reinforcement Learning with Task-Adaptive Retrieval via Hypernetwork</title><link>http://arxiv.org/abs/2306.10698v6</link><description>Deep reinforcement learning algorithms are usually impeded by samplinginefficiency, heavily depending on multiple interactions with the environmentto acquire accurate decision-making capabilities. In contrast, humans rely ontheir hippocampus to retrieve relevant information from past experiences ofrelevant tasks, which guides their decision-making when learning a new task,rather than exclusively depending on environmental interactions. Nevertheless,designing a hippocampus-like module for an agent to incorporate pastexperiences into established reinforcement learning algorithms presents twochallenges. The first challenge involves selecting the most relevant pastexperiences for the current task, and the second challenge is integrating suchexperiences into the decision network. To address these challenges, we proposea novel method that utilizes a retrieval network based on task-conditionedhypernetwork, which adapts the retrieval network's parameters depending on thetask. At the same time, a dynamic modification mechanism enhances thecollaborative efforts between the retrieval and decision networks. We evaluatethe proposed method across various tasks within a multitask scenario in theMinigrid environment. The experimental results demonstrate that our proposedmethod significantly outperforms strong baselines.</description><author>Yonggang Jin, Chenxu Wang, Tianyu Zheng, Liuyu Xiang, Yaodong Yang, Junge Zhang, Jie Fu, Zhaofeng He</author><pubDate>Wed, 06 Mar 2024 15:08:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10698v6</guid></item><item><title>VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs</title><link>http://arxiv.org/abs/2308.02117v3</link><description>GNN-to-MLP distillation aims to utilize knowledge distillation (KD) to learncomputationally-efficient multi-layer perceptron (student MLP) on graph data bymimicking the output representations of teacher GNN. Existing methods mainlymake the MLP to mimic the GNN predictions over a few class labels. However, theclass space may not be expressive enough for covering numerous diverse localgraph structures, thus limiting the performance of knowledge transfer from GNNto MLP. To address this issue, we propose to learn a new powerful graphrepresentation space by directly labeling nodes' diverse local structures forGNN-to-MLP distillation. Specifically, we propose a variant of VQ-VAE to learna structure-aware tokenizer on graph data that can encode each node's localsubstructure as a discrete code. The discrete codes constitute a codebook as anew graph representation space that is able to identify different local graphstructures of nodes with the corresponding code indices. Then, based on thelearned codebook, we propose a new distillation target, namely soft codeassignments, to directly transfer the structural knowledge of each node fromGNN to MLP. The resulting framework VQGraph achieves new state-of-the-artperformance on GNN-to-MLP distillation in both transductive and inductivesettings across seven graph datasets. We show that VQGraph with betterperformance infers faster than GNNs by 828x, and also achieves accuracyimprovement over GNNs and stand-alone MLPs by 3.90% and 28.05% on average,respectively. Code: https://github.com/YangLing0818/VQGraph.</description><author>Ling Yang, Ye Tian, Minkai Xu, Zhongyi Liu, Shenda Hong, Wei Qu, Wentao Zhang, Bin Cui, Muhan Zhang, Jure Leskovec</author><pubDate>Wed, 06 Mar 2024 15:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02117v3</guid></item><item><title>Verified Training for Counterfactual Explanation Robustness under Data Shift</title><link>http://arxiv.org/abs/2403.03773v1</link><description>Counterfactual explanations (CEs) enhance the interpretability of machinelearning models by describing what changes to an input are necessary to changeits prediction to a desired class. These explanations are commonly used toguide users' actions, e.g., by describing how a user whose loan application wasdenied can be approved for a loan in the future. Existing approaches generateCEs by focusing on a single, fixed model, and do not provide any formalguarantees on the CEs' future validity. When models are updated periodically toaccount for data shift, if the generated CEs are not robust to the shifts,users' actions may no longer have the desired impacts on their predictions.This paper introduces VeriTraCER, an approach that jointly trains a classifierand an explainer to explicitly consider the robustness of the generated CEs tosmall model shifts. VeriTraCER optimizes over a carefully designed lossfunction that ensures the verifiable robustness of CEs to local model updates,thus providing deterministic guarantees to CE validity. Our empiricalevaluation demonstrates that VeriTraCER generates CEs that (1) are verifiablyrobust to small model updates and (2) display competitive robustness tostate-of-the-art approaches in handling empirical model updates includingrandom initialization, leave-one-out, and distribution shifts.</description><author>Anna P. Meyer, Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni</author><pubDate>Wed, 06 Mar 2024 15:06:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03773v1</guid></item><item><title>AcceleratedLiNGAM: Learning Causal DAGs at the speed of GPUs</title><link>http://arxiv.org/abs/2403.03772v1</link><description>Existing causal discovery methods based on combinatorial optimization orsearch are slow, prohibiting their application on large-scale datasets. Inresponse, more recent methods attempt to address this limitation by formulatingcausal discovery as structure learning with continuous optimization but suchapproaches thus far provide no statistical guarantees. In this paper, we showthat by efficiently parallelizing existing causal discovery methods, we can infact scale them to thousands of dimensions, making them practical forsubstantially larger-scale problems. In particular, we parallelize the LiNGAMmethod, which is quadratic in the number of variables, obtaining up to a32-fold speed-up on benchmark datasets when compared with existing sequentialimplementations. Specifically, we focus on the causal ordering subprocedure inDirectLiNGAM and implement GPU kernels to accelerate it. This allows us toapply DirectLiNGAM to causal inference on large-scale gene expression data withgenetic interventions yielding competitive results compared with specializedcontinuous optimization methods, and Var-LiNGAM for causal discovery on U.S.stock data.</description><author>Victor Akinwande, J. Zico Kolter</author><pubDate>Wed, 06 Mar 2024 15:06:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03772v1</guid></item><item><title>Joint Sparsity Pattern Learning Based Channel Estimation for Massive MIMO-OTFS Systems</title><link>http://arxiv.org/abs/2403.03771v1</link><description>We propose a channel estimation scheme based on joint sparsity patternlearning (JSPL) for massive multi-input multi-output (MIMO) orthogonaltime-frequency-space (OTFS) modulation aided systems. By exploiting thepotential joint sparsity of the delay-Doppler-angle (DDA) domain channel, thechannel estimation problem is transformed into a sparse recovery problem. Tosolve it, we first apply the spike and slab prior model to iteratively estimatethe support set of the channel matrix, and a higher-accuracy parameter updaterule relying on the identified support set is introduced into the iteration.Then the specific values of the channel elements corresponding to the supportset are estimated by the orthogonal matching pursuit (OMP) method. Both oursimulation results and analysis demonstrate that the proposed JSPL channelestimation scheme achieves an improved performance over the representativestate-of-the-art baseline schemes, despite its reduced pilot overhead.</description><author>Kuo Meng, Shaoshi Yang, Xiao-Yang Wang, Yan Bu, Yurong Tang, Jianhua Zhang, Lajos Hanzo</author><pubDate>Wed, 06 Mar 2024 15:05:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03771v1</guid></item><item><title>DeepCRE: Revolutionizing Drug R&amp;D with Cutting-Edge Computational Models</title><link>http://arxiv.org/abs/2403.03768v1</link><description>The field of pharmaceutical development and therapeutic application both facesubstantial challenges. Therapeutic domain calls for more treatmentalternatives while numerous promising pre-clinical drugs fail in clinicaltrails. One of the reasons is the inadequacy of Cross-drug Response Evaluation(CRE) during the late stage of drug development. Although in-silico CRE modelsoffer a solution to this problem, existing methodologies are either limited toearly development stages or lack the capacity for a comprehensive CRE analysis.Herein, we introduce a novel computational model named DeepCRE and present thepotential of DeepCRE in advancing therapeutic discovery and development.DeepCRE outperforms the existing best models by achieving an averageperformance improvement of 17.7\% in patient-level CRE, and a 5-fold increasein indication-level CRE. Furthermore, DeepCRE has identified six drugcandidates that show significantly greater effectiveness than a comparator setof two approved drug in 5/8 colorectal cancer (CRC) organoids. This highlightsDeepCRE's ability to identify a collection of drug candidates with superiortherapeutic effects, underscoring its potential to revolutionize the field oftherapeutic development.</description><author>Yushuai Wu</author><pubDate>Wed, 06 Mar 2024 15:03:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03768v1</guid></item><item><title>Predicting the Temperature Dependence of Surfactant CMCs Using Graph Neural Networks</title><link>http://arxiv.org/abs/2403.03767v1</link><description>The critical micelle concentration (CMC) of surfactant molecules is anessential property for surfactant applications in industry. Recently, classicalQSPR and Graph Neural Networks (GNNs), a deep learning technique, have beensuccessfully applied to predict the CMC of surfactants at room temperature.However, these models have not yet considered the temperature dependency of theCMC, which is highly relevant for practical applications. We herein develop aGNN model for temperature-dependent CMC prediction of surfactants. We collectabout 1400 data points from public sources for all surfactant classes, i.e.,ionic, nonionic, and zwitterionic, at multiple temperatures. We test thepredictive quality of the model for following scenarios: i) when CMC data forsurfactants are present in the training of the model in at least one differenttemperature, and ii) CMC data for surfactants are not present in the training,i.e., generalizing to unseen surfactants. In both test scenarios, our modelexhibits a high predictive performance of R$^2 \geq $ 0.94 on test data. Wealso find that the model performance varies by surfactant class. Finally, weevaluate the model for sugar-based surfactants with complex molecularstructures, as these represent a more sustainable alternative to syntheticsurfactants and are therefore of great interest for future applications in thepersonal and home care industries.</description><author>Christoforos Brozos, Jan G. Rittig, Sandip Bhattacharya, Elie Akanny, Christina Kohlmann, Alexander Mitsos</author><pubDate>Wed, 06 Mar 2024 15:03:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03767v1</guid></item><item><title>Neural Koopman prior for data assimilation</title><link>http://arxiv.org/abs/2309.05317v2</link><description>With the increasing availability of large scale datasets, computational powerand tools like automatic differentiation and expressive neural networkarchitectures, sequential data are now often treated in a data-driven way, witha dynamical model trained from the observation data. While neural networks areoften seen as uninterpretable black-box architectures, they can still benefitfrom physical priors on the data and from mathematical knowledge. In thispaper, we use a neural network architecture which leverages the long-knownKoopman operator theory to embed dynamical systems in latent spaces where theirdynamics can be described linearly, enabling a number of appealing features. Weintroduce methods that enable to train such a model for long-term continuousreconstruction, even in difficult contexts where the data comes inirregularly-sampled time series. The potential for self-supervised learning isalso demonstrated, as we show the promising use of trained dynamical models aspriors for variational data assimilation techniques, with applications to e.g.time series interpolation and forecasting.</description><author>Anthony Frion, Lucas Drumetz, Mauro Dalla Mura, Guillaume Tochon, Abdeldjalil Aïssa El Bey</author><pubDate>Wed, 06 Mar 2024 14:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05317v2</guid></item><item><title>CWTM: Leveraging Contextualized Word Embeddings from BERT for Neural Topic Modeling</title><link>http://arxiv.org/abs/2305.09329v3</link><description>Most existing topic models rely on bag-of-words (BOW) representation, whichlimits their ability to capture word order information and leads to challengeswith out-of-vocabulary (OOV) words in new documents. Contextualized wordembeddings, however, show superiority in word sense disambiguation andeffectively address the OOV issue. In this work, we introduce a novel neuraltopic model called the Contextlized Word Topic Model (CWTM), which integratescontextualized word embeddings from BERT. The model is capable of learning thetopic vector of a document without BOW information. In addition, it can alsoderive the topic vectors for individual words within a document based on theircontextualized word embeddings. Experiments across various datasets show thatCWTM generates more coherent and meaningful topics compared to existing topicmodels, while also accommodating unseen words in newly encountered documents.</description><author>Zheng Fang, Yulan He, Rob Procter</author><pubDate>Wed, 06 Mar 2024 14:56:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09329v3</guid></item><item><title>Residual Multi-Fidelity Neural Network Computing</title><link>http://arxiv.org/abs/2310.03572v2</link><description>In this work, we consider the general problem of constructing a neuralnetwork surrogate model using multi-fidelity information. Motivated by rigorouserror and complexity estimates for ReLU neural networks, given an inexpensivelow-fidelity and an expensive high-fidelity computational model, we present aresidual multi-fidelity computational framework that formulates the correlationbetween models as a residual function, a possibly non-linear mapping between 1)the shared input space of the models together with the low-fidelity modeloutput and 2) the discrepancy between the two model outputs. To accomplishthis, we train two neural networks to work in concert. The first network learnsthe residual function on a small set of high-fidelity and low-fidelity data.Once trained, this network is used to generate additional synthetichigh-fidelity data, which is used in the training of a second network. Thissecond network, once trained, acts as our surrogate for the high-fidelityquantity of interest. We present three numerical examples to demonstrate thepower of the proposed framework. In particular, we show that dramatic savingsin computational cost may be achieved when the output predictions are desiredto be accurate within small tolerances.</description><author>Owen Davis, Mohammad Motamed, Raul Tempone</author><pubDate>Wed, 06 Mar 2024 14:54:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03572v2</guid></item><item><title>Parameterized quantum comb and simpler circuits for reversing unknown qubit-unitary operations</title><link>http://arxiv.org/abs/2403.03761v1</link><description>Quantum comb is an essential tool for characterizing complex quantumprotocols in quantum information processing. In this work, we introduce PQComb,a framework leveraging parameterized quantum circuits to explore thecapabilities of quantum combs for general quantum process transformation tasksand beyond. By optimizing PQComb for time-reversal simulations of unknownunitary evolutions, we develop a simpler protocol for unknown qubit unitaryinversion that reduces the ancilla qubit overhead from 6 to 3 compared to theexisting method in [Yoshida, Soeda, Murao, PRL 131, 120602, 2023]. Thisdemonstrates the utility of quantum comb structures and showcases PQComb'spotential for solving complex quantum tasks. Our results pave the way forbroader PQComb applications in quantum computing and quantum information,emphasizing its versatility for tackling diverse problems in quantum machinelearning.</description><author>Yin Mo, Lei Zhang, Yu-Ao Chen, Yingjian Liu, Tengxiang Lin, Xin Wang</author><pubDate>Wed, 06 Mar 2024 14:53:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03761v1</guid></item><item><title>$Se^2$: Sequential Example Selection for In-Context Learning</title><link>http://arxiv.org/abs/2402.13874v2</link><description>The remarkable capability of large language models (LLMs) for in-contextlearning (ICL) needs to be activated by demonstration examples. Prior work hasextensively explored the selection of examples for ICL, predominantly followingthe "select then organize" paradigm, such approaches often neglect the internalrelationships between examples and exist an inconsistency between the trainingand inference. In this paper, we formulate the problem as a$\textit{se}$quential $\textit{se}$lection problem and introduce $Se^2$, asequential-aware method that leverages the LLM's feedback on varying context,aiding in capturing inter-relationships and sequential information amongexamples, significantly enriching the contextuality and relevance of ICLprompts. Meanwhile, we utilize beam search to seek and construct examplesequences, enhancing both quality and diversity. Extensive experiments across23 NLP tasks from 8 distinct categories illustrate that $Se^2$ markedlysurpasses competitive baselines and achieves 42% relative improvement overrandom selection. Further in-depth analysis show the effectiveness of proposedstrategies, highlighting $Se^2$'s exceptional stability and adaptability acrossvarious scenarios. Our code will be released to facilitate future research.</description><author>Haoyu Liu, Jianfeng Liu, Shaohan Huang, Yuefeng Zhan, Hao Sun, Weiwei Deng, Furu Wei, Qi Zhang</author><pubDate>Wed, 06 Mar 2024 14:46:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13874v2</guid></item><item><title>German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset</title><link>http://arxiv.org/abs/2403.03750v1</link><description>The advent of Large Language Models (LLMs) has led to remarkable progress ona wide range of natural language processing tasks. Despite the advances, theselarge-sized models still suffer from hallucinating information in their output,which poses a major issue in automatic text summarization, as we must guaranteethat the generated summary is consistent with the content of the sourcedocument. Previous research addresses the challenging task of detectinghallucinations in the output (i.e. inconsistency detection) in order toevaluate the faithfulness of the generated summaries. However, these worksprimarily focus on English and recent multilingual approaches lack German data.This work presents absinth, a manually annotated dataset for hallucinationdetection in German news summarization and explores the capabilities of novelopen-source LLMs on this task in both fine-tuning and in-context learningsettings. We open-source and release the absinth dataset to foster furtherresearch on hallucination detection in German.</description><author>Laura Mascarell, Ribin Chalumattu, Annette Rios</author><pubDate>Wed, 06 Mar 2024 14:37:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03750v1</guid></item><item><title>Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm</title><link>http://arxiv.org/abs/2402.15653v2</link><description>While convolutional neural networks (CNNs) have achieved success in computervision tasks, it is vulnerable to backdoor attacks. Such attacks could misleadthe victim model to make attacker-chosen prediction with a specific triggerpattern. Until now, the trigger injection of existing attacks is mainly limitedto spatial domain. Recent works take advantage of perceptual properties ofplanting specific patterns in the frequency domain, which only reflectindistinguishable pixel-wise perturbations in pixel domain. However, in theblack-box setup, the inaccessibility of training process often renders morecomplex trigger designs. Existing frequency attacks simply handcraft themagnitude of spectrum, introducing anomaly frequency disparities between cleanand poisoned data and taking risks of being removed by image processingoperations (such as lossy compression and filtering). In this paper, we proposea robust low-frequency black-box backdoor attack (LFBA), which minimallyperturbs low-frequency components of frequency spectrum and maintains theperceptual similarity in spatial space simultaneously. The key insight of ourattack restrict the search for the optimal trigger to low-frequency region thatcan achieve high attack effectiveness, robustness against image transformationdefenses and stealthiness in dual space. We utilize simulated annealing (SA), aform of evolutionary algorithm, to optimize the properties of frequency triggerincluding the number of manipulated frequency bands and the perturbation ofeach frequency component, without relying on the knowledge from the victimclassifier. Extensive experiments on real-world datasets verify theeffectiveness and robustness of LFBA against image processing operations andthe state-of-the-art backdoor defenses, as well as its inherent stealthiness inboth spatial and frequency space, making it resilient against frequencyinspection.</description><author>Yanqi Qiao, Dazhuang Liu, Rui Wang, Kaitai Liang</author><pubDate>Wed, 06 Mar 2024 14:35:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15653v2</guid></item><item><title>Towards Safe and Aligned Large Language Models for Medicine</title><link>http://arxiv.org/abs/2403.03744v1</link><description>The capabilities of large language models (LLMs) have been progressing at abreathtaking speed, leaving even their own developers grappling with the depthof their potential and risks. While initial steps have been taken to evaluatethe safety and alignment of general-knowledge LLMs, exposing some weaknesses,to our knowledge, the safety and alignment of medical LLMs has not beenevaluated despite their risks for personal health and safety, public health andsafety, and human rights. To this end, we carry out the first safety evaluationfor medical LLMs. Specifically, we set forth a definition of medical safety andalignment for medical artificial intelligence systems, develop a dataset ofharmful medical questions to evaluate the medical safety and alignment of anLLM, evaluate both general and medical safety and alignment of medical LLMs,demonstrate fine-tuning as an effective mitigation strategy, and discussbroader, large-scale approaches used by the machine learning community todevelop safe and aligned LLMs. We hope that this work casts light on the safetyand alignment of medical LLMs and motivates future work to study it and developadditional mitigation strategies, minimizing the risks of harm of LLMs inmedicine.</description><author>Tessa Han, Aounon Kumar, Chirag Agarwal, Himabindu Lakkaraju</author><pubDate>Wed, 06 Mar 2024 14:34:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03744v1</guid></item><item><title>SUPClust: Active Learning at the Boundaries</title><link>http://arxiv.org/abs/2403.03741v1</link><description>Active learning is a machine learning paradigm designed to optimize modelperformance in a setting where labeled data is expensive to acquire. In thiswork, we propose a novel active learning method called SUPClust that seeks toidentify points at the decision boundary between classes. By targeting thesepoints, SUPClust aims to gather information that is most informative forrefining the model's prediction of complex decision regions. We demonstrateexperimentally that labeling these points leads to strong model performance.This improvement is observed even in scenarios characterized by strong classimbalance.</description><author>Yuta Ono, Till Aczel, Benjamin Estermann, Roger Wattenhofer</author><pubDate>Wed, 06 Mar 2024 14:30:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03741v1</guid></item></channel></rss>