<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 28 Aug 2024 01:00:33 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>A domain decomposition-based autoregressive deep learning model for unsteady and nonlinear partial differential equations</title><link>http://arxiv.org/abs/2408.14461v2</link><description>In this paper, we propose a domain-decomposition-based deep learning (DL)framework, named transient-CoMLSim, for accurately modeling unsteady andnonlinear partial differential equations (PDEs). The framework consists of twokey components: (a) a convolutional neural network (CNN)-based autoencoderarchitecture and (b) an autoregressive model composed of fully connectedlayers. Unlike existing state-of-the-art methods that operate on the entirecomputational domain, our CNN-based autoencoder computes a lower-dimensionalbasis for solution and condition fields represented on subdomains. Timesteppingis performed entirely in the latent space, generating embeddings of thesolution variables from the time history of embeddings of solution andcondition variables. This approach not only reduces computational complexitybut also enhances scalability, making it well-suited for large-scalesimulations. Furthermore, to improve the stability of our rollouts, we employ acurriculum learning (CL) approach during the training of the autoregressivemodel. The domain-decomposition strategy enables scaling to out-of-distributiondomain sizes while maintaining the accuracy of predictions -- a feature noteasily integrated into popular DL-based approaches for physics simulations. Webenchmark our model against two widely-used DL architectures, Fourier NeuralOperator (FNO) and U-Net, and demonstrate that our framework outperforms themin terms of accuracy, extrapolation to unseen timesteps, and stability for awide range of use cases.</description><author>Sheel Nidhan, Haoliang Jiang, Lalit Ghule, Clancy Umphrey, Rishikesh Ranade, Jay Pathak</author><pubDate>Tue, 27 Aug 2024 16:43:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14461v2</guid></item><item><title>CNN-Transformer Rectified Collaborative Learning for Medical Image Segmentation</title><link>http://arxiv.org/abs/2408.13698v2</link><description>Automatic and precise medical image segmentation (MIS) is of vital importancefor clinical diagnosis and analysis. Current MIS methods mainly rely on theconvolutional neural network (CNN) or self-attention mechanism (Transformer)for feature modeling. However, CNN-based methods suffer from the inaccuratelocalization owing to the limited global dependency while Transformer-basedmethods always present the coarse boundary for the lack of local emphasis.Although some CNN-Transformer hybrid methods are designed to synthesize thecomplementary local and global information for better performance, thecombination of CNN and Transformer introduces numerous parameters and increasesthe computation cost. To this end, this paper proposes a CNN-Transformerrectified collaborative learning (CTRCL) framework to learn stronger CNN-basedand Transformer-based models for MIS tasks via the bi-directional knowledgetransfer between them. Specifically, we propose a rectified logit-wisecollaborative learning (RLCL) strategy which introduces the ground truth toadaptively select and rectify the wrong regions in student soft labels foraccurate knowledge transfer in the logit space. We also propose a class-awarefeature-wise collaborative learning (CFCL) strategy to achieve effectiveknowledge transfer between CNN-based and Transformer-based models in thefeature space by granting their intermediate features the similar capability ofcategory perception. Extensive experiments on three popular MIS benchmarksdemonstrate that our CTRCL outperforms most state-of-the-art collaborativelearning methods under different evaluation metrics.</description><author>Lanhu Wu, Miao Zhang, Yongri Piao, Zhenyan Yao, Weibing Sun, Feng Tian, Huchuan Lu</author><pubDate>Tue, 27 Aug 2024 16:11:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13698v2</guid></item><item><title>RT-Attack: Jailbreaking Text-to-Image Models via Random Token</title><link>http://arxiv.org/abs/2408.13896v2</link><description>Recently, Text-to-Image(T2I) models have achieved remarkable success in imagegeneration and editing, yet these models still have many potential issues,particularly in generating inappropriate or Not-Safe-For-Work(NSFW) content.Strengthening attacks and uncovering such vulnerabilities can advance thedevelopment of reliable and practical T2I models. Most of the previous workstreat T2I models as white-box systems, using gradient optimization to generateadversarial prompts. However, accessing the model's gradient is oftenimpossible in real-world scenarios. Moreover, existing defense methods, thoseusing gradient masking, are designed to prevent attackers from obtainingaccurate gradient information. While some black-box jailbreak attacks have beenexplored, these typically rely on simply replacing sensitive words, leading tosuboptimal attack performance. To address this issue, we introduce a two-stagequery-based black-box attack method utilizing random search. In the firststage, we establish a preliminary prompt by maximizing the semantic similaritybetween the adversarial and target harmful prompts. In the second stage, we usethis initial prompt to refine our approach, creating a detailed adversarialprompt aimed at jailbreaking and maximizing the similarity in image featuresbetween the images generated from this prompt and those produced by the targetharmful prompt. Extensive experiments validate the effectiveness of our methodin attacking the latest prompt checkers, post-hoc image checkers, securelytrained T2I models, and online commercial models.</description><author>Sensen Gao, Xiaojun Jia, Yihao Huang, Ranjie Duan, Jindong Gu, Yang Liu, Qing Guo</author><pubDate>Tue, 27 Aug 2024 15:13:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13896v2</guid></item><item><title>Time Series Analysis for Education: Methods, Applications, and Future Directions</title><link>http://arxiv.org/abs/2408.13960v2</link><description>Recent advancements in the collection and analysis of sequential educationaldata have brought time series analysis to a pivotal position in educationalresearch, highlighting its essential role in facilitating data-drivendecision-making. However, there is a lack of comprehensive summaries thatconsolidate these advancements. To the best of our knowledge, this paper is thefirst to provide a comprehensive review of time series analysis techniquesspecifically within the educational context. We begin by exploring thelandscape of educational data analytics, categorizing various data sources andtypes relevant to education. We then review four prominent time seriesmethods-forecasting, classification, clustering, and anomalydetection-illustrating their specific application points in educationalsettings. Subsequently, we present a range of educational scenarios andapplications, focusing on how these methods are employed to address diverseeducational tasks, which highlights the practical integration of multiple timeseries methods to solve complex educational problems. Finally, we conclude witha discussion on future directions, including personalized learning analytics,multimodal data fusion, and the role of large language models (LLMs) ineducational time series. The contributions of this paper include a detailedtaxonomy of educational data, a synthesis of time series techniques withspecific educational applications, and a forward-looking perspective onemerging trends and future research opportunities in educational analysis. Therelated papers and resources are available and regularly updated at the projectpage.</description><author>Shengzhong Mao, Chaoli Zhang, Yichi Song, Jindong Wang, Xiao-Jun Zeng, Zenglin Xu, Qingsong Wen</author><pubDate>Tue, 27 Aug 2024 15:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13960v2</guid></item><item><title>Consistent machine learning for topology optimization with microstructure-dependent neural network material models</title><link>http://arxiv.org/abs/2408.13843v2</link><description>Additive manufacturing methods together with topology optimization haveenabled the creation of multiscale structures with controlled spatially-varyingmaterial microstructure. However, topology optimization or inverse design ofsuch structures in the presence of nonlinearities remains a challenge due tothe expense of computational homogenization methods and the complexity ofdifferentiably parameterizing the microstructural response. A solution to thischallenge lies in machine learning techniques that offer efficient,differentiable mappings between the material response and its microstructuraldescriptors. This work presents a framework for designing multiscaleheterogeneous structures with spatially varying microstructures by merging ahomogenization-based topology optimization strategy with a consistent machinelearning approach grounded in hyperelasticity theory. We leverage neuralarchitectures that adhere to critical physical principles such aspolyconvexity, objectivity, material symmetry, and thermodynamic consistency tosupply the framework with a reliable constitutive model that is dependent onmaterial microstructural descriptors. Our findings highlight the potential ofintegrating consistent machine learning models with density-based topologyoptimization for enhancing design optimization of heterogeneous hyperelasticstructures under finite deformations.</description><author>Harikrishnan Vijayakumaran, Jonathan B. Russ, Glaucio H. Paulino, Miguel A. Bessa</author><pubDate>Tue, 27 Aug 2024 14:24:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13843v2</guid></item><item><title>Recent Event Camera Innovations: A Survey</title><link>http://arxiv.org/abs/2408.13627v2</link><description>Event-based vision, inspired by the human visual system, offerstransformative capabilities such as low latency, high dynamic range, andreduced power consumption. This paper presents a comprehensive survey of eventcameras, tracing their evolution over time. It introduces the fundamentalprinciples of event cameras, compares them with traditional frame cameras, andhighlights their unique characteristics and operational differences. The surveycovers various event camera models from leading manufacturers, keytechnological milestones, and influential research contributions. It exploresdiverse application areas across different domains and discusses essentialreal-world and synthetic datasets for research advancement. Additionally, therole of event camera simulators in testing and development is discussed. Thissurvey aims to consolidate the current state of event cameras and inspirefurther innovation in this rapidly evolving field. To support the researchcommunity, a GitHub page(https://github.com/chakravarthi589/Event-based-Vision_Resources) categorizespast and future research articles and consolidates valuable resources.</description><author>Bharatesh Chakravarthi, Aayush Atul Verma, Kostas Daniilidis, Cornelia Fermuller, Yezhou Yang</author><pubDate>Tue, 27 Aug 2024 14:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13627v2</guid></item><item><title>Foundation Models for Music: A Survey</title><link>http://arxiv.org/abs/2408.14340v2</link><description>In recent years, foundation models (FMs) such as large language models (LLMs)and latent diffusion models (LDMs) have profoundly impacted diverse sectors,including music. This comprehensive review examines state-of-the-art (SOTA)pre-trained models and foundation models in music, spanning from representationlearning, generative learning and multimodal learning. We first contextualisethe significance of music in various industries and trace the evolution of AIin music. By delineating the modalities targeted by foundation models, wediscover many of the music representations are underexplored in FM development.Then, emphasis is placed on the lack of versatility of previous methods ondiverse music applications, along with the potential of FMs in musicunderstanding, generation and medical application. By comprehensively exploringthe details of the model pre-training paradigm, architectural choices,tokenisation, finetuning methodologies and controllability, we emphasise theimportant topics that should have been well explored, like instruction tuningand in-context learning, scaling law and emergent ability, as well aslong-sequence modelling etc. A dedicated section presents insights into musicagents, accompanied by a thorough analysis of datasets and evaluationsessential for pre-training and downstream tasks. Finally, by underscoring thevital importance of ethical considerations, we advocate that following researchon FM for music should focus more on such issues as interpretability,transparency, human responsibility, and copyright issues. The paper offersinsights into future challenges and trends on FMs for music, aiming to shapethe trajectory of human-AI collaboration in the music realm.</description><author>Yinghao Ma, Anders Øland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elio Quinton, Elona Shatri, Fabio Morreale, Ge Zhang, György Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wenhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang</author><pubDate>Tue, 27 Aug 2024 14:09:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14340v2</guid></item><item><title>Enhancing Uplift Modeling in Multi-Treatment Marketing Campaigns: Leveraging Score Ranking and Calibration Techniques</title><link>http://arxiv.org/abs/2408.13628v2</link><description>Uplift modeling is essential for optimizing marketing strategies by selectingindividuals likely to respond positively to specific marketing campaigns. Thisimportance escalates in multi-treatment marketing campaigns, where diversetreatment is available and we may want to assign the customers to treatmentthat can make the most impact. While there are existing approaches withconvenient frameworks like Causalml, there are potential spaces to enhance theeffect of uplift modeling in multi treatment cases. This paper introduces anovel approach to uplift modeling in multi-treatment campaigns, leveragingscore ranking and calibration techniques to improve overall performance of themarketing campaign. We review existing uplift models, including Meta Learnerframeworks (S, T, X), and their application in real-world scenarios.Additionally, we delve into insights from multi-treatment studies to highlightthe complexities and potential advancements in the field. Our methodologyincorporates Meta-Learner calibration and a scoring rank-based offer selectionstrategy. Extensive experiment results with real-world datasets demonstrate thepractical benefits and superior performance of our approach. The findingsunderscore the critical role of integrating score ranking and calibrationtechniques in refining the performance and reliability of uplift predictions,thereby advancing predictive modeling in marketing analytics and providingactionable insights for practitioners seeking to optimize their campaignstrategies.</description><author>Yoon Tae Park, Ting Xu, Mohamed Anany</author><pubDate>Tue, 27 Aug 2024 12:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13628v2</guid></item><item><title>Compressed Federated Reinforcement Learning with a Generative Model</title><link>http://arxiv.org/abs/2404.10635v5</link><description>Reinforcement learning has recently gained unprecedented popularity, yet itstill grapples with sample inefficiency. Addressing this challenge, federatedreinforcement learning (FedRL) has emerged, wherein agents collaborativelylearn a single policy by aggregating local estimations. However, thisaggregation step incurs significant communication costs. In this paper, wepropose CompFedRL, a communication-efficient FedRL approach incorporating both\textit{periodic aggregation} and (direct/error-feedback) compressionmechanisms. Specifically, we consider compressed federated $Q$-learning with agenerative model setup, where a central server learns an optimal $Q$-functionby periodically aggregating compressed $Q$-estimates from local agents. For thefirst time, we characterize the impact of these two mechanisms (which haveremained elusive) by providing a finite-time analysis of our algorithm,demonstrating strong convergence behaviors when utilizing either direct orerror-feedback compression. Our bounds indicate improved solution accuracyconcerning the number of agents and other federated hyperparameters whilesimultaneously reducing communication costs. To corroborate our theory, we alsoconduct in-depth numerical experiments to verify our findings, consideringTop-$K$ and Sparsified-$K$ sparsification operators.</description><author>Ali Beikmohammadi, Sarit Khirirat, Sindri Magnússon</author><pubDate>Tue, 27 Aug 2024 12:12:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10635v5</guid></item><item><title>Text3DAug -- Prompted Instance Augmentation for LiDAR Perception</title><link>http://arxiv.org/abs/2408.14253v2</link><description>LiDAR data of urban scenarios poses unique challenges, such as heterogeneouscharacteristics and inherent class imbalance. Therefore, large-scale datasetsare necessary to apply deep learning methods. Instance augmentation has emergedas an efficient method to increase dataset diversity. However, current methodsrequire the time-consuming curation of 3D models or costly manual dataannotation. To overcome these limitations, we propose Text3DAug, a novelapproach leveraging generative models for instance augmentation. Text3DAug doesnot depend on labeled data and is the first of its kind to generate instancesand annotations from text. This allows for a fully automated pipeline,eliminating the need for manual effort in practical applications. Additionally,Text3DAug is sensor agnostic and can be applied regardless of the LiDAR sensorused. Comprehensive experimental analysis on LiDAR segmentation, detection andnovel class discovery demonstrates that Text3DAug is effective in supplementingexisting methods or as a standalone method, performing on par or better thanestablished methods, however while overcoming their specific drawbacks. Thecode is publicly available.</description><author>Laurenz Reichardt, Luca Uhr, Oliver Wasenmüller</author><pubDate>Tue, 27 Aug 2024 10:50:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14253v2</guid></item><item><title>Estimating Causal Effects from Learned Causal Networks</title><link>http://arxiv.org/abs/2408.14101v2</link><description>The standard approach to answering an identifiable causal-effect query (e.g.,$P(Y|do(X)$) when given a causal diagram and observational data is to firstgenerate an estimand, or probabilistic expression over the observablevariables, which is then evaluated using the observational data. In this paper,we propose an alternative paradigm for answering causal-effect queries overdiscrete observable variables. We propose to instead learn the causal Bayesiannetwork and its confounding latent variables directly from the observationaldata. Then, efficient probabilistic graphical model (PGM) algorithms can beapplied to the learned model to answer queries. Perhaps surprisingly, we showthat this \emph{model completion} learning approach can be more effective thanestimand approaches, particularly for larger models in which the estimandexpressions become computationally difficult. We illustrate our method's potential using a benchmark collection of Bayesiannetworks and synthetically generated causal models.</description><author>Anna Raichev, Alexander Ihler, Jin Tian, Rina Dechter</author><pubDate>Tue, 27 Aug 2024 09:54:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14101v2</guid></item><item><title>Exploring Cross-model Neuronal Correlations in the Context of Predicting Model Performance and Generalizability</title><link>http://arxiv.org/abs/2408.08448v3</link><description>As Artificial Intelligence (AI) models are increasingly integrated intocritical systems, the need for a robust framework to establish thetrustworthiness of AI is increasingly paramount. While collaborative effortshave established conceptual foundations for such a framework, there remains asignificant gap in developing concrete, technically robust methods forassessing AI model quality and performance. A critical drawback in thetraditional methods for assessing the validity and generalizability of modelsis their dependence on internal developer datasets, rendering it challenging toindependently assess and verify their performance claims. This paper introducesa novel approach for assessing a newly trained model's performance based onanother known model by calculating correlation between neural networks. Theproposed method evaluates correlations by determining if, for each neuron inone network, there exists a neuron in the other network that produces similaroutput. This approach has implications for memory efficiency, allowing for theuse of smaller networks when high correlation exists between networks ofdifferent sizes. Additionally, the method provides insights into robustness,suggesting that if two highly correlated networks are compared and onedemonstrates robustness when operating in production environments, the other islikely to exhibit similar robustness. This contribution advances the technicaltoolkit for responsible AI, supporting more comprehensive and nuancedevaluations of AI models to ensure their safe and effective deployment. Code isavailable at https://github.com/aheldis/Cross-model-correlation.git.</description><author>Haniyeh Ehsani Oskouie, Lionel Levine, Majid Sarrafzadeh</author><pubDate>Tue, 27 Aug 2024 09:04:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08448v3</guid></item><item><title>Enhancing Robustness of Human Detection Algorithms in Maritime SAR through Augmented Aerial Images to Simulate Weather Conditions</title><link>http://arxiv.org/abs/2408.13766v2</link><description>7,651 cases of Search and Rescue Missions (SAR) were reported by the UnitedStates Coast Guard in 2024, with over 1322 SAR helicopters deployed in the 6first months alone. Through the utilizations of YOLO, we were able to rundifferent weather conditions and lighting from our augmented dataset fortraining. YOLO then utilizes CNNs to apply a series of convolutions and poolinglayers to the input image, where the convolution layers are able to extract themain features of the image. Through this, our YOLO model is able to learn todifferentiate different objects which may considerably improve its accuracy,possibly enhancing the efficiency of SAR operations through enhanced detectionaccuracy. This paper aims to improve the model's accuracy of human detection inmaritime SAR by evaluating a robust datasets containing various elevations andgeological locations, as well as through data augmentation which simulatesdifferent weather and lighting. We observed that models trained on augmenteddatasets outperformed their non-augmented counterparts in which the humanrecall scores ranged from 0.891 to 0.911 with an improvement rate of 3.4\% onthe YOLOv5l model. Results showed that these models demonstrate greaterrobustness to real-world conditions in varying of weather, brightness, tint,and contrast.</description><author>Miguel Tjia, Artem Kim, Elaine Wynette Wijaya, Hanna Tefara, Kevin Zhu</author><pubDate>Tue, 27 Aug 2024 08:07:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13766v2</guid></item><item><title>Enhancing Depression Diagnosis with Chain-of-Thought Prompting</title><link>http://arxiv.org/abs/2408.14053v2</link><description>When using AI to detect signs of depressive disorder, AI models habituallydraw preemptive conclusions. We theorize that using chain-of-thought (CoT)prompting to evaluate Patient Health Questionnaire-8 (PHQ-8) scores willimprove the accuracy of the scores determined by AI models. In our findings,when the models reasoned with CoT, the estimated PHQ-8 scores were consistentlycloser on average to the accepted true scores reported by each participantcompared to when not using CoT. Our goal is to expand upon AI models'understanding of the intricacies of human conversation, allowing them to moreeffectively assess a patient's feelings and tone, therefore being able to moreaccurately discern mental disorder symptoms; ultimately, we hope to augment AImodels' abilities, so that they can be widely accessible and used in themedical field.</description><author>Elysia Shi, Adithri Manda, London Chowdhury, Runeema Arun, Kevin Zhu, Michael Lam</author><pubDate>Tue, 27 Aug 2024 08:05:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14053v2</guid></item><item><title>Improving Water Quality Time-Series Prediction in Hong Kong using Sentinel-2 MSI Data and Google Earth Engine Cloud Computing</title><link>http://arxiv.org/abs/2408.14010v2</link><description>Effective water quality monitoring in coastal regions is crucial due to theprogressive deterioration caused by pollution and human activities. To addressthis, this study develops time-series models to predict chlorophyll-a (Chl-a),suspended solids (SS), and turbidity using Sentinel-2 satellite data and GoogleEarth Engine (GEE) in the coastal regions of Hong Kong. Leveraging LongShort-Term Memory (LSTM) Recurrent Neural Networks, the study incorporatesextensive temporal datasets to enhance prediction accuracy. The models utilizespectral data from Sentinel-2, focusing on optically active components, anddemonstrate that selected variables closely align with the spectralcharacteristics of Chl-a and SS. The results indicate improved predictiveperformance over previous methods, highlighting the potential for remotesensing technology in continuous and comprehensive water quality assessment.</description><author>Rohin Sood, Kevin Zhu</author><pubDate>Tue, 27 Aug 2024 08:02:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14010v2</guid></item><item><title>Improved identification of breakpoints in piecewise regression and its applications</title><link>http://arxiv.org/abs/2408.13751v2</link><description>Identifying breakpoints in piecewise regression is critical in enhancing thereliability and interpretability of data fitting. In this paper, we proposenovel algorithms based on the greedy algorithm to accurately and efficientlyidentify breakpoints in piecewise polynomial regression. The algorithm updatesthe breakpoints to minimize the error by exploring the neighborhood of eachbreakpoint. It has a fast convergence rate and stability to find optimalbreakpoints. Moreover, it can determine the optimal number of breakpoints. Thecomputational results for real and synthetic data show that its accuracy isbetter than any existing methods. The real-world datasets demonstrate thatbreakpoints through the proposed algorithm provide valuable data information.</description><author>Taehyeong Kim, Hyungu Lee, Hayoung Choi</author><pubDate>Tue, 27 Aug 2024 07:26:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13751v2</guid></item><item><title>Training-free Long Video Generation with Chain of Diffusion Model Experts</title><link>http://arxiv.org/abs/2408.13423v2</link><description>Video generation models hold substantial potential in areas such asfilmmaking. However, current video diffusion models need high computationalcosts and produce suboptimal results due to high complexity of video generationtask. In this paper, we propose \textbf{ConFiner}, an efficient high-qualityvideo generation framework that decouples video generation into easiersubtasks: structure \textbf{con}trol and spatial-temporal re\textbf{fine}ment.It can generate high-quality videos with chain of off-the-shelf diffusion modelexperts, each expert responsible for a decoupled subtask. During therefinement, we introduce coordinated denoising, which can merge multiplediffusion experts' capabilities into a single sampling. Furthermore, we designConFiner-Long framework, which can generate long coherent video with threeconstraint strategies on ConFiner. Experimental results indicate that with only10\% of the inference cost, our ConFiner surpasses representative models likeLavie and Modelscope across all objective and subjective metrics. AndConFiner-Long can generate high-quality and coherent videos with up to 600frames.</description><author>Wenhao Li, Yichao Cao, Xiu Su, Xi Lin, Shan You, Mingkai Zheng, Yi Chen, Chang Xu</author><pubDate>Tue, 27 Aug 2024 07:12:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13423v2</guid></item><item><title>GenFormer -- Generated Images are All You Need to Improve Robustness of Transformers on Small Datasets</title><link>http://arxiv.org/abs/2408.14131v2</link><description>Recent studies showcase the competitive accuracy of Vision Transformers(ViTs) in relation to Convolutional Neural Networks (CNNs), along with theirremarkable robustness. However, ViTs demand a large amount of data to achieveadequate performance, which makes their application to small datasetschallenging, falling behind CNNs. To overcome this, we propose GenFormer, adata augmentation strategy utilizing generated images, thereby improvingtransformer accuracy and robustness on small-scale image classification tasks.In our comprehensive evaluation we propose Tiny ImageNetV2, -R, and -A as newtest set variants of Tiny ImageNet by transferring established ImageNetgeneralization and robustness benchmarks to the small-scale data domain.Similarly, we introduce MedMNIST-C and EuroSAT-C as corrupted test set variantsof established fine-grained datasets in the medical and aerial domain. Througha series of experiments conducted on small datasets of various domains,including Tiny ImageNet, CIFAR, EuroSAT and MedMNIST datasets, we demonstratethe synergistic power of our method, in particular when combined with commontrain and test time augmentations, knowledge distillation, and architecturaldesign choices. Additionally, we prove the effectiveness of our approach underchallenging conditions with limited training data, demonstrating significantimprovements in both accuracy and robustness, bridging the gap between CNNs andViTs in the small-scale dataset domain.</description><author>Sven Oehri, Nikolas Ebert, Ahmed Abdullah, Didier Stricker, Oliver Wasenmüller</author><pubDate>Tue, 27 Aug 2024 05:54:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14131v2</guid></item><item><title>SwiftBrush v2: Make Your One-step Diffusion Model Better Than Its Teacher</title><link>http://arxiv.org/abs/2408.14176v2</link><description>In this paper, we aim to enhance the performance of SwiftBrush, a prominentone-step text-to-image diffusion model, to be competitive with its multi-stepStable Diffusion counterpart. Initially, we explore the quality-diversitytrade-off between SwiftBrush and SD Turbo: the former excels in imagediversity, while the latter excels in image quality. This observation motivatesour proposed modifications in the training methodology, including better weightinitialization and efficient LoRA training. Moreover, our introduction of anovel clamped CLIP loss enhances image-text alignment and results in improvedimage quality. Remarkably, by combining the weights of models trained withefficient LoRA and full training, we achieve a new state-of-the-art one-stepdiffusion model, achieving an FID of 8.14 and surpassing all GAN-based andmulti-step Stable Diffusion models. The project page is available athttps://swiftbrushv2.github.io.</description><author>Trung Dao, Thuan Hoang Nguyen, Thanh Le, Duc Vu, Khoi Nguyen, Cuong Pham, Anh Tran</author><pubDate>Tue, 27 Aug 2024 04:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14176v2</guid></item><item><title>GNN: Graph Neural Network and Large Language Model for Data Discovery</title><link>http://arxiv.org/abs/2408.13609v2</link><description>Our algorithm GNN: Graph Neural Network and Large Language Model for DataDiscovery inherit the benefits of \cite{hoang2024plod} (PLOD: PredictiveLearning Optimal Data Discovery), \cite{Hoang2024BODBO} (BOD: Blindly OptimalData Discovery) in terms of overcoming the challenges of having to predefineutility function and the human input for attribute ranking, which helps preventthe time-consuming loop process. In addition to these previous works, ouralgorithm GNN leverages the advantages of graph neural networks and largelanguage models to understand text type values that cannot be understood byPLOD and MOD, thus making the task of predicting outcomes more reliable. GNNcould be seen as an extension of PLOD in terms of understanding the text typevalue and the user's preferences, not only numerical values but also textvalues, making the promise of data science and analytics purposes.</description><author>Thomas Hoang</author><pubDate>Tue, 27 Aug 2024 04:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13609v2</guid></item><item><title>An Item Response Theory-based R Module for Algorithm Portfolio Analysis</title><link>http://arxiv.org/abs/2408.14025v2</link><description>Experimental evaluation is crucial in AI research, especially for assessingalgorithms across diverse tasks. Many studies often evaluate a limited set ofalgorithms, failing to fully understand their strengths and weaknesses within acomprehensive portfolio. This paper introduces an Item Response Theory (IRT)based analysis tool for algorithm portfolio evaluation called AIRT-Module.Traditionally used in educational psychometrics, IRT models test questiondifficulty and student ability using responses to test questions. Adapting IRTto algorithm evaluation, the AIRT-Module contains a Shiny web application andthe R package airt. AIRT-Module uses algorithm performance measures to computeanomalousness, consistency, and difficulty limits for an algorithm and thedifficulty of test instances. The strengths and weaknesses of algorithms arevisualised using the difficulty spectrum of the test instances. AIRT-Moduleoffers a detailed understanding of algorithm capabilities across varied testinstances, thus enhancing comprehensive AI method assessment. It is availableat https://sevvandi.shinyapps.io/AIRT/ .</description><author>Brodie Oldfield, Sevvandi Kandanaarachchi, Ziqi Xu, Mario Andrés Muñoz</author><pubDate>Tue, 27 Aug 2024 04:36:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14025v2</guid></item><item><title>SONICS: Synthetic Or Not -- Identifying Counterfeit Songs</title><link>http://arxiv.org/abs/2408.14080v2</link><description>The recent surge in AI-generated songs presents exciting possibilities andchallenges. While these tools democratize music creation, they also necessitatethe ability to distinguish between human-composed and AI-generated songs forsafeguarding artistic integrity and content curation. Existing research anddatasets in fake song detection only focus on singing voice deepfake detection(SVDD), where the vocals are AI-generated but the instrumental music is sourcedfrom real songs. However, this approach is inadequate for contemporaryend-to-end AI-generated songs where all components (vocals, lyrics, music, andstyle) could be AI-generated. Additionally, existing datasets lack lyrics-musicdiversity, long-duration songs, and open fake songs. To address these gaps, weintroduce SONICS, a novel dataset for end-to-end Synthetic Song Detection(SSD), comprising over 97k songs with over 49k synthetic songs from popularplatforms like Suno and Udio. Furthermore, we highlight the importance ofmodeling long-range temporal dependencies in songs for effective authenticitydetection, an aspect overlooked in existing methods. To capture these patterns,we propose a novel model, SpecTTTra, that is up to 3 times faster and 6 timesmore memory efficient compared to popular CNN and Transformer-based modelswhile maintaining competitive performance. Finally, we offer both AI-based andHuman evaluation benchmarks, addressing another deficiency in current research.</description><author>Md Awsafur Rahman, Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Bishmoy Paul, Shaikh Anowarul Fattah</author><pubDate>Tue, 27 Aug 2024 04:14:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14080v2</guid></item><item><title>Jump-teaching: Ultra Efficient and Robust Learning with Noisy Label</title><link>http://arxiv.org/abs/2405.17137v4</link><description>Sample selection is the most straightforward technique to combat label noise,aiming to distinguish mislabeled samples during training and avoid thedegradation of the robustness of the model. In the workflow, $\textit{selectingpossibly clean data}$ and $\textit{model update}$ are iterative. However, theirinterplay and intrinsic characteristics hinder the robustness and efficiency oflearning with noisy labels: 1) The model chooses clean data with selectionbias, leading to the accumulated error in the model update. 2) Most selectionstrategies leverage partner networks or supplementary information to mitigatelabel corruption, albeit with increased computation resources and lowerthroughput speed. Therefore, we employ only one network with the jump mannerupdate to decouple the interplay and mine more semantic information from theloss for a more precise selection. Specifically, the selection of clean datafor each model update is based on one of the prior models, excluding the lastiteration. The strategy of model update exhibits a jump behavior in the form.Moreover, we map the outputs of the network and labels into the same semanticfeature space, respectively. In this space, a detailed and simple lossdistribution is generated to distinguish clean samples more effectively. Ourproposed approach achieves almost up to $2.53\times$ speedup, $0.46\times$ peakmemory footprint, and superior robustness over state-of-the-art works withvarious noise settings.</description><author>Kangye Ji, Fei Cheng, Zeqing Wang, Bohu Huang</author><pubDate>Tue, 27 Aug 2024 04:02:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17137v4</guid></item><item><title>Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models</title><link>http://arxiv.org/abs/2408.14470v2</link><description>Fine-tuning large language models (LLMs) on downstream tasks requiressubstantial computational resources. A class of parameter-efficient fine-tuning(PEFT) aims to mitigate these computational challenges by selectivelyfine-tuning only a small fraction of the model parameters. Althoughcomputationally efficient, these techniques often fail to match the performanceof fully fine-tuned models, primarily due to inherent biases introduced duringparameter selection. Traditional selective PEFT techniques use a fixed set ofparameters based on a predefined budget (a process also known as unmasking),failing to capture parameter importance dynamically and often ending upexceeding the budget. We introduce $\text{ID}^3$, a novel selective PEFT methodthat calculates parameter importance continually and dynamically unmasksparameters by balancing exploration and exploitation in parameter selection.Our empirical study on 15 tasks spanning natural language understanding andgenerative tasks demonstrates the effectiveness of our method compared tofixed-masking-based PEFT techniques. We analytically show that $\text{ID}^3$reduces the number of gradient updates by a factor of two, enhancingcomputational efficiency. $\text{ID}^3$ is robust to random initialization ofneurons and, therefore, can be seamlessly integrated into existing additive andreparametrization-based PEFT modules such as adapters and LoRA for dynamicsparsification.</description><author>Aradhye Agarwal, Suhas K Ramesh, Ayan Sengupta, Tanmoy Chakraborty</author><pubDate>Tue, 27 Aug 2024 03:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14470v2</guid></item><item><title>ALIAS: DAG Learning with Efficient Unconstrained Policies</title><link>http://arxiv.org/abs/2408.13448v2</link><description>Recently, reinforcement learning (RL) has proved a promising alternative forconventional local heuristics in score-based approaches to learning directedacyclic causal graphs (DAGs) from observational data. However, the intricateacyclicity constraint still challenges the efficient exploration of the vastspace of DAGs in existing methods. In this study, we introduce ALIAS(reinforced dAg Learning wIthout Acyclicity conStraints), a novel approach tocausal discovery powered by the RL machinery. Our method features an efficientpolicy for generating DAGs in just a single step with an optimal quadraticcomplexity, fueled by a novel parametrization of DAGs that directly translatesa continuous space to the space of all DAGs, bypassing the need for explicitlyenforcing acyclicity constraints. This approach enables us to navigate thesearch space more effectively by utilizing policy gradient methods andestablished scoring functions. In addition, we provide compelling empiricalevidence for the strong performance of ALIAS in comparison withstate-of-the-arts in causal discovery over increasingly difficult experimentconditions on both synthetic and real datasets.</description><author>Bao Duong, Hung Le, Thin Nguyen</author><pubDate>Tue, 27 Aug 2024 03:28:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13448v2</guid></item><item><title>BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model</title><link>http://arxiv.org/abs/2408.10903v4</link><description>The rapid advancement of large language models (LLMs) has revolutionizedrole-playing, enabling the development of general role-playing models. However,current role-playing training has two significant issues: (I) Using apredefined role profile to prompt dialogue training for specific scenariosusually leads to inconsistencies and even conflicts between the dialogue andthe profile, resulting in training biases. (II) The model learns to imitate therole based solely on the profile, neglecting profile-dialogue alignment at thesentence level. In this work, we propose a simple yet effective frameworkcalled BEYOND DIALOGUE, designed to overcome these hurdles. This frameworkinnovatively introduces "beyond dialogue" tasks to align dialogue with profiletraits based on each specific scenario, thereby eliminating biases duringtraining. Furthermore, by adopting an innovative prompting mechanism thatgenerates reasoning outcomes for training, the framework allows the model toachieve fine-grained alignment between profile and dialogue at the sentencelevel. The aforementioned methods are fully automated and low-cost.Additionally, the integration of automated dialogue and objective evaluationmethods forms a comprehensive framework, paving the way for generalrole-playing. Experimental results demonstrate that our model excels inadhering to and reflecting various dimensions of role profiles, outperformingmost proprietary general and specialized role-playing baselines. All code anddatasets are available at https://github.com/yuyouyu32/BeyondDialogue.</description><author>Yeyong Yu, Runsheng Yu, Haojie Wei, Zhanqiu Zhang, Quan Qian</author><pubDate>Tue, 27 Aug 2024 02:58:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10903v4</guid></item><item><title>Verifiable cloud-based variational quantum algorithms</title><link>http://arxiv.org/abs/2408.13713v2</link><description>Variational quantum algorithms (VQAs) have shown potential for quantumadvantage with noisy intermediate-scale quantum (NISQ) devices for quantummachine learning (QML). However, given the high cost and limited availabilityof quantum resources, delegating VQAs via cloud networks is a more practicalsolution for clients with limited quantum capabilities. Recently, Shingu etal.[Physical Review A, 105, 022603 (2022)] proposed a variational secure cloudquantum computing protocol, utilizing ancilla-driven quantum computation (ADQC)for cloud-based VQAs with minimal quantum resource consumption. However, theirprotocol lacks verifiability, which exposes it to potential malicious behaviorsby the server. Additionally, channel loss requires frequent re-delegation asthe size of the delegated variational circuit grows, complicating verificationdue to increased circuit complexity. This paper introduces a new protocol toaddress these challenges and enhance both verifiability and tolerance tochannel loss in cloud-based VQAs.</description><author>Junhong Yang, Banghai Wang, Junyu Quan, Qin Li</author><pubDate>Tue, 27 Aug 2024 02:39:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13713v2</guid></item><item><title>Sapiens: Foundation for Human Vision Models</title><link>http://arxiv.org/abs/2408.12569v3</link><description>We present Sapiens, a family of models for four fundamental human-centricvision tasks -- 2D pose estimation, body-part segmentation, depth estimation,and surface normal prediction. Our models natively support 1K high-resolutioninference and are extremely easy to adapt for individual tasks by simplyfine-tuning models pretrained on over 300 million in-the-wild human images. Weobserve that, given the same computational budget, self-supervised pretrainingon a curated dataset of human images significantly boosts the performance for adiverse set of human-centric tasks. The resulting models exhibit remarkablegeneralization to in-the-wild data, even when labeled data is scarce orentirely synthetic. Our simple model design also brings scalability -- modelperformance across tasks improves as we scale the number of parameters from 0.3to 2 billion. Sapiens consistently surpasses existing baselines across varioushuman-centric benchmarks. We achieve significant improvements over the priorstate-of-the-art on Humans-5K (pose) by 7.6 mAP, Humans-2K (part-seg) by 17.1mIoU, Hi4D (depth) by 22.4% relative RMSE, and THuman2 (normal) by 53.5%relative angular error. Project page:https://about.meta.com/realitylabs/codecavatars/sapiens.</description><author>Rawal Khirodkar, Timur Bagautdinov, Julieta Martinez, Su Zhaoen, Austin James, Peter Selednik, Stuart Anderson, Shunsuke Saito</author><pubDate>Tue, 27 Aug 2024 02:31:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12569v3</guid></item><item><title>BCDNet: A Convolutional Neural Network For Breast Cancer Detection</title><link>http://arxiv.org/abs/2408.13800v2</link><description>Previous research has established that breast cancer is a prevalent cancertype, with Invasive Ductal Carcinoma (IDC) being the most common subtype. Theincidence of this dangerous cancer continues to rise, making accurate and rapiddiagnosis, particularly in the early stages, critically important. While modernComputer-Aided Diagnosis (CAD) systems can address most cases, medicalprofessionals still face challenges in using them in the field without powerfulcomputing resources. In this paper, we propose a novel CNN model called BCDNet,which effectively detects IDC in histopathological images with an accuracy ofup to 89.5% and reduces training time effectively.</description><author>Yujia Lin, Aiwei Lian, Mingyu Liao, Yipeng Liu</author><pubDate>Tue, 27 Aug 2024 02:30:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13800v2</guid></item><item><title>Data Augmentation for Continual RL via Adversarial Gradient Episodic Memory</title><link>http://arxiv.org/abs/2408.13452v2</link><description>Data efficiency of learning, which plays a key role in the ReinforcementLearning (RL) training process, becomes even more important in continual RLwith sequential environments. In continual RL, the learner interacts withnon-stationary, sequential tasks and is required to learn new tasks withoutforgetting previous knowledge. However, there is little work on implementingdata augmentation for continual RL. In this paper, we investigate the efficacyof data augmentation for continual RL. Specifically, we provide benchmarkingdata augmentations for continual RL, by (1) summarising existing dataaugmentation methods and (2) including a new augmentation method for continualRL: Adversarial Augmentation with Gradient Episodic Memory (Adv-GEM). Extensiveexperiments show that data augmentations, such as random amplitude scaling,state-switch, mixup, adversarial augmentation, and Adv-GEM, can improveexisting continual RL algorithms in terms of their average performance,catastrophic forgetting, and forward transfer, on robot control tasks. All dataaugmentation methods are implemented as plug-in modules for trivial integrationinto continual RL methods.</description><author>Sihao Wu, Xingyu Zhao, Xiaowei Huang</author><pubDate>Tue, 27 Aug 2024 02:19:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13452v2</guid></item><item><title>Prompt-Softbox-Prompt: A free-text Embedding Control for Image Editing</title><link>http://arxiv.org/abs/2408.13623v2</link><description>Text-driven diffusion models have achieved remarkable success in imageediting, but a crucial component in these models-text embeddings-has not beenfully explored. The entanglement and opacity of text embeddings presentsignificant challenges to achieving precise image editing. In this paper, weprovide a comprehensive and in-depth analysis of text embeddings in StableDiffusion XL, offering three key insights. First, while the 'aug_embedding'captures the full semantic content of the text, its contribution to the finalimage generation is relatively minor. Second, 'BOS' and 'Padding_embedding' donot contain any semantic information. Lastly, the 'EOS' holds the semanticinformation of all words and contains the most style features. Each wordembedding plays a unique role without interfering with one another. Based onthese insights, we propose a novel approach for controllable image editingusing a free-text embedding control method called PSP (Prompt-Softbox-Prompt).PSP enables precise image editing by inserting or adding text embeddings withinthe cross-attention layers and using Softbox to define and control the specificarea for semantic injection. This technique allows for obejct additions andreplacements while preserving other areas of the image. Additionally, PSP canachieve style transfer by simply replacing text embeddings. Extensiveexperimental results show that PSP achieves significant results in tasks suchas object replacement, object addition, and style transfer.</description><author>Yitong Yang, Yinglin Wang, Jing Wang, Tian Zhang</author><pubDate>Tue, 27 Aug 2024 01:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13623v2</guid></item><item><title>Attack on Scene Flow using Point Clouds</title><link>http://arxiv.org/abs/2404.13621v5</link><description>Deep neural networks have made significant advancements in accuratelyestimating scene flow using point clouds, which is vital for many applicationslike video analysis, action recognition, and navigation. The robustness ofthese techniques, however, remains a concern, particularly in the face ofadversarial attacks that have been proven to deceive state-of-the-art deepneural networks in many domains. Surprisingly, the robustness of scene flownetworks against such attacks has not been thoroughly investigated. To addressthis problem, the proposed approach aims to bridge this gap by introducingadversarial white-box attacks specifically tailored for scene flow networks.Experimental results show that the generated adversarial examples obtain up to33.7 relative degradation in average end-point error on the KITTI andFlyingThings3D datasets. The study also reveals the significant impact thatattacks targeting point clouds in only one dimension or color channel have onaverage end-point error. Analyzing the success and failure of these attacks onthe scene flow networks and their 2D optical flow network variants shows ahigher vulnerability for the optical flow networks. Code is available athttps://github.com/aheldis/Attack-on-Scene-Flow-using-Point-Clouds.git.</description><author>Haniyeh Ehsani Oskouie, Mohammad-Shahram Moin, Shohreh Kasaei</author><pubDate>Tue, 27 Aug 2024 01:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.13621v5</guid></item><item><title>Advancing Humanoid Locomotion: Mastering Challenging Terrains with Denoising World Model Learning</title><link>http://arxiv.org/abs/2408.14472v1</link><description>Humanoid robots, with their human-like skeletal structure, are especiallysuited for tasks in human-centric environments. However, this structure isaccompanied by additional challenges in locomotion controller design,especially in complex real-world environments. As a result, existing humanoidrobots are limited to relatively simple terrains, either with model-basedcontrol or model-free reinforcement learning. In this work, we introduceDenoising World Model Learning (DWL), an end-to-end reinforcement learningframework for humanoid locomotion control, which demonstrates the world's firsthumanoid robot to master real-world challenging terrains such as snowy andinclined land in the wild, up and down stairs, and extremely uneven terrains.All scenarios run the same learned neural network with zero-shot sim-to-realtransfer, indicating the superior robustness and generalization capability ofthe proposed method.</description><author>Xinyang Gu, Yen-Jen Wang, Xiang Zhu, Chengming Shi, Yanjiang Guo, Yichen Liu, Jianyu Chen</author><pubDate>Mon, 26 Aug 2024 17:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14472v1</guid></item><item><title>A Practitioner's Guide to Continual Multimodal Pretraining</title><link>http://arxiv.org/abs/2408.14471v1</link><description>Multimodal foundation models serve numerous applications at the intersectionof vision and language. Still, despite being pretrained on extensive data, theybecome outdated over time. To keep models updated, research into continualpretraining mainly explores scenarios with either (1) infrequent,indiscriminate updates on large-scale new data, or (2) frequent, sample-levelupdates. However, practical model deployment often operates in the gap betweenthese two limit cases, as real-world applications often demand adaptation tospecific subdomains, tasks or concepts -- spread over the entire, varying lifecycle of a model. In this work, we complement current perspectives on continualpretraining through a research test bed as well as provide comprehensiveguidance for effective continual model updates in such scenarios. We firstintroduce FoMo-in-Flux, a continual multimodal pretraining benchmark withrealistic compute constraints and practical deployment requirements,constructed over 63 datasets with diverse visual and semantic coverage. UsingFoMo-in-Flux, we explore the complex landscape of practical continualpretraining through multiple perspectives: (1) A data-centric investigation ofdata mixtures and stream orderings that emulate real-world deploymentsituations, (2) a method-centric investigation ranging from simple fine-tuningand traditional continual learning strategies to parameter-efficient updatesand model merging, (3) meta learning rate schedules and mechanistic designchoices, and (4) the influence of model and compute scaling. Together, ourinsights provide a practitioner's guide to continual multimodal pretraining forreal-world deployment. Our benchmark and code is here:https://github.com/ExplainableML/fomo_in_flux.</description><author>Karsten Roth, Vishaal Udandarao, Sebastian Dziadzio, Ameya Prabhu, Mehdi Cherti, Oriol Vinyals, Olivier Hénaff, Samuel Albanie, Matthias Bethge, Zeynep Akata</author><pubDate>Mon, 26 Aug 2024 17:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14471v1</guid></item><item><title>Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models</title><link>http://arxiv.org/abs/2408.14470v1</link><description>Fine-tuning large language models (LLMs) on downstream tasks requiressubstantial computational resources. A class of parameter-efficient fine-tuning(PEFT) aims to mitigate these computational challenges by selectivelyfine-tuning only a small fraction of the model parameters. Althoughcomputationally efficient, these techniques often fail to match the performanceof fully fine-tuned models, primarily due to inherent biases introduced duringparameter selection. Traditional selective PEFT techniques use a fixed set ofparameters based on a predefined budget (a process also known as unmasking),failing to capture parameter importance dynamically and often ending upexceeding the budget. We introduce $\text{ID}^3$, a novel selective PEFT methodthat calculates parameter importance continually and dynamically unmasksparameters by balancing exploration and exploitation in parameter selection.Our empirical study on 15 tasks spanning natural language understanding andgenerative tasks demonstrates the effectiveness of our method compared tofixed-masking-based PEFT techniques. We analytically show that $\text{ID}^3$reduces the number of gradient updates by a factor of two, enhancingcomputational efficiency. $\text{ID}^3$ is robust to random initialization ofneurons and, therefore, can be seamlessly integrated into existing additive andreparametrization-based PEFT modules such as adapters and LoRA for dynamicsparsification.</description><author>Aradhye Agarwal, Suhas K Ramesh, Ayan Sengupta, Tanmoy Chakraborty</author><pubDate>Mon, 26 Aug 2024 17:58:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14470v1</guid></item><item><title>Grounded Multi-Hop VideoQA in Long-Form Egocentric Videos</title><link>http://arxiv.org/abs/2408.14469v1</link><description>This paper considers the problem of Multi-Hop Video Question Answering(MH-VidQA) in long-form egocentric videos. This task not only requires toanswer visual questions, but also to localize multiple relevant time intervalswithin the video as visual evidences. We develop an automated pipeline tocreate multi-hop question-answering pairs with associated temporal evidence,enabling to construct a large-scale dataset for instruction-tuning. To monitorthe progress of this new task, we further curate a high-quality benchmark,MultiHop-EgoQA, with careful manual verification and refinement. Experimentalresults reveal that existing multi-modal systems exhibit inadequate multi-hopgrounding and reasoning abilities, resulting in unsatisfactory performance. Wethen propose a novel architecture, termed as Grounding Scattered Evidence withLarge Language Model (GeLM), that enhances multi-modal large language models(MLLMs) by incorporating a grounding module to retrieve temporal evidence fromvideos using flexible grounding tokens. Trained on our visual instruction data,GeLM demonstrates improved multi-hop grounding and reasoning capabilities,setting a new baseline for this challenging task. Furthermore, when trained onthird-person view videos, the same architecture also achieves state-of-the-artperformance on the single-hop VidQA benchmark, ActivityNet-RTL, demonstratingits effectiveness.</description><author>Qirui Chen, Shangzhe Di, Weidi Xie</author><pubDate>Mon, 26 Aug 2024 17:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14469v1</guid></item><item><title>K-Sort Arena: Efficient and Reliable Benchmarking for Generative Models via K-wise Human Preferences</title><link>http://arxiv.org/abs/2408.14468v1</link><description>The rapid advancement of visual generative models necessitates efficient andreliable evaluation methods. Arena platform, which gathers user votes on modelcomparisons, can rank models with human preferences. However, traditional Arenamethods, while established, require an excessive number of comparisons forranking to converge and are vulnerable to preference noise in voting,suggesting the need for better approaches tailored to contemporary evaluationchallenges. In this paper, we introduce K-Sort Arena, an efficient and reliableplatform based on a key insight: images and videos possess higher perceptualintuitiveness than texts, enabling rapid evaluation of multiple samplessimultaneously. Consequently, K-Sort Arena employs K-wise comparisons, allowingK models to engage in free-for-all competitions, which yield much richerinformation than pairwise comparisons. To enhance the robustness of the system,we leverage probabilistic modeling and Bayesian updating techniques. We proposean exploration-exploitation-based matchmaking strategy to facilitate moreinformative comparisons. In our experiments, K-Sort Arena exhibits 16.3x fasterconvergence compared to the widely used ELO algorithm. To further validate thesuperiority and obtain a comprehensive leaderboard, we collect human feedbackvia crowdsourced evaluations of numerous cutting-edge text-to-image andtext-to-video models. Thanks to its high efficiency, K-Sort Arena cancontinuously incorporate emerging models and update the leaderboard withminimal votes. Our project has undergone several months of internal testing andis now available at https://huggingface.co/spaces/ksort/K-Sort-Arena</description><author>Zhikai Li, Xuewen Liu, Dongrong Fu, Jianquan Li, Qingyi Gu, Kurt Keutzer, Zhen Dong</author><pubDate>Mon, 26 Aug 2024 17:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14468v1</guid></item><item><title>Explicit Inductive Inference using Large Language Models</title><link>http://arxiv.org/abs/2408.14467v1</link><description>Large Language Models (LLMs) are reported to hold undesirable attestationbias on inference tasks: when asked to predict if a premise P entails ahypothesis H, instead of considering H's conditional truthfulness entailed byP, LLMs tend to use the out-of-context truth label of H as a fragile proxy. Inthis paper, we propose a pipeline that exploits this bias to do explicitinductive inference. Our pipeline uses an LLM to transform a premise into a setof attested alternatives, and then aggregate answers of the derived newentailment inquiries to support the original inference prediction. On adirectional predicate entailment benchmark, we demonstrate that by applyingthis simple pipeline, we can improve the overall performance of LLMs oninference and substantially alleviate the impact of their attestation bias.</description><author>Tianyang Liu, Tianyi Li, Liang Cheng, Mark Steedman</author><pubDate>Mon, 26 Aug 2024 17:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14467v1</guid></item><item><title>A domain decomposition-based autoregressive deep learning model for unsteady and nonlinear partial differential equations</title><link>http://arxiv.org/abs/2408.14461v1</link><description>In this paper, we propose a domain-decomposition-based deep learning (DL)framework, named transient-CoMLSim, for accurately modeling unsteady andnonlinear partial differential equations (PDEs). The framework consists of twokey components: (a) a convolutional neural network (CNN)-based autoencoderarchitecture and (b) an autoregressive model composed of fully connectedlayers. Unlike existing state-of-the-art methods that operate on the entirecomputational domain, our CNN-based autoencoder computes a lower-dimensionalbasis for solution and condition fields represented on subdomains. Timesteppingis performed entirely in the latent space, generating embeddings of thesolution variables from the time history of embeddings of solution andcondition variables. This approach not only reduces computational complexitybut also enhances scalability, making it well-suited for large-scalesimulations. Furthermore, to improve the stability of our rollouts, we employ acurriculum learning (CL) approach during the training of the autoregressivemodel. The domain-decomposition strategy enables scaling to out-of-distributiondomain sizes while maintaining the accuracy of predictions -- a feature noteasily integrated into popular DL-based approaches for physics simulations. Webenchmark our model against two widely-used DL architectures, Fourier NeuralOperator (FNO) and U-Net, and demonstrate that our framework outperforms themin terms of accuracy, extrapolation to unseen timesteps, and stability for awide range of use cases.</description><author>Sheel Nidhan, Haoliang Jiang, Lalit Ghule, Clancy Umphrey, Rishikesh Ranade, Jay Pathak</author><pubDate>Mon, 26 Aug 2024 17:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14461v1</guid></item><item><title>LLM Pruning and Distillation in Practice: The Minitron Approach</title><link>http://arxiv.org/abs/2408.11796v2</link><description>We present a comprehensive report on compressing the Llama 3.1 8B and MistralNeMo 12B models to 4B and 8B parameters, respectively, using pruning anddistillation. We explore two distinct pruning strategies: (1) depth pruning and(2) joint hidden/attention/MLP (width) pruning, and evaluate the results oncommon benchmarks from the LM Evaluation Harness. The models are then alignedwith NeMo Aligner and tested in instruct-tuned versions. This approach producesa compelling 4B model from Llama 3.1 8B and a state-of-the-artMistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo12B. We found that with no access to the original data, it is beneficial toslightly fine-tune teacher models on the distillation dataset. We open-sourceour base model weights on Hugging Face with a permissive license.</description><author>Sharath Turuvekere Sreenivas, Saurav Muralidharan, Raviraj Joshi, Marcin Chochowski, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, Pavlo Molchanov</author><pubDate>Mon, 26 Aug 2024 17:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11796v2</guid></item><item><title>Dense Center-Direction Regression for Object Counting and Localization with Point Supervision</title><link>http://arxiv.org/abs/2408.14457v1</link><description>Object counting and localization problems are commonly addressed with pointsupervised learning, which allows the use of less labor-intensive pointannotations. However, learning based on point annotations poses challenges dueto the high imbalance between the sets of annotated and unannotated pixels,which is often treated with Gaussian smoothing of point annotations and focalloss. However, these approaches still focus on the pixels in the immediatevicinity of the point annotations and exploit the rest of the data onlyindirectly. In this work, we propose a novel approach termed CeDiRNet forpoint-supervised learning that uses a dense regression of directions pointingtowards the nearest object centers, i.e. center-directions. This providesgreater support for each center point arising from many surrounding pixelspointing towards the object center. We propose a formulation ofcenter-directions that allows the problem to be split into the domain-specificdense regression of center-directions and the final localization task based ona small, lightweight, and domain-agnostic localization network that can betrained with synthetic data completely independent of the target domain. Wedemonstrate the performance of the proposed method on six different datasetsfor object counting and localization, and show that it outperforms the existingstate-of-the-art methods. The code is accessible on GitHub athttps://github.com/vicoslab/CeDiRNet.git.</description><author>Domen Tabernik, Jon Muhovič, Danijel Skočaj</author><pubDate>Mon, 26 Aug 2024 17:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14457v1</guid></item><item><title>Center Direction Network for Grasping Point Localization on Cloths</title><link>http://arxiv.org/abs/2408.14456v1</link><description>Object grasping is a fundamental challenge in robotics and computer vision,critical for advancing robotic manipulation capabilities. Deformable objects,like fabrics and cloths, pose additional challenges due to their non-rigidnature. In this work, we introduce CeDiRNet-3DoF, a deep-learning model forgrasp point detection, with a particular focus on cloth objects. CeDiRNet-3DoFemploys center direction regression alongside a localization network, attainingfirst place in the perception task of ICRA 2023's Cloth Manipulation Challenge.Recognizing the lack of standardized benchmarks in the literature that hindereffective method comparison, we present the ViCoS Towel Dataset. This extensivebenchmark dataset comprises 8,000 real and 12,000 synthetic images, serving asa robust resource for training and evaluating contemporary data-drivendeep-learning approaches. Extensive evaluation revealed CeDiRNet-3DoF'srobustness in real-world performance, outperforming state-of-the-art methods,including the latest transformer-based models. Our work bridges a crucial gap,offering a robust solution and benchmark for cloth grasping in computer visionand robotics. Code and dataset are available at:https://github.com/vicoslab/CeDiRNet-3DoF</description><author>Domen Tabernik, Jon Muhovič, Matej Urbas, Danijel Skočaj</author><pubDate>Mon, 26 Aug 2024 17:49:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14456v1</guid></item><item><title>Reconstructing physiological signals from fMRI across the adult lifespan</title><link>http://arxiv.org/abs/2408.14453v1</link><description>Interactions between the brain and body are of fundamental importance forhuman behavior and health. Functional magnetic resonance imaging (fMRI)captures whole-brain activity noninvasively, and modeling how fMRI signalsinteract with physiological dynamics of the body can provide new insight intobrain function and offer potential biomarkers of disease. However,physiological recordings are not always possible to acquire since they requireextra equipment and setup, and even when they are, the recorded physiologicalsignals may contain substantial artifacts. To overcome this limitation, machinelearning models have been proposed to directly extract features of respiratoryand cardiac activity from resting-state fMRI signals. To date, such work hasbeen carried out only in healthy young adults and in a pediatric population,leaving open questions about the efficacy of these approaches on older adults.Here, we propose a novel framework that leverages Transformer-basedarchitectures for reconstructing two key physiological signals - low-frequencyrespiratory volume (RV) and heart rate (HR) fluctuations - from fMRI data, andtest these models on a dataset of individuals aged 36-89 years old. Ourframework outperforms previously proposed approaches (attaining mediancorrelations between predicted and measured signals of r ~ .698 for RV and r ~.618 for HR), indicating the potential of leveraging attention mechanisms tomodel fMRI-physiological signal relationships. We also evaluate several modeltraining and fine-tuning strategies, and find that incorporating young-adultdata during training improves the performance when predicting physiologicalsignals in the aging cohort. Overall, our approach successfully infers keyphysiological variables directly from fMRI data from individuals across a widerange of the adult lifespan.</description><author>Shiyu Wang, Ziyuan Xu, Yamin Li, Mara Mather, Roza G. Bayrak, Catie Chang</author><pubDate>Mon, 26 Aug 2024 17:48:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14453v1</guid></item><item><title>Symmetry &amp; Critical Points</title><link>http://arxiv.org/abs/2408.14445v1</link><description>Critical points of an invariant function may or may not be symmetric. Weprove, however, that if a symmetric critical point exists, those adjacent to itare generically symmetry breaking. This mathematical mechanism is shown tocarry important implications for our ability to efficiently minimize invariantnonconvex functions, in particular those associated with neural networks.</description><author>Yossi Arjevani</author><pubDate>Mon, 26 Aug 2024 17:36:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14445v1</guid></item><item><title>Temporal Ensemble Logic</title><link>http://arxiv.org/abs/2408.14443v1</link><description>We introduce Temporal Ensemble Logic (TEL), a monadic, first-order modallogic for linear-time temporal reasoning. TEL includes primitive temporalconstructs such as ``always up to $t$ time later'' ($\Box_t$), ``sometimesbefore $t$ time in the future'' ($\Diamond_t$), and ``$t$-time later''$\varphi_t$. TEL has been motivated from the requirement for rigor andreproducibility for cohort specification and discovery in clinical andpopulation health research, to fill a gap in formalizing temporal reasoning inbiomedicine. In this paper, we first introduce TEL in a general set up, withdiscrete and dense time as special cases. We then focus on the theoreticaldevelopment of discrete TEL on the temporal domain of positive integers$\mathbb{N}^+$, denoted as ${\rm TEL}_{\mathbb{N}^+}$. ${\rmTEL}_{\mathbb{N}^+}$ is strictly more expressive than the standard monadicsecond order logic, characterized by B\"{u}chi automata. We present its formalsemantics, a proof system, and provide a proof for the undecidability of thesatisfiability of ${\rm TEL}_{\mathbb{N}^+}$. We also discuss expressivenessand decidability fragments for ${\rm TEL}_{\mathbb{N}^+}$, followed byillustrative applications.</description><author>Guo-Qiang Zhang</author><pubDate>Mon, 26 Aug 2024 17:36:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14443v1</guid></item><item><title>Model Parallel Training and Transfer Learning for Convolutional Neural Networks by Domain Decomposition</title><link>http://arxiv.org/abs/2408.14442v1</link><description>Deep convolutional neural networks (CNNs) have been shown to be verysuccessful in a wide range of image processing applications. However, due totheir increasing number of model parameters and an increasing availability oflarge amounts of training data, parallelization strategies to efficiently traincomplex CNNs are necessary. In previous work by the authors, a novel modelparallel CNN architecture was proposed which is loosely inspired by domaindecomposition. In particular, the novel network architecture is based on adecomposition of the input data into smaller subimages. For each of thesesubimages, local CNNs with a proportionally smaller number of parameters aretrained in parallel and the resulting local classifications are then aggregatedin a second step by a dense feedforward neural network (DNN). In the presentwork, we compare the resulting CNN-DNN architecture to less costly alternativesto combine the local classifications into a final, global decision.Additionally, we investigate the performance of the CNN-DNN trained as onecoherent model as well as using a transfer learning strategy, where theparameters of the pre-trained local CNNs are used as initial values for asubsequently trained global coherent CNN-DNN model.</description><author>Axel Klawonn, Martin Lanser, Janine Weber</author><pubDate>Mon, 26 Aug 2024 17:35:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14442v1</guid></item><item><title>Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data</title><link>http://arxiv.org/abs/2306.13840v3</link><description>Current trends in pre-training Large Language Models (LLMs) primarily focuson the scaling of model and dataset size. While the quality of pre-trainingdata is considered an important factor for training powerful LLMs, it remains anebulous concept that has not been rigorously characterized. To this end, wepropose a formalization of one key aspect of data quality -- measuring thevariability of natural language data -- specifically via a measure we call thediversity coefficient. Our empirical analysis shows that the proposed diversitycoefficient aligns with the intuitive properties of diversity and variability,e.g., it increases as the number of latent concepts increases. Then, we measurethe diversity coefficient of publicly available pre-training datasets anddemonstrate that their formal diversity is high compared to theoretical lowerand upper bounds. Finally, we conduct a comprehensive set of controlledinterventional experiments with GPT-2 and LLaMAv2 that demonstrate thediversity coefficient of pre-training data characterizes useful aspects ofdownstream model evaluation performance -- totaling 44 models of various sizes(51M to 7B parameters). We conclude that our formal notion of diversity is animportant aspect of data quality that captures variability and causally leadsto improved evaluation performance.</description><author>Brando Miranda, Alycia Lee, Sudharsan Sundar, Allison Casasola, Sanmi Koyejo</author><pubDate>Mon, 26 Aug 2024 17:34:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13840v3</guid></item><item><title>Attend-Fusion: Efficient Audio-Visual Fusion for Video Classification</title><link>http://arxiv.org/abs/2408.14441v1</link><description>Exploiting both audio and visual modalities for video classification is achallenging task, as the existing methods require large model architectures,leading to high computational complexity and resource requirements. Smallerarchitectures, on the other hand, struggle to achieve optimal performance. Inthis paper, we propose Attend-Fusion, an audio-visual (AV) fusion approach thatintroduces a compact model architecture specifically designed to captureintricate audio-visual relationships in video data. Through extensiveexperiments on the challenging YouTube-8M dataset, we demonstrate thatAttend-Fusion achieves an F1 score of 75.64\% with only 72M parameters, whichis comparable to the performance of larger baseline models such asFully-Connected Late Fusion (75.96\% F1 score, 341M parameters). Attend-Fusionachieves similar performance to the larger baseline model while reducing themodel size by nearly 80\%, highlighting its efficiency in terms of modelcomplexity. Our work demonstrates that the Attend-Fusion model effectivelycombines audio and visual information for video classification, achievingcompetitive performance with significantly reduced model size. This approachopens new possibilities for deploying high-performance video understandingsystems in resource-constrained environments across various applications.</description><author>Mahrukh Awan, Asmar Nadeem, Muhammad Junaid Awan, Armin Mustafa, Syed Sameed Husain</author><pubDate>Mon, 26 Aug 2024 17:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14441v1</guid></item><item><title>Improved Uncertainty Estimation of Graph Neural Network Potentials Using Engineered Latent Space Distances</title><link>http://arxiv.org/abs/2407.10844v2</link><description>Graph neural networks (GNNs) have been shown to be astonishingly capablemodels for molecular property prediction, particularly as surrogates forexpensive density functional theory calculations of relaxed energy for novelmaterial discovery. However, one limitation of GNNs in this context is the lackof useful uncertainty prediction methods, as this is critical to the materialdiscovery pipeline. In this work, we show that uncertainty quantification forrelaxed energy calculations is more complex than uncertainty quantification forother kinds of molecular property prediction, due to the effect that structureoptimizations have on the error distribution. We propose that distribution-freetechniques are more useful tools for assessing calibration, recalibrating, anddeveloping uncertainty prediction methods for GNNs performing relaxed energycalculations. We also develop a relaxed energy task for evaluating uncertaintymethods for equivariant GNNs, based on distribution-free recalibration andusing the Open Catalyst Project dataset. We benchmark a set of popularuncertainty prediction methods on this task, and show that latent distancemethods, with our novel improvements, are the most well-calibrated andeconomical approach for relaxed energy calculations. Finally, we demonstratethat our latent space distance method produces results which align with ourexpectations on a clustering example, and on specific equation of state andadsorbate coverage examples from outside the training dataset.</description><author>Joseph Musielewicz, Janice Lan, Matt Uyttendaele, John R. Kitchin</author><pubDate>Mon, 26 Aug 2024 17:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10844v2</guid></item><item><title>Tracing Privacy Leakage of Language Models to Training Data via Adjusted Influence Functions</title><link>http://arxiv.org/abs/2408.10468v3</link><description>The responses generated by Large Language Models (LLMs) can include sensitiveinformation from individuals and organizations, leading to potential privacyleakage. This work implements Influence Functions (IFs) to trace privacyleakage back to the training data, thereby mitigating privacy concerns ofLanguage Models (LMs). However, we notice that current IFs struggle toaccurately estimate the influence of tokens with large gradient norms,potentially overestimating their influence. When tracing the most influentialsamples, this leads to frequently tracing back to samples with large gradientnorm tokens, overshadowing the actual most influential samples even if theirinfluences are well estimated. To address this issue, we propose HeuristicallyAdjusted IF (HAIF), which reduces the weight of tokens with large gradientnorms, thereby significantly improving the accuracy of tracing the mostinfluential samples. To establish easily obtained groundtruth for tracingprivacy leakage, we construct two datasets, PII-E and PII-CR, representing twodistinct scenarios: one with identical text in the model outputs andpre-training data, and the other where models leverage their reasoningabilities to generate text divergent from pre-training data. HAIF significantlyimproves tracing accuracy, enhancing it by 20.96% to 73.71% on the PII-Edataset and 3.21% to 45.93% on the PII-CR dataset, compared to the best SOTAIFs against various GPT-2 and QWen-1.5 models. HAIF also outperforms SOTA IFson real-world pretraining data CLUECorpus2020, demonstrating strong robustnessregardless prompt and response lengths.</description><author>Jinxin Liu, Zao Yang</author><pubDate>Mon, 26 Aug 2024 17:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10468v3</guid></item><item><title>Evaluating Large Language Models on Spatial Tasks: A Multi-Task Benchmarking Study</title><link>http://arxiv.org/abs/2408.14438v1</link><description>The advent of large language models such as ChatGPT, Gemini, and others hasunderscored the importance of evaluating their diverse capabilities, rangingfrom natural language understanding to code generation. However, theirperformance on spatial tasks has not been comprehensively assessed. This studyaddresses this gap by introducing a novel multi-task spatial evaluationdataset, designed to systematically explore and compare the performance ofseveral advanced models on spatial tasks. The dataset encompasses twelvedistinct task types, including spatial understanding and path planning, eachwith verified, accurate answers. We evaluated multiple models, includingOpenAI's gpt-3.5-turbo, gpt-4o, and ZhipuAI's glm-4, through a two-phasetesting approach. Initially, we conducted zero-shot testing, followed bycategorizing the dataset by difficulty and performing prompt tuning tests.Results indicate that gpt-4o achieved the highest overall accuracy in the firstphase, with an average of 71.3%. Although moonshot-v1-8k slightlyunderperformed overall, it surpassed gpt-4o in place name recognition tasks.The study also highlights the impact of prompt strategies on model performancein specific tasks. For example, the Chain-of-Thought (COT) strategy increasedgpt-4o's accuracy in path planning from 12.4% to 87.5%, while a one-shotstrategy enhanced moonshot-v1-8k's accuracy in mapping tasks from 10.1% to76.3%.</description><author>Liuchang Xu Shuo Zhao, Qingming Lin, Luyao Chen, Qianqian Luo, Sensen Wu, Xinyue Ye, Hailin Feng, Zhenhong Du</author><pubDate>Mon, 26 Aug 2024 17:25:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14438v1</guid></item><item><title>Sparsity-Aware Hardware-Software Co-Design of Spiking Neural Networks: An Overview</title><link>http://arxiv.org/abs/2408.14437v1</link><description>Spiking Neural Networks (SNNs) are inspired by the sparse and event-drivennature of biological neural processing, and offer the potential forultra-low-power artificial intelligence. However, realizing their efficiencybenefits requires specialized hardware and a co-design approach thateffectively leverages sparsity. We explore the hardware-software co-design ofsparse SNNs, examining how sparsity representation, hardware architectures, andtraining techniques influence hardware efficiency. We analyze the impact ofstatic and dynamic sparsity, discuss the implications of different neuronmodels and encoding schemes, and investigate the need for adaptability inhardware designs. Our work aims to illuminate the path towards embeddedneuromorphic systems that fully exploit the computational advantages of sparseSNNs.</description><author>Ilkin Aliyev, Kama Svoboda, Tosiron Adegbija, Jean-Marc Fellous</author><pubDate>Mon, 26 Aug 2024 17:22:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14437v1</guid></item><item><title>Social perception of faces in a vision-language model</title><link>http://arxiv.org/abs/2408.14435v1</link><description>We explore social perception of human faces in CLIP, a widely usedopen-source vision-language model. To this end, we compare the similarity inCLIP embeddings between different textual prompts and a set of face images. Ourtextual prompts are constructed from well-validated social psychology termsdenoting social perception. The face images are synthetic and aresystematically and independently varied along six dimensions: the legallyprotected attributes of age, gender, and race, as well as facial expression,lighting, and pose. Independently and systematically manipulating faceattributes allows us to study the effect of each on social perception andavoids confounds that can occur in wild-collected data due to uncontrolledsystematic correlations between attributes. Thus, our findings are experimentalrather than observational. Our main findings are three. First, while CLIP istrained on the widest variety of images and texts, it is able to makefine-grained human-like social judgments on face images. Second, age, gender,and race do systematically impact CLIP's social perception of faces, suggestingan undesirable bias in CLIP vis-a-vis legally protected attributes. Moststrikingly, we find a strong pattern of bias concerning the faces of Blackwomen, where CLIP produces extreme values of social perception across differentages and facial expressions. Third, facial expression impacts social perceptionmore than age and lighting as much as age. The last finding predicts thatstudies that do not control for unprotected visual attributes may reach thewrong conclusions on bias. Our novel method of investigation, which is foundedon the social psychology literature and on the experiments involving themanipulation of individual attributes, yields sharper and more reliableobservations than previous observational methods and may be applied to studybiases in any vision-language model.</description><author>Carina I. Hausladen, Manuel Knott, Colin F. Camerer, Pietro Perona</author><pubDate>Mon, 26 Aug 2024 17:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14435v1</guid></item><item><title>Employing Artificial Intelligence to Steer Exascale Workflows with Colmena</title><link>http://arxiv.org/abs/2408.14434v1</link><description>Computational workflows are a common class of application on supercomputers,yet the loosely coupled and heterogeneous nature of workflows often fails totake full advantage of their capabilities. We created Colmena to leverage themassive parallelism of a supercomputer by using Artificial Intelligence (AI) tolearn from and adapt a workflow as it executes. Colmena allows scientists todefine how their application should respond to events (e.g., task completion)as a series of cooperative agents. In this paper, we describe the design ofColmena, the challenges we overcame while deploying applications on exascalesystems, and the science workflows we have enhanced through interweaving AI.The scaling challenges we discuss include developing steering strategies thatmaximize node utilization, introducing data fabrics that reduce communicationoverhead of data-intensive tasks, and implementing workflow tasks that cachecostly operations between invocations. These innovations coupled with a varietyof application patterns accessible through our agent-based steering model haveenabled science advances in chemistry, biophysics, and materials science usingdifferent types of AI. Our vision is that Colmena will spur creative solutionsthat harness AI across many domains of scientific computing.</description><author>Logan Ward, J. Gregory Pauloski, Valerie Hayot-Sasson, Yadu Babuji, Alexander Brace, Ryan Chard, Kyle Chard, Rajeev Thakur, Ian Foster</author><pubDate>Mon, 26 Aug 2024 17:21:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14434v1</guid></item><item><title>Contextual Bandit with Herding Effects: Algorithms and Recommendation Applications</title><link>http://arxiv.org/abs/2408.14432v1</link><description>Contextual bandits serve as a fundamental algorithmic framework foroptimizing recommendation decisions online. Though extensive attention has beenpaid to tailoring contextual bandits for recommendation applications, the"herding effects" in user feedback have been ignored. These herding effectsbias user feedback toward historical ratings, breaking down the assumption ofunbiased feedback inherent in contextual bandits. This paper develops a novelvariant of the contextual bandit that is tailored to address the feedback biascaused by the herding effects. A user feedback model is formulated to capturethis feedback bias. We design the TS-Conf (Thompson Sampling under Conformity)algorithm, which employs posterior sampling to balance the exploration andexploitation tradeoff. We prove an upper bound for the regret of the algorithm,revealing the impact of herding effects on learning speed. Extensiveexperiments on datasets demonstrate that TS-Conf outperforms four benchmarkalgorithms. Analysis reveals that TS-Conf effectively mitigates the negativeimpact of herding effects, resulting in faster learning and improvedrecommendation accuracy.</description><author>Luyue Xu, Liming Wang, Hong Xie, Mingqiang Zhou</author><pubDate>Mon, 26 Aug 2024 17:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14432v1</guid></item><item><title>Few-Shot 3D Volumetric Segmentation with Multi-Surrogate Fusion</title><link>http://arxiv.org/abs/2408.14427v1</link><description>Conventional 3D medical image segmentation methods typically require learningheavy 3D networks (e.g., 3D-UNet), as well as large amounts of in-domain datawith accurate pixel/voxel-level labels to avoid overfitting. These solutionsare thus extremely time- and labor-expensive, but also may easily fail togeneralize to unseen objects during training. To alleviate this issue, wepresent MSFSeg, a novel few-shot 3D segmentation framework with a lightweightmulti-surrogate fusion (MSF). MSFSeg is able to automatically segment unseen 3Dobjects/organs (during training) provided with one or a few annotated 2D slicesor 3D sequence segments, via learning dense query-support organ/lesion anatomycorrelations across patient populations. Our proposed MSF module minescomprehensive and diversified morphology correlations between unlabeled and thefew labeled slices/sequences through multiple designated surrogates, making itable to generate accurate cross-domain 3D segmentation masks given annotatedslices or sequences. We demonstrate the effectiveness of our proposed frameworkby showing superior performance on conventional few-shot segmentationbenchmarks compared to prior art, and remarkable cross-domain cross-volumesegmentation performance on proprietary 3D segmentation datasets forchallenging entities, i.e., tubular structures, with only limited 2D or 3Dlabels.</description><author>Meng Zheng, Benjamin Planche, Zhongpai Gao, Terrence Chen, Richard J. Radke, Ziyan Wu</author><pubDate>Mon, 26 Aug 2024 17:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14427v1</guid></item><item><title>Tackling GenAI Copyright Issues: Originality Estimation and Genericization</title><link>http://arxiv.org/abs/2406.03341v4</link><description>The rapid progress of generative AI technology has sparked significantcopyright concerns, leading to numerous lawsuits filed against AI developers.While various techniques for mitigating copyright issues have been studied,significant risks remain. Here, we propose a genericization method thatmodifies the outputs of a generative model to make them more generic and lesslikely to infringe copyright. To achieve this, we introduce a metric forquantifying the level of originality of data in a manner that is consistentwith the legal framework. This metric can be practically estimated by drawingsamples from a generative model, which is then used for the genericizationprocess. As a practical implementation, we introduce PREGen, which combines ourgenericization method with an existing mitigation technique. Experimentsdemonstrate that our genericization method successfully modifies the output ofa text-to-image generative model so that it produces more generic,copyright-compliant images. Compared to the existing method, PREGen reduces thelikelihood of generating copyrighted characters by more than half when thenames of copyrighted characters are used as the prompt, dramatically improvingthe performance. Additionally, while generative models can produce copyrightedcharacters even when their names are not directly mentioned in the prompt,PREGen almost entirely prevents the generation of such characters in thesecases.</description><author>Hiroaki Chiba-Okabe, Weijie J. Su</author><pubDate>Mon, 26 Aug 2024 17:12:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03341v4</guid></item><item><title>Asymptotic Dynamics of Alternating Minimization for Bilinear Regression</title><link>http://arxiv.org/abs/2402.04751v2</link><description>This study investigates the asymptotic dynamics of alternating minimizationapplied to optimize a bilinear non-convex function with normally distributedcovariates. This is achieved by employing the replica method to amulti-temperature glassy system which unfolds the algorithm's time evolution.Our results show that the dynamics can be described effectively by atwo-dimensional discrete stochastic process, where each step depends on allprevious time steps, revealing the structure of the memory dependence in theevolution of alternating minimization. The theoretical framework developed inthis work can be applied to the analysis of various iterative algorithms,extending beyond the scope of alternating minimization.</description><author>Koki Okajima, Takashi Takahashi</author><pubDate>Mon, 26 Aug 2024 17:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04751v2</guid></item><item><title>Efficient Model-Stealing Attacks Against Inductive Graph Neural Networks</title><link>http://arxiv.org/abs/2405.12295v3</link><description>Graph Neural Networks (GNNs) are recognized as potent tools for processingreal-world data organized in graph structures. Especially inductive GNNs, whichallow for the processing of graph-structured data without relying on predefinedgraph structures, are becoming increasingly important in a wide range ofapplications. As such these networks become attractive targets formodel-stealing attacks where an adversary seeks to replicate the functionalityof the targeted network. Significant efforts have been devoted to developingmodel-stealing attacks that extract models trained on images and texts.However, little attention has been given to stealing GNNs trained on graphdata. This paper identifies a new method of performing unsupervisedmodel-stealing attacks against inductive GNNs, utilizing graph contrastivelearning and spectral graph augmentations to efficiently extract informationfrom the targeted model. The new type of attack is thoroughly evaluated on sixdatasets and the results show that our approach outperforms the currentstate-of-the-art by Shen et al. (2021). In particular, our attack surpasses thebaseline across all benchmarks, attaining superior fidelity and downstreamaccuracy of the stolen model while necessitating fewer queries directed towardthe target model.</description><author>Marcin Podhajski, Jan Dubiński, Franziska Boenisch, Adam Dziedzic, Agnieszka Pregowska And Tomasz Michalak</author><pubDate>Mon, 26 Aug 2024 17:10:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12295v3</guid></item><item><title>Evaluating saliency scores in point clouds of natural environments by learning surface anomalies</title><link>http://arxiv.org/abs/2408.14421v1</link><description>In recent years, three-dimensional point clouds are used increasingly todocument natural environments. Each dataset contains a diverse set of objects,at varying shapes and sizes, distributed throughout the data and intricatelyintertwined with the topography. Therefore, regions of interest are difficultto find and consequent analyses become a challenge. Inspired from visualperception principles, we propose to differentiate objects of interest from thecluttered environment by evaluating how much they stand out from theirsurroundings, i.e., their geometric salience. Previous saliency detectionapproaches suggested mostly handcrafted attributes for the task. However, suchmethods fail when the data are too noisy or have high levels of texture. Herewe propose a learning-based mechanism that accommodates noise and texturedsurfaces. We assume that within the natural environment any change from theprevalent surface would suggest a salient object. Thus, we first learn theunderlying surface and then search for anomalies within it. Initially, a deepneural network is trained to reconstruct the surface. Regions where thereconstructed part deviates significantly from the original point cloud yield asubstantial reconstruction error, signifying an anomaly, i.e., saliency. Wedemonstrate the effectiveness of the proposed approach by searching for salientfeatures in various natural scenarios, which were acquired by differentacquisition platforms. We show the strong correlation between thereconstruction error and salient objects.</description><author>Reuma Arav, Dennis Wittich, Franz Rottensteiner</author><pubDate>Mon, 26 Aug 2024 17:04:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14421v1</guid></item><item><title>CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2408.14419v1</link><description>We introduce CHARTOM, a visual theory-of-mind benchmark for multimodal largelanguage models. CHARTOM consists of specially designed data visualizingcharts. Given a chart, a language model needs to not only correctly comprehendthe chart (the FACT question) but also judge if the chart will be misleading toa human reader (the MIND question). Both questions have significant societalbenefits. We detail the construction of the CHARTOM benchmark including itscalibration on human performance.</description><author>Shubham Bharti, Shiyun Cheng, Jihyun Rho, Martina Rao, Xiaojin Zhu</author><pubDate>Mon, 26 Aug 2024 17:04:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14419v1</guid></item><item><title>MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues</title><link>http://arxiv.org/abs/2408.14418v1</link><description>Automatic Speech Recognition (ASR) systems are pivotal in transcribing speechinto text, yet the errors they introduce can significantly degrade theperformance of downstream tasks like summarization. This issue is particularlypronounced in clinical dialogue summarization, a low-resource domain wheresupervised data for fine-tuning is scarce, necessitating the use of ASR modelsas black-box solutions. Employing conventional data augmentation for enhancingthe noise robustness of summarization models is not feasible either due to theunavailability of sufficient medical dialogue audio recordings andcorresponding ASR transcripts. To address this challenge, we propose MEDSAGE,an approach for generating synthetic samples for data augmentation using LargeLanguage Models (LLMs). Specifically, we leverage the in-context learningcapabilities of LLMs and instruct them to generate ASR-like errors based on afew available medical dialogue examples with audio recordings. Experimentalresults show that LLMs can effectively model ASR noise, and incorporating thisnoisy data into the training process significantly improves the robustness andaccuracy of medical dialogue summarization systems. This approach addresses thechallenges of noisy ASR outputs in critical applications, offering a robustsolution to enhance the reliability of clinical dialogue summarization.</description><author>Kuluhan Binici, Abhinav Ramesh Kashyap, Viktor Schlegel, Andy T. Liu, Vijay Prakash Dwivedi, Thanh-Tung Nguyen, Xiaoxue Gao, Nancy F. Chen, Stefan Winkler</author><pubDate>Mon, 26 Aug 2024 17:04:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14418v1</guid></item><item><title>Hyperdimensional Computing Empowered Federated Foundation Model over Wireless Networks for Metaverse</title><link>http://arxiv.org/abs/2408.14416v1</link><description>The Metaverse, a burgeoning collective virtual space merging augmentedreality and persistent virtual worlds, necessitates advanced artificialintelligence (AI) and communication technologies to support immersive andinteractive experiences. Federated learning (FL) has emerged as a promisingtechnique for collaboratively training AI models while preserving data privacy.However, FL faces challenges such as high communication overhead andsubstantial computational demands, particularly for neural network (NN) models.To address these issues, we propose an integrated federated split learning andhyperdimensional computing (FSL-HDC) framework for emerging foundation models.This novel approach reduces communication costs, computation load, and privacyrisks, making it particularly suitable for resource-constrained edge devices inthe Metaverse, ensuring real-time responsive interactions. Additionally, weintroduce an optimization algorithm that concurrently optimizes transmissionpower and bandwidth to minimize the maximum transmission time among all usersto the server. The simulation results based on the MNIST dataset indicate thatFSL-HDC achieves an accuracy rate of approximately 87.5%, which is slightlylower than that of FL-HDC. However, FSL-HDC exhibits a significantly fasterconvergence speed, approximately 3.733x that of FSL-NN, and demonstratesrobustness to non-IID data distributions. Moreover, our proposed optimizationalgorithm can reduce the maximum transmission time by up to 64% compared withthe baseline.</description><author>Yahao Ding, Wen Shang, Minrui Xu, Zhaohui Yang, Ye Hu, Dusit Niyato, Mohammad Shikh-Bahaei</author><pubDate>Mon, 26 Aug 2024 17:03:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14416v1</guid></item><item><title>LoG-VMamba: Local-Global Vision Mamba for Medical Image Segmentation</title><link>http://arxiv.org/abs/2408.14415v1</link><description>Mamba, a State Space Model (SSM), has recently shown competitive performanceto Convolutional Neural Networks (CNNs) and Transformers in Natural LanguageProcessing and general sequence modeling. Various attempts have been made toadapt Mamba to Computer Vision tasks, including medical image segmentation(MIS). Vision Mamba (VM)-based networks are particularly attractive due totheir ability to achieve global receptive fields, similar to VisionTransformers, while also maintaining linear complexity in the number of tokens.However, the existing VM models still struggle to maintain both spatially localand global dependencies of tokens in high dimensional arrays due to theirsequential nature. Employing multiple and/or complicated scanning strategies iscomputationally costly, which hinders applications of SSMs to high-dimensional2D and 3D images that are common in MIS problems. In this work, we proposeLocal-Global Vision Mamba, LoG-VMamba, that explicitly enforces spatiallyadjacent tokens to remain nearby on the channel axis, and retains the globalcontext in a compressed form. Our method allows the SSMs to access the localand global contexts even before reaching the last token while requiring only asimple scanning strategy. Our segmentation models are computationally efficientand substantially outperform both CNN and Transformers-based baselines on adiverse set of 2D and 3D MIS tasks. The implementation of LoG-VMamba isavailable at \url{https://github.com/Oulu-IMEDS/LoG-VMamba}.</description><author>Trung Dinh Quoc Dang, Huy Hoang Nguyen, Aleksei Tiulpin</author><pubDate>Mon, 26 Aug 2024 17:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14415v1</guid></item><item><title>Prediction Instability in Machine Learning Ensembles</title><link>http://arxiv.org/abs/2407.03194v5</link><description>In machine learning ensembles predictions from multiple models areaggregated. Despite widespread use and strong performance of ensembles inapplied problems little is known about the mathematical properties ofaggregating models and associated consequences for safe, explainable use ofsuch models. In this paper we prove a theorem that shows that any ensemble willexhibit at least one of the following forms of prediction instability. It willeither ignore agreement among all underlying models, change its mind when noneof the underlying models have done so, or be manipulable through inclusion orexclusion of options it would never actually predict. As a consequence,ensemble aggregation procedures will always need to balance the benefits ofinformation use against the risk of these prediction instabilities. Thisanalysis also sheds light on what specific forms of prediction instability toexpect from particular ensemble algorithms; for example popular tree ensembleslike random forest, or xgboost will violate basic, intuitive fairnessproperties. Finally, we show that this can be ameliorated by using consistentmodels in asymptotic conditions.</description><author>Jeremy Kedziora</author><pubDate>Mon, 26 Aug 2024 16:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03194v5</guid></item><item><title>Implicit Concept Removal of Diffusion Models</title><link>http://arxiv.org/abs/2310.05873v6</link><description>Text-to-image (T2I) diffusion models often inadvertently generate unwantedconcepts such as watermarks and unsafe images. These concepts, termed as the"implicit concepts", could be unintentionally learned during training and thenbe generated uncontrollably during inference. Existing removal methods stillstruggle to eliminate implicit concepts primarily due to their dependency onthe model's ability to recognize concepts it actually can not discern. Toaddress this, we utilize the intrinsic geometric characteristics of implicitconcepts and present the Geom-Erasing, a novel concept removal method based onthe geometric-driven control. Specifically, once an unwanted implicit conceptis identified, we integrate the existence and geometric information of theconcept into the text prompts with the help of an accessible classifier ordetector model. Subsequently, the model is optimized to identify anddisentangle this information, which is then adopted as negative prompts duringgeneration. Moreover, we introduce the Implicit Concept Dataset (ICD), a novelimage-text dataset imbued with three typical implicit concepts (i.e., QR codes,watermarks, and text), reflecting real-life situations where implicit conceptsare easily injected. Geom-Erasing effectively mitigates the generation ofimplicit concepts, achieving the state-of-the-art results on the InappropriateImage Prompts (I2P) and our challenging Implicit Concept Dataset (ICD)benchmarks.</description><author>Zhili Liu, Kai Chen, Yifan Zhang, Jianhua Han, Lanqing Hong, Hang Xu, Zhenguo Li, Dit-Yan Yeung, James Kwok</author><pubDate>Mon, 26 Aug 2024 16:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05873v6</guid></item><item><title>Spectrally Informed Learning of Fluid Flows</title><link>http://arxiv.org/abs/2408.14407v1</link><description>Accurate and efficient fluid flow models are essential for applicationsrelating to many physical phenomena including geophysical, aerodynamic, andbiological systems. While these flows may exhibit rich and multiscale dynamics,in many cases underlying low-rank structures exist which describe the bulk ofthe motion. These structures tend to be spatially large and temporally slow,and may contain most of the energy in a given flow. The extraction andparsimonious representation of these low-rank dynamics from high-dimensionaldata is a key challenge. Inspired by the success of physics-informed machinelearning methods, we propose a spectrally-informed approach to extract low-rankmodels of fluid flows by leveraging known spectral properties in the learningprocess. We incorporate this knowledge by imposing regularizations on thelearned dynamics, which bias the training process towards learninglow-frequency structures with corresponding higher power. We demonstrate theeffectiveness of this method to improve prediction and produce learned modelswhich better match the underlying spectral properties of prototypical fluidflows.</description><author>Benjamin D. Shaffer, Jeremy R. Vorenberg, M. Ani Hsieh</author><pubDate>Mon, 26 Aug 2024 16:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14407v1</guid></item><item><title>A Dataset and Benchmark for Hospital Course Summarization with Adapted Large Language Models</title><link>http://arxiv.org/abs/2403.05720v2</link><description>Brief hospital course (BHC) summaries are clinical documents that summarize apatient's hospital stay. While large language models (LLMs) depict remarkablecapabilities in automating real-world tasks, their capabilities for healthcareapplications such as synthesizing BHCs from clinical notes have not been shown.We introduce a novel pre-processed dataset, the MIMIC-IV-BHC, encapsulatingclinical note and brief hospital course (BHC) pairs to adapt LLMs for BHCsynthesis. Furthermore, we introduce a benchmark of the summarizationperformance of two general-purpose LLMs and three healthcare-adapted LLMs. Using clinical notes as input, we apply prompting-based (using in-contextlearning) and fine-tuning-based adaptation strategies to three open-source LLMs(Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5,GPT-4). We evaluate these LLMs across multiple context-length inputs usingnatural language similarity metrics. We further conduct a clinical study withfive clinicians, comparing clinician-written and LLM-generated BHCs across 30samples, focusing on their potential to enhance clinical decision-makingthrough improved summary quality. We observe that the Llama2-13B fine-tuned LLMoutperforms other domain-adapted models given quantitative evaluation metricsof BLEU and BERT-Score. GPT-4 with in-context learning shows more robustness toincreasing context lengths of clinical note inputs than fine-tuned Llama2-13B.Despite comparable quantitative metrics, the reader study depicts a significantpreference for summaries generated by GPT-4 with in-context learning comparedto both Llama2-13B fine-tuned summaries and the original summaries,highlighting the need for qualitative clinical evaluation.</description><author>Asad Aali, Dave Van Veen, Yamin Ishraq Arefeen, Jason Hom, Christian Bluethgen, Eduardo Pontes Reis, Sergios Gatidis, Namuun Clifford, Joseph Daws, Arash S. Tehrani, Jangwon Kim, Akshay S. Chaudhari</author><pubDate>Mon, 26 Aug 2024 16:48:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05720v2</guid></item><item><title>Application of Neural Ordinary Differential Equations for ITER Burning Plasma Dynamics</title><link>http://arxiv.org/abs/2408.14404v1</link><description>The dynamics of burning plasmas in tokamaks are crucial for advancingcontrolled thermonuclear fusion. This study introduces the NeuralPlasmaODE, amulti-region multi-timescale transport model to simulate the complex energytransfer processes in ITER deuterium-tritium (D-T) plasmas. Our model capturesthe interactions between energetic alpha particles, electrons, and ions, whichare vital for understanding phenomena such as thermal runaway instability. Weemploy neural ordinary differential equations (Neural ODEs) for the numericalderivation of diffusivity parameters, enabling precise modeling of energyinteractions between different plasma regions. By leveraging transfer learning,we utilize model parameters derived from DIII-D experimental data, enhancingthe efficiency and accuracy of our simulations without training from scratch.Applying this model to ITER's inductive and non-inductive operationalscenarios, our results demonstrate that radiation and transport processeseffectively remove excess heat from the core plasma, preventing thermal runawayinstability. This study underscores the potential of machine learning inadvancing our understanding and control of burning plasma dynamics in fusionreactors.</description><author>Zefang Liu, Weston M. Stacey</author><pubDate>Mon, 26 Aug 2024 16:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14404v1</guid></item><item><title>Global Attractor for a Reaction-Diffusion Model Arising in Biological Dynamic in 3D Soil Structure</title><link>http://arxiv.org/abs/2310.02060v3</link><description>Partial Differential Equations (PDEs) play a crucial role as tools formodeling and comprehending intricate natural processes, notably within thedomain of biology. This research explores the domain of microbial activitywithin the complex matrix of 3D soil structures, providing valuableunderstanding into both the existence and uniqueness of solutions and theasymptotic behavior of the corresponding PDE model. Our investigation resultsin the discovery of a global attractor, a fundamental feature with significantimplications for long-term system behavior. To enhance the clarity of ourfindings, numerical simulations are employed to visually illustrate theattributes of this global attractor.</description><author>Mohamed Elghandouri, Khalil Ezzinbi, Mouad Klai, Olivier Monga</author><pubDate>Mon, 26 Aug 2024 16:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02060v3</guid></item><item><title>A quasi-Bayesian sequential approach to deconvolution density estimation</title><link>http://arxiv.org/abs/2408.14402v1</link><description>Density deconvolution addresses the estimation of the unknown (probability)density function $f$ of a random signal from data that are observed with anindependent additive random noise. This is a classical problem in statistics,for which frequentist and Bayesian nonparametric approaches are available todeal with static or batch data. In this paper, we consider the problem ofdensity deconvolution in a streaming or online setting where noisy data arriveprogressively, with no predetermined sample size, and we develop a sequentialnonparametric approach to estimate $f$. By relying on a quasi-Bayesiansequential approach, often referred to as Newton's algorithm, we obtainestimates of $f$ that are of easy evaluation, computationally efficient, andwith a computational cost that remains constant as the amount of dataincreases, which is critical in the streaming setting. Large sample asymptoticproperties of the proposed estimates are studied, yielding provable guaranteeswith respect to the estimation of $f$ at a point (local) and on an interval(uniform). In particular, we establish local and uniform central limittheorems, providing corresponding asymptotic credible intervals and bands. Wevalidate empirically our methods on synthetic and real data, by considering thecommon setting of Laplace and Gaussian noise distributions, and make acomparison with respect to the kernel-based approach and a Bayesiannonparametric approach with a Dirichlet process mixture prior.</description><author>Stefano Favaro, Sandra Fortini</author><pubDate>Mon, 26 Aug 2024 16:40:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14402v1</guid></item><item><title>Satellite Sunroof: High-res Digital Surface Models and Roof Segmentation for Global Solar Mapping</title><link>http://arxiv.org/abs/2408.14400v1</link><description>The transition to renewable energy, particularly solar, is key to mitigatingclimate change. Google's Solar API aids this transition by estimating solarpotential from aerial imagery, but its impact is constrained by geographicalcoverage. This paper proposes expanding the API's reach using satelliteimagery, enabling global solar potential assessment. We tackle challengesinvolved in building a Digital Surface Model (DSM) and roof instancesegmentation from lower resolution and single oblique views using deep learningmodels. Our models, trained on aligned satellite and aerial datasets, produce25cm DSMs and roof segments. With ~1m DSM MAE on buildings, ~5deg roof pitcherror and ~56% IOU on roof segmentation, they significantly enhance the SolarAPI's potential to promote solar adoption.</description><author>Vishal Batchu, Alex Wilson, Betty Peng, Carl Elkin, Umangi Jain, Christopher Van Arsdale, Ross Goroshin, Varun Gulshan</author><pubDate>Mon, 26 Aug 2024 16:34:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14400v1</guid></item><item><title>Language-specific Calibration for Pruning Multilingual Language Models</title><link>http://arxiv.org/abs/2408.14398v1</link><description>Recent advances in large language model (LLM) pruning have shownstate-of-the-art compression results in post-training and retraining-freesettings while maintaining high predictive performance. However, such researchmainly considers calibrating pruning using English text, despite themultilingual nature of modern LLMs and their frequent uses in non-Englishlanguages. In this paper, we set out to explore effective strategies forcalibrating the pruning of multilingual language models. We present the firstcomprehensive empirical study, comparing different calibration languages forpruning multilingual models across diverse tasks, models, and state-of-the-artpruning techniques. Our results present practical suggestions, for example,calibrating in the target language can efficiently yield lower perplexity, butdoes not necessarily benefit downstream tasks. Our further analysis experimentsunveil that calibration in the target language mainly contributes to preservinglanguage-specific features related to fluency and coherence, but might notcontribute to capturing language-agnostic features such as languageunderstanding and reasoning. Last, we provide practical recommendations forfuture practitioners.</description><author>Simon Kurz, Zhixue Zhao, Jian-Jia Chen, Lucie Flek</author><pubDate>Mon, 26 Aug 2024 16:29:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14398v1</guid></item><item><title>Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs</title><link>http://arxiv.org/abs/2408.14397v1</link><description>Recent advancements in artificial intelligence have significantly improvedthe automatic generation of radiology reports. However, existing evaluationmethods fail to reveal the models' understanding of radiological images andtheir capacity to achieve human-level granularity in descriptions. To bridgethis gap, we introduce a system, named ReXKG, which extracts structuredinformation from processed reports to construct a comprehensive radiologyknowledge graph. We then propose three metrics to evaluate the similarity ofnodes (ReXKG-NSC), distribution of edges (ReXKG-AMS), and coverage of subgraphs(ReXKG-SCS) across various knowledge graphs. We conduct an in-depth comparativeanalysis of AI-generated and human-written radiology reports, assessing theperformance of both specialist and generalist models. Our study provides adeeper understanding of the capabilities and limitations of current AI modelsin radiology report generation, offering valuable insights for improving modelperformance and clinical applicability.</description><author>Xiaoman Zhang, Julián N. Acosta, Hong-Yu Zhou, Pranav Rajpurkar</author><pubDate>Mon, 26 Aug 2024 16:28:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14397v1</guid></item><item><title>On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection Strategy</title><link>http://arxiv.org/abs/2402.00752v4</link><description>3D Gaussian Splatting has garnered extensive attention and application inreal-time neural rendering. Concurrently, concerns have been raised about thelimitations of this technology in aspects such as point cloud storage,performance, and robustness in sparse viewpoints, leading to variousimprovements. However, there has been a notable lack of attention to thefundamental problem of projection errors introduced by the local affineapproximation inherent in the splatting itself, and the consequential impact ofthese errors on the quality of photo-realistic rendering. This paper addressesthe projection error function of 3D Gaussian Splatting, commencing with theresidual error from the first-order Taylor expansion of the projectionfunction. The analysis establishes a correlation between the error and theGaussian mean position. Subsequently, leveraging function optimization theory,this paper analyzes the function's minima to provide an optimal projectionstrategy for Gaussian Splatting referred to Optimal Gaussian Splatting, whichcan accommodate a variety of camera models. Experimental validation furtherconfirms that this projection methodology reduces artifacts, resulting in amore convincingly realistic rendering.</description><author>Letian Huang, Jiayang Bai, Jie Guo, Yuanqi Li, Yanwen Guo</author><pubDate>Mon, 26 Aug 2024 16:27:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00752v4</guid></item><item><title>DQ-DETR: DETR with Dynamic Query for Tiny Object Detection</title><link>http://arxiv.org/abs/2404.03507v3</link><description>Despite previous DETR-like methods having performed successfully in genericobject detection, tiny object detection is still a challenging task for themsince the positional information of object queries is not customized fordetecting tiny objects, whose scale is extraordinarily smaller than generalobjects. Also, DETR-like methods using a fixed number of queries make themunsuitable for aerial datasets, which only contain tiny objects, and thenumbers of instances are imbalanced between different images. Thus, we presenta simple yet effective model, named DQ-DETR, which consists of three differentcomponents: categorical counting module, counting-guided feature enhancement,and dynamic query selection to solve the above-mentioned problems. DQ-DETR usesthe prediction and density maps from the categorical counting module todynamically adjust the number of object queries and improve the positionalinformation of queries. Our model DQ-DETR outperforms previous CNN-based andDETR-like methods, achieving state-of-the-art mAP 30.2% on the AI-TOD-V2dataset, which mostly consists of tiny objects.</description><author>Yi-Xin Huang, Hou-I Liu, Hong-Han Shuai, Wen-Huang Cheng</author><pubDate>Mon, 26 Aug 2024 16:22:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03507v3</guid></item><item><title>CURE4Rec: A Benchmark for Recommendation Unlearning with Deeper Influence</title><link>http://arxiv.org/abs/2408.14393v1</link><description>With increasing privacy concerns in artificial intelligence, regulations havemandated the right to be forgotten, granting individuals the right to withdrawtheir data from models. Machine unlearning has emerged as a potential solutionto enable selective forgetting in models, particularly in recommender systemswhere historical data contains sensitive user information. Despite recentadvances in recommendation unlearning, evaluating unlearning methodscomprehensively remains challenging due to the absence of a unified evaluationframework and overlooked aspects of deeper influence, e.g., fairness. Toaddress these gaps, we propose CURE4Rec, the first comprehensive benchmark forrecommendation unlearning evaluation. CURE4Rec covers four aspects, i.e.,unlearning Completeness, recommendation Utility, unleaRning efficiency, andrecommendation fairnEss, under three data selection strategies, i.e., coredata, edge data, and random data. Specifically, we consider the deeperinfluence of unlearning on recommendation fairness and robustness towards datawith varying impact levels. We construct multiple datasets with CURE4Recevaluation and conduct extensive experiments on existing recommendationunlearning methods. Our code is released athttps://github.com/xiye7lai/CURE4Rec.</description><author>Chaochao Chen, Jiaming Zhang, Yizhao Zhang, Li Zhang, Lingjuan Lyu, Yuyuan Li, Biao Gong, Chenggang Yan</author><pubDate>Mon, 26 Aug 2024 16:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14393v1</guid></item><item><title>SpikeGS: Reconstruct 3D scene via fast-moving bio-inspired sensors</title><link>http://arxiv.org/abs/2407.03771v2</link><description>3D Gaussian Splatting (3DGS) demonstrates unparalleled superior performancein 3D scene reconstruction. However, 3DGS heavily relies on the sharp images.Fulfilling this requirement can be challenging in real-world scenariosespecially when the camera moves fast, which severely limits the application of3DGS. To address these challenges, we proposed Spike Gausian Splatting(SpikeGS), the first framework that integrates the spike streams into 3DGSpipeline to reconstruct 3D scenes via a fast-moving bio-inspired camera. Withaccumulation rasterization, interval supervision, and a specially designedpipeline, SpikeGS extracts detailed geometry and texture from high temporalresolution but texture lacking spike stream, reconstructs 3D scenes captured in1 second. Extensive experiments on multiple synthetic and real-world datasetsdemonstrate the superiority of SpikeGS compared with existing spike-based anddeblur 3D scene reconstruction methods. Codes and data will be released soon.</description><author>Yijia Guo, Liwen Hu, Lei Ma, Tiejun Huang</author><pubDate>Mon, 26 Aug 2024 16:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03771v2</guid></item><item><title>GloSoFarID: Global multispectral dataset for Solar Farm IDentification in satellite imagery</title><link>http://arxiv.org/abs/2404.05180v2</link><description>Solar Photovoltaic (PV) technology is increasingly recognized as a pivotalsolution in the global pursuit of clean and renewable energy. This technologyaddresses the urgent need for sustainable energy alternatives by convertingsolar power into electricity without greenhouse gas emissions. It not onlycurtails global carbon emissions but also reduces reliance on finite,non-renewable energy sources. In this context, monitoring solar panel farmsbecomes essential for understanding and facilitating the worldwide shift towardclean energy. This study contributes to this effort by developing the firstcomprehensive global dataset of multispectral satellite imagery of solar panelfarms. This dataset is intended to form the basis for training robust machinelearning models, which can accurately map and analyze the expansion anddistribution of solar panel farms globally. The insights gained from thisendeavor will be instrumental in guiding informed decision-making for asustainable energy future. https://github.com/yzyly1992/GloSoFarID</description><author>Zhiyuan Yang, Ryan Rad</author><pubDate>Mon, 26 Aug 2024 16:13:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05180v2</guid></item><item><title>Reprogramming Foundational Large Language Models(LLMs) for Enterprise Adoption for Spatio-Temporal Forecasting Applications: Unveiling a New Era in Copilot-Guided Cross-Modal Time Series Representation Learning</title><link>http://arxiv.org/abs/2408.14387v1</link><description>Spatio-temporal forecasting plays a crucial role in various sectors such astransportation systems, logistics, and supply chain management. However,existing methods are limited by their ability to handle large, complexdatasets. To overcome this limitation, we introduce a hybrid approach thatcombines the strengths of open-source large and small-scale language models(LLMs and LMs) with traditional forecasting methods. We augment traditionalmethods with dynamic prompting and a grouped-query, multi-head attentionmechanism to more effectively capture both intra-series and inter-seriesdependencies in evolving nonlinear time series data. In addition, we facilitateon-premises customization by fine-tuning smaller open-source LMs for timeseries trend analysis utilizing descriptions generated by open-source large LMson consumer-grade hardware using Low-Rank Adaptation with Activation MemoryReduction (LoRA-AMR) technique to reduce computational overhead and activationstorage memory demands while preserving inference latency. We combine languagemodel processing for time series trend analysis with traditional time seriesrepresentation learning method for cross-modal integration, achieving robustand accurate forecasts. The framework effectiveness is demonstrated throughextensive experiments on various real-world datasets, outperforming existingmethods by significant margins in terms of forecast accuracy.</description><author>Sakhinana Sagar Srinivas, Chidaksh Ravuru, Geethan Sannidhi, Venkataramana Runkana</author><pubDate>Mon, 26 Aug 2024 16:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14387v1</guid></item><item><title>Learning Tree-Structured Composition of Data Augmentation</title><link>http://arxiv.org/abs/2408.14381v1</link><description>Data augmentation is widely used for training a neural network given littlelabeled data. A common practice of augmentation training is applying acomposition of multiple transformations sequentially to the data. Existingaugmentation methods such as RandAugment randomly sample from a list ofpre-selected transformations, while methods such as AutoAugment apply advancedsearch to optimize over an augmentation set of size $k^d$, which is the numberof transformation sequences of length $d$, given a list of $k$ transformations. In this paper, we design efficient algorithms whose running time complexityis much faster than the worst-case complexity of $O(k^d)$, provably. We proposea new algorithm to search for a binary tree-structured composition of $k$transformations, where each tree node corresponds to one transformation. Thebinary tree generalizes sequential augmentations, such as the SimCLRaugmentation scheme for contrastive learning. Using a top-down, recursivesearch procedure, our algorithm achieves a runtime complexity of $O(2^d k)$,which is much faster than $O(k^d)$ as $k$ increases above $2$. We apply ouralgorithm to tackle data distributions with heterogeneous subpopulations bysearching for one tree in each subpopulation and then learning a weightedcombination, resulting in a forest of trees. We validate our proposed algorithms on numerous graph and image datasets,including a multi-label graph classification dataset we collected. The datasetexhibits significant variations in the sizes of graphs and their averagedegrees, making it ideal for studying data augmentation. We show that ourapproach can reduce the computation cost by 43% over existing search methodswhile improving performance by 4.3%. The tree structures can be used tointerpret the relative importance of each transformation, such as identifyingthe important transformations on small vs. large graphs.</description><author>Dongyue Li, Kailai Chen, Predrag Radivojac, Hongyang R. Zhang</author><pubDate>Mon, 26 Aug 2024 16:04:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14381v1</guid></item><item><title>Probing Causality Manipulation of Large Language Models</title><link>http://arxiv.org/abs/2408.14380v1</link><description>Large language models (LLMs) have shown various ability on natural languageprocessing, including problems about causality. It is not intuitive for LLMs tocommand causality, since pretrained models usually work on statisticalassociations, and do not focus on causes and effects in sentences. So thatprobing internal manipulation of causality is necessary for LLMs. This paperproposes a novel approach to probe causality manipulation hierarchically, byproviding different shortcuts to models and observe behaviors. We exploitretrieval augmented generation (RAG) and in-context learning (ICL) for modelson a designed causality classification task. We conduct experiments onmainstream LLMs, including GPT-4 and some smaller and domain-specific models.Our results suggest that LLMs can detect entities related to causality andrecognize direct causal relationships. However, LLMs lack specialized cognitionfor causality, merely treating them as part of the global semantic of thesentence.</description><author>Chenyang Zhang, Haibo Tong, Bin Zhang, Dongyu Zhang</author><pubDate>Mon, 26 Aug 2024 16:00:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14380v1</guid></item><item><title>Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics</title><link>http://arxiv.org/abs/2404.19178v2</link><description>Transformers have generally supplanted recurrent neural networks as thedominant architecture for both natural language processing tasks and formodelling the effect of predictability on online human language comprehension.However, two recently developed recurrent model architectures, RWKV and Mamba,appear to perform natural language tasks comparably to or better thantransformers of equivalent scale. In this paper, we show that contemporaryrecurrent models are now also able to match - and in some cases, exceed - theperformance of comparably sized transformers at modeling online human languagecomprehension. This suggests that transformer language models are not uniquelysuited to this task, and opens up new directions for debates about the extentto which architectural features of language models make them better or worsemodels of human language comprehension.</description><author>James A. Michaelov, Catherine Arnett, Benjamin K. Bergen</author><pubDate>Mon, 26 Aug 2024 15:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19178v2</guid></item><item><title>SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery</title><link>http://arxiv.org/abs/2408.14371v1</link><description>In this paper, we address Generalized Category Discovery, aiming tosimultaneously uncover novel categories and accurately classify known ones.Traditional methods, which lean heavily on self-supervision and contrastivelearning, often fall short when distinguishing between fine-grained categories.To address this, we introduce a novel concept called `self-expertise', whichenhances the model's ability to recognize subtle differences and uncoverunknown categories. Our approach combines unsupervised and supervisedself-expertise strategies to refine the model's discernment and generalization.Initially, hierarchical pseudo-labeling is used to provide `soft supervision',improving the effectiveness of self-expertise. Our supervised technique differsfrom traditional methods by utilizing more abstract positive and negativesamples, aiding in the formation of clusters that can generalize to novelcategories. Meanwhile, our unsupervised strategy encourages the model tosharpen its category distinctions by considering within-category examples as`hard' negatives. Supported by theoretical insights, our empirical resultsshowcase that our method outperforms existing state-of-the-art techniques inGeneralized Category Discovery across several fine-grained datasets. Our codeis available at: https://github.com/SarahRastegar/SelEx.</description><author>Sarah Rastegar, Mohammadreza Salehi, Yuki M. Asano, Hazel Doughty, Cees G. M. Snoek</author><pubDate>Mon, 26 Aug 2024 15:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14371v1</guid></item><item><title>Graph-SCP: Accelerating Set Cover Problems with Graph Neural Networks</title><link>http://arxiv.org/abs/2310.07979v2</link><description>Machine learning (ML) approaches are increasingly being used to acceleratecombinatorial optimization (CO) problems. We investigate the Set Cover Problem(SCP) and propose Graph-SCP, a graph neural network method that augmentsexisting optimization solvers by learning to identify a much smallersub-problem that contains the solution space. Graph-SCP uses both supervisedlearning from prior solved instances and unsupervised learning aimed atminimizing the SCP objective. We evaluate the performance of Graph-SCP onsynthetically weighted and unweighted SCP instances with diverse problemcharacteristics and complexities, and on instances from the OR Library, acanonical benchmark for SCP. We show that Graph-SCP reduces the problem size by60-80% and achieves runtime speedups of up to 10x on average when compared toGurobi (a state-of-the-art commercial solver), while maintaining solutionquality. This is in contrast to fast greedy solutions that significantlycompromise solution quality to achieve guaranteed polynomial runtime. Weshowcase Graph-SCP's ability to generalize to larger problem sizes, training onSCP instances with up to 3,000 subsets and testing on SCP instances with up to10,000 subsets.</description><author>Zohair Shafi, Benjamin A. Miller, Tina Eliassi-Rad, Rajmonda S. Caceres</author><pubDate>Mon, 26 Aug 2024 15:51:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07979v2</guid></item><item><title>Exploiting Conjugate Label Information for Multi-Instance Partial-Label Learning</title><link>http://arxiv.org/abs/2408.14369v1</link><description>Multi-instance partial-label learning (MIPL) addresses scenarios where eachtraining sample is represented as a multi-instance bag associated with acandidate label set containing one true label and several false positives.Existing MIPL algorithms have primarily focused on mapping multi-instance bagsto candidate label sets for disambiguation, disregarding the intrinsicproperties of the label space and the supervised information provided bynon-candidate label sets. In this paper, we propose an algorithm named ELIMIPL,i.e., Exploiting conjugate Label Information for Multi-Instance Partial-Labellearning, which exploits the conjugate label information to improve thedisambiguation performance. To achieve this, we extract the label informationembedded in both candidate and non-candidate label sets, incorporating theintrinsic properties of the label space. Experimental results obtained frombenchmark and real-world datasets demonstrate the superiority of the proposedELIMIPL over existing MIPL algorithms and other well-established partial-labellearning algorithms.</description><author>Wei Tang, Weijia Zhang, Min-Ling Zhang</author><pubDate>Mon, 26 Aug 2024 15:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14369v1</guid></item><item><title>GR-MG: Leveraging Partially Annotated Data via Multi-Modal Goal Conditioned Policy</title><link>http://arxiv.org/abs/2408.14368v1</link><description>The robotics community has consistently aimed to achieve generalizable robotmanipulation with flexible natural language instructions. One of the primarychallenges is that obtaining robot data fully annotated with both actions andtexts is time-consuming and labor-intensive. However, partially annotated data,such as human activity videos without action labels and robot play data withoutlanguage labels, is much easier to collect. Can we leverage these data toenhance the generalization capability of robots? In this paper, we proposeGR-MG, a novel method which supports conditioning on both a languageinstruction and a goal image. During training, GR-MG samples goal images fromtrajectories and conditions on both the text and the goal image or solely onthe image when text is unavailable. During inference, where only the text isprovided, GR-MG generates the goal image via a diffusion-based image-editingmodel and condition on both the text and the generated image. This approachenables GR-MG to leverage large amounts of partially annotated data while stillusing language to flexibly specify tasks. To generate accurate goal images, wepropose a novel progress-guided goal image generation model which injects taskprogress information into the generation process, significantly improving thefidelity and the performance. In simulation experiments, GR-MG improves theaverage number of tasks completed in a row of 5 from 3.35 to 4.04. Inreal-robot experiments, GR-MG is able to perform 47 different tasks andimproves the success rate from 62.5% to 75.0% and 42.4% to 57.6% in simple andgeneralization settings, respectively. Code and checkpoints will be availableat the project page: https://gr-mg.github.io/.</description><author>Peiyan Li, Hongtao Wu, Yan Huang, Chilam Cheang, Liang Wang, Tao Kong</author><pubDate>Mon, 26 Aug 2024 15:46:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14368v1</guid></item><item><title>Controller Synthesis for Timeline-based Games</title><link>http://arxiv.org/abs/2307.12289v4</link><description>In the timeline-based approach to planning, the evolution over time of a setof state variables (the timelines) is governed by a set of temporalconstraints. Traditional timeline-based planning systems excel at theintegration of planning with execution by handling temporal uncertainty. Inorder to handle general nondeterminism as well, the concept of timeline-basedgames has been recently introduced. It has been proved that finding whether awinning strategy exists for such games is 2EXPTIME-complete. However, aconcrete approach to synthesize controllers implementing such strategies ismissing. This paper fills this gap, by providing an effective andcomputationally optimal approach to controller synthesis for timeline-basedgames.</description><author>Renato Acampora, Luca Geatti, Nicola Gigante, Angelo Montanari, Valentino Picotti</author><pubDate>Mon, 26 Aug 2024 15:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12289v4</guid></item><item><title>Swin transformers are robust to distribution and concept drift in endoscopy-based longitudinal rectal cancer assessment</title><link>http://arxiv.org/abs/2405.03762v2</link><description>Endoscopic images are used at various stages of rectal cancer treatmentstarting from cancer screening, diagnosis, during treatment to assess responseand toxicity from treatments such as colitis, and at follow up to detect newtumor or local regrowth (LR). However, subjective assessment is highly variableand can underestimate the degree of response in some patients, subjecting themto unnecessary surgery, or overestimate response that places patients at riskof disease spread. Advances in deep learning has shown the ability to produceconsistent and objective response assessment for endoscopic images. However,methods for detecting cancers, regrowth, and monitoring response during theentire course of patient treatment and follow-up are lacking. This is because,automated diagnosis and rectal cancer response assessment requires methods thatare robust to inherent imaging illumination variations and confoundingconditions (blood, scope, blurring) present in endoscopy images as well aschanges to the normal lumen and tumor during treatment. Hence, a hierarchicalshifted window (Swin) transformer was trained to distinguish rectal cancer fromnormal lumen using endoscopy images. Swin as well as two convolutional(ResNet-50, WideResNet-50), and vision transformer (ViT) models were trainedand evaluated on follow-up longitudinal images to detect LR on private datasetas well as on out-of-distribution (OOD) public colonoscopy datasets to detectpre/non-cancerous polyps. Color shifts were applied using optimal transport tosimulate distribution shifts. Swin and ResNet models were similarly accurate inthe in-distribution dataset. Swin was more accurate than other methods(follow-up: 0.84, OOD: 0.83) even when subject to color shifts (follow-up:0.83, OOD: 0.87), indicating capability to provide robust performance forlongitudinal cancer assessment.</description><author>Jorge Tapias Gomez, Aneesh Rangnekar, Hannah Williams, Hannah Thompson, Julio Garcia-Aguilar, Joshua Jesse Smith, Harini Veeraraghavan</author><pubDate>Mon, 26 Aug 2024 15:40:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03762v2</guid></item><item><title>An Embedding is Worth a Thousand Noisy Labels</title><link>http://arxiv.org/abs/2408.14358v1</link><description>The performance of deep neural networks scales with dataset size and labelquality, rendering the efficient mitigation of low-quality data annotationscrucial for building robust and cost-effective systems. Existing strategies toaddress label noise exhibit severe limitations due to computational complexityand application dependency. In this work, we propose WANN, a Weighted AdaptiveNearest Neighbor approach that builds on self-supervised featurerepresentations obtained from foundation models. To guide the weighted votingscheme, we introduce a reliability score, which measures the likelihood of adata label being correct. WANN outperforms reference methods, including alinear layer trained with robust loss functions, on diverse datasets of varyingsize and under various noise types and severities. WANN also exhibits superiorgeneralization on imbalanced data compared to both Adaptive-NNs (ANN) and fixedk-NNs. Furthermore, the proposed weighting scheme enhances superviseddimensionality reduction under noisy labels. This yields a significant boost inclassification performance with 10x and 100x smaller image embeddings,minimizing latency and storage requirements. Our approach, emphasizingefficiency and explainability, emerges as a simple, robust solution to overcomethe inherent limitations of deep neural network training. The code is availableat https://github.com/francescodisalvo05/wann-noisy-labels .</description><author>Francesco Di Salvo, Sebastian Doerrich, Ines Rieger, Christian Ledig</author><pubDate>Mon, 26 Aug 2024 15:32:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14358v1</guid></item><item><title>SWE-bench-java: A GitHub Issue Resolving Benchmark for Java</title><link>http://arxiv.org/abs/2408.14354v1</link><description>GitHub issue resolving is a critical task in software engineering, recentlygaining significant attention in both industry and academia. Within this task,SWE-bench has been released to evaluate issue resolving capabilities of largelanguage models (LLMs), but has so far only focused on Python version. However,supporting more programming languages is also important, as there is a strongdemand in industry. As a first step toward multilingual support, we havedeveloped a Java version of SWE-bench, called SWE-bench-java. We have publiclyreleased the dataset, along with the corresponding Docker-based evaluationenvironment and leaderboard, which will be continuously maintained and updatedin the coming months. To verify the reliability of SWE-bench-java, we implementa classic method SWE-agent and test several powerful LLMs on it. As is wellknown, developing a high-quality multi-lingual benchmark is time-consuming andlabor-intensive, so we welcome contributions through pull requests orcollaboration to accelerate its iteration and refinement, paving the way forfully automated programming.</description><author>Daoguang Zan, Zhirong Huang, Ailun Yu, Shaoxin Lin, Yifan Shi, Wei Liu, Dong Chen, Zongshuai Qi, Hao Yu, Lei Yu, Dezhi Ran, Muhan Zeng, Bo Shen, Pan Bian, Guangtai Liang, Bei Guan, Pengjie Huang, Tao Xie, Yongji Wang, Qianxiang Wang</author><pubDate>Mon, 26 Aug 2024 15:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14354v1</guid></item><item><title>Assessing Contamination in Large Language Models: Introducing the LogProber method</title><link>http://arxiv.org/abs/2408.14352v1</link><description>In machine learning, contamination refers to situations where testing dataleak into the training set. The issue is particularly relevant for theevaluation of the performance of Large Language Models (LLMs), which aregenerally trained on gargantuan, and generally opaque, corpora of text scrapedfrom the world wide web. Developing tools to detect contamination is thereforecrucial to be able to fairly and properly track the evolution of theperformance of LLMs. Most recent works in the field are not tailored toquantify contamination on short sequences of text like we find in psychologyquestionnaires. In the present paper we introduce LogProber, a novel,efficient, algorithm that we show able to detect contamination using tokenprobability in given sentences. In the second part we investigate thelimitations of the method and discuss how different training methods cancontaminate models without leaving traces in the token probabilities.</description><author>Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri</author><pubDate>Mon, 26 Aug 2024 15:29:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14352v1</guid></item><item><title>Deep learning-based ecological analysis of camera trap images is impacted by training data quality and size</title><link>http://arxiv.org/abs/2408.14348v1</link><description>Large wildlife image collections from camera traps are crucial forbiodiversity monitoring, offering insights into species richness, occupancy,and activity patterns. However, manual processing of these data istime-consuming, hindering analytical processes. To address this, deep neuralnetworks have been widely adopted to automate image analysis. Despite theirgrowing use, the impact of model training decisions on downstream ecologicalmetrics remains unclear. Here, we analyse camera trap data from an Africansavannah and an Asian sub-tropical dry forest to compare key ecological metricsderived from expert-generated species identifications with those generated fromdeep neural networks. We assess the impact of model architecture, training datanoise, and dataset size on ecological metrics, including species richness,occupancy, and activity patterns. Our results show that while modelarchitecture has minimal impact, large amounts of noise and reduced datasetsize significantly affect these metrics. Nonetheless, estimated ecologicalmetrics are resilient to considerable noise, tolerating up to 10% error inspecies labels and a 50% reduction in training set size without changingsignificantly. We also highlight that conventional metrics like classificationerror may not always be representative of a model's ability to accuratelymeasure ecological metrics. We conclude that ecological metrics derived fromdeep neural network predictions closely match those calculated from expertlabels and remain robust to variations in the factors explored. However,training decisions for deep neural networks can impact downstream ecologicalanalysis. Therefore, practitioners should prioritize creating large, cleantraining sets and evaluate deep neural network solutions based on their abilityto measure the ecological metrics of interest.</description><author>Omiros Pantazis, Peggy Bevan, Holly Pringle, Guilherme Braga Ferreira, Daniel J. Ingram, Emily Madsen, Liam Thomas, Dol Raj Thanet, Thakur Silwal, Santosh Rayamajhi, Gabriel Brostow, Oisin Mac Aodha, Kate E. Jones</author><pubDate>Mon, 26 Aug 2024 15:26:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14348v1</guid></item><item><title>Binocular Model: A deep learning solution for online melt pool temperature analysis using dual-wavelength Imaging Pyrometry</title><link>http://arxiv.org/abs/2408.11126v2</link><description>In metal Additive Manufacturing (AM), monitoring the temperature of the MeltPool (MP) is crucial for ensuring part quality, process stability, defectprevention, and overall process optimization. Traditional methods, are slow toconverge and require extensive manual effort to translate data into actionableinsights, rendering them impractical for real-time monitoring and control. Toaddress this challenge, we propose an Artificial Intelligence (AI)-basedsolution aimed at reducing manual data processing reliance and improving theefficiency of transitioning from data to insight. In our study, we utilize adataset comprising dual-wavelength real-time process monitoring data andcorresponding temperature maps. We introduce a deep learning model called the"Binocular model," which exploits dual input observations to perform a preciseanalysis of MP temperature in Laser Powder Bed Fusion (L-PBF). Through advanceddeep learning techniques, we seamlessly convert raw data into temperature maps,significantly streamlining the process and enabling batch processing at a rateof up to 750 frames per second, approximately 1000 times faster thanconventional methods. Our Binocular model achieves high accuracy in temperatureestimation, evidenced by a 0.95 R-squared score, while simultaneously enhancingprocessing efficiency by a factor of $\sim1000x$ times. This model directlyaddresses the challenge of real-time MP temperature monitoring and offersinsights into the encountered constraints and the benefits of our DeepLearning-based approach. By combining efficiency and precision, our workcontributes to the advancement of temperature monitoring in L-PBF, thus drivingprogress in the field of metal AM.</description><author>Javid Akhavan, Chaitanya Krishna Vallabh, Xiayun Zhao, Souran Manoochehri</author><pubDate>Mon, 26 Aug 2024 15:19:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11126v2</guid></item><item><title>A Brief Analysis of the Iterative Next Boundary Detection Network for Tree Rings Delineation in Images of Pinus taeda</title><link>http://arxiv.org/abs/2408.14343v1</link><description>This work presents the INBD network proposed by Gillert et al. in CVPR-2023and studies its application for delineating tree rings in RGB images of Pinustaeda cross sections captured by a smartphone (UruDendro dataset), which areimages with different characteristics from the ones used to train the method.The INBD network operates in two stages: first, it segments the background,pith, and ring boundaries. In the second stage, the image is transformed intopolar coordinates, and ring boundaries are iteratively segmented from the pithto the bark. Both stages are based on the U-Net architecture. The methodachieves an F-Score of 77.5, a mAR of 0.540, and an ARAND of 0.205 on theevaluation set. The code for the experiments is available athttps://github.com/hmarichal93/mlbrief_inbd.</description><author>Henry Marichal, Gregory Randall</author><pubDate>Mon, 26 Aug 2024 15:16:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14343v1</guid></item><item><title>Graph Reinforcement Learning for Power Grids: A Comprehensive Survey</title><link>http://arxiv.org/abs/2407.04522v3</link><description>The rise of renewable energy and distributed generation requires newapproaches to overcome the limitations of traditional methods. In this context,Graph Neural Networks are promising due to their ability to learn fromgraph-structured data. Combined with Reinforcement Learning, they can serve ascontrol approaches to determine remedial network actions. This review analyseshow Graph Reinforcement Learning (GRL) can improve representation learning anddecision making in power grid use cases. Although GRL has demonstratedadaptability to unpredictable events and noisy data, it is primarily at aproof-of-concept stage. We highlight open challenges and limitations withrespect to real-world applications.</description><author>Mohamed Hassouna, Clara Holzhüter, Pawel Lytaev, Josephine Thomas, Bernhard Sick, Christoph Scholz</author><pubDate>Mon, 26 Aug 2024 15:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04522v3</guid></item><item><title>Foundation Models for Music: A Survey</title><link>http://arxiv.org/abs/2408.14340v1</link><description>In recent years, foundation models (FMs) such as large language models (LLMs)and latent diffusion models (LDMs) have profoundly impacted diverse sectors,including music. This comprehensive review examines state-of-the-art (SOTA)pre-trained models and foundation models in music, spanning from representationlearning, generative learning and multimodal learning. We first contextualisethe significance of music in various industries and trace the evolution of AIin music. By delineating the modalities targeted by foundation models, wediscover many of the music representations are underexplored in FM development.Then, emphasis is placed on the lack of versatility of previous methods ondiverse music applications, along with the potential of FMs in musicunderstanding, generation and medical application. By comprehensively exploringthe details of the model pre-training paradigm, architectural choices,tokenisation, finetuning methodologies and controllability, we emphasise theimportant topics that should have been well explored, like instruction tuningand in-context learning, scaling law and emergent ability, as well aslong-sequence modelling etc. A dedicated section presents insights into musicagents, accompanied by a thorough analysis of datasets and evaluationsessential for pre-training and downstream tasks. Finally, by underscoring thevital importance of ethical considerations, we advocate that following researchon FM for music should focus more on such issues as interpretability,transparency, human responsibility, and copyright issues. The paper offersinsights into future challenges and trends on FMs for music, aiming to shapethe trajectory of human-AI collaboration in the music realm.</description><author>Yinghao Ma, Anders Øland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elio Quinton, Elona Shatri, Fabio Morreale, Ge Zhang, György Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wehhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang</author><pubDate>Mon, 26 Aug 2024 15:13:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14340v1</guid></item><item><title>ConceptMix: A Compositional Image Generation Benchmark with Controllable Difficulty</title><link>http://arxiv.org/abs/2408.14339v1</link><description>Compositionality is a critical capability in Text-to-Image (T2I) models, asit reflects their ability to understand and combine multiple concepts from textdescriptions. Existing evaluations of compositional capability rely heavily onhuman-designed text prompts or fixed templates, limiting their diversity andcomplexity, and yielding low discriminative power. We propose ConceptMix, ascalable, controllable, and customizable benchmark which automaticallyevaluates compositional generation ability of T2I models. This is done in twostages. First, ConceptMix generates the text prompts: concretely, usingcategories of visual concepts (e.g., objects, colors, shapes, spatialrelationships), it randomly samples an object and k-tuples of visual concepts,then uses GPT4-o to generate text prompts for image generation based on thesesampled concepts. Second, ConceptMix evaluates the images generated in responseto these prompts: concretely, it checks how many of the k concepts actuallyappeared in the image by generating one question per visual concept and using astrong VLM to answer them. Through administering ConceptMix to a diverse set ofT2I models (proprietary as well as open ones) using increasing values of k, weshow that our ConceptMix has higher discrimination power than earlierbenchmarks. Specifically, ConceptMix reveals that the performance of severalmodels, especially open models, drops dramatically with increased k.Importantly, it also provides insight into the lack of prompt diversity inwidely-used training datasets. Additionally, we conduct extensive human studiesto validate the design of ConceptMix and compare our automatic grading withhuman judgement. We hope it will guide future T2I model development.</description><author>Xindi Wu, Dingli Yu, Yangsibo Huang, Olga Russakovsky, Sanjeev Arora</author><pubDate>Mon, 26 Aug 2024 15:08:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14339v1</guid></item><item><title>Machine Learning for Quantifier Selection in cvc5</title><link>http://arxiv.org/abs/2408.14338v1</link><description>In this work we considerably improve the state-of-the-art SMT solving onfirst-order quantified problems by efficient machine learning guidance ofquantifier selection. Quantifiers represent a significant challenge for SMT andare technically a source of undecidability. In our approach, we train anefficient machine learning model that informs the solver which quantifiersshould be instantiated and which not. Each quantifier may be instantiatedmultiple times and the set of the active quantifiers changes as the solvingprogresses. Therefore, we invoke the ML predictor many times, during the wholerun of the solver. To make this efficient, we use fast ML models based ongradient boosting decision trees. We integrate our approach into thestate-of-the-art cvc5 SMT solver and show a considerable increase of thesystem's holdout-set performance after training it on a large set offirst-order problems collected from the Mizar Mathematical Library.</description><author>Jan Jakubův, Mikoláš Janota, Jelle Piepenbrock, Josef Urban</author><pubDate>Mon, 26 Aug 2024 15:07:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14338v1</guid></item><item><title>Equivariant Reinforcement Learning under Partial Observability</title><link>http://arxiv.org/abs/2408.14336v1</link><description>Incorporating inductive biases is a promising approach for tacklingchallenging robot learning domains with sample-efficient solutions. This paperidentifies partially observable domains where symmetries can be a usefulinductive bias for efficient learning. Specifically, by encoding theequivariance regarding specific group symmetries into the neural networks, ouractor-critic reinforcement learning agents can reuse solutions in the past forrelated scenarios. Consequently, our equivariant agents outperformnon-equivariant approaches significantly in terms of sample efficiency andfinal performance, demonstrated through experiments on a range of robotic tasksin simulation and real hardware.</description><author>Hai Nguyen, Andrea Baisero, David Klee, Dian Wang, Robert Platt, Christopher Amato</author><pubDate>Mon, 26 Aug 2024 15:07:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14336v1</guid></item></channel></rss>