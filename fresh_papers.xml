<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 08 Feb 2024 06:00:24 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>DiSK: A Diffusion Model for Structured Knowledge</title><link>http://arxiv.org/abs/2312.05253v2</link><description>Structured (dictionary-like) data presents challenges for left-to-rightlanguage models, as they can struggle with structured entities for a widevariety of reasons such as formatting and sensitivity to the order in whichattributes are presented. Tabular generative models suffer from a different setof limitations such as their lack of flexibility. We introduce Diffusion Modelsof Structured Knowledge (DiSK) - a new architecture and training approachspecialized for structured data. DiSK handles text, categorical, and continuousnumerical data using a Gaussian mixture model approach, which allows forimproved precision when dealing with numbers. It employs diffusion training tomodel relationships between properties. Experiments demonstrate DiSK'sstate-of-the-art performance on tabular data modeling, synthesis, andimputation on over 15 datasets across diverse domains. DiSK provides aneffective inductive bias for generative modeling and manipulation of structureddata. The techniques we propose could open the door to improved knowledgemanipulation in future language models.</description><author>Ouail Kitouni, Niklas Nolte, James Hensman, Bhaskar Mitra</author><pubDate>Wed, 07 Feb 2024 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05253v2</guid></item><item><title>Edu-ConvoKit: An Open-Source Library for Education Conversation Data</title><link>http://arxiv.org/abs/2402.05111v1</link><description>We introduce Edu-ConvoKit, an open-source library designed to handlepre-processing, annotation and analysis of conversation data in education.Resources for analyzing education conversation data are scarce, making theresearch challenging to perform and therefore hard to access. We address thesechallenges with Edu-ConvoKit. Edu-ConvoKit is open-source(https://github.com/stanfordnlp/edu-convokit ), pip-installable(https://pypi.org/project/edu-convokit/ ), with comprehensive documentation(https://edu-convokit.readthedocs.io/en/latest/ ). Our demo video is availableat: https://youtu.be/zdcI839vAko?si=h9qlnl76ucSuXb8- . We include additionalresources, such as Colab applications of Edu-ConvoKit to three diverseeducation datasets and a repository of Edu-ConvoKit related papers, that can befound in our GitHub repository.</description><author>Rose E. Wang, Dorottya Demszky</author><pubDate>Wed, 07 Feb 2024 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05111v1</guid></item><item><title>Opening the AI black box: program synthesis via mechanistic interpretability</title><link>http://arxiv.org/abs/2402.05110v1</link><description>We present MIPS, a novel method for program synthesis based on automatedmechanistic interpretability of neural networks trained to perform the desiredtask, auto-distilling the learned algorithm into Python code. We test MIPS on abenchmark of 62 algorithmic tasks that can be learned by an RNN and find ithighly complementary to GPT-4: MIPS solves 32 of them, including 13 that arenot solved by GPT-4 (which also solves 30). MIPS uses an integer autoencoder toconvert the RNN into a finite state machine, then applies Boolean or integersymbolic regression to capture the learned algorithm. As opposed to largelanguage models, this program synthesis technique makes no use of (and istherefore not limited by) human training data such as algorithms and code fromGitHub. We discuss opportunities and challenges for scaling up this approach tomake machine-learned models more interpretable and trustworthy.</description><author>Eric J. Michaud, Isaac Liao, Vedang Lad, Ziming Liu, Anish Mudide, Chloe Loughridge, Zifan Carl Guo, Tara Rezaei Kheirkhah, Mateja Vukelić, Max Tegmark</author><pubDate>Wed, 07 Feb 2024 18:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05110v1</guid></item><item><title>Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding</title><link>http://arxiv.org/abs/2402.05109v1</link><description>To combat the memory bandwidth-bound nature of autoregressive LLM inference,previous research has proposed the speculative decoding framework. To performspeculative decoding, a small draft model proposes candidate continuations ofthe input sequence, that are then verified in parallel by the base model. Oneway to specify the draft model, as used in the recent Medusa decodingframework, is as a collection of light-weight heads, called draft heads, thatoperate on the base model's hidden states. To date, all existing draft headshave been sequentially independent, meaning that they speculate tokens in thecandidate continuation independently of any preceding tokens in the candidatecontinuation. In this work, we propose Hydra heads, a sequentially dependent,drop-in replacement for standard draft heads that significantly improvesspeculation accuracy. Decoding with Hydra heads improves throughput compared toMedusa decoding with standard draft heads. We further explore the design spaceof Hydra head training objectives and architectures, and propose acarefully-tuned Hydra head recipe, which we call Hydra++, that improvesdecoding throughput by 1.31x and 2.71x compared to Medusa decoding andautoregressive decoding, respectively. Overall, Hydra heads are a simpleintervention on standard draft heads that significantly improve the end-to-endspeed of draft head based speculative decoding.</description><author>Zachary Ankner, Rishab Parthasarathy, Aniruddha Nrusimha, Christopher Rinard, Jonathan Ragan-Kelley, William Brandon</author><pubDate>Wed, 07 Feb 2024 18:58:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05109v1</guid></item><item><title>Image captioning for Brazilian Portuguese using GRIT model</title><link>http://arxiv.org/abs/2402.05106v1</link><description>This work presents the early development of a model of image captioning forthe Brazilian Portuguese language. We used the GRIT (Grid - and Region-basedImage captioning Transformer) model to accomplish this work. GRIT is aTransformer-only neural architecture that effectively utilizes two visualfeatures to generate better captions. The GRIT method emerged as a proposal tobe a more efficient way to generate image captioning. In this work, we adaptthe GRIT model to be trained in a Brazilian Portuguese dataset to have an imagecaptioning method for the Brazilian Portuguese Language.</description><author>Rafael Silva de Alencar, William Alberto Cruz Castañeda, Marcellus Amadeus</author><pubDate>Wed, 07 Feb 2024 18:57:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05106v1</guid></item><item><title>Vision-Language Dataset Distillation</title><link>http://arxiv.org/abs/2308.07545v3</link><description>Dataset distillation methods reduce large-scale datasets to smaller sets ofsynthetic data, which preserve sufficient information for quickly training anew model from scratch. However, prior work on dataset distillation has focusedexclusively on image classification datasets, whereas modern large-scaledatasets are primarily in the vision-language space. In this work, we designthe first vision-language dataset distillation method, building on the idea oftrajectory matching. A key challenge is that vision-language datasets do nothave a set of discrete classes. To overcome this, our proposed method jointlydistills the image-text pairs in a contrastive formulation. Further, weleverage Low-Rank Adaptation (LoRA) matching to enable more efficient andeffective trajectory matching in complex modern vision-language models. Sincethere are no existing baselines, we compare our distillation approach to threeadapted vision-language coreset selection methods. We demonstrate significantimprovements on the challenging Flickr30K and COCO retrieval benchmarks: forexample, on Flickr30K, the best coreset selection method selecting 1000image-text pairs for training achieves only 5.6% image-to-text retrievalaccuracy (i.e., recall@1); in contrast, our dataset distillation approachalmost doubles that to 9.9% with just 100 (an order of magnitude fewer)training pairs.</description><author>Xindi Wu, Byron Zhang, Zhiwei Deng, Olga Russakovsky</author><pubDate>Wed, 07 Feb 2024 18:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07545v3</guid></item><item><title>Tighter Generalisation Bounds via Interpolation</title><link>http://arxiv.org/abs/2402.05101v1</link><description>This paper contains a recipe for deriving new PAC-Bayes generalisation boundsbased on the $(f, \Gamma)$-divergence, and, in addition, presents PAC-Bayesgeneralisation bounds where we interpolate between a series of probabilitydivergences (including but not limited to KL, Wasserstein, and totalvariation), making the best out of many worlds depending on the posteriordistributions properties. We explore the tightness of these bounds and connectthem to earlier results from statistical learning, which are specific cases. Wealso instantiate our bounds as training objectives, yielding non-trivialguarantees and practical performances.</description><author>Paul Viallard, Maxime Haddouche, Umut Şimşekli, Benjamin Guedj</author><pubDate>Wed, 07 Feb 2024 18:55:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05101v1</guid></item><item><title>OLMo: Accelerating the Science of Language Models</title><link>http://arxiv.org/abs/2402.00838v2</link><description>Language models (LMs) have become ubiquitous in both NLP research and incommercial product offerings. As their commercial importance has surged, themost powerful models have become closed off, gated behind proprietaryinterfaces, with important details of their training data, architectures, anddevelopment undisclosed. Given the importance of these details inscientifically studying these models, including their biases and potentialrisks, we believe it is essential for the research community to have access topowerful, truly open LMs. To this end, this technical report details the firstrelease of OLMo, a state-of-the-art, truly Open Language Model and itsframework to build and study the science of language modeling. Unlike mostprior efforts that have only released model weights and inference code, werelease OLMo and the whole framework, including training data and training andevaluation code. We hope this release will empower and strengthen the openresearch community and inspire a new wave of innovation.</description><author>Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson, Russell Authur, Khyathi Raghavi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar, Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk, Saurabh Shah, Will Smith, Emma Strubell, Nishant Subramani, Mitchell Wortsman, Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, Hannaneh Hajishirzi</author><pubDate>Wed, 07 Feb 2024 18:53:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00838v2</guid></item><item><title>Hydragen: High-Throughput LLM Inference with Shared Prefixes</title><link>http://arxiv.org/abs/2402.05099v1</link><description>Transformer-based large language models (LLMs) are now deployed to hundredsof millions of users. LLM inference is commonly performed on batches ofsequences that share a prefix, such as few-shot examples or a chatbot systemprompt. Decoding in this large-batch setting can be bottlenecked by theattention operation, which reads large key-value (KV) caches from memory andcomputes inefficient matrix-vector products for every sequence in the batch. Inthis work, we introduce Hydragen, a hardware-aware exact implementation ofattention with shared prefixes. Hydragen computes attention over the sharedprefix and unique suffixes separately. This decomposition enables efficientprefix attention by batching queries together across sequences, reducingredundant memory reads and enabling the use of hardware-friendly matrixmultiplications. Our method can improve end-to-end LLM throughput by up to 32xagainst competitive baselines, with speedup growing with the batch size andshared prefix length. Hydragen also enables the use of very long sharedcontexts: with a high batch size, increasing the prefix length from 1K to 16Ktokens decreases Hydragen throughput by less than 15%, while the throughput ofbaselines drops by over 90%. Hydragen generalizes beyond simple prefix-suffixdecomposition and can be applied to tree-based prompt sharing patterns,allowing us to further reduce inference time on competitive programmingproblems by 55%.</description><author>Jordan Juravsky, Bradley Brown, Ryan Ehrlich, Daniel Y. Fu, Christopher Ré, Azalia Mirhoseini</author><pubDate>Wed, 07 Feb 2024 18:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05099v1</guid></item><item><title>Factorized Explainer for Graph Neural Networks</title><link>http://arxiv.org/abs/2312.05596v2</link><description>Graph Neural Networks (GNNs) have received increasing attention due to theirability to learn from graph-structured data. To open the black-box of thesedeep learning models, post-hoc instance-level explanation methods have beenproposed to understand GNN predictions. These methods seek to discoversubstructures that explain the prediction behavior of a trained GNN. In thispaper, we show analytically that for a large class of explanation tasks,conventional approaches, which are based on the principle of graph informationbottleneck (GIB), admit trivial solutions that do not align with the notion ofexplainability. Instead, we argue that a modified GIB principle may be used toavoid the aforementioned trivial solutions. We further introduce a novelfactorized explanation model with theoretical performance guarantees. Themodified GIB is used to analyze the structural properties of the proposedfactorized explainer. We conduct extensive experiments on both synthetic andreal-world datasets to validate the effectiveness of our proposed factorizedexplainer.</description><author>Rundong Huang, Farhad Shirani, Dongsheng Luo</author><pubDate>Wed, 07 Feb 2024 18:52:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05596v2</guid></item><item><title>On diffusion models for amortized inference: Benchmarking and improving stochastic control and sampling</title><link>http://arxiv.org/abs/2402.05098v1</link><description>We study the problem of training diffusion models to sample from adistribution with a given unnormalized density or energy function. We benchmarkseveral diffusion-structured inference methods, including simulation-basedvariational approaches and off-policy methods (continuous generative flownetworks). Our results shed light on the relative advantages of existingalgorithms while bringing into question some claims from past work. We alsopropose a novel exploration strategy for off-policy methods, based on localsearch in the target space with the use of a replay buffer, and show that itimproves the quality of samples on a variety of target distributions. Our codefor the sampling methods and benchmarks studied is made public athttps://github.com/GFNOrg/gfn-diffusion as a base for future work on diffusionmodels for amortized inference.</description><author>Marcin Sendera, Minsu Kim, Sarthak Mittal, Pablo Lemos, Luca Scimeca, Jarrid Rector-Brooks, Alexandre Adam, Yoshua Bengio, Nikolay Malkin</author><pubDate>Wed, 07 Feb 2024 18:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05098v1</guid></item><item><title>A Differentiable Partially Observable Generalized Linear Model with Forward-Backward Message Passing</title><link>http://arxiv.org/abs/2402.01263v2</link><description>The partially observable generalized linear model (POGLM) is a powerful toolfor understanding neural connectivity under the assumption of existing hiddenneurons. With spike trains only recorded from visible neurons, existing worksuse variational inference to learn POGLM meanwhile presenting the difficulty oflearning this latent variable model. There are two main issues: (1) the sampledPoisson hidden spike count hinders the use of the pathwise gradient estimatorin VI; and (2) the existing design of the variational model is neitherexpressive nor time-efficient, which further affects the performance. For (1),we propose a new differentiable POGLM, which enables the pathwise gradientestimator, better than the score function gradient estimator used in existingworks. For (2), we propose the forward-backward message-passing sampling schemefor the variational model. Comprehensive experiments show that ourdifferentiable POGLMs with our forward-backward message passing produce abetter performance on one synthetic and two real-world datasets. Furthermore,our new method yields more interpretable parameters, underscoring itssignificance in neuroscience.</description><author>Chengrui Li, Weihan Li, Yule Wang, Anqi Wu</author><pubDate>Wed, 07 Feb 2024 18:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01263v2</guid></item><item><title>Language-Based Augmentation to Address Shortcut Learning in Object Goal Navigation</title><link>http://arxiv.org/abs/2402.05090v1</link><description>Deep Reinforcement Learning (DRL) has shown great potential in enablingrobots to find certain objects (e.g., `find a fridge') in environments likehomes or schools. This task is known as Object-Goal Navigation (ObjectNav). DRLmethods are predominantly trained and evaluated using environment simulators.Although DRL has shown impressive results, the simulators may be biased orlimited. This creates a risk of shortcut learning, i.e., learning a policytailored to specific visual details of training environments. We aim to deepenour understanding of shortcut learning in ObjectNav, its implications andpropose a solution. We design an experiment for inserting a shortcut bias inthe appearance of training environments. As a proof-of-concept, we associateroom types to specific wall colors (e.g., bedrooms with green walls), andobserve poor generalization of a state-of-the-art (SOTA) ObjectNav method toenvironments where this is not the case (e.g., bedrooms with blue walls). Wefind that shortcut learning is the root cause: the agent learns to navigate totarget objects, by simply searching for the associated wall color of the targetobject's room. To solve this, we propose Language-Based (L-B) augmentation. Ourkey insight is that we can leverage the multimodal feature space of aVision-Language Model (VLM) to augment visual representations directly at thefeature-level, requiring no changes to the simulator, and only an addition ofone layer to the model. Where the SOTA ObjectNav method's success rate drops69%, our proposal has only a drop of 23%.</description><author>Dennis Hoftijzer, Gertjan Burghouts, Luuk Spreeuwers</author><pubDate>Wed, 07 Feb 2024 18:44:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05090v1</guid></item><item><title>PAGAR: Taming Reward Misalignment in Inverse Reinforcement Learning-Based Imitation Learning with Protagonist Antagonist Guided Adversarial Reward</title><link>http://arxiv.org/abs/2306.01731v3</link><description>Many imitation learning (IL) algorithms employ inverse reinforcement learning(IRL) to infer the intrinsic reward function that an expert is implicitlyoptimizing for based on their demonstrated behaviors. However, in practice,IRL-based IL can fail to accomplish the underlying task due to a misalignmentbetween the inferred reward and the objective of the task. In this paper, weaddress the susceptibility of IL to such misalignment by introducing asemi-supervised reward design paradigm called Protagonist Antagonist GuidedAdversarial Reward (PAGAR). PAGAR-based IL trains a policy to perform wellunder mixed reward functions instead of a single reward function as inIRL-based IL. We identify the theoretical conditions under which PAGAR-based ILcan avoid the task failures caused by reward misalignment. We also present apractical on-and-off policy approach to implementing PAGAR-based IL.Experimental results show that our algorithm outperforms standard IL baselinesin complex tasks and challenging transfer settings.</description><author>Weichao Zhou, Wenchao Li</author><pubDate>Wed, 07 Feb 2024 18:41:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01731v3</guid></item><item><title>A General Theory for Kernel Packets: from state space model to compactly supported basis</title><link>http://arxiv.org/abs/2402.04022v2</link><description>It is well known that the state space (SS) model formulation of a Gaussianprocess (GP) can lower its training and prediction time both to O(n) for n datapoints. We prove that an $m$-dimensional SS model formulation of GP isequivalent to a concept we introduce as the general right Kernel Packet (KP): atransformation for the GP covariance function $K$ such that$\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \leq t_1$, 0 $\leq j\leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes$j$-th order derivative acting on $t$. We extend this idea to the backward SSmodel formulation of the GP, leading to the concept of the left KP for next $m$consecutive points: $\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\geqt_{2m}$. By combining both left and right KPs, we can prove that a suitablelinear combination of these covariance functions yields $m$ compactly supportedKP functions: $\phi^{(j)}(t)=0$ for any $t\not\in(t_0,t_{2m})$ and$j=0,\cdots,m-1$. KPs further reduce the prediction time of GP to O(log n) oreven O(1), can be applied to more general problems involving the derivative ofGPs, and have multi-dimensional generalization for scattered data.</description><author>Liang Ding, Tuo Rui</author><pubDate>Wed, 07 Feb 2024 18:36:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04022v2</guid></item><item><title>Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation</title><link>http://arxiv.org/abs/2402.05079v1</link><description>In recent advancements in medical image analysis, Convolutional NeuralNetworks (CNN) and Vision Transformers (ViT) have set significant benchmarks.While the former excels in capturing local features through its convolutionoperations, the latter achieves remarkable global context understanding byleveraging self-attention mechanisms. However, both architectures exhibitlimitations in efficiently modeling long-range dependencies within medicalimages, which is a critical aspect for precise segmentation. Inspired by theMamba architecture, known for its proficiency in handling long sequences andglobal contextual information with enhanced computational efficiency as a StateSpace Model (SSM), we propose Mamba-UNet, a novel architecture that synergizesthe U-Net in medical image segmentation with Mamba's capability. Mamba-UNetadopts a pure Visual Mamba (VMamba)-based encoder-decoder structure, infusedwith skip connections to preserve spatial information across different scalesof the network. This design facilitates a comprehensive feature learningprocess, capturing intricate details and broader semantic contexts withinmedical images. We introduce a novel integration mechanism within the VMambablocks to ensure seamless connectivity and information flow between the encoderand decoder paths, enhancing the segmentation performance. We conductedexperiments on publicly available MRI cardiac multi-structures segmentationdataset. The results show that Mamba-UNet outperforms UNet, Swin-UNet inmedical image segmentation under the same hyper-parameter setting. The sourcecode and baseline implementations are available.</description><author>Ziyang Wang, Jian-Qing Zheng, Yichi Zhang, Ge Cui, Lei Li</author><pubDate>Wed, 07 Feb 2024 18:33:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05079v1</guid></item><item><title>NITO: Neural Implicit Fields for Resolution-free Topology Optimization</title><link>http://arxiv.org/abs/2402.05073v1</link><description>Topology optimization is a critical task in engineering design, where thegoal is to optimally distribute material in a given space for maximumperformance. We introduce Neural Implicit Topology Optimization (NITO), a novelapproach to accelerate topology optimization problems using deep learning. NITOstands out as one of the first frameworks to offer a resolution-free anddomain-agnostic solution in deep learning-based topology optimization. NITOsynthesizes structures with up to seven times better structural efficiencycompared to SOTA diffusion models and does so in a tenth of the time. In theNITO framework, we introduce a novel method, the Boundary Point Order-InvariantMLP (BPOM), to represent boundary conditions in a sparse and domain-agnosticmanner, moving away from expensive simulation-based approaches. Crucially, NITOcircumvents the domain and resolution limitations that restrict ConvolutionalNeural Network (CNN) models to a structured domain of fixed size -- limitationsthat hinder the widespread adoption of CNNs in engineering applications. Thisgeneralizability allows a single NITO model to train and generate solutions incountless domains, eliminating the need for numerous domain-specific CNNs andtheir extensive datasets. Despite its generalizability, NITO outperforms SOTAmodels even in specialized tasks, is an order of magnitude smaller, and ispractically trainable at high resolutions that would be restrictive for CNNs.This combination of versatility, efficiency, and performance underlines NITO'spotential to transform the landscape of engineering design optimizationproblems through implicit fields.</description><author>Amin Heyrani Nobari, Giorgio Giannone, Lyle Regenwetter, Faez Ahmed</author><pubDate>Wed, 07 Feb 2024 18:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05073v1</guid></item><item><title>Extending the Reach of First-Order Algorithms for Nonconvex Min-Max Problems with Cohypomonotonicity</title><link>http://arxiv.org/abs/2402.05071v1</link><description>We focus on constrained, $L$-smooth, nonconvex-nonconcave min-max problemseither satisfying $\rho$-cohypomonotonicity or admitting a solution to the$\rho$-weakly Minty Variational Inequality (MVI), where larger values of theparameter $\rho&gt;0$ correspond to a greater degree of nonconvexity. Theseproblem classes include examples in two player reinforcement learning,interaction dominant min-max problems, and certain synthetic test problems onwhich classical min-max algorithms fail. It has been conjectured thatfirst-order methods can tolerate value of $\rho$ no larger than $\frac{1}{L}$,but existing results in the literature have stagnated at the tighterrequirement $\rho &lt; \frac{1}{2L}$. With a simple argument, we obtain optimal orbest-known complexity guarantees with cohypomonotonicity or weak MVI conditionsfor $\rho &lt; \frac{1}{L}$. The algorithms we analyze are inexact variants ofHalpern and Krasnosel'ski\u{\i}-Mann (KM) iterations. We also providealgorithms and complexity guarantees in the stochastic case with the same rangeon $\rho$. Our main insight for the improvements in the convergence analyses isto harness the recently proposed "conic nonexpansiveness" property ofoperators. As byproducts, we provide a refined analysis for inexact Halperniteration and propose a stochastic KM iteration with a multilevel Monte Carloestimator.</description><author>Ahmet Alacaoglu, Donghwan Kim, Stephen J. Wright</author><pubDate>Wed, 07 Feb 2024 18:22:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05071v1</guid></item><item><title>A Roadmap to Pluralistic Alignment</title><link>http://arxiv.org/abs/2402.05070v1</link><description>With increased power and prevalence of AI systems, it is ever more criticalthat AI systems are designed to serve all, i.e., people with diverse values andperspectives. However, aligning models to serve pluralistic human valuesremains an open research question. In this piece, we propose a roadmap topluralistic alignment, specifically using language models as a test bed. Weidentify and formalize three possible ways to define and operationalizepluralism in AI systems: 1) Overton pluralistic models that present a spectrumof reasonable responses; 2) Steerably pluralistic models that can steer toreflect certain perspectives; and 3) Distributionally pluralistic models thatare well-calibrated to a given population in distribution. We also propose andformalize three possible classes of pluralistic benchmarks: 1) Multi-objectivebenchmarks, 2) Trade-off steerable benchmarks, which incentivize models tosteer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks whichexplicitly model diverse human ratings. We use this framework to argue thatcurrent alignment techniques may be fundamentally limited for pluralistic AI;indeed, we highlight empirical evidence, both from our own experiments and fromother work, that standard alignment procedures might reduce distributionalpluralism in models, motivating the need for further research on pluralisticalignment.</description><author>Taylor Sorensen, Jared Moore, Jillian Fisher, Mitchell Gordon, Niloofar Mireshghallah, Christopher Michael Rytting, Andre Ye, Liwei Jiang, Ximing Lu, Nouha Dziri, Tim Althoff, Yejin Choi</author><pubDate>Wed, 07 Feb 2024 18:21:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05070v1</guid></item><item><title>Multiscale Modelling with Physics-informed Neural Network: from Large-scale Dynamics to Small-scale Predictions in Complex Systems</title><link>http://arxiv.org/abs/2402.05067v1</link><description>Multiscale phenomena manifest across various scientific domains, presenting aubiquitous challenge in accurately and effectively predicting multiscaledynamics in complex systems. In this paper, a novel solving mode is proposedfor characterizing multiscale dynamics through a decoupling method. Bymodelling large-scale dynamics independently and treating small-scale dynamicsas a slaved system, a Spectral PINN is developed to approach the small-scalesystem in an orthogonal basis functional space. The effectiveness of the methodis demonstrated through extensive numerical experiments, includingone-dimensional Kuramot-Sivashinsky (KS) equation, two- and three-dimensionalNavier-Stokes (NS) equations, showcasing its versatility in addressing problemsof fluid dynamics. Furthermore, we also delve into the application of theproposed approach to more complex problems, including non-uniform meshes,complex geometries, large-scale data with noise, and high-dimensionalsmall-scale dynamics. The discussions about these scenarios contribute to acomprehensive understanding of the method's capabilities and limitations. Thisnovel decoupling approach simplifies the analysis and prediction ofspatiotemporal systems, where large-scale data can be obtained with lowcomputational demands, followed by Spectral PINNs for capturing small-scaledynamics with improved efficiency and accuracy.</description><author>Jing Wang, Zheng Li, Pengyu Lai, Rui Wang, Di Yang, Hui Xu</author><pubDate>Wed, 07 Feb 2024 18:19:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05067v1</guid></item><item><title>Solving Large-scale Spatial Problems with Convolutional Neural Networks</title><link>http://arxiv.org/abs/2306.08191v2</link><description>Over the past decade, deep learning research has been accelerated byincreasingly powerful hardware, which facilitated rapid growth in the modelcomplexity and the amount of data ingested. This is becoming unsustainable andtherefore refocusing on efficiency is necessary. In this paper, we employtransfer learning to improve training efficiency for large-scale spatialproblems. We propose that a convolutional neural network (CNN) can be trainedon small windows of signals, but evaluated on arbitrarily large signals withlittle to no performance degradation, and provide a theoretical bound on theresulting generalization error. Our proof leverages shift-equivariance of CNNs,a property that is underexploited in transfer learning. The theoretical resultsare experimentally supported in the context of mobile infrastructure on demand(MID). The proposed approach is able to tackle MID at large scales withhundreds of agents, which was computationally intractable prior to this work.</description><author>Damian Owerko, Charilaos I. Kanatsoulis, Alejandro Ribeiro</author><pubDate>Wed, 07 Feb 2024 18:18:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08191v2</guid></item><item><title>High-dimensional and Permutation Invariant Anomaly Detection</title><link>http://arxiv.org/abs/2306.03933v5</link><description>Methods for anomaly detection of new physics processes are often limited tolow-dimensional spaces due to the difficulty of learning high-dimensionalprobability densities. Particularly at the constituent level, incorporatingdesirable properties such as permutation invariance and variable-length inputsbecomes difficult within popular density estimation methods. In this work, weintroduce a permutation-invariant density estimator for particle physics databased on diffusion models, specifically designed to handle variable-lengthinputs. We demonstrate the efficacy of our methodology by utilizing the learneddensity as a permutation-invariant anomaly detection score, effectivelyidentifying jets with low likelihood under the background-only hypothesis. Tovalidate our density estimation method, we investigate the ratio of learneddensities and compare to those obtained by a supervised classificationalgorithm.</description><author>Vinicius Mikuni, Benjamin Nachman</author><pubDate>Wed, 07 Feb 2024 18:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03933v5</guid></item><item><title>A Critical Survey on Fairness Benefits of XAI</title><link>http://arxiv.org/abs/2310.13007v5</link><description>In this critical survey, we analyze typical claims on the relationshipbetween explainable AI (XAI) and fairness to disentangle the multidimensionalrelationship between these two concepts. Based on a systematic literaturereview and a subsequent qualitative content analysis, we identify sevenarchetypal claims from 175 papers on the alleged fairness benefits of XAI. Wepresent crucial caveats with respect to these claims and provide an entry pointfor future discussions around the potentials and limitations of XAI forspecific fairness desiderata. Importantly, we notice that claims are often (i)vague and simplistic, (ii) lacking normative grounding, or (iii) poorly alignedwith the actual capabilities of XAI. We encourage to conceive XAI not as anethical panacea but as one of many tools to approach the multidimensional,sociotechnical challenge of algorithmic fairness. Moreover, when making a claimabout XAI and fairness, we emphasize the need to be more specific about whatkind of XAI method is used and which fairness desideratum it refers to, howexactly it enables fairness, and who is the stakeholder that benefits from XAI.</description><author>Luca Deck, Jakob Schoeffer, Maria De-Arteaga, Niklas Kühl</author><pubDate>Wed, 07 Feb 2024 18:07:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13007v5</guid></item><item><title>Empirical Risk Minimization with Shuffled SGD: A Primal-Dual Perspective and Improved Bounds</title><link>http://arxiv.org/abs/2306.12498v2</link><description>Stochastic gradient descent (SGD) is perhaps the most prevalent optimizationmethod in modern machine learning. Contrary to the empirical practice ofsampling from the datasets without replacement and with (possible) reshufflingat each epoch, the theoretical counterpart of SGD usually relies on theassumption of sampling with replacement. It is only very recently that SGD withsampling without replacement -- shuffled SGD -- has been analyzed. For convexfinite sum problems with $n$ components and under the $L$-smoothness assumptionfor each component function, there are matching upper and lower bounds, undersufficiently small -- $\mathcal{O}(\frac{1}{nL})$ -- step sizes. Yet thosebounds appear too pessimistic -- in fact, the predicted performance isgenerally no better than for full gradient descent -- and do not agree with theempirical observations. In this work, to narrow the gap between the theory andpractice of shuffled SGD, we sharpen the focus from general finite sum problemsto empirical risk minimization with linear predictors. This allows us to take aprimal-dual perspective and interpret shuffled SGD as a primal-dual method withcyclic coordinate updates on the dual side. Leveraging this perspective, weprove fine-grained complexity bounds that depend on the data matrix and arenever worse than what is predicted by the existing bounds. Notably, our boundspredict much faster convergence than the existing analyses -- by a factor ofthe order of $\sqrt{n}$ in some cases. We empirically demonstrate that oncommon machine learning datasets our bounds are indeed much tighter. We furtherextend our analysis to nonsmooth convex problems and more general finite-sumproblems, with similar improvements.</description><author>Xufeng Cai, Cheuk Yin Lin, Jelena Diakonikolas</author><pubDate>Wed, 07 Feb 2024 18:06:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12498v2</guid></item><item><title>VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation</title><link>http://arxiv.org/abs/2402.03561v2</link><description>Outdoor Vision-and-Language Navigation (VLN) requires an agent to navigatethrough realistic 3D outdoor environments based on natural languageinstructions. The performance of existing VLN methods is limited byinsufficient diversity in navigation environments and limited training data. Toaddress these issues, we propose VLN-Video, which utilizes the diverse outdoorenvironments present in driving videos in multiple cities in the U.S. augmentedwith automatically generated navigation instructions and actions to improveoutdoor VLN performance. VLN-Video combines the best of intuitive classicalapproaches and modern deep learning techniques, using template infilling togenerate grounded navigation instructions, combined with an image rotationsimilarity-based navigation action predictor to obtain VLN style data fromdriving videos for pretraining deep learning VLN models. We pre-train the modelon the Touchdown dataset and our video-augmented dataset created from drivingvideos with three proxy tasks: Masked Language Modeling, Instruction andTrajectory Matching, and Next Action Prediction, so as to learntemporally-aware and visually-aligned instruction representations. The learnedinstruction representation is adapted to the state-of-the-art navigator whenfine-tuning on the Touchdown dataset. Empirical results demonstrate thatVLN-Video significantly outperforms previous state-of-the-art models by 2.1% intask completion rate, achieving a new state-of-the-art on the Touchdowndataset.</description><author>Jialu Li, Aishwarya Padmakumar, Gaurav Sukhatme, Mohit Bansal</author><pubDate>Wed, 07 Feb 2024 18:02:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03561v2</guid></item><item><title>LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation</title><link>http://arxiv.org/abs/2402.05054v1</link><description>3D content creation has achieved significant progress in terms of bothquality and speed. Although current feed-forward models can produce 3D objectsin seconds, their resolution is constrained by the intensive computationrequired during training. In this paper, we introduce Large Multi-View GaussianModel (LGM), a novel framework designed to generate high-resolution 3D modelsfrom text prompts or single-view images. Our key insights are two-fold: 1) 3DRepresentation: We propose multi-view Gaussian features as an efficient yetpowerful representation, which can then be fused together for differentiablerendering. 2) 3D Backbone: We present an asymmetric U-Net as a high-throughputbackbone operating on multi-view images, which can be produced from text orsingle-view image input by leveraging multi-view diffusion models. Extensiveexperiments demonstrate the high fidelity and efficiency of our approach.Notably, we maintain the fast speed to generate 3D objects within 5 secondswhile boosting the training resolution to 512, thereby achievinghigh-resolution 3D content generation.</description><author>Jiaxiang Tang, Zhaoxi Chen, Xiaokang Chen, Tengfei Wang, Gang Zeng, Ziwei Liu</author><pubDate>Wed, 07 Feb 2024 17:57:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05054v1</guid></item><item><title>Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems</title><link>http://arxiv.org/abs/2402.01748v2</link><description>Large language models (LLMs) and foundation models have been recently toutedas a game-changer for 6G systems. However, recent efforts on LLMs for wirelessnetworks are limited to a direct application of existing language models thatwere designed for natural language processing (NLP) applications. To addressthis challenge and create wireless-centric foundation models, this paperpresents a comprehensive vision on how to design universal foundation modelsthat are tailored towards the deployment of artificial intelligence (AI)-nativenetworks. Diverging from NLP-based foundation models, the proposed frameworkpromotes the design of large multi-modal models (LMMs) fostered by three keycapabilities: 1) processing of multi-modal sensing data, 2) grounding ofphysical symbol representations in real-world wireless systems using causalreasoning and retrieval-augmented generation (RAG), and 3) enablinginstructibility from the wireless environment feedback to facilitate dynamicnetwork adaptation thanks to logical and mathematical reasoning facilitated byneuro-symbolic AI. In essence, these properties enable the proposed LMMframework to build universal capabilities that cater to various cross-layernetworking tasks and alignment of intents across different domains. Preliminaryresults from experimental evaluation demonstrate the efficacy of groundingusing RAG in LMMs, and showcase the alignment of LMMs with wireless systemdesigns. Furthermore, the enhanced rationale exhibited in the responses tomathematical questions by LMMs, compared to vanilla LLMs, demonstrates thelogical and mathematical reasoning capabilities inherent in LMMs. Building onthose results, we present a sequel of open questions and challenges for LMMs.We then conclude with a set of recommendations that ignite the path towardsLMM-empowered AI-native systems.</description><author>Shengzhe Xu, Christo Kurisummoottil Thomas, Omar Hashash, Nikhil Muralidhar, Walid Saad, Naren Ramakrishnan</author><pubDate>Wed, 07 Feb 2024 17:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01748v2</guid></item><item><title>Causal Representation Learning from Multiple Distributions: A General Setting</title><link>http://arxiv.org/abs/2402.05052v1</link><description>In many problems, the measured variables (e.g., image pixels) are justmathematical functions of the hidden causal variables (e.g., the underlyingconcepts or objects). For the purpose of making predictions in changingenvironments or making proper changes to the system, it is helpful to recoverthe hidden causal variables $Z_i$ and their causal relations represented bygraph $\mathcal{G}_Z$. This problem has recently been known as causalrepresentation learning. This paper is concerned with a general, completelynonparametric setting of causal representation learning from multipledistributions (arising from heterogeneous data or nonstationary time series),without assuming hard interventions behind distribution changes. We aim todevelop general solutions in this fundamental case; as a by product, this helpssee the unique benefit offered by other assumptions such as parametric causalmodels or hard interventions. We show that under the sparsity constraint on therecovered graph over the latent variables and suitable sufficient changeconditions on the causal influences, interestingly, one can recover themoralized graph of the underlying directed acyclic graph, and the recoveredlatent variables and their relations are related to the underlying causal modelin a specific, nontrivial way. In some cases, each latent variable can even berecovered up to component-wise transformations. Experimental results verify ourtheoretical claims.</description><author>Kun Zhang, Shaoan Xie, Ignavier Ng, Yujia Zheng</author><pubDate>Wed, 07 Feb 2024 17:51:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05052v1</guid></item><item><title>Federated Learning Can Find Friends That Are Beneficial</title><link>http://arxiv.org/abs/2402.05050v1</link><description>In Federated Learning (FL), the distributed nature and heterogeneity ofclient data present both opportunities and challenges. While collaborationamong clients can significantly enhance the learning process, not allcollaborations are beneficial; some may even be detrimental. In this study, weintroduce a novel algorithm that assigns adaptive aggregation weights toclients participating in FL training, identifying those with data distributionsmost conducive to a specific learning objective. We demonstrate that ouraggregation method converges no worse than the method that aggregates only theupdates received from clients with the same data distribution. Furthermore,empirical evaluations consistently reveal that collaborations guided by ouralgorithm outperform traditional FL approaches. This underscores the criticalrole of judicious client selection and lays the foundation for more streamlinedand effective FL implementations in the coming years.</description><author>Nazarii Tupitsa, Samuel Horváth, Martin Takáč, Eduard Gorbunov</author><pubDate>Wed, 07 Feb 2024 17:46:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05050v1</guid></item><item><title>Efficient Numerical Wave Propagation Enhanced By An End-to-End Deep Learning Model</title><link>http://arxiv.org/abs/2402.02304v2</link><description>In a variety of scientific and engineering domains, the need forhigh-fidelity and efficient solutions for high-frequency wave propagation holdsgreat significance. Recent advances in wave modeling use sufficiently accuratefine solver outputs to train a neural networks that enhances the accuracy of afast but inaccurate coarse solver. A stable and fast solver allows the use ofParareal, a parallel-in-time algorithm to correct high-frequency wavecomponents. In this paper we build upon the work of Nguyen and Tsai (2023) andpresent a unified system that integrates a numerical solver with a neuralnetwork into an end-to-end framework. In the proposed setting, we investigaterefinements to the deep learning architecture, data generation algorithm andParareal scheme. Our results show that the cohesive structure improvesperformance without sacrificing speed, and demonstrate the importance oftemporal dynamics, as well as Parareal, for accurate wave propagation.</description><author>Luis Kaiser, Richard Tsai, Christian Klingenberg</author><pubDate>Wed, 07 Feb 2024 17:42:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02304v2</guid></item><item><title>How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation</title><link>http://arxiv.org/abs/2402.05048v1</link><description>Artificial intelligence (AI) has driven many information and communicationtechnology (ICT) breakthroughs. Nonetheless, the scope of ICT systems hasexpanded far beyond AI since the Turing test proposal. Critically, recent AIregulation proposals adopt AI definitions affecting ICT techniques, approaches,and systems that are not AI. In some cases, even works from mathematics,statistics, and engineering would be affected. Worryingly, AI misdefinitionsare observed from Western societies to the Global South. In this paper, wepropose a framework to score how \textit{validated as appropriately-defined forregulation} (VADER) an AI definition is. Our online, publicly-available VADERframework scores the coverage of premises that should underlie AI definitionsfor regulation, which aim to (i) reproduce principles observed in othersuccessful technology regulations, and (ii) include all AI techniques andapproaches while excluding non-AI works. Regarding the latter, our score isbased on a dataset of representative AI, non-AI ICT, and non-ICT examples. Wedemonstrate our contribution by reviewing the AI regulation proposals of keyplayers, namely the United States, United Kingdom, European Union, and Brazil.Importantly, none of the proposals assessed achieve the appropriateness score,ranging from a revision need to a concrete risk to ICT systems and works fromother fields.</description><author>Leonardo C. T. Bezerra, Alexander E. I. Brownlee, Luana Ferraz Alvarenga, Renan Cipriano Moioli, Thais Vasconcelos Batista</author><pubDate>Wed, 07 Feb 2024 17:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05048v1</guid></item><item><title>Efficient Multi-Resolution Fusion for Remote Sensing Data with Label Uncertainty</title><link>http://arxiv.org/abs/2402.05045v1</link><description>Multi-modal sensor data fusion takes advantage of complementary orreinforcing information from each sensor and can boost overall performance inapplications such as scene classification and target detection. This paperpresents a new method for fusing multi-modal and multi-resolution remote sensordata without requiring pixel-level training labels, which can be difficult toobtain. Previously, we developed a Multiple Instance Multi-Resolution Fusion(MIMRF) framework that addresses label uncertainty for fusion, but it can beslow to train due to the large search space for the fuzzy measures used tointegrate sensor data sources. We propose a new method based on binary fuzzymeasures, which reduces the search space and significantly improves theefficiency of the MIMRF framework. We present experimental results on syntheticdata and a real-world remote sensing detection task and show that the proposedMIMRF-BFM algorithm can effectively and efficiently perform multi-resolutionfusion given remote sensing data with uncertainty.</description><author>Hersh Vakharia, Xiaoxiao Du</author><pubDate>Wed, 07 Feb 2024 17:34:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05045v1</guid></item><item><title>SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2402.05044v1</link><description>In the rapidly evolving landscape of Large Language Models (LLMs), ensuringrobust safety measures is paramount. To meet this crucial need, we propose\emph{SALAD-Bench}, a safety benchmark specifically designed for evaluatingLLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Benchtranscends conventional benchmarks through its large scale, rich diversity,intricate taxonomy spanning three levels, and versatilefunctionalities.SALAD-Bench is crafted with a meticulous array of questions,from standard queries to complex ones enriched with attack, defensemodifications and multiple-choice. To effectively manage the inherentcomplexity, we introduce an innovative evaluators: the LLM-based MD-Judge forQA pairs with a particular focus on attack-enhanced queries, ensuring aseamless, and reliable evaluation. Above components extend SALAD-Bench fromstandard LLM safety evaluation to both LLM attack and defense methodsevaluation, ensuring the joint-purpose utility. Our extensive experiments shedlight on the resilience of LLMs against emerging threats and the efficacy ofcontemporary defense tactics. Data and evaluator are released under\url{https://github.com/OpenSafetyLab/SALAD-BENCH}. Warning: this paperincludes examples that may be offensive or harmful.</description><author>Lijun Li, Bowen Dong, Ruohui Wang, Xuhao Hu, Wangmeng Zuo, Dahua Lin, Yu Qiao, Jing Shao</author><pubDate>Wed, 07 Feb 2024 17:33:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05044v1</guid></item><item><title>Can Generative Agents Predict Emotion?</title><link>http://arxiv.org/abs/2402.04232v2</link><description>Large Language Models (LLMs) have demonstrated a number of human-likeabilities, however the empathic understanding and emotional state of LLMs isyet to be aligned to that of humans. In this work, we investigate how theemotional state of generative LLM agents evolves as they perceive new events,introducing a novel architecture in which new experiences are compared to pastmemories. Through this comparison, the agent gains the ability to understandnew experiences in context, which according to the appraisal theory of emotionis vital in emotion creation. First, the agent perceives new experiences astime series text data. After perceiving each new input, the agent generates asummary of past relevant memories, referred to as the norm, and compares thenew experience to this norm. Through this comparison we can analyse how theagent reacts to the new experience in context. The PANAS, a test of affect, isadministered to the agent, capturing the emotional state of the agent after theperception of the new event. Finally, the new experience is then added to theagents memory to be used in the creation of future norms. By creating multipleexperiences in natural language from emotionally charged situations, we testthe proposed architecture on a wide range of scenarios. The mixed resultssuggests that introducing context can occasionally improve the emotionalalignment of the agent, but further study and comparison with human evaluatorsis necessary. We hope that this paper is another step towards the alignment ofgenerative agents.</description><author>Ciaran Regan, Nanami Iwahashi, Shogo Tanaka, Mizuki Oka</author><pubDate>Wed, 07 Feb 2024 17:27:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04232v2</guid></item><item><title>Scalable 3D Panoptic Segmentation As Superpoint Graph Clustering</title><link>http://arxiv.org/abs/2401.06704v2</link><description>We introduce a highly efficient method for panoptic segmentation of large 3Dpoint clouds by redefining this task as a scalable graph clustering problem.This approach can be trained using only local auxiliary tasks, therebyeliminating the resource-intensive instance-matching step during training.Moreover, our formulation can easily be adapted to the superpoint paradigm,further increasing its efficiency. This allows our model to process scenes withmillions of points and thousands of objects in a single inference. Our method,called SuperCluster, achieves a new state-of-the-art panoptic segmentationperformance for two indoor scanning datasets: $50.1$ PQ ($+7.8$) for S3DISArea~5, and $58.7$ PQ ($+25.2$) for ScanNetV2. We also set the firststate-of-the-art for two large-scale mobile mapping benchmarks: KITTI-360 andDALES. With only $209$k parameters, our model is over $30$ times smaller thanthe best-competing method and trains up to $15$ times faster. Our code andpretrained models are available athttps://github.com/drprojects/superpoint_transformer.</description><author>Damien Robert, Hugo Raguet, Loic Landrieu</author><pubDate>Wed, 07 Feb 2024 17:26:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06704v2</guid></item><item><title>PAC Learnability under Explanation-Preserving Graph Perturbations</title><link>http://arxiv.org/abs/2402.05039v1</link><description>Graphical models capture relations between entities in a wide range ofapplications including social networks, biology, and natural languageprocessing, among others. Graph neural networks (GNN) are neural models thatoperate over graphs, enabling the model to leverage the complex relationshipsand dependencies in graph-structured data. A graph explanation is a subgraphwhich is an `almost sufficient' statistic of the input graph with respect toits classification label. Consequently, the classification label is invariant,with high probability, to perturbations of graph edges not belonging to itsexplanation subgraph. This work considers two methods for leveraging suchperturbation invariances in the design and training of GNNs. First,explanation-assisted learning rules are considered. It is shown that the samplecomplexity of explanation-assisted learning can be arbitrarily smaller thanexplanation-agnostic learning. Next, explanation-assisted data augmentation isconsidered, where the training set is enlarged by artificially producing newtraining samples via perturbation of the non-explanation edges in the originaltraining set. It is shown that such data augmentation methods may improveperformance if the augmented data is in-distribution, however, it may also leadto worse sample complexity compared to explanation-agnostic learning rules ifthe augmented data is out-of-distribution. Extensive empirical evaluations areprovided to verify the theoretical analysis.</description><author>Xu Zheng, Farhad Shirani, Tianchun Wang, Shouwei Gao, Wenqian Dong, Wei Cheng, Dongsheng Luo</author><pubDate>Wed, 07 Feb 2024 17:23:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05039v1</guid></item><item><title>Deep Fusion: Efficient Network Training via Pre-trained Initializations</title><link>http://arxiv.org/abs/2306.11903v2</link><description>In recent years, deep learning has made remarkable progress in a wide rangeof domains, with a particularly notable impact on natural language processingtasks. One of the challenges associated with training deep neural networks inthe context of LLMs is the need for large amounts of computational resourcesand time. To mitigate this, network growing algorithms offer potential costsavings, but their underlying mechanisms are poorly understood. We present twonotable contributions in this paper. First, we present Deep Fusion, anefficient approach to network training that leverages pre-trainedinitializations of smaller networks. Second, we propose a theoretical frameworkusing backward error analysis to illustrate the dynamics of mid-trainingnetwork growth. Our experiments show how Deep Fusion is a practical andeffective approach that not only accelerates the training process but alsoreduces computational requirements, maintaining or surpassing traditionaltraining methods' performance in various NLP tasks and T5 model sizes. Finally,we validate our theoretical framework, which guides the optimal use of DeepFusion, showing that with carefully optimized training dynamics, itsignificantly reduces both training time and resource consumption.</description><author>Hanna Mazzawi, Xavi Gonzalvo, Michael Wunder, Sammy Jerome, Benoit Dherin</author><pubDate>Wed, 07 Feb 2024 17:18:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11903v2</guid></item><item><title>When Analytic Calculus Cracks AdaBoost Code</title><link>http://arxiv.org/abs/2308.01070v2</link><description>The principle of boosting in supervised learning involves combining multipleweak classifiers to obtain a stronger classifier. AdaBoost has the reputationto be a perfect example of this approach. This study analyzes the (two classes) AdaBoost procedure implemented inscikit-learn. This paper shows that AdaBoost is an algorithm in name only, as the resultingcombination of weak classifiers can be explicitly calculated using a truthtable. Indeed, using a logical analysis of the training set with weak classifiersconstructing a truth table, we recover, through an analytical formula, theweights of the combination of these weak classifiers obtained by the procedure. We observe that this formula does not give the point of minimum of the risk,we provide a system to compute the exact point of minimum and we check that theAdaBoost procedure in scikit-learn does not implement the algorithm describedby Freund and Schapire.</description><author>Jean-Marc Brossier, Olivier Lafitte, Lenny Réthoré</author><pubDate>Wed, 07 Feb 2024 17:13:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01070v2</guid></item><item><title>A Survey on Domain Generalization for Medical Image Analysis</title><link>http://arxiv.org/abs/2402.05035v1</link><description>Medical Image Analysis (MedIA) has emerged as a crucial tool incomputer-aided diagnosis systems, particularly with the advancement of deeplearning (DL) in recent years. However, well-trained deep models oftenexperience significant performance degradation when deployed in differentmedical sites, modalities, and sequences, known as a domain shift issue. Inlight of this, Domain Generalization (DG) for MedIA aims to address the domainshift challenge by generalizing effectively and performing robustly acrossunknown data distributions. This paper presents the a comprehensive review ofsubstantial developments in this area. First, we provide a formal definition ofdomain shift and domain generalization in medical field, and discuss severalrelated settings. Subsequently, we summarize the recent methods from threeviewpoints: data manipulation level, feature representation level, and modeltraining level, and present some algorithms in detail for each viewpoints.Furthermore, we introduce the commonly used datasets. Finally, we summarizeexisting literature and present some potential research topics for the future.For this survey, we also created a GitHub project by collecting the supportingresources, at the link: https://github.com/Ziwei-Niu/DG_for_MedIA</description><author>Ziwei Niu, Shuyi Ouyang, Shiao Xie, Yen-wei Chen, Lanfen Lin</author><pubDate>Wed, 07 Feb 2024 17:08:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05035v1</guid></item><item><title>How BERT Speaks Shakespearean English? Evaluating Historical Bias in Contextual Language Models</title><link>http://arxiv.org/abs/2402.05034v1</link><description>In this paper, we explore the idea of analysing the historical bias ofcontextual language models based on BERT by measuring their adequacy withrespect to Early Modern (EME) and Modern (ME) English. In our preliminaryexperiments, we perform fill-in-the-blank tests with 60 masked sentences (20EME-specific, 20 ME-specific and 20 generic) and three different models (i.e.,BERT Base, MacBERTh, English HLM). We then rate the model predictions accordingto a 5-point bipolar scale between the two language varieties and derive aweighted score to measure the adequacy of each model to EME and ME varieties ofEnglish.</description><author>Miriam Cuscito, Alfio Ferrara, Martin Ruskov</author><pubDate>Wed, 07 Feb 2024 17:07:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05034v1</guid></item><item><title>Simulated Overparameterization</title><link>http://arxiv.org/abs/2402.05033v1</link><description>In this work, we introduce a novel paradigm called SimulatedOverparametrization (SOP). SOP merges the computational efficiency of compactmodels with the advanced learning proficiencies of overparameterized models.SOP proposes a unique approach to model training and inference, where a modelwith a significantly larger number of parameters is trained in such a way thata smaller, efficient subset of these parameters is used for the actualcomputation during inference. Building upon this framework, we present a novel,architecture agnostic algorithm called "majority kernels", which seamlesslyintegrates with predominant architectures, including Transformer models.Majority kernels enables the simulated training of overparameterized models,resulting in performance gains across architectures and tasks. Furthermore, ourapproach adds minimal overhead to the cost incurred (wall clock time) attraining time. The proposed approach shows strong performance on a wide varietyof datasets and models, even outperforming strong baselines such ascombinatorial optimization methods based on submodular optimization.</description><author>Hanna Mazzawi, Pranjal Awasthi, Xavi Gonzalvo, Srikumar Ramalingam</author><pubDate>Wed, 07 Feb 2024 17:07:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05033v1</guid></item><item><title>AI Does Not Alter Perceptions of Text Messages</title><link>http://arxiv.org/abs/2402.01726v2</link><description>For many people, anxiety, depression, and other social and mental factors canmake composing text messages an active challenge. To remedy this problem, largelanguage models (LLMs) may yet prove to be the perfect tool to assist usersthat would otherwise find texting difficult or stressful. However, despiterapid uptake in LLM usage, considerations for their assistive usage in textmessage composition have not been explored. A primary concern regarding LLMusage is that poor public sentiment regarding AI introduces the possibilitythat its usage may harm perceptions of AI-assisted text messages, making usagecounter-productive. To (in)validate this possibility, we explore how the beliefthat a text message did or did not receive AI assistance in composition altersits perceived tone, clarity, and ability to convey intent. In this study, wesurvey the perceptions of 26 participants on 18 randomly labeled pre-composedtext messages. In analyzing the participants' ratings of message tone, clarity,and ability to convey intent, we find that there is no statisticallysignificant evidence that the belief that AI is utilized alters recipientperceptions. This provides hopeful evidence that LLM-based text messagecomposition assistance can be implemented without the risk ofcounter-productive outcomes.</description><author>N'yoma Diamond</author><pubDate>Wed, 07 Feb 2024 17:04:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01726v2</guid></item><item><title>Compact Binary Systems Waveform Generation with Generative Pre-trained Transformer</title><link>http://arxiv.org/abs/2310.20172v2</link><description>Space-based gravitational wave detection is one of the most anticipatedgravitational wave (GW) detection projects in the next decade, which ispromising to detect abundant compact binary systems. However, the preciseprediction of space GW waveforms remains unexplored. To solve the dataprocessing difficulty in the increasing waveform complexity caused bydetectors' response and second-generation time-delay interferometry (TDI 2.0),an interpretable pre-trained large model named CBS-GPT (Compact Binary SystemsWaveform Generation with Generative Pre-trained Transformer) is proposed. Forcompact binary system waveforms, three models were trained to predict thewaveforms of massive black hole binary (MBHB), extreme mass-ratio inspirals(EMRIs), and galactic binary (GB), achieving prediction accuracies of 99%, 91%,and 99%, respectively at most.The CBS-GPT model exhibits notable generalizationand interpretability, with its hidden parameters effectively capturing theintricate information of waveforms, even with complex instrument response and awide parameter range. Our research demonstrates the potential of largepre-trained models in gravitational wave realm, opening up new opportunitiesand guidance for future researches such as the complex waveforms generation,gap completion, and deep learning model design for GW science.</description><author>Ruijun Shi, Yue Zhou, Tianyu Zhao, Zhoujian Cao, Zhixiang Ren</author><pubDate>Wed, 07 Feb 2024 16:58:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20172v2</guid></item><item><title>Multivariate Probabilistic Time Series Forecasting with Correlated Errors</title><link>http://arxiv.org/abs/2402.01000v2</link><description>Modeling the correlations among errors is closely associated with howaccurately the model can quantify predictive uncertainty in probabilistic timeseries forecasting. Recent multivariate models have made significant progressin accounting for contemporaneous correlations among errors, while a commonassumption on these errors is that they are temporally independent for the sakeof statistical simplicity. However, real-world observations often deviate fromthis assumption, since errors usually exhibit substantial autocorrelation dueto various factors such as the exclusion of temporally correlated covariates.In this work, we propose an efficient method, based on a low-rank-plus-diagonalparameterization of the covariance matrix, which can effectively characterizethe autocorrelation of errors. The proposed method possesses several desirableproperties: the complexity does not scale with the number of time series, theresulting covariance can be used for calibrating predictions, and it canseamlessly integrate with any model with Gaussian-distributed errors. Weempirically demonstrate these properties using two distinct neural forecastingmodels-GPVar and Transformer. Our experimental results confirm theeffectiveness of our method in enhancing predictive accuracy and the quality ofuncertainty quantification on multiple real-world datasets.</description><author>Vincent Zhihao Zheng, Lijun Sun</author><pubDate>Wed, 07 Feb 2024 16:53:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01000v2</guid></item><item><title>Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs with Recurrent Message Passing</title><link>http://arxiv.org/abs/2402.05027v1</link><description>Graph-based environments pose unique challenges to multi-agent reinforcementlearning. In decentralized approaches, agents operate within a given graph andmake decisions based on partial or outdated observations. The size of theobserved neighborhood limits the generalizability to different graphs andaffects the reactivity of agents, the quality of the selected actions, and thecommunication overhead. This work focuses on generalizability and resolves thetrade-off in observed neighborhood size with a continuous information flow inthe whole graph. We propose a recurrent message-passing model that iterateswith the environment's steps and allows nodes to create a global representationof the graph by exchanging messages with their neighbors. Agents receive theresulting learned graph observations based on their location in the graph. Ourapproach can be used in a decentralized manner at runtime and in combinationwith a reinforcement learning algorithm of choice. We evaluate our methodacross 1000 diverse graphs in the context of routing in communication networksand find that it enables agents to generalize and adapt to changes in thegraph.</description><author>Jannis Weil, Zhenghua Bao, Osama Abboud, Tobias Meuser</author><pubDate>Wed, 07 Feb 2024 16:53:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05027v1</guid></item><item><title>Strong convexity-guided hyper-parameter optimization for flatter losses</title><link>http://arxiv.org/abs/2402.05025v1</link><description>We propose a novel white-box approach to hyper-parameter optimization.Motivated by recent work establishing a relationship between flat minima andgeneralization, we first establish a relationship between the strong convexityof the loss and its flatness. Based on this, we seek to find hyper-parameterconfigurations that improve flatness by minimizing the strong convexity of theloss. By using the structure of the underlying neural network, we deriveclosed-form equations to approximate the strong convexity parameter, andattempt to find hyper-parameters that minimize it in a randomized fashion.Through experiments on 14 classification datasets, we show that our methodachieves strong performance at a fraction of the runtime.</description><author>Rahul Yedida, Snehanshu Saha</author><pubDate>Wed, 07 Feb 2024 16:47:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05025v1</guid></item><item><title>OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?</title><link>http://arxiv.org/abs/2309.09992v2</link><description>The authors explain where OpenAI got the tax law example in its livestreamdemonstration of GPT-4, why GPT-4 got the wrong answer, and how it fails toreliably calculate taxes.</description><author>Andrew Blair-Stanek, Nils Holzenberger, Benjamin Van Durme</author><pubDate>Wed, 07 Feb 2024 16:40:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09992v2</guid></item><item><title>A Sober Look at LLMs for Material Discovery: Are They Actually Good for Bayesian Optimization Over Molecules?</title><link>http://arxiv.org/abs/2402.05015v1</link><description>Automation is one of the cornerstones of contemporary material discovery.Bayesian optimization (BO) is an essential part of such workflows, enablingscientists to leverage prior domain knowledge into efficient exploration of alarge molecular space. While such prior knowledge can take many forms, therehas been significant fanfare around the ancillary scientific knowledgeencapsulated in large language models (LLMs). However, existing work thus farhas only explored LLMs for heuristic materials searches. Indeed, recent workobtains the uncertainty estimate -- an integral part of BO -- frompoint-estimated, non-Bayesian LLMs. In this work, we study the question ofwhether LLMs are actually useful to accelerate principled Bayesian optimizationin the molecular space. We take a sober, dispassionate stance in answering thisquestion. This is done by carefully (i) viewing LLMs as fixed featureextractors for standard but principled BO surrogate models and by (ii)leveraging parameter-efficient finetuning methods and Bayesian neural networksto obtain the posterior of the LLM surrogate. Our extensive experiments withreal-world chemistry problems show that LLMs can be useful for BO overmolecules, but only if they have been pretrained or finetuned withdomain-specific data.</description><author>Agustinus Kristiadi, Felix Strieth-Kalthoff, Marta Skreta, Pascal Poupart, Alán Aspuru-Guzik, Geoff Pleiss</author><pubDate>Wed, 07 Feb 2024 16:32:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05015v1</guid></item><item><title>Compression of Structured Data with Autoencoders: Provable Benefit of Nonlinearities and Depth</title><link>http://arxiv.org/abs/2402.05013v1</link><description>Autoencoders are a prominent model in many empirical branches of machinelearning and lossy data compression. However, basic theoretical questionsremain unanswered even in a shallow two-layer setting. In particular, to whatdegree does a shallow autoencoder capture the structure of the underlying datadistribution? For the prototypical case of the 1-bit compression of sparseGaussian data, we prove that gradient descent converges to a solution thatcompletely disregards the sparse structure of the input. Namely, theperformance of the algorithm is the same as if it was compressing a Gaussiansource - with no sparsity. For general data distributions, we give evidence ofa phase transition phenomenon in the shape of the gradient descent minimizer,as a function of the data sparsity: below the critical sparsity level, theminimizer is a rotation taken uniformly at random (just like in the compressionof non-sparse data); above the critical sparsity, the minimizer is the identity(up to a permutation). Finally, by exploiting a connection with approximatemessage passing algorithms, we show how to improve upon Gaussian performancefor the compression of sparse data: adding a denoising function to a shallowarchitecture already reduces the loss provably, and a suitable multi-layerdecoder leads to a further improvement. We validate our findings on imagedatasets, such as CIFAR-10 and MNIST.</description><author>Kevin Kögler, Alexander Shevchenko, Hamed Hassani, Marco Mondelli</author><pubDate>Wed, 07 Feb 2024 16:32:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05013v1</guid></item><item><title>Navigating Complexity: Toward Lossless Graph Condensation via Expanding Window Matching</title><link>http://arxiv.org/abs/2402.05011v1</link><description>Graph condensation aims to reduce the size of a large-scale graph dataset bysynthesizing a compact counterpart without sacrificing the performance of GraphNeural Networks (GNNs) trained on it, which has shed light on reducing thecomputational cost for training GNNs. Nevertheless, existing methods often fallshort of accurately replicating the original graph for certain datasets,thereby failing to achieve the objective of lossless condensation. Tounderstand this phenomenon, we investigate the potential reasons and revealthat the previous state-of-the-art trajectory matching method provides biasedand restricted supervision signals from the original graph when optimizing thecondensed one. This significantly limits both the scale and efficacy of thecondensed graph. In this paper, we make the first attempt toward\textit{lossless graph condensation} by bridging the previously neglectedsupervision signals. Specifically, we employ a curriculum learning strategy totrain expert trajectories with more diverse supervision signals from theoriginal graph, and then effectively transfer the information into thecondensed graph with expanding window matching. Moreover, we design a lossfunction to further extract knowledge from the expert trajectories. Theoreticalanalysis justifies the design of our method and extensive experiments verifyits superiority across different datasets. Code is released athttps://github.com/NUS-HPC-AI-Lab/GEOM.</description><author>Yuchen Zhang, Tianle Zhang, Kai Wang, Ziyao Guo, Yuxuan Liang, Xavier Bresson, Wei Jin, Yang You</author><pubDate>Wed, 07 Feb 2024 16:32:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05011v1</guid></item><item><title>EfficientViT-SAM: Accelerated Segment Anything Model Without Performance Loss</title><link>http://arxiv.org/abs/2402.05008v1</link><description>We present EfficientViT-SAM, a new family of accelerated segment anythingmodels. We retain SAM's lightweight prompt encoder and mask decoder whilereplacing the heavy image encoder with EfficientViT. For the training, we beginwith the knowledge distillation from the SAM-ViT-H image encoder toEfficientViT. Subsequently, we conduct end-to-end training on the SA-1Bdataset. Benefiting from EfficientViT's efficiency and capacity,EfficientViT-SAM delivers 48.9x measured TensorRT speedup on A100 GPU overSAM-ViT-H without sacrificing performance. Our code and pre-trained models arereleased at https://github.com/mit-han-lab/efficientvit.</description><author>Zhuoyang Zhang, Han Cai, Song Han</author><pubDate>Wed, 07 Feb 2024 16:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05008v1</guid></item><item><title>Example-based Explanations for Random Forests using Machine Unlearning</title><link>http://arxiv.org/abs/2402.05007v1</link><description>Tree-based machine learning models, such as decision trees and randomforests, have been hugely successful in classification tasks primarily becauseof their predictive power in supervised learning tasks and ease ofinterpretation. Despite their popularity and power, these models have beenfound to produce unexpected or discriminatory outcomes. Given theiroverwhelming success for most tasks, it is of interest to identify sources oftheir unexpected and discriminatory behavior. However, there has not been muchwork on understanding and debugging tree-based classifiers in the context offairness. We introduce FairDebugger, a system that utilizes recent advances in machineunlearning research to identify training data subsets responsible for instancesof fairness violations in the outcomes of a random forest classifier.FairDebugger generates top-$k$ explanations (in the form of coherent trainingdata subsets) for model unfairness. Toward this goal, FairDebugger firstutilizes machine unlearning to estimate the change in the tree structures ofthe random forest when parts of the underlying training data are removed, andthen leverages the Apriori algorithm from frequent itemset mining to reduce thesubset search space. We empirically evaluate our approach on three real-worlddatasets, and demonstrate that the explanations generated by FairDebugger areconsistent with insights from prior studies on these datasets.</description><author>Tanmay Surve, Romila Pradhan</author><pubDate>Wed, 07 Feb 2024 16:28:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05007v1</guid></item><item><title>Randomized Confidence Bounds for Stochastic Partial Monitoring</title><link>http://arxiv.org/abs/2402.05002v1</link><description>The partial monitoring (PM) framework provides a theoretical formulation ofsequential learning problems with incomplete feedback. On each round, alearning agent plays an action while the environment simultaneously chooses anoutcome. The agent then observes a feedback signal that is only partiallyinformative about the (unobserved) outcome. The agent leverages the receivedfeedback signals to select actions that minimize the (unobserved) cumulativeloss. In contextual PM, the outcomes depend on some side information that isobservable by the agent before selecting the action on each round. In thispaper, we consider the contextual and non-contextual PM settings withstochastic outcomes. We introduce a new class of strategies based on therandomization of deterministic confidence bounds, that extend regret guaranteesto settings where existing stochastic strategies are not applicable. Ourexperiments show that the proposed RandCBP and RandCBPside* strategies improvestate-of-the-art baselines in PM games. To encourage the adoption of the PMframework, we design a use case on the real-world problem of monitoring theerror rate of any deployed classification system.</description><author>Maxime Heuillet, Ola Ahmad, Audrey Durand</author><pubDate>Wed, 07 Feb 2024 16:18:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05002v1</guid></item><item><title>APT-Pipe: An Automatic Prompt-Tuning Tool for Social Computing Data Annotation</title><link>http://arxiv.org/abs/2402.01697v2</link><description>Recent research has highlighted the potential of LLM applications, likeChatGPT, for performing label annotation on social computing text. However, itis already well known that performance hinges on the quality of the inputprompts. To address this, there has been a flurry of research into prompttuning -- techniques and guidelines that attempt to improve the quality ofprompts. Yet these largely rely on manual effort and prior knowledge of thedataset being annotated. To address this limitation, we propose APT-Pipe, anautomated prompt-tuning pipeline. APT-Pipe aims to automatically tune promptsto enhance ChatGPT's text classification performance on any given dataset. Weimplement APT-Pipe and test it across twelve distinct text classificationdatasets. We find that prompts tuned by APT-Pipe help ChatGPT achieve higherweighted F1-score on nine out of twelve experimented datasets, with animprovement of 7.01% on average. We further highlight APT-Pipe's flexibility asa framework by showing how it can be extended to support additional tuningmechanisms.</description><author>Yiming Zhu, Zhizhuo Yin, Ehsan-Ul Haq, Lik-Hang Lee, Gareth Tyson, Pan Hui</author><pubDate>Wed, 07 Feb 2024 16:17:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01697v2</guid></item><item><title>Statistical Guarantees for Link Prediction using Graph Neural Networks</title><link>http://arxiv.org/abs/2402.02692v2</link><description>This paper derives statistical guarantees for the performance of Graph NeuralNetworks (GNNs) in link prediction tasks on graphs generated by a graphon. Wepropose a linear GNN architecture (LG-GNN) that produces consistent estimatorsfor the underlying edge probabilities. We establish a bound on the mean squarederror and give guarantees on the ability of LG-GNN to detect high-probabilityedges. Our guarantees hold for both sparse and dense graphs. Finally, wedemonstrate some of the shortcomings of the classical GCN architecture, as wellas verify our results on real and synthetic datasets.</description><author>Alan Chung, Amin Saberi, Morgane Austern</author><pubDate>Wed, 07 Feb 2024 16:16:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02692v2</guid></item><item><title>Pedagogical Alignment of Large Language Models</title><link>http://arxiv.org/abs/2402.05000v1</link><description>In this paper, we introduce the novel concept of pedagogically aligned LargeLanguage Models (LLMs) that signifies a transformative shift in the applicationof LLMs within educational contexts. Rather than providing direct responses touser queries, pedagogically-aligned LLMs function as scaffolding tools,breaking complex problems into manageable subproblems and guiding studentstowards the final answer through constructive feedback and hints. The objectiveis to equip learners with problem-solving strategies that deepen theirunderstanding and internalization of the subject matter. Previous research inthis field has primarily applied the supervised finetuning approach withoutframing the objective as an alignment problem, hence not employingreinforcement learning through human feedback (RLHF) methods. This studyreinterprets the narrative by viewing the task through the lens of alignmentand demonstrates how RLHF methods emerge naturally as a superior alternativefor aligning LLM behaviour. Building on this perspective, we propose a novelapproach for constructing a reward dataset specifically designed for thepedagogical alignment of LLMs. We apply three state-of-the-art RLHF algorithmsand find that they outperform SFT significantly. Our qualitative analysesacross model differences and hyperparameter sensitivity further validate thesuperiority of RLHF over SFT. Also, our study sheds light on the potential ofonline feedback for enhancing the performance of pedagogically-aligned LLMs,thus providing valuable insights for the advancement of these models ineducational settings.</description><author>Shashank Sonkar, Kangqi Ni, Sapana Chaudhary, Richard G. Baraniuk</author><pubDate>Wed, 07 Feb 2024 16:15:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05000v1</guid></item><item><title>Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design</title><link>http://arxiv.org/abs/2402.04997v1</link><description>Combining discrete and continuous data is an important capability forgenerative models. We present Discrete Flow Models (DFMs), a new flow-basedmodel of discrete data that provides the missing link in enabling flow-basedgenerative models to be applied to multimodal continuous and discrete dataproblems. Our key insight is that the discrete equivalent of continuous spaceflow matching can be realized using Continuous Time Markov Chains. DFMs benefitfrom a simple derivation that includes discrete diffusion models as a specificinstance while allowing improved performance over existing diffusion-basedapproaches. We utilize our DFMs method to build a multimodal flow-basedmodeling framework. We apply this capability to the task of protein co-design,wherein we learn a model for jointly generating protein structure and sequence.Our approach achieves state-of-the-art co-design performance while allowing thesame multimodal model to be used for flexible generation of the sequence orstructure.</description><author>Andrew Campbell, Jason Yim, Regina Barzilay, Tom Rainforth, Tommi Jaakkola</author><pubDate>Wed, 07 Feb 2024 16:15:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04997v1</guid></item><item><title>Heuristic Optimal Transport in Branching Networks</title><link>http://arxiv.org/abs/2311.06650v3</link><description>Optimal transport aims to learn a mapping of sources to targets by minimizingthe cost, which is typically defined as a function of distance. The solution tothis problem consists of straight line segments optimally connecting sources totargets, and it does not exhibit branching. These optimal solutions are instark contrast with both natural, and man-made transportation networks, wherebranching structures are prevalent. Here we discuss a fast heuristic branchingmethod for optimal transport in networks. We also provide several numericalapplications to synthetic examples, a simplified cardiovascular network, andthe "Santa Claus" distribution network which includes 141,182 cities around theworld, with known location and population.</description><author>M. Andrecut</author><pubDate>Wed, 07 Feb 2024 16:12:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06650v3</guid></item><item><title>PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses</title><link>http://arxiv.org/abs/2402.04987v1</link><description>This work studies algorithms for learning from aggregate responses. We focuson the construction of aggregation sets (called bags in the literature) forevent-level loss functions. We prove for linear regression and generalizedlinear models (GLMs) that the optimal bagging problem reduces toone-dimensional size-constrained $k$-means clustering. Further, wetheoretically quantify the advantage of using curated bags over random bags. Wethen propose the PriorBoost algorithm, which adaptively forms bags of samplesthat are increasingly homogeneous with respect to (unobserved) individualresponses to improve model quality. We study label differential privacy foraggregate learning, and we also provide extensive experiments showing thatPriorBoost regularly achieves optimal model quality for event-levelpredictions, in stark contrast to non-adaptive algorithms.</description><author>Adel Javanmard, Matthew Fahrbach, Vahab Mirrokni</author><pubDate>Wed, 07 Feb 2024 16:06:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04987v1</guid></item><item><title>Vector Quantile Regression on Manifolds</title><link>http://arxiv.org/abs/2307.01037v2</link><description>Quantile regression (QR) is a statistical tool for distribution-freeestimation of conditional quantiles of a target variable given explanatoryfeatures. QR is limited by the assumption that the target distribution isunivariate and defined on an Euclidean domain. Although the notion of quantileswas recently extended to multi-variate distributions, QR for multi-variatedistributions on manifolds remains underexplored, even though many importantapplications inherently involve data distributed on, e.g., spheres (climate andgeological phenomena), and tori (dihedral angles in proteins). By leveragingoptimal transport theory and c-concave functions, we meaningfully defineconditional vector quantile functions of high-dimensional variables onmanifolds (M-CVQFs). Our approach allows for quantile estimation, regression,and computation of conditional confidence sets and likelihoods. We demonstratethe approach's efficacy and provide insights regarding the meaning ofnon-Euclidean quantiles through synthetic and real data experiments.</description><author>Marco Pegoraro, Sanketh Vedula, Aviv A. Rosenberg, Irene Tallini, Emanuele Rodolà, Alex M. Bronstein</author><pubDate>Wed, 07 Feb 2024 16:00:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01037v2</guid></item><item><title>Score-based Conditional Generation with Fewer Labeled Data by Self-calibrating Classifier Guidance</title><link>http://arxiv.org/abs/2307.04081v3</link><description>Score-based generative models (SGMs) are a popular family of deep generativemodels that achieve leading image generation quality. Early studies extend SGMsto tackle class-conditional generation by coupling an unconditional SGM withthe guidance of a trained classifier. Nevertheless, such classifier-guided SGMsdo not always achieve accurate conditional generation, especially when trainedwith fewer labeled data. We argue that the problem is rooted in theclassifier's tendency to overfit without coordinating with the underlyingunconditional distribution. To make the classifier respect the unconditionaldistribution, we propose improving classifier-guided SGMs by letting theclassifier regularize itself. The key idea of our proposed method is to useprinciples from energy-based models to convert the classifier into another viewof the unconditional SGM. Existing losses for unconditional SGMs can then beleveraged to achieve regularization by calibrating the classifier's internalunconditional scores. The regularization scheme can be applied to not only thelabeled data but also unlabeled ones to further improve the classifier. Acrossvarious percentages of fewer labeled data, empirical results show that theproposed approach significantly enhances conditional generation quality. Theenhancements confirm the potential of the proposed self-calibration techniquefor generative modeling with limited labeled data.</description><author>Paul Kuo-Ming Huang, Si-An Chen, Hsuan-Tien Lin</author><pubDate>Wed, 07 Feb 2024 16:00:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.04081v3</guid></item><item><title>Beyond explaining: XAI-based Adaptive Learning with SHAP Clustering for Energy Consumption Prediction</title><link>http://arxiv.org/abs/2402.04982v1</link><description>This paper presents an approach integrating explainable artificialintelligence (XAI) techniques with adaptive learning to enhance energyconsumption prediction models, with a focus on handling data distributionshifts. Leveraging SHAP clustering, our method provides interpretableexplanations for model predictions and uses these insights to adaptively refinethe model, balancing model complexity with predictive performance. We introducea three-stage process: (1) obtaining SHAP values to explain model predictions,(2) clustering SHAP values to identify distinct patterns and outliers, and (3)refining the model based on the derived SHAP clustering characteristics. Ourapproach mitigates overfitting and ensures robustness in handling datadistribution shifts. We evaluate our method on a comprehensive datasetcomprising energy consumption records of buildings, as well as two additionaldatasets to assess the transferability of our approach to other domains,regression, and classification problems. Our experiments demonstrate theeffectiveness of our approach in both task types, resulting in improvedpredictive performance and interpretable model explanations.</description><author>Tobias Clement, Hung Truong Thanh Nguyen, Nils Kemmerzell, Mohamed Abdelaal, Davor Stjelja</author><pubDate>Wed, 07 Feb 2024 15:58:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04982v1</guid></item><item><title>Asymptotics of feature learning in two-layer networks after one gradient-step</title><link>http://arxiv.org/abs/2402.04980v1</link><description>In this manuscript we investigate the problem of how two-layer neuralnetworks learn features from data, and improve over the kernel regime, afterbeing trained with a single gradient descent step. Leveraging a connection from(Ba et al., 2022) with a non-linear spiked matrix model and recent progress onGaussian universality (Dandi et al., 2023), we provide an exact asymptoticdescription of the generalization error in the high-dimensional limit where thenumber of samples $n$, the width $p$ and the input dimension $d$ grow at aproportional rate. We characterize exactly how adapting to the data is crucialfor the network to efficiently learn non-linear functions in the direction ofthe gradient -- where at initialization it can only express linear functions inthis regime. To our knowledge, our results provides the first tight descriptionof the impact of feature learning in the generalization of two-layer neuralnetworks in the large learning rate regime $\eta=\Theta_{d}(d)$, beyondperturbative finite width corrections of the conjugate and neural tangentkernels.</description><author>Hugo Cui, Luca Pesce, Yatin Dandi, Florent Krzakala, Yue M. Lu, Lenka Zdeborová, Bruno Loureiro</author><pubDate>Wed, 07 Feb 2024 15:57:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04980v1</guid></item><item><title>Detection and Pose Estimation of flat, Texture-less Industry Objects on HoloLens using synthetic Training</title><link>http://arxiv.org/abs/2402.04979v1</link><description>Current state-of-the-art 6d pose estimation is too compute intensive to bedeployed on edge devices, such as Microsoft HoloLens (2) or Apple iPad, bothused for an increasing number of augmented reality applications. The quality ofAR is greatly dependent on its capabilities to detect and overlay geometrywithin the scene. We propose a synthetically trained client-server-basedaugmented reality application, demonstrating state-of-the-art object poseestimation of metallic and texture-less industry objects on edge devices.Synthetic data enables training without real photographs, i.e. foryet-to-be-manufactured objects. Our qualitative evaluation on an AR-assistedsorting task, and quantitative evaluation on both renderings, as well asreal-world data recorded on HoloLens 2, sheds light on its real-worldapplicability.</description><author>Thomas Pöllabauer, Fabian Rücker, Andreas Franek, Felix Gorschlüter</author><pubDate>Wed, 07 Feb 2024 15:57:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04979v1</guid></item><item><title>Continuous Monte Carlo Graph Search</title><link>http://arxiv.org/abs/2210.01426v3</link><description>Online planning is crucial for high performance in many complex sequentialdecision-making tasks. Monte Carlo Tree Search (MCTS) employs a principledmechanism for trading off exploration for exploitation for efficient onlineplanning, and it outperforms comparison methods in many discretedecision-making domains such as Go, Chess, and Shogi. Subsequently, extensionsof MCTS to continuous domains have been developed. However, the inherent highbranching factor and the resulting explosion of the search tree size arelimiting the existing methods. To address this problem, we propose ContinuousMonte Carlo Graph Search (CMCGS), an extension of MCTS to online planning inenvironments with continuous state and action spaces. CMCGS takes advantage ofthe insight that, during planning, sharing the same action policy betweenseveral states can yield high performance. To implement this idea, at each timestep, CMCGS clusters similar states into a limited number of stochastic actionbandit nodes, which produce a layered directed graph instead of an MCTS searchtree. Experimental evaluation shows that CMCGS outperforms comparable planningmethods in several complex continuous DeepMind Control Suite benchmarks and 2Dnavigation and exploration tasks with limited sample budgets. Furthermore,CMCGS can be scaled up through parallelization, and it outperforms theCross-Entropy Method (CEM) in continuous control with learned dynamics models.</description><author>Kalle Kujanpää, Amin Babadi, Yi Zhao, Juho Kannala, Alexander Ilin, Joni Pajarinen</author><pubDate>Wed, 07 Feb 2024 15:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.01426v3</guid></item><item><title>An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration</title><link>http://arxiv.org/abs/2402.04978v1</link><description>While Large Language Models (LLMs) demonstrate exceptional performance in amultitude of Natural Language Processing (NLP) tasks, they encounter challengesin practical applications, including issues with hallucinations, inadequateknowledge updating, and limited transparency in the reasoning process. Toovercome these limitations, this study innovatively proposes a collaborativetraining-free reasoning scheme involving tight cooperation between KnowledgeGraph (KG) and LLMs. This scheme first involves using LLMs to iterativelyexplore KG, selectively retrieving a task-relevant knowledge subgraph tosupport reasoning. The LLMs are then guided to further combine inherentimplicit knowledge to reason on the subgraph while explicitly elucidating thereasoning process. Through such a cooperative approach, our scheme achievesmore reliable knowledge-based reasoning and facilitates the tracing of thereasoning results. Experimental results show that our scheme significantlyprogressed across multiple datasets, notably achieving over a 10% improvementon the QALD10 dataset compared to the best baseline and the fine-tunedstate-of-the-art (SOTA) work. Building on this success, this study hopes tooffer a valuable reference for future research in the fusion of KG and LLMs,thereby enhancing LLMs' proficiency in solving complex issues.</description><author>Yihao Li, Ru Zhang, Jianyi Liu, Gongshen Liu</author><pubDate>Wed, 07 Feb 2024 15:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04978v1</guid></item><item><title>ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12</title><link>http://arxiv.org/abs/2402.04975v1</link><description>As Computational Thinking (CT) continues to permeate younger age groups inK-12 education, established CT platforms such as Scratch face challenges incatering to these younger learners, particularly those in the elementary school(ages 6-12). Through formative investigation with Scratch experts, we uncoverthree key obstacles to children's autonomous Scratch learning: artist's blockin project planning, bounded creativity in asset creation, and inadequatecoding guidance during implementation. To address these barriers, we introduceChatScratch, an AI-augmented system to facilitate autonomous programminglearning for young children. ChatScratch employs structured interactivestoryboards and visual cues to overcome artist's block, integrates digitaldrawing and advanced image generation technologies to elevate creativity, andleverages Scratch-specialized Large Language Models (LLMs) for professionalcoding guidance. Our study shows that, compared to Scratch, ChatScratchefficiently fosters autonomous programming learning, and contributes to thecreation of high-quality, personally meaningful Scratch projects for children.</description><author>Liuqing Chen, Shuhong Xiao, Yunnong Chen, Ruoyu Wu, Yaxuan Song, Lingyun Sun</author><pubDate>Wed, 07 Feb 2024 15:55:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04975v1</guid></item><item><title>Multi-Sender Persuasion -- A Computational Perspective</title><link>http://arxiv.org/abs/2402.04971v1</link><description>We consider multiple senders with informational advantage signaling toconvince a single self-interested actor towards certain actions. Generalizingthe seminal Bayesian Persuasion framework, such settings are ubiquitous incomputational economics, multi-agent learning, and machine learning withmultiple objectives. The core solution concept here is the Nash equilibrium ofsenders' signaling policies. Theoretically, we prove that finding anequilibrium in general is PPAD-Hard; in fact, even computing a sender's bestresponse is NP-Hard. Given these intrinsic difficulties, we turn to findinglocal Nash equilibria. We propose a novel differentiable neural network toapproximate this game's non-linear and discontinuous utilities. Complementingthis with the extra-gradient algorithm, we discover local equilibria thatPareto dominates full-revelation equilibria and those found by existing neuralnetworks. Broadly, our theoretical and empirical contributions are of interestto a large class of economic problems.</description><author>Safwan Hossain, Tonghan Wang, Tao Lin, Yiling Chen, David C. Parkes, Haifeng Xu</author><pubDate>Wed, 07 Feb 2024 15:50:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04971v1</guid></item><item><title>Kaizen: Practical Self-supervised Continual Learning with Continual Fine-tuning</title><link>http://arxiv.org/abs/2303.17235v2</link><description>Self-supervised learning (SSL) has shown remarkable performance in computervision tasks when trained offline. However, in a Continual Learning (CL)scenario where new data is introduced progressively, models still suffer fromcatastrophic forgetting. Retraining a model from scratch to adapt to newlygenerated data is time-consuming and inefficient. Previous approaches suggestedre-purposing self-supervised objectives with knowledge distillation to mitigateforgetting across tasks, assuming that labels from all tasks are availableduring fine-tuning. In this paper, we generalize self-supervised continuallearning in a practical setting where available labels can be leveraged in anystep of the SSL process. With an increasing number of continual tasks, thisoffers more flexibility in the pre-training and fine-tuning phases. WithKaizen, we introduce a training architecture that is able to mitigatecatastrophic forgetting for both the feature extractor and classifier with acarefully designed loss function. By using a set of comprehensive evaluationmetrics reflecting different aspects of continual learning, we demonstratedthat Kaizen significantly outperforms previous SSL models in competitive visionbenchmarks, with up to 16.5% accuracy improvement on split CIFAR-100. Kaizen isable to balance the trade-off between knowledge retention and learning from newdata with an end-to-end model, paving the way for practical deployment ofcontinual learning systems.</description><author>Chi Ian Tang, Lorena Qendro, Dimitris Spathis, Fahim Kawsar, Cecilia Mascolo, Akhil Mathur</author><pubDate>Wed, 07 Feb 2024 15:45:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17235v2</guid></item><item><title>Text or Image? What is More Important in Cross-Domain Generalization Capabilities of Hate Meme Detection Models?</title><link>http://arxiv.org/abs/2402.04967v1</link><description>This paper delves into the formidable challenge of cross-domaingeneralization in multimodal hate meme detection, presenting compellingfindings. We provide enough pieces of evidence supporting the hypothesis thatonly the textual component of hateful memes enables the existing multimodalclassifier to generalize across different domains, while the image componentproves highly sensitive to a specific training dataset. The evidence includesdemonstrations showing that hate-text classifiers perform similarly tohate-meme classifiers in a zero-shot setting. Simultaneously, the introductionof captions generated from images of memes to the hate-meme classifier worsensperformance by an average F1 of 0.02. Through blackbox explanations, weidentify a substantial contribution of the text modality (average of 83%),which diminishes with the introduction of meme's image captions (52%).Additionally, our evaluation on a newly created confounder dataset revealshigher performance on text confounders as compared to image confounders with anaverage $\Delta$F1 of 0.18.</description><author>Piush Aggarwal, Jawar Mehrabanian, Weigang Huang, Özge Alacam, Torsten Zesch</author><pubDate>Wed, 07 Feb 2024 15:44:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04967v1</guid></item><item><title>ConvLoRA and AdaBN based Domain Adaptation via Self-Training</title><link>http://arxiv.org/abs/2402.04964v1</link><description>Existing domain adaptation (DA) methods often involve pre-training on thesource domain and fine-tuning on the target domain. For multi-target domainadaptation, having a dedicated/separate fine-tuned network for each targetdomain, that retain all the pre-trained model parameters, is prohibitivelyexpensive. To address this limitation, we propose Convolutional Low-RankAdaptation (ConvLoRA). ConvLoRA freezes pre-trained model weights, addstrainable low-rank decomposition matrices to convolutional layers, andbackpropagates the gradient through these matrices thus greatly reducing thenumber of trainable parameters. To further boost adaptation, we utilizeAdaptive Batch Normalization (AdaBN) which computes target-specific runningstatistics and use it along with ConvLoRA. Our method has fewer trainableparameters and performs better or on-par with large independent fine-tunednetworks (with less than 0.9% trainable parameters of the total base model)when tested on the segmentation of Calgary-Campinas dataset containing brainMRI images. Our approach is simple, yet effective and can be applied to anydeep learning-based architecture which uses convolutional and batchnormalization layers. Code is available at:https://github.com/aleemsidra/ConvLoRA.</description><author>Sidra Aleem, Julia Dietlmeier, Eric Arazo, Suzanne Little</author><pubDate>Wed, 07 Feb 2024 15:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04964v1</guid></item><item><title>Channel-Selective Normalization for Label-Shift Robust Test-Time Adaptation</title><link>http://arxiv.org/abs/2402.04958v1</link><description>Deep neural networks have useful applications in many different tasks,however their performance can be severely affected by changes in the datadistribution. For example, in the biomedical field, their performance can beaffected by changes in the data (different machines, populations) betweentraining and test datasets. To ensure robustness and generalization toreal-world scenarios, test-time adaptation has been recently studied as anapproach to adjust models to a new data distribution during inference.Test-time batch normalization is a simple and popular method that achievedcompelling performance on domain shift benchmarks. It is implemented byrecalculating batch normalization statistics on test batches. Prior work hasfocused on analysis with test data that has the same label distribution as thetraining data. However, in many practical applications this technique isvulnerable to label distribution shifts, sometimes producing catastrophicfailure. This presents a risk in applying test time adaptation methods indeployment. We propose to tackle this challenge by only selectively adaptingchannels in a deep network, minimizing drastic adaptation that is sensitive tolabel shifts. Our selection scheme is based on two principles that weempirically motivate: (1) later layers of networks are more sensitive to labelshift (2) individual features can be sensitive to specific classes. We applythe proposed technique to three classification tasks, including CIFAR10-C,Imagenet-C, and diagnosis of fatty liver, where we explore both covariate andlabel distribution shifts. We find that our method allows to bring the benefitsof TTA while significantly reducing the risk of failure common in othermethods, while being robust to choice in hyperparameters.</description><author>Pedro Vianna, Muawiz Chaudhary, Paria Mehrbod, An Tang, Guy Cloutier, Guy Wolf, Michael Eickenberg, Eugene Belilovsky</author><pubDate>Wed, 07 Feb 2024 15:41:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04958v1</guid></item><item><title>MAC-DO: An Efficient Output-Stationary GEMM Accelerator for CNNs Using DRAM Technology</title><link>http://arxiv.org/abs/2207.07862v3</link><description>DRAM-based in-situ accelerators have shown their potential in addressing thememory wall challenge of the traditional von Neumann architecture. Suchaccelerators exploit charge sharing or logic circuits for simple logicoperations at the DRAM subarray level. However, their throughput is limited dueto low array utilization, as only a few row cells in a DRAM array participatein operations while most rows remain deactivated. Moreover, they require manycycles for more complex operations such as a multi-bit multiply-accumulate(MAC) operation, resulting in significant data access and movement andpotentially worsening power efficiency. To overcome these limitations, thispaper presents MAC-DO, an efficient and low-power DRAM-based in-situaccelerator. Compared to previous DRAM-based in-situ accelerators, a MAC-DOcell, consisting of two 1T1C DRAM cells (two transistors and two capacitors),innately supports a multi-bit MAC operation within a single cycle, ensuringgood linearity and compatibility with existing 1T1C DRAM cells and arraystructures. This achievement is facilitated by a novel analog computationmethod utilizing charge steering. Additionally, MAC-DO enables concurrentindividual MAC operations in each MAC-DO cell without idle cells, significantlyimproving throughput and energy efficiency. As a result, a MAC-DO arrayefficiently can accelerate matrix multiplications based on output stationarymapping, supporting the majority of computations performed in deep neuralnetworks (DNNs). Furthermore, a MAC-DO array efficiently reuses three types ofdata (input, weight and output), minimizing data movement.</description><author>Minki Jeong, Wanyeong Jung</author><pubDate>Wed, 07 Feb 2024 15:40:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.07862v3</guid></item><item><title>Reconfidencing LLMs from the Grouping Loss Perspective</title><link>http://arxiv.org/abs/2402.04957v1</link><description>Large Language Models (LLMs), including ChatGPT and LLaMA, are susceptible togenerating hallucinated answers in a confident tone. While efforts to elicitand calibrate confidence scores have proven useful, recent findings show thatcontrolling uncertainty must go beyond calibration: predicted scores maydeviate significantly from the actual posterior probabilities due to the impactof grouping loss. In this work, we construct a new evaluation dataset derivedfrom a knowledge base to assess confidence scores given to answers of Mistraland LLaMA. Experiments show that they tend to be overconfident. Further, weshow that they are more overconfident on some answers than others, \emph{eg}depending on the nationality of the person in the query. Inuncertainty-quantification theory, this is grouping loss. To address this, wepropose a solution to reconfidence LLMs, canceling not only calibration butalso grouping loss. The LLMs, after the reconfidencing process, indicateimproved confidence alignment with the accuracy of their responses.</description><author>Lihu Chen, Alexandre Perez-Lebel, Fabian M. Suchanek, Gaël Varoquaux</author><pubDate>Wed, 07 Feb 2024 15:40:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04957v1</guid></item><item><title>Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems</title><link>http://arxiv.org/abs/2402.04955v1</link><description>Cognitive assistants (CA) are chatbots that provide context-aware support tohuman workers in knowledge-intensive tasks. Traditionally, cognitive assistantsrespond in specific ways to predefined user intents and conversation patterns.However, this rigidness does not handle the diversity of natural language well.Recent advances in natural language processing (NLP), powering large languagemodels (LLM) such as GPT-4, Llama2, and Gemini, could enable CAs to converse ina more flexible, human-like manner. However, the additional degrees of freedommay have unforeseen consequences, especially in knowledge-intensive contextswhere accuracy is crucial. As a preliminary step to assessing the potential ofusing LLMs in these contexts, we conducted a user study comparing an LLM-basedCA to an intent-based system regarding interaction efficiency, user experience,workload, and usability. This revealed that LLM-based CAs exhibited better userexperience, task completion rate, usability, and perceived performance thanintent-based systems, suggesting that switching NLP techniques should beinvestigated further.</description><author>Samuel Kernan Freire, Chaofan Wang, Evangelos Niforatos</author><pubDate>Wed, 07 Feb 2024 15:39:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04955v1</guid></item><item><title>cDVGAN: One Flexible Model for Multi-class Gravitational Wave Signal and Glitch Generation</title><link>http://arxiv.org/abs/2401.16356v3</link><description>Simulating realistic time-domain observations of gravitational waves (GWs)and GW detector glitches can help in advancing GW data analysis. Simulated datacan be used in downstream tasks by augmenting datasets for signal searches,balancing data sets for machine learning, and validating detection schemes. Inthis work, we present Conditional Derivative GAN (cDVGAN), a novel conditionalmodel in the Generative Adversarial Network framework for simulating multipleclasses of time-domain observations that represent gravitational waves (GWs)and detector glitches. cDVGAN can also generate generalized hybrid samples thatspan the variation between classes through interpolation in the conditionedclass vector. cDVGAN introduces an additional player into the typical 2-playeradversarial game of GANs, where an auxiliary discriminator analyzes thefirst-order derivative time-series. Our results show that this providessynthetic data that better captures the features of the original data. cDVGANconditions on three classes, two denoised from LIGO blip and tomte glitchevents from its 3rd observing run (O3), and the third representing binary blackhole (BBH) mergers. Our proposed cDVGAN outperforms 4 different baseline GANmodels in replicating the features of the three classes. Specifically, ourexperiments show that training convolutional neural networks (CNNs) with ourcDVGAN-generated data improves the detection of samples embedded in detectornoise beyond the synthetic data from other state-of-the-art GAN models. Ourbest synthetic dataset yields as much as a 4.2% increase inarea-under-the-curve (AUC) performance compared to synthetic datasets frombaseline GANs. Moreover, training the CNN with hybrid samples from our cDVGANoutperforms CNNs trained only on the standard classes, when identifying realsamples embedded in LIGO detector background (4% AUC improvement for cDVGAN).</description><author>Tom Dooney, Lyana Curier, Daniel Tan, Melissa Lopez, Chris Van Den Broeck, Stefano Bromuri</author><pubDate>Wed, 07 Feb 2024 15:37:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16356v3</guid></item><item><title>4-Dimensional deformation part model for pose estimation using Kalman filter constraints</title><link>http://arxiv.org/abs/2402.04953v1</link><description>The main goal of this article is to analyze the effect on pose estimationaccuracy when using a Kalman filter added to 4-dimensional deformation partmodel partial solutions. The experiments run with two data sets showing thatthis method improves pose estimation accuracy compared with state-of-the-artmethods and that a Kalman filter helps to increase this accuracy.</description><author>Enrique Martinez-Berti, Antonio-Jose Sanchez-Salmeron, Carlos Ricolfe-Viala</author><pubDate>Wed, 07 Feb 2024 15:37:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04953v1</guid></item><item><title>Metrics on Markov Equivalence Classes for Evaluating Causal Discovery Algorithms</title><link>http://arxiv.org/abs/2402.04952v1</link><description>Many state-of-the-art causal discovery methods aim to generate an outputgraph that encodes the graphical separation and connection statements of thecausal graph that underlies the data-generating process. In this work, we arguethat an evaluation of a causal discovery method against synthetic data shouldinclude an analysis of how well this explicit goal is achieved by measuring howclosely the separations/connections of the method's output align with those ofthe ground truth. We show that established evaluation measures do notaccurately capture the difference in separations/connections of two causalgraphs, and we introduce three new measures of distance called s/c-distance,Markov distance and Faithfulness distance that address this shortcoming. Wecomplement our theoretical analysis with toy examples, empirical experimentsand pseudocode.</description><author>Jonas Wahl, Jakob Runge</author><pubDate>Wed, 07 Feb 2024 15:36:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04952v1</guid></item><item><title>General Neural Gauge Fields</title><link>http://arxiv.org/abs/2305.03462v3</link><description>The recent advance of neural fields, such as neural radiance fields, hassignificantly pushed the boundary of scene representation learning. Aiming toboost the computation efficiency and rendering quality of 3D scenes, a popularline of research maps the 3D coordinate system to another measuring system,e.g., 2D manifolds and hash tables, for modeling neural fields. The conversionof coordinate systems can be typically dubbed as \emph{gauge transformation},which is usually a pre-defined mapping function, e.g., orthogonal projection orspatial hash function. This begs a question: can we directly learn a desiredgauge transformation along with the neural field in an end-to-end manner? Inthis work, we extend this problem to a general paradigm with a taxonomy ofdiscrete \&amp; continuous cases, and develop a learning framework to jointlyoptimize gauge transformations and neural fields. To counter the problem thatthe learning of gauge transformations can collapse easily, we derive a generalregularization mechanism from the principle of information conservation duringthe gauge transformation. To circumvent the high computation cost in gaugelearning with regularization, we directly derive an information-invariant gaugetransformation which allows to preserve scene information inherently and yieldsuperior performance. Project: https://fnzhan.com/Neural-Gauge-Fields</description><author>Fangneng Zhan, Lingjie Liu, Adam Kortylewski, Christian Theobalt</author><pubDate>Wed, 07 Feb 2024 15:17:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03462v3</guid></item><item><title>An approach to automated videogame beta testing</title><link>http://arxiv.org/abs/2402.04938v1</link><description>Videogames developed in the 1970s and 1980s were modest programs created in acouple of months by a single person, who played the roles of designer, artistand programmer. Since then, videogames have evolved to become a multi-milliondollar industry. Today, AAA game development involves hundreds of peopleworking together over several years. Management and engineering requirementshave changed at the same pace. Although many of the processes have been adaptedover time, this is not quite true for quality assurance tasks, which are stilldone mainly manually by human beta testers due to the specific peculiarities ofvideogames. This paper presents an approach to automate this beta testing.</description><author>Jennifer Hernández-Bécares, Luis Costero, Pedro Pablo Gómez-Martín</author><pubDate>Wed, 07 Feb 2024 15:16:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04938v1</guid></item><item><title>A Bayesian Approach to Online Learning for Contextual Restless Bandits with Applications to Public Health</title><link>http://arxiv.org/abs/2402.04933v1</link><description>Restless multi-armed bandits (RMABs) are used to model sequential resourceallocation in public health intervention programs. In these settings, theunderlying transition dynamics are often unknown a priori, requiring onlinereinforcement learning (RL). However, existing methods in online RL for RMABscannot incorporate properties often present in real-world public healthapplications, such as contextual information and non-stationarity. We presentBayesian Learning for Contextual RMABs (BCoR), an online RL approach for RMABsthat novelly combines techniques in Bayesian modeling with Thompson sampling toflexibly model a wide range of complex RMAB settings, such as contextual andnon-stationary RMABs. A key contribution of our approach is its ability toleverage shared information within and between arms to learn unknown RMABtransition dynamics quickly in budget-constrained settings with relativelyshort time horizons. Empirically, we show that BCoR achieves substantiallyhigher finite-sample performance than existing approaches over a range ofexperimental settings, including one constructed from a real-world publichealth campaign in India.</description><author>Biyonka Liang, Lily Xu, Aparna Taneja, Milind Tambe, Lucas Janson</author><pubDate>Wed, 07 Feb 2024 15:11:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04933v1</guid></item><item><title>4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes</title><link>http://arxiv.org/abs/2402.03307v2</link><description>We consider the problem of novel view synthesis (NVS) for dynamic scenes.Recent neural approaches have accomplished exceptional NVS results for static3D scenes, but extensions to 4D time-varying scenes remain non-trivial. Priorefforts often encode dynamics by learning a canonical space plus implicit orexplicit deformation fields, which struggle in challenging scenarios likesudden movements or capturing high-fidelity renderings. In this paper, weintroduce 4D Gaussian Splatting (4DGS), a novel method that represents dynamicscenes with anisotropic 4D XYZT Gaussians, inspired by the success of 3DGaussian Splatting in static scenes. We model dynamics at each timestamp bytemporally slicing the 4D Gaussians, which naturally compose dynamic 3DGaussians and can be seamlessly projected into images. As an explicitspatial-temporal representation, 4DGS demonstrates powerful capabilities formodeling complicated dynamics and fine details, especially for scenes withabrupt motions. We further implement our temporal slicing and splattingtechniques in a highly optimized CUDA acceleration framework, achievingreal-time inference rendering speeds of up to 277 FPS on an RTX 3090 GPU and583 FPS on an RTX 4090 GPU. Rigorous evaluations on scenes with diverse motionsshowcase the superior efficiency and effectiveness of 4DGS, which consistentlyoutperforms existing methods both quantitatively and qualitatively.</description><author>Yuanxing Duan, Fangyin Wei, Qiyu Dai, Yuhang He, Wenzheng Chen, Baoquan Chen</author><pubDate>Wed, 07 Feb 2024 15:09:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03307v2</guid></item><item><title>Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs</title><link>http://arxiv.org/abs/2401.04319v2</link><description>In this paper, we explore a new way for user targeting, where non-expertmarketers could select their target users solely given demands in naturallanguage form. The key to this issue is how to transform natural languages intopractical structured logical languages, i.e., the structured understanding ofmarketer demands. Considering the impressive natural language processingability of large language models (LLMs), we try to leverage LLMs to solve thisissue. Past research indicates that the reasoning ability of LLMs can beeffectively enhanced through chain-of-thought (CoT) prompting. But existingmethods still have some limitations: (1) Previous methods either use simple"Let's think step by step" spells or provide fixed examples in demonstrationswithout considering compatibility between prompts and questions, making LLMsineffective in some complex reasoning tasks such as structured languagetransformation. (2) Previous methods are often implemented in closed-sourcemodels or excessively large models, which is not suitable in industrialpractical scenarios. Based on these, we propose ARALLM (i.e., AnalogicalReasoning Augmented Large Language Models) consisting of two modules:Analogical Reasoning based Prompting and Reasoning-Augmented Multi-Task ModelDistillation.</description><author>Junjie Wang, Dan Yang, Binbin Hu, Yue Shen, Ziqi Liu, Wen Zhang, Jinjie Gu, Zhiqiang Zhang</author><pubDate>Wed, 07 Feb 2024 15:01:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04319v2</guid></item><item><title>Blue noise for diffusion models</title><link>http://arxiv.org/abs/2402.04930v1</link><description>Most of the existing diffusion models use Gaussian noise for training andsampling across all time steps, which may not optimally account for thefrequency contents reconstructed by the denoising network. Despite the diverseapplications of correlated noise in computer graphics, its potential forimproving the training process has been underexplored. In this paper, weintroduce a novel and general class of diffusion models taking correlated noisewithin and across images into account. More specifically, we propose atime-varying noise model to incorporate correlated noise into the trainingprocess, as well as a method for fast generation of correlated noise mask. Ourmodel is built upon deterministic diffusion models and utilizes blue noise tohelp improve the generation quality compared to using Gaussian white (random)noise only. Further, our framework allows introducing correlation across imageswithin a single mini-batch to improve gradient flow. We perform bothqualitative and quantitative evaluations on a variety of datasets using ourmethod, achieving improvements on different tasks over existing deterministicdiffusion models in terms of FID metric.</description><author>Xingchang Huang, Corentin Salaün, Cristina Vasconcelos, Christian Theobalt, Cengiz Öztireli, Gurprit Singh</author><pubDate>Wed, 07 Feb 2024 14:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04930v1</guid></item><item><title>Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation</title><link>http://arxiv.org/abs/2402.04929v1</link><description>This paper introduces a novel approach to leverage the generalizabilitycapability of Diffusion Models for Source-Free Domain Adaptation (DM-SFDA). Ourproposed DM-SFDA method involves fine-tuning a pre-trained text-to-imagediffusion model to generate source domain images using features from the targetimages to guide the diffusion process. Specifically, the pre-trained diffusionmodel is fine-tuned to generate source samples that minimize entropy andmaximize confidence for the pre-trained source model. We then apply establishedunsupervised domain adaptation techniques to align the generated source imageswith target domain data. We validate our approach through comprehensiveexperiments across a range of datasets, including Office-31, Office-Home, andVisDA. The results highlight significant improvements in SFDA performance,showcasing the potential of diffusion models in generating contextuallyrelevant, domain-specific images.</description><author>Shivang Chopra, Suraj Kothawade, Houda Aynaou, Aman Chadha</author><pubDate>Wed, 07 Feb 2024 14:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04929v1</guid></item><item><title>Two Trades is not Baffled: Condense Graph via Crafting Rational Gradient Matching</title><link>http://arxiv.org/abs/2402.04924v1</link><description>Training on large-scale graphs has achieved remarkable results in graphrepresentation learning, but its cost and storage have raised growing concerns.As one of the most promising directions, graph condensation methods addressthese issues by employing gradient matching, aiming to condense the full graphinto a more concise yet information-rich synthetic set. Though encouraging,these strategies primarily emphasize matching directions of the gradients,which leads to deviations in the training trajectories. Such deviations arefurther magnified by the differences between the condensation and evaluationphases, culminating in accumulated errors, which detrimentally affect theperformance of the condensed graphs. In light of this, we propose a novel graphcondensation method named \textbf{C}raf\textbf{T}ing \textbf{R}ationa\textbf{L}trajectory (\textbf{CTRL}), which offers an optimized starting point closer tothe original dataset's feature distribution and a more refined strategy forgradient matching. Theoretically, CTRL can effectively neutralize the impact ofaccumulated errors on the performance of condensed graphs. We provide extensiveexperiments on various graph datasets and downstream tasks to support theeffectiveness of CTRL. Code is released athttps://github.com/NUS-HPC-AI-Lab/CTRL.</description><author>Tianle Zhang, Yuchen Zhang, Kun Wang, Kai Wang, Beining Yang, Kaipeng Zhang, Wenqi Shao, Ping Liu, Joey Tianyi Zhou, Yang You</author><pubDate>Wed, 07 Feb 2024 14:49:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04924v1</guid></item><item><title>Entropy-MCMC: Sampling from Flat Basins with Ease</title><link>http://arxiv.org/abs/2310.05401v3</link><description>Bayesian deep learning counts on the quality of posterior distributionestimation. However, the posterior of deep neural networks is highlymulti-modal in nature, with local modes exhibiting varying generalizationperformance. Given a practical budget, targeting at the original posterior canlead to suboptimal performance, as some samples may become trapped in "bad"modes and suffer from overfitting. Leveraging the observation that "good" modeswith low generalization error often reside in flat basins of the energylandscape, we propose to bias sampling on the posterior toward these flatregions. Specifically, we introduce an auxiliary guiding variable, thestationary distribution of which resembles a smoothed posterior free from sharpmodes, to lead the MCMC sampler to flat basins. By integrating this guidingvariable with the model parameter, we create a simple joint distribution thatenables efficient sampling with minimal computational overhead. We prove theconvergence of our method and further show that it converges faster thanseveral existing flatness-aware methods in the strongly convex setting.Empirical results demonstrate that our method can successfully sample from flatbasins of the posterior, and outperforms all compared baselines on multiplebenchmarks including classification, calibration, and out-of-distributiondetection.</description><author>Bolian Li, Ruqi Zhang</author><pubDate>Wed, 07 Feb 2024 14:49:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05401v3</guid></item><item><title>Online Uniform Risk Times Sampling: First Approximation Algorithms, Learning Augmentation with Full Confidence Interval Integration</title><link>http://arxiv.org/abs/2402.01995v2</link><description>In digital health, the strategy of allocating a limited treatment budgetacross available risk times is crucial to reduce user fatigue. This strategy,however, encounters a significant obstacle due to the unknown actual number ofrisk times, a factor not adequately addressed by existing methods lackingtheoretical guarantees. This paper introduces, for the first time, the onlineuniform risk times sampling problem within the approximation algorithmframework. We propose two online approximation algorithms for this problem, onewith and one without learning augmentation, and provide rigorous theoreticalperformance guarantees for them using competitive ratio analysis. We assess theperformance of our algorithms using both synthetic experiments and a real-worldcase study on HeartSteps mobile applications.</description><author>Xueqing Liu, Kyra Gan, Esmaeil Keyvanshokooh, Susan Murphy</author><pubDate>Wed, 07 Feb 2024 14:48:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01995v2</guid></item><item><title>Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)</title><link>http://arxiv.org/abs/2402.04140v2</link><description>This study consists of a novel approach toward the analysis of courtjudgments spanning five countries, including the United States, the UnitedKingdom, Rwanda, Sweden and Hong Kong. This study also explores theintersection of the latest advancements in artificial intelligence (AI) andlegal analysis, emphasizing the role of AI (specifically generative AI) inidentifying human biases and facilitating automated, valid, and coherentmultisided argumentation of court judgments with the goal of ensuringconsistent application of laws in and across various jurisdictions. Byincorporating Advanced Language Models (ALMs) and a newly introduced human-AIcollaborative framework, this paper seeks to analyze Grounded Theory-basedresearch design with Advanced Language Models (ALMs) in the practice of law.SHIRLEY is the name of the AI-based application (built on top of OpenAI's GPTtechnology), focusing on detecting logical inconsistencies and biases acrossvarious legal decisions. SHIRLEY analysis is aggregated and is accompanied by acomparison-oriented AI-based application called SAM (also an ALM) to identifyrelative deviations in SHIRLEY bias detections. Further, a CRITIC is generatedwithin semi-autonomous arbitration process via the ALM, SARA. A novel approachis introduced in the utilization of an AI arbitrator to critically evaluatebiases and qualitative-in-nature nuances identified by the aforementioned AIapplications (SAM in concert with SHIRLEY), based on the Hague Rules onBusiness and Human Rights Arbitration. This Semi-Automated Arbitration Process(SAAP) aims to uphold the integrity and fairness of legal judgments by ensuringa nuanced debate-resultant "understanding" through a hybrid system of AI andhuman-based collaborative analysis.</description><author>Michael De'Shazer</author><pubDate>Wed, 07 Feb 2024 14:48:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04140v2</guid></item><item><title>Voronoi Candidates for Bayesian Optimization</title><link>http://arxiv.org/abs/2402.04922v1</link><description>Bayesian optimization (BO) offers an elegant approach for efficientlyoptimizing black-box functions. However, acquisition criteria demand their ownchallenging inner-optimization, which can induce significant overhead. Manypractical BO methods, particularly in high dimension, eschew a formal,continuous optimization of the acquisition function and instead searchdiscretely over a finite set of space-filling candidates. Here, we propose touse candidates which lie on the boundary of the Voronoi tessellation of thecurrent design points, so they are equidistant to two or more of them. Wediscuss strategies for efficient implementation by directly sampling theVoronoi boundary without explicitly generating the tessellation, thusaccommodating large designs in high dimension. On a battery of test problemsoptimized via Gaussian processes with expected improvement, our proposedapproach significantly improves the execution time of a multi-start continuoussearch without a loss in accuracy.</description><author>Nathan Wycoff, John W. Smith, Annie S. Booth, Robert B. Gramacy</author><pubDate>Wed, 07 Feb 2024 14:47:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04922v1</guid></item><item><title>Is Two-shot All You Need? A Label-efficient Approach for Video Segmentation in Breast Ultrasound</title><link>http://arxiv.org/abs/2402.04921v1</link><description>Breast lesion segmentation from breast ultrasound (BUS) videos could assistin early diagnosis and treatment. Existing video object segmentation (VOS)methods usually require dense annotation, which is often inaccessible formedical datasets. Furthermore, they suffer from accumulative errors and a lackof explicit space-time awareness. In this work, we propose a novel two-shottraining paradigm for BUS video segmentation. It not only is able to capturefree-range space-time consistency but also utilizes a source-dependentaugmentation scheme. This label-efficient learning framework is validated on achallenging in-house BUS video dataset. Results showed that it gainedcomparable performance to the fully annotated ones given only 1.9% traininglabels.</description><author>Jiajun Zeng, Ruobing Huang, Dong Ni</author><pubDate>Wed, 07 Feb 2024 14:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04921v1</guid></item><item><title>Prompting Implicit Discourse Relation Annotation</title><link>http://arxiv.org/abs/2402.04918v1</link><description>Pre-trained large language models, such as ChatGPT, archive outstandingperformance in various reasoning tasks without supervised training and werefound to have outperformed crowdsourcing workers. Nonetheless, ChatGPT'sperformance in the task of implicit discourse relation classification, promptedby a standard multiple-choice question, is still far from satisfactory andconsiderably inferior to state-of-the-art supervised approaches. This workinvestigates several proven prompting techniques to improve ChatGPT'srecognition of discourse relations. In particular, we experimented withbreaking down the classification task that involves numerous abstract labelsinto smaller subtasks. Nonetheless, experiment results show that the inferenceaccuracy hardly changes even with sophisticated prompt engineering, suggestingthat implicit discourse relation classification is not yet resolvable underzero-shot or few-shot settings.</description><author>Frances Yung, Mansoor Ahmad, Merel Scholman, Vera Demberg</author><pubDate>Wed, 07 Feb 2024 14:44:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04918v1</guid></item><item><title>Imitation Learning from Observation with Automatic Discount Scheduling</title><link>http://arxiv.org/abs/2310.07433v3</link><description>Humans often acquire new skills through observation and imitation. Forrobotic agents, learning from the plethora of unlabeled video demonstrationdata available on the Internet necessitates imitating the expert without accessto its action, presenting a challenge known as Imitation Learning fromObservations (ILfO). A common approach to tackle ILfO problems is to convertthem into inverse reinforcement learning problems, utilizing a proxy rewardcomputed from the agent's and the expert's observations. Nonetheless, weidentify that tasks characterized by a progress dependency property posesignificant challenges for such approaches; in these tasks, the agent needs toinitially learn the expert's preceding behaviors before mastering thesubsequent ones. Our investigation reveals that the main cause is that thereward signals assigned to later steps hinder the learning of initialbehaviors. To address this challenge, we present a novel ILfO framework thatenables the agent to master earlier behaviors before advancing to later ones.We introduce an Automatic Discount Scheduling (ADS) mechanism that adaptivelyalters the discount factor in reinforcement learning during the training phase,prioritizing earlier rewards initially and gradually engaging later rewardsonly when the earlier behaviors have been mastered. Our experiments, conductedon nine Meta-World tasks, demonstrate that our method significantly outperformsstate-of-the-art methods across all tasks, including those that are unsolvableby them.</description><author>Yuyang Liu, Weijun Dong, Yingdong Hu, Chuan Wen, Zhao-Heng Yin, Chongjie Zhang, Yang Gao</author><pubDate>Wed, 07 Feb 2024 14:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07433v3</guid></item><item><title>Labeled Interactive Topic Models</title><link>http://arxiv.org/abs/2311.09438v2</link><description>Topic models are valuable for understanding extensive document collections,but they don't always identify the most relevant topics. Classicalprobabilistic and anchor-based topic models offer interactive versions thatallow users to guide the models towards more pertinent topics. However, suchinteractive features have been lacking in neural topic models. To correct thislacuna, we introduce a user-friendly interaction for neural topic models. Thisinteraction permits users to assign a word label to a topic, leading to anupdate in the topic model where the words in the topic become closely alignedwith the given label. Our approach encompasses two distinct kinds of neuraltopic models. The first includes models where topic embeddings are trainableand evolve during the training process. The second kind involves models wheretopic embeddings are integrated post-training, offering a different approach totopic refinement. To facilitate user interaction with these neural topicmodels, we have developed an interactive interface. This interface enablesusers to engage with and re-label topics as desired. We evaluate our methodthrough a human study, where users can relabel topics to find relevantdocuments. Using our method, user labeling improves document rank scores,helping to find more relevant documents to a given query when compared to nouser labeling.</description><author>Kyle Seelman, Mozhi Zhang, Jordan Boyd-Graber</author><pubDate>Wed, 07 Feb 2024 14:41:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09438v2</guid></item><item><title>Moco: A Learnable Meta Optimizer for Combinatorial Optimization</title><link>http://arxiv.org/abs/2402.04915v1</link><description>Relevant combinatorial optimization problems (COPs) are often NP-hard. Whilethey have been tackled mainly via handcrafted heuristics in the past, advancesin neural networks have motivated the development of general methods to learnheuristics from data. Many approaches utilize a neural network to directlyconstruct a solution, but are limited in further improving based on alreadyconstructed solutions at inference time. Our approach, Moco, learns a graphneural network that updates the solution construction procedure based onfeatures extracted from the current search state. This meta training proceduretargets the overall best solution found during the search procedure giveninformation such as the search budget. This allows Moco to adapt to varyingcircumstances such as different computational budgets. Moco is a fullylearnable meta optimizer that does not utilize any problem specific localsearch or decomposition. We test Moco on the Traveling Salesman Problem (TSP)and Maximum Independent Set (MIS) and show that it outperforms other approacheson MIS and is overall competitive on the TSP, especially outperforming relatedapproaches, partially even if they use additional local search.</description><author>Tim Dernedde, Daniela Thyssens, Sören Dittrich, Maximilan Stubbemann, Lars Schmidt-Thieme</author><pubDate>Wed, 07 Feb 2024 14:41:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04915v1</guid></item><item><title>Personalized Text Generation with Fine-Grained Linguistic Control</title><link>http://arxiv.org/abs/2402.04914v1</link><description>As the text generation capabilities of large language models becomeincreasingly prominent, recent studies have focused on controlling particularaspects of the generated text to make it more personalized. However, mostresearch on controllable text generation focuses on controlling the content ormodeling specific high-level/coarse-grained attributes that reflect authors'writing styles, such as formality, domain, or sentiment. In this paper, wefocus on controlling fine-grained attributes spanning multiple linguisticdimensions, such as lexical and syntactic attributes. We introduce a novelbenchmark to train generative models and evaluate their ability to generatepersonalized text based on multiple fine-grained linguistic attributes. Wesystematically investigate the performance of various large language models onour benchmark and draw insights from the factors that impact their performance.We make our code, data, and pretrained models publicly available.</description><author>Bashar Alhafni, Vivek Kulkarni, Dhruv Kumar, Vipul Raheja</author><pubDate>Wed, 07 Feb 2024 14:41:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04914v1</guid></item><item><title>Towards Biologically Plausible and Private Gene Expression Data Generation</title><link>http://arxiv.org/abs/2402.04912v1</link><description>Generative models trained with Differential Privacy (DP) are becomingincreasingly prominent in the creation of synthetic data for downstreamapplications. Existing literature, however, primarily focuses on basicbenchmarking datasets and tends to report promising results only for elementarymetrics and relatively simple data distributions. In this paper, we initiate asystematic analysis of how DP generative models perform in their naturalapplication scenarios, specifically focusing on real-world gene expressiondata. We conduct a comprehensive analysis of five representative DP generationmethods, examining them from various angles, such as downstream utility,statistical properties, and biological plausibility. Our extensive evaluationilluminates the unique characteristics of each DP generation method, offeringcritical insights into the strengths and weaknesses of each approach, anduncovering intriguing possibilities for future developments. Perhapssurprisingly, our analysis reveals that most methods are capable of achievingseemingly reasonable downstream utility, according to the standard evaluationmetrics considered in existing literature. Nevertheless, we find that none ofthe DP methods are able to accurately capture the biological characteristics ofthe real dataset. This observation suggests a potential over-optimisticassessment of current methodologies in this field and underscores a pressingneed for future enhancements in model design.</description><author>Dingfan Chen, Marie Oestreich, Tejumade Afonja, Raouf Kerkouche, Matthias Becker, Mario Fritz</author><pubDate>Wed, 07 Feb 2024 14:39:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04912v1</guid></item><item><title>An Outlook into the Future of Egocentric Vision</title><link>http://arxiv.org/abs/2308.07123v2</link><description>What will the future be? We wonder! In this survey, we explore the gapbetween current research in egocentric vision and the ever-anticipated future,where wearable computing, with outward facing cameras and digital overlays, isexpected to be integrated in our every day lives. To understand this gap, thearticle starts by envisaging the future through character-based stories,showcasing through examples the limitations of current technology. We thenprovide a mapping between this future and previously defined research tasks.For each task, we survey its seminal works, current state-of-the-artmethodologies and available datasets, then reflect on shortcomings that limitits applicability to future research. Note that this survey focuses on softwaremodels for egocentric vision, independent of any specific hardware. The paperconcludes with recommendations for areas of immediate explorations so as tounlock our path to the future always-on, personalised and life-enhancingegocentric vision.</description><author>Chiara Plizzari, Gabriele Goletto, Antonino Furnari, Siddhant Bansal, Francesco Ragusa, Giovanni Maria Farinella, Dima Damen, Tatiana Tommasi</author><pubDate>Wed, 07 Feb 2024 14:37:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07123v2</guid></item><item><title>On a Combinatorial Problem Arising in Machine Teaching</title><link>http://arxiv.org/abs/2402.04907v1</link><description>We study a model of machine teaching where the teacher mapping is constructedfrom a size function on both concepts and examples. The main question inmachine teaching is the minimum number of examples needed for any concept, theso-called teaching dimension. A recent paper [7] conjectured that the worstcase for this model, as a function of the size of the concept class, occurswhen the consistency matrix contains the binary representations of numbers fromzero and up. In this paper we prove their conjecture. The result can be seen asa generalization of a theorem resolving the edge isoperimetry problem forhypercubes [12], and our proof is based on a lemma of [10].</description><author>Brigt Håvardstun, Jan Kratochvíl, Joakim Sunde, Jan Arne</author><pubDate>Wed, 07 Feb 2024 14:37:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04907v1</guid></item><item><title>Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects</title><link>http://arxiv.org/abs/2402.04906v1</link><description>Knowledge of the effect of interventions, called the treatment effect, isparamount for decision-making. Approaches to estimating this treatment effect,e.g. by using Conditional Average Treatment Effect (CATE) estimators, oftenonly provide a point estimate of this treatment effect, while additionaluncertainty quantification is frequently desired instead. Therefore, we presenta novel method, the Conformal Monte Carlo (CMC) meta-learners, leveragingconformal predictive systems, Monte Carlo sampling, and CATE meta-learners, toinstead produce a predictive distribution usable in individualizeddecision-making. Furthermore, we show how specific assumptions on the noisedistribution of the outcome heavily affect these uncertainty predictions.Nonetheless, the CMC framework shows strong experimental coverage whileretaining small interval widths to provide estimates of the true individualtreatment effect.</description><author>Jef Jonkers, Jarne Verhaeghe, Glenn Van Wallendael, Luc Duchateau, Sofie Van Hoecke</author><pubDate>Wed, 07 Feb 2024 14:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04906v1</guid></item></channel></rss>