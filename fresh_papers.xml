<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 14 Feb 2025 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Poly-Autoregressive Prediction for Modeling Interactions</title><link>http://arxiv.org/abs/2502.08646v1</link><description>We introduce a simple framework for predicting the behavior of an agent inmulti-agent settings. In contrast to autoregressive (AR) tasks, such aslanguage processing, our focus is on scenarios with multiple agents whoseinteractions are shaped by physical constraints and internal motivations. Tothis end, we propose Poly-Autoregressive (PAR) modeling, which forecasts an egoagent's future behavior by reasoning about the ego agent's state history andthe past and current states of other interacting agents. At its core, PARrepresents the behavior of all agents as a sequence of tokens, eachrepresenting an agent's state at a specific timestep. With minimal datapre-processing changes, we show that PAR can be applied to three differentproblems: human action forecasting in social situations, trajectory predictionfor autonomous vehicles, and object pose forecasting during hand-objectinteraction. Using a small proof-of-concept transformer backbone, PARoutperforms AR across these three scenarios. The project website can be foundat https://neerja.me/PAR/.</description><author>Neerja Thakkar, Tara Sadjadpour, Jathushan Rajasegaran, Shiry Ginosar, Jitendra Malik</author><pubDate>Wed, 12 Feb 2025 18:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08646v1</guid></item><item><title>Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and learning in neural networks</title><link>http://arxiv.org/abs/2502.08644v1</link><description>The brain can rapidly adapt to new contexts and learn from limited data, acoveted characteristic that artificial intelligence algorithms have struggledto mimic. Inspired by oscillatory rhythms of the mechanical structures ofneural cells, we developed a learning paradigm that is based on oscillations inlink strengths and associates learning with the coordination of theseoscillations. We find that this paradigm yields rapid adaptation and learningin artificial neural networks. Link oscillations can rapidly changecoordination, endowing the network with the ability to sense subtle contextchanges in an unsupervised manner. In other words, the network generates themissing contextual tokens required to perform as a generalist AI architecturecapable of predicting dynamics in multiple contexts. Oscillations also allowthe network to extrapolate dynamics to never-seen-before contexts. Thesecapabilities make our learning paradigm a powerful starting point for novelmodels of learning and cognition. Furthermore, learning through linkcoordination is agnostic to the specifics of the neural network architecture,hence our study opens the door for introducing rapid adaptation and learningcapabilities into leading AI models.</description><author>Hoony Kang, Wolfgang Losert</author><pubDate>Wed, 12 Feb 2025 18:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08644v1</guid></item><item><title>A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards</title><link>http://arxiv.org/abs/2502.08643v1</link><description>Task specification for robotic manipulation in open-world environments ischallenging, requiring flexible and adaptive objectives that align with humanintentions and can evolve through iterative feedback. We introduce IterativeKeypoint Reward (IKER), a visually grounded, Python-based reward function thatserves as a dynamic task specification. Our framework leverages VLMs togenerate and refine these reward functions for multi-step manipulation tasks.Given RGB-D observations and free-form language instructions, we samplekeypoints in the scene and generate a reward function conditioned on thesekeypoints. IKER operates on the spatial relationships between keypoints,leveraging commonsense priors about the desired behaviors, and enabling preciseSE(3) control. We reconstruct real-world scenes in simulation and use thegenerated rewards to train reinforcement learning (RL) policies, which are thendeployed into the real world-forming a real-to-sim-to-real loop. Our approachdemonstrates notable capabilities across diverse scenarios, including bothprehensile and non-prehensile tasks, showcasing multi-step task execution,spontaneous error recovery, and on-the-fly strategy adjustments. The resultshighlight IKER's effectiveness in enabling robots to perform multi-step tasksin dynamic environments through iterative reward shaping.</description><author>Shivansh Patel, Xinchen Yin, Wenlong Huang, Shubham Garg, Hooshang Nayyeri, Li Fei-Fei, Svetlana Lazebnik, Yunzhu Li</author><pubDate>Wed, 12 Feb 2025 18:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08643v1</guid></item><item><title>SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation</title><link>http://arxiv.org/abs/2502.08642v1</link><description>Recent advancements in large vision-language models have enabled highlyexpressive and diverse vector sketch generation. However, state-of-the-artmethods rely on a time-consuming optimization process involving repeatedfeedback from a pretrained model to determine stroke placement. Consequently,despite producing impressive sketches, these methods are limited in practicalapplications. In this work, we introduce SwiftSketch, a diffusion model forimage-conditioned vector sketch generation that can produce high-qualitysketches in less than a second. SwiftSketch operates by progressively denoisingstroke control points sampled from a Gaussian distribution. Itstransformer-decoder architecture is designed to effectively handle the discretenature of vector representation and capture the inherent global dependenciesbetween strokes. To train SwiftSketch, we construct a synthetic dataset ofimage-sketch pairs, addressing the limitations of existing sketch datasets,which are often created by non-artists and lack professional quality. Forgenerating these synthetic sketches, we introduce ControlSketch, a method thatenhances SDS-based techniques by incorporating precise spatial control througha depth-aware ControlNet. We demonstrate that SwiftSketch generalizes acrossdiverse concepts, efficiently producing sketches that combine high fidelitywith a natural and visually appealing style.</description><author>Ellie Arar, Yarden Frenkel, Daniel Cohen-Or, Ariel Shamir, Yael Vinker</author><pubDate>Wed, 12 Feb 2025 18:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08642v1</guid></item><item><title>Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs</title><link>http://arxiv.org/abs/2502.08640v1</link><description>As AIs rapidly advance and become more agentic, the risk they pose isgoverned not only by their capabilities but increasingly by their propensities,including goals and values. Tracking the emergence of goals and values hasproven a longstanding problem, and despite much interest over the years itremains unclear whether current AIs have meaningful values. We propose asolution to this problem, leveraging the framework of utility functions tostudy the internal coherence of AI preferences. Surprisingly, we find thatindependently-sampled preferences in current LLMs exhibit high degrees ofstructural coherence, and moreover that this emerges with scale. These findingssuggest that value systems emerge in LLMs in a meaningful sense, a finding withbroad implications. To study these emergent value systems, we propose utilityengineering as a research agenda, comprising both the analysis and control ofAI utilities. We uncover problematic and often shocking values in LLMassistants despite existing control measures. These include cases where AIsvalue themselves over humans and are anti-aligned with specific individuals. Toconstrain these emergent value systems, we propose methods of utility control.As a case study, we show how aligning utilities with a citizen assembly reducespolitical biases and generalizes to new scenarios. Whether we like it or not,value systems have already emerged in AIs, and much work remains to fullyunderstand and control these emergent representations.</description><author>Mantas Mazeika, Xuwang Yin, Rishub Tamirisa, Jaehyuk Lim, Bruce W. Lee, Richard Ren, Long Phan, Norman Mu, Adam Khoja, Oliver Zhang, Dan Hendrycks</author><pubDate>Wed, 12 Feb 2025 18:55:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08640v1</guid></item><item><title>CineMaster: A 3D-Aware and Controllable Framework for Cinematic Text-to-Video Generation</title><link>http://arxiv.org/abs/2502.08639v1</link><description>In this work, we present CineMaster, a novel framework for 3D-aware andcontrollable text-to-video generation. Our goal is to empower users withcomparable controllability as professional film directors: precise placement ofobjects within the scene, flexible manipulation of both objects and camera in3D space, and intuitive layout control over the rendered frames. To achievethis, CineMaster operates in two stages. In the first stage, we design aninteractive workflow that allows users to intuitively construct 3D-awareconditional signals by positioning object bounding boxes and defining cameramovements within the 3D space. In the second stage, these controlsignals--comprising rendered depth maps, camera trajectories and object classlabels--serve as the guidance for a text-to-video diffusion model, ensuring togenerate the user-intended video content. Furthermore, to overcome the scarcityof in-the-wild datasets with 3D object motion and camera pose annotations, wecarefully establish an automated data annotation pipeline that extracts 3Dbounding boxes and camera trajectories from large-scale video data. Extensivequalitative and quantitative experiments demonstrate that CineMastersignificantly outperforms existing methods and implements prominent 3D-awaretext-to-video generation. Project page: https://cinemaster-dev.github.io/.</description><author>Qinghe Wang, Yawen Luo, Xiaoyu Shi, Xu Jia, Huchuan Lu, Tianfan Xue, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai</author><pubDate>Wed, 12 Feb 2025 18:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08639v1</guid></item><item><title>Examining Multilingual Embedding Models Cross-Lingually Through LLM-Generated Adversarial Examples</title><link>http://arxiv.org/abs/2502.08638v1</link><description>The evaluation of cross-lingual semantic search capabilities of models isoften limited to existing datasets from tasks such as information retrieval andsemantic textual similarity. To allow for domain-specific evaluation, weintroduce Cross Lingual Semantic Discrimination (CLSD), a novel cross-lingualsemantic search task that requires only a set of parallel sentence pairs of thelanguage pair of interest within the target domain. This task focuses on theability of a model to cross-lingually rank the true parallel sentence higherthan hard negatives generated by a large language model. We create fourinstances of our introduced CLSD task for the language pair German-Frenchwithin the domain of news. Within this case study, we find that models that arealso fine-tuned for retrieval tasks (e.g., multilingual E5) benefit from usingEnglish as the pivot language, while bitext mining models such as LaBSE performbest directly cross-lingually. We also show a fine-grained similarity analysisenabled by our distractor generation strategy, indicating that differentembedding models are sensitive to different types of perturbations.</description><author>Andrianos Michail, Simon Clematide, Rico Sennrich</author><pubDate>Wed, 12 Feb 2025 18:54:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08638v1</guid></item><item><title>Joint Transmit and Pinching Beamforming for PASS: Optimization-Based or Learning-Based?</title><link>http://arxiv.org/abs/2502.08637v1</link><description>A novel pinching antenna system (PASS)-enabled downlink multi-usermultiple-input single-output (MISO) framework is proposed. PASS consists ofmultiple waveguides spanning over thousands of wavelength, which equip numerouslow-cost dielectric particles, named pinching antennas (PAs), to radiatesignals into free space. The positions of PAs can be reconfigured to changeboth the large-scale path losses and phases of signals, thus facilitating thenovel pinching beamforming design. A sum rate maximization problem isformulated, which jointly optimizes the transmit and pinching beamforming toadaptively achieve constructive signal enhancement and destructive interferencemitigation. To solve this highly coupled and nonconvex problem, bothoptimization-based and learning-based methods are proposed. 1) For theoptimization-based method, a majorization-minimization and penalty dualdecomposition (MM-PDD) algorithm is developed, which handles the nonconvexcomplex exponential component using a Lipschitz surrogate function and theninvokes PDD for problem decoupling. 2) For the learning-based method, a novelKarush-Kuhn-Tucker (KKT)-guided dual learning (KDL) approach is proposed, whichenables KKT solutions to be reconstructed in a data-driven manner by learningdual variables. Following this idea, a KDL-Tranformer algorithm is developed,which captures both inter-PA/inter-user dependencies andchannel-state-information (CSI)-beamforming dependencies by attentionmechanisms. Simulation results demonstrate that: i) The proposed PASS frameworksignificantly outperforms conventional massive multiple input multiple output(MIMO) system even with a few PAs. ii) The proposed KDL-Transformer can improveover 30% system performance than MM-PDD algorithm, while achieving amillisecond-level response on modern GPUs.</description><author>Xiaoxia Xu, Xidong Mu, Yuanwei Liu, Arumugam Nallanathan</author><pubDate>Wed, 12 Feb 2025 18:54:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08637v1</guid></item><item><title>PulseCheck457: A Diagnostic Benchmark for Comprehensive Spatial Reasoning of Large Multimodal Models</title><link>http://arxiv.org/abs/2502.08636v1</link><description>Although large multimodal models (LMMs) have demonstrated remarkablecapabilities in visual scene interpretation and reasoning, their capacity forcomplex and precise 3-dimensional spatial reasoning remains uncertain. Existingbenchmarks focus predominantly on 2D spatial understanding and lack a frameworkto comprehensively evaluate 6D spatial reasoning across varying complexities.To address this limitation, we present PulseCheck457, a scalable and unbiasedsynthetic dataset designed with 4 key capability for spatial reasoning:multi-object recognition, 2D location, 3D location, and 3D orientation. Wedevelop a cascading evaluation structure, constructing 7 question types across5 difficulty levels that range from basic single object recognition to our newproposed complex 6D spatial reasoning tasks. We evaluated various largemultimodal models (LMMs) on PulseCheck457, observing a general decline inperformance as task complexity increases, particularly in 3D reasoning and 6Dspatial tasks. To quantify these challenges, we introduce the RelativePerformance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoningcapabilities. Leveraging the unbiased attribute design of our dataset, we alsouncover prediction biases across different attributes, with similar patternsobserved in real-world image settings.</description><author>Xingrui Wang, Wufei Ma, Tiezheng Zhang, Celso M de Melo, Jieneng Chen, Alan Yuille</author><pubDate>Wed, 12 Feb 2025 18:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08636v1</guid></item><item><title>Rapid Whole Brain Mesoscale In-vivo MR Imaging using Multi-scale Implicit Neural Representation</title><link>http://arxiv.org/abs/2502.08634v1</link><description>Purpose: To develop and validate a novel image reconstruction technique usingimplicit neural representations (INR) for multi-view thick-slice acquisitionswhile reducing the scan time but maintaining high signal-to-noise ratio (SNR).Methods: We propose Rotating-view super-resolution (ROVER)-MRI, an unsupervisedneural network-based algorithm designed to reconstruct MRI data from multi-viewthick slices, effectively reducing scan time by 2-fold while maintaining fineanatomical details. We compare our method to both bicubic interpolation and thecurrent state-of-the-art regularized least-squares super-resolutionreconstruction (LS-SRR) technique. Validation is performed using ground-truthex-vivo monkey brain data, and we demonstrate superior reconstruction qualityacross several in-vivo human datasets. Notably, we achieve the reconstructionof a whole human brain in-vivo T2-weighted image with an unprecedented180{\mu}m isotropic spatial resolution, accomplished in just 17 minutes of scantime on a 7T MRI scanner. Results: ROVER-MRI outperformed LS-SRR method interms of reconstruction quality with 22.4% lower relative error (RE) and 7.5%lower full-width half maximum (FWHM) indicating better preservation of finestructural details in nearly half the scan time. Conclusion: ROVER-MRI offersan efficient and robust approach for mesoscale MR imaging, enabling rapid,high-resolution whole-brain scans. Its versatility holds great promise forresearch applications requiring anatomical details and time-efficient imaging.</description><author>Jun Lyu, Lipeng Ning, William Consagra, Qiang Liu, Richard J. Rushmore, Berkin Bilgic, Yogesh Rathi</author><pubDate>Wed, 12 Feb 2025 18:48:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08634v1</guid></item><item><title>Necessary and Sufficient Oracles: Toward a Computational Taxonomy For Reinforcement Learning</title><link>http://arxiv.org/abs/2502.08632v1</link><description>Algorithms for reinforcement learning (RL) in large state spaces cruciallyrely on supervised learning subroutines to estimate objects such as valuefunctions or transition probabilities. Since only the simplest supervisedlearning problems can be solved provably and efficiently, practical performanceof an RL algorithm depends on which of these supervised learning "oracles" itassumes access to (and how they are implemented). But which oracles are betteror worse? Is there a minimal oracle? In this work, we clarify the impact of the choice of supervised learningoracle on the computational complexity of RL, as quantified by the oraclestrength. First, for the task of reward-free exploration in Block MDPs in thestandard episodic access model -- a ubiquitous setting for RL with functionapproximation -- we identify two-context regression as a minimal oracle, i.e.an oracle that is both necessary and sufficient (under a mild regularityassumption). Second, we identify one-context regression as a near-minimaloracle in the stronger reset access model, establishing a provablecomputational benefit of resets in the process. Third, we broaden our focus toLow-Rank MDPs, where we give cryptographic evidence that the analogous oraclefrom the Block MDP setting is insufficient.</description><author>Dhruv Rohatgi, Dylan J. Foster</author><pubDate>Wed, 12 Feb 2025 18:47:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08632v1</guid></item><item><title>Ensemble based approach to quantifying uncertainty of LLM based classifications</title><link>http://arxiv.org/abs/2502.08631v1</link><description>The output of Large Language Models (LLMs) are a function of the internalmodel's parameters and the input provided into the context window. Thehypothesis presented here is that under a greedy sampling strategy the variancein the LLM's output is a function of the conceptual certainty embedded in themodel's parametric knowledge, as well as the lexical variance in the input.Finetuning the model results in reducing the sensitivity of the model output tothe lexical input variations. This is then applied to a classification problemand a probabilistic method is proposed for estimating the certainties of thepredicted classes.</description><author>Srijith Rajamohan, Ahmed Salhin, Josh Frazier, Rohit Kumar, Yu-Cheng Tsai, Todd Cook</author><pubDate>Wed, 12 Feb 2025 18:42:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08631v1</guid></item><item><title>Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment</title><link>http://arxiv.org/abs/2502.04328v2</link><description>Recent advances in large language models, particularly following GPT-4o, havesparked increasing interest in developing omni-modal models capable ofunderstanding more modalities. While some open-source alternatives haveemerged, there is still a notable lag behind specialized single-modality modelsin performance. In this paper, we present Ola, an Omni-modal language modelthat achieves competitive performance across image, video, and audiounderstanding compared to specialized counterparts. The core design of Ola liesin its progressive modality alignment strategy that extends the supportingmodality of the language model progressively. Our training pipeline begins withthe most distinct modalities: image and text, then gradually expands the skillsets of the model using speech data that connects language and audio knowledge,and video data that connects all modalities. The progressive learning pipelinealso enables us to maintain a relatively small size of the cross-modalalignment data, making developing omni-modal from existing vision-languagemodels easy and less costly. Moreover, to unlock an advanced interactiveexperience like GPT-4o, we further design a sentence-wise decoding solution forstreaming speech generation. Extensive experiments demonstrate that Olasurpasses existing open omni-modal LLMs across all modalities while achievinghighly competitive performance compared to state-of-the-art specialized modelsof similar sizes. We aim to make Ola a fully open omni-modal understandingsolution to advance future research in this emerging field. Model weights,code, and data are open-sourced at https://github.com/Ola-Omni/Ola.</description><author>Zuyan Liu, Yuhao Dong, Jiahui Wang, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao</author><pubDate>Wed, 12 Feb 2025 18:40:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.04328v2</guid></item><item><title>ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning</title><link>http://arxiv.org/abs/2502.04689v2</link><description>Large language models (LLMs) achieve remarkable performance on challengingbenchmarks that are often structured as multiple-choice question-answering (QA)tasks. Zero-shot Chain-of-Thought (CoT) prompting enhances reasoning in LLMsbut provides only vague and generic guidance ("think step by step"). This paperintroduces ARR, an intuitive and effective zero-shot prompting method thatexplicitly incorporates three key steps in QA solving: analyzing the intent ofthe question, retrieving relevant information, and reasoning step by step.Comprehensive experiments across diverse and challenging QA tasks demonstratethat ARR consistently improves the Baseline (without ARR prompting) andoutperforms CoT. Ablation and case studies further validate the positivecontributions of each component: analyzing, retrieving, and reasoning. Notably,intent analysis plays a vital role in ARR. Additionally, extensive evaluationsacross various model sizes, LLM series, and generation settings solidify theeffectiveness, robustness, and generalizability of ARR.</description><author>Yuwei Yin, Giuseppe Carenini</author><pubDate>Wed, 12 Feb 2025 18:36:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.04689v2</guid></item><item><title>Transcoders Beat Sparse Autoencoders for Interpretability</title><link>http://arxiv.org/abs/2501.18823v2</link><description>Sparse autoencoders (SAEs) extract human-interpretable features from deepneural networks by transforming their activations into a sparse, higherdimensional latent space, and then reconstructing the activations from theselatents. Transcoders are similar to SAEs, but they are trained to reconstructthe output of a component of a deep network given its input. In this work, wecompare the features found by transcoders and SAEs trained on the same modeland data, finding that transcoder features are significantly moreinterpretable. We also propose skip transcoders, which add an affine skipconnection to the transcoder architecture, and show that these achieve lowerreconstruction loss with no effect on interpretability.</description><author>Gonçalo Paulo, Stepan Shabalin, Nora Belrose</author><pubDate>Wed, 12 Feb 2025 18:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18823v2</guid></item><item><title>Sample complexity of data-driven tuning of model hyperparameters in neural networks with structured parameter-dependent dual function</title><link>http://arxiv.org/abs/2501.13734v3</link><description>Modern machine learning algorithms, especially deep learning basedtechniques, typically involve careful hyperparameter tuning to achieve the bestperformance. Despite the surge of intense interest in practical techniques likeBayesian optimization and random search based approaches to automating thislaborious and compute intensive task, the fundamental learning theoreticcomplexity of tuning hyperparameters for deep neural networks is poorlyunderstood. Inspired by this glaring gap, we initiate the formal study ofhyperparameter tuning complexity in deep learning through a recently introduceddata driven setting. We assume that we have a series of deep learning tasks,and we have to tune hyperparameters to do well on average over the distributionof tasks. A major difficulty is that the utility function as a function of thehyperparameter is very volatile and furthermore, it is given implicitly by anoptimization problem over the model parameters. To tackle this challenge, weintroduce a new technique to characterize the discontinuities and oscillationsof the utility function on any fixed problem instance as we vary thehyperparameter; our analysis relies on subtle concepts including tools fromdifferential/algebraic geometry and constrained optimization. This can be usedto show that the learning theoretic complexity of the corresponding family ofutility functions is bounded. We instantiate our results and provide samplecomplexity bounds for concrete applications tuning a hyperparameter thatinterpolates neural activation functions and setting the kernel parameter ingraph neural networks.</description><author>Maria-Florina Balcan, Anh Tuan Nguyen, Dravyansh Sharma</author><pubDate>Wed, 12 Feb 2025 18:32:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13734v3</guid></item><item><title>Concentration Inequalities for the Stochastic Optimization of Unbounded Objectives with Application to Denoising Score Matching</title><link>http://arxiv.org/abs/2502.08628v1</link><description>We derive novel concentration inequalities that bound the statistical errorfor a large class of stochastic optimization problems, focusing on the case ofunbounded objective functions. Our derivations utilize the following tools: 1)A new form of McDiarmid's inequality that is based on sample dependent onecomponent difference bounds and which leads to a novel uniform law of largenumbers result for unbounded functions. 2) A Rademacher complexity bound forfamilies of functions that satisfy an appropriate local Lipschitz property. Asan application of these results, we derive statistical error bounds fordenoising score matching (DSM), an application that inherently requires one toconsider unbounded objective functions, even when the data distribution hasbounded support. In addition, our results establish the benefit of sample reusein algorithms that employ easily sampled auxiliary random variables in additionto the training data, e.g., as in DSM, which uses auxiliary Gaussian randomvariables.</description><author>Jeremiah Birrell</author><pubDate>Wed, 12 Feb 2025 18:30:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08628v1</guid></item><item><title>Matcha: Mitigating Graph Structure Shifts with Test-Time Adaptation</title><link>http://arxiv.org/abs/2410.06976v2</link><description>Powerful as they are, graph neural networks (GNNs) are known to be vulnerableto distribution shifts. Recently, test-time adaptation (TTA) has attractedattention due to its ability to adapt a pre-trained model to a target domain,without re-accessing the source domain. However, existing TTA algorithms areprimarily designed for attribute shifts in vision tasks, where samples areindependent. These methods perform poorly on graph data that experiencestructure shifts, where node connectivity differs between source and targetgraphs. We attribute this performance gap to the distinct impact of nodeattribute shifts versus graph structure shifts: the latter significantlydegrades the quality of node representations and blurs the boundaries betweendifferent node categories. To address structure shifts in graphs, we proposeMatcha, an innovative framework designed for effective and efficient adaptationto structure shifts by adjusting the htop-aggregation parameters in GNNs. Toenhance the representation quality, we design a prediction-informed clusteringloss to encourage the formation of distinct clusters for different nodecategories. Additionally, Matcha seamlessly integrates with existing TTAalgorithms, allowing it to handle attribute shifts effectively while improvingoverall performance under combined structure and attribute shifts. We validatethe effectiveness of Matcha on both synthetic and real-world datasets,demonstrating its robustness across various combinations of structure andattribute shifts. Our code is available at https://github.com/baowenxuan/Matcha .</description><author>Wenxuan Bao, Zhichen Zeng, Zhining Liu, Hanghang Tong, Jingrui He</author><pubDate>Wed, 12 Feb 2025 18:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06976v2</guid></item><item><title>Randomness of Low-Layer Parameters Determines Confusing Samples in Terms of Interaction Representations of a DNN</title><link>http://arxiv.org/abs/2502.08625v1</link><description>In this paper, we find that the complexity of interactions encoded by a deepneural network (DNN) can explain its generalization power. We also discoverthat the confusing samples of a DNN, which are represented by non-generalizableinteractions, are determined by its low-layer parameters. In comparison, otherfactors, such as high-layer parameters and network architecture, have much lessimpact on the composition of confusing samples. Two DNNs with differentlow-layer parameters usually have fully different sets of confusing samples,even though they have similar performance. This finding extends theunderstanding of the lottery ticket hypothesis, and well explains distinctiverepresentation power of different DNNs.</description><author>Junpeng Zhang, Lei Cheng, Qing Li, Liang Lin, Quanshi Zhang</author><pubDate>Wed, 12 Feb 2025 18:25:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08625v1</guid></item><item><title>Uncovering Intermediate Variables in Transformers using Circuit Probing</title><link>http://arxiv.org/abs/2311.04354v3</link><description>Neural network models have achieved high performance on a wide variety ofcomplex tasks, but the algorithms that they implement are notoriously difficultto interpret. It is often necessary to hypothesize intermediate variablesinvolved in a network's computation in order to understand these algorithms.For example, does a language model depend on particular syntactic propertieswhen generating a sentence? Yet, existing analysis tools make it difficult totest hypotheses of this type. We propose a new analysis technique - circuitprobing - that automatically uncovers low-level circuits that computehypothesized intermediate variables. This enables causal analysis throughtargeted ablation at the level of model parameters. We apply this method tomodels trained on simple arithmetic tasks, demonstrating its effectiveness at(1) deciphering the algorithms that models have learned, (2) revealing modularstructure within a model, and (3) tracking the development of circuits overtraining. Across these three experiments we demonstrate that circuit probingcombines and extends the capabilities of existing methods, providing oneunified approach for a variety of analyses. Finally, we demonstrate circuitprobing on a real-world use case: uncovering circuits that are responsible forsubject-verb agreement and reflexive anaphora in GPT2-Small and Medium.</description><author>Michael A. Lepori, Thomas Serre, Ellie Pavlick</author><pubDate>Wed, 12 Feb 2025 18:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04354v3</guid></item><item><title>Tensor-Var: Variational Data Assimilation in Tensor Product Feature Space</title><link>http://arxiv.org/abs/2501.13312v2</link><description>Variational data assimilation estimates the dynamical system states byminimizing a cost function that fits the numerical models with observationaldata. The widely used method, four-dimensional variational assimilation(4D-Var), has two primary challenges: (1) computationally demanding for complexnonlinear systems and (2) relying on state-observation mappings, which areoften not perfectly known. Deep learning (DL) has been used as a moreexpressive class of efficient model approximators to address these challenges.However, integrating such models into 4D-Var remains challenging due to theirinherent nonlinearities and the lack of theoretical guarantees for consistencyin assimilation results. In this paper, we propose Tensor-Var to address thesechallenges using kernel Conditional Mean Embedding (CME). Tensor-Var improvesoptimization efficiency by characterizing system dynamics and state-observationmappings as linear operators, leading to a convex cost function in the featurespace. Furthermore, our method provides a new perspective to incorporate CMEinto 4D-Var, offering theoretical guarantees of consistent assimilation resultsbetween the original and feature spaces. To improve scalability, we propose amethod to learn deep features (DFs) using neural networks within the Tensor-Varframework. Experiments on chaotic systems and global weather prediction withreal-time observations show that Tensor-Var outperforms conventional and DLhybrid 4D-Var baselines in accuracy while achieving efficiency comparable tothe static 3D-Var method.</description><author>Yiming Yang, Xiaoyuan Cheng, Daniel Giles, Sibo Cheng, Yi He, Xiao Xue, Boli Chen, Yukun Hu</author><pubDate>Wed, 12 Feb 2025 18:22:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13312v2</guid></item><item><title>Forecasting Drought Using Machine Learning in California</title><link>http://arxiv.org/abs/2502.08622v1</link><description>Drought is a frequent and costly natural disaster in California, with majornegative impacts on agricultural production and water resource availability,particularly groundwater. This study investigated the performance of applyingdifferent machine learning approaches to predicting the U.S. Drought Monitorclassification in California. Four approaches were used: a convolutional neuralnetwork (CNN), random forest, XGBoost, and long short term memory (LSTM)recurrent neural network, and compared to a baseline persistence model. Weevaluated the models' performance in predicting severe drought (USDM droughtcategory D2 or higher) using a macro F1 binary classification metric. The LSTMmodel emerged as the top performer, followed by XGBoost, CNN, and randomforest. Further evaluation of our results at the county level suggested thatthe LSTM model would perform best in counties with more consistent droughtpatterns and where severe drought was more common, and the LSTM model wouldperform worse where drought scores increased rapidly. Utilizing 30 weeks ofhistorical data, the LSTM model successfully forecasted drought scores for a12-week period with a Mean Absolute Error (MAE) of 0.33, equivalent to lessthan half a drought category on a scale of 0 to 5. Additionally, the LSTMachieved a macro F1 score of 0.9, indicating high accuracy in binaryclassification for severe drought conditions. Evaluation of different windowand future horizon sizes in weeks suggested that at least 24 weeks of datawould result in the best performance, with best performance for shorter horizonsizes, particularly less than eight weeks.</description><author>Nan K. Li, Angela Chang, David Sherman</author><pubDate>Wed, 12 Feb 2025 18:20:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08622v1</guid></item><item><title>Mathematical Data Science</title><link>http://arxiv.org/abs/2502.08620v1</link><description>Can machine learning help discover new mathematical structures? In thisarticle we discuss an approach to doing this which one can call "mathematicaldata science". In this paradigm, one studies mathematical objects collectivelyrather than individually, by creating datasets and doing machine learningexperiments and interpretations. After an overview, we present two casestudies: murmurations in number theory and loadings of partitions related toKronecker coefficients in representation theory and combinatorics.</description><author>Michael R. Douglas, Kyu-Hwan Lee</author><pubDate>Wed, 12 Feb 2025 18:15:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08620v1</guid></item><item><title>Deep Spatiotemporal Clutter Filtering of Transthoracic Echocardiographic Images: Leveraging Contextual Attention and Residual Learning</title><link>http://arxiv.org/abs/2401.13147v2</link><description>This study presents a deep convolutional autoencoder network for filteringreverberation clutter from transthoracic echocardiographic (TTE) imagesequences. Given the spatiotemporal nature of this type of clutter, thefiltering network employs 3D convolutional layers to suppress it throughout thecardiac cycle. The design of the network incorporates two key features thatcontribute to the effectiveness of the filter: 1) an attention mechanism forfocusing on cluttered regions and leveraging contextual information, and 2)residual learning for preserving fine image structures. To train the network, adiverse set of artifact patterns was simulated and superimposed ontoultra-realistic synthetic TTE sequences from six ultrasound vendors, generatinginput for the filtering network. The artifact-free sequences served asground-truth. Performance of the filtering network was evaluated using unseensynthetic and in vivo artifactual sequences. Results from the in vivo datasetconfirmed the network's strong generalization capabilities, despite beingtrained solely on synthetic data and simulated artifacts. The suitability ofthe filtered sequences for downstream processing was assessed by computingsegmental strain curves. A significant reduction in the discrepancy betweenstrain profiles computed from cluttered and clutter-free segments was observedafter filtering the cluttered sequences with the proposed network. The trainednetwork processes a TTE sequence in a fraction of a second, enabling real-timeclutter filtering and potentially improving the precision of clinicallyrelevant indices derived from TTE sequences. The source code of the proposedmethod and example video files of the filtering results are available at:\href{https://github.com/MahdiTabassian/Deep-Clutter-Filtering/tree/main}{https://github.com/MahdiTabassian/Deep-Clutter-Filtering/tree/main}.</description><author>Mahdi Tabassian, Somayeh Akbari, Sandro Queirós, Jan D'hooge</author><pubDate>Wed, 12 Feb 2025 18:15:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13147v2</guid></item><item><title>Wrapped Gaussian on the manifold of Symmetric Positive Definite Matrices</title><link>http://arxiv.org/abs/2502.01512v2</link><description>Circular and non-flat data distributions are prevalent across diverse domainsof data science, yet their specific geometric structures often remainunderutilized in machine learning frameworks. A principled approach toaccounting for the underlying geometry of such data is pivotal, particularlywhen extending statistical models, like the pervasive Gaussian distribution. Inthis work, we tackle those issue by focusing on the manifold of symmetricpositive definite matrices, a key focus in information geometry. We introduceda non-isotropic wrapped Gaussian by leveraging the exponential map, we derivetheoretical properties of this distribution and propose a maximum likelihoodframework for parameter estimation. Furthermore, we reinterpret establishedclassifiers on SPD through a probabilistic lens and introduce new classifiersbased on the wrapped Gaussian model. Experiments on synthetic and real-worlddatasets demonstrate the robustness and flexibility of this geometry-awaredistribution, underscoring its potential to advance manifold-based dataanalysis. This work lays the groundwork for extending classical machinelearning and statistical methods to more complex and structured data.</description><author>Thibault de Surrel, Fabien Lotte, Sylvain Chevallier, Florian Yger</author><pubDate>Wed, 12 Feb 2025 18:11:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01512v2</guid></item><item><title>Continuous Cardiac Arrest Prediction in ICU using PPG Foundation Model</title><link>http://arxiv.org/abs/2502.08612v1</link><description>Non-invasive patient monitoring for tracking and predicting adverse acutehealth events is an emerging area of research. We pursue in-hospital cardiacarrest (IHCA) prediction using only single-channel finger photoplethysmography(PPG) signals. Our proposed two-stage model Feature Extractor-AggregatorNetwork (FEAN) leverages powerful representations from pre-trained PPGfoundation models (PPG-GPT of size up to 1 Billion) stacked with sequentialclassification models. We propose two FEAN variants ("1H", "FH") which use thelatest one-hour and (max) 24-hour history to make decisions respectively. Ourstudy is the first to present IHCA prediction results in ICU patients usingonly unimodal (continuous PPG signal) waveform deep representations. With ourbest model, we obtain an average of 0.79 AUROC over 24~h prediction windowbefore CA event onset with our model peaking performance at 0.82 one hourbefore CA. We also provide a comprehensive analysis of our model througharchitectural tuning and PaCMAP visualization of patient health trajectory inlatent space.</description><author>Saurabh Kataria, Ran Xiao, Timothy Ruchti, Matthew Clark, Jiaying Lu, Randall J. Lee, Jocelyn Grunwell, Xiao Hu</author><pubDate>Wed, 12 Feb 2025 18:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08612v1</guid></item><item><title>Robustly Learning Monotone Generalized Linear Models via Data Augmentation</title><link>http://arxiv.org/abs/2502.08611v1</link><description>We study the task of learning Generalized Linear models (GLMs) in theagnostic model under the Gaussian distribution. We give the firstpolynomial-time algorithm that achieves a constant-factor approximation for\textit{any} monotone Lipschitz activation. Prior constant-factor GLM learnerssucceed for a substantially smaller class of activations. Our work resolves awell-known open problem, by developing a robust counterpart to the classicalGLMtron algorithm (Kakade et al., 2011). Our robust learner applies moregenerally, encompassing all monotone activations with bounded$(2+\zeta)$-moments, for any fixed $\zeta&gt;0$ -- a condition that is essentiallynecessary. To obtain our results, we leverage a novel data augmentationtechnique with decreasing Gaussian noise injection and prove a number ofstructural results that may be useful in other settings.</description><author>Nikos Zarifis, Puqian Wang, Ilias Diakonikolas, Jelena Diakonikolas</author><pubDate>Wed, 12 Feb 2025 17:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08611v1</guid></item><item><title>Evaluating the Performance of ChatGPT for Spam Email Detection</title><link>http://arxiv.org/abs/2402.15537v3</link><description>Email continues to be a pivotal and extensively utilized communication mediumwithin professional and commercial domains. Nonetheless, the prevalence of spamemails poses a significant challenge for users, disrupting their daily routinesand diminishing productivity. Consequently, accurately identifying andfiltering spam based on content has become crucial for cybersecurity. Recentadvancements in natural language processing, particularly with large languagemodels like ChatGPT, have shown remarkable performance in tasks such asquestion answering and text generation. However, its potential in spamidentification remains underexplored. To fill in the gap, this study attemptsto evaluate ChatGPT's capabilities for spam identification in both English andChinese email datasets. We employ ChatGPT for spam email detection usingin-context learning, which requires a prompt instruction with (or without) afew demonstrations. We also investigate how the number of demonstrations in theprompt affects the performance of ChatGPT. For comparison, we also implementfive popular benchmark methods, including naive Bayes, support vector machines(SVM), logistic regression (LR), feedforward dense neural networks (DNN), andBERT classifiers. Through extensive experiments, the performance of ChatGPT issignificantly worse than deep supervised learning methods in the large Englishdataset, while it presents superior performance on the low-resourced Chinesedataset. This study provides insights into the potential and limitations ofChatGPT for spam identification, highlighting its potential as a viablesolution for resource-constrained language domains.</description><author>Shijing Si, Yuwei Wu, Le Tang, Yugui Zhang, Jedrek Wosik, Qinliang Su</author><pubDate>Wed, 12 Feb 2025 17:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15537v3</guid></item><item><title>Quantifying Security Vulnerabilities: A Metric-Driven Security Analysis of Gaps in Current AI Standards</title><link>http://arxiv.org/abs/2502.08610v1</link><description>As AI systems integrate into critical infrastructure, security gaps in AIcompliance frameworks demand urgent attention. This paper audits and quantifiessecurity risks in three major AI governance standards: NIST AI RMF 1.0, UK's AIand Data Protection Risk Toolkit, and the EU's ALTAI. Using a novel riskassessment methodology, we develop four key metrics: Risk Severity Index (RSI),Attack Potential Index (AVPI), Compliance-Security Gap Percentage (CSGP), andRoot Cause Vulnerability Score (RCVS). Our analysis identifies 136 concernsacross the frameworks, exposing significant gaps. NIST fails to address 69.23percent of identified risks, ALTAI has the highest attack vector vulnerability(AVPI = 0.51) and the ICO Toolkit has the largest compliance-security gap, with80.00 percent of high-risk concerns remaining unresolved. Root cause analysishighlights under-defined processes (ALTAI RCVS = 033) and weak implementationguidance (NIST and ICO RCVS = 0.25) as critical weaknesses. These findingsemphasize the need for stronger, enforceable security controls in AIcompliance. We offer targeted recommendations to enhance security posture andbridge the gap between compliance and real-world AI risks.</description><author>Keerthana Madhavan, Abbas Yazdinejad, Fattane Zarrinkalam, Ali Dehghantanha</author><pubDate>Wed, 12 Feb 2025 17:57:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08610v1</guid></item><item><title>Interactive incremental learning of generalizable skills with local trajectory modulation</title><link>http://arxiv.org/abs/2409.05655v2</link><description>The problem of generalization in learning from demonstration (LfD) hasreceived considerable attention over the years, particularly within the contextof movement primitives, where a number of approaches have emerged. Recently,two important approaches have gained recognition. While one leveragesvia-points to adapt skills locally by modulating demonstrated trajectories,another relies on so-called task-parameterized models that encode movementswith respect to different coordinate systems, using a product of probabilitiesfor generalization. While the former are well-suited to precise, localmodulations, the latter aim at generalizing over large regions of the workspaceand often involve multiple objects. Addressing the quality of generalization byleveraging both approaches simultaneously has received little attention. Inthis work, we propose an interactive imitation learning framework thatsimultaneously leverages local and global modulations of trajectorydistributions. Building on the kernelized movement primitives (KMP) framework,we introduce novel mechanisms for skill modulation from direct human correctivefeedback. Our approach particularly exploits the concept of via-points toincrementally and interactively 1) improve the model accuracy locally, 2) addnew objects to the task during execution and 3) extend the skill into regionswhere demonstrations were not provided. We evaluate our method on a bearingring-loading task using a torque-controlled, 7-DoF, DLR SARA robot.</description><author>Markus Knauer, Alin Albu-Schäffer, Freek Stulp, João Silvério</author><pubDate>Wed, 12 Feb 2025 17:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05655v2</guid></item><item><title>Distillation Scaling Laws</title><link>http://arxiv.org/abs/2502.08606v1</link><description>We provide a distillation scaling law that estimates distilled modelperformance based on a compute budget and its allocation between the studentand teacher. Our findings reduce the risks associated with using distillationat scale; compute allocation for both the teacher and student models can now bedone to maximize student performance. We provide compute optimal distillationrecipes for when 1) a teacher exists, or 2) a teacher needs training. If manystudents are to be distilled, or a teacher already exists, distillationoutperforms supervised pretraining until a compute level which growspredictably with student size. If one student is to be distilled and a teacheralso needs training, supervised learning should be done instead. Additionally,we provide insights across our large scale study of distillation, whichincrease our understanding of distillation and inform experimental design.</description><author>Dan Busbridge, Amitis Shidani, Floris Weers, Jason Ramapuram, Etai Littwin, Russ Webb</author><pubDate>Wed, 12 Feb 2025 17:52:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08606v1</guid></item><item><title>Lightweight Neural App Control</title><link>http://arxiv.org/abs/2410.17883v2</link><description>This paper introduces a novel mobile phone control architecture, LightweightMulti-modal App Control (LiMAC), for efficient interactions and control acrossvarious Android apps. LiMAC takes as input a textual goal and a sequence ofpast mobile observations, such as screenshots and corresponding UI trees, togenerate precise actions. To address the computational constraints inherent tosmartphones, we introduce a small Action Transformer (AcT) integrated with afine-tuned vision-language model (VLM) for real-time decision-making and taskexecution. We evaluate LiMAC on two open-source mobile control datasets,demonstrating the superior performance of our small-form-factor approachagainst fine-tuned versions of open-source VLMs, such as Florence2 andQwen2-VL. It also significantly outperforms prompt engineering baselinesutilising closed-source foundation models like GPT-4o. More specifically, LiMACincreases the overall action accuracy by up to 19% compared to fine-tuned VLMs,and up to 42% compared to prompt-engineering baselines.</description><author>Filippos Christianos, Georgios Papoudakis, Thomas Coste, Jianye Hao, Jun Wang, Kun Shao</author><pubDate>Wed, 12 Feb 2025 17:51:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17883v2</guid></item><item><title>CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection</title><link>http://arxiv.org/abs/2502.08605v1</link><description>Does the intrinsic curvature of complex networks hold the key to unveilinggraph anomalies that conventional approaches overlook? Reconstruction-basedgraph anomaly detection (GAD) methods overlook such geometric outliers,focusing only on structural and attribute-level anomalies. To this end, wepropose CurvGAD - a mixed-curvature graph autoencoder that introduces thenotion of curvature-based geometric anomalies. CurvGAD introduces two parallelpipelines for enhanced anomaly interpretability: (1) Curvature-equivariantgeometry reconstruction, which focuses exclusively on reconstructing the edgecurvatures using a mixed-curvature, Riemannian encoder and Gaussiankernel-based decoder; and (2) Curvature-invariant structure and attributereconstruction, which decouples structural and attribute anomalies fromgeometric irregularities by regularizing graph curvature under discreteOllivier-Ricci flow, thereby isolating the non-geometric anomalies. Byleveraging curvature, CurvGAD refines the existing anomaly classifications andidentifies new curvature-driven anomalies. Extensive experimentation over 10real-world datasets (both homophilic and heterophilic) demonstrates animprovement of up to 6.5% over state-of-the-art GAD methods.</description><author>Karish Grover, Geoffrey J. Gordon, Christos Faloutsos</author><pubDate>Wed, 12 Feb 2025 17:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08605v1</guid></item><item><title>Scalable Thermodynamic Second-order Optimization</title><link>http://arxiv.org/abs/2502.08603v1</link><description>Many hardware proposals have aimed to accelerate inference in AI workloads.Less attention has been paid to hardware acceleration of training, despite theenormous societal impact of rapid training of AI models. Physics-basedcomputers, such as thermodynamic computers, offer an efficient means to solvekey primitives in AI training algorithms. Optimizers that normally would becomputationally out-of-reach (e.g., due to expensive matrix inversions) ondigital hardware could be unlocked with physics-based hardware. In this work,we propose a scalable algorithm for employing thermodynamic computers toaccelerate a popular second-order optimizer called Kronecker-factoredapproximate curvature (K-FAC). Our asymptotic complexity analysis predictsincreasing advantage with our algorithm as $n$, the number of neurons perlayer, increases. Numerical experiments show that even under significantquantization noise, the benefits of second-order optimization can be preserved.Finally, we predict substantial speedups for large-scale vision and graphproblems based on realistic hardware characteristics.</description><author>Kaelan Donatella, Samuel Duffield, Denis Melanson, Maxwell Aifer, Phoebe Klett, Rajath Salegame, Zach Belateche, Gavin Crooks, Antonio J. Martinez, Patrick J. Coles</author><pubDate>Wed, 12 Feb 2025 17:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08603v1</guid></item><item><title>Sketched Equivariant Imaging Regularization and Deep Internal Learning for Inverse Problems</title><link>http://arxiv.org/abs/2411.05771v3</link><description>Equivariant Imaging (EI) regularization has become the de-facto technique forunsupervised training of deep imaging networks, without any need ofground-truth data. Observing that the EI-based unsupervised training paradigmcurrently has significant computational redundancy leading to inefficiency inhigh-dimensional applications, we propose a sketched EI regularization whichleverages the randomized sketching techniques for acceleration. We then extendour sketched EI regularization to develop an accelerated deep internal learningframework, Sketched Equivariant Deep Image Prior (Sk-EI-DIP), which can beefficiently applied for single-image and task-adapted reconstruction.Additionally, for network adaptation tasks, we propose a parameter-efficientapproach for accelerating both EI-DIP and Sk-EI-DIP via optimizing only thenormalization layers. Our numerical study on X-ray CT and multi-coil MRI imagereconstruction tasks demonstrate that our approach can achieve significantcomputational acceleration over standard EI-based counterpart in single-inputsetting and network adaptation at test time.</description><author>Guixian Xu, Jinglai Li, Junqi Tang</author><pubDate>Wed, 12 Feb 2025 17:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.05771v3</guid></item><item><title>chebgreen: Learning and Interpolating Continuous Empirical Green's Functions from Data</title><link>http://arxiv.org/abs/2501.18715v2</link><description>In this work, we present a mesh-independent, data-driven library, chebgreen,to mathematically model one-dimensional systems, possessing an associatedcontrol parameter, and whose governing partial differential equation isunknown. The proposed method learns an Empirical Green's Function for theassociated, but hidden, boundary value problem, in the form of a RationalNeural Network from which we subsequently construct a bivariate representationin a Chebyshev basis. We uncover the Green's function, at an unseen controlparameter value, by interpolating the left and right singular functions withina suitable library, expressed as points on a manifold of Quasimatrices, whilethe associated singular values are interpolated with Lagrange polynomials.</description><author>Harshwardhan Praveen, Jacob Brown, Christopher Earls</author><pubDate>Wed, 12 Feb 2025 17:41:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18715v2</guid></item><item><title>An Explainable Pipeline for Machine Learning with Functional Data</title><link>http://arxiv.org/abs/2501.07602v2</link><description>Machine learning (ML) models have shown success in applications with anobjective of prediction, but the algorithmic complexity of some models makesthem difficult to interpret. Methods have been proposed to provide insight intothese "black-box" models, but there is little research that focuses onsupervised ML when the model inputs are functional data. In this work, weconsider two applications from high-consequence spaces with objectives ofmaking predictions using functional data inputs. One application aims toclassify material types to identify explosive materials given hyperspectralcomputed tomography scans of the materials. The other application considers theforensics science task of connecting an inkjet printed document to the sourceprinter using color signatures extracted by Raman spectroscopy. An instinctiveroute to consider for analyzing these data is a data driven ML model forclassification, but due to the high consequence nature of the applications, weargue it is important to appropriately account for the nature of the data inthe analysis to not obscure or misrepresent patterns. As such, we propose theVariable importance Explainable Elastic Shape Analysis (VEESA) pipeline fortraining ML models with functional data that (1) accounts for the vertical andhorizontal variability in the functional data and (2) provides an explanationin the original data space of how the model uses variability in the functionaldata for prediction. The pipeline makes use of elastic functional principalcomponents analysis (efPCA) to generate uncorrelated model inputs andpermutation feature importance (PFI) to identify the principal componentsimportant for prediction. The variability captured by the important principalcomponents in visualized the original data space. We ultimately discuss ideasfor natural extensions of the VEESA pipeline and challenges for futureresearch.</description><author>Katherine Goode, J. Derek Tucker, Daniel Ries, Heike Hofmann</author><pubDate>Wed, 12 Feb 2025 17:41:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.07602v2</guid></item><item><title>Two-stage hybrid models for enhancing forecasting accuracy on heterogeneous time series</title><link>http://arxiv.org/abs/2502.08600v1</link><description>Compared to local models built in a series-by-series manner, global modelsleverage relevant information across time series, resulting in improvedforecasting performance and generalization capacity. Constructing global modelson a set of time series is becoming mainstream in the field of time seriesforecasting. However, the advantages of global models may not always berealized when dealing with heterogeneous data. While they can adapt toheterogeneous datasets by increasing the model complexity, the model cannot beinfinitely complex due to the finite sample size, which poses challenges forthe application of global models. Additionally, determining whether the timeseries data is homogeneous or heterogeneous can be ambiguous in practice. Toaddress these research gaps, this paper argues that the heterogeneity of thedata should be defined by the global model used, and for each series, theportion not modelled by the global model represents heterogeneity. It furtherproposes two-stage hybrid models, which include a second stage to identify andmodel heterogeneous patterns. In this second stage, we can estimate either alllocal models or sub-global models across different domains divided based onheterogeneity. Experiments on four open datasets reveal that the proposedmethods significantly outperform five existing models, indicating theycontribute to fully unleash the potential of global models on heterogeneousdatasets.</description><author>Junru Ren, Shaomin Wu</author><pubDate>Wed, 12 Feb 2025 17:39:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08600v1</guid></item><item><title>SPeCtrum: A Grounded Framework for Multidimensional Identity Representation in LLM-Based Agent</title><link>http://arxiv.org/abs/2502.08599v1</link><description>Existing methods for simulating individual identities often oversimplifyhuman complexity, which may lead to incomplete or flattened representations. Toaddress this, we introduce SPeCtrum, a grounded framework for constructingauthentic LLM agent personas by incorporating an individual's multidimensionalself-concept. SPeCtrum integrates three core components: Social Identity (S),Personal Identity (P), and Personal Life Context (C), each contributingdistinct yet interconnected aspects of identity. To evaluate SPeCtrum'seffectiveness in identity representation, we conducted automated and humanevaluations. Automated evaluations using popular drama characters showed thatPersonal Life Context (C)-derived from short essays on preferences and dailyroutines-modeled characters' identities more effectively than Social Identity(S) and Personal Identity (P) alone and performed comparably to the full SPCcombination. In contrast, human evaluations involving real-world individualsfound that the full SPC combination provided a more comprehensive self-conceptrepresentation than C alone. Our findings suggest that while C alone maysuffice for basic identity simulation, integrating S, P, and C enhances theauthenticity and accuracy of real-world identity representation. Overall,SPeCtrum offers a structured approach for simulating individuals in LLM agents,enabling more personalized human-AI interactions and improving the realism ofsimulation-based behavioral studies.</description><author>Keyeun Lee, Seo Hyeong Kim, Seolhee Lee, Jinsu Eun, Yena Ko, Hayeon Jeon, Esther Hehsun Kim, Seonghye Cho, Soeun Yang, Eun-mee Kim, Hajin Lim</author><pubDate>Wed, 12 Feb 2025 17:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08599v1</guid></item><item><title>Enhancing Diffusion Models Efficiency by Disentangling Total-Variance and Signal-to-Noise Ratio</title><link>http://arxiv.org/abs/2502.08598v1</link><description>The long sampling time of diffusion models remains a significant bottleneck,which can be mitigated by reducing the number of diffusion time steps. However,the quality of samples with fewer steps is highly dependent on the noiseschedule, i.e., the specific manner in which noise is introduced and the signalis reduced at each step. Although prior work has improved upon the originalvariance-preserving and variance-exploding schedules, these approaches$\textit{passively}$ adjust the total variance, without direct control over it.In this work, we propose a novel total-variance/signal-to-noise-ratiodisentangled (TV/SNR) framework, where TV and SNR can be controlledindependently. Our approach reveals that different existing schedules, wherethe TV explodes exponentially, can be $\textit{improved}$ by setting a constantTV schedule while preserving the same SNR schedule. Furthermore, generalizingthe SNR schedule of the optimal transport flow matching significantly improvesthe performance in molecular structure generation, achieving few stepgeneration of stable molecules. A similar tendency is observed in imagegeneration, where our approach with a uniform diffusion time grid performscomparably to the highly tailored EDM sampler.</description><author>Khaled Kahouli, Winfried Ripken, Stefan Gugler, Oliver T. Unke, Klaus-Robert Müller, Shinichi Nakajima</author><pubDate>Wed, 12 Feb 2025 17:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08598v1</guid></item><item><title>Learning in Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners</title><link>http://arxiv.org/abs/2502.08597v1</link><description>We analyze the performance of heterogeneous learning agents in asset marketswith stochastic payoffs. Our agents aim to maximize the expected growth rate oftheir wealth but have different theories on how to learn this best. We focus oncomparing Bayesian and no-regret learners in market dynamics. Bayesian learnerswith a prior over a finite set of models that assign positive prior probabilityto the correct model have posterior probabilities that converge exponentiallyto the correct model. Consequently, they survive even in the presence of agentswho invest according to the correct model of the stochastic process. Bayesianswith a continuum prior converge to the correct model at a rate of $O((\logT)/T)$. Online learning theory provides no-regret algorithms for maximizing thelog of wealth in this setting, achieving a worst-case regret bound of $O(\logT)$ without assuming a steady underlying stochastic process but comparing tothe best fixed investment rule. This regret, as we observe, is of the sameorder of magnitude as that of a Bayesian learner with a continuum prior.However, we show that even such low regret may not be sufficient for survivalin asset markets: an agent can have regret as low as $O(\log T)$, but stillvanish in market dynamics when competing against agents who invest according tothe correct model or even against a perfect Bayesian with a finite prior. Onthe other hand, we show that Bayesian learning is fragile, while no-regretlearning requires less knowledge of the environment and is therefore morerobust. Any no-regret learner will drive out of the market an imperfectBayesian whose finite prior or update rule has even small errors. We formallyestablish the relationship between notions of survival, vanishing, and marketdomination studied in economics and the framework of regret minimization, thusbridging these theories.</description><author>David Easley, Yoav Kolumbus, Eva Tardos</author><pubDate>Wed, 12 Feb 2025 17:34:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08597v1</guid></item><item><title>Toward Universal Laws of Outlier Propagation</title><link>http://arxiv.org/abs/2502.08593v1</link><description>We argue that Algorithmic Information Theory (AIT) admits a principled way toquantify outliers in terms of so-called randomness deficiency. For theprobability distribution generated by a causal Bayesian network, we show thatthe randomness deficiency of the joint state decomposes into randomnessdeficiencies of each causal mechanism, subject to the Independence ofMechanisms Principle. Accordingly, anomalous joint observations can bequantitatively attributed to their root causes, i.e., the mechanisms thatbehaved anomalously. As an extension of Levin's law of randomness conservation,we show that weak outliers cannot cause strong ones when Independence ofMechanisms holds. We show how these information theoretic laws provide a betterunderstanding of the behaviour of outliers defined with respect to existingscores.</description><author>Yuhao Wang, Aram Ebtekar, Dominik Janzing</author><pubDate>Wed, 12 Feb 2025 17:32:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08593v1</guid></item><item><title>Oscillatory State-Space Models</title><link>http://arxiv.org/abs/2410.03943v2</link><description>We propose Linear Oscillatory State-Space models (LinOSS) for efficientlylearning on long sequences. Inspired by cortical dynamics of biological neuralnetworks, we base our proposed LinOSS model on a system of forced harmonicoscillators. A stable discretization, integrated over time using fastassociative parallel scans, yields the proposed state-space model. We provethat LinOSS produces stable dynamics only requiring nonnegative diagonal statematrix. This is in stark contrast to many previous state-space models relyingheavily on restrictive parameterizations. Moreover, we rigorously show thatLinOSS is universal, i.e., it can approximate any continuous and causaloperator mapping between time-varying functions, to desired accuracy. Inaddition, we show that an implicit-explicit discretization of LinOSS perfectlyconserves the symmetry of time reversibility of the underlying dynamics.Together, these properties enable efficient modeling of long-rangeinteractions, while ensuring stable and accurate long-horizon forecasting.Finally, our empirical results, spanning a wide range of time-series tasks frommid-range to very long-range classification and regression, as well aslong-horizon forecasting, demonstrate that our proposed LinOSS modelconsistently outperforms state-of-the-art sequence models. Notably, LinOSSoutperforms Mamba by nearly 2x and LRU by 2.5x on a sequence modeling task withsequences of length 50k.</description><author>T. Konstantin Rusch, Daniela Rus</author><pubDate>Wed, 12 Feb 2025 17:29:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03943v2</guid></item><item><title>Topological Blindspots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity</title><link>http://arxiv.org/abs/2408.05486v2</link><description>Topological deep learning (TDL) is a rapidly growing field that seeks toleverage topological structure in data and facilitate learning from datasupported on topological objects, ranging from molecules to 3D shapes. Most TDLarchitectures can be unified under the framework of higher-ordermessage-passing (HOMP), which generalizes graph message-passing to higher-orderdomains. In the first part of the paper, we explore HOMP's expressive powerfrom a topological perspective, demonstrating the framework's inability tocapture fundamental topological and metric invariants such as diameter,orientability, planarity, and homology. In addition, we demonstrate HOMP'slimitations in fully leveraging lifting and pooling methods on graphs. To thebest of our knowledge, this is the first work to study the expressivity of TDLfrom a \emph{topological} perspective. In the second part of the paper, wedevelop two new classes of architectures -- multi-cellular networks (MCN) andscalable MCN (SMCN) -- which draw inspiration from expressive GNNs. MCN canreach full expressivity, but scaling it to large data objects can becomputationally expansive. Designed as a more scalable alternative, SMCN stillmitigates many of HOMP's expressivity limitations. Finally, we create newbenchmarks for evaluating models based on their ability to learn topologicalproperties of complexes. We then evaluate SMCN on these benchmarks and onreal-world graph datasets, demonstrating improvements over both HOMP baselinesand expressive graph methods, highlighting the value of expressively leveragingtopological information. Code and data are available athttps://github.com/yoavgelberg/SMCN.</description><author>Yam Eitan, Yoav Gelberg, Guy Bar-Shalom, Fabrizio Frasca, Michael Bronstein, Haggai Maron</author><pubDate>Wed, 12 Feb 2025 17:29:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05486v2</guid></item><item><title>Light-A-Video: Training-free Video Relighting via Progressive Light Fusion</title><link>http://arxiv.org/abs/2502.08590v1</link><description>Recent advancements in image relighting models, driven by large-scaledatasets and pre-trained diffusion models, have enabled the imposition ofconsistent lighting. However, video relighting still lags, primarily due to theexcessive training costs and the scarcity of diverse, high-quality videorelighting datasets. A simple application of image relighting models on aframe-by-frame basis leads to several issues: lighting source inconsistency andrelighted appearance inconsistency, resulting in flickers in the generatedvideos. In this work, we propose Light-A-Video, a training-free approach toachieve temporally smooth video relighting. Adapted from image relightingmodels, Light-A-Video introduces two key techniques to enhance lightingconsistency. First, we design a Consistent Light Attention (CLA) module, whichenhances cross-frame interactions within the self-attention layers to stabilizethe generation of the background lighting source. Second, leveraging thephysical principle of light transport independence, we apply linear blendingbetween the source video's appearance and the relighted appearance, using aProgressive Light Fusion (PLF) strategy to ensure smooth temporal transitionsin illumination. Experiments show that Light-A-Video improves the temporalconsistency of relighted video while maintaining the image quality, ensuringcoherent lighting transitions across frames. Project page:https://bujiazi.github.io/light-a-video.github.io/.</description><author>Yujie Zhou, Jiazi Bu, Pengyang Ling, Pan Zhang, Tong Wu, Qidong Huang, Jinsong Li, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Anyi Rao, Jiaqi Wang, Li Niu</author><pubDate>Wed, 12 Feb 2025 17:24:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08590v1</guid></item><item><title>ETM: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models</title><link>http://arxiv.org/abs/2407.07313v3</link><description>The task of Text-to-SQL enables anyone to retrieve information from SQLdatabases using natural language. While this task has made substantialprogress, the two primary evaluation metrics -- Execution Accuracy (EXE) andExact Set Matching Accuracy (ESM) -- suffer from inherent limitations that canmisrepresent performance. Specifically, ESM's rigid matching overlookssemantically correct but stylistically different queries, whereas EXE canoverestimate correctness by ignoring structural errors that yield correctoutputs. These shortcomings become especially problematic when assessingoutputs from large language model (LLM)-based approaches without fine-tuning,which vary more in style and structure compared to their fine-tunedcounterparts. Thus, we introduce a new metric, Enhanced Tree Matching (ETM),which mitigates these issues by comparing queries using both syntactic andsemantic elements. Through evaluating nine LLM-based models, we show that EXEand ESM can produce false positive and negative rates as high as 23.0% and28.9%, while ETM reduces these rates to 0.3% and 2.7%, respectively. We releaseour ETM script as open source, offering the community a more robust andreliable approach to evaluating Text-to-SQL.</description><author>Benjamin G. Ascoli, Yasoda Sai Ram Kandikonda, Jinho D. Choi</author><pubDate>Wed, 12 Feb 2025 17:20:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07313v3</guid></item><item><title>Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks</title><link>http://arxiv.org/abs/2502.08586v1</link><description>A high volume of recent ML security literature focuses on attacks againstaligned large language models (LLMs). These attacks may extract privateinformation or coerce the model into producing harmful outputs. In real-worlddeployments, LLMs are often part of a larger agentic pipeline including memorysystems, retrieval, web access, and API calling. Such additional componentsintroduce vulnerabilities that make these LLM-powered agents much easier toattack than isolated LLMs, yet relatively little work focuses on the securityof LLM agents. In this paper, we analyze security and privacy vulnerabilitiesthat are unique to LLM agents. We first provide a taxonomy of attackscategorized by threat actors, objectives, entry points, attacker observability,attack strategies, and inherent vulnerabilities of agent pipelines. We thenconduct a series of illustrative attacks on popular open-source and commercialagents, demonstrating the immediate practical implications of theirvulnerabilities. Notably, our attacks are trivial to implement and require nounderstanding of machine learning.</description><author>Ang Li, Yin Zhou, Vethavikashini Chithrra Raghuram, Tom Goldstein, Micah Goldblum</author><pubDate>Wed, 12 Feb 2025 17:19:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08586v1</guid></item><item><title>Scalable Bilevel Loss Balancing for Multi-Task Learning</title><link>http://arxiv.org/abs/2502.08585v1</link><description>Multi-task learning (MTL) has been widely adopted for its ability tosimultaneously learn multiple tasks. While existing gradient manipulationmethods often yield more balanced solutions than simple scalarization-basedapproaches, they typically incur a significant computational overhead of$\mathcal{O}(K)$ in both time and memory, where $K$ is the number of tasks. Inthis paper, we propose BiLB4MTL, a simple and scalable loss balancing approachfor MTL, formulated from a novel bilevel optimization perspective. Our methodincorporates three key components: (i) an initial loss normalization, (ii) abilevel loss-balancing formulation, and (iii) a scalable first-order algorithmthat requires only $\mathcal{O}(1)$ time and memory. Theoretically, we provethat BiLB4MTL guarantees convergence not only to a stationary point of thebilevel loss balancing problem but also to an $\epsilon$-accurate Paretostationary point for all $K$ loss functions under mild conditions. Extensiveexperiments on diverse multi-task datasets demonstrate that BiLB4MTL achievesstate-of-the-art performance in both accuracy and efficiency. Code is availableat https://github.com/OptMN-Lab/-BiLB4MTL.</description><author>Peiyao Xiao, Chaosheng Dong, Shaofeng Zou, Kaiyi Ji</author><pubDate>Wed, 12 Feb 2025 17:18:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08585v1</guid></item><item><title>A method for classification of data with uncertainty using hypothesis testing</title><link>http://arxiv.org/abs/2502.08582v1</link><description>Binary classification is a task that involves the classification of data intoone of two distinct classes. It is widely utilized in various fields. However,conventional classifiers tend to make overconfident predictions for data thatbelong to overlapping regions of the two class distributions or for dataoutside the distributions (out-of-distribution data). Therefore, conventionalclassifiers should not be applied in high-risk fields where classificationresults can have significant consequences. In order to address this issue, itis necessary to quantify uncertainty and adopt decision-making approaches thattake it into account. Many methods have been proposed for this purpose;however, implementing these methods often requires performing resampling,improving the structure or performance of models, and optimizing the thresholdsof classifiers. We propose a new decision-making approach using two types ofhypothesis testing. This method is capable of detecting ambiguous data thatbelong to the overlapping regions of two class distributions, as well asout-of-distribution data that are not included in the training datadistribution. In addition, we quantify uncertainty using the empiricaldistribution of feature values derived from the training data obtained throughthe trained model. The classification threshold is determined by the$\alpha$-quantile and ($1-\alpha$)-quantile, where the significance level$\alpha$ is set according to each specific situation.</description><author>Shoma Yokura, Akihisa Ichiki</author><pubDate>Wed, 12 Feb 2025 17:14:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08582v1</guid></item><item><title>Ultrasound Image Generation using Latent Diffusion Models</title><link>http://arxiv.org/abs/2502.08580v1</link><description>Diffusion models for image generation have been a subject of increasinginterest due to their ability to generate diverse, high-quality images. Imagegeneration has immense potential in medical imaging because open-source medicalimages are difficult to obtain compared to natural images, especially for rareconditions. The generated images can be used later to train classification andsegmentation models. In this paper, we propose simulating realistic ultrasound(US) images by successive fine-tuning of large diffusion models on differentpublicly available databases. To do so, we fine-tuned Stable Diffusion, astate-of-the-art latent diffusion model, on BUSI (Breast US Images) anultrasound breast image dataset. We successfully generated high-quality USimages of the breast using simple prompts that specify the organ and pathology,which appeared realistic to three experienced US scientists and a USradiologist. Additionally, we provided user control by conditioning the modelwith segmentations through ControlNet. We will release the source code athttp://code.sonography.ai/ to allow fast US image generation to the scientificcommunity.</description><author>Benoit Freiche, Anthony El-Khoury, Ali Nasiri-Sarvi, Mahdi S. Hosseini, Damien Garcia, Adrian Basarab, Mathieu Boily, Hassan Rivaz</author><pubDate>Wed, 12 Feb 2025 17:11:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08580v1</guid></item><item><title>FBFL: A Field-Based Coordination Approach for Data Heterogeneity in Federated Learning</title><link>http://arxiv.org/abs/2502.08577v1</link><description>In the last years, Federated learning (FL) has become a popular solution totrain machine learning models in domains with high privacy concerns. However,FL scalability and performance face significant challenges in real-worlddeployments where data across devices are non-independently and identicallydistributed (non-IID). The heterogeneity in data distribution frequently arisesfrom spatial distribution of devices, leading to degraded model performance inthe absence of proper handling. Additionally, FL typical reliance oncentralized architectures introduces bottlenecks and single-point-of-failurerisks, particularly problematic at scale or in dynamic environments. To closethis gap, we propose Field-Based Federated Learning (FBFL), a novel approachleveraging macroprogramming and field coordination to address these limitationsthrough: (i) distributed spatial-based leader election for personalization tomitigate non-IID data challenges; and (ii) construction of a self-organizing,hierarchical architecture using advanced macroprogramming patterns. Moreover,FBFL not only overcomes the aforementioned limitations, but also enables thedevelopment of more specialized models tailored to the specific datadistribution in each subregion. This paper formalizes FBFL and evaluates itextensively using MNIST, FashionMNIST, and Extended MNIST datasets. Wedemonstrate that, when operating under IID data conditions, FBFL performscomparably to the widely-used FedAvg algorithm. Furthermore, in challengingnon-IID scenarios, FBFL not only outperforms FedAvg but also surpasses otherstate-of-the-art methods, namely FedProx and Scaffold, which have beenspecifically designed to address non-IID data distributions. Additionally, weshowcase the resilience of FBFL's self-organizing hierarchical architectureagainst server failures.</description><author>Davide Domini, Gianluca Aguzzi, Lukas Esterle, Mirko Viroli</author><pubDate>Wed, 12 Feb 2025 17:10:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08577v1</guid></item><item><title>Truthful Aggregation of LLMs with an Application to Online Advertising</title><link>http://arxiv.org/abs/2405.05905v5</link><description>The next frontier of online advertising is revenue generation fromLLM-generated content. We consider a setting where advertisers aim to influencethe responses of an LLM to align with their interests, while platforms seek tomaximize advertiser value and ensure user satisfaction. The challenge is thatadvertisers' preferences generally conflict with those of the user, andadvertisers may misreport their preferences. To address this, we introduceMOSAIC, an auction mechanism that ensures that truthful reporting is a dominantstrategy for advertisers and that aligns the utility of each advertiser withtheir contribution to social welfare. Importantly, the mechanism operateswithout LLM fine-tuning or access to model weights and provably converges tothe output of the optimally fine-tuned LLM as computational resources increase.Additionally, it can incorporate contextual information about advertisers,which significantly improves social welfare. Through experiments with apublicly available LLM, we show that MOSAIC leads to high advertiser value andplatform revenue with low computational overhead. While our motivatingapplication is online advertising, our mechanism can be applied in any settingwith monetary transfers, making it a general-purpose solution for truthfullyaggregating the preferences of self-interested agents over LLM-generatedreplies.</description><author>Ermis Soumalias, Michael J. Curry, Sven Seuken</author><pubDate>Wed, 12 Feb 2025 17:10:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05905v5</guid></item><item><title>Mapping the Landscape of Generative AI in Network Monitoring and Management</title><link>http://arxiv.org/abs/2502.08576v1</link><description>Generative Artificial Intelligence (GenAI) models such as LLMs, GPTs, andDiffusion Models have recently gained widespread attention from both theresearch and the industrial communities. This survey explores their applicationin network monitoring and management, focusing on prominent use cases, as wellas challenges and opportunities. We discuss how network traffic generation andclassification, network intrusion detection, networked system log analysis, andnetwork digital assistance can benefit from the use of GenAI models.Additionally, we provide an overview of the available GenAI models, datasetsfor large-scale training phases, and platforms for the development of suchmodels. Finally, we discuss research directions that potentially mitigate theroadblocks to the adoption of GenAI for network monitoring and management. Ourinvestigation aims to map the current landscape and pave the way for futureresearch in leveraging GenAI for network monitoring and management.</description><author>Giampaolo Bovenzi, Francesco Cerasuolo, Domenico Ciuonzo, Davide Di Monda, Idio Guarino, Antonio Montieri, Valerio Persico, Antonio Pescapè</author><pubDate>Wed, 12 Feb 2025 17:10:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08576v1</guid></item><item><title>COAST: Intelligent Time-Adaptive Neural Operators</title><link>http://arxiv.org/abs/2502.08574v1</link><description>We introduce Causal Operator with Adaptive Solver Transformer (COAST), anovel neural operator learning method that leverages a causal language model(CLM) framework to dynamically adapt time steps. Our method predicts both theevolution of a system and its optimal time step, intelligently balancingcomputational efficiency and accuracy. We find that COAST generates variablestep sizes that correlate with the underlying system intrinsicities, bothwithin and across dynamical systems. Within a single trajectory, smaller stepsare taken in regions of high complexity, while larger steps are employed insimpler regions. Across different systems, more complex dynamics receive moregranular time steps. Benchmarked on diverse systems with varied dynamics, COASTconsistently outperforms state-of-the-art methods, achieving superiorperformance in both efficiency and accuracy. This work underscores thepotential of CLM-based intelligent adaptive solvers for scalable operatorlearning of dynamical systems.</description><author>Zhikai Wu, Shiyang Zhang, Sizhuang He, Sifan Wang, Min Zhu, Anran Jiao, Lu Lu, David van Dijk</author><pubDate>Wed, 12 Feb 2025 17:09:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08574v1</guid></item><item><title>A Novel Approach to for Multimodal Emotion Recognition : Multimodal semantic information fusion</title><link>http://arxiv.org/abs/2502.08573v1</link><description>With the advancement of artificial intelligence and computer visiontechnologies, multimodal emotion recognition has become a prominent researchtopic. However, existing methods face challenges such as heterogeneous datafusion and the effective utilization of modality correlations. This paperproposes a novel multimodal emotion recognition approach, DeepMSI-MER, based onthe integration of contrastive learning and visual sequence compression. Theproposed method enhances cross-modal feature fusion through contrastivelearning and reduces redundancy in the visual modality by leveraging visualsequence compression. Experimental results on two public datasets, IEMOCAP andMELD, demonstrate that DeepMSI-MER significantly improves the accuracy androbustness of emotion recognition, validating the effectiveness of multimodalfeature fusion and the proposed approach.</description><author>Wei Dai, Dequan Zheng, Feng Yu, Yanrong Zhang, Yaohui Hou</author><pubDate>Wed, 12 Feb 2025 17:07:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08573v1</guid></item><item><title>A Stability Principle for Learning under Non-Stationarity</title><link>http://arxiv.org/abs/2310.18304v4</link><description>We develop a versatile framework for statistical learning in non-stationaryenvironments. In each time period, our approach applies a stability principleto select a look-back window that maximizes the utilization of historical datawhile keeping the cumulative bias within an acceptable range relative to thestochastic error. Our theory and numerical experiments showcase the adaptivityof this approach to unknown non-stationarity. We prove regret bounds that areminimax optimal up to logarithmic factors when the population losses arestrongly convex, or Lipschitz only. At the heart of our analysis lie two novelcomponents: a measure of similarity between functions and a segmentationtechnique for dividing the non-stationary data sequence into quasi-stationarypieces.</description><author>Chengpiao Huang, Kaizheng Wang</author><pubDate>Wed, 12 Feb 2025 17:02:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18304v4</guid></item><item><title>AR Glulam: Accurate Augmented Reality Using Multiple Fiducial Markers for Glulam Fabrication</title><link>http://arxiv.org/abs/2502.08566v1</link><description>Recent advancements in Augmented Reality (AR) have demonstrated applicationsin architecture, design, and fabrication. Compared to conventional 2Dconstruction drawings, AR can be used to superimpose contextual instructions,display 3D spatial information and enable on-site engagement. Despite thepotential of AR, the widespread adoption of the technology in the industry islimited by its precision. Precision is important for projects requiring strictconstruction tolerances, design fidelity, and fabrication feedback. Forexample, the manufacturing of glulam beams requires tolerances of less than2mm. The goal of this project is to explore the industrial application of usingmultiple fiducial markers for high-precision AR fabrication. While the methodhas been validated in lab settings with a precision of 0.97, this paper focuseson fabricating glulam beams in a factory setting with an industry manufacturer,Unalam Factory.</description><author>Alexander Htet Kyaw, Arvin Xu, Sasa Zivkovic, Gwyllim Jahn, Cameron Newnham, Nick Van Den Berg</author><pubDate>Wed, 12 Feb 2025 16:56:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08566v1</guid></item><item><title>SoK: A Classification for AI-driven Personalized Privacy Assistants</title><link>http://arxiv.org/abs/2502.07693v2</link><description>To help users make privacy-related decisions, personalized privacy assistantsbased on AI technology have been developed in recent years. These AI-drivenPersonalized Privacy Assistants (AI-driven PPAs) can reap significant benefitsfor users, who may otherwise struggle to make decisions regarding theirpersonal data in environments saturated with privacy-related decision requests.However, no study systematically inquired about the features of these AI-drivenPPAs, their underlying technologies, or the accuracy of their decisions. Tofill this gap, we present a Systematization of Knowledge (SoK) to map theexisting solutions found in the scientific literature. We screened 1697 uniqueresearch papers over the last decade (2013-2023), constructing a classificationfrom 39 included papers. As a result, this SoK reviews several aspects ofexisting research on AI-driven PPAs in terms of types of publications,contributions, methodological quality, and other quantitative insights.Furthermore, we provide a comprehensive classification for AI-driven PPAs,delving into their architectural choices, system contexts, types of AI used,data sources, types of decisions, and control over decisions, among otherfacets. Based on our SoK, we further underline the research gaps and challengesand formulate recommendations for the design and development of AI-driven PPAsas well as avenues for future research.</description><author>Victor Morel, Leonardo Iwaya, Simone Fischer-Hübner</author><pubDate>Wed, 12 Feb 2025 16:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07693v2</guid></item><item><title>Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems</title><link>http://arxiv.org/abs/2412.20163v3</link><description>The use of knowledge graphs in recommender systems has become one of thecommon approaches to addressing data sparsity and cold start problems. Recentadvances in large language models (LLMs) offer new possibilities for processingside and context information within knowledge graphs. However, consistentintegration across various systems remains challenging due to the need fordomain expert intervention and differences in system characteristics. Toaddress these issues, we propose a consistent approach that extracts bothgeneral and specific topics from both side and context information using LLMs.First, general topics are iteratively extracted and updated from sideinformation. Then, specific topics are extracted using context information.Finally, to address synonymous topics generated during the specific topicextraction process, a refining algorithm processes and resolves these issueseffectively. This approach allows general topics to capture broad knowledgeacross diverse item characteristics, while specific topics emphasize detailedattributes, providing a more comprehensive understanding of the semanticfeatures of items and the preferences of users. Experimental resultsdemonstrate significant improvements in recommendation performance acrossdiverse knowledge graphs.</description><author>Minhye Jeon, Seokho Ahn, Young-Duk Seo</author><pubDate>Wed, 12 Feb 2025 16:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.20163v3</guid></item><item><title>Quality-Aware Decoding: Unifying Quality Estimation and Decoding</title><link>http://arxiv.org/abs/2502.08561v1</link><description>An emerging research direction in NMT involves the use of Quality Estimation(QE) models, which have demonstrated high correlations with human judgment andcan enhance translations through Quality-Aware Decoding. Although severalapproaches have been proposed based on sampling multiple candidatetranslations, none have integrated these models directly into the decodingprocess. In this paper, we address this by proposing a novel token-level QEmodel capable of reliably scoring partial translations. We build auni-directional QE model for this, as decoder models are inherently trained andefficient on partial sequences. We then present a decoding strategy thatintegrates the QE model for Quality-Aware decoding and demonstrate that thetranslation quality improves when compared to the N-best list re-ranking withstate-of-the-art QE models (upto $1.39$ XCOMET-XXL $\uparrow$). Finally, weshow that our approach provides significant benefits in document translationtasks, where the quality of N-best lists is typically suboptimal.</description><author>Sai Koneru, Matthias Huck, Miriam Exel, Jan Niehues</author><pubDate>Wed, 12 Feb 2025 16:49:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08561v1</guid></item><item><title>URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics</title><link>http://arxiv.org/abs/2501.04686v3</link><description>Chain-of-Thought (CoT) reasoning is widely used to enhance the mathematicalreasoning capabilities of large language models (LLMs). The introduction ofprocess supervision for CoT trajectories has sparked discussions on improvingtest-time scaling, thereby unlocking the System 2-style thinking capabilitiesof these models. However, in multimodal mathematical reasoning, the scarcity ofhigh-quality CoT training data has hindered existing models from achieving bothdeliberate reasoning and fine-grained verification. In this work, we propose anovel framework that introduces System 2-style thinking to multimodalmathematical reasoning. We introduce a three-module CoT data synthesis processthat integrates CoT distillation, trajectory-format rewriting, and formatunification. This process generates MMathCoT-1M, a high-quality CoT reasoninginstruction fine-tuning dataset. Furthermore, we implement a dual-viewtrajectory labeling automation that targets both visual grounding fidelity anddeductive chain validity, resulting in the DualMath-1.1M dataset. The URSA-8Bmodel, trained on MMathCoT-1M, achieves new state-of-the-art (SOTA) performanceamong similarly sized multimodal LLMs on six popular reasoning benchmarks.Training URSA-8B further on the DualMath-1.1M dataset yields URSA-RM-8B, averifier that enhances URSA-8B's test-time performance and surpasses strongclosed-source multimodal MLLMs like GPT-4o. The model weights, training data,and code have been open-sourced: https://github.com/URSA-MATH/URSA-MATH.</description><author>Ruilin Luo, Zhuofan Zheng, Yifan Wang, Yiyao Yu, Xinzhe Ni, Zicheng Lin, Jin Zeng, Yujiu Yang</author><pubDate>Wed, 12 Feb 2025 16:49:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04686v3</guid></item><item><title>Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion</title><link>http://arxiv.org/abs/2502.08560v1</link><description>The growing availability of longitudinal Magnetic Resonance Imaging (MRI)datasets has facilitated Artificial Intelligence (AI)-driven modeling ofdisease progression, making it possible to predict future medical scans forindividual patients. However, despite significant advancements in AI, currentmethods continue to face challenges including achieving patient-specificindividualization, ensuring spatiotemporal consistency, efficiently utilizinglongitudinal data, and managing the substantial memory demands of 3D scans. Toaddress these challenges, we propose Brain Latent Progression (BrLP), a novelspatiotemporal model designed to predict individual-level disease progressionin 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operatesin a small latent space, mitigating the computational challenges posed byhigh-dimensional imaging data; (ii) it explicitly integrates subject metadatato enhance the individualization of predictions; (iii) it incorporates priorknowledge of disease dynamics through an auxiliary model, facilitating theintegration of longitudinal data; and (iv) it introduces the Latent AverageStabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency inthe predicted progression at inference time and (b) allows us to derive ameasure of the uncertainty for the prediction. We train and evaluate BrLP on11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate itsgeneralizability on an external test set comprising 2,257 MRIs from 962subjects. Our experiments compare BrLP-generated MRI scans with real follow-upMRIs, demonstrating state-of-the-art accuracy compared to existing methods. Thecode is publicly available at: https://github.com/LemuelPuglisi/BrLP.</description><author>Lemuel Puglisi, Daniel C. Alexander, Daniele Ravì</author><pubDate>Wed, 12 Feb 2025 16:47:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08560v1</guid></item><item><title>UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge</title><link>http://arxiv.org/abs/2502.06914v2</link><description>Enzyme-catalyzed protein cleavage is essential for many biological functions.Accurate prediction of cleavage sites can facilitate various applications suchas drug development, enzyme design, and a deeper understanding of biologicalmechanisms. However, most existing models are restricted to an individualenzyme, which neglects shared knowledge of enzymes and fails generalize tonovel enzymes. Thus, we introduce a unified protein cleavage site predictornamed UniZyme, which can generalize across diverse enzymes. To enhance theenzyme encoding for the protein cleavage site prediction, UniZyme employs anovel biochemically-informed model architecture along with active-siteknowledge of proteolytic enzymes. Extensive experiments demonstrate thatUniZyme achieves high accuracy in predicting cleavage sites across a range ofproteolytic enzymes, including unseen enzymes. The code is available inhttps://anonymous.4open.science/r/UniZyme-4A67.</description><author>Chenao Li, Shuo Yan, Enyan Dai</author><pubDate>Wed, 12 Feb 2025 16:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.06914v2</guid></item><item><title>TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning</title><link>http://arxiv.org/abs/2410.19702v2</link><description>Multimodal Large Language Models (MLLMs) have demonstrated impressiveperformance in short video understanding. However, understanding long-formvideos still remains challenging for MLLMs. This paper proposes TimeSuite, acollection of new designs to adapt the existing short-form video MLLMs for longvideo understanding, including a simple yet efficient framework to process longvideo sequence, a high-quality video dataset for grounded tuning of MLLMs, anda carefully-designed instruction tuning task to explicitly incorporate thegrounding supervision in the traditional QA format. Specifically, based onVideoChat, we propose our long-video MLLM, coined as VideoChat-T, byimplementing a token shuffling to compress long video tokens and introducingTemporal Adaptive Position Encoding (TAPE) to enhance the temporal awareness ofvisual representation. Meanwhile, we introduce the TimePro, a comprehensivegrounding-centric instruction tuning dataset composed of 9 tasks and 349khigh-quality grounded annotations. Notably, we design a new instruction tuningtask type, called Temporal Grounded Caption, to peform detailed videodescriptions with the corresponding time stamps prediction. This explicittemporal location prediction will guide MLLM to correctly attend on the visualcontent when generating description, and thus reduce the hallucination riskcaused by the LLMs. Experimental results demonstrate that our TimeSuiteprovides a successful solution to enhance the long video understandingcapability of short-form MLLM, achieving improvement of 5.6% and 6.8% on thebenchmarks of Egoschema and VideoMME, respectively. In addition, VideoChat-Texhibits robust zero-shot temporal grounding capabilities, significantlyoutperforming the existing state-of-the-art MLLMs. After fine-tuning, itperforms on par with the traditional supervised expert models.</description><author>Xiangyu Zeng, Kunchang Li, Chenting Wang, Xinhao Li, Tianxiang Jiang, Ziang Yan, Songze Li, Yansong Shi, Zhengrong Yue, Yi Wang, Yali Wang, Yu Qiao, Limin Wang</author><pubDate>Wed, 12 Feb 2025 16:47:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19702v2</guid></item><item><title>Causal Discovery from Conditionally Stationary Time Series</title><link>http://arxiv.org/abs/2110.06257v3</link><description>Causal discovery, i.e., inferring underlying causal relationships fromobservational data, is highly challenging for AI systems. In a time seriesmodeling context, traditional causal discovery methods mainly considerconstrained scenarios with fully observed variables and/or data from stationarytime-series. We develop a causal discovery approach to handle a wide class ofnonstationary time series that are conditionally stationary, where thenonstationary behaviour is modeled as stationarity conditioned on a set oflatent state variables. Named State-Dependent Causal Inference (SDCI), ourapproach is able to recover the underlying causal dependencies, with provableidentifiablity for the state-dependent causal structures. Empirical experimentson nonlinear particle interaction data and gene regulatory networks demonstrateSDCI's superior performance over baseline causal discovery methods. Improvedresults over non-causal RNNs on modeling NBA player movements demonstrate thepotential of our method and motivate the use of causality-driven methods forforecasting.</description><author>Carles Balsells-Rodas, Xavier Sumba, Tanmayee Narendra, Ruibo Tu, Gabriele Schweikert, Hedvig Kjellstrom, Yingzhen Li</author><pubDate>Wed, 12 Feb 2025 16:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.06257v3</guid></item><item><title>QA-Expand: Multi-Question Answer Generation for Enhanced Query Expansion in Information Retrieval</title><link>http://arxiv.org/abs/2502.08557v1</link><description>Query expansion is widely used in Information Retrieval (IR) to improvesearch outcomes by enriching queries with additional contextual information.Although recent Large Language Model (LLM) based methods generatepseudo-relevant content and expanded terms via multiple prompts, they oftenyield repetitive, narrow expansions that lack the diverse context needed toretrieve all relevant information. In this paper, we introduce QA-Expand, anovel and effective framework for query expansion. It first generates multiplerelevant questions from the initial query and subsequently producescorresponding pseudo-answers as surrogate documents. A feedback model furtherrewrites and filters these answers to ensure only the most informativeaugmentations are incorporated. Extensive experiments on benchmarks such asBEIR and TREC demonstrate that QA-Expand enhances retrieval performance by upto 13% over state-of-the-art methods, offering a robust solution for modernretrieval challenges.</description><author>Wonduk Seo, Seunghyun Lee</author><pubDate>Wed, 12 Feb 2025 16:39:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08557v1</guid></item><item><title>Human-Centric Foundation Models: Perception, Generation and Agentic Modeling</title><link>http://arxiv.org/abs/2502.08556v1</link><description>Human understanding and generation are critical for modeling digital humansand humanoid embodiments. Recently, Human-centric Foundation Models (HcFMs)inspired by the success of generalist models, such as large language and visionmodels, have emerged to unify diverse human-centric tasks into a singleframework, surpassing traditional task-specific approaches. In this survey, wepresent a comprehensive overview of HcFMs by proposing a taxonomy thatcategorizes current approaches into four groups: (1) Human-centric PerceptionFoundation Models that capture fine-grained features for multi-modal 2D and 3Dunderstanding. (2) Human-centric AIGC Foundation Models that generatehigh-fidelity, diverse human-related content. (3) Unified Perception andGeneration Models that integrate these capabilities to enhance both humanunderstanding and synthesis. (4) Human-centric Agentic Foundation Models thatextend beyond perception and generation to learn human-like intelligence andinteractive behaviors for humanoid embodied tasks. We review state-of-the-arttechniques, discuss emerging challenges and future research directions. Thissurvey aims to serve as a roadmap for researchers and practitioners workingtowards more robust, versatile, and intelligent digital human and embodimentsmodeling.</description><author>Shixiang Tang, Yizhou Wang, Lu Chen, Yuan Wang, Sida Peng, Dan Xu, Wanli Ouyang</author><pubDate>Wed, 12 Feb 2025 16:38:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08556v1</guid></item><item><title>A Machine Learning-Ready Data Processing Tool for Near Real-Time Forecasting</title><link>http://arxiv.org/abs/2502.08555v1</link><description>Space weather forecasting is critical for mitigating radiation risks in spaceexploration and protecting Earth-based technologies from geomagneticdisturbances. This paper presents the development of a Machine Learning (ML)-ready data processing tool for Near Real-Time (NRT) space weather forecasting.By merging data from diverse NRT sources such as solar imagery, magnetic fieldmeasurements, and energetic particle fluxes, the tool addresses key gaps incurrent space weather prediction capabilities. The tool processes andstructures the data for machine learning models, focusing on time-seriesforecasting and event detection for extreme solar events. It provides userswith a framework to download, process, and label data for ML applications,streamlining the workflow for improved NRT space weather forecasting andscientific research.</description><author>Maher A Dayeh, Michael J Starkey, Subhamoy Chatterjee, Heather Elliott, Samuel Hart, Kimberly Moreland</author><pubDate>Wed, 12 Feb 2025 16:35:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08555v1</guid></item><item><title>Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies</title><link>http://arxiv.org/abs/2502.08554v1</link><description>Large language models (LLMs) can produce erroneous responses that soundfluent and convincing, raising the risk that users will rely on these responsesas if they were correct. Mitigating such overreliance is a key challenge.Through a think-aloud study in which participants use an LLM-infusedapplication to answer objective questions, we identify several features of LLMresponses that shape users' reliance: explanations (supporting details foranswers), inconsistencies in explanations, and sources. Through a large-scale,pre-registered, controlled experiment (N=308), we isolate and study the effectsof these features on users' reliance, accuracy, and other measures. We findthat the presence of explanations increases reliance on both correct andincorrect responses. However, we observe less reliance on incorrect responseswhen sources are provided or when explanations exhibit inconsistencies. Wediscuss the implications of these findings for fostering appropriate relianceon LLMs.</description><author>Sunnie S. Y. Kim, Jennifer Wortman Vaughan, Q. Vera Liao, Tania Lombrozo, Olga Russakovsky</author><pubDate>Wed, 12 Feb 2025 16:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08554v1</guid></item><item><title>LLMs can implicitly learn from mistakes in-context</title><link>http://arxiv.org/abs/2502.08550v1</link><description>Learning from mistakes is a fundamental feature of human intelligence.Previous work has shown that Large Language Models (LLMs) can also learn fromincorrect answers when provided with a comprehensive rationale detailing why ananswer is wrong or how to correct it. In this work, we examine whether LLMs canlearn from mistakes in mathematical reasoning tasks when these explanations arenot provided. We investigate if LLMs are able to implicitly infer suchrationales simply from observing both incorrect and correct answers.Surprisingly, we find that LLMs perform better, on average, when rationales areeliminated from the context and incorrect answers are simply shown alongsidecorrect ones. This approach also substantially outperforms chain-of-thoughtprompting in our evaluations. We show that these results are consistent acrossLLMs of different sizes and varying reasoning abilities. Further, we carry outan in-depth analysis, and show that prompting with both wrong and correctanswers leads to greater performance and better generalisation than introducingadditional, more diverse question-answer pairs into the context. Finally, weshow that new rationales generated by models that have only observed incorrectand correct answers are scored equally as highly by humans as those producedwith the aid of exemplar rationales. Our results demonstrate that LLMs areindeed capable of in-context implicit learning.</description><author>Lisa Alazraki, Maximilian Mozes, Jon Ander Campos, Yi Chern Tan, Marek Rei, Max Bartolo</author><pubDate>Wed, 12 Feb 2025 16:31:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08550v1</guid></item><item><title>Copula-based mixture model identification for subgroup clustering with imaging applications</title><link>http://arxiv.org/abs/2502.08549v1</link><description>Model-based clustering techniques have been widely applied to variousapplication areas, while most studies focus on canonical mixtures with uniquecomponent distribution form. However, this strict assumption is often hard tosatisfy. In this paper, we consider the more flexible Copula-Based MixtureModels (CBMMs) for clustering, which allow heterogeneous componentdistributions composed by flexible choices of marginal and copula forms. Morespecifically, we propose an adaptation of the Generalized Iterative ConditionalEstimation (GICE) algorithm to identify the CBMMs in an unsupervised manner,where the marginal and copula forms and their parameters are estimatediteratively. GICE is adapted from its original version developed for switchingMarkov model identification with the choice of realization time. Our CBMM-GICEclustering method is then tested on synthetic two-cluster data (N=2000 samples)with discussion of the factors impacting its convergence. Finally, it iscompared to the Expectation Maximization identified mixture models with uniquecomponent form on the entire MNIST database (N=70000), and on real cardiacmagnetic resonance data (N=276) to illustrate its value for imagingapplications.</description><author>Fei Zheng, Nicolas Duchateau</author><pubDate>Wed, 12 Feb 2025 16:30:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08549v1</guid></item><item><title>Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data</title><link>http://arxiv.org/abs/2502.08547v1</link><description>The adoption of EHRs has expanded opportunities to leverage data-drivenalgorithms in clinical care and research. A major bottleneck in effectivelyconducting multi-institutional EHR studies is the data heterogeneity acrosssystems with numerous codes that either do not exist or represent differentclinical concepts across institutions. The need for data privacy further limitsthe feasibility of including multi-institutional patient-level data required tostudy similarities and differences across patient subgroups. To address thesechallenges, we developed the GAME algorithm. Tested and validated across 7institutions and 2 languages, GAME integrates data in several levels: (1) atthe institutional level with knowledge graphs to establish relationshipsbetween codes and existing knowledge sources, providing the medical context forstandard codes and their relationship to each other; (2) between institutions,leveraging language models to determine the relationships betweeninstitution-specific codes with established standard codes; and (3) quantifyingthe strength of the relationships between codes using a graph attentionnetwork. Jointly trained embeddings are created using transfer and federatedlearning to preserve data privacy. In this study, we demonstrate theapplicability of GAME in selecting relevant features as inputs for AI-drivenalgorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.We then highlight the application of GAME harmonized multi-institutional EHRdata in a study of Alzheimer's disease outcomes and suicide risk among patientswith mental health disorders, without sharing patient-level data outsideindividual institutions.</description><author>Doudou Zhou, Han Tong, Linshanshan Wang, Suqi Liu, Xin Xiong, Ziming Gan, Romain Griffier, Boris Hejblum, Yun-Chung Liu, Chuan Hong, Clara-Lea Bonzel, Tianrun Cai, Kevin Pan, Yuk-Lam Ho, Lauren Costa, Vidul A. Panickan, J. Michael Gaziano, Kenneth Mandl, Vianney Jouhet, Rodolphe Thiebaut, Zongqi Xia, Kelly Cho, Katherine Liao, Tianxi Cai</author><pubDate>Wed, 12 Feb 2025 16:29:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08547v1</guid></item><item><title>Moment of Untruth: Dealing with Negative Queries in Video Moment Retrieval</title><link>http://arxiv.org/abs/2502.08544v1</link><description>Video Moment Retrieval is a common task to evaluate the performance ofvisual-language models - it involves localising start and end times of momentsin videos from query sentences. The current task formulation assumes that thequeried moment is present in the video, resulting in false positive momentpredictions when irrelevant query sentences are provided. In this paper we propose the task of Negative-Aware Video Moment Retrieval(NA-VMR), which considers both moment retrieval accuracy and negative queryrejection accuracy. We make the distinction between In-Domain and Out-of-Domainnegative queries and provide new evaluation benchmarks for two popular videomoment retrieval datasets: QVHighlights and Charades-STA. We analyse theability of current SOTA video moment retrieval approaches to adapt toNegative-Aware Video Moment Retrieval and propose UniVTG-NA, an adaptation ofUniVTG designed to tackle NA-VMR. UniVTG-NA achieves high negative rejectionaccuracy (avg. $98.4\%$) scores while retaining moment retrieval scores towithin $3.87\%$ Recall@1. Dataset splits and code are available athttps://github.com/keflanagan/MomentofUntruth</description><author>Kevin Flanagan, Dima Damen, Michael Wray</author><pubDate>Wed, 12 Feb 2025 16:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08544v1</guid></item><item><title>Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making</title><link>http://arxiv.org/abs/2502.08542v1</link><description>Conventional decision-support systems, primarily based on supervisedlearning, focus on outcome prediction models to recommend actions. However,they often fail to account for the complexities of multi-actor environments,where diverse and potentially conflicting stakeholder preferences must bebalanced. In this paper, we propose a novel participatory framework thatredefines decision-making as a multi-stakeholder optimization problem,capturing each actor's preferences through context-dependent reward functions.Our framework leverages $k$-fold cross-validation to fine-tune user-providedoutcome prediction models and evaluate decision strategies, includingcompromise functions mediating stakeholder trade-offs. We introduce a syntheticscoring mechanism that exploits user-defined preferences across multiplemetrics to rank decision-making strategies and identify the optimaldecision-maker. The selected decision-maker can then be used to generateactionable recommendations for new data. We validate our framework using tworeal-world use cases, demonstrating its ability to deliver recommendations thateffectively balance multiple metrics, achieving results that are often beyondthe scope of purely prediction-based methods. Ablation studies demonstrate thatour framework, with its modular, model-agnostic, and inherently transparentdesign, integrates seamlessly with various predictive models, rewardstructures, evaluation metrics, and sample sizes, making it particularly suitedfor complex, high-stakes decision-making contexts.</description><author>Vittoria Vineis, Giuseppe Perelli, Gabriele Tolomei</author><pubDate>Wed, 12 Feb 2025 16:27:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08542v1</guid></item><item><title>Automated Capability Discovery via Model Self-Exploration</title><link>http://arxiv.org/abs/2502.07577v2</link><description>Foundation models have become general-purpose assistants, exhibiting diversecapabilities across numerous domains through training on web-scale data. Itremains challenging to precisely characterize even a fraction of the fullspectrum of capabilities and potential risks in any new model. Existingevaluation approaches often require significant human effort, and it is takingincreasing effort to design ever harder challenges for more capable models. Weintroduce Automated Capability Discovery (ACD), a framework that designates onefoundation model as a scientist to systematically propose open-ended tasksprobing the abilities of a subject model (potentially itself). By combiningfrontier models with ideas from the field of open-endedness, ACD automaticallyand systematically uncovers both surprising capabilities and failures in thesubject model. We demonstrate ACD across a range of foundation models(including the GPT, Claude, and Llama series), showing that it automaticallyreveals thousands of capabilities that would be challenging for any single teamto uncover. We further validate our method's automated scoring with extensivehuman surveys, observing high agreement between model-generated and humanevaluations. By leveraging foundation models' ability to both create tasks andself-evaluate, ACD is a significant step toward scalable, automated evaluationof novel AI systems. All code and evaluation logs are open-sourced athttps://github.com/conglu1997/ACD.</description><author>Cong Lu, Shengran Hu, Jeff Clune</author><pubDate>Wed, 12 Feb 2025 16:25:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07577v2</guid></item><item><title>A Survey on Image Quality Assessment: Insights, Analysis, and Future Outlook</title><link>http://arxiv.org/abs/2502.08540v1</link><description>Image quality assessment (IQA) represents a pivotal challenge inimage-focused technologies, significantly influencing the advancementtrajectory of image processing and computer vision. Recently, IQA has witnesseda notable surge in innovative research efforts, driven by the emergence ofnovel architectural paradigms and sophisticated computational techniques. Thissurvey delivers an extensive analysis of contemporary IQA methodologies,organized according to their application scenarios, serving as a beneficialreference for both beginners and experienced researchers. We analyze theadvantages and limitations of current approaches and suggest potential futureresearch pathways. The survey encompasses both general and specific IQAmethodologies, including conventional statistical measures, machine learningtechniques, and cutting-edge deep learning models such as convolutional neuralnetworks (CNNs) and Transformer models. The analysis within this surveyhighlights the necessity for distortion-specific IQA methods tailored tovarious application scenarios, emphasizing the significance of practicality,interpretability, and ease of implementation in future developments.</description><author>Chengqian Ma, Zhengyi Shi, Zhiqiang Lu, Shenghao Xie, Fei Chao, Yao Sui</author><pubDate>Wed, 12 Feb 2025 16:24:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08540v1</guid></item><item><title>Annealed Winner-Takes-All for Motion Forecasting</title><link>http://arxiv.org/abs/2409.11172v3</link><description>In autonomous driving, motion prediction aims at forecasting the futuretrajectories of nearby agents, helping the ego vehicle to anticipate behaviorsand drive safely. A key challenge is generating a diverse set of futurepredictions, commonly addressed using data-driven models with Multiple ChoiceLearning (MCL) architectures and Winner-Takes-All (WTA) training objectives.However, these methods face initialization sensitivity and traininginstabilities. Additionally, to compensate for limited performance, someapproaches rely on training with a large set of hypotheses, requiring apost-selection step during inference to significantly reduce the number ofpredictions. To tackle these issues, we take inspiration from annealed MCL, arecently introduced technique that improves the convergence properties of MCLmethods through an annealed Winner-Takes-All loss (aWTA). In this paper, wedemonstrate how the aWTA loss can be integrated with state-of-the-art motionforecasting models to enhance their performance using only a minimal set ofhypotheses, eliminating the need for the cumbersome post-selection step. Ourapproach can be easily incorporated into any trajectory prediction modelnormally trained using WTA and yields significant improvements. To facilitatethe application of our approach to future motion forecasting models, the codeis made publicly available: https://github.com/valeoai/MF_aWTA.</description><author>Yihong Xu, Victor Letzelter, Mickaël Chen, Éloi Zablocki, Matthieu Cord</author><pubDate>Wed, 12 Feb 2025 16:23:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.11172v3</guid></item><item><title>Matrix Completion with Graph Information: A Provable Nonconvex Optimization Approach</title><link>http://arxiv.org/abs/2502.08536v1</link><description>We consider the problem of matrix completion with graphs as side informationdepicting the interrelations between variables. The key challenge lies inleveraging the similarity structure of the graph to enhance matrix recovery.Existing approaches, primarily based on graph Laplacian regularization, sufferfrom several limitations: (1) they focus only on the similarity betweenneighboring variables, while overlooking long-range correlations; (2) they arehighly sensitive to false edges in the graphs and (3) they lack theoreticalguarantees regarding statistical and computational complexities. To addressthese issues, we propose in this paper a novel graph regularized matrixcompletion algorithm called GSGD, based on preconditioned projected gradientdescent approach. We demonstrate that GSGD effectively captures thehigher-order correlation information behind the graphs, and achieves superiorrobustness and stability against the false edges. Theoretically, we prove thatGSGD achieves linear convergence to the global optimum with near-optimal samplecomplexity, providing the first theoretical guarantees for both recoveryaccuracy and efficacy in the perspective of nonconvex optimization. Ournumerical experiments on both synthetic and real-world data further validatethat GSGD achieves superior recovery accuracy and scalability compared withseveral popular alternatives.</description><author>Yao Wang, Yiyang Yang, Kaidong Wang, Shanxing Gao, Xiuwu Liao</author><pubDate>Wed, 12 Feb 2025 16:21:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08536v1</guid></item><item><title>Input convex neural networks: universal approximation theorem and implementation for isotropic polyconvex hyperelastic energies</title><link>http://arxiv.org/abs/2502.08534v1</link><description>This paper presents a novel framework of neural networks for isotropichyperelasticity that enforces necessary physical and mathematical constraintswhile simultaneously satisfying the universal approximation theorem. The twokey ingredients are an input convex network architecture and a formulation inthe elementary polynomials of the signed singular values of the deformationgradient. In line with previously published networks, it can rigorously captureframe-indifference and polyconvexity - as well as further constraints likebalance of angular momentum and growth conditions. However and in contrast toprevious networks, a universal approximation theorem for the proposed approachis proven. To be more explicit, the proposed network can approximate anyframe-indifferent, isotropic polyconvex energy (provided the network is largeenough). This is possible by working with a sufficient and necessary criterionfor frame-indifferent, isotropic polyconvex functions. Comparative studies withexisting approaches identify the advantages of the proposed method,particularly in approximating non-polyconvex energies as well as computingpolyconvex hulls.</description><author>Gian-Luca Geuken, Patrick Kurzeja, David Wiedemann, Jörn Mosler</author><pubDate>Wed, 12 Feb 2025 16:15:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08534v1</guid></item><item><title>On Different Notions of Redundancy in Conditional-Independence-Based Discovery of Graphical Models</title><link>http://arxiv.org/abs/2502.08531v1</link><description>The goal of conditional-independence-based discovery of graphical models isto find a graph that represents the independence structure of variables in agiven dataset. To learn such a representation, conditional-independence-basedapproaches conduct a set of statistical tests that suffices to identify thegraphical representation under some assumptions on the underlying distributionof the data. In this work, we highlight that due to the conciseness of thegraphical representation, there are often many tests that are not used in theconstruction of the graph. These redundant tests have the potential to detector sometimes correct errors in the learned model. We show that not all testscontain this additional information and that such redundant tests have to beapplied with care. Precisely, we argue that particularly those conditional(in)dependence statements are interesting that follow only from graphicalassumptions but do not hold for every probability distribution.</description><author>Philipp M. Faller, Dominik Janzing</author><pubDate>Wed, 12 Feb 2025 16:08:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08531v1</guid></item><item><title>On the convergence rate of noisy Bayesian Optimization with Expected Improvement</title><link>http://arxiv.org/abs/2501.09262v2</link><description>Expected improvement (EI) is one of the most widely used acquisitionfunctions in Bayesian optimization (BO). Despite its proven success inapplications for decades, important open questions remain on the theoreticalconvergence behaviors and rates for EI. In this paper, we contribute to theconvergence theory of EI in three novel and critical areas. First, we considerobjective functions that fit under the Gaussian process (GP) prior assumption,whereas existing works mostly focus on functions in the reproducing kernelHilbert space (RKHS). Second, we establish for the first time the asymptoticerror bound and its corresponding rate for GP-EI with noisy observations underthe GP prior assumption. Third, by investigating the exploration andexploitation properties of the non-convex EI function, we establish improvederror bounds of GP-EI for both the noise-free and noisy cases.</description><author>Jingyi Wang, Haowei Wang, Nai-Yuan Chiang, Cosmin G. Petra</author><pubDate>Wed, 12 Feb 2025 16:07:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09262v2</guid></item><item><title>BCDDM: Branch-Corrected Denoising Diffusion Model for Black Hole Image Generation</title><link>http://arxiv.org/abs/2502.08528v1</link><description>The properties of black holes and accretion flows can be inferred by fittingEvent Horizon Telescope (EHT) data to simulated images generated throughgeneral relativistic ray tracing (GRRT). However, due to the computationallyintensive nature of GRRT, the efficiency of generating specific radiation fluximages needs to be improved. This paper introduces the Branch CorrectionDenoising Diffusion Model (BCDDM), which uses a branch correction mechanism anda weighted mixed loss function to improve the accuracy of generated black holeimages based on seven physical parameters of the radiatively inefficientaccretion flow (RIAF) model. Our experiments show a strong correlation betweenthe generated images and their physical parameters. By enhancing the GRRTdataset with BCDDM-generated images and using ResNet50 for parameterregression, we achieve significant improvements in parameter predictionperformance. This approach reduces computational costs and provides a faster,more efficient method for dataset expansion, parameter estimation, and modelfitting.</description><author>Ao liu, Zelin Zhang, Songbai Chen, Cuihong Wen</author><pubDate>Wed, 12 Feb 2025 16:05:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08528v1</guid></item><item><title>LLM Pretraining with Continuous Concepts</title><link>http://arxiv.org/abs/2502.08524v1</link><description>Next token prediction has been the standard training objective used in largelanguage model pretraining. Representations are learned as a result ofoptimizing for token-level perplexity. We propose Continuous Concept Mixing(CoCoMix), a novel pretraining framework that combines discrete next tokenprediction with continuous concepts. Specifically, CoCoMix predicts continuousconcepts learned from a pretrained sparse autoencoder and mixes them into themodel's hidden state by interleaving with token hidden representations. Throughexperiments on multiple benchmarks, including language modeling and downstreamreasoning tasks, we show that CoCoMix is more sample efficient and consistentlyoutperforms standard next token prediction, knowledge distillation andinserting pause tokens. We find that combining both concept learning andinterleaving in an end-to-end framework is critical to performance gains.Furthermore, CoCoMix enhances interpretability and steerability by allowingdirect inspection and modification of the predicted concept, offering atransparent way to guide the model's internal reasoning process.</description><author>Jihoon Tack, Jack Lanchantin, Jane Yu, Andrew Cohen, Ilia Kulikov, Janice Lan, Shibo Hao, Yuandong Tian, Jason Weston, Xian Li</author><pubDate>Wed, 12 Feb 2025 16:00:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08524v1</guid></item><item><title>Algorithmic Persuasion Through Simulation</title><link>http://arxiv.org/abs/2311.18138v5</link><description>We study a Bayesian persuasion game where a sender wants to persuade areceiver to take a binary action, such as purchasing a product. The sender isinformed about the (real-valued) state of the world, such as the quality of theproduct, but only has limited information about the receiver's beliefs andutilities. Motivated by customer surveys, user studies, and recent advances inAI, we allow the sender to learn more about the receiver by querying an oraclethat simulates the receiver's behavior. After a fixed number of queries, thesender commits to a messaging policy and the receiver takes the action thatmaximizes her expected utility given the message she receives. We characterizethe sender's optimal messaging policy given any distribution over receivertypes. We then design a polynomial-time querying algorithm that optimizes thesender's expected utility in this game. We also consider approximate oracles,more general query structures, and costly queries.</description><author>Keegan Harris, Nicole Immorlica, Brendan Lucier, Aleksandrs Slivkins</author><pubDate>Wed, 12 Feb 2025 15:56:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18138v5</guid></item><item><title>Exploiting Sparsity for Long Context Inference: Million Token Contexts on Commodity GPUs</title><link>http://arxiv.org/abs/2502.06766v2</link><description>There is growing demand for performing inference with hundreds of thousandsof input tokens on trained transformer models. Inference at this extreme scaledemands significant computational resources, hindering the application oftransformers at long contexts on commodity (i.e not data center scale)hardware. To address the inference time costs associated with runningself-attention based transformer language models on long contexts and enabletheir adoption on widely available hardware, we propose a tunable mechanismthat reduces the cost of the forward pass by attending to only the mostrelevant tokens at every generation step using a top-k selection mechanism. Weshowcase the efficiency gains afforded by our method by performing inference oncontext windows up to 1M tokens using approximately 16GB of GPU RAM. Ourexperiments reveal that models are capable of handling the sparsity induced bythe reduced number of keys and values. By attending to less than 2% of inputtokens, we achieve over 95% of model performance on common benchmarks (RULER,AlpacaEval, and Open LLM Leaderboard).</description><author>Ryan Synk, Monte Hoover, John Kirchenbauer, Neel Jain, Alex Stein, Manli Shu, Josue Melendez Sanchez, Ramani Duraiswami, Tom Goldstein</author><pubDate>Wed, 12 Feb 2025 15:55:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.06766v2</guid></item><item><title>FedMHO: Heterogeneous One-Shot Federated Learning Towards Resource-Constrained Edge Devices</title><link>http://arxiv.org/abs/2502.08518v1</link><description>Federated Learning (FL) is increasingly adopted in edge computing scenarios,where a large number of heterogeneous clients operate under constrained orsufficient resources. The iterative training process in conventional FLintroduces significant computation and communication overhead, which isunfriendly for resource-constrained edge devices. One-shot FL has emerged as apromising approach to mitigate communication overhead, and model-heterogeneousFL solves the problem of diverse computing resources across clients. However,existing methods face challenges in effectively managing model-heterogeneousone-shot FL, often leading to unsatisfactory global model performance orreliance on auxiliary datasets. To address these challenges, we propose a novelFL framework named FedMHO, which leverages deep classification models onresource-sufficient clients and lightweight generative models onresource-constrained devices. On the server side, FedMHO involves a two-stageprocess that includes data generation and knowledge fusion. Furthermore, weintroduce FedMHO-MD and FedMHO-SD to mitigate the knowledge-forgetting problemduring the knowledge fusion stage, and an unsupervised data optimizationsolution to improve the quality of synthetic samples. Comprehensive experimentsdemonstrate the effectiveness of our methods, as they outperformstate-of-the-art baselines in various experimental setups.</description><author>Dezhong Yao, Yuexin Shi, Tongtong Liu, Zhiqiang Xu</author><pubDate>Wed, 12 Feb 2025 15:54:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08518v1</guid></item><item><title>Fast Convergence of $Φ$-Divergence Along the Unadjusted Langevin Algorithm and Proximal Sampler</title><link>http://arxiv.org/abs/2410.10699v2</link><description>We study the mixing time of two popular discrete-time Markov chains incontinuous space, the Unadjusted Langevin Algorithm and the Proximal Sampler,which are discretizations of the Langevin dynamics. We extend mixing timeanalyses for these Markov chains to hold in $\Phi$-divergence. We show that any$\Phi$-divergence arising from a twice-differentiable strictly convex function$\Phi$ converges to $0$ exponentially fast along these Markov chains, under theassumption that their stationary distributions satisfy the corresponding$\Phi$-Sobolev inequality, which holds for example when the target distributionof the Langevin dynamics is strongly log-concave. Our setting includes asspecial cases popular mixing time regimes, namely the mixing in chi-squareddivergence under a Poincar\'e inequality, and the mixing in relative entropyunder a log-Sobolev inequality. Our results follow by viewing the samplingalgorithms as noisy channels and bounding the contraction coefficients arisingin the appropriate strong data processing inequalities.</description><author>Siddharth Mitra, Andre Wibisono</author><pubDate>Wed, 12 Feb 2025 15:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10699v2</guid></item><item><title>The Paradox of Stochasticity: Limited Creativity and Computational Decoupling in Temperature-Varied LLM Outputs of Structured Fictional Data</title><link>http://arxiv.org/abs/2502.08515v1</link><description>This study examines how temperature settings and model architectures affectthe generation of structured fictional data (names, birthdates) across threelarge language models (LLMs): llama3.1:8b, deepseek-r1:8b, and mistral:latest.By systematically testing temperature values from 0.0 to 1.0 in increments of0.1, we conducted 330 trials yielding 889 structured entities, validated forsyntactic consistency. Key findings reveal that model architecturesignificantly influences computational efficiency, with mistral:latest andllama3.1:8b processing data 8x faster than deepseek-r1:8b. Contrary toexpectations, temperature showed no correlation with processing time,challenging assumptions about stochastic sampling costs. Output diversityremained limited, as models consistently defaulted to common name archetypes(e.g., 'John Doe' and 'Jane Smith') across all temperatures, though rare namesclustered at intermediate values (0.3-0.7). These results demonstrate thatarchitectural optimizations, rather than temperature adjustments, dominateperformance in structured generation tasks. The findings emphasize prioritizingmodel selection over hyperparameter tuning for efficiency and suggest explicitdiversity constraints are necessary to mitigate default output biases insynthetic data pipelines.</description><author>Evgenii Evstafev</author><pubDate>Wed, 12 Feb 2025 15:47:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08515v1</guid></item><item><title>Faithful, Unfaithful or Ambiguous? Multi-Agent Debate with Initial Stance for Summary Evaluation</title><link>http://arxiv.org/abs/2502.08514v1</link><description>Faithfulness evaluators based on large language models (LLMs) are oftenfooled by the fluency of the text and struggle with identifying errors in thesummaries. We propose an approach to summary faithfulness evaluation in whichmultiple LLM-based agents are assigned initial stances (regardless of whattheir belief might be) and forced to come up with a reason to justify theimposed belief, thus engaging in a multi-round debate to reach an agreement.The uniformly distributed initial assignments result in a greater diversity ofstances leading to more meaningful debates and ultimately more errorsidentified. Furthermore, by analyzing the recent faithfulness evaluationdatasets, we observe that naturally, it is not always the case for a summary tobe either faithful to the source document or not. We therefore introduce a newdimension, ambiguity, and a detailed taxonomy to identify such special cases.Experiments demonstrate our approach can help identify ambiguities, and haveeven a stronger performance on non-ambiguous summaries.</description><author>Mahnaz Koupaee, Jake W. Vincent, Saab Mansour, Igor Shalyminov, Han He, Hwanjun Song, Raphael Shu, Jianfeng He, Yi Nian, Amy Wing-mei Wong, Kyu J. Han, Hang Su</author><pubDate>Wed, 12 Feb 2025 15:46:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08514v1</guid></item><item><title>Measuring Diversity in Synthetic Datasets</title><link>http://arxiv.org/abs/2502.08512v1</link><description>Large language models (LLMs) are widely adopted to generate syntheticdatasets for various natural language processing (NLP) tasks, such as textclassification and summarization. However, accurately measuring the diversityof these synthetic datasets-an aspect crucial for robust modelperformance-remains a significant challenge. In this paper, we introduceDCScore, a novel method for measuring synthetic dataset diversity from aclassification perspective. Specifically, DCScore formulates diversityevaluation as a sample classification task, leveraging mutual relationshipsamong samples. We further provide theoretical verification of thediversity-related axioms satisfied by DCScore, highlighting its role as aprincipled diversity evaluation method. Experimental results on syntheticdatasets reveal that DCScore enjoys a stronger correlation with multiplediversity pseudo-truths of evaluated datasets, underscoring its effectiveness.Moreover, both empirical and theoretical evidence demonstrate that DCScoresubstantially reduces computational costs compared to existing approaches. Codeis available at: https://github.com/BlueWhaleLab/DCScore.</description><author>Yuchang Zhu, Huizhe Zhang, Bingzhe Wu, Jintang Li, Zibin Zheng, Peilin Zhao, Liang Chen, Yatao Bian</author><pubDate>Wed, 12 Feb 2025 15:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08512v1</guid></item><item><title>Explanation based In-Context Demonstrations Retrieval for Multilingual Grammatical Error Correction</title><link>http://arxiv.org/abs/2502.08507v1</link><description>Grammatical error correction (GEC) aims to correct grammatical, spelling, andsemantic errors in natural language text. With the growing of large languagemodels (LLMs), direct text generation has gradually become the focus of the GECmethods, and few-shot in-context learning presents a cost-effective solution.However, selecting effective in-context examples remains challenging, as thesimilarity between input texts does not necessarily correspond to similargrammatical error patterns. In this paper, we propose a novel retrieval methodbased on natural language grammatical error explanations (GEE) to address thisissue. Our method retrieves suitable few-shot demonstrations by matching theGEE of the test input with that of pre-constructed database samples, whereexplanations for erroneous samples are generated by LLMs. We conductedmultilingual GEC few-shot experiments on both major open-source andclosed-source LLMs. Experiments across five languages show that our methodoutperforms existing semantic and BM25-based retrieval techniques, withoutrequiring additional training or language adaptation. This also suggests thatmatching error patterns is key to selecting examples.</description><author>Wei Li, Wen Luo, Guangyue Peng, Houfeng Wang</author><pubDate>Wed, 12 Feb 2025 15:41:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08507v1</guid></item><item><title>Do Large Code Models Understand Programming Concepts? Counterfactual Analysis for Code Predicates</title><link>http://arxiv.org/abs/2402.05980v3</link><description>Large Language Models' success on text generation has also made them betterat code generation and coding tasks. While a lot of work has demonstrated theirremarkable performance on tasks such as code completion and editing, it isstill unclear as to why. We help bridge this gap by exploring to what degreeauto-regressive models understand the logical constructs of the underlyingprograms. We propose Counterfactual Analysis for Programming Concept Predicates(CACP) as a counterfactual testing framework to evaluate whether Large CodeModels understand programming concepts. With only black-box access to themodel, we use CACP to evaluate ten popular Large Code Models for four differentprogramming concepts. Our findings suggest that current models lackunderstanding of concepts such as data flow and control flow.</description><author>Ashish Hooda, Mihai Christodorescu, Miltiadis Allamanis, Aaron Wilson, Kassem Fawaz, Somesh Jha</author><pubDate>Wed, 12 Feb 2025 15:40:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05980v3</guid></item><item><title>Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation</title><link>http://arxiv.org/abs/2501.14679v2</link><description>Attention-based methods have demonstrated exceptional performance inmodelling long-range dependencies on spherical cortical surfaces, surpassingtraditional Geometric Deep Learning (GDL) models. However, their extensiveinference time and high memory demands pose challenges for application to largedatasets with limited computing resources. Inspired by the state space model incomputer vision, we introduce the attention-free Vision Mamba (Vim) tospherical surfaces, presenting a domain-agnostic architecture for analyzingdata on spherical manifolds. Our method achieves surface patching byrepresenting spherical data as a sequence of triangular patches derived from asubdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated onmultiple neurodevelopmental phenotype regression tasks using cortical surfacemetrics from neonatal brains. Experimental results demonstrate that SiMoutperforms both attention- and GDL-based methods, delivering 4.8 times fasterinference and achieving 91.7% lower memory consumption compared to the SurfaceVision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivityanalysis further underscores the potential of SiM to identify subtle cognitivedevelopmental patterns. The code is available athttps://github.com/Rongzhao-He/surface-vision-mamba.</description><author>Rongzhao He, Weihao Zheng, Leilei Zhao, Ying Wang, Dalin Zhu, Dan Wu, Bin Hu</author><pubDate>Wed, 12 Feb 2025 15:37:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14679v2</guid></item><item><title>Bridging Domain Adaptation and Graph Neural Networks: A Tensor-Based Framework for Effective Label Propagation</title><link>http://arxiv.org/abs/2502.08505v1</link><description>Graph Neural Networks (GNNs) have recently become the predominant tools forstudying graph data. Despite state-of-the-art performance on graphclassification tasks, GNNs are overwhelmingly trained in a single domain undersupervision, thus necessitating a prohibitively high demand for labels andresulting in poorly transferable representations. To address this challenge, wepropose the Label-Propagation Tensor Graph Neural Network (LP-TGNN) frameworkto bridge the gap between graph data and traditional domain adaptation methods.It extracts graph topological information holistically with a tensorarchitecture and then reduces domain discrepancy through label propagation. Itis readily compatible with general GNNs and domain adaptation techniques withminimal adjustment through pseudo-labeling. Experiments on various real-worldbenchmarks show that our LP-TGNN outperforms baselines by a notable margin. Wealso validate and analyze each component of the proposed framework in theablation study.</description><author>Tao Wen, Elynn Chen, Yuzhou Chen, Qi Lei</author><pubDate>Wed, 12 Feb 2025 15:36:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08505v1</guid></item><item><title>Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?</title><link>http://arxiv.org/abs/2502.08503v1</link><description>In this work, we identify the "2D-Cheating" problem in 3D LLM evaluation,where these tasks might be easily solved by VLMs with rendered images of pointclouds, exposing ineffective evaluation of 3D LLMs' unique 3D capabilities. Wetest VLM performance across multiple 3D LLM benchmarks and, using this as areference, propose principles for better assessing genuine 3D understanding. Wealso advocate explicitly separating 3D abilities from 1D or 2D aspects whenevaluating 3D LLMs.</description><author>Jiahe Jin, Yanheng He, Mingyan Yang</author><pubDate>Wed, 12 Feb 2025 15:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08503v1</guid></item><item><title>Random ReLU Neural Networks as Non-Gaussian Processes</title><link>http://arxiv.org/abs/2405.10229v2</link><description>We consider a large class of shallow neural networks with randomlyinitialized parameters and rectified linear unit activation functions. We provethat these random neural networks are well-defined non-Gaussian processes. As aby-product, we demonstrate that these networks are solutions to stochasticdifferential equations driven by impulsive white noise (combinations of randomDirac measures). These processes are parameterized by the law of the weightsand biases as well as the density of activation thresholds in each boundedregion of the input domain. We prove that these processes are isotropic andwide-sense self-similar with Hurst exponent 3/2. We also derive a remarkablysimple closed-form expression for their autocovariance function. Our resultsare fundamentally different from prior work in that we consider anon-asymptotic viewpoint: The number of neurons in each bounded region of theinput domain (i.e., the width) is itself a random variable with a Poisson lawwith mean proportional to the density parameter. Finally, we show that, undersuitable hypotheses, as the expected width tends to infinity, these processescan converge in law not only to Gaussian processes, but also to non-Gaussianprocesses depending on the law of the weights. Our asymptotic results provide anew take on several classical results (wide networks converge to Gaussianprocesses) as well as some new ones (wide networks can converge to non-Gaussianprocesses).</description><author>Rahul Parhi, Pakshal Bohra, Ayoub El Biari, Mehrsa Pourya, Michael Unser</author><pubDate>Wed, 12 Feb 2025 15:34:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10229v2</guid></item><item><title>Fine-Tuning Topics through Weighting Aspect Keywords</title><link>http://arxiv.org/abs/2502.08496v1</link><description>Topic modeling often requires examining topics from multiple perspectives touncover hidden patterns, especially in less explored areas. This paper presentsan approach to address this need, utilizing weighted keywords from variousaspects derived from a domain knowledge. The research method starts withstandard topic modeling. Then, it adds a process consisting of four key steps.First, it defines keywords for each aspect. Second, it gives weights to thesekeywords based on their relevance. Third, it calculates relevance scores foraspect-weighted keywords and topic keywords to create aspect-topic models.Fourth, it uses these scores to tune relevant new documents. Finally, thegenerated topic models are interpreted and validated. The findings show thattop-scoring documents are more likely to be about the same aspect of a topic.This highlights the model's effectiveness in finding the related documents tothe aspects.</description><author>Ali Nazari, Michael Weiss</author><pubDate>Wed, 12 Feb 2025 15:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08496v1</guid></item><item><title>Salamandra Technical Report</title><link>http://arxiv.org/abs/2502.08489v1</link><description>This work introduces Salamandra, a suite of open-source decoder-only largelanguage models available in three different sizes: 2, 7, and 40 billionparameters. The models were trained from scratch on highly multilingual datathat comprises text in 35 European languages and code. Our carefully curatedcorpus is made exclusively from open-access data compiled from a wide varietyof sources. Along with the base models, supplementary checkpoints that werefine-tuned on public-domain instruction data are also released for chatapplications. Additionally, we also share our preliminary experiments onmultimodality, which serve as proof-of-concept to showcase potentialapplications for the Salamandra family. Our extensive evaluations onmultilingual benchmarks reveal that Salamandra has strong capabilities,achieving competitive performance when compared to similarly sized open-sourcemodels. We provide comprehensive evaluation results both on standard downstreamtasks as well as key aspects related to bias and safety.With this technicalreport, we intend to promote open science by sharing all the details behind ourdesign choices, data curation strategy and evaluation methodology. In additionto that, we deviate from the usual practice by making our training andevaluation scripts publicly accessible. We release all models under apermissive Apache 2.0 license in order to foster future research and facilitatecommercial use, thereby contributing to the open-source ecosystem of largelanguage models.</description><author>Aitor Gonzalez-Agirre, Marc Pàmies, Joan Llop, Irene Baucells, Severino Da Dalt, Daniel Tamayo, José Javier Saiz, Ferran Espuña, Jaume Prats, Javier Aula-Blasco, Mario Mina, Adrián Rubio, Alexander Shvets, Anna Sallés, Iñaki Lacunza, Iñigo Pikabea, Jorge Palomar, Júlia Falcão, Lucía Tormo, Luis Vasquez-Reina, Montserrat Marimon, Valle Ruíz-Fernández, Marta Villegas</author><pubDate>Wed, 12 Feb 2025 15:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08489v1</guid></item><item><title>One-Shot Federated Learning with Classifier-Free Diffusion Models</title><link>http://arxiv.org/abs/2502.08488v1</link><description>Federated learning (FL) enables collaborative learning without datacentralization but introduces significant communication costs due to multiplecommunication rounds between clients and the server. One-shot federatedlearning (OSFL) addresses this by forming a global model with a singlecommunication round, often relying on the server's model distillation orauxiliary dataset generation - often through pre-trained diffusion models(DMs). Existing DM-assisted OSFL methods, however, typically employclassifier-guided DMs, which require training auxiliary classifier models ateach client, introducing additional computation overhead. This work introducesOSCAR (One-Shot Federated Learning with Classifier-Free Diffusion Models), anovel OSFL approach that eliminates the need for auxiliary models. OSCAR usesfoundation models to devise category-specific data representations at eachclient, seamlessly integrated into a classifier-free diffusion model pipelinefor server-side data generation. OSCAR is a simple yet cost-effective OSFLapproach that outperforms the state-of-the-art on four benchmarking datasetswhile reducing the communication load by at least 99%.</description><author>Obaidullah Zaland, Shutong Jin, Florian T. Pokorny, Monowar Bhuyan</author><pubDate>Wed, 12 Feb 2025 15:23:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08488v1</guid></item><item><title>Referring Remote Sensing Image Segmentation via Bidirectional Alignment Guided Joint Prediction</title><link>http://arxiv.org/abs/2502.08486v1</link><description>Referring Remote Sensing Image Segmentation (RRSIS) is critical forecological monitoring, urban planning, and disaster management, requiringprecise segmentation of objects in remote sensing imagery guided by textualdescriptions. This task is uniquely challenging due to the considerablevision-language gap, the high spatial resolution and broad coverage of remotesensing imagery with diverse categories and small targets, and the presence ofclustered, unclear targets with blurred edges. To tackle these issues, wepropose \ours, a novel framework designed to bridge the vision-language gap,enhance multi-scale feature interaction, and improve fine-grained objectdifferentiation. Specifically, \ours introduces: (1) the Bidirectional SpatialCorrelation (BSC) for improved vision-language feature alignment, (2) theTarget-Background TwinStream Decoder (T-BTD) for precise distinction betweentargets and non-targets, and (3) the Dual-Modal Object Learning Strategy(D-MOLS) for robust multimodal feature reconstruction. Extensive experiments onthe benchmark datasets RefSegRS and RRSIS-D demonstrate that \ours achievesstate-of-the-art performance. Specifically, \ours improves the overall IoU(oIoU) by 3.76 percentage points (80.57) and 1.44 percentage points (79.23) onthe two datasets, respectively. Additionally, it outperforms previous methodsin the mean IoU (mIoU) by 5.37 percentage points (67.95) and 1.84 percentagepoints (66.04), effectively addressing the core challenges of RRSIS withenhanced precision and robustness.</description><author>Tianxiang Zhang, Zhaokun Wen, Bo Kong, Kecheng Liu, Yisi Zhang, Peixian Zhuang, Jiangyun Li</author><pubDate>Wed, 12 Feb 2025 15:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08486v1</guid></item></channel></rss>