<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 09 Aug 2024 01:00:30 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Image Segmentation</title><link>http://arxiv.org/abs/2407.14153v3</link><description>The universality of deep neural networks across different modalities andtheir generalization capabilities to unseen domains play an essential role inmedical image segmentation. The recent Segment Anything Model (SAM) hasdemonstrated its potential in both settings. However, the huge computationalcosts, demand for manual annotations as prompts and conflict-prone decodingprocess of SAM degrade its generalizability and applicability in clinicalscenarios. To address these issues, we propose an efficient self-prompting SAMfor universal domain-generalized medical image segmentation, named ESP-MedSAM.Specifically, we first devise the Multi-Modal Decoupled Knowledge Distillation(MMDKD) strategy to construct a lightweight semi-parameter sharing imageencoder that produces discriminative visual features for diverse modalities.Further, we introduce the Self-Patch Prompt Generator (SPPG) to automaticallygenerate high-quality dense prompt embeddings for guiding segmentationdecoding. Finally, we design the Query-Decoupled Modality Decoder (QDMD) thatleverages a one-to-one strategy to provide an independent decoding channel forevery modality. Extensive experiments indicate that ESP-MedSAM outperformsstate-of-the-arts in diverse medical imaging segmentation tasks, displayingsuperior modality universality and generalization capabilities. Especially,ESP-MedSAM uses only 4.5\% parameters compared to SAM-H. The source code isavailable at https://github.com/xq141839/ESP-MedSAM.</description><author>Qing Xu, Jiaxuan Li, Xiangjian He, Ziyu Liu, Zhen Chen, Wenting Duan, Chenxin Li, Maggie M. He, Fiseha B. Tesema, Wooi P. Cheah, Yi Wang, Rong Qu, Jonathan M. Garibaldi</author><pubDate>Thu, 08 Aug 2024 16:20:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14153v3</guid></item><item><title>Autonomous, Self-driving Multi-Step Growth of Semiconductor Heterostructures Guided by Machine Learning</title><link>http://arxiv.org/abs/2408.03508v2</link><description>The semiconductor industry has prioritized automating repetitive tasks byclosed-loop, autonomous experimentation which enables accelerated optimizationof complex multi-step processes. The emergence of machine learning (ML) hasushered in automated process with minimal human intervention. In this work, wedevelop SemiEpi, a self-driving automation platform capable of executingmolecular beam epitaxy (MBE) growth with multi-steps, continuous in-situmonitoring, and on-the-fly feedback control. By integrating standard hardware,homemade software, curve fitting, and multiple ML models, SemiEpi operatesautonomously, eliminating the need for extensive expertise in MBE processes toachieve optimal outcomes. The platform actively learns from previousexperimental results, identifying favorable conditions and proposing newexperiments to achieve the desired results. We standardize and optimize growthfor InAs/GaAs quantum dots (QDs) heterostructures to showcase the power ofML-guided multi-step growth. A temperature calibration was implemented to getthe initial growth condition, and fine control of the process was executedusing ML. Leveraging RHEED movies acquired during the growth, SemiEpisuccessfully identified and optimized a novel route for multi-stepheterostructure growth. This work demonstrates the capabilities of closed-loop,ML-guided systems in addressing challenges in multi-step growth for any device.Our method is critical to achieve repeatable materials growth usingcommercially scalable tools. Our strategy facilitates the development of ahardware-independent process and enhancing process repeatability and stability,even without exhaustive knowledge of growth parameters.</description><author>Chao Shen, Wenkang Zhan, Hongyu Sun, Kaiyao Xin, Bo Xu, Zhanguo Wang, Chao Zhao</author><pubDate>Thu, 08 Aug 2024 15:37:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03508v2</guid></item><item><title>RL-ADN: A High-Performance Deep Reinforcement Learning Environment for Optimal Energy Storage Systems Dispatch in Active Distribution Networks</title><link>http://arxiv.org/abs/2408.03685v2</link><description>Deep Reinforcement Learning (DRL) presents a promising avenue for optimizingEnergy Storage Systems (ESSs) dispatch in distribution networks. This paperintroduces RL-ADN, an innovative open-source library specifically designed forsolving the optimal ESSs dispatch in active distribution networks. RL-ADNoffers unparalleled flexibility in modeling distribution networks, and ESSs,accommodating a wide range of research goals. A standout feature of RL-ADN isits data augmentation module, based on Gaussian Mixture Model and Copula (GMC)functions, which elevates the performance ceiling of DRL agents. Additionally,RL-ADN incorporates the Laurent power flow solver, significantly reducing thecomputational burden of power flow calculations during training withoutsacrificing accuracy. The effectiveness of RL-ADN is demonstrated using indifferent sizes of distribution networks, showing marked performanceimprovements in the adaptability of DRL algorithms for ESS dispatch tasks. Thisenhancement is particularly beneficial from the increased diversity of trainingscenarios. Furthermore, RL-ADN achieves a tenfold increase in computationalefficiency during training, making it highly suitable for large-scale networkapplications. The library sets a new benchmark in DRL-based ESSs dispatch indistribution networks and it is poised to advance DRL applications indistribution network operations significantly. RL-ADN is available at:https://github.com/ShengrenHou/RL-ADN andhttps://github.com/distributionnetworksTUDelft/RL-ADN.</description><author>Shengren Hou, Shuyi Gao, Weijie Xia, Edgar Mauricio Salazar Duque, Peter Palensky, Pedro P. Vergara</author><pubDate>Thu, 08 Aug 2024 13:52:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03685v2</guid></item><item><title>The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums</title><link>http://arxiv.org/abs/2408.03354v2</link><description>Large language models (LLMs) can be used to analyze cyber threat intelligence(CTI) data from cybercrime forums, which contain extensive information and keydiscussions about emerging cyber threats. However, to date, the level ofaccuracy and efficiency of LLMs for such critical tasks has yet to bethoroughly evaluated. Hence, this study assesses the accuracy of an LLM systembuilt on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To doso, a random sample of 500 daily conversations from three cybercrime forums,XSS, Exploit_in, and RAMP, was extracted, and the LLM system was instructed tosummarize the conversations and code 10 key CTI variables, such as whether alarge organization and/or a critical infrastructure is being targeted. Then,two coders reviewed each conversation and evaluated whether the informationextracted by the LLM was accurate. The LLM system performed strikingly well,with an average accuracy score of 98%. Various ways to enhance the model wereuncovered, such as the need to help the LLM distinguish between stories andpast events, as well as being careful with verb tenses in prompts.Nevertheless, the results of this study highlight the efficiency and relevanceof using LLMs for cyber threat intelligence.</description><author>Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay</author><pubDate>Thu, 08 Aug 2024 12:31:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03354v2</guid></item><item><title>SynopGround: A Large-Scale Dataset for Multi-Paragraph Video Grounding from TV Dramas and Synopses</title><link>http://arxiv.org/abs/2408.01669v3</link><description>Video grounding is a fundamental problem in multimodal content understanding,aiming to localize specific natural language queries in an untrimmed video.However, current video grounding datasets merely focus on simple events and areeither limited to shorter videos or brief sentences, which hinders the modelfrom evolving toward stronger multimodal understanding capabilities. To addressthese limitations, we present a large-scale video grounding dataset namedSynopGround, in which more than 2800 hours of videos are sourced from popularTV dramas and are paired with accurately localized human-written synopses. Eachparagraph in the synopsis serves as a language query and is manually annotatedwith precise temporal boundaries in the long video. These paragraph queries aretightly correlated to each other and contain a wealth of abstract expressionssummarizing video storylines and specific descriptions portraying eventdetails, which enables the model to learn multimodal perception on moreintricate concepts over longer context dependencies. Based on the dataset, wefurther introduce a more complex setting of video grounding dubbedMulti-Paragraph Video Grounding (MPVG), which takes as input multipleparagraphs and a long video for grounding each paragraph query to its temporalinterval. In addition, we propose a novel Local-Global Multimodal Reasoner(LGMR) to explicitly model the local-global structures of long-term multimodalinputs for MPVG. Our method provides an effective baseline solution to themulti-paragraph video grounding problem. Extensive experiments verify theproposed model's effectiveness as well as its superiority in long-termmulti-paragraph video grounding over prior state-of-the-arts. Dataset and codeare publicly available. Project page: https://synopground.github.io/.</description><author>Chaolei Tan, Zihang Lin, Junfu Pu, Zhongang Qi, Wei-Yi Pei, Zhi Qu, Yexin Wang, Ying Shan, Wei-Shi Zheng, Jian-Fang Hu</author><pubDate>Thu, 08 Aug 2024 11:19:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01669v3</guid></item><item><title>CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging</title><link>http://arxiv.org/abs/2407.11652v6</link><description>Federated Learning (FL) offers a privacy-preserving approach to train modelson decentralized data. Its potential in healthcare is significant, butchallenges arise due to cross-client variations in medical image data,exacerbated by limited annotations. This paper introduces Cross-ClientVariations Adaptive Federated Learning (CCVA-FL) to address these issues.CCVA-FL aims to minimize cross-client variations by transforming images into acommon feature space. It involves expert annotation of a subset of images fromeach client, followed by the selection of a client with the least datacomplexity as the target. Synthetic medical images are then generated usingScalable Diffusion Models with Transformers (DiT) based on the target client'sannotated images. These synthetic images, capturing diversity and representingthe original data, are shared with other clients. Each client then translatesits local images into the target image space using image-to-image translation.The translated images are subsequently used in a federated learning setting todevelop a server model. Our results demonstrate that CCVA-FL outperformsVanilla Federated Averaging by effectively addressing data distributiondifferences across clients without compromising privacy.</description><author>Sunny Gupta, Amit Sethi</author><pubDate>Thu, 08 Aug 2024 08:44:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11652v6</guid></item><item><title>KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance</title><link>http://arxiv.org/abs/2408.02912v2</link><description>Online Imitation Learning methods struggle with the gap between extensiveonline exploration space and limited expert trajectories, which hinderefficient exploration due to inaccurate task-aware reward estimation. Inspiredby the findings from cognitive neuroscience that task decomposition couldfacilitate cognitive processing for efficient learning, we hypothesize that anagent could estimate precise task-aware imitation rewards for efficient onlineexploration by decomposing the target task into the objectives of "what to do"and the mechanisms of "how to do". In this work, we introduce the hybridKey-state guided Online Imitation (KOI) learning approach, which leverages theintegration of semantic and motion key states as guidance for task-aware rewardestimation. Initially, we utilize the visual-language models to segment theexpert trajectory into semantic key states, indicating the objectives of "whatto do". Within the intervals between semantic key states, optical flow isemployed to capture motion key states to understand the process of "how to do".By integrating a thorough grasp of both semantic and motion key states, werefine the trajectory-matching reward computation, encouraging task-awareexploration for efficient online imitation learning. Our experiment resultsprove that our method is more sample efficient in the Meta-World and LIBEROenvironments. We also conduct real-world robotic manipulation experiments tovalidate the efficacy of our method, demonstrating the practical applicabilityof our KOI method.</description><author>Jingxian Lu, Wenke Xia, Dong Wang, Zhigang Wang, Bin Zhao, Di Hu, Xuelong Li</author><pubDate>Thu, 08 Aug 2024 07:02:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02912v2</guid></item><item><title>Nighttime Pedestrian Detection Based on Fore-Background Contrast Learning</title><link>http://arxiv.org/abs/2408.03030v2</link><description>The significance of background information is frequently overlooked incontemporary research concerning channel attention mechanisms. This studyaddresses the issue of suboptimal single-spectral nighttime pedestriandetection performance under low-light conditions by incorporating backgroundinformation into the channel attention mechanism. Despite numerous studiesfocusing on the development of efficient channel attention mechanisms, therelevance of background information has been largely disregarded. By adopting acontrast learning approach, we reexamine channel attention with regard topedestrian objects and background information for nighttime pedestriandetection, resulting in the proposed Fore-Background Contrast Attention (FBCA).FBCA possesses two primary attributes: (1) channel descriptors form remotedependencies with global spatial feature information; (2) the integration ofbackground information enhances the distinction between channels concentratingon low-light pedestrian features and those focusing on background information.Consequently, the acquired channel descriptors exhibit a higher semantic leveland spatial accuracy. Experimental outcomes demonstrate that FBCA significantlyoutperforms existing methods in single-spectral nighttime pedestrian detection,achieving state-of-the-art results on the NightOwls and TJU-DHD-pedestriandatasets. Furthermore, this methodology also yields performance improvementsfor the multispectral LLVIP dataset. These findings indicate that integratingbackground information into the channel attention mechanism effectivelymitigates detector performance degradation caused by illumination factors innighttime scenarios.</description><author>He Yao, Yongjun Zhang, Huachun Jian, Li Zhang, Ruzhong Cheng</author><pubDate>Thu, 08 Aug 2024 06:32:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03030v2</guid></item><item><title>EXAONE 3.0 7.8B Instruction Tuned Language Model</title><link>http://arxiv.org/abs/2408.03541v2</link><description>We introduce EXAONE 3.0 instruction-tuned language model, the first openmodel in the family of Large Language Models (LLMs) developed by LG AIResearch. Among different model sizes, we publicly release the 7.8Binstruction-tuned model to promote open research and innovations. Throughextensive evaluations across a wide range of public and in-house benchmarks,EXAONE 3.0 demonstrates highly competitive real-world performance withinstruction-following capability against other state-of-the-art open models ofsimilar size. Our comparative analysis shows that EXAONE 3.0 excelsparticularly in Korean, while achieving compelling performance across generaltasks and complex reasoning. With its strong real-world effectiveness andbilingual proficiency, we hope that EXAONE keeps contributing to advancementsin Expert AI. Our EXAONE 3.0 instruction-tuned model is available athttps://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct</description><author>LG AI Research, :, Soyoung An, Kyunghoon Bae, Eunbi Choi, Stanley Jungkyu Choi, Yemuk Choi, Seokhee Hong, Yeonjung Hong, Junwon Hwang, Hyojin Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Yountae Jung, Euisoon Kim, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Moontae Lee, Seungjun Lee, Woohyung Lim, Sangha Park, Sooyoun Park, Yongmin Park, Boseong Seo, Sihoon Yang, Heuiyeen Yeen, Kyungjae Yoo, Hyeongu Yun</author><pubDate>Thu, 08 Aug 2024 04:35:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03541v2</guid></item><item><title>Exploring the extent of similarities in software failures across industries using LLMs</title><link>http://arxiv.org/abs/2408.03528v2</link><description>The rapid evolution of software development necessitates enhanced safetymeasures. Extracting information about software failures from companies isbecoming increasingly more available through news articles. This research utilizes the Failure Analysis Investigation with LLMs (FAIL)model to extract industry-specific information. Although the FAIL model'sdatabase is rich in information, it could benefit from further categorizationand industry-specific insights to further assist software engineers. In previous work news articles were collected from reputable sources andcategorized by incidents inside a database. Prompt engineering and LargeLanguage Models (LLMs) were then applied to extract relevant informationregarding the software failure. This research extends these methods bycategorizing articles into specific domains and types of software failures. Theresults are visually represented through graphs. The analysis shows that throughout the database some software failures occursignificantly more often in specific industries. This categorization provides avaluable resource for software engineers and companies to identify and addresscommon failures. This research highlights the synergy between software engineering and LargeLanguage Models (LLMs) to automate and enhance the analysis of softwarefailures. By transforming data from the database into an industry specificmodel, we provide a valuable resource that can be used to identify commonvulnerabilities, predict potential risks, and implement proactive measures forpreventing software failures. Leveraging the power of the current FAIL databaseand data visualization, we aim to provide an avenue for safer and more securesoftware in the future.</description><author>Martin Detloff</author><pubDate>Thu, 08 Aug 2024 03:52:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03528v2</guid></item><item><title>EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions</title><link>http://arxiv.org/abs/2402.17485v3</link><description>In this work, we tackle the challenge of enhancing the realism andexpressiveness in talking head video generation by focusing on the dynamic andnuanced relationship between audio cues and facial movements. We identify thelimitations of traditional techniques that often fail to capture the fullspectrum of human expressions and the uniqueness of individual facial styles.To address these issues, we propose EMO, a novel framework that utilizes adirect audio-to-video synthesis approach, bypassing the need for intermediate3D models or facial landmarks. Our method ensures seamless frame transitionsand consistent identity preservation throughout the video, resulting in highlyexpressive and lifelike animations. Experimental results demonsrate that EMO isable to produce not only convincing speaking videos but also singing videos invarious styles, significantly outperforming existing state-of-the-artmethodologies in terms of expressiveness and realism.</description><author>Linrui Tian, Qi Wang, Bang Zhang, Liefeng Bo</author><pubDate>Thu, 08 Aug 2024 03:48:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17485v3</guid></item><item><title>Compression-Realized Deep Structural Network for Video Quality Enhancement</title><link>http://arxiv.org/abs/2405.06342v3</link><description>This paper focuses on the task of quality enhancement for compressed videos.Although deep network-based video restorers achieve impressive progress, mostof the existing methods lack a structured design to optimally leverage thepriors within compression codecs. Since the quality degradation of the video isprimarily induced by the compression algorithm, a new paradigm is urgentlyneeded for a more ``conscious'' process of quality enhancement. As a result, wepropose the Compression-Realized Deep Structural Network (CRDS), introducingthree inductive biases aligned with the three primary processes in the classiccompression codec, merging the strengths of classical encoder architecture withdeep network capabilities. Inspired by the residual extraction and domaintransformation process in the codec, a pre-trained Latent Degradation ResidualAuto-Encoder is proposed to transform video frames into a latent feature space,and the mutual neighborhood attention mechanism is integrated for precisemotion estimation and residual extraction. Furthermore, drawing inspirationfrom the quantization noise distribution of the codec, CRDS proposes a novelProgressive Denoising framework with intermediate supervision that decomposesthe quality enhancement into a series of simpler denoising sub-tasks.Experimental results on datasets like LDV 2.0 and MFQE 2.0 indicate ourapproach surpasses state-of-the-art models.</description><author>Hanchi Sun, Xiaohong Liu, Xinyang Jiang, Yifei Shen, Dongsheng Li, Xiongkuo Min, Guangtao Zhai</author><pubDate>Thu, 08 Aug 2024 03:25:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06342v3</guid></item><item><title>GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI</title><link>http://arxiv.org/abs/2408.03361v2</link><description>Large Vision-Language Models (LVLMs) are capable of handling diverse datatypes such as imaging, text, and physiological signals, and can be applied invarious fields. In the medical field, LVLMs have a high potential to offersubstantial assistance for diagnosis and treatment. Before that, it is crucialto develop benchmarks to evaluate LVLMs' effectiveness in various medicalapplications. Current benchmarks are often built upon specific academicliterature, mainly focusing on a single domain, and lacking varying perceptualgranularities. Thus, they face specific challenges, including limited clinicalrelevance, incomplete evaluations, and insufficient guidance for interactiveLVLMs. To address these limitations, we developed the GMAI-MMBench, the mostcomprehensive general medical AI benchmark with well-categorized data structureand multi-perceptual granularity to date. It is constructed from 285 datasetsacross 39 medical image modalities, 18 clinical-related tasks, 18 departments,and 4 perceptual granularities in a Visual Question Answering (VQA) format.Additionally, we implemented a lexical tree structure that allows users tocustomize evaluation tasks, accommodating various assessment needs andsubstantially supporting medical AI research and applications. We evaluated 50LVLMs, and the results show that even the advanced GPT-4o only achieves anaccuracy of 52%, indicating significant room for improvement. Moreover, weidentified five key insufficiencies in current cutting-edge LVLMs that need tobe addressed to advance the development of better medical applications. Webelieve that GMAI-MMBench will stimulate the community to build the nextgeneration of LVLMs toward GMAI. Project Page: https://uni-medical.github.io/GMAI-MMBench.github.io/</description><author>Pengcheng Chen, Jin Ye, Guoan Wang, Yanjun Li, Zhongying Deng, Wei Li, Tianbin Li, Haodong Duan, Ziyan Huang, Yanzhou Su, Benyou Wang, Shaoting Zhang, Bin Fu, Jianfei Cai, Bohan Zhuang, Eric J Seibel, Junjun He, Yu Qiao</author><pubDate>Thu, 08 Aug 2024 02:43:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03361v2</guid></item><item><title>Advancing Prompt Learning through an External Layer</title><link>http://arxiv.org/abs/2407.19674v4</link><description>Prompt learning represents a promising method for adapting pre-trainedvision-language models (VLMs) to various downstream tasks by learning a set oftext embeddings. One challenge inherent to these methods is the poorgeneralization performance due to the invalidity of the learned text embeddingsfor unseen tasks. A straightforward approach to bridge this gap is to freezethe text embeddings in prompts, which results in a lack of capacity to adaptVLMs for downstream tasks. To address this dilemma, we propose a paradigmcalled EnPrompt with a novel External Layer (EnLa). Specifically, we propose atextual external layer and learnable visual embeddings for adapting VLMs todownstream tasks. The learnable external layer is built upon valid embeddingsof pre-trained CLIP. This design considers the balance of learning capabilitiesbetween the two branches. To align the textual and visual features, we proposea novel two-pronged approach: i) we introduce the optimal transport as thediscrepancy metric to align the vision and text modalities, and ii) weintroduce a novel strengthening feature to enhance the interaction betweenthese two modalities. Four representative experiments (i.e., base-to-novelgeneralization, few-shot learning, cross-dataset generalization, domain shiftsgeneralization) across 15 datasets demonstrate that our method outperforms theexisting prompt learning method.</description><author>Fangming Cui, Xun Yang, Chao Wu, Liang Xiao, Xinmei Tian</author><pubDate>Thu, 08 Aug 2024 02:39:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19674v4</guid></item><item><title>NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time</title><link>http://arxiv.org/abs/2408.03675v2</link><description>Large Language Models (LLMs) have ignited an innovative surge of AIapplications, marking a new era of exciting possibilities equipped withextended context windows. However, hosting these models is cost-prohibitivemainly due to the extensive memory consumption of KV Cache involvinglong-context modeling. Despite several works proposing to evict unnecessarytokens from the KV Cache, most of them rely on the biased local statistics ofaccumulated attention scores and report performance using unconvincing metriclike perplexity on inadequate short-text evaluation. In this paper, we proposeNACL, a general framework for long-context KV cache eviction that achieves moreoptimal and efficient eviction in a single operation during the encoding phase.Due to NACL's efficiency, we combine more accurate attention score statisticsin PROXY TOKENS EVICTION with the diversified random eviction strategy ofRANDOM EVICTION, aiming to alleviate the issue of attention bias and enhancethe robustness in maintaining pivotal tokens for long-context modeling tasks.Notably, our method significantly improves the performance on short- andlong-text tasks by 80% and 76% respectively, reducing KV Cache by up to 50%with over 95% performance maintenance. The code is available athttps://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2024-NACL.</description><author>Yilong Chen, Guoxia Wang, Junyuan Shang, Shiyao Cui, Zhenyu Zhang, Tingwen Liu, Shuohuan Wang, Yu Sun, Dianhai Yu, Hua Wu</author><pubDate>Thu, 08 Aug 2024 01:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03675v2</guid></item><item><title>PAGED: A Benchmark for Procedural Graphs Extraction from Documents</title><link>http://arxiv.org/abs/2408.03630v2</link><description>Automatic extraction of procedural graphs from documents creates a low-costway for users to easily understand a complex procedure by skimming visualgraphs. Despite the progress in recent studies, it remains unanswered: whetherthe existing studies have well solved this task (Q1) and whether the emerginglarge language models (LLMs) can bring new opportunities to this task (Q2). Tothis end, we propose a new benchmark PAGED, equipped with a large high-qualitydataset and standard evaluations. It investigates five state-of-the-artbaselines, revealing that they fail to extract optimal procedural graphs wellbecause of their heavy reliance on hand-written rules and limited availabledata. We further involve three advanced LLMs in PAGED and enhance them with anovel self-refine strategy. The results point out the advantages of LLMs inidentifying textual elements and their gaps in building logical structures. Wehope PAGED can serve as a major landmark for automatic procedural graphextraction and the investigations in PAGED can offer insights into the researchon logic reasoning among non-sequential elements.</description><author>Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei</author><pubDate>Thu, 08 Aug 2024 01:19:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03630v2</guid></item><item><title>CARE: A Clue-guided Assistant for CSRs to Read User Manuals</title><link>http://arxiv.org/abs/2408.03633v2</link><description>It is time-saving to build a reading assistant for customer servicerepresentations (CSRs) when reading user manuals, especially information-richones. Current solutions don't fit the online custom service scenarios well dueto the lack of attention to user questions and possible responses. Hence, wepropose to develop a time-saving and careful reading assistant for CSRs, namedCARE. It can help the CSRs quickly find proper responses from the user manualsvia explicit clue chains. Specifically, each of the clue chains is formed byinferring over the user manuals, starting from the question clue aligned withthe user question and ending at a possible response. To overcome the shortageof supervised data, we adopt the self-supervised strategy for model learning.The offline experiment shows that CARE is efficient in automatically inferringaccurate responses from the user manual. The online experiment furtherdemonstrates the superiority of CARE to reduce CSRs' reading burden and keephigh service quality, in particular with &gt;35% decrease in time spent andkeeping a &gt;0.75 ICC score.</description><author>Weihong Du, Jia Liu, Zujie Wen, Dingnan Jin, Hongru Liang, Wenqiang Lei</author><pubDate>Thu, 08 Aug 2024 01:17:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03633v2</guid></item><item><title>Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval</title><link>http://arxiv.org/abs/2408.02964v2</link><description>Large language models (LLMs) are fundamentally transforming human-facingapplications in the health and well-being domains: boosting patient engagement,accelerating clinical decision-making, and facilitating medical education.Although state-of-the-art LLMs have shown superior performance in severalconversational applications, evaluations within nutrition and diet applicationsare still insufficient. In this paper, we propose to employ the RegisteredDietitian (RD) exam to conduct a standard and comprehensive evaluation ofstate-of-the-art LLMs, GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro, assessingboth accuracy and consistency in nutrition queries. Our evaluation includes1050 RD exam questions encompassing several nutrition topics and proficiencylevels. In addition, for the first time, we examine the impact of Zero-Shot(ZS), Chain of Thought (CoT), Chain of Thought with Self Consistency (CoT-SC),and Retrieval Augmented Prompting (RAP) on both accuracy and consistency of theresponses. Our findings revealed that while these LLMs obtained acceptableoverall performance, their results varied considerably with different promptsand question domains. GPT-4o with CoT-SC prompting outperformed the otherapproaches, whereas Gemini 1.5 Pro with ZS recorded the highest consistency.For GPT-4o and Claude 3.5, CoT improved the accuracy, and CoT-SC improved bothaccuracy and consistency. RAP was particularly effective for GPT-4o to answerExpert level questions. Consequently, choosing the appropriate LLM andprompting technique, tailored to the proficiency level and specific domain, canmitigate errors and potential risks in diet and nutrition chatbots.</description><author>Iman Azimi, Mohan Qi, Li Wang, Amir M. Rahmani, Youlin Li</author><pubDate>Wed, 07 Aug 2024 18:50:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02964v2</guid></item><item><title>How Well Can Vision Language Models See Image Details?</title><link>http://arxiv.org/abs/2408.03940v1</link><description>Large Language Model-based Vision-Language Models (LLM-based VLMs) havedemonstrated impressive results in various vision-language understanding tasks.However, how well these VLMs can see image detail beyond the semantic levelremains unclear. In our study, we introduce a pixel value prediction task (PVP)to explore "How Well Can Vision Language Models See Image Details?" and toassist VLMs in perceiving more details. Typically, these models comprise afrozen CLIP visual encoder, a large language model, and a connecting module.After fine-tuning VLMs on the PVP task, we find: 1) existing VLMs struggle topredict precise pixel values by only fine-tuning the connection module and LLM;and 2) prediction precision is significantly improved when the vision encoderis also adapted. Additionally, our research reveals that incorporating pixelvalue prediction as one of the VLM pre-training tasks and vision encoderadaptation markedly boosts VLM performance on downstream image-languageunderstanding tasks requiring detailed image perception, such as referringimage segmentation (with an average +10.19 cIoU improvement) and video gamedecision making (with average score improvements of +80.34 and +70.54 on twogames, respectively).</description><author>Chenhui Gou, Abdulwahab Felemban, Faizan Farooq Khan, Deyao Zhu, Jianfei Cai, Hamid Rezatofighi, Mohamed Elhoseiny</author><pubDate>Wed, 07 Aug 2024 17:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03940v1</guid></item><item><title>SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature</title><link>http://arxiv.org/abs/2408.03936v1</link><description>Natural language processing (NLP) has seen significant advancements with theadvent of large language models (LLMs). However, substantial improvements arestill needed for languages other than English, especially for specific domainslike the applications of Mercosur Common Nomenclature (NCM), a BrazilianHarmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, afoundational Portuguese LLM, as an LLM source to implement the NCM applicationprocessing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)technique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.This approach retains the chain-of-thought (CoT) methodology for promptdevelopment in a more concise and streamlined manner, utilizing brief andfocused documents for training. The proposed model demonstrates an efficientand cost-effective alternative for fine-tuning smaller LLMs, significantlyoutperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although theresearch focuses on NCM applications, the methodology can be easily adapted forHS applications worldwide.</description><author>Vinícius Di Oliveira, Yuri Façanha Bezerra, Li Weigang, Pedro Carvalho Brom, Victor Rafael R. Celestino</author><pubDate>Wed, 07 Aug 2024 17:54:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03936v1</guid></item><item><title>From Words to Worth: Newborn Article Impact Prediction with LLM</title><link>http://arxiv.org/abs/2408.03934v1</link><description>As the academic landscape expands, the challenge of efficiently identifyingpotentially high-impact articles among the vast number of newly published worksbecomes critical. This paper introduces a promising approach, leveraging thecapabilities of fine-tuned LLMs to predict the future impact of newbornarticles solely based on titles and abstracts. Moving beyond traditionalmethods heavily reliant on external information, the proposed method discernsthe shared semantic features of highly impactful papers from a large collectionof title-abstract and potential impact pairs. These semantic features arefurther utilized to regress an improved metric, TNCSI_SP, which has beenendowed with value, field, and time normalization properties. Additionally, acomprehensive dataset has been constructed and released for fine-tuning theLLM, containing over 12,000 entries with corresponding titles, abstracts, andTNCSI_SP. The quantitative results, with an NDCG@20 of 0.901, demonstrate thatthe proposed approach achieves state-of-the-art performance in predicting theimpact of newborn articles when compared to competitive counterparts. Finally,we demonstrate a real-world application for predicting the impact of newbornjournal articles to demonstrate its noteworthy practical value. Overall, ourfindings challenge existing paradigms and propose a shift towards a morecontent-focused prediction of academic impact, offering new insights forassessing newborn article impact.</description><author>Penghai Zhao, Qinghua Xing, Kairan Dou, Jinyu Tian, Ying Tai, Jian Yang, Ming-Ming Cheng, Xiang Li</author><pubDate>Wed, 07 Aug 2024 17:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03934v1</guid></item><item><title>Open-Set Multivariate Time-Series Anomaly Detection</title><link>http://arxiv.org/abs/2310.12294v3</link><description>Numerous methods for time-series anomaly detection (TSAD) have emerged inrecent years, most of which are unsupervised and assume that only normalsamples are available during the training phase, due to the challenge ofobtaining abnormal data in real-world scenarios. Still, limited samples ofabnormal data are often available, albeit they are far from representative ofall possible anomalies. Supervised methods can be utilized to classify normaland seen anomalies, but they tend to overfit to the seen anomalies presentduring training, hence, they fail to generalize to unseen anomalies. We proposethe first algorithm to address the open-set TSAD problem, called MultivariateOpen-Set Time-Series Anomaly Detector (MOSAD), that leverages only a few shotsof labeled anomalies during the training phase in order to achieve superioranomaly detection performance compared to both supervised and unsupervised TSADalgorithms. MOSAD is a novel multi-head TSAD framework with a sharedrepresentation space and specialized heads, including the Generative head, theDiscriminative head, and the Anomaly-Aware Contrastive head. The latterproduces a superior representation space for anomaly detection compared toconventional supervised contrastive learning. Extensive experiments on threereal-world datasets establish MOSAD as a new state-of-the-art in the TSADfield.</description><author>Thomas Lai, Thi Kieu Khanh Ho, Narges Armanfard</author><pubDate>Wed, 07 Aug 2024 17:46:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12294v3</guid></item><item><title>Advancing Prompt Learning through an External Layer</title><link>http://arxiv.org/abs/2407.19674v3</link><description>Prompt learning represents a promising method for adapting pre-trainedvision-language models (VLMs) to various downstream tasks by learning a set oftext embeddings. One challenge inherent to these methods is the poorgeneralization performance due to the invalidity of the learned text embeddingsfor unseen tasks. A straightforward approach to bridge this gap is to freezethe text embeddings in prompts, which results in a lack of capacity to adaptVLMs for downstream tasks. To address this dilemma, we propose a paradigmcalled EnPrompt with a novel External Layer (EnLa). Specifically, we propose atextual external layer and learnable visual embeddings for adapting VLMs todownstream tasks. The learnable external layer is built upon valid embeddingsof pre-trained CLIP. This design considers the balance of learning capabilitiesbetween the two branches. To align the textual and visual features, we proposea novel two-pronged approach: i) we introduce the optimal transport as thediscrepancy metric to align the vision and text modalities, and ii) weintroduce a novel strengthening feature to enhance the interaction betweenthese two modalities. Four representative experiments (i.e., base-to-novelgeneralization, few-shot learning, cross-dataset generalization, domain shiftsgeneralization) across 15 datasets demonstrate that our method outperforms theexisting prompt learning method.</description><author>Fangming Cui, Xun Yang, Chao Wu, Liang Xiao, Xinmei Tian</author><pubDate>Wed, 07 Aug 2024 17:45:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19674v3</guid></item><item><title>Fast Sprite Decomposition from Animated Graphics</title><link>http://arxiv.org/abs/2408.03923v1</link><description>This paper presents an approach to decomposing animated graphics intosprites, a set of basic elements or layers. Our approach builds on theoptimization of sprite parameters to fit the raster video. For efficiency, weassume static textures for sprites to reduce the search space while preventingartifacts using a texture prior model. To further speed up the optimization, weintroduce the initialization of the sprite parameters utilizing a pre-trainedvideo object segmentation model and user input of single frame annotations. Forour study, we construct the Crello Animation dataset from an online designservice and define quantitative metrics to measure the quality of the extractedsprites. Experiments show that our method significantly outperforms baselinesfor similar decomposition tasks in terms of the quality/efficiency tradeoff.</description><author>Tomoyuki Suzuki, Kotaro Kikuchi, Kota Yamaguchi</author><pubDate>Wed, 07 Aug 2024 17:30:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03923v1</guid></item><item><title>FourierMamba: Fourier Learning Integration with State Space Models for Image Deraining</title><link>http://arxiv.org/abs/2405.19450v2</link><description>Image deraining aims to remove rain streaks from rainy images and restoreclear backgrounds. Currently, some research that employs the Fourier transformhas proved to be effective for image deraining, due to it acting as aneffective frequency prior for capturing rain streaks. However, despite thereexists dependency of low frequency and high frequency in images, theseFourier-based methods rarely exploit the correlation of different frequenciesfor conjuncting their learning procedures, limiting the full utilization offrequency information for image deraining. Alternatively, the recently emergedMamba technique depicts its effectiveness and efficiency for modelingcorrelation in various domains (e.g., spatial, temporal), and we argue thatintroducing Mamba into its unexplored Fourier spaces to correlate differentfrequencies would help improve image deraining. This motivates us to propose anew framework termed FourierMamba, which performs image deraining with Mamba inthe Fourier space. Owning to the unique arrangement of frequency orders inFourier space, the core of FourierMamba lies in the scanning encoding ofdifferent frequencies, where the low-high frequency order formats exhibitdifferently in the spatial dimension (unarranged in axis) and channel dimension(arranged in axis). Therefore, we design FourierMamba that correlates Fourierspace information in the spatial and channel dimensions with distinct designs.Specifically, in the spatial dimension Fourier space, we introduce the zigzagcoding to scan the frequencies to rearrange the orders from low to highfrequencies, thereby orderly correlating the connections between frequencies;in the channel dimension Fourier space with arranged orders of frequencies inaxis, we can directly use Mamba to perform frequency correlation and improvethe channel information representation.</description><author>Dong Li, Yidi Liu, Xueyang Fu, Senyan Xu, Zheng-Jun Zha</author><pubDate>Wed, 07 Aug 2024 17:30:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19450v2</guid></item><item><title>FMiFood: Multi-modal Contrastive Learning for Food Image Classification</title><link>http://arxiv.org/abs/2408.03922v1</link><description>Food image classification is the fundamental step in image-based dietaryassessment, which aims to estimate participants' nutrient intake from eatingoccasion images. A common challenge of food images is the intra-class diversityand inter-class similarity, which can significantly hinder classificationperformance. To address this issue, we introduce a novel multi-modalcontrastive learning framework called FMiFood, which learns more discriminativefeatures by integrating additional contextual information, such as foodcategory text descriptions, to enhance classification accuracy. Specifically,we propose a flexible matching technique that improves the similarity matchingbetween text and image embeddings to focus on multiple key information.Furthermore, we incorporate the classification objectives into the frameworkand explore the use of GPT-4 to enrich the text descriptions and provide moredetailed context. Our method demonstrates improved performance on both theUPMC-101 and VFN datasets compared to existing methods.</description><author>Xinyue Pan, Jiangpeng He, Fengqing Zhu</author><pubDate>Wed, 07 Aug 2024 17:29:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03922v1</guid></item><item><title>Hard to Explain: On the Computational Hardness of In-Distribution Model Interpretation</title><link>http://arxiv.org/abs/2408.03915v1</link><description>The ability to interpret Machine Learning (ML) models is becomingincreasingly essential. However, despite significant progress in the field,there remains a lack of rigorous characterization regarding the innateinterpretability of different models. In an attempt to bridge this gap, recentwork has demonstrated that it is possible to formally assess interpretabilityby studying the computational complexity of explaining the decisions of variousmodels. In this setting, if explanations for a particular model can be obtainedefficiently, the model is considered interpretable (since it can be explained``easily''). However, if generating explanations over an ML model iscomputationally intractable, it is considered uninterpretable. Prior researchidentified two key factors that influence the complexity of interpreting an MLmodel: (i) the type of the model (e.g., neural networks, decision trees, etc.);and (ii) the form of explanation (e.g., contrastive explanations, Shapleyvalues, etc.). In this work, we claim that a third, important factor must alsobe considered for this analysis -- the underlying distribution over which theexplanation is obtained. Considering the underlying distribution is key inavoiding explanations that are socially misaligned, i.e., convey informationthat is biased and unhelpful to users. We demonstrate the significant influenceof the underlying distribution on the resulting overall interpretationcomplexity, in two settings: (i) prediction models paired with an externalout-of-distribution (OOD) detector; and (ii) prediction models designed toinherently generate socially aligned explanations. Our findings prove that theexpressiveness of the distribution can significantly influence the overallcomplexity of interpretation, and identify essential prerequisites that a modelmust possess to generate socially aligned explanations.</description><author>Guy Amir, Shahaf Bassan, Guy Katz</author><pubDate>Wed, 07 Aug 2024 17:20:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03915v1</guid></item><item><title>AdapMTL: Adaptive Pruning Framework for Multitask Learning Model</title><link>http://arxiv.org/abs/2408.03913v1</link><description>In the domain of multimedia and multimodal processing, the efficient handlingof diverse data streams such as images, video, and sensor data is paramount.Model compression and multitask learning (MTL) are crucial in this field,offering the potential to address the resource-intensive demands of processingand interpreting multiple forms of media simultaneously. However, effectivelycompressing a multitask model presents significant challenges due to thecomplexities of balancing sparsity allocation and accuracy performance acrossmultiple tasks. To tackle these challenges, we propose AdapMTL, an adaptivepruning framework for MTL models. AdapMTL leverages multiple learnable softthresholds independently assigned to the shared backbone and the task-specificheads to capture the nuances in different components' sensitivity to pruning.During training, it co-optimizes the soft thresholds and MTL model weights toautomatically determine the suitable sparsity level at each component toachieve both high task accuracy and high overall sparsity. It furtherincorporates an adaptive weighting mechanism that dynamically adjusts theimportance of task-specific losses based on each task's robustness to pruning.We demonstrate the effectiveness of AdapMTL through comprehensive experimentson popular multitask datasets, namely NYU-v2 and Tiny-Taskonomy, with differentarchitectures, showcasing superior performance compared to state-of-the-artpruning methods.</description><author>Mingcan Xiang, Steven Jiaxun Tang, Qizheng Yang, Hui Guan, Tongping Liu</author><pubDate>Wed, 07 Aug 2024 17:19:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03913v1</guid></item><item><title>CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases</title><link>http://arxiv.org/abs/2408.03910v1</link><description>Large Language Models (LLMs) excel in stand-alone code tasks like HumanEvaland MBPP, but struggle with handling entire code repositories. This challengehas prompted research on enhancing LLM-codebase interaction at a repositoryscale. Current solutions rely on similarity-based retrieval or manual tools andAPIs, each with notable drawbacks. Similarity-based retrieval often has lowrecall in complex tasks, while manual tools and APIs are typicallytask-specific and require expert knowledge, reducing their generalizabilityacross diverse code tasks and real-world applications. To mitigate theselimitations, we introduce \framework, a system that integrates LLM agents withgraph database interfaces extracted from code repositories. By leveraging thestructural properties of graph databases and the flexibility of the graph querylanguage, \framework enables the LLM agent to construct and execute queries,allowing for precise, code structure-aware context retrieval and codenavigation. We assess \framework using three benchmarks: CrossCodeEval,SWE-bench, and EvoCodeBench. Additionally, we develop five real-world codingapplications. With a unified graph database schema, \framework demonstratescompetitive performance and potential in both academic and real-worldenvironments, showcasing its versatility and efficacy in software engineering.Our application demo:https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.</description><author>Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Wenmeng Zhou, Fei Wang, Michael Shieh</author><pubDate>Wed, 07 Aug 2024 17:13:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03910v1</guid></item><item><title>LaFA: Latent Feature Attacks on Non-negative Matrix Factorization</title><link>http://arxiv.org/abs/2408.03909v1</link><description>As Machine Learning (ML) applications rapidly grow, concerns aboutadversarial attacks compromising their reliability have gained significantattention. One unsupervised ML method known for its resilience to such attacksis Non-negative Matrix Factorization (NMF), an algorithm that decomposes inputdata into lower-dimensional latent features. However, the introduction ofpowerful computational tools such as Pytorch enables the computation ofgradients of the latent features with respect to the original data, raisingconcerns about NMF's reliability. Interestingly, naively deriving theadversarial loss for NMF as in the case of ML would result in thereconstruction loss, which can be shown theoretically to be an ineffectiveattacking objective. In this work, we introduce a novel class of attacks in NMFtermed Latent Feature Attacks (LaFA), which aim to manipulate the latentfeatures produced by the NMF process. Our method utilizes the Feature Error(FE) loss directly on the latent features. By employing FE loss, we generateperturbations in the original data that significantly affect the extractedlatent features, revealing vulnerabilities akin to those found in other MLtechniques. To handle large peak-memory overhead from gradient back-propagationin FE attacks, we develop a method based on implicit differentiation whichenables their scaling to larger datasets. We validate NMF vulnerabilities andFE attacks effectiveness through extensive experiments on synthetic andreal-world data.</description><author>Minh Vu, Ben Nebgen, Erik Skau, Geigh Zollicoffer, Juan Castorena, Kim Rasmussen, Boian Alexandrov, Manish Bhattarai</author><pubDate>Wed, 07 Aug 2024 17:13:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03909v1</guid></item><item><title>Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models</title><link>http://arxiv.org/abs/2408.03907v1</link><description>Large Language Models (LLMs) have excelled at language understanding andgenerating human-level text. However, even with supervised training and humanalignment, these LLMs are susceptible to adversarial attacks where malicioususers can prompt the model to generate undesirable text. LLMs also inherentlyencode potential biases that can cause various harmful effects duringinteractions. Bias evaluation metrics lack standards as well as consensus andexisting methods often rely on human-generated templates and annotations whichare expensive and labor intensive. In this work, we train models toautomatically create adversarial prompts to elicit biased responses from targetLLMs. We present LLM- based bias evaluation metrics and also analyze severalexisting automatic evaluation methods and metrics. We analyze the variousnuances of model responses, identify the strengths and weaknesses of modelfamilies, and assess where evaluation methods fall short. We compare thesemetrics to human evaluation and validate that the LLM-as-a-Judge metric alignswith human judgement on bias in response generation.</description><author>Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman</author><pubDate>Wed, 07 Aug 2024 17:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03907v1</guid></item><item><title>Generative Adversarial Models for Extreme Geospatial Downscaling</title><link>http://arxiv.org/abs/2402.14049v2</link><description>Addressing the challenges of climate change requires accurate andhigh-resolution mapping of geospatial data, especially climate and weathervariables. However, many existing geospatial datasets, such as the griddedoutputs of the state-of-the-art numerical climate models (e.g., generalcirculation models), are only available at very coarse spatial resolutions dueto the model complexity and extremely high computational demand.Deep-learning-based methods, particularly generative adversarial networks(GANs) and their variants, have proved effective for refining natural imagesand have shown great promise in improving geospatial datasets. This paperdescribes a conditional GAN-based stochastic geospatial downscaling method thatcan accommodates very high scaling factors. Compared to most existing methods,the method can generate high-resolution accurate climate datasets from verylow-resolution inputs. More importantly, the method explicitly considers theuncertainty inherent to the downscaling process that tends to be ignored inexisting methods. Given an input, the method can produce a multitude ofplausible high-resolution samples instead of one single deterministic result.These samples allow for an empirical exploration and inferences of modeluncertainty and robustness. With a case study of gridded climate datasets (windvelocity and solar irradiance), we demonstrate the performances of theframework in downscaling tasks with large scaling factors (up to $64\times$)and highlight the advantages of the framework with a comprehensive comparisonwith commonly used and most recent downscaling methods, including area-to-point(ATP) kriging, deep image prior (DIP), enhanced super-resolution generativeadversarial networks (ESRGAN), physics-informed resolution-enhancing GAN (PhIREGAN), and an efficient diffusion model for remote sensing imagesuper-resolution (EDiffSR).</description><author>Guiye Li, Guofeng Cao</author><pubDate>Wed, 07 Aug 2024 17:09:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14049v2</guid></item><item><title>Lightweight Video Denoising Using a Classic Bayesian Backbone</title><link>http://arxiv.org/abs/2408.03904v1</link><description>In recent years, state-of-the-art image and video denoising networks havebecome increasingly large, requiring millions of trainable parameters toachieve best-in-class performance. Improved denoising quality has come at thecost of denoising speed, where modern transformer networks are far slower torun than smaller denoising networks such as FastDVDnet and classic Bayesiandenoisers such as the Wiener filter. In this paper, we implement a hybrid Wiener filter which leverages smallancillary networks to increase the original denoiser performance, whileretaining fast denoising speeds. These networks are used to refine the Wienercoring estimate, optimise windowing functions and estimate the unknown noiseprofile. Using these methods, we outperform several popular denoisers andremain within 0.2 dB, on average, of the popular VRT transformer. Our methodwas found to be over x10 faster than the transformer method, with a far lowerparameter cost.</description><author>Clément Bled, François Pitié</author><pubDate>Wed, 07 Aug 2024 17:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03904v1</guid></item><item><title>ESP-MedSAM: Efficient Self-Prompting SAM for Universal Image Segmentation</title><link>http://arxiv.org/abs/2407.14153v2</link><description>The Segment Anything Model (SAM) has demonstrated outstanding adaptation tomedical image segmentation but still faces three major challenges. Firstly, thehuge computational costs of SAM limit its real-world applicability. Secondly,SAM depends on manual annotations (e.g., points, boxes) as prompts, which arelaborious and impractical in clinical scenarios. Thirdly, SAM handles allsegmentation targets equally, which is suboptimal for diverse medicalmodalities with inherent heterogeneity. To address these issues, we propose anEfficient Self-Prompting SAM for universal medical image segmentation, namedESP-MedSAM. We devise a Multi-Modal Decoupled Knowledge Distillation (MMDKD)strategy to distil common image knowledge and domain-specific medical knowledgefrom the foundation model to train a lightweight image encoder and a modalitycontroller. Further, they combine with the additionally introduced Self-PatchPrompt Generator (SPPG) and Query-Decoupled Modality Decoder (QDMD) toconstruct ESP-MedSAM. Specifically, SPPG aims to generate a set of patchprompts automatically and QDMD leverages a one-to-one strategy to provide anindependent decoding channel for every modality. Extensive experiments indicatethat ESP-MedSAM outperforms state-of-the-arts in diverse medical imagingsegmentation takes, displaying superior zero-shot learning and modalitytransfer ability. Especially, our framework uses only 31.4% parameters comparedto SAM-Base.</description><author>Qing Xu, Jiaxuan Li, Xiangjian He, Ziyu Liu, Zhen Chen, Wenting Duan, Chenxin Li, Maggie M. He, Fiseha B. Tesema, Wooi P. Cheah, Yi Wang, Rong Qu, Jonathan M. Garibaldi</author><pubDate>Wed, 07 Aug 2024 17:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14153v2</guid></item><item><title>UniTraj: A Unified Framework for Scalable Vehicle Trajectory Prediction</title><link>http://arxiv.org/abs/2403.15098v3</link><description>Vehicle trajectory prediction has increasingly relied on data-drivensolutions, but their ability to scale to different data domains and the impactof larger dataset sizes on their generalization remain under-explored. Whilethese questions can be studied by employing multiple datasets, it ischallenging due to several discrepancies, e.g., in data formats, mapresolution, and semantic annotation types. To address these challenges, weintroduce UniTraj, a comprehensive framework that unifies various datasets,models, and evaluation criteria, presenting new opportunities for the vehicletrajectory prediction field. In particular, using UniTraj, we conduct extensiveexperiments and find that model performance significantly drops whentransferred to other datasets. However, enlarging data size and diversity cansubstantially improve performance, leading to a new state-of-the-art result forthe nuScenes dataset. We provide insights into dataset characteristics toexplain these findings. The code can be found here:https://github.com/vita-epfl/UniTraj</description><author>Lan Feng, Mohammadhossein Bahari, Kaouther Messaoud Ben Amor, Éloi Zablocki, Matthieu Cord, Alexandre Alahi</author><pubDate>Wed, 07 Aug 2024 17:03:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15098v3</guid></item><item><title>Subjective-Aligned Dataset and Metric for Text-to-Video Quality Assessment</title><link>http://arxiv.org/abs/2403.11956v5</link><description>With the rapid development of generative models, ArtificialIntelligence-Generated Contents (AIGC) have exponentially increased in dailylives. Among them, Text-to-Video (T2V) generation has received widespreadattention. Though many T2V models have been released for generating highperceptual quality videos, there is still lack of a method to evaluate thequality of these videos quantitatively. To solve this issue, we establish thelargest-scale Text-to-Video Quality Assessment DataBase (T2VQA-DB) to date. Thedataset is composed of 10,000 videos generated by 9 different T2V models. Wealso conduct a subjective study to obtain each video's corresponding meanopinion score. Based on T2VQA-DB, we propose a novel transformer-based modelfor subjective-aligned Text-to-Video Quality Assessment (T2VQA). The modelextracts features from text-video alignment and video fidelity perspectives,then it leverages the ability of a large language model to give the predictionscore. Experimental results show that T2VQA outperforms existing T2V metricsand SOTA video quality assessment models. Quantitative analysis indicates thatT2VQA is capable of giving subjective-align predictions, validating itseffectiveness. The dataset and code will be released athttps://github.com/QMME/T2VQA.</description><author>Tengchuan Kou, Xiaohong Liu, Zicheng Zhang, Chunyi Li, Haoning Wu, Xiongkuo Min, Guangtao Zhai, Ning Liu</author><pubDate>Wed, 07 Aug 2024 17:02:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11956v5</guid></item><item><title>LiNR: Model Based Neural Retrieval on GPUs at LinkedIn</title><link>http://arxiv.org/abs/2407.13218v3</link><description>This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrievalsystem. LiNR supports a billion-sized index on GPU models. We discuss ourexperiences and challenges in creating scalable, differentiable search indexesusing TensorFlow and PyTorch at production scale. In LiNR, both items and modelweights are integrated into the model binary. Viewing index construction as aform of model training, we describe scaling our system for large indexes,incorporating full scans and efficient filtering. A key focus is on enablingattribute-based pre-filtering for exhaustive GPU searches, addressing thecommon challenge of post-filtering in KNN searches that often reduces systemquality. We further provide multi-embedding retrieval algorithms and strategiesfor tackling cold start issues in retrieval. Our advancements in supportinglarger indexes through quantization are also discussed. We believe LiNRrepresents one of the industry's first Live-updated model-based retrievalindexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNRhas contributed to a 3% relative increase in professional daily active users.We envisage LiNR as a step towards integrating retrieval and ranking into asingle GPU model, simplifying complex infrastructures and enabling end-to-endoptimization of the entire differentiable infrastructure through gradientdescent.</description><author>Fedor Borisyuk, Qingquan Song, Mingzhou Zhou, Ganesh Parameswaran, Madhu Arun, Siva Popuri, Tugrul Bingol, Zhuotao Pei, Kuang-Hsuan Lee, Lu Zheng, Qizhan Shao, Ali Naqvi, Sen Zhou, Aman Gupta</author><pubDate>Wed, 07 Aug 2024 16:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13218v3</guid></item><item><title>Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond</title><link>http://arxiv.org/abs/2408.03900v1</link><description>We present Speech-MASSIVE, a multilingual Spoken Language Understanding (SLU)dataset comprising the speech counterpart for a portion of the MASSIVE textualcorpus. Speech-MASSIVE covers 12 languages from different families and inheritsfrom MASSIVE the annotations for the intent prediction and slot-filling tasks.Our extension is prompted by the scarcity of massively multilingual SLUdatasets and the growing need for versatile speech datasets to assessfoundation models (LLMs, speech encoders) across languages and tasks. Weprovide a multimodal, multitask, multilingual dataset and report SLU baselinesusing both cascaded and end-to-end architectures in various training scenarios(zero-shot, few-shot, and full fine-tune). Furthermore, we demonstrate thesuitability of Speech-MASSIVE for benchmarking other tasks such as speechtranscription, language identification, and speech translation. The dataset,models, and code are publicly available at:https://github.com/hlt-mt/Speech-MASSIVE</description><author>Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier</author><pubDate>Wed, 07 Aug 2024 16:55:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03900v1</guid></item><item><title>Simplifying Scholarly Abstracts for Accessible Digital Libraries</title><link>http://arxiv.org/abs/2408.03899v1</link><description>Standing at the forefront of knowledge dissemination, digital librariescurate vast collections of scientific literature. However, these scholarlywritings are often laden with jargon and tailored for domain experts ratherthan the general public. As librarians, we strive to offer services to adiverse audience, including those with lower reading levels. To extend ourservices beyond mere access, we propose fine-tuning a language model to rewritescholarly abstracts into more comprehensible versions, thereby making scholarlyliterature more accessible when requested. We began by introducing a corpusspecifically designed for training models to simplify scholarly abstracts. Thiscorpus consists of over three thousand pairs of abstracts and significancestatements from diverse disciplines. We then fine-tuned four language modelsusing this corpus. The outputs from the models were subsequently examined bothquantitatively for accessibility and semantic coherence, and qualitatively forlanguage quality, faithfulness, and completeness. Our findings show that theresulting models can improve readability by over three grade levels, whilemaintaining fidelity to the original content. Although commercialstate-of-the-art models still hold an edge, our models are much more compact,can be deployed locally in an affordable manner, and alleviate the privacyconcerns associated with using commercial models. We envision this work as astep toward more inclusive and accessible libraries, improving our services foryoung readers and those without a college degree.</description><author>Haining Wang, Jason Clark</author><pubDate>Wed, 07 Aug 2024 16:55:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03899v1</guid></item><item><title>Algorithmic Collective Action in Machine Learning</title><link>http://arxiv.org/abs/2302.04262v3</link><description>We initiate a principled study of algorithmic collective action on digitalplatforms that deploy machine learning algorithms. We propose a simpletheoretical model of a collective interacting with a firm's learning algorithm.The collective pools the data of participating individuals and executes analgorithmic strategy by instructing participants how to modify their own datato achieve a collective goal. We investigate the consequences of this model inthree fundamental learning-theoretic settings: the case of a nonparametricoptimal learning algorithm, a parametric risk minimizer, and gradient-basedoptimization. In each setting, we come up with coordinated algorithmicstrategies and characterize natural success criteria as a function of thecollective's size. Complementing our theory, we conduct systematic experimentson a skill classification task involving tens of thousands of resumes from agig platform for freelancers. Through more than two thousand model trainingruns of a BERT-like language model, we see a striking correspondence emergebetween our empirical observations and the predictions made by our theory.Taken together, our theory and experiments broadly support the conclusion thatalgorithmic collectives of exceedingly small fractional size can exertsignificant control over a platform's learning algorithm.</description><author>Moritz Hardt, Eric Mazumdar, Celestine Mendler-Dünner, Tijana Zrnic</author><pubDate>Wed, 07 Aug 2024 16:54:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04262v3</guid></item><item><title>LiRank: Industrial Large Scale Ranking Models at LinkedIn</title><link>http://arxiv.org/abs/2402.06859v2</link><description>We present LiRank, a large-scale ranking framework at LinkedIn that brings toproduction state-of-the-art modeling architectures and optimization methods. Weunveil several modeling improvements, including Residual DCN, which addsattention and residual connections to the famous DCNv2 architecture. We shareinsights into combining and tuning SOTA architectures to create a unifiedmodel, including Dense Gating, Transformers and Residual DCN. We also proposenovel techniques for calibration and describe how we productionalized deeplearning based explore/exploit methods. To enable effective, production-gradeserving of large ranking models, we detail how to train and compress modelsusing quantization and vocabulary compression. We provide details about thedeployment setup for large-scale use cases of Feed ranking, JobsRecommendations, and Ads click-through rate (CTR) prediction. We summarize ourlearnings from various A/B tests by elucidating the most effective technicalapproaches. These ideas have contributed to relative metrics improvementsacross the board at LinkedIn: +0.5% member sessions in the Feed, +1.76%qualified job applications for Jobs search and recommendations, and +4.3% forAds CTR. We hope this work can provide practical insights and solutions forpractitioners interested in leveraging large-scale deep ranking systems.</description><author>Fedor Borisyuk, Mingzhou Zhou, Qingquan Song, Siyu Zhu, Birjodh Tiwana, Ganesh Parameswaran, Siddharth Dangi, Lars Hertel, Qiang Xiao, Xiaochen Hou, Yunbo Ouyang, Aman Gupta, Sheallika Singh, Dan Liu, Hailing Cheng, Lei Le, Jonathan Hung, Sathiya Keerthi, Ruoyan Wang, Fengyu Zhang, Mohit Kothari, Chen Zhu, Daqi Sun, Yun Dai, Xun Luan, Sirou Zhu, Zhiwei Wang, Neil Daftary, Qianqi Shen, Chengming Jiang, Haichao Wei, Maneesh Varshney, Amol Ghoting, Souvik Ghosh</author><pubDate>Wed, 07 Aug 2024 16:54:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06859v2</guid></item><item><title>MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems</title><link>http://arxiv.org/abs/2408.03892v1</link><description>Cyber-Physical Systems (CPSs) are increasingly prevalent across variousindustrial and daily-life domains, with applications ranging from roboticoperations to autonomous driving. With recent advancements in artificialintelligence (AI), learning-based components, especially AI controllers, havebecome essential in enhancing the functionality and efficiency of CPSs.However, the lack of interpretability in these AI controllers presentschallenges to the safety and quality assurance of AI-enabled CPSs (AI-CPSs).Existing methods for improving the safety of AI controllers often involveneural network repair, which requires retraining with additional adversarialexamples or access to detailed internal information of the neural network.Hence, these approaches have limited applicability for black-box policies,where only the inputs and outputs are accessible during operation. To overcomethis, we propose MORTAR, a runtime action repair framework designed for AI-CPSsin this work. MORTAR begins by constructing a prediction model that forecaststhe quality of actions proposed by the AI controller. If an unsafe action isdetected, MORTAR then initiates a repair process to correct it. The generationof repaired actions is achieved through an optimization process guided by thesafety estimates from the prediction model. We evaluate the effectiveness ofMORTAR across various CPS tasks and AI controllers. The results demonstratethat MORTAR can efficiently improve task completion rates of AI controllersunder specified safety specifications. Meanwhile, it also maintains minimalcomputational overhead, ensuring real-time operation of the AI-CPSs.</description><author>Renzhi Wang, Zhehua Zhou, Jiayang Song, Xuan Xie, Xiaofei Xie, Lei Ma</author><pubDate>Wed, 07 Aug 2024 16:44:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03892v1</guid></item><item><title>Dual-Modeling Decouple Distillation for Unsupervised Anomaly Detection</title><link>http://arxiv.org/abs/2408.03888v1</link><description>Knowledge distillation based on student-teacher network is one of themainstream solution paradigms for the challenging unsupervised AnomalyDetection task, utilizing the difference in representation capabilities of theteacher and student networks to implement anomaly localization. However,over-generalization of the student network to the teacher network may lead tonegligible differences in representation capabilities of anomaly, thusaffecting the detection effectiveness. Existing methods address the possibleover-generalization by using differentiated students and teachers from thestructural perspective or explicitly expanding distilled information from thecontent perspective, which inevitably result in an increased likelihood ofunderfitting of the student network and poor anomaly detection capabilities inanomaly center or edge. In this paper, we propose Dual-Modeling DecoupleDistillation (DMDD) for the unsupervised anomaly detection. In DMDD, a DecoupleStudent-Teacher Network is proposed to decouple the initial student featuresinto normality and abnormality features. We further introduce Dual-ModelingDistillation based on normal-anomaly image pairs, fitting normality features ofanomalous image and the teacher features of the corresponding normal image,widening the distance between abnormality features and the teacher features inanomalous regions. Synthesizing these two distillation ideas, we achieveanomaly detection which focuses on both edge and center of anomaly. Finally, aMulti-perception Segmentation Network is proposed to achieve focused anomalymap fusion based on multiple attention. Experimental results on MVTec AD showthat DMDD surpasses SOTA localization performance of previous knowledgedistillation-based methods, reaching 98.85% on pixel-level AUC and 96.13% onPRO.</description><author>Xinyue Liu, Jianyuan Wang, Biao Leng, Shuo Zhang</author><pubDate>Wed, 07 Aug 2024 16:39:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03888v1</guid></item><item><title>Global-Local Progressive Integration Network for Blind Image Quality Assessment</title><link>http://arxiv.org/abs/2408.03885v1</link><description>Vision transformers (ViTs) excel in computer vision for modeling long-termdependencies, yet face two key challenges for image quality assessment (IQA):discarding fine details during patch embedding, and requiring extensivetraining data due to lack of inductive biases. In this study, we propose aGlobal-Local progressive INTegration network for IQA, called GlintIQA, toaddress these issues through three key components: 1) Hybrid feature extractioncombines ViT-based global feature extractor (VGFE) and convolutional neuralnetworks (CNNs)-based local feature extractor (CLFE) to capture globalcoarse-grained features and local fine-grained features, respectively. Theincorporation of CNNs mitigates the patch-level information loss and inductivebias constraints inherent to ViT architectures. 2) Progressive featureintegration leverages diverse kernel sizes in embedding to spatially aligncoarse- and fine-grained features, and progressively aggregate these featuresby interactively stacking channel-wise attention and spatial enhancementmodules to build effective quality-aware representations. 3) Contentsimilarity-based labeling approach is proposed that automatically assignsquality labels to images with diverse content based on subjective qualityscores. This addresses the scarcity of labeled training data in syntheticdatasets and bolsters model generalization. The experimental resultsdemonstrate the efficacy of our approach, yielding 5.04% average SROCC gains oncross-authentic dataset evaluations. Moreover, our model and its counterpartpre-trained on the proposed dataset respectively exhibited 5.40% and 13.23%improvements on across-synthetic datasets evaluation. The codes and proposeddataset will be released at https://github.com/XiaoqiWang/GlintIQA.</description><author>Xiaoqi Wang, Yun Zhang</author><pubDate>Wed, 07 Aug 2024 16:34:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03885v1</guid></item><item><title>Every Dataset Counts: Scaling up Monocular 3D Object Detection with Joint Datasets Training</title><link>http://arxiv.org/abs/2310.00920v3</link><description>Monocular 3D object detection plays a crucial role in autonomous driving.However, existing monocular 3D detection algorithms depend on 3D labels derivedfrom LiDAR measurements, which are costly to acquire for new datasets andchallenging to deploy in novel environments. Specifically, this studyinvestigates the pipeline for training a monocular 3D object detection model ona diverse collection of 3D and 2D datasets. The proposed framework comprisesthree components: (1) a robust monocular 3D model capable of functioning acrossvarious camera settings, (2) a selective-training strategy to accommodatedatasets with differing class annotations, and (3) a pseudo 3D trainingapproach using 2D labels to enhance detection performance in scenes containingonly 2D labels. With this framework, we could train models on a joint set ofvarious open 3D/2D datasets to obtain models with significantly strongergeneralization capability and enhanced performance on new dataset with only 2Dlabels. We conduct extensive experiments onKITTI/nuScenes/ONCE/Cityscapes/BDD100K datasets to demonstrate the scalingability of the proposed method.</description><author>Fulong Ma, Xiaoyang Yan, Guoyang Zhao, Xiaojie Xu, Yuxuan Liu, Ming Liu</author><pubDate>Wed, 07 Aug 2024 16:30:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00920v3</guid></item><item><title>Knowledge Probing for Graph Representation Learning</title><link>http://arxiv.org/abs/2408.03877v1</link><description>Graph learning methods have been extensively applied in diverse applicationareas. However, what kind of inherent graph properties e.g. graph proximity,graph structural information has been encoded into graph representationlearning for downstream tasks is still under-explored. In this paper, wepropose a novel graph probing framework (GraphProbe) to investigate andinterpret whether the family of graph learning methods has encoded differentlevels of knowledge in graph representation learning. Based on the intrinsicproperties of graphs, we design three probes to systematically investigate thegraph representation learning process from different perspectives, respectivelythe node-wise level, the path-wise level, and the structural level. Weconstruct a thorough evaluation benchmark with nine representative graphlearning methods from random walk based approaches, basic graph neural networksand self-supervised graph methods, and probe them on six benchmark datasets fornode classification, link prediction and graph classification. The experimentalevaluation verify that GraphProbe can estimate the capability of graphrepresentation learning. Remaking results have been concluded: GCN andWeightedGCN methods are relatively versatile methods achieving better resultswith respect to different tasks.</description><author>Mingyu Zhao, Xingyu Huang, Ziyu Lyu, Yanlin Wang, Lixin Cui, Lu Bai</author><pubDate>Wed, 07 Aug 2024 16:27:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03877v1</guid></item><item><title>Personalized Clinical Note Generation from Doctor-Patient Conversations</title><link>http://arxiv.org/abs/2408.03874v1</link><description>In this work, we present a novel technique to improve the quality of draftclinical notes for physicians. This technique is concentrated on the ability tomodel implicit physician conversation styles and note preferences. We alsointroduce a novel technique for the enrollment of new physicians when a limitednumber of clinical notes paired with conversations are available for thatphysician, without the need to re-train a model to support them. We show thatour technique outperforms the baseline model by improving the ROUGE-2 score ofthe History of Present Illness section by 13.8%, the Physical Examinationsection by 88.6%, and the Assessment &amp; Plan section by 50.8%.</description><author>Nathan Brake, Thomas Schaaf</author><pubDate>Wed, 07 Aug 2024 16:24:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03874v1</guid></item><item><title>Inter-Series Transformer: Attending to Products in Time Series Forecasting</title><link>http://arxiv.org/abs/2408.03872v1</link><description>Time series forecasting is an important task in many fields ranging fromsupply chain management to weather forecasting. Recently, Transformer neuralnetwork architectures have shown promising results in forecasting on commontime series benchmark datasets. However, application to supply chain demandforecasting, which can have challenging characteristics such as sparsity andcross-series effects, has been limited. In this work, we explore the application of Transformer-based models tosupply chain demand forecasting. In particular, we develop a newTransformer-based forecasting approach using a shared, multi-task per-timeseries network with an initial component applying attention across time series,to capture interactions and help address sparsity. We provide a case studyapplying our approach to successfully improve demand prediction for a medicaldevice manufacturing company. To further validate our approach, we also applyit to public demand forecasting datasets as well and demonstrate competitive tosuperior performance compared to a variety of baseline and state-of-the-artforecast methods across the private and public datasets.</description><author>Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni</author><pubDate>Wed, 07 Aug 2024 16:22:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03872v1</guid></item><item><title>BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability</title><link>http://arxiv.org/abs/2408.03871v1</link><description>In this system report, we describe the models and methods we used for ourparticipation in the PLABA2023 task on biomedical abstract simplification, partof the TAC 2023 tracks. The system outputs we submitted come from the followingthree categories: 1) domain fine-tuned T5-like models including Biomedical-T5and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes(via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work wecarried out for this task on BioGPT finetuning. In the official automaticevaluation using SARI scores, BeeManc ranks 2nd among all teams and our modelLaySciFive ranks 3rd among all 13 evaluated systems. In the official humanevaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; Italso produced a high score 91.57 on Fluency in comparison to the highest score93.53. In the second round of submissions, our team using ChatGPT-promptingranks the 2nd in several categories including simplified term accuracy score92.26 and completeness score 96.58, and a very similar score on faithfulnessscore 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Ourcodes, fine-tuned models, prompts, and data splits from the system developmentstage will be available at https://github.com/ HECTA-UoM/PLABA-MU</description><author>Zihao Li, Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Matthew Shardlow, Goran Nenadic</author><pubDate>Wed, 07 Aug 2024 16:21:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03871v1</guid></item><item><title>PraFFL: A Preference-Aware Scheme in Fair Federated Learning</title><link>http://arxiv.org/abs/2404.08973v2</link><description>Fairness in federated learning has emerged as a critical concern, aiming todevelop an unbiased model for any special group (e.g., male or female) ofsensitive features. However, there is a trade-off between model performance andfairness, i.e., improving model fairness will decrease model performance.Existing approaches have characterized such a trade-off by introducinghyperparameters to quantify client's preferences for model fairness and modelperformance. Nevertheless, these approaches are limited to scenarios where eachclient has only a single pre-defined preference, and fail to work in practicalsystems where each client generally have multiple preferences. The keychallenge is to design a method that allows the model to adapt to diversepreferences of each client in real time. To this end, we propose aPreference-aware scheme in Fair Federated Learning paradigm (called PraFFL) togenerate preference-wise model in real time. PraFFL can adaptively adjust themodel based on each client's preferences to meet their needs. We theoreticallyprove that PraFFL can offer the optimal model tailored to an arbitrarypreference of each client, and show its linear convergence. Experimentalresults show that our proposed PraFFL outperforms five fair federated learningalgorithms in terms of the model's capability of adapting to clients' differentpreferences.</description><author>Rongguang Ye, Wei-Bin Kou, Ming Tang</author><pubDate>Wed, 07 Aug 2024 16:21:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08973v2</guid></item><item><title>Digital Twins and Civil Engineering Phases: Reorienting Adoption Strategies</title><link>http://arxiv.org/abs/2403.02426v2</link><description>Digital twin (DT) technology has received immense attention over the yearsdue to the promises it presents to various stakeholders in science andengineering. As a result, different thematic areas of DT have been explored.This is no different in specific fields such as manufacturing, automation, oiland gas, and civil engineering, leading to fragmented approaches forfield-specific applications. The civil engineering industry is furtherdisadvantaged in this regard as it relies on external techniques by otherengineering fields for its DT adoption. A rising consequence of theseextensions is a concentrated application of DT to the operations andmaintenance phase. On another spectrum, Building Information Modeling (BIM) ispervasively utilized in the planning/design phase, and the transient nature ofthe construction phase remains a challenge for its DT adoption. In this paper,we present a phase-based development of DT in the Architecture, Engineering,and Construction industry. We commence by presenting succinct expositions on DTas a concept and as a service, and establish a five-level scale system.Furthermore, we present separately a systematic literature review of theconventional techniques employed at each civil engineering phase. In thisregard, we identified enabling technologies such as computer vision forextended sensing and the Internet of Things for reliable integration.Ultimately, we attempt to reveal DT as an important tool across the entire lifecycle of civil engineering projects, and nudge researchers to think moreholistically in their quest for the integration of DT for civil engineeringapplications.</description><author>Taiwo A. Adebiyi, Nafeezat A. Ajenifuja, Ruda Zhang</author><pubDate>Wed, 07 Aug 2024 16:20:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02426v2</guid></item><item><title>ORBIT: Oak Ridge Base Foundation Model for Earth System Predictability</title><link>http://arxiv.org/abs/2404.14712v3</link><description>Earth system predictability is challenged by the complexity of environmentaldynamics and the multitude of variables involved. Current AI foundation models,although advanced by leveraging large and heterogeneous data, are oftenconstrained by their size and data integration, limiting their effectiveness inaddressing the full range of Earth system prediction challenges. To overcomethese limitations, we introduce the Oak Ridge Base Foundation Model for EarthSystem Predictability (ORBIT), an advanced vision transformer model that scalesup to 113 billion parameters using a novel hybrid tensor-data orthogonalparallelism technique. As the largest model of its kind, ORBIT surpasses thecurrent climate AI foundation model size by a thousandfold. Performance scalingtests conducted on the Frontier supercomputer have demonstrated that ORBITachieves 684 petaFLOPS to 1.6 exaFLOPS sustained throughput, with scalingefficiency maintained at 41% to 85% across 49,152 AMD GPUs. These breakthroughsestablish new advances in AI-driven climate modeling and demonstrate promise tosignificantly improve the Earth system predictability.</description><author>Xiao Wang, Siyan Liu, Aristeidis Tsaris, Jong-Youl Choi, Ashwin Aji, Ming Fan, Wei Zhang, Junqi Yin, Moetasim Ashfaq, Dan Lu, Prasanna Balaprakash</author><pubDate>Wed, 07 Aug 2024 16:19:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14712v3</guid></item><item><title>Surgformer: Surgical Transformer with Hierarchical Temporal Attention for Surgical Phase Recognition</title><link>http://arxiv.org/abs/2408.03867v1</link><description>Existing state-of-the-art methods for surgical phase recognition either relyon the extraction of spatial-temporal features at a short-range temporalresolution or adopt the sequential extraction of the spatial and temporalfeatures across the entire temporal resolution. However, these methods havelimitations in modeling spatial-temporal dependency and addressingspatial-temporal redundancy: 1) These methods fail to effectively modelspatial-temporal dependency, due to the lack of long-range information or jointspatial-temporal modeling. 2) These methods utilize dense spatial featuresacross the entire temporal resolution, resulting in significantspatial-temporal redundancy. In this paper, we propose the Surgical Transformer(Surgformer) to address the issues of spatial-temporal modeling and redundancyin an end-to-end manner, which employs divided spatial-temporal attention andtakes a limited set of sparse frames as input. Moreover, we propose a novelHierarchical Temporal Attention (HTA) to capture both global and localinformation within varied temporal resolutions from a target frame-centricperspective. Distinct from conventional temporal attention that primarilyemphasizes dense long-range similarity, HTA not only captures long-terminformation but also considers local latent consistency among informativeframes. HTA then employs pyramid feature aggregation to effectively utilizetemporal information across diverse temporal resolutions, thereby enhancing theoverall temporal representation. Extensive experiments on two challengingbenchmark datasets verify that our proposed Surgformer performs favorablyagainst the state-of-the-art methods. The code is released athttps://github.com/isyangshu/Surgformer.</description><author>Shu Yang, Luyang Luo, Qiong Wang, Hao Chen</author><pubDate>Wed, 07 Aug 2024 16:16:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03867v1</guid></item><item><title>PackMamba: Efficient Processing of Variable-Length Sequences in Mamba training</title><link>http://arxiv.org/abs/2408.03865v1</link><description>With the evolution of large language models, traditional Transformer modelsbecome computationally demanding for lengthy sequences due to the quadraticgrowth in computation with respect to the sequence length. Mamba, emerging as agroundbreaking architecture in the field of generative AI, demonstratesremarkable proficiency in handling elongated sequences with reducedcomputational and memory complexity. Nevertheless, the existing trainingframework of Mamba presents inefficiency with variable-length sequence inputs.Either single-sequence training results in low GPU utilization, or batchedprocessing of variable-length sequences to a maximum length incurs considerablememory and computational overhead. To address this problem, we analyze theperformance of bottleneck operators in Mamba under diverse tensor shapes andproposed PackMamba, a high-throughput Mamba that efficiently handlesvariable-length sequences. Diving deep into state-space models (SSMs), wemodify the parallel operators to avoid passing information between individualsequences while maintaining high performance. Experimental results on an NVIDIAA100 GPU demonstrate throughput exceeding the baseline single-sequenceprocessing scheme: 3.06x speedup on the 1.4B model and 2.62x on the 2.8B model.</description><author>Haoran Xu, Ziqian Liu, Rong Fu, Zhongling Su, Zerui Wang, Zheng Cai, Zhilin Pei, Xingcheng Zhang</author><pubDate>Wed, 07 Aug 2024 16:13:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03865v1</guid></item><item><title>Visualize and Paint GAN Activations</title><link>http://arxiv.org/abs/2405.15636v3</link><description>We investigate how generated structures of GANs correlate with theiractivations in hidden layers, with the purpose of better understanding theinner workings of those models and being able to paint structures withunconditionally trained GANs. This gives us more control over the generatedimages, allowing to generate them from a semantic segmentation map while notrequiring such a segmentation in the training data. To this end we introducethe concept of tileable features, allowing us to identify activations that workwell for painting.</description><author>Rudolf Herdt, Peter Maass</author><pubDate>Wed, 07 Aug 2024 16:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15636v3</guid></item><item><title>Out-of-Distribution-Aware Electric Vehicle Charging</title><link>http://arxiv.org/abs/2311.05941v3</link><description>We tackle the challenge of learning to charge Electric Vehicles (EVs) withOut-of-Distribution (OOD) data. Traditional scheduling algorithms typicallyfail to balance near-optimal average performance with worst-case guarantees,particularly with OOD data. Model Predictive Control (MPC) is often tooconservative and data-independent, whereas Reinforcement Learning (RL) tends tobe overly aggressive and fully trusts the data, hindering their ability toconsistently achieve the best-of-both-worlds. To bridge this gap, we introducea novel OOD-aware scheduling algorithm, denoted OOD-Charging. This algorithmemploys a dynamic "awareness radius", which updates in real-time based on theTemporal Difference (TD)-error that reflects the severity of OOD. TheOOD-Charging algorithm allows for a more effective balance between consistencyand robustness in EV charging schedules, thereby significantly enhancingadaptability and efficiency in real-world charging environments. Our resultsdemonstrate that this approach improves the scheduling reward reliably underreal OOD scenarios with remarkable shifts of EV charging behaviors caused byCOVID-19 in the Caltech ACN-Data.</description><author>Tongxin Li, Chenxi Sun</author><pubDate>Wed, 07 Aug 2024 15:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05941v3</guid></item><item><title>Sólo Escúchame: Spanish Emotional Accompaniment Chatbot</title><link>http://arxiv.org/abs/2408.01852v2</link><description>According to the World Health Organization (WHO), suicide was the fourthleading cause of death in the world for individuals aged 15 to 29 in 2019.Given the rapid increase in mental health issues, providing psychologicalsupport is both crucial and urgent. In this paper: (1) we propose S\'oloEsc\'uchame, the first open-source Spanish emotional assistance chatbot, basedon LLaMA-2-7b-Chat. (2) We introduced the HEAR (Hispanic EmotionalAccompaniment Responses) dataset, compiled from multiple English sourcestranslated into Spanish, as well as generic data generated usingChatGPT-3.5-Turbo. Finally, (3) we propose an evaluation metric based on twosemi-automatic assessment methods. Our system outperforms a range ofstate-of-the-art models in providing psychological assistance in Spanish. Ourmodels and datasets are publicly available to facilitate reproducibility.</description><author>Bruno Gil Ramírez, Jessica López Espejel, María del Carmen Santiago Díaz, Gustavo Trinidad Rubín Linares</author><pubDate>Wed, 07 Aug 2024 15:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01852v2</guid></item><item><title>Why transformers are obviously good models of language</title><link>http://arxiv.org/abs/2408.03855v1</link><description>Nobody knows how language works, but many theories abound. Transformers are aclass of neural networks that process language automatically with more successthan alternatives, both those based on neural computations and those that relyon other (e.g. more symbolic) mechanisms. Here, I highlight direct connectionsbetween the transformer architecture and certain theoretical perspectives onlanguage. The empirical success of transformers relative to alternative modelsprovides circumstantial evidence that the linguistic approaches thattransformers embody should be, at least, evaluated with greater scrutiny by thelinguistics community and, at best, considered to be the currently bestavailable theories.</description><author>Felix Hill</author><pubDate>Wed, 07 Aug 2024 15:52:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03855v1</guid></item><item><title>Hate Speech Detection and Classification in Amharic Text with Deep Learning</title><link>http://arxiv.org/abs/2408.03849v1</link><description>Hate speech is a growing problem on social media. It can seriously impactsociety, especially in countries like Ethiopia, where it can trigger conflictsamong diverse ethnic and religious groups. While hate speech detection inresource rich languages are progressing, for low resource languages such asAmharic are lacking. To address this gap, we develop Amharic hate speech dataand SBi-LSTM deep learning model that can detect and classify text into fourcategories of hate speech: racial, religious, gender, and non-hate speech. Wehave annotated 5k Amharic social media post and comment data into fourcategories. The data is annotated using a custom annotation tool by a total of100 native Amharic speakers. The model achieves a 94.8 F1-score performance.Future improvements will include expanding the dataset and develop state-of-theart models. Keywords: Amharic hate speech detection, classification, Amharic dataset,Deep Learning, SBi-LSTM</description><author>Samuel Minale Gashe, Seid Muhie Yimam, Yaregal Assabie</author><pubDate>Wed, 07 Aug 2024 15:46:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03849v1</guid></item><item><title>G-invariant diffusion maps</title><link>http://arxiv.org/abs/2306.07350v3</link><description>The diffusion maps embedding of data lying on a manifold has shown success intasks such as dimensionality reduction, clustering, and data visualization. Inthis work, we consider embedding data sets that were sampled from a manifoldwhich is closed under the action of a continuous matrix group. An example ofsuch a data set is images whose planar rotations are arbitrary. The G-invariantgraph Laplacian, introduced in Part I of this work, admits eigenfunctions inthe form of tensor products between the elements of the irreducible unitaryrepresentations of the group and eigenvectors of certain matrices. We employthese eigenfunctions to derive diffusion maps that intrinsically account forthe group action on the data. In particular, we construct both equivariant andinvariant embeddings, which can be used to cluster and align the data points.We demonstrate the utility of our construction in the problem of randomcomputerized tomography.</description><author>Eitan Rosen, Xiuyuan Cheng, Yoel Shkolnisky</author><pubDate>Wed, 07 Aug 2024 15:36:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07350v3</guid></item><item><title>Bi-Level Spatial and Channel-aware Transformer for Learned Image Compression</title><link>http://arxiv.org/abs/2408.03842v1</link><description>Recent advancements in learned image compression (LIC) methods havedemonstrated superior performance over traditional hand-crafted codecs. Theselearning-based methods often employ convolutional neural networks (CNNs) orTransformer-based architectures. However, these nonlinear approaches frequentlyoverlook the frequency characteristics of images, which limits theircompression efficiency. To address this issue, we propose a novelTransformer-based image compression method that enhances the transformationstage by considering frequency components within the feature map. Our methodintegrates a novel Hybrid Spatial-Channel Attention Transformer Block (HSCATB),where a spatial-based branch independently handles high and low frequencies atthe attention layer, and a Channel-aware Self-Attention (CaSA) module capturesinformation across channels, significantly improving compression performance.Additionally, we introduce a Mixed Local-Global Feed Forward Network (MLGFFN)within the Transformer block to enhance the extraction of diverse and richinformation, which is crucial for effective compression. These innovationscollectively improve the transformation's ability to project data into a moredecorrelated latent space, thereby boosting overall compression efficiency.Experimental results demonstrate that our framework surpasses state-of-the-artLIC methods in rate-distortion performance.</description><author>Hamidreza Soltani, Erfan Ghasemi</author><pubDate>Wed, 07 Aug 2024 15:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03842v1</guid></item><item><title>MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models</title><link>http://arxiv.org/abs/2408.03841v1</link><description>The application of large language models to facilitate automated softwareoperations and tool generation (SOTG), thus augmenting software productivity,mirrors the early stages of human evolution when the ability to create and usetools accelerated the progress of civilization. These complex tasks require AIto continuously summarize and improve. Current research often overlooks theimportance of converting real-time task experiences into system memory anddifferentiating the value of existing knowledge for future reference. Thispaper addresses these issues by evolving external memory models intoMemory-Loop Networks for timely memorization and experience referencing. Wealso enhance a RAG mechanism with knowledge precision segmentation to utilizememory based on value differentiation, and design the MaxMind model for SOTGaccordingly.To demonstrate our approach, we developed MaxMind4Sheet, anelectronic spreadsheet processing system aligned with the MaxMind philosophy.Comparative experiments with SheetCopilot have demonstrated that theaccumulation and recycling of task memories lead to a steady enhancement intask success rate, with an improvement rate of approximately 3%-6% per round inthis implementation example. Note that as the memories continue to grow, thiscumulative improvement may be substantial. The inclusion of memory recyclingcan also boost the system's task execution efficiency by up to 25%, and it canaddress the retraining issue faced by LLMs when handling specialized tasksthrough memories transfer.These suggest that MaxMind has significant potentialto enhance the capabilities and productivity of LLM systems in SOTG.</description><author>Yuchen Dong, XiaoXiang Fang, Yuchen Hu, Renshuang Jiang, Zhe Jiang</author><pubDate>Wed, 07 Aug 2024 15:27:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03841v1</guid></item><item><title>Using a Distance Sensor to Detect Deviations in a Planar Surface</title><link>http://arxiv.org/abs/2408.03838v1</link><description>We investigate methods for determining if a planar surface contains geometricdeviations (e.g., protrusions, objects, divots, or cliffs) using only aninstantaneous measurement from a miniature optical time-of-flight sensor. Thekey to our method is to utilize the entirety of information encoded in rawtime-of-flight data captured by off-the-shelf distance sensors. We provide ananalysis of the problem in which we identify the key ambiguity between geometryand surface photometrics. To overcome this challenging ambiguity, we fit aGaussian mixture model to a small dataset of planar surface measurements. Thismodel implicitly captures the expected geometry and distribution ofphotometrics of the planar surface and is used to identify measurements thatare likely to contain deviations. We characterize our method on a variety ofsurfaces and planar deviations across a range of scenarios. We find that ourmethod utilizing raw time-of-flight data outperforms baselines which use onlyderived distance estimates. We build an example application in which our methodenables mobile robot obstacle and cliff avoidance over a wide field-of-view.</description><author>Carter Sifferman, William Sun, Mohit Gupta, Michael Gleicher</author><pubDate>Wed, 07 Aug 2024 15:24:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03838v1</guid></item><item><title>WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models</title><link>http://arxiv.org/abs/2408.03837v1</link><description>WalledEval is a comprehensive AI safety testing toolkit designed to evaluatelarge language models (LLMs). It accommodates a diverse range of models,including both open-weight and API-based ones, and features over 35 safetybenchmarks covering areas such as multilingual safety, exaggerated safety, andprompt injections. The framework supports both LLM and judge benchmarking, andincorporates custom mutators to test safety against various text-stylemutations such as future tense and paraphrasing. Additionally, WalledEvalintroduces WalledGuard, a new, small and performant content moderation tool,and SGXSTest, a benchmark for assessing exaggerated safety in culturalcontexts. We make WalledEval publicly available athttps://github.com/walledai/walledevalA.</description><author>Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria</author><pubDate>Wed, 07 Aug 2024 15:22:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03837v1</guid></item><item><title>Target Prompting for Information Extraction with Vision Language Model</title><link>http://arxiv.org/abs/2408.03834v1</link><description>The recent trend in the Large Vision and Language model has brought a newchange in how information extraction systems are built. VLMs have set a newbenchmark with their State-of-the-art techniques in understanding documents andbuilding question-answering systems across various industries. They aresignificantly better at generating text from document images and providingaccurate answers to questions. However, there are still some challenges ineffectively utilizing these models to build a precise conversational system.General prompting techniques used with large language models are often notsuitable for these specially designed vision language models. The outputgenerated by such generic input prompts is ordinary and may contain informationgaps when compared with the actual content of the document. To obtain moreaccurate and specific answers, a well-targeted prompt is required by the visionlanguage model, along with the document image. In this paper, a technique isdiscussed called Target prompting, which focuses on explicitly targeting partsof document images and generating related answers from those specific regionsonly. The paper also covers the evaluation of response for each promptingtechnique using different user queries and input prompts.</description><author>Dipankar Medhi</author><pubDate>Wed, 07 Aug 2024 15:17:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03834v1</guid></item><item><title>An Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases</title><link>http://arxiv.org/abs/2407.10853v2</link><description>Large language models (LLMs) can exhibit bias in a variety of ways. Suchbiases can create or exacerbate unfair outcomes for certain groups within aprotected attribute, including, but not limited to sex, race, sexualorientation, or age. This paper aims to provide a technical guide forpractitioners to assess bias and fairness risks in LLM use cases. The maincontribution of this work is a decision framework that allows practitioners todetermine which metrics to use for a specific LLM use case. To achieve this,this study categorizes LLM bias and fairness risks, maps those risks to ataxonomy of LLM use cases, and then formally defines various metrics to assesseach type of risk. As part of this work, several new bias and fairness metricsare introduced, including innovative counterfactual metrics as well as metricsbased on stereotype classifiers. Instead of focusing solely on the modelitself, the sensitivity of both prompt-risk and model-risk are taken intoaccount by defining evaluations at the level of an LLM use case, characterizedby a model and a population of prompts. Furthermore, because all of theevaluation metrics are calculated solely using the LLM output, the proposedframework is highly practical and easily actionable for practitioners.</description><author>Dylan Bouchard</author><pubDate>Wed, 07 Aug 2024 15:12:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10853v2</guid></item><item><title>DenseNets Reloaded: Paradigm Shift Beyond ResNets and ViTs</title><link>http://arxiv.org/abs/2403.19588v2</link><description>This paper revives Densely Connected Convolutional Networks (DenseNets) andreveals the underrated effectiveness over predominant ResNet-stylearchitectures. We believe DenseNets' potential was overlooked due to untouchedtraining methods and traditional design elements not fully revealing theircapabilities. Our pilot study shows dense connections through concatenation arestrong, demonstrating that DenseNets can be revitalized to compete with modernarchitectures. We methodically refine suboptimal components - architecturaladjustments, block redesign, and improved training recipes towards wideningDenseNets and boosting memory efficiency while keeping concatenation shortcuts.Our models, employing simple architectural elements, ultimately surpass SwinTransformer, ConvNeXt, and DeiT-III - key architectures in the residuallearning lineage. Furthermore, our models exhibit near state-of-the-artperformance on ImageNet-1K, competing with the very recent models anddownstream tasks, ADE20k semantic segmentation, and COCO objectdetection/instance segmentation. Finally, we provide empirical analyses thatuncover the merits of the concatenation over additive shortcuts, steering arenewed preference towards DenseNet-style designs. Our code is available athttps://github.com/naver-ai/rdnet.</description><author>Donghyun Kim, Byeongho Heo, Dongyoon Han</author><pubDate>Wed, 07 Aug 2024 15:11:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19588v2</guid></item><item><title>New Job, New Gender? Measuring the Social Bias in Image Generation Models</title><link>http://arxiv.org/abs/2401.00763v2</link><description>Image generation models can generate or edit images from a given text. Recentadvancements in image generation technology, exemplified by DALL-E andMidjourney, have been groundbreaking. These advanced models, despite theirimpressive capabilities, are often trained on massive Internet datasets, makingthem susceptible to generating content that perpetuates social stereotypes andbiases, which can lead to severe consequences. Prior research on assessing biaswithin image generation models suffers from several shortcomings, includinglimited accuracy, reliance on extensive human labor, and lack of comprehensiveanalysis. In this paper, we propose BiasPainter, a novel evaluation frameworkthat can accurately, automatically and comprehensively trigger social bias inimage generation models. BiasPainter uses a diverse range of seed images ofindividuals and prompts the image generation models to edit these images usinggender, race, and age-neutral queries. These queries span 62 professions, 39activities, 57 types of objects, and 70 personality traits. The framework thencompares the edited images to the original seed images, focusing on thesignificant changes related to gender, race, and age. BiasPainter adopts a keyinsight that these characteristics should not be modified when subjected toneutral prompts. Built upon this design, BiasPainter can trigger the socialbias and evaluate the fairness of image generation models. We use BiasPainterto evaluate six widely-used image generation models, such as stable diffusionand Midjourney. Experimental results show that BiasPainter can successfullytrigger social bias in image generation models. According to our humanevaluation, BiasPainter can achieve 90.8% accuracy on automatic bias detection,which is significantly higher than the results reported in previous work.</description><author>Wenxuan Wang, Haonan Bai, Jen-tse Huang, Yuxuan Wan, Youliang Yuan, Haoyi Qiu, Nanyun Peng, Michael R. Lyu</author><pubDate>Wed, 07 Aug 2024 15:10:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00763v2</guid></item><item><title>Anomalies, Representations, and Self-Supervision</title><link>http://arxiv.org/abs/2301.04660v2</link><description>We develop a self-supervised method for density-based anomaly detection usingcontrastive learning, and test it using event-level anomaly data from CMSADC2021. The AnomalyCLR technique is data-driven and uses augmentations of thebackground data to mimic non-Standard-Model events in a model-agnostic way. Ituses a permutation-invariant Transformer Encoder architecture to map theobjects measured in a collider event to the representation space, where thedata augmentations define a representation space which is sensitive topotential anomalous features. An AutoEncoder trained on backgroundrepresentations then computes anomaly scores for a variety of signals in therepresentation space. With AnomalyCLR we find significant improvements onperformance metrics for all signals when compared to the raw data baseline.</description><author>Barry M. Dillon, Luigi Favaro, Friedrich Feiden, Tanmoy Modak, Tilman Plehn</author><pubDate>Wed, 07 Aug 2024 15:07:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.04660v2</guid></item><item><title>Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps</title><link>http://arxiv.org/abs/2408.03827v1</link><description>Accessibility is crucial for inclusive app usability, yet developers oftenstruggle to identify and fix app accessibility issues due to a lack ofawareness, expertise, and inadequate tools. Current accessibility testing toolscan identify accessibility issues but may not always provide guidance on how toaddress them. We introduce FixAlly, an automated tool designed to suggestsource code fixes for accessibility issues detected by automated accessibilityscanners. FixAlly employs a multi-agent LLM architecture to generate fixstrategies, localize issues within the source code, and propose codemodification suggestions to fix the accessibility issue. Our empirical studydemonstrates FixAlly's capability in suggesting fixes that resolve issues foundby accessibility scanners -- with an effectiveness of 77% in generatingplausible fix suggestions -- and our survey of 12 iOS developers finds theywould be willing to accept 69.4% of evaluated fix suggestions.</description><author>Forough Mehralian, Titus Barik, Jeff Nichols, Amanda Swearngin</author><pubDate>Wed, 07 Aug 2024 15:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03827v1</guid></item><item><title>Towards Real-Time Gaussian Splatting: Accelerating 3DGS through Photometric SLAM</title><link>http://arxiv.org/abs/2408.03825v1</link><description>Initial applications of 3D Gaussian Splatting (3DGS) in Visual SimultaneousLocalization and Mapping (VSLAM) demonstrate the generation of high-qualityvolumetric reconstructions from monocular video streams. However, despite thesepromising advancements, current 3DGS integrations have reduced trackingperformance and lower operating speeds compared to traditional VSLAM. Toaddress these issues, we propose integrating 3DGS with Direct Sparse Odometry,a monocular photometric SLAM system. We have done preliminary experimentsshowing that using Direct Sparse Odometry point cloud outputs, as opposed tostandard structure-from-motion methods, significantly shortens the trainingtime needed to achieve high-quality renders. Reducing 3DGS training timeenables the development of 3DGS-integrated SLAM systems that operate inreal-time on mobile hardware. These promising initial findings suggest furtherexploration is warranted in combining traditional VSLAM systems with 3DGS.</description><author>Yan Song Hu, Dayou Mao, Yuhao Chen, John Zelek</author><pubDate>Wed, 07 Aug 2024 15:01:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03825v1</guid></item><item><title>Compact 3D Gaussian Splatting for Static and Dynamic Radiance Fields</title><link>http://arxiv.org/abs/2408.03822v1</link><description>3D Gaussian splatting (3DGS) has recently emerged as an alternativerepresentation that leverages a 3D Gaussian-based representation and introducesan approximated volumetric rendering, achieving very fast rendering speed andpromising image quality. Furthermore, subsequent studies have successfullyextended 3DGS to dynamic 3D scenes, demonstrating its wide range ofapplications. However, a significant drawback arises as 3DGS and its followingmethods entail a substantial number of Gaussians to maintain the high fidelityof the rendered images, which requires a large amount of memory and storage. Toaddress this critical issue, we place a specific emphasis on two keyobjectives: reducing the number of Gaussian points without sacrificingperformance and compressing the Gaussian attributes, such as view-dependentcolor and covariance. To this end, we propose a learnable mask strategy thatsignificantly reduces the number of Gaussians while preserving highperformance. In addition, we propose a compact but effective representation ofview-dependent color by employing a grid-based neural field rather than relyingon spherical harmonics. Finally, we learn codebooks to compactly represent thegeometric and temporal attributes by residual vector quantization. With modelcompression techniques such as quantization and entropy coding, we consistentlyshow over 25x reduced storage and enhanced rendering speed compared to 3DGS forstatic scenes, while maintaining the quality of the scene representation. Fordynamic scenes, our approach achieves more than 12x storage efficiency andretains a high-quality reconstruction compared to the existing state-of-the-artmethods. Our work provides a comprehensive framework for 3D scenerepresentation, achieving high performance, fast training, compactness, andreal-time rendering. Our project page is available athttps://maincold2.github.io/c3dgs/.</description><author>Joo Chan Lee, Daniel Rho, Xiangyu Sun, Jong Hwan Ko, Eunbyung Park</author><pubDate>Wed, 07 Aug 2024 14:56:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03822v1</guid></item><item><title>Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning</title><link>http://arxiv.org/abs/2408.03819v1</link><description>Active Learning (AL) allows models to learn interactively from user feedback.This paper introduces a counterfactual data augmentation approach to AL,particularly addressing the selection of datapoints for user querying, apivotal concern in enhancing data efficiency. Our approach is inspired byVariation Theory, a theory of human concept learning that emphasizes theessential features of a concept by focusing on what stays the same and whatchanges. Instead of just querying with existing datapoints, our approachsynthesizes artificial datapoints that highlight potential key similarities anddifferences among labels using a neuro-symbolic pipeline combining largelanguage models (LLMs) and rule-based models. Through an experiment in theexample domain of text classification, we show that our approach achievessignificantly higher performance when there are fewer annotated data. As theannotated training data gets larger the impact of the generated data starts todiminish showing its capability to address the cold start problem in AL. Thisresearch sheds light on integrating theories of human learning into theoptimization of AL.</description><author>Simret Araya Gebreegziabher, Kuangshi Ai, Zheng Zhang, Elena L. Glassman, Toby Jia-Jun Li</author><pubDate>Wed, 07 Aug 2024 14:55:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03819v1</guid></item><item><title>SpecRover: Code Intent Extraction via LLMs</title><link>http://arxiv.org/abs/2408.02232v2</link><description>Autonomous program improvement typically involves automatically producing bugfixes and feature additions. Such program improvement can be accomplished by acombination of large language model (LLM) and program analysis capabilities, inthe form of an LLM agent. Since program repair or program improvement typicallyrequires a specification of intended behavior - specification inference can beuseful for producing high quality program patches. In this work, we examineefficient and low-cost workflows for iterative specification inference withinan LLM agent. Given a GitHub issue to be resolved in a software project, ourgoal is to conduct iterative code search accompanied by specification inference- thereby inferring intent from both the project structure and behavior. Theintent thus captured is examined by a reviewer agent with the goal of vettingthe patches as well as providing a measure of confidence in the vetted patches.Our approach SpecRover (AutoCodeRover-v2) is built on the open-source LLM agentAutoCodeRover. In an evaluation on the full SWE-Bench consisting of 2294 GitHubissues, it shows more than 50% improvement in efficacy over AutoCodeRover.Compared to the open-source agents available, our work shows modest cost ($0.65per issue) in resolving an average GitHub issue in SWE-Bench lite. Theproduction of explanation by SpecRover allows for a better "signal" to be givento the developer, on when the suggested patches can be accepted withconfidence. SpecRover also seeks to demonstrate the continued importance ofspecification inference in automated program repair, even as program repairtechnologies enter the LLM era.</description><author>Haifeng Ruan, Yuntong Zhang, Abhik Roychoudhury</author><pubDate>Wed, 07 Aug 2024 14:52:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02232v2</guid></item><item><title>Early Prediction of Causes (not Effects) in Healthcare by Long-Term Clinical Time Series Forecasting</title><link>http://arxiv.org/abs/2408.03816v1</link><description>Machine learning for early syndrome diagnosis aims to solve the intricatetask of predicting a ground truth label that most often is the outcome (effect)of a medical consensus definition applied to observed clinical measurements(causes), given clinical measurements observed several hours before. Instead offocusing on the prediction of the future effect, we propose to directly predictthe causes via time series forecasting (TSF) of clinical variables anddetermine the effect by applying the gold standard consensus definition to theforecasted values. This method has the invaluable advantage of beingstraightforwardly interpretable to clinical practitioners, and because modeltraining does not rely on a particular label anymore, the forecasted data canbe used to predict any consensus-based label. We exemplify our method by meansof long-term TSF with Transformer models, with a focus on accurate predictionof sparse clinical variables involved in the SOFA-based Sepsis-3 definition andthe new Simplified Acute Physiology Score (SAPS-II) definition. Our experimentsare conducted on two datasets and show that contrary to recent proposals whichadvocate set function encoders for time series and direct multi-step decoders,best results are achieved by a combination of standard dense encoders withiterative multi-step decoders. The key for success of iterative multi-stepdecoding can be attributed to its ability to capture cross-variate dependenciesand to a student forcing training strategy that teaches the model to rely onits own previous time step predictions for the next time step prediction.</description><author>Michael Staniek, Marius Fracarolli, Michael Hagmann, Stefan Riezler</author><pubDate>Wed, 07 Aug 2024 14:52:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03816v1</guid></item><item><title>Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring</title><link>http://arxiv.org/abs/2408.03811v1</link><description>Automated Short Answer Scoring (ASAS) is a critical component in educationalassessment. While traditional ASAS systems relied on rule-based algorithms orcomplex deep learning methods, recent advancements in Generative LanguageModels (GLMs) offer new opportunities for improvement. This study explores theapplication of GLMs to ASAS, leveraging their off-the-shelf capabilities andperformance in various domains. We propose a novel pipeline that combinesvector databases, transformer-based encoders, and GLMs to enhance short answerscoring accuracy. Our approach stores training responses in a vector database,retrieves semantically similar responses during inference, and employs a GLM toanalyze these responses and determine appropriate scores. We further optimizethe system through fine-tuned retrieval processes and prompt engineering.Evaluation on the SemEval 2013 dataset demonstrates a significant improvementon the SCIENTSBANK 3-way and 2-way tasks compared to existing methods,highlighting the potential of GLMs in advancing ASAS technology.</description><author>Zifan Wang, Christopher Ormerod</author><pubDate>Wed, 07 Aug 2024 14:42:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03811v1</guid></item><item><title>Compression-Realized Deep Structural Network for Video Quality Enhancement</title><link>http://arxiv.org/abs/2405.06342v2</link><description>This paper focuses on the task of quality enhancement for compressed videos.Although deep network-based video restorers achieve impressive progress, mostof the existing methods lack a structured design to optimally leverage thepriors within compression codecs. Since the quality degradation of the video isprimarily induced by the compression algorithm, a new paradigm is urgentlyneeded for a more ``conscious'' process of quality enhancement. As a result, wepropose the Compression-Realized Deep Structural Network (CRDS), introducingthree inductive biases aligned with the three primary processes in the classiccompression codec, merging the strengths of classical encoder architecture withdeep network capabilities. Inspired by the residual extraction and domaintransformation process in the codec, a pre-trained Latent Degradation ResidualAuto-Encoder is proposed to transform video frames into a latent feature space,and the mutual neighborhood attention mechanism is integrated for precisemotion estimation and residual extraction. Furthermore, drawing inspirationfrom the quantization noise distribution of the codec, CRDS proposes a novelProgressive Denoising framework with intermediate supervision that decomposesthe quality enhancement into a series of simpler denoising sub-tasks.Experimental results on datasets like LDV 2.0 and MFQE 2.0 indicate ourapproach surpasses state-of-the-art models. Codes are available athttps://github.com/shc15522/CRDS.</description><author>Hanchi Sun, Xiaohong Liu, Xinyang Jiang, Yifei Shen, Dongsheng Li, Xiongkuo Min, Guangtao Zhai</author><pubDate>Wed, 07 Aug 2024 14:33:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06342v2</guid></item><item><title>Text-Region Matching for Multi-Label Image Recognition with Missing Labels</title><link>http://arxiv.org/abs/2407.18520v2</link><description>Recently, large-scale visual language pre-trained (VLP) models havedemonstrated impressive performance across various downstream tasks. Motivatedby these advancements, pioneering efforts have emerged in multi-label imagerecognition with missing labels, leveraging VLP prompt-tuning technology.However, they usually cannot match text and vision features well, due tocomplicated semantics gaps and missing labels in a multi-label image. To tacklethis challenge, we propose \textbf{T}ext-\textbf{R}egion \textbf{M}atching foroptimizing \textbf{M}ulti-\textbf{L}abel prompt tuning, namely TRM-ML, a novelmethod for enhancing meaningful cross-modal matching. Compared to existingmethods, we advocate exploring the information of category-aware regions ratherthan the entire image or pixels, which contributes to bridging the semantic gapbetween textual and visual representations in a one-to-one matching manner.Concurrently, we further introduce multimodal contrastive learning to narrowthe semantic gap between textual and visual modalities and establishintra-class and inter-class relationships. Additionally, to deal with missinglabels, we propose a multimodal category prototype that leverages intra- andinter-category semantic relationships to estimate unknown labels, facilitatingpseudo-label generation. Extensive experiments on the MS-COCO, PASCAL VOC,Visual Genome, NUS-WIDE, and CUB-200-211 benchmark datasets demonstrate thatour proposed framework outperforms the state-of-the-art methods by asignificant margin. Our code is availablehere\href{https://github.com/yu-gi-oh-leilei/TRM-ML}{\raisebox{-1pt}{\faGithub}}.</description><author>Leilei Ma, Hongxing Xie, Lei Wang, Yanping Fu, Dengdi Sun, Haifeng Zhao</author><pubDate>Wed, 07 Aug 2024 14:33:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18520v2</guid></item><item><title>Navigating the Human Maze: Real-Time Robot Pathfinding with Generative Imitation Learning</title><link>http://arxiv.org/abs/2408.03807v1</link><description>This paper addresses navigation in crowded environments by integratinggoal-conditioned generative models with Sampling-based Model Predictive Control(SMPC). We introduce goal-conditioned autoregressive models to generate crowdbehaviors, capturing intricate interactions among individuals. The modelprocesses potential robot trajectory samples and predicts the reactions ofsurrounding individuals, enabling proactive robotic navigation in complexscenarios. Extensive experiments show that this algorithm enables real-timenavigation, significantly reducing collision rates and path lengths, andoutperforming selected baseline methods. The practical effectiveness of thisalgorithm is validated on an actual robotic platform, demonstrating itscapability in dynamic settings.</description><author>Martin Moder, Stephen Adhisaputra, Josef Pauli</author><pubDate>Wed, 07 Aug 2024 14:32:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03807v1</guid></item><item><title>Trustworthy Image Semantic Communication with GenAI: Explainablity, Controllability, and Efficiency</title><link>http://arxiv.org/abs/2408.03806v1</link><description>Image semantic communication (ISC) has garnered significant attention for itspotential to achieve high efficiency in visual content transmission. However,existing ISC systems based on joint source-channel coding face challenges ininterpretability, operability, and compatibility. To address these limitations,we propose a novel trustworthy ISC framework. This approach leverages textextraction and segmentation mapping techniques to convert images intoexplainable semantics, while employing Generative Artificial Intelligence(GenAI) for multiple downstream inference tasks. We also introduce a multi-rateISC transmission protocol that dynamically adapts to both the receivedexplainable semantic content and specific task requirements at the receiver.Simulation results demonstrate that our framework achieves explainablelearning, decoupled training, and compatible transmission in variousapplication scenarios. Finally, some intriguing research directions andapplication scenarios are identified.</description><author>Xijun Wang, Dongshan Ye, Chenyuan Feng, Howard H. Yang, Xiang Chen, Tony Q. S. Quek</author><pubDate>Wed, 07 Aug 2024 14:32:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03806v1</guid></item><item><title>Frank's triangular norms in Piaget's logical proportions</title><link>http://arxiv.org/abs/2408.03795v1</link><description>Starting from the Boolean notion of logical proportion in Piaget's sense,which turns out to be equivalent to analogical proportion, this note proposes adefinition of analogical proportion between numerical values based ontriangular norms (and dual co-norms). Frank's family of triangular norms isparticularly interesting from this perspective. The article concludes with acomparative discussion with another very recent proposal for defininganalogical proportions between numerical values based on the family ofgeneralized means.</description><author>Henri Prade, Gilles Richard</author><pubDate>Wed, 07 Aug 2024 14:20:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03795v1</guid></item><item><title>Dynamic Language Group-Based MoE: Enhancing Code-Switching Speech Recognition with Hierarchical Routing</title><link>http://arxiv.org/abs/2407.18581v2</link><description>The Mixture of Experts (MoE) approach is well-suited for multilingual andcode-switching (CS) tasks due to its multi-expert architecture. This workintroduces the DLG-MoE, a Dynamic Language Group-based MoE optimized forbilingual and CS scenarios. DLG-MoE operates based on a hierarchical routingmechanism. First, the language router explicitly models the language anddispatches the representations to the corresponding language expert groups.Subsequently, the unsupervised router within each language group implicitlymodels attributes beyond language, and coordinates expert routing andcollaboration. The model achieves state-of-the-art (SOTA) performance whilealso having unparalleled flexibility. It supports different top-k inference andstreaming capabilities, and can also prune the model parameters to obtain amonolingual sub-model. The Code will be released.</description><author>Hukai Huang, Shenghui Lu, Yahui Shan, He Qu, Wenhao Guan, Qingyang Hong, Lin Li</author><pubDate>Wed, 07 Aug 2024 14:19:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18581v2</guid></item><item><title>Vision-Language Guidance for LiDAR-based Unsupervised 3D Object Detection</title><link>http://arxiv.org/abs/2408.03790v1</link><description>Accurate 3D object detection in LiDAR point clouds is crucial for autonomousdriving systems. To achieve state-of-the-art performance, the supervisedtraining of detectors requires large amounts of human-annotated data, which isexpensive to obtain and restricted to predefined object categories. To mitigatemanual labeling efforts, recent unsupervised object detection approachesgenerate class-agnostic pseudo-labels for moving objects, subsequently servingas supervision signal to bootstrap a detector. Despite promising results, theseapproaches do not provide class labels or generalize well to static objects.Furthermore, they are mostly restricted to data containing multiple drives fromthe same scene or images from a precisely calibrated and synchronized camerasetup. To overcome these limitations, we propose a vision-language-guidedunsupervised 3D detection approach that operates exclusively on LiDAR pointclouds. We transfer CLIP knowledge to classify point clusters of static andmoving objects, which we discover by exploiting the inherent spatio-temporalinformation of LiDAR point clouds for clustering, tracking, as well as box andlabel refinement. Our approach outperforms state-of-the-art unsupervised 3Dobject detectors on the Waymo Open Dataset ($+23~\text{AP}_{3D}$) and Argoverse2 ($+7.9~\text{AP}_{3D}$) and provides class labels not solely based on objectsize assumptions, marking a significant advancement in the field.</description><author>Christian Fruhwirth-Reisinger, Wei Lin, Dušan Malić, Horst Bischof, Horst Possegger</author><pubDate>Wed, 07 Aug 2024 14:14:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03790v1</guid></item><item><title>Counterfactuals and Uncertainty-Based Explainable Paradigm for the Automated Detection and Segmentation of Renal Cysts in Computed Tomography Images: A Multi-Center Study</title><link>http://arxiv.org/abs/2408.03789v1</link><description>Routine computed tomography (CT) scans often detect a wide range of renalcysts, some of which may be malignant. Early and precise localization of thesecysts can significantly aid quantitative image analysis. Current segmentationmethods, however, do not offer sufficient interpretability at the feature andpixel levels, emphasizing the necessity for an explainable framework that candetect and rectify model inaccuracies. We developed an interpretablesegmentation framework and validated it on a multi-centric dataset. AVariational Autoencoder Generative Adversarial Network (VAE-GAN) was employedto learn the latent representation of 3D input patches and reconstruct inputimages. Modifications in the latent representation using the gradient of thesegmentation model generated counterfactual explanations for varying dicesimilarity coefficients (DSC). Radiomics features extracted from thesecounterfactual images, using a ground truth cyst mask, were analyzed todetermine their correlation with segmentation performance. The DSCs for theoriginal and VAE-GAN reconstructed images for counterfactual image generationshowed no significant differences. Counterfactual explanations highlighted howvariations in cyst image features influence segmentation outcomes and showedmodel discrepancies. Radiomics features correlating positively and negativelywith dice scores were identified. The uncertainty of the predicted segmentationmasks was estimated using posterior sampling of the weight space. Thecombination of counterfactual explanations and uncertainty maps provided adeeper understanding of the image features within the segmented renal cyststhat lead to high uncertainty. The proposed segmentation framework not onlyachieved high segmentation accuracy but also increased interpretabilityregarding how image features impact segmentation performance.</description><author>Zohaib Salahuddin, Abdalla Ibrahim, Sheng Kuang, Yousif Widaatalla, Razvan L. Miclea, Oliver Morin, Spencer Behr, Marnix P. M. Kop, Tom Marcelissen, Patricia Zondervan, Auke Jager, Philippe Lambin, Henry C Woodruff</author><pubDate>Wed, 07 Aug 2024 14:14:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03789v1</guid></item><item><title>Diffusion-based Human Motion Style Transfer with Semantic Guidance</title><link>http://arxiv.org/abs/2405.06646v2</link><description>3D Human motion style transfer is a fundamental problem in computer graphicand animation processing. Existing AdaIN- based methods necessitate datasetswith balanced style distribution and content/style labels to train theclustered latent space. However, we may encounter a single unseen style examplein practical scenarios, but not in sufficient quantity to constitute a stylecluster for AdaIN-based methods. Therefore, in this paper, we propose a noveltwo-stage framework for few-shot style transfer learning based on the diffusionmodel. Specifically, in the first stage, we pre-train a diffusion-basedtext-to-motion model as a generative prior so that it can cope with variouscontent motion inputs. In the second stage, based on the single style example,we fine-tune the pre-trained diffusion model in a few-shot manner to make itcapable of style transfer. The key idea is regarding the reverse process ofdiffusion as a motion-style translation process since the motion styles can beviewed as special motion variations. During the fine-tuning for style transfer,a simple yet effective semantic-guided style transfer loss coordinated withstyle example reconstruction loss is introduced to supervise the style transferin CLIP semantic space. The qualitative and quantitative evaluationsdemonstrate that our method can achieve state-of-the-art performance and haspractical applications.</description><author>Lei Hu, Zihao Zhang, Yongjing Ye, Yiwen Xu, Shihong Xia</author><pubDate>Wed, 07 Aug 2024 14:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06646v2</guid></item><item><title>A Comprehensive Survey on Kolmogorov Arnold Networks (KAN)</title><link>http://arxiv.org/abs/2407.11075v2</link><description>Through this comprehensive survey of Kolmogorov-Arnold Networks(KAN), we havegained a thorough understanding of its theoretical foundation, architecturaldesign, application scenarios, and current research progress. KAN, with itsunique architecture and flexible activation functions, excels in handlingcomplex data patterns and nonlinear relationships, demonstrating wide-rangingapplication potential. While challenges remain, KAN is poised to pave the wayfor innovative solutions in various fields, potentially revolutionizing how weapproach complex computational problems.</description><author>Yuntian Hou, Di Zhang</author><pubDate>Wed, 07 Aug 2024 14:05:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11075v2</guid></item><item><title>Multi-times Monte Carlo Rendering for Inter-reflection Reconstruction</title><link>http://arxiv.org/abs/2407.05771v2</link><description>Inverse rendering methods have achieved remarkable performance inreconstructing high-fidelity 3D objects with disentangled geometries,materials, and environmental light. However, they still face huge challenges inreflective surface reconstruction. Although recent methods model the lighttrace to learn specularity, the ignorance of indirect illumination makes ithard to handle inter-reflections among multiple smooth objects. In this work,we propose Ref-MC2 that introduces the multi-time Monte Carlo sampling whichcomprehensively computes the environmental illumination and meanwhile considersthe reflective light from object surfaces. To address the computation challengeas the times of Monte Carlo sampling grow, we propose a specularity-adaptivesampling strategy, significantly reducing the computational complexity. Besidesthe computational resource, higher geometry accuracy is also required becausegeometric errors accumulate multiple times. Therefore, we further introduce areflection-aware surface model to initialize the geometry and refine it duringinverse rendering. We construct a challenging dataset containing scenes withmultiple objects and inter-reflections. Experiments show that our methodoutperforms other inverse rendering methods on various object groups. We alsoshow downstream applications, e.g., relighting and material editing, toillustrate the disentanglement ability of our method.</description><author>Tengjie Zhu, Zhuo Chen, Jingnan Gao, Yichao Yan, Xiaokang Yang</author><pubDate>Wed, 07 Aug 2024 14:01:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05771v2</guid></item><item><title>CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning</title><link>http://arxiv.org/abs/2407.15793v2</link><description>With the emergence of Transformers and Vision-Language Models (VLMs) such asCLIP, large pre-trained models have become a common strategy to enhanceperformance in Continual Learning scenarios. This led to the development ofnumerous prompting strategies to effectively fine-tune transformer-based modelswithout succumbing to catastrophic forgetting. However, these methods struggleto specialize the model on domains significantly deviating from thepre-training and preserving its zero-shot capabilities. In this work, wepropose Continual Generative training for Incremental prompt-Learning, a novelapproach to mitigate forgetting while adapting a VLM, which exploits generativereplay to align prompts to tasks. We also introduce a new metric to evaluatezero-shot capabilities within CL benchmarks. Through extensive experiments ondifferent domains, we demonstrate the effectiveness of our framework inadapting to new tasks while improving zero-shot capabilities. Further analysisreveals that our approach can bridge the gap with joint prompt tuning. Thecodebase is available at https://github.com/aimagelab/mammoth.</description><author>Emanuele Frascaroli, Aniello Panariello, Pietro Buzzega, Lorenzo Bonicelli, Angelo Porrello, Simone Calderara</author><pubDate>Wed, 07 Aug 2024 13:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.15793v2</guid></item><item><title>Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations</title><link>http://arxiv.org/abs/2408.03772v1</link><description>Providing recommendations that are both relevant and diverse is a keyconsideration of modern recommender systems. Optimizing both of these measurespresents a fundamental trade-off, as higher diversity typically comes at thecost of relevance, resulting in lower user engagement. Existing recommendationalgorithms try to resolve this trade-off by combining the two measures,relevance and diversity, into one aim and then seeking recommendations thatoptimize the combined objective, for a given number of items to recommend.Traditional approaches, however, do not consider the user interaction with therecommended items. In this paper, we put the user at the central stage, and build on theinterplay between relevance, diversity, and user behavior. In contrast toapplications where the goal is solely to maximize engagement, we focus onscenarios aiming at maximizing the total amount of knowledge encountered by theuser. We use diversity as a surrogate of the amount of knowledge obtained bythe user while interacting with the system, and we seek to maximize diversity.We propose a probabilistic user-behavior model in which users keep interactingwith the recommender system as long as they receive relevant recommendations,but they may stop if the relevance of the recommended items drops. Thus, for arecommender system to achieve a high-diversity measure, it will need to producerecommendations that are both relevant and diverse. Finally, we propose a novel recommendation strategy that combines relevanceand diversity by a copula function. We conduct an extensive evaluation of theproposed methodology over multiple datasets, and we show that our strategyoutperforms several state-of-the-art competitors. Our implementation ispublicly available at https://github.com/EricaCoppolillo/EXPLORE.</description><author>Erica Coppolillo, Giuseppe Manco, Aristides Gionis</author><pubDate>Wed, 07 Aug 2024 13:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03772v1</guid></item><item><title>Methodological Explainability Evaluation of an Interpretable Deep Learning Model for Post-Hepatectomy Liver Failure Prediction Incorporating Counterfactual Explanations and Layerwise Relevance Propagation: A Prospective In Silico Trial</title><link>http://arxiv.org/abs/2408.03771v1</link><description>Artificial intelligence (AI)-based decision support systems have demonstratedvalue in predicting post-hepatectomy liver failure (PHLF) in hepatocellularcarcinoma (HCC). However, they often lack transparency, and the impact of modelexplanations on clinicians' decisions has not been thoroughly evaluated.Building on prior research, we developed a variational autoencoder-multilayerperceptron (VAE-MLP) model for preoperative PHLF prediction. This modelintegrated counterfactuals and layerwise relevance propagation (LRP) to provideinsights into its decision-making mechanism. Additionally, we proposed amethodological framework for evaluating the explainability of AI systems. Thisframework includes qualitative and quantitative assessments of explanationsagainst recognized biomarkers, usability evaluations, and an in silico clinicaltrial. Our evaluations demonstrated that the model's explanation correlatedwith established biomarkers and exhibited high usability at both the case andsystem levels. Furthermore, results from the three-track in silico clinicaltrial showed that clinicians' prediction accuracy and confidence increased whenAI explanations were provided.</description><author>Xian Zhong, Zohaib Salahuddin, Yi Chen, Henry C Woodruff, Haiyi Long, Jianyun Peng, Nuwan Udawatte, Roberto Casale, Ayoub Mokhtari, Xiaoer Zhang, Jiayao Huang, Qingyu Wu, Li Tan, Lili Chen, Dongming Li, Xiaoyan Xie, Manxia Lin, Philippe Lambin</author><pubDate>Wed, 07 Aug 2024 13:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03771v1</guid></item><item><title>RCA: Region Conditioned Adaptation for Visual Abductive Reasoning</title><link>http://arxiv.org/abs/2303.10428v5</link><description>Visual abductive reasoning aims to make likely explanations for visualobservations. We propose a simple yet effective Region Conditioned Adaptation,a hybrid parameter-efficient fine-tuning method that equips the frozen CLIPwith the ability to infer explanations from local visual cues. We encode``local hints'' and ``global contexts'' into visual prompts of the CLIP modelseparately at fine and coarse-grained levels. Adapters are used for fine-tuningCLIP models for downstream tasks and we design a new attention adapter, thatdirectly steers the focus of the attention map with trainable query and keyprojections of a frozen CLIP model. Finally, we train our new model with amodified contrastive loss to regress the visual feature simultaneously towardfeatures of literal description and plausible explanations. The loss enablesCLIP to maintain both perception and reasoning abilities. Experiments on theSherlock visual abductive reasoning benchmark show that the RCA significantlyoutstands previous SOTAs, ranking the \nth{1} on the leaderboards (e.g., HumanAcc: RCA 31.74 \textit{vs} CPT-CLIP 29.58, higher =better). We also validatethe RCA is generalizable to local perception benchmarks like RefCOCO. Weopen-source our project at\textit{\color{magenta}{\url{https://github.com/LUNAProject22/RPA}}}.</description><author>Hao Zhang, Yeo Keat Ee, Basura Fernando</author><pubDate>Wed, 07 Aug 2024 13:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10428v5</guid></item><item><title>Sampling for Model Predictive Trajectory Planning in Autonomous Driving using Normalizing Flows</title><link>http://arxiv.org/abs/2404.09657v3</link><description>Alongside optimization-based planners, sampling-based approaches are oftenused in trajectory planning for autonomous driving due to their simplicity.Model predictive path integral control is a framework that builds uponoptimization principles while incorporating stochastic sampling of inputtrajectories. This paper investigates several sampling approaches fortrajectory generation. In this context, normalizing flows originating from thefield of variational inference are considered for the generation of samplingdistributions, as they model transformations of simple to more complexdistributions. Accordingly, learning-based normalizing flow models are trainedfor a more efficient exploration of the input domain for the task at hand. Thedeveloped algorithm and the proposed sampling distributions are evaluated intwo simulation scenarios.</description><author>Georg Rabenstein, Lars Ullrich, Knut Graichen</author><pubDate>Wed, 07 Aug 2024 13:44:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09657v3</guid></item><item><title>CA-LoRA: Adapting Existing LoRA for Compressed LLMs to Enable Efficient Multi-Tasking on Personal Devices</title><link>http://arxiv.org/abs/2307.07705v3</link><description>Recently, there has been a demand to deploy Large Language Models (LLMs) onpersonal devices such as laptops and smartphones. These LLMs have differentmodel variants when handling different tasks. However, personal devices havelimited resources and require reduced storage overhead. To address this, thereare two key methods available: the first is model compression, which compressesLLMs into smaller sizes; the second is LoRA, which can transfer an LLM to othertasks with very few parameters, avoiding the storage of multiple model variantsin multi-task scenarios by only preserving LoRAs. However, our experiments showthat directly combining these two methods yields sub-optimal performance.Considering that the open-source community has already contributed many LoRAsto LLMs, we propose to adapt these existing LoRAs from the LLMs to theircompressed version and introduce a Compression-Aware LoRA (CA-LoRA) framework.We incorporate knowledge inheritance and recovery strategies to recover thelost knowledge caused by model compression. Experiment results demonstrate thatCA-LoRA outperforms the vanilla LoRA methods applied to a compressed LLM andachieves comparable performance to the non-compressed LLM with existing LoRAmodules. The source code of CA-LoRA is available athttps://github.com/thunlp/CA-LoRA.</description><author>Weilin Zhao, Yuxiang Huang, Xu Han, Zhiyuan Liu, Zhengyan Zhang, Kuai Li, Chen Chen, Tao Yang, Maosong Sun</author><pubDate>Wed, 07 Aug 2024 13:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07705v3</guid></item><item><title>Nadaraya-Watson kernel smoothing as a random energy model</title><link>http://arxiv.org/abs/2408.03769v1</link><description>We investigate the behavior of the Nadaraya-Watson kernel smoothing estimatorin high dimensions using its relationship to the random energy model and todense associative memories.</description><author>Jacob A. Zavatone-Veth, Cengiz Pehlevan</author><pubDate>Wed, 07 Aug 2024 13:43:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03769v1</guid></item><item><title>TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities</title><link>http://arxiv.org/abs/2407.21693v2</link><description>Task-oriented dialogue (TOD) systems aim to efficiently handle task-orientedconversations, including information collection. How to utilize TOD accurately,efficiently and effectively for information collection has always been acritical and challenging task. Recent studies have demonstrated that LargeLanguage Models (LLMs) excel in dialogue, instruction generation, andreasoning, and can significantly enhance the performance of TOD throughfine-tuning. However, current datasets primarily cater to user-led systems andare limited to predefined specific scenarios and slots, thereby necessitatingimprovements in the proactiveness, diversity, and capabilities of TOD. In thisstudy, we present a detailed multi-domain task-oriented data constructionprocess for conversations, and a Chinese dialogue dataset generated based onthis process, TransferTOD, which authentically simulates human-computerdialogues in 30 popular life service scenarios. Leveraging this dataset, wetrained a model called TransferTOD-7B using full-parameter fine-tuning,showcasing notable abilities in slot filling and questioning. Our work hasdemonstrated its strong generalization capabilities in various downstreamscenarios, significantly enhancing both data utilization efficiency and systemperformance. The data is released inhttps://github.com/KongLongGeFDU/TransferTOD.</description><author>Ming Zhang, Caishuang Huang, Yilong Wu, Shichun Liu, Huiyuan Zheng, Yurui Dong, Yujiong Shen, Shihan Dou, Jun Zhao, Junjie Ye, Qi Zhang, Tao Gui, Xuanjing Huang</author><pubDate>Wed, 07 Aug 2024 13:42:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21693v2</guid></item><item><title>Investigating and Defending Shortcut Learning in Personalized Diffusion Models</title><link>http://arxiv.org/abs/2406.18944v3</link><description>Personalized diffusion models have gained popularity for adapting pre-trainedtext-to-image models to generate images of specific topics with minimaltraining data. However, these models are vulnerable to minor adversarialperturbations, leading to degraded performance on corrupted datasets. Suchvulnerabilities are further exploited to craft protective perturbations onsensitive images like portraits that prevent unauthorized generation. Inresponse, diffusion-based purification methods have been proposed to removethese perturbations and retain generation performance. However, existing worksturn to over-purifying the images, which causes information loss. In thispaper, we take a closer look at the fine-tuning process of personalizeddiffusion models through the lens of shortcut learning. And we propose ahypothesis explaining the manipulation mechanisms of existing perturbationmethods, demonstrating that perturbed images significantly deviate from theiroriginal prompts in the CLIP-based latent space. This misalignment duringfine-tuning causes models to associate noisy patterns with identifiers,resulting in performance degradation. Based on these insights, we introduce asystematic approach to maintain training performance through purification. Ourmethod first purifies the images to realign them with their original semanticmeanings in latent space. Then, we introduce contrastive learning with negativetokens to decouple the learning of clean identities from noisy patterns, whichshows a strong potential capacity against adaptive perturbation. Our studyuncovers shortcut learning vulnerabilities in personalized diffusion models andprovides a firm evaluation framework for future protective perturbationresearch. Code is available at https://github.com/liuyixin-louis/DiffShortcut.</description><author>Yixin Liu, Ruoxi Chen, Lichao Sun</author><pubDate>Wed, 07 Aug 2024 13:37:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18944v3</guid></item><item><title>Reliable Node Similarity Matrix Guided Contrastive Graph Clustering</title><link>http://arxiv.org/abs/2408.03765v1</link><description>Graph clustering, which involves the partitioning of nodes within a graphinto disjoint clusters, holds significant importance for numerous subsequentapplications. Recently, contrastive learning, known for utilizing supervisoryinformation, has demonstrated encouraging results in deep graph clustering.This methodology facilitates the learning of favorable node representations forclustering by attracting positively correlated node pairs and distancingnegatively correlated pairs within the representation space. Nevertheless, asignificant limitation of existing methods is their inadequacy in thoroughlyexploring node-wise similarity. For instance, some hypothesize that the nodesimilarity matrix within the representation space is identical, ignoring theinherent semantic relationships among nodes. Given the fundamental role ofinstance similarity in clustering, our research investigates contrastive graphclustering from the perspective of the node similarity matrix. We argue that anideal node similarity matrix within the representation space should accuratelyreflect the inherent semantic relationships among nodes, ensuring thepreservation of semantic similarities in the learned representations. Inresponse to this, we introduce a new framework, Reliable Node Similarity MatrixGuided Contrastive Graph Clustering (NS4GC), which estimates an approximatelyideal node similarity matrix within the representation space to guiderepresentation learning. Our method introduces node-neighbor alignment andsemantic-aware sparsification, ensuring the node similarity matrix is bothaccurate and efficiently sparse. Comprehensive experiments conducted on $8$real-world datasets affirm the efficacy of learning the node similarity matrixand the superior performance of NS4GC.</description><author>Yunhui Liu, Xinyi Gao, Tieke He, Tao Zheng, Jianhua Zhao, Hongzhi Yin</author><pubDate>Wed, 07 Aug 2024 13:36:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03765v1</guid></item><item><title>'Finance Wizard' at the FinLLM Challenge Task: Financial Text Summarization</title><link>http://arxiv.org/abs/2408.03762v1</link><description>This paper presents our participation under the team name `Finance Wizard' inthe FinNLP-AgentScen 2024 shared task #2: Financial Text Summarization. Itdocuments our pipeline approach of fine-tuning a foundation model into atask-specific model for Financial Text Summarization. It involves (1) adaptingLlama3 8B, a foundation model, to the Finance domain via continuedpre-training, (2) multi-task instruction-tuning to further equip the model withmore finance-related capabilities, (3) finally fine-tuning the model into atask-specific `expert'. Our model, FinLlama3\_sum, yielded commendable results,securing the third position in its category with a ROUGE-1 score of 0.521.</description><author>Meisin Lee, Soon Lay-Ki</author><pubDate>Wed, 07 Aug 2024 13:31:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03762v1</guid></item><item><title>MMSummary: Multimodal Summary Generation for Fetal Ultrasound Video</title><link>http://arxiv.org/abs/2408.03761v1</link><description>We present the first automated multimodal summary generation system,MMSummary, for medical imaging video, particularly with a focus on fetalultrasound analysis. Imitating the examination process performed by a humansonographer, MMSummary is designed as a three-stage pipeline, progressing fromkeyframe detection to keyframe captioning and finally anatomy segmentation andmeasurement. In the keyframe detection stage, an innovative automated workflowis proposed to progressively select a concise set of keyframes, preservingsufficient video information without redundancy. Subsequently, we adapt a largelanguage model to generate meaningful captions for fetal ultrasound keyframesin the keyframe captioning stage. If a keyframe is captioned as fetal biometry,the segmentation and measurement stage estimates biometric parameters bysegmenting the region of interest according to the textual prior. The MMSummarysystem provides comprehensive summaries for fetal ultrasound examinations andbased on reported experiments is estimated to reduce scanning time byapproximately 31.5%, thereby suggesting the potential to enhance clinicalworkflow efficiency.</description><author>Xiaoqing Guo, Qianhui Men, J. Alison Noble</author><pubDate>Wed, 07 Aug 2024 13:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03761v1</guid></item><item><title>Improved Monte Carlo tree search formulation with multiple root nodes for discrete sizing optimization of truss structures</title><link>http://arxiv.org/abs/2309.06045v4</link><description>This paper proposes a novel reinforcement learning (RL) algorithm usingimproved Monte Carlo tree search (IMCTS) formulation for discrete optimumdesign of truss structures. IMCTS with multiple root nodes includes updateprocess, the best reward, accelerating technique, and terminal condition.Update process means that once a final solution is found, it is used as theinitial solution for next search tree. The best reward is used in thebackpropagation step. Accelerating technique is introduced by decreasing thewidth of search tree and reducing maximum number of iterations. The agent istrained to minimize the total structural weight under various constraints untilthe terminal condition is satisfied. Then, optimal solution is the minimumvalue of all solutions found by search trees. These numerical examples showthat the agent can find optimal solution with low computational cost, stablyproduces an optimal design, and is suitable for multi-objective structuraloptimization and large-scale structures.</description><author>Fu-Yao Ko, Katsuyuki Suzuki, Kazuo Yonekura</author><pubDate>Wed, 07 Aug 2024 13:29:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06045v4</guid></item></channel></rss>