<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 23 Jul 2023 06:00:09 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Data-driven criteria for quantum correlations</title><link>http://arxiv.org/abs/2307.11091v1</link><description>We build a machine learning model to detect correlations in a three-qubitsystem using a neural network trained in an unsupervised manner on randomlygenerated states. The network is forced to recognize separable states, andcorrelated states are detected as anomalies. Quite surprisingly, we find thatthe proposed detector performs much better at distinguishing a weaker form ofquantum correlations, namely, the quantum discord, than entanglement. In fact,it has a tendency to grossly overestimate the set of entangled states even atthe optimal threshold for entanglement detection, while it underestimates theset of discordant states to a much lesser extent. In order to illustrate thenature of states classified as quantum-correlated, we construct a diagramcontaining various types of states -- entangled, as well as separable, bothdiscordant and non-discordant. We find that the near-zero value of therecognition loss reproduces the shape of the non-discordant separable stateswith high accuracy, especially considering the non-trivial shape of this set onthe diagram. The network architecture is designed carefully: it preservesseparability, and its output is equivariant with respect to qubit permutations.We show that the choice of architecture is important to get the highestdetection accuracy, much better than for a baseline model that just utilizes apartial trace operation.</description><author>Mateusz Krawczyk, Jarosław Pawłowski, Maciej M. Maśka, Katarzyna Roszak</author><pubDate>Thu, 20 Jul 2023 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11091v1</guid></item><item><title>L-Eval: Instituting Standardized Evaluation for Long Context Language Models</title><link>http://arxiv.org/abs/2307.11088v1</link><description>Recently, there has been growing interest in extending the context length ofinstruction-following models in order to effectively process single-turn longinput (e.g. summarizing a paper) and conversations with more extensivehistories. While proprietary models such as GPT-4 and Claude have demonstratedconsiderable advancements in handling tens of thousands of tokens of context,open-sourced models are still in the early stages of experimentation. It alsoremains unclear whether developing these long context models can offersubstantial gains on practical downstream tasks over retrieval-based methods ormodels simply trained on chunked contexts. To address this challenge, wepropose to institute standardized evaluation for long context language models.Concretely, we develop L-Eval which contains 411 long documents and over 2,000query-response pairs manually annotated and checked by the authors encompassingareas such as law, finance, school lectures, lengthy conversations, news,long-form novels, and meetings. L-Eval also adopts diverse evaluation methodsand instruction styles, enabling a more reliable assessment of Long ContextLanguage Models (LCLMs). Our findings indicate that while open-source modelstypically lag behind their commercial counterparts, they still exhibitimpressive performance. LLaMA2 achieves the best results (win 45\% vsturbo-16k) on open-ended tasks with only 4k context length and ChatGLM2achieves the best results on closed-ended tasks with 8k input tokens. Werelease our new evaluation suite, code, and all generation results includingpredictions from all open-sourced LCLMs, GPT4-32k, Cluade-100k at{\url{https://github.com/OpenLMLab/LEval}}.</description><author>Chenxin An, Shansan Gong, Ming Zhong, Mukai Li, Jun Zhang, Lingpeng Kong, Xipeng Qiu</author><pubDate>Thu, 20 Jul 2023 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11088v1</guid></item><item><title>DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI</title><link>http://arxiv.org/abs/2307.10172v2</link><description>Despite advancements in conversational AI, language models encounterchallenges to handle diverse conversational tasks, and existing dialoguedataset collections often lack diversity and comprehensiveness. To tackle theseissues, we introduce DialogStudio: the largest and most diverse collection ofdialogue datasets, unified under a consistent format while preserving theiroriginal information. Our collection encompasses data from open-domaindialogues, task-oriented dialogues, natural language understanding,conversational recommendation, dialogue summarization, and knowledge-groundeddialogues, making it an incredibly rich and diverse resource for dialogueresearch and model training. To further enhance the utility of DialogStudio, weidentify the licenses for each dataset and design domain-aware prompts forselected dialogues to facilitate instruction-aware fine-tuning. Furthermore, wedevelop conversational AI models using the dataset collection, and ourexperiments in both zero-shot and few-shot learning scenarios demonstrate thesuperiority of DialogStudio. To improve transparency and support dataset andtask-based research, as well as language model pre-training, all datasets,licenses, codes, and models associated with DialogStudio are made publiclyaccessible at https://github.com/salesforce/DialogStudio</description><author>Jianguo Zhang, Kun Qian, Zhiwei Liu, Shelby Heinecke, Rui Meng, Ye Liu, Zhou Yu, Huan Wang, Silvio Savarese, Caiming Xiong</author><pubDate>Thu, 20 Jul 2023 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10172v2</guid></item><item><title>PAPR: Proximity Attention Point Rendering</title><link>http://arxiv.org/abs/2307.11086v1</link><description>Learning accurate and parsimonious point cloud representations of scenesurfaces from scratch remains a challenge in 3D representation learning.Existing point-based methods often suffer from the vanishing gradient problemor require a large number of points to accurately model scene geometry andtexture. To address these limitations, we propose Proximity Attention PointRendering (PAPR), a novel method that consists of a point-based scenerepresentation and a differentiable renderer. Our scene representation uses apoint cloud where each point is characterized by its spatial position,foreground score, and view-independent feature vector. The renderer selects therelevant points for each ray and produces accurate colours using theirassociated features. PAPR effectively learns point cloud positions to representthe correct scene geometry, even when the initialization drastically differsfrom the target geometry. Notably, our method captures fine texture detailswhile using only a parsimonious set of points. We also demonstrate fourpractical applications of our method: geometry editing, object manipulation,texture transfer, and exposure control. More results and code are available onour project website at https://zvict.github.io/papr/.</description><author>Yanshu Zhang, Shichong Peng, Alireza Moazeni, Ke Li</author><pubDate>Thu, 20 Jul 2023 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11086v1</guid></item><item><title>Frequency Domain Adversarial Training for Robust Volumetric Medical Segmentation</title><link>http://arxiv.org/abs/2307.07269v2</link><description>It is imperative to ensure the robustness of deep learning models in criticalapplications such as, healthcare. While recent advances in deep learning haveimproved the performance of volumetric medical image segmentation models, thesemodels cannot be deployed for real-world applications immediately due to theirvulnerability to adversarial attacks. We present a 3D frequency domainadversarial attack for volumetric medical image segmentation models anddemonstrate its advantages over conventional input or voxel domain attacks.Using our proposed attack, we introduce a novel frequency domain adversarialtraining approach for optimizing a robust model against voxel and frequencydomain attacks. Moreover, we propose frequency consistency loss to regulate ourfrequency domain adversarial training that achieves a better tradeoff betweenmodel's performance on clean and adversarial samples. Code is publiclyavailable at https://github.com/asif-hanif/vafa.</description><author>Asif Hanif, Muzammal Naseer, Salman Khan, Mubarak Shah, Fahad Shahbaz Khan</author><pubDate>Thu, 20 Jul 2023 18:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07269v2</guid></item><item><title>Mathematical Capabilities of ChatGPT</title><link>http://arxiv.org/abs/2301.13867v2</link><description>We investigate the mathematical capabilities of two iterations of ChatGPT(released 9-January-2023 and 30-January-2023) and of GPT-4 by testing them onpublicly available datasets, as well as hand-crafted ones, using a novelmethodology. In contrast to formal mathematics, where large databases of formalproofs are available (e.g., the Lean Mathematical Library), current datasets ofnatural-language mathematics, used to benchmark language models, either coveronly elementary mathematics or are very small. We address this by publiclyreleasing two new datasets: GHOSTS and miniGHOSTS. These are the firstnatural-language datasets curated by working researchers in mathematics that(1) aim to cover graduate-level mathematics, (2) provide a holistic overview ofthe mathematical capabilities of language models, and (3) distinguish multipledimensions of mathematical reasoning. These datasets also test whether ChatGPTand GPT-4 can be helpful assistants to professional mathematicians by emulatinguse cases that arise in the daily professional activities of mathematicians. Webenchmark the models on a range of fine-grained performance metrics. Foradvanced mathematics, this is the most detailed evaluation effort to date. Wefind that ChatGPT can be used most successfully as a mathematical assistant forquerying facts, acting as a mathematical search engine and knowledge baseinterface. GPT-4 can additionally be used for undergraduate-level mathematicsbut fails on graduate-level difficulty. Contrary to many positive reports inthe media about GPT-4 and ChatGPT's exam-solving abilities (a potential case ofselection bias), their overall mathematical performance is well below the levelof a graduate student. Hence, if your goal is to use ChatGPT to pass agraduate-level math exam, you would be better off copying from your averagepeer!</description><author>Simon Frieder, Luca Pinchetti, Alexis Chevalier, Ryan-Rhys Griffiths, Tommaso Salvatori, Thomas Lukasiewicz, Philipp Christian Petersen, Julius Berner</author><pubDate>Thu, 20 Jul 2023 18:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13867v2</guid></item><item><title>Representation Learning in Anomaly Detection: Successes, Limits and a Grand Challenge</title><link>http://arxiv.org/abs/2307.11085v1</link><description>In this perspective paper, we argue that the dominant paradigm in anomalydetection cannot scale indefinitely and will eventually hit fundamental limits.This is due to the a no free lunch principle for anomaly detection. Theselimitations can be overcome when there are strong tasks priors, as is the casefor many industrial tasks. When such priors do not exists, the task is muchharder for anomaly detection. We pose two such tasks as grand challenges foranomaly detection: i) scientific discovery by anomaly detection ii) a"mini-grand" challenge of detecting the most anomalous image in the ImageNetdataset. We believe new anomaly detection tools and ideas would need to bedeveloped to overcome these challenges.</description><author>Yedid Hoshen</author><pubDate>Thu, 20 Jul 2023 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11085v1</guid></item><item><title>Torchhd: An Open Source Python Library to Support Research on Hyperdimensional Computing and Vector Symbolic Architectures</title><link>http://arxiv.org/abs/2205.09208v2</link><description>Hyperdimensional computing (HD), also known as vector symbolic architectures(VSA), is a framework for computing with distributed representations byexploiting properties of random high-dimensional vector spaces. The commitmentof the scientific community to aggregate and disseminate research in thisparticularly multidisciplinary area has been fundamental for its advancement.Joining these efforts, we present Torchhd, a high-performance open sourcePython library for HD/VSA. Torchhd seeks to make HD/VSA more accessible andserves as an efficient foundation for further research and applicationdevelopment. The easy-to-use library builds on top of PyTorch and featuresstate-of-the-art HD/VSA functionality, clear documentation, and implementationexamples from well-known publications. Comparing publicly available code withtheir corresponding Torchhd implementation shows that experiments can run up to100x faster. Torchhd is available at:https://github.com/hyperdimensional-computing/torchhd.</description><author>Mike Heddes, Igor Nunes, Pere Vergés, Denis Kleyko, Danny Abraham, Tony Givargis, Alexandru Nicolau, Alexander Veidenbaum</author><pubDate>Thu, 20 Jul 2023 18:57:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.09208v2</guid></item><item><title>GLSFormer : Gated - Long, Short Sequence Transformer for Step Recognition in Surgical Videos</title><link>http://arxiv.org/abs/2307.11081v1</link><description>Automated surgical step recognition is an important task that cansignificantly improve patient safety and decision-making during surgeries.Existing state-of-the-art methods for surgical step recognition either rely onseparate, multi-stage modeling of spatial and temporal information or operateon short-range temporal resolution when learned jointly. However, the benefitsof joint modeling of spatio-temporal features and long-range information arenot taken in account. In this paper, we propose a vision transformer-basedapproach to jointly learn spatio-temporal features directly from sequence offrame-level patches. Our method incorporates a gated-temporal attentionmechanism that intelligently combines short-term and long-term spatio-temporalfeature representations. We extensively evaluate our approach on two cataractsurgery video datasets, namely Cataract-101 and D99, and demonstrate superiorperformance compared to various state-of-the-art methods. These resultsvalidate the suitability of our proposed approach for automated surgical steprecognition. Our code is released at:https://github.com/nisargshah1999/GLSFormer</description><author>Nisarg A. Shah, Shameema Sikder, S. Swaroop Vedula, Vishal M. Patel</author><pubDate>Thu, 20 Jul 2023 18:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11081v1</guid></item><item><title>Brain2Music: Reconstructing Music from Human Brain Activity</title><link>http://arxiv.org/abs/2307.11078v1</link><description>The process of reconstructing experiences from human brain activity offers aunique lens into how the brain interprets and represents the world. In thispaper, we introduce a method for reconstructing music from brain activity,captured using functional magnetic resonance imaging (fMRI). Our approach useseither music retrieval or the MusicLM music generation model conditioned onembeddings derived from fMRI data. The generated music resembles the musicalstimuli that human subjects experienced, with respect to semantic propertieslike genre, instrumentation, and mood. We investigate the relationship betweendifferent components of MusicLM and brain activity through a voxel-wiseencoding modeling analysis. Furthermore, we discuss which brain regionsrepresent information derived from purely textual descriptions of musicstimuli. We provide supplementary material including examples of thereconstructed music at https://google-research.github.io/seanet/brain2music</description><author>Timo I. Denk, Yu Takagi, Takuya Matsuyama, Andrea Agostinelli, Tomoya Nakai, Christian Frank, Shinji Nishimoto</author><pubDate>Thu, 20 Jul 2023 18:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11078v1</guid></item><item><title>AlignDet: Aligning Pre-training and Fine-tuning in Object Detection</title><link>http://arxiv.org/abs/2307.11077v1</link><description>The paradigm of large-scale pre-training followed by downstream fine-tuninghas been widely employed in various object detection algorithms. In this paper,we reveal discrepancies in data, model, and task between the pre-training andfine-tuning procedure in existing practices, which implicitly limit thedetector's performance, generalization ability, and convergence speed. To thisend, we propose AlignDet, a unified pre-training framework that can be adaptedto various existing detectors to alleviate the discrepancies. AlignDetdecouples the pre-training process into two stages, i.e., image-domain andbox-domain pre-training. The image-domain pre-training optimizes the detectionbackbone to capture holistic visual abstraction, and box-domain pre-traininglearns instance-level semantics and task-aware concepts to initialize the partsout of the backbone. By incorporating the self-supervised pre-trainedbackbones, we can pre-train all modules for various detectors in anunsupervised paradigm. As depicted in Figure 1, extensive experimentsdemonstrate that AlignDet can achieve significant improvements across diverseprotocols, such as detection algorithm, model backbone, data setting, andtraining schedule. For example, AlignDet improves FCOS by 5.3 mAP, RetinaNet by2.1 mAP, Faster R-CNN by 3.3 mAP, and DETR by 2.3 mAP under fewer epochs.</description><author>Ming Li, Jie Wu, Xionghui Wang, Chen Chen, Jie Qin, Xuefeng Xiao, Rui Wang, Min Zheng, Xin Pan</author><pubDate>Thu, 20 Jul 2023 18:55:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11077v1</guid></item><item><title>Learning Dense UV Completion for Human Mesh Recovery</title><link>http://arxiv.org/abs/2307.11074v1</link><description>Human mesh reconstruction from a single image is challenging in the presenceof occlusion, which can be caused by self, objects, or other humans. Existingmethods either fail to separate human features accurately or lack propersupervision for feature completion. In this paper, we propose Dense InpaintingHuman Mesh Recovery (DIMR), a two-stage method that leverages densecorrespondence maps to handle occlusion. Our method utilizes a densecorrespondence map to separate visible human features and completes humanfeatures on a structured UV map dense human with an attention-based featurecompletion module. We also design a feature inpainting training procedure thatguides the network to learn from unoccluded features. We evaluate our method onseveral datasets and demonstrate its superior performance under heavilyoccluded scenarios compared to other methods. Extensive experiments show thatour method obviously outperforms prior SOTA methods on heavily occluded imagesand achieves comparable results on the standard benchmarks (3DPW).</description><author>Yanjun Wang, Qingping Sun, Wenjia Wang, Jun Ling, Zhongang Cai, Rong Xie, Li Song</author><pubDate>Thu, 20 Jul 2023 18:53:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11074v1</guid></item><item><title>OBJECT 3DIT: Language-guided 3D-aware Image Editing</title><link>http://arxiv.org/abs/2307.11073v1</link><description>Existing image editing tools, while powerful, typically disregard theunderlying 3D geometry from which the image is projected. As a result, editsmade using these tools may become detached from the geometry and lightingconditions that are at the foundation of the image formation process. In thiswork, we formulate the newt ask of language-guided 3D-aware editing, whereobjects in an image should be edited according to a language instruction incontext of the underlying 3D scene. To promote progress towards this goal, werelease OBJECT: a dataset consisting of 400K editing examples created fromprocedurally generated 3D scenes. Each example consists of an input image,editing instruction in language, and the edited image. We also introduce 3DIT :single and multi-task models for four editing tasks. Our models show impressiveabilities to understand the 3D composition of entire scenes, factoring insurrounding objects, surfaces, lighting conditions, shadows, andphysically-plausible object configurations. Surprisingly, training on onlysynthetic scenes from OBJECT, editing capabilities of 3DIT generalize toreal-world images.</description><author>Oscar Michel, Anand Bhattad, Eli VanderBilt, Ranjay Krishna, Aniruddha Kembhavi, Tanmay Gupta</author><pubDate>Thu, 20 Jul 2023 18:53:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11073v1</guid></item><item><title>Mitigating Calibration Bias Without Fixed Attribute Grouping for Improved Fairness in Medical Imaging Analysis</title><link>http://arxiv.org/abs/2307.01738v2</link><description>Trustworthy deployment of deep learning medical imaging models intoreal-world clinical practice requires that they be calibrated. However, modelsthat are well calibrated overall can still be poorly calibrated for asub-population, potentially resulting in a clinician unwittingly making poordecisions for this group based on the recommendations of the model. Althoughmethods have been shown to successfully mitigate biases across subgroups interms of model accuracy, this work focuses on the open problem of mitigatingcalibration biases in the context of medical image analysis. Our method doesnot require subgroup attributes during training, permitting the flexibility tomitigate biases for different choices of sensitive attributes withoutre-training. To this end, we propose a novel two-stage method: Cluster-Focal tofirst identify poorly calibrated samples, cluster them into groups, and thenintroduce group-wise focal loss to improve calibration bias. We evaluate ourmethod on skin lesion classification with the public HAM10000 dataset, and onpredicting future lesional activity for multiple sclerosis (MS) patients. Inaddition to considering traditional sensitive attributes (e.g. age, sex) withdemographic subgroups, we also consider biases among groups with differentimage-derived attributes, such as lesion load, which are required in medicalimage analysis. Our results demonstrate that our method effectively controlscalibration error in the worst-performing subgroups while preserving predictionperformance, and outperforming recent baselines.</description><author>Changjian Shui, Justin Szeto, Raghav Mehta, Douglas L. Arnold, Tal Arbel</author><pubDate>Thu, 20 Jul 2023 18:53:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01738v2</guid></item><item><title>Effectiveness and predictability of in-network storage cache for scientific workflows</title><link>http://arxiv.org/abs/2307.11069v1</link><description>Large scientific collaborations often have multiple scientists accessing thesame set of files while doing different analyses, which create repeatedaccesses to the large amounts of shared data located far away. These dataaccesses have long latency due to distance and occupy the limited bandwidthavailable over the wide-area network. To reduce the wide-area network trafficand the data access latency, regional data storage caches have been installedas a new networking service. To study the effectiveness of such a cache systemin scientific applications, we examine the Southern California Petabyte ScaleCache for a high-energy physics experiment. By examining about 3TB ofoperational logs, we show that this cache removed 67.6% of file requests fromthe wide-area network and reduced the traffic volume on wide-area network by12.3TB (or 35.4%) an average day. The reduction in the traffic volume (35.4%)is less than the reduction in file counts (67.6%) because the larger files areless likely to be reused. Due to this difference in data access patterns, thecache system has implemented a policy to avoid evicting smaller files whenprocessing larger files. We also build a machine learning model to study thepredictability of the cache behavior. Tests show that this model is able toaccurately predict the cache accesses, cache misses, and network throughput,making the model useful for future studies on resource provisioning andplanning.</description><author>Caitlin Sim, Kesheng Wu, Alex Sim, Inder Monga, Chin Guok, Frank Wurthwein, Diego Davila, Harvey Newman, Justas Balcas</author><pubDate>Thu, 20 Jul 2023 18:52:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11069v1</guid></item><item><title>CNOS: A Strong Baseline for CAD-based Novel Object Segmentation</title><link>http://arxiv.org/abs/2307.11067v1</link><description>We propose a simple three-stage approach to segment unseen objects in RGBimages using their CAD models. Leveraging recent powerful foundation models,DINOv2 and Segment Anything, we create descriptors and generate proposals,including binary masks for a given input RGB image. By matching proposals withreference descriptors created from CAD models, we achieve precise object IDassignment along with modal masks. We experimentally demonstrate that ourmethod achieves state-of-the-art results in CAD-based novel objectsegmentation, surpassing existing approaches on the seven core datasets of theBOP challenge by 19.8\% AP using the same BOP evaluation protocol. Our sourcecode is available at https://github.com/nv-nguyen/cnos.</description><author>Van Nguyen Nguyen, Tomas Hodan, Georgy Ponimatkin, Thibault Groueix, Vincent Lepetit</author><pubDate>Thu, 20 Jul 2023 18:46:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11067v1</guid></item><item><title>Potential Benefits of Employing Large Language Models in Research in Moral Education and Development</title><link>http://arxiv.org/abs/2306.13805v2</link><description>Recently, computer scientists have developed large language models (LLMs) bytraining prediction models with large-scale language corpora and humanreinforcements. The LLMs have become one promising way to implement artificialintelligence with accuracy in various fields. Interestingly, recent LLMspossess emergent functional features that emulate sophisticated humancognition, especially in-context learning and the chain of thought, which wereunavailable in previous prediction models. In this paper, I will examine howLLMs might contribute to moral education and development research. To achievethis goal, I will review the most recently published conference papers andArXiv preprints to overview the novel functional features implemented in LLMs.I also intend to conduct brief experiments with ChatGPT to investigate how LLMsbehave while addressing ethical dilemmas and external feedback. The resultssuggest that LLMs might be capable of solving dilemmas based on reasoning andrevising their reasoning process with external input. Furthermore, apreliminary experimental result from the moral exemplar test may demonstratethat exemplary stories can elicit moral elevation in LLMs as do they amonghuman participants. I will discuss the potential implications of LLMs onresearch on moral education and development with the results.</description><author>Hyemin Han</author><pubDate>Thu, 20 Jul 2023 18:45:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13805v2</guid></item><item><title>Driving Policy Prediction based on Deep Learning Models</title><link>http://arxiv.org/abs/2307.11058v1</link><description>In this project, we implemented an end-to-end system that takes in combinedvisual features of video frames from a normal camera and depth information froma cloud points scanner, and predicts driving policies (vehicle speed andsteering angle). We verified the safety of our system by comparing thepredicted results with standard behaviors by real-world experienced drivers.Our test results show that the predictions can be considered as accurate in atlease half of the testing cases (50% 80%, depending on the model), and usingcombined features improved the performance in most cases than using videoframes only.</description><author>Fuxiao Liu</author><pubDate>Thu, 20 Jul 2023 18:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11058v1</guid></item><item><title>Sabiá: Portuguese Large Language Models</title><link>http://arxiv.org/abs/2304.07880v3</link><description>As the capabilities of language models continue to advance, it is conceivablethat "one-size-fits-all" model will remain as the main paradigm. For instance,given the vast number of languages worldwide, many of which are low-resource,the prevalent practice is to pretrain a single model on multiple languages. Inthis paper, we add to the growing body of evidence that challenges thispractice, demonstrating that monolingual pretraining on the target languagesignificantly improves models already extensively trained on diverse corpora.More specifically, we further pretrain GPT-J and LLaMA models on Portuguesetexts using 3% or less of their original pretraining budget. Few-shotevaluations on Poeta, a suite of 14 Portuguese datasets, reveal that our modelsoutperform English-centric and multilingual counterparts by a significantmargin. Our best model, Sabi\'a-65B, performs on par with GPT-3.5-turbo. Byevaluating on datasets originally conceived in the target language as well astranslated ones, we study the contributions of language-specific pretraining interms of 1) capturing linguistic nuances and structures inherent to the targetlanguage, and 2) enriching the model's knowledge about a domain or culture. Ourresults indicate that the majority of the benefits stem from thedomain-specific knowledge acquired through monolingual pretraining.</description><author>Ramon Pires, Hugo Abonizio, Thales Sales Almeida, Rodrigo Nogueira</author><pubDate>Thu, 20 Jul 2023 18:34:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07880v3</guid></item><item><title>HRFNet: High-Resolution Forgery Network for Localizing Satellite Image Manipulation</title><link>http://arxiv.org/abs/2307.11052v1</link><description>Existing high-resolution satellite image forgery localization methods rely onpatch-based or downsampling-based training. Both of these training methods havemajor drawbacks, such as inaccurate boundaries between pristine and forgedregions, the generation of unwanted artifacts, etc. To tackle theaforementioned challenges, inspired by the high-resolution image segmentationliterature, we propose a novel model called HRFNet to enable satellite imageforgery localization effectively. Specifically, equipped with shallow and deepbranches, our model can successfully integrate RGB and resampling features inboth global and local manners to localize forgery more accurately. We performvarious experiments to demonstrate that our method achieves the bestperformance, while the memory requirement and processing speed are notcompromised compared to existing methods.</description><author>Fahim Faisal Niloy, Kishor Kumar Bhaumik, Simon S. Woo</author><pubDate>Thu, 20 Jul 2023 18:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11052v1</guid></item><item><title>Breadcrumbs to the Goal: Goal-Conditioned Exploration from Human-in-the-Loop Feedback</title><link>http://arxiv.org/abs/2307.11049v1</link><description>Exploration and reward specification are fundamental and intertwinedchallenges for reinforcement learning. Solving sequential decision-making tasksrequiring expansive exploration requires either careful design of rewardfunctions or the use of novelty-seeking exploration bonuses. Human supervisorscan provide effective guidance in the loop to direct the exploration process,but prior methods to leverage this guidance require constant synchronoushigh-quality human feedback, which is expensive and impractical to obtain. Inthis work, we present a technique called Human Guided Exploration (HuGE), whichuses low-quality feedback from non-expert users that may be sporadic,asynchronous, and noisy. HuGE guides exploration for reinforcement learning notonly in simulation but also in the real world, all without meticulous rewardspecification. The key concept involves bifurcating human feedback and policylearning: human feedback steers exploration, while self-supervised learningfrom the exploration data yields unbiased policies. This procedure can leveragenoisy, asynchronous human feedback to learn policies with no hand-craftedreward design or exploration bonuses. HuGE is able to learn a variety ofchallenging multi-stage robotic navigation and manipulation tasks in simulationusing crowdsourced feedback from non-expert users. Moreover, this paradigm canbe scaled to learning directly on real-world robots, using occasional,asynchronous feedback from human supervisors.</description><author>Marcel Torne, Max Balsells, Zihan Wang, Samedh Desai, Tao Chen, Pulkit Agrawal, Abhishek Gupta</author><pubDate>Thu, 20 Jul 2023 18:30:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11049v1</guid></item><item><title>A Definition of Continual Reinforcement Learning</title><link>http://arxiv.org/abs/2307.11046v1</link><description>In this paper we develop a foundation for continual reinforcement learning.</description><author>David Abel, André Barreto, Benjamin Van Roy, Doina Precup, Hado van Hasselt, Satinder Singh</author><pubDate>Thu, 20 Jul 2023 18:28:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11046v1</guid></item><item><title>On the Convergence of Bounded Agents</title><link>http://arxiv.org/abs/2307.11044v1</link><description>When has an agent converged? Standard models of the reinforcement learningproblem give rise to a straightforward definition of convergence: An agentconverges when its behavior or performance in each environment state stopschanging. However, as we shift the focus of our learning problem from theenvironment's state to the agent's state, the concept of an agent's convergencebecomes significantly less clear. In this paper, we propose two complementaryaccounts of agent convergence in a framing of the reinforcement learningproblem that centers around bounded agents. The first view says that a boundedagent has converged when the minimal number of states needed to describe theagent's future behavior cannot decrease. The second view says that a boundedagent has converged just when the agent's performance only changes if theagent's internal state changes. We establish basic properties of these twodefinitions, show that they accommodate typical views of convergence instandard settings, and prove several facts about their nature and relationship.We take these perspectives, definitions, and analysis to bring clarity to acentral idea of the field.</description><author>David Abel, André Barreto, Hado van Hasselt, Benjamin Van Roy, Doina Precup, Satinder Singh</author><pubDate>Thu, 20 Jul 2023 18:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11044v1</guid></item><item><title>LA-Net: Landmark-Aware Learning for Reliable Facial Expression Recognition under Label Noise</title><link>http://arxiv.org/abs/2307.09023v3</link><description>Facial expression recognition (FER) remains a challenging task due to theambiguity of expressions. The derived noisy labels significantly harm theperformance in real-world scenarios. To address this issue, we present a newFER model named Landmark-Aware Net~(LA-Net), which leverages facial landmarksto mitigate the impact of label noise from two perspectives. Firstly, LA-Netuses landmark information to suppress the uncertainty in expression space andconstructs the label distribution of each sample by neighborhood aggregation,which in turn improves the quality of training supervision. Secondly, the modelincorporates landmark information into expression representations using thedevised expression-landmark contrastive loss. The enhanced expression featureextractor can be less susceptible to label noise. Our method can be integratedwith any deep neural network for better training supervision withoutintroducing extra inference costs. We conduct extensive experiments on bothin-the-wild datasets and synthetic noisy datasets and demonstrate that LA-Netachieves state-of-the-art performance.</description><author>Zhiyu Wu, Jinshi Cui</author><pubDate>Thu, 20 Jul 2023 18:23:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09023v3</guid></item><item><title>Understanding Uncertainty Sampling</title><link>http://arxiv.org/abs/2307.02719v3</link><description>Uncertainty sampling is a prevalent active learning algorithm that queriessequentially the annotations of data samples which the current prediction modelis uncertain about. However, the usage of uncertainty sampling has been largelyheuristic: (i) There is no consensus on the proper definition of "uncertainty"for a specific task under a specific loss; (ii) There is no theoreticalguarantee that prescribes a standard protocol to implement the algorithm, forexample, how to handle the sequentially arrived annotated data under theframework of optimization algorithms such as stochastic gradient descent. Inthis work, we systematically examine uncertainty sampling algorithms under bothstream-based and pool-based active learning. We propose a notion of equivalentloss which depends on the used uncertainty measure and the original lossfunction and establish that an uncertainty sampling algorithm essentiallyoptimizes against such an equivalent loss. The perspective verifies theproperness of existing uncertainty measures from two aspects: surrogateproperty and loss convexity. Furthermore, we propose a new notion for designinguncertainty measures called \textit{loss as uncertainty}. The idea is to usethe conditional expected loss given the features as the uncertainty measure.Such an uncertainty measure has nice analytical properties and generality tocover both classification and regression problems, which enable us to providethe first generalization bound for uncertainty sampling algorithms under bothstream-based and pool-based settings, in the full generality of the underlyingmodel and problem. Lastly, we establish connections between certain variants ofthe uncertainty sampling algorithms with risk-sensitive objectives anddistributional robustness, which can partly explain the advantage ofuncertainty sampling algorithms when the sample size is small.</description><author>Shang Liu, Xiaocheng Li</author><pubDate>Thu, 20 Jul 2023 18:17:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02719v3</guid></item><item><title>Towards a Complete Analysis of Langevin Monte Carlo: Beyond Poincaré Inequality</title><link>http://arxiv.org/abs/2303.03589v2</link><description>Langevin diffusions are rapidly convergent under appropriate functionalinequality assumptions. Hence, it is natural to expect that with additionalsmoothness conditions to handle the discretization errors, theirdiscretizations like the Langevin Monte Carlo (LMC) converge in a similarfashion. This research program was initiated by Vempala and Wibisono (2019),who established results under log-Sobolev inequalities. Chewi et al. (2022)extended the results to handle the case of Poincar\'e inequalities. In thispaper, we go beyond Poincar\'e inequalities, and push this research program toits limit. We do so by establishing upper and lower bounds for Langevindiffusions and LMC under weak Poincar\'e inequalities that are satisfied by alarge class of densities including polynomially-decaying heavy-tailed densities(i.e., Cauchy-type). Our results explicitly quantify the effect of theinitializer on the performance of the LMC algorithm. In particular, we showthat as the tail goes from sub-Gaussian, to sub-exponential, and finally toCauchy-like, the dependency on the initial error goes from being logarithmic,to polynomial, and then finally to being exponential. This three-step phasetransition is in particular unavoidable as demonstrated by our lower bounds,clearly defining the boundaries of LMC.</description><author>Alireza Mousavi-Hosseini, Tyler Farghly, Ye He, Krishnakumar Balasubramanian, Murat A. Erdogdu</author><pubDate>Thu, 20 Jul 2023 18:15:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03589v2</guid></item><item><title>Cascade-DETR: Delving into High-Quality Universal Object Detection</title><link>http://arxiv.org/abs/2307.11035v1</link><description>Object localization in general environments is a fundamental part of visionsystems. While dominating on the COCO benchmark, recent Transformer-baseddetection methods are not competitive in diverse domains. Moreover, thesemethods still struggle to very accurately estimate the object bounding boxes incomplex environments. We introduce Cascade-DETR for high-quality universal object detection. Wejointly tackle the generalization to diverse domains and localization accuracyby proposing the Cascade Attention layer, which explicitly integratesobject-centric information into the detection decoder by limiting the attentionto the previous box prediction. To further enhance accuracy, we also revisitthe scoring of queries. Instead of relying on classification scores, we predictthe expected IoU of the query, leading to substantially more well-calibratedconfidences. Lastly, we introduce a universal object detection benchmark,UDB10, that contains 10 datasets from diverse domains. While also advancing thestate-of-the-art on COCO, Cascade-DETR substantially improves DETR-baseddetectors on all datasets in UDB10, even by over 10 mAP in some cases. Theimprovements under stringent quality requirements are even more pronounced. Ourcode and models will be released at https://github.com/SysCV/cascade-detr.</description><author>Mingqiao Ye, Lei Ke, Siyuan Li, Yu-Wing Tai, Chi-Keung Tang, Martin Danelljan, Fisher Yu</author><pubDate>Thu, 20 Jul 2023 18:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11035v1</guid></item><item><title>Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot Classification</title><link>http://arxiv.org/abs/2307.11031v1</link><description>Recent work has shown that language models' (LMs) prompt-based learningcapabilities make them well suited for automating data labeling in domainswhere manual annotation is expensive. The challenge is that while writing aninitial prompt is cheap, improving a prompt is costly -- practitioners oftenrequire significant labeled data in order to evaluate the impact of promptmodifications. Our work asks whether it is possible to improve prompt-basedlearning without additional labeled data. We approach this problem byattempting to modify the predictions of a prompt, rather than the promptitself. Our intuition is that accurate predictions should also be consistent:samples which are similar under some feature representation should receive thesame prompt prediction. We propose Embroid, a method which computes multiplerepresentations of a dataset under different embedding functions, and uses theconsistency between the LM predictions for neighboring samples to identifymispredictions. Embroid then uses these neighborhoods to create additionalpredictions for each sample, and combines these predictions with a simplelatent variable graphical model in order to generate a final correctedprediction. In addition to providing a theoretical analysis of Embroid, weconduct a rigorous empirical evaluation across six different LMs and up to 95different tasks. We find that (1) Embroid substantially improves performanceover original prompts (e.g., by an average of 7.3 points on GPT-JT), (2) alsorealizes improvements for more sophisticated prompting strategies (e.g.,chain-of-thought), and (3) can be specialized to domains like law through theembedding functions.</description><author>Neel Guha, Mayee F. Chen, Kush Bhatia, Azalia Mirhoseini, Frederic Sala, Christopher Ré</author><pubDate>Thu, 20 Jul 2023 18:07:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11031v1</guid></item><item><title>Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering</title><link>http://arxiv.org/abs/2307.11030v1</link><description>Despite the empirical success and practical significance of (relational)knowledge distillation that matches (the relations of) features between teacherand student models, the corresponding theoretical interpretations remainlimited for various knowledge distillation paradigms. In this work, we take aninitial step toward a theoretical understanding of relational knowledgedistillation (RKD), with a focus on semi-supervised classification problems. Westart by casting RKD as spectral clustering on a population-induced graphunveiled by a teacher model. Via a notion of clustering error that quantifiesthe discrepancy between the predicted and ground truth clusterings, weillustrate that RKD over the population provably leads to low clustering error.Moreover, we provide a sample complexity bound for RKD with limited unlabeledsamples. For semi-supervised learning, we further demonstrate the labelefficiency of RKD through a general framework of cluster-aware semi-supervisedlearning that assumes low clustering errors. Finally, by unifying dataaugmentation consistency regularization into this cluster-aware framework, weshow that despite the common effect of learning accurate clusterings, RKDfacilitates a "global" perspective through spectral clustering, whereasconsistency regularization focuses on a "local" perspective via expansion.</description><author>Yijun Dong, Kevin Miller, Qi Lei, Rachel Ward</author><pubDate>Thu, 20 Jul 2023 18:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11030v1</guid></item><item><title>"It Felt Like Having a Second Mind": Investigating Human-AI Co-creativity in Prewriting with Large Language Models</title><link>http://arxiv.org/abs/2307.10811v1</link><description>Prewriting is the process of discovering and developing ideas before a firstdraft, which requires divergent thinking and often implies unstructuredstrategies such as diagramming, outlining, free-writing, etc. Although largelanguage models (LLMs) have been demonstrated to be useful for a variety oftasks including creative writing, little is known about how users wouldcollaborate with LLMs to support prewriting. The preferred collaborative roleand initiative of LLMs during such a creativity process is also unclear. Toinvestigate human-LLM collaboration patterns and dynamics during prewriting, weconducted a three-session qualitative study with 15 participants in twocreative tasks: story writing and slogan writing. The findings indicated thatduring collaborative prewriting, there appears to be a three-stage iterativeHuman-AI Co-creativity process that includes Ideation, Illumination, andImplementation stages. This collaborative process champions the human in adominant role, in addition to mixed and shifting levels of initiative thatexist between humans and LLMs. This research also reports on collaborationbreakdowns that occur during this process, user perceptions of using existingLLMs during Human-AI Co-creativity, and discusses design implications tosupport this co-creativity process.</description><author>Qian Wan, Siying Hu, Yu Zhang, Piaohong Wang, Bo Wen, Zhicong Lu</author><pubDate>Thu, 20 Jul 2023 17:55:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10811v1</guid></item><item><title>Vector Symbolic Architectures as a Computing Framework for Emerging Hardware</title><link>http://arxiv.org/abs/2106.05268v2</link><description>This article reviews recent progress in the development of the computingframework vector symbolic architectures (VSA) (also known as hyperdimensionalcomputing). This framework is well suited for implementation in stochastic,emerging hardware, and it naturally expresses the types of cognitive operationsrequired for artificial intelligence (AI). We demonstrate in this article thatthe field-like algebraic structure of VSA offers simple but powerful operationson high-dimensional vectors that can support all data structures andmanipulations relevant to modern computing. In addition, we illustrate thedistinguishing feature of VSA, "computing in superposition," which sets itapart from conventional computing. It also opens the door to efficientsolutions to the difficult combinatorial search problems inherent in AIapplications. We sketch ways of demonstrating that VSA are computationallyuniversal. We see them acting as a framework for computing with distributedrepresentations that can play a role of an abstraction layer for emergingcomputing hardware. This article serves as a reference for computer architectsby illustrating the philosophy behind VSA, techniques of distributed computingwith them, and their relevance to emerging computing hardware, such asneuromorphic computing.</description><author>Denis Kleyko, Mike Davies, E. Paxon Frady, Pentti Kanerva, Spencer J. Kent, Bruno A. Olshausen, Evgeny Osipov, Jan M. Rabaey, Dmitri A. Rachkovskij, Abbas Rahimi, Friedrich T. Sommer</author><pubDate>Thu, 20 Jul 2023 17:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.05268v2</guid></item><item><title>Can point cloud networks learn statistical shape models of anatomies?</title><link>http://arxiv.org/abs/2305.05610v2</link><description>Statistical Shape Modeling (SSM) is a valuable tool for investigating andquantifying anatomical variations within populations of anatomies. However,traditional correspondence-based SSM generation methods have a prohibitiveinference process and require complete geometric proxies (e.g., high-resolutionbinary volumes or surface meshes) as input shapes to construct the SSM.Unordered 3D point cloud representations of shapes are more easily acquiredfrom various medical imaging practices (e.g., thresholded images and surfacescanning). Point cloud deep networks have recently achieved remarkable successin learning permutation-invariant features for different point cloud tasks(e.g., completion, semantic segmentation, classification). However, theirapplication to learning SSM from point clouds is to-date unexplored. In thiswork, we demonstrate that existing point cloud encoder-decoder-based completionnetworks can provide an untapped potential for SSM, capturing population-levelstatistical representations of shapes while reducing the inference burden andrelaxing the input requirement. We discuss the limitations of these techniquesto the SSM application and suggest future improvements. Our work paves the wayfor further exploration of point cloud deep learning for SSM, a promisingavenue for advancing shape analysis literature and broadening SSM to diverseuse cases.</description><author>Jadie Adams, Shireen Elhabian</author><pubDate>Thu, 20 Jul 2023 17:46:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05610v2</guid></item><item><title>Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation</title><link>http://arxiv.org/abs/2307.11019v1</link><description>Knowledge-intensive tasks (e.g., open-domain question answering (QA)) requirea substantial amount of factual knowledge and often rely on externalinformation for assistance. Recently, large language models (LLMs) (e.g.,ChatGPT), have demonstrated impressive prowess in solving a wide range of taskswith world knowledge, including knowledge-intensive tasks. However, it remainsunclear how well LLMs are able to perceive their factual knowledge boundaries,particularly how they behave when incorporating retrieval augmentation. In thisstudy, we present an initial analysis of the factual knowledge boundaries ofLLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially,we focus on three primary research questions and analyze them by examining QAperformance, priori judgement and posteriori judgement of LLMs. We showevidence that LLMs possess unwavering confidence in their capabilities torespond to questions and the accuracy of their responses. Furthermore,retrieval augmentation proves to be an effective approach in enhancing LLMs'awareness of knowledge boundaries, thereby improving their judgementalabilities. Additionally, we also find that LLMs have a propensity to rely onthe provided retrieval results when formulating answers, while the quality ofthese results significantly impacts their reliance. The code to reproduce thiswork is available at https://github.com/RUCAIBox/LLM-Knowledge-Boundary.</description><author>Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hao Tian, Hua Wu, Ji-Rong Wen, Haifeng Wang</author><pubDate>Thu, 20 Jul 2023 17:46:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11019v1</guid></item><item><title>Amortized Variational Inference: When and Why?</title><link>http://arxiv.org/abs/2307.11018v1</link><description>Amortized variational inference (A-VI) is a method for approximating theintractable posterior distributions that arise in probabilistic models. Thedefining feature of A-VI is that it learns a global inference function thatmaps each observation to its local latent variable's approximate posterior.This stands in contrast to the more classical factorized (or mean-field)variational inference (F-VI), which directly learns the parameters of theapproximating distribution for each latent variable. In deep generative models,A-VI is used as a computational trick to speed up inference for local latentvariables. In this paper, we study A-VI as a general alternative to F-VI forapproximate posterior inference. A-VI cannot produce an approximation with alower Kullback-Leibler divergence than F-VI's optimal solution, because theamortized family is a subset of the factorized family. Thus a centraltheoretical problem is to characterize when A-VI still attains F-VI's optimalsolution. We derive conditions on both the model and the inference functionunder which A-VI can theoretically achieve F-VI's optimum. We show that for abroad class of hierarchical models, including deep generative models, it ispossible to close the gap between A-VI and F-VI. Further, for an even broaderclass of models, we establish when and how to expand the domain of theinference function to make amortization a feasible strategy. Finally, we provethat for certain models -- including hidden Markov models and Gaussianprocesses -- A-VI cannot match F-VI's solution, no matter how expressive theinference function is. We also study A-VI empirically [...]</description><author>Charles C. Margossian, David M. Blei</author><pubDate>Thu, 20 Jul 2023 17:45:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11018v1</guid></item><item><title>Multi-objective point cloud autoencoders for explainable myocardial infarction prediction</title><link>http://arxiv.org/abs/2307.11017v1</link><description>Myocardial infarction (MI) is one of the most common causes of death in theworld. Image-based biomarkers commonly used in the clinic, such as ejectionfraction, fail to capture more complex patterns in the heart's 3D anatomy andthus limit diagnostic accuracy. In this work, we present the multi-objectivepoint cloud autoencoder as a novel geometric deep learning approach forexplainable infarction prediction, based on multi-class 3D point cloudrepresentations of cardiac anatomy and function. Its architecture consists ofmultiple task-specific branches connected by a low-dimensional latent space toallow for effective multi-objective learning of both reconstruction and MIprediction, while capturing pathology-specific 3D shape information in aninterpretable latent space. Furthermore, its hierarchical branch design withpoint cloud-based deep learning operations enables efficient multi-scalefeature learning directly on high-resolution anatomy point clouds. In ourexperiments on a large UK Biobank dataset, the multi-objective point cloudautoencoder is able to accurately reconstruct multi-temporal 3D shapes withChamfer distances between predicted and input anatomies below the underlyingimages' pixel resolution. Our method outperforms multiple machine learning anddeep learning benchmarks for the task of incident MI prediction by 19% in termsof Area Under the Receiver Operating Characteristic curve. In addition, itstask-specific compact latent space exhibits easily separable control and MIclusters with clinically plausible associations between subject encodings andcorresponding 3D shapes, thus demonstrating the explainability of theprediction.</description><author>Marcel Beetz, Abhirup Banerjee, Vicente Grau</author><pubDate>Thu, 20 Jul 2023 17:45:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11017v1</guid></item><item><title>Full Characterization of Adaptively Strong Majority Voting in Crowdsourcing</title><link>http://arxiv.org/abs/2111.06390v2</link><description>In crowdsourcing, quality control is commonly achieved by having workersexamine items and vote on their correctness. To minimize the impact ofunreliable worker responses, a $\delta$-margin voting process is utilized,where additional votes are solicited until a predetermined threshold $\delta$for agreement between workers is exceeded. The process is widely adopted butonly as a heuristic. Our research presents a modeling approach using absorbingMarkov chains to analyze the characteristics of this voting process that matterin crowdsourced processes. We provide closed-form equations for the quality ofresulting consensus vote, the expected number of votes required for consensus,the variance of vote requirements, and other distribution moments. Our findingsdemonstrate how the threshold $\delta$ can be adjusted to achieve qualityequivalence across voting processes that employ workers with varying accuracylevels. We also provide efficiency-equalizing payment rates for votingprocesses with different expected response accuracy levels. Additionally, ourmodel considers items with varying degrees of difficulty and uncertainty aboutthe difficulty of each example. Our simulations, using real-world crowdsourcedvote data, validate the effectiveness of our theoretical model incharacterizing the consensus aggregation process. The results of our study canbe effectively employed in practical crowdsourcing applications.</description><author>Margarita Boyarskaya, Panos Ipeirotis</author><pubDate>Thu, 20 Jul 2023 17:45:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.06390v2</guid></item><item><title>Data-Driven Modeling of Noise Time Series with Convolutional Generative Adversarial Networks</title><link>http://arxiv.org/abs/2207.01110v3</link><description>Random noise arising from physical processes is an inherent characteristic ofmeasurements and a limiting factor for most signal processing and data analysistasks. Given the recent interest in generative adversarial networks (GANs) fordata-driven modeling, it is important to determine to what extent GANs canfaithfully reproduce noise in target data sets. In this paper, we present anempirical investigation that aims to shed light on this issue for time series.Namely, we assess two general-purpose GANs for time series that are based onthe popular deep convolutional GAN (DCGAN) architecture, a direct time-seriesmodel and an image-based model that uses a short-time Fourier transform (STFT)data representation. The GAN models are trained and quantitatively evaluatedusing distributions of simulated noise time series with known ground-truthparameters. Target time series distributions include a broad range of noisetypes commonly encountered in physical measurements, electronics, andcommunication systems: band-limited thermal noise, power law noise, shot noise,and impulsive noise. We find that GANs are capable of learning many noisetypes, although they predictably struggle when the GAN architecture is not wellsuited to some aspects of the noise, e.g., impulsive time-series with extremeoutliers. Our findings provide insights into the capabilities and potentiallimitations of current approaches to time-series GANs and highlight areas forfurther research. In addition, our battery of tests provides a useful benchmarkto aid the development of deep generative models for time series.</description><author>Adam Wunderlich, Jack Sklar</author><pubDate>Thu, 20 Jul 2023 17:44:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.01110v3</guid></item><item><title>Variational Mixture of HyperGenerators for Learning Distributions Over Functions</title><link>http://arxiv.org/abs/2302.06223v3</link><description>Recent approaches build on implicit neural representations (INRs) to proposegenerative models over function spaces. However, they are computationallycostly when dealing with inference tasks, such as missing data imputation, ordirectly cannot tackle them. In this work, we propose a novel deep generativemodel, named VAMoH. VAMoH combines the capabilities of modeling continuousfunctions using INRs and the inference capabilities of Variational Autoencoders(VAEs). In addition, VAMoH relies on a normalizing flow to define the prior,and a mixture of hypernetworks to parametrize the data log-likelihood. Thisgives VAMoH a high expressive capability and interpretability. Throughexperiments on a diverse range of data types, such as images, voxels, andclimate data, we show that VAMoH can effectively learn rich distributions overcontinuous functions. Furthermore, it can perform inference-related tasks, suchas conditional super-resolution generation and in-painting, as well or betterthan previous approaches, while being less computationally demanding.</description><author>Batuhan Koyuncu, Pablo Sanchez-Martin, Ignacio Peis, Pablo M. Olmos, Isabel Valera</author><pubDate>Thu, 20 Jul 2023 17:40:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06223v3</guid></item><item><title>Perceptron Theory Can Predict the Accuracy of Neural Networks</title><link>http://arxiv.org/abs/2012.07881v2</link><description>Multilayer neural networks set the current state of the art for manytechnical classification problems. But, these networks are still, essentially,black boxes in terms of analyzing them and predicting their performance. Here,we develop a statistical theory for the one-layer perceptron and show that itcan predict performances of a surprisingly large variety of neural networkswith different architectures. A general theory of classification withperceptrons is developed by generalizing an existing theory for analyzingreservoir computing models and connectionist models for symbolic reasoningknown as vector symbolic architectures. Our statistical theory offers threeformulas leveraging the signal statistics with increasing detail. The formulasare analytically intractable, but can be evaluated numerically. The descriptionlevel that captures maximum details requires stochastic sampling methods.Depending on the network model, the simpler formulas already yield highprediction accuracy. The quality of the theory predictions is assessed in threeexperimental settings, a memorization task for echo state networks (ESNs) fromreservoir computing literature, a collection of classification datasets forshallow randomly connected networks, and the ImageNet dataset for deepconvolutional neural networks. We find that the second description level of theperceptron theory can predict the performance of types of ESNs, which could notbe described previously. The theory can predict deep multilayer neural networksby being applied to their output layer. While other methods for prediction ofneural networks performance commonly require to train an estimator model, theproposed theory requires only the first two moments of the distribution of thepostsynaptic sums in the output neurons. The perceptron theory comparesfavorably to other methods that do not rely on training an estimator model.</description><author>Denis Kleyko, Antonello Rosato, E. Paxon Frady, Massimo Panella, Friedrich T. Sommer</author><pubDate>Thu, 20 Jul 2023 17:38:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.07881v2</guid></item><item><title>Flow Map Learning for Unknown Dynamical Systems: Overview, Implementation, and Benchmarks</title><link>http://arxiv.org/abs/2307.11013v1</link><description>Flow map learning (FML), in conjunction with deep neural networks (DNNs), hasshown promises for data driven modeling of unknown dynamical systems. Aremarkable feature of FML is that it is capable of producing accuratepredictive models for partially observed systems, even when their exactmathematical models do not exist. In this paper, we present an overview of theFML framework, along with the important computational details for itssuccessful implementation. We also present a set of well defined benchmarkproblems for learning unknown dynamical systems. All the numerical details ofthese problems are presented, along with their FML results, to ensure that theproblems are accessible for cross-examination and the results are reproducible.</description><author>Victor Churchill, Dongbin Xiu</author><pubDate>Thu, 20 Jul 2023 17:38:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11013v1</guid></item><item><title>Fully Bayesian VIB-DeepSSM</title><link>http://arxiv.org/abs/2305.05797v2</link><description>Statistical shape modeling (SSM) enables population-based quantitativeanalysis of anatomical shapes, informing clinical diagnosis. Deep learningapproaches predict correspondence-based SSM directly from unsegmented 3D imagesbut require calibrated uncertainty quantification, motivating Bayesianformulations. Variational information bottleneck DeepSSM (VIB-DeepSSM) is aneffective, principled framework for predicting probabilistic shapes of anatomyfrom images with aleatoric uncertainty quantification. However, VIB is onlyhalf-Bayesian and lacks epistemic uncertainty inference. We derive a fullyBayesian VIB formulation and demonstrate the efficacy of two scalableimplementation approaches: concrete dropout and batch ensemble. Additionally,we introduce a novel combination of the two that further enhances uncertaintycalibration via multimodal marginalization. Experiments on synthetic shapes andleft atrium data demonstrate that the fully Bayesian VIB network predicts SSMfrom images with improved uncertainty reasoning without sacrificing accuracy.</description><author>Jadie Adams, Shireen Elhabian</author><pubDate>Thu, 20 Jul 2023 17:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05797v2</guid></item><item><title>Neuron Sensitivity Guided Test Case Selection for Deep Learning Testing</title><link>http://arxiv.org/abs/2307.11011v1</link><description>Deep Neural Networks~(DNNs) have been widely deployed in software to addressvarious tasks~(e.g., autonomous driving, medical diagnosis). However, theycould also produce incorrect behaviors that result in financial losses and eventhreaten human safety. To reveal the incorrect behaviors in DNN and repairthem, DNN developers often collect rich unlabeled datasets from the naturalworld and label them to test the DNN models. However, properly labeling a largenumber of unlabeled datasets is a highly expensive and time-consuming task. To address the above-mentioned problem, we propose NSS, Neuron Sensitivityguided test case Selection, which can reduce the labeling time by selectingvaluable test cases from unlabeled datasets. NSS leverages the internalneuron's information induced by test cases to select valuable test cases, whichhave high confidence in causing the model to behave incorrectly. We evaluateNSS with four widely used datasets and four well-designed DNN models comparedto SOTA baseline methods. The results show that NSS performs well in assessingthe test cases' probability of fault triggering and model improvementcapabilities. Specifically, compared with baseline approaches, NSS obtains ahigher fault detection rate~(e.g., when selecting 5\% test case from theunlabeled dataset in MNIST \&amp; LeNet1 experiment, NSS can obtain 81.8\% faultdetection rate, 20\% higher than baselines).</description><author>Dong Huang, Qingwen Bu, Yichao Fu, Yuhao Qing, Bocheng Xiao, Heming Cui</author><pubDate>Thu, 20 Jul 2023 17:36:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11011v1</guid></item><item><title>Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization</title><link>http://arxiv.org/abs/2307.11007v1</link><description>Despite extensive studies, the underlying reason as to why overparameterizedneural networks can generalize remains elusive. Existing theory shows thatcommon stochastic optimizers prefer flatter minimizers of the training loss,and thus a natural potential explanation is that flatness impliesgeneralization. This work critically examines this explanation. Throughtheoretical and empirical investigation, we identify the following threescenarios for two-layer ReLU networks: (1) flatness provably impliesgeneralization; (2) there exist non-generalizing flattest models and sharpnessminimization algorithms fail to generalize, and (3) perhaps most surprisingly,there exist non-generalizing flattest models, but sharpness minimizationalgorithms still generalize. Our results suggest that the relationship betweensharpness and generalization subtly depends on the data distributions and themodel architectures and sharpness minimization algorithms do not only minimizesharpness to achieve better generalization. This calls for the search for otherexplanations for the generalization of over-parameterized neural networks.</description><author>Kaiyue Wen, Tengyu Ma, Zhiyuan Li</author><pubDate>Thu, 20 Jul 2023 17:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11007v1</guid></item><item><title>Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding</title><link>http://arxiv.org/abs/2307.11005v1</link><description>There has been an increased interest in the integration of pretrained speechrecognition (ASR) and language models (LM) into the SLU framework. However,prior methods often struggle with a vocabulary mismatch between pretrainedmodels, and LM cannot be directly utilized as they diverge from its NLUformulation. In this study, we propose a three-pass end-to-end (E2E) SLU systemthat effectively integrates ASR and LM subnetworks into the SLU formulation forsequence generation tasks. In the first pass, our architecture predicts ASRtranscripts using the ASR subnetwork. This is followed by the LM subnetwork,which makes an initial SLU prediction. Finally, in the third pass, thedeliberation subnetwork conditions on representations from the ASR and LMsubnetworks to make the final prediction. Our proposed three-pass SLU systemshows improved performance over cascaded and E2E SLU models on two benchmarkSLU datasets, SLURP and SLUE, especially on acoustically challengingutterances.</description><author>Siddhant Arora, Hayato Futami, Yosuke Kashiwagi, Emiru Tsunoo, Brian Yan, Shinji Watanabe</author><pubDate>Thu, 20 Jul 2023 17:34:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11005v1</guid></item><item><title>NeoSySPArtaN: A Neuro-Symbolic Spin Prediction Architecture for higher-order multipole waveforms from eccentric Binary Black Hole mergers using Numerical Relativity</title><link>http://arxiv.org/abs/2307.11003v1</link><description>The prediction of spin magnitudes in binary black hole and neutron starmergers is crucial for understanding the astrophysical processes andgravitational wave (GW) signals emitted during these cataclysmic events. Inthis paper, we present a novel Neuro-Symbolic Architecture (NSA) that combinesthe power of neural networks and symbolic regression to accurately predict spinmagnitudes of black hole and neutron star mergers. Our approach utilizes GWwaveform data obtained from numerical relativity simulations in the SXSWaveform catalog. By combining these two approaches, we leverage the strengthsof both paradigms, enabling a comprehensive and accurate prediction of spinmagnitudes. Our experiments demonstrate that the proposed architecture achievesan impressive root-mean-squared-error (RMSE) of 0.05 and mean-squared-error(MSE) of 0.03 for the NSA model and an RMSE of 0.12 for the symbolic regressionmodel alone. We train this model to handle higher-order multipole waveforms,with a specific focus on eccentric candidates, which are known to exhibitunique characteristics. Our results provide a robust and interpretableframework for predicting spin magnitudes in mergers. This has implications forunderstanding the astrophysical properties of black holes and deciphering thephysics underlying the GW signals.</description><author>Amrutaa Vibho, Ali Al Bataineh</author><pubDate>Thu, 20 Jul 2023 17:30:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11003v1</guid></item><item><title>Private Federated Learning with Autotuned Compression</title><link>http://arxiv.org/abs/2307.10999v1</link><description>We propose new techniques for reducing communication in private federatedlearning without the need for setting or tuning compression rates. Ouron-the-fly methods automatically adjust the compression rate based on the errorinduced during training, while maintaining provable privacy guarantees throughthe use of secure aggregation and differential privacy. Our techniques areprovably instance-optimal for mean estimation, meaning that they can adapt tothe ``hardness of the problem" with minimal interactivity. We demonstrate theeffectiveness of our approach on real-world datasets by achieving favorablecompression rates without the need for tuning.</description><author>Enayat Ullah, Christopher A. Choquette-Choo, Peter Kairouz, Sewoong Oh</author><pubDate>Thu, 20 Jul 2023 17:27:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10999v1</guid></item><item><title>DREAM: Domain-free Reverse Engineering Attributes of Black-box Model</title><link>http://arxiv.org/abs/2307.10997v1</link><description>Deep learning models are usually black boxes when deployed on machinelearning platforms. Prior works have shown that the attributes ($e.g.$, thenumber of convolutional layers) of a target black-box neural network can beexposed through a sequence of queries. There is a crucial limitation: theseworks assume the dataset used for training the target model to be knownbeforehand and leverage this dataset for model attribute attack. However, it isdifficult to access the training dataset of the target black-box model inreality. Therefore, whether the attributes of a target black-box model could bestill revealed in this case is doubtful. In this paper, we investigate a newproblem of Domain-agnostic Reverse Engineering the Attributes of a black-boxtarget Model, called DREAM, without requiring the availability of the targetmodel's training dataset, and put forward a general and principled framework bycasting this problem as an out of distribution (OOD) generalization problem. Inthis way, we can learn a domain-agnostic model to inversely infer theattributes of a target black-box model with unknown training data. This makesour method one of the kinds that can gracefully apply to an arbitrary domainfor model attribute reverse engineering with strong generalization ability.Extensive experimental studies are conducted and the results validate thesuperiority of our proposed method over the baselines.</description><author>Rongqing Li, Jiaqi Yu, Changsheng Li, Wenhan Luo, Ye Yuan, Guoren Wang</author><pubDate>Thu, 20 Jul 2023 17:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10997v1</guid></item><item><title>Progressive distillation diffusion for raw music generation</title><link>http://arxiv.org/abs/2307.10994v1</link><description>This paper aims to apply a new deep learning approach to the task ofgenerating raw audio files. It is based on diffusion models, a recent type ofdeep generative model. This new type of method has recently shown outstandingresults with image generation. A lot of focus has been given to those models bythe computer vision community. On the other hand, really few have been givenfor other types of applications such as music generation in waveform domain. In this paper the model for unconditional generating applied to music isimplemented: Progressive distillation diffusion with 1D U-Net. Then, acomparison of different parameters of diffusion and their value in a fullresult is presented. One big advantage of the methods implemented through thiswork is the fact that the model is able to deal with progressing audioprocessing and generating , using transformation from 1-channel 128 x 384 to3-channel 128 x 128 mel-spectrograms and looped generation. The empiricalcomparisons are realized across different self-collected datasets.</description><author>Svetlana Pavlova</author><pubDate>Thu, 20 Jul 2023 17:25:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10994v1</guid></item><item><title>MAP: Multimodal Uncertainty-Aware Vision-Language Pre-training Model</title><link>http://arxiv.org/abs/2210.05335v3</link><description>Multimodal semantic understanding often has to deal with uncertainty, whichmeans the obtained messages tend to refer to multiple targets. Such uncertaintyis problematic for our interpretation, including inter- and intra-modaluncertainty. Little effort has studied the modeling of this uncertainty,particularly in pre-training on unlabeled datasets and fine-tuning intask-specific downstream datasets. In this paper, we project therepresentations of all modalities as probabilistic distributions via aProbability Distribution Encoder (PDE) by utilizing sequence-levelinteractions. Compared to the existing deterministic methods, such uncertaintymodeling can convey richer multimodal semantic information and more complexrelationships. Furthermore, we integrate uncertainty modeling with popularpre-training frameworks and propose suitable pre-training tasks:Distribution-based Vision-Language Contrastive learning (D-VLC),Distribution-based Masked Language Modeling (D-MLM), and Distribution-basedImage-Text Matching (D-ITM). The fine-tuned models are applied to challengingdownstream tasks, including image-text retrieval, visual question answering,visual reasoning, and visual entailment, and achieve state-of-the-art results.</description><author>Yatai Ji, Junjie Wang, Yuan Gong, Lin Zhang, Yanru Zhu, Hongfa Wang, Jiaxing Zhang, Tetsuya Sakai, Yujiu Yang</author><pubDate>Thu, 20 Jul 2023 17:24:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.05335v3</guid></item><item><title>Tuning Stochastic Gradient Algorithms for Statistical Inference via Large-Sample Asymptotics</title><link>http://arxiv.org/abs/2207.12395v3</link><description>The tuning of stochastic gradient algorithms (SGAs) for optimization andsampling is often based on heuristics and trial-and-error rather thangeneralizable theory. We address this theory--practice gap by characterizingthe large-sample statistical asymptotics of SGAs via a jointstep-size--sample-size scaling limit. We show that iterate averaging with alarge fixed step size is robust to the choice of tuning parameters andasymptotically has covariance proportional to that of the MLE samplingdistribution. We also prove a Bernstein--von Mises-like theorem to guidetuning, including for generalized posteriors that are robust to modelmisspecification. Numerical experiments validate our results andrecommendations in realistic finite-sample regimes. Our work lays thefoundation for a systematic analysis of other stochastic gradient Markov chainMonte Carlo algorithms for a wide range of models.</description><author>Jeffrey Negrea, Jun Yang, Haoyue Feng, Daniel M. Roy, Jonathan H. Huggins</author><pubDate>Thu, 20 Jul 2023 17:21:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.12395v3</guid></item><item><title>Dense Sample Deep Learning</title><link>http://arxiv.org/abs/2307.10991v1</link><description>Deep Learning (DL) , a variant of the neural network algorithms originallyproposed in the 1980s, has made surprising progress in Artificial Intelligence(AI), ranging from language translation, protein folding, autonomous cars, andmore recently human-like language models (CHATbots), all that seemedintractable until very recently. Despite the growing use of Deep Learning (DL)networks, little is actually understood about the learning mechanisms andrepresentations that makes these networks effective across such a diverse rangeof applications. Part of the answer must be the huge scale of the architectureand of course the large scale of the data, since not much has changed since1987. But the nature of deep learned representations remain largely unknown.Unfortunately training sets with millions or billions of tokens have unknowncombinatorics and Networks with millions or billions of hidden units cannoteasily be visualized and their mechanisms cannot be easily revealed. In thispaper, we explore these questions with a large (1.24M weights; VGG) DL in anovel high density sample task (5 unique tokens with at minimum 500 exemplarsper token) which allows us to more carefully follow the emergence of categorystructure and feature construction. We use various visualization methods forfollowing the emergence of the classification and the development of thecoupling of feature detectors and structures that provide a type of graphicalbootstrapping, From these results we harvest some basic observations of thelearning dynamics of DL and propose a new theory of complex featureconstruction based on our results.</description><author>Stephen Josè Hanson, Vivek Yadev, Catherine Hanson</author><pubDate>Thu, 20 Jul 2023 17:21:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10991v1</guid></item><item><title>Investigating minimizing the training set fill distance in machine learning regression</title><link>http://arxiv.org/abs/2307.10988v1</link><description>Many machine learning regression methods leverage large datasets for trainingpredictive models. However, using large datasets may not be feasible due tocomputational limitations or high labelling costs. Therefore, sampling smalltraining sets from large pools of unlabelled data points is essential tomaximize model performance while maintaining computational efficiency. In thiswork, we study a sampling approach aimed to minimize the fill distance of theselected set. We derive an upper bound for the maximum expected predictionerror that linearly depends on the training set fill distance, conditional tothe knowledge of data features. For empirical validation, we performexperiments using two regression models on two datasets. We empirically showthat selecting a training set by aiming to minimize the fill distance, therebyminimizing the bound, significantly reduces the maximum prediction error ofvarious regression models, outperforming existing sampling approaches by alarge margin.</description><author>Paolo Climaco, Jochen Garcke</author><pubDate>Thu, 20 Jul 2023 17:18:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10988v1</guid></item><item><title>Characterising Decision Theories with Mechanised Causal Graphs</title><link>http://arxiv.org/abs/2307.10987v1</link><description>How should my own decisions affect my beliefs about the outcomes I expect toachieve? If taking a certain action makes me view myself as a certain type ofperson, it might affect how I think others view me, and how I view others whoare similar to me. This can influence my expected utility calculations andchange which action I perceive to be best. Whether and how it should is subjectto debate, with contenders for how to think about it including evidentialdecision theory, causal decision theory, and functional decision theory. Inthis paper, we show that mechanised causal models can be used to characteriseand differentiate the most important decision theories, and generate a taxonomyof different decision theories.</description><author>Matt MacDermott, Tom Everitt, Francesco Belardinelli</author><pubDate>Thu, 20 Jul 2023 17:18:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10987v1</guid></item><item><title>Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image</title><link>http://arxiv.org/abs/2307.10984v1</link><description>Reconstructing accurate 3D scenes from images is a long-standing vision task.Due to the ill-posedness of the single-image reconstruction problem, mostwell-established methods are built upon multi-view geometry. State-of-the-art(SOTA) monocular metric depth estimation methods can only handle a singlecamera model and are unable to perform mixed-data training due to the metricambiguity. Meanwhile, SOTA monocular methods trained on large mixed datasetsachieve zero-shot generalization by learning affine-invariant depths, whichcannot recover real-world metrics. In this work, we show that the key to azero-shot single-view metric depth model lies in the combination of large-scaledata training and resolving the metric ambiguity from various camera models. Wepropose a canonical camera space transformation module, which explicitlyaddresses the ambiguity problems and can be effortlessly plugged into existingmonocular models. Equipped with our module, monocular models can be stablytrained with over 8 million images with thousands of camera models, resultingin zero-shot generalization to in-the-wild images with unseen camera settings.Experiments demonstrate SOTA performance of our method on 7 zero-shotbenchmarks. Notably, our method won the championship in the 2nd Monocular DepthEstimation Challenge. Our method enables the accurate recovery of metric 3Dstructures on randomly collected internet images, paving the way for plausiblesingle-image metrology. The potential benefits extend to downstream tasks,which can be significantly improved by simply plugging in our model. Forexample, our model relieves the scale drift issues of monocular-SLAM (Fig. 1),leading to high-quality metric scale dense mapping. The code is available athttps://github.com/YvanYin/Metric3D.</description><author>Wei Yin, Chi Zhang, Hao Chen, Zhipeng Cai, Gang Yu, Kaixuan Wang, Xiaozhi Chen, Chunhua Shen</author><pubDate>Thu, 20 Jul 2023 17:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10984v1</guid></item><item><title>Impatient Bandits: Optimizing Recommendations for the Long-Term Without Delay</title><link>http://arxiv.org/abs/2307.09943v2</link><description>Recommender systems are a ubiquitous feature of online platforms.Increasingly, they are explicitly tasked with increasing users' long-termsatisfaction. In this context, we study a content exploration task, which weformalize as a multi-armed bandit problem with delayed rewards. We observe thatthere is an apparent trade-off in choosing the learning signal: Waiting for thefull reward to become available might take several weeks, hurting the rate atwhich learning happens, whereas measuring short-term proxy rewards reflects theactual long-term goal only imperfectly. We address this challenge in two steps.First, we develop a predictive model of delayed rewards that incorporates allinformation obtained to date. Full observations as well as partial (short ormedium-term) outcomes are combined through a Bayesian filter to obtain aprobabilistic belief. Second, we devise a bandit algorithm that takes advantageof this new predictive model. The algorithm quickly learns to identify contentaligned with long-term success by carefully balancing exploration andexploitation. We apply our approach to a podcast recommendation problem, wherewe seek to identify shows that users engage with repeatedly over two months. Weempirically validate that our approach results in substantially betterperformance compared to approaches that either optimize for short-term proxies,or wait for the long-term outcome to be fully realized.</description><author>Thomas M. McDonald, Lucas Maystre, Mounia Lalmas, Daniel Russo, Kamil Ciosek</author><pubDate>Thu, 20 Jul 2023 17:11:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09943v2</guid></item><item><title>MASR: Metadata Aware Speech Representation</title><link>http://arxiv.org/abs/2307.10982v1</link><description>In the recent years, speech representation learning is constructed primarilyas a self-supervised learning (SSL) task, using the raw audio signal alone,while ignoring the side-information that is often available for a given speechrecording. In this paper, we propose MASR, a Metadata Aware SpeechRepresentation learning framework, which addresses the aforementionedlimitations. MASR enables the inclusion of multiple external knowledge sourcesto enhance the utilization of meta-data information. The external knowledgesources are incorporated in the form of sample-level pair-wise similaritymatrices that are useful in a hard-mining loss. A key advantage of the MASRframework is that it can be combined with any choice of SSL method. Using MASRrepresentations, we perform evaluations on several downstream tasks such aslanguage identification, speech recognition and other non-semantic tasks suchas speaker and emotion recognition. In these experiments, we illustratesignificant performance improvements for the MASR over other establishedbenchmarks. We perform a detailed analysis on the language identification taskto provide insights on how the proposed loss function enables therepresentations to separate closely related languages.</description><author>Anjali Raj, Shikhar Bharadwaj, Sriram Ganapathy, Min Ma, Shikhar Vashishth</author><pubDate>Thu, 20 Jul 2023 17:09:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10982v1</guid></item><item><title>PATROL: Privacy-Oriented Pruning for Collaborative Inference Against Model Inversion Attacks</title><link>http://arxiv.org/abs/2307.10981v1</link><description>Collaborative inference has been a promising solution to enableresource-constrained edge devices to perform inference using state-of-the-artdeep neural networks (DNNs). In collaborative inference, the edge device firstfeeds the input to a partial DNN locally and then uploads the intermediateresult to the cloud to complete the inference. However, recent researchindicates model inversion attacks (MIAs) can reconstruct input data fromintermediate results, posing serious privacy concerns for collaborativeinference. Existing perturbation and cryptography techniques are inefficientand unreliable in defending against MIAs while performing accurate inference.This paper provides a viable solution, named PATROL, which developsprivacy-oriented pruning to balance privacy, efficiency, and utility ofcollaborative inference. PATROL takes advantage of the fact that later layersin a DNN can extract more task-specific features. Given limited local resourcesfor collaborative inference, PATROL intends to deploy more layers at the edgebased on pruning techniques to enforce task-specific features for inference andreduce task-irrelevant but sensitive features for privacy preservation. Toachieve privacy-oriented pruning, PATROL introduces two key components:Lipschitz regularization and adversarial reconstruction training, whichincrease the reconstruction errors by reducing the stability of MIAs andenhance the target inference model by adversarial training, respectively.</description><author>Shiwei Ding, Lan Zhang, Miao Pan, Xiaoyong Yuan</author><pubDate>Thu, 20 Jul 2023 17:09:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10981v1</guid></item><item><title>Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study</title><link>http://arxiv.org/abs/2305.03017v3</link><description>Our research investigates the recommendation of code examples to aid softwaredevelopers, a practice that saves developers significant time by providingready-to-use code snippets. The focus of our study is Stack Overflow, acommonly used resource for coding discussions and solutions, particularly inthe context of the Java programming language. We applied BERT, a powerful LargeLanguage Model (LLM) that enables us to transform code examples into numericalvectors by extracting their semantic information. Once these numericalrepresentations are prepared, we identify Approximate Nearest Neighbors (ANN)using Locality-Sensitive Hashing (LSH). Our research employed two variants ofLSH: Random Hyperplane-based LSH and Query-Aware LSH. We rigorously comparedthese two approaches across four parameters: HitRate, Mean Reciprocal Rank(MRR), Average Execution Time, and Relevance. Our study revealed that theQuery-Aware (QA) approach showed superior performance over the RandomHyperplane-based (RH) method. Specifically, it exhibited a notable improvementof 20% to 35% in HitRate for query pairs compared to the RH approach.Furthermore, the QA approach proved significantly more time-efficient, with itsspeed in creating hashing tables and assigning data samples to buckets being atleast four times faster. It can return code examples within milliseconds,whereas the RH approach typically requires several seconds to recommend codeexamples. Due to the superior performance of the QA approach, we tested itagainst PostFinder and FaCoY, the state-of-the-art baselines. Our QA methodshowed comparable efficiency proving its potential for effective coderecommendation.</description><author>Sajjad Rahmani, AmirHossein Naghshzan, Latifa Guerrouj</author><pubDate>Thu, 20 Jul 2023 17:05:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03017v3</guid></item><item><title>Class-Incremental Learning based on Label Generation</title><link>http://arxiv.org/abs/2306.12619v2</link><description>Despite the great success of pre-trained language models, it is still achallenge to use these models for continual learning, especially for theclass-incremental learning (CIL) setting due to catastrophic forgetting (CF).This paper reports our finding that if we formulate CIL as a continual labelgeneration problem, CF is drastically reduced and the generalizablerepresentations of pre-trained models can be better retained. We thus propose anew CIL method (VAG) that also leverages the sparsity of vocabulary to focusthe generation and creates pseudo-replay samples by using label semantics.Experimental results show that VAG outperforms baselines by a large margin.</description><author>Yijia Shao, Yiduo Guo, Dongyan Zhao, Bing Liu</author><pubDate>Thu, 20 Jul 2023 17:04:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12619v2</guid></item><item><title>Domain Adaptation based Enhanced Detection for Autonomous Driving in Foggy and Rainy Weather</title><link>http://arxiv.org/abs/2307.09676v2</link><description>Typically, object detection methods for autonomous driving that rely onsupervised learning make the assumption of a consistent feature distributionbetween the training and testing data, however such assumption may fail indifferent weather conditions. Due to the domain gap, a detection model trainedunder clear weather may not perform well in foggy and rainy conditions.Overcoming detection bottlenecks in foggy and rainy weather is a real challengefor autonomous vehicles deployed in the wild. To bridge the domain gap andimprove the performance of object detectionin foggy and rainy weather, thispaper presents a novel framework for domain-adaptive object detection. Theadaptations at both the image-level and object-level are intended to minimizethe differences in image style and object appearance between domains.Furthermore, in order to improve the model's performance on challengingexamples, we introduce a novel adversarial gradient reversal layer thatconducts adversarial mining on difficult instances in addition to domainadaptation. Additionally, we suggest generating an auxiliary domain throughdata augmentation to enforce a new domain-level metric regularization.Experimental findings on public V2V benchmark exhibit a substantial enhancementin object detection specifically for foggy and rainy driving scenarios.</description><author>Jinlong Li, Runsheng Xu, Jin Ma, Qin Zou, Jiaqi Ma, Hongkai Yu</author><pubDate>Thu, 20 Jul 2023 17:04:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09676v2</guid></item><item><title>Globally Normalising the Transducer for Streaming Speech Recognition</title><link>http://arxiv.org/abs/2307.10975v1</link><description>The Transducer (e.g. RNN-Transducer or Conformer-Transducer) generates anoutput label sequence as it traverses the input sequence. It is straightforwardto use in streaming mode, where it generates partial hypotheses before thecomplete input has been seen. This makes it popular in speech recognition.However, in streaming mode the Transducer has a mathematical flaw which, simplyput, restricts the model's ability to change its mind. The fix is to replacelocal normalisation (e.g. a softmax) with global normalisation, but then theloss function becomes impossible to evaluate exactly. A recent paper proposesto solve this by approximating the model, severely degrading performance.Instead, this paper proposes to approximate the loss function, allowing globalnormalisation to apply to a state-of-the-art streaming model. Globalnormalisation reduces its word error rate by 9-11% relative, closing almosthalf the gap between streaming and lookahead mode.</description><author>Rogier van Dalen</author><pubDate>Thu, 20 Jul 2023 17:04:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10975v1</guid></item><item><title>When are Local Queries Useful for Robust Learning?</title><link>http://arxiv.org/abs/2210.06089v2</link><description>Distributional assumptions have been shown to be necessary for the robustlearnability of concept classes when considering the exact-in-the-ball robustrisk and access to random examples by Gourdeau et al. (2019). In this paper, westudy learning models where the learner is given more power through the use oflocal queries, and give the first distribution-free algorithms that performrobust empirical risk minimization (ERM) for this notion of robustness. Thefirst learning model we consider uses local membership queries (LMQ), where thelearner can query the label of points near the training sample. We show that,under the uniform distribution, LMQs do not increase the robustness thresholdof conjunctions and any superclass, e.g., decision lists and halfspaces. Facedwith this negative result, we introduce the local equivalence query($\mathsf{LEQ}$) oracle, which returns whether the hypothesis and targetconcept agree in the perturbation region around a point in the training sample,as well as a counterexample if it exists. We show a separation result: on theone hand, if the query radius $\lambda$ is strictly smaller than theadversary's perturbation budget $\rho$, then distribution-free robust learningis impossible for a wide variety of concept classes; on the other hand, thesetting $\lambda=\rho$ allows us to develop robust ERM algorithms. We thenbound the query complexity of these algorithms based on online learningguarantees and further improve these bounds for the special case ofconjunctions. We finish by giving robust learning algorithms for halfspaces on$\{0,1\}^n$ and then obtaining robustness guarantees for halfspaces in$\mathbb{R}^n$ against precision-bounded adversaries.</description><author>Pascale Gourdeau, Varun Kanade, Marta Kwiatkowska, James Worrell</author><pubDate>Thu, 20 Jul 2023 17:01:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06089v2</guid></item><item><title>Deep Spiking-UNet for Image Processing</title><link>http://arxiv.org/abs/2307.10974v1</link><description>U-Net, known for its simple yet efficient architecture, is widely utilizedfor image processing tasks and is particularly suitable for deployment onneuromorphic chips. This paper introduces the novel concept of Spiking-UNet forimage processing, which combines the power of Spiking Neural Networks (SNNs)with the U-Net architecture. To achieve an efficient Spiking-UNet, we face twoprimary challenges: ensuring high-fidelity information propagation through thenetwork via spikes and formulating an effective training strategy. To addressthe issue of information loss, we introduce multi-threshold spiking neurons,which improve the efficiency of information transmission within theSpiking-UNet. For the training strategy, we adopt a conversion and fine-tuningpipeline that leverage pre-trained U-Net models. During the conversion process,significant variability in data distribution across different parts is observedwhen utilizing skip connections. Therefore, we propose a connection-wisenormalization method to prevent inaccurate firing rates. Furthermore, we adopta flow-based training method to fine-tune the converted models, reducing timesteps while preserving performance. Experimental results show that, on imagesegmentation and denoising, our Spiking-UNet achieves comparable performance toits non-spiking counterpart, surpassing existing SNN methods. Compared with theconverted Spiking-UNet without fine-tuning, our Spiking-UNet reduces inferencetime by approximately 90\%. This research broadens the application scope ofSNNs in image processing and is expected to inspire further exploration in thefield of neuromorphic engineering. The code for our Spiking-UNet implementationis available at https://github.com/SNNresearch/Spiking-UNet.</description><author>Hebei Li, Yueyi Zhang, Zhiwei Xiong, Zheng-jun Zha, Xiaoyan Sun</author><pubDate>Thu, 20 Jul 2023 17:00:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10974v1</guid></item><item><title>A Review of Machine Learning Methods Applied to Structural Dynamics and Vibroacoustic</title><link>http://arxiv.org/abs/2204.06362v2</link><description>The use of Machine Learning (ML) has rapidly spread across several fields,having encountered many applications in Structural Dynamics and Vibroacoustic(SD\&amp;V). The increasing capabilities of ML to unveil insights from data, drivenby unprecedented data availability, algorithms advances and computationalpower, enhance decision making, uncertainty handling, patterns recognition andreal-time assessments. Three main applications in SD\&amp;V have taken advantage ofthese benefits. In Structural Health Monitoring, ML detection and prognosislead to safe operation and optimized maintenance schedules. Systemidentification and control design are leveraged by ML techniques in ActiveNoise Control and Active Vibration Control. Finally, the so-called ML-basedsurrogate models provide fast alternatives to costly simulations, enablingrobust and optimized product design. Despite the many works in the area, theyhave not been reviewed and analyzed. Therefore, to keep track and understandthis ongoing integration of fields, this paper presents a survey of MLapplications in SD\&amp;V analyses, shedding light on the current state ofimplementation and emerging opportunities. The main methodologies, advantages,limitations, and recommendations based on scientific knowledge were identifiedfor each of the three applications. Moreover, the paper considers the role ofDigital Twins and Physics Guided ML to overcome current challenges and powerfuture research progress. As a result, the survey provides a broad overview ofthe present landscape of ML applied in SD\&amp;V and guides the reader to anadvanced understanding of progress and prospects in the field.</description><author>Barbara Cunha, Christophe Droz, Abdelmalek Zine, Stéphane Foulard, Mohamed Ichchou</author><pubDate>Thu, 20 Jul 2023 16:48:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.06362v2</guid></item><item><title>Spinal nerve segmentation method and dataset construction in endoscopic surgical scenarios</title><link>http://arxiv.org/abs/2307.10955v1</link><description>Endoscopic surgery is currently an important treatment method in the field ofspinal surgery and avoiding damage to the spinal nerves through video guidanceis a key challenge. This paper presents the first real-time segmentation methodfor spinal nerves in endoscopic surgery, which provides crucial navigationalinformation for surgeons. A finely annotated segmentation dataset ofapproximately 10,000 consec-utive frames recorded during surgery is constructedfor the first time for this field, addressing the problem of semanticsegmentation. Based on this dataset, we propose FUnet (Frame-Unet), whichachieves state-of-the-art performance by utilizing inter-frame information andself-attention mechanisms. We also conduct extended exper-iments on a similarpolyp endoscopy video dataset and show that the model has good generalizationability with advantageous performance. The dataset and code of this work arepresented at: https://github.com/zzzzzzpc/FUnet .</description><author>Shaowu Peng, Pengcheng Zhao, Yongyu Ye, Junying Chen, Yunbing Chang, Xiaoqing Zheng</author><pubDate>Thu, 20 Jul 2023 16:26:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10955v1</guid></item><item><title>Soft-tissue Driven Craniomaxillofacial Surgical Planning</title><link>http://arxiv.org/abs/2307.10954v1</link><description>In CMF surgery, the planning of bony movement to achieve a desired facialoutcome is a challenging task. Current bone driven approaches focus onnormalizing the bone with the expectation that the facial appearance will becorrected accordingly. However, due to the complex non-linear relationshipbetween bony structure and facial soft-tissue, such bone-driven methods areinsufficient to correct facial deformities. Despite efforts to simulate facialchanges resulting from bony movement, surgical planning still relies oniterative revisions and educated guesses. To address these issues, we propose asoft-tissue driven framework that can automatically create and verify surgicalplans. Our framework consists of a bony planner network that estimates the bonymovements required to achieve the desired facial outcome and a facial simulatornetwork that can simulate the possible facial changes resulting from theestimated bony movement plans. By combining these two models, we can verify anddetermine the final bony movement required for planning. The proposed frameworkwas evaluated using a clinical dataset, and our experimental resultsdemonstrate that the soft-tissue driven approach greatly improves the accuracyand efficacy of surgical planning when compared to the conventional bone-drivenapproach.</description><author>Xi Fang, Daeseung Kim, Xuanang Xu, Tianshu Kuang, Nathan Lampen, Jungwook Lee, Hannah H. Deng, Jaime Gateno, Michael A. K. Liebschner, James J. Xia, Pingkun Yan</author><pubDate>Thu, 20 Jul 2023 16:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10954v1</guid></item><item><title>PE-YOLO: Pyramid Enhancement Network for Dark Object Detection</title><link>http://arxiv.org/abs/2307.10953v1</link><description>Current object detection models have achieved good results on many benchmarkdatasets, detecting objects in dark conditions remains a large challenge. Toaddress this issue, we propose a pyramid enhanced network (PENet) and joint itwith YOLOv3 to build a dark object detection framework named PE-YOLO. Firstly,PENet decomposes the image into four components of different resolutions usingthe Laplacian pyramid. Specifically we propose a detail processing module (DPM)to enhance the detail of images, which consists of context branch and edgebranch. In addition, we propose a low-frequency enhancement filter (LEF) tocapture low-frequency semantics and prevent high-frequency noise. PE-YOLOadopts an end-to-end joint training approach and only uses normal detectionloss to simplify the training process. We conduct experiments on the low-lightobject detection dataset ExDark to demonstrate the effectiveness of ours. Theresults indicate that compared with other dark detectors and low-lightenhancement models, PE-YOLO achieves the advanced results, achieving 78.0% inmAP and 53.6 in FPS, respectively, which can adapt to object detection underdifferent low-light conditions. The code is available athttps://github.com/XiangchenYin/PE-YOLO.</description><author>Xiangchen Yin, Zhenda Yu, Zetao Fei, Wenjun Lv, Xin Gao</author><pubDate>Thu, 20 Jul 2023 16:25:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10953v1</guid></item><item><title>Improving Online Lane Graph Extraction by Object-Lane Clustering</title><link>http://arxiv.org/abs/2307.10947v1</link><description>Autonomous driving requires accurate local scene understanding information.To this end, autonomous agents deploy object detection and online BEV lanegraph extraction methods as a part of their perception stack. In this work, wepropose an architecture and loss formulation to improve the accuracy of locallane graph estimates by using 3D object detection outputs. The proposed methodlearns to assign the objects to centerlines by considering the centerlines ascluster centers and the objects as data points to be assigned a probabilitydistribution over the cluster centers. This training scheme ensures directsupervision on the relationship between lanes and objects, thus leading tobetter performance. The proposed method improves lane graph estimationsubstantially over state-of-the-art methods. The extensive ablations show thatour method can achieve significant performance improvements by using theoutputs of existing 3D object detection methods. Since our method uses thedetection outputs rather than detection method intermediate representations, asingle model of our method can use any detection method at test time.</description><author>Yigit Baran Can, Alexander Liniger, Danda Pani Paudel, Luc Van Gool</author><pubDate>Thu, 20 Jul 2023 16:21:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10947v1</guid></item><item><title>$α$-$β$-Factorization and the Binary Case of Simon's Congruence</title><link>http://arxiv.org/abs/2306.14192v2</link><description>In 1991 H\'ebrard introduced a factorization of words that turned out to be apowerful tool for the investigation of a word's scattered factors (also knownas (scattered) subwords or subsequences). Based on this, first Karandikar andSchnoebelen introduced the notion of $k$-richness and later on Barker et al.the notion of $k$-universality. In 2022 Fleischmann et al. presented ageneralization of the arch factorization by intersecting the arch factorizationof a word and its reverse. While the authors merely used this factorization forthe investigation of shortest absent scattered factors, in this work weinvestigate this new $\alpha$-$\beta$-factorization as such. We characterizethe famous Simon congruence of $k$-universal words in terms of $1$-universalwords. Moreover, we apply these results to binary words. In this special case,we obtain a full characterization of the classes and calculate the index of thecongruence. Lastly, we start investigating the ternary case, present a fulllist of possibilities for $\alpha\beta\alpha$-factors, and characterize theircongruence.</description><author>Pamela Fleischmann, Jonas Höfer, Annika Huch, Dirk Nowotka</author><pubDate>Thu, 20 Jul 2023 16:20:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14192v2</guid></item><item><title>Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery</title><link>http://arxiv.org/abs/2307.10943v1</link><description>Recent advances in deep learning have significantly improved the performanceof various computer vision applications. However, discovering novel categoriesin an incremental learning scenario remains a challenging problem due to thelack of prior knowledge about the number and nature of new categories. Existingmethods for novel category discovery are limited by their reliance on labeleddatasets and prior knowledge about the number of novel categories and theproportion of novel samples in the batch. To address the limitations and moreaccurately reflect real-world scenarios, in this paper, we propose a novelunsupervised class incremental learning approach for discovering novelcategories on unlabeled sets without prior knowledge. The proposed methodfine-tunes the feature extractor and proxy anchors on labeled sets, then splitssamples into old and novel categories and clusters on the unlabeled dataset.Furthermore, the proxy anchors-based exemplar generates representative categoryvectors to mitigate catastrophic forgetting. Experimental results demonstratethat our proposed approach outperforms the state-of-the-art methods onfine-grained datasets under real-world scenarios.</description><author>Hyungmin Kim, Sungho Suh, Daehwan Kim, Daun Jeong, Hansang Cho, Junmo Kim</author><pubDate>Thu, 20 Jul 2023 16:13:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10943v1</guid></item><item><title>Collaborative Perception in Autonomous Driving: Methods, Datasets and Challenges</title><link>http://arxiv.org/abs/2301.06262v2</link><description>Collaborative perception is essential to address occlusion and sensor failureissues in autonomous driving. In recent years, theoretical and experimentalinvestigations of novel works for collaborative perception have increasedtremendously. So far, however, few reviews have focused on systematicalcollaboration modules and large-scale collaborative perception datasets. Thiswork reviews recent achievements in this field to bridge this gap and motivatefuture research. We start with a brief overview of collaboration schemes. Afterthat, we systematically summarize the collaborative perception methods forideal scenarios and real-world issues. The former focus on collaborationmodules and efficiency, and the latter is devoted to addressing the problems inactual application. Furthermore, we present large-scale public datasets andsummarize quantitative results on these benchmarks. Finally, we highlight gapsand overlooked challenges between current academic research and real-worldapplications.</description><author>Yushan Han, Hui Zhang, Huifang Li, Yi Jin, Congyan Lang, Yidong Li</author><pubDate>Thu, 20 Jul 2023 16:09:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06262v2</guid></item><item><title>PASTA: Pretrained Action-State Transformer Agents</title><link>http://arxiv.org/abs/2307.10936v1</link><description>Self-supervised learning has brought about a revolutionary paradigm shift invarious computing domains, including NLP, vision, and biology. Recentapproaches involve pre-training transformer models on vast amounts of unlabeleddata, serving as a starting point for efficiently solving downstream tasks. Inthe realm of reinforcement learning, researchers have recently adapted theseapproaches by developing models pre-trained on expert trajectories, enablingthem to address a wide range of tasks, from robotics to recommendation systems.However, existing methods mostly rely on intricate pre-training objectivestailored to specific downstream applications. This paper presents acomprehensive investigation of models we refer to as Pretrained Action-StateTransformer Agents (PASTA). Our study uses a unified methodology and covers anextensive set of general downstream tasks including behavioral cloning, offlineRL, sensor failure robustness, and dynamics change adaptation. Our goal is tosystematically compare various design choices and provide valuable insights topractitioners for building robust models. Key highlights of our study includetokenization at the action and state component level, using fundamentalpre-training objectives like next token prediction, training models acrossdiverse domains simultaneously, and using parameter efficient fine-tuning(PEFT). The developed models in our study contain fewer than 10 millionparameters and the application of PEFT enables fine-tuning of fewer than 10,000parameters during downstream adaptation, allowing a broad community to usethese models and reproduce our experiments. We hope that this study willencourage further research into the use of transformers with first-principlesdesign choices to represent RL trajectories and contribute to robust policylearning.</description><author>Raphael Boige, Yannis Flet-Berliac, Arthur Flajolet, Guillaume Richard, Thomas Pierrot</author><pubDate>Thu, 20 Jul 2023 16:09:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10936v1</guid></item><item><title>Inorganic synthesis-structure maps in zeolites with machine learning and crystallographic distances</title><link>http://arxiv.org/abs/2307.10935v1</link><description>Zeolites are inorganic materials known for their diversity of applications,synthesis conditions, and resulting polymorphs. Although their synthesis iscontrolled both by inorganic and organic synthesis conditions, computationalstudies of zeolite synthesis have focused mostly on organic template design. Inthis work, we use a strong distance metric between crystal structures andmachine learning (ML) to create inorganic synthesis maps in zeolites. Startingwith 253 known zeolites, we show how the continuous distances betweenframeworks reproduce inorganic synthesis conditions from the literature withoutusing labels such as building units. An unsupervised learning analysis showsthat neighboring zeolites according to our metric often share similar inorganicsynthesis conditions, even in template-based routes. In combination with MLclassifiers, we find synthesis-structure relationships for 14 common inorganicconditions in zeolites, namely Al, B, Be, Ca, Co, F, Ga, Ge, K, Mg, Na, P, Si,and Zn. By explaining the model predictions, we demonstrate how(dis)similarities towards known structures can be used as features for thesynthesis space. Finally, we show how these methods can be used to predictinorganic synthesis conditions for unrealized frameworks in hypotheticaldatabases and interpret the outcomes by extracting local structural patternsfrom zeolites. In combination with template design, this work can acceleratethe exploration of the space of synthesis conditions for zeolites.</description><author>Daniel Schwalbe-Koda, Daniel E. Widdowson, Tuan Anh Pham, Vitaliy A. Kurlin</author><pubDate>Thu, 20 Jul 2023 16:07:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10935v1</guid></item><item><title>OCTraN: 3D Occupancy Convolutional Transformer Network in Unstructured Traffic Scenarios</title><link>http://arxiv.org/abs/2307.10934v1</link><description>Modern approaches for vision-centric environment perception for autonomousnavigation make extensive use of self-supervised monocular depth estimationalgorithms that output disparity maps. However, when this disparity map isprojected onto 3D space, the errors in disparity are magnified, resulting in adepth estimation error that increases quadratically as the distance from thecamera increases. Though Light Detection and Ranging (LiDAR) can solve thisissue, it is expensive and not feasible for many applications. To address thechallenge of accurate ranging with low-cost sensors, we propose, OCTraN, atransformer architecture that uses iterative-attention to convert 2D imagefeatures into 3D occupancy features and makes use of convolution and transposeconvolution to efficiently operate on spatial information. We also develop aself-supervised training pipeline to generalize the model to any scene byeliminating the need for LiDAR ground truth by substituting it withpseudo-ground truth labels obtained from boosted monocular depth estimation.</description><author>Aditya Nalgunda Ganesh, Dhruval Pobbathi Badrinath, Harshith Mohan Kumar, Priya SS, Surabhi Narayan</author><pubDate>Thu, 20 Jul 2023 16:06:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10934v1</guid></item><item><title>Identical and Fraternal Twins: Fine-Grained Semantic Contrastive Learning of Sentence Representations</title><link>http://arxiv.org/abs/2307.10932v1</link><description>The enhancement of unsupervised learning of sentence representations has beensignificantly achieved by the utility of contrastive learning. This approachclusters the augmented positive instance with the anchor instance to create adesired embedding space. However, relying solely on the contrastive objectivecan result in sub-optimal outcomes due to its inability to differentiate subtlesemantic variations between positive pairs. Specifically, common dataaugmentation techniques frequently introduce semantic distortion, leading to asemantic margin between the positive pair. While the InfoNCE loss functionoverlooks the semantic margin and prioritizes similarity maximization betweenpositive pairs during training, leading to the insensitive semanticcomprehension ability of the trained model. In this paper, we introduce a novelIdentical and Fraternal Twins of Contrastive Learning (named IFTCL) framework,capable of simultaneously adapting to various positive pairs generated bydifferent augmentation techniques. We propose a \textit{Twins Loss} to preservethe innate margin during training and promote the potential of data enhancementin order to overcome the sub-optimal issue. We also present proof-of-conceptexperiments combined with the contrastive objective to prove the validity ofthe proposed Twins Loss. Furthermore, we propose a hippocampus queue mechanismto restore and reuse the negative instances without additional calculation,which further enhances the efficiency and performance of the IFCL. We verifythe IFCL framework on nine semantic textual similarity tasks with both Englishand Chinese datasets, and the experimental results show that IFCL outperformsstate-of-the-art methods.</description><author>Qingfa Xiao, Shuangyin Li, Lei Chen</author><pubDate>Thu, 20 Jul 2023 16:02:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10932v1</guid></item><item><title>MediaGPT : A Large Language Model Target Chinese Media</title><link>http://arxiv.org/abs/2307.10930v1</link><description>The development of large language models (LLMs) has seen rapid progress inrecent years. One of the most widely used LLMs is the Generative Pre-trainedTransformer (GPT) series, which has been applied in various fields, includingthe media domain. However, in practical applications, the differences betweenthe media's use cases and the general-purpose applications of LLMs have becomeincreasingly apparent, especially Chinese. As a result, there is a growing needto develop LLM that are specifically tailored to the unique requirements of themedia domain. In this paper, we present MediaGPT, a large language modeltraining on variety of media data and addressing the practical needs of Chinesemedia. We have designed a diverse set of task instruction types to cater to thespecific requirements of the domain. To further validate the effectiveness ofour proposed LLM, we have constructed unique datasets that are tailored to themedia domain and have also developed verification methods that are specificallydesigned for generative-type tasks. By doing so, we aim to bridge the gapbetween the general-purpose LLM and the requirements of the media domain, andto pave the way for more effective and efficient use of LLM in this field. Thispaper aims to explore the challenges and opportunities of developing LLM formedia applications and to propose potential solutions for addressing thesechallenges.</description><author>Zhonghao Wang</author><pubDate>Thu, 20 Jul 2023 15:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10930v1</guid></item><item><title>FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets</title><link>http://arxiv.org/abs/2307.10928v1</link><description>Evaluation of Large Language Models (LLMs) is challenging because aligning tohuman values requires the composition of multiple skills and the required setof skills varies depending on the instruction. Recent studies have evaluatedthe performance of LLMs in two ways, (1) automatic evaluation on severalindependent benchmarks and (2) human or machined-based evaluation giving anoverall score to the response. However, both settings are coarse-grainedevaluations, not considering the nature of user instructions that requireinstance-wise skill composition, which limits the interpretation of the truecapabilities of LLMs. In this paper, we introduce FLASK (Fine-grained LanguageModel Evaluation based on Alignment SKill Sets), a fine-grained evaluationprotocol that can be used for both model-based and human-based evaluation whichdecomposes coarse-level scoring to an instance-wise skill set-level.Specifically, we define 12 fine-grained skills needed for LLMs to followopen-ended user instructions and construct an evaluation set by allocating aset of skills for each instance. Additionally, by annotating the target domainsand difficulty level for each instance, FLASK provides a holistic view with acomprehensive analysis of a model's performance depending on skill, domain, anddifficulty. Through using FLASK, we compare multiple open-sourced andproprietary LLMs and observe highly-correlated findings between model-based andhuman-based evaluations. FLASK enables developers to more accurately measurethe model performance and how it can be improved by analyzing factors that makeLLMs proficient in particular skills. For practitioners, FLASK can be used torecommend suitable models for particular situations through comprehensivecomparison among various LLMs. We release the evaluation data and codeimplementation at https://github.com/kaistAI/FLASK.</description><author>Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang, Seungone Kim, Yongrae Jo, James Thorne, Juho Kim, Minjoon Seo</author><pubDate>Thu, 20 Jul 2023 15:56:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10928v1</guid></item><item><title>Modeling 3D cardiac contraction and relaxation with point cloud deformation networks</title><link>http://arxiv.org/abs/2307.10927v1</link><description>Global single-valued biomarkers of cardiac function typically used inclinical practice, such as ejection fraction, provide limited insight on thetrue 3D cardiac deformation process and hence, limit the understanding of bothhealthy and pathological cardiac mechanics. In this work, we propose the PointCloud Deformation Network (PCD-Net) as a novel geometric deep learning approachto model 3D cardiac contraction and relaxation between the extreme ends of thecardiac cycle. It employs the recent advances in point cloud-based deeplearning into an encoder-decoder structure, in order to enable efficientmulti-scale feature learning directly on multi-class 3D point cloudrepresentations of the cardiac anatomy. We evaluate our approach on a largedataset of over 10,000 cases from the UK Biobank study and find average Chamferdistances between the predicted and ground truth anatomies below the pixelresolution of the underlying image acquisition. Furthermore, we observe similarclinical metrics between predicted and ground truth populations and show thatthe PCD-Net can successfully capture subpopulation-specific differences betweennormal subjects and myocardial infarction (MI) patients. We then demonstratethat the learned 3D deformation patterns outperform multiple clinicalbenchmarks by 13% and 7% in terms of area under the receiver operatingcharacteristic curve for the tasks of prevalent MI detection and incident MIprediction and by 7% in terms of Harrell's concordance index for MI survivalanalysis.</description><author>Marcel Beetz, Abhirup Banerjee, Vicente Grau</author><pubDate>Thu, 20 Jul 2023 15:56:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10927v1</guid></item><item><title>Confidence intervals for performance estimates in 3D medical image segmentation</title><link>http://arxiv.org/abs/2307.10926v1</link><description>Medical segmentation models are evaluated empirically. As such an evaluationis based on a limited set of example images, it is unavoidably noisy. Beyond amean performance measure, reporting confidence intervals is thus crucial.However, this is rarely done in medical image segmentation. The width of theconfidence interval depends on the test set size and on the spread of theperformance measure (its standard-deviation across of the test set). Forclassification, many test images are needed to avoid wide confidence intervals.Segmentation, however, has not been studied, and it differs by the amount ofinformation brought by a given test image. In this paper, we study the typicalconfidence intervals in medical image segmentation. We carry experiments on 3Dimage segmentation using the standard nnU-net framework, two datasets from theMedical Decathlon challenge and two performance measures: the Dice accuracy andthe Hausdorff distance. We show that the parametric confidence intervals arereasonable approximations of the bootstrap estimates for varying test set sizesand spread of the performance metric. Importantly, we show that the test sizeneeded to achieve a given precision is often much lower than for classificationtasks. Typically, a 1% wide confidence interval requires about 100-200 testsamples when the spread is low (standard-deviation around 3%). More difficultsegmentation tasks may lead to higher spreads and require over 1000 samples.</description><author>R. El Jurdi, G. Varoquax, O. Colliot</author><pubDate>Thu, 20 Jul 2023 15:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10926v1</guid></item><item><title>Intrinsic Appearance Decomposition Using Point Cloud Representation</title><link>http://arxiv.org/abs/2307.10924v1</link><description>Intrinsic decomposition is to infer the albedo and shading from the image.Since it is a heavily ill-posed problem, previous methods rely on priorassumptions from 2D images, however, the exploration of the data representationitself is limited. The point cloud is known as a rich format of scenerepresentation, which naturally aligns the geometric information and the colorinformation of an image. Our proposed method, Point Intrinsic Net, in short,PoInt-Net, jointly predicts the albedo, light source direction, and shading,using point cloud representation. Experiments reveal the benefits of PoInt-Net,in terms of accuracy, it outperforms 2D representation approaches on multiplemetrics across datasets; in terms of efficiency, it trains on small-scale pointclouds and performs stably on any-scale point clouds; in terms of robustness,it only trains on single object level dataset, and demonstrates reasonablegeneralization ability for unseen objects and scenes.</description><author>Xiaoyan Xing, Konrad Groh, Sezer Karaoglu, Theo Gevers</author><pubDate>Thu, 20 Jul 2023 15:51:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10924v1</guid></item><item><title>Sequential Multi-Dimensional Self-Supervised Learning for Clinical Time Series</title><link>http://arxiv.org/abs/2307.10923v1</link><description>Self-supervised learning (SSL) for clinical time series data has receivedsignificant attention in recent literature, since these data are highly richand provide important information about a patient's physiological state.However, most existing SSL methods for clinical time series are limited in thatthey are designed for unimodal time series, such as a sequence of structuredfeatures (e.g., lab values and vitals signs) or an individual high-dimensionalphysiological signal (e.g., an electrocardiogram). These existing methodscannot be readily extended to model time series that exhibit multimodality,with structured features and high-dimensional data being recorded at eachtimestep in the sequence. In this work, we address this gap and propose a newSSL method -- Sequential Multi-Dimensional SSL -- where a SSL loss is appliedboth at the level of the entire sequence and at the level of the individualhigh-dimensional data points in the sequence in order to better captureinformation at both scales. Our strategy is agnostic to the specific form ofloss function used at each level -- it can be contrastive, as in SimCLR, ornon-contrastive, as in VICReg. We evaluate our method on two real-worldclinical datasets, where the time series contains sequences of (1)high-frequency electrocardiograms and (2) structured data from lab values andvitals signs. Our experimental results indicate that pre-training with ourmethod and then fine-tuning on downstream tasks improves performance overbaselines on both datasets, and in several settings, can lead to improvementsacross different self-supervised loss functions.</description><author>Aniruddh Raghu, Payal Chandak, Ridwan Alam, John Guttag, Collin M. Stultz</author><pubDate>Thu, 20 Jul 2023 15:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10923v1</guid></item><item><title>Language-based Action Concept Spaces Improve Video Self-Supervised Learning</title><link>http://arxiv.org/abs/2307.10922v1</link><description>Recent contrastive language image pre-training has led to learning highlytransferable and robust image representations. However, adapting these modelsto video domains with minimal supervision remains an open problem. We explore asimple step in that direction, using language tied self-supervised learning toadapt an image CLIP model to the video domain. A backbone modified for temporalmodeling is trained under self-distillation settings with train objectivesoperating in an action concept space. Feature vectors of various actionconcepts extracted from a language encoder using relevant textual promptsconstruct this space. We introduce two train objectives, concept distillationand concept alignment, that retain generality of original representations whileenforcing relations between actions and their attributes. Our approach improveszero-shot and linear probing performance on three action recognitionbenchmarks.</description><author>Kanchana Ranasinghe, Michael Ryoo</author><pubDate>Thu, 20 Jul 2023 15:47:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10922v1</guid></item><item><title>Revisiting Fine-Tuning Strategies for Self-supervised Medical Imaging Analysis</title><link>http://arxiv.org/abs/2307.10915v1</link><description>Despite the rapid progress in self-supervised learning (SSL), end-to-endfine-tuning still remains the dominant fine-tuning strategy for medical imaginganalysis. However, it remains unclear whether this approach is truly optimalfor effectively utilizing the pre-trained knowledge, especially considering thediverse categories of SSL that capture different types of features. In thispaper, we first establish strong contrastive and restorative SSL baselines thatoutperform SOTA methods across four diverse downstream tasks. Building uponthese strong baselines, we conduct an extensive fine-tuning analysis acrossmultiple pre-training and fine-tuning datasets, as well as various fine-tuningdataset sizes. Contrary to the conventional wisdom of fine-tuning only the lastfew layers of a pre-trained network, we show that fine-tuning intermediatelayers is more effective, with fine-tuning the second quarter (25-50%) of thenetwork being optimal for contrastive SSL whereas fine-tuning the third quarter(50-75%) of the network being optimal for restorative SSL. Compared to thede-facto standard of end-to-end fine-tuning, our best fine-tuning strategy,which fine-tunes a shallower network consisting of the first three quarters(0-75%) of the pre-trained network, yields improvements of as much as 5.48%.Additionally, using these insights, we propose a simple yet effective method toleverage the complementary strengths of multiple SSL models, resulting inenhancements of up to 3.57% compared to using the best model alone. Hence, ourfine-tuning strategies not only enhance the performance of individual SSLmodels, but also enable effective utilization of the complementary strengthsoffered by multiple SSL models, leading to significant improvements inself-supervised medical imaging analysis.</description><author>Muhammad Osama Khan, Yi Fang</author><pubDate>Thu, 20 Jul 2023 15:39:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10915v1</guid></item><item><title>Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients</title><link>http://arxiv.org/abs/2212.14319v3</link><description>Partial differential equations (PDEs) are important tools to model physicalsystems and including them into machine learning models is an important way ofincorporating physical knowledge. Given any system of linear PDEs with constantcoefficients, we propose a family of Gaussian process (GP) priors, which wecall EPGP, such that all realizations are exact solutions of this system. Weapply the Ehrenpreis-Palamodov fundamental principle, which works as anon-linear Fourier transform, to construct GP kernels mirroring standardspectral methods for GPs. Our approach can infer probable solutions of linearPDE systems from any data such as noisy measurements, or pointwise definedinitial and boundary conditions. Constructing EPGP-priors is algorithmic,generally applicable, and comes with a sparse version (S-EPGP) that learns therelevant spectral frequencies and works better for big data sets. Wedemonstrate our approach on three families of systems of PDEs, the heatequation, wave equation, and Maxwell's equations, where we improve upon thestate of the art in computation time and precision, in some experiments byseveral orders of magnitude.</description><author>Marc Härkönen, Markus Lange-Hegermann, Bogdan Raiţă</author><pubDate>Thu, 20 Jul 2023 15:37:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.14319v3</guid></item><item><title>Provably Efficient UCB-type Algorithms For Learning Predictive State Representations</title><link>http://arxiv.org/abs/2307.00405v2</link><description>The general sequential decision-making problem, which includes Markovdecision processes (MDPs) and partially observable MDPs (POMDPs) as specialcases, aims at maximizing a cumulative reward by making a sequence of decisionsbased on a history of observations and actions over time. Recent studies haveshown that the sequential decision-making problem is statistically learnable ifit admits a low-rank structure modeled by predictive state representations(PSRs). Despite these advancements, existing approaches typically involveoracles or steps that are not computationally efficient. On the other hand, theupper confidence bound (UCB) based approaches, which have served successfullyas computationally efficient methods in bandits and MDPs, have not beeninvestigated for more general PSRs, due to the difficulty of optimistic bonusdesign in these more challenging settings. This paper proposes the first knownUCB-type approach for PSRs, featuring a novel bonus term that upper bounds thetotal variation distance between the estimated and true models. We furthercharacterize the sample complexity bounds for our designed UCB-type algorithmsfor both online and offline PSRs. In contrast to existing approaches for PSRs,our UCB-type algorithms enjoy computational efficiency, last-iterate guaranteednear-optimal policy, and guaranteed model accuracy.</description><author>Ruiquan Huang, Yingbin Liang, Jing Yang</author><pubDate>Thu, 20 Jul 2023 15:36:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00405v2</guid></item><item><title>WeakPolyp: You Only Look Bounding Box for Polyp Segmentation</title><link>http://arxiv.org/abs/2307.10912v1</link><description>Limited by expensive pixel-level labels, polyp segmentation models areplagued by data shortage and suffer from impaired generalization. In contrast,polyp bounding box annotations are much cheaper and more accessible. Thus, toreduce labeling cost, we propose to learn a weakly supervised polypsegmentation model (i.e., WeakPolyp) completely based on bounding boxannotations. However, coarse bounding boxes contain too much noise. To avoidinterference, we introduce the mask-to-box (M2B) transformation. By supervisingthe outer box mask of the prediction instead of the prediction itself, M2Bgreatly mitigates the mismatch between the coarse label and the preciseprediction. But, M2B only provides sparse supervision, leading to non-uniquepredictions. Therefore, we further propose a scale consistency (SC) loss fordense supervision. By explicitly aligning predictions across the same image atdifferent scales, the SC loss largely reduces the variation of predictions.Note that our WeakPolyp is a plug-and-play model, which can be easily ported toother appealing backbones. Besides, the proposed modules are only used duringtraining, bringing no computation cost to inference. Extensive experimentsdemonstrate the effectiveness of our proposed WeakPolyp, which surprisinglyachieves a comparable performance with a fully supervised model, requiring nomask annotations at all.</description><author>Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou, Zhen Li</author><pubDate>Thu, 20 Jul 2023 15:34:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10912v1</guid></item><item><title>The Role of Entropy and Reconstruction in Multi-View Self-Supervised Learning</title><link>http://arxiv.org/abs/2307.10907v1</link><description>The mechanisms behind the success of multi-view self-supervised learning(MVSSL) are not yet fully understood. Contrastive MVSSL methods have beenstudied through the lens of InfoNCE, a lower bound of the Mutual Information(MI). However, the relation between other MVSSL methods and MI remains unclear.We consider a different lower bound on the MI consisting of an entropy and areconstruction term (ER), and analyze the main MVSSL families through its lens.Through this ER bound, we show that clustering-based methods such asDeepCluster and SwAV maximize the MI. We also re-interpret the mechanisms ofdistillation-based approaches such as BYOL and DINO, showing that theyexplicitly maximize the reconstruction term and implicitly encourage a stableentropy, and we confirm this empirically. We show that replacing the objectivesof common MVSSL methods with this ER bound achieves competitive performance,while making them stable when training with smaller batch sizes or smallerexponential moving average (EMA) coefficients. Github repo: https://github.com/apple/ml-entropy-reconstruction.</description><author>Borja Rodríguez-Gálvez, Arno Blaas, Pau Rodríguez, Adam Goliński, Xavier Suau, Jason Ramapuram, Dan Busbridge, Luca Zappella</author><pubDate>Thu, 20 Jul 2023 15:29:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10907v1</guid></item><item><title>GSMorph: Gradient Surgery for cine-MRI Cardiac Deformable Registration</title><link>http://arxiv.org/abs/2306.14687v2</link><description>Deep learning-based deformable registration methods have been widelyinvestigated in diverse medical applications. Learning-based deformableregistration relies on weighted objective functions trading off registrationaccuracy and smoothness of the deformation field. Therefore, they inevitablyrequire tuning the hyperparameter for optimal registration performance. Tuningthe hyperparameters is highly computationally expensive and introducesundesired dependencies on domain knowledge. In this study, we construct aregistration model based on the gradient surgery mechanism, named GSMorph, toachieve a hyperparameter-free balance on multiple losses. In GSMorph, wereformulate the optimization procedure by projecting the gradient of similarityloss orthogonally to the plane associated with the smoothness constraint,rather than additionally introducing a hyperparameter to balance these twocompeting terms. Furthermore, our method is model-agnostic and can be mergedinto any deep registration network without introducing extra parameters orslowing down inference. In this study, We compared our method withstate-of-the-art (SOTA) deformable registration approaches over two publiclyavailable cardiac MRI datasets. GSMorph proves superior to five SOTAlearning-based registration models and two conventional registrationtechniques, SyN and Demons, on both registration accuracy and smoothness.</description><author>Haoran Dou, Ning Bi, Luyi Han, Yuhao Huang, Ritse Mann, Xin Yang, Dong Ni, Nishant Ravikumar, Alejandro F. Frangi, Yunzhi Huang</author><pubDate>Thu, 20 Jul 2023 15:29:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14687v2</guid></item><item><title>High-order Tensor Pooling with Attention for Action Recognition</title><link>http://arxiv.org/abs/2110.05216v2</link><description>We aim at capturing high-order statistics of feature vectors formed by aneural network, and propose end-to-end second- and higher-order pooling to forma tensor descriptor. Tensor descriptors require a robust similarity measure dueto low numbers of aggregated vectors and the burstiness phenomenon, when agiven feature appears more/less frequently than statistically expected. TheHeat Diffusion Process (HDP) on a graph Laplacian is closely related to theEigenvalue Power Normalization (EPN) of the covariance/auto-correlation matrix,whose inverse forms a loopy graph Laplacian. We show that the HDP and the EPNplay the same role, i.e., to boost or dampen the magnitude of the eigenspectrumthus preventing the burstiness. We equip higher-order tensors with EPN whichacts as a spectral detector of higher-order occurrences to prevent burstiness.We also prove that for a tensor of order r built from d dimensional featuredescriptors, such a detector gives the likelihood if at least one higher-orderoccurrence is 'projected' into one of binom(d,r) subspaces represented by thetensor; thus forming a tensor power normalization metric endowed withbinom(d,r) such 'detectors'. For experimental contributions, we apply severalsecond- and higher-order pooling variants to action recognition, providepreviously not presented comparisons of such pooling variants, and showstate-of-the-art results on HMDB-51, YUP++ and MPII Cooking Activities.</description><author>Piotr Koniusz, Lei Wang, Ke Sun</author><pubDate>Thu, 20 Jul 2023 15:29:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.05216v2</guid></item><item><title>Variational Point Encoding Deformation for Dental Modeling</title><link>http://arxiv.org/abs/2307.10895v1</link><description>Digital dentistry has made significant advancements in recent years, yetnumerous challenges remain to be addressed. In this study, we release a newextensive dataset of tooth meshes to encourage further research. Additionally,we propose Variational FoldingNet (VF-Net), which extends FoldingNet to enableprobabilistic learning of point cloud representations. A key challenge inexisting latent variable models for point clouds is the lack of a 1-to-1mapping between input points and output points. Instead, they must rely onoptimizing Chamfer distances, a metric that does not have a normalizeddistributional counterpart, preventing its usage in probabilistic models. Wedemonstrate that explicit minimization of Chamfer distances can be replaced bya suitable encoder, which allows us to increase computational efficiency whilesimplifying the probabilistic extension. Our experimental findings presentempirical evidence demonstrating the superior performance of VF-Net overexisting models in terms of dental scan reconstruction and extrapolation.Additionally, our investigation highlights the robustness of VF-Net's latentrepresentations. These results underscore the promising prospects of VF-Net asan effective and reliable method for point cloud reconstruction and analysis.</description><author>Johan Ziruo Ye, Thomas Ørkild, Peter Lempel Søndergaard, Søren Hauberg</author><pubDate>Thu, 20 Jul 2023 15:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10895v1</guid></item><item><title>Human Motion Generation: A Survey</title><link>http://arxiv.org/abs/2307.10894v1</link><description>Human motion generation aims to generate natural human pose sequences andshows immense potential for real-world applications. Substantial progress hasbeen made recently in motion data collection technologies and generationmethods, laying the foundation for increasing interest in human motiongeneration. Most research within this field focuses on generating human motionsbased on conditional signals, such as text, audio, and scene contexts. Whilesignificant advancements have been made in recent years, the task continues topose challenges due to the intricate nature of human motion and its implicitrelationship with conditional signals. In this survey, we present acomprehensive literature review of human motion generation, which, to the bestof our knowledge, is the first of its kind in this field. We begin byintroducing the background of human motion and generative models, followed byan examination of representative methods for three mainstream sub-tasks:text-conditioned, audio-conditioned, and scene-conditioned human motiongeneration. Additionally, we provide an overview of common datasets andevaluation metrics. Lastly, we discuss open problems and outline potentialfuture research directions. We hope that this survey could provide thecommunity with a comprehensive glimpse of this rapidly evolving field andinspire novel ideas that address the outstanding challenges.</description><author>Wentao Zhu, Xiaoxuan Ma, Dongwoo Ro, Hai Ci, Jinlu Zhang, Jiaxin Shi, Feng Gao, Qi Tian, Yizhou Wang</author><pubDate>Thu, 20 Jul 2023 15:15:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10894v1</guid></item><item><title>Learning and Generalizing Polynomials in Simulation Metamodeling</title><link>http://arxiv.org/abs/2307.10892v1</link><description>The ability to learn polynomials and generalize out-of-distribution isessential for simulation metamodels in many disciplines of engineering, wherethe time step updates are described by polynomials. While feed forward neuralnetworks can fit any function, they cannot generalize out-of-distribution forhigher-order polynomials. Therefore, this paper collects and proposesmultiplicative neural network (MNN) architectures that are used as recursivebuilding blocks for approximating higher-order polynomials. Our experimentsshow that MNNs are better than baseline models at generalizing, and theirperformance in validation is true to their performance in out-of-distributiontests. In addition to MNN architectures, a simulation metamodeling approach isproposed for simulations with polynomial time step updates. For thesesimulations, simulating a time interval can be performed in fewer steps byincreasing the step size, which entails approximating higher-order polynomials.While our approach is compatible with any simulation with polynomial time stepupdates, a demonstration is shown for an epidemiology simulation model, whichalso shows the inductive bias in MNNs for learning and generalizinghigher-order polynomials.</description><author>Jesper Hauch, Christoffer Riis, Francisco C. Pereira</author><pubDate>Thu, 20 Jul 2023 15:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10892v1</guid></item><item><title>Syntactic vs Semantic Linear Abstraction and Refinement of Neural Networks</title><link>http://arxiv.org/abs/2307.10891v1</link><description>Abstraction is a key verification technique to improve scalability. However,its use for neural networks is so far extremely limited. Previous approachesfor abstracting classification networks replace several neurons with one ofthem that is similar enough. We can classify the similarity as defined eithersyntactically (using quantities on the connections between neurons) orsemantically (on the activation values of neurons for various inputs).Unfortunately, the previous approaches only achieve moderate reductions, whenimplemented at all. In this work, we provide a more flexible framework where aneuron can be replaced with a linear combination of other neurons, improvingthe reduction. We apply this approach both on syntactic and semanticabstractions, and implement and evaluate them experimentally. Further, weintroduce a refinement method for our abstractions, allowing for finding abetter balance between reduction and precision.</description><author>Calvin Chau, Jan Křetínský, Stefanie Mohr</author><pubDate>Thu, 20 Jul 2023 15:10:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10891v1</guid></item><item><title>Player-optimal Stable Regret for Bandit Learning in Matching Markets</title><link>http://arxiv.org/abs/2307.10890v1</link><description>The problem of matching markets has been studied for a long time in theliterature due to its wide range of applications. Finding a stable matching isa common equilibrium objective in this problem. Since market participants areusually uncertain of their preferences, a rich line of recent works study theonline setting where one-side participants (players) learn their unknownpreferences from iterative interactions with the other side (arms). Mostprevious works in this line are only able to derive theoretical guarantees forplayer-pessimal stable regret, which is defined compared with the players'least-preferred stable matching. However, under the pessimal stable matching,players only obtain the least reward among all stable matchings. To maximizeplayers' profits, player-optimal stable matching would be the most desirable.Though \citet{basu21beyond} successfully bring an upper bound forplayer-optimal stable regret, their result can be exponentially large ifplayers' preference gap is small. Whether a polynomial guarantee for thisregret exists is a significant but still open problem. In this work, we providea new algorithm named explore-then-Gale-Shapley (ETGS) and show that theoptimal stable regret of each player can be upper bounded by $O(K\logT/\Delta^2)$ where $K$ is the number of arms, $T$ is the horizon and $\Delta$is the players' minimum preference gap among the first $N+1$-ranked arms. Thisresult significantly improves previous works which either have a weakerplayer-pessimal stable matching objective or apply only to markets with specialassumptions. When the preferences of participants satisfy some specialconditions, our regret upper bound also matches the previously derived lowerbound.</description><author>Fang Kong, Shuai Li</author><pubDate>Thu, 20 Jul 2023 15:10:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10890v1</guid></item><item><title>$ν^2$-Flows: Fast and improved neutrino reconstruction in multi-neutrino final states with conditional normalizing flows</title><link>http://arxiv.org/abs/2307.02405v2</link><description>In this work we introduce $\nu^2$-Flows, an extension of the $\nu$-Flowsmethod to final states containing multiple neutrinos. The architecture cannatively scale for all combinations of object types and multiplicities in thefinal state for any desired neutrino multiplicities. In $t\bar{t}$ dileptonevents, the momenta of both neutrinos and correlations between them arereconstructed more accurately than when using the most popular standardanalytical techniques, and solutions are found for all events. Inference timeis significantly faster than competing methods, and can be reduced further byevaluating in parallel on graphics processing units. We apply $\nu^2$-Flows to$t\bar{t}$ dilepton events and show that the per-bin uncertainties in unfoldeddistributions is much closer to the limit of performance set by perfectneutrino reconstruction than standard techniques. For the chosen doubledifferential observables $\nu^2$-Flows results in improved statisticalprecision for each bin by a factor of 1.5 to 2 in comparison to the NeutrinoWeighting method and up to a factor of four in comparison to the Ellipseapproach.</description><author>John Andrew Raine, Matthew Leigh, Knut Zoch, Tobias Golling</author><pubDate>Thu, 20 Jul 2023 15:10:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02405v2</guid></item><item><title>Topological Point Cloud Clustering</title><link>http://arxiv.org/abs/2303.16716v2</link><description>We present Topological Point Cloud Clustering (TPCC), a new method to clusterpoints in an arbitrary point cloud based on their contribution to globaltopological features. TPCC synthesizes desirable features from spectralclustering and topological data analysis and is based on considering thespectral properties of a simplicial complex associated to the considered pointcloud. As it is based on considering sparse eigenvector computations, TPCC issimilarly easy to interpret and implement as spectral clustering. However, byfocusing not just on a single matrix associated to a graph created from thepoint cloud data, but on a whole set of Hodge-Laplacians associated to anappropriately constructed simplicial complex, we can leverage a far richer setof topological features to characterize the data points within the point cloudand benefit from the relative robustness of topological techniques againstnoise. We test the performance of TPCC on both synthetic and real-world dataand compare it with classical spectral clustering.</description><author>Vincent P. Grande, Michael T. Schaub</author><pubDate>Thu, 20 Jul 2023 14:54:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.16716v2</guid></item><item><title>My Boli: Code-mixed Marathi-English Corpora, Pretrained Language Models and Evaluation Benchmarks</title><link>http://arxiv.org/abs/2306.14030v2</link><description>The research on code-mixed data is limited due to the unavailability ofdedicated code-mixed datasets and pre-trained language models. In this work, wefocus on the low-resource Indian language Marathi which lacks any prior work incode-mixing. We present L3Cube-MeCorpus, a large code-mixed Marathi-English(Mr-En) corpus with 10 million social media sentences for pretraining. We alsorelease L3Cube-MeBERT and MeRoBERTa, code-mixed BERT-based transformer modelspre-trained on MeCorpus. Furthermore, for benchmarking, we present threesupervised datasets MeHate, MeSent, and MeLID for downstream tasks likecode-mixed Mr-En hate speech detection, sentiment analysis, and languageidentification respectively. These evaluation datasets individually consist ofmanually annotated \url{~}12,000 Marathi-English code-mixed tweets. Ablationsshow that the models trained on this novel corpus significantly outperform theexisting state-of-the-art BERT models. This is the first work that presentsartifacts for code-mixed Marathi research. All datasets and models are publiclyreleased at https://github.com/l3cube-pune/MarathiNLP .</description><author>Tanmay Chavan, Omkar Gokhale, Aditya Kane, Shantanu Patankar, Raviraj Joshi</author><pubDate>Thu, 20 Jul 2023 14:54:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14030v2</guid></item><item><title>Risk-optimized Outlier Removal for Robust Point Cloud Classification</title><link>http://arxiv.org/abs/2307.10875v1</link><description>The popularity of point cloud deep models for safety-critical purposes hasincreased, but the reliability and security of these models can be compromisedby intentional or naturally occurring point cloud noise. To combat this issue,we present a novel point cloud outlier removal method called PointCVaR, whichempowers standard-trained models to eliminate additional outliers and restorethe data. Our approach begins by conducting attribution analysis to determinethe influence of each point on the model output, which we refer to as pointrisk. We then optimize the process of filtering high-risk points usingConditional Value at Risk (CVaR) as the objective. The rationale for thisapproach is based on the observation that noise points in point clouds tend tocluster in the tail of the risk distribution, with a low frequency but a highlevel of risk, resulting in significant interference with classificationresults. Despite requiring no additional training effort, our method producesexceptional results in various removal-and-classification experiments for noisypoint clouds, which are corrupted by random noise, adversarial noise, andbackdoor trigger noise. Impressively, it achieves 87% accuracy in defenseagainst the backdoor attack by removing triggers. Overall, the proposedPointCVaR effectively eliminates noise points and enhances point cloudclassification, making it a promising plug-in module for various models indifferent scenarios.</description><author>Xinke Li, Junchi Lu</author><pubDate>Thu, 20 Jul 2023 14:47:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10875v1</guid></item><item><title>Conservative Estimation of Perception Relevance of Dynamic Objects for Safe Trajectories in Automotive Scenarios</title><link>http://arxiv.org/abs/2307.10873v1</link><description>Having efficient testing strategies is a core challenge that needs to beovercome for the release of automated driving. This necessitates clearrequirements as well as suitable methods for testing. In this work, therequirements for perception modules are considered with respect to relevance.The concept of relevance currently remains insufficiently defined andspecified. In this paper, we propose a novel methodology to overcome thischallenge by exemplary application to collision safety in the highway domain.Using this general system and use case specification, a corresponding conceptfor relevance is derived. Irrelevant objects are thus defined as objects whichdo not limit the set of safe actions available to the ego vehicle underconsideration of all uncertainties. As an initial step, the use case isdecomposed into functional scenarios with respect to collision relevance. Foreach functional scenario, possible actions of both the ego vehicle and anyother dynamic object are formalized as equations. This set of possible actionsis constrained by traffic rules, yielding relevance criteria. As a result, wepresent a conservative estimation which dynamic objects are relevant forperception and need to be considered for a complete evaluation. The estimationprovides requirements which are applicable for offline testing and validationof perception components. A visualization is presented for examples from thehighD dataset, showing the plausibility of the results. Finally, a possibilityfor a future validation of the presented relevance concept is outlined.</description><author>Ken Mori, Kai Storms, Steven Peters</author><pubDate>Thu, 20 Jul 2023 14:43:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10873v1</guid></item><item><title>Nonlinear Meta-Learning Can Guarantee Faster Rates</title><link>http://arxiv.org/abs/2307.10870v1</link><description>Many recent theoretical works on \emph{meta-learning} aim to achieveguarantees in leveraging similar representational structures from related taskstowards simplifying a target task. Importantly, the main aim in theory works onthe subject is to understand the extent to which convergence rates -- inlearning a common representation -- \emph{may scale with the number $N$ oftasks} (as well as the number of samples per task). First steps in this settingdemonstrate this property when both the shared representation amongst tasks,and task-specific regression functions, are linear. This linear setting readilyreveals the benefits of aggregating tasks, e.g., via averaging arguments. Inpractice, however, the representation is often highly nonlinear, introducingnontrivial biases in each task that cannot easily be averaged out as in thelinear case. In the present work, we derive theoretical guarantees formeta-learning with nonlinear representations. In particular, assuming theshared nonlinearity maps to an infinite-dimensional RKHS, we show thatadditional biases can be mitigated with careful regularization that leveragesthe smoothness of task-specific regression functions,</description><author>Dimitri Meunier, Zhu Li, Arthur Gretton, Samory Kpotufe</author><pubDate>Thu, 20 Jul 2023 14:42:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10870v1</guid></item></channel></rss>