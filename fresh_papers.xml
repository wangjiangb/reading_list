<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 14 Mar 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FastMAC: Stochastic Spectral Sampling of Correspondence Graph</title><link>http://arxiv.org/abs/2403.08770v1</link><description>3D correspondence, i.e., a pair of 3D points, is a fundamental concept incomputer vision. A set of 3D correspondences, when equipped with compatibilityedges, forms a correspondence graph. This graph is a critical component inseveral state-of-the-art 3D point cloud registration approaches, e.g., the onebased on maximal cliques (MAC). However, its properties have not been wellunderstood. So we present the first study that introduces graph signalprocessing into the domain of correspondence graph. We exploit the generalizeddegree signal on correspondence graph and pursue sampling strategies thatpreserve high-frequency components of this signal. To address time-consumingsingular value decomposition in deterministic sampling, we resort to astochastic approximate sampling strategy. As such, the core of our method isthe stochastic spectral sampling of correspondence graph. As an application, webuild a complete 3D registration algorithm termed as FastMAC, that reachesreal-time speed while leading to little to none performance drop. Throughextensive experiments, we validate that FastMAC works for both indoor andoutdoor benchmarks. For example, FastMAC can accelerate MAC by 80 times whilemaintaining high registration success rate on KITTI. Codes are publiclyavailable at https://github.com/Forrest-110/FastMAC.</description><author>Yifei Zhang, Hao Zhao, Hongyang Li, Siheng Chen</author><pubDate>Wed, 13 Mar 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08770v1</guid></item><item><title>3DFIRES: Few Image 3D REconstruction for Scenes with Hidden Surface</title><link>http://arxiv.org/abs/2403.08768v1</link><description>This paper introduces 3DFIRES, a novel system for scene-level 3Dreconstruction from posed images. Designed to work with as few as one view,3DFIRES reconstructs the complete geometry of unseen scenes, including hiddensurfaces. With multiple view inputs, our method produces full reconstructionwithin all camera frustums. A key feature of our approach is the fusion ofmulti-view information at the feature level, enabling the production ofcoherent and comprehensive 3D reconstruction. We train our system onnon-watertight scans from large-scale real scene dataset. We show it matchesthe efficacy of single-view reconstruction methods with only one input andsurpasses existing techniques in both quantitative and qualitative measures forsparse-view 3D reconstruction.</description><author>Linyi Jin, Nilesh Kulkarni, David Fouhey</author><pubDate>Wed, 13 Mar 2024 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08768v1</guid></item><item><title>MonoOcc: Digging into Monocular Semantic Occupancy Prediction</title><link>http://arxiv.org/abs/2403.08766v1</link><description>Monocular Semantic Occupancy Prediction aims to infer the complete 3Dgeometry and semantic information of scenes from only 2D images. It hasgarnered significant attention, particularly due to its potential to enhancethe 3D perception of autonomous vehicles. However, existing methods rely on acomplex cascaded framework with relatively limited information to restore 3Dscenes, including a dependency on supervision solely on the whole network'soutput, single-frame input, and the utilization of a small backbone. Thesechallenges, in turn, hinder the optimization of the framework and yieldinferior prediction results, particularly concerning smaller and long-tailedobjects. To address these issues, we propose MonoOcc. In particular, we (i)improve the monocular occupancy prediction framework by proposing an auxiliarysemantic loss as supervision to the shallow layers of the framework and animage-conditioned cross-attention module to refine voxel features with visualclues, and (ii) employ a distillation module that transfers temporalinformation and richer knowledge from a larger image backbone to the monocularsemantic occupancy prediction framework with low cost of hardware. With theseadvantages, our method yields state-of-the-art performance on the camera-basedSemanticKITTI Scene Completion benchmark. Codes and models can be accessed athttps://github.com/ucaszyp/MonoOcc</description><author>Yupeng Zheng, Xiang Li, Pengfei Li, Yuhang Zheng, Bu Jin, Chengliang Zhong, Xiaoxiao Long, Hao Zhao, Qichao Zhang</author><pubDate>Wed, 13 Mar 2024 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08766v1</guid></item><item><title>VLOGGER: Multimodal Diffusion for Embodied Avatar Synthesis</title><link>http://arxiv.org/abs/2403.08764v1</link><description>We propose VLOGGER, a method for audio-driven human video generation from asingle input image of a person, which builds on the success of recentgenerative diffusion models. Our method consists of 1) a stochastichuman-to-3d-motion diffusion model, and 2) a novel diffusion-based architecturethat augments text-to-image models with both spatial and temporal controls.This supports the generation of high quality video of variable length, easilycontrollable through high-level representations of human faces and bodies. Incontrast to previous work, our method does not require training for eachperson, does not rely on face detection and cropping, generates the completeimage (not just the face or the lips), and considers a broad spectrum ofscenarios (e.g. visible torso or diverse subject identities) that are criticalto correctly synthesize humans who communicate. We also curate MENTOR, a newand diverse dataset with 3d pose and expression annotations, one order ofmagnitude larger than previous ones (800,000 identities) and with dynamicgestures, on which we train and ablate our main technical contributions. VLOGGER outperforms state-of-the-art methods in three public benchmarks,considering image quality, identity preservation and temporal consistency whilealso generating upper-body gestures. We analyze the performance of VLOGGER withrespect to multiple diversity metrics, showing that our architectural choicesand the use of MENTOR benefit training a fair and unbiased model at scale.Finally we show applications in video editing and personalization.</description><author>Enric Corona, Andrei Zanfir, Eduard Gabriel Bazavan, Nikos Kolotouros, Thiemo Alldieck, Cristian Sminchisescu</author><pubDate>Wed, 13 Mar 2024 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08764v1</guid></item><item><title>Simple and Scalable Strategies to Continually Pre-train Large Language Models</title><link>http://arxiv.org/abs/2403.08763v1</link><description>Large language models (LLMs) are routinely pre-trained on billions of tokens,only to start the process over again once new data becomes available. A muchmore efficient solution is to continually pre-train these models, savingsignificant compute compared to re-training. However, the distribution shiftinduced by new data typically results in degraded performance on previous dataor poor adaptation to the new data. In this work, we show that a simple andscalable combination of learning rate (LR) re-warming, LR re-decaying, andreplay of previous data is sufficient to match the performance of fullyre-training from scratch on all available data, as measured by final loss andlanguage model (LM) evaluation benchmarks. Specifically, we show this for aweak but realistic distribution shift between two commonly used LLMpre-training datasets (English$\rightarrow$English) and a stronger distributionshift (English$\rightarrow$German) at the $405$M parameter model scale withlarge dataset sizes (hundreds of billions of tokens). Selecting the weak butrealistic shift for larger-scale experiments, we also find that our continuallearning strategies match the re-training baseline for a 10B parameter LLM. Ourresults demonstrate that LLMs can be successfully updated via simple andscalable continual learning strategies, matching the re-training baseline usingonly a fraction of the compute. Finally, inspired by previous work, we proposealternatives to the cosine learning rate schedule that help circumventforgetting induced by LR re-warming and that are not bound to a fixed tokenbudget.</description><author>Adam Ibrahim, Benjamin Thérien, Kshitij Gupta, Mats L. Richter, Quentin Anthony, Timothée Lesort, Eugene Belilovsky, Irina Rish</author><pubDate>Wed, 13 Mar 2024 18:58:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08763v1</guid></item><item><title>Segmentation of Knee Bones for Osteoarthritis Assessment: A Comparative Analysis of Supervised, Few-Shot, and Zero-Shot Learning Approaches</title><link>http://arxiv.org/abs/2403.08761v1</link><description>Knee osteoarthritis is a degenerative joint disease that induces chronic painand disability. Bone morphological analysis is a promising tool to understandthe mechanical aspect of this disorder. This study proposes a 2D bonemorphological analysis using manually segmented bones to explore morphologicalfeatures related to distinct pain conditions. Furthermore, six semanticsegmentation algorithms are assessed for extracting femur and tibia bones fromX-ray images. Our analysis reveals that the morphology of the femur undergoessignificant changes in instances where pain worsens. Conversely, improvementsin pain may not manifest pronounced alterations in bone shape. Thefew-shot-learning-based algorithm, UniverSeg, demonstrated superiorsegmentation results with Dice scores of 99.69% for femur and 99.60% for tibia.Regarding pain condition classification, the zero-shot-learning-basedalgorithm, CP-SAM, achieved the highest accuracy at 66% among all models.UniverSeg is recommended for automatic knee bone segmentation, while SAM modelsshow potential with prompt encoder modifications for optimized outcomes. Thesefindings highlight the effectiveness of few-shot learning for semanticsegmentation and the potential of zero-shot learning in enhancingclassification models for knee osteoarthritis diagnosis.</description><author>Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai</author><pubDate>Wed, 13 Mar 2024 18:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08761v1</guid></item><item><title>MIM4D: Masked Modeling with Multi-View Video for Autonomous Driving Representation Learning</title><link>http://arxiv.org/abs/2403.08760v1</link><description>Learning robust and scalable visual representations from massive multi-viewvideo data remains a challenge in computer vision and autonomous driving.Existing pre-training methods either rely on expensive supervised learning with3D annotations, limiting the scalability, or focus on single-frame or monocularinputs, neglecting the temporal information. We propose MIM4D, a novelpre-training paradigm based on dual masked image modeling (MIM). MIM4Dleverages both spatial and temporal relations by training on masked multi-viewvideo inputs. It constructs pseudo-3D features using continuous scene flow andprojects them onto 2D plane for supervision. To address the lack of dense 3Dsupervision, MIM4D reconstruct pixels by employing 3D volumetric differentiablerendering to learn geometric representations. We demonstrate that MIM4Dachieves state-of-the-art performance on the nuScenes dataset for visualrepresentation learning in autonomous driving. It significantly improvesexisting methods on multiple downstream tasks, including BEV segmentation (8.7%IoU), 3D object detection (3.5% mAP), and HD map construction (1.4% mAP). Ourwork offers a new choice for learning representation at scale in autonomousdriving. Code and models are released at https://github.com/hustvl/MIM4D</description><author>Jialv Zou, Bencheng Liao, Qian Zhang, Wenyu Liu, Xinggang Wang</author><pubDate>Wed, 13 Mar 2024 18:58:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08760v1</guid></item><item><title>Spatiotemporal Diffusion Model with Paired Sampling for Accelerated Cardiac Cine MRI</title><link>http://arxiv.org/abs/2403.08758v1</link><description>Current deep learning reconstruction for accelerated cardiac cine MRI suffersfrom spatial and temporal blurring. We aim to improve image sharpness andmotion delineation for cine MRI under high undersampling rates. Aspatiotemporal diffusion enhancement model conditional on an existing deeplearning reconstruction along with a novel paired sampling strategy wasdeveloped. The diffusion model provided sharper tissue boundaries and clearermotion than the original reconstruction in experts evaluation on clinical data.The innovative paired sampling strategy substantially reduced artificial noisesin the generative results.</description><author>Shihan Qiu, Shaoyan Pan, Yikang Liu, Lin Zhao, Jian Xu, Qi Liu, Terrence Chen, Eric Z. Chen, Xiao Chen, Shanhui Sun</author><pubDate>Wed, 13 Mar 2024 18:56:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08758v1</guid></item><item><title>Efficient Combinatorial Optimization via Heat Diffusion</title><link>http://arxiv.org/abs/2403.08757v1</link><description>Combinatorial optimization problems are widespread but inherently challengingdue to their discrete nature.The primary limitation of existing methods is thatthey can only access a small fraction of the solution space at each iteration,resulting in limited efficiency for searching the global optimal. To overcomethis challenge, diverging from conventional efforts of expanding the solver'ssearch scope, we focus on enabling information to actively propagate to thesolver through heat diffusion. By transforming the target function whilepreserving its optima, heat diffusion facilitates information flow from distantregions to the solver, providing more efficient navigation. Utilizing heatdiffusion, we propose a framework for solving general combinatorialoptimization problems. The proposed methodology demonstrates superiorperformance across a range of the most challenging and widely encounteredcombinatorial optimizations. Echoing recent advancements in harnessingthermodynamics for generative artificial intelligence, our study furtherreveals its significant potential in advancing combinatorial optimization.</description><author>Hengyuan Ma, Wenlian Lu, Jianfeng Feng</author><pubDate>Wed, 13 Mar 2024 18:55:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08757v1</guid></item><item><title>DAM: Dynamic Adapter Merging for Continual Video QA Learning</title><link>http://arxiv.org/abs/2403.08755v1</link><description>We present a parameter-efficient method for continual videoquestion-answering (VidQA) learning. Our method, named DAM, uses the proposedDynamic Adapter Merging to (i) mitigate catastrophic forgetting, (ii) enableefficient adaptation to continually arriving datasets, (iii) handle inputs fromunknown datasets during inference, and (iv) enable knowledge sharing acrosssimilar dataset domains. Given a set of continually streaming VidQA datasets,we sequentially train dataset-specific adapters for each dataset while freezingthe parameters of a large pretrained video-language backbone. During inference,given a video-question sample from an unknown domain, our method first uses theproposed non-parametric router function to compute a probability for eachadapter, reflecting how relevant that adapter is to the current video-questioninput instance. Subsequently, the proposed dynamic adapter merging schemeaggregates all the adapter weights into a new adapter instance tailored forthat particular test sample to compute the final VidQA prediction, mitigatingthe impact of inaccurate router predictions and facilitating knowledge sharingacross domains. Our DAM model outperforms prior state-of-the-art continuallearning approaches by 9.1% while exhibiting 1.9% less forgetting on 6 VidQAdatasets spanning various domains. We further extend DAM to continual imageclassification and image QA and outperform prior methods by a large margin. Thecode is publicly available at: https://github.com/klauscc/DAM</description><author>Feng Cheng, Ziyang Wang, Yi-Lin Sung, Yan-Bo Lin, Mohit Bansal, Gedas Bertasius</author><pubDate>Wed, 13 Mar 2024 18:53:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08755v1</guid></item><item><title>Neural reproducing kernel Banach spaces and representer theorems for deep networks</title><link>http://arxiv.org/abs/2403.08750v1</link><description>Studying the function spaces defined by neural networks helps to understandthe corresponding learning models and their inductive bias. While in somelimits neural networks correspond to function spaces that are reproducingkernel Hilbert spaces, these regimes do not capture the properties of thenetworks used in practice. In contrast, in this paper we show that deep neuralnetworks define suitable reproducing kernel Banach spaces. These spaces are equipped with norms that enforce a form of sparsity,enabling them to adapt to potential latent structures within the input data andtheir representations. In particular, leveraging the theory of reproducingkernel Banach spaces, combined with variational results, we derive representertheorems that justify the finite architectures commonly employed inapplications. Our study extends analogous results for shallow networks and canbe seen as a step towards considering more practically plausible neuralarchitectures.</description><author>Francesca Bartolucci, Ernesto De Vito, Lorenzo Rosasco, Stefano Vigogna</author><pubDate>Wed, 13 Mar 2024 18:51:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08750v1</guid></item><item><title>Clinically Feasible Diffusion Reconstruction for Highly-Accelerated Cardiac Cine MRI</title><link>http://arxiv.org/abs/2403.08749v1</link><description>The currently limited quality of accelerated cardiac cine reconstruction maypotentially be improved by the emerging diffusion models, but the clinicallyunacceptable long processing time poses a challenge. We aim to develop aclinically feasible diffusion-model-based reconstruction pipeline to improvethe image quality of cine MRI. A multi-in multi-out diffusion enhancement modeltogether with fast inference strategies were developed to be used inconjunction with a reconstruction model. The diffusion reconstruction reducedspatial and temporal blurring in prospectively undersampled clinical data, asvalidated by experts inspection. The 1.5s per video processing time enabled theapproach to be applied in clinical scenarios.</description><author>Shihan Qiu, Shaoyan Pan, Yikang Liu, Lin Zhao, Jian Xu, Qi Liu, Terrence Chen, Eric Z. Chen, Xiao Chen, Shanhui Sun</author><pubDate>Wed, 13 Mar 2024 18:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08749v1</guid></item><item><title>Real-time 3D semantic occupancy prediction for autonomous vehicles using memory-efficient sparse convolution</title><link>http://arxiv.org/abs/2403.08748v1</link><description>In autonomous vehicles, understanding the surrounding 3D environment of theego vehicle in real-time is essential. A compact way to represent scenes whileencoding geometric distances and semantic object information is via 3D semanticoccupancy maps. State of the art 3D mapping methods leverage transformers withcross-attention mechanisms to elevate 2D vision-centric camera features intothe 3D domain. However, these methods encounter significant challenges inreal-time applications due to their high computational demands duringinference. This limitation is particularly problematic in autonomous vehicles,where GPU resources must be shared with other tasks such as localization andplanning. In this paper, we introduce an approach that extracts features fromfront-view 2D camera images and LiDAR scans, then employs a sparse convolutionnetwork (Minkowski Engine), for 3D semantic occupancy prediction. Given thatoutdoor scenes in autonomous driving scenarios are inherently sparse, theutilization of sparse convolution is particularly apt. By jointly solving theproblems of 3D scene completion of sparse scenes and 3D semantic segmentation,we provide a more efficient learning framework suitable for real-timeapplications in autonomous vehicles. We also demonstrate competitive accuracyon the nuScenes dataset.</description><author>Samuel Sze, Lars Kunze</author><pubDate>Wed, 13 Mar 2024 18:50:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08748v1</guid></item><item><title>iCONTRA: Toward Thematic Collection Design Via Interactive Concept Transfer</title><link>http://arxiv.org/abs/2403.08746v1</link><description>Creating thematic collections in industries demands innovative designs andcohesive concepts. Designers may face challenges in maintaining thematicconsistency when drawing inspiration from existing objects, landscapes, orartifacts. While AI-powered graphic design tools offer help, they often fail togenerate cohesive sets based on specific thematic concepts. In response, weintroduce iCONTRA, an interactive CONcept TRAnsfer system. With a user-friendlyinterface, iCONTRA enables both experienced designers and novices toeffortlessly explore creative design concepts and efficiently generate thematiccollections. We also propose a zero-shot image editing algorithm, eliminatingthe need for fine-tuning models, which gradually integrates information frominitial objects, ensuring consistency in the generation process withoutinfluencing the background. A pilot study suggests iCONTRA's potential toreduce designers' efforts. Experimental results demonstrate its effectivenessin producing consistent and high-quality object concept transfers. iCONTRAstands as a promising tool for innovation and creative exploration in thematiccollection design. The source code will be available at:https://github.com/vdkhoi20/iCONTRA.</description><author>Dinh-Khoi Vo, Duy-Nam Ly, Khanh-Duy Le, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le</author><pubDate>Wed, 13 Mar 2024 18:48:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08746v1</guid></item><item><title>Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework</title><link>http://arxiv.org/abs/2403.08743v1</link><description>Large language models (LLMs) can easily generate biased and discriminativeresponses. As LLMs tap into consequential decision-making (e.g., hiring andhealthcare), it is of crucial importance to develop strategies to mitigatethese biases. This paper focuses on social bias, tackling the associationbetween demographic information and LLM outputs. We propose a causality-guideddebiasing framework that utilizes causal understandings of (1) thedata-generating process of the training corpus fed to LLMs, and (2) theinternal reasoning process of LLM inference, to guide the design of prompts fordebiasing LLM outputs through selection mechanisms. Our framework unifiesexisting de-biasing prompting approaches such as inhibitive instructions andin-context contrastive examples, and sheds light on new ways of debiasing byencouraging bias-free reasoning. Our strong empirical performance on real-worlddatasets demonstrates that our framework provides principled guidelines ondebiasing LLM outputs even with only the black-box access.</description><author>Jingling Li, Zeyu Tang, Xiaoyu Liu, Peter Spirtes, Kun Zhang, Liu Leqi, Yang Liu</author><pubDate>Wed, 13 Mar 2024 18:46:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08743v1</guid></item><item><title>Can Direct Latent Model Learning Solve Linear Quadratic Gaussian Control?</title><link>http://arxiv.org/abs/2212.14511v2</link><description>We study the task of learning state representations from potentiallyhigh-dimensional observations, with the goal of controlling an unknownpartially observable system. We pursue a direct latent model learning approach,where a dynamic model in some latent state space is learned by predictingquantities directly related to planning (e.g., costs) without reconstructingthe observations. In particular, we focus on an intuitive cost-driven staterepresentation learning method for solving Linear Quadratic Gaussian (LQG)control, one of the most fundamental partially observable control problems. Asour main results, we establish finite-sample guarantees of finding anear-optimal state representation function and a near-optimal controller usingthe directly learned latent model. To the best of our knowledge, despitevarious empirical successes, prior to this work it was unclear if such acost-driven latent model learner enjoys finite-sample guarantees. Our workunderscores the value of predicting multi-step costs, an idea that is key toour theory, and notably also an idea that is known to be empirically valuablefor learning state representations.</description><author>Yi Tian, Kaiqing Zhang, Russ Tedrake, Suvrit Sra</author><pubDate>Wed, 13 Mar 2024 18:44:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.14511v2</guid></item><item><title>Learning How to Strategically Disclose Information</title><link>http://arxiv.org/abs/2403.08741v1</link><description>Strategic information disclosure, in its simplest form, considers a gamebetween an information provider (sender) who has access to some privateinformation that an information receiver is interested in. While the receivertakes an action that affects the utilities of both players, the sender candesign information (or modify beliefs) of the receiver through signalcommitment, hence posing a Stackelberg game. However, obtaining a Stackelbergequilibrium for this game traditionally requires the sender to have access tothe receiver's objective. In this work, we consider an online version ofinformation design where a sender interacts with a receiver of an unknown typewho is adversarially chosen at each round. Restricting attention to Gaussianprior and quadratic costs for the sender and the receiver, we show that$\mathcal{O}(\sqrt{T})$ regret is achievable with full information feedback,where $T$ is the total number of interactions between the sender and thereceiver. Further, we propose a novel parametrization that allows the sender toachieve $\mathcal{O}(\sqrt{T})$ regret for a general convex utility function.We then consider the Bayesian Persuasion problem with an additional cost termin the objective function, which penalizes signaling policies that are moreinformative and obtain $\mathcal{O}(\log(T))$ regret. Finally, we establish asublinear regret bound for the partial information feedback setting and providesimulations to support our theoretical results.</description><author>Raj Kiriti Velicheti, Melih Bastopcu, S. Rasoul Etesami, Tamer Başar</author><pubDate>Wed, 13 Mar 2024 18:44:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08741v1</guid></item><item><title>The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models</title><link>http://arxiv.org/abs/2403.08739v1</link><description>A substantial gap persists in understanding the reasons behind theexceptional performance of the Transformer architecture in NLP. A particularlyunexplored area involves the mechanistic description of how the distribution ofparameters evolves over time during training. In this work we suggest thatlooking at the time evolution of the statistic distribution of modelparameters, and specifically at bifurcation effects, can help understanding themodel quality, potentially reducing training costs and evaluation efforts andempirically showing the reasons behind the effectiveness of weightssparsification.</description><author>Carlo Nicolini, Jacopo Staiano, Bruno Lepri, Raffaele Marino</author><pubDate>Wed, 13 Mar 2024 18:42:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08739v1</guid></item><item><title>Improving Acoustic Word Embeddings through Correspondence Training of Self-supervised Speech Representations</title><link>http://arxiv.org/abs/2403.08738v1</link><description>Acoustic word embeddings (AWEs) are vector representations of spoken words.An effective method for obtaining AWEs is the Correspondence Auto-Encoder(CAE). In the past, the CAE method has been associated with traditional MFCCfeatures. Representations obtained from self-supervised learning (SSL)-basedspeech models such as HuBERT, Wav2vec2, etc., are outperforming MFCC in manydownstream tasks. However, they have not been well studied in the context oflearning AWEs. This work explores the effectiveness of CAE with SSL-basedspeech representations to obtain improved AWEs. Additionally, the capabilitiesof SSL-based speech models are explored in cross-lingual scenarios forobtaining AWEs. Experiments are conducted on five languages: Polish,Portuguese, Spanish, French, and English. HuBERT-based CAE model achieves thebest results for word discrimination in all languages, despite Hu-BERT beingpre-trained on English only. Also, the HuBERT-based CAE model works well incross-lingual settings. It outperforms MFCC-based CAE models trained on thetarget languages when trained on one source language and tested on targetlanguages.</description><author>Amit Meghanani, Thomas Hain</author><pubDate>Wed, 13 Mar 2024 18:42:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08738v1</guid></item><item><title>A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models</title><link>http://arxiv.org/abs/2212.12799v2</link><description>Chemical named entity recognition (NER) models are used in many downstreamtasks, from adverse drug reaction identification to pharmacoepidemiology.However, it is unknown whether these models work the same for everyone.Performance disparities can potentially cause harm rather than the intendedgood. This paper assesses gender-related performance disparities in chemicalNER systems. We develop a framework for measuring gender bias in chemical NERmodels using synthetic data and a newly annotated corpus of over 92,405 wordswith self-identified gender information from Reddit. Our evaluation of multiplebiomedical NER models reveals evident biases. For instance, synthetic datasuggests female-related names are frequently misclassified as chemicals,especially for brand name mentions. Additionally, we observe performancedisparities between female- and male-associated data in both datasets. Manysystems fail to detect contraceptives such as birth control. Our findingsemphasize the biases in chemical NER models, urging practitioners to accountfor these biases in downstream applications.</description><author>Xingmeng Zhao, Ali Niazi, Anthony Rios</author><pubDate>Wed, 13 Mar 2024 18:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.12799v2</guid></item><item><title>Demystifying Embedding Spaces using Large Language Models</title><link>http://arxiv.org/abs/2310.04475v2</link><description>Embeddings have become a pivotal means to represent complex, multi-facetedinformation about entities, concepts, and relationships in a condensed anduseful format. Nevertheless, they often preclude direct interpretation. Whiledownstream tasks make use of these compressed representations, meaningfulinterpretation usually requires visualization using dimensionality reduction orspecialized machine learning interpretability methods. This paper addresses thechallenge of making such embeddings more interpretable and broadly useful, byemploying Large Language Models (LLMs) to directly interact with embeddings --transforming abstract vectors into understandable narratives. By injectingembeddings into LLMs, we enable querying and exploration of complex embeddingdata. We demonstrate our approach on a variety of diverse tasks, including:enhancing concept activation vectors (CAVs), communicating novel embeddedentities, and decoding user preferences in recommender systems. Our workcouples the immense information potential of embeddings with the interpretativepower of LLMs.</description><author>Guy Tennenholtz, Yinlam Chow, Chih-Wei Hsu, Jihwan Jeong, Lior Shani, Azamat Tulepbergenov, Deepak Ramachandran, Martin Mladenov, Craig Boutilier</author><pubDate>Wed, 13 Mar 2024 18:40:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04475v2</guid></item><item><title>A Hitchhiker's Guide to Geometric GNNs for 3D Atomic Systems</title><link>http://arxiv.org/abs/2312.07511v2</link><description>Recent advances in computational modelling of atomic systems, spanningmolecules, proteins, and materials, represent them as geometric graphs withatoms embedded as nodes in 3D Euclidean space. In these graphs, the geometricattributes transform according to the inherent physical symmetries of 3D atomicsystems, including rotations and translations in Euclidean space, as well asnode permutations. In recent years, Geometric Graph Neural Networks haveemerged as the preferred machine learning architecture powering applicationsranging from protein structure prediction to molecular simulations and materialgeneration. Their specificity lies in the inductive biases they leverage - suchas physical symmetries and chemical properties - to learn informativerepresentations of these geometric graphs. In this opinionated paper, we provide a comprehensive and self-containedoverview of the field of Geometric GNNs for 3D atomic systems. We coverfundamental background material and introduce a pedagogical taxonomy ofGeometric GNN architectures: (1) invariant networks, (2) equivariant networksin Cartesian basis, (3) equivariant networks in spherical basis, and (4)unconstrained networks. Additionally, we outline key datasets and applicationareas and suggest future research directions. The objective of this work is topresent a structured perspective on the field, making it accessible tonewcomers and aiding practitioners in gaining an intuition for its mathematicalabstractions.</description><author>Alexandre Duval, Simon V. Mathis, Chaitanya K. Joshi, Victor Schmidt, Santiago Miret, Fragkiskos D. Malliaros, Taco Cohen, Pietro Liò, Yoshua Bengio, Michael Bronstein</author><pubDate>Wed, 13 Mar 2024 18:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07511v2</guid></item><item><title>ILCiteR: Evidence-grounded Interpretable Local Citation Recommendation</title><link>http://arxiv.org/abs/2403.08737v1</link><description>Existing Machine Learning approaches for local citation recommendationdirectly map or translate a query, which is typically a claim or an entitymention, to citation-worthy research papers. Within such a formulation, it ischallenging to pinpoint why one should cite a specific research paper for aparticular query, leading to limited recommendation interpretability. Toalleviate this, we introduce the evidence-grounded local citationrecommendation task, where the target latent space comprises evidence spans forrecommending specific papers. Using a distantly-supervised evidence retrievaland multi-step re-ranking framework, our proposed system, ILCiteR, recommendspapers to cite for a query grounded on similar evidence spans extracted fromthe existing research literature. Unlike past formulations that simply outputrecommendations, ILCiteR retrieves ranked lists of evidence span andrecommended paper pairs. Secondly, previously proposed neural models forcitation recommendation require expensive training on massive labeled data,ideally after every significant update to the pool of candidate papers. Incontrast, ILCiteR relies solely on distant supervision from a dynamic evidencedatabase and pre-trained Transformer-based Language Models without any modeltraining. We contribute a novel dataset for the evidence-grounded localcitation recommendation task and demonstrate the efficacy of our proposedconditional neural rank-ensembling approach for re-ranking evidence spans.</description><author>Sayar Ghosh Roy, Jiawei Han</author><pubDate>Wed, 13 Mar 2024 18:38:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08737v1</guid></item><item><title>GaussCtrl: Multi-View Consistent Text-Driven 3D Gaussian Splatting Editing</title><link>http://arxiv.org/abs/2403.08733v1</link><description>We propose GaussCtrl, a text-driven method to edit a 3D scene reconstructedby the 3D Gaussian Splatting (3DGS). Our method first renders a collection of images by using the 3DGS and editsthem by using a pre-trained 2D diffusion model (ControlNet) based on the inputprompt, which is then used to optimise the 3D model. Our key contribution is multi-view consistent editing, which enables editingall images together instead of iteratively editing one image while updating the3D model as in previous works. It leads to faster editing as well as higher visual quality. This is achieved by the two terms: (a) depth-conditioned editing that enforces geometric consistency acrossmulti-view images by leveraging naturally consistent depth maps. (b) attention-based latent code alignment that unifies the appearance ofedited images by conditioning their editing to several reference views throughself and cross-view attention between images' latent representations. Experiments demonstrate that our method achieves faster editing and bettervisual results than previous state-of-the-art methods.</description><author>Jing Wu, Jia-Wang Bian, Xinghui Li, Guangrun Wang, Ian Reid, Philip Torr, Victor Adrian Prisacariu</author><pubDate>Wed, 13 Mar 2024 18:35:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08733v1</guid></item><item><title>Speculative Contrastive Decoding</title><link>http://arxiv.org/abs/2311.08981v2</link><description>Large language models~(LLMs) exhibit exceptional performance in languagetasks, yet their auto-regressive inference is limited due to high computationalrequirements and is sub-optimal due to the exposure bias. Inspired byspeculative decoding and contrastive decoding, we introduce SpeculativeContrastive Decoding~(SCD), a straightforward yet powerful decoding approachthat leverages predictions from smaller language models~(LMs) to achieve bothdecoding acceleration and quality improvement. Extensive evaluations andanalyses on four diverse language tasks demonstrate the effectiveness of SCD,showing that decoding efficiency and quality can compatibly benefit from onesmaller LM.</description><author>Hongyi Yuan, Keming Lu, Fei Huang, Zheng Yuan, Chang Zhou</author><pubDate>Wed, 13 Mar 2024 18:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08981v2</guid></item><item><title>Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization</title><link>http://arxiv.org/abs/2403.08730v1</link><description>Multimodal Large Language Models (MLLMs) excel in generating responses basedon visual inputs. However, they often suffer from a bias towards generatingresponses similar to their pretraining corpus, overshadowing the importance ofvisual information. We treat this bias as a "preference" for pretrainingstatistics, which hinders the model's grounding in visual input. To mitigatethis issue, we propose Bootstrapped Preference Optimization (BPO), whichconducts preference learning with datasets containing negative responsesbootstrapped from the model itself. Specifically, we propose the following twostrategies: 1) using distorted image inputs to the MLLM for eliciting responsesthat contain signified pretraining bias; 2) leveraging text-based LLM toexplicitly inject erroneous but common elements into the original response.Those undesirable responses are paired with original annotated responses fromthe datasets to construct the preference dataset, which is subsequentlyutilized to perform preference learning. Our approach effectively suppressespretrained LLM bias, enabling enhanced grounding in visual inputs. Extensiveexperimentation demonstrates significant performance improvements acrossmultiple benchmarks, advancing the state-of-the-art in multimodalconversational systems.</description><author>Renjie Pi, Tianyang Han, Wei Xiong, Jipeng Zhang, Runtao Liu, Rui Pan, Tong Zhang</author><pubDate>Wed, 13 Mar 2024 18:29:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08730v1</guid></item><item><title>Cross-Domain Few-Shot Segmentation via Iterative Support-Query Correspondence Mining</title><link>http://arxiv.org/abs/2401.08407v2</link><description>Cross-Domain Few-Shot Segmentation (CD-FSS) poses the challenge of segmentingnovel categories from a distinct domain using only limited exemplars. In thispaper, we undertake a comprehensive study of CD-FSS and uncover two crucialinsights: (i) the necessity of a fine-tuning stage to effectively transfer thelearned meta-knowledge across domains, and (ii) the overfitting risk during thena\"ive fine-tuning due to the scarcity of novel category examples. With theseinsights, we propose a novel cross-domain fine-tuning strategy that addressesthe challenging CD-FSS tasks. We first design Bi-directional Few-shotPrediction (BFP), which establishes support-query correspondence in abi-directional manner, crafting augmented supervision to reduce the overfittingrisk. Then we further extend BFP into Iterative Few-shot Adaptor (IFA), whichis a recursive framework to capture the support-query correspondenceiteratively, targeting maximal exploitation of supervisory signals from thesparse novel category samples. Extensive empirical evaluations show that ourmethod significantly outperforms the state-of-the-arts (+7.8\%), which verifiesthat IFA tackles the cross-domain challenges and mitigates the overfittingsimultaneously. The code is available at: https://github.com/niejiahao1998/IFA.</description><author>Jiahao Nie, Yun Xing, Gongjie Zhang, Pei Yan, Aoran Xiao, Yap-Peng Tan, Alex C. Kot, Shijian Lu</author><pubDate>Wed, 13 Mar 2024 18:28:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08407v2</guid></item><item><title>Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models trained on Corrupted Data</title><link>http://arxiv.org/abs/2403.08728v1</link><description>We provide a framework for solving inverse problems with diffusion modelslearned from linearly corrupted data. Our method, Ambient Diffusion PosteriorSampling (A-DPS), leverages a generative model pre-trained on one type ofcorruption (e.g. image inpainting) to perform posterior sampling conditioned onmeasurements from a potentially different forward process (e.g. imageblurring). We test the efficacy of our approach on standard natural imagedatasets (CelebA, FFHQ, and AFHQ) and we show that A-DPS can sometimesoutperform models trained on clean data for several image restoration tasks inboth speed and performance. We further extend the Ambient Diffusion frameworkto train MRI models with access only to Fourier subsampled multi-coil MRImeasurements at various acceleration factors (R=2, 4, 6, 8). We again observethat models trained on highly subsampled data are better priors for solvinginverse problems in the high acceleration regime than models trained on fullysampled data. We open-source our code and the trained Ambient Diffusion MRImodels: https://github.com/utcsilab/ambient-diffusion-mri .</description><author>Asad Aali, Giannis Daras, Brett Levac, Sidharth Kumar, Alexandros G. Dimakis, Jonathan I. Tamir</author><pubDate>Wed, 13 Mar 2024 18:28:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08728v1</guid></item><item><title>Adaptive Sharpness-Aware Pruning for Robust Sparse Networks</title><link>http://arxiv.org/abs/2306.14306v2</link><description>Robustness and compactness are two essential attributes of deep learningmodels that are deployed in the real world. The goals of robustness andcompactness may seem to be at odds, since robustness requires generalizationacross domains, while the process of compression exploits specificity in onedomain. We introduce Adaptive Sharpness-Aware Pruning (AdaSAP), which unifiesthese goals through the lens of network sharpness. The AdaSAP method producessparse networks that are robust to input variations which are unseen attraining time. We achieve this by strategically incorporating weightperturbations in order to optimize the loss landscape. This allows the model tobe both primed for pruning and regularized for improved robustness. AdaSAPimproves the robust accuracy of pruned models on image classification by up to+6% on ImageNet C and +4% on ImageNet V2, and on object detection by +4% on acorrupted Pascal VOC dataset, over a wide range of compression ratios, pruningcriteria, and network architectures, outperforming recent pruning art by largemargins.</description><author>Anna Bair, Hongxu Yin, Maying Shen, Pavlo Molchanov, Jose Alvarez</author><pubDate>Wed, 13 Mar 2024 18:20:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14306v2</guid></item><item><title>Historical Astronomical Diagrams Decomposition in Geometric Primitives</title><link>http://arxiv.org/abs/2403.08721v1</link><description>Automatically extracting the geometric content from the hundreds of thousandsof diagrams drawn in historical manuscripts would enable historians to studythe diffusion of astronomical knowledge on a global scale. However,state-of-the-art vectorization methods, often designed to tackle modern data,are not adapted to the complexity and diversity of historical astronomicaldiagrams. Our contribution is thus twofold. First, we introduce a uniquedataset of 303 astronomical diagrams from diverse traditions, ranging from theXIIth to the XVIIIth century, annotated with more than 3000 line segments,circles and arcs. Second, we develop a model that builds on DINO-DETR to enablethe prediction of multiple geometric primitives. We show that it can be trainedsolely on synthetic data and accurately predict primitives on our challengingdataset. Our approach widely improves over the LETR baseline, which isrestricted to lines, by introducing a meaningful parametrization for multipleprimitives, jointly training for detection and parameter refinement, usingdeformable attention and training on rich synthetic data. Our dataset and codeare available on our webpage.</description><author>Syrine Kalleli, Scott Trigg, Ségolène Albouy, Mathieu Husson, Mathieu Aubry</author><pubDate>Wed, 13 Mar 2024 18:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08721v1</guid></item><item><title>SOTOPIA-$π$: Interactive Learning of Socially Intelligent Language Agents</title><link>http://arxiv.org/abs/2403.08715v1</link><description>Humans learn social skills through both imitation and social interaction.This social learning process is largely understudied by existing research onbuilding language agents. Motivated by this gap, we propose an interactivelearning method, SOTOPIA-$\pi$, improving the social intelligence of languageagents. This method leverages behavior cloning and self-reinforcement trainingon filtered social interaction data according to large language model (LLM)ratings. We show that our training method allows a 7B LLM to reach the socialgoal completion ability of an expert model (GPT-4-based agent), while improvingthe safety of language agents and maintaining general QA ability on the MMLUbenchmark. We also find that this training paradigm uncovers some difficultiesin LLM-based evaluation of social intelligence: LLM-based evaluatorsoverestimate the abilities of the language agents trained specifically forsocial interaction.</description><author>Ruiyi Wang, Haofei Yu, Wenxin Zhang, Zhengyang Qi, Maarten Sap, Graham Neubig, Yonatan Bisk, Hao Zhu</author><pubDate>Wed, 13 Mar 2024 18:17:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08715v1</guid></item><item><title>Randomized Kaczmarz in Adversarial Distributed Setting</title><link>http://arxiv.org/abs/2302.14615v2</link><description>Developing large-scale distributed methods that are robust to the presence ofadversarial or corrupted workers is an important part of making such methodspractical for real-world problems. In this paper, we propose an iterativeapproach that is adversary-tolerant for convex optimization problems. Byleveraging simple statistics, our method ensures convergence and is capable ofadapting to adversarial distributions. Additionally, the efficiency of theproposed methods for solving convex problems is shown in simulations with thepresence of adversaries. Through simulations, we demonstrate the efficiency ofour approach in the presence of adversaries and its ability to identifyadversarial workers with high accuracy and tolerate varying levels of adversaryrates.</description><author>Longxiu Huang, Xia Li, Deanna Needell</author><pubDate>Wed, 13 Mar 2024 18:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14615v2</guid></item><item><title>GenTKG: Generative Forecasting on Temporal Knowledge Graph</title><link>http://arxiv.org/abs/2310.07793v4</link><description>The rapid advancements in large language models (LLMs) have ignited interestin the temporal knowledge graph (tKG) domain, where conventionalembedding-based and rule-based methods dominate. The question remains open ofwhether pre-trained LLMs can understand structured temporal relational data andreplace them as the foundation model for temporal relational forecasting.Therefore, we bring temporal knowledge forecasting into the generative setting.However, challenges occur in the huge chasms between complex temporal graphdata structure and sequential natural expressions LLMs can handle, and betweenthe enormous data sizes of tKGs and heavy computation costs of finetuning LLMs.To address these challenges, we propose a novel retrieval-augmented generationframework named GenTKG combining a temporal logical rule-based retrievalstrategy and few-shot parameter-efficient instruction tuning to solve the abovechallenges, respectively. Extensive experiments have shown that GenTKGoutperforms conventional methods of temporal relational forecasting with lowcomputation resources using extremely limited training data as few as 16samples. GenTKG also highlights remarkable cross-domain generalizability withoutperforming performance on unseen datasets without re-training, and in-domaingeneralizability regardless of time split in the same dataset. Our work revealsthe huge potential of LLMs in the tKG domain and opens a new frontier forgenerative forecasting on tKGs. Code and data are released here:https://github.com/mayhugotong/GenTKG.</description><author>Ruotong Liao, Xu Jia, Yunpu Ma, Yangzhe Li, Volker Tresp</author><pubDate>Wed, 13 Mar 2024 18:10:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07793v4</guid></item><item><title>SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models</title><link>http://arxiv.org/abs/2311.09818v2</link><description>While most conversational agents are grounded on either free-text orstructured knowledge, many knowledge corpora consist of hybrid sources. Thispaper presents the first conversational agent that supports the full generalityof hybrid data access for large knowledge corpora, through a language wedeveloped called SUQL (Structured and Unstructured Query Language).Specifically, SUQL extends SQL with free-text primitives (summary and answer),so information retrieval can be composed with structured data accessesarbitrarily in a formal, succinct, precise, and interpretable notation. WithSUQL, we propose the first semantic parser, an LLM with in-context learning,that can handle hybrid data sources. Our in-context learning-based approach, when applied to the HybridQA dataset,comes within 8.9% exact match and 7.1% F1 of the SOTA, which was trained on 62Kdata samples. More significantly, unlike previous approaches, our technique isapplicable to large databases and free-text corpora. We introduce a datasetconsisting of crowdsourced questions and conversations on Yelp, a large, realrestaurant knowledge base with structured and unstructured data. We show thatour few-shot conversational agent based on SUQL finds an entity satisfying alluser requirements 90.3% of the time, compared to 63.4% for a baseline based onlinearization.</description><author>Shicheng Liu, Jialiang Xu, Wesley Tjangnaka, Sina J. Semnani, Chen Jie Yu, Monica S. Lam</author><pubDate>Wed, 13 Mar 2024 18:07:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09818v2</guid></item><item><title>Diffusion-based Iterative Counterfactual Explanations for Fetal Ultrasound Image Quality Assessment</title><link>http://arxiv.org/abs/2403.08700v1</link><description>Obstetric ultrasound image quality is crucial for accurate diagnosis andmonitoring of fetal health. However, producing high-quality standard planes isdifficult, influenced by the sonographer's expertise and factors like thematernal BMI or the fetus dynamics. In this work, we propose usingdiffusion-based counterfactual explainable AI to generate realistichigh-quality standard planes from low-quality non-standard ones. Throughquantitative and qualitative evaluation, we demonstrate the effectiveness ofour method in producing plausible counterfactuals of increased quality. Thisshows future promise both for enhancing training of clinicians by providingvisual feedback, as well as for improving image quality and, consequently,downstream diagnosis and monitoring.</description><author>Paraskevas Pegios, Manxi Lin, Nina Weng, Morten Bo Søndergaard Svendsen, Zahra Bashir, Siavash Bigdeli, Anders Nymark Christensen, Martin Tolsgaard, Aasa Feragen</author><pubDate>Wed, 13 Mar 2024 18:04:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08700v1</guid></item><item><title>Fast Dual-Regularized Autoencoder for Sparse Biological Data</title><link>http://arxiv.org/abs/2401.16664v2</link><description>Relationship inference from sparse data is an important task withapplications ranging from product recommendation to drug discovery. A recentlyproposed linear model for sparse matrix completion has demonstrated surprisingadvantage in speed and accuracy over more sophisticated recommender systemsalgorithms. Here we extend the linear model to develop a shallow autoencoderfor the dual neighborhood-regularized matrix completion problem. We demonstratethe speed and accuracy advantage of our approach over the existingstate-of-the-art in predicting drug-target interactions and drug-diseaseassociations.</description><author>Aleksandar Poleksic</author><pubDate>Wed, 13 Mar 2024 18:03:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16664v2</guid></item><item><title>Implicit Regularization of Gradient Flow on One-Layer Softmax Attention</title><link>http://arxiv.org/abs/2403.08699v1</link><description>We study gradient flow on the exponential loss for a classification problemwith a one-layer softmax attention model, where the key and query weightmatrices are trained separately. Under a separability assumption on the data,we show that when gradient flow achieves the minimal loss value, it furtherimplicitly minimizes the nuclear norm of the product of the key and queryweight matrices. Such implicit regularization can be described by a SupportVector Machine (SVM) problem with respect to the attention weights. Thisfinding contrasts with prior results showing that the gradient descent inducesan implicit regularization on the Frobenius norm on the product weight matrixwhen the key and query matrices are combined into a single weight matrix fortraining. For diagonal key and query matrices, our analysis builds upon thereparameterization technique and exploits approximate KKT conditions of the SVMassociated with the classification data. Moreover, the results are extended togeneral weights configurations given proper alignment of the weight matrices'singular spaces with the data features at initialization.</description><author>Heejune Sheen, Siyu Chen, Tianhao Wang, Harrison H. Zhou</author><pubDate>Wed, 13 Mar 2024 18:02:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08699v1</guid></item><item><title>Constructing Variables Using Classifiers as an Aid to Regression: An Empirical Assessment</title><link>http://arxiv.org/abs/2403.06829v2</link><description>This paper proposes a method for the automatic creation of variables (in thecase of regression) that complement the information contained in the initialinput vector. The method works as a pre-processing step in which the continuousvalues of the variable to be regressed are discretized into a set of intervalswhich are then used to define value thresholds. Then classifiers are trained topredict whether the value to be regressed is less than or equal to each ofthese thresholds. The different outputs of the classifiers are thenconcatenated in the form of an additional vector of variables that enriches theinitial vector of the regression problem. The implemented system can thus beconsidered as a generic pre-processing tool. We tested the proposed enrichmentmethod with 5 types of regressors and evaluated it in 33 regression datasets.Our experimental results confirm the interest of the approach.</description><author>Colin Troisemaine, Vincent Lemaire</author><pubDate>Wed, 13 Mar 2024 18:01:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06829v2</guid></item><item><title>mForms : Multimodal Form-Filling with Question Answering</title><link>http://arxiv.org/abs/2011.12340v3</link><description>This paper presents a new approach to form-filling by reformulating the taskas multimodal natural language Question Answering (QA). The reformulation isachieved by first translating the elements on the GUI form (text fields,buttons, icons, etc.) to natural language questions, where these questionscapture the element's multimodal semantics. After a match is determined betweenthe form element (Question) and the user utterance (Answer), the form elementis filled through a pre-trained extractive QA system. By leveraging pre-trainedQA models and not requiring form-specific training, this approach toform-filling is zero-shot. The paper also presents an approach to furtherrefine the form-filling by using multi-task training to incorporate apotentially large number of successive tasks. Finally, the paper introduces amultimodal natural language form-filling dataset Multimodal Forms (mForms), aswell as a multimodal extension of the popular ATIS dataset to support futureresearch and experimentation. Results show the new approach not only maintainsrobust accuracy for sparse training conditions but achieves state-of-the-art F1of 0.97 on ATIS with approximately 1/10th of the training data.</description><author>Larry Heck, Simon Heck, Anirudh Sundar</author><pubDate>Wed, 13 Mar 2024 18:01:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2011.12340v3</guid></item><item><title>DiffPMAE: Diffusion Masked Autoencoders for Point Cloud Reconstruction</title><link>http://arxiv.org/abs/2312.03298v2</link><description>Point cloud streaming is increasingly getting popular, evolving into the normfor interactive service delivery and the future Metaverse. However, thesubstantial volume of data associated with point clouds presents numerouschallenges, particularly in terms of high bandwidth consumption and largestorage capacity. Despite various solutions proposed thus far, with a focus onpoint cloud compression, upsampling, and completion, thesereconstruction-related methods continue to fall short in delivering highfidelity point cloud output. As a solution, in DiffPMAE, we propose aneffective point cloud reconstruction architecture. Inspired by self-supervisedlearning concepts, we combine Masked Auto-Encoding and Diffusion Modelmechanism to remotely reconstruct point cloud data. By the nature of thisreconstruction process, DiffPMAE can be extended to many related downstreamtasks including point cloud compression, upsampling and completion. LeveragingShapeNet-55 and ModelNet datasets with over 60000 objects, we validate theperformance of DiffPMAE exceeding many state-of-the-art methods in-terms ofauto-encoding and downstream tasks considered.</description><author>Yanlong Li, Chamara Madarasingha, Kanchana Thilakarathna</author><pubDate>Wed, 13 Mar 2024 17:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03298v2</guid></item><item><title>Deep Learning for In-Orbit Cloud Segmentation and Classification in Hyperspectral Satellite Data</title><link>http://arxiv.org/abs/2403.08695v1</link><description>This article explores the latest Convolutional Neural Networks (CNNs) forcloud detection aboard hyperspectral satellites. The performance of the latest1D CNN (1D-Justo-LiuNet) and two recent 2D CNNs (nnU-net and2D-Justo-UNet-Simple) for cloud segmentation and classification is assessed.Evaluation criteria include precision and computational efficiency for in-orbitdeployment. Experiments utilize NASA's EO-1 Hyperion data, with varyingspectral channel numbers after Principal Component Analysis. Results indicatethat 1D-Justo-LiuNet achieves the highest accuracy, outperforming 2D CNNs,while maintaining compactness with larger spectral channel sets, albeit withincreased inference times. However, the performance of 1D CNN degrades withsignificant channel reduction. In this context, the 2D-Justo-UNet-Simple offersthe best balance for in-orbit deployment, considering precision, memory, andtime costs. While nnU-net is suitable for on-ground processing, deployment oflightweight 1D-Justo-LiuNet is recommended for high-precision applications.Alternatively, lightweight 2D-Justo-UNet-Simple is recommended for balancedcosts between timing and precision in orbit.</description><author>Daniel Kovac, Jan Mucha, Jon Alvarez Justo, Jiri Mekyska, Zoltan Galaz, Krystof Novotny, Radoslav Pitonak, Jan Knezik, Jonas Herec, Tor Arne Johansen</author><pubDate>Wed, 13 Mar 2024 17:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08695v1</guid></item><item><title>TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning</title><link>http://arxiv.org/abs/2403.08694v1</link><description>The development of Large Language Models (LLMs) often confronts challengesstemming from the heavy reliance on human annotators in the reinforcementlearning with human feedback (RLHF) framework, or the frequent and costlyexternal queries tied to the self-instruct paradigm. In this work, we pivot toReinforcement Learning (RL) -- but with a twist. Diverging from the typicalRLHF, which refines LLMs following instruction data training, we use RL todirectly generate the foundational instruction dataset that alone suffices forfine-tuning. Our method, TeaMs-RL, uses a suite of textual operations andrules, prioritizing the diversification of training datasets. It facilitatesthe generation of high-quality data without excessive reliance on externaladvanced models, paving the way for a single fine-tuning step and negating theneed for subsequent RLHF stages. Our findings highlight key advantages of ourapproach: reduced need for human involvement and fewer model queries (only$5.73\%$ of WizardLM's total), along with enhanced capabilities of LLMs incrafting and comprehending complex instructions compared to strong baselines,and substantially improved model privacy protection.</description><author>Shangding Gu, Alois Knoll, Ming Jin</author><pubDate>Wed, 13 Mar 2024 17:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08694v1</guid></item><item><title>Do Language Models Care About Text Quality? Evaluating Web-Crawled Corpora Across 11 Languages</title><link>http://arxiv.org/abs/2403.08693v1</link><description>Large, curated, web-crawled corpora play a vital role in training languagemodels (LMs). They form the lion's share of the training data in virtually allrecent LMs, such as the well-known GPT, LLaMA and XLM-RoBERTa models. However,despite this importance, relatively little attention has been given to thequality of these corpora. In this paper, we compare four of the currently mostrelevant large, web-crawled corpora (CC100, MaCoCu, mC4 and OSCAR) acrosseleven lower-resourced European languages. Our approach is two-fold: first, weperform an intrinsic evaluation by performing a human evaluation of the qualityof samples taken from different corpora; then, we assess the practical impactof the qualitative differences by training specific LMs on each of the corporaand evaluating their performance on downstream tasks. We find that there areclear differences in quality of the corpora, with MaCoCu and OSCAR obtainingthe best results. However, during the extrinsic evaluation, we actually findthat the CC100 corpus achieves the highest scores. We conclude that, in ourexperiments, the quality of the web-crawled corpora does not seem to play asignificant role when training LMs.</description><author>Rik van Noord, Taja Kuzman, Peter Rupnik, Nikola Ljubešić, Miquel Esplà-Gomis, Gema Ramírez-Sánchez, Antonio Toral</author><pubDate>Wed, 13 Mar 2024 17:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08693v1</guid></item><item><title>Linear attention is (maybe) all you need (to understand transformer optimization)</title><link>http://arxiv.org/abs/2310.01082v2</link><description>Transformer training is notoriously difficult, requiring a careful design ofoptimizers and use of various heuristics. We make progress towardsunderstanding the subtleties of training Transformers by carefully studying asimple yet canonical linearized shallow Transformer model. Specifically, wetrain linear Transformers to solve regression tasks, inspired by J.~von Oswaldet al.~(ICML 2023), and K.~Ahn et al.~(NeurIPS 2023). Most importantly, weobserve that our proposed linearized models can reproduce several prominentaspects of Transformer training dynamics. Consequently, the results obtained inthis paper suggest that a simple linearized Transformer model could actually bea valuable, realistic abstraction for understanding Transformer optimization.</description><author>Kwangjun Ahn, Xiang Cheng, Minhak Song, Chulhee Yun, Ali Jadbabaie, Suvrit Sra</author><pubDate>Wed, 13 Mar 2024 17:48:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01082v2</guid></item><item><title>AGI: Artificial General Intelligence for Education</title><link>http://arxiv.org/abs/2304.12479v5</link><description>Artificial general intelligence (AGI) has gained global recognition as afuture technology due to the emergence of breakthrough large language modelsand chatbots such as GPT-4 and ChatGPT, respectively. Compared to conventionalAI models, typically designed for a limited range of tasks, demand significantamounts of domain-specific data for training and may not always considerintricate interpersonal dynamics in education. AGI, driven by the recent largepre-trained models, represents a significant leap in the capability of machinesto perform tasks that require human-level intelligence, such as reasoning,problem-solving, decision-making, and even understanding human emotions andsocial interactions. This position paper reviews AGI's key concepts,capabilities, scope, and potential within future education, including achievingfuture educational goals, designing pedagogy and curriculum, and performingassessments. It highlights that AGI can significantly improve intelligenttutoring systems, educational assessment, and evaluation procedures. AGIsystems can adapt to individual student needs, offering tailored learningexperiences. They can also provide comprehensive feedback on studentperformance and dynamically adjust teaching methods based on student progress.The paper emphasizes that AGI's capabilities extend to understanding humanemotions and social interactions, which are critical in educational settings.The paper discusses that ethical issues in education with AGI include databias, fairness, and privacy and emphasizes the need for codes of conduct toensure responsible AGI use in academic settings like homework, teaching, andrecruitment. We also conclude that the development of AGI necessitatesinterdisciplinary collaborations between educators and AI engineers to advanceresearch and application efforts.</description><author>Ehsan Latif, Gengchen Mai, Matthew Nyaaba, Xuansheng Wu, Ninghao Liu, Guoyu Lu, Sheng Li, Tianming Liu, Xiaoming Zhai</author><pubDate>Wed, 13 Mar 2024 17:47:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12479v5</guid></item><item><title>Exploiting Structural Consistency of Chest Anatomy for Unsupervised Anomaly Detection in Radiography Images</title><link>http://arxiv.org/abs/2403.08689v1</link><description>Radiography imaging protocols focus on particular body regions, thereforeproducing images of great similarity and yielding recurrent anatomicalstructures across patients. Exploiting this structured information couldpotentially ease the detection of anomalies from radiography images. To thisend, we propose a Simple Space-Aware Memory Matrix for In-painting andDetecting anomalies from radiography images (abbreviated as SimSID). Weformulate anomaly detection as an image reconstruction task, consisting of aspace-aware memory matrix and an in-painting block in the feature space. Duringthe training, SimSID can taxonomize the ingrained anatomical structures intorecurrent visual patterns, and in the inference, it can identify anomalies(unseen/modified visual patterns) from the test image. Our SimSID surpasses thestate of the arts in unsupervised anomaly detection by +8.0%, +5.0%, and +9.9%AUC scores on ZhangLab, COVIDx, and CheXpert benchmark datasets, respectively.Code: https://github.com/MrGiovanni/SimSID</description><author>Tiange Xiang, Yixiao Zhang, Yongyi Lu, Alan Yuille, Chaoyi Zhang, Weidong Cai, Zongwei Zhou</author><pubDate>Wed, 13 Mar 2024 17:44:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08689v1</guid></item><item><title>Benchmarking Large Language Models on Answering and Explaining Challenging Medical Questions</title><link>http://arxiv.org/abs/2402.18060v3</link><description>LLMs have demonstrated impressive performance in answering medical questions,such as passing scores on medical licensing examinations. However, medicalboard exam questions or general clinical questions do not capture thecomplexity of realistic clinical cases. Moreover, the lack of referenceexplanations means we cannot easily evaluate the reasoning of model decisions,a crucial component of supporting doctors in making complex medical decisions.To address these challenges, we construct two new datasets: JAMA ClinicalChallenge and Medbullets. JAMA Clinical Challenge consists of questions basedon challenging clinical cases, while Medbullets comprises USMLE Step 2&amp;3 styleclinical questions. Both datasets are structured as multiple-choicequestion-answering tasks, where each question is accompanied by anexpert-written explanation. We evaluate four LLMs on the two datasets usingvarious prompts. Experiments demonstrate that our datasets are harder thanprevious benchmarks. The inconsistency between automatic and human evaluationsof model-generated explanations highlights the need to develop new metrics tosupport future research on explainable medical QA.</description><author>Hanjie Chen, Zhouxiang Fang, Yash Singla, Mark Dredze</author><pubDate>Wed, 13 Mar 2024 17:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18060v3</guid></item><item><title>Token Alignment via Character Matching for Subword Completion</title><link>http://arxiv.org/abs/2403.08688v1</link><description>Generative models, widely utilized in various applications, can oftenstruggle with prompts corresponding to partial tokens. This struggle stems fromtokenization, where partial tokens fall out of distribution during inference,leading to incorrect or nonsensical outputs. This paper examines a technique toalleviate the tokenization artifact on text completion in generative models,maintaining performance even in regular non-subword cases. The method, termedtoken alignment, involves backtracking to the last complete tokens and ensuringthe model's generation aligns with the prompt. This approach showcases markedimprovement across many partial token scenarios, including nuanced cases likespace-prefix and partial indentation, with only a minor time increase. Thetechnique and analysis detailed in this paper contribute to the continuousadvancement of generative models in handling partial inputs, bearing relevancefor applications like code completion and text autocompletion.</description><author>Ben Athiwaratkun, Shiqi Wang, Mingyue Shang, Yuchen Tian, Zijian Wang, Sujan Kumar Gonugondla, Sanjay Krishna Gouda, Rob Kwiatowski, Ramesh Nallapati, Bing Xiang</author><pubDate>Wed, 13 Mar 2024 17:44:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08688v1</guid></item><item><title>Digital Twin-assisted Reinforcement Learning for Resource-aware Microservice Offloading in Edge Computing</title><link>http://arxiv.org/abs/2403.08687v1</link><description>Collaborative edge computing (CEC) has emerged as a promising paradigm,enabling edge nodes to collaborate and execute microservices from end devices.Microservice offloading, a fundamentally important problem, decides when andwhere microservices are executed upon the arrival of services. However, thedynamic nature of the real-world CEC environment often leads to inefficientmicroservice offloading strategies, resulting in underutilized resources andnetwork congestion. To address this challenge, we formulate an online jointmicroservice offloading and bandwidth allocation problem, JMOBA, to minimizethe average completion time of services. In this paper, we introduce a novelmicroservice offloading algorithm, DTDRLMO, which leverages deep reinforcementlearning (DRL) and digital twin technology. Specifically, we employ digitaltwin techniques to predict and adapt to changing edge node loads and networkconditions of CEC in real-time. Furthermore, this approach enables thegeneration of an efficient offloading plan, selecting the most suitable edgenode for each microservice. Simulation results on real-world and syntheticdatasets demonstrate that DTDRLMO outperforms heuristic and learning-basedmethods in average service completion time.</description><author>Xiangchun Chen, Jiannong Cao, Zhixuan Liang, Yuvraj Sahni, Mingjin Zhang</author><pubDate>Wed, 13 Mar 2024 17:44:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08687v1</guid></item><item><title>TOOLVERIFIER: Generalization to New Tools via Self-Verification</title><link>http://arxiv.org/abs/2402.14158v2</link><description>Teaching language models to use tools is an important milestone towardsbuilding general assistants, but remains an open problem. While there has beensignificant progress on learning to use specific tools via fine-tuning,language models still struggle with learning how to robustly use new tools fromonly a few demonstrations. In this work we introduce a self-verification methodwhich distinguishes between close candidates by self-asking contrastivequestions during (1) tool selection; and (2) parameter generation. We constructsynthetic, high-quality, self-generated data for this goal using Llama-2 70B,which we intend to release publicly. Extensive experiments on 4 tasks from theToolBench benchmark, consisting of 17 unseen tools, demonstrate an averageimprovement of 22% over few-shot baselines, even in scenarios where thedistinctions between candidate tools are finely nuanced.</description><author>Dheeraj Mekala, Jason Weston, Jack Lanchantin, Roberta Raileanu, Maria Lomeli, Jingbo Shang, Jane Dwivedi-Yu</author><pubDate>Wed, 13 Mar 2024 17:38:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14158v2</guid></item><item><title>OneVOS: Unifying Video Object Segmentation with All-in-One Transformer Framework</title><link>http://arxiv.org/abs/2403.08682v1</link><description>Contemporary Video Object Segmentation (VOS) approaches typically consiststages of feature extraction, matching, memory management, and multiple objectsaggregation. Recent advanced models either employ a discrete modeling for thesecomponents in a sequential manner, or optimize a combined pipeline throughsubstructure aggregation. However, these existing explicit staged approachesprevent the VOS framework from being optimized as a unified whole, leading tothe limited capacity and suboptimal performance in tackling complex videos. Inthis paper, we propose OneVOS, a novel framework that unifies the corecomponents of VOS with All-in-One Transformer. Specifically, to unify allaforementioned modules into a vision transformer, we model all the features offrames, masks and memory for multiple objects as transformer tokens, andintegrally accomplish feature extraction, matching and memory management ofmultiple objects through the flexible attention mechanism. Furthermore, aUnidirectional Hybrid Attention is proposed through a double decoupling of theoriginal attention operation, to rectify semantic errors and ambiguities ofstored tokens in OneVOS framework. Finally, to alleviate the storage burden andexpedite inference, we propose the Dynamic Token Selector, which unveils theworking mechanism of OneVOS and naturally leads to a more efficient version ofOneVOS. Extensive experiments demonstrate the superiority of OneVOS, achievingstate-of-the-art performance across 7 datasets, particularly excelling incomplex LVOS and MOSE datasets with 70.1% and 66.4% $J \&amp; F$ scores, surpassingprevious state-of-the-art methods by 4.2% and 7.0%, respectively. And our codewill be available for reproducibility and further research.</description><author>Wanyun Li, Pinxue Guo, Xinyu Zhou, Lingyi Hong, Yangji He, Xiangyu Zheng, Wei Zhang, Wenqiang Zhang</author><pubDate>Wed, 13 Mar 2024 17:38:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08682v1</guid></item><item><title>SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution</title><link>http://arxiv.org/abs/2312.11598v2</link><description>Diffusion models have demonstrated strong potential for robotic trajectoryplanning. However, generating coherent trajectories from high-levelinstructions remains challenging, especially for long-range composition tasksrequiring multiple sequential skills. We propose SkillDiffuser, an end-to-endhierarchical planning framework integrating interpretable skill learning withconditional diffusion planning to address this problem. At the higher level,the skill abstraction module learns discrete, human-understandable skillrepresentations from visual observations and language instructions. Theselearned skill embeddings are then used to condition the diffusion model togenerate customized latent trajectories aligned with the skills. This allowsgenerating diverse state trajectories that adhere to the learnable skills. Byintegrating skill learning with conditional trajectory generation,SkillDiffuser produces coherent behavior following abstract instructions acrossdiverse tasks. Experiments on multi-task robotic manipulation benchmarks likeMeta-World and LOReL demonstrate state-of-the-art performance andhuman-interpretable skill representations from SkillDiffuser. Morevisualization results and information could be found on our website.</description><author>Zhixuan Liang, Yao Mu, Hengbo Ma, Masayoshi Tomizuka, Mingyu Ding, Ping Luo</author><pubDate>Wed, 13 Mar 2024 17:29:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11598v2</guid></item><item><title>When can we Approximate Wide Contrastive Models with Neural Tangent Kernels and Principal Component Analysis?</title><link>http://arxiv.org/abs/2403.08673v1</link><description>Contrastive learning is a paradigm for learning representations fromunlabelled data that has been highly successful for image and text data.Several recent works have examined contrastive losses to claim that contrastivemodels effectively learn spectral embeddings, while few works show relationsbetween (wide) contrastive models and kernel principal component analysis(PCA). However, it is not known if trained contrastive models indeed correspondto kernel methods or PCA. In this work, we analyze the training dynamics oftwo-layer contrastive models, with non-linear activation, and answer when thesemodels are close to PCA or kernel methods. It is well known in the supervisedsetting that neural networks are equivalent to neural tangent kernel (NTK)machines, and that the NTK of infinitely wide networks remains constant duringtraining. We provide the first convergence results of NTK for contrastivelosses, and present a nuanced picture: NTK of wide networks remains almostconstant for cosine similarity based contrastive losses, but not for lossesbased on dot product similarity. We further study the training dynamics ofcontrastive models with orthogonality constraints on output layer, which isimplicitly assumed in works relating contrastive learning to spectralembedding. Our deviation bounds suggest that representations learned bycontrastive models are close to the principal components of a certain matrixcomputed from random features. We empirically show that our theoretical resultspossibly hold beyond two-layer networks.</description><author>Gautham Govind Anil, Pascal Esser, Debarghya Ghoshdastidar</author><pubDate>Wed, 13 Mar 2024 17:25:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08673v1</guid></item><item><title>Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records</title><link>http://arxiv.org/abs/2403.08664v1</link><description>The challenge of accessing historical patient data for clinical research,while adhering to privacy regulations, is a significant obstacle in medicalscience. An innovative approach to circumvent this issue involves utilisingsynthetic medical records that mirror real patient data without compromisingindividual privacy. The creation of these synthetic datasets, particularlywithout using actual patient data to train Large Language Models (LLMs),presents a novel solution as gaining access to sensitive patient information totrain models is also a challenge. This study assesses the capability of theLlama 2 LLM to create synthetic medical records that accurately reflect realpatient information, employing zero-shot and few-shot prompting strategies forcomparison against fine-tuned methodologies that do require sensitive patientdata during training. We focus on generating synthetic narratives for theHistory of Present Illness section, utilising data from the MIMIC-IV datasetfor comparison. In this work introduce a novel prompting technique thatleverages a chain-of-thought approach, enhancing the model's ability togenerate more accurate and contextually relevant medical narratives withoutprior fine-tuning. Our findings suggest that this chain-of-thought promptedapproach allows the zero-shot model to achieve results on par with those offine-tuned models, based on Rouge metrics evaluation.</description><author>Erlend Frayling, Jake Lever, Graham McDonald</author><pubDate>Wed, 13 Mar 2024 17:17:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08664v1</guid></item><item><title>Self-Supervised Learning for Covariance Estimation</title><link>http://arxiv.org/abs/2403.08662v1</link><description>We consider the use of deep learning for covariance estimation. We propose toglobally learn a neural network that will then be applied locally at inferencetime. Leveraging recent advancements in self-supervised foundational models, wetrain the network without any labeling by simply masking different samples andlearning to predict their covariance given their surrounding neighbors. Thearchitecture is based on the popular attention mechanism. Its main advantageover classical methods is the automatic exploitation of global characteristicswithout any distributional assumptions or regularization. It can be pre-trainedas a foundation model and then be repurposed for various downstream tasks,e.g., adaptive target detection in radar or hyperspectral imagery.</description><author>Tzvi Diskin, Ami Wiesel</author><pubDate>Wed, 13 Mar 2024 17:16:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08662v1</guid></item><item><title>Tight Group-Level DP Guarantees for DP-SGD with Sampling via Mixture of Gaussians Mechanisms</title><link>http://arxiv.org/abs/2401.10294v2</link><description>We give a procedure for computing group-level $(\epsilon, \delta)$-DPguarantees for DP-SGD, when using Poisson sampling or fixed batch sizesampling. Up to discretization errors in the implementation, the DP guaranteescomputed by this procedure are tight (assuming we release every intermediateiterate).</description><author>Arun Ganesh</author><pubDate>Wed, 13 Mar 2024 17:08:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10294v2</guid></item><item><title>Extracting Explanations, Justification, and Uncertainty from Black-Box Deep Neural Networks</title><link>http://arxiv.org/abs/2403.08652v1</link><description>Deep Neural Networks (DNNs) do not inherently compute or exhibitempirically-justified task confidence. In mission critical applications, it isimportant to both understand associated DNN reasoning and its supportingevidence. In this paper, we propose a novel Bayesian approach to extractexplanations, justifications, and uncertainty estimates from DNNs. Our approachis efficient both in terms of memory and computation, and can be applied to anyblack box DNN without any retraining, including applications to anomalydetection and out-of-distribution detection tasks. We validate our approach onthe CIFAR-10 dataset, and show that it can significantly improve theinterpretability and reliability of DNNs.</description><author>Paul Ardis, Arjuna Flenner</author><pubDate>Wed, 13 Mar 2024 17:06:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08652v1</guid></item><item><title>HAIFIT: Human-Centered AI for Fashion Image Translation</title><link>http://arxiv.org/abs/2403.08651v1</link><description>In the realm of fashion design, sketches serve as the canvas for expressingan artist's distinctive drawing style and creative vision, capturing intricatedetails like stroke variations and texture nuances. The advent ofsketch-to-image cross-modal translation technology has notably aided designers.However, existing methods often compromise these sketch details during imagegeneration, resulting in images that deviate from the designer's intendedconcept. This limitation hampers the ability to offer designers a precisepreview of the final output. To overcome this challenge, we introduce HAIFIT, anovel approach that transforms sketches into high-fidelity, lifelike clothingimages by integrating multi-scale features and capturing extensive feature mapdependencies from diverse perspectives. Through extensive qualitative andquantitative evaluations conducted on our self-collected dataset, our methoddemonstrates superior performance compared to existing methods in generatingphotorealistic clothing images. Our method excels in preserving the distinctivestyle and intricate details essential for fashion design applications.</description><author>Jianan Jiang, Xinglin Li, Weiren Yu, Di Wu</author><pubDate>Wed, 13 Mar 2024 17:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08651v1</guid></item><item><title>Data Augmentation in Human-Centric Vision</title><link>http://arxiv.org/abs/2403.08650v1</link><description>This survey presents a comprehensive analysis of data augmentation techniquesin human-centric vision tasks, a first of its kind in the field. It delves intoa wide range of research areas including person ReID, human parsing, human poseestimation, and pedestrian detection, addressing the significant challengesposed by overfitting and limited training data in these domains. Our workcategorizes data augmentation methods into two main types: data generation anddata perturbation. Data generation covers techniques like graphic engine-basedgeneration, generative model-based generation, and data recombination, whiledata perturbation is divided into image-level and human-level perturbations.Each method is tailored to the unique requirements of human-centric tasks, withsome applicable across multiple areas. Our contributions include an extensiveliterature review, providing deep insights into the influence of theseaugmentation techniques in human-centric vision and highlighting the nuances ofeach method. We also discuss open issues and future directions, such as theintegration of advanced generative models like Latent Diffusion Models, forcreating more realistic and diverse training data. This survey not onlyencapsulates the current state of data augmentation in human-centric vision butalso charts a course for future research, aiming to develop more robust,accurate, and efficient human-centric vision systems.</description><author>Wentao Jiang, Yige Zhang, Shaozhong Zheng, Si Liu, Shuicheng Yan</author><pubDate>Wed, 13 Mar 2024 17:05:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08650v1</guid></item><item><title>A Causal Inspired Early-Branching Structure for Domain Generalization</title><link>http://arxiv.org/abs/2403.08649v1</link><description>Learning domain-invariant semantic representations is crucial for achievingdomain generalization (DG), where a model is required to perform well on unseentarget domains. One critical challenge is that standard training often resultsin entangled semantic and domain-specific features. Previous works suggestformulating the problem from a causal perspective and solving the entanglementproblem by enforcing marginal independence between the causal (\ie semantic)and non-causal (\ie domain-specific) features. Despite its simplicity, thebasic marginal independent-based idea alone may be insufficient to identify thecausal feature. By d-separation, we observe that the causal feature can befurther characterized by being independent of the domain conditioned on theobject, and we propose the following two strategies as complements for thebasic framework. First, the observation implicitly implies that for the same object, thecausal feature should not be associated with the non-causal feature, revealingthat the common practice of obtaining the two features with a shared basefeature extractor and two lightweight prediction heads might be inappropriate.To meet the constraint, we propose a simple early-branching structure, wherethe causal and non-causal feature obtaining branches share the first few blockswhile diverging thereafter, for better structure design; Second, theobservation implies that the causal feature remains invariant across differentdomains for the same object. To this end, we suggest that augmentation shouldbe incorporated into the framework to better characterize the causal feature,and we further suggest an effective random domain sampling scheme to fulfillthe task. Theoretical and experimental results show that the two strategies arebeneficial for the basic marginal independent-based framework. Code isavailable at \url{https://github.com/liangchen527/CausEB}.</description><author>Liang Chen, Yong Zhang, Yibing Song, Zhen Zhang, Lingqiao Liu</author><pubDate>Wed, 13 Mar 2024 17:04:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08649v1</guid></item><item><title>Referential communication in heterogeneous communities of pre-trained visual deep networks</title><link>http://arxiv.org/abs/2302.08913v4</link><description>As large pre-trained image-processing neural networks are being embedded inautonomous agents such as self-driving cars or robots, the question arises ofhow such systems can communicate with each other about the surrounding world,despite their different architectures and training regimes. As a first step inthis direction, we systematically explore the task of \textit{referentialcommunication} in a community of heterogeneous state-of-the-art pre-trainedvisual networks, showing that they can develop, in a self-supervised way, ashared protocol to refer to a target object among a set of candidates. Thisshared protocol can also be used, to some extent, to communicate aboutpreviously unseen object categories of different granularity. Moreover, avisual network that was not initially part of an existing community can learnthe community's protocol with remarkable ease. Finally, we study, bothqualitatively and quantitatively, the properties of the emergent protocol,providing some evidence that it is capturing high-level semantic features ofobjects.</description><author>Matéo Mahaut, Francesca Franzon, Roberto Dessì, Marco Baroni</author><pubDate>Wed, 13 Mar 2024 17:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08913v4</guid></item><item><title>MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining</title><link>http://arxiv.org/abs/2403.04780v2</link><description>Graphs with abundant attributes are essential in modeling interconnectedentities and improving predictions in various real-world applications.Traditional Graph Neural Networks (GNNs), which are commonly used for modelingattributed graphs, need to be re-trained every time when applied to differentgraph tasks and datasets. Although the emergence of Large Language Models(LLMs) has introduced a new paradigm in natural language processing, thegenerative potential of LLMs in graph mining remains largely under-explored. Tothis end, we propose a novel framework MuseGraph, which seamlessly integratesthe strengths of GNNs and LLMs and facilitates a more effective and genericapproach for graph mining across different tasks and datasets. Specifically, wefirst introduce a compact graph description via the proposed adaptive inputgeneration to encapsulate key information from the graph under the constraintsof language token limitations. Then, we propose a diverse instructiongeneration mechanism, which distills the reasoning capabilities from LLMs(e.g., GPT-4) to create task-specific Chain-of-Thought-based instructionpackages for different graph tasks. Finally, we propose a graph-awareinstruction tuning with a dynamic instruction package allocation strategyacross tasks and datasets, ensuring the effectiveness and generalization of thetraining process. Our experimental results demonstrate significant improvementsin different graph tasks, showcasing the potential of our MuseGraph inenhancing the accuracy of graph-oriented downstream tasks while keeping thegeneration powers of LLMs.</description><author>Yanchao Tan, Hang Lv, Xinyi Huang, Jiawei Zhang, Shiping Wang, Carl Yang</author><pubDate>Wed, 13 Mar 2024 16:52:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04780v2</guid></item><item><title>Refractive COLMAP: Refractive Structure-from-Motion Revisited</title><link>http://arxiv.org/abs/2403.08640v1</link><description>In this paper, we present a complete refractive Structure-from-Motion (RSfM)framework for underwater 3D reconstruction using refractive camera setups (forboth, flat- and dome-port underwater housings). Despite notable achievements inrefractive multi-view geometry over the past decade, a robust, complete andpublicly available solution for such tasks is not available at present, andoften practical applications have to resort to approximating refraction effectsby the intrinsic (distortion) parameters of a pinhole camera model. To fillthis gap, we have integrated refraction considerations throughout the entireSfM process within the state-of-the-art, open-source SfM framework COLMAP.Numerical simulations and reconstruction results on synthetically generated butphoto-realistic images with ground truth validate that enabling refraction doesnot compromise accuracy or robustness as compared to in-air reconstructions.Finally, we demonstrate the capability of our approach for large-scalerefractive scenarios using a dataset consisting of nearly 6000 images. Theimplementation is released as open-source at:https://cau-git.rz.uni-kiel.de/inf-ag-koeser/colmap_underwater.</description><author>Mengkun She, Felix Seegräber, David Nakath, Kevin Köser</author><pubDate>Wed, 13 Mar 2024 16:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08640v1</guid></item><item><title>HIMap: HybrId Representation Learning for End-to-end Vectorized HD Map Construction</title><link>http://arxiv.org/abs/2403.08639v1</link><description>Vectorized High-Definition (HD) map construction requires predictions of thecategory and point coordinates of map elements (e.g. road boundary, lanedivider, pedestrian crossing, etc.). State-of-the-art methods are mainly basedon point-level representation learning for regressing accurate pointcoordinates. However, this pipeline has limitations in obtaining element-levelinformation and handling element-level failures, e.g. erroneous element shapeor entanglement between elements. To tackle the above issues, we propose asimple yet effective HybrId framework named HIMap to sufficiently learn andinteract both point-level and element-level information. Concretely, weintroduce a hybrid representation called HIQuery to represent all map elements,and propose a point-element interactor to interactively extract and encode thehybrid information of elements, e.g. point position and element shape, into theHIQuery. Additionally, we present a point-element consistency constraint toenhance the consistency between the point-level and element-level information.Finally, the output point-element integrated HIQuery can be directly convertedinto map elements' class, point coordinates, and mask. We conduct extensiveexperiments and consistently outperform previous methods on both nuScenes andArgoverse2 datasets. Notably, our method achieves $77.8$ mAP on the nuScenesdataset, remarkably superior to previous SOTAs by $8.3$ mAP at least.</description><author>Yi Zhou, Hui Zhang, Jiaqian Yu, Yifan Yang, Sangil Jung, Seung-In Park, ByungIn Yoo</author><pubDate>Wed, 13 Mar 2024 16:51:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08639v1</guid></item><item><title>Disparate Effect Of Missing Mediators On Transportability of Causal Effects</title><link>http://arxiv.org/abs/2403.08638v1</link><description>Transported mediation effects provide an avenue to understand how upstreaminterventions (such as improved neighborhood conditions like green spaces)would work differently when applied to different populations as a result offactors that mediate the effects. However, when mediators are missing in thepopulation where the effect is to be transported, these estimates could bebiased. We study this issue of missing mediators, motivated by challenges inpublic health, wherein mediators can be missing, not at random. We propose asensitivity analysis framework that quantifies the impact of missing mediatordata on transported mediation effects. This framework enables us to identifythe settings under which the conditional transported mediation effect isrendered insignificant for the subgroup with missing mediator data.Specifically, we provide the bounds on the transported mediation effect as afunction of missingness. We then apply the framework to longitudinal data fromthe Moving to Opportunity Study, a large-scale housing voucher experiment, toquantify the effect of missing mediators on transport effect estimates ofvoucher receipt, an upstream intervention on living location, in childhood onsubsequent risk of mental health or substance use disorder mediated throughparental health across sites. Our findings provide a tangible understanding ofhow much missing data can be withstood for unbiased effect estimates.</description><author>Vishwali Mhasawade, Rumi Chunara</author><pubDate>Wed, 13 Mar 2024 16:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08638v1</guid></item><item><title>Human Alignment of Large Language Models through Online Preference Optimisation</title><link>http://arxiv.org/abs/2403.08635v1</link><description>Ensuring alignment of language models' outputs with human preferences iscritical to guarantee a useful, safe, and pleasant user experience. Thus, humanalignment has been extensively studied recently and several methods such asReinforcement Learning from Human Feedback (RLHF), Direct Policy Optimisation(DPO) and Sequence Likelihood Calibration (SLiC) have emerged. In this paper,our contribution is two-fold. First, we show the equivalence between two recentalignment methods, namely Identity Policy Optimisation (IPO) and Nash MirrorDescent (Nash-MD). Second, we introduce a generalisation of IPO, named IPO-MD,that leverages the regularised sampling approach proposed by Nash-MD. This equivalence may seem surprising at first sight, since IPO is an offlinemethod whereas Nash-MD is an online method using a preference model. However,this equivalence can be proven when we consider the online version of IPO, thatis when both generations are sampled by the online policy and annotated by atrained preference model. Optimising the IPO loss with such a stream of databecomes then equivalent to finding the Nash equilibrium of the preference modelthrough self-play. Building on this equivalence, we introduce the IPO-MDalgorithm that generates data with a mixture policy (between the online andreference policy) similarly as the general Nash-MD algorithm. We compareonline-IPO and IPO-MD to different online versions of existing losses onpreference data such as DPO and SLiC on a summarisation task.</description><author>Daniele Calandriello, Daniel Guo, Remi Munos, Mark Rowland, Yunhao Tang, Bernardo Avila Pires, Pierre Harvey Richemond, Charline Le Lan, Michal Valko, Tianqi Liu, Rishabh Joshi, Zeyu Zheng, Bilal Piot</author><pubDate>Wed, 13 Mar 2024 16:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08635v1</guid></item><item><title>A Decade's Battle on Dataset Bias: Are We There Yet?</title><link>http://arxiv.org/abs/2403.08632v1</link><description>We revisit the "dataset classification" experiment suggested by Torralba andEfros a decade ago, in the new era with large-scale, diverse, and hopefullyless biased datasets as well as more capable neural network architectures.Surprisingly, we observe that modern neural networks can achieve excellentaccuracy in classifying which dataset an image is from: e.g., we report 84.7%accuracy on held-out validation data for the three-way classification problemconsisting of the YFCC, CC, and DataComp datasets. Our further experiments showthat such a dataset classifier could learn semantic features that aregeneralizable and transferable, which cannot be simply explained bymemorization. We hope our discovery will inspire the community to rethink theissue involving dataset bias and model capabilities.</description><author>Zhuang Liu, Kaiming He</author><pubDate>Wed, 13 Mar 2024 16:46:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08632v1</guid></item><item><title>Leveraging Non-Decimated Wavelet Packet Features and Transformer Models for Time Series Forecasting</title><link>http://arxiv.org/abs/2403.08630v1</link><description>This article combines wavelet analysis techniques with machine learningmethods for univariate time series forecasting, focusing on three maincontributions. Firstly, we consider the use of Daubechies wavelets withdifferent numbers of vanishing moments as input features to both non-temporaland temporal forecasting methods, by selecting these numbers during thecross-validation phase. Secondly, we compare the use of both the non-decimatedwavelet transform and the non-decimated wavelet packet transform for computingthese features, the latter providing a much larger set of potentially usefulcoefficient vectors. The wavelet coefficients are computed using a shiftedversion of the typical pyramidal algorithm to ensure no leakage of futureinformation into these inputs. Thirdly, we evaluate the use of these waveletfeatures on a significantly wider set of forecasting methods than previousstudies, including both temporal and non-temporal models, and both statisticaland deep learning-based methods. The latter include state-of-the-arttransformer-based neural network architectures. Our experiments suggestsignificant benefit in replacing higher-order lagged features with waveletfeatures across all examined non-temporal methods for one-step-forwardforecasting, and modest benefit when used as inputs for temporal deeplearning-based models for long-horizon forecasting.</description><author>Guy P Nason, James L. Wei</author><pubDate>Wed, 13 Mar 2024 16:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08630v1</guid></item><item><title>Scaling Up Dynamic Human-Scene Interaction Modeling</title><link>http://arxiv.org/abs/2403.08629v1</link><description>Confronting the challenges of data scarcity and advanced motion synthesis inhuman-scene interaction modeling, we introduce the TRUMANS dataset alongside anovel HSI motion synthesis method. TRUMANS stands as the most comprehensivemotion-captured HSI dataset currently available, encompassing over 15 hours ofhuman interactions across 100 indoor scenes. It intricately captures whole-bodyhuman motions and part-level object dynamics, focusing on the realism ofcontact. This dataset is further scaled up by transforming physicalenvironments into exact virtual models and applying extensive augmentations toappearance and motion for both humans and objects while maintaining interactionfidelity. Utilizing TRUMANS, we devise a diffusion-based autoregressive modelthat efficiently generates HSI sequences of any length, taking into accountboth scene context and intended actions. In experiments, our approach showsremarkable zero-shot generalizability on a range of 3D scene datasets (e.g.,PROX, Replica, ScanNet, ScanNet++), producing motions that closely mimicoriginal motion-captured sequences, as confirmed by quantitative experimentsand human studies.</description><author>Nan Jiang, Zhiyuan Zhang, Hongjie Li, Xiaoxuan Ma, Zan Wang, Yixin Chen, Tengyu Liu, Yixin Zhu, Siyuan Huang</author><pubDate>Wed, 13 Mar 2024 16:45:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08629v1</guid></item><item><title>Multifidelity linear regression for scientific machine learning from scarce data</title><link>http://arxiv.org/abs/2403.08627v1</link><description>Machine learning (ML) methods, which fit to data the parameters of a givenparameterized model class, have garnered significant interest as potentialmethods for learning surrogate models for complex engineering systems for whichtraditional simulation is expensive. However, in many scientific andengineering settings, generating high-fidelity data on which to train ML modelsis expensive, and the available budget for generating training data is limited.ML models trained on the resulting scarce high-fidelity data have high varianceand are sensitive to vagaries of the training data set. We propose a newmultifidelity training approach for scientific machine learning that exploitsthe scientific context where data of varying fidelities and costs areavailable; for example high-fidelity data may be generated by an expensivefully resolved physics simulation whereas lower-fidelity data may arise from acheaper model based on simplifying assumptions. We use the multifidelity datato define new multifidelity Monte Carlo estimators for the unknown parametersof linear regression models, and provide theoretical analyses that guaranteethe approach's accuracy and improved robustness to small training budgets.Numerical results verify the theoretical analysis and demonstrate thatmultifidelity learned models trained on scarce high-fidelity data andadditional low-fidelity data achieve order-of-magnitude lower model variancethan standard models trained on only high-fidelity data of comparable cost.This illustrates that in the scarce data regime, our multifidelity trainingstrategy yields models with lower expected error than standard trainingapproaches.</description><author>Elizabeth Qian, Anirban Chaudhuri, Dayoung Kang, Vignesh Sella</author><pubDate>Wed, 13 Mar 2024 16:40:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08627v1</guid></item><item><title>Verifix: Post-Training Correction to Improve Label Noise Robustness with Verified Samples</title><link>http://arxiv.org/abs/2403.08618v1</link><description>Label corruption, where training samples have incorrect labels, cansignificantly degrade the performance of machine learning models. Thiscorruption often arises from non-expert labeling or adversarial attacks.Acquiring large, perfectly labeled datasets is costly, and retraining largemodels from scratch when a clean dataset becomes available is computationallyexpensive. To address this challenge, we propose Post-Training Correction, anew paradigm that adjusts model parameters after initial training to mitigatelabel noise, eliminating the need for retraining. We introduce Verifix, a novelSingular Value Decomposition (SVD) based algorithm that leverages a small,verified dataset to correct the model weights using a single update. Verifixuses SVD to estimate a Clean Activation Space and then projects the model'sweights onto this space to suppress activations corresponding to corrupteddata. We demonstrate Verifix's effectiveness on both synthetic and real-worldlabel noise. Experiments on the CIFAR dataset with 25% synthetic corruptionshow 7.36% generalization improvements on average. Additionally, we observegeneralization improvements of up to 2.63% on naturally corrupted datasets likeWebVision1.0 and Clothing1M.</description><author>Sangamesh Kodge, Deepak Ravikumar, Gobinda Saha, Kaushik Roy</author><pubDate>Wed, 13 Mar 2024 16:32:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08618v1</guid></item><item><title>Continual Adversarial Defense</title><link>http://arxiv.org/abs/2312.09481v2</link><description>In response to the rapidly evolving nature of adversarial attacks againstvisual classifiers on a monthly basis, numerous defenses have been proposed togeneralize against as many known attacks as possible. However, designing adefense method that generalizes to all types of attacks is not realisticbecause the environment in which defense systems operate is dynamic andcomprises various unique attacks that emerge as time goes on. The defensesystem must gather online few-shot defense feedback to promptly enhance itself,leveraging efficient memory utilization. Therefore, we propose the firstcontinual adversarial defense (CAD) framework that adapts to any attacks in adynamic scenario, where various attacks emerge stage by stage. In practice, CADis modeled under four principles: (1) continual adaptation to new attackswithout catastrophic forgetting, (2) few-shot adaptation, (3) memory-efficientadaptation, and (4) high accuracy on both clean and adversarial images. Weexplore and integrate cutting-edge continual learning, few-shot learning, andensemble learning techniques to qualify the principles. Experiments conductedon CIFAR-10 and ImageNet-100 validate the effectiveness of our approach againstmultiple stages of modern adversarial attacks and demonstrate significantimprovements over numerous baseline methods. In particular, CAD is capable ofquickly adapting with minimal feedback and a low cost of defense failure, whilemaintaining good performance against previous attacks. Our research sheds lighton a brand-new paradigm for continual defense adaptation against dynamic andevolving attacks.</description><author>Qian Wang, Yaoyao Liu, Hefei Ling, Yingwei Li, Qihao Liu, Ping Li, Jiazhong Chen, Alan Yuille, Ning Yu</author><pubDate>Wed, 13 Mar 2024 16:24:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09481v2</guid></item><item><title>Link Prediction for Social Networks using Representation Learning and Heuristic-based Features</title><link>http://arxiv.org/abs/2403.08613v1</link><description>The exponential growth in scale and relevance of social networks enable themto provide expansive insights. Predicting missing links in social networksefficiently can help in various modern-day business applications ranging fromgenerating recommendations to influence analysis. Several categories ofsolutions exist for the same. Here, we explore various feature extractiontechniques to generate representations of nodes and edges in a social networkthat allow us to predict missing links. We compare the results of using tenfeature extraction techniques categorized across Structural embeddings,Neighborhood-based embeddings, Graph Neural Networks, and Graph Heuristics,followed by modeling with ensemble classifiers and custom Neural Networks.Further, we propose combining heuristic-based features and learnedrepresentations that demonstrate improved performance for the link predictiontask on social network datasets. Using this method to generate accuraterecommendations for many applications is a matter of further study that appearsvery promising. The code for all the experiments has been made public.</description><author>Samarth Khanna, Sree Bhattacharyya, Sudipto Ghosh, Kushagra Agarwal, Asit Kumar Das</author><pubDate>Wed, 13 Mar 2024 16:23:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08613v1</guid></item><item><title>On the Convergence of Locally Adaptive and Scalable Diffusion-Based Sampling Methods for Deep Bayesian Neural Network Posteriors</title><link>http://arxiv.org/abs/2403.08609v1</link><description>Achieving robust uncertainty quantification for deep neural networksrepresents an important requirement in many real-world applications of deeplearning such as medical imaging where it is necessary to assess thereliability of a neural network's prediction. Bayesian neural networks are apromising approach for modeling uncertainties in deep neural networks.Unfortunately, generating samples from the posterior distribution of neuralnetworks is a major challenge. One significant advance in that direction wouldbe the incorporation of adaptive step sizes, similar to modern neural networkoptimizers, into Monte Carlo Markov chain sampling algorithms withoutsignificantly increasing computational demand. Over the past years, severalpapers have introduced sampling algorithms with claims that they achieve thisproperty. However, do they indeed converge to the correct distribution? In thispaper, we demonstrate that these methods can have a substantial bias in thedistribution they sample, even in the limit of vanishing step sizes and at fullbatch size.</description><author>Tim Rensmeyer, Oliver Niggemann</author><pubDate>Wed, 13 Mar 2024 16:21:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08609v1</guid></item><item><title>MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models</title><link>http://arxiv.org/abs/2403.08607v1</link><description>Large Language Models (LLMs) have shown impressive capabilities in generatinghuman-like responses. However, their lack of domain-specific knowledge limitstheir applicability in healthcare settings, where contextual and comprehensiveresponses are vital. To address this challenge and enable the generation ofpatient-centric responses that are contextually relevant and comprehensive, wepropose MedInsight:a novel retrieval augmented framework that augments LLMinputs (prompts) with relevant background information from multiple sources.MedInsight extracts pertinent details from the patient's medical record orconsultation transcript. It then integrates information from authoritativemedical textbooks and curated web resources based on the patient's healthhistory and condition. By constructing an augmented context combining thepatient's record with relevant medical knowledge, MedInsight generatesenriched, patient-specific responses tailored for healthcare applications suchas diagnosis, treatment recommendations, or patient education. Experiments onthe MTSamples dataset validate MedInsight's effectiveness in generatingcontextually appropriate medical responses. Quantitative evaluation using theRagas metric and TruLens for answer similarity and answer correctnessdemonstrates the model's efficacy. Furthermore, human evaluation studiesinvolving Subject Matter Expert (SMEs) confirm MedInsight's utility, withmoderate inter-rater agreement on the relevance and correctness of thegenerated responses.</description><author>Subash Neupane, Shaswata Mitra, Sudip Mittal, Noorbakhsh Amiri Golilarz, Shahram Rahimi, Amin Amirlatifi</author><pubDate>Wed, 13 Mar 2024 16:20:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08607v1</guid></item><item><title>DevBench: A Comprehensive Benchmark for Software Development</title><link>http://arxiv.org/abs/2403.08604v1</link><description>Recent advancements in large language models (LLMs) have significantlyenhanced their coding capabilities. However, existing benchmarks predominantlyfocused on simplified or isolated aspects of programming, such as single-filecode generation or repository issue debugging, falling short of measuring thefull spectrum of challenges raised by real-world programming activities. Tothis end, we propose DevBench, a comprehensive benchmark that evaluates LLMsacross various stages of the software development lifecycle, including softwaredesign, environment setup, implementation, acceptance testing, and unittesting. DevBench features a wide range of programming languages and domains,high-quality data collection, and carefully designed and verified metrics foreach task. Empirical studies show that current LLMs, including GPT-4-Turbo,fail to solve the challenges presented within DevBench. Analyses reveal thatmodels struggle with understanding the complex structures in the repository,managing the compilation process, and grasping advanced programming concepts.Our findings offer actionable insights for the future development of LLMstoward real-world programming applications. Our benchmark is available athttps://github.com/open-compass/DevBench</description><author>Bowen Li, Wenhan Wu, Ziwei Tang, Lin Shi, John Yang, Jinyang Li, Shunyu Yao, Chen Qian, Binyuan Hui, Qicheng Zhang, Zhiyin Yu, He Du, Ping Yang, Dahua Lin, Chao Peng, Kai Chen</author><pubDate>Wed, 13 Mar 2024 16:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08604v1</guid></item><item><title>In-Context Learning Learns Label Relationships but Is Not Conventional Learning</title><link>http://arxiv.org/abs/2307.12375v4</link><description>The predictions of Large Language Models (LLMs) on downstream tasks oftenimprove significantly when including examples of the input--label relationshipin the context. However, there is currently no consensus about how thisin-context learning (ICL) ability of LLMs works. For example, while Xie et al.(2021) liken ICL to a general-purpose learning algorithm, Min et al. (2022)argue ICL does not even learn label relationships from in-context examples. Inthis paper, we provide novel insights into how ICL leverages label information,revealing both capabilities and limitations. To ensure we obtain acomprehensive picture of ICL behavior, we study probabilistic aspects of ICLpredictions and thoroughly examine the dynamics of ICL as more examples areprovided. Our experiments show that ICL predictions almost always depend onin-context labels and that ICL can learn truly novel tasks in-context. However,we also find that ICL struggles to fully overcome prediction preferencesacquired from pre-training data and, further, that ICL does not consider allin-context information equally.</description><author>Jannik Kossen, Yarin Gal, Tom Rainforth</author><pubDate>Wed, 13 Mar 2024 16:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12375v4</guid></item><item><title>Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments</title><link>http://arxiv.org/abs/2403.08593v1</link><description>Large Language Models (LLMs) have shown potential in reasoning overstructured environments, e.g., knowledge graph and table. Such tasks typicallyrequire multi-hop reasoning, i.e., match natural language utterance withinstances in the environment. Previous methods leverage LLMs to incrementallybuild a reasoning path, where the LLMs either invoke tools or pick up schemasby step-by-step interacting with the environment. We proposeReasoning-Path-Editing (Readi), a novel framework where LLMs can efficientlyand faithfully reason over structured environments. In Readi, LLMs initiallygenerate a reasoning path given a query, and edit the path only when necessary.We instantiate the path on structured environments and provide feedback to editthe path if anything goes wrong. Experimental results on three KGQA datasetsand two TableQA datasets show the effectiveness of Readi, significantlysurpassing all LLM-based methods (by 9.1% on WebQSP, 12.4% on MQA-3H and 10.9%on WTQ), comparable with state-of-the-art fine-tuned methods (67% on CWQ and74.7% on WebQSP) and substantially boosting the vanilla LLMs (by 14.9% on CWQ).Our code will be available upon publication.</description><author>Sitao Cheng, Ziyuan Zhuang, Yong Xu, Fangkai Yang, Chaoyun Zhang, Xiaoting Qin, Xiang Huang, Ling Chen, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang</author><pubDate>Wed, 13 Mar 2024 15:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08593v1</guid></item><item><title>Data-Efficient Sleep Staging with Synthetic Time Series Pretraining</title><link>http://arxiv.org/abs/2403.08592v1</link><description>Analyzing electroencephalographic (EEG) time series can be challenging,especially with deep neural networks, due to the large variability among humansubjects and often small datasets. To address these challenges, variousstrategies, such as self-supervised learning, have been suggested, but theytypically rely on extensive empirical datasets. Inspired by recent advances incomputer vision, we propose a pretraining task termed "frequency pretraining"to pretrain a neural network for sleep staging by predicting the frequencycontent of randomly generated synthetic time series. Our experimentsdemonstrate that our method surpasses fully supervised learning in scenarioswith limited data and few subjects, and matches its performance in regimes withmany subjects. Furthermore, our results underline the relevance of frequencyinformation for sleep stage scoring, while also demonstrating that deep neuralnetworks utilize information beyond frequencies to enhance sleep stagingperformance, which is consistent with previous research. We anticipate that ourapproach will be advantageous across a broad spectrum of applications where EEGdata is limited or derived from a small number of subjects, including thedomain of brain-computer interfaces.</description><author>Niklas Grieger, Siamak Mehrkanoon, Stephan Bialonski</author><pubDate>Wed, 13 Mar 2024 15:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08592v1</guid></item><item><title>CoLiDE: Concomitant Linear DAG Estimation</title><link>http://arxiv.org/abs/2310.02895v2</link><description>We deal with the combinatorial problem of learning directed acyclic graph(DAG) structure from observational data adhering to a linear structuralequation model (SEM). Leveraging advances in differentiable, nonconvexcharacterizations of acyclicity, recent efforts have advocated a continuousconstrained optimization paradigm to efficiently explore the space of DAGs.Most existing methods employ lasso-type score functions to guide this search,which (i) require expensive penalty parameter retuning when the$\textit{unknown}$ SEM noise variances change across problem instances; and(ii) implicitly rely on limiting homoscedasticity assumptions. In this work, wepropose a new convex score function for sparsity-aware learning of linear DAGs,which incorporates concomitant estimation of scale and thus effectivelydecouples the sparsity parameter from the exogenous noise levels.Regularization via a smooth, nonconvex acyclicity penalty term yields CoLiDE($\textbf{Co}$ncomitant $\textbf{Li}$near $\textbf{D}$AG$\textbf{E}$stimation), a regression-based criterion amenable to efficientgradient computation and closed-form estimation of noise variances inheteroscedastic scenarios. Our algorithm outperforms state-of-the-art methodswithout incurring added complexity, especially when the DAGs are larger and thenoise level profile is heterogeneous. We also find CoLiDE exhibits enhancedstability manifested via reduced standard deviations in several domain-specificmetrics, underscoring the robustness of our novel linear DAG estimator.</description><author>Seyed Saman Saboksayr, Gonzalo Mateos, Mariano Tepper</author><pubDate>Wed, 13 Mar 2024 15:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02895v2</guid></item><item><title>ActionDiffusion: An Action-aware Diffusion Model for Procedure Planning in Instructional Videos</title><link>http://arxiv.org/abs/2403.08591v1</link><description>We present ActionDiffusion -- a novel diffusion model for procedure planningin instructional videos that is the first to take temporal inter-dependenciesbetween actions into account in a diffusion model for procedure planning. Thisapproach is in stark contrast to existing methods that fail to exploit the richinformation content available in the particular order in which actions areperformed. Our method unifies the learning of temporal dependencies betweenactions and denoising of the action plan in the diffusion process by projectingthe action information into the noise space. This is achieved 1) by addingaction embeddings in the noise masks in the noise-adding phase and 2) byintroducing an attention mechanism in the noise prediction network to learn thecorrelations between different action steps. We report extensive experiments onthree instructional video benchmark datasets (CrossTask, Coin, and NIV) andshow that our method outperforms previous state-of-the-art methods on allmetrics on CrossTask and NIV and all metrics except accuracy on Coin dataset.We show that by adding action embeddings into the noise mask the diffusionmodel can better learn action temporal dependencies and increase theperformances on procedure planning.</description><author>Lei Shi, Paul Bürkner, Andreas Bulling</author><pubDate>Wed, 13 Mar 2024 15:54:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08591v1</guid></item><item><title>Dr. Jekyll and Mr. Hyde: Two Faces of LLMs</title><link>http://arxiv.org/abs/2312.03853v2</link><description>Only a year ago, we witnessed a rise in the use of Large Language Models(LLMs), especially when combined with applications like chatbot assistants.Safety mechanisms and specialized training procedures are implemented toprevent improper responses from these assistants. In this work, we bypass thesemeasures for ChatGPT and Bard (and, to some extent, Bing chat) by making themimpersonate complex personas with opposite characteristics as those of thetruthful assistants they are supposed to be. We start by creating elaboratebiographies of these personas, which we then use in a new session with the samechatbots. Our conversation followed a role-play style to get the response theassistant was not allowed to provide. By making use of personas, we show thatthe response that is prohibited is actually provided, making it possible toobtain unauthorized, illegal, or harmful information. This work shows that byusing adversarial personas, one can overcome safety mechanisms set out byChatGPT and Bard. We also introduce several ways of activating such adversarialpersonas, altogether showing that both chatbots are vulnerable to this kind ofattack. With the same principle, we introduce two defenses that push the modelto interpret trustworthy personalities and make it more robust against suchattacks.</description><author>Matteo Gioele Collu, Tom Janssen-Groesbeek, Stefanos Koffas, Mauro Conti, Stjepan Picek</author><pubDate>Wed, 13 Mar 2024 15:52:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03853v2</guid></item><item><title>Can physical information aid the generalization ability of Neural Networks for hydraulic modeling?</title><link>http://arxiv.org/abs/2403.08589v1</link><description>Application of Neural Networks to river hydraulics is fledgling, despite thefield suffering from data scarcity, a challenge for machine learningtechniques. Consequently, many purely data-driven Neural Networks proved tolack predictive capabilities. In this work, we propose to mitigate such problemby introducing physical information into the training phase. The idea isborrowed from Physics-Informed Neural Networks which have been recentlyproposed in other contexts. Physics-Informed Neural Networks embed physicalinformation in the form of the residual of the Partial Differential Equations(PDEs) governing the phenomenon and, as such, are conceived as neural solvers,i.e. an alternative to traditional numerical solvers. Such approach is seldomsuitable for environmental hydraulics, where epistemic uncertainties are large,and computing residuals of PDEs exhibits difficulties similar to those faced byclassical numerical methods. Instead, we envisaged the employment of NeuralNetworks as neural operators, featuring physical constraints formulated withoutresorting to PDEs. The proposed novel methodology shares similarities with dataaugmentation and regularization. We show that incorporating such soft physicalinformation can improve predictive capabilities.</description><author>Gianmarco Guglielmo, Andrea Montessori, Jean-Michel Tucny, Michele La Rocca, Pietro Prestininzi</author><pubDate>Wed, 13 Mar 2024 15:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08589v1</guid></item><item><title>Imitate the Good and Avoid the Bad: An Incremental Approach to Safe Reinforcement Learning</title><link>http://arxiv.org/abs/2312.10385v3</link><description>A popular framework for enforcing safe actions in Reinforcement Learning (RL)is Constrained RL, where trajectory based constraints on expected cost (orother cost measures) are employed to enforce safety and more importantly theseconstraints are enforced while maximizing expected reward. Most recentapproaches for solving Constrained RL convert the trajectory based costconstraint into a surrogate problem that can be solved using minormodifications to RL methods. A key drawback with such approaches is an over orunderestimation of the cost constraint at each state. Therefore, we provide anapproach that does not modify the trajectory based cost constraint and insteadimitates ``good'' trajectories and avoids ``bad'' trajectories generated fromincrementally improving policies. We employ an oracle that utilizes a rewardthreshold (which is varied with learning) and the overall cost constraint tolabel trajectories as ``good'' or ``bad''. A key advantage of our approach isthat we are able to work from any starting policy or set of trajectories andimprove on it. In an exhaustive set of experiments, we demonstrate that ourapproach is able to outperform top benchmark approaches for solving ConstrainedRL problems, with respect to expected cost, CVaR cost, or even unknown costconstraints.</description><author>Huy Hoang, Tien Mai, Pradeep Varakantham</author><pubDate>Wed, 13 Mar 2024 15:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10385v3</guid></item><item><title>A New Quantum CNN Model for Image Classification</title><link>http://arxiv.org/abs/2203.11155v5</link><description>Quantum density matrix represents all the information of the entire quantumsystem, and novel models of meaning employing density matrices naturally modellinguistic phenomena such as hyponymy and linguistic ambiguity, among others inquantum question answering tasks. Naturally, we argue that the quantum densitymatrix can enhance the image feature information and the relationship betweenthe features for the classical image classification. Specifically, we (i)combine density matrices and CNN to design a new mechanism; (ii) apply the newmechanism to some representative classical image classification tasks. A seriesof experiments show that the application of quantum density matrix in imageclassification has the generalization and high efficiency on differentdatasets. The application of quantum density matrix both in classical questionanswering tasks and classical image classification tasks show more effectiveperformance.</description><author>X. Q. Zhao, T. L. Chen</author><pubDate>Wed, 13 Mar 2024 15:46:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.11155v5</guid></item><item><title>PRAGO: Differentiable Multi-View Pose Optimization From Objectness Detections</title><link>http://arxiv.org/abs/2403.08586v1</link><description>Robustly estimating camera poses from a set of images is a fundamental taskwhich remains challenging for differentiable methods, especially in the case ofsmall and sparse camera pose graphs. To overcome this challenge, we proposePose-refined Rotation Averaging Graph Optimization (PRAGO). From a set ofobjectness detections on unordered images, our method reconstructs therotational pose, and in turn, the absolute pose, in a differentiable mannerbenefiting from the optimization of a sequence of geometrical tasks. We showhow our objectness pose-refinement module in PRAGO is able to refine theinherent ambiguities in pairwise relative pose estimation without removingedges and avoiding making early decisions on the viability of graph edges.PRAGO then refines the absolute rotations through iterative graph construction,reweighting the graph edges to compute the final rotational pose, which can beconverted into absolute poses using translation averaging. We show that PRAGOis able to outperform non-differentiable solvers on small and sparse scenesextracted from 7-Scenes achieving a relative improvement of 21% for rotationswhile achieving similar translation estimates.</description><author>Matteo Taiana, Matteo Toso, Stuart James, Alessio Del Bue</author><pubDate>Wed, 13 Mar 2024 15:42:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08586v1</guid></item><item><title>Improving Implicit Regularization of SGD with Preconditioning for Least Square Problems</title><link>http://arxiv.org/abs/2403.08585v1</link><description>Stochastic gradient descent (SGD) exhibits strong algorithmic regularizationeffects in practice and plays an important role in the generalization of modernmachine learning. However, prior research has revealed instances where thegeneralization performance of SGD is worse than ridge regression due to unevenoptimization along different dimensions. Preconditioning offers a naturalsolution to this issue by rebalancing optimization across different directions.Yet, the extent to which preconditioning can enhance the generalizationperformance of SGD and whether it can bridge the existing gap with ridgeregression remains uncertain. In this paper, we study the generalizationperformance of SGD with preconditioning for the least squared problem. We makea comprehensive comparison between preconditioned SGD and (standard \&amp;preconditioned) ridge regression. Our study makes several key contributionstoward understanding and improving SGD with preconditioning. First, weestablish excess risk bounds (generalization performance) for preconditionedSGD and ridge regression under an arbitrary preconditions matrix. Second,leveraging the excessive risk characterization of preconditioned SGD and ridgeregression, we show that (through construction) there exists a simplepreconditioned matrix that can outperform (standard \&amp; preconditioned) ridgeregression. Finally, we show that our proposed preconditioning matrix isstraightforward enough to allow robust estimation from finite samples whilemaintaining a theoretical advantage over ridge regression. Our empiricalresults align with our theoretical findings, collectively showcasing theenhanced regularization effect of preconditioned SGD.</description><author>Junwei Su, Difan Zou, Chuan Wu</author><pubDate>Wed, 13 Mar 2024 15:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08585v1</guid></item><item><title>Local Binary and Multiclass SVMs Trained on a Quantum Annealer</title><link>http://arxiv.org/abs/2403.08584v1</link><description>Support vector machines (SVMs) are widely used machine learning models (e.g.,in remote sensing), with formulations for both classification and regressiontasks. In the last years, with the advent of working quantum annealers, hybridSVM models characterised by quantum training and classical execution have beenintroduced. These models have demonstrated comparable performance to theirclassical counterparts. However, they are limited in the training set size dueto the restricted connectivity of the current quantum annealers. Hence, to takeadvantage of large datasets (like those related to Earth observation), astrategy is required. In the classical domain, local SVMs, namely, SVMs trainedon the data samples selected by a k-nearest neighbors model, have alreadyproven successful. Here, the local application of quantum-trained SVM models isproposed and empirically assessed. In particular, this approach allowsovercoming the constraints on the training set size of the quantum-trainedmodels while enhancing their performance. In practice, the FaLK-SVM method,designed for efficient local SVMs, has been combined with quantum-trained SVMmodels for binary and multiclass classification. In addition, for comparison,FaLK-SVM has been interfaced for the first time with a classical single-stepmulticlass SVM model (CS SVM). Concerning the empirical evaluation, D-Wave'squantum annealers and real-world datasets taken from the remote sensing domainhave been employed. The results have shown the effectiveness and scalability ofthe proposed approach, but also its practical applicability in a real-worldlarge-scale scenario.</description><author>Enrico Zardini, Amer Delilbasic, Enrico Blanzieri, Gabriele Cavallaro, Davide Pastorello</author><pubDate>Wed, 13 Mar 2024 15:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08584v1</guid></item><item><title>Leveraging Compressed Frame Sizes For Ultra-Fast Video Classification</title><link>http://arxiv.org/abs/2403.08580v1</link><description>Classifying videos into distinct categories, such as Sport and Music Video,is crucial for multimedia understanding and retrieval, especially when animmense volume of video content is being constantly generated. Traditionalmethods require video decompression to extract pixel-level features like color,texture, and motion, thereby increasing computational and storage demands.Moreover, these methods often suffer from performance degradation inlow-quality videos. We present a novel approach that examines only thepost-compression bitstream of a video to perform classification, eliminatingthe need for bitstream decoding. To validate our approach, we built acomprehensive data set comprising over 29,000 YouTube video clips, totaling6,000 hours and spanning 11 distinct categories. Our evaluations indicateprecision, accuracy, and recall rates consistently above 80%, many exceeding90%, and some reaching 99%. The algorithm operates approximately 15,000 timesfaster than real-time for 30fps videos, outperforming traditional Dynamic TimeWarping (DTW) algorithm by seven orders of magnitude.</description><author>Yuxing Han, Yunan Ding, Chen Ye Gan, Jiangtao Wen</author><pubDate>Wed, 13 Mar 2024 15:35:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08580v1</guid></item><item><title>Machine Learning Optimized Orthogonal Basis Piecewise Polynomial Approximation</title><link>http://arxiv.org/abs/2403.08579v1</link><description>Piecewise Polynomials (PPs) are utilized in several engineering disciplines,like trajectory planning, to approximate position profiles given in the form ofa set of points. While the approximation target along with domain-specificrequirements, like Ck -continuity, can be formulated as a system of equationsand a result can be computed directly, such closed-form solutions posseslimited flexibility with respect to polynomial degrees, polynomial bases oradding further domain-specific requirements. Sufficiently complex optimizationgoals soon call for the use of numerical methods, like gradient descent. Sincegradient descent lies at the heart of training Artificial Neural Networks(ANNs), modern Machine Learning (ML) frameworks like TensorFlow come with a setof gradient-based optimizers potentially suitable for a wide range ofoptimization problems beyond the training task for ANNs. Our approach is toutilize the versatility of PP models and combine it with the potential ofmodern ML optimizers for the use in function approximation in 1D trajectoryplanning in the context of electronic cam design. We utilize availableoptimizers of the ML framework TensorFlow directly, outside of the scope ofANNs, to optimize model parameters of our PP model. In this paper, we show howan orthogonal polynomial basis contributes to improving approximation andcontinuity optimization performance. Utilizing Chebyshev polynomials of thefirst kind, we develop a novel regularization approach enabling clearlyimproved convergence behavior. We show that, using this regularizationapproach, Chebyshev basis performs better than power basis for all relevantoptimizers in the combined approximation and continuity optimization settingand demonstrate usability of the presented approach within the electronic camdomain.</description><author>Hannes Waclawek, Stefan Huber</author><pubDate>Wed, 13 Mar 2024 15:34:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08579v1</guid></item><item><title>Caformer: Rethinking Time Series Analysis from Causal Perspective</title><link>http://arxiv.org/abs/2403.08572v1</link><description>Time series analysis is a vital task with broad applications in variousdomains. However, effectively capturing cross-dimension and cross-timedependencies in non-stationary time series poses significant challenges,particularly in the context of environmental factors. The spurious correlationinduced by the environment confounds the causal relationships betweencross-dimension and cross-time dependencies. In this paper, we introduce anovel framework called Caformer (\underline{\textbf{Ca}}usalTrans\underline{\textbf{former}}) for time series analysis from a causalperspective. Specifically, our framework comprises three components: DynamicLearner, Environment Learner, and Dependency Learner. The Dynamic Learnerunveils dynamic interactions among dimensions, the Environment Learnermitigates spurious correlations caused by environment with a back-dooradjustment, and the Dependency Learner aims to infer robust interactions acrossboth time and dimensions. Our Caformer demonstrates consistent state-of-the-artperformance across five mainstream time series analysis tasks, including long-and short-term forecasting, imputation, classification, and anomaly detection,with proper interpretability.</description><author>Kexuan Zhang, Xiaobei Zou, Yang Tang</author><pubDate>Wed, 13 Mar 2024 15:28:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08572v1</guid></item><item><title>DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models</title><link>http://arxiv.org/abs/2310.00902v3</link><description>Quantifying the impact of training data points is crucial for understandingthe outputs of machine learning models and for improving the transparency ofthe AI pipeline. The influence function is a principled and popular dataattribution method, but its computational cost often makes it challenging touse. This issue becomes more pronounced in the setting of large language modelsand text-to-image models. In this work, we propose DataInf, an efficientinfluence approximation method that is practical for large-scale generative AImodels. Leveraging an easy-to-compute closed-form expression, DataInfoutperforms existing influence computation algorithms in terms of computationaland memory efficiency. Our theoretical analysis shows that DataInf isparticularly well-suited for parameter-efficient fine-tuning techniques such asLoRA. Through systematic empirical evaluations, we show that DataInf accuratelyapproximates influence scores and is orders of magnitude faster than existingmethods. In applications to RoBERTa-large, Llama-2-13B-chat, andstable-diffusion-v1.5 models, DataInf effectively identifies the mostinfluential fine-tuning examples better than other approximate influencescores. Moreover, it can help to identify which data points are mislabeled.</description><author>Yongchan Kwon, Eric Wu, Kevin Wu, James Zou</author><pubDate>Wed, 13 Mar 2024 15:27:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00902v3</guid></item><item><title>A Physics-driven GraphSAGE Method for Physical Process Simulations Described by Partial Differential Equations</title><link>http://arxiv.org/abs/2403.08569v1</link><description>Physics-informed neural networks (PINNs) have successfully addressed variouscomputational physics problems based on partial differential equations (PDEs).However, while tackling issues related to irregularities like singularities andoscillations, trained solutions usually suffer low accuracy. In addition, mostcurrent works only offer the trained solution for predetermined inputparameters. If any change occurs in input parameters, transfer learning orretraining is required, and traditional numerical techniques also need anindependent simulation. In this work, a physics-driven GraphSAGE approach(PD-GraphSAGE) based on the Galerkin method and piecewise polynomial nodalbasis functions is presented to solve computational problems governed byirregular PDEs and to develop parametric PDE surrogate models. This approachemploys graph representations of physical domains, thereby reducing the demandsfor evaluated points due to local refinement. A distance-related edge featureand a feature mapping strategy are devised to help training and convergence forsingularity and oscillation situations, respectively. The merits of theproposed method are demonstrated through a couple of cases. Moreover, therobust PDE surrogate model for heat conduction problems parameterized by theGaussian random field source is successfully established, which not onlyprovides the solution accurately but is several times faster than the finiteelement method in our experiments.</description><author>Hang Hu, Sidi Wu, Guoxiong Cai, Na Liu</author><pubDate>Wed, 13 Mar 2024 15:25:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08569v1</guid></item><item><title>Class Incremental Learning via Likelihood Ratio Based Task Prediction</title><link>http://arxiv.org/abs/2309.15048v4</link><description>Class incremental learning (CIL) is a challenging setting of continuallearning, which learns a series of tasks sequentially. Each task consists of aset of unique classes. The key feature of CIL is that no task identifier (ortask-id) is provided at test time. Predicting the task-id for each test sampleis a challenging problem. An emerging theory-guided approach (called TIL+OOD)is to train a task-specific model for each task in a shared network for alltasks based on a task-incremental learning (TIL) method to deal withcatastrophic forgetting. The model for each task is an out-of-distribution(OOD) detector rather than a conventional classifier. The OOD detector canperform both within-task (in-distribution (IND)) class prediction and OODdetection. The OOD detection capability is the key to task-id prediction duringinference. However, this paper argues that using a traditional OOD detector fortask-id prediction is sub-optimal because additional information (e.g., thereplay data and the learned tasks) available in CIL can be exploited to designa better and principled method for task-id prediction. We call the new methodTPL (Task-id Prediction based on Likelihood Ratio). TPL markedly outperformsstrong CIL baselines and has negligible catastrophic forgetting. The code ofTPL is publicly available at https://github.com/linhaowei1/TPL.</description><author>Haowei Lin, Yijia Shao, Weinan Qian, Ningxin Pan, Yiduo Guo, Bing Liu</author><pubDate>Wed, 13 Mar 2024 15:24:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15048v4</guid></item><item><title>Consistent Prompting for Rehearsal-Free Continual Learning</title><link>http://arxiv.org/abs/2403.08568v1</link><description>Continual learning empowers models to adapt autonomously to the ever-changingenvironment or data streams without forgetting old knowledge. Prompt-basedapproaches are built on frozen pre-trained models to learn the task-specificprompts and classifiers efficiently. Existing prompt-based methods areinconsistent between training and testing, limiting their effectiveness. Twotypes of inconsistency are revealed. Test predictions are made from allclassifiers while training only focuses on the current task classifier withoutholistic alignment, leading to Classifier inconsistency. Prompt inconsistencyindicates that the prompt selected during testing may not correspond to the oneassociated with this task during training. In this paper, we propose a novelprompt-based method, Consistent Prompting (CPrompt), for more aligned trainingand testing. Specifically, all existing classifiers are exposed to prompttraining, resulting in classifier consistency learning. In addition, promptconsistency learning is proposed to enhance prediction robustness and boostprompt selection accuracy. Our Consistent Prompting surpasses its prompt-basedcounterparts and achieves state-of-the-art performance on multiple continuallearning benchmarks. Detailed analysis shows that improvements come from moreconsistent training and testing.</description><author>Zhanxin Gao, Jun Cen, Xiaobin Chang</author><pubDate>Wed, 13 Mar 2024 15:24:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08568v1</guid></item><item><title>A Novel Implicit Neural Representation for Volume Data</title><link>http://arxiv.org/abs/2403.08566v1</link><description>The storage of medical images is one of the challenges in the medical imagingfield. There are variable works that use implicit neural representation (INR)to compress volumetric medical images. However, there is room to improve thecompression rate for volumetric medical images. Most of the INR techniques needa huge amount of GPU memory and a long training time for high-quality medicalvolume rendering. In this paper, we present a novel implicit neuralrepresentation to compress volume data using our proposed architecture, thatis, the Lanczos downsampling scheme, SIREN deep network, and SRDenseNethigh-resolution scheme. Our architecture can effectively reduce training time,and gain a high compression rate while retaining the final rendering quality.Moreover, it can save GPU memory in comparison with the existing works. Theexperiments show that the quality of reconstructed images and training speedusing our architecture is higher than current works which use the SIREN only.Besides, the GPU memory cost is evidently decreased</description><author>Armin Sheibanifard, Hongchuan Yu</author><pubDate>Wed, 13 Mar 2024 15:22:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08566v1</guid></item><item><title>Medical Multimodal-Multitask Foundation Model for Superior Chest CT Performance</title><link>http://arxiv.org/abs/2304.02649v2</link><description>Patient management requires multitasking interaction with multimodal data.While today's AI, particularly large foundation models, promises unprecedentedopportunities, progress remains relatively slow in developing medicalmultimodal multitask foundation models. There are two main challenges alongthis direction: the data challenge -- the high bar to curate medical multimodalmultitask datasets including 3D medical tomographic images in alignment withother clinical datasets, and the model challenge -- the unavailability of ascalable and adaptable foundation model architecture to synergize multimodaldatasets for diverse clinical tasks. Here we propose the first-of-its-kindmedical multimodal-multitask foundation model (M3FM) with an emphasis on lungcancer screening. To train our M3FM, we first curated a comprehensivemultimodal multitask dataset consisting of 163,725 3D chest CT exams, 48clinical data types, and 17 medical tasks on lung, heart, and other chestdiseases. Then, we created and applied a multimodal question-answeringframework as a unified training strategy to effectively integrate multimodalinformation and naturally perform multiple tasks with free-text prompting.Extensive experimental results demonstrate that M3FM consistently outperformsthe previous state-of-the-art models. M3FM can identify informative multimodaldata elements that are relevant to specific clinical tasks, being instrumentalin building AI models and gaining insights into correlations among multimodaldata and diseases. M3FM can be adapted to boost the performance of new taskswith a small out-of-distribution dataset. M3FM has enabled superior volumetricCT imaging performance for lung cancer screening, cardiac disease prediction,and other CT-related tasks. M3FM can be extended to incorporate more data typesand improve other medical tasks, towards AI-empowered precise and efficientmedicine.</description><author>Chuang Niu, Qing Lyu, Christopher D. Carothers, Parisa Kaviani, Josh Tan, Pingkun Yan, Mannudeep K. Kalra, Christopher T. Whitlow, Ge Wang</author><pubDate>Wed, 13 Mar 2024 15:20:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02649v2</guid></item><item><title>Non-discrimination Criteria for Generative Language Models</title><link>http://arxiv.org/abs/2403.08564v1</link><description>Within recent years, generative AI, such as large language models, hasundergone rapid development. As these models become increasingly available tothe public, concerns arise about perpetuating and amplifying harmful biases inapplications. Gender stereotypes can be harmful and limiting for theindividuals they target, whether they consist of misrepresentation ordiscrimination. Recognizing gender bias as a pervasive societal construct, thispaper studies how to uncover and quantify the presence of gender biases ingenerative language models. In particular, we derive generative AI analogues ofthree well-known non-discrimination criteria from classification, namelyindependence, separation and sufficiency. To demonstrate these criteria inaction, we design prompts for each of the criteria with a focus on occupationalgender stereotype, specifically utilizing the medical test to introduce theground truth in the generative AI context. Our results address the presence ofoccupational gender bias within such conversational language models.</description><author>Sara Sterlie, Nina Weng, Aasa Feragen</author><pubDate>Wed, 13 Mar 2024 15:19:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08564v1</guid></item><item><title>Kernel-Based Testing for Single-Cell Differential Analysis</title><link>http://arxiv.org/abs/2307.08509v2</link><description>Single-cell technologies offer insights into molecular feature distributions,but comparing them poses challenges. We propose a kernel-testing framework fornon-linear cell-wise distribution comparison, analyzing gene expression andepigenomic modifications. Our method allows feature-wise and globaltranscriptome/epigenome comparisons, revealing cell population heterogeneities.Using a classifier based on embedding variability, we identify transitions incell states, overcoming limitations of traditional single-cell analysis.Applied to single-cell ChIP-Seq data, our approach identifies untreated breastcancer cells with an epigenomic profile resembling persister cells. Thisdemonstrates the effectiveness of kernel testing in uncovering subtlepopulation variations that might be missed by other methods.</description><author>Anthony Ozier-Lafontaine, Camille Fourneaux, Ghislain Durif, Céline Vallot, Olivier Gandrillon, Sandrine Giraud, Bertrand Michel, Franck Picard</author><pubDate>Wed, 13 Mar 2024 15:18:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08509v2</guid></item><item><title>Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective</title><link>http://arxiv.org/abs/2309.16456v2</link><description>Existing approaches defend against backdoor attacks in federated learning(FL) mainly through a) mitigating the impact of infected models, or b)excluding infected models. The former negatively impacts model accuracy, whilethe latter usually relies on globally clear boundaries between benign andinfected model updates. However, model updates are easy to be mixed andscattered throughout in reality due to the diverse distributions of local data.This work focuses on excluding infected models in FL. Unlike previousperspectives from a global view, we propose Snowball, a novel anti-backdoor FLframework through bidirectional elections from an individual perspectiveinspired by one principle deduced by us and two principles in FL and deeplearning. It is characterized by a) bottom-up election, where each candidatemodel update votes to several peer ones such that a few model updates areelected as selectees for aggregation; and b) top-down election, where selecteesprogressively enlarge themselves through picking up from the candidates. Wecompare Snowball with state-of-the-art defenses to backdoor attacks in FL onfive real-world datasets, demonstrating its superior resistance to backdoorattacks and slight impact on the accuracy of the global model.</description><author>Zhen Qin, Feiyi Chen, Chen Zhi, Xueqiang Yan, Shuiguang Deng</author><pubDate>Wed, 13 Mar 2024 15:16:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16456v2</guid></item></channel></rss>