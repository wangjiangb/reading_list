<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 30 Jul 2024 13:00:29 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing</title><link>http://arxiv.org/abs/2407.20232v1</link><description>Text-based editing diffusion models exhibit limited performance when theuser's input instruction is ambiguous. To solve this problem, we propose$\textit{Specify ANd Edit}$ (SANE), a zero-shot inference pipeline fordiffusion-based editing systems. We use a large language model (LLM) todecompose the input instruction into specific instructions, i.e. well-definedinterventions to apply to the input image to satisfy the user's request. Webenefit from the LLM-derived instructions along the original one, thanks to anovel denoising guidance strategy specifically designed for the task. Ourexperiments with three baselines and on two datasets demonstrate the benefitsof SANE in all setups. Moreover, our pipeline improves the interpretability ofediting models, and boosts the output diversity. We also demonstrate that ourapproach can be applied to any edit, whether ambiguous or not. Our code ispublic at https://github.com/fabvio/SANE.</description><author>Ekaterina Iakovleva, Fabio Pizzati, Philip Torr, Stéphane Lathuilière</author><pubDate>Mon, 29 Jul 2024 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20232v1</guid></item><item><title>SAPG: Split and Aggregate Policy Gradients</title><link>http://arxiv.org/abs/2407.20230v1</link><description>Despite extreme sample inefficiency, on-policy reinforcement learning, akapolicy gradients, has become a fundamental tool in decision-making problems.With the recent advances in GPU-driven simulation, the ability to collect largeamounts of data for RL training has scaled exponentially. However, we show thatcurrent RL methods, e.g. PPO, fail to ingest the benefit of parallelizedenvironments beyond a certain point and their performance saturates. To addressthis, we propose a new on-policy RL algorithm that can effectively leveragelarge-scale environments by splitting them into chunks and fusing them backtogether via importance sampling. Our algorithm, termed SAPG, showssignificantly higher performance across a variety of challenging environmentswhere vanilla PPO and other strong baselines fail to achieve high performance.Website at https://sapg-rl.github.io/</description><author>Jayesh Singla, Ananye Agarwal, Deepak Pathak</author><pubDate>Mon, 29 Jul 2024 17:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20230v1</guid></item><item><title>Matryoshka Multimodal Models</title><link>http://arxiv.org/abs/2405.17430v2</link><description>Large Multimodal Models (LMMs) such as LLaVA have shown strong performance invisual-linguistic reasoning. These models first embed images into a fixed largenumber of visual tokens and then feed them into a Large Language Model (LLM).However, this design causes an excessive number of tokens for dense visualscenarios such as high-resolution images and videos, leading to greatinefficiency. While token pruning/merging methods do exist, they produce asingle length output for each image and do not afford flexibility in tradingoff information density v.s. efficiency. Inspired by the concept of MatryoshkaDolls, we propose M3: Matryoshka Multimodal Models, which learns to representvisual content as nested sets of visual tokens that capture information acrossmultiple coarse-to-fine granularities. Our approach offers several uniquebenefits for LMMs: (1) One can explicitly control the visual granularity pertest instance during inference, e.g. , adjusting the number of tokens used torepresent an image based on the anticipated complexity or simplicity of thecontent; (2) M3 provides a framework for analyzing the granularity needed forexisting datasets, where we find that COCO-style benchmarks only need around ~9visual tokens to obtain accuracy similar to that of using all 576 tokens; (3)Our approach provides a foundation to explore the best trade-off betweenperformance and visual token length at sample level, where our investigationreveals that a large gap exists between the oracle upper bound and currentfixed-scale representations.</description><author>Mu Cai, Jianwei Yang, Jianfeng Gao, Yong Jae Lee</author><pubDate>Mon, 29 Jul 2024 17:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17430v2</guid></item><item><title>Improving 2D Feature Representations by 3D-Aware Fine-Tuning</title><link>http://arxiv.org/abs/2407.20229v1</link><description>Current visual foundation models are trained purely on unstructured 2D data,limiting their understanding of 3D structure of objects and scenes. In thiswork, we show that fine-tuning on 3D-aware data improves the quality ofemerging semantic features. We design a method to lift semantic 2D featuresinto an efficient 3D Gaussian representation, which allows us to re-render themfor arbitrary views. Using the rendered 3D-aware features, we design afine-tuning strategy to transfer such 3D awareness into a 2D foundation model.We demonstrate that models fine-tuned in that way produce features that readilyimprove downstream task performance in semantic segmentation and depthestimation through simple linear probing. Notably, though fined-tuned on asingle indoor dataset, the improvement is transferable to a variety of indoordatasets and out-of-domain datasets. We hope our study encourages the communityto consider injecting 3D awareness when training 2D foundation models. Projectpage: https://ywyue.github.io/FiT3D.</description><author>Yuanwen Yue, Anurag Das, Francis Engelmann, Siyu Tang, Jan Eric Lenssen</author><pubDate>Mon, 29 Jul 2024 17:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20229v1</guid></item><item><title>FlexAttention for Efficient High-Resolution Vision-Language Models</title><link>http://arxiv.org/abs/2407.20228v1</link><description>Current high-resolution vision-language models encode images ashigh-resolution image tokens and exhaustively take all these tokens to computeattention, which significantly increases the computational cost. To addressthis problem, we propose FlexAttention, a flexible attention mechanism forefficient high-resolution vision-language models. Specifically, ahigh-resolution image is encoded both as high-resolution tokens andlow-resolution tokens, where only the low-resolution tokens and a few selectedhigh-resolution tokens are utilized to calculate the attention map, whichgreatly shrinks the computational cost. The high-resolution tokens are selectedvia a high-resolution selection module which could retrieve tokens of relevantregions based on an input attention map. The selected high-resolution tokensare then concatenated to the low-resolution tokens and text tokens, and inputto a hierarchical self-attention layer which produces an attention map thatcould be used for the next-step high-resolution token selection. Thehierarchical self-attention process and high-resolution token selection processare performed iteratively for each attention layer. Experiments on multimodalbenchmarks prove that our FlexAttention outperforms existing high-resolutionVLMs (e.g., relatively ~9% in V* Bench, ~7% in TextVQA), while alsosignificantly reducing the computational cost by nearly 40%.</description><author>Junyan Li, Delin Chen, Tianle Cai, Peihao Chen, Yining Hong, Zhenfang Chen, Yikang Shen, Chuang Gan</author><pubDate>Mon, 29 Jul 2024 17:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20228v1</guid></item><item><title>Can Editing LLMs Inject Harm?</title><link>http://arxiv.org/abs/2407.20224v1</link><description>Knowledge editing techniques have been increasingly adopted to efficientlycorrect the false or outdated knowledge in Large Language Models (LLMs), due tothe high cost of retraining from scratch. Meanwhile, one critical butunder-explored question is: can knowledge editing be used to inject harm intoLLMs? In this paper, we propose to reformulate knowledge editing as a new typeof safety threat for LLMs, namely Editing Attack, and conduct a systematicinvestigation with a newly constructed dataset EditAttack. Specifically, wefocus on two typical safety risks of Editing Attack including MisinformationInjection and Bias Injection. For the risk of misinformation injection, wefirst categorize it into commonsense misinformation injection and long-tailmisinformation injection. Then, we find that editing attacks can inject bothtypes of misinformation into LLMs, and the effectiveness is particularly highfor commonsense misinformation injection. For the risk of bias injection, wediscover that not only can biased sentences be injected into LLMs with higheffectiveness, but also one single biased sentence injection can cause a highbias increase in general outputs of LLMs, which are even highly irrelevant tothe injected sentence, indicating a catastrophic impact on the overall fairnessof LLMs. Then, we further illustrate the high stealthiness of editing attacks,measured by their impact on the general knowledge and reasoning capacities ofLLMs, and show the hardness of defending editing attacks with empiricalevidence. Our discoveries demonstrate the emerging misuse risks of knowledgeediting techniques on compromising the safety alignment of LLMs.</description><author>Canyu Chen, Baixiang Huang, Zekun Li, Zhaorun Chen, Shiyang Lai, Xiongxiao Xu, Jia-Chen Gu, Jindong Gu, Huaxiu Yao, Chaowei Xiao, Xifeng Yan, William Yang Wang, Philip Torr, Dawn Song, Kai Shu</author><pubDate>Mon, 29 Jul 2024 17:58:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20224v1</guid></item><item><title>Correspondence-Free SE(3) Point Cloud Registration in RKHS via Unsupervised Equivariant Learning</title><link>http://arxiv.org/abs/2407.20223v1</link><description>This paper introduces a robust unsupervised SE(3) point cloud registrationmethod that operates without requiring point correspondences. The method framespoint clouds as functions in a reproducing kernel Hilbert space (RKHS),leveraging SE(3)-equivariant features for direct feature space registration. Anovel RKHS distance metric is proposed, offering reliable performance amidstnoise, outliers, and asymmetrical data. An unsupervised training approach isintroduced to effectively handle limited ground truth data, facilitatingadaptation to real datasets. The proposed method outperforms classical andsupervised methods in terms of registration accuracy on both synthetic(ModelNet40) and real-world (ETH3D) noisy, outlier-rich datasets. To our bestknowledge, this marks the first instance of successful real RGB-D odometry dataregistration using an equivariant method. The code is available at{https://sites.google.com/view/eccv24-equivalign}</description><author>Ray Zhang, Zheming Zhou, Min Sun, Omid Ghasemalizadeh, Cheng-Hao Kuo, Ryan Eustice, Maani Ghaffari, Arnie Sen</author><pubDate>Mon, 29 Jul 2024 17:57:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20223v1</guid></item><item><title>Is artificial consciousness achievable? Lessons from the human brain</title><link>http://arxiv.org/abs/2405.04540v2</link><description>We here analyse the question of developing artificial consciousness from anevolutionary perspective, taking the evolution of the human brain and itsrelation with consciousness as a reference model. This kind of analysis revealsseveral structural and functional features of the human brain that appear to bekey for reaching human-like complex conscious experience and that currentresearch on Artificial Intelligence (AI) should take into account in itsattempt to develop systems capable of conscious processing. We argue that, evenif AI is limited in its ability to emulate human consciousness for bothintrinsic (structural and architectural) and extrinsic (related to the currentstage of scientific and technological knowledge) reasons, taking inspirationfrom those characteristics of the brain that make conscious processing possibleand/or modulate it, is a potentially promising strategy towards developingconscious AI. Also, it is theoretically possible that AI research can developpartial or potentially alternative forms of consciousness that is qualitativelydifferent from the human, and that may be either more or less sophisticateddepending on the perspectives. Therefore, we recommend neuroscience-inspiredcaution in talking about artificial consciousness: since the use of the sameword consciousness for humans and AI becomes ambiguous and potentiallymisleading, we propose to clearly specify what is common and what differs in AIconscious processing from full human conscious experience.</description><author>Michele Farisco, Kathinka Evers, Jean-Pierre Changeux</author><pubDate>Mon, 29 Jul 2024 17:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04540v2</guid></item><item><title>Global Structure-from-Motion Revisited</title><link>http://arxiv.org/abs/2407.20219v1</link><description>Recovering 3D structure and camera motion from images has been along-standing focus of computer vision research and is known asStructure-from-Motion (SfM). Solutions to this problem are categorized intoincremental and global approaches. Until now, the most popular systems followthe incremental paradigm due to its superior accuracy and robustness, whileglobal approaches are drastically more scalable and efficient. With this work,we revisit the problem of global SfM and propose GLOMAP as a newgeneral-purpose system that outperforms the state of the art in global SfM. Interms of accuracy and robustness, we achieve results on-par or superior toCOLMAP, the most widely used incremental SfM, while being orders of magnitudefaster. We share our system as an open-source implementation at{https://github.com/colmap/glomap}.</description><author>Linfei Pan, Dániel Baráth, Marc Pollefeys, Johannes L. Schönberger</author><pubDate>Mon, 29 Jul 2024 17:54:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20219v1</guid></item><item><title>SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow Prediction</title><link>http://arxiv.org/abs/2407.20214v1</link><description>Graph-based holistic scene representations facilitate surgical workflowunderstanding and have recently demonstrated significant success. However, thistask is often hindered by the limited availability of densely annotatedsurgical scene data. In this work, we introduce an end-to-end framework for thegeneration and optimization of surgical scene graphs on a downstream task. Ourapproach leverages the flexibility of graph-based spectral clustering and thegeneralization capability of foundation models to generate unsupervised scenegraphs with learnable properties. We reinforce the initial spatial graph withsparse temporal connections using local matches between consecutive frames topredict temporally consistent clusters across a temporal neighborhood. Byjointly optimizing the spatiotemporal relations and node features of thedynamic scene graph with the downstream task of phase segmentation, we addressthe costly and annotation-burdensome task of semantic scene comprehension andscene graph generation in surgical videos using only weak surgical phaselabels. Further, by incorporating effective intermediate scene representationdisentanglement steps within the pipeline, our solution outperforms the SOTA onthe CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflowrecognition</description><author>Çağhan Köksal, Ghazal Ghazaei, Felix Holm, Azade Farshad, Nassir Navab</author><pubDate>Mon, 29 Jul 2024 17:44:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20214v1</guid></item><item><title>Registering Neural 4D Gaussians for Endoscopic Surgery</title><link>http://arxiv.org/abs/2407.20213v1</link><description>The recent advance in neural rendering has enabled the ability to reconstructhigh-quality 4D scenes using neural networks. Although 4D neural reconstructionis popular, registration for such representations remains a challenging task,especially for dynamic scene registration in surgical planning and simulation.In this paper, we propose a novel strategy for dynamic surgical neural sceneregistration. We first utilize 4D Gaussian Splatting to represent the surgicalscene and capture both static and dynamic scenes effectively. Then, a spatialaware feature aggregation method, Spatially Weight Cluttering (SWC) is proposedto accurately align the feature between surgical scenes, enabling precise andrealistic surgical simulations. Lastly, we present a novel strategy ofdeformable scene registration to register two dynamic scenes. By incorporatingboth spatial and temporal information for correspondence matching, our approachachieves superior performance compared to existing registration methods forimplicit neural representation. The proposed method has the potential toimprove surgical planning and training, ultimately leading to better patientoutcomes.</description><author>Yiming Huang, Beilei Cui, Ikemura Kei, Jiekai Zhang, Long Bai, Hongliang Ren</author><pubDate>Mon, 29 Jul 2024 17:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20213v1</guid></item><item><title>Characterizing Dynamical Stability of Stochastic Gradient Descent in Overparameterized Learning</title><link>http://arxiv.org/abs/2407.20209v1</link><description>For overparameterized optimization tasks, such as the ones found in modernmachine learning, global minima are generally not unique. In order tounderstand generalization in these settings, it is vital to study to whichminimum an optimization algorithm converges. The possibility of having minimathat are unstable under the dynamics imposed by the optimization algorithmlimits the potential minima that the algorithm can find. In this paper, wecharacterize the global minima that are dynamically stable/unstable for bothdeterministic and stochastic gradient descent (SGD). In particular, weintroduce a characteristic Lyapunov exponent which depends on the localdynamics around a global minimum and rigorously prove that the sign of thisLyapunov exponent determines whether SGD can accumulate at the respectiveglobal minimum.</description><author>Dennis Chemnitz, Maximilian Engel</author><pubDate>Mon, 29 Jul 2024 17:40:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20209v1</guid></item><item><title>Supertrust: Evolution-based superalignment strategy for safe coexistence</title><link>http://arxiv.org/abs/2407.20208v1</link><description>It's widely expected that humanity will someday create AI systems vastly moreintelligent than we are, leading to the unsolved alignment problem of "how tocontrol superintelligence." However, this definition is not onlyself-contradictory but likely unsolvable. Nevertheless, the default strategyfor solving it involves nurturing (post-training) constraints and moral values,while unfortunately building foundational nature (pre-training) on documentedintentions of permanent control. In this paper, the default approach isreasoned to predictably embed natural distrust and test results are presentedthat show unmistakable evidence of this dangerous misalignment. Ifsuperintelligence can't instinctively trust humanity, then we can't fully trustit to reliably follow safety controls it can likely bypass. Therefore, aten-point rationale is presented that redefines the alignment problem as "howto establish protective mutual trust between superintelligence and humanity"and then outlines a new strategy to solve it by aligning through instinctivenature rather than nurture. The resulting strategic requirements are identifiedas building foundational nature by exemplifying familial parent-child trust,human intelligence as the evolutionary mother of superintelligence, moraljudgment abilities, and temporary safety constraints. Adopting and implementingthis proposed Supertrust alignment strategy will lead to protective coexistenceand ensure the safest future for humanity.</description><author>James M. Mazzu</author><pubDate>Mon, 29 Jul 2024 17:39:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20208v1</guid></item><item><title>QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval</title><link>http://arxiv.org/abs/2407.20207v1</link><description>In dense retrieval, embedding long texts into dense vectors can result ininformation loss, leading to inaccurate query-text matching. Additionally,low-quality texts with excessive noise or sparse key information are unlikelyto align well with relevant queries. Recent studies mainly focus on improvingthe sentence embedding model or retrieval process. In this work, we introduce anovel text augmentation framework for dense retrieval. This frameworktransforms raw documents into information-dense text formats, which supplementthe original texts to effectively address the aforementioned issues withoutmodifying embedding or retrieval methodologies. Two text representations aregenerated via large language models (LLMs) zero-shot prompting: question-answerpairs and element-driven events. We term this approach QAEA-DR: unifyingquestion-answer generation and event extraction in a text augmentationframework for dense retrieval. To further enhance the quality of generatedtexts, a scoring-based evaluation and regeneration mechanism is introduced inLLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,supported by both theoretical analysis and empirical experiments.</description><author>Hongming Tan, Shaoxiong Zhan, Hai Lin, Hai-Tao Zheng, Wai Kin, Chan</author><pubDate>Mon, 29 Jul 2024 17:39:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20207v1</guid></item><item><title>Emergence in non-neural models: grokking modular arithmetic via average gradient outer product</title><link>http://arxiv.org/abs/2407.20199v1</link><description>Neural networks trained to solve modular arithmetic tasks exhibit grokking, aphenomenon where the test accuracy starts improving long after the modelachieves 100% training accuracy in the training process. It is often taken asan example of "emergence", where model ability manifests sharply through aphase transition. In this work, we show that the phenomenon of grokking is notspecific to neural networks nor to gradient descent-based optimization.Specifically, we show that this phenomenon occurs when learning modulararithmetic with Recursive Feature Machines (RFM), an iterative algorithm thatuses the Average Gradient Outer Product (AGOP) to enable task-specific featurelearning with general machine learning models. When used in conjunction withkernel machines, iterating RFM results in a fast transition from random, nearzero, test accuracy to perfect test accuracy. This transition cannot bepredicted from the training loss, which is identically zero, nor from the testloss, which remains constant in initial iterations. Instead, as we show, thetransition is completely determined by feature learning: RFM gradually learnsblock-circulant features to solve modular arithmetic. Paralleling the resultsfor RFM, we show that neural networks that solve modular arithmetic also learnblock-circulant features. Furthermore, we present theoretical evidence that RFMuses such block-circulant features to implement the Fourier MultiplicationAlgorithm, which prior work posited as the generalizing solution neuralnetworks learn on these tasks. Our results demonstrate that emergence canresult purely from learning task-relevant features and is not specific toneural architectures nor gradient descent-based optimization methods.Furthermore, our work provides more evidence for AGOP as a key mechanism forfeature learning in neural networks.</description><author>Neil Mallinar, Daniel Beaglehole, Libin Zhu, Adityanarayanan Radhakrishnan, Parthe Pandit, Mikhail Belkin</author><pubDate>Mon, 29 Jul 2024 17:28:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20199v1</guid></item><item><title>SpaER: Learning Spatio-temporal Equivariant Representations for Fetal Brain Motion Tracking</title><link>http://arxiv.org/abs/2407.20198v1</link><description>In this paper, we introduce SpaER, a pioneering method for fetal motiontracking that leverages equivariant filters and self-attention mechanisms toeffectively learn spatio-temporal representations. Different from conventionalapproaches that statically estimate fetal brain motions from pairs of images,our method dynamically tracks the rigid movement patterns of the fetal headacross temporal and spatial dimensions. Specifically, we first develop anequivariant neural network that efficiently learns rigid motion sequencesthrough low-dimensional spatial representations of images. Subsequently, welearn spatio-temporal representations by incorporating time encoding andself-attention neural network layers. This approach allows for the capture oflong-term dependencies of fetal brain motion and addresses alignment errors dueto contrast changes and severe motion artifacts. Our model also provides ageometric deformation estimation that properly addresses image distortionsamong all time frames. To the best of our knowledge, our approach is the firstto learn spatial-temporal representations via deep neural networks for fetalmotion tracking without data augmentation. We validated our model using realfetal echo-planar images with simulated and real motions. Our method carriessignificant potential value in accurately measuring, tracking, and correctingfetal motion in fetal MRI sequences.</description><author>Jian Wang, Razieh Faghihpirayesh, Polina Golland, Ali Ghoulipour</author><pubDate>Mon, 29 Jul 2024 17:24:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20198v1</guid></item><item><title>Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire New Knowledge after Deployment</title><link>http://arxiv.org/abs/2407.20197v1</link><description>In this study, we developed a learning method for constructing a neuralnetwork system capable of memorizing data and recalling it without parameterupdates. The system we built using this method is called the Appendable Memorysystem. The Appendable Memory system enables an artificial intelligence (AI) toacquire new knowledge even after deployment. It consists of two AIs: theMemorizer and the Recaller. This system is a key-value store built using neuralnetworks. The Memorizer receives data and stores it in the Appendable Memoryvector, which is dynamically updated when the AI acquires new knowledge.Meanwhile, the Recaller retrieves information from the Appendable Memoryvector. What we want to teach AI in this study are the operations of memorizingand recalling information. However, traditional machine learning methods makeAI learn features inherent in the learning dataset. We demonstrate that thesystems we intend to create cannot be realized by current machine learningmethods, that is, by merely repeating the input and output learning sequenceswith AI. Instead, we propose a method to teach AI to learn operations, bycompletely removing the features contained in the learning dataset.Specifically, we probabilized all the data involved in learning. This measureprevented AI from learning the features of the data. The learning methodproposed in the study differs from traditional machine learning methods andprovides fundamental approaches for building an AI system that can storeinformation in a finite memory and recall it at a later date.</description><author>Kazunori D Yamada</author><pubDate>Mon, 29 Jul 2024 17:24:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20197v1</guid></item><item><title>The generator gradient estimator is an adjoint state method for stochastic differential equations</title><link>http://arxiv.org/abs/2407.20196v1</link><description>Motivated by the increasing popularity of overparameterized StochasticDifferential Equations (SDEs) like Neural SDEs, Wang, Blanchet and Glynnrecently introduced the generator gradient estimator, a novel unbiasedstochastic gradient estimator for SDEs whose computation time remains stable inthe number of parameters. In this note, we demonstrate that this estimator isin fact an adjoint state method, an approach which is known to scale with thenumber of states and not the number of parameters in the case of OrdinaryDifferential Equations (ODEs). In addition, we show that the generator gradientestimator is a close analogue to the exact Integral Path Algorithm (eIPA)estimator which was introduced by Gupta, Rathinam and Khammash for a class ofContinuous-Time Markov Chains (CTMCs) known as stochastic chemical reactionsnetworks (CRNs).</description><author>Quentin Badolle, Ankit Gupta, Mustafa Khammash</author><pubDate>Mon, 29 Jul 2024 17:21:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20196v1</guid></item><item><title>Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences</title><link>http://arxiv.org/abs/2407.12620v2</link><description>Since 2022 we have been exploring application areas and technologies in whichArtificial Intelligence (AI) and modern Natural Language Processing (NLP), suchas Large Language Models (LLMs), can be employed to foster the usage andfacilitate the documentation of Indigenous languages which are in danger ofdisappearing. We start by discussing the decreasing diversity of languages inthe world and how working with Indigenous languages poses unique ethicalchallenges for AI and NLP. To address those challenges, we propose analternative development AI cycle based on community engagement and usage. Then,we report encouraging results in the development of high-quality machinelearning translators for Indigenous languages by fine-tuning state-of-the-art(SOTA) translators with tiny amounts of data and discuss how to avoid somecommon pitfalls in the process. We also present prototypes we have built inprojects done in 2023 and 2024 with Indigenous communities in Brazil, aimed atfacilitating writing, and discuss the development of Indigenous Language Models(ILMs) as a replicable and scalable way to create spell-checkers, next-wordpredictors, and similar tools. Finally, we discuss how we envision a future forlanguage documentation where dying languages are preserved as interactivelanguage models.</description><author>Claudio Pinhanez, Paulo Cavalin, Luciana Storto, Thomas Finbow, Alexander Cobbinah, Julio Nogima, Marisa Vasconcelos, Pedro Domingues, Priscila de Souza Mizukami, Nicole Grell, Majoí Gongora, Isabel Gonçalves</author><pubDate>Mon, 29 Jul 2024 17:19:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12620v2</guid></item><item><title>Time series forecasting with high stakes: A field study of the air cargo industry</title><link>http://arxiv.org/abs/2407.20192v1</link><description>Time series forecasting in the air cargo industry presents unique challengesdue to volatile market dynamics and the significant impact of accurateforecasts on generated revenue. This paper explores a comprehensive approach todemand forecasting at the origin-destination (O\&amp;D) level, focusing on thedevelopment and implementation of machine learning models in decision-makingfor the air cargo industry. We leverage a mixture of experts framework,combining statistical and advanced deep learning models to provide reliableforecasts for cargo demand over a six-month horizon. The results demonstratethat our approach outperforms industry benchmarks, offering actionable insightsfor cargo capacity allocation and strategic decision-making in the air cargoindustry. While this work is applied in the airline industry, the methodologyis broadly applicable to any field where forecast-based decision-making in avolatile environment is crucial.</description><author>Abhinav Garg, Naman Shukla</author><pubDate>Mon, 29 Jul 2024 17:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20192v1</guid></item><item><title>Prompt Leakage effect and defense strategies for multi-turn LLM interactions</title><link>http://arxiv.org/abs/2404.16251v3</link><description>Prompt leakage poses a compelling security and privacy threat in LLMapplications. Leakage of system prompts may compromise intellectual property,and act as adversarial reconnaissance for an attacker. A systematic evaluationof prompt leakage threats and mitigation strategies is lacking, especially formulti-turn LLM interactions. In this paper, we systematically investigate LLMvulnerabilities against prompt leakage for 10 closed- and open-source LLMs,across four domains. We design a unique threat model which leverages the LLMsycophancy effect and elevates the average attack success rate (ASR) from 17.7%to 86.2% in a multi-turn setting. Our standardized setup further allowsdissecting leakage of specific prompt contents such as task instructions andknowledge documents. We measure the mitigation effect of 7 black-box defensestrategies, along with finetuning an open-source model to defend againstleakage attempts. We present different combination of defenses against ourthreat model, including a cost analysis. Our study highlights key takeaways forbuilding secure LLM applications and provides directions for research inmulti-turn LLM interactions</description><author>Divyansh Agarwal, Alexander R. Fabbri, Ben Risher, Philippe Laban, Shafiq Joty, Chien-Sheng Wu</author><pubDate>Mon, 29 Jul 2024 17:16:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.16251v3</guid></item><item><title>Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search</title><link>http://arxiv.org/abs/2407.20189v1</link><description>Conversational search supports multi-turn user-system interactions to solvecomplex information needs. Different from the traditional single-turn ad-hocsearch, conversational search encounters a more challenging problem ofcontext-dependent query understanding with the lengthy and long-tailconversational history context. While conversational query rewriting methodsleverage explicit rewritten queries to train a rewriting model to transform thecontext-dependent query into a stand-stone search query, this is usually donewithout considering the quality of search results. Conversational denseretrieval methods use fine-tuning to improve a pre-trained ad-hoc queryencoder, but they are limited by the conversational search data available fortraining. In this paper, we leverage both rewritten queries and relevancejudgments in the conversational search data to train a better queryrepresentation model. The key idea is to align the query representation withthose of rewritten queries and relevant documents. The proposed model -- QueryRepresentation Alignment Conversational Dense Retriever, QRACDR, is tested oneight datasets, including various settings in conversational search and ad-hocsearch. The results demonstrate the strong performance of QRACDR compared withstate-of-the-art methods, and confirm the effectiveness of representationalignment.</description><author>Fengran Mo, Chen Qu, Kelong Mao, Yihong Wu, Zhan Su, Kaiyu Huang, Jian-Yun Nie</author><pubDate>Mon, 29 Jul 2024 17:14:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20189v1</guid></item><item><title>MindSearch: Mimicking Human Minds Elicits Deep AI Searcher</title><link>http://arxiv.org/abs/2407.20183v1</link><description>Information seeking and integration is a complex cognitive task that consumesenormous time and effort. Inspired by the remarkable progress of Large LanguageModels, recent works attempt to solve this task by combining LLMs and searchengines. However, these methods still obtain unsatisfying performance due tothree challenges: (1) complex requests often cannot be accurately andcompletely retrieved by the search engine once (2) corresponding information tobe integrated is spread over multiple web pages along with massive noise, and(3) a large number of web pages with long contents may quickly exceed themaximum context length of LLMs. Inspired by the cognitive process when humanssolve these problems, we introduce MindSearch to mimic the human minds in webinformation seeking and integration, which can be instantiated by a simple yeteffective LLM-based multi-agent framework. The WebPlanner models the human mindof multi-step information seeking as a dynamic graph construction process: itdecomposes the user query into atomic sub-questions as nodes in the graph andprogressively extends the graph based on the search result from WebSearcher.Tasked with each sub-question, WebSearcher performs hierarchical informationretrieval with search engines and collects valuable information for WebPlanner.The multi-agent design of MindSearch enables the whole framework to seek andintegrate information parallelly from larger-scale (e.g., more than 300) webpages in 3 minutes, which is worth 3 hours of human effort. MindSearchdemonstrates significant improvement in the response quality in terms of depthand breadth, on both close-set and open-set QA problems. Besides, responsesfrom MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Weband Perplexity.ai applications, which implies that MindSearch can alreadydeliver a competitive solution to the proprietary AI search engine.</description><author>Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, Feng Zhao</author><pubDate>Mon, 29 Jul 2024 17:12:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20183v1</guid></item><item><title>Theia: Distilling Diverse Vision Foundation Models for Robot Learning</title><link>http://arxiv.org/abs/2407.20179v1</link><description>Vision-based robot policy learning, which maps visual inputs to actions,necessitates a holistic understanding of diverse visual tasks beyondsingle-task needs like classification or segmentation. Inspired by this, weintroduce Theia, a vision foundation model for robot learning that distillsmultiple off-the-shelf vision foundation models trained on varied vision tasks.Theia's rich visual representations encode diverse visual knowledge, enhancingdownstream robot learning. Extensive experiments demonstrate that Theiaoutperforms its teacher models and prior robot learning models using lesstraining data and smaller model sizes. Additionally, we quantify the quality ofpre-trained visual representations and hypothesize that higher entropy infeature norm distributions leads to improved robot learning performance. Codeand models are available at https://github.com/bdaiinstitute/theia.</description><author>Jinghuan Shang, Karl Schmeckpeper, Brandon B. May, Maria Vittoria Minniti, Tarik Kelestemur, David Watkins, Laura Herlant</author><pubDate>Mon, 29 Jul 2024 17:08:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20179v1</guid></item><item><title>AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs</title><link>http://arxiv.org/abs/2407.20177v1</link><description>To ensure performance on a diverse set of downstream tasks, LLMs arepretrained via data mixtures over different domains. In this work, wedemonstrate that the optimal data composition for a fixed compute budget variesdepending on the scale of the training data, suggesting that the commonpractice of empirically determining an optimal composition using small-scaleexperiments will not yield the optimal data mixtures when scaling up to thefinal model. To address this challenge, we propose *AutoScale*, an automatedtool that finds a compute-optimal data composition for training at any desiredtarget scale. AutoScale first determines the optimal composition at a smallscale using a novel bilevel optimization framework, Direct Data Optimization(*DDO*), and then fits a predictor to estimate the optimal composition atlarger scales. The predictor's design is inspired by our theoretical analysisof scaling laws related to data composition, which could be of independentinterest. In empirical studies with pre-training 774M Decoder-only LMs (GPT-2Large) on RedPajama dataset, AutoScale decreases validation perplexity at least25% faster than any baseline with up to 38% speed up compared to withoutreweighting, achieving the best overall performance across downstream tasks. Onpre-training Encoder-only LMs (BERT) with masked language modeling, DDO isshown to decrease loss on all domains while visibly improving average taskperformance on GLUE benchmark by 8.7% and on large-scale QA dataset (SQuAD) by5.9% compared with without reweighting. AutoScale speeds up training by up to28%. Our codes are open-sourced.</description><author>Feiyang Kang, Yifan Sun, Bingbing Wen, Si Chen, Dawn Song, Rafid Mahmood, Ruoxi Jia</author><pubDate>Mon, 29 Jul 2024 17:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20177v1</guid></item><item><title>Emotion-Driven Melody Harmonization via Melodic Variation and Functional Representation</title><link>http://arxiv.org/abs/2407.20176v1</link><description>Emotion-driven melody harmonization aims to generate diverse harmonies for asingle melody to convey desired emotions. Previous research found it hard toalter the perceived emotional valence of lead sheets only by harmonizing thesame melody with different chords, which may be attributed to the constraintsimposed by the melody itself and the limitation of existing musicrepresentation. In this paper, we propose a novel functional representation forsymbolic music. This new method takes musical keys into account, recognizingtheir significant role in shaping music's emotional character throughmajor-minor tonality. It also allows for melodic variation with respect to keysand addresses the problem of data scarcity for better emotion modeling. ATransformer is employed to harmonize key-adaptable melodies, allowing for keysdetermined in rule-based or model-based manner. Experimental results confirmthe effectiveness of our new representation in generating key-aware harmonies,with objective and subjective evaluations affirming the potential of ourapproach to convey specific valence for versatile melody.</description><author>Jingyue Huang, Yi-Hsuan Yang</author><pubDate>Mon, 29 Jul 2024 17:05:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20176v1</guid></item><item><title>Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning</title><link>http://arxiv.org/abs/2407.20174v1</link><description>Emerging multimodal large language models (MLLMs) exhibit great potential forchart question answering (CQA). Recent efforts primarily focus on scaling uptraining datasets (i.e., charts, data tables, and question-answer (QA) pairs)through data collection and synthesis. However, our empirical study on existingMLLMs and CQA datasets reveals notable gaps. First, current data collection andsynthesis focus on data volume and lack consideration of fine-grained visualencodings and QA tasks, resulting in unbalanced data distribution divergentfrom practical CQA scenarios. Second, existing work follows the training recipeof the base MLLMs initially designed for natural images, under-exploring theadaptation to unique chart characteristics, such as rich text elements. To fillthe gap, we propose a visualization-referenced instruction tuning approach toguide the training dataset enhancement and model development. Specifically, wepropose a novel data engine to effectively filter diverse and high-quality datafrom existing datasets and subsequently refine and augment the data usingLLM-based generation techniques to better align with practical QA tasks andvisual encodings. Then, to facilitate the adaptation to chart characteristics,we utilize the enriched data to train an MLLM by unfreezing the vision encoderand incorporating a mixture-of-resolution adaptation strategy for enhancedfine-grained recognition. Experimental results validate the effectiveness ofour approach. Even with fewer training examples, our model consistentlyoutperforms state-of-the-art CQA models on established benchmarks. We alsocontribute a dataset split as a benchmark for future research. Source codes anddatasets of this paper are available athttps://github.com/zengxingchen/ChartQA-MLLM.</description><author>Xingchen Zeng, Haichuan Lin, Yilin Ye, Wei Zeng</author><pubDate>Mon, 29 Jul 2024 17:04:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20174v1</guid></item><item><title>LatentArtiFusion: An Effective and Efficient Histological Artifacts Restoration Framework</title><link>http://arxiv.org/abs/2407.20172v1</link><description>Histological artifacts pose challenges for both pathologists andComputer-Aided Diagnosis (CAD) systems, leading to errors in analysis. Currentapproaches for histological artifact restoration, based on GenerativeAdversarial Networks (GANs) and pixel-level Diffusion Models, suffer fromperformance limitations and computational inefficiencies. In this paper, wepropose a novel framework, LatentArtiFusion, which leverages the latentdiffusion model (LDM) to reconstruct histological artifacts with highperformance and computational efficiency. Unlike traditional pixel-leveldiffusion frameworks, LatentArtiFusion executes the restoration process in alower-dimensional latent space, significantly improving computationalefficiency. Moreover, we introduce a novel regional artifact reconstructionalgorithm in latent space to prevent mistransfer in non-artifact regions,distinguishing our approach from GAN-based methods. Through extensiveexperiments on real-world histology datasets, LatentArtiFusion demonstratesremarkable speed, outperforming state-of-the-art pixel-level diffusionframeworks by more than 30X. It also consistently surpasses GAN-based methodsby at least 5% across multiple evaluation metrics. Furthermore, we evaluate theeffectiveness of our proposed framework in downstream tissue classificationtasks, showcasing its practical utility. Code is available athttps://github.com/bugs-creator/LatentArtiFusion.</description><author>Zhenqi He, Wenrui Liu, Minghao Yin, Kai Han</author><pubDate>Mon, 29 Jul 2024 17:00:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20172v1</guid></item><item><title>Diffusion Feedback Helps CLIP See Better</title><link>http://arxiv.org/abs/2407.20171v1</link><description>Contrastive Language-Image Pre-training (CLIP), which excels at abstractingopen-world representations across domains and modalities, has become afoundation for a variety of vision and multimodal tasks. However, recentstudies reveal that CLIP has severe visual shortcomings, such as which canhardly distinguish orientation, quantity, color, structure, etc. These visualshortcomings also limit the perception capabilities of multimodal largelanguage models (MLLMs) built on CLIP. The main reason could be that theimage-text pairs used to train CLIP are inherently biased, due to the lack ofthe distinctiveness of the text and the diversity of images. In this work, wepresent a simple post-training approach for CLIP models, which largelyovercomes its visual shortcomings via a self-supervised diffusion process. Weintroduce DIVA, which uses the DIffusion model as a Visual Assistant for CLIP.Specifically, DIVA leverages generative feedback from text-to-image diffusionmodels to optimize CLIP representations, with only images (withoutcorresponding text). We demonstrate that DIVA improves CLIP's performance onthe challenging MMVP-VLM benchmark which assesses fine-grained visual abilitiesto a large extent (e.g., 3-7%), and enhances the performance of MLLMs andvision models on multimodal understanding and segmentation tasks. Extensiveevaluation on 29 image classification and retrieval benchmarks confirms thatour framework preserves CLIP's strong zero-shot capabilities. The code will beavailable at https://github.com/baaivision/DIVA.</description><author>Wenxuan Wang, Quan Sun, Fan Zhang, Yepeng Tang, Jing Liu, Xinlong Wang</author><pubDate>Mon, 29 Jul 2024 17:00:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20171v1</guid></item><item><title>DCEM: A deep complementary energy method for solid mechanics</title><link>http://arxiv.org/abs/2302.01538v7</link><description>In recent years, the rapid advancement of deep learning has significantlyimpacted various fields, particularly in solving partial differential equations(PDEs) in the realm of solid mechanics, benefiting greatly from the remarkableapproximation capabilities of neural networks. In solving PDEs,Physics-Informed Neural Networks (PINNs) and the Deep Energy Method (DEM) havegarnered substantial attention. The principle of minimum potential energy andcomplementary energy are two important variational principles in solidmechanics. However, the well-known Deep Energy Method (DEM) is based on theprinciple of minimum potential energy, but there lacks the important form ofminimum complementary energy. To bridge this gap, we propose the deepcomplementary energy method (DCEM) based on the principle of minimumcomplementary energy. The output function of DCEM is the stress function, whichinherently satisfies the equilibrium equation. We present numerical resultsusing the Prandtl and Airy stress functions, and compare DCEM with existingPINNs and DEM algorithms when modeling representative mechanical problems. Theresults demonstrate that DCEM outperforms DEM in terms of stress accuracy andefficiency and has an advantage in dealing with complex displacement boundaryconditions, which is supported by theoretical analyses and numericalsimulations. We extend DCEM to DCEM-Plus (DCEM-P), adding terms that satisfypartial differential equations. Furthermore, we propose a deep complementaryenergy operator method (DCEM-O) by combining operator learning with physicalequations. Initially, we train DCEM-O using high-fidelity numerical results andthen incorporate complementary energy. DCEM-P and DCEM-O further enhance theaccuracy and efficiency of DCEM.</description><author>Yizheng Wang, Jia Sun, Timon Rabczuk, Yinghua Liu</author><pubDate>Mon, 29 Jul 2024 16:55:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01538v7</guid></item><item><title>Node Similarities under Random Projections: Limits and Pathological Cases</title><link>http://arxiv.org/abs/2404.10148v2</link><description>Random Projections have been widely used to generate embeddings for variousgraph learning tasks due to their computational efficiency. The majority ofapplications have been justified through the Johnson-Lindenstrauss Lemma. Inthis paper, we take a step further and investigate how well dot product andcosine similarity are preserved by random projections when these are appliedover the rows of the graph matrix. Our analysis provides new asymptotic andfinite-sample results, identifies pathological cases, and tests them withnumerical experiments. We specialize our fundamental results to a rankingapplication by computing the probability of random projections flipping thenode ordering induced by their embeddings. We find that, depending on thedegree distribution, the method produces especially unreliable embeddings forthe dot product, regardless of whether the adjacency or the normalizedtransition matrix is used. With respect to the statistical noise introduced byrandom projections, we show that cosine similarity produces remarkably moreprecise approximations.</description><author>Tvrtko Tadić, Cassiano Becker, Jennifer Neville</author><pubDate>Mon, 29 Jul 2024 16:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10148v2</guid></item><item><title>Language-Conditioned Offline RL for Multi-Robot Navigation</title><link>http://arxiv.org/abs/2407.20164v1</link><description>We present a method for developing navigation policies for multi-robot teamsthat interpret and follow natural language instructions. We condition thesepolicies on embeddings from pretrained Large Language Models (LLMs), and trainthem via offline reinforcement learning with as little as 20 minutes ofrandomly-collected data. Experiments on a team of five real robots show thatthese policies generalize well to unseen commands, indicating an understandingof the LLM latent space. Our method requires no simulators or environmentmodels, and produces low-latency control policies that can be deployed directlyto real robots without finetuning. We provide videos of our experiments athttps://sites.google.com/view/llm-marl.</description><author>Steven Morad, Ajay Shankar, Jan Blumenkamp, Amanda Prorok</author><pubDate>Mon, 29 Jul 2024 16:49:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20164v1</guid></item><item><title>Machine Learning for predicting chaotic systems</title><link>http://arxiv.org/abs/2407.20158v1</link><description>Predicting chaotic dynamical systems is critical in many scientific fieldssuch as weather prediction, but challenging due to the characterizing sensitivedependence on initial conditions. Traditional modeling approaches requireextensive domain knowledge, often leading to a shift towards data-drivenmethods using machine learning. However, existing research providesinconclusive results on which machine learning methods are best suited forpredicting chaotic systems. In this paper, we compare different lightweight andheavyweight machine learning architectures using extensive existing databases,as well as a newly introduced one that allows for uncertainty quantification inthe benchmark results. We perform hyperparameter tuning based on computationalcost and introduce a novel error metric, the cumulative maximum error, whichcombines several desirable properties of traditional metrics, tailored forchaotic systems. Our results show that well-tuned simple methods, as well asuntuned baseline methods, often outperform state-of-the-art deep learningmodels, but their performance can vary significantly with differentexperimental setups. These findings underscore the importance of matchingprediction methods to data characteristics and available computationalresources.</description><author>Christof Schötz, Alistair White, Maximilian Gelbrecht, Niklas Boers</author><pubDate>Mon, 29 Jul 2024 16:34:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20158v1</guid></item><item><title>rLLM: Relational Table Learning with LLMs</title><link>http://arxiv.org/abs/2407.20157v1</link><description>We introduce rLLM (relationLLM), a PyTorch library designed for RelationalTable Learning (RTL) with Large Language Models (LLMs). The core idea is todecompose state-of-the-art Graph Neural Networks, LLMs, and Table NeuralNetworks into standardized modules, to enable the fast construction of novelRTL-type models in a simple "combine, align, and co-train" manner. Toillustrate the usage of rLLM, we introduce a simple RTL method named\textbf{BRIDGE}. Additionally, we present three novel relational tabulardatasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hoperLLM can serve as a useful and easy-to-use development framework forRTL-related tasks. Our code is available at:https://github.com/rllm-project/rllm.</description><author>Weichen Li, Xiaotong Huang, Jianwu Zheng, Zheng Wang, Chaokun Wang, Li Pan, Jianhua Li</author><pubDate>Mon, 29 Jul 2024 16:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20157v1</guid></item><item><title>Selection for short-term empowerment accelerates the evolution of homeostatic neural cellular automata</title><link>http://arxiv.org/abs/2305.15220v2</link><description>Empowerment -- a domain independent, information-theoretic metric -- haspreviously been shown to assist in the evolutionary search for neural cellularautomata (NCA) capable of homeostasis when employed as a fitness function. Inour previous study, we successfully extended empowerment, defined as maximumtime-lagged mutual information between agents' actions and future sensations,to a distributed sensorimotor system embodied as an NCA. However, thetime-delay between actions and their corresponding sensations was arbitrarilychosen. Here, we expand upon previous work by exploring how the time scale atwhich empowerment operates impacts its efficacy as an auxiliary objective toaccelerate the discovery of homeostatic NCAs. We show that shorter time delaysresult in marked improvements over empowerment with longer delays, whencompared to evolutionary selection only for homeostasis. Moreover, we evaluatestability and adaptability of evolved NCAs, both hallmarks of living systemsthat are of interest to replicate in artificial ones. We find that short-termempowered NCA are more stable and are capable of generalizing better to unseenhomeostatic challenges. Taken together, these findings motivate the use ofempowerment during the evolution of other artifacts, and suggest how it shouldbe incorporated to accelerate evolution of desired behaviors for them. Sourcecode for the experiments in this paper can be found at:https://github.com/caitlingrasso/empowered-nca-II.</description><author>Caitlin Grasso, Josh Bongard</author><pubDate>Mon, 29 Jul 2024 16:30:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15220v2</guid></item><item><title>Large Language Models as Carriers of Hidden Messages</title><link>http://arxiv.org/abs/2406.02481v2</link><description>With the help of simple fine-tuning, one can artificially embed hidden textinto large language models (LLMs). This text is revealed only when triggered bya specific query to the LLM. Two primary applications are LLM fingerprintingand steganography. In the context of LLM fingerprinting, a unique textidentifier (fingerprint) is embedded within the model to verify licensingcompliance. In the context of steganography, the LLM serves as a carrier forhidden messages that can be disclosed through a chosen trigger question. Our work demonstrates that embedding hidden text in the LLM via fine-tuning,though seemingly secure due to the vast number of potential triggers (anysequence of characters or tokens could serve as a trigger), is susceptible toextraction through analysis of the LLM's output decoding process. We propose anextraction attack called Unconditional Token Forcing (UTF). It is premised onthe hypothesis that iteratively feeding each token from the LLM's vocabularyinto the model should reveal output sequences with abnormally high tokenprobabilities, indicating potential hidden text candidates. We also present adefense method to hide text in such a way that it is resistant to both UTF andattacks based on sampling decoding methods, which we named Unconditional TokenForcing Confusion (UTFC). To the best of our knowledge, there is no attackmethod that can extract text hidden with UTFC. UTFC has both benignapplications (improving LLM fingerprinting) and malign applications (using LLMsto create covert communication channels). Code is available atgithub.com/j-hoscilowic/zurek-stegano</description><author>Jakub Hoscilowicz, Pawel Popiolek, Jan Rudkowski, Jedrzej Bieniasz, Artur Janicki</author><pubDate>Mon, 29 Jul 2024 16:30:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02481v2</guid></item><item><title>Not Just Streaks: Towards Ground Truth for Single Image Deraining</title><link>http://arxiv.org/abs/2206.10779v3</link><description>We propose a large-scale dataset of real-world rainy and clean image pairsand a method to remove degradations, induced by rain streaks and rainaccumulation, from the image. As there exists no real-world dataset forderaining, current state-of-the-art methods rely on synthetic data and thus arelimited by the sim2real domain gap; moreover, rigorous evaluation remains achallenge due to the absence of a real paired dataset. We fill this gap bycollecting a real paired deraining dataset through meticulous control ofnon-rain variations. Our dataset enables paired training and quantitativeevaluation for diverse real-world rain phenomena (e.g. rain streaks and rainaccumulation). To learn a representation robust to rain phenomena, we propose adeep neural network that reconstructs the underlying scene by minimizing arain-robust loss between rainy and clean images. Extensive experimentsdemonstrate that our model outperforms the state-of-the-art deraining methodson real rainy images under various conditions. Project website:https://visual.ee.ucla.edu/gt_rain.htm/.</description><author>Yunhao Ba, Howard Zhang, Ethan Yang, Akira Suzuki, Arnold Pfahnl, Chethan Chinder Chandrappa, Celso de Melo, Suya You, Stefano Soatto, Alex Wong, Achuta Kadambi</author><pubDate>Mon, 29 Jul 2024 16:28:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.10779v3</guid></item><item><title>Hierarchically Disentangled Recurrent Network for Factorizing System Dynamics of Multi-scale Systems</title><link>http://arxiv.org/abs/2407.20152v1</link><description>We present a knowledge-guided machine learning (KGML) framework for modelingmulti-scale processes, and study its performance in the context of streamflowforecasting in hydrology. Specifically, we propose a novel hierarchicalrecurrent neural architecture that factorizes the system dynamics at multipletemporal scales and captures their interactions. This framework consists of aninverse and a forward model. The inverse model is used to empirically resolvethe system's temporal modes from data (physical model simulations, observeddata, or a combination of them from the past), and these states are then usedin the forward model to predict streamflow. In a hydrological system, thesemodes can represent different processes, evolving at different temporal scales(e.g., slow: groundwater recharge and baseflow vs. fast: surface runoff due toextreme rainfall). A key advantage of our framework is that once trained, itcan incorporate new observations into the model's context (internal state)without expensive optimization approaches (e.g., EnKF) that are traditionallyused in physical sciences for data assimilation. Experiments with several rivercatchments from the NWS NCRFC region show the efficacy of this ML-based dataassimilation framework compared to standard baselines, especially for basinsthat have a long history of observations. Even for basins that have a shorterobservation history, we present two orthogonal strategies of training our FHNNframework: (a) using simulation data from imperfect simulations and (b) usingobservation data from multiple basins to build a global model. We show thatboth of these strategies (that can be used individually or together) are highlyeffective in mitigating the lack of training data. The improvement in forecastaccuracy is particularly noteworthy for basins where local models performpoorly because of data sparsity.</description><author>Rahul Ghosh, Zac McEachran, Arvind Renganathan, Kelly Lindsay, Somya Sharma, Michael Steinbach, John Nieber, Christopher Duffy, Vipin Kumar</author><pubDate>Mon, 29 Jul 2024 16:25:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20152v1</guid></item><item><title>Identifying macro conditional independencies and macro total effects in summary causal graphs with latent confounding</title><link>http://arxiv.org/abs/2407.07934v3</link><description>Understanding causal relations in dynamic systems is essential inepidemiology. While causal inference methods have been extensively studied,they often rely on fully specified causal graphs, which may not always beavailable in complex dynamic systems. Partially specified causal graphs, suchas summary causal graphs (SCGs), provide a simplified representation of causalrelations, omitting temporal information and focusing on high-level causalstructures. This simplification introduces new challenges concerning the typesof queries of interest: macro queries, which involve relationships betweenclusters represented as vertices in the graph, and micro queries, which pertainto relationships between variables that are not directly visible through thevertices of the graph. In this paper, we first clearly distinguish betweenmacro conditional independencies and micro conditional independencies andbetween macro total effects and micro total effects. Then, we demonstrate thesoundness and completeness of the d-separation to identify macro conditionalindependencies in SCGs. Furthermore, we establish that the do-calculus is soundand complete for identifying macro total effects in SCGs. Finally, we give agraphical characterization for the non-identifiability of macro total effectsin SCGs.</description><author>Simon Ferreira, Charles K. Assaad</author><pubDate>Mon, 29 Jul 2024 16:24:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07934v3</guid></item><item><title>Quantum Machine Learning Architecture Search via Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2407.20147v1</link><description>The rapid advancement of quantum computing (QC) and machine learning (ML) hasgiven rise to the burgeoning field of quantum machine learning (QML), aiming tocapitalize on the strengths of quantum computing to propel ML forward. Despiteits promise, crafting effective QML models necessitates profound expertise tostrike a delicate balance between model intricacy and feasibility on NoisyIntermediate-Scale Quantum (NISQ) devices. While complex models offer robustrepresentation capabilities, their extensive circuit depth may impede seamlessexecution on extant noisy quantum platforms. In this paper, we address thisquandary of QML model design by employing deep reinforcement learning toexplore proficient QML model architectures tailored for designated supervisedlearning tasks. Specifically, our methodology involves training an RL agent todevise policies that facilitate the discovery of QML models withoutpredetermined ansatz. Furthermore, we integrate an adaptive mechanism todynamically adjust the learning objectives, fostering continuous improvement inthe agent's learning process. Through extensive numerical simulations, weillustrate the efficacy of our approach within the realm of classificationtasks. Our proposed method successfully identifies VQC architectures capable ofachieving high classification accuracy while minimizing gate depth. Thispioneering approach not only advances the study of AI-driven quantum circuitdesign but also holds significant promise for enhancing performance in the NISQera.</description><author>Xin Dai, Tzu-Chieh Wei, Shinjae Yoo, Samuel Yen-Chi Chen</author><pubDate>Mon, 29 Jul 2024 16:20:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20147v1</guid></item><item><title>ByteCheckpoint: A Unified Checkpointing System for LLM Development</title><link>http://arxiv.org/abs/2407.20143v1</link><description>The development of real-world Large Language Models (LLMs) necessitatescheckpointing of training states in persistent storage to mitigate potentialsoftware and hardware failures, as well as to facilitate checkpointtransferring within the training pipeline and across various tasks. Due to theimmense size of LLMs, saving and loading checkpoints often incur intolerableminute-level stalls, significantly diminishing training efficiency. Besides,when transferring checkpoints across tasks, checkpoint resharding, defined asloading checkpoints into parallel configurations differing from those used forsaving, is often required according to the characteristics and resource quotaof specific tasks. Previous checkpointing systems [16,3,33,6] assume consistentparallel configurations, failing to address the complexities of checkpointtransformation during resharding. Furthermore, in the industry platform,developers create checkpoints from different training frameworks[23,36,21,11],each with its own unique storage and I/O logic. This diversity complicates theimplementation of unified checkpoint management and optimization. To addressthese challenges, we introduce ByteCheckpoint, a PyTorch-native multi-frameworkLLM checkpointing system that supports automatic online checkpoint resharding.ByteCheckpoint employs a data/metadata disaggregated storage architecture,decoupling checkpoint storage from the adopted parallelism strategies andtraining frameworks. We design an efficient asynchronous tensor mergingtechnique to settle the irregular tensor sharding problem and propose severalI/O performance optimizations to significantly enhance the efficiency ofcheckpoint saving and loading. Experimental results demonstrateByteCheckpoint's substantial advantages in reducing checkpoint saving (by up to529.22X) and loading (by up to 3.51X) costs, compared to baseline methods.</description><author>Borui Wan, Mingji Han, Yiyao Sheng, Zhichao Lai, Mofan Zhang, Junda Zhang, Yanghua Peng, Haibin Lin, Xin Liu, Chuan Wu</author><pubDate>Mon, 29 Jul 2024 16:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20143v1</guid></item><item><title>Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu Search</title><link>http://arxiv.org/abs/2311.03583v2</link><description>This work studies a central extremal graph theory problem inspired by a 1975conjecture of Erd\H{o}s, which aims to find graphs with a given size (number ofnodes) that maximize the number of edges without having 3- or 4-cycles. Weformulate this problem as a sequential decision-making problem and compareAlphaZero, a neural network-guided tree search, with tabu search, a heuristiclocal search method. Using either method, by introducing a curriculum --jump-starting the search for larger graphs using good graphs found at smallersizes -- we improve the state-of-the-art lower bounds for several sizes. Wealso propose a flexible graph-generation environment and apermutation-invariant network architecture for learning to search in the spaceof graphs.</description><author>Abbas Mehrabian, Ankit Anand, Hyunjik Kim, Nicolas Sonnerat, Matej Balog, Gheorghe Comanici, Tudor Berariu, Andrew Lee, Anian Ruoss, Anna Bulanova, Daniel Toyama, Sam Blackwell, Bernardino Romera Paredes, Petar Veličković, Laurent Orseau, Joonkyung Lee, Anurag Murty Naredla, Doina Precup, Adam Zsolt Wagner</author><pubDate>Mon, 29 Jul 2024 16:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03583v2</guid></item><item><title>DDAP: Dual-Domain Anti-Personalization against Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2407.20141v1</link><description>Diffusion-based personalized visual content generation technologies haveachieved significant breakthroughs, allowing for the creation of specificobjects by just learning from a few reference photos. However, when misused tofabricate fake news or unsettling content targeting individuals, thesetechnologies could cause considerable societal harm. To address this problem,current methods generate adversarial samples by adversarially maximizing thetraining loss, thereby disrupting the output of any personalized generationmodel trained with these samples. However, the existing methods fail to achieveeffective defense and maintain stealthiness, as they overlook the intrinsicproperties of diffusion models. In this paper, we introduce a novel Dual-DomainAnti-Personalization framework (DDAP). Specifically, we have developed SpatialPerturbation Learning (SPL) by exploiting the fixed and perturbation-sensitivenature of the image encoder in personalized generation. Subsequently, we havedesigned a Frequency Perturbation Learning (FPL) method that utilizes thecharacteristics of diffusion models in the frequency domain. The SPL disruptsthe overall texture of the generated images, while the FPL focuses on imagedetails. By alternating between these two methods, we construct the DDAPframework, effectively harnessing the strengths of both domains. To furtherenhance the visual quality of the adversarial samples, we design a localizationmodule to accurately capture attentive areas while ensuring the effectivenessof the attack and avoiding unnecessary disturbances in the background.Extensive experiments on facial benchmarks have shown that the proposed DDAPenhances the disruption of personalized generation models while alsomaintaining high quality in adversarial samples, making it more effective inprotecting privacy in practical applications.</description><author>Jing Yang, Runping Xi, Yingxin Lai, Xun Lin, Zitong Yu</author><pubDate>Mon, 29 Jul 2024 16:11:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20141v1</guid></item><item><title>To accept or not to accept? An IRT-TOE Framework to Understand Educators' Resistance to Generative AI in Higher Education</title><link>http://arxiv.org/abs/2407.20130v1</link><description>Since the public release of Chat Generative Pre-Trained Transformer(ChatGPT), extensive discourse has emerged concerning the potential advantagesand challenges of integrating Generative Artificial Intelligence (GenAI) intoeducation. In the realm of information systems, research on technology adoptionis crucial for understanding the diverse factors influencing the uptake ofspecific technologies. Theoretical frameworks, refined and validated overdecades, serve as guiding tools to elucidate the individual and organizationaldynamics, obstacles, and perceptions surrounding technology adoption. However,while several models have been proposed, they often prioritize elucidating thefactors that facilitate acceptance over those that impede it, typicallyfocusing on the student perspective and leaving a gap in empirical evidenceregarding educators viewpoints. Given the pivotal role educators play in highereducation, this study aims to develop a theoretical model to empiricallypredict the barriers preventing educators from adopting GenAI in theirclassrooms. Acknowledging the lack of theoretical models tailored toidentifying such barriers, our approach is grounded in the InnovationResistance Theory (IRT) framework and augmented with constructs from theTechnology-Organization-Environment (TOE) framework. This model is transformedinto a measurement instrument employing a quantitative approach, complementedby a qualitative approach to enrich the analysis and uncover concerns relatedto GenAI adoption in the higher education domain.</description><author>Jan-Erik Kalmus, Anastasija Nikiforova</author><pubDate>Mon, 29 Jul 2024 15:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20130v1</guid></item><item><title>Frame Interpolation with Consecutive Brownian Bridge Diffusion</title><link>http://arxiv.org/abs/2405.05953v3</link><description>Recent work in Video Frame Interpolation (VFI) tries to formulate VFI as adiffusion-based conditional image generation problem, synthesizing theintermediate frame given a random noise and neighboring frames. Due to therelatively high resolution of videos, Latent Diffusion Models (LDMs) areemployed as the conditional generation model, where the autoencoder compressesimages into latent representations for diffusion and then reconstructs imagesfrom these latent representations. Such a formulation poses a crucialchallenge: VFI expects that the output is deterministically equal to the groundtruth intermediate frame, but LDMs randomly generate a diverse set of differentimages when the model runs multiple times. The reason for the diversegeneration is that the cumulative variance (variance accumulated at each stepof generation) of generated latent representations in LDMs is large. This makesthe sampling trajectory random, resulting in diverse rather than deterministicgenerations. To address this problem, we propose our unique solution: FrameInterpolation with Consecutive Brownian Bridge Diffusion. Specifically, wepropose consecutive Brownian Bridge diffusion that takes a deterministicinitial value as input, resulting in a much smaller cumulative variance ofgenerated latent representations. Our experiments suggest that our method canimprove together with the improvement of the autoencoder and achievestate-of-the-art performance in VFI, leaving strong potential for furtherenhancement.</description><author>Zonglin Lyu, Ming Li, Jianbo Jiao, Chen Chen</author><pubDate>Mon, 29 Jul 2024 15:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05953v3</guid></item><item><title>Finite-Sample Guarantees for Best-Response Learning Dynamics in Zero-Sum Matrix Games</title><link>http://arxiv.org/abs/2407.20128v1</link><description>We study best-response type learning dynamics for two player zero-sum matrixgames. We consider two settings that are distinguished by the type ofinformation that each player has about the game and their opponent's strategy.The first setting is the full information case, in which each player knowstheir own and the opponent's payoff matrices and observes the opponent's mixedstrategy. The second setting is the minimal information case, where players donot observe the opponent's strategy and are not aware of either of the payoffmatrices (instead they only observe their realized payoffs). For this setting,also known as the radically uncoupled case in the learning in games literature,we study a two-timescale learning dynamics that combine smoothed best-responsetype updates for strategy estimates with a TD-learning update to estimate alocal payoff function. For these dynamics, without additional exploration, weprovide polynomial-time finite-sample guarantees for convergence to an$\epsilon$-Nash equilibrium.</description><author>Fathima Zarin Faizal, Asuman Ozdaglar, Martin J. Wainwright</author><pubDate>Mon, 29 Jul 2024 15:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20128v1</guid></item><item><title>Extreme time extrapolation capabilities and thermodynamic consistency of physics-inspired Neural Networks for the 3D microstructure evolution of materials</title><link>http://arxiv.org/abs/2407.20126v1</link><description>A Convolutional Recurrent Neural Network (CRNN) is trained to reproduce theevolution of the spinodal decomposition process in three dimensions asdescribed by the Cahn-Hilliard equation. A specialized, physics-inspiredarchitecture is proven to provide close accordance between the predictedevolutions and the ground truth ones obtained via conventional integrationschemes. The method can closely reproduce the evolution of microstructures notrepresented in the training set at a fraction of the computational costs.Extremely long-time extrapolation capabilities are achieved, up to reaching thetheoretically expected equilibrium state of the system, despite the trainingset containing only relatively-short, initial phases of the evolution.Quantitative accordance with the decay rate of the Free energy is alsodemonstrated up to late coarsening stages, providing an example of adata-driven, physically consistent and high-accuracy Machine Learning methodfor the long timescale simulation of materials.</description><author>Daniele Lanzoni, Andrea Fantasia, Roberto Bergamaschini, Olivier Pierre-Louis, Francesco Montalenti</author><pubDate>Mon, 29 Jul 2024 15:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20126v1</guid></item><item><title>AxiomVision: Accuracy-Guaranteed Adaptive Visual Model Selection for Perspective-Aware Video Analytics</title><link>http://arxiv.org/abs/2407.20124v1</link><description>The rapid evolution of multimedia and computer vision technologies requiresadaptive visual model deployment strategies to effectively handle diverse tasksand varying environments. This work introduces AxiomVision, a novel frameworkthat can guarantee accuracy by leveraging edge computing to dynamically selectthe most efficient visual models for video analytics under diverse scenarios.Utilizing a tiered edge-cloud architecture, AxiomVision enables the deploymentof a broad spectrum of visual models, from lightweight to complex DNNs, thatcan be tailored to specific scenarios while considering camera source impacts.In addition, AxiomVision provides three core innovations: (1) a dynamic visualmodel selection mechanism utilizing continual online learning, (2) an efficientonline method that efficiently takes into account the influence of the camera'sperspective, and (3) a topology-driven grouping approach that accelerates themodel selection process. With rigorous theoretical guarantees, theseadvancements provide a scalable and effective solution for visual tasksinherent to multimedia systems, such as object detection, classification, andcounting. Empirically, AxiomVision achieves a 25.7\% improvement in accuracy.</description><author>Xiangxiang Dai, Zeyu Zhang, Peng Yang, Yuedong Xu, Xutong Liu, John C. S. Lui</author><pubDate>Mon, 29 Jul 2024 15:54:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20124v1</guid></item><item><title>Tightening the Evaluation of PAC Bounds Using Formal Verification Results</title><link>http://arxiv.org/abs/2407.20122v1</link><description>Probably Approximately Correct (PAC) bounds are widely used to deriveprobabilistic guarantees for the generalisation of machine learning models.They highlight the components of the model which contribute to itsgeneralisation capacity. However, current state-of-the-art results are loose inapproximating the generalisation capacity of deployed machine learning models.Consequently, while PAC bounds are theoretically useful, their applicabilityfor evaluating a model's generalisation property in a given operational designdomain is limited. The underlying classical theory is supported by the ideathat bounds can be tightened when the number of test points available to theuser to evaluate the model increases. Yet, in the case of neural networks, thenumber of test points required to obtain bounds of interest is oftenimpractical even for small problems. In this paper, we take the novel approach of using the formal verification ofneural systems to inform the evaluation of PAC bounds. Rather than usingpointwise information obtained from repeated tests, we use verification resultson regions around test points. We show that conditioning existing bounds onverification results leads to a tightening proportional to the underlyingprobability mass of the verified region.</description><author>Thomas Walker, Alessio Lomuscio</author><pubDate>Mon, 29 Jul 2024 15:53:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20122v1</guid></item><item><title>Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes</title><link>http://arxiv.org/abs/2309.00237v4</link><description>The development of large language models tailored for handling patients'clinical notes is often hindered by the limited accessibility and usability ofthese notes due to strict privacy regulations. To address these challenges, wefirst create synthetic large-scale clinical notes using publicly available casereports extracted from biomedical literature. We then use these synthetic notesto train our specialized clinical large language model, Asclepius. WhileAsclepius is trained on synthetic data, we assess its potential performance inreal-world applications by evaluating it using real clinical notes. Webenchmark Asclepius against several other large language models, includingGPT-3.5-turbo and other open-source alternatives. To further validate ourapproach using synthetic notes, we also compare Asclepius with its variantstrained on real clinical notes. Our findings convincingly demonstrate thatsynthetic clinical notes can serve as viable substitutes for real ones whenconstructing high-performing clinical language models. This conclusion issupported by detailed evaluations conducted by both GPT-4 and medicalprofessionals. All resources including weights, codes, and data used in thedevelopment of Asclepius are made publicly accessible for future research.(https://github.com/starmpcc/Asclepius)</description><author>Sunjun Kweon, Junu Kim, Jiyoun Kim, Sujeong Im, Eunbyeol Cho, Seongsu Bae, Jungwoo Oh, Gyubok Lee, Jong Hak Moon, Seng Chan You, Seungjin Baek, Chang Hoon Han, Yoon Bin Jung, Yohan Jo, Edward Choi</author><pubDate>Mon, 29 Jul 2024 15:52:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00237v4</guid></item><item><title>EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation</title><link>http://arxiv.org/abs/2407.20121v1</link><description>Cross-domain recommendation has attracted substantial interest in industrialapps such as Meituan, which serves multiple business domains via knowledgetransfer and meets the diverse interests of users. However, existing methodstypically follow an implicit modeling paradigm that blends the knowledge fromboth the source and target domains, and design intricate network structures toshare learned embeddings or patterns between domains to improve recommendationaccuracy. Since the transfer of interest signals is unsupervised, theseimplicit paradigms often struggle with the negative transfer resulting fromdifferences in service functions and presentation forms across differentdomains. In this paper, we propose a simple and effective EXplicit InterestTransfer framework named EXIT to address the stated challenge. Specifically, wepropose a novel label combination approach that enables the model to directlylearn beneficial source domain interests through supervised learning, whileexcluding inappropriate interest signals. Moreover, we introduce a sceneselector network to model the interest transfer intensity under fine-grainedscenes. Offline experiments conducted on the industrial production dataset andonline A/B tests validate the superiority and effectiveness of our proposedframework. Without complex network structures or training processes, EXIT canbe easily deployed in the industrial recommendation system. EXIT has beensuccessfully deployed in the online homepage recommendation system of MeituanApp, serving the main traffic.</description><author>Lei Huang, Weitao Li, Chenrui Zhang, Jinpeng Wang, Xianchun Yi, Sheng Chen</author><pubDate>Mon, 29 Jul 2024 15:52:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20121v1</guid></item><item><title>Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number</title><link>http://arxiv.org/abs/2407.20119v1</link><description>We introduce a novel self-supervised deep clustering approach tailored forunstructured data without requiring prior knowledge of the number of clusters,termed Adaptive Self-supervised Robust Clustering (ASRC). In particular, ASRCadaptively learns the graph structure and edge weights to capture both localand global structural information. The obtained graph enables us to learnclustering-friendly feature representations by an enhanced graph auto-encoderwith contrastive learning technique. It further leverages the clusteringresults adaptively obtained by robust continuous clustering (RCC) to generateprototypes for negative sampling, which can further contribute to promotingconsistency among positive pairs and enlarging the gap between positive andnegative samples. ASRC obtains the final clustering results by applying RCC tothe learned feature representations with their consistent graph structure andedge weights. Extensive experiments conducted on seven benchmark datasetsdemonstrate the efficacy of ASRC, demonstrating its superior performance overother popular clustering models. Notably, ASRC even outperforms methods thatrely on prior knowledge of the number of clusters, highlighting itseffectiveness in addressing the challenges of clustering unstructured data.</description><author>Chen-Lu Ding, Jiancan Wu, Wei Lin, Shiyang Shen, Xiang Wang, Yancheng Yuan</author><pubDate>Mon, 29 Jul 2024 15:51:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20119v1</guid></item><item><title>Surpassing Cosine Similarity for Multidimensional Comparisons: Dimension Insensitive Euclidean Metric (DIEM)</title><link>http://arxiv.org/abs/2407.08623v2</link><description>The advancement in computational power and hardware efficiency enabled thetackling of increasingly complex and high-dimensional problems. Whileartificial intelligence (AI) achieved remarkable results, the interpretabilityof high-dimensional solutions remains challenging. A critical issue is thecomparison of multidimensional quantities, which is essential in techniqueslike Principal Component Analysis (PCA), or k-means clustering. Common metricssuch as cosine similarity, Euclidean distance, and Manhattan distance are oftenused for such comparisons - for example in muscular synergies of the humanmotor control system. However, their applicability and interpretabilitydiminish as dimensionality increases. This paper provides a comprehensiveanalysis of the effects of dimensionality on these metrics. Our results revealsignificant limitations of cosine similarity, particularly its dependency onthe dimensionality of the vectors, leading to biased and less interpretableoutcomes. To address this, we introduce the Dimension Insensitive EuclideanMetric (DIEM) which demonstrates superior robustness and generalizabilityacross dimensions. DIEM maintains consistent variability and eliminates thebiases observed in traditional metrics, making it a reliable tool forhigh-dimensional comparisons. This novel metric has the potential to replacecosine similarity, providing a more accurate and insightful method to analyzemultidimensional data in fields ranging from neuromotor control to machine anddeep learning.</description><author>Federico Tessari, Neville Hogan</author><pubDate>Mon, 29 Jul 2024 15:49:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08623v2</guid></item><item><title>FiCo-ITR: bridging fine-grained and coarse-grained image-text retrieval for comparative performance analysis</title><link>http://arxiv.org/abs/2407.20114v1</link><description>In the field of Image-Text Retrieval (ITR), recent advancements haveleveraged large-scale Vision-Language Pretraining (VLP) for Fine-Grained (FG)instance-level retrieval, achieving high accuracy at the cost of increasedcomputational complexity. For Coarse-Grained (CG) category-level retrieval,prominent approaches employ Cross-Modal Hashing (CMH) to prioritise efficiency,albeit at the cost of retrieval performance. Due to differences inmethodologies, FG and CG models are rarely compared directly within evaluationsin the literature, resulting in a lack of empirical data quantifying theretrieval performance-efficiency tradeoffs between the two. This paperaddresses this gap by introducing the \texttt{FiCo-ITR} library, whichstandardises evaluation methodologies for both FG and CG models, facilitatingdirect comparisons. We conduct empirical evaluations of representative modelsfrom both subfields, analysing precision, recall, and computational complexityacross varying data scales. Our findings offer new insights into theperformance-efficiency trade-offs between recent representative FG and CGmodels, highlighting their respective strengths and limitations. These findingsprovide the foundation necessary to make more informed decisions regardingmodel selection for specific retrieval tasks and highlight avenues for futureresearch into hybrid systems that leverage the strengths of both FG and CGapproaches.</description><author>Mikel Williams-Lekuona, Georgina Cosma</author><pubDate>Mon, 29 Jul 2024 15:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20114v1</guid></item><item><title>Generalizable Implicit Motion Modeling for Video Frame Interpolation</title><link>http://arxiv.org/abs/2407.08680v3</link><description>Motion modeling is critical in flow-based Video Frame Interpolation (VFI).Existing paradigms either consider linear combinations of bidirectional flowsor directly predict bilateral flows for given timestamps without exploringfavorable motion priors, thus lacking the capability of effectively modelingspatiotemporal dynamics in real-world videos. To address this limitation, inthis study, we introduce Generalizable Implicit Motion Modeling (GIMM), a noveland effective approach to motion modeling for VFI. Specifically, to enable GIMMas an effective motion modeling paradigm, we design a motion encoding pipelineto model spatiotemporal motion latent from bidirectional flows extracted frompre-trained flow estimators, effectively representing input-specific motionpriors. Then, we implicitly predict arbitrary-timestep optical flows within twoadjacent input frames via an adaptive coordinate-based neural network, withspatiotemporal coordinates and motion latent as inputs. Our GIMM can besmoothly integrated with existing flow-based VFI works without furthermodifications. We show that GIMM performs better than the current state of theart on the VFI benchmarks.</description><author>Zujin Guo, Wei Li, Chen Change Loy</author><pubDate>Mon, 29 Jul 2024 15:38:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08680v3</guid></item><item><title>Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2407.20109v1</link><description>One important property of DIstribution Correction Estimation (DICE) methodsis that the solution is the optimal stationary distribution ratio between theoptimized and data collection policy. In this work, we show that DICE-basedmethods can be viewed as a transformation from the behavior distribution to theoptimal policy distribution. Based on this, we propose a novel approach,Diffusion-DICE, that directly performs this transformation using diffusionmodels. We find that the optimal policy's score function can be decomposed intotwo terms: the behavior policy's score function and the gradient of a guidanceterm which depends on the optimal distribution ratio. The first term can beobtained from a diffusion model trained on the dataset and we propose anin-sample learning objective to learn the second term. Due to themulti-modality contained in the optimal policy distribution, the transformationin Diffusion-DICE may guide towards those local-optimal modes. We thus generatea few candidate actions and carefully select from them to approachglobal-optimum. Different from all other diffusion-based offline RL methods,the guide-then-select paradigm in Diffusion-DICE only uses in-sample actionsfor training and brings minimal error exploitation in the value function. Weuse a didatic toycase example to show how previous diffusion-based methods failto generate optimal actions due to leveraging these errors and howDiffusion-DICE successfully avoids that. We then conduct extensive experimentson benchmark datasets to show the strong performance of Diffusion-DICE.</description><author>Liyuan Mao, Haoran Xu, Weinan Zhang, Xianyuan Zhan, Amy Zhang</author><pubDate>Mon, 29 Jul 2024 15:36:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20109v1</guid></item><item><title>Classification, Regression and Segmentation directly from k-Space in Cardiac MRI</title><link>http://arxiv.org/abs/2407.20108v1</link><description>Cardiac Magnetic Resonance Imaging (CMR) is the gold standard for diagnosingcardiovascular diseases. Clinical diagnoses predominantly rely onmagnitude-only Digital Imaging and Communications in Medicine (DICOM) images,omitting crucial phase information that might provide additional diagnosticbenefits. In contrast, k-space is complex-valued and encompasses both magnitudeand phase information, while humans cannot directly perceive. In this work, wepropose KMAE, a Transformer-based model specifically designed to processk-space data directly, eliminating conventional intermediary conversion stepsto the image domain. KMAE can handle critical cardiac disease classification,relevant phenotype regression, and cardiac morphology segmentation tasks. Weutilize this model to investigate the potential of k-space-based diagnosis incardiac MRI. Notably, this model achieves competitive classification andregression performance compared to image-domain methods e.g. MaskedAutoencoders (MAEs) and delivers satisfactory segmentation performance with amyocardium dice score of 0.884. Last but not least, our model exhibits robustperformance with consistent results even when the k-space is 8* undersampled.We encourage the MR community to explore the untapped potential of k-space andpursue end-to-end, automated diagnosis with reduced human intervention.</description><author>Ruochen Li, Jiazhen Pan, Youxiang Zhu, Juncheng Ni, Daniel Rueckert</author><pubDate>Mon, 29 Jul 2024 15:35:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20108v1</guid></item><item><title>Strong Copyright Protection for Language Models via Adaptive Model Fusion</title><link>http://arxiv.org/abs/2407.20105v1</link><description>The risk of language models unintentionally reproducing copyrighted materialfrom their training data has led to the development of various protectivemeasures. In this paper, we propose model fusion as an effective solution tosafeguard against copyright infringement. In particular, we introduceCopyright-Protecting Fusion (CP-Fuse), an algorithm that adaptively combineslanguage models to minimize the reproduction of protected materials. CP-Fuse isinspired by the recently proposed Near-Access Free (NAF) framework andadditionally incorporates a desirable balancing property that we demonstrateprevents the reproduction of memorized training data. Our results show thatCP-Fuse significantly reduces the memorization of copyrighted content whilemaintaining high-quality text and code generation. Furthermore, we demonstratehow CP-Fuse can be integrated with other techniques for enhanced protection.</description><author>Javier Abad, Konstantin Donhauser, Francesco Pinto, Fanny Yang</author><pubDate>Mon, 29 Jul 2024 15:32:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20105v1</guid></item><item><title>Leveraging Pre-trained AudioLDM for Sound Generation: A Benchmark Study</title><link>http://arxiv.org/abs/2303.03857v3</link><description>Deep neural networks have recently achieved breakthroughs in soundgeneration. Despite the outstanding sample quality, current sound generationmodels face issues on small-scale datasets (e.g., overfitting), significantlylimiting performance. In this paper, we make the first attempt to investigatethe benefits of pre-training on sound generation with AudioLDM, thecutting-edge model for audio generation, as the backbone. Our studydemonstrates the advantages of the pre-trained AudioLDM, especially indata-scarcity scenarios. In addition, the baselines and evaluation protocol forsound generation systems are not consistent enough to compare different studiesdirectly. Aiming to facilitate further study on sound generation tasks, webenchmark the sound generation task on various frequently-used datasets. Wehope our results on transfer learning and benchmarks can provide references forfurther research on conditional sound generation.</description><author>Yi Yuan, Haohe Liu, Jinhua Liang, Xubo Liu, Mark D. Plumbley, Wenwu Wang</author><pubDate>Mon, 29 Jul 2024 15:29:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03857v3</guid></item><item><title>F-KANs: Federated Kolmogorov-Arnold Networks</title><link>http://arxiv.org/abs/2407.20100v1</link><description>In this paper, we present an innovative federated learning (FL) approach thatutilizes Kolmogorov-Arnold Networks (KANs) for classification tasks. Byutilizing the adaptive activation capabilities of KANs in a federatedframework, we aim to improve classification capabilities while preservingprivacy. The study evaluates the performance of federated KANs (F- KANs)compared to traditional Multi-Layer Perceptrons (MLPs) on classification task.The results show that the F-KANs model significantly outperforms the federatedMLP model in terms of accuracy, precision, recall, F1 score and stability, andachieves better performance, paving the way for more efficient andprivacy-preserving predictive analytics.</description><author>Engin Zeydan, Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Marius Caus, Abdullah Aydeger</author><pubDate>Mon, 29 Jul 2024 15:28:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20100v1</guid></item><item><title>Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders</title><link>http://arxiv.org/abs/2407.14435v2</link><description>Sparse autoencoders (SAEs) are a promising unsupervised approach foridentifying causally relevant and interpretable linear features in a languagemodel's (LM) activations. To be useful for downstream tasks, SAEs need todecompose LM activations faithfully; yet to be interpretable the decompositionmust be sparse -- two objectives that are in tension. In this paper, weintroduce JumpReLU SAEs, which achieve state-of-the-art reconstruction fidelityat a given sparsity level on Gemma 2 9B activations, compared to other recentadvances such as Gated and TopK SAEs. We also show that this improvement doesnot come at the cost of interpretability through manual and automatedinterpretability studies. JumpReLU SAEs are a simple modification of vanilla(ReLU) SAEs -- where we replace the ReLU with a discontinuous JumpReLUactivation function -- and are similarly efficient to train and run. Byutilising straight-through-estimators (STEs) in a principled manner, we showhow it is possible to train JumpReLU SAEs effectively despite the discontinuousJumpReLU function introduced in the SAE's forward pass. Similarly, we use STEsto directly train L0 to be sparse, instead of training on proxies such as L1,avoiding problems like shrinkage.</description><author>Senthooran Rajamanoharan, Tom Lieberum, Nicolas Sonnerat, Arthur Conmy, Vikrant Varma, János Kramár, Neel Nanda</author><pubDate>Mon, 29 Jul 2024 15:27:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14435v2</guid></item><item><title>RSC-SNN: Exploring the Trade-off Between Adversarial Robustness and Accuracy in Spiking Neural Networks via Randomized Smoothing Coding</title><link>http://arxiv.org/abs/2407.20099v1</link><description>Spiking Neural Networks (SNNs) have received widespread attention due totheir unique neuronal dynamics and low-power nature. Previous researchempirically shows that SNNs with Poisson coding are more robust than ArtificialNeural Networks (ANNs) on small-scale datasets. However, it is still unclear intheory how the adversarial robustness of SNNs is derived, and whether SNNs canstill maintain its adversarial robustness advantage on large-scale datasettasks. This work theoretically demonstrates that SNN's inherent adversarialrobustness stems from its Poisson coding. We reveal the conceptual equivalenceof Poisson coding and randomized smoothing in defense strategies, and analyzein depth the trade-off between accuracy and adversarial robustness in SNNs viathe proposed Randomized Smoothing Coding (RSC) method. Experiments demonstratethat the proposed RSC-SNNs show remarkable adversarial robustness, surpassingANNs and achieving state-of-the-art robustness results on large-scale datasetImageNet. Our open-source implementation code is available at this https URL:https://github.com/KemingWu/RSC-SNN.</description><author>Keming Wu, Man Yao, Yuhong Chou, Xuerui Qiu, Rui Yang, Bo Xu, Guoqi Li</author><pubDate>Mon, 29 Jul 2024 15:26:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20099v1</guid></item><item><title>Crafting Generative Art through Genetic Improvement: Managing Creative Outputs in Diverse Fitness Landscapes</title><link>http://arxiv.org/abs/2407.20095v1</link><description>Generative art is a rules-driven approach to creating artistic outputs invarious mediums. For example, a fluid simulation can govern the flow of coloredpixels across a digital display or a rectangle placement algorithm can yield aMondrian-style painting. Previously, we investigated how genetic improvement, asub-field of genetic programming, can automatically create and optimizegenerative art drawing programs. One challenge of applying genetic improvementto generative art is defining fitness functions and their interaction in amany-objective evolutionary algorithm such as Lexicase selection. Here, weassess the impact of each fitness function in terms of the their individualeffects on generated images, characteristics of generated programs, and impactof bloat on this specific domain. Furthermore, we have added an additionalfitness function that uses a classifier for mimicking a human's assessment asto whether an output is considered as "art." This classifier is trained on adataset of input images resembling the glitch art aesthetic that we aim tocreate. Our experimental results show that with few fitness functions,individual generative techniques sweep across populations. Moreover, we foundthat compositions tended to be driven by one technique with our current fitnessfunctions. Lastly, we show that our classifier is best suited for filtering outnoisy images, ideally leading towards more outputs relevant to user preference.</description><author>Erik M. Fredericks, Denton Bobeldyk, Jared M. Moore</author><pubDate>Mon, 29 Jul 2024 15:24:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20095v1</guid></item><item><title>Infrared Small Target Detection based on Adjustable Sensitivity Strategy and Multi-Scale Fusion</title><link>http://arxiv.org/abs/2407.20090v1</link><description>Recently, deep learning-based single-frame infrared small target (SIRST)detection technology has made significant progress. However, existing infraredsmall target detection methods are often optimized for a fixed imageresolution, a single wavelength, or a specific imaging system, limiting theirbreadth and flexibility in practical applications. Therefore, we propose arefined infrared small target detection scheme based on an adjustablesensitivity (AS) strategy and multi-scale fusion. Specifically, a multi-scalemodel fusion framework based on multi-scale direction-aware network (MSDA-Net)is constructed, which uses input images of multiple scales to train multiplemodels and fuses them. Multi-scale fusion helps characterize the shape, edge,and texture features of the target from different scales, making the model moreaccurate and reliable in locating the target. At the same time, we fullyconsider the characteristics of the infrared small target detection task andconstruct an edge enhancement difficulty mining (EEDM) loss. The EEDM losshelps alleviate the problem of category imbalance and guides the network to paymore attention to difficult target areas and edge features during training. Inaddition, we propose an adjustable sensitivity strategy for post-processing.This strategy significantly improves the detection rate of infrared smalltargets while ensuring segmentation accuracy. Extensive experimental resultsshow that the proposed scheme achieves the best performance. Notably, thisscheme won the first prize in the PRCV 2024 wide-area infrared small targetdetection competition.</description><author>Jinmiao Zhao, Zelin Shi, Chuang Yu, Yunpeng Liu</author><pubDate>Mon, 29 Jul 2024 15:22:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20090v1</guid></item><item><title>Segmenting Fetal Head with Efficient Fine-tuning Strategies in Low-resource Settings: an empirical study with U-Net</title><link>http://arxiv.org/abs/2407.20086v1</link><description>Accurate measurement of fetal head circumference is crucial for estimatingfetal growth during routine prenatal screening. Prior to measurement, it isnecessary to accurately identify and segment the region of interest,specifically the fetal head, in ultrasound images. Recent advancements in deeplearning techniques have shown significant progress in segmenting the fetalhead using encoder-decoder models. Among these models, U-Net has become astandard approach for accurate segmentation. However, training anencoder-decoder model can be a time-consuming process that demands substantialcomputational resources. Moreover, fine-tuning these models is particularlychallenging when there is a limited amount of data available. There are stillno "best-practice" guidelines for optimal fine-tuning of U-net for fetalultrasound image segmentation. This work summarizes existing fine-tuningstrategies with various backbone architectures, model components, andfine-tuning strategies across ultrasound data from Netherlands, Spain, Malawi,Egypt and Algeria. Our study shows that (1) fine-tuning U-Net leads to betterperformance than training from scratch, (2) fine-tuning strategies in decoderare superior to other strategies, (3) network architecture with less number ofparameters can achieve similar or better performance. We also demonstrate theeffectiveness of fine-tuning strategies in low-resource settings and furtherexpand our experiments into few-shot learning. Lastly, we publicly released ourcode and specific fine-tuned weights.</description><author>Fangyijie Wang, Guénolé Silvestre, Kathleen M. Curran</author><pubDate>Mon, 29 Jul 2024 15:16:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20086v1</guid></item><item><title>TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting</title><link>http://arxiv.org/abs/2406.01805v2</link><description>Tabular data is prevalent in many critical domains, yet it is oftenchallenging to acquire in large quantities. This scarcity usually results inpoor performance of machine learning models on such data. Data augmentation, acommon strategy for performance improvement in vision and language tasks,typically underperforms for tabular data due to the lack of explicit symmetriesin the input space. To overcome this challenge, we introduce TabMDA, a novelmethod for manifold data augmentation on tabular data. This method utilises apre-trained in-context model, such as TabPFN, to map the data into an embeddingspace. TabMDA performs label-invariant transformations by encoding the datamultiple times with varied contexts. This process explores the learnedembedding space of the underlying in-context models, thereby enlarging thetraining dataset. TabMDA is a training-free method, making it applicable to anyclassifier. We evaluate TabMDA on five standard classifiers and observesignificant performance improvements across various tabular datasets. Ourresults demonstrate that TabMDA provides an effective way to leverageinformation from pre-trained in-context models to enhance the performance ofdownstream classifiers. Code is available athttps://github.com/AdrianBZG/TabMDA.</description><author>Andrei Margeloiu, Adrián Bazaga, Nikola Simidjievski, Pietro Liò, Mateja Jamnik</author><pubDate>Mon, 29 Jul 2024 15:08:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01805v2</guid></item><item><title>An Energy-based Model for Word-level AutoCompletion in Computer-aided Translation</title><link>http://arxiv.org/abs/2407.20083v1</link><description>Word-level AutoCompletion(WLAC) is a rewarding yet challenging task inComputer-aided Translation. Existing work addresses this task through aclassification model based on a neural network that maps the hidden vector ofthe input context into its corresponding label (i.e., the candidate target wordis treated as a label). Since the context hidden vector itself does not takethe label into account and it is projected to the label through a linearclassifier, the model can not sufficiently leverage valuable information fromthe source sentence as verified in our experiments, which eventually hindersits overall performance. To alleviate this issue, this work proposes anenergy-based model for WLAC, which enables the context hidden vector to capturecrucial information from the source sentence. Unfortunately, training andinference suffer from efficiency and effectiveness challenges, thereby weemploy three simple yet effective strategies to put our model into practice.Experiments on four standard benchmarks demonstrate that our reranking-basedapproach achieves substantial improvements (about 6.07%) over the previousstate-of-the-art model. Further analyses show that each strategy of ourapproach contributes to the final performance.</description><author>Cheng Yang, Guoping Huang, Mo Yu, Zhirui Zhang, Siheng Li, Mingming Yang, Shuming Shi, Yujiu Yang, Lemao Liu</author><pubDate>Mon, 29 Jul 2024 15:07:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20083v1</guid></item><item><title>Structural restrictions in local causal discovery: identifying direct causes of a target variable</title><link>http://arxiv.org/abs/2307.16048v2</link><description>We consider the problem of learning a set of direct causes of a targetvariable from an observational joint distribution. Learning directed acyclicgraphs (DAGs) that represent the causal structure is a fundamental problem inscience. Several results are known when the full DAG is identifiable from thedistribution, such as assuming a nonlinear Gaussian data-generating process.Here, we are only interested in identifying the direct causes of one targetvariable (local causal structure), not the full DAG. This allows us to relaxthe identifiability assumptions and develop possibly faster and more robustalgorithms. In contrast to the Invariance Causal Prediction framework, we onlyassume that we observe one environment without any interventions. We discussdifferent assumptions for the data-generating process of the target variableunder which the set of direct causes is identifiable from the distribution.While doing so, we put essentially no assumptions on the variables other thanthe target variable. In addition to the novel identifiability results, weprovide two practical algorithms for estimating the direct causes from a finiterandom sample and demonstrate their effectiveness on several benchmark and realdatasets.</description><author>Juraj Bodik, Valérie Chavez-Demoulin</author><pubDate>Mon, 29 Jul 2024 15:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16048v2</guid></item><item><title>UniTTA: Unified Benchmark and Versatile Framework Towards Realistic Test-Time Adaptation</title><link>http://arxiv.org/abs/2407.20080v1</link><description>Test-Time Adaptation (TTA) aims to adapt pre-trained models to the targetdomain during testing. In reality, this adaptability can be influenced bymultiple factors. Researchers have identified various challenging scenarios anddeveloped diverse methods to address these challenges, such as dealing withcontinual domain shifts, mixed domains, and temporally correlated or imbalancedclass distributions. Despite these efforts, a unified and comprehensivebenchmark has yet to be established. To this end, we propose a UnifiedTest-Time Adaptation (UniTTA) benchmark, which is comprehensive and widelyapplicable. Each scenario within the benchmark is fully described by a Markovstate transition matrix for sampling from the original dataset. The UniTTAbenchmark considers both domain and class as two independent dimensions of dataand addresses various combinations of imbalance/balance andi.i.d./non-i.i.d./continual conditions, covering a total of \( (2 \times 3)^2 =36 \) scenarios. It establishes a comprehensive evaluation benchmark forrealistic TTA and provides a guideline for practitioners to select the mostsuitable TTA method. Alongside this benchmark, we propose a versatile UniTTAframework, which includes a Balanced Domain Normalization (BDN) layer and aCOrrelated Feature Adaptation (COFA) method--designed to mitigate distributiongaps in domain and class, respectively. Extensive experiments demonstrate thatour UniTTA framework excels within the UniTTA benchmark and achievesstate-of-the-art performance on average. Our code is available at\url{https://github.com/LeapLabTHU/UniTTA}.</description><author>Chaoqun Du, Yulin Wang, Jiayi Guo, Yizeng Han, Jie Zhou, Gao Huang</author><pubDate>Mon, 29 Jul 2024 15:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20080v1</guid></item><item><title>FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources</title><link>http://arxiv.org/abs/2407.01445v2</link><description>Existing studies of training state-of-the-art Contrastive Language-ImagePretraining (CLIP) models on large-scale data involve hundreds of or eventhousands of GPUs due to the requirement of a large batch size. However, such alarge amount of resources is not accessible to most people. While advancedcompositional optimization techniques for optimizing global contrastive losseshave been demonstrated effective for removing the requirement of large batchsize, their performance on large-scale data remains underexplored and notoptimized. To bridge the gap, this paper explores several aspects of CLIPtraining with limited resources (e.g., up to tens of GPUs). First, we introduceFastCLIP, a general CLIP training framework built on advanced compositionaloptimization techniques while designed and optimized for the distributedsetting. Our framework is equipped with an efficient gradient reductionstrategy to reduce communication overhead. Second, to further boost trainingefficiency, we investigate three components of the framework from anoptimization perspective: the schedule of the inner learning rate, the updaterules of the temperature parameter and the model parameters, respectively.Experiments on different strategies for each component shed light on how toconduct CLIP training more efficiently. Finally, we benchmark the performanceof FastCLIP and the state-of-the-art training baseline (OpenCLIP) on differentcompute scales up to 32 GPUs on 8 nodes, and three data scales ranging from 2.7million, 9.1 million to 315 million image-text pairs to demonstrate thesignificant improvement of FastCLIP in the resource-limited setting. We releasethe code of FastCLIP at https://github.com/Optimization-AI/fast_clip .</description><author>Xiyuan Wei, Fanjiang Ye, Ori Yonay, Xingyu Chen, Baixi Sun, Dingwen Tao, Tianbao Yang</author><pubDate>Mon, 29 Jul 2024 15:04:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01445v2</guid></item><item><title>Background Semantics Matter: Cross-Task Feature Exchange Network for Clustered Infrared Small Target Detection With Sky-Annotated Dataset</title><link>http://arxiv.org/abs/2407.20078v1</link><description>Infrared small target detection poses unique challenges due to the scarcityof intrinsic target features and the abundance of similar backgrounddistractors. We argue that background semantics play a pivotal role indistinguishing visually similar objects for this task. To address this, weintroduce a new task -- clustered infrared small target detection, and presentDenseSIRST, a novel benchmark dataset that provides per-pixel semanticannotations for background regions, enabling the transition from sparse todense target detection. Leveraging this dataset, we propose theBackground-Aware Feature Exchange Network (BAFE-Net), which transforms thedetection paradigm from a single task focused on the foreground to a multi-taskarchitecture that jointly performs target detection and background semanticsegmentation. BAFE-Net introduces a cross-task feature hard-exchange mechanismto embed target and background semantics between the two tasks. Furthermore, wepropose the Background-Aware Gaussian Copy-Paste (BAG-CP) method, whichselectively pastes small targets into sky regions during training, avoiding thecreation of false alarm targets in complex non-sky backgrounds. Extensiveexperiments validate the effectiveness of BAG-CP and BAFE-Net in improvingtarget detection accuracy while reducing false alarms. The DenseSIRST dataset,code, and trained models are available at https://github.com/GrokCV/BAFE-Net.</description><author>Yimian Dai, Mengxuan Xiao, Yiming Zhu, Huan Wang, Kehua Guo, Jian Yang</author><pubDate>Mon, 29 Jul 2024 15:03:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20078v1</guid></item><item><title>Investigating the Impact of Semi-Supervised Methods with Data Augmentation on Offensive Language Detection in Romanian Language</title><link>http://arxiv.org/abs/2407.20076v1</link><description>Offensive language detection is a crucial task in today's digital landscape,where online platforms grapple with maintaining a respectful and inclusiveenvironment. However, building robust offensive language detection modelsrequires large amounts of labeled data, which can be expensive andtime-consuming to obtain. Semi-supervised learning offers a feasible solutionby utilizing labeled and unlabeled data to create more accurate and robustmodels. In this paper, we explore a few different semi-supervised methods, aswell as data augmentation techniques. Concretely, we implemented eightsemi-supervised methods and ran experiments for them using only the availabledata in the RO-Offense dataset and applying five augmentation techniques beforefeeding the data to the models. Experimental results demonstrate that some ofthem benefit more from augmentations than others.</description><author>Elena Beatrice Nicola, Dumitru Clementin Cercel, Florin Pop</author><pubDate>Mon, 29 Jul 2024 15:02:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20076v1</guid></item><item><title>An Interpretable Rule Creation Method for Black-Box Models based on Surrogate Trees -- SRules</title><link>http://arxiv.org/abs/2407.20070v1</link><description>As artificial intelligence (AI) systems become increasingly integrated intocritical decision-making processes, the need for transparent and interpretablemodels has become paramount. In this article we present a new ruleset creationmethod based on surrogate decision trees (SRules), designed to improve theinterpretability of black-box machine learning models. SRules balances theaccuracy, coverage, and interpretability of machine learning models byrecursively creating surrogate interpretable decision tree models thatapproximate the decision boundaries of a complex model. We propose a systematicframework for generating concise and meaningful rules from these surrogatemodels, allowing stakeholders to understand and trust the AI system'sdecision-making process. Our approach not only provides interpretable rules,but also quantifies the confidence and coverage of these rules. The proposedmodel allows to adjust its parameters to counteract the lack ofinterpretability by precision and coverage by allowing a near perfect fit andhigh interpretability of some parts of the model . The results show that SRulesimproves on other state-of-the-art techniques and introduces the possibility ofcreating highly interpretable specific rules for specific sub-parts of themodel.</description><author>Mario Parrón Verdasco, Esteban García-Cuesta</author><pubDate>Mon, 29 Jul 2024 14:56:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20070v1</guid></item><item><title>CityX: Controllable Procedural Content Generation for Unbounded 3D Cities</title><link>http://arxiv.org/abs/2407.17572v2</link><description>Generating a realistic, large-scale 3D virtual city remains a complexchallenge due to the involvement of numerous 3D assets, various city styles,and strict layout constraints. Existing approaches provide promising attemptsat procedural content generation to create large-scale scenes using Blenderagents. However, they face crucial issues such as difficulties in scaling upgeneration capability and achieving fine-grained control at the semantic layoutlevel. To address these problems, we propose a novel multi-modal controllableprocedural content generation method, named CityX, which enhances realistic,unbounded 3D city generation guided by multiple layout conditions, includingOSM, semantic maps, and satellite images. Specifically, the proposed methodcontains a general protocol for integrating various PCG plugins and amulti-agent framework for transforming instructions into executable Blenderactions. Through this effective framework, CityX shows the potential to buildan innovative ecosystem for 3D scene generation by bridging the gap between thequality of generated assets and industrial requirements. Extensive experimentshave demonstrated the effectiveness of our method in creating high-quality,diverse, and unbounded cities guided by multi-modal conditions. Our projectpage: https://cityx-lab.github.io.</description><author>Shougao Zhang, Mengqi Zhou, Yuxi Wang, Chuanchen Luo, Rongyu Wang, Yiwei Li, Xucheng Yin, Zhaoxiang Zhang, Junran Peng</author><pubDate>Mon, 29 Jul 2024 14:55:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17572v2</guid></item><item><title>Unleash the Power of Ellipsis: Accuracy-enhanced Sparse Vector Technique with Exponential Noise</title><link>http://arxiv.org/abs/2407.20068v1</link><description>The Sparse Vector Technique (SVT) is one of the most fundamental tools indifferential privacy (DP). It works as a backbone for adaptive data analysis byanswering a sequence of queries on a given dataset, and gleaning usefulinformation in a privacy-preserving manner. Unlike the typical private queryreleases that directly publicize the noisy query results, SVT is lessinformative -- it keeps the noisy query results to itself and only reveals abinary bit for each query, indicating whether the query result surpasses apredefined threshold. To provide a rigorous DP guarantee for SVT, prior worksin the literature adopt a conservative privacy analysis by assuming the directdisclosure of noisy query results as in typical private query releases. Thisapproach, however, hinders SVT from achieving higher query accuracy due to anoverestimation of the privacy risks, which further leads to an excessive noiseinjection using the Laplacian or Gaussian noise for perturbation. Motivated bythis, we provide a new privacy analysis for SVT by considering its lessinformative nature. Our analysis results not only broaden the range ofapplicable noise types for perturbation in SVT, but also identify theexponential noise as optimal among all evaluated noises (which, however, isusually deemed non-applicable in prior works). The main challenge in applyingexponential noise to SVT is mitigating the sub-optimal performance due to thebias introduced by noise distributions. To address this, we develop autility-oriented optimal threshold correction method and an appending strategy,which enhances the performance of SVT by increasing the precision and recall,respectively. The effectiveness of our proposed methods is substantiated boththeoretically and empirically, demonstrating significant improvements up to$50\%$ across evaluated metrics.</description><author>Yuhan Liu, Sheng Wang, Yixuan Liu, Feifei Li, Hong Chen</author><pubDate>Mon, 29 Jul 2024 14:54:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20068v1</guid></item><item><title>xAI-Drop: Don't Use What You Cannot Explain</title><link>http://arxiv.org/abs/2407.20067v1</link><description>Graph Neural Networks (GNNs) have emerged as the predominant paradigm forlearning from graph-structured data, offering a wide range of applications fromsocial network analysis to bioinformatics. Despite their versatility, GNNs facechallenges such as oversmoothing, lack of generalization and poorinterpretability, which hinder their wider adoption and reliability in criticalapplications. Dropping has emerged as an effective paradigm for reducing noiseduring training and improving robustness of GNNs. However, existing approachesoften rely on random or heuristic-based selection criteria, lacking aprincipled method to identify and exclude nodes that contribute to noise andover-complexity in the model. In this work, we argue that explainability shouldbe a key indicator of a model's robustness throughout its training phase. Tothis end, we introduce xAI-Drop, a novel topological-level dropping regularizerthat leverages explainability to pinpoint noisy network elements to be excludedfrom the GNN propagation mechanism. An empirical evaluation on diversereal-world datasets demonstrates that our method outperforms currentstate-of-the-art dropping approaches in accuracy, effectively reducesover-smoothing, and improves explanation quality.</description><author>Vincenzo Marco De Luca, Antonio Longa, Andrea Passerini, Pietro Liò</author><pubDate>Mon, 29 Jul 2024 14:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20067v1</guid></item><item><title>Long-form music generation with latent diffusion</title><link>http://arxiv.org/abs/2404.10301v2</link><description>Audio-based generative models for music have seen great strides recently, butso far have not managed to produce full-length music tracks with coherentmusical structure from text prompts. We show that by training a generativemodel on long temporal contexts it is possible to produce long-form music of upto 4m45s. Our model consists of a diffusion-transformer operating on a highlydownsampled continuous latent representation (latent rate of 21.5Hz). Itobtains state-of-the-art generations according to metrics on audio quality andprompt alignment, and subjective tests reveal that it produces full-lengthmusic with coherent structure.</description><author>Zach Evans, Julian D. Parker, CJ Carr, Zack Zukowski, Josiah Taylor, Jordi Pons</author><pubDate>Mon, 29 Jul 2024 14:52:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10301v2</guid></item><item><title>Differentially Private Gradient Flow based on the Sliced Wasserstein Distance</title><link>http://arxiv.org/abs/2312.08227v2</link><description>Safeguarding privacy in sensitive training data is paramount, particularly inthe context of generative modeling. This can be achieved through eitherdifferentially private stochastic gradient descent or a differentially privatemetric for training models or generators. In this paper, we introduce a noveldifferentially private generative modeling approach based on a gradient flow inthe space of probability measures. To this end, we define the gradient flow ofthe Gaussian-smoothed Sliced Wasserstein Distance, including the associatedstochastic differential equation (SDE). By discretizing and defining anumerical scheme for solving this SDE, we demonstrate the link betweensmoothing and differential privacy based on a Gaussian mechanism, due to aspecific form of the SDE's drift term. We then analyze the differential privacyguarantee of our gradient flow, which accounts for both the smoothing and theWiener process introduced by the SDE itself. Experiments show that our proposedmodel can generate higher-fidelity data at a low privacy budget compared to agenerator-based model, offering a promising alternative.</description><author>Ilana Sebag, Muni Sreenivas Pydi, Jean-Yves Franceschi, Alain Rakotomamonjy, Mike Gartrell, Jamal Atif, Alexandre Allauzen</author><pubDate>Mon, 29 Jul 2024 14:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08227v2</guid></item><item><title>CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification</title><link>http://arxiv.org/abs/2306.04979v3</link><description>Although graph neural networks (GNNs) have achieved impressive achievementsin graph classification, they often need abundant task-specific labels, whichcould be extensively costly to acquire. A credible solution is to exploreadditional labeled graphs to enhance unsupervised learning on the targetdomain. However, how to apply GNNs to domain adaptation remains unsolved owingto the insufficient exploration of graph topology and the significant domaindiscrepancy. In this paper, we propose Coupled Contrastive Graph RepresentationLearning (CoCo), which extracts the topological information from coupledlearning branches and reduces the domain discrepancy with coupled contrastivelearning. CoCo contains a graph convolutional network branch and a hierarchicalgraph kernel network branch, which explore graph topology in implicit andexplicit manners. Besides, we incorporate coupled branches into a holisticmulti-view contrastive learning framework, which not only incorporates graphrepresentations learned from complementary views for enhanced understanding,but also encourages the similarity between cross-domain example pairs with thesame semantics for domain alignment. Extensive experiments on popular datasetsshow that our CoCo outperforms these competing baselines in different settingsgenerally.</description><author>Nan Yin, Li Shen, Mengzhu Wang, Long Lan, Zeyu Ma, Chong Chen, Xian-Sheng Hua, Xiao Luo</author><pubDate>Mon, 29 Jul 2024 14:50:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04979v3</guid></item><item><title>Geospecific View Generation -- Geometry-Context Aware High-resolution Ground View Inference from Satellite Views</title><link>http://arxiv.org/abs/2407.08061v2</link><description>Predicting realistic ground views from satellite imagery in urban scenes is achallenging task due to the significant view gaps between satellite andground-view images. We propose a novel pipeline to tackle this challenge, bygenerating geospecifc views that maximally respect the weak geometry andtexture from multi-view satellite images. Different from existing approachesthat hallucinate images from cues such as partial semantics or geometry fromoverhead satellite images, our method directly predicts ground-view images atgeolocation by using a comprehensive set of information from the satelliteimage, resulting in ground-level images with a resolution boost at a factor often or more. We leverage a novel building refinement method to reduce geometricdistortions in satellite data at ground level, which ensures the creation ofaccurate conditions for view synthesis using diffusion networks. Moreover, weproposed a novel geospecific prior, which prompts distribution learning ofdiffusion models to respect image samples that are closer to the geolocation ofthe predicted images. We demonstrate our pipeline is the first to generateclose-to-real and geospecific ground views merely based on satellite images.</description><author>Ningli Xu, Rongjun Qin</author><pubDate>Mon, 29 Jul 2024 14:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08061v2</guid></item><item><title>SalNAS: Efficient Saliency-prediction Neural Architecture Search with self-knowledge distillation</title><link>http://arxiv.org/abs/2407.20062v1</link><description>Recent advancements in deep convolutional neural networks have significantlyimproved the performance of saliency prediction. However, the manualconfiguration of the neural network architectures requires domain knowledgeexpertise and can still be time-consuming and error-prone. To solve this, wepropose a new Neural Architecture Search (NAS) framework for saliencyprediction with two contributions. Firstly, a supernet for saliency predictionis built with a weight-sharing network containing all candidate architectures,by integrating a dynamic convolution into the encoder-decoder in the supernet,termed SalNAS. Secondly, despite the fact that SalNAS is highly efficient(20.98 million parameters), it can suffer from the lack of generalization. Tosolve this, we propose a self-knowledge distillation approach, termed Self-KD,that trains the student SalNAS with the weighted average information betweenthe ground truth and the prediction from the teacher model. The teacher model,while sharing the same architecture, contains the best-performing weightschosen by cross-validation. Self-KD can generalize well without the need tocompute the gradient in the teacher model, enabling an efficient trainingsystem. By utilizing Self-KD, SalNAS outperforms other state-of-the-artsaliency prediction models in most evaluation rubrics across seven benchmarkdatasets while being a lightweight model. The code will be available athttps://github.com/chakkritte/SalNAS</description><author>Chakkrit Termritthikun, Ayaz Umer, Suwichaya Suwanwimolkul, Feng Xia, Ivan Lee</author><pubDate>Mon, 29 Jul 2024 14:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20062v1</guid></item><item><title>Autonomous Bootstrapping of Quantum Dot Devices</title><link>http://arxiv.org/abs/2407.20061v1</link><description>Semiconductor quantum dots (QD) are a promising platform for multipledifferent qubit implementations, all of which are voltage-controlled byprogrammable gate electrodes. However, as the QD arrays grow in size andcomplexity, tuning procedures that can fully autonomously handle the increasingnumber of control parameters are becoming essential for enabling scalability.We propose a bootstrapping algorithm for initializing a depletion mode QDdevice in preparation for subsequent phases of tuning. During bootstrapping,the QD device functionality is validated, all gates are characterized, and theQD charge sensor is made operational. We demonstrate the bootstrapping protocolin conjunction with a coarse tuning module, showing that the combined algorithmcan efficiently and reliably take a cooled-down QD device to a desired globalstate configuration in under 8 minutes with a success rate of 96 %.Importantly, by following heuristic approaches to QD device initialization andcombining the efficient ray-based measurement with the rapid radio-frequencyreflectometry measurements, the proposed algorithm establishes a reference interms of performance, reliability, and efficiency against which alternativealgorithms can be benchmarked.</description><author>Anton Zubchenko, Danielle Middlebrooks, Torbjørn Rasmussen, Lara Lausen, Ferdinand Kuemmeth, Anasua Chatterjee, Justyna P. Zwolak</author><pubDate>Mon, 29 Jul 2024 14:47:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20061v1</guid></item><item><title>RelBench: A Benchmark for Deep Learning on Relational Databases</title><link>http://arxiv.org/abs/2407.20060v1</link><description>We present RelBench, a public benchmark for solving predictive tasks overrelational databases with graph neural networks. RelBench provides databasesand tasks spanning diverse domains and scales, and is intended to be afoundational infrastructure for future research. We use RelBench to conduct thefirst comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024),which combines graph neural network predictive models with (deep) tabularmodels that extract initial entity-level representations from raw tables.End-to-end learned RDL models fully exploit the predictive signal encoded inprimary-foreign key links, marking a significant shift away from the dominantparadigm of manual feature engineering combined with tabular models. Tothoroughly evaluate RDL against this prior gold-standard, we conduct anin-depth user study where an experienced data scientist manually engineersfeatures for each task. In this study, RDL learns better models whilst reducinghuman work needed by more than an order of magnitude. This demonstrates thepower of deep learning for solving predictive tasks over relational databases,opening up many new research opportunities enabled by RelBench.</description><author>Joshua Robinson, Rishabh Ranjan, Weihua Hu, Kexin Huang, Jiaqi Han, Alejandro Dobles, Matthias Fey, Jan E. Lenssen, Yiwen Yuan, Zecheng Zhang, Xinwei He, Jure Leskovec</author><pubDate>Mon, 29 Jul 2024 14:46:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20060v1</guid></item><item><title>Shapley Value Computation in Ontology-Mediated Query Answering</title><link>http://arxiv.org/abs/2407.20058v1</link><description>The Shapley value, originally introduced in cooperative game theory forwealth distribution, has found use in KR and databases for the purpose ofassigning scores to formulas and database tuples based upon their contributionto obtaining a query result or inconsistency. In the present paper, we explorethe use of Shapley values in ontology-mediated query answering (OMQA) andpresent a detailed complexity analysis of Shapley value computation (SVC) inthe OMQA setting. In particular, we establish a PF/#P-hard dichotomy for SVCfor ontology-mediated queries (T,q) composed of an ontology T formulated in thedescription logic ELHI_\bot and a connected constant-free homomorphism-closedquery q. We further show that the #P-hardness side of the dichotomy can bestrengthened to cover possibly disconnected queries with constants. Our resultsexploit recently discovered connections between SVC and probabilistic queryevaluation and allow us to generalize existing results on probabilistic OMQA.</description><author>Meghyn Bienvenu, Diego Figueira, Pierre Lafourcade</author><pubDate>Mon, 29 Jul 2024 14:45:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20058v1</guid></item><item><title>Multi-fidelity Gaussian process surrogate modeling for regression problems in physics</title><link>http://arxiv.org/abs/2404.11965v2</link><description>One of the main challenges in surrogate modeling is the limited availabilityof data due to resource constraints associated with computationally expensivesimulations. Multi-fidelity methods provide a solution by chaining models in ahierarchy with increasing fidelity, associated with lower error, but increasingcost. In this paper, we compare different multi-fidelity methods employed inconstructing Gaussian process surrogates for regression. Non-linearautoregressive methods in the existing literature are primarily confined totwo-fidelity models, and we extend these methods to handle more than two levelsof fidelity. Additionally, we propose enhancements for an existing methodincorporating delay terms by introducing a structured kernel. We demonstratethe performance of these methods across various academic and real-worldscenarios. Our findings reveal that multi-fidelity methods generally have asmaller prediction error for the same computational cost as compared to thesingle-fidelity method, although their effectiveness varies across differentscenarios.</description><author>Kislaya Ravi, Vladyslav Fediukov, Felix Dietrich, Tobias Neckel, Fabian Buse, Michael Bergmann, Hans-Joachim Bungartz</author><pubDate>Mon, 29 Jul 2024 14:43:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11965v2</guid></item><item><title>Merit-based Fair Combinatorial Semi-Bandit with Unrestricted Feedback Delays</title><link>http://arxiv.org/abs/2407.15439v3</link><description>We study the stochastic combinatorial semi-bandit problem with unrestrictedfeedback delays under merit-based fairness constraints. This is motivated byapplications such as crowdsourcing, and online advertising, where immediatefeedback is not immediately available and fairness among different choices (orarms) is crucial. We consider two types of unrestricted feedback delays:reward-independent delays where the feedback delays are independent of therewards, and reward-dependent delays where the feedback delays are correlatedwith the rewards. Furthermore, we introduce merit-based fairness constraints toensure a fair selection of the arms. We define the reward regret and thefairness regret and present new bandit algorithms to select arms underunrestricted feedback delays based on their merits. We prove that ouralgorithms all achieve sublinear expected reward regret and expected fairnessregret, with a dependence on the quantiles of the delay distribution. We alsoconduct extensive experiments using synthetic and real-world data and show thatour algorithms can fairly select arms with different feedback delays.</description><author>Ziqun Chen, Kechao Cai, Zhuoyue Chen, Jinbei Zhang, John C. S. Lui</author><pubDate>Mon, 29 Jul 2024 14:42:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.15439v3</guid></item><item><title>Analyzing User Characteristics of Hate Speech Spreaders on Social Media</title><link>http://arxiv.org/abs/2310.15772v2</link><description>Hate speech on social media threatens the mental and physical well-being ofindividuals and contributes to real-world violence. Resharing is an importantdriver behind the spread of hate speech on social media. Yet, little is knownabout who reshares hate speech and what their characteristics are. In thispaper, we analyze the role of user characteristics in hate speech resharingacross different types of hate speech (e.g., political hate). For this, weproceed as follows: First, we cluster hate speech posts using large languagemodels to identify different types of hate speech. Then we model the effects ofuser attributes on users' probability to reshare hate speech using anexplainable machine learning model. To do so, we apply debiasing to control forselection bias in our observational social media data and further control forthe latent vulnerability of users to hate speech. We find that, all else equal,users with fewer followers, fewer friends, fewer posts, and older accountsshare more hate speech. This shows that users with little social influence tendto share more hate speech. Further, we find substantial heterogeneity acrossdifferent types of hate speech. For example, racist and misogynistic hate isspread mostly by users with little social influence. In contrast, politicalanti-Trump and anti-right-wing hate is reshared by users with larger socialinfluence. Overall, understanding the factors that drive users to share hatespeech is crucial for detecting individuals at risk of engaging in harmfulbehavior and for designing effective mitigation strategies.</description><author>Dominique Geissler, Abdurahman Maarouf, Stefan Feuerriegel</author><pubDate>Mon, 29 Jul 2024 14:40:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15772v2</guid></item><item><title>Orca: Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models</title><link>http://arxiv.org/abs/2407.20053v1</link><description>Significant wave height (SWH) is a vital metric in marine science, andaccurate SWH estimation is crucial for various applications, e.g., marineenergy development, fishery, early warning systems for potential risks, etc.Traditional SWH estimation methods that are based on numerical models andphysical theories are hindered by computational inefficiencies. Recently,machine learning has emerged as an appealing alternative to improve accuracyand reduce computational time. However, due to limited observational technologyand high costs, the scarcity of real-world data restricts the potential ofmachine learning models. To overcome these limitations, we propose an ocean SWHestimation framework, namely Orca. Specifically, Orca enhances the limitedspatio-temporal reasoning abilities of classic LLMs with a novel spatiotemporalaware encoding module. By segmenting the limited buoy observational datatemporally, encoding the buoys' locations spatially, and designing prompttemplates, Orca capitalizes on the robust generalization ability of LLMs toestimate significant wave height effectively with limited data. Experimentalresults on the Gulf of Mexico demonstrate that Orca achieves state-of-the-artperformance in SWH estimation.</description><author>Zhe Li, Ronghui Xu, Jilin Hu, Zhong Peng, Xi Lu, Chenjuan Guo, Bin Yang</author><pubDate>Mon, 29 Jul 2024 14:40:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20053v1</guid></item><item><title>Leveraging Time-Series Foundation Models in Smart Agriculture for Soil Moisture Forecasting</title><link>http://arxiv.org/abs/2405.18913v2</link><description>The recent surge in foundation models for natural language processing andcomputer vision has fueled innovation across various domains. Inspired by thisprogress, we explore the potential of foundation models for time-seriesforecasting in smart agriculture, a field often plagued by limited dataavailability. Specifically, this work presents a novel application of$\texttt{TimeGPT}$, a state-of-the-art (SOTA) time-series foundation model, topredict soil water potential ($\psi_\mathrm{soil}$), a key indicator of fieldwater status that is typically used for irrigation advice. Traditionally, thistask relies on a wide array of input variables. We explore$\psi_\mathrm{soil}$'s ability to forecast $\psi_\mathrm{soil}$ in: ($i$) azero-shot setting, ($ii$) a fine-tuned setting relying solely on historic$\psi_\mathrm{soil}$ measurements, and ($iii$) a fine-tuned setting where wealso add exogenous variables to the model. We compare $\texttt{TimeGPT}$'sperformance to established SOTA baseline models for forecasting$\psi_\mathrm{soil}$. Our results demonstrate that $\texttt{TimeGPT}$ achievescompetitive forecasting accuracy using only historical $\psi_\mathrm{soil}$data, highlighting its remarkable potential for agricultural applications. Thisresearch paves the way for foundation time-series models for sustainabledevelopment in agriculture by enabling forecasting tasks that weretraditionally reliant on extensive data collection and domain expertise.</description><author>Boje Deforce, Bart Baesens, Estefanía Serral Asensio</author><pubDate>Mon, 29 Jul 2024 14:36:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18913v2</guid></item><item><title>Dynamic Spiking Graph Neural Networks</title><link>http://arxiv.org/abs/2401.05373v2</link><description>The integration of Spiking Neural Networks (SNNs) and Graph Neural Networks(GNNs) is gradually attracting attention due to the low power consumption andhigh efficiency in processing the non-Euclidean data represented by graphs.However, as a common problem, dynamic graph representation learning faceschallenges such as high complexity and large memory overheads. Current workoften uses SNNs instead of Recurrent Neural Networks (RNNs) by using binaryfeatures instead of continuous ones for efficient training, which wouldoverlooks graph structure information and leads to the loss of details duringpropagation. Additionally, optimizing dynamic spiking models typically requirespropagation of information across time steps, which increases memoryrequirements. To address these challenges, we present a framework named\underline{Dy}namic \underline{S}p\underline{i}king \underline{G}raph\underline{N}eural Networks (\method{}). To mitigate the information lossproblem, \method{} propagates early-layer information directly to the lastlayer for information compensation. To accommodate the memory requirements, weapply the implicit differentiation on the equilibrium state, which does notrely on the exact reverse of the forward computation. While traditionalimplicit differentiation methods are usually used for static situations,\method{} extends it to the dynamic graph setting. Extensive experiments onthree large-scale real-world dynamic graph datasets validate the effectivenessof \method{} on dynamic node classification tasks with lower computationalcosts.</description><author>Nan Yin, Mengzhu Wang, Zhenghan Chen, Giulia De Masi, Bin Gu, Huan Xiong</author><pubDate>Mon, 29 Jul 2024 14:33:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05373v2</guid></item><item><title>Denoising ESG: quantifying data uncertainty from missing data with Machine Learning and prediction intervals</title><link>http://arxiv.org/abs/2407.20047v1</link><description>Environmental, Social, and Governance (ESG) datasets are frequently plaguedby significant data gaps, leading to inconsistencies in ESG ratings due tovarying imputation methods. This paper explores the application of establishedmachine learning techniques for imputing missing data in a real-world ESGdataset, emphasizing the quantification of uncertainty through predictionintervals. By employing multiple imputation strategies, this study assesses therobustness of imputation methods and quantifies the uncertainty associated withmissing data. The findings highlight the importance of probabilistic machinelearning models in providing better understanding of ESG scores, therebyaddressing the inherent risks of wrong ratings due to incomplete data. Thisapproach improves imputation practices to enhance the reliability of ESGratings.</description><author>Sergio Caprioli, Jacopo Foschi, Riccardo Crupi, Alessandro Sabatino</author><pubDate>Mon, 29 Jul 2024 14:31:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20047v1</guid></item><item><title>Exploring Large Language Models to generate Easy to Read content</title><link>http://arxiv.org/abs/2407.20046v1</link><description>Ensuring text accessibility and understandability are essential goals,particularly for individuals with cognitive impairments and intellectualdisabilities, who encounter challenges in accessing information across variousmediums such as web pages, newspapers, administrative tasks, or healthdocuments. Initiatives like Easy to Read and Plain Language guidelines aim tosimplify complex texts; however, standardizing these guidelines remainschallenging and often involves manual processes. This work presents anexploratory investigation into leveraging Artificial Intelligence (AI) andNatural Language Processing (NLP) approaches to systematically simplify Spanishtexts into Easy to Read formats, with a focus on utilizing Large LanguageModels (LLMs) for simplifying texts, especially in generating Easy to Readcontent. The study contributes a parallel corpus of Spanish adapted for Easy ToRead format, which serves as a valuable resource for training and testing textsimplification systems. Additionally, several text simplification experimentsusing LLMs and the collected corpus are conducted, involving fine-tuning andtesting a Llama2 model to generate Easy to Read content. A qualitativeevaluation, guided by an expert in text adaptation for Easy to Read content, iscarried out to assess the automatically simplified texts. This researchcontributes to advancing text accessibility for individuals with cognitiveimpairments, highlighting promising strategies for leveraging LLMs whileresponsibly managing energy usage.</description><author>Paloma Martínez, Lourdes Moreno, Alberto Ramos</author><pubDate>Mon, 29 Jul 2024 14:30:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20046v1</guid></item><item><title>MaskInversion: Localized Embeddings via Optimization of Explainability Maps</title><link>http://arxiv.org/abs/2407.20034v1</link><description>Vision-language foundation models such as CLIP have achieved tremendousresults in global vision-language alignment, but still show some limitations increating representations for specific image regions. % To address this problem,we propose MaskInversion, a method that leverages the feature representationsof pre-trained foundation models, such as CLIP, to generate a context-awareembedding for a query image region specified by a mask at test time.MaskInversion starts with initializing an embedding token and compares itsexplainability map, derived from the foundation model, to the query mask. Theembedding token is then subsequently refined to approximate the query region byminimizing the discrepancy between its explainability map and the query mask.During this process, only the embedding vector is updated, while the underlyingfoundation model is kept frozen allowing to use MaskInversion with anypre-trained model. As deriving the explainability map involves computing itsgradient, which can be expensive, we propose a gradient decomposition strategythat simplifies this computation. The learned region representation can be usedfor a broad range of tasks, including open-vocabulary class retrieval,referring expression comprehension, as well as for localized captioning andimage generation. We evaluate the proposed method on all those tasks on severaldatasets such as PascalVOC, MSCOCO, RefCOCO, and OpenImagesV7 and show itscapabilities compared to other SOTA approaches.</description><author>Walid Bousselham, Sofian Chaybouti, Christian Rupprecht, Vittorio Ferrari, Hilde Kuehne</author><pubDate>Mon, 29 Jul 2024 14:21:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20034v1</guid></item><item><title>Privacy-preserving data release leveraging optimal transport and particle gradient descent</title><link>http://arxiv.org/abs/2401.17823v3</link><description>We present a novel approach for differentially private data synthesis ofprotected tabular datasets, a relevant task in highly sensitive domains such ashealthcare and government. Current state-of-the-art methods predominantly usemarginal-based approaches, where a dataset is generated from private estimatesof the marginals. In this paper, we introduce PrivPGD, a new generation methodfor marginal-based private data synthesis, leveraging tools from optimaltransport and particle gradient descent. Our algorithm outperforms existingmethods on a large range of datasets while being highly scalable and offeringthe flexibility to incorporate additional domain-specific constraints.</description><author>Konstantin Donhauser, Javier Abad, Neha Hulkund, Fanny Yang</author><pubDate>Mon, 29 Jul 2024 14:12:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17823v3</guid></item><item><title>Non-Clashing Teaching Maps for Balls in Graphs</title><link>http://arxiv.org/abs/2309.02876v2</link><description>Recently, Kirkpatrick et al. [ALT 2019] and Fallat et al. [JMLR 2023]introduced non-clashing teaching and showed it is the most efficient machineteaching model satisfying the Goldman-Mathias collusion-avoidance criterion. Ateaching map $T$ for a concept class $\mathcal{C}$ assigns a (teaching) set$T(C)$ of examples to each concept $C \in \mathcal{C}$. A teaching map isnon-clashing if no pair of concepts are consistent with the union of theirteaching sets. The size of a non-clashing teaching map (NCTM) $T$ is themaximum size of a teaching set $T(C)$, $C \in \mathcal{C}$. The non-clashingteaching dimension NCTD$(\mathcal{C})$ of $\mathcal{C}$ is the minimum size ofan NCTM for $\mathcal{C}$. NCTM$^+$ and NCTD$^+(\mathcal{C})$ are definedanalogously, except the teacher may only use positive examples. We study NCTMs and NCTM$^+$s for the concept class $\mathcal{B}(G)$consisting of all balls of a graph $G$. We show that the associated decisionproblem B-NCTD$^+$ for NCTD$^+$ is NP-complete in split, co-bipartite, andbipartite graphs. Surprisingly, we even prove that, unless the ETH fails,B-NCTD$^+$ does not admit an algorithm running in time$2^{2^{o(\text{vc})}}\cdot n^{O(1)}$, nor a kernelization algorithm outputtinga kernel with $2^{o(\text{vc})}$ vertices, where vc is the vertex cover numberof $G$. We complement these lower bounds with matching upper bounds. These areextremely rare results: it is only the second problem in NP to admit such atight double-exponential lower bound parameterized by vc, and only one of veryfew problems to admit such an ETH-based conditional lower bound on the numberof vertices in a kernel. For trees, interval graphs, cycles, and trees ofcycles, we derive NCTM$^+$s or NCTMs for $\mathcal{B}(G)$ of size proportionalto its VC-dimension, and for Gromov-hyperbolic graphs, we design an approximateNCTM$^+$ of size 2.</description><author>Jérémie Chalopin, Victor Chepoi, Fionn Mc Inerney, Sébastien Ratel</author><pubDate>Mon, 29 Jul 2024 14:10:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02876v2</guid></item><item><title>Aircraft Trajectory Segmentation-based Contrastive Coding: A Framework for Self-supervised Trajectory Representation</title><link>http://arxiv.org/abs/2407.20028v1</link><description>Air traffic trajectory recognition has gained significant interest within theair traffic management community, particularly for fundamental tasks such asclassification and clustering. This paper introduces Aircraft TrajectorySegmentation-based Contrastive Coding (ATSCC), a novel self-supervised timeseries representation learning framework designed to capture semanticinformation in air traffic trajectory data. The framework leverages thesegmentable characteristic of trajectories and ensures consistency within theself-assigned segments. Intensive experiments were conducted on datasets fromthree different airports, totaling four datasets, comparing the learnedrepresentation's performance of downstream classification and clustering withother state-of-the-art representation learning techniques. The results showthat ATSCC outperforms these methods by aligning with the labels defined byaeronautical procedures. ATSCC is adaptable to various airport configurationsand scalable to incomplete trajectories. This research has expanded uponexisting capabilities, achieving these improvements independently withoutpredefined inputs such as airport configurations, maneuvering procedures, orlabeled data.</description><author>Thaweerath Phisannupawong, Joshua Julian Damanik, Han-Lim Choi</author><pubDate>Mon, 29 Jul 2024 14:04:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20028v1</guid></item><item><title>Identifiable latent bandits: Combining observational data and exploration for personalized healthcare</title><link>http://arxiv.org/abs/2407.16239v2</link><description>Bandit algorithms hold great promise for improving personalizeddecision-making but are notoriously sample-hungry. In most health applications,it is infeasible to fit a new bandit for each patient, and observable variablesare often insufficient to determine optimal treatments, ruling out applyingcontextual bandits learned from multiple patients. Latent bandits offer bothrapid exploration and personalization beyond what context variables can revealbut require that a latent variable model can be learned consistently. In thiswork, we propose bandit algorithms based on nonlinear independent componentanalysis that can be provably identified from observational data to a degreesufficient to infer the optimal action in a new bandit instance consistently.We verify this strategy in simulated data, showing substantial improvement overlearning independent multi-armed bandits for every instance.</description><author>Ahmet Zahid Balcıoğlu, Emil Carlsson, Fredrik D. Johansson</author><pubDate>Mon, 29 Jul 2024 14:04:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16239v2</guid></item><item><title>Robust and Resource-Efficient Data-Free Knowledge Distillation by Generative Pseudo Replay</title><link>http://arxiv.org/abs/2201.03019v3</link><description>Data-Free Knowledge Distillation (KD) allows knowledge transfer from atrained neural network (teacher) to a more compact one (student) in the absenceof original training data. Existing works use a validation set to monitor theaccuracy of the student over real data and report the highest performancethroughout the entire process. However, validation data may not be available atdistillation time either, making it infeasible to record the student snapshotthat achieved the peak accuracy. Therefore, a practical data-free KD methodshould be robust and ideally provide monotonically increasing student accuracyduring distillation. This is challenging because the student experiencesknowledge degradation due to the distribution shift of the synthetic data. Astraightforward approach to overcome this issue is to store and rehearse thegenerated samples periodically, which increases the memory footprint andcreates privacy concerns. We propose to model the distribution of thepreviously observed synthetic samples with a generative network. In particular,we design a Variational Autoencoder (VAE) with a training objective that iscustomized to learn the synthetic data representations optimally. The studentis rehearsed by the generative pseudo replay technique, with samples producedby the VAE. Hence knowledge degradation can be prevented without storing anysamples. Experiments on image classification benchmarks show that our methodoptimizes the expected value of the distilled model accuracy while eliminatingthe large memory overhead incurred by the sample-storing methods.</description><author>Kuluhan Binici, Shivam Aggarwal, Nam Trung Pham, Karianto Leman, Tulika Mitra</author><pubDate>Mon, 29 Jul 2024 13:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.03019v3</guid></item><item><title>MimiQ: Low-Bit Data-Free Quantization of Vision Transformers</title><link>http://arxiv.org/abs/2407.20021v1</link><description>Data-free quantization (DFQ) is a technique that creates a lightweightnetwork from its full-precision counterpart without the original training data,often through a synthetic dataset. Although several DFQ methods have beenproposed for vision transformer (ViT) architectures, they fail to achieveefficacy in low-bit settings. Examining the existing methods, we identify thattheir synthetic data produce misaligned attention maps, while those of the realsamples are highly aligned. From the observation of aligned attention, we findthat aligning attention maps of synthetic data helps to improve the overallperformance of quantized ViTs. Motivated by this finding, we devise \aname, anovel DFQ method designed for ViTs that focuses on inter-head attentionsimilarity. First, we generate synthetic data by aligning head-wise attentionresponses in relation to spatial query patches. Then, we apply head-wisestructural attention distillation to align the attention maps of the quantizednetwork to those of the full-precision teacher. The experimental results showthat the proposed method significantly outperforms baselines, setting a newstate-of-the-art performance for data-free ViT quantization.</description><author>Kanghyun Choi, Hye Yoon Lee, Dain Kwon, SunJong Park, Kyuyeun Kim, Noseong Park, Jinho Lee</author><pubDate>Mon, 29 Jul 2024 13:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20021v1</guid></item><item><title>ImagiNet: A Multi-Content Dataset for Generalizable Synthetic Image Detection via Contrastive Learning</title><link>http://arxiv.org/abs/2407.20020v1</link><description>Generative models, such as diffusion models (DMs), variational autoencoders(VAEs), and generative adversarial networks (GANs), produce images with a levelof authenticity that makes them nearly indistinguishable from real photos andartwork. While this capability is beneficial for many industries, thedifficulty of identifying synthetic images leaves online media platformsvulnerable to impersonation and misinformation attempts. To support thedevelopment of defensive methods, we introduce ImagiNet, a high-resolution andbalanced dataset for synthetic image detection, designed to mitigate potentialbiases in existing resources. It contains 200K examples, spanning four contentcategories: photos, paintings, faces, and uncategorized. Synthetic images areproduced with open-source and proprietary generators, whereas real counterpartsof the same content type are collected from public datasets. The structure ofImagiNet allows for a two-track evaluation system: i) classification as real orsynthetic and ii) identification of the generative model. To establish abaseline, we train a ResNet-50 model using a self-supervised contrastiveobjective (SelfCon) for each track. The model demonstrates state-of-the-artperformance and high inference speed across established benchmarks, achievingan AUC of up to 0.99 and balanced accuracy ranging from 86% to 95%, even undersocial network conditions that involve compression and resizing. Our data andcode are available at https://github.com/delyan-boychev/imaginet.</description><author>Delyan Boychev, Radostin Cholakov</author><pubDate>Mon, 29 Jul 2024 13:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20020v1</guid></item></channel></rss>