<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 19 Oct 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing</title><link>http://arxiv.org/abs/2310.12153v1</link><description>Adiabatic quantum computing (AQC) is a promising quantum computing approachfor discrete and often NP-hard optimization problems. Current AQCs allow toimplement problems of research interest, which has sparked the development ofquantum representations for many machine learning and computer vision tasks.Despite requiring multiple measurements from the noisy AQC, current approachesonly utilize the best measurement, discarding information contained in theremaining ones. In this work, we explore the potential of using thisinformation for probabilistic balanced k-means clustering. Instead ofdiscarding non-optimal solutions, we propose to use them to compute calibratedposterior probabilities with little additional compute cost. This allows us toidentify ambiguous solutions and data points, which we demonstrate on a D-WaveAQC on synthetic and real data.</description><author>Jan-Nico Zaech, Martin Danelljan, Luc Van Gool</author><pubDate>Wed, 18 Oct 2023 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12153v1</guid></item><item><title>Learning from Rich Semantics and Coarse Locations for Long-tailed Object Detection</title><link>http://arxiv.org/abs/2310.12152v1</link><description>Long-tailed object detection (LTOD) aims to handle the extreme data imbalancein real-world datasets, where many tail classes have scarce instances. Onepopular strategy is to explore extra data with image-level labels, yet itproduces limited results due to (1) semantic ambiguity -- an image-level labelonly captures a salient part of the image, ignoring the remaining richsemantics within the image; and (2) location sensitivity -- the label highlydepends on the locations and crops of the original image, which may changeafter data transformations like random cropping. To remedy this, we proposeRichSem, a simple but effective method, which is robust to learn rich semanticsfrom coarse locations without the need of accurate bounding boxes. RichSemleverages rich semantics from images, which are then served as additional softsupervision for training detectors. Specifically, we add a semantic branch toour detector to learn these soft semantics and enhance feature representationsfor long-tailed object detection. The semantic branch is only used for trainingand is removed during inference. RichSem achieves consistent improvements onboth overall and rare-category of LVIS under different backbones and detectors.Our method achieves state-of-the-art performance without requiring complextraining and testing procedures. Moreover, we show the effectiveness of ourmethod on other long-tailed datasets with additional experiments. Code isavailable at \url{https://github.com/MengLcool/RichSem}.</description><author>Lingchen Meng, Xiyang Dai, Jianwei Yang, Dongdong Chen, Yinpeng Chen, Mengchen Liu, Yi-Ling Chen, Zuxuan Wu, Lu Yuan, Yu-Gang Jiang</author><pubDate>Wed, 18 Oct 2023 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12152v1</guid></item><item><title>Understanding Retrieval Augmentation for Long-Form Question Answering</title><link>http://arxiv.org/abs/2310.12150v1</link><description>We present a study of retrieval-augmented language models (LMs) on long-formquestion answering. We analyze how retrieval augmentation impacts differentLMs, by comparing answers generated from models while using the same evidencedocuments, and how differing quality of retrieval document set impacts theanswers generated from the same LM. We study various attributes of generatedanswers (e.g., fluency, length, variance) with an emphasis on the attributionof generated long-form answers to in-context evidence documents. We collecthuman annotations of answer attribution and evaluate methods for automaticallyjudging attribution. Our study provides new insights on how retrievalaugmentation impacts long, knowledge-rich text generation of LMs. We furtheridentify attribution patterns for long text generation and analyze the mainculprits of attribution errors. Together, our analysis reveals how retrievalaugmentation impacts long knowledge-rich text generation and provide directionsfor future work.</description><author>Hung-Ting Chen, Fangyuan Xu, Shane A. Arora, Eunsol Choi</author><pubDate>Wed, 18 Oct 2023 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12150v1</guid></item><item><title>Object-aware Inversion and Reassembly for Image Editing</title><link>http://arxiv.org/abs/2310.12149v1</link><description>By comparing the original and target prompts in editing task, we can obtainnumerous editing pairs, each comprising an object and its corresponding editingtarget. To allow editability while maintaining fidelity to the input image,existing editing methods typically involve a fixed number of inversion stepsthat project the whole input image to its noisier latent representation,followed by a denoising process guided by the target prompt. However, we findthat the optimal number of inversion steps for achieving ideal editing resultsvaries significantly among different editing pairs, owing to varying editingdifficulties. Therefore, the current literature, which relies on a fixed numberof inversion steps, produces sub-optimal generation quality, especially whenhandling multiple editing pairs in a natural image. To this end, we propose anew image editing paradigm, dubbed Object-aware Inversion and Reassembly (OIR),to enable object-level fine-grained editing. Specifically, we design a newsearch metric, which determines the optimal inversion steps for each editingpair, by jointly considering the editability of the target and the fidelity ofthe non-editing region. We use our search metric to find the optimal inversionstep for each editing pair when editing an image. We then edit these editingpairs separately to avoid concept mismatch. Subsequently, we propose anadditional reassembly step to seamlessly integrate the respective editingresults and the non-editing region to obtain the final edited image. Tosystematically evaluate the effectiveness of our method, we collect twodatasets for benchmarking single- and multi-object editing, respectively.Experiments demonstrate that our method achieves superior performance inediting object shapes, colors, materials, categories, etc., especially inmulti-object editing scenarios.</description><author>Zhen Yang, Dinggang Gui, Wen Wang, Hao Chen, Bohan Zhuang, Chunhua Shen</author><pubDate>Wed, 18 Oct 2023 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12149v1</guid></item><item><title>InViG: Benchmarking Interactive Visual Grounding with 500K Human-Robot Interactions</title><link>http://arxiv.org/abs/2310.12147v1</link><description>Ambiguity is ubiquitous in human communication. Previous approaches inHuman-Robot Interaction (HRI) have often relied on predefined interactiontemplates, leading to reduced performance in realistic and open-endedscenarios. To address these issues, we present a large-scale dataset, \invig,for interactive visual grounding under language ambiguity. Our datasetcomprises over 520K images accompanied by open-ended goal-orienteddisambiguation dialogues, encompassing millions of object instances andcorresponding question-answer pairs. Leveraging the \invig dataset, we conductextensive studies and propose a set of baseline solutions for end-to-endinteractive visual disambiguation and grounding, achieving a 45.6\% successrate during validation. To the best of our knowledge, the \invig dataset is thefirst large-scale dataset for resolving open-ended interactive visualgrounding, presenting a practical yet highly challenging benchmark forambiguity-aware HRI. Codes and datasets are available at:\href{https://openivg.github.io}{https://openivg.github.io}.</description><author>Hanbo Zhang, Jie Xu, Yuchen Mo, Tao Kong</author><pubDate>Wed, 18 Oct 2023 18:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12147v1</guid></item><item><title>Fairer and More Accurate Tabular Models Through NAS</title><link>http://arxiv.org/abs/2310.12145v1</link><description>Making models algorithmically fairer in tabular data has been long studied,with techniques typically oriented towards fixes which usually take a neuralmodel with an undesirable outcome and make changes to how the data areingested, what the model weights are, or how outputs are processed. We employan emergent and different strategy where we consider updating the model'sarchitecture and training hyperparameters to find an entirely new model withbetter outcomes from the beginning of the debiasing procedure. In this work, wepropose using multi-objective Neural Architecture Search (NAS) andHyperparameter Optimization (HPO) in the first application to the verychallenging domain of tabular data. We conduct extensive exploration ofarchitectural and hyperparameter spaces (MLP, ResNet, and FT-Transformer)across diverse datasets, demonstrating the dependence of accuracy and fairnessmetrics of model predictions on hyperparameter combinations. We show thatmodels optimized solely for accuracy with NAS often fail to inherently addressfairness concerns. We propose a novel approach that jointly optimizesarchitectural and training hyperparameters in a multi-objective constraint ofboth accuracy and fairness. We produce architectures that consistently Paretodominate state-of-the-art bias mitigation methods either in fairness, accuracyor both, all of this while being Pareto-optimal over hyperparameters achievedthrough single-objective (accuracy) optimization runs. This researchunderscores the promise of automating fairness and accuracy optimization indeep learning models.</description><author>Richeek Das, Samuel Dooley</author><pubDate>Wed, 18 Oct 2023 18:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12145v1</guid></item><item><title>Dynamic financial processes identification using sparse regressive reservoir computers</title><link>http://arxiv.org/abs/2310.12144v1</link><description>In this document, we present key findings in structured matrix approximationtheory, with applications to the regressive representation of dynamic financialprocesses. Initially, we explore a comprehensive approach involving genericnonlinear time delay embedding for time series data extracted from a financialor economic system under examination. Subsequently, we employ sparseleast-squares and structured matrix approximation methods to discernapproximate representations of the output coupling matrices. Theserepresentations play a pivotal role in establishing the regressive modelscorresponding to the recursive structures inherent in a given financial system.The document further introduces prototypical algorithms that leverage theaforementioned techniques. These algorithms are demonstrated throughapplications in approximate identification and predictive simulation of dynamicfinancial and economic processes, encompassing scenarios that may or may notexhibit chaotic behavior.</description><author>Fredy Vides, Idelfonso B. R. Nogueira, Lendy Banegas, Evelyn Flores</author><pubDate>Wed, 18 Oct 2023 18:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12144v1</guid></item><item><title>Simple Mechanisms for Representing, Indexing and Manipulating Concepts</title><link>http://arxiv.org/abs/2310.12143v1</link><description>Deep networks typically learn concepts via classifiers, which involvessetting up a model and training it via gradient descent to fit theconcept-labeled data. We will argue instead that learning a concept could bedone by looking at its moment statistics matrix to generate a concreterepresentation or signature of that concept. These signatures can be used todiscover structure across the set of concepts and could recursively producehigher-level concepts by learning this structure from those signatures. Whenthe concepts are `intersected', signatures of the concepts can be used to finda common theme across a number of related `intersected' concepts. This processcould be used to keep a dictionary of concepts so that inputs could correctlyidentify and be routed to the set of concepts involved in the (latent)generation of the input.</description><author>Yuanzhi Li, Raghu Meka, Rina Panigrahy, Kulin Shah</author><pubDate>Wed, 18 Oct 2023 18:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12143v1</guid></item><item><title>Online Estimation with Rolling Validation: Adaptive Nonparametric Estimation with Stream Data</title><link>http://arxiv.org/abs/2310.12140v1</link><description>Online nonparametric estimators are gaining popularity due to their efficientcomputation and competitive generalization abilities. An important exampleincludes variants of stochastic gradient descent. These algorithms often takeone sample point at a time and instantly update the parameter estimate ofinterest. In this work we consider model selection and hyperparameter tuningfor such online algorithms. We propose a weighted rolling-validation procedure,an online variant of leave-one-out cross-validation, that costs minimal extracomputation for many typical stochastic gradient descent estimators. Similar tobatch cross-validation, it can boost base estimators to achieve a better,adaptive convergence rate. Our theoretical analysis is straightforward, relyingmainly on some general statistical stability assumptions. The simulation studyunderscores the significance of diverging weights in rolling validation inpractice and demonstrates its sensitivity even when there is only a slimdifference between candidate estimators.</description><author>Tianyu Zhang, Jing Lei</author><pubDate>Wed, 18 Oct 2023 18:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12140v1</guid></item><item><title>Pseudointelligence: A Unifying Framework for Language Model Evaluation</title><link>http://arxiv.org/abs/2310.12135v1</link><description>With large language models surpassing human performance on an increasingnumber of benchmarks, we must take a principled approach for targetedevaluation of model capabilities. Inspired by pseudorandomness, we proposepseudointelligence, which captures the maxim that "(perceived) intelligencelies in the eye of the beholder". That is, that claims of intelligence aremeaningful only when their evaluator is taken into account. Concretely, wepropose a complexity-theoretic framework of model evaluation cast as a dynamicinteraction between a model and a learned evaluator. We demonstrate that thisframework can be used to reason about two case studies in language modelevaluation, as well as analyze existing evaluation methods.</description><author>Shikhar Murty, Orr Paradise, Pratyusha Sharma</author><pubDate>Wed, 18 Oct 2023 18:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12135v1</guid></item><item><title>A comprehensible analysis of the efficacy of Ensemble Models for Bug Prediction</title><link>http://arxiv.org/abs/2310.12133v1</link><description>The correctness of software systems is vital for their effective operation.It makes discovering and fixing software bugs an important development task.The increasing use of Artificial Intelligence (AI) techniques in SoftwareEngineering led to the development of a number of techniques that can assistsoftware developers in identifying potential bugs in code. In this paper, wepresent a comprehensible comparison and analysis of the efficacy of twoAI-based approaches, namely single AI models and ensemble AI models, forpredicting the probability of a Java class being buggy. We used two open-sourceApache Commons Project's Java components for training and evaluating themodels. Our experimental findings indicate that the ensemble of AI models canoutperform the results of applying individual AI models. We also offer insightinto the factors that contribute to the enhanced performance of the ensemble AImodel. The presented results demonstrate the potential of using ensemble AImodels to enhance bug prediction results, which could ultimately result in morereliable software systems.</description><author>Ingrid Marçal, Rogério Eduardo Garcia</author><pubDate>Wed, 18 Oct 2023 18:43:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12133v1</guid></item><item><title>Direction-oriented Multi-objective Learning: Simple and Provable Stochastic Algorithms</title><link>http://arxiv.org/abs/2305.18409v2</link><description>Multi-objective optimization (MOO) has become an influential framework inmany machine learning problems with multiple objectives such as learning withmultiple criteria and multi-task learning (MTL). In this paper, we propose anew direction-oriented multi-objective problem by regularizing the commondescent direction within a neighborhood of a direction that optimizes a linearcombination of objectives such as the average loss in MTL. This formulationincludes GD and MGDA as special cases, enjoys the direction-oriented benefit asin CAGrad, and facilitates the design of stochastic algorithms. To solve thisproblem, we propose Stochastic Direction-oriented Multi-objective Gradientdescent (SDMGrad) with simple SGD type of updates, and its variant SDMGrad-OSwith an efficient objective sampling in the setting where the number ofobjectives is large. For a constant-level regularization parameter $\lambda$,we show that SDMGrad and SDMGrad-OS provably converge to a Pareto stationarypoint with improved complexities and milder assumptions. For an increasing$\lambda$, this convergent point reduces to a stationary point of the linearcombination of objectives. We demonstrate the superior performance of theproposed methods in a series of tasks on multi-task supervised learning andreinforcement learning. Code is provided athttps://github.com/ml-opt-lab/sdmgrad.</description><author>Peiyao Xiao, Hao Ban, Kaiyi Ji</author><pubDate>Wed, 18 Oct 2023 18:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18409v2</guid></item><item><title>DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning</title><link>http://arxiv.org/abs/2310.12128v1</link><description>Text-to-image (T2I) generation has seen significant growth over the past fewyears. Despite this, there has been little work on generating diagrams with T2Imodels. A diagram is a symbolic/schematic representation that explainsinformation using structurally rich and spatially complex visualizations (e.g.,a dense combination of related objects, text labels, directional arrows,connection lines, etc.). Existing state-of-the-art T2I models often fail atdiagram generation because they lack fine-grained object layout control whenmany objects are densely connected via complex relations such as arrows/linesand also often fail to render comprehensible text labels. To address this gap,we present DiagrammerGPT, a novel two-stage text-to-diagram generationframework that leverages the layout guidance capabilities of LLMs (e.g., GPT-4)to generate more accurate open-domain, open-platform diagrams. In the firststage, we use LLMs to generate and iteratively refine 'diagram plans' (in aplanner-auditor feedback loop) which describe all the entities (objects andtext labels), their relationships (arrows or lines), and their bounding boxlayouts. In the second stage, we use a diagram generator, DiagramGLIGEN, and atext label rendering module to generate diagrams following the diagram plans.To benchmark the text-to-diagram generation task, we introduce AI2D-Caption, adensely annotated diagram dataset built on top of the AI2D dataset. We showquantitatively and qualitatively that our DiagrammerGPT framework produces moreaccurate diagrams, outperforming existing T2I models. We also providecomprehensive analysis including open-domain diagram generation, vector graphicdiagram generation in different platforms, human-in-the-loop diagram planediting, and multimodal planner/auditor LLMs (e.g., GPT-4Vision). We hope ourwork can inspire further research on diagram generation via T2I models andLLMs.</description><author>Abhay Zala, Han Lin, Jaemin Cho, Mohit Bansal</author><pubDate>Wed, 18 Oct 2023 18:37:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12128v1</guid></item><item><title>A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation</title><link>http://arxiv.org/abs/2310.12127v1</link><description>Recent instruction fine-tuned models can solve multiple NLP tasks whenprompted to do so, with machine translation (MT) being a prominent use case.However, current research often focuses on standard performance benchmarks,leaving compelling fairness and ethical considerations behind. In MT, thismight lead to misgendered translations, resulting, among other harms, in theperpetuation of stereotypes and prejudices. In this work, we address this gapby investigating whether and to what extent such models exhibit gender bias inmachine translation and how we can mitigate it. Concretely, we computeestablished gender bias metrics on the WinoMT corpus from English to German andSpanish. We discover that IFT models default to male-inflected translations,even disregarding female occupational stereotypes. Next, using interpretabilitymethods, we unveil that models systematically overlook the pronoun indicatingthe gender of a target occupation in misgendered translations. Finally, basedon this finding, we propose an easy-to-implement and effective bias mitigationsolution based on few-shot learning that leads to significantly fairertranslations.</description><author>Giuseppe Attanasio, Flor Miriam Plaza-del-Arco, Debora Nozza, Anne Lauscher</author><pubDate>Wed, 18 Oct 2023 18:36:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12127v1</guid></item><item><title>SHARCS: Efficient Transformers through Routing with Dynamic Width Sub-networks</title><link>http://arxiv.org/abs/2310.12126v1</link><description>We introduce SHARCS for adaptive inference that takes into account thehardness of input samples. SHARCS can train a router on any transformernetwork, enabling the model to direct different samples to sub-networks withvarying widths. Our experiments demonstrate that: (1) SHARCS outperforms orcomplements existing per-sample adaptive inference methods across variousclassification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizesacross different architectures and can be even applied to compressed andefficient transformer encoders to further improve their efficiency; (3) SHARCScan provide a 2 times inference speed up at an insignificant drop in accuracy.</description><author>Mohammadreza Salehi, Sachin Mehta, Aditya Kusupati, Ali Farhadi, Hannaneh Hajishirzi</author><pubDate>Wed, 18 Oct 2023 18:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12126v1</guid></item><item><title>Bayesian longitudinal tensor response regression for modeling neuroplasticity</title><link>http://arxiv.org/abs/2309.10065v2</link><description>A major interest in longitudinal neuroimaging studies involves investigatingvoxel-level neuroplasticity due to treatment and other factors across visits.However, traditional voxel-wise methods are beset with several pitfalls, whichcan compromise the accuracy of these approaches. We propose a novel Bayesiantensor response regression approach for longitudinal imaging data, which poolsinformation across spatially-distributed voxels to infer significant changeswhile adjusting for covariates. The proposed method, which is implemented usingMarkov chain Monte Carlo (MCMC) sampling, utilizes low-rank decomposition toreduce dimensionality and preserve spatial configurations of voxels whenestimating coefficients. It also enables feature selection via joint credibleregions which respect the shape of the posterior distributions for moreaccurate inference. In addition to group level inferences, the method is ableto infer individual-level neuroplasticity, allowing for examination ofpersonalized disease or recovery trajectories. The advantages of the proposedapproach in terms of prediction and feature selection over voxel-wiseregression are highlighted via extensive simulation studies. Subsequently, weapply the approach to a longitudinal Aphasia dataset consisting of taskfunctional MRI images from a group of subjects who were administered either acontrol intervention or intention treatment at baseline and were followed upover subsequent visits. Our analysis revealed that while the control therapyshowed long-term increases in brain activity, the intention treatment producedpredominantly short-term changes, both of which were concentrated in distinctlocalized regions. In contrast, the voxel-wise regression failed to detect anysignificant neuroplasticity after multiplicity adjustments, which isbiologically implausible and implies lack of power.</description><author>Suprateek Kundu, Alec Reinhardt, Serena Song, Joo Han, M. Lawson Meadows, Bruce Crosson, Venkatagiri Krishnamurthy</author><pubDate>Wed, 18 Oct 2023 18:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10065v2</guid></item><item><title>Limited-Memory Greedy Quasi-Newton Method with Non-asymptotic Superlinear Convergence Rate</title><link>http://arxiv.org/abs/2306.15444v2</link><description>Non-asymptotic convergence analysis of quasi-Newton methods has gainedattention with a landmark result establishing an explicit local superlinearrate of O$((1/\sqrt{t})^t)$. The methods that obtain this rate, however,exhibit a well-known drawback: they require the storage of the previous Hessianapproximation matrix or all past curvature information to form the currentHessian inverse approximation. Limited-memory variants of quasi-Newton methodssuch as the celebrated L-BFGS alleviate this issue by leveraging a limitedwindow of past curvature information to construct the Hessian inverseapproximation. As a result, their per iteration complexity and storagerequirement is O$(\tau d)$ where $\tau\le d$ is the size of the window and $d$is the problem dimension reducing the O$(d^2)$ computational cost and memoryrequirement of standard quasi-Newton methods. However, to the best of ourknowledge, there is no result showing a non-asymptotic superlinear convergencerate for any limited-memory quasi-Newton method. In this work, we close thisgap by presenting a Limited-memory Greedy BFGS (LG-BFGS) method that canachieve an explicit non-asymptotic superlinear rate. We incorporatedisplacement aggregation, i.e., decorrelating projection, in post-processinggradient variations, together with a basis vector selection scheme on variablevariations, which greedily maximizes a progress measure of the Hessian estimateto the true Hessian. Their combination allows past curvature information toremain in a sparse subspace while yielding a valid representation of the fullhistory. Interestingly, our established non-asymptotic superlinear convergencerate demonstrates an explicit trade-off between the convergence speed andmemory requirement, which to our knowledge, is the first of its kind. Numericalresults corroborate our theoretical findings and demonstrate the effectivenessof our method.</description><author>Zhan Gao, Aryan Mokhtari, Alec Koppel</author><pubDate>Wed, 18 Oct 2023 18:21:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15444v2</guid></item><item><title>Automatic prediction of mortality in patients with mental illness using electronic health records</title><link>http://arxiv.org/abs/2310.12121v1</link><description>Mental disorders impact the lives of millions of people globally, not onlyimpeding their day-to-day lives but also markedly reducing life expectancy.This paper addresses the persistent challenge of predicting mortality inpatients with mental diagnoses using predictive machine-learning models withelectronic health records (EHR). Data from patients with mental diseasediagnoses were extracted from the well-known clinical MIMIC-III data setutilizing demographic, prescription, and procedural information. Four machinelearning algorithms (Logistic Regression, Random Forest, Support VectorMachine, and K-Nearest Neighbors) were used, with results indicating thatRandom Forest and Support Vector Machine models outperformed others, with AUCscores of 0.911. Feature importance analysis revealed that drug prescriptions,particularly Morphine Sulfate, play a pivotal role in prediction. We applied avariety of machine learning algorithms to predict 30-day mortality followed byfeature importance analysis. This study can be used to assist hospital workersin identifying at-risk patients to reduce excess mortality.</description><author>Sean Kim, Samuel Kim</author><pubDate>Wed, 18 Oct 2023 18:21:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12121v1</guid></item><item><title>AcTExplore: Active Tactile Exploration on Unknown Objects</title><link>http://arxiv.org/abs/2310.08745v2</link><description>Tactile exploration plays a crucial role in understanding object structuresfor fundamental robotics tasks such as grasping and manipulation. However,efficiently exploring such objects using tactile sensors is challenging,primarily due to the large-scale unknown environments and limited sensingcoverage of these sensors. To this end, we present AcTExplore, an activetactile exploration method driven by reinforcement learning for objectreconstruction at scales that automatically explores the object surfaces in alimited number of steps. Through sufficient exploration, our algorithmincrementally collects tactile data and reconstructs 3D shapes of the objectsas well, which can serve as a representation for higher-level downstream tasks.Our method achieves an average of 95.97% IoU coverage on unseen YCB objectswhile just being trained on primitive shapes. Project Webpage:https://prg.cs.umd$.$edu/AcTExplore</description><author>Amir-Hossein Shahidzadeh, Seong Jong Yoo, Pavan Mantripragada, Chahat Deep Singh, Cornelia Fermüller, Yiannis Aloimonos</author><pubDate>Wed, 18 Oct 2023 18:18:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08745v2</guid></item><item><title>Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers</title><link>http://arxiv.org/abs/2310.12118v1</link><description>Neural networks have revolutionized language modeling and excelled in variousdownstream tasks. However, the extent to which these models achievecompositional generalization comparable to human cognitive abilities remains atopic of debate. While existing approaches in the field have mainly focused onnovel architectures and alternative learning paradigms, we introduce apioneering method harnessing the power of dataset cartography (Swayamdipta etal., 2020). By strategically identifying a subset of compositionalgeneralization data using this approach, we achieve a remarkable improvement inmodel accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets.Notably, our technique incorporates dataset cartography as a curriculumlearning criterion, eliminating the need for hyperparameter tuning whileconsistently achieving superior performance. Our findings highlight theuntapped potential of dataset cartography in unleashing the full capabilitiesof compositional generalization within Transformer models. Our code isavailable at https://github.com/cyberiada/cartography-for-compositionality.</description><author>Osman Batur İnce, Tanin Zeraati, Semih Yagcioglu, Yadollah Yaghoobzadeh, Erkut Erdem, Aykut Erdem</author><pubDate>Wed, 18 Oct 2023 18:14:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12118v1</guid></item><item><title>MMD-based Variable Importance for Distributional Random Forest</title><link>http://arxiv.org/abs/2310.12115v1</link><description>Distributional Random Forest (DRF) is a flexible forest-based method toestimate the full conditional distribution of a multivariate output of interestgiven input variables. In this article, we introduce a variable importancealgorithm for DRFs, based on the well-established drop and relearn principleand MMD distance. While traditional importance measures only detect variableswith an influence on the output mean, our algorithm detects variables impactingthe output distribution more generally. We show that the introduced importancemeasure is consistent, exhibits high empirical performance on both real andsimulated data, and outperforms competitors. In particular, our algorithm ishighly efficient to select variables through recursive feature elimination, andcan therefore provide small sets of variables to build accurate estimates ofconditional output distributions.</description><author>Clément Bénard, Jeffrey Näf, Julie Josse</author><pubDate>Wed, 18 Oct 2023 18:12:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12115v1</guid></item><item><title>Marich: A Query-efficient Distributionally Equivalent Model Extraction Attack using Public Data</title><link>http://arxiv.org/abs/2302.08466v2</link><description>We study design of black-box model extraction attacks that can send minimalnumber of queries from a publicly available dataset to a target ML modelthrough a predictive API with an aim to create an informative anddistributionally equivalent replica of the target. First, we definedistributionally equivalent and Max-Information model extraction attacks, andreduce them into a variational optimisation problem. The attacker sequentiallysolves this optimisation problem to select the most informative queries thatsimultaneously maximise the entropy and reduce the mismatch between the targetand the stolen models. This leads to an active sampling-based query selectionalgorithm, Marich, which is model-oblivious. Then, we evaluate Marich ondifferent text and image data sets, and different models, including CNNs andBERT. Marich extracts models that achieve $\sim 60-95\%$ of true model'saccuracy and uses $\sim 1,000 - 8,500$ queries from the publicly availabledatasets, which are different from the private training datasets. Modelsextracted by Marich yield prediction distributions, which are $\sim 2-4\times$closer to the target's distribution in comparison to the existing activesampling-based attacks. The extracted models also lead to $84-96\%$ accuracyunder membership inference attacks. Experimental results validate that Marichis query-efficient, and capable of performing task-accurate, high-fidelity, andinformative model extraction.</description><author>Pratik Karmakar, Debabrota Basu</author><pubDate>Wed, 18 Oct 2023 18:08:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08466v2</guid></item><item><title>A Cautionary Tale: On the Role of Reference Data in Empirical Privacy Defenses</title><link>http://arxiv.org/abs/2310.12112v1</link><description>Within the realm of privacy-preserving machine learning, empirical privacydefenses have been proposed as a solution to achieve satisfactory levels oftraining data privacy without a significant drop in model utility. Mostexisting defenses against membership inference attacks assume access toreference data, defined as an additional dataset coming from the same (or asimilar) underlying distribution as training data. Despite the common use ofreference data, previous works are notably reticent about defining andevaluating reference data privacy. As gains in model utility and/or trainingdata privacy may come at the expense of reference data privacy, it is essentialthat all three aspects are duly considered. In this paper, we first examine theavailability of reference data and its privacy treatment in previous works anddemonstrate its necessity for fairly comparing defenses. Second, we propose abaseline defense that enables the utility-privacy tradeoff with respect to bothtraining and reference data to be easily understood. Our method is formulatedas an empirical risk minimization with a constraint on the generalizationerror, which, in practice, can be evaluated as a weighted empirical riskminimization (WERM) over the training and reference datasets. Although weconceived of WERM as a simple baseline, our experiments show that,surprisingly, it outperforms the most well-studied and current state-of-the-artempirical privacy defenses using reference data for nearly all relative privacylevels of reference and training data. Our investigation also reveals thatthese existing methods are unable to effectively trade off reference dataprivacy for model utility and/or training data privacy. Overall, our workhighlights the need for a proper evaluation of the triad model utility /training data privacy / reference data privacy when comparing privacy defenses.</description><author>Caelin G. Kaplan, Chuan Xu, Othmane Marfoq, Giovanni Neglia, Anderson Santana de Oliveira</author><pubDate>Wed, 18 Oct 2023 18:07:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12112v1</guid></item><item><title>DASA: Difficulty-Aware Semantic Augmentation for Speaker Verification</title><link>http://arxiv.org/abs/2310.12111v1</link><description>Data augmentation is vital to the generalization ability and robustness ofdeep neural networks (DNNs) models. Existing augmentation methods for speakerverification manipulate the raw signal, which are time-consuming and theaugmented samples lack diversity. In this paper, we present a noveldifficulty-aware semantic augmentation (DASA) approach for speakerverification, which can generate diversified training samples in speakerembedding space with negligible extra computing cost. Firstly, we augmenttraining samples by perturbing speaker embeddings along semantic directions,which are obtained from speaker-wise covariance matrices. Secondly, accuratecovariance matrices are estimated from robust speaker embeddings duringtraining, so we introduce difficultyaware additive margin softmax(DAAM-Softmax) to obtain optimal speaker embeddings. Finally, we assume thenumber of augmented samples goes to infinity and derive a closed-form upperbound of the expected loss with DASA, which achieves compatibility andefficiency. Extensive experiments demonstrate the proposed approach can achievea remarkable performance improvement. The best result achieves a 14.6% relativereduction in EER metric on CN-Celeb evaluation set.</description><author>Yuanyuan Wang, Yang Zhang, Zhiyong Wu, Zhihan Yang, Tao Wei, Kun Zou, Helen Meng</author><pubDate>Wed, 18 Oct 2023 18:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12111v1</guid></item><item><title>Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture</title><link>http://arxiv.org/abs/2310.12109v1</link><description>Machine learning models are increasingly being scaled in both sequence lengthand model dimension to reach longer contexts and better performance. However,existing architectures such as Transformers scale quadratically along boththese axes. We ask: are there performant architectures that can scalesub-quadratically along sequence length and model dimension? We introduceMonarch Mixer (M2), a new architecture that uses the same sub-quadraticprimitive along both sequence length and model dimension: Monarch matrices, asimple class of expressive structured matrices that captures many lineartransforms, achieves high hardware efficiency on GPUs, and scalessub-quadratically. As a proof of concept, we explore the performance of M2 inthree domains: non-causal BERT-style language modeling, ViT-style imageclassification, and causal GPT-style language modeling. For non-causalBERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUEquality with up to 27% fewer parameters, and achieves up to 9.1$\times$ higherthroughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% inaccuracy, with only half the parameters. Causal GPT-style models introduce atechnical challenge: enforcing causality via masking introduces a quadraticbottleneck. To alleviate this bottleneck, we develop a novel theoretical viewof Monarch matrices based on multivariate polynomial evaluation andinterpolation, which lets us parameterize M2 to be causal while remainingsub-quadratic. Using this parameterization, M2 matches GPT-style Transformersat 360M parameters in pretraining perplexity on The PILE--showing for the firsttime that it may be possible to match Transformer quality without attention orMLPs.</description><author>Daniel Y. Fu, Simran Arora, Jessica Grogan, Isys Johnson, Sabri Eyuboglu, Armin W. Thomas, Benjamin Spector, Michael Poli, Atri Rudra, Christopher Ré</author><pubDate>Wed, 18 Oct 2023 18:06:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12109v1</guid></item><item><title>Prompting ChatGPT in MNER: Enhanced Multimodal Named Entity Recognition with Auxiliary Refined Knowledge</title><link>http://arxiv.org/abs/2305.12212v2</link><description>Multimodal Named Entity Recognition (MNER) on social media aims to enhancetextual entity prediction by incorporating image-based clues. Existing studiesmainly focus on maximizing the utilization of pertinent image information orincorporating external knowledge from explicit knowledge bases. However, thesemethods either neglect the necessity of providing the model with externalknowledge, or encounter issues of high redundancy in the retrieved knowledge.In this paper, we present PGIM -- a two-stage framework that aims to leverageChatGPT as an implicit knowledge base and enable it to heuristically generateauxiliary knowledge for more efficient entity prediction. Specifically, PGIMcontains a Multimodal Similar Example Awareness module that selects suitableexamples from a small number of predefined artificial samples. These examplesare then integrated into a formatted prompt template tailored to the MNER andguide ChatGPT to generate auxiliary refined knowledge. Finally, the acquiredknowledge is integrated with the original text and fed into a downstream modelfor further processing. Extensive experiments show that PGIM outperformsstate-of-the-art methods on two classic MNER datasets and exhibits a strongerrobustness and generalization capability.</description><author>Jinyuan Li, Han Li, Zhuo Pan, Di Sun, Jiahao Wang, Wenkun Zhang, Gang Pan</author><pubDate>Wed, 18 Oct 2023 18:05:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12212v2</guid></item><item><title>An Online Learning Theory of Brokerage</title><link>http://arxiv.org/abs/2310.12107v1</link><description>We investigate brokerage between traders from an online learning perspective.At any round $t$, two traders arrive with their private valuations, and thebroker proposes a trading price. Unlike other bilateral trade problems alreadystudied in the online learning literature, we focus on the case where there areno designated buyer and seller roles: each trader will attempt to either buy orsell depending on the current price of the good. We assume the agents' valuations are drawn i.i.d. from a fixed but unknowndistribution. If the distribution admits a density bounded by some constant$M$, then, for any time horizon $T$: $\bullet$ If the agents' valuations are revealed after each interaction, weprovide an algorithm achieving regret $M \log T$ and show this rate is optimal,up to constant factors. $\bullet$ If only their willingness to sell or buy at the proposed price isrevealed after each interaction, we provide an algorithm achieving regret$\sqrt{M T}$ and show this rate is optimal, up to constant factors. Finally, if we drop the bounded density assumption, we show that the optimalrate degrades to $\sqrt{T}$ in the first case, and the problem becomesunlearnable in the second.</description><author>Nataša Bolić, Tommaso Cesari, Roberto Colomboni</author><pubDate>Wed, 18 Oct 2023 18:01:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12107v1</guid></item><item><title>Quality control using convolutional neural networks applied to samples of very small size</title><link>http://arxiv.org/abs/2310.10608v2</link><description>Although there is extensive literature on the application of artificialneural networks (NNs) in quality control (QC), to monitor the conformity of aprocess to quality specifications, at least five QC measurements are required,increasing the related cost. To explore the application of neural networks tosamples of QC measurements of very small size, four one-dimensional (1-D)convolutional neural networks (CNNs) were designed, trained, and tested withdatasets of $ n $-tuples of simulated standardized normally distributed QCmeasurements, for $ 1 \leq n \leq 4$. The designed neural networks werecompared to statistical QC functions with equal probabilities for falserejection, applied to samples of the same size. When the $ n $-tuples includedat least two QC measurements distributed as $ \mathcal{N}(\mu, \sigma^2) $,where $ 0.2 &lt; |\mu| \leq 6.0 $, and $ 1.0 &lt; \sigma \leq 7.0 $, the designedneural networks outperformed the respective statistical QC functions.Therefore, 1-D CNNs applied to samples of 2-4 quality control measurements canbe used to increase the probability of detection of the nonconformity of aprocess to the quality specifications, with lower cost.</description><author>Rallou A. Chatzimichail, Aristides T. Hatjimihail</author><pubDate>Wed, 18 Oct 2023 17:53:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10608v2</guid></item><item><title>Quality Diversity through Human Feedback</title><link>http://arxiv.org/abs/2310.12103v1</link><description>Reinforcement learning from human feedback (RLHF) has exhibited the potentialto enhance the performance of foundation models for qualitative tasks. Despiteits promise, its efficacy is often restricted when conceptualized merely as amechanism to maximize learned reward models of averaged human preferences,especially in areas such as image generation which demand diverse modelresponses. Meanwhile, quality diversity (QD) algorithms, dedicated to seekingdiverse, high-quality solutions, are often constrained by the dependency onmanually defined diversity metrics. Interestingly, such limitations of RLHF andQD can be overcome by blending insights from both. This paper introducesQuality Diversity through Human Feedback (QDHF), which employs human feedbackfor inferring diversity metrics, expanding the applicability of QD algorithms.Empirical results reveal that QDHF outperforms existing QD methods regardingautomatic diversity discovery, and matches the search capabilities of QD withhuman-constructed metrics. Notably, when deployed for a latent spaceillumination task, QDHF markedly enhances the diversity of images generated bya Diffusion model. The study concludes with an in-depth analysis of QDHF'ssample efficiency and the quality of its derived diversity metrics, emphasizingits promise for enhancing exploration and diversity in optimization forcomplex, open-ended tasks.</description><author>Li Ding, Jenny Zhang, Jeff Clune, Lee Spector, Joel Lehman</author><pubDate>Wed, 18 Oct 2023 17:46:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12103v1</guid></item><item><title>On the Convergence of No-Regret Learning Dynamics in Time-Varying Games</title><link>http://arxiv.org/abs/2301.11241v3</link><description>Most of the literature on learning in games has focused on the restrictivesetting where the underlying repeated game does not change over time. Much lessis known about the convergence of no-regret learning algorithms in dynamicmultiagent settings. In this paper, we characterize the convergence ofoptimistic gradient descent (OGD) in time-varying games. Our framework yieldssharp convergence bounds for the equilibrium gap of OGD in zero-sum gamesparameterized on natural variation measures of the sequence of games, subsumingknown results for static games. Furthermore, we establish improved second-ordervariation bounds under strong convexity-concavity, as long as each game isrepeated multiple times. Our results also apply to time-varying general-summulti-player games via a bilinear formulation of correlated equilibria, whichhas novel implications for meta-learning and for obtaining refinedvariation-dependent regret bounds, addressing questions left open in priorpapers. Finally, we leverage our framework to also provide new insights ondynamic regret guarantees in static games.</description><author>Ioannis Anagnostides, Ioannis Panageas, Gabriele Farina, Tuomas Sandholm</author><pubDate>Wed, 18 Oct 2023 17:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11241v3</guid></item><item><title>Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling</title><link>http://arxiv.org/abs/2310.12100v1</link><description>Large language models (LLMs) and vision language models (VLMs) demonstrateexcellent performance on a wide range of tasks by scaling up parameter countsfrom O(10^9) to O(10^{12}) levels and further beyond. These large scales makeit impossible to adapt and deploy fully specialized models given a task ofinterest. Parameter-efficient fine-tuning (PEFT) emerges as a promisingdirection to tackle the adaptation and serving challenges for such largemodels. We categorize PEFT techniques into two types: intrusive andnon-intrusive. Intrusive PEFT techniques directly change a model's internalarchitecture. Though more flexible, they introduce significant complexities fortraining and serving. Non-intrusive PEFT techniques leave the internalarchitecture unchanged and only adapt model-external parameters, such asembeddings for input. In this work, we describe AdaLink as a non-intrusive PEFTtechnique that achieves competitive performance compared to SoTA intrusive PEFT(LoRA) and full model fine-tuning (FT) on various tasks. We evaluate using bothtext-only and multimodal tasks, with experiments that account for bothparameter-count scaling and training regime (with and without instructiontuning).</description><author>Yaqing Wang, Jialin Wu, Tanmaya Dabral, Jiageng Zhang, Geoff Brown, Chun-Ta Lu, Frederick Liu, Yi Liang, Bo Pang, Michael Bendersky, Radu Soricut</author><pubDate>Wed, 18 Oct 2023 17:43:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12100v1</guid></item><item><title>On the latent dimension of deep autoencoders for reduced order modeling of PDEs parametrized by random fields</title><link>http://arxiv.org/abs/2310.12095v1</link><description>Deep Learning is having a remarkable impact on the design of Reduced OrderModels (ROMs) for Partial Differential Equations (PDEs), where it is exploitedas a powerful tool for tackling complex problems for which classical methodsmight fail. In this respect, deep autoencoders play a fundamental role, as theyprovide an extremely flexible tool for reducing the dimensionality of a givenproblem by leveraging on the nonlinear capabilities of neural networks. Indeed,starting from this paradigm, several successful approaches have already beendeveloped, which are here referred to as Deep Learning-based ROMs (DL-ROMs).Nevertheless, when it comes to stochastic problems parameterized by randomfields, the current understanding of DL-ROMs is mostly based on empiricalevidence: in fact, their theoretical analysis is currently limited to the caseof PDEs depending on a finite number of (deterministic) parameters. The purposeof this work is to extend the existing literature by providing some theoreticalinsights about the use of DL-ROMs in the presence of stochasticity generated byrandom fields. In particular, we derive explicit error bounds that can guidedomain practitioners when choosing the latent dimension of deep autoencoders.We evaluate the practical usefulness of our theory by means of numericalexperiments, showing how our analysis can significantly impact the performanceof DL-ROMs.</description><author>Nicola Rares Franco, Daniel Fraulin, Andrea Manzoni, Paolo Zunino</author><pubDate>Wed, 18 Oct 2023 17:38:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12095v1</guid></item><item><title>HSTR-Net: Reference Based Video Super-resolution for Aerial Surveillance with Dual Cameras</title><link>http://arxiv.org/abs/2310.12092v1</link><description>Aerial surveillance requires high spatio-temporal resolution (HSTR) video formore accurate detection and tracking of objects. This is especially true forwide-area surveillance (WAS), where the surveyed region is large and theobjects of interest are small. This paper proposes a dual camera system for thegeneration of HSTR video using reference-based super-resolution (RefSR). Onecamera captures high spatial resolution low frame rate (HSLF) video while theother captures low spatial resolution high frame rate (LSHF) videosimultaneously for the same scene. A novel deep learning architecture isproposed to fuse HSLF and LSHF video feeds and synthesize HSTR video frames atthe output. The proposed model combines optical flow estimation and(channel-wise and spatial) attention mechanisms to capture the fine motion andintricate dependencies between frames of the two video feeds. Simulations showthat the proposed model provides significant improvement over existingreference-based SR techniques in terms of PSNR and SSIM metrics. The methodalso exhibits sufficient frames per second (FPS) for WAS when deployed on apower-constrained drone equipped with dual cameras.</description><author>H. Umut Suluhan, Hasan F. Ates, Bahadir K. Gunturk</author><pubDate>Wed, 18 Oct 2023 17:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12092v1</guid></item><item><title>Boundary Guided Learning-Free Semantic Control with Diffusion Models</title><link>http://arxiv.org/abs/2302.08357v3</link><description>Applying pre-trained generative denoising diffusion models (DDMs) fordownstream tasks such as image semantic editing usually requires eitherfine-tuning DDMs or learning auxiliary editing networks in the existingliterature. In this work, we present our BoundaryDiffusion method forefficient, effective and light-weight semantic control with frozen pre-trainedDDMs, without learning any extra networks. As one of the first learning-freediffusion editing works, we start by seeking a comprehensive understanding ofthe intermediate high-dimensional latent spaces by theoretically andempirically analyzing their probabilistic and geometric behaviors in the Markovchain. We then propose to further explore the critical step for editing in thedenoising trajectory that characterizes the convergence of a pre-trained DDMand introduce an automatic search method. Last but not least, in contrast tothe conventional understanding that DDMs have relatively poor semanticbehaviors, we prove that the critical latent space we found already exhibitssemantic subspace boundaries at the generic level in unconditional DDMs, whichallows us to do controllable manipulation by guiding the denoising trajectorytowards the targeted boundary via a single-step operation. We conduct extensiveexperiments on multiple DPMs architectures (DDPM, iDDPM) and datasets (CelebA,CelebA-HQ, LSUN-church, LSUN-bedroom, AFHQ-dog) with different resolutions (64,256), achieving superior or state-of-the-art performance in various taskscenarios (image semantic editing, text-based editing, unconditional semanticcontrol) to demonstrate the effectiveness.</description><author>Ye Zhu, Yu Wu, Zhiwei Deng, Olga Russakovsky, Yan Yan</author><pubDate>Wed, 18 Oct 2023 17:35:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08357v3</guid></item><item><title>YATO: Yet Another deep learning based Text analysis Open toolkit</title><link>http://arxiv.org/abs/2209.13877v4</link><description>We introduce YATO, an open-source, easy-to-use toolkit for text analysis withdeep learning. Different from existing heavily engineered toolkits andplatforms, YATO is lightweight and user-friendly for researchers fromcross-disciplinary areas. Designed in a hierarchical structure, YATO supportsfree combinations of three types of widely used features including 1)traditional neural networks (CNN, RNN, etc.); 2) pre-trained language models(BERT, RoBERTa, ELECTRA, etc.); and 3) user-customized neural features via asimple configurable file. Benefiting from the advantages of flexibility andease of use, YATO can facilitate fast reproduction and refinement ofstate-of-the-art NLP models, and promote the cross-disciplinary applications ofNLP techniques. The code, examples, and documentation are publicly available athttps://github.com/jiesutd/YATO. A demo video is also available athttps://www.youtube.com/playlist?list=PLJ0mhzMcRuDUlTkzBfAftOqiJRxYTTjXH.</description><author>Zeqiang Wang, Yile Wang, Jiageng Wu, Zhiyang Teng, Jie Yang</author><pubDate>Wed, 18 Oct 2023 17:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.13877v4</guid></item><item><title>Unveiling the Siren's Song: Towards Reliable Fact-Conflicting Hallucination Detection</title><link>http://arxiv.org/abs/2310.12086v1</link><description>Large Language Models (LLMs), such as ChatGPT/GPT-4, have garnered widespreadattention owing to their myriad of practical applications, yet their adoptionhas been constrained by issues of fact-conflicting hallucinations across webplatforms. The assessment of factuality in text, produced by LLMs, remainsinadequately explored, extending not only to the judgment of vanilla facts butalso encompassing the evaluation of factual errors emerging in complexinferential tasks like multi-hop, and etc. In response, we introduce FactCHD, afact-conflicting hallucination detection benchmark meticulously designed forLLMs. Functioning as a pivotal tool in evaluating factuality within"Query-Respons" contexts, our benchmark assimilates a large-scale dataset,encapsulating a broad spectrum of factuality patterns, such as vanilla,multi-hops, comparison, and set-operation patterns. A distinctive feature ofour benchmark is its incorporation of fact-based chains of evidence, therebyfacilitating comprehensive and conducive factual reasoning throughout theassessment process. We evaluate multiple LLMs, demonstrating the effectivenessof the benchmark and current methods fall short of faithfully detecting factualerrors. Furthermore, we present TRUTH-TRIANGULATOR that synthesizes reflectiveconsiderations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aimingto yield more credible detection through the amalgamation of predictive resultsand evidence. The benchmark dataset and source code will be made available inhttps://github.com/zjunlp/FactCHD.</description><author>Xiang Chen, Duanzheng Song, Honghao Gui, Chengxi Wang, Ningyu Zhang, Fei Huang, Chengfei Lv, Dan Zhang, Huajun Chen</author><pubDate>Wed, 18 Oct 2023 17:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12086v1</guid></item><item><title>On the Benefit of Generative Foundation Models for Human Activity Recognition</title><link>http://arxiv.org/abs/2310.12085v1</link><description>In human activity recognition (HAR), the limited availability of annotateddata presents a significant challenge. Drawing inspiration from the latestadvancements in generative AI, including Large Language Models (LLMs) andmotion synthesis models, we believe that generative AI can address this datascarcity by autonomously generating virtual IMU data from text descriptions.Beyond this, we spotlight several promising research pathways that couldbenefit from generative AI for the community, including the generatingbenchmark datasets, the development of foundational models specific to HAR, theexploration of hierarchical structures within HAR, breaking down complexactivities, and applications in health sensing and activity summarization.</description><author>Zikang Leng, Hyeokhyen Kwon, Thomas Plötz</author><pubDate>Wed, 18 Oct 2023 17:27:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12085v1</guid></item><item><title>What model does MuZero learn?</title><link>http://arxiv.org/abs/2306.00840v2</link><description>Model-based reinforcement learning has drawn considerable interest in recentyears, given its promise to improve sample efficiency. Moreover, when usingdeep-learned models, it is potentially possible to learn compact models fromcomplex sensor data. However, the effectiveness of these learned models,particularly their capacity to plan, i.e., to improve the current policy,remains unclear. In this work, we study MuZero, a well-known deep model-basedreinforcement learning algorithm, and explore how far it achieves its learningobjective of a value-equivalent model and how useful the learned models are forpolicy improvement. Amongst various other insights, we conclude that the modellearned by MuZero cannot effectively generalize to evaluate unseen policies,which limits the extent to which we can additionally improve the current policyby planning with the model.</description><author>Jinke He, Thomas M. Moerland, Frans A. Oliehoek</author><pubDate>Wed, 18 Oct 2023 17:25:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00840v2</guid></item><item><title>Contributing Components of Metabolic Energy Models to Metabolic Cost Estimations in Gait</title><link>http://arxiv.org/abs/2310.12083v1</link><description>Objective: As metabolic cost is a primary factor influencing humans' gait, wewant to deepen our understanding of metabolic energy expenditure models.Therefore, this paper identifies the parameters and input variables, such asmuscle or joint states, that contribute to accurate metabolic cost estimations.Methods: We explored the parameters of four metabolic energy expenditure modelsin a Monte Carlo sensitivity analysis. Then, we analysed the model parametersby their calculated sensitivity indices, physiological context, and theresulting metabolic rates during the gait cycle. The parameter combination withthe highest accuracy in the Monte Carlo simulations represented aquasi-optimized model. In the second step, we investigated the importance ofinput parameters and variables by analysing the accuracy of neural networkstrained with different input features. Results: Power-related parameters weremost influential in the sensitivity analysis and the neural network-basedfeature selection. We observed that the quasi-optimized models producednegative metabolic rates, contradicting muscle physiology. Neural network-basedmodels showed promising abilities but have been unable to match the accuracy oftraditional metabolic energy expenditure models. Conclusion: We showed thatpower-related metabolic energy expenditure model parameters and inputs are mostinfluential during gait. Furthermore, our results suggest that neuralnetwork-based metabolic energy expenditure models are viable. However, biggerdatasets are required to achieve better accuracy. Significance: As there is aneed for more accurate metabolic energy expenditure models, we explored whichmusculoskeletal parameters are essential when developing a model to estimatemetabolic energy.</description><author>Markus Gambietz, Marlies Nitschke, Jörg Miehling, Anne Koelewijn</author><pubDate>Wed, 18 Oct 2023 17:24:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12083v1</guid></item><item><title>DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework</title><link>http://arxiv.org/abs/2310.12081v1</link><description>Graph matching is one of the most significant graph analytic tasks inpractice, which aims to find the node correspondence across different graphs.Most existing approaches rely on adjacency matrices or node embeddings whenmatching graphs, whose performances are often sub-optimal because of not fullyleveraging the multi-modal information hidden in graphs, such as nodeattributes, subgraph structures, etc. In this study, we propose a novel andeffective graph matching method based on a differentiable hierarchical optimaltransport (HOT) framework, called DHOT-GM. Essentially, our method representseach graph as a set of relational matrices corresponding to the information ofdifferent modalities. Given two graphs, we enumerate all relational matrixpairs and obtain their matching results, and accordingly, infer the nodecorrespondence by the weighted averaging of the matching results. This methodcan be implemented as computing the HOT distance between the two graphs -- eachmatching result is an optimal transport plan associated with theGromov-Wasserstein (GW) distance between two relational matrices, and theweights of all matching results are the elements of an upper-level optimaltransport plan defined on the matrix sets. We propose a bi-level optimizationalgorithm to compute the HOT distance in a differentiable way, making thesignificance of the relational matrices adjustable. Experiments on variousgraph matching tasks demonstrate the superiority and robustness of our methodcompared to state-of-the-art approaches.</description><author>Haoran Cheng, Dixin Luo, Hongteng Xu</author><pubDate>Wed, 18 Oct 2023 17:16:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12081v1</guid></item><item><title>Differential Equation Scaling Limits of Shaped and Unshaped Neural Networks</title><link>http://arxiv.org/abs/2310.12079v1</link><description>Recent analyses of neural networks with shaped activations (i.e. theactivation function is scaled as the network size grows) have led to scalinglimits described by differential equations. However, these results do not apriori tell us anything about "ordinary" unshaped networks, where theactivation is unchanged as the network size grows. In this article, we findsimilar differential equation based asymptotic characterization for two typesof unshaped networks. Firstly, we show that the following two architectures converge to the sameinfinite-depth-and-width limit at initialization: (i) a fully connected ResNetwith a $d^{-1/2}$ factor on the residual branch, where $d$ is the networkdepth. (ii) a multilayer perceptron (MLP) with depth $d \ll$ width $n$ andshaped ReLU activation at rate $d^{-1/2}$. Secondly, for an unshaped MLP at initialization, we derive the first orderasymptotic correction to the layerwise correlation. In particular, if$\rho_\ell$ is the correlation at layer $\ell$, then $q_t = \ell^2 (1 -\rho_\ell)$ with $t = \frac{\ell}{n}$ converges to an SDE with a singularity at$t=0$. These results together provide a connection between shaped and unshapednetwork architectures, and opens up the possibility of studying the effect ofnormalization methods and how it connects with shaping activation functions.</description><author>Mufan Bill Li, Mihai Nica</author><pubDate>Wed, 18 Oct 2023 17:15:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12079v1</guid></item><item><title>One-Shot Imitation Learning: A Pose Estimation Perspective</title><link>http://arxiv.org/abs/2310.12077v1</link><description>In this paper, we study imitation learning under the challenging setting of:(1) only a single demonstration, (2) no further data collection, and (3) noprior task or object knowledge. We show how, with these constraints, imitationlearning can be formulated as a combination of trajectory transfer and unseenobject pose estimation. To explore this idea, we provide an in-depth study onhow state-of-the-art unseen object pose estimators perform for one-shotimitation learning on ten real-world tasks, and we take a deep dive into theeffects that camera calibration, pose estimation error, and spatialgeneralisation have on task success rates. For videos, please visithttps://www.robot-learning.uk/pose-estimation-perspective.</description><author>Pietro Vitiello, Kamil Dreczkowski, Edward Johns</author><pubDate>Wed, 18 Oct 2023 17:13:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12077v1</guid></item><item><title>Exploring Fairness in Pre-trained Visual Transformer based Natural and GAN Generated Image Detection Systems and Understanding the Impact of Image Compression in Fairness</title><link>http://arxiv.org/abs/2310.12076v1</link><description>It is not only sufficient to construct computational models that canaccurately classify or detect fake images from real images taken from a camera,but it is also important to ensure whether these computational models are fairenough or produce biased outcomes that can eventually harm certain socialgroups or cause serious security threats. Exploring fairness in forensicalgorithms is an initial step towards correcting these biases. Since visualtransformers are recently being widely used in most image classification basedtasks due to their capability to produce high accuracies, this study tries toexplore bias in the transformer based image forensic algorithms that classifynatural and GAN generated images. By procuring a bias evaluation corpora, thisstudy analyzes bias in gender, racial, affective, and intersectional domainsusing a wide set of individual and pairwise bias evaluation measures. As thegeneralizability of the algorithms against image compression is an importantfactor to be considered in forensic tasks, this study also analyzes the role ofimage compression on model bias. Hence to study the impact of image compressionon model bias, a two phase evaluation setting is followed, where a set ofexperiments is carried out in the uncompressed evaluation setting and the otherin the compressed evaluation setting.</description><author>Manjary P. Gangan, Anoop Kadan, Lajish V L</author><pubDate>Wed, 18 Oct 2023 17:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12076v1</guid></item><item><title>A Systematic Study of Joint Representation Learning on Protein Sequences and Structures</title><link>http://arxiv.org/abs/2303.06275v2</link><description>Learning effective protein representations is critical in a variety of tasksin biology such as predicting protein functions. Recent sequence representationlearning methods based on Protein Language Models (PLMs) excel insequence-based tasks, but their direct adaptation to tasks involving proteinstructures remains a challenge. In contrast, structure-based methods leverage3D structural information with graph neural networks and geometric pre-trainingmethods show potential in function prediction tasks, but still suffers from thelimited number of available structures. To bridge this gap, our studyundertakes a comprehensive exploration of joint protein representation learningby integrating a state-of-the-art PLM (ESM-2) with distinct structure encoders(GVP, GearNet, CDConv). We introduce three representation fusion strategies andexplore different pre-training techniques. Our method achieves significantimprovements over existing sequence- and structure-based methods, setting newstate-of-the-art for function annotation. This study underscores severalimportant design choices for fusing protein sequence and structure information.Our implementation is available athttps://github.com/DeepGraphLearning/ESM-GearNet.</description><author>Zuobai Zhang, Chuanrui Wang, Minghao Xu, Vijil Chenthamarakshan, Aurélie Lozano, Payel Das, Jian Tang</author><pubDate>Wed, 18 Oct 2023 17:11:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06275v2</guid></item><item><title>Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas Incidents for Preventing Future Failures</title><link>http://arxiv.org/abs/2310.12074v1</link><description>This paper introduces a new IncidentAI dataset for safety prevention.Different from prior corpora that usually contain a single task, our datasetcomprises three tasks: named entity recognition, cause-effect extraction, andinformation retrieval. The dataset is annotated by domain experts who have atleast six years of practical experience as high-pressure gas conservationmanagers. We validate the contribution of the dataset in the scenario of safetyprevention. Preliminary results on the three tasks show that NLP techniques arebeneficial for analyzing incident reports to prevent future failures. Thedataset facilitates future research in NLP and incident management communities.The access to the dataset is also provided (the IncidentAI dataset is availableat: https://github.com/Cinnamon/incident-ai-dataset).</description><author>Shumpei Inoue, Minh-Tien Nguyen, Hiroki Mizokuchi, Tuan-Anh D. Nguyen, Huu-Hiep Nguyen, Dung Tien Le</author><pubDate>Wed, 18 Oct 2023 17:07:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12074v1</guid></item><item><title>SPEED: Speculative Pipelined Execution for Efficient Decoding</title><link>http://arxiv.org/abs/2310.12072v1</link><description>Generative Large Language Models (LLMs) based on the Transformer architecturehave recently emerged as a dominant foundation model for a wide range ofNatural Language Processing tasks. Nevertheless, their application in real-timescenarios has been highly restricted due to the significant inference latencyassociated with these models. This is particularly pronounced due to theautoregressive nature of generative LLM inference, where tokens are generatedsequentially since each token depends on all previous output tokens. It istherefore challenging to achieve any token-level parallelism, making inferenceextremely memory-bound. In this work, we propose SPEED, which improvesinference efficiency by speculatively executing multiple future tokens inparallel with the current token using predicted values based on early-layerhidden states. For Transformer decoders that employ parameter sharing, thememory operations for the tokens executing in parallel can be amortized, whichallows us to accelerate generative LLM inference. We demonstrate the efficiencyof our method in terms of latency reduction relative to model accuracy anddemonstrate how speculation allows for training deeper decoders with parametersharing with minimal runtime overhead.</description><author>Coleman Hooper, Sehoon Kim, Hiva Mohammadzadeh, Hasan Genc, Kurt Keutzer, Amir Gholami, Sophia Shao</author><pubDate>Wed, 18 Oct 2023 17:07:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12072v1</guid></item><item><title>Global k-Space Interpolation for Dynamic MRI Reconstruction using Masked Image Modeling</title><link>http://arxiv.org/abs/2307.12672v2</link><description>In dynamic Magnetic Resonance Imaging (MRI), k-space is typicallyundersampled due to limited scan time, resulting in aliasing artifacts in theimage domain. Hence, dynamic MR reconstruction requires not only modelingspatial frequency components in the x and y directions of k-space but alsoconsidering temporal redundancy. Most previous works rely on image-domainregularizers (priors) to conduct MR reconstruction. In contrast, we focus oninterpolating the undersampled k-space before obtaining images with Fouriertransform. In this work, we connect masked image modeling with k-spaceinterpolation and propose a novel Transformer-based k-space GlobalInterpolation Network, termed k-GIN. Our k-GIN learns global dependencies amonglow- and high-frequency components of 2D+t k-space and uses it to interpolateunsampled data. Further, we propose a novel k-space Iterative Refinement Module(k-IRM) to enhance the high-frequency components learning. We evaluate ourapproach on 92 in-house 2D+t cardiac MR subjects and compare it to MRreconstruction methods with image-domain regularizers. Experiments show thatour proposed k-space interpolation method quantitatively and qualitativelyoutperforms baseline methods. Importantly, the proposed approach achievessubstantially higher robustness and generalizability in cases ofhighly-undersampled MR data. For video presentation, poster, GIF results andcode please check our project page:https://jzpeterpan.github.io/k-gin.github.io/.</description><author>Jiazhen Pan, Suprosanna Shit, Özgün Turgut, Wenqi Huang, Hongwei Bran Li, Nil Stolt-Ansó, Thomas Küstner, Kerstin Hammernik, Daniel Rueckert</author><pubDate>Wed, 18 Oct 2023 17:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12672v2</guid></item><item><title>Transformers for scientific data: a pedagogical review for astronomers</title><link>http://arxiv.org/abs/2310.12069v1</link><description>The deep learning architecture associated with ChatGPT and related generativeAI products is known as transformers. Initially applied to Natural LanguageProcessing, transformers and the self-attention mechanism they exploit havegained widespread interest across the natural sciences. The goal of thispedagogical and informal review is to introduce transformers to scientists. Ourpedagogical and informal review includes the mathematics underlying theattention mechanism, a description of the original transformer architecture,and a section on applications to time series and imaging data in astronomy. Weinclude with a Frequently Asked Questions section for readers who are curiousabout generative AI and interested in getting started with transformers fortheir research problem.</description><author>Dimitrios Tanoglidis, Bhuvnesh Jain, Helen Qu</author><pubDate>Wed, 18 Oct 2023 17:02:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12069v1</guid></item><item><title>A Hybrid Genetic Algorithm for the min-max Multiple Traveling Salesman Problem</title><link>http://arxiv.org/abs/2307.07120v2</link><description>This paper proposes a hybrid genetic algorithm for solving the MultipleTraveling Salesman Problem (mTSP) to minimize the length of the longest tour.The genetic algorithm utilizes a TSP sequence as the representation of eachindividual, and a dynamic programming algorithm is employed to evaluate theindividual and find the optimal mTSP solution for the given sequence of cities.A novel crossover operator is designed to combine similar tours from twoparents and offers great diversity for the population. For some of thegenerated offspring, we detect and remove intersections between tours to obtaina solution with no intersections. This is particularly useful for the min-maxmTSP. The generated offspring are also improved by a self-adaptive random localsearch and a thorough neighborhood search. Our algorithm outperforms allexisting algorithms on average, with similar cutoff time thresholds, whentested against multiple benchmark sets found in the literature. Additionally,we improve the best-known solutions for $21$ out of $89$ instances on fourbenchmark sets.</description><author>Sasan Mahmoudinazlou, Changhyun Kwon</author><pubDate>Wed, 18 Oct 2023 16:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07120v2</guid></item><item><title>Code Book for the Annotation of Diverse Cross-Document Coreference of Entities in News Articles</title><link>http://arxiv.org/abs/2310.12064v1</link><description>This paper presents a scheme for annotating coreference across news articles,extending beyond traditional identity relations by also consideringnear-identity and bridging relations. It includes a precise description of howto set up Inception, a respective annotation tool, how to annotate entities innews articles, connect them with diverse coreferential relations, and link themacross documents to Wikidata's global knowledge graph. This multi-layeredannotation approach is discussed in the context of the problem of media bias.Our main contribution lies in providing a methodology for creating a diversecross-document coreference corpus which can be applied to the analysis of mediabias by word-choice and labelling.</description><author>Jakob Vogel</author><pubDate>Wed, 18 Oct 2023 16:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12064v1</guid></item><item><title>Black-Box Training Data Identification in GANs via Detector Networks</title><link>http://arxiv.org/abs/2310.12063v1</link><description>Since their inception Generative Adversarial Networks (GANs) have beenpopular generative models across images, audio, video, and tabular data. Inthis paper we study whether given access to a trained GAN, as well as freshsamples from the underlying distribution, if it is possible for an attacker toefficiently identify if a given point is a member of the GAN's training data.This is of interest for both reasons related to copyright, where a user maywant to determine if their copyrighted data has been used to train a GAN, andin the study of data privacy, where the ability to detect training setmembership is known as a membership inference attack. Unlike the majority ofprior work this paper investigates the privacy implications of using GANs inblack-box settings, where the attack only has access to samples from thegenerator, rather than access to the discriminator as well. We introduce asuite of membership inference attacks against GANs in the black-box setting andevaluate our attacks on image GANs trained on the CIFAR10 dataset and tabularGANs trained on genomic data. Our most successful attack, called The Detector,involve training a second network to score samples based on their likelihood ofbeing generated by the GAN, as opposed to a fresh sample from the distribution.We prove under a simple model of the generator that the detector is anapproximately optimal membership inference attack. Across a wide range oftabular and image datasets, attacks, and GAN architectures, we find thatadversaries can orchestrate non-trivial privacy attacks when provided withaccess to samples from the generator. At the same time, the attack successachievable against GANs still appears to be lower compared to other generativeand discriminative models; this leaves the intriguing open question of whetherGANs are in fact more private, or if it is a matter of developing strongerattacks.</description><author>Lukman Olagoke, Salil Vadhan, Seth Neel</author><pubDate>Wed, 18 Oct 2023 16:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12063v1</guid></item><item><title>Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities</title><link>http://arxiv.org/abs/2310.08565v2</link><description>Robotics and Artificial Intelligence (AI) have been inextricably intertwinedsince their inception. Today, AI-Robotics systems have become an integral partof our daily lives, from robotic vacuum cleaners to semi-autonomous cars. Thesesystems are built upon three fundamental architectural elements: perception,navigation and planning, and control. However, while the integration ofAI-Robotics systems has enhanced the quality our lives, it has also presented aserious problem - these systems are vulnerable to security attacks. Thephysical components, algorithms, and data that make up AI-Robotics systems canbe exploited by malicious actors, potentially leading to dire consequences.Motivated by the need to address the security concerns in AI-Robotics systems,this paper presents a comprehensive survey and taxonomy across threedimensions: attack surfaces, ethical and legal concerns, and Human-RobotInteraction (HRI) security. Our goal is to provide users, developers and otherstakeholders with a holistic understanding of these areas to enhance theoverall AI-Robotics system security. We begin by surveying potential attacksurfaces and provide mitigating defensive strategies. We then delve intoethical issues, such as dependency and psychological impact, as well as thelegal concerns regarding accountability for these systems. Besides, emergingtrends such as HRI are discussed, considering privacy, integrity, safety,trustworthiness, and explainability concerns. Finally, we present our visionfor future research directions in this dynamic and promising field.</description><author>Subash Neupane, Shaswata Mitra, Ivan A. Fernandez, Swayamjit Saha, Sudip Mittal, Jingdao Chen, Nisha Pillai, Shahram Rahimi</author><pubDate>Wed, 18 Oct 2023 16:53:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08565v2</guid></item><item><title>Clifford Group Equivariant Neural Networks</title><link>http://arxiv.org/abs/2305.11141v4</link><description>We introduce Clifford Group Equivariant Neural Networks: a novel approach forconstructing $\mathrm{O}(n)$- and $\mathrm{E}(n)$-equivariant models. Weidentify and study the $\textit{Clifford group}$, a subgroup inside theClifford algebra whose definition we adjust to achieve several favorableproperties. Primarily, the group's action forms an orthogonal automorphism thatextends beyond the typical vector space to the entire Clifford algebra whilerespecting the multivector grading. This leads to several non-equivalentsubrepresentations corresponding to the multivector decomposition. Furthermore,we prove that the action respects not just the vector space structure of theClifford algebra but also its multiplicative structure, i.e., the geometricproduct. These findings imply that every polynomial in multivectors, Anadvantage worth mentioning is that we obtain expressive layers that canelegantly generalize to inner-product spaces of any dimension. We demonstrate,notably from a single core implementation, state-of-the-art performance onseveral distinct tasks, including a three-dimensional $n$-body experiment, afour-dimensional Lorentz-equivariant high-energy physics experiment, and afive-dimensional convex hull experiment.</description><author>David Ruhe, Johannes Brandstetter, Patrick Forré</author><pubDate>Wed, 18 Oct 2023 16:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11141v4</guid></item><item><title>On the use of Vision-Language models for Visual Sentiment Analysis: a study on CLIP</title><link>http://arxiv.org/abs/2310.12062v1</link><description>This work presents a study on how to exploit the CLIP embedding space toperform Visual Sentiment Analysis. We experiment with two architectures builton top of the CLIP embedding space, which we denote by CLIP-E. We train theCLIP-E models with WEBEmo, the largest publicly available and manually labeledbenchmark for Visual Sentiment Analysis, and perform two sets of experiments.First, we test on WEBEmo and compare the CLIP-E architectures withstate-of-the-art (SOTA) models and with CLIP Zero-Shot. Second, we performcross dataset evaluation, and test the CLIP-E architectures trained with WEBEmoon other Visual Sentiment Analysis benchmarks. Our results show that the CLIP-Eapproaches outperform SOTA models in WEBEmo fine grained categorization, andthey also generalize better when tested on datasets that have not been seenduring training. Interestingly, we observed that for the FI dataset, CLIPZero-Shot produces better accuracies than SOTA models and CLIP-E trained onWEBEmo. These results motivate several questions that we discuss in this paper,such as how we should design new benchmarks and evaluate Visual SentimentAnalysis, and whether we should keep designing tailored Deep Learning modelsfor Visual Sentiment Analysis or focus our efforts on better using theknowledge encoded in large vision-language models such as CLIP for this task.</description><author>Cristina Bustos, Carles Civit, Brian Du, Albert Sole-Ribalta, Agata Lapedriza</author><pubDate>Wed, 18 Oct 2023 16:50:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12062v1</guid></item><item><title>Robust Class-Conditional Distribution Alignment for Partial Domain Adaptation</title><link>http://arxiv.org/abs/2310.12060v1</link><description>Unwanted samples from private source categories in the learning objective ofa partial domain adaptation setup can lead to negative transfer and reduceclassification performance. Existing methods, such as re-weighting oraggregating target predictions, are vulnerable to this issue, especially duringinitial training stages, and do not adequately address overlapping categoricaldistributions. We propose a solution to overcome these limitations by exploringbeyond the first-order moments for robust alignment of categoricaldistributions. We employ objectives that optimize the intra and inter-classdistributions in a domain-invariant fashion and design a robust pseudo-labelingfor efficient target supervision. Our approach incorporates a complemententropy objective module to reduce classification uncertainty and flattenincorrect category predictions. The experimental findings and ablation analysisof the proposed modules demonstrate the superior performance of our proposedmodel compared to benchmarks.</description><author>Sandipan Choudhuri, Arunabha Sen</author><pubDate>Wed, 18 Oct 2023 16:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12060v1</guid></item><item><title>Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education</title><link>http://arxiv.org/abs/2310.12059v1</link><description>In this paper, we evaluate the ability of large language models (LLMs) toperform multiple choice symbol binding (MCSB) for multiple choice questionanswering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focuson Vietnamese, with fewer challenging MCQA datasets than in English. The twoexisting datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recentresearch in Vietnamese natural language processing (NLP) has focused on theVietnamese National High School Graduation Examination (VNHSGE) from 2019 to2023 to evaluate ChatGPT. However, these studies have mainly focused on howChatGPT solves the VNHSGE step by step. We aim to create a novel andhigh-quality dataset by providing structured guidelines for typing LaTeXformulas for mathematics, physics, chemistry, and biology. This dataset can beused to evaluate the MCSB ability of LLMs and smaller language models (LMs)because it is typed in a strict LaTeX style. We focus on predicting thecharacter (A, B, C, or D) that is the most likely answer to a question, giventhe context of the question. Our evaluation of six well-known LLMs, namelyBLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on theViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promisingresults on the MCSB ability of LLMs for Vietnamese. The dataset is availablefor research purposes only.</description><author>Duc-Vu Nguyen, Quoc-Nam Nguyen</author><pubDate>Wed, 18 Oct 2023 16:48:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12059v1</guid></item><item><title>Edge-InversionNet: Enabling Efficient Inference of InversionNet on Edge Devices</title><link>http://arxiv.org/abs/2310.09667v2</link><description>Seismic full waveform inversion (FWI) is a widely used technique ingeophysics for inferring subsurface structures from seismic data. AndInversionNet is one of the most successful data-driven machine learning modelsthat is applied to seismic FWI. However, the high computing costs to runInversionNet have made it challenging to be efficiently deployed on edgedevices that are usually resource-constrained. Therefore, we propose to employthe structured pruning algorithm to get a lightweight version of InversionNet,which can make an efficient inference on edge devices. And we also made aprototype with Raspberry Pi to run the lightweight InversionNet. Experimentalresults show that the pruned InversionNet can achieve up to 98.2 % reduction incomputing resources with moderate model performance degradation.</description><author>Zhepeng Wang, Isaacshubhanand Putla, Weiwen Jiang, Youzuo Lin</author><pubDate>Wed, 18 Oct 2023 16:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09667v2</guid></item><item><title>TRANSOM: An Efficient Fault-Tolerant System for Training LLMs</title><link>http://arxiv.org/abs/2310.10046v3</link><description>Large language models (LLMs) with hundreds of billions or trillions ofparameters, represented by chatGPT, have achieved profound impact on variousfields. However, training LLMs with super-large-scale parameters requires largehigh-performance GPU clusters and long training periods lasting for months. Dueto the inevitable hardware and software failures in large-scale clusters,maintaining uninterrupted and long-duration training is extremely challenging.As a result, A substantial amount of training time is devoted to taskcheckpoint saving and loading, task rescheduling and restart, and task manualanomaly checks, which greatly harms the overall training efficiency. To addressthese issues, we propose TRANSOM, a novel fault-tolerant LLM training system.In this work, we design three key subsystems: the training pipeline automaticfault tolerance and recovery mechanism named Transom Operator and Launcher(TOL), the training task multi-dimensional metric automatic anomaly detectionsystem named Transom Eagle Eye (TEE), and the training checkpoint asynchronousaccess automatic fault tolerance and recovery technology named TransomCheckpoint Engine (TCE). Here, TOL manages the lifecycle of training tasks,while TEE is responsible for task monitoring and anomaly reporting. TEE detectstraining anomalies and reports them to TOL, who automatically enters the faulttolerance strategy to eliminate abnormal nodes and restart the training task.And the asynchronous checkpoint saving and loading functionality provided byTCE greatly shorten the fault tolerance overhead. The experimental resultsindicate that TRANSOM significantly enhances the efficiency of large-scale LLMtraining on clusters. Specifically, the pre-training time for GPT3-175B hasbeen reduced by 28%, while checkpoint saving and loading performance haveimproved by a factor of 20.</description><author>Baodong Wu, Lei Xia, Qingping Li, Kangyu Li, Xu Chen, Yongqiang Guo, Tieyao Xiang, Yuheng Chen, Shigang Li</author><pubDate>Wed, 18 Oct 2023 16:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10046v3</guid></item><item><title>Understanding Reward Ambiguity Through Optimal Transport Theory in Inverse Reinforcement Learning</title><link>http://arxiv.org/abs/2310.12055v1</link><description>In inverse reinforcement learning (IRL), the central objective is to inferunderlying reward functions from observed expert behaviors in a way that notonly explains the given data but also generalizes to unseen scenarios. Thisensures robustness against reward ambiguity where multiple reward functions canequally explain the same expert behaviors. While significant efforts have beenmade in addressing this issue, current methods often face challenges withhigh-dimensional problems and lack a geometric foundation. This paper harnessesthe optimal transport (OT) theory to provide a fresh perspective on thesechallenges. By utilizing the Wasserstein distance from OT, we establish ageometric framework that allows for quantifying reward ambiguity andidentifying a central representation or centroid of reward functions. Theseinsights pave the way for robust IRL methodologies anchored in geometricinterpretations, offering a structured approach to tackle reward ambiguity inhigh-dimensional settings.</description><author>Ali Baheri</author><pubDate>Wed, 18 Oct 2023 16:42:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12055v1</guid></item><item><title>Mixed-Type Wafer Classification For Low Memory Devices Using Knowledge Distillation</title><link>http://arxiv.org/abs/2303.13974v2</link><description>Manufacturing wafers is an intricate task involving thousands of steps.Defect Pattern Recognition (DPR) of wafer maps is crucial for determining theroot cause of production defects, which may further provide insight for yieldimprovement in wafer foundry. During manufacturing, various defects may appearstandalone in the wafer or may appear as different combinations. Identifyingmultiple defects in a wafer is generally harder compared to identifying asingle defect. Recently, deep learning methods have gained significant tractionin mixed-type DPR. However, the complexity of defects requires complex andlarge models making them very difficult to operate on low-memory embeddeddevices typically used in fabrication labs. Another common issue is theunavailability of labeled data to train complex networks. In this work, wepropose an unsupervised training routine to distill the knowledge of complexpre-trained models to lightweight deployment-ready models. We empirically showthat this type of training compresses the model without sacrificing accuracydespite being up to 10 times smaller than the teacher model. The compressedmodel also manages to outperform contemporary state-of-the-art models.</description><author>Nitish Shukla, Anurima Dey, Srivatsan K</author><pubDate>Wed, 18 Oct 2023 16:37:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.13974v2</guid></item><item><title>Machine Learning-based Nutrient Application's Timeline Recommendation for Smart Agriculture: A Large-Scale Data Mining Approach</title><link>http://arxiv.org/abs/2310.12052v1</link><description>This study addresses the vital role of data analytics in monitoringfertiliser applications in crop cultivation. Inaccurate fertiliser applicationdecisions can lead to costly consequences, hinder food production, and causeenvironmental harm. We propose a solution to predict nutrient application bydetermining required fertiliser quantities for an entire season. The proposedsolution recommends adjusting fertiliser amounts based on weather conditionsand soil characteristics to promote cost-effective and environmentally friendlyagriculture. The collected dataset is high-dimensional and heterogeneous. Ourresearch examines large-scale heterogeneous datasets in the context of thedecision-making process, encompassing data collection and analysis. We alsostudy the impact of fertiliser applications combined with weather data on cropyield, using the winter wheat crop as a case study. By understanding localcontextual and geographic factors, we aspire to stabilise or even reduce thedemand for agricultural nutrients while enhancing crop development. Theproposed approach is proven to be efficient and scalable, as it is validatedusing a real-world and large dataset.</description><author>Usama Ikhlaq, Tahar Kechadi</author><pubDate>Wed, 18 Oct 2023 16:37:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12052v1</guid></item><item><title>Interactive Explanation with Varying Level of Details in an Explainable Scientific Literature Recommender System</title><link>http://arxiv.org/abs/2306.05809v3</link><description>Explainable recommender systems (RS) have traditionally followed aone-size-fits-all approach, delivering the same explanation level of detail toeach user, without considering their individual needs and goals. Further,explanations in RS have so far been presented mostly in a static andnon-interactive manner. To fill these research gaps, we aim in this paper toadopt a user-centered, interactive explanation model that provides explanationswith different levels of detail and empowers users to interact with, control,and personalize the explanations based on their needs and preferences. Wefollowed a user-centered approach to design interactive explanations with threelevels of detail (basic, intermediate, and advanced) and implemented them inthe transparent Recommendation and Interest Modeling Application (RIMA). Weconducted a qualitative user study (N=14) to investigate the impact ofproviding interactive explanations with varying level of details on the users'perception of the explainable RS. Our study showed qualitative evidence thatfostering interaction and giving users control in deciding which explanationthey would like to see can meet the demands of users with different needs,preferences, and goals, and consequently can have positive effects on differentcrucial aspects in explainable recommendation, including transparency, trust,satisfaction, and user experience.</description><author>Mouadh Guesmi, Mohamed Amine Chatti, Shoeb Joarder, Qurat Ul Ain, Rawaa Alatrash, Clara Siepmann, Tannaz Vahidi</author><pubDate>Wed, 18 Oct 2023 16:36:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05809v3</guid></item><item><title>SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation</title><link>http://arxiv.org/abs/2309.16661v2</link><description>Microscopic image segmentation is a challenging task, wherein the objectiveis to assign semantic labels to each pixel in a given microscopic image. Whileconvolutional neural networks (CNNs) form the foundation of many existingframeworks, they often struggle to explicitly capture long-range dependencies.Although transformers were initially devised to address this issue usingself-attention, it has been proven that both local and global features arecrucial for addressing diverse challenges in microscopic images, includingvariations in shape, size, appearance, and target region density. In thispaper, we introduce SA2-Net, an attention-guided method that leveragesmulti-scale feature learning to effectively handle diverse structures withinmicroscopic images. Specifically, we propose scale-aware attention (SA2) moduledesigned to capture inherent variations in scales and shapes of microscopicregions, such as cells, for accurate segmentation. This module incorporateslocal attention at each level of multi-stage features, as well as globalattention across multiple resolutions. Furthermore, we address the issue ofblurred region boundaries (e.g., cell boundaries) by introducing a novelupsampling strategy called the Adaptive Up-Attention (AuA) module. This moduleenhances the discriminative ability for improved localization of microscopicregions using an explicit attention mechanism. Extensive experiments on fivechallenging datasets demonstrate the benefits of our SA2-Net model. Our sourcecode is publicly available at \url{https://github.com/mustansarfiaz/SA2-Net}.</description><author>Mustansar Fiaz, Rao Muhammad Anwer, Hisham Cholakkal</author><pubDate>Wed, 18 Oct 2023 16:36:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16661v2</guid></item><item><title>Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models</title><link>http://arxiv.org/abs/2310.12049v1</link><description>Existing text scaling methods often require a large corpus, struggle withshort texts, or require labeled data. We develop a text scaling method thatleverages the pattern recognition capabilities of generative large languagemodels (LLMs). Specifically, we propose concept-guided chain-of-thought(CGCoT), which uses prompts designed to summarize ideas and identify targetparties in texts to generate concept-specific breakdowns, in many ways similarto guidance for human coder content analysis. CGCoT effectively shifts pairwisetext comparisons from a reasoning problem to a pattern recognition problem. Wethen pairwise compare concept-specific breakdowns using an LLM. We use theresults of these pairwise comparisons to estimate a scale using theBradley-Terry model. We use this approach to scale affective speech on Twitter.Our measures correlate more strongly with human judgments than alternativeapproaches like Wordfish. Besides a small set of pilot data to develop theCGCoT prompts, our measures require no additional labeled data and producebinary predictions comparable to a RoBERTa-Large model fine-tuned on thousandsof human-labeled tweets. We demonstrate how combining substantive knowledgewith LLMs can create state-of-the-art measures of abstract concepts.</description><author>Patrick Y. Wu, Jonathan Nagler, Joshua A. Tucker, Solomon Messing</author><pubDate>Wed, 18 Oct 2023 16:34:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12049v1</guid></item><item><title>Breathing New Life into 3D Assets with Generative Repainting</title><link>http://arxiv.org/abs/2309.08523v2</link><description>Diffusion-based text-to-image models ignited immense attention from thevision community, artists, and content creators. Broad adoption of these modelsis due to significant improvement in the quality of generations and efficientconditioning on various modalities, not just text. However, lifting the richgenerative priors of these 2D models into 3D is challenging. Recent works haveproposed various pipelines powered by the entanglement of diffusion models andneural fields. We explore the power of pretrained 2D diffusion models andstandard 3D neural radiance fields as independent, standalone tools anddemonstrate their ability to work together in a non-learned fashion. Suchmodularity has the intrinsic advantage of eased partial upgrades, which becamean important property in such a fast-paced domain. Our pipeline accepts anylegacy renderable geometry, such as textured or untextured meshes, orchestratesthe interaction between 2D generative refinement and 3D consistency enforcementtools, and outputs a painted input geometry in several formats. We conduct alarge-scale study on a wide range of objects and categories from theShapeNetSem dataset and demonstrate the advantages of our approach, bothqualitatively and quantitatively. Project page:https://www.obukhov.ai/repainting_3d_assets</description><author>Tianfu Wang, Menelaos Kanakis, Konrad Schindler, Luc Van Gool, Anton Obukhov</author><pubDate>Wed, 18 Oct 2023 16:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08523v2</guid></item><item><title>Applications of ML-Based Surrogates in Bayesian Approaches to Inverse Problems</title><link>http://arxiv.org/abs/2310.12046v1</link><description>Neural networks have become a powerful tool as surrogate models to providenumerical solutions for scientific problems with increased computationalefficiency. This efficiency can be advantageous for numerically challengingproblems where time to solution is important or when evaluation of many similaranalysis scenarios is required. One particular area of scientific interest isthe setting of inverse problems, where one knows the forward dynamics of asystem are described by a partial differential equation and the task is toinfer properties of the system given (potentially noisy) observations of thesedynamics. We consider the inverse problem of inferring the location of a wavesource on a square domain, given a noisy solution to the 2-D acoustic waveequation. Under the assumption of Gaussian noise, a likelihood function forsource location can be formulated, which requires one forward simulation of thesystem per evaluation. Using a standard neural network as a surrogate modelmakes it computationally feasible to evaluate this likelihood several times,and so Markov Chain Monte Carlo methods can be used to evaluate the posteriordistribution of the source location. We demonstrate that this method canaccurately infer source-locations from noisy data.</description><author>Pelin Ersin, Emma Hayes, Peter Matthews, Paramjyoti Mohapatra, Elisa Negrini, Karl Schulz</author><pubDate>Wed, 18 Oct 2023 16:32:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12046v1</guid></item><item><title>MAD Max Beyond Single-Node: Enabling Large Machine Learning Model Acceleration on Distributed Systems</title><link>http://arxiv.org/abs/2310.02784v2</link><description>Training and deploying large machine learning (ML) models is time-consumingand requires significant distributed computing infrastructures. Based onreal-world large model training on datacenter-scale infrastructures, we show14~32% of all GPU hours are spent on communication with no overlappingcomputation. To minimize the outstanding communication latency, in this work,we develop an agile performance modeling framework to guide parallelization andhardware-software co-design strategies. Using the suite of real-world large MLmodels on state-of-the-art GPU training hardware, we demonstrate 2.24x and5.27x throughput improvement potential for pre-training and inferencescenarios, respectively.</description><author>Samuel Hsia, Alicia Golden, Bilge Acun, Newsha Ardalani, Zachary DeVito, Gu-Yeon Wei, David Brooks, Carole-Jean Wu</author><pubDate>Wed, 18 Oct 2023 16:29:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02784v2</guid></item><item><title>A General Theoretical Paradigm to Understand Learning from Human Preferences</title><link>http://arxiv.org/abs/2310.12036v1</link><description>The prevalent deployment of learning from human preferences throughreinforcement learning (RLHF) relies on two important approximations: the firstassumes that pairwise preferences can be substituted with pointwise rewards.The second assumes that a reward model trained on these pointwise rewards cangeneralize from collected data to out-of-distribution data sampled by thepolicy. Recently, Direct Preference Optimisation (DPO) has been proposed as anapproach that bypasses the second approximation and learn directly a policyfrom collected data without the reward modelling stage. However, this methodstill heavily relies on the first approximation. In this paper we try to gain a deeper theoretical understanding of thesepractical algorithms. In particular we derive a new general objective called$\Psi$PO for learning from human preferences that is expressed in terms ofpairwise preferences and therefore bypasses both approximations. This newgeneral objective allows us to perform an in-depth analysis of the behavior ofRLHF and DPO (as special cases of $\Psi$PO) and to identify their potentialpitfalls. We then consider another special case for $\Psi$PO by setting $\Psi$simply to Identity, for which we can derive an efficient optimisationprocedure, prove performance guarantees and demonstrate its empiricalsuperiority to DPO on some illustrative examples.</description><author>Mohammad Gheshlaghi Azar, Mark Rowland, Bilal Piot, Daniel Guo, Daniele Calandriello, Michal Valko, Rémi Munos</author><pubDate>Wed, 18 Oct 2023 16:21:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12036v1</guid></item><item><title>Conformal Drug Property Prediction with Density Estimation under Covariate Shift</title><link>http://arxiv.org/abs/2310.12033v1</link><description>In drug discovery, it is vital to confirm the predictions of pharmaceuticalproperties from computational models using costly wet-lab experiments. Hence,obtaining reliable uncertainty estimates is crucial for prioritizing drugmolecules for subsequent experimental validation. Conformal Prediction (CP) isa promising tool for creating such prediction sets for molecular propertieswith a coverage guarantee. However, the exchangeability assumption of CP isoften challenged with covariate shift in drug discovery tasks: Most datasetscontain limited labeled data, which may not be representative of the vastchemical space from which molecules are drawn. To address this limitation, wepropose a method called CoDrug that employs an energy-based model leveragingboth training data and unlabelled data, and Kernel Density Estimation (KDE) toassess the densities of a molecule set. The estimated densities are then usedto weigh the molecule samples while building prediction sets and rectifying fordistribution shift. In extensive experiments involving realistic distributiondrifts in various small-molecule drug discovery tasks, we demonstrate theability of CoDrug to provide valid prediction sets and its utility inaddressing the distribution shift arising from de novo drug design models. Onaverage, using CoDrug can reduce the coverage gap by over 35% when compared toconformal prediction sets not adjusted for covariate shift.</description><author>Siddhartha Laghuvarapu, Zhen Lin, Jimeng Sun</author><pubDate>Wed, 18 Oct 2023 16:17:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12033v1</guid></item><item><title>Exact and efficient solutions of the LMC Multitask Gaussian Process model</title><link>http://arxiv.org/abs/2310.12032v1</link><description>The Linear Model of Co-regionalization (LMC) is a very general model ofmultitask gaussian process for regression or classification. While itsexpressivity and conceptual simplicity are appealing, naive implementationshave cubic complexity in the number of datapoints and number of tasks, makingapproximations mandatory for most applications. However, recent work has shownthat under some conditions the latent processes of the model can be decoupled,leading to a complexity that is only linear in the number of said processes. Wehere extend these results, showing from the most general assumptions that theonly condition necessary to an efficient exact computation of the LMC is a mildhypothesis on the noise model. We introduce a full parametrization of theresulting \emph{projected LMC} model, and an expression of the marginallikelihood enabling efficient optimization. We perform a parametric study onsynthetic data to show the excellent performance of our approach, compared toan unrestricted exact LMC and approximations of the latter. Overall, theprojected LMC appears as a credible and simpler alternative to state-of-the artmodels, which greatly facilitates some computations such as leave-one-outcross-validation and fantasization.</description><author>Olivier Truffinet, Karim Ammar, Jean-Philippe Argaud, Bertrand Bouriquet</author><pubDate>Wed, 18 Oct 2023 16:16:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12032v1</guid></item><item><title>SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment</title><link>http://arxiv.org/abs/2310.12031v1</link><description>This paper presents an adaptive transformer model named SegmATRon forembodied image semantic segmentation. Its distinctive feature is the adaptationof model weights during inference on several images using a hybridmulticomponent loss function. We studied this model on datasets collected inthe photorealistic Habitat and the synthetic AI2-THOR Simulators. We showedthat obtaining additional images using the agent's actions in an indoorenvironment can improve the quality of semantic segmentation. The code of theproposed approach and datasets are publicly available athttps://github.com/wingrune/SegmATRon.</description><author>Tatiana Zemskova, Margarita Kichik, Dmitry Yudin, Aleksei Staroverov, Aleksandr Panov</author><pubDate>Wed, 18 Oct 2023 16:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12031v1</guid></item><item><title>Model Checkers Are Cool: How to Model Check Voting Protocols in Uppaal</title><link>http://arxiv.org/abs/2007.12412v3</link><description>The design and implementation of an e-voting system is a challenging task.Formal analysis can be of great help here. In particular, it can lead to abetter understanding of how the voting system works, and what requirements onthe system are relevant. In this paper, we propose that the state-of-art modelchecker Uppaal provides a good environment for modelling and preliminaryverification of voting protocols. To illustrate this, we present an Uppaalmodel of Pr\^et \`a Voter, together with some natural extensions. We also showhow to verify a variant of receipt-freeness, despite the severe limitations ofthe property specification language in the model checker.</description><author>Wojciech Jamroga, Yan Kim, Damian Kurpiewski, Peter Y. A. Ryan</author><pubDate>Wed, 18 Oct 2023 16:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2007.12412v3</guid></item><item><title>Don't throw away your value model! Making PPO even better via Value-Guided Monte-Carlo Tree Search decoding</title><link>http://arxiv.org/abs/2309.15028v2</link><description>Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) mayseem unnecessary when generating natural language text based onstate-of-the-art reinforcement learning such as Proximal Policy Optimization(PPO). In this paper, we demonstrate that it is possible to get extra mileageout of PPO by integrating MCTS on top. The key idea is not to throw out thevalue network, a byproduct of PPO training for evaluating partial outputsequences, when decoding text out of the policy network. More concretely, wepresent a novel value-guided decoding algorithm called PPO-MCTS, which canintegrate the value network from PPO to work closely with the policy networkduring inference-time generation. Compared to prior approaches based on MCTSfor controlled text generation, the key strength of our approach is to reducethe fundamental mismatch of the scoring mechanisms of the partial outputsbetween training and test. Evaluation on four text generation tasks demonstratethat PPO-MCTS greatly improves the preferability of generated text compared tothe standard practice of using only the PPO policy. Our results demonstrate thepromise of search algorithms even on top of the aligned language models fromPPO, and the under-explored benefit of the value network.</description><author>Jiacheng Liu, Andrew Cohen, Ramakanth Pasunuru, Yejin Choi, Hannaneh Hajishirzi, Asli Celikyilmaz</author><pubDate>Wed, 18 Oct 2023 16:05:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15028v2</guid></item><item><title>Nonparametric Discrete Choice Experiments with Machine Learning Guided Adaptive Design</title><link>http://arxiv.org/abs/2310.12026v1</link><description>Designing products to meet consumers' preferences is essential for abusiness's success. We propose the Gradient-based Survey (GBS), a discretechoice experiment for multiattribute product design. The experiment elicitsconsumer preferences through a sequence of paired comparisons for partialprofiles. GBS adaptively constructs paired comparison questions based on therespondents' previous choices. Unlike the traditional random utilitymaximization paradigm, GBS is robust to model misspecification by not requiringa parametric utility model. Cross-pollinating the machine learning andexperiment design, GBS is scalable to products with hundreds of attributes andcan design personalized products for heterogeneous consumers. We demonstratethe advantage of GBS in accuracy and sample efficiency compared to the existingparametric and nonparametric methods in simulations.</description><author>Mingzhang Yin, Ruijiang Gao, Weiran Lin, Steven M. Shugan</author><pubDate>Wed, 18 Oct 2023 16:01:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12026v1</guid></item><item><title>CORE: A Few-Shot Company Relation Classification Dataset for Robust Domain Adaptation</title><link>http://arxiv.org/abs/2310.12024v1</link><description>We introduce CORE, a dataset for few-shot relation classification (RC)focused on company relations and business entities. CORE includes 4,708instances of 12 relation types with corresponding textual evidence extractedfrom company Wikipedia pages. Company names and business entities pose achallenge for few-shot RC models due to the rich and diverse informationassociated with them. For example, a company name may represent the legalentity, products, people, or business divisions depending on the context.Therefore, deriving the relation type between entities is highly dependent ontextual context. To evaluate the performance of state-of-the-art RC models onthe CORE dataset, we conduct experiments in the few-shot domain adaptationsetting. Our results reveal substantial performance gaps, confirming thatmodels trained on different domains struggle to adapt to CORE. Interestingly,we find that models trained on CORE showcase improved out-of-domainperformance, which highlights the importance of high-quality data for robustdomain adaptation. Specifically, the information richness embedded in businessentities allows models to focus on contextual nuances, reducing their relianceon superficial clues such as relation-specific verbs. In addition to thedataset, we provide relevant code snippets to facilitate reproducibility andencourage further research in the field.</description><author>Philipp Borchert, Jochen De Weerdt, Kristof Coussement, Arno De Caigny, Marie-Francine Moens</author><pubDate>Wed, 18 Oct 2023 15:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12024v1</guid></item><item><title>LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic Tabletop Manipulation</title><link>http://arxiv.org/abs/2310.12020v1</link><description>The convergence of embodied agents and large language models (LLMs) hasbrought significant advancements to embodied instruction following.Particularly, the strong reasoning capabilities of LLMs make it possible forrobots to perform long-horizon tasks without expensive annotateddemonstrations. However, public benchmarks for testing the long-horizonreasoning capabilities of language-conditioned robots in various scenarios arestill missing. To fill this gap, this work focuses on the tabletop manipulationtask and releases a simulation benchmark, \textit{LoHoRavens}, which coversvarious long-horizon reasoning aspects spanning color, size, space, arithmeticsand reference. Furthermore, there is a key modality bridging problem forlong-horizon manipulation tasks with LLMs: how to incorporate the observationfeedback during robot execution for the LLM's closed-loop planning, which ishowever less studied by prior work. We investigate two methods of bridging themodality gap: caption generation and learnable interface for incorporatingexplicit and implicit observation feedback to the LLM, respectively. Thesemethods serve as the two baselines for our proposed benchmark. Experiments showthat both methods struggle to solve some tasks, indicating long-horizonmanipulation tasks are still challenging for current popular models. We expectthe proposed public benchmark and baselines can help the community developbetter models for long-horizon tabletop manipulation tasks.</description><author>Shengqiang Zhang, Philipp Wicke, Lütfi Kerem Şenel, Luis Figueredo, Abdeldjallil Naceri, Sami Haddadin, Barbara Plank, Hinrich Schütze</author><pubDate>Wed, 18 Oct 2023 15:53:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12020v1</guid></item><item><title>Crystal: Introspective Reasoners Reinforced with Self-Feedback</title><link>http://arxiv.org/abs/2310.04921v2</link><description>Extensive work has shown that the performance and interpretability ofcommonsense reasoning can be improved via knowledge-augmented reasoningmethods, where the knowledge that underpins the reasoning process is explicitlyverbalized and utilized. However, existing implementations, including"chain-of-thought" and its variants, fall short in capturing the introspectivenature of knowledge required in commonsense reasoning, and in accounting forthe mutual adaptation between the generation and utilization of knowledge. Wepropose a novel method to develop an introspective commonsense reasoner,Crystal. To tackle commonsense problems, it first introspects for knowledgestatements related to the given question, and subsequently makes an informedprediction that is grounded in the previously introspected knowledge. Theknowledge introspection and knowledge-grounded reasoning modes of the model aretuned via reinforcement learning to mutually adapt, where the reward derivesfrom the feedback given by the model itself. Experiments show that Crystalsignificantly outperforms both the standard supervised finetuning andchain-of-thought distilled methods, and enhances the transparency of thecommonsense reasoning process. Our work ultimately validates the feasibilityand potential of reinforcing a neural model with self-feedback.</description><author>Jiacheng Liu, Ramakanth Pasunuru, Hannaneh Hajishirzi, Yejin Choi, Asli Celikyilmaz</author><pubDate>Wed, 18 Oct 2023 15:52:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04921v2</guid></item><item><title>Exploring Decision-based Black-box Attacks on Face Forgery Detection</title><link>http://arxiv.org/abs/2310.12017v1</link><description>Face forgery generation technologies generate vivid faces, which have raisedpublic concerns about security and privacy. Many intelligent systems, such aselectronic payment and identity verification, rely on face forgery detection.Although face forgery detection has successfully distinguished fake faces,recent studies have demonstrated that face forgery detectors are veryvulnerable to adversarial examples. Meanwhile, existing attacks rely on networkarchitectures or training datasets instead of the predicted labels, which leadsto a gap in attacking deployed applications. To narrow this gap, we firstexplore the decision-based attacks on face forgery detection. However, applyingexisting decision-based attacks directly suffers from perturbationinitialization failure and low image quality. First, we propose cross-taskperturbation to handle initialization failures by utilizing the highcorrelation of face features on different tasks. Then, inspired by usingfrequency cues by face forgery detection, we propose the frequencydecision-based attack. We add perturbations in the frequency domain and thenconstrain the visual quality in the spatial domain. Finally, extensiveexperiments demonstrate that our method achieves state-of-the-art attackperformance on FaceForensics++, CelebDF, and industrial APIs, with high queryefficiency and guaranteed image quality. Further, the fake faces by our methodcan pass face forgery detection and face recognition, which exposes thesecurity problems of face forgery detectors.</description><author>Zhaoyu Chen, Bo Li, Kaixun Jiang, Shuang Wu, Shouhong Ding, Wenqiang Zhang</author><pubDate>Wed, 18 Oct 2023 15:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12017v1</guid></item><item><title>Influence of the Geometry of the world model on Curiosity Based Exploration</title><link>http://arxiv.org/abs/2304.00188v2</link><description>In human spatial awareness, 3-D projective geometry structures informationintegration and action planning through perspective taking within an internalrepresentation space. The way different perspectives are related and transforma world model defines a specific perception and imagination scheme. Inmathematics, such collection of transformations corresponds to a 'group', whose'actions' characterize the geometry of a space. Imbuing world models with agroup structure may capture different agents' spatial awareness and affordanceschemes. We used group action as a special class of policies forperspective-dependent control. We explored how such geometric structure impactsagents' behavior, comparing how the Euclidean versus projective groups act onepistemic value in active inference, drive curiosity, and explorationbehaviors. We formally demonstrate and simulate how the groups induce distinctbehaviors in a simple search task. The projective group's nonlinearmagnification of information transformed epistemic value according to thechoice of frame, generating behaviors of approach toward an object of interest.The projective group structure within the agent's world model contains theProjective Consciousness Model, which is know to capture key features ofconsciousness. On the other hand, the Euclidean group had no effect onepistemic value : no action was better than the initial idle state. Instructuring a priori an agent's internal representation, we show how geometrycan play a key role in information integration and action planning.</description><author>Grégoire Sergeant-Perthuis, Nils Ruet, David Rudrauf, Dimitri Ognibene, Yvain Tisserand</author><pubDate>Wed, 18 Oct 2023 15:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00188v2</guid></item><item><title>Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements</title><link>http://arxiv.org/abs/2305.03695v3</link><description>Despite the much discussed capabilities of today's language models, they arestill prone to silly and unexpected commonsense failures. We consider aretrospective verification approach that reflects on the correctness of LMoutputs, and introduce Vera, a general-purpose model that estimates theplausibility of declarative statements based on commonsense knowledge. Trainedon ~7M commonsense statements created from 19 QA datasets and two large-scaleknowledge bases, and with a combination of three training objectives, Vera is aversatile model that effectively separates correct from incorrect statementsacross diverse commonsense domains. When applied to solving commonsenseproblems in the verification format, Vera substantially outperforms existingmodels that can be repurposed for commonsense verification, and it furtherexhibits generalization capabilities to unseen tasks and provideswell-calibrated outputs. We find that Vera excels at filtering LM-generatedcommonsense knowledge and is useful in detecting erroneous commonsensestatements generated by models like ChatGPT in real-world settings.</description><author>Jiacheng Liu, Wenya Wang, Dianzhuo Wang, Noah A. Smith, Yejin Choi, Hannaneh Hajishirzi</author><pubDate>Wed, 18 Oct 2023 15:48:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03695v3</guid></item><item><title>Learning Residual Elastic Warps for Image Stitching under Dirichlet Boundary Condition</title><link>http://arxiv.org/abs/2309.01406v3</link><description>Trendy suggestions for learning-based elastic warps enable the deep imagestitchings to align images exposed to large parallax errors. Despite theremarkable alignments, the methods struggle with occasional holes ordiscontinuity between overlapping and non-overlapping regions of a target imageas the applied training strategy mostly focuses on overlap region alignment. Asa result, they require additional modules such as seam finder and imageinpainting for hiding discontinuity and filling holes, respectively. In thiswork, we suggest Recurrent Elastic Warps (REwarp) that address the problem withDirichlet boundary condition and boost performances by residual learning forrecurrent misalign correction. Specifically, REwarp predicts a homography and aThin-plate Spline (TPS) under the boundary constraint for discontinuity andhole-free image stitching. Our experiments show the favorable aligns and thecompetitive computational costs of REwarp compared to the existing stitchingmethods. Our source code is available at https://github.com/minshu-kim/REwarp.</description><author>Minsu Kim, Yongjun Lee, Woo Kyoung Han, Kyong Hwan Jin</author><pubDate>Wed, 18 Oct 2023 15:47:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01406v3</guid></item><item><title>Gold: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection</title><link>http://arxiv.org/abs/2310.12011v1</link><description>Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning,yet constructing them through human annotations can be costly. As a result,various automatic methods have been proposed to construct CSKG with largersemantic coverage. However, these unsupervised approaches introduce spuriousnoise that can lower the quality of the resulting CSKG, which cannot be tackledeasily by existing denoising algorithms due to the unique characteristics ofnodes and structures in CSKGs. To address this issue, we propose Gold (Globaland Local-aware Denoising), a denoising framework for CSKGs that incorporatesentity semantic information, global rules, and local structural informationfrom the CSKG. Experiment results demonstrate that Gold outperforms allbaseline methods in noise detection tasks on synthetic noisy CSKG benchmarks.Furthermore, we show that denoising a real-world CSKG is effective and evenbenefits the downstream zero-shot commonsense question-answering task.</description><author>Zheye Deng, Weiqi Wang, Zhaowei Wang, Xin Liu, Yangqiu Song</author><pubDate>Wed, 18 Oct 2023 15:43:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12011v1</guid></item><item><title>Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting</title><link>http://arxiv.org/abs/2302.04813v3</link><description>Recent work has shown how to prompt large language models with explanationsto obtain strong performance on textual reasoning tasks, i.e., thechain-of-thought paradigm. However, subtly different explanations can yieldwidely varying downstream task accuracy. Explanations that have not been"tuned" for a task, such as off-the-shelf explanations written by nonexperts,may lead to mediocre performance. This paper tackles the problem of how tooptimize explanation-infused prompts in a blackbox fashion. We first generatesets of candidate explanations for each example in the prompt using aleave-one-out scheme, then find an effective combination of these explanationswith a two-stage framework. We first evaluate explanations for each in-contextexample in isolation according to two proxy metrics, log likelihood andaccuracy on new examples. Then, we search over combinations of explanations tofind one that yields high performance against a silver-labeled development set.Across four textual reasoning tasks spanning question answering, mathematicalreasoning, and natural language inference, results show that our proxy metricscorrelate with ground truth accuracy and our overall method can effectivelyimprove prompts over crowdworker annotations and naive search strategies</description><author>Xi Ye, Greg Durrett</author><pubDate>Wed, 18 Oct 2023 15:42:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04813v3</guid></item><item><title>Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs</title><link>http://arxiv.org/abs/2310.12008v1</link><description>Knowledge graph entity typing (KGET) aims at inferring plausible types ofentities in knowledge graphs. Existing approaches to KGET focus on how tobetter encode the knowledge provided by the neighbors and types of an entityinto its representation. However, they ignore the semantic knowledge providedby the way in which types can be clustered together. In this paper, we proposea novel method called Multi-view Contrastive Learning for knowledge graphEntity Typing (MCLET), which effectively encodes the coarse-grained knowledgeprovided by clusters into entity and type embeddings. MCLET is composed ofthree modules: i) Multi-view Generation and Encoder module, which encodesstructured information from entity-type, entity-cluster and cluster-type views;ii) Cross-view Contrastive Learning module, which encourages different views tocollaboratively improve view-specific representations of entities and types;iii) Entity Typing Prediction module, which integrates multi-head attention anda Mixture-of-Experts strategy to infer missing entity types. Extensiveexperiments show the strong performance of MCLET compared to thestate-of-the-art</description><author>Zhiwei Hu, Víctor Gutiérrez-Basulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan</author><pubDate>Wed, 18 Oct 2023 15:41:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12008v1</guid></item><item><title>KI-PMF: Knowledge Integrated Plausible Motion Forecasting</title><link>http://arxiv.org/abs/2310.12007v1</link><description>Accurately forecasting the motion of traffic actors is crucial for thedeployment of autonomous vehicles at a large scale. Current trajectoryforecasting approaches primarily concentrate on optimizing a loss function witha specific metric, which can result in predictions that do not adhere tophysical laws or violate external constraints. Our objective is to incorporateexplicit knowledge priors that allow a network to forecast future trajectoriesin compliance with both the kinematic constraints of a vehicle and the geometryof the driving environment. To achieve this, we introduce a non-parametricpruning layer and attention layers to integrate the defined knowledge priors.Our proposed method is designed to ensure reachability guarantees for trafficactors in both complex and dynamic situations. By conditioning the network tofollow physical laws, we can obtain accurate and safe predictions, essentialfor maintaining autonomous vehicles' safety and efficiency in real-worldsettings.In summary, this paper presents concepts that prevent off-roadpredictions for safe and reliable motion forecasting by incorporating knowledgepriors into the training process.</description><author>Abhishek Vivekanandan, Ahmed Abouelazm, Philip Schörner, J. Marius Zöllner</author><pubDate>Wed, 18 Oct 2023 15:40:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12007v1</guid></item><item><title>Image Super-resolution Via Latent Diffusion: A Sampling-space Mixture Of Experts And Frequency-augmented Decoder Approach</title><link>http://arxiv.org/abs/2310.12004v1</link><description>The recent use of diffusion prior, enhanced by pre-trained text-image models,has markedly elevated the performance of image super-resolution (SR). Toalleviate the huge computational cost required by pixel-based diffusion SR,latent-based methods utilize a feature encoder to transform the image and thenimplement the SR image generation in a compact latent space. Nevertheless,there are two major issues that limit the performance of latent-baseddiffusion. First, the compression of latent space usually causes reconstructiondistortion. Second, huge computational cost constrains the parameter scale ofthe diffusion model. To counteract these issues, we first propose a frequencycompensation module that enhances the frequency components from latent space topixel space. The reconstruction distortion (especially for high-frequencyinformation) can be significantly decreased. Then, we propose to useSample-Space Mixture of Experts (SS-MoE) to achieve more powerful latent-basedSR, which steadily improves the capacity of the model without a significantincrease in inference costs. These carefully crafted designs contribute toperformance improvements in largely explored 4x blind super-resolutionbenchmarks and extend to large magnification factors, i.e., 8x image SRbenchmarks. The code is available at https://github.com/amandaluof/moe_sr.</description><author>Feng Luo, Jinxi Xiang, Jun Zhang, Xiao Han, Wei Yang</author><pubDate>Wed, 18 Oct 2023 15:39:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12004v1</guid></item><item><title>Policy Optimization for Continuous Reinforcement Learning</title><link>http://arxiv.org/abs/2305.18901v4</link><description>We study reinforcement learning (RL) in the setting of continuous time andspace, for an infinite horizon with a discounted objective and the underlyingdynamics driven by a stochastic differential equation. Built upon recentadvances in the continuous approach to RL, we develop a notion of occupationtime (specifically for a discounted objective), and show how it can beeffectively used to derive performance-difference and local-approximationformulas. We further extend these results to illustrate their applications inthe PG (policy gradient) and TRPO/PPO (trust region policy optimization/proximal policy optimization) methods, which have been familiar and powerfultools in the discrete RL setting but under-developed in continuous RL. Throughnumerical experiments, we demonstrate the effectiveness and advantages of ourapproach.</description><author>Hanyang Zhao, Wenpin Tang, David D. Yao</author><pubDate>Wed, 18 Oct 2023 15:38:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18901v4</guid></item><item><title>Surrogate Active Subspaces for Jump-Discontinuous Functions</title><link>http://arxiv.org/abs/2310.10907v2</link><description>Surrogate modeling and active subspaces have emerged as powerful paradigms incomputational science and engineering. Porting such techniques to computationalmodels in the social sciences brings into sharp relief their limitations indealing with discontinuous simulators, such as Agent-Based Models, which havediscrete outputs. Nevertheless, prior applied work has shown that surrogateestimates of active subspaces for such estimators can yield interestingresults. But given that active subspaces are defined by way of gradients, it isnot clear what quantity is being estimated when this methodology is applied toa discontinuous simulator. We begin this article by showing some pathologiesthat can arise when conducting such an analysis. This motivates an extension ofactive subspaces to discontinuous functions, clarifying what is actually beingestimated in such analyses. We also conduct numerical experiments on synthetictest functions to compare Gaussian process estimates of active subspaces oncontinuous and discontinuous functions. Finally, we deploy our methodology onFlee, an agent-based model of refugee movement, yielding novel insights intowhich parameters of the simulation are most important across 8 displacementcrises in Africa and the Middle East.</description><author>Nathan Wycoff</author><pubDate>Wed, 18 Oct 2023 15:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10907v2</guid></item><item><title>Koopa: Learning Non-stationary Time Series Dynamics with Koopman Predictors</title><link>http://arxiv.org/abs/2305.18803v2</link><description>Real-world time series are characterized by intrinsic non-stationarity thatposes a principal challenge for deep forecasting models. While previous modelssuffer from complicated series variations induced by changing temporaldistribution, we tackle non-stationary time series with modern Koopman theorythat fundamentally considers the underlying time-variant dynamics. Inspired byKoopman theory of portraying complex dynamical systems, we disentangletime-variant and time-invariant components from intricate non-stationary seriesby Fourier Filter and design Koopman Predictor to advance respective dynamicsforward. Technically, we propose Koopa as a novel Koopman forecaster composedof stackable blocks that learn hierarchical dynamics. Koopa seeks measurementfunctions for Koopman embedding and utilizes Koopman operators as linearportraits of implicit transition. To cope with time-variant dynamics thatexhibits strong locality, Koopa calculates context-aware operators in thetemporal neighborhood and is able to utilize incoming ground truth to scale upforecast horizon. Besides, by integrating Koopman Predictors into deep residualstructure, we ravel out the binding reconstruction loss in previous Koopmanforecasters and achieve end-to-end forecasting objective optimization. Comparedwith the state-of-the-art model, Koopa achieves competitive performance whilesaving 77.3% training time and 76.0% memory.</description><author>Yong Liu, Chenyu Li, Jianmin Wang, Mingsheng Long</author><pubDate>Wed, 18 Oct 2023 15:33:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18803v2</guid></item><item><title>Reaching the Limit in Autonomous Racing: Optimal Control versus Reinforcement Learning</title><link>http://arxiv.org/abs/2310.10943v2</link><description>A central question in robotics is how to design a control system for an agilemobile robot. This paper studies this question systematically, focusing on achallenging setting: autonomous drone racing. We show that a neural networkcontroller trained with reinforcement learning (RL) outperformed optimalcontrol (OC) methods in this setting. We then investigated which fundamentalfactors have contributed to the success of RL or have limited OC. Our studyindicates that the fundamental advantage of RL over OC is not that it optimizesits objective better but that it optimizes a better objective. OC decomposesthe problem into planning and control with an explicit intermediaterepresentation, such as a trajectory, that serves as an interface. Thisdecomposition limits the range of behaviors that can be expressed by thecontroller, leading to inferior control performance when facing unmodeledeffects. In contrast, RL can directly optimize a task-level objective and canleverage domain randomization to cope with model uncertainty, allowing thediscovery of more robust control responses. Our findings allowed us to push anagile drone to its maximum performance, achieving a peak acceleration greaterthan 12 times the gravitational acceleration and a peak velocity of 108kilometers per hour. Our policy achieved superhuman control within minutes oftraining on a standard workstation. This work presents a milestone in agilerobotics and sheds light on the role of RL and OC in robot control.</description><author>Yunlong Song, Angel Romero, Matthias Mueller, Vladlen Koltun, Davide Scaramuzza</author><pubDate>Wed, 18 Oct 2023 15:32:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10943v2</guid></item><item><title>Bayesian Flow Networks in Continual Learning</title><link>http://arxiv.org/abs/2310.12001v1</link><description>Bayesian Flow Networks (BFNs) has been recently proposed as one of the mostpromising direction to universal generative modelling, having ability to learnany of the data type. Their power comes from the expressiveness of neuralnetworks and Bayesian inference which make them suitable in the context ofcontinual learning. We delve into the mechanics behind BFNs and conduct theexperiments to empirically verify the generative capabilities on non-stationarydata.</description><author>Mateusz Pyla, Kamil Deja, Bartłomiej Twardowski, Tomasz Trzciński</author><pubDate>Wed, 18 Oct 2023 15:32:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12001v1</guid></item><item><title>Iterative Methods for Vecchia-Laplace Approximations for Latent Gaussian Process Models</title><link>http://arxiv.org/abs/2310.12000v1</link><description>Latent Gaussian process (GP) models are flexible probabilistic non-parametricfunction models. Vecchia approximations are accurate approximations for GPs toovercome computational bottlenecks for large data, and the Laplaceapproximation is a fast method with asymptotic convergence guarantees toapproximate marginal likelihoods and posterior predictive distributions fornon-Gaussian likelihoods. Unfortunately, the computational complexity ofcombined Vecchia-Laplace approximations grows faster than linearly in thesample size when used in combination with direct solver methods such as theCholesky decomposition. Computations with Vecchia-Laplace approximations thusbecome prohibitively slow precisely when the approximations are usually themost accurate, i.e., on large data sets. In this article, we present severaliterative methods for inference with Vecchia-Laplace approximations which makecomputations considerably faster compared to Cholesky-based calculations. Weanalyze our proposed methods theoretically and in experiments with simulatedand real-world data. In particular, we obtain a speed-up of an order ofmagnitude compared to Cholesky-based inference and a threefold increase inprediction accuracy in terms of the continuous ranked probability scorecompared to a state-of-the-art method on a large satellite data set. Allmethods are implemented in a free C++ software library with high-level Pythonand R packages.</description><author>Pascal Kündig, Fabio Sigrist</author><pubDate>Wed, 18 Oct 2023 15:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12000v1</guid></item><item><title>Vulnerabilities in Video Quality Assessment Models: The Challenge of Adversarial Attacks</title><link>http://arxiv.org/abs/2309.13609v2</link><description>No-Reference Video Quality Assessment (NR-VQA) plays an essential role inimproving the viewing experience of end-users. Driven by deep learning, recentNR-VQA models based on Convolutional Neural Networks (CNNs) and Transformershave achieved outstanding performance. To build a reliable and practicalassessment system, it is of great necessity to evaluate their robustness.However, such issue has received little attention in the academic community. Inthis paper, we make the first attempt to evaluate the robustness of NR-VQAmodels against adversarial attacks, and propose a patch-based random searchmethod for black-box attack. Specifically, considering both the attack effecton quality score and the visual quality of adversarial video, the attackproblem is formulated as misleading the estimated quality score under theconstraint of just-noticeable difference (JND). Built upon such formulation, anovel loss function called Score-Reversed Boundary Loss is designed to push theadversarial video's estimated quality score far away from its ground-truthscore towards a specific boundary, and the JND constraint is modeled as astrict $L_2$ and $L_\infty$ norm restriction. By this means, both white-box andblack-box attacks can be launched in an effective and imperceptible manner. Thesource code is available at https://github.com/GZHU-DVL/AttackVQA.</description><author>Ao-Xiang Zhang, Yu Ran, Weixuan Tang, Yuan-Gen Wang</author><pubDate>Wed, 18 Oct 2023 15:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13609v2</guid></item><item><title>Removing Spurious Concepts from Neural Network Representations via Joint Subspace Estimation</title><link>http://arxiv.org/abs/2310.11991v1</link><description>Out-of-distribution generalization in neural networks is often hampered byspurious correlations. A common strategy is to mitigate this by removingspurious concepts from the neural network representation of the data. Existingconcept-removal methods tend to be overzealous by inadvertently eliminatingfeatures associated with the main task of the model, thereby harming modelperformance. We propose an iterative algorithm that separates spurious frommain-task concepts by jointly identifying two low-dimensional orthogonalsubspaces in the neural network representation. We evaluate the algorithm onbenchmark datasets for computer vision (Waterbirds, CelebA) and naturallanguage processing (MultiNLI), and show that it outperforms existing conceptremoval methods</description><author>Floris Holstege, Bram Wouters, Noud van Giersbergen, Cees Diks</author><pubDate>Wed, 18 Oct 2023 15:22:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11991v1</guid></item><item><title>Image Clustering with External Guidance</title><link>http://arxiv.org/abs/2310.11989v1</link><description>The core of clustering is incorporating prior knowledge to constructsupervision signals. From classic k-means based on data compactness to recentcontrastive clustering guided by self-supervision, the evolution of clusteringmethods intrinsically corresponds to the progression of supervision signals. Atpresent, substantial efforts have been devoted to mining internal supervisionsignals from data. Nevertheless, the abundant external knowledge such assemantic descriptions, which naturally conduces to clustering, is regrettablyoverlooked. In this work, we propose leveraging external knowledge as a newsupervision signal to guide clustering, even though it seems irrelevant to thegiven data. To implement and validate our idea, we design an externally guidedclustering method (Text-Aided Clustering, TAC), which leverages the textualsemantics of WordNet to facilitate image clustering. Specifically, TAC firstselects and retrieves WordNet nouns that best distinguish images to enhance thefeature discriminability. Then, to improve image clustering performance, TACcollaborates text and image modalities by mutually distilling cross-modalneighborhood information. Experiments demonstrate that TAC achievesstate-of-the-art performance on five widely used and three more challengingimage clustering benchmarks, including the full ImageNet-1K dataset.</description><author>Yunfan Li, Peng Hu, Dezhong Peng, Jiancheng Lv, Jianping Fan, Xi Peng</author><pubDate>Wed, 18 Oct 2023 15:20:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11989v1</guid></item><item><title>Learning to Compose Representations of Different Encoder Layers towards Improving Compositional Generalization</title><link>http://arxiv.org/abs/2305.12169v2</link><description>Recent studies have shown that sequence-to-sequence (seq2seq) models strugglewith compositional generalization (CG), i.e., the ability to systematicallygeneralize to unseen compositions of seen components. There is mountingevidence that one of the reasons hindering CG is the representation of theencoder uppermost layer is entangled, i.e., the syntactic and semanticrepresentations of sequences are entangled. However, we consider that thepreviously identified representation entanglement problem is not comprehensiveenough. Additionally, we hypothesize that the source keys and valuesrepresentations passing into different decoder layers are also entangled.Starting from this intuition, we propose \textsc{CompoSition} (\textbf{Compo}se\textbf{S}yntactic and Semant\textbf{i}c Representa\textbf{tion}s), anextension to seq2seq models which learns to compose representations ofdifferent encoder layers dynamically for different tasks, since recent studiesreveal that the bottom layers of the Transformer encoder contain more syntacticinformation and the top ones contain more semantic information. Specifically,we introduce a \textit{composed layer} between the encoder and decoder tocompose different encoder layers' representations to generate specific keys andvalues passing into different decoder layers. \textsc{CompoSition} achievescompetitive results on two comprehensive and realistic benchmarks, whichempirically demonstrates the effectiveness of our proposal. Codes are availableat~\url{https://github.com/thinkaboutzero/COMPOSITION}.</description><author>Lei Lin, Shuangtao Li, Yafang Zheng, Biao Fu, Shan Liu, Yidong Chen, Xiaodong Shi</author><pubDate>Wed, 18 Oct 2023 15:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12169v2</guid></item><item><title>Implicit Neural Image Stitching With Enhanced and Blended Feature Reconstruction</title><link>http://arxiv.org/abs/2309.01409v4</link><description>Existing frameworks for image stitching often provide visually reasonablestitchings. However, they suffer from blurry artifacts and disparities inillumination, depth level, etc. Although the recent learning-based stitchingsrelax such disparities, the required methods impose sacrifice of imagequalities failing to capture high-frequency details for stitched images. Toaddress the problem, we propose a novel approach, implicit Neural ImageStitching (NIS) that extends arbitrary-scale super-resolution. Our methodestimates Fourier coefficients of images for quality-enhancing warps. Then, thesuggested model blends color mismatches and misalignment in the latent spaceand decodes the features into RGB values of stitched images. Our experimentsshow that our approach achieves improvement in resolving the low-definitionimaging of the previous deep image stitching with favorable acceleratedimage-enhancing methods. Our source code is available athttps://github.com/minshu-kim/NIS.</description><author>Minsu Kim, Jaewon Lee, Byeonghun Lee, Sunghoon Im, Kyong Hwan Jin</author><pubDate>Wed, 18 Oct 2023 15:18:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01409v4</guid></item><item><title>PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts</title><link>http://arxiv.org/abs/2306.04528v4</link><description>The increasing reliance on Large Language Models (LLMs) across academia andindustry necessitates a comprehensive understanding of their robustness toprompts. In response to this vital need, we introduce PromptBench, a robustnessbenchmark designed to measure LLMs' resilience to adversarial prompts. Thisstudy uses a plethora of adversarial textual attacks targeting prompts acrossmultiple levels: character, word, sentence, and semantic. The adversarialprompts, crafted to mimic plausible user errors like typos or synonyms, aim toevaluate how slight deviations can affect LLM outcomes while maintainingsemantic integrity. These prompts are then employed in diverse tasks, such assentiment analysis, natural language inference, reading comprehension, machinetranslation, and math problem-solving. Our study generates 4788 adversarialprompts, meticulously evaluated over 8 tasks and 13 datasets. Our findingsdemonstrate that contemporary LLMs are not robust to adversarial prompts.Furthermore, we present comprehensive analysis to understand the mystery behindprompt robustness and its transferability. We then offer insightful robustnessanalysis and pragmatic recommendations for prompt composition, beneficial toboth researchers and everyday users. Code is available at:https://github.com/microsoft/promptbench.</description><author>Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Yue Zhang, Neil Zhenqiang Gong, Xing Xie</author><pubDate>Wed, 18 Oct 2023 15:16:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04528v4</guid></item><item><title>Sociotechnical Safety Evaluation of Generative AI Systems</title><link>http://arxiv.org/abs/2310.11986v1</link><description>Generative AI systems produce a range of risks. To ensure the safety ofgenerative AI systems, these risks must be evaluated. In this paper, we maketwo main contributions toward establishing such evaluations. First, we proposea three-layered framework that takes a structured, sociotechnical approach toevaluating these risks. This framework encompasses capability evaluations,which are the main current approach to safety evaluation. It then reachesfurther by building on system safety principles, particularly the insight thatcontext determines whether a given capability may cause harm. To account forrelevant context, our framework adds human interaction and systemic impacts asadditional layers of evaluation. Second, we survey the current state of safetyevaluation of generative AI systems and create a repository of existingevaluations. Three salient evaluation gaps emerge from this analysis. Wepropose ways forward to closing these gaps, outlining practical steps as wellas roles and responsibilities for different actors. Sociotechnical safetyevaluation is a tractable approach to the robust and comprehensive safetyevaluation of generative AI systems.</description><author>Laura Weidinger, Maribeth Rauh, Nahema Marchal, Arianna Manzini, Lisa Anne Hendricks, Juan Mateos-Garcia, Stevie Bergman, Jackie Kay, Conor Griffin, Ben Bariach, Iason Gabriel, Verena Rieser, William Isaac</author><pubDate>Wed, 18 Oct 2023 15:13:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11986v1</guid></item><item><title>A Finite-Horizon Approach to Active Level Set Estimation</title><link>http://arxiv.org/abs/2310.11985v1</link><description>We consider the problem of active learning in the context of spatial samplingfor level set estimation (LSE), where the goal is to localize all regions wherea function of interest lies above/below a given threshold as quickly aspossible. We present a finite-horizon search procedure to perform LSE in onedimension while optimally balancing both the final estimation error and thedistance traveled for a fixed number of samples. A tuning parameter is used totrade off between the estimation accuracy and distance traveled. We show thatthe resulting optimization problem can be solved in closed form and that theresulting policy generalizes existing approaches to this problem. We then showhow this approach can be used to perform level set estimation in higherdimensions under the popular Gaussian process model. Empirical results onsynthetic data indicate that as the cost of travel increases, our method'sability to treat distance nonmyopically allows it to significantly improve onthe state of the art. On real air quality data, our approach achieves roughlyone fifth the estimation error at less than half the cost of competingalgorithms.</description><author>Phillip Kearns, Bruno Jedynak, John Lipor</author><pubDate>Wed, 18 Oct 2023 15:11:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11985v1</guid></item></channel></rss>