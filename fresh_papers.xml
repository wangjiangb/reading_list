<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 16 Apr 2024 06:00:38 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>A replica analysis of under-bagging</title><link>http://arxiv.org/abs/2404.09779v1</link><description>A sharp asymptotics of the under-bagging (UB) method, which is a popularensemble learning method for training classifiers from an imbalanced data, isderived and used to compare with several other standard methods for learningfrom imbalanced data, in the scenario where a linear classifier is trained froma binary mixture data. The methods compared include the under-sampling (US)method, which trains a model using a single realization of the subsampleddataset, and the simple weighting (SW) method, which trains a model with aweighted loss on the entire data. It is shown that the performance of UB isimproved by increasing the size of the majority class, even if the classimbalance can be large, especially when the size of the minority class issmall. This is in contrast to US, whose performance does not change as the sizeof the majority class increases, and SW, whose performance decreases as theimbalance increases. These results are different from the case of the naivebagging in training generalized linear models without considering the structureof class imbalance, indicating the intrinsic difference between the ensemblingand the direct regularization on the parameters.</description><author>Takashi Takahashi</author><pubDate>Mon, 15 Apr 2024 14:31:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09779v1</guid></item><item><title>The Devil is in the Few Shots: Iterative Visual Knowledge Completion for Few-shot Learning</title><link>http://arxiv.org/abs/2404.09778v1</link><description>Contrastive Language-Image Pre-training (CLIP) has shown powerful zero-shotlearning performance. Few-shot learning aims to further enhance the transfercapability of CLIP by giving few images in each class, aka 'few shots'. Mostexisting methods either implicitly learn from the few shots by incorporatinglearnable prompts or adapters, or explicitly embed them in a cache model forinference. However, the narrow distribution of few shots often containsincomplete class information, leading to biased visual knowledge with high riskof misclassification. To tackle this problem, recent methods propose tosupplement visual knowledge by generative models or extra databases, which canbe costly and time-consuming. In this paper, we propose an Iterative VisualKnowledge CompLetion (KCL) method to complement visual knowledge by properlytaking advantages of unlabeled samples without access to any auxiliary orsynthetic data. Specifically, KCL first measures the similarities betweenunlabeled samples and each category. Then, the samples with top confidence toeach category is selected and collected by a designed confidence criterion.Finally, the collected samples are treated as labeled ones and added to fewshots to jointly re-estimate the remaining unlabeled ones. The above procedureswill be repeated for a certain number of iterations with more and more samplesbeing collected until convergence, ensuring a progressive and robust knowledgecompletion process. Extensive experiments on 11 benchmark datasets demonstratethe effectiveness and efficiency of KCL as a plug-and-play module under bothfew-shot and zero-shot learning settings. Code is available athttps://github.com/Mark-Sky/KCL.</description><author>Yaohui Li, Qifeng Zhou, Haoxing Chen, Jianbing Zhang, Xinyu Dai, Hao Zhou</author><pubDate>Mon, 15 Apr 2024 14:30:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09778v1</guid></item><item><title>RandAlign: A Parameter-Free Method for Regularizing Graph Convolutional Networks</title><link>http://arxiv.org/abs/2404.09774v1</link><description>Studies continually find that message-passing graph convolutional networkssuffer from the over-smoothing issue. Basically, the issue of over-smoothingrefers to the phenomenon that the learned embeddings for all nodes can becomevery similar to one another and therefore are uninformative after repeatedlyapplying message passing iterations. Intuitively, we can expect the generatedembeddings become smooth asymptotically layerwisely, that is each layer ofgraph convolution generates a smoothed version of embeddings as compared tothat generated by the previous layer. Based on this intuition, we proposeRandAlign, a stochastic regularization method for graph convolutional networks.The idea of RandAlign is to randomly align the learned embedding for each nodewith that of the previous layer using randomly interpolation in each graphconvolution layer. Through alignment, the smoothness of the generatedembeddings is explicitly reduced. To better maintain the benefit yielded by thegraph convolution, in the alignment step we introduce to first scale theembedding of the previous layer to the same norm as the generated embedding andthen perform random interpolation for aligning the generated embedding.RandAlign is a parameter-free method and can be directly applied withoutintroducing additional trainable weights or hyper-parameters. We experimentallyevaluate RandAlign on different graph domain tasks on seven benchmark datasets.The experimental results show that RandAlign is a general method that improvesthe generalization performance of various graph convolutional network modelsand also improves the numerical stability of optimization, advancing the stateof the art performance for graph representation learning.</description><author>Haimin Zhang, Min Xu</author><pubDate>Mon, 15 Apr 2024 14:28:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09774v1</guid></item><item><title>ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models</title><link>http://arxiv.org/abs/2403.16187v2</link><description>Parameter-efficient fine-tuning (PEFT) is widely studied for itseffectiveness and efficiency in the era of large language models. Low-rankadaptation (LoRA) has demonstrated commendable performance as a popular andrepresentative method. However, it is implemented with a fixed intrinsic rankthat might not be the ideal setting for the downstream tasks. Recognizing theneed for more flexible downstream task adaptation, we extend the methodology ofLoRA to an innovative approach we call allocating low-rank adaptation (ALoRA)that enables dynamic adjustments to the intrinsic rank during the adaptationprocess. First, we propose a novel method, AB-LoRA, that can effectivelyestimate the importance score of each LoRA rank. Second, guided by AB-LoRA, wegradually prune abundant and negatively impacting LoRA ranks and allocate thepruned LoRA budgets to important Transformer modules needing higher ranks. Wehave conducted experiments on various tasks, and the experimental resultsdemonstrate that our ALoRA method can outperform the recent baselines withcomparable tunable parameters.</description><author>Zequan Liu, Jiawen Lyn, Wei Zhu, Xing Tian, Yvette Graham</author><pubDate>Mon, 15 Apr 2024 14:25:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16187v2</guid></item><item><title>Contrastive Pretraining for Visual Concept Explanations of Socioeconomic Outcomes</title><link>http://arxiv.org/abs/2404.09768v1</link><description>Predicting socioeconomic indicators from satellite imagery with deep learninghas become an increasingly popular research direction. Post-hoc concept-basedexplanations can be an important step towards broader adoption of these modelsin policy-making as they enable the interpretation of socioeconomic outcomesbased on visual concepts that are intuitive to humans. In this paper, we studythe interplay between representation learning using an additional task-specificcontrastive loss and post-hoc concept explainability for socioeconomic studies.Our results on two different geographical locations and tasks indicate that thetask-specific pretraining imposes a continuous ordering of the latent spaceembeddings according to the socioeconomic outcomes. This improves the model'sinterpretability as it enables the latent space of the model to associate urbanconcepts with continuous intervals of socioeconomic outcomes. Further, weillustrate how analyzing the model's conceptual sensitivity for the intervalsof socioeconomic outcomes can shed light on new insights for urban studies.</description><author>Ivica Obadic, Alex Levering, Lars Pennig, Dario Oliveira, Diego Marcos, Xiaoxiang Zhu</author><pubDate>Mon, 15 Apr 2024 14:13:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09768v1</guid></item><item><title>On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm</title><link>http://arxiv.org/abs/2402.00389v3</link><description>Although adaptive gradient methods have been extensively used in deeplearning, their convergence rates proved in the literature are all slower thanthat of SGD, particularly with respect to their dependence on the dimension.This paper considers the classical RMSProp and its momentum extension andestablishes the convergence rate of $\frac{1}{T}\sum_{k=1}^T E\left[\|\nablaf(x^k)\|_1\right]\leq O(\frac{\sqrt{d}C}{T^{1/4}})$ measured by $\ell_1$ normwithout the bounded gradient assumption, where $d$ is the dimension of theoptimization variable, $T$ is the iteration number, and $C$ is a constantidentical to that appeared in the optimal convergence rate of SGD. Ourconvergence rate matches the lower bound with respect to all the coefficientsexcept the dimension $d$. Since $\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ forproblems with extremely large $d$, our convergence rate can be considered to beanalogous to the $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_2\right]\leqO(\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\|\nablaf(x)\|_1=\varTheta(\sqrt{d}\|\nabla f(x)\|_2)$.</description><author>Huan Li, Zhouchen Lin</author><pubDate>Mon, 15 Apr 2024 14:07:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00389v3</guid></item><item><title>KG-CTG: Citation Generation through Knowledge Graph-guided Large Language Models</title><link>http://arxiv.org/abs/2404.09763v1</link><description>Citation Text Generation (CTG) is a task in natural language processing (NLP)that aims to produce text that accurately cites or references a cited documentwithin a source document. In CTG, the generated text draws upon contextual cuesfrom both the source document and the cited paper, ensuring accurate andrelevant citation information is provided. Previous work in the field ofcitation generation is mainly based on the text summarization of documents.Following this, this paper presents a framework, and a comparative study todemonstrate the use of Large Language Models (LLMs) for the task of citationgeneration. Also, we have shown the improvement in the results of citationgeneration by incorporating the knowledge graph relations of the papers in theprompt for the LLM to better learn the relationship between the papers. Toassess how well our model is performing, we have used a subset of standardS2ORC dataset, which only consists of computer science academic research papersin the English Language. Vicuna performs best for this task with 14.15 Meteor,12.88 Rouge-1, 1.52 Rouge-2, and 10.94 Rouge-L. Also, Alpaca performs best, andimproves the performance by 36.98% in Rouge-1, and 33.14% in Meteor byincluding knowledge graphs.</description><author>Avinash Anand, Mohit Gupta, Kritarth Prasad, Ujjwal Goel, Naman Lal, Astha Verma, Rajiv Ratn Shah</author><pubDate>Mon, 15 Apr 2024 14:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09763v1</guid></item><item><title>Deep Learning-Based Segmentation of Tumors in PET/CT Volumes: Benchmark of Different Architectures and Training Strategies</title><link>http://arxiv.org/abs/2404.09761v1</link><description>Cancer is one of the leading causes of death globally, and early diagnosis iscrucial for patient survival. Deep learning algorithms have great potential forautomatic cancer analysis. Artificial intelligence has achieved highperformance in recognizing and segmenting single lesions. However, diagnosingmultiple lesions remains a challenge. This study examines and compares variousneural network architectures and training strategies for automaticallysegmentation of cancer lesions using PET/CT images from the head, neck, andwhole body. The authors analyzed datasets from the AutoPET and HECKTORchallenges, exploring popular single-step segmentation architectures andpresenting a two-step approach. The results indicate that the V-Net and nnU-Netmodels were the most effective for their respective datasets. The results forthe HECKTOR dataset ranged from 0.75 to 0.76 for the aggregated Dicecoefficient. Eliminating cancer-free cases from the AutoPET dataset was foundto improve the performance of most models. In the case of AutoPET data, theaverage segmentation efficiency after training only on images containing cancerlesions increased from 0.55 to 0.66 for the classic Dice coefficient and from0.65 to 0.73 for the aggregated Dice coefficient. The research demonstrates thepotential of artificial intelligence in precise oncological diagnostics and maycontribute to the development of more targeted and effective cancer assessmenttechniques.</description><author>Monika Górka, Daniel Jaworek, Marek Wodzinski</author><pubDate>Mon, 15 Apr 2024 14:03:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09761v1</guid></item><item><title>Effective Reinforcement Learning Based on Structural Information Principles</title><link>http://arxiv.org/abs/2404.09760v1</link><description>Although Reinforcement Learning (RL) algorithms acquire sequential behavioralpatterns through interactions with the environment, their effectiveness innoisy and high-dimensional scenarios typically relies on specific structuralpriors. In this paper, we propose a novel and general Structural Informationprinciples-based framework for effective Decision-Making, namely SIDM,approached from an information-theoretic perspective. This paper presents aspecific unsupervised partitioning method that forms vertex communities in thestate and action spaces based on their feature similarities. An aggregationfunction, which utilizes structural entropy as the vertex weight, is devisedwithin each community to obtain its embedding, thereby facilitatinghierarchical state and action abstractions. By extracting abstract elementsfrom historical trajectories, a directed, weighted, homogeneous transitiongraph is constructed. The minimization of this graph's high-dimensional entropyleads to the generation of an optimal encoding tree. An innovative two-layerskill-based learning mechanism is introduced to compute the common path entropyof each state transition as its identified probability, thereby obviating therequirement for expert knowledge. Moreover, SIDM can be flexibly incorporatedinto various single-agent and multi-agent RL algorithms, enhancing theirperformance. Finally, extensive evaluations on challenging benchmarksdemonstrate that, compared with SOTA baselines, our framework significantly andconsistently improves the policy's quality, stability, and efficiency up to32.70%, 88.26%, and 64.86%, respectively.</description><author>Xianghua Zeng, Hao Peng, Dingli Su, Angsheng Li</author><pubDate>Mon, 15 Apr 2024 14:02:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09760v1</guid></item><item><title>Resilience of Large Language Models for Noisy Instructions</title><link>http://arxiv.org/abs/2404.09754v1</link><description>As the rapidly advancing domain of natural language processing (NLP), largelanguage models (LLMs) have emerged as powerful tools for interpreting humancommands and generating text across various tasks. Nonetheless, the resilienceof LLMs to handle text containing inherent errors, stemming from humaninteractions and collaborative systems, has not been thoroughly explored. Ourstudy investigates the resilience of LLMs against five common types ofdisruptions including 1) ASR (Automatic Speech Recognition) errors, 2) OCR(Optical Character Recognition) errors, 3) grammatical mistakes, 4)typographical errors, and 5) distractive content. We aim to investigate howthese models react by deliberately embedding these errors into instructions.Our findings reveal that while some LLMs show a degree of resistance to certaintypes of noise, their overall performance significantly suffers. Thisemphasizes the importance of further investigation into enhancing modelresilience. In response to the observed decline in performance, our study alsoevaluates a "re-pass" strategy, designed to purify the instructions of noisebefore the LLMs process them. Our analysis indicates that correcting noisyinstructions, particularly for open-source LLMs, presents significantchallenges.</description><author>Bin Wang, Chengwei Wei, Zhengyuan Liu, Geyu Lin, Nancy F. Chen</author><pubDate>Mon, 15 Apr 2024 13:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09754v1</guid></item><item><title>Personalized Collaborative Fine-Tuning for On-Device Large Language Models</title><link>http://arxiv.org/abs/2404.09753v1</link><description>We explore on-device self-supervised collaborative fine-tuning of largelanguage models with limited local data availability. Taking inspiration fromthe collaborative learning community, we introduce three distincttrust-weighted gradient aggregation schemes: weight similarity-based,prediction similarity-based and validation performance-based. To minimizecommunication overhead, we integrate Low-Rank Adaptation (LoRA) and onlyexchange LoRA weight updates. Our protocols, driven by prediction andperformance metrics, surpass both FedAvg and local fine-tuning methods, whichis particularly evident in realistic scenarios with more diverse local datadistributions. The results underscore the effectiveness of our approach inaddressing heterogeneity and scarcity within local datasets.</description><author>Nicolas Wagner, Dongyang Fan, Martin Jaggi</author><pubDate>Mon, 15 Apr 2024 13:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09753v1</guid></item><item><title>Can We Break Free from Strong Data Augmentations in Self-Supervised Learning?</title><link>http://arxiv.org/abs/2404.09752v1</link><description>Self-supervised learning (SSL) has emerged as a promising solution foraddressing the challenge of limited labeled data in deep neural networks(DNNs), offering scalability potential. However, the impact of designdependencies within the SSL framework remains insufficiently investigated. Inthis study, we comprehensively explore SSL behavior across a spectrum ofaugmentations, revealing their crucial role in shaping SSL model performanceand learning mechanisms. Leveraging these insights, we propose a novel learningapproach that integrates prior knowledge, with the aim of curtailing the needfor extensive data augmentations and thereby amplifying the efficacy of learnedrepresentations. Notably, our findings underscore that SSL models imbued withprior knowledge exhibit reduced texture bias, diminished reliance on shortcutsand augmentations, and improved robustness against both natural and adversarialcorruptions. These findings not only illuminate a new direction in SSLresearch, but also pave the way for enhancing DNN performance whileconcurrently alleviating the imperative for intensive data augmentation,thereby enhancing scalability and real-world problem-solving capabilities.</description><author>Shruthi Gowda, Elahe Arani, Bahram Zonooz</author><pubDate>Mon, 15 Apr 2024 13:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09752v1</guid></item><item><title>LetsGo: Large-Scale Garage Modeling and Rendering via LiDAR-Assisted Gaussian Primitives</title><link>http://arxiv.org/abs/2404.09748v1</link><description>Large garages are ubiquitous yet intricate scenes in our daily lives, posingchallenges characterized by monotonous colors, repetitive patterns, reflectivesurfaces, and transparent vehicle glass. Conventional Structure from Motion(SfM) methods for camera pose estimation and 3D reconstruction fail in theseenvironments due to poor correspondence construction. To address thesechallenges, this paper introduces LetsGo, a LiDAR-assisted Gaussian splattingapproach for large-scale garage modeling and rendering. We develop a handheldscanner, Polar, equipped with IMU, LiDAR, and a fisheye camera, to facilitateaccurate LiDAR and image data scanning. With this Polar device, we present aGarageWorld dataset consisting of five expansive garage scenes with diversegeometric structures and will release the dataset to the community for furtherresearch. We demonstrate that the collected LiDAR point cloud by the Polardevice enhances a suite of 3D Gaussian splatting algorithms for garage scenemodeling and rendering. We also propose a novel depth regularizer for 3DGaussian splatting algorithm training, effectively eliminating floatingartifacts in rendered images, and a lightweight Level of Detail (LOD) Gaussianrenderer for real-time viewing on web-based devices. Additionally, we explore ahybrid representation that combines the advantages of traditional mesh indepicting simple geometry and colors (e.g., walls and the ground) with modern3D Gaussian representations capturing complex details and high-frequencytextures. This strategy achieves an optimal balance between memory performanceand rendering quality. Experimental results on our dataset, along withScanNet++ and KITTI-360, demonstrate the superiority of our method in renderingquality and resource efficiency.</description><author>Jiadi Cui, Junming Cao, Yuhui Zhong, Liao Wang, Fuqiang Zhao, Penghao Wang, Yifan Chen, Zhipeng He, Lan Xu, Yujiao Shi, Yingliang Zhang, Jingyi Yu</author><pubDate>Mon, 15 Apr 2024 13:50:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09748v1</guid></item><item><title>AMPCliff: quantitative definition and benchmarking of activity cliffs in antimicrobial peptides</title><link>http://arxiv.org/abs/2404.09738v1</link><description>Activity cliff (AC) is a phenomenon that a pair of similar molecules differby a small structural alternation but exhibit a large difference in theirbiochemical activities. The AC of small molecules has been extensivelyinvestigated but limited knowledge is accumulated about the AC phenomenon inpeptides with canonical amino acids. This study introduces a quantitativedefinition and benchmarking framework AMPCliff for the AC phenomenon inantimicrobial peptides (AMPs) composed by canonical amino acids. Acomprehensive analysis of the existing AMP dataset reveals a significantprevalence of AC within AMPs. AMPCliff quantifies the activities of AMPs by themetric minimum inhibitory concentration (MIC), and defines 0.9 as the minimumthreshold for the normalized BLOSUM62 similarity score between a pair ofaligned peptides with at least two-fold MIC changes. This study establishes abenchmark dataset of paired AMPs in Staphylococcus aureus from the publiclyavailable AMP dataset GRAMPA, and conducts a rigorous procedure to evaluatevarious AMP AC prediction models, including nine machine learning, four deeplearning algorithms, four masked language models, and four generative languagemodels. Our analysis reveals that these models are capable of detecting AMP ACevents and the pre-trained protein language ESM2 model demonstrates superiorperformance across the evaluations. The predictive performance of AMP activitycliffs remains to be further improved, considering that ESM2 with 33 layersonly achieves the Spearman correlation coefficient=0.50 for the regression taskof the MIC values on the benchmark dataset. Source code and additionalresources are available at https://www.healthinformaticslab.org/supp/ orhttps://github.com/Kewei2023/AMPCliff-generation.</description><author>Kewei Li, Yuqian Wu, Yutong Guo, Yinheng Li, Yusi Fan, Ruochi Zhang, Lan Huang, Fengfeng Zhou</author><pubDate>Mon, 15 Apr 2024 13:40:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09738v1</guid></item><item><title>Quantization of Large Language Models with an Overdetermined Basis</title><link>http://arxiv.org/abs/2404.09737v1</link><description>In this paper, we introduce an algorithm for data quantization based on theprinciples of Kashin representation. This approach hinges on decomposing anygiven vector, matrix, or tensor into two factors. The first factor maintains asmall infinity norm, while the second exhibits a similarly constrained normwhen multiplied by an orthogonal matrix. Surprisingly, the entries of factorsafter decomposition are well-concentrated around several peaks, which allows usto efficiently replace them with corresponding centroids for quantizationpurposes. We study the theoretical properties of the proposed approach andrigorously evaluate our compression algorithm in the context of next-wordprediction tasks and on a set of downstream tasks for text classification. Ourfindings demonstrate that Kashin Quantization achieves competitive or superiorquality in model performance while ensuring data compression, marking asignificant advancement in the field of data quantization.</description><author>Daniil Merkulov, Daria Cherniuk, Alexander Rudikov, Ivan Oseledets, Ekaterina Muravleva, Aleksandr Mikhalev, Boris Kashin</author><pubDate>Mon, 15 Apr 2024 13:38:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09737v1</guid></item><item><title>PerkwE_COQA: Enhanced Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models</title><link>http://arxiv.org/abs/2404.05406v2</link><description>Smart cities need the involvement of their residents to enhance quality oflife. Conversational query-answering is an emerging approach for userengagement. There is an increasing demand of an advanced conversationalquestion-answering that goes beyond classic systems. Existing approaches haveshown that LLMs offer promising capabilities for CQA, but may struggle tocapture the nuances of conversational contexts. The new approach involvesunderstanding the content and engaging in a multi-step conversation with theuser to fulfill their needs. This paper presents a novel method to elevate theperformance of Persian Conversational question-answering (CQA) systems. Itcombines the strengths of Large Language Models (LLMs) with contextual keywordextraction. Our method extracts keywords specific to the conversational flow,providing the LLM with additional context to understand the user's intent andgenerate more relevant and coherent responses. We evaluated the effectivenessof this combined approach through various metrics, demonstrating significantimprovements in CQA performance compared to an LLM-only baseline. The proposedmethod effectively handles implicit questions, delivers contextually relevantanswers, and tackles complex questions that rely heavily on conversationalcontext. The findings indicate that our method outperformed the evaluationbenchmarks up to 8% higher than existing methods and the LLM-only baseline.</description><author>Pardis Moradbeiki, Nasser Ghadiri</author><pubDate>Mon, 15 Apr 2024 13:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05406v2</guid></item><item><title>FSRT: Facial Scene Representation Transformer for Face Reenactment from Factorized Appearance, Head-pose, and Facial Expression Features</title><link>http://arxiv.org/abs/2404.09736v1</link><description>The task of face reenactment is to transfer the head motion and facialexpressions from a driving video to the appearance of a source image, which maybe of a different person (cross-reenactment). Most existing methods areCNN-based and estimate optical flow from the source image to the currentdriving frame, which is then inpainted and refined to produce the outputanimation. We propose a transformer-based encoder for computing a set-latentrepresentation of the source image(s). We then predict the output color of aquery pixel using a transformer-based decoder, which is conditioned withkeypoints and a facial expression vector extracted from the driving frame.Latent representations of the source person are learned in a self-supervisedmanner that factorize their appearance, head pose, and facial expressions.Thus, they are perfectly suited for cross-reenactment. In contrast to mostrelated work, our method naturally extends to multiple source images and canthus adapt to person-specific facial dynamics. We also propose dataaugmentation and regularization schemes that are necessary to preventoverfitting and support generalizability of the learned representations. Weevaluated our approach in a randomized user study. The results indicatesuperior performance compared to the state-of-the-art in terms of motiontransfer quality and temporal consistency.</description><author>Andre Rochow, Max Schwarz, Sven Behnke</author><pubDate>Mon, 15 Apr 2024 13:37:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09736v1</guid></item><item><title>Equipping Diffusion Models with Differentiable Spatial Entropy for Low-Light Image Enhancement</title><link>http://arxiv.org/abs/2404.09735v1</link><description>Image restoration, which aims to recover high-quality images from theircorrupted counterparts, often faces the challenge of being an ill-posed problemthat allows multiple solutions for a single input. However, most deep learningbased works simply employ l1 loss to train their network in a deterministicway, resulting in over-smoothed predictions with inferior perceptual quality.In this work, we propose a novel method that shifts the focus from adeterministic pixel-by-pixel comparison to a statistical perspective,emphasizing the learning of distributions rather than individual pixel values.The core idea is to introduce spatial entropy into the loss function to measurethe distribution difference between predictions and targets. To make thisspatial entropy differentiable, we employ kernel density estimation (KDE) toapproximate the probabilities for specific intensity values of each pixel withtheir neighbor areas. Specifically, we equip the entropy with diffusion modelsand aim for superior accuracy and enhanced perceptual quality over l1 basednoise matching loss. In the experiments, we evaluate the proposed method forlow light enhancement on two datasets and the NTIRE challenge 2024. All theseresults illustrate the effectiveness of our statistic-based entropy loss. Codeis available at https://github.com/shermanlian/spatial-entropy-loss.</description><author>Wenyi Lian, Wenjing Lian, Ziwei Luo</author><pubDate>Mon, 15 Apr 2024 13:35:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09735v1</guid></item><item><title>Photo-Realistic Image Restoration in the Wild with Controlled Vision-Language Models</title><link>http://arxiv.org/abs/2404.09732v1</link><description>Though diffusion models have been successfully applied to various imagerestoration (IR) tasks, their performance is sensitive to the choice oftraining datasets. Typically, diffusion models trained in specific datasetsfail to recover images that have out-of-distribution degradations. To addressthis problem, this work leverages a capable vision-language model and asynthetic degradation pipeline to learn image restoration in the wild (wildIR). More specifically, all low-quality images are simulated with a syntheticdegradation pipeline that contains multiple common degradations such as blur,resize, noise, and JPEG compression. Then we introduce robust training for adegradation-aware CLIP model to extract enriched image content features toassist high-quality image restoration. Our base diffusion model is the imagerestoration SDE (IR-SDE). Built upon it, we further present a posteriorsampling strategy for fast noise-free image generation. We evaluate our modelon both synthetic and real-world degradation datasets. Moreover, experiments onthe unified image restoration task illustrate that the proposed posteriorsampling improves image generation quality for various degradations.</description><author>Ziwei Luo, Fredrik K. Gustafsson, Zheng Zhao, Jens Sjölund, Thomas B. Schön</author><pubDate>Mon, 15 Apr 2024 13:34:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09732v1</guid></item><item><title>Convergence Analysis of Probability Flow ODE for Score-based Generative Models</title><link>http://arxiv.org/abs/2404.09730v1</link><description>Score-based generative models have emerged as a powerful approach forsampling high-dimensional probability distributions. Despite theireffectiveness, their theoretical underpinnings remain relativelyunderdeveloped. In this work, we study the convergence properties ofdeterministic samplers based on probability flow ODEs from both theoretical andnumerical perspectives. Assuming access to $L^2$-accurate estimates of thescore function, we prove the total variation between the target and thegenerated data distributions can be bounded above by$\mathcal{O}(d\sqrt{\delta})$ in the continuous time level, where $d$ denotesthe data dimension and $\delta$ represents the $L^2$-score matching error. Forpractical implementations using a $p$-th order Runge-Kutta integrator with stepsize $h$, we establish error bounds of $\mathcal{O}(d(\sqrt{\delta} + (dh)^p))$at the discrete level. Finally, we present numerical studies on problems up to$128$ dimensions to verify our theory, which indicate a better score matchingerror and dimension dependence.</description><author>Daniel Zhengyu Huang, Jiaoyang Huang, Zhengjiang Lin</author><pubDate>Mon, 15 Apr 2024 13:29:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09730v1</guid></item><item><title>Amplitude-Phase Fusion for Enhanced Electrocardiogram Morphological Analysis</title><link>http://arxiv.org/abs/2404.09729v1</link><description>Considering the variability of amplitude and phase patterns inelectrocardiogram (ECG) signals due to cardiac activity and individualdifferences, existing entropy-based studies have not fully utilized these twopatterns and lack integration. To address this gap, this paper proposes a novelfusion entropy metric, morphological ECG entropy (MEE) for the first time,specifically designed for ECG morphology, to comprehensively describe thefusion of amplitude and phase patterns. MEE is computed based on beat-levelsamples, enabling detailed analysis of each cardiac cycle. Experimental resultsdemonstrate that MEE achieves rapid, accurate, and label-free localization ofabnormal ECG arrhythmia regions. Furthermore, MEE provides a method forassessing sample diversity, facilitating compression of imbalanced trainingsets (via representative sample selection), and outperforms random pruning.Additionally, MEE exhibits the ability to describe areas of poor quality. Bydiscussing, it proves the robustness of MEE value calculation to noiseinterference and its low computational complexity. Finally, we integrate thismethod into a clinical interactive interface to provide a more convenient andintuitive user experience. These findings indicate that MEE serves as avaluable clinical descriptor for ECG characterization. The implementation codecan be referenced at the following link:https://github.com/fdu-harry/ECG-MEE-metric.</description><author>Shuaicong Hu, Yanan Wang, Jian Liu, Jingyu Lin, Shengmei Qin, Zhenning Nie, Zhifeng Yao, Wenjie Cai, Cuiwei Yang</author><pubDate>Mon, 15 Apr 2024 13:29:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09729v1</guid></item><item><title>Sparse Global Matching for Video Frame Interpolation with Large Motion</title><link>http://arxiv.org/abs/2404.06913v2</link><description>Large motion poses a critical challenge in Video Frame Interpolation (VFI)task. Existing methods are often constrained by limited receptive fields,resulting in sub-optimal performance when handling scenarios with large motion.In this paper, we introduce a new pipeline for VFI, which can effectivelyintegrate global-level information to alleviate issues associated with largemotion. Specifically, we first estimate a pair of initial intermediate flowsusing a high-resolution feature map for extracting local details. Then, weincorporate a sparse global matching branch to compensate for flow estimation,which consists of identifying flaws in initial flows and generating sparse flowcompensation with a global receptive field. Finally, we adaptively merge theinitial flow estimation with global flow compensation, yielding a more accurateintermediate flow. To evaluate the effectiveness of our method in handlinglarge motion, we carefully curate a more challenging subset from commonly usedbenchmarks. Our method demonstrates the state-of-the-art performance on theseVFI subsets with large motion.</description><author>Chunxu Liu, Guozhen Zhang, Rui Zhao, Limin Wang</author><pubDate>Mon, 15 Apr 2024 13:27:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06913v2</guid></item><item><title>RoHM: Robust Human Motion Reconstruction via Diffusion</title><link>http://arxiv.org/abs/2401.08570v2</link><description>We propose RoHM, an approach for robust 3D human motion reconstruction frommonocular RGB(-D) videos in the presence of noise and occlusions. Most previousapproaches either train neural networks to directly regress motion in 3D orlearn data-driven motion priors and combine them with optimization at testtime. The former do not recover globally coherent motion and fail underocclusions; the latter are time-consuming, prone to local minima, and requiremanual tuning. To overcome these shortcomings, we exploit the iterative,denoising nature of diffusion models. RoHM is a novel diffusion-based motionmodel that, conditioned on noisy and occluded input data, reconstructscomplete, plausible motions in consistent global coordinates. Given thecomplexity of the problem -- requiring one to address different tasks(denoising and infilling) in different solution spaces (local and globalmotion) -- we decompose it into two sub-tasks and learn two models, one forglobal trajectory and one for local motion. To capture the correlations betweenthe two, we then introduce a novel conditioning module, combining it with aniterative inference scheme. We apply RoHM to a variety of tasks -- from motionreconstruction and denoising to spatial and temporal infilling. Extensiveexperiments on three popular datasets show that our method outperformsstate-of-the-art approaches qualitatively and quantitatively, while beingfaster at test time. The code is available athttps://sanweiliti.github.io/ROHM/ROHM.html.</description><author>Siwei Zhang, Bharat Lal Bhatnagar, Yuanlu Xu, Alexander Winkler, Petr Kadlecek, Siyu Tang, Federica Bogo</author><pubDate>Mon, 15 Apr 2024 13:27:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08570v2</guid></item><item><title>VFLGAN: Vertical Federated Learning-based Generative Adversarial Network for Vertically Partitioned Data Publication</title><link>http://arxiv.org/abs/2404.09722v1</link><description>In the current artificial intelligence (AI) era, the scale and quality of thedataset play a crucial role in training a high-quality AI model. However, gooddata is not a free lunch and is always hard to access due to privacyregulations like the General Data Protection Regulation (GDPR). A potentialsolution is to release a synthetic dataset with a similar distribution to thatof the private dataset. Nevertheless, in some scenarios, it has been found thatthe attributes needed to train an AI model belong to different parties, andthey cannot share the raw data for synthetic data publication due to privacyregulations. In PETS 2023, Xue et al. proposed the first generative adversarynetwork-based model, VertiGAN, for vertically partitioned data publication.However, after thoroughly investigating, we found that VertiGAN is lesseffective in preserving the correlation among the attributes of differentparties. This article proposes a Vertical Federated Learning-based GenerativeAdversarial Network, VFLGAN, for vertically partitioned data publication toaddress the above issues. Our experimental results show that compared withVertiGAN, VFLGAN significantly improves the quality of synthetic data. Takingthe MNIST dataset as an example, the quality of the synthetic dataset generatedby VFLGAN is 3.2 times better than that generated by VertiGAN w.r.t. theFr\'echet Distance. We also designed a more efficient and effective Gaussianmechanism for the proposed VFLGAN to provide the synthetic dataset with adifferential privacy guarantee. On the other hand, differential privacy onlygives the upper bound of the worst-case privacy guarantee. This article alsoproposes a practical auditing scheme that applies membership inference attacksto estimate privacy leakage through the synthetic dataset.</description><author>Xun Yuan, Yang Yang, Prosanta Gope, Aryan Pasikhani, Biplab Sikdar</author><pubDate>Mon, 15 Apr 2024 13:25:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09722v1</guid></item><item><title>Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model</title><link>http://arxiv.org/abs/2404.09717v1</link><description>Many recent studies endeavor to improve open-source language models throughimitation learning, and re-training on the synthetic instruction data fromstate-of-the-art proprietary models like ChatGPT and GPT-4. However, the innatenature of synthetic data inherently contains noisy data, giving rise to asubstantial presence of low-quality data replete with erroneous responses, andflawed reasoning. Although we intuitively grasp the potential harm of noisydata, we lack a quantitative understanding of its impact. To this end, thispaper explores the correlation between the degree of noise and its impact onlanguage models through instruction tuning. We first introduce theFalsity-Controllable (FACO) dataset, which comprises pairs of true answers withcorresponding reasoning, as well as false pairs to manually control the falsityratio of the dataset.Through our extensive experiments, we found multipleintriguing findings of the correlation between the factuality of the datasetand instruction tuning: Specifically, we verified falsity of the instruction ishighly relevant to various benchmark scores. Moreover, when LLMs are trainedwith false instructions, they learn to lie and generate fake unfaithfulanswers, even though they know the correct answer for the user request.Additionally, we noted that once the language model is trained with a datasetcontaminated by noise, restoring its original performance is possible, but itfailed to reach full performance.</description><author>Hyunsoo Cho</author><pubDate>Mon, 15 Apr 2024 13:20:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09717v1</guid></item><item><title>Higher Replay Ratio Empowers Sample-Efficient Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2404.09715v1</link><description>One of the notorious issues for Reinforcement Learning (RL) is poor sampleefficiency. Compared to single agent RL, the sample efficiency for Multi-AgentReinforcement Learning (MARL) is more challenging because of its inherentpartial observability, non-stationary training, and enormous strategy space.Although much effort has been devoted to developing new methods and enhancingsample efficiency, we look at the widely used episodic training mechanism. Ineach training step, tens of frames are collected, but only one gradient step ismade. We argue that this episodic training could be a source of poor sampleefficiency. To better exploit the data already collected, we propose toincrease the frequency of the gradient updates per environment interaction(a.k.a. Replay Ratio or Update-To-Data ratio). To show its generality, weevaluate $3$ MARL methods on $6$ SMAC tasks. The empirical results validatethat a higher replay ratio significantly improves the sample efficiency forMARL algorithms. The codes to reimplement the results presented in this paperare open-sourced at https://anonymous.4open.science/r/rr_for_MARL-0D83/.</description><author>Linjie Xu, Zichuan Liu, Alexander Dockhorn, Diego Perez-Liebana, Jinyu Wang, Lei Song, Jiang Bian</author><pubDate>Mon, 15 Apr 2024 13:18:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09715v1</guid></item><item><title>Image-based Deep Learning for the time-dependent prediction of fresh concrete properties</title><link>http://arxiv.org/abs/2402.06611v2</link><description>Increasing the degree of digitisation and automation in the concreteproduction process can play a crucial role in reducing the CO$_2$ emissionsthat are associated with the production of concrete. In this paper, a method ispresented that makes it possible to predict the properties of fresh concreteduring the mixing process based on stereoscopic image sequences of theconcretes flow behaviour. A Convolutional Neural Network (CNN) is used for theprediction, which receives the images supported by information on the mixdesign as input. In addition, the network receives temporal information in theform of the time difference between the time at which the images are taken andthe time at which the reference values of the concretes are carried out. Withthis temporal information, the network implicitly learns the time-dependentbehaviour of the concretes properties. The network predicts the slump flowdiameter, the yield stress and the plastic viscosity. The time-dependentprediction potentially opens up the pathway to determine the temporaldevelopment of the fresh concrete properties already during mixing. Thisprovides a huge advantage for the concrete industry. As a result,countermeasures can be taken in a timely manner. It is shown that an approachbased on depth and optical flow images, supported by information of the mixdesign, achieves the best results.</description><author>Max Meyer, Amadeus Langer, Max Mehltretter, Dries Beyer, Max Coenen, Tobias Schack, Michael Haist, Christian Heipke</author><pubDate>Mon, 15 Apr 2024 13:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06611v2</guid></item><item><title>Psychometric Predictive Power of Large Language Models</title><link>http://arxiv.org/abs/2311.07484v3</link><description>Instruction tuning aligns the response of large language models (LLMs) withhuman preferences. Despite such efforts in human--LLM alignment, we find thatinstruction tuning does not always make LLMs human-like from a cognitivemodeling perspective. More specifically, next-word probabilities estimated byinstruction-tuned LLMs are often worse at simulating human reading behaviorthan those estimated by base LLMs. In addition, we explore promptingmethodologies for simulating human reading behavior with LLMs. Our results showthat prompts reflecting a particular linguistic hypothesis improve psychometricpredictive power, but are still inferior to small base models. These findingshighlight that recent advancements in LLMs, i.e., instruction tuning andprompting, do not offer better estimates than direct probability measurementsfrom base LLMs in cognitive modeling. In other words, pure next-wordprobability remains a strong predictor for human reading behavior, even in theage of LLMs.</description><author>Tatsuki Kuribayashi, Yohei Oseki, Timothy Baldwin</author><pubDate>Mon, 15 Apr 2024 13:12:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07484v3</guid></item><item><title>Scenario-Adaptive Fine-Grained Personalization Network: Tailoring User Behavior Representation to the Scenario Context</title><link>http://arxiv.org/abs/2404.09709v1</link><description>Existing methods often adjust representations adaptively only afteraggregating user behavior sequences. This coarse-grained approach tore-weighting the entire user sequence hampers the model's ability to accuratelymodel the user interest migration across different scenarios. To enhance themodel's capacity to capture user interests from historical behavior sequencesin each scenario, we develop a ranking framework named the Scenario-AdaptiveFine-Grained Personalization Network (SFPNet), which designs a kind offine-grained method for multi-scenario personalized recommendations.Specifically, SFPNet comprises a series of blocks named as Scenario-TailoringBlock, stacked sequentially. Each block initially deploys a parameterpersonalization unit to integrate scenario information at a coarse-grainedlevel by redefining fundamental features. Subsequently, we consolidatescenario-adaptively adjusted feature representations to serve as contextinformation. By employing residual connection, we incorporate this context intothe representation of each historical behavior, allowing for context-awarefine-grained customization of the behavior representations at thescenario-level, which in turn supports scenario-aware user interest modeling.</description><author>Moyu Zhang, Yongxiang Tang, Jinxin Hu, Yu Zhang</author><pubDate>Mon, 15 Apr 2024 13:08:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09709v1</guid></item><item><title>Human vs. LMMs: Exploring the Discrepancy in Emoji Interpretation and Usage in Digital Communication</title><link>http://arxiv.org/abs/2401.08212v2</link><description>Leveraging Large Multimodal Models (LMMs) to simulate human behaviors whenprocessing multimodal information, especially in the context of social media,has garnered immense interest due to its broad potential and far-reachingimplications. Emojis, as one of the most unique aspects of digitalcommunication, are pivotal in enriching and often clarifying the emotional andtonal dimensions. Yet, there is a notable gap in understanding how theseadvanced models, such as GPT-4V, interpret and employ emojis in the nuancedcontext of online interaction. This study intends to bridge this gap byexamining the behavior of GPT-4V in replicating human-like use of emojis. Thefindings reveal a discernible discrepancy between human and GPT-4V behaviors,likely due to the subjective nature of human interpretation and the limitationsof GPT-4V's English-centric training, suggesting cultural biases and inadequaterepresentation of non-English cultures.</description><author>Hanjia Lyu, Weihong Qi, Zhongyu Wei, Jiebo Luo</author><pubDate>Mon, 15 Apr 2024 13:08:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08212v2</guid></item><item><title>Kernel-based learning with guarantees for multi-agent applications</title><link>http://arxiv.org/abs/2404.09708v1</link><description>This paper addresses a kernel-based learning problem for a network of agentslocally observing a latent multidimensional, nonlinear phenomenon in a noisyenvironment. We propose a learning algorithm that requires only mild a prioriknowledge about the phenomenon under investigation and delivers a model withcorresponding non-asymptotic high probability error bounds. Both non-asymptoticanalysis of the method and numerical simulation results are presented anddiscussed in the paper.</description><author>Krzysztof Kowalczyk, Paweł Wachel, Cristian R. Rojas</author><pubDate>Mon, 15 Apr 2024 13:06:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09708v1</guid></item><item><title>Adaptive Patching for High-resolution Image Segmentation with Transformers</title><link>http://arxiv.org/abs/2404.09707v1</link><description>Attention-based models are proliferating in the space of image analytics,including segmentation. The standard method of feeding images to transformerencoders is to divide the images into patches and then feed the patches to themodel as a linear sequence of tokens. For high-resolution images, e.g.microscopic pathology images, the quadratic compute and memory cost prohibitsthe use of an attention-based model, if we are to use smaller patch sizes thatare favorable in segmentation. The solution is to either use custom complexmulti-resolution models or approximate attention schemes. We take inspirationfrom Adapative Mesh Refinement (AMR) methods in HPC by adaptively patching theimages, as a pre-processing step, based on the image details to reduce thenumber of patches being fed to the model, by orders of magnitude. This methodhas a negligible overhead, and works seamlessly with any attention-based model,i.e. it is a pre-processing step that can be adopted by any attention-basedmodel without friction. We demonstrate superior segmentation quality over SoTAsegmentation models for real-world pathology datasets while gaining a geomeanspeedup of $6.9\times$ for resolutions up to $64K^2$, on up to $2,048$ GPUs.</description><author>Enzhi Zhang, Isaac Lyngaas, Peng Chen, Xiao Wang, Jun Igarashi, Yuankai Huo, Mohamed Wahib, Masaharu Munetomo</author><pubDate>Mon, 15 Apr 2024 13:06:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09707v1</guid></item><item><title>AI Competitions and Benchmarks: Dataset Development</title><link>http://arxiv.org/abs/2404.09703v1</link><description>Machine learning is now used in many applications thanks to its ability topredict, generate, or discover patterns from large quantities of data. However,the process of collecting and transforming data for practical use is intricate.Even in today's digital era, where substantial data is generated daily, it isuncommon for it to be readily usable; most often, it necessitates meticulousmanual data preparation. The haste in developing new models can frequentlyresult in various shortcomings, potentially posing risks when deployed inreal-world scenarios (eg social discrimination, critical failures), leading tothe failure or substantial escalation of costs in AI-based projects. Thischapter provides a comprehensive overview of established methodological tools,enriched by our practical experience, in the development of datasets formachine learning. Initially, we develop the tasks involved in datasetdevelopment and offer insights into their effective management (includingrequirements, design, implementation, evaluation, distribution, andmaintenance). Then, we provide more details about the implementation processwhich includes data collection, transformation, and quality evaluation.Finally, we address practical considerations regarding dataset distribution andmaintenance.</description><author>Romain Egele, Julio C. S. Jacques Junior, Jan N. van Rijn, Isabelle Guyon, Xavier Baró, Albert Clapés, Prasanna Balaprakash, Sergio Escalera, Thomas Moeslund, Jun Wan</author><pubDate>Mon, 15 Apr 2024 13:01:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09703v1</guid></item><item><title>HSIDMamba: Exploring Bidirectional State-Space Models for Hyperspectral Denoising</title><link>http://arxiv.org/abs/2404.09697v1</link><description>Effectively discerning spatial-spectral dependencies in HSI denoising iscrucial, but prevailing methods using convolution or transformers still facecomputational efficiency limitations. Recently, the emerging Selective StateSpace Model(Mamba) has risen with its nearly linear computational complexity inprocessing natural language sequences, which inspired us to explore itspotential in handling long spectral sequences. In this paper, we proposeHSIDMamba(HSDM), tailored to exploit the linear complexity for effectivelycapturing spatial-spectral dependencies in HSI denoising. In particular, HSDMcomprises multiple Hyperspectral Continuous Scan Blocks, incorporatingBCSM(Bidirectional Continuous Scanning Mechanism), scale residual, and spectralattention mechanisms to enhance the capture of long-range and localspatial-spectral information. BCSM strengthens spatial-spectral interactions bylinking forward and backward scans and enhancing information from eightdirections through SSM, significantly enhancing the perceptual capability ofHSDM and improving denoising performance more effectively. Extensiveevaluations against HSI denoising benchmarks validate the superior performanceof HSDM, achieving state-of-the-art results in performance and surpassing theefficiency of the latest transformer architectures by $30\%$.</description><author>Yang Liu, Jiahua Xiao, Yu Guo, Peilin Jiang, Haiwei Yang, Fei Wang</author><pubDate>Mon, 15 Apr 2024 12:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09697v1</guid></item><item><title>Are Large Language Models Reliable Argument Quality Annotators?</title><link>http://arxiv.org/abs/2404.09696v1</link><description>Evaluating the quality of arguments is a crucial aspect of any systemleveraging argument mining. However, it is a challenge to obtain reliable andconsistent annotations regarding argument quality, as this usually requiresdomain-specific expertise of the annotators. Even among experts, the assessmentof argument quality is often inconsistent due to the inherent subjectivity ofthis task. In this paper, we study the potential of using state-of-the-artlarge language models (LLMs) as proxies for argument quality annotators. Toassess the capability of LLMs in this regard, we analyze the agreement betweenmodel, human expert, and human novice annotators based on an establishedtaxonomy of argument quality dimensions. Our findings highlight that LLMs canproduce consistent annotations, with a moderately high agreement with humanexperts across most of the quality dimensions. Moreover, we show that usingLLMs as additional annotators can significantly improve the agreement betweenannotators. These results suggest that LLMs can serve as a valuable tool forautomated argument quality assessment, thus streamlining and accelerating theevaluation of large argument datasets.</description><author>Nailia Mirzakhmedova, Marcel Gohsen, Chia Hao Chang, Benno Stein</author><pubDate>Mon, 15 Apr 2024 12:54:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09696v1</guid></item><item><title>LoRAP: Transformer Sub-Layers Deserve Differentiated Structured Compression for Large Language Models</title><link>http://arxiv.org/abs/2404.09695v1</link><description>Large language models (LLMs) show excellent performance in difficult tasks,but they often require massive memories and computational resources. How toreduce the parameter scale of LLMs has become research hotspots. In this study,we make an important observation that the multi-head self-attention (MHA)sub-layer of Transformer exhibits noticeable low-rank structure, while thefeed-forward network (FFN) sub-layer does not. With this regard, we design amixed compression model, which organically combines Low-Rank matrixapproximation And structured Pruning (LoRAP). For the MHA sub-layer, we proposean input activation weighted singular value decomposition method to strengthenthe low-rank characteristic. Furthermore, we discover that the weight matricesin MHA sub-layer have different low-rank degrees. Thus, a novel parameterallocation scheme according to the discrepancy of low-rank degrees is devised.For the FFN sub-layer, we propose a gradient-free structured channel pruningmethod. During the pruning, we get an interesting finding that the leastimportant 1% of parameter actually play a vital role in model performance.Extensive evaluations on zero-shot perplexity and zero-shot task classificationindicate that our proposal is superior to previous structured compressionrivals under multiple compression ratios.</description><author>Guangyan Li, Yongqiang Tang, Wensheng Zhang</author><pubDate>Mon, 15 Apr 2024 12:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09695v1</guid></item><item><title>New methods for drug synergy prediction: a mini-review</title><link>http://arxiv.org/abs/2404.02484v2</link><description>In this mini-review, we explore the new prediction methods for drugcombination synergy relying on high-throughput combinatorial screens. The fastprogress of the field is witnessed in the more than thirty original machinelearning methods published since 2021, a clear majority of them based on deeplearning techniques. We aim to put these papers under a unifying lens byhighlighting the core technologies, the data sources, the input data types andsynergy scores used in the methods, as well as the prediction scenarios andevaluation protocols that the papers deal with. Our finding is that the bestmethods accurately solve the synergy prediction scenarios involving known drugsor cell lines while the scenarios involving new drugs or cell lines still fallshort of an accurate prediction level.</description><author>Fatemeh Abbasi, Juho Rousu</author><pubDate>Mon, 15 Apr 2024 12:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02484v2</guid></item><item><title>XoFTR: Cross-modal Feature Matching Transformer</title><link>http://arxiv.org/abs/2404.09692v1</link><description>We introduce, XoFTR, a cross-modal cross-view method for local featurematching between thermal infrared (TIR) and visible images. Unlike visibleimages, TIR images are less susceptible to adverse lighting and weatherconditions but present difficulties in matching due to significant texture andintensity differences. Current hand-crafted and learning-based methods forvisible-TIR matching fall short in handling viewpoint, scale, and texturediversities. To address this, XoFTR incorporates masked image modelingpre-training and fine-tuning with pseudo-thermal image augmentation to handlethe modality differences. Additionally, we introduce a refined matchingpipeline that adjusts for scale discrepancies and enhances match reliabilitythrough sub-pixel level refinement. To validate our approach, we collect acomprehensive visible-thermal dataset, and show that our method outperformsexisting methods on many benchmarks.</description><author>Önder Tuzcuoğlu, Aybora Köksal, Buğra Sofu, Sinan Kalkan, A. Aydın Alatan</author><pubDate>Mon, 15 Apr 2024 12:46:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09692v1</guid></item><item><title>Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration</title><link>http://arxiv.org/abs/2404.09690v1</link><description>The emergence of Large Multimodal Models (LMMs) marks a significant milestonein the development of artificial intelligence. Insurance, as a vast and complexdiscipline, involves a wide variety of data forms in its operational processes,including text, images, and videos, thereby giving rise to diverse multimodaltasks. Despite this, there has been limited systematic exploration ofmultimodal tasks specific to insurance, nor a thorough investigation into howLMMs can address these challenges. In this paper, we explore GPT-4V'scapabilities in the insurance domain. We categorize multimodal tasks byfocusing primarily on visual aspects based on types of insurance (e.g., auto,household/commercial property, health, and agricultural insurance) andinsurance stages (e.g., risk assessment, risk monitoring, and claimsprocessing). Our experiment reveals that GPT-4V exhibits remarkable abilitiesin insurance-related tasks, demonstrating not only a robust understanding ofmultimodal content in the insurance domain but also a comprehensive knowledgeof insurance scenarios. However, there are notable shortcomings: GPT-4Vstruggles with detailed risk rating and loss assessment, suffers fromhallucination in image understanding, and shows variable support for differentlanguages. Through this work, we aim to bridge the insurance domain withcutting-edge LMM technology, facilitate interdisciplinary exchange anddevelopment, and provide a foundation for the continued advancement andevolution of future research endeavors.</description><author>Chenwei Lin, Hanjia Lyu, Jiebo Luo, Xian Xu</author><pubDate>Mon, 15 Apr 2024 12:45:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09690v1</guid></item><item><title>Physics-guided Shape-from-Template: Monocular Video Perception through Neural Surrogate Models</title><link>http://arxiv.org/abs/2311.12796v3</link><description>3D reconstruction of dynamic scenes is a long-standing problem in computergraphics and increasingly difficult the less information is available.Shape-from-Template (SfT) methods aim to reconstruct a template-based geometryfrom RGB images or video sequences, often leveraging just a single monocularcamera without depth information, such as regular smartphone recordings.Unfortunately, existing reconstruction methods are either unphysical and noisyor slow in optimization. To solve this problem, we propose a novel SfTreconstruction algorithm for cloth using a pre-trained neural surrogate modelthat is fast to evaluate, stable, and produces smooth reconstructions due to aregularizing physics simulation. Differentiable rendering of the simulated meshenables pixel-wise comparisons between the reconstruction and a target videosequence that can be used for a gradient-based optimization procedure toextract not only shape information but also physical parameters such asstretching, shearing, or bending stiffness of the cloth. This allows to retaina precise, stable, and smooth reconstructed geometry while reducing the runtimeby a factor of 400-500 compared to $\phi$-SfT, a state-of-the-art physics-basedSfT approach.</description><author>David Stotko, Nils Wandel, Reinhard Klein</author><pubDate>Mon, 15 Apr 2024 12:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12796v3</guid></item><item><title>Plus Strategies are Exponentially Slower for Planted Optima of Random Height</title><link>http://arxiv.org/abs/2404.09687v1</link><description>We compare the $(1,\lambda)$-EA and the $(1 + \lambda)$-EA on the recentlyintroduced benchmark DisOM, which is the OneMax function with randomly plantedlocal optima. Previous work showed that if all local optima have the samerelative height, then the plus strategy never loses more than a factor $O(n\logn)$ compared to the comma strategy. Here we show that even small randomfluctuations in the heights of the local optima have a devastating effect forthe plus strategy and lead to super-polynomial runtimes. On the other hand, dueto their ability to escape local optima, comma strategies are unaffected by theheight of the local optima and remain efficient. Our results hold for a broadclass of possible distortions and show that the plus strategy, but not thecomma strategy, is generally deceived by sparse unstructured fluctuations of asmooth landscape.</description><author>Johannes Lengler, Leon Schiller, Oliver Sieberling</author><pubDate>Mon, 15 Apr 2024 12:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09687v1</guid></item><item><title>AntBatchInfer: Elastic Batch Inference in the Kubernetes Cluster</title><link>http://arxiv.org/abs/2404.09686v1</link><description>Offline batch inference is a common task in the industry for deep learningapplications, but it can be challenging to ensure stability and performancewhen dealing with large amounts of data and complicated inference pipelines.This paper demonstrated AntBatchInfer, an elastic batch inference framework,which is specially optimized for the non-dedicated cluster. AntBatchInferaddresses these challenges by providing multi-level fault-tolerantcapabilities, enabling the stable execution of versatile and long-runninginference tasks. It also improves inference efficiency by pipelining,intra-node, and inter-node scaling. It further optimizes the performance incomplicated multiple-model batch inference scenarios. Through extensiveexperiments and real-world statistics, we demonstrate the superiority of ourframework in terms of stability and efficiency. In the experiment, itoutperforms the baseline by at least $2\times$ and $6\times$ in thesingle-model or multiple-model batch inference. Also, it is widely used at AntGroup, with thousands of daily jobs from various scenarios, including DLRM, CV,and NLP, which proves its practicability in the industry.</description><author>Siyuan Li, Youshao Xiao, Fanzhuang Meng, Lin Ju, Lei Liang, Lin Wang, Jun Zhou</author><pubDate>Mon, 15 Apr 2024 12:37:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09686v1</guid></item><item><title>Post-Training Network Compression for 3D Medical Image Segmentation: Reducing Computational Efforts via Tucker Decomposition</title><link>http://arxiv.org/abs/2404.09683v1</link><description>We address the computational barrier of deploying advanced deep learningsegmentation models in clinical settings by studying the efficacy of networkcompression through tensor decomposition. We propose a post-training Tuckerfactorization that enables the decomposition of pre-existing models to reducecomputational requirements without impeding segmentation accuracy. We appliedTucker decomposition to the convolutional kernels of the TotalSegmentator (TS)model, an nnU-Net model trained on a comprehensive dataset for automaticsegmentation of 117 anatomical structures. Our approach reduced thefloating-point operations (FLOPs) and memory required during inference,offering an adjustable trade-off between computational efficiency andsegmentation quality. This study utilized the publicly available TS dataset,employing various downsampling factors to explore the relationship betweenmodel size, inference speed, and segmentation performance. The application ofTucker decomposition to the TS model substantially reduced the model parametersand FLOPs across various compression rates, with limited loss in segmentationaccuracy. We removed up to 88% of the model's parameters with no significantperformance changes in the majority of classes after fine-tuning. Practicalbenefits varied across different graphics processing unit (GPU) architectures,with more distinct speed-ups on less powerful hardware. Post-hoc networkcompression via Tucker decomposition presents a viable strategy for reducingthe computational demand of medical image segmentation models withoutsubstantially sacrificing accuracy. This approach enables the broader adoptionof advanced deep learning technologies in clinical practice, offering a way tonavigate the constraints of hardware capabilities.</description><author>Tobias Weber, Jakob Dexl, David Rügamer, Michael Ingrisch</author><pubDate>Mon, 15 Apr 2024 12:36:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09683v1</guid></item><item><title>Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation</title><link>http://arxiv.org/abs/2404.09682v1</link><description>The quality of the dataset is crucial for ensuring optimal performance andreliability of downstream task models. However, datasets often contain noisydata inadvertently included during the construction process. Numerous attemptshave been made to correct this issue through human annotators. However, hiringand managing human annotators is expensive and time-consuming. As analternative, recent studies are exploring the use of large language models(LLMs) for data annotation. In this study, we present a case study that extends the application ofLLM-based data annotation to enhance the quality of existing datasets through acleansing strategy. Specifically, we leverage approaches such aschain-of-thought (CoT) and majority voting to imitate human annotation andclassify unrelated documents from the Multi-News dataset, which is widely usedfor the multi-document summarization task. Through our proposed cleansingmethod, we introduce an enhanced Multi-News+. By employing LLMs for datacleansing, we demonstrate an efficient and effective approach to improvingdataset quality without relying on expensive human annotation efforts.</description><author>Juhwan Choi, Jungmin Yun, Kyohoon Jin, YoungBin Kim</author><pubDate>Mon, 15 Apr 2024 12:36:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09682v1</guid></item><item><title>Exploring Non-Regular Extensions of Propositional Dynamic Logic with Description-Logics Features</title><link>http://arxiv.org/abs/2307.09913v4</link><description>We investigate the impact of non-regular path expressions on the decidabilityof satisfiability checking and querying in description logics extending ALC.Our primary objects of interest are ALCreg and ALCvpl, the extensions of withpath expressions employing, respectively, regular and visibly-pushdownlanguages. The first one, ALCreg, is a notational variant of the well-knownPropositional Dynamic Logic of Fischer and Ladner. The second one, ALCvpl, wasintroduced and investigated by Loding and Serre in 2007. The logic ALCvplgeneralises many known decidable non-regular extensions of ALCreg. We provide a series of undecidability results. First, we show thatdecidability of the concept satisfiability problem for ALCvpl is lost uponadding the seemingly innocent Self operator. Second, we establishundecidability for the concept satisfiability problem for ALCvpl extended withnominals. Interestingly, our undecidability proof relies only on one singlenon-regular (visibly-pushdown) language, namely on r#s# := { r^n s^n | n in N }for fixed role names r and s. Finally, in contrast to the classical databasesetting, we establish undecidability of query entailment for queries involvingnon-regular atoms from r#s#, already in the case of ALC-TBoxes.</description><author>Bartosz Bednarczyk</author><pubDate>Mon, 15 Apr 2024 12:32:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09913v4</guid></item><item><title>AntDT: A Self-Adaptive Distributed Training Framework for Leader and Straggler Nodes</title><link>http://arxiv.org/abs/2404.09679v1</link><description>Many distributed training techniques like Parameter Server and AllReduce havebeen proposed to take advantage of the increasingly large data and richfeatures. However, stragglers frequently occur in distributed training due toresource contention and hardware heterogeneity, which significantly hampers thetraining efficiency. Previous works only address part of the stragglers andcould not adaptively solve various stragglers in practice. Additionally, it ischallenging to use a systematic framework to address all stragglers becausedifferent stragglers require diverse data allocation and fault-tolerancemechanisms. Therefore, this paper proposes a unified distributed trainingframework called AntDT (Ant Distributed Training Framework) to adaptively solvethe straggler problems. Firstly, the framework consists of four components,including the Stateful Dynamic Data Sharding service, Monitor, Controller, andAgent. These components work collaboratively to efficiently distributeworkloads and provide a range of pre-defined straggler mitigation methods withfault tolerance, thereby hiding messy details of data allocation and faulthandling. Secondly, the framework provides a high degree of flexibility,allowing for the customization of straggler mitigation solutions based on thespecific circumstances of the cluster. Leveraging this flexibility, weintroduce two straggler mitigation solutions, namely AntDT-ND for non-dedicatedclusters and AntDT-DD for dedicated clusters, as practical examples to resolvevarious types of stragglers at Ant Group. Justified by our comprehensiveexperiments and industrial deployment statistics, AntDT outperforms other SOTAmethods more than 3x in terms of training efficiency. Additionally, in Alipay'shomepage recommendation scenario, using AntDT reduces the training duration ofthe ranking model from 27.8 hours to just 5.4 hours.</description><author>Youshao Xiao, Lin Ju, Zhenglei Zhou, Siyuan Li, Zhaoxin Huan, Dalong Zhang, Rujie Jiang, Lin Wang, Xiaolu Zhang, Lei Liang, Jun Zhou</author><pubDate>Mon, 15 Apr 2024 12:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09679v1</guid></item><item><title>Towards Variable and Coordinated Holistic Co-Speech Motion Generation</title><link>http://arxiv.org/abs/2404.00368v2</link><description>This paper addresses the problem of generating lifelike holistic co-speechmotions for 3D avatars, focusing on two key aspects: variability andcoordination. Variability allows the avatar to exhibit a wide range of motionseven with similar speech content, while coordination ensures a harmoniousalignment among facial expressions, hand gestures, and body poses. We aim toachieve both with ProbTalk, a unified probabilistic framework designed tojointly model facial, hand, and body movements in speech. ProbTalk builds onthe variational autoencoder (VAE) architecture and incorporates three coredesigns. First, we introduce product quantization (PQ) to the VAE, whichenriches the representation of complex holistic motion. Second, we devise anovel non-autoregressive model that embeds 2D positional encoding into theproduct-quantized representation, thereby preserving essential structureinformation of the PQ codes. Last, we employ a secondary stage to refine thepreliminary prediction, further sharpening the high-frequency details. Couplingthese three designs enables ProbTalk to generate natural and diverse holisticco-speech motions, outperforming several state-of-the-art methods inqualitative and quantitative evaluations, particularly in terms of realism. Ourcode and model will be released for research purposes athttps://feifeifeiliu.github.io/probtalk/.</description><author>Yifei Liu, Qiong Cao, Yandong Wen, Huaiguang Jiang, Changxing Ding</author><pubDate>Mon, 15 Apr 2024 12:18:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00368v2</guid></item><item><title>Dancing with Still Images: Video Distillation via Static-Dynamic Disentanglement</title><link>http://arxiv.org/abs/2312.00362v2</link><description>Recently, dataset distillation has paved the way towards efficient machinelearning, especially for image datasets. However, the distillation for videos,characterized by an exclusive temporal dimension, remains an underexploreddomain. In this work, we provide the first systematic study of videodistillation and introduce a taxonomy to categorize temporal compression. Ourinvestigation reveals that the temporal information is usually not well learnedduring distillation, and the temporal dimension of synthetic data contributeslittle. The observations motivate our unified framework of disentangling thedynamic and static information in the videos. It first distills the videos intostill images as static memory and then compensates the dynamic and motioninformation with a learnable dynamic memory block. Our method achievesstate-of-the-art on video datasets at different scales, with a notably smallermemory storage budget. Our code is available athttps://github.com/yuz1wan/video_distillation.</description><author>Ziyu Wang, Yue Xu, Cewu Lu, Yong-Lu Li</author><pubDate>Mon, 15 Apr 2024 12:03:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00362v2</guid></item><item><title>Deformable MRI Sequence Registration for AI-based Prostate Cancer Diagnosis</title><link>http://arxiv.org/abs/2404.09666v1</link><description>The PI-CAI (Prostate Imaging: Cancer AI) challenge led to expert-leveldiagnostic algorithms for clinically significant prostate cancer detection. Thealgorithms receive biparametric MRI scans as input, which consist ofT2-weighted and diffusion-weighted scans. These scans can be misaligned due tomultiple factors in the scanning process. Image registration can alleviate thisissue by predicting the deformation between the sequences. We investigate theeffect of image registration on the diagnostic performance of AI-based prostatecancer diagnosis. First, the image registration algorithm, developed inMeVisLab, is analyzed using a dataset with paired lesion annotations. Second,the effect on diagnosis is evaluated by comparing case-level cancer diagnosisperformance between using the original dataset, rigidly aligneddiffusion-weighted scans, or deformably aligned diffusion-weighted scans. Rigidregistration showed no improvement. Deformable registration demonstrated asubstantial improvement in lesion overlap (+10% median Dice score) and apositive yet non-significant improvement in diagnostic performance (+0.3%AUROC, p=0.18). Our investigation shows that a substantial improvement inlesion alignment does not directly lead to a significant improvement indiagnostic performance. Qualitative analysis indicated that jointly developingimage registration methods and diagnostic AI algorithms could enhancediagnostic accuracy and patient outcomes.</description><author>Alessa Hering, Sarah de Boer, Anindo Saha, Jasper J. Twilt, Derya Yakar, Maarten de Rooij, Henkjan Huisman, Joeran S. Bosma</author><pubDate>Mon, 15 Apr 2024 11:57:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09666v1</guid></item><item><title>CBQ: Cross-Block Quantization for Large Language Models</title><link>http://arxiv.org/abs/2312.07950v4</link><description>Post-training quantization (PTQ) has played a key role in compressing largelanguage models (LLMs) with ultra-low costs. However, existing PTQ methods onlyfocus on handling the outliers within one layer or one block, which ignores thedependency of blocks and leads to severe performance degradation in low-bitsettings. In this paper, we propose CBQ, a cross-block reconstruction-based PTQmethod for LLMs. CBQ employs a cross-block dependency using a homologousreconstruction scheme, establishing long-range dependencies across multipleblocks to minimize error accumulation. Furthermore, CBQ incorporates acoarse-to-fine preprocessing (CFP) strategy for suppressing weight andactivation outliers, coupled with an adaptive LoRA-Rounding technique forprecise weight quantization. These innovations enable CBQ to not only handleextreme outliers effectively but also improve overall quantization accuracy.Extensive experiments show that CBQ achieves superior low-bit quantization(W4A4, W4A8, W2A16) and outperforms existing state-of-the-art methods acrossvarious LLMs and datasets. Notably, CBQ quantizes the 4-bit LLAMA1-65B modelwithin only 4.3 hours on a single GPU, achieving a commendable tradeoff betweenperformance and quantization efficiency.</description><author>Xin Ding, Xiaoyu Liu, Zhijun Tu, Yun Zhang, Wei Li, Jie Hu, Hanting Chen, Yehui Tang, Zhiwei Xiong, Baoqun Yin, Yunhe Wang</author><pubDate>Mon, 15 Apr 2024 11:57:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07950v4</guid></item><item><title>Closing the Gap in the Trade-off between Fair Representations and Accuracy</title><link>http://arxiv.org/abs/2404.09664v1</link><description>The rapid developments of various machine learning models and theirdeployments in several applications has led to discussions around theimportance of looking beyond the accuracies of these models. Fairness of suchmodels is one such aspect that is deservedly gaining more attention. In thiswork, we analyse the natural language representations of documents andsentences (i.e., encodings) for any embedding-level bias that could potentiallyalso affect the fairness of the downstream tasks that rely on them. We identifybias in these encodings either towards or against different sub-groups based onthe difference in their reconstruction errors along various subsets ofprincipal components. We explore and recommend ways to mitigate such bias inthe encodings while also maintaining a decent accuracy in classification modelsthat use them.</description><author>Biswajit Rout, Ananya B. Sai, Arun Rajkumar</author><pubDate>Mon, 15 Apr 2024 11:54:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09664v1</guid></item><item><title>A Survey of Neural Network Robustness Assessment in Image Recognition</title><link>http://arxiv.org/abs/2404.08285v2</link><description>In recent years, there has been significant attention given to the robustnessassessment of neural networks. Robustness plays a critical role in ensuringreliable operation of artificial intelligence (AI) systems in complex anduncertain environments. Deep learning's robustness problem is particularlysignificant, highlighted by the discovery of adversarial attacks on imageclassification models. Researchers have dedicated efforts to evaluaterobustness in diverse perturbation conditions for image recognition tasks.Robustness assessment encompasses two main techniques: robustness verification/certification for deliberate adversarial attacks and robustness testing forrandom data corruptions. In this survey, we present a detailed examination ofboth adversarial robustness (AR) and corruption robustness (CR) in neuralnetwork assessment. Analyzing current research papers and standards, we providean extensive overview of robustness assessment in image recognition. Threeessential aspects are analyzed: concepts, metrics, and assessment methods. Weinvestigate the perturbation metrics and range representations used to measurethe degree of perturbations on images, as well as the robustness metricsspecifically for the robustness conditions of classification models. Thestrengths and limitations of the existing methods are also discussed, and somepotential directions for future research are provided.</description><author>Jie Wang, Jun Ai, Minyan Lu, Haoran Su, Dan Yu, Yutao Zhang, Junda Zhu, Jingyu Liu</author><pubDate>Mon, 15 Apr 2024 11:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08285v2</guid></item><item><title>Sampling for Model Predictive Trajectory Planning in Autonomous Driving using Normalizing Flows</title><link>http://arxiv.org/abs/2404.09657v1</link><description>Alongside optimization-based planners, sampling-based approaches are oftenused in trajectory planning for autonomous driving due to their simplicity.Model predictive path integral control is a framework that builds uponoptimization principles while incorporating stochastic sampling of inputtrajectories. This paper investigates several sampling approaches fortrajectory generation. In this context, normalizing flows originating from thefield of variational inference are considered for the generation of samplingdistributions, as they model transformations of simple to more complexdistributions. Accordingly, learning-based normalizing flow models are trainedfor a more efficient exploration of the input domain for the task at hand. Thedeveloped algorithm and the proposed sampling distributions are evaluated intwo simulation scenarios.</description><author>Georg Rabenstein, Lars Ullrich, Knut Graichen</author><pubDate>Mon, 15 Apr 2024 11:45:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09657v1</guid></item><item><title>Learn Your Reference Model for Real Good Alignment</title><link>http://arxiv.org/abs/2404.09656v1</link><description>The complexity of the alignment problem stems from the fact that existingmethods are unstable. Researchers continuously invent various tricks to addressthis shortcoming. For instance, in the fundamental Reinforcement Learning FromHuman Feedback (RLHF) technique of Language Model alignment, in addition toreward maximization, the Kullback-Leibler divergence between the trainablepolicy and the SFT policy is minimized. This addition prevents the model frombeing overfitted to the Reward Model (RM) and generating texts that areout-of-domain for the RM. The Direct Preference Optimization (DPO) methodreformulates the optimization task of RLHF and eliminates the Reward Modelwhile tacitly maintaining the requirement for the policy to be close to the SFTpolicy. In our paper, we argue that this implicit limitation in the DPO methodleads to sub-optimal results. We propose a new method called Trust Region DPO(TR-DPO), which updates the reference policy during training. With such astraightforward update, we demonstrate the effectiveness of TR-DPO against DPOon the Anthropic HH and TLDR datasets. We show that TR-DPO outperforms DPO byup to 19%, measured by automatic evaluation with GPT-4. The new alignmentapproach that we propose allows us to improve the quality of models acrossseveral parameters at once, such as coherence, correctness, level of detail,helpfulness, and harmlessness.</description><author>Alexey Gorbatovski, Boris Shaposhnikov, Alexey Malakhov, Nikita Surnachev, Yaroslav Aksenov, Ian Maksimov, Nikita Balagansky, Daniil Gavrilov</author><pubDate>Mon, 15 Apr 2024 11:44:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09656v1</guid></item><item><title>Do LLMs Understand Visual Anomalies? Uncovering LLM Capabilities in Zero-shot Anomaly Detection</title><link>http://arxiv.org/abs/2404.09654v1</link><description>Large vision-language models (LVLMs) are markedly proficient in derivingvisual representations guided by natural language. Recent explorations haveutilized LVLMs to tackle zero-shot visual anomaly detection (VAD) challenges bypairing images with textual descriptions indicative of normal and abnormalconditions, referred to as anomaly prompts. However, existing approaches dependon static anomaly prompts that are prone to cross-semantic ambiguity, andprioritize global image-level representations over crucial local pixel-levelimage-to-text alignment that is necessary for accurate anomaly localization. Inthis paper, we present ALFA, a training-free approach designed to address thesechallenges via a unified model. We propose a run-time prompt adaptationstrategy, which first generates informative anomaly prompts to leverage thecapabilities of a large language model (LLM). This strategy is enhanced by acontextual scoring mechanism for per-image anomaly prompt adaptation andcross-semantic ambiguity mitigation. We further introduce a novel fine-grainedaligner to fuse local pixel-level semantics for precise anomaly localization,by projecting the image-text alignment from global to local semantic spaces.Extensive evaluations on the challenging MVTec and VisA datasets confirm ALFA'seffectiveness in harnessing the language potential for zero-shot VAD, achievingsignificant PRO improvements of 12.1% on MVTec AD and 8.9% on VisA compared tostate-of-the-art zero-shot VAD approaches.</description><author>Jiaqi Zhu, Shaofeng Cai, Fang Deng, Junran Wu</author><pubDate>Mon, 15 Apr 2024 11:42:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09654v1</guid></item><item><title>Monitoring Second-Order Hyperproperties</title><link>http://arxiv.org/abs/2404.09652v1</link><description>Hyperproperties express the relationship between multiple executions of asystem. This is needed in many AI-related fields, such as knowledgerepresentation and planning, to capture system properties related to knowledge,information flow, and privacy. In this paper, we study the monitoring ofcomplex hyperproperties at runtime. Previous work in this area has eitherfocused on the simpler problem of monitoring trace properties (which are setsof traces, while hyperproperties are sets of sets of traces) or on monitoringfirst-order hyperproperties, which are expressible in temporal logics withfirst-order quantification over traces, such as HyperLTL. We present the firstmonitoring algorithm for the much more expressive class of second-orderhyperproperties. Second-order hyperproperties include system properties likecommon knowledge, which cannot be expressed in first-order logics likeHyperLTL. We introduce Hyper$^2$LTL$_f$, a temporal logic over finite traces thatallows for second-order quantification over sets of traces. We study themonitoring problem in two fundamental execution models: (1) the parallel model,where a fixed number of traces is monitored in parallel, and (2) the sequentialmodel, where an unbounded number of traces is observed sequentially, one traceafter the other. For the parallel model, we show that the monitoring of thesecond-order hyperproperties of Hyper$^2$LTL$_f$ can be reduced to monitoringfirst-order hyperproperties. For the sequential model, we present a monitoringalgorithm that handles second-order quantification efficiently, exploitingoptimizations based on the monotonicity of subformulas, graph-based storing ofexecutions, and fixpoint hashing. We present experimental results from a rangeof benchmarks, including examples from common knowledge and planning.</description><author>Raven Beutner, Bernd Finkbeiner, Hadar Frenkel, Niklas Metzger</author><pubDate>Mon, 15 Apr 2024 11:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09652v1</guid></item><item><title>SyncDreamer: Generating Multiview-consistent Images from a Single-view Image</title><link>http://arxiv.org/abs/2309.03453v2</link><description>In this paper, we present a novel diffusion model called that generatesmultiview-consistent images from a single-view image. Using pretrainedlarge-scale 2D diffusion models, recent work Zero123 demonstrates the abilityto generate plausible novel views from a single-view image of an object.However, maintaining consistency in geometry and colors for the generatedimages remains a challenge. To address this issue, we propose a synchronizedmultiview diffusion model that models the joint probability distribution ofmultiview images, enabling the generation of multiview-consistent images in asingle reverse process. SyncDreamer synchronizes the intermediate states of allthe generated images at every step of the reverse process through a 3D-awarefeature attention mechanism that correlates the corresponding features acrossdifferent views. Experiments show that SyncDreamer generates images with highconsistency across different views, thus making it well-suited for various 3Dgeneration tasks such as novel-view-synthesis, text-to-3D, and image-to-3D.</description><author>Yuan Liu, Cheng Lin, Zijiao Zeng, Xiaoxiao Long, Lingjie Liu, Taku Komura, Wenping Wang</author><pubDate>Mon, 15 Apr 2024 11:28:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03453v2</guid></item><item><title>Real-world Instance-specific Image Goal Navigation for Service Robots: Bridging the Domain Gap with Contrastive Learning</title><link>http://arxiv.org/abs/2404.09645v1</link><description>Improving instance-specific image goal navigation (InstanceImageNav), whichlocates the identical object in a real-world environment from a query image, isessential for robotic systems to assist users in finding desired objects. Thechallenge lies in the domain gap between low-quality images observed by themoving robot, characterized by motion blur and low-resolution, and high-qualityquery images provided by the user. Such domain gaps could significantly reducethe task success rate but have not been the focus of previous work. To addressthis, we propose a novel method called Few-shot Cross-quality Instance-awareAdaptation (CrossIA), which employs contrastive learning with an instanceclassifier to align features between massive low- and few high-quality images.This approach effectively reduces the domain gap by bringing the latentrepresentations of cross-quality images closer on an instance basis.Additionally, the system integrates an object image collection with apre-trained deblurring model to enhance the observed image quality. Our methodfine-tunes the SimSiam model, pre-trained on ImageNet, using CrossIA. Weevaluated our method's effectiveness through an InstanceImageNav task with 20different types of instances, where the robot identifies the same instance in areal-world environment as a high-quality query image. Our experiments showedthat our method improves the task success rate by up to three times compared tothe baseline, a conventional approach based on SuperGlue. These findingshighlight the potential of leveraging contrastive learning and imageenhancement techniques to bridge the domain gap and improve object localizationin robotic applications. The project website ishttps://emergentsystemlabstudent.github.io/DomainBridgingNav/.</description><author>Taichi Sakaguchi, Akira Taniguchi, Yoshinobu Hagiwara, Lotfi El Hafi, Shoichi Hasegawa, Tadahiro Taniguchi</author><pubDate>Mon, 15 Apr 2024 11:24:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09645v1</guid></item><item><title>CREST: Cross-modal Resonance through Evidential Deep Learning for Enhanced Zero-Shot Learning</title><link>http://arxiv.org/abs/2404.09640v1</link><description>Zero-shot learning (ZSL) enables the recognition of novel classes byleveraging semantic knowledge transfer from known to unknown categories. Thisknowledge, typically encapsulated in attribute descriptions, aids inidentifying class-specific visual features, thus facilitating visual-semanticalignment and improving ZSL performance. However, real-world challenges such asdistribution imbalances and attribute co-occurrence among instances oftenhinder the discernment of local variances in images, a problem exacerbated bythe scarcity of fine-grained, region-specific attribute annotations. Moreover,the variability in visual presentation within categories can also skewattribute-category associations. In response, we propose a bidirectionalcross-modal ZSL approach CREST. It begins by extracting representations forattribute and visual localization and employs Evidential Deep Learning (EDL) tomeasure underlying epistemic uncertainty, thereby enhancing the model'sresilience against hard negatives. CREST incorporates dual learning pathways,focusing on both visual-category and attribute-category alignments, to ensurerobust correlation between latent and observable spaces. Moreover, we introducean uncertainty-informed cross-modal fusion technique to refine visual-attributeinference. Extensive experiments demonstrate our model's effectiveness andunique explainability across multiple datasets. Our code and data are availableat: Comments: Ongoing work; 10 pages, 2 Tables, 9 Figures; Repo is available athttps://github.com/JethroJames/CREST.</description><author>Haojian Huang, Xiaozhen Qiao, Zhuo Chen, Haodong Chen, Bingyu Li, Zhe Sun, Mulin Chen, Xuelong Li</author><pubDate>Mon, 15 Apr 2024 11:19:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09640v1</guid></item><item><title>Mind-to-Image: Projecting Visual Mental Imagination of the Brain from fMRI</title><link>http://arxiv.org/abs/2404.05468v2</link><description>The reconstruction of images observed by subjects from fMRI data collectedduring visual stimuli has made significant strides in the past decade, thanksto the availability of extensive fMRI datasets and advancements in generativemodels for image generation. However, the application of visual reconstructionhas remained limited. Reconstructing visual imagination presents a greaterchallenge, with potentially revolutionary applications ranging from aidingindividuals with disabilities to verifying witness accounts in court. Theprimary hurdles in this field are the absence of data collection protocols forvisual imagery and the lack of datasets on the subject. Traditionally,fMRI-to-image relies on data collected from subjects exposed to visual stimuli,which poses issues for generating visual imagery based on the difference ofbrain activity between visual stimulation and visual imagery. For the firsttime, we have compiled a substantial dataset (around 6h of scans) on visualimagery along with a proposed data collection protocol. We then train amodified version of an fMRI-to-image model and demonstrate the feasibility ofreconstructing images from two modes of imagination: from memory and from pureimagination. This marks an important step towards creating a technology thatallow direct reconstruction of visual imagery.</description><author>Hugo Caselles-Dupré, Charles Mellerio, Paul Hérent, Alizée Lopez-Persem, Benoit Béranger, Mathieu Soularue, Pierre Fautrel, Gauthier Vernier, Matthieu Cord</author><pubDate>Mon, 15 Apr 2024 11:13:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05468v2</guid></item><item><title>Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models</title><link>http://arxiv.org/abs/2308.11672v2</link><description>A central characteristic of Bayesian statistics is the ability toconsistently incorporate prior knowledge into various modeling processes. Inthis paper, we focus on translating domain expert knowledge into correspondingprior distributions over model parameters, a process known as priorelicitation. Expert knowledge can manifest itself in diverse formats, includinginformation about raw data, summary statistics, or model parameters. A majorchallenge for existing elicitation methods is how to effectively utilize all ofthese different formats in order to formulate prior distributions that alignwith the expert's expectations, regardless of the model structure. To addressthese challenges, we develop a simulation-based elicitation method that canlearn the hyperparameters of potentially any parametric prior distribution froma wide spectrum of expert knowledge using stochastic gradient descent. Wevalidate the effectiveness and robustness of our elicitation method in fourrepresentative case studies covering linear models, generalized linear models,and hierarchical models. Our results support the claim that our method islargely independent of the underlying model structure and adaptable to variouselicitation techniques, including quantile-based, moment-based, andhistogram-based methods.</description><author>Florence Bockting, Stefan T. Radev, Paul-Christian Bürkner</author><pubDate>Mon, 15 Apr 2024 11:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11672v2</guid></item><item><title>All-in-one simulation-based inference</title><link>http://arxiv.org/abs/2404.09636v1</link><description>Amortized Bayesian inference trains neural networks to solve stochasticinference problems using model simulations, thereby making it possible torapidly perform Bayesian inference for any newly observed data. However,current simulation-based amortized inference methods are simulation-hungry andinflexible: They require the specification of a fixed parametric prior,simulator, and inference tasks ahead of time. Here, we present a new amortizedinference method -- the Simformer -- which overcomes these limitations. Bytraining a probabilistic diffusion model with transformer architectures, theSimformer outperforms current state-of-the-art amortized inference approacheson benchmark tasks and is substantially more flexible: It can be applied tomodels with function-valued parameters, it can handle inference scenarios withmissing or unstructured data, and it can sample arbitrary conditionals of thejoint distribution of parameters and data, including both posterior andlikelihood. We showcase the performance and flexibility of the Simformer onsimulators from ecology, epidemiology, and neuroscience, and demonstrate thatit opens up new possibilities and application domains for amortized Bayesianinference on simulation-based models.</description><author>Manuel Gloeckler, Michael Deistler, Christian Weilbach, Frank Wood, Jakob H. Macke</author><pubDate>Mon, 15 Apr 2024 11:12:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09636v1</guid></item><item><title>Are NeRFs ready for autonomous driving? Towards closing the real-to-simulation gap</title><link>http://arxiv.org/abs/2403.16092v2</link><description>Neural Radiance Fields (NeRFs) have emerged as promising tools for advancingautonomous driving (AD) research, offering scalable closed-loop simulation anddata augmentation capabilities. However, to trust the results achieved insimulation, one needs to ensure that AD systems perceive real and rendered datain the same way. Although the performance of rendering methods is increasing,many scenarios will remain inherently challenging to reconstruct faithfully. Tothis end, we propose a novel perspective for addressing the real-to-simulateddata gap. Rather than solely focusing on improving rendering fidelity, weexplore simple yet effective methods to enhance perception model robustness toNeRF artifacts without compromising performance on real data. Moreover, weconduct the first large-scale investigation into the real-to-simulated data gapin an AD setting using a state-of-the-art neural rendering technique.Specifically, we evaluate object detectors and an online mapping model on realand simulated data, and study the effects of different fine-tuningstrategies.Our results show notable improvements in model robustness tosimulated data, even improving real-world performance in some cases. Last, wedelve into the correlation between the real-to-simulated gap and imagereconstruction metrics, identifying FID and LPIPS as strong indicators. Seehttps://research.zenseact.com/publications/closing-real2sim-gap for our projectpage.</description><author>Carl Lindström, Georg Hess, Adam Lilja, Maryam Fatemi, Lars Hammarstrand, Christoffer Petersson, Lennart Svensson</author><pubDate>Mon, 15 Apr 2024 11:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16092v2</guid></item><item><title>Geometrically-driven Aggregation for Zero-shot 3D Point Cloud Understanding</title><link>http://arxiv.org/abs/2312.02244v3</link><description>Zero-shot 3D point cloud understanding can be achieved via 2D Vision-LanguageModels (VLMs). Existing strategies directly map Vision-Language Models from 2Dpixels of rendered or captured views to 3D points, overlooking the inherent andexpressible point cloud geometric structure. Geometrically similar or closeregions can be exploited for bolstering point cloud understanding as they arelikely to share semantic information. To this end, we introduce the firsttraining-free aggregation technique that leverages the point cloud's 3Dgeometric structure to improve the quality of the transferred Vision-LanguageModels. Our approach operates iteratively, performing local-to-globalaggregation based on geometric and semantic point-level reasoning. We benchmarkour approach on three downstream tasks, including classification, partsegmentation, and semantic segmentation, with a variety of datasetsrepresenting both synthetic/real-world, and indoor/outdoor scenarios. Ourapproach achieves new state-of-the-art results in all benchmarks. Our approachoperates iteratively, performing local-to-global aggregation based on geometricand semantic point-level reasoning. Code and dataset are available athttps://luigiriz.github.io/geoze-website/</description><author>Guofeng Mei, Luigi Riz, Yiming Wang, Fabio Poiesi</author><pubDate>Mon, 15 Apr 2024 11:06:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02244v3</guid></item><item><title>In-Context Translation: Towards Unifying Image Recognition, Processing, and Generation</title><link>http://arxiv.org/abs/2404.09633v1</link><description>We propose In-Context Translation (ICT), a general learning framework tounify visual recognition (e.g., semantic segmentation), low-level imageprocessing (e.g., denoising), and conditional image generation (e.g.,edge-to-image synthesis). Thanks to unification, ICT significantly reduces theinherent inductive bias that comes with designing models for specific tasks,and it maximizes mutual enhancement across similar tasks. However, theunification across a large number of tasks is non-trivial due to various dataformats and training pipelines. To this end, ICT introduces two designs.Firstly, it standardizes input-output data of different tasks into RGB imagepairs, e.g., semantic segmentation data pairs an RGB image with itssegmentation mask in the same RGB format. This turns different tasks into ageneral translation task between two RGB images. Secondly, it standardizes thetraining of different tasks into a general in-context learning, where"in-context" means the input comprises an example input-output pair of thetarget task and a query image. The learning objective is to generate the"missing" data paired with the query. The implicit translation process is thusbetween the query and the generated image. In experiments, ICT unifies tenvision tasks and showcases impressive performance on their respectivebenchmarks. Notably, compared to its competitors, e.g., Painter andPromptDiffusion, ICT trained on only 4 RTX 3090 GPUs is shown to be moreefficient and less costly in training.</description><author>Han Xue, Qianru Sun, Li Song, Wenjun Zhang, Zhiwu Huang</author><pubDate>Mon, 15 Apr 2024 11:05:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09633v1</guid></item><item><title>Bridging Vision and Language Spaces with Assignment Prediction</title><link>http://arxiv.org/abs/2404.09632v1</link><description>This paper introduces VLAP, a novel approach that bridges pretrained visionmodels and large language models (LLMs) to make frozen LLMs understand thevisual world. VLAP transforms the embedding space of pretrained vision modelsinto the LLMs' word embedding space using a single linear layer for efficientand general-purpose visual and language understanding. Specifically, we harnesswell-established word embeddings to bridge two modality embedding spaces. Thevisual and text representations are simultaneously assigned to a set of wordembeddings within pretrained LLMs by formulating the assigning procedure as anoptimal transport problem. We predict the assignment of one modality from therepresentation of another modality data, enforcing consistent assignments forpaired multimodal data. This allows vision and language representations tocontain the same information, grounding the frozen LLMs' word embedding spacein visual data. Moreover, a robust semantic taxonomy of LLMs can be preservedwith visual data since the LLMs interpret and reason linguistic informationfrom correlations between word embeddings. Experimental results show that VLAPachieves substantial improvements over the previous linear transformation-basedapproaches across a range of vision-language tasks, including image captioning,visual question answering, and cross-modal retrieval. We also demonstrate thelearned visual representations hold a semantic taxonomy of LLMs, making visualsemantic arithmetic possible.</description><author>Jungin Park, Jiyoung Lee, Kwanghoon Sohn</author><pubDate>Mon, 15 Apr 2024 11:04:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09632v1</guid></item><item><title>Action Model Learning with Guarantees</title><link>http://arxiv.org/abs/2404.09631v1</link><description>This paper studies the problem of action model learning with fullobservability. Following the learning by search paradigm by Mitchell, wedevelop a theory for action model learning based on version spaces thatinterprets the task as search for hypothesis that are consistent with thelearning examples. Our theoretical findings are instantiated in an onlinealgorithm that maintains a compact representation of all solutions of theproblem. Among these range of solutions, we bring attention to actions modelsapproximating the actual transition system from below (sound models) and fromabove (complete models). We show how to manipulate the output of our learningalgorithm to build deterministic and non-deterministic formulations of thesound and complete models and prove that, given enough examples, bothformulations converge into the very same true model. Our experiments revealtheir usefulness over a range of planning domains.</description><author>Diego Aineto, Enrico Scala</author><pubDate>Mon, 15 Apr 2024 11:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09631v1</guid></item><item><title>Privacy-Preserving Intrusion Detection using Convolutional Neural Networks</title><link>http://arxiv.org/abs/2404.09625v1</link><description>Privacy-preserving analytics is designed to protect valuable assets. A commonservice provision involves the input data from the client and the model on theanalyst's side. The importance of the privacy preservation is fuelled by legalobligations and intellectual property concerns. We explore the use case of amodel owner providing an analytic service on customer's private data. Noinformation about the data shall be revealed to the analyst and no informationabout the model shall be leaked to the customer. Current methods involve costs:accuracy deterioration and computational complexity. The complexity, in turn,results in a longer processing time, increased requirement on computingresources, and involves data communication between the client and the server.In order to deploy such service architecture, we need to evaluate the optimalsetting that fits the constraints. And that is what this paper addresses. Inthis work, we enhance an attack detection system based on Convolutional NeuralNetworks with privacy-preserving technology based on PriMIA framework that isinitially designed for medical data.</description><author>Martin Kodys, Zhongmin Dai, Vrizlynn L. L. Thing</author><pubDate>Mon, 15 Apr 2024 10:56:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09625v1</guid></item><item><title>AesExpert: Towards Multi-modality Foundation Model for Image Aesthetics Perception</title><link>http://arxiv.org/abs/2404.09624v1</link><description>The highly abstract nature of image aesthetics perception (IAP) posessignificant challenge for current multimodal large language models (MLLMs). Thelack of human-annotated multi-modality aesthetic data further exacerbates thisdilemma, resulting in MLLMs falling short of aesthetics perceptioncapabilities. To address the above challenge, we first introduce acomprehensively annotated Aesthetic Multi-Modality Instruction Tuning (AesMMIT)dataset, which serves as the footstone for building multi-modality aestheticsfoundation models. Specifically, to align MLLMs with human aestheticsperception, we construct a corpus-rich aesthetic critique database with 21,904diverse-sourced images and 88K human natural language feedbacks, which arecollected via progressive questions, ranging from coarse-grained aestheticgrades to fine-grained aesthetic descriptions. To ensure that MLLMs can handlediverse queries, we further prompt GPT to refine the aesthetic critiques andassemble the large-scale aesthetic instruction tuning dataset, i.e. AesMMIT,which consists of 409K multi-typed instructions to activate stronger aestheticcapabilities. Based on the AesMMIT database, we fine-tune the open-sourcedgeneral foundation models, achieving multi-modality Aesthetic Expert models,dubbed AesExpert. Extensive experiments demonstrate that the proposed AesExpertmodels deliver significantly better aesthetic perception performances than thestate-of-the-art MLLMs, including the most advanced GPT-4V andGemini-Pro-Vision. Source data will be available athttps://github.com/yipoh/AesExpert.</description><author>Yipo Huang, Xiangfei Sheng, Zhichao Yang, Quan Yuan, Zhichao Duan, Pengfei Chen, Leida Li, Weisi Lin, Guangming Shi</author><pubDate>Mon, 15 Apr 2024 10:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09624v1</guid></item><item><title>Flattening the Parent Bias: Hierarchical Semantic Segmentation in the Poincaré Ball</title><link>http://arxiv.org/abs/2404.03778v3</link><description>Hierarchy is a natural representation of semantic taxonomies, including theones routinely used in image segmentation. Indeed, recent work on semanticsegmentation reports improved accuracy from supervised training leveraginghierarchical label structures. Encouraged by these results, we revisit thefundamental assumptions behind that work. We postulate and then empiricallyverify that the reasons for the observed improvement in segmentation accuracymay be entirely unrelated to the use of the semantic hierarchy. To demonstratethis, we design a range of cross-domain experiments with a representativehierarchical approach. We find that on the new testing domains, a flat(non-hierarchical) segmentation network, in which the parents are inferred fromthe children, has superior segmentation accuracy to the hierarchical approachacross the board. Complementing these findings and inspired by the intrinsicproperties of hyperbolic spaces, we study a more principled approach tohierarchical segmentation using the Poincar\'e ball model. The hyperbolicrepresentation largely outperforms the previous (Euclidean) hierarchicalapproach as well and is on par with our flat Euclidean baseline in terms ofsegmentation accuracy. However, it additionally exhibits surprisingly strongcalibration quality of the parent nodes in the semantic hierarchy, especiallyon the more challenging domains. Our combined analysis suggests that theestablished practice of hierarchical segmentation may be limited to in-domainsettings, whereas flat classifiers generalize substantially better, especiallyif they are modeled in the hyperbolic space.</description><author>Simon Weber, Barış Zöngür, Nikita Araslanov, Daniel Cremers</author><pubDate>Mon, 15 Apr 2024 10:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03778v3</guid></item><item><title>TTK is Getting MPI-Ready</title><link>http://arxiv.org/abs/2310.08339v2</link><description>This system paper documents the technical foundations for the extension ofthe Topology ToolKit (TTK) to distributed-memory parallelism with the MessagePassing Interface (MPI). While several recent papers introduced topology-basedapproaches for distributed-memory environments, these were reportingexperiments obtained with tailored, mono-algorithm implementations. Incontrast, we describe in this paper a versatile approach (supporting bothtriangulated domains and regular grids) for the support of topological analysispipelines, i.e. a sequence of topological algorithms interacting together.While developing this extension, we faced several algorithmic and softwareengineering challenges, which we document in this paper. We describe an MPIextension of TTK's data structure for triangulation representation andtraversal, a central component to the global performance and generality ofTTK's topological implementations. We also introduce an intermediate interfacebetween TTK and MPI, both at the global pipeline level, and at the fine-grainalgorithmic level. We provide a taxonomy for the distributed-memory topologicalalgorithms supported by TTK, depending on their communication needs and provideexamples of hybrid MPI+thread parallelizations. Performance analyses show thatparallel efficiencies range from 20% to 80% (depending on the algorithms), andthat the MPI-specific preconditioning introduced by our framework induces anegligible computation time overhead. We illustrate the new distributed-memorycapabilities of TTK with an example of advanced analysis pipeline, combiningmultiple algorithms, run on the largest publicly available dataset we havefound (120 billion vertices) on a cluster with 64 nodes (for a total of 1536cores). Finally, we provide a roadmap for the completion of TTK's MPIextension, along with generic recommendations for each algorithm communicationcategory.</description><author>Eve Le Guillou, Michael Will, Pierre Guillou, Jonas Lukasczyk, Pierre Fortin, Christoph Garth, Julien Tierny</author><pubDate>Mon, 15 Apr 2024 10:51:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08339v2</guid></item><item><title>DIDLM:A Comprehensive Multi-Sensor Dataset with Infrared Cameras, Depth Cameras, LiDAR, and 4D Millimeter-Wave Radar in Challenging Scenarios for 3D Mapping</title><link>http://arxiv.org/abs/2404.09622v1</link><description>This study presents a comprehensive multi-sensor dataset designed for 3Dmapping in challenging indoor and outdoor environments. The dataset comprisesdata from infrared cameras, depth cameras, LiDAR, and 4D millimeter-wave radar,facilitating exploration of advanced perception and mapping techniques.Integration of diverse sensor data enhances perceptual capabilities in extremeconditions such as rain, snow, and uneven road surfaces. The dataset alsoincludes interactive robot data at different speeds indoors and outdoors,providing a realistic background environment. Slam comparisons between similarroutes are conducted, analyzing the influence of different complex scenes onvarious sensors. Various SLAM algorithms are employed to process the dataset,revealing performance differences among algorithms in different scenarios. Insummary, this dataset addresses the problem of data scarcity in specialenvironments, fostering the development of perception and mapping algorithmsfor extreme conditions. Leveraging multi-sensor data including infrared, depthcameras, LiDAR, 4D millimeter-wave radar, and robot interactions, the datasetadvances intelligent mapping and perception capabilities.Our dataset isavailable at https://github.com/GongWeiSheng/DIDLM.</description><author>WeiSheng Gong, Chen He, KaiJie Su, QingYong Li</author><pubDate>Mon, 15 Apr 2024 10:49:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09622v1</guid></item><item><title>UNIAA: A Unified Multi-modal Image Aesthetic Assessment Baseline and Benchmark</title><link>http://arxiv.org/abs/2404.09619v1</link><description>As an alternative to expensive expert evaluation, Image Aesthetic Assessment(IAA) stands out as a crucial task in computer vision. However, traditional IAAmethods are typically constrained to a single data source or task, restrictingthe universality and broader application. In this work, to better align withhuman aesthetics, we propose a Unified Multi-modal Image Aesthetic Assessment(UNIAA) framework, including a Multi-modal Large Language Model (MLLM) namedUNIAA-LLaVA and a comprehensive benchmark named UNIAA-Bench. We choose MLLMswith both visual perception and language ability for IAA and establish alow-cost paradigm for transforming the existing datasets into unified andhigh-quality visual instruction tuning data, from which the UNIAA-LLaVA istrained. To further evaluate the IAA capability of MLLMs, we construct theUNIAA-Bench, which consists of three aesthetic levels: Perception, Description,and Assessment. Extensive experiments validate the effectiveness andrationality of UNIAA. UNIAA-LLaVA achieves competitive performance on alllevels of UNIAA-Bench, compared with existing MLLMs. Specifically, our modelperforms better than GPT-4V in aesthetic perception and even approaches thejunior-level human. We find MLLMs have great potential in IAA, yet thereremains plenty of room for further improvement. The UNIAA-LLaVA and UNIAA-Benchwill be released.</description><author>Zhaokun Zhou, Qiulin Wang, Bin Lin, Yiwei Su, Rui Chen, Xin Tao, Amin Zheng, Li Yuan, Pengfei Wan, Di Zhang</author><pubDate>Mon, 15 Apr 2024 10:47:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09619v1</guid></item><item><title>Safeguarding adaptive methods: global convergence of Barzilai-Borwein and other stepsize choices</title><link>http://arxiv.org/abs/2404.09617v1</link><description>Leveraging on recent advancements on adaptive methods for convex minimizationproblems, this paper provides a linesearch-free proximal gradient framework forglobalizing the convergence of popular stepsize choices such asBarzilai-Borwein and one-dimensional Anderson acceleration. This framework cancope with problems in which the gradient of the differentiable function ismerely locally H\"older continuous. Our analysis not only encompasses but alsorefines existing results upon which it builds. The theory is corroborated bynumerical evidence that showcases the synergetic interplay between faststepsize selections and adaptive methods.</description><author>Ou Hongjia, Andreas Themelis</author><pubDate>Mon, 15 Apr 2024 10:46:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09617v1</guid></item><item><title>A Review and Efficient Implementation of Scene Graph Generation Metrics</title><link>http://arxiv.org/abs/2404.09616v1</link><description>Scene graph generation has emerged as a prominent research field in computervision, witnessing significant advancements in the recent years. However,despite these strides, precise and thorough definitions for the metrics used toevaluate scene graph generation models are lacking. In this paper, we addressthis gap in the literature by providing a review and precise definition ofcommonly used metrics in scene graph generation. Our comprehensive examinationclarifies the underlying principles of these metrics and can serve as areference or introduction to scene graph metrics. Furthermore, to facilitate the usage of these metrics, we introduce astandalone Python package called SGBench that efficiently implements alldefined metrics, ensuring their accessibility to the research community.Additionally, we present a scene graph benchmarking web service, that enablesresearchers to compare scene graph generation methods and increase visibilityof new methods in a central place. All of our code can be found at https://lorjul.github.io/sgbench/.</description><author>Julian Lorenz, Robin Schön, Katja Ludwig, Rainer Lienhart</author><pubDate>Mon, 15 Apr 2024 10:40:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09616v1</guid></item><item><title>If there's a Trigger Warning, then where's the Trigger? Investigating Trigger Warnings at the Passage Level</title><link>http://arxiv.org/abs/2404.09615v1</link><description>Trigger warnings are labels that preface documents with sensitive content ifthis content could be perceived as harmful by certain groups of readers. Sincewarnings about a document intuitively need to be shown before reading it,authors usually assign trigger warnings at the document level. What parts oftheir writing prompted them to assign a warning, however, remains unclear. Weinvestigate for the first time the feasibility of identifying the triggeringpassages of a document, both manually and computationally. We create a datasetof 4,135 English passages, each annotated with one of eight common triggerwarnings. In a large-scale evaluation, we then systematically evaluate theeffectiveness of fine-tuned and few-shot classifiers, and theirgeneralizability. We find that trigger annotation belongs to the group ofsubjective annotation tasks in NLP, and that automatic trigger classificationremains challenging but feasible.</description><author>Matti Wiegmann, Jennifer Rakete, Magdalena Wolska, Benno Stein, Martin Potthast</author><pubDate>Mon, 15 Apr 2024 10:37:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09615v1</guid></item><item><title>CrossKD: Cross-Head Knowledge Distillation for Object Detection</title><link>http://arxiv.org/abs/2306.11369v2</link><description>Knowledge Distillation (KD) has been validated as an effective modelcompression technique for learning compact object detectors. Existingstate-of-the-art KD methods for object detection are mostly based on featureimitation. In this paper, we present a general and effective predictionmimicking distillation scheme, called CrossKD, which delivers the intermediatefeatures of the student's detection head to the teacher's detection head. Theresulting cross-head predictions are then forced to mimic the teacher'spredictions. This manner relieves the student's head from receivingcontradictory supervision signals from the annotations and the teacher'spredictions, greatly improving the student's detection performance. Moreover,as mimicking the teacher's predictions is the target of KD, CrossKD offers moretask-oriented information in contrast with feature imitation. On MS COCO, withonly prediction mimicking losses applied, our CrossKD boosts the averageprecision of GFL ResNet-50 with 1x training schedule from 40.2 to 43.7,outperforming all existing KD methods. In addition, our method also works wellwhen distilling detectors with heterogeneous backbones. Code is available athttps://github.com/jbwang1997/CrossKD.</description><author>Jiabao Wang, Yuming Chen, Zhaohui Zheng, Xiang Li, Ming-Ming Cheng, Qibin Hou</author><pubDate>Mon, 15 Apr 2024 10:33:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11369v2</guid></item><item><title>Efficient and accurate neural field reconstruction using resistive memory</title><link>http://arxiv.org/abs/2404.09613v1</link><description>Human beings construct perception of space by integrating sparse observationsinto massively interconnected synapses and neurons, offering a superiorparallelism and efficiency. Replicating this capability in AI finds wideapplications in medical imaging, AR/VR, and embodied AI, where input data isoften sparse and computing resources are limited. However, traditional signalreconstruction methods on digital computers face both software and hardwarechallenges. On the software front, difficulties arise from storageinefficiencies in conventional explicit signal representation. Hardwareobstacles include the von Neumann bottleneck, which limits data transferbetween the CPU and memory, and the limitations of CMOS circuits in supportingparallel processing. We propose a systematic approach with software-hardwareco-optimizations for signal reconstruction from sparse inputs. Software-wise,we employ neural field to implicitly represent signals via neural networks,which is further compressed using low-rank decomposition and structuredpruning. Hardware-wise, we design a resistive memory-based computing-in-memory(CIM) platform, featuring a Gaussian Encoder (GE) and an MLP Processing Engine(PE). The GE harnesses the intrinsic stochasticity of resistive memory forefficient input encoding, while the PE achieves precise weight mapping througha Hardware-Aware Quantization (HAQ) circuit. We demonstrate the system'sefficacy on a 40nm 256Kb resistive memory-based in-memory computing macro,achieving huge energy efficiency and parallelism improvements withoutcompromising reconstruction quality in tasks like 3D CT sparse reconstruction,novel view synthesis, and novel view synthesis for dynamic scenes. This workadvances the AI-driven signal restoration technology and paves the way forfuture efficient and robust medical AI and 3D vision applications.</description><author>Yifei Yu, Shaocong Wang, Woyu Zhang, Xinyuan Zhang, Xiuzhe Wu, Yangu He, Jichang Yang, Yue Zhang, Ning Lin, Bo Wang, Xi Chen, Songqi Wang, Xumeng Zhang, Xiaojuan Qi, Zhongrui Wang, Dashan Shang, Qi Liu, Kwang-Ting Cheng, Ming Liu</author><pubDate>Mon, 15 Apr 2024 10:33:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09613v1</guid></item><item><title>LoRA Dropout as a Sparsity Regularizer for Overfitting Control</title><link>http://arxiv.org/abs/2404.09610v1</link><description>Parameter-efficient fine-tuning methods, represented by LoRA, play anessential role in adapting large-scale pre-trained models to downstream tasks.However, fine-tuning LoRA-series models also faces the risk of overfitting onthe training dataset, and yet there's still a lack of theoretical guidance andpractical mechanism to control overfitting on LoRA-based PEFT methods. In thispaper, we propose a LoRA Dropout mechanism for the LoRA-based methods byintroducing random noises to the learnable low-rank matrices and increasingparameter sparsity. We then demonstrate the theoretical mechanism of our LoRADropout mechanism from the perspective of sparsity regularization by providinga generalization error bound under this framework. Theoretical results showthat appropriate sparsity would help tighten the gap between empirical andgeneralization risks and thereby control overfitting. Furthermore, based on theLoRA Dropout framework, we introduce a test-time ensemble strategy and providetheoretical evidence demonstrating that the ensemble method can furthercompress the error bound, and lead to better performance during inference time.Extensive experiments on various NLP tasks provide practical validations of theeffectiveness of our LoRA Dropout framework in improving model accuracy andcalibration.</description><author>Yang Lin, Xinyu Ma, Xu Chu, Yujie Jin, Zhibang Yang, Yasha Wang, Hong Mei</author><pubDate>Mon, 15 Apr 2024 10:32:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09610v1</guid></item><item><title>Z-GMOT: Zero-shot Generic Multiple Object Tracking</title><link>http://arxiv.org/abs/2305.17648v3</link><description>Despite recent significant progress, Multi-Object Tracking (MOT) faceslimitations such as reliance on prior knowledge and predefined categories andstruggles with unseen objects. To address these issues, Generic Multiple ObjectTracking (GMOT) has emerged as an alternative approach, requiring less priorinformation. However, current GMOT methods often rely on initial bounding boxesand struggle to handle variations in factors such as viewpoint, lighting,occlusion, and scale, among others. Our contributions commence with theintroduction of the \textit{Referring GMOT dataset} a collection of videos,each accompanied by detailed textual descriptions of their attributes.Subsequently, we propose $\mathtt{Z-GMOT}$, a cutting-edge tracking solutioncapable of tracking objects from \textit{never-seen categories} without theneed of initial bounding boxes or predefined categories. Within our$\mathtt{Z-GMOT}$ framework, we introduce two novel components: (i)$\mathtt{iGLIP}$, an improved Grounded language-image pretraining, foraccurately detecting unseen objects with specific characteristics. (ii)$\mathtt{MA-SORT}$, a novel object association approach that adeptly integratesmotion and appearance-based matching strategies to tackle the complex task oftracking objects with high similarity. Our contributions are benchmarkedthrough extensive experiments conducted on the Referring GMOT dataset for GMOTtask. Additionally, to assess the generalizability of the proposed$\mathtt{Z-GMOT}$, we conduct ablation studies on the DanceTrack and MOT20datasets for the MOT task. Our dataset, code, and models are released at:https://fsoft-aic.github.io/Z-GMOT.</description><author>Kim Hoang Tran, Anh Duy Le Dinh, Tien Phat Nguyen, Thinh Phan, Pha Nguyen, Khoa Luu, Donald Adjeroh, Gianfranco Doretto, Ngan Hoang Le</author><pubDate>Mon, 15 Apr 2024 10:31:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17648v3</guid></item><item><title>A Self-feedback Knowledge Elicitation Approach for Chemical Reaction Predictions</title><link>http://arxiv.org/abs/2404.09606v1</link><description>The task of chemical reaction predictions (CRPs) plays a pivotal role inadvancing drug discovery and material science. However, its effectiveness isconstrained by the vast and uncertain chemical reaction space and challenges incapturing reaction selectivity, particularly due to existing methods'limitations in exploiting the data's inherent knowledge. To address thesechallenges, we introduce a data-curated self-feedback knowledge elicitationapproach. This method starts from iterative optimization of molecularrepresentations and facilitates the extraction of knowledge on chemicalreaction types (RTs). Then, we employ adaptive prompt learning to infuse theprior knowledge into the large language model (LLM). As a result, we achievesignificant enhancements: a 14.2% increase in retrosynthesis predictionaccuracy, a 74.2% rise in reagent prediction accuracy, and an expansion in themodel's capability for handling multi-task chemical reactions. This researchoffers a novel paradigm for knowledge elicitation in scientific research andshowcases the untapped potential of LLMs in CRPs.</description><author>Pengfei Liu, Jun Tao, Zhixiang Ren</author><pubDate>Mon, 15 Apr 2024 10:26:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09606v1</guid></item><item><title>Machine learning-based optimization workflow of the homogeneity of spunbond nonwovens with human validation</title><link>http://arxiv.org/abs/2404.09604v1</link><description>In the last ten years, the average annual growth rate of nonwoven productionwas 4%. In 2020 and 2021, nonwoven production has increased even further due tothe huge demand for nonwoven products needed for protective clothing such asFFP2 masks to combat the COVID19 pandemic. Optimizing the production process isstill a challenge due to its high nonlinearity. In this paper, we present amachine learning-based optimization workflow aimed at improving the homogeneityof spunbond nonwovens. The optimization workflow is based on a mathematicalmodel that simulates the microstructures of nonwovens. Based on trainingy datacoming from this simulator, different machine learning algorithms are trainedin order to find a surrogate model for the time-consuming simulator. Humanvalidation is employed to verify the outputs of machine learning algorithms byassessing the aesthetics of the nonwovens. We include scientific and expertknowledge into the training data to reduce the computational costs involved inthe optimization process. We demonstrate the necessity and effectiveness of ourworkflow in optimizing the homogeneity of nonwovens.</description><author>Viny Saajan Victor, Andre Schmeißer, Heike Leitte, Simone Gramsch</author><pubDate>Mon, 15 Apr 2024 10:22:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09604v1</guid></item><item><title>Stimulating the Diffusion Model for Image Denoising via Adaptive Embedding and Ensembling</title><link>http://arxiv.org/abs/2307.03992v4</link><description>Image denoising is a fundamental problem in computational photography, whereachieving high perception with low distortion is highly demanding. Currentmethods either struggle with perceptual quality or suffer from significantdistortion. Recently, the emerging diffusion model has achievedstate-of-the-art performance in various tasks and demonstrates great potentialfor image denoising. However, stimulating diffusion models for image denoisingis not straightforward and requires solving several critical problems. For onething, the input inconsistency hinders the connection between diffusion modelsand image denoising. For another, the content inconsistency between thegenerated image and the desired denoised image introduces distortion. To tacklethese problems, we present a novel strategy called the Diffusion Model forImage Denoising (DMID) by understanding and rethinking the diffusion model froma denoising perspective. Our DMID strategy includes an adaptive embeddingmethod that embeds the noisy image into a pre-trained unconditional diffusionmodel and an adaptive ensembling method that reduces distortion in the denoisedimage. Our DMID strategy achieves state-of-the-art performance on bothdistortion-based and perception-based metrics, for both Gaussian and real-worldimage denoising.The code is available at https://github.com/Li-Tong-621/DMID.</description><author>Tong Li, Hansen Feng, Lizhi Wang, Zhiwei Xiong, Hua Huang</author><pubDate>Mon, 15 Apr 2024 10:19:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03992v4</guid></item><item><title>Reactive Model Correction: Mitigating Harm to Task-Relevant Features via Conditional Bias Suppression</title><link>http://arxiv.org/abs/2404.09601v1</link><description>Deep Neural Networks are prone to learning and relying on spuriouscorrelations in the training data, which, for high-risk applications, can havefatal consequences. Various approaches to suppress model reliance on harmfulfeatures have been proposed that can be applied post-hoc without additionaltraining. Whereas those methods can be applied with efficiency, they also tendto harm model performance by globally shifting the distribution of latentfeatures. To mitigate unintended overcorrection of model behavior, we propose areactive approach conditioned on model-derived knowledge and eXplainableArtificial Intelligence (XAI) insights. While the reactive approach can beapplied to many post-hoc methods, we demonstrate the incorporation ofreactivity in particular for P-ClArC (Projective Class Artifact Compensation),introducing a new method called R-ClArC (Reactive Class Artifact Compensation).Through rigorous experiments in controlled settings (FunnyBirds) and with areal-world dataset (ISIC2019), we show that introducing reactivity can minimizethe detrimental effect of the applied correction while simultaneously ensuringlow reliance on spurious features.</description><author>Dilyara Bareeva, Maximilian Dreyer, Frederik Pahde, Wojciech Samek, Sebastian Lapuschkin</author><pubDate>Mon, 15 Apr 2024 10:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09601v1</guid></item><item><title>Evaluating Text-to-Image Synthesis: Survey and Taxonomy of Image Quality Metrics</title><link>http://arxiv.org/abs/2403.11821v3</link><description>Recent advances in text-to-image synthesis enabled through a combination oflanguage and vision foundation models have led to a proliferation of the toolsavailable and an increased attention to the field. When conductingtext-to-image synthesis, a central goal is to ensure that the content betweentext and image is aligned. As such, there exist numerous evaluation metricsthat aim to mimic human judgement. However, it is often unclear which metric touse for evaluating text-to-image synthesis systems as their evaluation ishighly nuanced. In this work, we provide a comprehensive overview of existingtext-to-image evaluation metrics. Based on our findings, we propose a newtaxonomy for categorizing these metrics. Our taxonomy is grounded in theassumption that there are two main quality criteria, namely compositionalityand generality, which ideally map to human preferences. Ultimately, we deriveguidelines for practitioners conducting text-to-image evaluation, discuss openchallenges of evaluation mechanisms, and surface limitations of currentmetrics.</description><author>Sebastian Hartwig, Dominik Engel, Leon Sick, Hannah Kniesel, Tristan Payer, Poonam Poonam, Michael Glöckler, Alex Bäuerle, Timo Ropinski</author><pubDate>Mon, 15 Apr 2024 10:10:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11821v3</guid></item><item><title>The Last JITAI? The Unreasonable Effectiveness of Large Language Models in Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting</title><link>http://arxiv.org/abs/2402.08658v2</link><description>We investigated the viability of using Large Language Models (LLMs) fortriggering and personalizing content for Just-in-Time Adaptive Interventions(JITAIs) in digital health. JITAIs are being explored as a key mechanism forsustainable behavior change, adapting interventions to an individual's currentcontext and needs. However, traditional rule-based and machine learning modelsfor JITAI implementation face scalability and flexibility limitations, such aslack of personalization, difficulty in managing multi-parametric systems, andissues with data sparsity. To investigate JITAI implementation via LLMs, wetested the contemporary overall performance-leading model 'GPT-4' with examplesgrounded in the use case of fostering heart-healthy physical activity inoutpatient cardiac rehabilitation. Three personas and five sets of contextinformation per persona were used as a basis of triggering and personalizingJITAIs. Subsequently, we generated a total of 450 proposed JITAI decisions andmessage content, divided equally into JITAIs generated by 10 iterations withGPT-4, a baseline provided by 10 laypersons (LayPs), and a gold standard set by10 healthcare professionals (HCPs). Ratings from 27 LayPs and 11 HCPs indicatedthat JITAIs generated by GPT-4 were superior to those by HCPs and LayPs overall assessed scales: i.e., appropriateness, engagement, effectiveness, andprofessionality. This study indicates that LLMs have significant potential forimplementing JITAIs as a building block of personalized or "precision" health,offering scalability, effective personalization based on opportunisticallysampled information, and good acceptability.</description><author>David Haag, Devender Kumar, Sebastian Gruber, Mahdi Sareban, Gunnar Treff, Josef Niebauer, Christopher Bull, Jan David Smeddinck</author><pubDate>Mon, 15 Apr 2024 10:08:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08658v2</guid></item><item><title>Building Semantic Communication System via Molecules: An End-to-End Training Approach</title><link>http://arxiv.org/abs/2404.09595v1</link><description>The concept of semantic communication provides a novel approach forapplications in scenarios with limited communication resources. In this paper,we propose an end-to-end (E2E) semantic molecular communication system, aimingto enhance the efficiency of molecular communication systems by reducing thetransmitted information. Specifically, following the joint source channelcoding paradigm, the network is designed to encode the task-relevantinformation into the concentration of the information molecules, which isrobust to the degradation of the molecular communication channel. Furthermore,we propose a channel network to enable the E2E learning over thenon-differentiable molecular channel. Experimental results demonstrate thesuperior performance of the semantic molecular communication system over theconventional methods in classification tasks.</description><author>Yukun Cheng, Wei Chen, Bo Ai</author><pubDate>Mon, 15 Apr 2024 10:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09595v1</guid></item><item><title>Improving Recall of Large Language Models: A Model Collaboration Approach for Relational Triple Extraction</title><link>http://arxiv.org/abs/2404.09593v1</link><description>Relation triple extraction, which outputs a set of triples from longsentences, plays a vital role in knowledge acquisition. Large language modelscan accurately extract triples from simple sentences through few-shot learningor fine-tuning when given appropriate instructions. However, they often missout when extracting from complex sentences. In this paper, we design anevaluation-filtering framework that integrates large language models with smallmodels for relational triple extraction tasks. The framework includes anevaluation model that can extract related entity pairs with high precision. Wepropose a simple labeling principle and a deep neural network to build themodel, embedding the outputs as prompts into the extraction process of thelarge model. We conduct extensive experiments to demonstrate that the proposedmethod can assist large language models in obtaining more accurate extractionresults, especially from complex sentences containing multiple relationaltriples. Our evaluation model can also be embedded into traditional extractionmodels to enhance their extraction precision from complex sentences.</description><author>Zepeng Ding, Wenhao Huang, Jiaqing Liang, Deqing Yang, Yanghua Xiao</author><pubDate>Mon, 15 Apr 2024 10:03:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09593v1</guid></item><item><title>3D Gaussian Splatting as Markov Chain Monte Carlo</title><link>http://arxiv.org/abs/2404.09591v1</link><description>While 3D Gaussian Splatting has recently become popular for neural rendering,current methods rely on carefully engineered cloning and splitting strategiesfor placing Gaussians, which does not always generalize and may lead topoor-quality renderings. In addition, for real-world scenes, they rely on agood initial point cloud to perform well. In this work, we rethink 3D Gaussiansas random samples drawn from an underlying probability distribution describingthe physical representation of the scene -- in other words, Markov Chain MonteCarlo (MCMC) samples. Under this view, we show that the 3D Gaussian updates arestrikingly similar to a Stochastic Langevin Gradient Descent (SGLD) update. Aswith MCMC, samples are nothing but past visit locations, adding new Gaussiansunder our framework can simply be realized without heuristics as placingGaussians at existing Gaussian locations. To encourage using fewer Gaussiansfor efficiency, we introduce an L1-regularizer on the Gaussians. On variousstandard evaluation scenes, we show that our method provides improved renderingquality, easy control over the number of Gaussians, and robustness toinitialization.</description><author>Shakiba Kheradmand, Daniel Rebain, Gopal Sharma, Weiwei Sun, Jeff Tseng, Hossam Isack, Abhishek Kar, Andrea Tagliasacchi, Kwang Moo Yi</author><pubDate>Mon, 15 Apr 2024 10:01:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09591v1</guid></item><item><title>Wisdom of Instruction-Tuned Language Model Crowds. Exploring Model Label Variation</title><link>http://arxiv.org/abs/2307.12973v2</link><description>Large Language Models (LLMs) exhibit remarkable text classificationcapabilities, excelling in zero- and few-shot learning (ZSL and FSL) scenarios.However, since they are trained on different datasets, performance varieswidely across tasks between those models. Recent studies emphasize theimportance of considering human label variation in data annotation. However,how this human label variation also applies to LLMs remains unexplored. Giventhis likely model specialization, we ask: Do aggregate LLM labels improve overindividual models (as for human annotators)? We evaluate four recentinstruction-tuned LLMs as annotators on five subjective tasks across fourlanguages. We use ZSL and FSL setups and label aggregation from humanannotation. Aggregations are indeed substantially better than any individualmodel, benefiting from specialization in diverse tasks or languages.Surprisingly, FSL does not surpass ZSL, as it depends on the quality of theselected examples. However, there seems to be no good information-theoreticalstrategy to select those. We find that no LLM method rivals even simplesupervised models. We also discuss the tradeoffs in accuracy, cost, andmoral/ethical considerations between LLM and human annotation.</description><author>Flor Miriam Plaza-del-Arco, Debora Nozza, Dirk Hovy</author><pubDate>Mon, 15 Apr 2024 10:00:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12973v2</guid></item><item><title>German Tourism Knowledge Graph</title><link>http://arxiv.org/abs/2404.09587v1</link><description>Tourism is one of the most critical sectors of the global economy. Due to itsheterogeneous and fragmented nature, it provides one of the most suitable usecases for knowledge graphs. In this poster, we introduce the German TourismKnowledge Graph that integrates tourism-related data from 16 federal states ofGermany and various other sources to provide a curated knowledge source forvarious applications. It is publicly available through GUIs and an API.</description><author>Umutcan Serles, Elias Kärle, Richard Hunkel, Dieter Fensel</author><pubDate>Mon, 15 Apr 2024 09:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09587v1</guid></item><item><title>Mitigating the Curse of Dimensionality for Certified Robustness via Dual Randomized Smoothing</title><link>http://arxiv.org/abs/2404.09586v1</link><description>Randomized Smoothing (RS) has been proven a promising method for endowing anarbitrary image classifier with certified robustness. However, the substantialuncertainty inherent in the high-dimensional isotropic Gaussian noise imposesthe curse of dimensionality on RS. Specifically, the upper bound of ${\ell_2}$certified robustness radius provided by RS exhibits a diminishing trend withthe expansion of the input dimension $d$, proportionally decreasing at a rateof $1/\sqrt{d}$. This paper explores the feasibility of providing ${\ell_2}$certified robustness for high-dimensional input through the utilization of dualsmoothing in the lower-dimensional space. The proposed Dual RandomizedSmoothing (DRS) down-samples the input image into two sub-images and smoothsthe two sub-images in lower dimensions. Theoretically, we prove that DRSguarantees a tight ${\ell_2}$ certified robustness radius for the originalinput and reveal that DRS attains a superior upper bound on the ${\ell_2}$robustness radius, which decreases proportionally at a rate of $(1/\sqrt m +1/\sqrt n )$ with $m+n=d$. Extensive experiments demonstrate thegeneralizability and effectiveness of DRS, which exhibits a notable capabilityto integrate with established methodologies, yielding substantial improvementsin both accuracy and ${\ell_2}$ certified robustness baselines of RS on theCIFAR-10 and ImageNet datasets. Code is available athttps://github.com/xiasong0501/DRS.</description><author>Song Xia, Yu Yi, Xudong Jiang, Henghui Ding</author><pubDate>Mon, 15 Apr 2024 09:54:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09586v1</guid></item><item><title>A Graph Transformer-Driven Approach for Network Robustness Learning</title><link>http://arxiv.org/abs/2306.06913v2</link><description>Learning and analysis of network robustness, including controllabilityrobustness and connectivity robustness, is critical for various networkedsystems against attacks. Traditionally, network robustness is determined byattack simulations, which is very time-consuming and even incapable forlarge-scale networks. Network Robustness Learning, which is dedicated tolearning network robustness with high precision and high speed, provides apowerful tool to analyze network robustness by replacing simulations. In thispaper, a novel versatile and unified robustness learning approach via graphtransformer (NRL-GT) is proposed, which accomplishes the task ofcontrollability robustness learning and connectivity robustness learning frommultiple aspects including robustness curve learning, overall robustnesslearning, and synthetic network classification. Numerous experiments show that:1) NRL-GT is a unified learning framework for controllability robustness andconnectivity robustness, demonstrating a strong generalization ability toensure high precision when training and test sets are distributed differently;2) Compared to the cutting-edge methods, NRL-GT can simultaneously performnetwork robustness learning from multiple aspects and obtains superior resultsin less time. NRL-GT is also able to deal with complex networks of differentsize with low learning error and high efficiency; 3) It is worth mentioningthat the backbone of NRL-GT can serve as a transferable feature learning modulefor complex networks of different size and different downstream tasks.</description><author>Yu Zhang, Jia Li, Jie Ding, Xiang Li</author><pubDate>Mon, 15 Apr 2024 09:54:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06913v2</guid></item><item><title>Pseudo-label Learning with Calibrated Confidence Using an Energy-based Model</title><link>http://arxiv.org/abs/2404.09585v1</link><description>In pseudo-labeling (PL), which is a type of semi-supervised learning,pseudo-labels are assigned based on the confidence scores provided by theclassifier; therefore, accurate confidence is important for successful PL. Inthis study, we propose a PL algorithm based on an energy-based model (EBM),which is referred to as the energy-based PL (EBPL). In EBPL, a neuralnetwork-based classifier and an EBM are jointly trained by sharing theirfeature extraction parts. This approach enables the model to learn both theclass decision boundary and input data distribution, enhancing confidencecalibration during network training. The experimental results demonstrate thatEBPL outperforms the existing PL method in semi-supervised image classificationtasks, with superior confidence calibration error and recognition accuracy.</description><author>Masahito Toba, Seiichi Uchida, Hideaki Hayashi</author><pubDate>Mon, 15 Apr 2024 09:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09585v1</guid></item><item><title>Backward Learning for Goal-Conditioned Policies</title><link>http://arxiv.org/abs/2312.05044v2</link><description>Can we learn policies in reinforcement learning without rewards? Can we learna policy just by trying to reach a goal state? We answer these questionspositively by proposing a multi-step procedure that first learns a world modelthat goes backward in time, secondly generates goal-reaching backwardtrajectories, thirdly improves those sequences using shortest path findingalgorithms, and finally trains a neural network policy by imitation learning.We evaluate our method on a deterministic maze environment where theobservations are $64\times 64$ pixel bird's eye images and can show that itconsistently reaches several goals.</description><author>Marc Höftmann, Jan Robine, Stefan Harmeling</author><pubDate>Mon, 15 Apr 2024 09:45:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05044v2</guid></item><item><title>On the Convergence of Continual Learning with Adaptive Methods</title><link>http://arxiv.org/abs/2404.05555v2</link><description>One of the objectives of continual learning is to prevent catastrophicforgetting in learning multiple tasks sequentially, and the existing solutionshave been driven by the conceptualization of the plasticity-stability dilemma.However, the convergence of continual learning for each sequential task is lessstudied so far. In this paper, we provide a convergence analysis ofmemory-based continual learning with stochastic gradient descent and empiricalevidence that training current tasks causes the cumulative degradation ofprevious tasks. We propose an adaptive method for nonconvex continual learning(NCCL), which adjusts step sizes of both previous and current tasks with thegradients. The proposed method can achieve the same convergence rate as the SGDmethod when the catastrophic forgetting term which we define in the paper issuppressed at each iteration. Further, we demonstrate that the proposedalgorithm improves the performance of continual learning over existing methodsfor several image classification tasks.</description><author>Seungyub Han, Yeongmo Kim, Taehyun Cho, Jungwoo Lee</author><pubDate>Mon, 15 Apr 2024 09:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05555v2</guid></item><item><title>PEAN: A Diffusion-Based Prior-Enhanced Attention Network for Scene Text Image Super-Resolution</title><link>http://arxiv.org/abs/2311.17955v2</link><description>Scene text image super-resolution (STISR) aims at simultaneously increasingthe resolution and readability of low-resolution scene text images, thusboosting the performance of the downstream recognition task. Two factors inscene text images, visual structure and semantic information, affect therecognition performance significantly. To mitigate the effects from thesefactors, this paper proposes a Prior-Enhanced Attention Network (PEAN).Specifically, an attention-based modulation module is leveraged to understandscene text images by neatly perceiving the local and global dependence ofimages, despite the shape of the text. Meanwhile, a diffusion-based module isdeveloped to enhance the text prior, hence offering better guidance for the SRnetwork to generate SR images with higher semantic accuracy. Additionally, amulti-task learning paradigm is employed to optimize the network, enabling themodel to generate legible SR images. As a result, PEAN establishes new SOTAresults on the TextZoom benchmark. Experiments are also conducted to analyzethe importance of the enhanced text prior as a means of improving theperformance of the SR network. Code will be made available athttps://github.com/jdfxzzy/PEAN.</description><author>Zuoyan Zhao, Hui Xue, Pengfei Fang, Shipeng Zhu</author><pubDate>Mon, 15 Apr 2024 09:43:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17955v2</guid></item><item><title>Modelling Language</title><link>http://arxiv.org/abs/2404.09579v1</link><description>This paper argues that large language models have a valuable scientific roleto play in serving as scientific models of a language. Linguistic study shouldnot only be concerned with the cognitive processes behind linguisticcompetence, but also with language understood as an external, social entity.Once this is recognized, the value of large language models as scientificmodels becomes clear. This paper defends this position against a number ofarguments to the effect that language models provide no linguistic insight. Italso draws upon recent work in philosophy of science to show how large languagemodels could serve as scientific models.</description><author>Jumbly Grindrod</author><pubDate>Mon, 15 Apr 2024 09:40:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09579v1</guid></item><item><title>Transformers, Contextualism, and Polysemy</title><link>http://arxiv.org/abs/2404.09577v1</link><description>The transformer architecture, introduced by Vaswani et al. (2017), is at theheart of the remarkable recent progress in the development of language models,including famous chatbots such as Chat-gpt and Bard. In this paper, I arguethat we an extract from the way the transformer architecture works a picture ofthe relationship between context and meaning. I call this the transformerpicture, and I argue that it is a novel with regard to two relatedphilosophical debates: the contextualism debate regarding the extent ofcontext-sensitivity across natural language, and the polysemy debate regardinghow polysemy should be captured within an account of word meaning. Althoughmuch of the paper merely tries to position the transformer picture with respectto these two debates, I will also begin to make the case for the transformerpicture.</description><author>Jumbly Grindrod</author><pubDate>Mon, 15 Apr 2024 09:38:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09577v1</guid></item><item><title>Do More With What You Have: Transferring Depth-Scale from Labeled to Unlabeled Domains</title><link>http://arxiv.org/abs/2303.07662v3</link><description>Transferring the absolute depth prediction capabilities of an estimator to anew domain is a task with significant real-world applications. This task isspecifically challenging when images from the new domain are collected withoutground-truth depth measurements, and possibly with sensors of differentintrinsics. To overcome such limitations, a recent zero-shot solution wastrained on an extensive training dataset and encoded the various cameraintrinsics. Other solutions generated synthetic data with depth labels thatmatched the intrinsics of the new target data to enable depth-scale transferbetween the domains. In this work we present an alternative solution that can utilize any existingsynthetic or real dataset, that has a small number of images annotated withground truth depth labels. Specifically, we show that self-supervised depthestimators result in up-to-scale predictions that are linearly correlated totheir absolute depth values across the domain, a property that we model in thiswork using a single scalar. In addition, aligning the field-of-view of twodatasets prior to training, results in a common linear relationship for bothdomains. We use this observed property to transfer the depth-scale from sourcedatasets that have absolute depth labels to new target datasets that lack thesemeasurements, enabling absolute depth predictions in the target domain. The suggested method was successfully demonstrated on the KITTI, DDAD andnuScenes datasets, while using other existing real or synthetic sourcedatasets, that have a different field-of-view, other image style or structuralcontent, achieving comparable or better accuracy than other existing methodsthat do not use target ground-truth depths.</description><author>Alexandra Dana, Nadav Carmel, Amit Shomer, Ofer Manela, Tomer Peleg</author><pubDate>Mon, 15 Apr 2024 09:37:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07662v3</guid></item></channel></rss>