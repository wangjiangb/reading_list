<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 21 Nov 2024 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Generative World Explorer</title><link>http://arxiv.org/abs/2411.11844v2</link><description>Planning with partial observation is a central challenge in embodied AI. Amajority of prior works have tackled this challenge by developing agents thatphysically explore their environment to update their beliefs about the worldstate. In contrast, humans can $\textit{imagine}$ unseen parts of the worldthrough a mental exploration and $\textit{revise}$ their beliefs with imaginedobservations. Such updated beliefs can allow them to make more informeddecisions, without necessitating the physical exploration of the world at alltimes. To achieve this human-like ability, we introduce the $\textit{GenerativeWorld Explorer (Genex)}$, an egocentric world exploration framework that allowsan agent to mentally explore a large-scale 3D world (e.g., urban scenes) andacquire imagined observations to update its belief. This updated belief willthen help the agent to make a more informed decision at the current step. Totrain $\textit{Genex}$, we create a synthetic urban scene dataset, Genex-DB.Our experimental results demonstrate that (1) $\textit{Genex}$ can generatehigh-quality and consistent observations during long-horizon exploration of alarge virtual physical world and (2) the beliefs updated with the generatedobservations can inform an existing decision-making model (e.g., an LLM agent)to make better plans.</description><author>Taiming Lu, Tianmin Shu, Alan Yuille, Daniel Khashabi, Jieneng Chen</author><pubDate>Tue, 19 Nov 2024 18:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.11844v2</guid></item><item><title>ACING: Actor-Critic for Instruction Learning in Black-Box Large Language Models</title><link>http://arxiv.org/abs/2411.12736v1</link><description>The effectiveness of Large Language Models (LLMs) in solving tasks vastlydepends on the quality of the instructions, which often require fine-tuningthrough extensive human effort. This highlights the need for automatedinstruction optimization; however, this optimization is particularlychallenging when dealing with black-box LLMs, where model parameters andgradients remain inaccessible. We propose ACING, a task-specific promptoptimization approach framed as a stateless continuous-action ReinforcementLearning (RL) problem, known as the continuum bandit setting. ACING leveragesan actor-critic-based method to optimize prompts, learning fromnon-differentiable reward signals. We validate ACING by optimizing prompts forChatGPT on 30 instruction-based tasks. ACING consistently outperforms baselinemethods, achieving a median score improvement of 10 percentage points.Furthermore, ACING not only recovers but also surpasses human-crafted expertinstructions, achieving up to a 39 percentage point improvement against humanbenchmarks.</description><author>Salma Kharrat, Fares Fourati, Marco Canini</author><pubDate>Tue, 19 Nov 2024 18:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12736v1</guid></item><item><title>The More the Merrier: On Evolving Five-valued Spectra Boolean Functions</title><link>http://arxiv.org/abs/2411.12735v1</link><description>Evolving Boolean functions with specific properties is an interestingoptimization problem since, depending on the combination of properties andBoolean function size, the problem can range from very simple to (almost)impossible to solve. Moreover, some problems are more interesting as there maybe only a few options for generating the required Boolean functions. This paperinvestigates one such problem: evolving five-valued spectra Boolean functions,which are the functions whose Walsh-Hadamard coefficients can only take fivedistinct values. We experimented with three solution encodings, two fitnessfunctions, and 12 Boolean function sizes and showed that the tree encoding issuperior to other choices, as we can obtain five-valued Boolean functions withhigh nonlinearity.</description><author>Claude Carlet, Marko Ðurasevic, Domagoj Jakobovic, Luca Mariot, Stjepan Picek</author><pubDate>Tue, 19 Nov 2024 18:57:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12735v1</guid></item><item><title>Benchmarking Positional Encodings for GNNs and Graph Transformers</title><link>http://arxiv.org/abs/2411.12732v1</link><description>Recent advances in Graph Neural Networks (GNNs) and Graph Transformers (GTs)have been driven by innovations in architectures and Positional Encodings(PEs), which are critical for augmenting node features and capturing graphtopology. PEs are essential for GTs, where topological information wouldotherwise be lost without message-passing. However, PEs are often testedalongside novel architectures, making it difficult to isolate their effect onestablished models. To address this, we present a comprehensive benchmark ofPEs in a unified framework that includes both message-passing GNNs and GTs. Wealso establish theoretical connections between MPNNs and GTs and introduce asparsified GRIT attention mechanism to examine the influence of globalconnectivity. Our findings demonstrate that previously untested combinations ofGNN architectures and PEs can outperform existing methods and offer a morecomprehensive picture of the state-of-the-art. To support future research andexperimentation in our framework, we make the code publicly available.</description><author>Florian Grötschla, Jiaqing Xie, Roger Wattenhofer</author><pubDate>Tue, 19 Nov 2024 18:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12732v1</guid></item><item><title>Conformal Prediction for Class-wise Coverage via Augmented Label Rank Calibration</title><link>http://arxiv.org/abs/2406.06818v4</link><description>Conformal prediction (CP) is an emerging uncertainty quantification frameworkthat allows us to construct a prediction set to cover the true label with apre-specified marginal or conditional probability. Although the valid coverageguarantee has been extensively studied for classification problems, CP oftenproduces large prediction sets which may not be practically useful. This issueis exacerbated for the setting of class-conditional coverage on imbalancedclassification tasks with many and/or imbalanced classes. This paper proposesthe Rank Calibrated Class-conditional CP (RC3P) algorithm to reduce theprediction set sizes to achieve class-conditional coverage, where the validcoverage holds for each class. In contrast to the standard class-conditional CP(CCP) method that uniformly thresholds the class-wise conformity score for eachclass, the augmented label rank calibration step allows RC3P to selectivelyiterate this class-wise thresholding subroutine only for a subset of classeswhose class-wise top-k error is small. We prove that agnostic to the classifierand data distribution, RC3P achieves class-wise coverage. We also show thatRC3P reduces the size of prediction sets compared to the CCP method.Comprehensive experiments on multiple real-world datasets demonstrate that RC3Pachieves class-wise coverage and 26.25% reduction in prediction set sizes onaverage.</description><author>Yuanjie Shi, Subhankar Ghosh, Taha Belkhouja, Janardhan Rao Doppa, Yan Yan</author><pubDate>Tue, 19 Nov 2024 18:56:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06818v4</guid></item><item><title>Testing classical properties from quantum data</title><link>http://arxiv.org/abs/2411.12730v1</link><description>Many properties of Boolean functions can be tested far more efficiently thanthe function can be learned. However, this advantage often disappears whentesters are limited to random samples--a natural setting for datascience--rather than queries. In this work we investigate the quantum versionof this scenario: quantum algorithms that test properties of a function $f$solely from quantum data in the form of copies of the function state for $f$. For three well-established properties, we show that the speedup lost whenrestricting classical testers to samples can be recovered by testers that usequantum data. For monotonicity testing, we give a quantum algorithm that uses$\tilde{\mathcal{O}}(n^2)$ function state copies as compared to the$2^{\Omega(\sqrt{n})}$ samples required classically. We also present$\mathcal{O}(1)$-copy testers for symmetry and triangle-freeness, comparingfavorably to classical lower bounds of $\Omega(n^{1/4})$ and $\Omega(n)$samples respectively. These algorithms are time-efficient and necessarilyinclude techniques beyond the Fourier sampling approaches applied to earliertesting problems. These results make the case for a general study of the advantages afforded byquantum data for testing. We contribute to this project by complementing ourupper bounds with a lower bound of $\Omega(1/\varepsilon)$ for monotonicitytesting from quantum data in the proximity regime$\varepsilon\leq\mathcal{O}(n^{-3/2})$. This implies a strict separationbetween testing monotonicity from quantum data and from quantum queries--where$\tilde{\mathcal{O}}(n)$ queries suffice when $\varepsilon=\Theta(n^{-3/2})$.We also exhibit a testing problem that can be solved from $\mathcal{O}(1)$classical queries but requires $\Omega(2^{n/2})$ function state copies,complementing a separation of the same magnitude in the opposite directionderived from the Forrelation problem.</description><author>Matthias C. Caro, Preksha Naik, Joseph Slote</author><pubDate>Tue, 19 Nov 2024 18:52:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12730v1</guid></item><item><title>Information Theory of Meaningful Communication</title><link>http://arxiv.org/abs/2411.12728v1</link><description>In Shannon's seminal paper, entropy of printed English, treated as astationary stochastic process, was estimated to be roughly 1 bit per character.However, considered as a means of communication, language differs considerablyfrom its printed form: (i) the units of information are not characters or evenwords but clauses, i.e. shortest meaningful parts of speech; and (ii) what istransmitted is principally the meaning of what is being said or written, whilethe precise phrasing that was used to communicate the meaning is typicallyignored. In this study, we show that one can leverage recently developed largelanguage models to quantify information communicated in meaningful narrativesin terms of bits of meaning per clause.</description><author>Doron Sivan, Misha Tsodyks</author><pubDate>Tue, 19 Nov 2024 18:51:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12728v1</guid></item><item><title>Debiased Regression for Root-N-Consistent Conditional Mean Estimation</title><link>http://arxiv.org/abs/2411.11748v2</link><description>This study introduces a debiasing method for regression estimators, includinghigh-dimensional and nonparametric regression estimators. For example,nonparametric regression methods allow for the estimation of regressionfunctions in a data-driven manner with minimal assumptions; however, thesemethods typically fail to achieve $\sqrt{n}$-consistency in their convergencerates, and many, including those in machine learning, lack guarantees thattheir estimators asymptotically follow a normal distribution. To address thesechallenges, we propose a debiasing technique for nonparametric estimators byadding a bias-correction term to the original estimators, extending theconventional one-step estimator used in semiparametric analysis. Specifically,for each data point, we estimate the conditional expected residual of theoriginal nonparametric estimator, which can, for instance, be computed usingkernel (Nadaraya-Watson) regression, and incorporate it as a bias-reductionterm. Our theoretical analysis demonstrates that the proposed estimatorachieves $\sqrt{n}$-consistency and asymptotic normality under a mildconvergence rate condition for both the original nonparametric estimator andthe conditional expected residual estimator. Notably, this approach remainsmodel-free as long as the original estimator and the conditional expectedresidual estimator satisfy the convergence rate condition. The proposed methodoffers several advantages, including improved estimation accuracy andsimplified construction of confidence intervals.</description><author>Masahiro Kato</author><pubDate>Tue, 19 Nov 2024 18:50:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.11748v2</guid></item><item><title>LazyDINO: Fast, scalable, and efficiently amortized Bayesian inversion via structure-exploiting and surrogate-driven measure transport</title><link>http://arxiv.org/abs/2411.12726v1</link><description>We present LazyDINO, a transport map variational inference method for fast,scalable, and efficiently amortized solutions of high-dimensional nonlinearBayesian inverse problems with expensive parameter-to-observable (PtO) maps.Our method consists of an offline phase in which we construct aderivative-informed neural surrogate of the PtO map using joint samples of thePtO map and its Jacobian. During the online phase, when given observationaldata, we seek rapid posterior approximation using surrogate-driven training ofa lazy map [Brennan et al., NeurIPS, (2020)], i.e., a structure-exploitingtransport map with low-dimensional nonlinearity. The trained lazy map thenproduces approximate posterior samples or density evaluations. Our surrogateconstruction is optimized for amortized Bayesian inversion using lazy mapvariational inference. We show that (i) the derivative-based reduced basisarchitecture [O'Leary-Roseberry et al., Comput. Methods Appl. Mech. Eng., 388(2022)] minimizes the upper bound on the expected error in surrogate posteriorapproximation, and (ii) the derivative-informed training formulation[O'Leary-Roseberry et al., J. Comput. Phys., 496 (2024)] minimizes the expectederror due to surrogate-driven transport map optimization. Our numerical resultsdemonstrate that LazyDINO is highly efficient in cost amortization for Bayesianinversion. We observe one to two orders of magnitude reduction of offline costfor accurate posterior approximation, compared to simulation-based amortizedinference via conditional transport and conventional surrogate-driventransport. In particular, LazyDINO outperforms Laplace approximationconsistently using fewer than 1000 offline samples, while other amortizedinference methods struggle and sometimes fail at 16,000 offline samples.</description><author>Lianghao Cao, Joshua Chen, Michael Brennan, Thomas O'Leary-Roseberry, Youssef Marzouk, Omar Ghattas</author><pubDate>Tue, 19 Nov 2024 18:48:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12726v1</guid></item><item><title>Reinforcement Learning, Collusion, and the Folk Theorem</title><link>http://arxiv.org/abs/2411.12725v1</link><description>We explore the behaviour emerging from learning agents repeatedly interactingstrategically for a wide range of learning dynamics that includes projectedgradient, replicator and log-barrier dynamics. Going beyond thebetter-understood classes of potential games and zero-sum games, we considerthe setting of a general repeated game with finite recall, for different formsof monitoring. We obtain a Folk Theorem-like result and characterise the set ofpayoff vectors that can be obtained by these dynamics, discovering a wide rangeof possibilities for the emergence of algorithmic collusion.</description><author>Galit Askenazi-Golan, Domenico Mergoni Cecchelli, Edward Plumb</author><pubDate>Tue, 19 Nov 2024 18:45:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12725v1</guid></item><item><title>Heuristic-Free Multi-Teacher Learning</title><link>http://arxiv.org/abs/2411.12724v1</link><description>We introduce Teacher2Task, a novel framework for multi-teacher learning thateliminates the need for manual aggregation heuristics. Existing multi-teachermethods typically rely on such heuristics to combine predictions from multipleteachers, often resulting in sub-optimal aggregated labels and the propagationof aggregation errors. Teacher2Task addresses these limitations by introducingteacher-specific input tokens and reformulating the training process. Insteadof relying on aggregated labels, the framework transforms the training data,consisting of ground truth labels and annotations from N teachers, into N+1distinct tasks: N auxiliary tasks that predict the labeling styles of the Nindividual teachers, and one primary task that focuses on the ground truthlabels. This approach, drawing upon principles from multiple learningparadigms, demonstrates strong empirical results across a range ofarchitectures, modalities, and tasks.</description><author>Huy Thong Nguyen, En-Hung Chu, Lenord Melvix, Jazon Jiao, Chunglin Wen, Benjamin Louie</author><pubDate>Tue, 19 Nov 2024 18:45:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12724v1</guid></item><item><title>Scaling laws for nonlinear dynamical models of speech</title><link>http://arxiv.org/abs/2411.12720v1</link><description>The addition of a nonlinear restoring force to dynamical models of the speechgesture significantly improves the empirical accuracy of model predictions, butnonlinearity introduces challenges in selecting appropriate parameters andnumerical stability, especially when modelling variation in empirical data. Weaddress this issue by introducing simple numerical methods for parameterizationof nonlinear task dynamic models. We first illustrate the problem and thenoutline solutions in the form of power laws that scale nonlinear stiffnessterms. We apply the scaling laws to a cubic model and show how they facilitateinterpretable simulations of the nonlinear gestural dynamics underpinningspeech production.</description><author>Sam Kirkham</author><pubDate>Tue, 19 Nov 2024 18:38:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12720v1</guid></item><item><title>Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation</title><link>http://arxiv.org/abs/2411.12719v1</link><description>Despite rapid advancements in TTS models, a consistent and robust humanevaluation framework is still lacking. For example, MOS tests fail todifferentiate between similar models, and CMOS's pairwise comparisons aretime-intensive. The MUSHRA test is a promising alternative for evaluatingmultiple TTS systems simultaneously, but in this work we show that its relianceon matching human reference speech unduly penalises the scores of modern TTSsystems that can exceed human speech quality. More specifically, we conduct acomprehensive assessment of the MUSHRA test, focusing on its sensitivity tofactors such as rater variability, listener fatigue, and reference bias. Basedon our extensive evaluation involving 471 human listeners across Hindi andTamil we identify two primary shortcomings: (i) reference-matching bias, whereraters are unduly influenced by the human reference, and (ii) judgementambiguity, arising from a lack of clear fine-grained guidelines. To addressthese issues, we propose two refined variants of the MUSHRA test. The firstvariant enables fairer ratings for synthesized samples that surpass humanreference quality. The second variant reduces ambiguity, as indicated by therelatively lower variance across raters. By combining these approaches, weachieve both more reliable and more fine-grained assessments. We also releaseMANGO, a massive dataset of 47,100 human ratings, the first-of-its-kindcollection for Indian languages, aiding in analyzing human preferences anddeveloping automatic metrics for evaluating TTS systems.</description><author>Praveen Srinivasa Varadhan, Amogh Gulati, Ashwin Sankar, Srija Anand, Anirudh Gupta, Anirudh Mukherjee, Shiva Kumar Marepally, Ankur Bhatia, Saloni Jaju, Suvrat Bhooshan, Mitesh M. Khapra</author><pubDate>Tue, 19 Nov 2024 18:37:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12719v1</guid></item><item><title>CATCH: Complementary Adaptive Token-level Contrastive Decoding to Mitigate Hallucinations in LVLMs</title><link>http://arxiv.org/abs/2411.12713v1</link><description>Large Vision-Language Model (LVLM) systems have demonstrated impressivevision-language reasoning capabilities but suffer from pervasive and severehallucination issues, posing significant risks in critical domains such ashealthcare and autonomous systems. Despite previous efforts to mitigatehallucinations, a persistent issue remains: visual defect from vision-languagemisalignment, creating a bottleneck in visual processing capacity. To addressthis challenge, we develop Complementary Adaptive Token-level ContrastiveDecoding to Mitigate Hallucinations in LVLMs (CATCH), based on the InformationBottleneck theory. CATCH introduces Complementary Visual Decoupling (CVD) forvisual information separation, Non-Visual Screening (NVS) for hallucinationdetection, and Adaptive Token-level Contrastive Decoding (ATCD) forhallucination mitigation. CATCH addresses issues related to visual defects thatcause diminished fine-grained feature perception and cumulative hallucinationsin open-ended scenarios. It is applicable to various visual question-answeringtasks without requiring any specific data or prior knowledge, and generalizesrobustly to new tasks without additional training, opening new possibilitiesfor advancing LVLM in various challenging applications.</description><author>Zhehan Kan, Ce Zhang, Zihan Liao, Yapeng Tian, Wenming Yang, Junyuan Xiao, Xu Li, Dongmei Jiang, Yaowei Wang, Qingmin Liao</author><pubDate>Tue, 19 Nov 2024 18:27:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12713v1</guid></item><item><title>Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs</title><link>http://arxiv.org/abs/2411.12712v1</link><description>In this research, we explored the improvement in terms of multi-class diseaseclassification via pre-trained language models over Medical-Abstracts-TC-Corpusthat spans five medical conditions. We excluded non-cancer conditions andexamined four specific diseases. We assessed four LLMs, BioBERT, XLNet, andBERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trainedon medical data, demonstrated superior performance in medical textclassification (97% accuracy). Surprisingly, XLNet followed closely (96%accuracy), demonstrating its generalizability across domains even though it wasnot pre-trained on medical data. LastBERT, a custom model based on the lighterversion of BERT, also proved competitive with 87.10% accuracy (just underBERT's 89.33%). Our findings confirm the importance of specialized models suchas BioBERT and also support impressions around more general solutions likeXLNet and well-tuned transformer architectures with fewer parameters (in thiscase, LastBERT) in medical domain tasks.</description><author>Ahmed Akib Jawad Karim, Muhammad Zawad Mahmud, Samiha Islam, Aznur Azam</author><pubDate>Tue, 19 Nov 2024 18:27:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12712v1</guid></item><item><title>GraphSnapShot: Graph Machine Learning Acceleration with Fast Storage and Retrieval</title><link>http://arxiv.org/abs/2406.17918v3</link><description>In our recent research, we have developed a framework called GraphSnapShot,which has been proven an useful tool for graph learning acceleration.GraphSnapShot is a framework for fast cache, storage, retrieval and computationfor graph learning. It can quickly store and update the local topology of graphstructure and allows us to track patterns in the structure of graph networks,just like take snapshots of the graphs. In experiments, GraphSnapShot showsefficiency, it can achieve up to 30% training acceleration and 73% memoryreduction for lossless graph ML training compared to current baselines such asdgl.This technique is particular useful for large dynamic graph learning taskssuch as social media analysis and recommendation systems to process complexrelationships between entities. The code for GraphSnapShot is publicly available athttps://github.com/NoakLiu/GraphSnapShot.</description><author>Dong Liu, Roger Waleffe, Meng Jiang, Shivaram Venkataraman</author><pubDate>Tue, 19 Nov 2024 18:24:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17918v3</guid></item><item><title>Barttender: An approachable &amp; interpretable way to compare medical imaging and non-imaging data</title><link>http://arxiv.org/abs/2411.12707v1</link><description>Imaging-based deep learning has transformed healthcare research, yet itsclinical adoption remains limited due to challenges in comparing imaging modelswith traditional non-imaging and tabular data. To bridge this gap, we introduceBarttender, an interpretable framework that uses deep learning for the directcomparison of the utility of imaging versus non-imaging tabular data for taskslike disease prediction. Barttender converts non-imaging tabular features, such as scalar data fromelectronic health records, into grayscale bars, facilitating an interpretableand scalable deep learning based modeling of both data modalities. Ourframework allows researchers to evaluate differences in utility throughperformance measures, as well as local (sample-level) and global(population-level) explanations. We introduce a novel measure to define globalfeature importances for image-based deep learning models, which we call gIoU.Experiments on the CheXpert and MIMIC datasets with chest X-rays and scalardata from electronic health records show that Barttender performs comparably totraditional methods and offers enhanced explainability using deep learningmodels.</description><author>Ayush Singla, Shakson Isaac, Chirag J. Patel</author><pubDate>Tue, 19 Nov 2024 18:22:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12707v1</guid></item><item><title>Regulating Chatbot Output via Inter-Informational Competition</title><link>http://arxiv.org/abs/2403.11046v2</link><description>The advent of ChatGPT has sparked over a year of regulatory frenzy. However,few existing studies have rigorously questioned the assumption that, if leftunregulated, AI chatbot's output would inflict tangible, severe real harm onhuman affairs. Most researchers have overlooked the critical possibility thatthe information market itself can effectively mitigate these risks and, as aresult, they tend to use regulatory tools to address the issue directly. ThisArticle develops a yardstick for reevaluating both AI-related content risks andcorresponding regulatory proposals by focusing on inter-informationalcompetition among various outlets. The decades-long history of regulatinginformation and communications technologies indicates that regulators tend toerr too much on the side of caution and to put forward excessive regulatorymeasures when encountering the uncertainties brought about by new technologies.In fact, a trove of empirical evidence has demonstrated that market competitionamong information outlets can effectively mitigate most risks and thatoverreliance on regulation is not only unnecessary but detrimental, as well.This Article argues that sufficient competition among chatbots and otherinformation outlets in the information marketplace can sufficiently mitigateand even resolve most content risks posed by generative AI technologies. Thisrenders certain loudly advocated regulatory strategies, like mandatoryprohibitions, licensure, curation of datasets, and notice-and-response regimes,truly unnecessary and even toxic to desirable competition and innovationthroughout the AI industry. Ultimately, the ideas that I advance in thisArticle should pour some much-needed cold water on the regulatory frenzy overgenerative AI and steer the issue back to a rational track.</description><author>Jiawei Zhang</author><pubDate>Tue, 19 Nov 2024 18:18:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11046v2</guid></item><item><title>Strengthening Fake News Detection: Leveraging SVM and Sophisticated Text Vectorization Techniques. Defying BERT?</title><link>http://arxiv.org/abs/2411.12703v1</link><description>The rapid spread of misinformation, particularly through online platforms,underscores the urgent need for reliable detection systems. This study exploresthe utilization of machine learning and natural language processing,specifically Support Vector Machines (SVM) and BERT, to detect news that arefake. We employ three distinct text vectorization methods for SVM: TermFrequency Inverse Document Frequency (TF-IDF), Word2Vec, and Bag of Words (BoW)evaluating their effectiveness in distinguishing between genuine and fake news.Additionally, we compare these methods against the transformer large languagemodel, BERT. Our comprehensive approach includes detailed preprocessing steps,rigorous model implementation, and thorough evaluation to determine the mosteffective techniques. The results demonstrate that while BERT achieves superioraccuracy with 99.98% and an F1-score of 0.9998, the SVM model with a linearkernel and BoW vectorization also performs exceptionally well, achieving 99.81%accuracy and an F1-score of 0.9980. These findings highlight that, despiteBERT's superior performance, SVM models with BoW and TF-IDF vectorizationmethods come remarkably close, offering highly competitive performance with theadvantage of lower computational requirements.</description><author>Ahmed Akib Jawad Karim, Kazi Hafiz Md Asad, Aznur Azam</author><pubDate>Tue, 19 Nov 2024 18:15:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12703v1</guid></item><item><title>KTO: Model Alignment as Prospect Theoretic Optimization</title><link>http://arxiv.org/abs/2402.01306v4</link><description>Kahneman &amp; Tversky's $\textit{prospect theory}$ tells us that humans perceiverandom variables in a biased but well-defined manner (1992); for example,humans are famously loss-averse. We show that objectives for aligning LLMs withhuman feedback implicitly incorporate many of these biases -- the success ofthese objectives (e.g., DPO) over cross-entropy minimization can partly beascribed to them belonging to a family of loss functions that we call$\textit{human-aware losses}$ (HALOs). However, the utility functions thesemethods attribute to humans still differ from those in the prospect theoryliterature. Using a Kahneman-Tversky model of human utility, we propose a HALOthat directly maximizes the utility of generations instead of maximizing thelog-likelihood of preferences, as current methods do. We call this approachKTO, and it matches or exceeds the performance of preference-based methods atscales from 1B to 30B, despite only learning from a binary signal of whether anoutput is desirable. More broadly, our work suggests that there is no one HALOthat is universally superior; the best loss depends on the inductive biasesmost appropriate for a given setting, an oft-overlooked consideration.</description><author>Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, Douwe Kiela</author><pubDate>Tue, 19 Nov 2024 18:12:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01306v4</guid></item><item><title>When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations</title><link>http://arxiv.org/abs/2411.12701v1</link><description>Large Language Models (LLMs) are vulnerable to backdoor attacks, where hiddentriggers can maliciously manipulate model behavior. While several backdoorattack methods have been proposed, the mechanisms by which backdoor functionsoperate in LLMs remain underexplored. In this paper, we move beyond attackingLLMs and investigate backdoor functionality through the novel lens of naturallanguage explanations. Specifically, we leverage LLMs' generative capabilitiesto produce human-understandable explanations for their decisions, allowing usto compare explanations for clean and poisoned samples. We explore variousbackdoor attacks and embed the backdoor into LLaMA models for multiple tasks.Our experiments show that backdoored models produce higher-quality explanationsfor clean data compared to poisoned data, while generating significantly moreconsistent explanations for poisoned data than for clean data. We furtheranalyze the explanation generation process, revealing that at the token level,the explanation token of poisoned samples only appears in the final fewtransformer layers of the LLM. At the sentence level, attention dynamicsindicate that poisoned inputs shift attention from the input context whengenerating the explanation. These findings deepen our understanding of backdoorattack mechanisms in LLMs and offer a framework for detecting suchvulnerabilities through explainability techniques, contributing to thedevelopment of more secure LLMs.</description><author>Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang</author><pubDate>Tue, 19 Nov 2024 18:11:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12701v1</guid></item><item><title>Learning multivariate Gaussians with imperfect advice</title><link>http://arxiv.org/abs/2411.12700v1</link><description>We revisit the problem of distribution learning within the framework oflearning-augmented algorithms. In this setting, we explore the scenario where aprobability distribution is provided as potentially inaccurate advice on thetrue, unknown distribution. Our objective is to develop learning algorithmswhose sample complexity decreases as the quality of the advice improves,thereby surpassing standard learning lower bounds when the advice issufficiently accurate. Specifically, we demonstrate that this outcome is achievable for the problemof learning a multivariate Gaussian distribution $N(\boldsymbol{\mu},\boldsymbol{\Sigma})$ in the PAC learning setting. Classically, in theadvice-free setting, $\tilde{\Theta}(d^2/\varepsilon^2)$ samples are sufficientand worst case necessary to learn $d$-dimensional Gaussians up to TV distance$\varepsilon$ with constant probability. When we are additionally given aparameter $\tilde{\boldsymbol{\Sigma}}$ as advice, we show that$\tilde{O}(d^{2-\beta}/\varepsilon^2)$ samples suffices whenever $\|\tilde{\boldsymbol{\Sigma}}^{-1/2} \boldsymbol{\Sigma}\tilde{\boldsymbol{\Sigma}}^{-1/2} - \boldsymbol{I_d} \|_1 \leq \varepsilond^{1-\beta}$ (where $\|\cdot\|_1$ denotes the entrywise $\ell_1$ norm) for any$\beta &gt; 0$, yielding a polynomial improvement over the advice-free setting.</description><author>Arnab Bhattacharyya, Davin Choo, Philips George John, Themis Gouleakis</author><pubDate>Tue, 19 Nov 2024 18:08:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12700v1</guid></item><item><title>Attribute Inference Attacks for Federated Regression Tasks</title><link>http://arxiv.org/abs/2411.12697v1</link><description>Federated Learning (FL) enables multiple clients, such as mobile phones andIoT devices, to collaboratively train a global machine learning model whilekeeping their data localized. However, recent studies have revealed that thetraining phase of FL is vulnerable to reconstruction attacks, such as attributeinference attacks (AIA), where adversaries exploit exchanged messages andauxiliary public information to uncover sensitive attributes of targetedclients. While these attacks have been extensively studied in the context ofclassification tasks, their impact on regression tasks remains largelyunexplored. In this paper, we address this gap by proposing novel model-basedAIAs specifically designed for regression tasks in FL environments. Ourapproach considers scenarios where adversaries can either eavesdrop onexchanged messages or directly interfere with the training process. Webenchmark our proposed attacks against state-of-the-art methods usingreal-world datasets. The results demonstrate a significant increase inreconstruction accuracy, particularly in heterogeneous client datasets, acommon scenario in FL. The efficacy of our model-based AIAs makes them bettercandidates for empirically quantifying privacy leakage for federated regressiontasks.</description><author>Francesco Diana, Othmane Marfoq, Chuan Xu, Giovanni Neglia, Frédéric Giroire, Eoin Thomas</author><pubDate>Tue, 19 Nov 2024 18:06:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12697v1</guid></item><item><title>AdaCM$^2$: On Understanding Extremely Long-Term Video with Adaptive Cross-Modality Memory Reduction</title><link>http://arxiv.org/abs/2411.12593v1</link><description>The advancements in large language models (LLMs) have propelled theimprovement of video understanding tasks by incorporating LLMs with visualmodels. However, most existing LLM-based models (e.g., VideoLLaMA, VideoChat)are constrained to processing short-duration videos. Recent attempts tounderstand long-term videos by extracting and compressing visual features intoa fixed memory size. Nevertheless, those methods leverage only visual modalityto merge video tokens and overlook the correlation between visual and textualqueries, leading to difficulties in effectively handling complexquestion-answering tasks. To address the challenges of long videos and complexprompts, we propose AdaCM$^2$, which, for the first time, introduces anadaptive cross-modality memory reduction approach to video-text alignment in anauto-regressive manner on video streams. Our extensive experiments on variousvideo understanding tasks, such as video captioning, video question answering,and video classification, demonstrate that AdaCM$^2$ achieves state-of-the-artperformance across multiple datasets while significantly reducing memory usage.Notably, it achieves a 4.5% improvement across multiple tasks in the LVUdataset with a GPU memory consumption reduction of up to 65%.</description><author>Yuanbin Man, Ying Huang, Chengming Zhang, Bingzhe Li, Wei Niu, Miao Yin</author><pubDate>Tue, 19 Nov 2024 18:04:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12593v1</guid></item><item><title>IMUVIE: Pickup Timeline Action Localization via Motion Movies</title><link>http://arxiv.org/abs/2411.12689v1</link><description>Falls among seniors due to difficulties with tasks such as picking up objectspose significant health and safety risks, impacting quality of life andindependence. Reliable, accessible assessment tools are critical for earlyintervention but often require costly clinic-based equipment and trainedpersonnel, limiting their use in daily life. Existing wearable-based pickupmeasurement solutions address some needs but face limitations ingeneralizability. We present IMUVIE, a wearable system that uses motion movies and amachine-learning model to automatically detect and measure pickup events,providing a practical solution for frequent monitoring. IMUVIE's designprinciples-data normalization, occlusion handling, and streamlinedvisuals-enhance model performance and are adaptable to tasks beyond pickupclassification. In rigorous leave one subject out cross validation evaluations, IMUVIEachieves exceptional window level localization accuracy of 91-92% for pickupaction classification on 256,291 motion movie frame candidates whilemaintaining an event level recall of 97% when evaluated on 129 pickup events.IMUVIE has strong generalization and performs well on unseen subjects. In aninterview survey, IMUVIE demonstrated strong user interest and trust, with easeof use identified as the most critical factor for adoption. IMUVIE offers apractical, at-home solution for fall risk assessment, facilitating earlydetection of movement deterioration, and supporting safer, independent livingfor seniors.</description><author>John Clapham, Kenneth Koltermann, Yanfu Zhang, Yuming Sun, Evie N Burnet, Gang Zhou</author><pubDate>Tue, 19 Nov 2024 17:53:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12689v1</guid></item><item><title>Is Programming by Example solved by LLMs?</title><link>http://arxiv.org/abs/2406.08316v3</link><description>Programming-by-Examples (PBE) aims to generate an algorithm from input-outputexamples. Such systems are practically and theoretically important: from anend-user perspective, they are deployed to millions of people, and from an AIperspective, PBE corresponds to a very general form of few-shot inductiveinference. Given the success of Large Language Models (LLMs) in code-generationtasks, we investigate here the extent to which LLMs can be said to have"solved" PBE. We experiment on classic domains such as lists and strings, andan uncommon graphics programming domain not well represented in typicalpretraining data. We find that pretrained models are not effective at PBE, butthat they can be fine-tuned for much higher performance, provided the testproblems are in-distribution. We analyze empirically what causes these modelsto succeed and fail, and take steps toward understanding how to achieve betterout-of-distribution generalization. Collectively these results suggest thatLLMs make strong progress toward solving the typical suite of PBE tasks,potentially increasing the flexibility and applicability of PBE systems, whilealso identifying ways in which LLMs still fall short.</description><author>Wen-Ding Li, Kevin Ellis</author><pubDate>Tue, 19 Nov 2024 17:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08316v3</guid></item><item><title>A Demonstration of Adaptive Collaboration of Large Language Models for Medical Decision-Making</title><link>http://arxiv.org/abs/2411.00248v2</link><description>Medical Decision-Making (MDM) is a multi-faceted process that requiresclinicians to assess complex multi-modal patient data patient, oftencollaboratively. Large Language Models (LLMs) promise to streamline thisprocess by synthesizing vast medical knowledge and multi-modal health data.However, single-agent are often ill-suited for nuanced medical contextsrequiring adaptable, collaborative problem-solving. Our MDAgents addresses thisneed by dynamically assigning collaboration structures to LLMs based on taskcomplexity, mimicking real-world clinical collaboration and decision-making.This framework improves diagnostic accuracy and supports adaptive responses incomplex, real-world medical scenarios, making it a valuable tool for cliniciansin various healthcare settings, and at the same time, being more efficient interms of computing cost than static multi-agent decision making methods.</description><author>Yubin Kim, Chanwoo Park, Hyewon Jeong, Cristina Grau-Vilchez, Yik Siu Chan, Xuhai Xu, Daniel McDuff, Hyeonhoon Lee, Cynthia Breazeal, Hae Won Park</author><pubDate>Tue, 19 Nov 2024 17:46:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.00248v2</guid></item><item><title>VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?</title><link>http://arxiv.org/abs/2411.10979v2</link><description>The advancement of Multimodal Large Language Models (MLLMs) has enabledsignificant progress in multimodal understanding, expanding their capacity toanalyze video content. However, existing evaluation benchmarks for MLLMsprimarily focus on abstract video comprehension, lacking a detailed assessmentof their ability to understand video compositions, the nuanced interpretationof how visual elements combine and interact within highly compiled videocontexts. We introduce VidComposition, a new benchmark specifically designed toevaluate the video composition understanding capabilities of MLLMs usingcarefully curated compiled videos and cinematic-level annotations.VidComposition includes 982 videos with 1706 multiple-choice questions,covering various compositional aspects such as camera movement, angle, shotsize, narrative structure, character actions and emotions, etc. Ourcomprehensive evaluation of 33 open-source and proprietary MLLMs reveals asignificant performance gap between human and model capabilities. Thishighlights the limitations of current MLLMs in understanding complex, compiledvideo compositions and offers insights into areas for further improvement. Theleaderboard and evaluation code are available athttps://yunlong10.github.io/VidComposition/.</description><author>Yunlong Tang, Junjia Guo, Hang Hua, Susan Liang, Mingqian Feng, Xinyang Li, Rui Mao, Chao Huang, Jing Bi, Zeliang Zhang, Pooyan Fazli, Chenliang Xu</author><pubDate>Tue, 19 Nov 2024 17:46:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10979v2</guid></item><item><title>Enhanced Sign Language Translation between American Sign Language (ASL) and Indian Sign Language (ISL) Using LLMs</title><link>http://arxiv.org/abs/2411.12685v1</link><description>We have come up with a research that hopes to provide a bridge between theusers of American Sign Language and the users of spoken language and IndianSign Language (ISL). The research enabled us to create a novel framework thatwe have developed for Learner Systems. Leveraging art of Large models to createkey features including: - Real-time translation between these two signlanguages in an efficient manner. Making LLM's capability available forseamless translations to ISL. Here is the full study showing its implementationin this paper. The core of the system is a sophisticated pipeline that beginswith reclassification and recognition of ASL gestures based on a strong RandomForest Classifier. By recognizing the ASL, it is translated into text which canbe more easily processed. Highly evolved natural language NLP (Natural LanguageProcessing) techniques come in handy as they play a role in our LLM integrationwhere you then use LLMs to be able to convert the ASL text to ISL whichprovides you with the intent of sentence or phrase. The final step is tosynthesize the translated text back into ISL gestures, creating an end-to-endtranslation experience using RIFE-Net. This framework is tasked with keychallenges such as automatically dealing with gesture variability andovercoming the linguistic differences between ASL and ISL. By automating thetranslation process, we hope to vastly improve accessibility for sign languageusers. No longer will the communication gap between ASL and ISL createbarriers; this totally cool innovation aims to bring our communities closertogether. And we believe, with full confidence in our framework, that we'reable to apply the same principles across a wide variety of sign languagedialects.</description><author>Malay Kumar, S. Sarvajit Visagan, Tanish Sarang Mahajan, Anisha Natarajan</author><pubDate>Tue, 19 Nov 2024 17:45:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12685v1</guid></item><item><title>RLtools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control</title><link>http://arxiv.org/abs/2306.03530v4</link><description>Deep Reinforcement Learning (RL) can yield capable agents and controlpolicies in several domains but is commonly plagued by prohibitively longtraining times. Additionally, in the case of continuous control problems, theapplicability of learned policies on real-world embedded devices is limited dueto the lack of real-time guarantees and portability of existing libraries. Toaddress these challenges, we present RLtools, a dependency-free, header-only,pure C++ library for deep supervised and reinforcement learning. Its novelarchitecture allows RLtools to be used on a wide variety of platforms, from HPCclusters over workstations and laptops to smartphones, smartwatches, andmicrocontrollers. Specifically, due to the tight integration of the RLalgorithms with simulation environments, RLtools can solve popular RL problemsup to 76 times faster than other popular RL frameworks. We also benchmark theinference on a diverse set of microcontrollers and show that in most cases ouroptimized implementation is by far the fastest. Finally, RLtools enables thefirst-ever demonstration of training a deep RL algorithm directly on amicrocontroller, giving rise to the field of TinyRL. The source code as well asdocumentation and live demos are available through our project page athttps://rl.tools.</description><author>Jonas Eschmann, Dario Albani, Giuseppe Loianno</author><pubDate>Tue, 19 Nov 2024 17:41:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03530v4</guid></item><item><title>AI Guided Early Screening of Cervical Cancer</title><link>http://arxiv.org/abs/2411.12681v1</link><description>In order to support the creation of reliable machine learning models foranomaly detection, this project focuses on preprocessing, enhancing, andorganizing a medical imaging dataset. There are two classifications in thedataset: normal and abnormal, along with extra noise fluctuations. In order toimprove the photographs' quality, undesirable artifacts, including visiblemedical equipment at the edges, were eliminated using central cropping.Adjusting the brightness and contrast was one of the additional preprocessingprocesses. Normalization was then performed to normalize the data. To makeclassification jobs easier, the dataset was methodically handled by combiningseveral image subsets into two primary categories: normal and pathological. Toprovide a strong training set that adapts well to real-world situations,sophisticated picture preprocessing techniques were used, such as contrastenhancement and real-time augmentation (including rotations, zooms, andbrightness modifications). To guarantee efficient model evaluation, the datawas subsequently divided into training and testing subsets. In order to createprecise and effective machine learning models for medical anomaly detection,high-quality input data is ensured via this thorough approach. Because of theproject pipeline's flexible and scalable design, it can be easily integratedwith bigger clinical decision-support systems.</description><author>Dharanidharan S I, Suhitha Renuka S V, Ajishi Singh, Sheena Christabel Pravin</author><pubDate>Tue, 19 Nov 2024 17:39:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12681v1</guid></item><item><title>Realised Volatility Forecasting: Machine Learning via Financial Word Embedding</title><link>http://arxiv.org/abs/2108.00480v4</link><description>This study develops a financial word embedding using 15 years of businessnews. Our results show that this specialised language model produces moreaccurate results than general word embeddings, based on a financial benchmarkwe established. As an application, we incorporate this word embedding into asimple machine learning model to enhance the HAR model for forecasting realisedvolatility. This approach statistically and economically outperformsestablished econometric models. Using an explainable AI method, we alsoidentify key phrases in business news that contribute significantly tovolatility, offering insights into language patterns tied to market dynamics.</description><author>Eghbal Rahimikia, Stefan Zohren, Ser-Huang Poon</author><pubDate>Tue, 19 Nov 2024 17:33:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.00480v4</guid></item><item><title>Deep Learning-Driven Heat Map Analysis for Evaluating thickness of Wounded Skin Layers</title><link>http://arxiv.org/abs/2411.12678v1</link><description>Understanding the appropriate skin layer thickness in wounded sites is animportant tool to move forward on wound healing practices and treatmentprotocols. Methods to measure depth often are invasive and less specific. Thispaper introduces a novel method that is non-invasive with deep learningtechniques using classifying of skin layers that helps in measurement of wounddepth through heatmap analysis. A set of approximately 200 labeled images ofskin allows five classes to be distinguished: scars, wounds, and healthy skin,among others. Each image has annotated key layers, namely the stratum cornetum,the epidermis, and the dermis, in the software Roboflow. In the preliminarystage, the Heatmap generator VGG16 was used to enhance the visibility of tissuelayers, based upon which their annotated images were used to train ResNet18with early stopping techniques. It ended up at a very high accuracy rate of97.67%. To do this, the comparison of the models ResNet18, VGG16, DenseNet121,and EfficientNet has been done where both EfficientNet and ResNet18 haveattained accuracy rates of almost 95.35%. For further hyperparameter tuning,EfficientNet and ResNet18 were trained at six different learning rates todetermine the best model configuration. It has been noted that the accuracy hashuge variations with different learning rates. In the case of EfficientNet, themaximum achievable accuracy was 95.35% at the rate of 0.0001. The same was truefor ResNet18, which also attained its peak value of 95.35% at the same rate.These facts indicate that the model can be applied and utilized in actual-time,non-invasive wound assessment, which holds a great promise to improve clinicaldiagnosis and treatment planning.</description><author>Devakumar GR, JB Kaarthikeyan, Dominic Immanuel T, Sheena Christabel Pravin</author><pubDate>Tue, 19 Nov 2024 17:31:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12678v1</guid></item><item><title>IoT-Based 3D Pose Estimation and Motion Optimization for Athletes: Application of C3D and OpenPose</title><link>http://arxiv.org/abs/2411.12676v1</link><description>This study proposes the IoT-Enhanced Pose Optimization Network (IE-PONet) forhigh-precision 3D pose estimation and motion optimization of track and fieldathletes. IE-PONet integrates C3D for spatiotemporal feature extraction,OpenPose for real-time keypoint detection, and Bayesian optimization forhyperparameter tuning. Experimental results on NTURGB+D and FineGYM datasetsdemonstrate superior performance, with AP\(^p50\) scores of 90.5 and 91.0, andmAP scores of 74.3 and 74.0, respectively. Ablation studies confirm theessential roles of each module in enhancing model accuracy. IE-PONet provides arobust tool for athletic performance analysis and optimization, offeringprecise technical insights for training and injury prevention. Future work willfocus on further model optimization, multimodal data integration, anddeveloping real-time feedback mechanisms to enhance practical applications.</description><author>Fei Ren, Chao Ren, Tianyi Lyu</author><pubDate>Tue, 19 Nov 2024 17:29:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12676v1</guid></item><item><title>Combining Induction and Transduction for Abstract Reasoning</title><link>http://arxiv.org/abs/2411.02272v3</link><description>When learning an input-output mapping from very few examples, is it better tofirst infer a latent function that explains the examples, or is it better todirectly predict new test outputs, e.g. using a neural network? We study thisquestion on ARC, a highly diverse dataset of abstract reasoning tasks. We trainneural models for induction (inferring latent functions) and transduction(directly predicting the test output for a given test input). Our models aretrained on synthetic data generated by prompting LLMs to produce Python codespecifying a function to be inferred, plus a stochastic subroutine forgenerating inputs to that function. We find inductive and transductive modelssolve very different problems, despite training on the same problems, anddespite sharing the same neural architecture.</description><author>Wen-Ding Li, Keya Hu, Carter Larsen, Yuqing Wu, Simon Alford, Caleb Woo, Spencer M. Dunn, Hao Tang, Michelangelo Naim, Dat Nguyen, Wei-Long Zheng, Zenna Tavares, Yewen Pu, Kevin Ellis</author><pubDate>Tue, 19 Nov 2024 17:29:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.02272v3</guid></item><item><title>Neurosymbolic Graph Enrichment for Grounded World Models</title><link>http://arxiv.org/abs/2411.12671v1</link><description>The development of artificial intelligence systems capable of understandingand reasoning about complex real-world scenarios is a significant challenge. Inthis work we present a novel approach to enhance and exploit LLM reactivecapability to address complex problems and interpret deeply contextualreal-world meaning. We introduce a method and a tool for creating a multimodal,knowledge-augmented formal representation of meaning that combines thestrengths of large language models with structured semantic representations.Our method begins with an image input, utilizing state-of-the-art largelanguage models to generate a natural language description. This description isthen transformed into an Abstract Meaning Representation (AMR) graph, which isformalized and enriched with logical design patterns, and layered semanticsderived from linguistic and factual knowledge bases. The resulting graph isthen fed back into the LLM to be extended with implicit knowledge activated bycomplex heuristic learning, including semantic implicatures, moral values,embodied cognition, and metaphorical representations. By bridging the gapbetween unstructured language models and formal semantic structures, our methodopens new avenues for tackling intricate problems in natural languageunderstanding and reasoning.</description><author>Stefano De Giorgis, Aldo Gangemi, Alessandro Russo</author><pubDate>Tue, 19 Nov 2024 17:23:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12671v1</guid></item><item><title>Machine Learning Approaches on Crop Pattern Recognition a Comparative Analysis</title><link>http://arxiv.org/abs/2411.12667v1</link><description>Monitoring agricultural activities is important to ensure food security.Remote sensing plays a significant role for large-scale continuous monitoringof cultivation activities. Time series remote sensing data were used for thegeneration of the cropping pattern. Classification algorithms are used toclassify crop patterns and mapped agriculture land used. Some conventionalclassification methods including support vector machine (SVM) and decisiontrees were applied for crop pattern recognition. However, in this paper, we areproposing Deep Neural Network (DNN) based classification to improve theperformance of crop pattern recognition and make a comparative analysis withtwo (2) other machine learning approaches including Naive Bayes and RandomForest.</description><author>Kazi Hasibul Kabir, Md. Zahiruddin Aqib, Sharmin Sultana, Shamim Akhter</author><pubDate>Tue, 19 Nov 2024 17:19:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12667v1</guid></item><item><title>Auto-Evaluation with Few Labels through Post-hoc Regression</title><link>http://arxiv.org/abs/2411.12665v1</link><description>Continually evaluating large generative models provides a unique challenge.Often, human annotations are necessary to evaluate high-level properties ofthese models (e.g. in text or images). However, collecting human annotations ofsamples can be resource intensive, and using other machine learning systems toprovide the annotations, or automatic evaluation, can introduce systematicerrors into the evaluation. The Prediction Powered Inference (PPI) frameworkprovides a way of leveraging both the statistical power of automatic evaluationand a small pool of labelled data to produce a low-variance, unbiased estimateof the quantity being evaluated for. However, most work on PPI considers arelatively sizable set of labelled samples, which is not always practical toobtain. To this end, we present two new PPI-based techniques that leveragerobust regressors to produce even lower variance estimators in the few-labelregime.</description><author>Benjamin Eyre, David Madras</author><pubDate>Tue, 19 Nov 2024 17:17:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12665v1</guid></item><item><title>PoM: Efficient Image and Video Generation with the Polynomial Mixer</title><link>http://arxiv.org/abs/2411.12663v1</link><description>Diffusion models based on Multi-Head Attention (MHA) have become ubiquitousto generate high quality images and videos. However, encoding an image or avideo as a sequence of patches results in costly attention patterns, as therequirements both in terms of memory and compute grow quadratically. Toalleviate this problem, we propose a drop-in replacement for MHA called thePolynomial Mixer (PoM) that has the benefit of encoding the entire sequenceinto an explicit state. PoM has a linear complexity with respect to the numberof tokens. This explicit state also allows us to generate frames in asequential fashion, minimizing memory and compute requirement, while stillbeing able to train in parallel. We show the Polynomial Mixer is a universalsequence-to-sequence approximator, just like regular MHA. We adapt severalDiffusion Transformers (DiT) for generating images and videos with PoMreplacing MHA, and we obtain high quality samples while using lesscomputational resources. The code is available athttps://github.com/davidpicard/HoMM.</description><author>David Picard, Nicolas Dufour</author><pubDate>Tue, 19 Nov 2024 17:16:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12663v1</guid></item><item><title>Scientific Machine Learning Based Reduced-Order Models for Plasma Turbulence Simulations</title><link>http://arxiv.org/abs/2401.05972v3</link><description>This paper investigates non-intrusive Scientific Machine Learning (SciML)Reduced-Order Models (ROMs) for plasma turbulence simulations. In particular,we focus on Operator Inference (OpInf) to build low-cost physics-based ROMsfrom data for such simulations. As a representative example, we consider the(classical) Hasegawa-Wakatani (HW) equations used for modeling two-dimensionalelectrostatic drift-wave turbulence. For a comprehensive perspective of thepotential of OpInf to construct predictive ROMs, we consider three setups forthe HW equations by varying a key parameter, namely the adiabaticitycoefficient. These setups lead to the formation of complex and nonlineardynamics, which makes the construction of predictive ROMs of any kindchallenging. We generate the training datasets by performing direct numericalsimulations of the HW equations and recording the computed state data andoutputs the over a time horizon of $100$ time units in the turbulent phase. Wethen use these datasets to construct OpInf ROMs for predictions over $400$additional time units, that is, $400\%$ more than the training horizon. Ourresults show that the OpInf ROMs capture important statistical features of theturbulent dynamics and generalize beyond the training time horizon whilereducing the computational effort of the high-fidelity simulation by up to fiveorders of magnitude. In the broader context of fusion research, this shows thatnon-intrusive SciML ROMs have the potential to drastically accelerate numericalstudies, which can ultimately enable tasks such as the design of optimizedfusion devices.</description><author>Constantin Gahr, Ionut-Gabriel Farcas, Frank Jenko</author><pubDate>Tue, 19 Nov 2024 17:16:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05972v3</guid></item><item><title>Information Extraction from Clinical Notes: Are We Ready to Switch to Large Language Models?</title><link>http://arxiv.org/abs/2411.10020v3</link><description>Backgrounds: Information extraction (IE) is critical in clinical naturallanguage processing (NLP). While large language models (LLMs) excel ongenerative tasks, their performance on extractive tasks remains debated.Methods: We investigated Named Entity Recognition (NER) and Relation Extraction(RE) using 1,588 clinical notes from four sources (UT Physicians, MTSamples,MIMIC-III, and i2b2). We developed an annotated corpus covering 4 clinicalentities and 16 modifiers, and compared instruction-tuned LLaMA-2 and LLaMA-3against BiomedBERT in terms of performance, generalizability, computationalresources, and throughput to BiomedBERT. Results: LLaMA models outperformedBiomedBERT across datasets. With sufficient training data, LLaMA showed modestimprovements (1% on NER, 1.5-3.7% on RE); improvements were larger with limitedtraining data. On unseen i2b2 data, LLaMA-3-70B outperformed BiomedBERT by 7%(F1) on NER and 4% on RE. However, LLaMA models required more computingresources and ran up to 28 times slower. We implemented "Kiwi," a clinical IEpackage featuring both models, available at https://kiwi.clinicalnlp.org/.Conclusion: This study is among the first to develop and evaluate acomprehensive clinical IE system using open-source LLMs. Results indicate thatLLaMA models outperform BiomedBERT for clinical NER and RE but with highercomputational costs and lower throughputs. These findings highlight thatchoosing between LLMs and traditional deep learning methods for clinical IEapplications should remain task-specific, taking into account both performancemetrics and practical considerations such as available computing resources andthe intended use case scenarios.</description><author>Yan Hu, Xu Zuo, Yujia Zhou, Xueqing Peng, Jimin Huang, Vipina K. Keloth, Vincent J. Zhang, Ruey-Ling Weng, Qingyu Chen, Xiaoqian Jiang, Kirk E. Roberts, Hua Xu</author><pubDate>Tue, 19 Nov 2024 17:14:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10020v3</guid></item><item><title>Smart Predict-then-Optimize Method with Dependent Data: Risk Bounds and Calibration of Autoregression</title><link>http://arxiv.org/abs/2411.12653v1</link><description>The predict-then-optimize (PTO) framework is indispensable for addressingpractical stochastic decision-making tasks. It consists of two crucial steps:initially predicting unknown parameters of an optimization model andsubsequently solving the problem based on these predictions. Elmachtoub andGrigas [1] introduced the Smart Predict-then-Optimize (SPO) loss for theframework, which gauges the decision error arising from predicted parameters,and a convex surrogate, the SPO+ loss, which incorporates the underlyingstructure of the optimization model. The consistency of these different lossfunctions is guaranteed under the assumption of i.i.d. training data.Nevertheless, various types of data are often dependent, such as power loadfluctuations over time. This dependent nature can lead to diminished modelperformance in testing or real-world applications. Motivated to makeintelligent predictions for time series data, we present an autoregressive SPOmethod directly targeting the optimization problem at the decision stage inthis paper, where the conditions of consistency are no longer met. Therefore,we first analyze the generalization bounds of the SPO loss within ourautoregressive model. Subsequently, the uniform calibration results in Liu andGrigas [2] are extended in the proposed model. Finally, we conduct experimentsto empirically demonstrate the effectiveness of the SPO+ surrogate compared tothe absolute loss and the least squares loss, especially when the cost vectorsare determined by stationary dynamical systems and demonstrate the relationshipbetween normalized regret and mixing coefficients.</description><author>Jixian Liu, Tao Xu, Jianping He, Chongrong Fang</author><pubDate>Tue, 19 Nov 2024 17:02:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12653v1</guid></item><item><title>Optimizing Airline Reservation Systems with Edge-Enabled Microservices: A Framework for Real-Time Data Processing and Enhanced User Responsiveness</title><link>http://arxiv.org/abs/2411.12650v1</link><description>The growing complexity of the operations of airline reservations requires asmart solution for the adoption of novel approaches to the development ofquick, efficient, and adaptive reservation systems. This paper outlines indetail a conceptual framework for the implementation of edge computingmicroservices in order to address the shortcomings of traditional centralizedarchitectures. Specifically, as edge computing allows for certain activitiessuch as seat inventory checks, booking processes and even confirmation to bedone nearer to the user, thus lessening the overall response time and improvingthe performance of the system. In addition, the framework value should includeachieving the high performance of the system such as low latency, highthroughput and higher user experience. The major design components includedeployed distributed computing microservices orchestrated by Kubernetes,real-time message processing system with Kafka and its elastic scaling. Otheroperational components include Prometheus and Grafana, which are used tomonitor and manage resources, ensuring that all operational processes areoptimized. Although this research focuses on a design and theoretical schemingof the framework, its use is foreseen to be more advantageous in facilitating atransform in the provision of services in the airline industry by improvingcustomers' satisfaction, providing infrastructure which is cheap to install andefficiently supporting technology changes such as artificial intelligence andinternet of things embedded systems. This research addresses the increasingdemand for new technologies with modern well-distributed and real-time-centricsystems and also provides a basis for future case implementation and testing.As such, the proposed architecture offers a market-ready, extensible solutionto the problems posed by existing airline reservation systems .</description><author>Biman Barua, M. Shamim Kaiser</author><pubDate>Tue, 19 Nov 2024 16:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12650v1</guid></item><item><title>TransDreamer: Reinforcement Learning with Transformer World Models</title><link>http://arxiv.org/abs/2202.09481v2</link><description>The Dreamer agent provides various benefits of Model-Based ReinforcementLearning (MBRL) such as sample efficiency, reusable knowledge, and safeplanning. However, its world model and policy networks inherit the limitationsof recurrent neural networks and thus an important question is how an MBRLframework can benefit from the recent advances of transformers and what thechallenges are in doing so. In this paper, we propose a transformer-based MBRLagent, called TransDreamer. We first introduce the Transformer State-SpaceModel, a world model that leverages a transformer for dynamics predictions. Wethen share this world model with a transformer-based policy network and obtainstability in training a transformer-based RL agent. In experiments, we applythe proposed model to 2D visual RL and 3D first-person visual RL tasks bothrequiring long-range memory access for memory-based reasoning. We show that theproposed model outperforms Dreamer in these complex tasks.</description><author>Chang Chen, Yi-Fu Wu, Jaesik Yoon, Sungjin Ahn</author><pubDate>Tue, 19 Nov 2024 16:55:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.09481v2</guid></item><item><title>CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval</title><link>http://arxiv.org/abs/2411.12644v1</link><description>Despite the success of text retrieval in many NLP tasks, code retrievalremains a largely underexplored area. Most text retrieval systems are tailoredfor natural language queries, often neglecting the specific challenges ofretrieving code. This gap leaves existing models unable to effectively capturethe diversity of programming languages and tasks across different domains,highlighting the need for more focused research in code retrieval. To addressthis, we introduce CodeXEmbed, a family of large-scale code embedding modelsranging from 400M to 7B parameters. Our novel training pipeline unifiesmultiple programming languages and transforms various code-related tasks into acommon retrieval framework, enhancing model generalizability and retrievalperformance. Our 7B model sets a new state-of-the-art (SOTA) in code retrieval,outperforming the previous leading model, Voyage-Code, by over 20% on CoIRbenchmark. In addition to excelling in code retrieval, our models demonstratecompetitive performance on the widely adopted BeIR text retrieval benchmark,offering versatility across domains. Experimental results demonstrate thatimproving retrieval performance significantly enhances end-to-endRetrieval-Augmented Generation (RAG) performance for code-related tasks.</description><author>Ye Liu, Rui Meng, Shafiq Jot, Silvio Savarese, Caiming Xiong, Yingbo Zhou, Semih Yavuz</author><pubDate>Tue, 19 Nov 2024 16:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12644v1</guid></item><item><title>DLBacktrace: A Model Agnostic Explainability for any Deep Learning Models</title><link>http://arxiv.org/abs/2411.12643v1</link><description>The rapid advancement of artificial intelligence has led to increasinglysophisticated deep learning models, which frequently operate as opaque 'blackboxes' with limited transparency in their decision-making processes. This lackof interpretability presents considerable challenges, especially in high-stakesapplications where understanding the rationale behind a model's outputs is asessential as the outputs themselves. This study addresses the pressing need forinterpretability in AI systems, emphasizing its role in fostering trust,ensuring accountability, and promoting responsible deployment inmission-critical fields. To address the interpretability challenge in deeplearning, we introduce DLBacktrace, an innovative technique developed by theAryaXAI team to illuminate model decisions across a wide array of domains,including simple Multi Layer Perceptron (MLPs), Convolutional Neural Networks(CNNs), Large Language Models (LLMs), Computer Vision Models, and more. We provide a comprehensive overview of the DLBacktrace algorithm and presentbenchmarking results, comparing its performance against establishedinterpretability methods, such as SHAP, LIME, GradCAM, Integrated Gradients,SmoothGrad, and Attention Rollout, using diverse task-based metrics. Theproposed DLBacktrace technique is compatible with various model architecturesbuilt in PyTorch and TensorFlow, supporting models like Llama 3.2, other NLParchitectures such as BERT and LSTMs, computer vision models like ResNet andU-Net, as well as custom deep neural network (DNN) models for tabular data.This flexibility underscores DLBacktrace's adaptability and effectiveness inenhancing model transparency across a broad spectrum of applications. Thelibrary is open-sourced and available at https://github.com/AryaXAI/DLBacktrace .</description><author>Vinay Kumar Sankarapu, Chintan Chitroda, Yashwardhan Rathore, Neeraj Kumar Singh, Pratinav Seth</author><pubDate>Tue, 19 Nov 2024 16:54:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12643v1</guid></item><item><title>Leadsee-Precip: A Deep Learning Diagnostic Model for Precipitation</title><link>http://arxiv.org/abs/2411.12640v1</link><description>Recently, deep-learning weather forecasting models have surpassed traditionalnumerical models in terms of the accuracy of meteorological variables. However,there is considerable potential for improvements in precipitation forecasts,especially for heavy precipitation events. To address this deficiency, wepropose Leadsee-Precip, a global deep learning model to generate precipitationfrom meteorological circulation fields. The model utilizes an informationbalance scheme to tackle the challenges of predicting heavy precipitationcaused by the long-tail distribution of precipitation data. Additionally, moreaccurate satellite and radar-based precipitation retrievals are used astraining targets. Compared to artificial intelligence global weather models,the heavy precipitation from Leadsee-Precip is more consistent withobservations and shows competitive performance against global numerical weatherprediction models. Leadsee-Precip can be integrated with any global circulationmodel to generate precipitation forecasts. But the deviations between thepredicted and the ground-truth circulation fields may lead to a weakenedprecipitation forecast, which could potentially be mitigated by furtherfine-tuning based on the predicted circulation fields.</description><author>Weiwen Ji, Jin Feng, Yueqi Liu, Yulu Qiu, Hua Gao</author><pubDate>Tue, 19 Nov 2024 16:51:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12640v1</guid></item><item><title>PyAWD: A Library for Generating Large Synthetic Datasets of Acoustic Wave Propagation with Devito</title><link>http://arxiv.org/abs/2411.12636v1</link><description>Seismic data is often sparse and unevenly distributed due to the high costsand logistical challenges associated with deploying physical seismometers,limiting the application of Machine Learning (ML) in earthquake analysis. Toaddress this gap, we introduce PyAWD, a Python library designed to generatehigh-resolution synthetic datasets simulating spatio-temporal acoustic wavepropagation in both two-dimensional and three-dimensional heterogeneous media.By allowing fine control over parameters such as wave speed, external forces,spatial and temporal discretization, and media composition, PyAWD enables thecreation of ML-scale datasets that capture the complexity of seismic wavebehavior. We illustrate the library's potential with an epicenter retrievaltask, showcasing its suitability for designing complex, accurate seismicproblems that support advanced ML approaches in the absence or lack of densereal-world data.</description><author>Pascal Tribel, Gianluca Bontempi</author><pubDate>Tue, 19 Nov 2024 16:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12636v1</guid></item><item><title>M3D: Dual-Stream Selective State Spaces and Depth-Driven Framework for High-Fidelity Single-View 3D Reconstruction</title><link>http://arxiv.org/abs/2411.12635v1</link><description>The precise reconstruction of 3D objects from a single RGB image in complexscenes presents a critical challenge in virtual reality, autonomous driving,and robotics. Existing neural implicit 3D representation methods facesignificant difficulties in balancing the extraction of global and localfeatures, particularly in diverse and complex environments, leading toinsufficient reconstruction precision and quality. We propose M3D, a novelsingle-view 3D reconstruction framework, to tackle these challenges. Thisframework adopts a dual-stream feature extraction strategy based on SelectiveState Spaces to effectively balance the extraction of global and localfeatures, thereby improving scene comprehension and representation precision.Additionally, a parallel branch extracts depth information, effectivelyintegrating visual and geometric features to enhance reconstruction quality andpreserve intricate details. Experimental results indicate that the fusion ofmulti-scale features with depth information via the dual-branch featureextraction significantly boosts geometric consistency and fidelity, achievingstate-of-the-art reconstruction performance.</description><author>Luoxi Zhang, Pragyan Shrestha, Yu Zhou, Chun Xie, Itaru Kitahara</author><pubDate>Tue, 19 Nov 2024 16:49:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12635v1</guid></item><item><title>log-RRIM: Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling</title><link>http://arxiv.org/abs/2411.03320v3</link><description>Accurate prediction of chemical reaction yields is crucial for optimizingorganic synthesis, potentially reducing time and resources spent onexperimentation. With the rise of artificial intelligence (AI), there isgrowing interest in leveraging AI-based methods to accelerate yield predictionswithout conducting in vitro experiments. We present log-RRIM, an innovativegraph transformer-based framework designed for predicting chemical reactionyields. Our approach implements a unique local-to-global reactionrepresentation learning strategy. This approach initially captures detailedmolecule-level information and then models and aggregates intermolecularinteractions, ensuring that the impact of varying-sizes molecular fragments onyield is accurately accounted for. Another key feature of log-RRIM is itsintegration of a cross-attention mechanism that focuses on the interplaybetween reagents and reaction centers. This design reflects a fundamentalprinciple in chemical reactions: the crucial role of reagents in influencingbond-breaking and formation processes, which ultimately affect reaction yields.log-RRIM outperforms existing methods in our experiments, especially for mediumto high-yielding reactions, proving its reliability as a predictor. Itsadvanced modeling of reactant-reagent interactions and sensitivity to smallmolecular fragments make it a valuable tool for reaction planning andoptimization in chemical synthesis. The data and codes of log-RRIM areaccessible through https://github.com/ninglab/Yield_log_RRIM.</description><author>Xiao Hu, Ziqi Chen, Bo Peng, Daniel Adu-Ampratwum, Xia Ning</author><pubDate>Tue, 19 Nov 2024 16:49:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03320v3</guid></item><item><title>Instant Policy: In-Context Imitation Learning via Graph Diffusion</title><link>http://arxiv.org/abs/2411.12633v1</link><description>Following the impressive capabilities of in-context learning with largetransformers, In-Context Imitation Learning (ICIL) is a promising opportunityfor robotics. We introduce Instant Policy, which learns new tasks instantly(without further training) from just one or two demonstrations, achieving ICILthrough two key components. First, we introduce inductive biases through agraph representation and model ICIL as a graph generation problem with alearned diffusion process, enabling structured reasoning over demonstrations,observations, and actions. Second, we show that such a model can be trainedusing pseudo-demonstrations - arbitrary trajectories generated in simulation -as a virtually infinite pool of training data. Simulated and real experimentsshow that Instant Policy enables rapid learning of various everyday robottasks. We also show how it can serve as a foundation for cross-embodiment andzero-shot transfer to language-defined tasks. Code and videos are available athttps://www.robot-learning.uk/instant-policy.</description><author>Vitalis Vosylius, Edward Johns</author><pubDate>Tue, 19 Nov 2024 16:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12633v1</guid></item><item><title>DIG-FACE: De-biased Learning for Generalized Facial Expression Category Discovery</title><link>http://arxiv.org/abs/2409.20098v2</link><description>We introduce a novel task, Generalized Facial Expression Category Discovery(G-FACE), that discovers new, unseen facial expressions while recognizing knowncategories effectively. Even though there are generalized category discoverymethods for natural images, they show compromised performance on G-FACE. Weidentified two biases that affect the learning: implicit bias, coming from anunderlying distributional gap between new categories in unlabeled data andknown categories in labeled data, and explicit bias, coming from shiftedpreference on explicit visual facial change characteristics from knownexpressions to unknown expressions. By addressing the challenges caused by bothbiases, we propose a Debiased G-FACE method, namely DIG-FACE, that facilitatesthe debiasing of both implicit and explicit biases. In the implicit debiasingprocess of DIG-FACE, we devise a novel learning strategy that aims atestimating and minimizing the upper bound of implicit bias. In the explicitdebiasing process, we optimize the model's ability to handle nuanced visualfacial expression data by introducing a hierarchical category-discriminationrefinement strategy: sample-level, triplet-level, and distribution-leveloptimizations. Extensive experiments demonstrate that our DIG-FACEsignificantly enhances recognition accuracy for both known and new categories,setting a first-of-its-kind standard for the task.</description><author>Tingzhang Luo, Yichao Liu, Yuanyuan Liu, Andi Zhang, Xin Wang, Yibing Zhan, Chang Tang, Leyuan Liu, Zhe Chen</author><pubDate>Tue, 19 Nov 2024 16:45:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.20098v2</guid></item><item><title>Estimating Dark Matter Halo Masses in Simulated Galaxy Clusters with Graph Neural Networks</title><link>http://arxiv.org/abs/2411.12629v1</link><description>Galaxies grow and evolve in dark matter halos. Because dark matter is notvisible, galaxies' halo masses ($\rm{M}_{\rm{halo}}$) must be inferredindirectly. We present a graph neural network (GNN) model for predicting$\rm{M}_{\rm{halo}}$ from stellar mass ($\rm{M}_{*}$) in simulated galaxyclusters using data from the IllustrisTNG simulation suite. Unlike traditionalmachine learning models like random forests, our GNN captures theinformation-rich substructure of galaxy clusters by using spatial and kinematicrelationships between galaxy neighbour. A GNN model trained on the TNG-Clusterdataset and independently tested on the TNG300 simulation achieves superiorpredictive performance compared to other baseline models we tested. Future workwill extend this approach to different simulations and real observationaldatasets to further validate the GNN model's ability to generalise.</description><author>Nikhil Garuda, John F. Wu, Dylan Nelson, Annalisa Pillepich</author><pubDate>Tue, 19 Nov 2024 16:40:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12629v1</guid></item><item><title>HEARTS: A Holistic Framework for Explainable, Sustainable and Robust Text Stereotype Detection</title><link>http://arxiv.org/abs/2409.11579v2</link><description>Stereotypes are generalised assumptions about societal groups, and evenstate-of-the-art LLMs using in-context learning struggle to identify themaccurately. Due to the subjective nature of stereotypes, where what constitutesa stereotype can vary widely depending on cultural, social, and individualperspectives, robust explainability is crucial. Explainable models ensure thatthese nuanced judgments can be understood and validated by human users,promoting trust and accountability. We address these challenges by introducingHEARTS (Holistic Framework for Explainable, Sustainable, and Robust TextStereotype Detection), a framework that enhances model performance, minimisescarbon footprint, and provides transparent, interpretable explanations. Weestablish the Expanded Multi-Grain Stereotype Dataset (EMGSD), comprising57,201 labelled texts across six groups, including under-representeddemographics like LGBTQ+ and regional stereotypes. Ablation studies confirmthat BERT models fine-tuned on EMGSD outperform those trained on individualcomponents. We then analyse a fine-tuned, carbon-efficient ALBERT-V2 modelusing SHAP to generate token-level importance values, ensuring alignment withhuman understanding, and calculate explainability confidence scores bycomparing SHAP and LIME outputs...</description><author>Theo King, Zekun Wu, Adriano Koshiyama, Emre Kazim, Philip Treleaven</author><pubDate>Tue, 19 Nov 2024 16:39:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.11579v2</guid></item><item><title>Exploring the Manifold of Neural Networks Using Diffusion Geometry</title><link>http://arxiv.org/abs/2411.12626v1</link><description>Drawing motivation from the manifold hypothesis, which posits that mosthigh-dimensional data lies on or near low-dimensional manifolds, we applymanifold learning to the space of neural networks. We learn manifolds wheredatapoints are neural networks by introducing a distance between the hiddenlayer representations of the neural networks. These distances are then fed tothe non-linear dimensionality reduction algorithm PHATE to create a manifold ofneural networks. We characterize this manifold using features of therepresentation, including class separation, hierarchical cluster structure,spectral entropy, and topological structure. Our analysis reveals thathigh-performing networks cluster together in the manifold, displayingconsistent embedding patterns across all these features. Finally, wedemonstrate the utility of this approach for guiding hyperparameteroptimization and neural architecture search by sampling from the manifold.</description><author>Elliott Abel, Peyton Crevasse, Yvan Grinspan, Selma Mazioud, Folu Ogundipe, Kristof Reimann, Ellie Schueler, Andrew J. Steindl, Ellen Zhang, Dhananjay Bhaskar, Siddharth Viswanath, Yanlei Zhang, Tim G. J. Rudner, Ian Adelstein, Smita Krishnaswamy</author><pubDate>Tue, 19 Nov 2024 16:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12626v1</guid></item><item><title>How to Choose How to Choose Your Chatbot: A Massively Multi-System MultiReference Data Set for Dialog Metric Evaluation</title><link>http://arxiv.org/abs/2305.14533v2</link><description>We release MMSMR, a Massively Multi-System MultiReference dataset to enablefuture work on metrics and evaluation for dialog. Automatic metrics fordialogue evaluation should be robust proxies for human judgments; however, theverification of robustness is currently far from satisfactory. To quantify therobustness correlation and understand what is necessary in a test set, wecreate and release an 8-reference dialog dataset by extending single-referenceevaluation sets and introduce this new language learning conversation dataset.We then train 1750 systems and evaluate them on our novel test set and theDailyDialog dataset. We release the novel test set, and model hyper parameters,inference outputs, and metric scores for each system on a variety of datasets.</description><author>Huda Khayrallah, Zuhaib Akhtar, Edward Cohen, Jyothir S V, João Sedoc</author><pubDate>Tue, 19 Nov 2024 16:34:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14533v2</guid></item><item><title>Feasibility of Federated Learning from Client Databases with Different Brain Diseases and MRI Modalities</title><link>http://arxiv.org/abs/2406.11636v3</link><description>Segmentation models for brain lesions in MRI are typically developed for aspecific disease and trained on data with a predefined set of MRI modalities.Such models cannot segment the disease using data with a different set of MRImodalities, nor can they segment other types of diseases. Moreover, thistraining paradigm prevents a model from using the advantages of learning fromheterogeneous databases that may contain scans and segmentation labels fordifferent brain pathologies and diverse sets of MRI modalities. Additionally,the confidentiality of patient data often prevents central data aggregation,necessitating a decentralized approach. Is it feasible to use FederatedLearning (FL) to train a single model on client databases that contain scansand labels of different brain pathologies and diverse sets of MRI modalities?We demonstrate promising results by combining appropriate, simple, andpractical modifications to the model and training strategy: Designing a modelwith input channels that cover the whole set of modalities available acrossclients, training with random modality drop, and exploring the effects offeature normalization methods. Evaluation on 7 brain MRI databases with 5different diseases shows that this FL framework can train a single modelachieving very promising results in segmenting all disease types seen duringtraining. Importantly, it can segment these diseases in new databases thatcontain sets of modalities different from those in training clients. Theseresults demonstrate, for the first time, the feasibility and effectiveness ofusing FL to train a single 3D segmentation model on decentralised data withdiverse brain diseases and MRI modalities, a necessary step towards leveragingheterogeneous real-world databases. Code:https://github.com/FelixWag/FedUniBrain</description><author>Felix Wagner, Wentian Xu, Pramit Saha, Ziyun Liang, Daniel Whitehouse, David Menon, Virginia Newcombe, Natalie Voets, J. Alison Noble, Konstantinos Kamnitsas</author><pubDate>Tue, 19 Nov 2024 16:27:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11636v3</guid></item><item><title>Maps from Motion (MfM): Generating 2D Semantic Maps from Sparse Multi-view Images</title><link>http://arxiv.org/abs/2411.12620v1</link><description>World-wide detailed 2D maps require enormous collective efforts.OpenStreetMap is the result of 11 million registered users manually annotatingthe GPS location of over 1.75 billion entries, including distinctive landmarksand common urban objects. At the same time, manual annotations can includeerrors and are slow to update, limiting the map's accuracy. Maps from Motion(MfM) is a step forward to automatize such time-consuming map making procedureby computing 2D maps of semantic objects directly from a collection ofuncalibrated multi-view images. From each image, we extract a set of objectdetections, and estimate their spatial arrangement in a top-down local mapcentered in the reference frame of the camera that captured the image. Aligningthese local maps is not a trivial problem, since they provide incomplete, noisyfragments of the scene, and matching detections across them is unreliablebecause of the presence of repeated pattern and the limited appearancevariability of urban objects. We address this with a novel graph-basedframework, that encodes the spatial and semantic distribution of the objectsdetected in each image, and learns how to combine them to predict the objects'poses in a global reference system, while taking into account all possibledetection matches and preserving the topology observed in each image. Despitethe complexity of the problem, our best model achieves global 2D registrationwith an average accuracy within 4 meters (i.e., below GPS accuracy) even onsparse sequences with strong viewpoint change, on which COLMAP has an 80%failure rate. We provide extensive evaluation on synthetic and real-world data,showing how the method obtains a solution even in scenarios where standardoptimization techniques fail.</description><author>Matteo Toso, Stefano Fiorini, Stuart James, Alessio Del Bue</author><pubDate>Tue, 19 Nov 2024 16:27:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12620v1</guid></item><item><title>Leveraging Virtual Reality and AI Tutoring for Language Learning: A Case Study of a Virtual Campus Environment with OpenAI GPT Integration with Unity 3D</title><link>http://arxiv.org/abs/2411.12619v1</link><description>This paper presents a new approach to multiple language learning, with Hindithe language to be learnt in our case, by using the integration of virtualreality environments and AI enabled tutoring systems using OpenAIs GPT apicalls. We have developed a scenario which has a virtual campus environmentusing Unity which focuses on a detailed representation of our universitysbuildings 11th floor, where most of the cultural and technological activitiestake place. Within this virtual environment that we have created, we have an AItutor powered by OpenAI's GPT model which was called using an api which movesaround with the user. This provided language learning support in Hindi, as GPTis able to take care of language translation. Our approach mainly involvesutilising speech to text, text to text conversion and text to speechcapabilities to facilitate real time interaction between users and the AI tutorin the presence of internet. This research demonstrates the use of combining VRtechnology with AI tutoring for immersive language learning experiences andprovides interaction.</description><author>Adithya TG, Abhinavaram N, Gowri Srinivasa</author><pubDate>Tue, 19 Nov 2024 16:26:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12619v1</guid></item><item><title>A Multimodal Approach Combining Structural and Cross-domain Textual Guidance for Weakly Supervised OCT Segmentation</title><link>http://arxiv.org/abs/2411.12615v1</link><description>Accurate segmentation of Optical Coherence Tomography (OCT) images is crucialfor diagnosing and monitoring retinal diseases. However, the labor-intensivenature of pixel-level annotation limits the scalability of supervised learningwith large datasets. Weakly Supervised Semantic Segmentation (WSSS) provides apromising alternative by leveraging image-level labels. In this study, wepropose a novel WSSS approach that integrates structural guidance withtext-driven strategies to generate high-quality pseudo labels, significantlyimproving segmentation performance. In terms of visual information, our methodemploys two processing modules that exchange raw image features and structuralfeatures from OCT images, guiding the model to identify where lesions arelikely to occur. In terms of textual information, we utilize large-scalepretrained models from cross-domain sources to implement label-informed textualguidance and synthetic descriptive integration with two textual processingmodules that combine local semantic features with consistent syntheticdescriptions. By fusing these visual and textual components within a multimodalframework, our approach enhances lesion localization accuracy. Experimentalresults on three OCT datasets demonstrate that our method achievesstate-of-the-art performance, highlighting its potential to improve diagnosticaccuracy and efficiency in medical imaging.</description><author>Jiaqi Yang, Nitish Mehta, Xiaoling Hu, Chao Chen, Chia-Ling Tsai</author><pubDate>Tue, 19 Nov 2024 16:20:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12615v1</guid></item><item><title>Reward driven workflows for unsupervised explainable analysis of phases and ferroic variants from atomically resolved imaging data</title><link>http://arxiv.org/abs/2411.12612v1</link><description>Rapid progress in aberration corrected electron microscopy necessitatesdevelopment of robust methods for the identification of phases, ferroicvariants, and other pertinent aspects of materials structure from imaging data.While unsupervised methods for clustering and classification are widely usedfor these tasks, their performance can be sensitive to hyperparameter selectionin the analysis workflow. In this study, we explore the effects of descriptorsand hyperparameters on the capability of unsupervised ML methods to distilllocal structural information, exemplified by discovery of polarization andlattice distortion in Sm doped BiFeO3 (BFO) thin films. We demonstrate that areward-driven approach can be used to optimize these key hyperparameters acrossthe full workflow, where rewards were designed to reflect domain wallcontinuity and straightness, ensuring that the analysis aligns with thematerial's physical behavior. This approach allows us to discover localdescriptors that are best aligned with the specific physical behavior,providing insight into the fundamental physics of materials. We further extendthe reward driven workflows to disentangle structural factors of variation viaoptimized variational autoencoder (VAE). Finally, the importance ofwell-defined rewards was explored as a quantifiable measure of success of theworkflow.</description><author>Kamyar Barakati, Yu Liu, Chris Nelson, Maxim A. Ziatdinov, Xiaohang Zhang, Ichiro Takeuchi, Sergei V. Kalinin</author><pubDate>Tue, 19 Nov 2024 16:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12612v1</guid></item><item><title>Improving Multi-task Learning via Seeking Task-based Flat Regions</title><link>http://arxiv.org/abs/2211.13723v3</link><description>Multi-Task Learning (MTL) is a widely-used and powerful learning paradigm fortraining deep neural networks that allows learning more than one objective by asingle backbone. Compared to training tasks separately, MTL significantlyreduces computational costs, improves data efficiency, and potentially enhancesmodel performance by leveraging knowledge across tasks. Hence, it has beenadopted in a variety of applications, ranging from computer vision to naturallanguage processing and speech recognition. Among them, there is an emergingline of work in MTL that focuses on manipulating the task gradient to derive anultimate gradient descent direction to benefit all tasks. Despite achievingimpressive results on many benchmarks, directly applying these approacheswithout using appropriate regularization techniques might lead to suboptimalsolutions on real-world problems. In particular, standard training thatminimizes the empirical loss on the training data can easily suffer fromoverfitting to low-resource tasks or be spoiled by noisy-labeled ones, whichcan cause negative transfer between tasks and overall performance drop. Toalleviate such problems, we propose to leverage a recently introduced trainingmethod, named Sharpness-aware Minimization, which can enhance modelgeneralization ability on single-task learning. Accordingly, we present a novelMTL training methodology, encouraging the model to find task-based flat minimafor coherently improving its generalization capability on all tasks. Finally,we conduct comprehensive experiments on a variety of applications todemonstrate the merit of our proposed approach to existing gradient-based MTLmethods, as suggested by our developed theory.</description><author>Hoang Phan, Lam Tran, Quyen Tran, Ngoc N. Tran, Tuan Truong, Nhat Ho, Dinh Phung, Trung Le</author><pubDate>Tue, 19 Nov 2024 16:17:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13723v3</guid></item><item><title>SG-LRA: Self-Generating Automatic Scoliosis Cobb Angle Measurement with Low-Rank Approximation</title><link>http://arxiv.org/abs/2411.12604v1</link><description>Automatic Cobb angle measurement from X-ray images is crucial for scoliosisscreening and diagnosis. However, most existing regression-based methods andsegmentation-based methods struggle with inaccurate spine representations ormask connectivity/fragmentation issues. Besides, landmark-based methods sufferfrom insufficient training data and annotations. To address these challenges,we propose a novel framework including Self-Generation pipeline and Low-RankApproximation representation (SG-LRA) for automatic Cobb angle measurement.Specifically, we propose a parameterized spine contour representation based onLRA, which enables eigen-spine decomposition and spine contour reconstruction.We can directly obtain spine contour with only regressed LRA coefficients,which form a more accurate spine representation than rectangular boxes. Also,we combine LRA coefficient regression with anchor box classification to solveinaccurate predictions and mask connectivity issues. Moreover, we develop adata engine with automatic annotation and automatic selection in an iterativemanner, which is trained on a private Spinal2023 dataset. With our data engine,we generate the largest scoliosis X-ray dataset named Spinal-AI2024 largelywithout privacy leaks. Extensive experiments on public AASCE2019, privateSpinal2023, and generated Spinal-AI2024 datasets demonstrate that our methodachieves state-of-the-art Cobb angle measurement performance. Our code andSpinal-AI2024 dataset are available at https://github.com/Ernestchenchen/SG-LRAand https://github.com/Ernestchenchen/Spinal-AI2024, respectively.</description><author>Zhiwen Shao, Yichen Yuan, Lizhuang Ma, Dit-Yan Yeung, Xiaojia Zhu</author><pubDate>Tue, 19 Nov 2024 16:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12604v1</guid></item><item><title>STREAM: A Universal State-Space Model for Sparse Geometric Data</title><link>http://arxiv.org/abs/2411.12603v1</link><description>Handling sparse and unstructured geometric data, such as point clouds orevent-based vision, is a pressing challenge in the field of machine vision.Recently, sequence models such as Transformers and state-space models enteredthe domain of geometric data. These methods require specialized preprocessingto create a sequential view of a set of points. Furthermore, prior worksinvolving sequence models iterate geometric data with either uniform or learnedstep sizes, implicitly relying on the model to infer the underlying geometricstructure. In this work, we propose to encode geometric structure explicitlyinto the parameterization of a state-space model. State-space models are basedon linear dynamics governed by a one-dimensional variable such as time or aspatial coordinate. We exploit this dynamic variable to inject relativedifferences of coordinates into the step size of the state-space model. Theresulting geometric operation computes interactions between all pairs of Npoints in O(N) steps. Our model deploys the Mamba selective state-space modelwith a modified CUDA kernel to efficiently map sparse geometric data to modernhardware. The resulting sequence model, which we call STREAM, achievescompetitive results on a range of benchmarks from point-cloud classification toevent-based vision and audio classification. STREAM demonstrates a powerfulinductive bias for sparse geometric data by improving the PointMamba baselinewhen trained from scratch on the ModelNet40 and ScanObjectNN point cloudanalysis datasets. It further achieves, for the first time, 100% test accuracyon all 11 classes of the DVS128 Gestures dataset.</description><author>Mark Schöne, Yash Bhisikar, Karan Bania, Khaleelulla Khan Nazeer, Christian Mayr, Anand Subramoney, David Kappel</author><pubDate>Tue, 19 Nov 2024 16:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12603v1</guid></item><item><title>SAM Carries the Burden: A Semi-Supervised Approach Refining Pseudo Labels for Medical Segmentation</title><link>http://arxiv.org/abs/2411.12602v1</link><description>Semantic segmentation is a crucial task in medical imaging. Althoughsupervised learning techniques have proven to be effective in performing thistask, they heavily depend on large amounts of annotated training data. Therecently introduced Segment Anything Model (SAM) enables prompt-basedsegmentation and offers zero-shot generalization to unfamiliar objects. In ourwork, we leverage SAM's abstract object understanding for medical imagesegmentation to provide pseudo labels for semi-supervised learning, therebymitigating the need for extensive annotated training data. Our approach refinesinitial segmentations that are derived from a limited amount of annotated data(comprising up to 43 cases) by extracting bounding boxes and seed points asprompts forwarded to SAM. Thus, it enables the generation of dense segmentationmasks as pseudo labels for unlabelled data. The results show that training withour pseudo labels yields an improvement in Dice score from $74.29\,\%$ to$84.17\,\%$ and from $66.63\,\%$ to $74.87\,\%$ for the segmentation of bonesof the paediatric wrist and teeth in dental radiographs, respectively. As aresult, our method outperforms intensity-based post-processing methods,state-of-the-art supervised learning for segmentation (nnU-Net), and thesemi-supervised mean teacher approach. Our Code is available on GitHub.</description><author>Ron Keuth, Lasse Hansen, Maren Balks, Ronja Jäger, Anne-Nele Schröder, Ludger Tüshaus, Mattias Heinrich</author><pubDate>Tue, 19 Nov 2024 16:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12602v1</guid></item><item><title>Hypergraph $p$-Laplacian equations for data interpolation and semi-supervised learning</title><link>http://arxiv.org/abs/2411.12601v1</link><description>Hypergraph learning with $p$-Laplacian regularization has attracted a lot ofattention due to its flexibility in modeling higher-order relationships indata. This paper focuses on its fast numerical implementation, which ischallenging due to the non-differentiability of the objective function and thenon-uniqueness of the minimizer. We derive a hypergraph $p$-Laplacian equationfrom the subdifferential of the $p$-Laplacian regularization. A simplifiedequation that is mathematically well-posed and computationally efficient isproposed as an alternative. Numerical experiments verify that the simplified$p$-Laplacian equation suppresses spiky solutions in data interpolation andimproves classification accuracy in semi-supervised learning. The remarkablylow computational cost enables further applications.</description><author>Kehan Shi, Martin Burger</author><pubDate>Tue, 19 Nov 2024 16:05:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12601v1</guid></item><item><title>Provable unlearning in topic modeling and downstream tasks</title><link>http://arxiv.org/abs/2411.12600v1</link><description>Machine unlearning algorithms are increasingly important as legal concernsarise around the provenance of training data, but verifying the success ofunlearning is often difficult. Provable guarantees for unlearning are oftenlimited to supervised learning settings. In this paper, we provide the firsttheoretical guarantees for unlearning in the pre-training and fine-tuningparadigm by studying topic models, simple bag-of-words language models that canbe adapted to solve downstream tasks like retrieval and classification. First,we design a provably effective unlearning algorithm for topic models thatincurs a computational overhead independent of the size of the originaldataset. Our analysis additionally quantifies the deletion capacity of themodel -- i.e., the number of examples that can be unlearned without incurring asignificant cost in model performance. Finally, we formally extend our analysesto account for adaptation to a given downstream task. In particular, we designan efficient algorithm to perform unlearning after fine-tuning the topic modelvia a linear head. Notably, we show that it is easier to unlearn pre-trainingdata from models that have been fine-tuned to a particular task, and one canunlearn this data without modifying the base model.</description><author>Stanley Wei, Sadhika Malladi, Sanjeev Arora, Amartya Sanyal</author><pubDate>Tue, 19 Nov 2024 16:04:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12600v1</guid></item><item><title>Grammarization-Based Grasping with Deep Multi-Autoencoder Latent Space Exploration by Reinforcement Learning Agent</title><link>http://arxiv.org/abs/2411.08566v2</link><description>Grasping by a robot in unstructured environments is deemed a criticalchallenge because of the requirement for effective adaptation to a widevariation in object geometries, material properties, and other environmentalfactors. In this paper, we propose a novel framework for robotic grasping basedon the idea of compressing high-dimensional target and gripper features in acommon latent space using a set of autoencoders. Our approach simplifiesgrasping by using three autoencoders dedicated to the target, the gripper, anda third one that fuses their latent representations. This allows the RL agentto achieve higher learning rates at the initial stages of exploration of a newenvironment, as well as at non-zero shot grasp attempts. The agent explores thelatent space of the third autoencoder for better quality grasp without explicitreconstruction of objects. By implementing the PoWER algorithm into the RLtraining process, updates on the agent's policy will be made through theperturbation in the reward-weighted latent space. The successful explorationefficiently constrains both position and pose integrity for feasible executionsof grasps. We evaluate our system on a diverse set of objects, demonstratingthe high success rate in grasping with minimum computational overhead. We foundthat approach enhances the adaptation of the RL agent by more than 35 % insimulation experiments.</description><author>Leonidas Askianakis</author><pubDate>Tue, 19 Nov 2024 16:03:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08566v2</guid></item><item><title>GNNAS-Dock: Budget Aware Algorithm Selection with Graph Neural Networks for Molecular Docking</title><link>http://arxiv.org/abs/2411.12597v1</link><description>Molecular docking is a major element in drug discovery and design. It enablesthe prediction of ligand-protein interactions by simulating the binding ofsmall molecules to proteins. Despite the availability of numerous dockingalgorithms, there is no single algorithm consistently outperforms the othersacross a diverse set of docking scenarios. This paper introduces GNNAS-Dock, anovel Graph Neural Network (GNN)-based automated algorithm selection system formolecular docking in blind docking situations. GNNs are accommodated to processthe complex structural data of both ligands and proteins. They benefit from theinherent graph-like properties to predict the performance of various dockingalgorithms under different conditions. The present study pursues two mainobjectives: 1) predict the performance of each candidate docking algorithm, interms of Root Mean Square Deviation (RMSD), thereby identifying the mostaccurate method for specific scenarios; and 2) choose the best computationallyefficient docking algorithm for each docking case, aiming to reduce the timerequired for docking while maintaining high accuracy. We validate our approachon PDBBind 2020 refined set, which contains about 5,300 pairs of protein-ligandcomplexes.</description><author>Yiliang Yuan, Mustafa Misir</author><pubDate>Tue, 19 Nov 2024 16:01:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12597v1</guid></item><item><title>Smile upon the Face but Sadness in the Eyes: Emotion Recognition based on Facial Expressions and Eye Behaviors</title><link>http://arxiv.org/abs/2411.05879v2</link><description>Emotion Recognition (ER) is the process of identifying human emotions fromgiven data. Currently, the field heavily relies on facial expressionrecognition (FER) because facial expressions contain rich emotional cues.However, it is important to note that facial expressions may not alwaysprecisely reflect genuine emotions and FER-based results may yield misleadingER. To understand and bridge this gap between FER and ER, we introduce eyebehaviors as an important emotional cues for the creation of a newEye-behavior-aided Multimodal Emotion Recognition (EMER) dataset. Differentfrom existing multimodal ER datasets, the EMER dataset employs a stimulusmaterial-induced spontaneous emotion generation method to integratenon-invasive eye behavior data, like eye movements and eye fixation maps, withfacial videos, aiming to obtain natural and accurate human emotions. Notably,for the first time, we provide annotations for both ER and FER in the EMER,enabling a comprehensive analysis to better illustrate the gap between bothtasks. Furthermore, we specifically design a new EMERT architecture toconcurrently enhance performance in both ER and FER by efficiently identifyingand bridging the emotion gap between the two.Specifically, our EMERT employsmodality-adversarial feature decoupling and multi-task Transformer to augmentthe modeling of eye behaviors, thus providing an effective complement to facialexpressions. In the experiment, we introduce seven multimodal benchmarkprotocols for a variety of comprehensive evaluations of the EMER dataset. Theresults show that the EMERT outperforms other state-of-the-art multimodalmethods by a great margin, revealing the importance of modeling eye behaviorsfor robust ER. To sum up, we provide a comprehensive analysis of the importanceof eye behaviors in ER, advancing the study on addressing the gap between FERand ER for more robust ER performance.</description><author>Yuanyuan Liu, Lin Wei, Kejun Liu, Yibing Zhan, Zijing Chen, Zhe Chen, Shiguang Shan</author><pubDate>Tue, 19 Nov 2024 16:00:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.05879v2</guid></item><item><title>Learning the Simplicity of Scattering Amplitudes</title><link>http://arxiv.org/abs/2408.04720v2</link><description>The simplification and reorganization of complex expressions lies at the coreof scientific progress, particularly in theoretical high-energy physics. Thiswork explores the application of machine learning to a particular facet of thischallenge: the task of simplifying scattering amplitudes expressed in terms ofspinor-helicity variables. We demonstrate that an encoder-decoder transformerarchitecture achieves impressive simplification capabilities for expressionscomposed of handfuls of terms. Lengthier expressions are implemented in anadditional embedding network, trained using contrastive learning, whichisolates subexpressions that are more likely to simplify. The resultingframework is capable of reducing expressions with hundreds of terms - a regularoccurrence in quantum field theory calculations - to vastly simpler equivalentexpressions. Starting from lengthy input expressions, our networks can generatethe Parke-Taylor formula for five-point gluon scattering, as well as newcompact expressions for five-point amplitudes involving scalars and gravitons.An interactive demonstration can be found athttps://spinorhelicity.streamlit.app .</description><author>Clifford Cheung, Aurélien Dersy, Matthew D. Schwartz</author><pubDate>Tue, 19 Nov 2024 15:57:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04720v2</guid></item><item><title>Whisper Finetuning on Nepali Language</title><link>http://arxiv.org/abs/2411.12587v1</link><description>Despite the growing advancements in Automatic Speech Recognition (ASR)models, the development of robust models for underrepresented languages, suchas Nepali, remains a challenge. This research focuses on making an exhaustiveand generalized dataset followed by fine-tuning OpenAI's Whisper models ofdifferent sizes to improve transcription (speech-to-text) accuracy for theNepali language. We leverage publicly available ASR datasets and self-recordedcustom datasets with a diverse range of accents, dialects, and speaking stylesfurther enriched through augmentation. Our experimental results demonstratethat fine-tuning Whisper models on our curated custom dataset substantiallyreduces the Word Error Rate (WER) across all model sizes attributed to largerdata variations in terms of speaker's age, gender, and sentiment, acousticenvironment, dialect, denser audio segments (15-30 seconds) that are morecompatible with Whisper's input, and manual curation of audios andtranscriptions. Notably, our approach outperforms Whisper's baseline modelstrained on Fleur's dataset, achieving WER reductions of up to 36.2% on thesmall and 23.8% on medium models. Furthermore, we show that data augmentationplays a significant role in enhancing model robustness. Our approach underlinesthe importance of dataset quality, variation, and augmentation in theadaptation of state-of-the-art models to underrepresented languages fordeveloping accurate ASR systems.</description><author>Sanjay Rijal, Shital Adhikari, Manish Dahal, Manish Awale, Vaghawan Ojha</author><pubDate>Tue, 19 Nov 2024 15:55:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12587v1</guid></item><item><title>A SAM-guided Two-stream Lightweight Model for Anomaly Detection</title><link>http://arxiv.org/abs/2402.19145v2</link><description>In industrial anomaly detection, model efficiency and mobile-friendlinessbecome the primary concerns in real-world applications. Simultaneously, theimpressive generalization capabilities of Segment Anything (SAM) have garneredbroad academic attention, making it an ideal choice for localizing unseenanomalies and diverse real-world patterns. In this paper, considering these twocritical factors, we propose a SAM-guided Two-stream Lightweight Model forunsupervised anomaly detection (STLM) that not only aligns with the twopractical application requirements but also harnesses the robust generalizationcapabilities of SAM. We employ two lightweight image encoders, i.e., ourtwo-stream lightweight module, guided by SAM's knowledge. To be specific, onestream is trained to generate discriminative and general featurerepresentations in both normal and anomalous regions, while the other streamreconstructs the same images without anomalies, which effectively enhances thedifferentiation of two-stream representations when facing anomalous regions.Furthermore, we employ a shared mask decoder and a feature aggregation moduleto generate anomaly maps. Our experiments conducted on MVTec AD benchmark showthat STLM, with about 16M parameters and achieving an inference time in 20ms,competes effectively with state-of-the-art methods in terms of performance,98.26% on pixel-level AUC and 94.92% on PRO. We further experiment on moredifficult datasets, e.g., VisA and DAGM, to demonstrate the effectiveness andgeneralizability of STLM.</description><author>Chenghao Li, Lei Qi, Xin Geng</author><pubDate>Tue, 19 Nov 2024 15:54:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19145v2</guid></item><item><title>Identifying Differential Patient Care Through Inverse Intent Inference</title><link>http://arxiv.org/abs/2411.07372v2</link><description>Sepsis is a life-threatening condition defined by end-organ dysfunction dueto a dysregulated host response to infection. Although the Surviving SepsisCampaign has launched and has been releasing sepsis treatment guidelines tounify and normalize the care for sepsis patients, it has been reported innumerous studies that disparities in care exist across the trajectory ofpatient stay in the emergency department and intensive care unit. Here, weapply a number of reinforcement learning techniques including behavioralcloning, imitation learning, and inverse reinforcement learning, to learn theoptimal policy in the management of septic patient subgroups using expertdemonstrations. Then we estimate the counterfactual optimal policies byapplying the model to another subset of unseen medical populations and identifythe difference in cure by comparing it to the real policy. Our data comes fromthe sepsis cohort of MIMIC-IV and the clinical data warehouses of the MassGeneral Brigham healthcare system. The ultimate objective of this work is touse the optimal learned policy function to estimate the counterfactualtreatment policy and identify deviations across sub-populations of interest. Wehope this approach would help us identify any disparities in care and alsochanges in cure in response to the publication of national sepsis treatmentguidelines.</description><author>Hyewon Jeong, Siddharth Nayak, Taylor Killian, Sanjat Kanjilal</author><pubDate>Tue, 19 Nov 2024 15:53:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07372v2</guid></item><item><title>Combinatorial Logistic Bandits</title><link>http://arxiv.org/abs/2410.17075v2</link><description>We introduce a novel framework called combinatorial logistic bandits (CLogB),where in each round, a subset of base arms (called the super arm) is selected,with the outcome of each base arm being binary and its expectation following alogistic parametric model. The feedback is governed by a general arm triggeringprocess. Our study covers CLogB with reward functions satisfying two smoothnessconditions, capturing application scenarios such as online content delivery,online learning to rank, and dynamic channel allocation. We first propose asimple yet efficient algorithm, CLogUCB, utilizing a variance-agnosticexploration bonus. Under the 1-norm triggering probability modulated (TPM)smoothness condition, CLogUCB achieves a regret bound of$\tilde{O}(d\sqrt{\kappa KT})$, where $\tilde{O}$ ignores logarithmic factors,$d$ is the dimension of the feature vector, $\kappa$ represents thenonlinearity of the logistic model, and $K$ is the maximum number of base armsa super arm can trigger. This result improves on prior work by a factor of$\tilde{O}(\sqrt{\kappa})$. We then enhance CLogUCB with a variance-adaptiveversion, VA-CLogUCB, which attains a regret bound of $\tilde{O}(d\sqrt{KT})$under the same 1-norm TPM condition, improving another$\tilde{O}(\sqrt{\kappa})$ factor. VA-CLogUCB shows even greater promise underthe stronger triggering probability and variance modulated (TPVM) condition,achieving a leading $\tilde{O}(d\sqrt{T})$ regret, thus removing the additionaldependency on the action-size $K$. Furthermore, we enhance the computationalefficiency of VA-CLogUCB by eliminating the nonconvex optimization process whenthe context feature map is time-invariant while maintaining the tight$\tilde{O}(d\sqrt{T})$ regret. Finally, experiments on synthetic and real-worlddatasets demonstrate the superior performance of our algorithms compared tobenchmark algorithms.</description><author>Xutong Liu, Xiangxiang Dai, Xuchuang Wang, Mohammad Hajiesmaili, John C. S. Lui</author><pubDate>Tue, 19 Nov 2024 15:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17075v2</guid></item><item><title>BAISeg: Boundary Assisted Weakly Supervised Instance Segmentation</title><link>http://arxiv.org/abs/2406.18558v2</link><description>How to extract instance-level masks without instance-level supervision is themain challenge of weakly supervised instance segmentation (WSIS). Popular WSISmethods estimate a displacement field (DF) via learning inter-pixel relationsand perform clustering to identify instances. However, the resulting instancecentroids are inherently unstable and vary significantly across differentclustering algorithms. In this paper, we propose Boundary-Assisted InstanceSegmentation (BAISeg), which is a novel paradigm for WSIS that realizesinstance segmentation with pixel-level annotations. BAISeg comprises aninstance-aware boundary detection (IABD) branch and a semantic segmentationbranch. The IABD branch identifies instances by predicting class-agnosticinstance boundaries rather than instance centroids, therefore, it is differentfrom previous DF-based approaches. In particular, we proposed the CascadeFusion Module (CFM) and the Deep Mutual Attention (DMA) in the IABD branch toobtain rich contextual information and capture instance boundaries with weakresponses. During the training phase, we employed Pixel-to-Pixel Contrast toenhance the discriminative capacity of the IABD branch. This furtherstrengthens the continuity and closedness of the instance boundaries. Extensiveexperiments on PASCAL VOC 2012 and MS COCO demonstrate the effectiveness of ourapproach, and we achieve considerable performance with only pixel-levelannotations. The code will be available at https://github.com/wsis-seg/BAISeg.</description><author>Tengbo Wang, Yu Bai</author><pubDate>Tue, 19 Nov 2024 15:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18558v2</guid></item><item><title>Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models</title><link>http://arxiv.org/abs/2411.12580v1</link><description>The capabilities and limitations of Large Language Models have been sketchedout in great detail in recent years, providing an intriguing yet conflictingpicture. On the one hand, LLMs demonstrate a general ability to solve problems.On the other hand, they show surprising reasoning gaps when compared to humans,casting doubt on the robustness of their generalisation strategies. The sheervolume of data used in the design of LLMs has precluded us from applying themethod traditionally used to measure generalisation: train-test set separation.To overcome this, we study what kind of generalisation strategies LLMs employwhen performing reasoning tasks by investigating the pretraining data they relyon. For two models of different sizes (7B and 35B) and 2.5B of theirpretraining tokens, we identify what documents influence the model outputs forthree simple mathematical reasoning tasks and contrast this to the data thatare influential for answering factual questions. We find that, while the modelsrely on mostly distinct sets of data for each factual question, a documentoften has a similar influence across different reasoning questions within thesame task, indicating the presence of procedural knowledge. We further findthat the answers to factual questions often show up in the most influentialdata. However, for reasoning questions the answers usually do not show up ashighly influential, nor do the answers to the intermediate reasoning steps.When we characterise the top ranked documents for the reasoning questionsqualitatively, we confirm that the influential documents often containprocedural knowledge, like demonstrating how to obtain a solution usingformulae or code. Our findings indicate that the approach to reasoning themodels use is unlike retrieval, and more like a generalisable strategy thatsynthesises procedural knowledge from documents doing a similar form ofreasoning.</description><author>Laura Ruis, Maximilian Mozes, Juhan Bae, Siddhartha Rao Kamalakara, Dwarak Talupuru, Acyr Locatelli, Robert Kirk, Tim Rocktäschel, Edward Grefenstette, Max Bartolo</author><pubDate>Tue, 19 Nov 2024 15:47:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12580v1</guid></item><item><title>Can Agents Spontaneously Form a Society? Introducing a Novel Architecture for Generative Multi-Agents to Elicit Social Emergence</title><link>http://arxiv.org/abs/2409.06750v2</link><description>Generative agents have demonstrated impressive capabilities in specifictasks, but most of these frameworks focus on independent tasks and lackattention to social interactions. We introduce a generative agent architecturecalled ITCMA-S, which includes a basic framework for individual agents and aframework called LTRHA that supports social interactions among multi-agents.This architecture enables agents to identify and filter out behaviors that aredetrimental to social interactions, guiding them to choose more favorableactions. We designed a sandbox environment to simulate the natural evolution ofsocial relationships among multiple identity-less agents for experimentalevaluation. The results showed that ITCMA-S performed well on multipleevaluation indicators, demonstrating its ability to actively explore theenvironment, recognize new agents, and acquire new information throughcontinuous actions and dialogue. Observations show that as agents establishconnections with each other, they spontaneously form cliques with internalhierarchies around a selected leader and organize collective activities.</description><author>H. Zhang, J. Yin, M. Jiang, C. Su</author><pubDate>Tue, 19 Nov 2024 15:44:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06750v2</guid></item><item><title>Stochastic BIQA: Median Randomized Smoothing for Certified Blind Image Quality Assessment</title><link>http://arxiv.org/abs/2411.12575v1</link><description>Most modern No-Reference Image-Quality Assessment (NR-IQA) metrics are basedon neural networks vulnerable to adversarial attacks. Attacks on such metricslead to incorrect image/video quality predictions, which poses significantrisks, especially in public benchmarks. Developers of image processingalgorithms may unfairly increase the score of a target IQA metric withoutimproving the actual quality of the adversarial image. Although some empiricaldefenses for IQA metrics were proposed, they do not provide theoreticalguarantees and may be vulnerable to adaptive attacks. This work focuses ondeveloping a provably robust no-reference IQA metric. Our method is based onMedian Smoothing (MS) combined with an additional convolution denoiser withranking loss to improve the SROCC and PLCC scores of the defended IQA metric.Compared with two prior methods on three datasets, our method exhibitedsuperior SROCC and PLCC scores while maintaining comparable certifiedguarantees.</description><author>Ekaterina Shumitskaya, Mikhail Pautov, Dmitriy Vatolin, Anastasia Antsiferova</author><pubDate>Tue, 19 Nov 2024 15:42:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12575v1</guid></item><item><title>Large Language Models for Combinatorial Optimization of Design Structure Matrix</title><link>http://arxiv.org/abs/2411.12571v1</link><description>Combinatorial optimization (CO) is essential for improving efficiency andperformance in engineering applications. As complexity increases with largerproblem sizes and more intricate dependencies, identifying the optimal solutionbecome challenging. When it comes to real-world engineering problems,algorithms based on pure mathematical reasoning are limited and incapable tocapture the contextual nuances necessary for optimization. This study exploresthe potential of Large Language Models (LLMs) in solving engineering COproblems by leveraging their reasoning power and contextual knowledge. Wepropose a novel LLM-based framework that integrates network topology and domainknowledge to optimize the sequencing of Design Structure Matrix (DSM)-a commonCO problem. Our experiments on various DSM cases demonstrate that the proposedmethod achieves faster convergence and higher solution quality than benchmarkmethods. Moreover, results show that incorporating contextual domain knowledgesignificantly improves performance despite the choice of LLMs. These findingshighlight the potential of LLMs in tackling complex real-world CO problems bycombining semantic and mathematical reasoning. This approach paves the way fora new paradigm in in real-world combinatorial optimization.</description><author>Shuo Jiang, Min Xie, Jianxi Luo</author><pubDate>Tue, 19 Nov 2024 15:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12571v1</guid></item><item><title>BiSSL: Bilevel Optimization for Self-Supervised Pre-Training and Fine-Tuning</title><link>http://arxiv.org/abs/2410.02387v2</link><description>In this work, we present BiSSL, a first-of-its-kind training framework thatintroduces bilevel optimization to enhance the alignment between the pretextpre-training and downstream fine-tuning stages in self-supervised learning.BiSSL formulates the pretext and downstream task objectives as the lower- andupper-level objectives in a bilevel optimization problem and serves as anintermediate training stage within the self-supervised learning pipeline. Bymore explicitly modeling the interdependence of these training stages, BiSSLfacilitates enhanced information sharing between them, ultimately leading to abackbone parameter initialization that is better suited for the downstreamtask. We propose a training algorithm that alternates between optimizing thetwo objectives defined in BiSSL. Using a ResNet-18 backbone pre-trained withSimCLR on the STL10 dataset, we demonstrate that our proposed frameworkconsistently achieves improved or competitive classification accuracies acrossvarious downstream image classification datasets compared to the conventionalself-supervised learning pipeline. Qualitative analyses of the backbonefeatures further suggest that BiSSL enhances the alignment of downstreamfeatures in the backbone prior to fine-tuning.</description><author>Gustav Wagner Zakarias, Lars Kai Hansen, Zheng-Hua Tan</author><pubDate>Tue, 19 Nov 2024 15:39:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02387v2</guid></item><item><title>A data driven approach to classify descriptors based on their efficiency in translating noisy trajectories into physically-relevant information</title><link>http://arxiv.org/abs/2411.12570v1</link><description>Reconstructing the physical complexity of many-body dynamical systems can bechallenging. Starting from the trajectories of their constitutive units (rawdata), typical approaches require selecting appropriate descriptors to convertthem into time-series, which are then analyzed to extract interpretableinformation. However, identifying the most effective descriptor is oftennon-trivial. Here, we report a data-driven approach to compare the efficiencyof various descriptors in extracting information from noisy trajectories andtranslating it into physically relevant insights. As a prototypical system withnon-trivial internal complexity, we analyze molecular dynamics trajectories ofan atomistic system where ice and water coexist in equilibrium near thesolid/liquid transition temperature. We compare general and specificdescriptors often used in aqueous systems: number of neighbors, molecularvelocities, Smooth Overlap of Atomic Positions (SOAP), Local Environments andNeighbors Shuffling (LENS), Orientational Tetrahedral Order, and distance fromthe fifth neighbor ($d_5$). Using Onion Clustering -- an efficient unsupervisedmethod for single-point time-series analysis -- we assess the maximumextractable information for each descriptor and rank them via ahigh-dimensional metric. Our results show that advanced descriptors like SOAPand LENS outperform classical ones due to higher signal-to-noise ratios.Nonetheless, even simple descriptors can rival or exceed advanced ones afterlocal signal denoising. For example, $d_5$, initially among the weakest,becomes the most effective at resolving the system's non-local dynamicalcomplexity after denoising. This work highlights the critical role of noise ininformation extraction from molecular trajectories and offers a data-drivenapproach to identify optimal descriptors for systems with characteristicinternal complexity.</description><author>Simone Martino, Domiziano Doria, Chiara Lionello, Matteo Becchi, Giovanni M. Pavan</author><pubDate>Tue, 19 Nov 2024 15:39:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12570v1</guid></item><item><title>Plurals: A System for Guiding LLMs Via Simulated Social Ensembles</title><link>http://arxiv.org/abs/2409.17213v5</link><description>Recent debates raised concerns that language models may favor certainviewpoints. But what if the solution is not to aim for a 'view from nowhere'but rather to leverage different viewpoints? We introduce Plurals, a system andPython library for pluralistic AI deliberation. Plurals consists of Agents(LLMs, optionally with personas) which deliberate within customizableStructures, with Moderators overseeing deliberation. Plurals is a generator ofsimulated social ensembles. Plurals integrates with government datasets tocreate nationally representative personas, includes deliberation templatesinspired by deliberative democracy, and allows users to customize bothinformation-sharing structures and deliberation behavior within Structures. Sixcase studies demonstrate fidelity to theoretical constructs and efficacy. Threerandomized experiments show simulated focus groups produced output resonantwith an online sample of the relevant audiences (chosen over zero-shotgeneration in 75% of trials). Plurals is both a paradigm and a concrete systemfor pluralistic AI. The Plurals library is available athttps://github.com/josh-ashkinaze/plurals and will be continually updated.</description><author>Joshua Ashkinaze, Emily Fry, Narendra Edara, Eric Gilbert, Ceren Budak</author><pubDate>Tue, 19 Nov 2024 15:37:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.17213v5</guid></item><item><title>Leveraging Computational Pathology AI for Noninvasive Optical Imaging Analysis Without Retraining</title><link>http://arxiv.org/abs/2411.11613v2</link><description>Noninvasive optical imaging modalities can probe patient's tissue in 3D andover time generate gigabytes of clinically relevant data per sample. There is aneed for AI models to analyze this data and assist clinical workflow. The lackof expert labelers and the large dataset required (&gt;100,000 images) for modeltraining and tuning are the main hurdles in creating foundation models. In thispaper we introduce FoundationShift, a method to apply any AI model fromcomputational pathology without retraining. We show our method is more accuratethan state of the art models (SAM, MedSAM, SAM-Med2D, CellProfiler, Hover-Net,PLIP, UNI and ChatGPT), with multiple imaging modalities (OCT and RCM). This isachieved without the need for model retraining or fine-tuning. Applying ourmethod to noninvasive in vivo images could enable physicians to readilyincorporate optical imaging modalities into their clinical practice, providingreal time tissue analysis and improving patient care.</description><author>Danny Barash, Emilie Manning, Aidan Van Vleck, Omri Hirsch, Kyi Lei Aye, Jingxi Li, Philip O. Scumpia, Aydogan Ozcan, Sumaira Aasi, Kerri E. Rieger, Kavita Y. Sarin, Oren Freifeld, Yonatan Winetraub</author><pubDate>Tue, 19 Nov 2024 15:36:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.11613v2</guid></item><item><title>Approximating Families of Sharp Solutions to Fisher's Equation with Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2402.08313v2</link><description>This paper employs physics-informed neural networks (PINNs) to solve Fisher'sequation, a fundamental reaction-diffusion system with both simplicity andsignificance. The focus is on investigating Fisher's equation under conditionsof large reaction rate coefficients, where solutions exhibit steep travelingwaves that often present challenges for traditional numerical methods. Toaddress these challenges, a residual weighting scheme is introduced in thenetwork training to mitigate the difficulties associated with standard PINNapproaches. Additionally, a specialized network architecture designed tocapture traveling wave solutions is explored. The paper also assesses theability of PINNs to approximate a family of solutions by generalizing acrossmultiple reaction rate coefficients. The proposed method demonstrates higheffectiveness in solving Fisher's equation with large reaction ratecoefficients and shows promise for meshfree solutions of generalizedreaction-diffusion systems.</description><author>Franz M. Rohrhofer, Stefan Posch, Clemens Gößnitzer, Bernhard C. Geiger</author><pubDate>Tue, 19 Nov 2024 15:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08313v2</guid></item><item><title>Stream-Based Active Learning for Process Monitoring</title><link>http://arxiv.org/abs/2411.12563v1</link><description>Statistical process monitoring (SPM) methods are essential tools in qualitymanagement to check the stability of industrial processes, i.e., to dynamicallyclassify the process state as in control (IC), under normal operatingconditions, or out of control (OC), otherwise. Traditional SPM methods arebased on unsupervised approaches, which are popular because in most industrialapplications the true OC states of the process are not explicitly known. Thishampered the development of supervised methods that could instead takeadvantage of process data containing labels on the true process state, althoughthey still need improvement in dealing with class imbalance, as OC states arerare in high-quality processes, and the dynamic recognition of unseen classes,e.g., the number of possible OC states. This article presents a novelstream-based active learning strategy for SPM that enhances partially hiddenMarkov models to deal with data streams. The ultimate goal is to optimizelabeling resources constrained by a limited budget and dynamically update thepossible OC states. The proposed method performance in classifying the truestate of the process is assessed through a simulation and a case study on theSPM of a resistance spot welding process in the automotive industry, whichmotivated this research.</description><author>Christian Capezza, Antonio Lepore, Kamran Paynabar</author><pubDate>Tue, 19 Nov 2024 15:27:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12563v1</guid></item><item><title>Partially Unitary Learning</title><link>http://arxiv.org/abs/2405.10263v2</link><description>The problem of an optimal mapping between Hilbert spaces $IN$ of$\left|\psi\right\rangle$ and $OUT$ of $\left|\phi\right\rangle$ based on a setof wavefunction measurements (within a phase) $\psi_l \to \phi_l$, $l=1\dotsM$, is formulated as an optimization problem maximizing the total fidelity$\sum_{l=1}^{M} \omega^{(l)}\left|\langle\phi_l|\mathcal{U}|\psi_l\rangle\right|^2$ subject to probabilitypreservation constraints on $\mathcal{U}$ (partial unitarity). The constructedoperator $\mathcal{U}$ can be considered as an $IN$ to $OUT$ quantum channel;it is a partially unitary rectangular matrix (an isometry) of dimension$\dim(OUT) \times \dim(IN)$ transforming operators as $A^{OUT}=\mathcal{U}A^{IN} \mathcal{U}^{\dagger}$. An iterative algorithm for finding the globalmaximum of this optimization problem is developed, and its application to anumber of problems is demonstrated. A software product implementing thealgorithm is available from the authors.</description><author>Mikhail Gennadievich Belov, Vladislav Gennadievich Malyshkin</author><pubDate>Tue, 19 Nov 2024 15:27:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10263v2</guid></item><item><title>Topological Symmetry Enhanced Graph Convolution for Skeleton-Based Action Recognition</title><link>http://arxiv.org/abs/2411.12560v1</link><description>Skeleton-based action recognition has achieved remarkable performance withthe development of graph convolutional networks (GCNs). However, most of thesemethods tend to construct complex topology learning mechanisms while neglectingthe inherent symmetry of the human body. Additionally, the use of temporalconvolutions with certain fixed receptive fields limits their capacity toeffectively capture dependencies in time sequences. To address the issues, we(1) propose a novel Topological Symmetry Enhanced Graph Convolution (TSE-GC) toenable distinct topology learning across different channel partitions whileincorporating topological symmetry awareness and (2) construct a Multi-BranchDeformable Temporal Convolution (MBDTC) for skeleton-based action recognition.The proposed TSE-GC emphasizes the inherent symmetry of the human body whileenabling efficient learning of dynamic topologies. Meanwhile, the design ofMBDTC introduces the concept of deformable modeling, leading to more flexiblereceptive fields and stronger modeling capacity of temporal dependencies.Combining TSE-GC with MBDTC, our final model, TSE-GCN, achieves competitiveperformance with fewer parameters compared with state-of-the-art methods onthree large datasets, NTU RGB+D, NTU RGB+D 120, and NW-UCLA. On thecross-subject and cross-set evaluations of NTU RGB+D 120, the accuracies of ourmodel reach 90.0\% and 91.1\%, with 1.1M parameters and 1.38 GFLOPS for onestream.</description><author>Zeyu Liang, Hailun Xia, Naichuan Zheng, Huan Xu</author><pubDate>Tue, 19 Nov 2024 15:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12560v1</guid></item><item><title>On Size and Hardness Generalization in Unsupervised Learning for the Travelling Salesman Problem</title><link>http://arxiv.org/abs/2403.20212v2</link><description>We study the generalization capability of Unsupervised Learning in solvingthe Travelling Salesman Problem (TSP). We use a Graph Neural Network (GNN)trained with a surrogate loss function to generate an embedding for each node.We use these embeddings to construct a heat map that indicates the likelihoodof each edge being part of the optimal route. We then apply local search togenerate our final predictions. Our investigation explores how differenttraining instance sizes, embedding dimensions, and distributions influence theoutcomes of Unsupervised Learning methods. Our results show that training withlarger instance sizes and increasing embedding dimensions can build a moreeffective representation, enhancing the model's ability to solve TSP.Furthermore, in evaluating generalization across different distributions, wefirst determine the hardness of various distributions and explore how differenthardnesses affect the final results. Our findings suggest that models trainedon harder instances exhibit better generalization capabilities, highlightingthe importance of selecting appropriate training instances in solving TSP usingUnsupervised Learning.</description><author>Yimeng Min, Carla P. Gomes</author><pubDate>Tue, 19 Nov 2024 15:23:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20212v2</guid></item><item><title>Look Before You Decide: Prompting Active Deduction of MLLMs for Assumptive Reasoning</title><link>http://arxiv.org/abs/2404.12966v4</link><description>Recently, Multimodal Large Language Models (MLLMs) have achieved significantsuccess across multiple disciplines due to their exceptionalinstruction-following capabilities and extensive world knowledge. However,whether these MLLMs possess human-like compositional reasoning abilitiesremains an open problem. To unveil their reasoning behaviors, we first curate a\textbf{M}ultimodal \textbf{A}ssumptive \textbf{R}ea\textbf{s}oning Benchmark(MARS-Bench) in this paper. Interestingly, we find that most prevalent MLLMscan be easily fooled by the introduction of a presupposition into the question,whereas such presuppositions appear naive to human reasoning. Besides, we alsopropose a simple yet effective method, Active Deduction (AD), to encourage themodel to actively perform composite deduction before reaching a final decision.Equipped with the proposed AD method, a MLLM demonstrates significantimprovements in assumptive reasoning abilities without compromising itsgeneral-purpose question-answering performance. We also provide extensiveevaluations of both open-source and private MLLMs on MARS-Bench, along withexperimental analyses of the AD method.</description><author>Yian Li, Wentao Tian, Yang Jiao, Jingjing Chen, Na Zhao, Yu-Gang Jiang</author><pubDate>Tue, 19 Nov 2024 15:22:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12966v4</guid></item><item><title>Recall and Refine: A Simple but Effective Source-free Open-set Domain Adaptation Framework</title><link>http://arxiv.org/abs/2411.12558v1</link><description>Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled sourcedomain to an unlabeled target domain, where novel classes - also referred to astarget-private unknown classes - are present. Source-free Open-set DomainAdaptation (SF-OSDA) methods address OSDA without accessing labeled sourcedata, making them particularly relevant under privacy constraints. However,SF-OSDA presents significant challenges due to distribution shifts and theintroduction of novel classes. Existing SF-OSDA methods typically rely onthresholding the prediction entropy of a sample to identify it as either aknown or unknown class but fail to explicitly learn discriminative features forthe target-private unknown classes. We propose Recall and Refine (RRDA), anovel SF-OSDA framework designed to address these limitations by explicitlylearning features for target-private unknown classes. RRDA employs a two-stepprocess. First, we enhance the model's capacity to recognize unknown classes bytraining a target classifier with an additional decision boundary, guided bysynthetic samples generated from target domain features. This enables theclassifier to effectively separate known and unknown classes. In the secondstep, we adapt the entire model to the target domain, addressing both domainshifts and improving generalization to unknown classes. Any off-the-shelfsource-free domain adaptation method (e.g., SHOT, AaD) can be seamlesslyintegrated into our framework at this stage. Extensive experiments on threebenchmark datasets demonstrate that RRDA significantly outperforms existingSF-OSDA and OSDA methods.</description><author>Ismail Nejjar, Hao Dong, Olga Fink</author><pubDate>Tue, 19 Nov 2024 15:18:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12558v1</guid></item><item><title>UMGAD: Unsupervised Multiplex Graph Anomaly Detection</title><link>http://arxiv.org/abs/2411.12556v1</link><description>Graph anomaly detection (GAD) is a critical task in graph machine learning,with the primary objective of identifying anomalous nodes that deviatesignificantly from the majority. This task is widely applied in variousreal-world scenarios, including fraud detection and social network analysis.However, existing GAD methods still face two major challenges: (1) They areoften limited to detecting anomalies in single-type interaction graphs andstruggle with multiple interaction types in multiplex heterogeneous graphs; (2)In unsupervised scenarios, selecting appropriate anomaly score thresholdsremains a significant challenge for accurate anomaly detection. To address theabove challenges, we propose a novel Unsupervised Multiplex Graph AnomalyDetection method, named UMGAD. We first learn multi-relational correlationsamong nodes in multiplex heterogeneous graphs and capture anomaly informationduring node attribute and structure reconstruction through graph-maskedautoencoder (GMAE). Then, to further weaken the influence of noise andredundant information on abnormal information extraction, we generateattribute-level and subgraph-level augmented-view graphs respectively, andperform attribute and structure reconstruction through GMAE. Finally, We learnto optimize node attributes and structural features through contrastivelearning between original-view and augmented-view graphs to improve the model'sability to capture anomalies. Meanwhile, we also propose a new anomaly scorethreshold selection strategy, which allows the model to be independent of theground truth in real unsupervised scenarios. Extensive experiments on fourdatasets show that our \model significantly outperforms state-of-the-artmethods, achieving average improvements of 13.48% in AUC and 11.68% in Macro-F1across all datasets.</description><author>Xiang Li, Jianpeng Qi, Zhongying Zhao, Guanjie Zheng, Lei Cao, Junyu Dong, Yanwei Yu</author><pubDate>Tue, 19 Nov 2024 15:15:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12556v1</guid></item><item><title>Multivariate and Online Transfer Learning with Uncertainty Quantification</title><link>http://arxiv.org/abs/2411.12555v1</link><description>Untreated periodontitis causes inflammation within the supporting tissue ofthe teeth and can ultimately lead to tooth loss. Modeling periodontal outcomesis beneficial as they are difficult and time consuming to measure, butdisparities in representation between demographic groups must be considered.There may not be enough participants to build group specific models and it canbe ineffective, and even dangerous, to apply a model to participants in anunderrepresented group if demographic differences were not considered duringtraining. We propose an extension to RECaST Bayesian transfer learningframework. Our method jointly models multivariate outcomes, exhibitingsignificant improvement over the previous univariate RECaST method. Further, weintroduce an online approach to model sequential data sets. Negative transferis mitigated to ensure that the information shared from the other demographicgroups does not negatively impact the modeling of the underrepresentedparticipants. The Bayesian framework naturally provides uncertaintyquantification on predictions. Especially important in medical applications,our method does not share data between domains. We demonstrate theeffectiveness of our method in both predictive performance and uncertaintyquantification on simulated data and on a database of dental records from theHealthPartners Institute.</description><author>Jimmy Hickey, Jonathan P. Williams, Brian J. Reich, Emily C. Hector</author><pubDate>Tue, 19 Nov 2024 15:14:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12555v1</guid></item><item><title>Machine Learning Algorithms to Assess Site Closure Time Frames for Soil and Groundwater Contamination</title><link>http://arxiv.org/abs/2411.10214v2</link><description>Monitored Natural Attenuation (MNA) is gaining prominence as an effectivemethod for managing soil and groundwater contamination due to itscost-efficiency and minimal environmental disruption. Despite its benefits, MNAnecessitates extensive groundwater monitoring to ensure that contaminant levelsdecrease to meet safety standards. This study expands the capabilities ofPyLEnM, a Python package designed for long-term environmental monitoring, byincorporating new algorithms to enhance its predictive and analyticalfunctionalities. We introduce methods to estimate the timeframe required forcontaminants like Sr-90 and I-129 to reach regulatory safety standards usinglinear regression and to forecast future contaminant levels with theBidirectional Long Short-Term Memory (Bi-LSTM) networks. Additionally, RandomForest regression is employed to identify factors influencing the time to reachsafety standards. Our methods are illustrated using data from the SavannahRiver Site (SRS) F-Area, where preliminary findings reveal a notable downwardtrend in contaminant levels, with variability linked to initial concentrationsand groundwater flow dynamics. The Bi-LSTM model effectively predictscontaminant concentrations for the next four years, demonstrating the potentialof advanced time series analysis to improve MNA strategies and reduce relianceon manual groundwater sampling. The code, along with its usage instructions,validation, and requirements, is available at:https://github.com/csplevuanh/pylenm_extension.</description><author>Vu-Anh Le, Haruko Murakami Wainwright, Hansell Gonzalez-Raymat, Carol Eddy-Dilek</author><pubDate>Tue, 19 Nov 2024 15:09:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10214v2</guid></item><item><title>CARLA2Real: a tool for reducing the sim2real gap in CARLA simulator</title><link>http://arxiv.org/abs/2410.18238v3</link><description>Simulators are indispensable for research in autonomous systems such asself-driving cars, autonomous robots and drones. Despite significant progressin various simulation aspects, such as graphical realism, an evident gappersists between the virtual and real-world environments. Since the ultimategoal is to deploy the autonomous systems in the real world, closing thesim2real gap is of utmost importance. In this paper, we employ astate-of-the-art approach to enhance the photorealism of simulated data,aligning them with the visual characteristics of real-world datasets. Based onthis, we developed CARLA2Real, an easy-to-use, publicly available tool(plug-in) for the widely used and open-source CARLA simulator. This toolenhances the output of CARLA in near real-time, achieving a frame rate of 13FPS, translating it to the visual style and realism of real-world datasets suchas Cityscapes, KITTI, and Mapillary Vistas. By employing the proposed tool, wegenerated synthetic datasets from both the simulator and the enhancement modeloutputs, including their corresponding ground truth annotations for tasksrelated to autonomous driving. Then, we performed a number of experiments toevaluate the impact of the proposed approach on feature extraction and semanticsegmentation methods when trained on the enhanced synthetic data. The resultsdemonstrate that the sim2real gap is significant and can indeed be reduced bythe introduced approach.</description><author>Stefanos Pasios, Nikos Nikolaidis</author><pubDate>Tue, 19 Nov 2024 15:06:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18238v3</guid></item><item><title>S3TU-Net: Structured Convolution and Superpixel Transformer for Lung Nodule Segmentation</title><link>http://arxiv.org/abs/2411.12547v1</link><description>The irregular and challenging characteristics of lung adenocarcinoma nodulesin computed tomography (CT) images complicate staging diagnosis, makingaccurate segmentation critical for clinicians to extract detailed lesioninformation. In this study, we propose a segmentation model, S3TU-Net, whichintegrates multi-dimensional spatial connectors and a superpixel-based visualtransformer. S3TU-Net is built on a multi-view CNN-Transformer hybridarchitecture, incorporating superpixel algorithms, structured weighting, andspatial shifting techniques to achieve superior segmentation performance. Themodel leverages structured convolution blocks (DWF-Conv/D2BR-Conv) to extractmulti-scale local features while mitigating overfitting. To enhance multi-scalefeature fusion, we introduce the S2-MLP Link, integrating spatial shifting andattention mechanisms at the skip connections. Additionally, the residual-basedsuperpixel visual transformer (RM-SViT) effectively merges global and localfeatures by employing sparse correlation learning and multi-branch attention tocapture long-range dependencies, with residual connections enhancing stabilityand computational efficiency. Experimental results on the LIDC-IDRI datasetdemonstrate that S3TU-Net achieves a DSC, precision, and IoU of 89.04%, 90.73%,and 90.70%, respectively. Compared to recent methods, S3TU-Net improves DSC by4.52% and sensitivity by 3.16%, with other metrics showing an approximate 2%increase. In addition to comparison and ablation studies, we validated thegeneralization ability of our model on the EPDB private dataset, achieving aDSC of 86.40%.</description><author>Yuke Wu, Xiang Liu, Yunyu Shi, Xinyi Chen, Zhenglei Wang, YuQing Xu, Shuo Hong Wang</author><pubDate>Tue, 19 Nov 2024 15:00:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12547v1</guid></item><item><title>Automatic Classification of General Movements in Newborns</title><link>http://arxiv.org/abs/2411.09821v2</link><description>General movements (GMs) are spontaneous, coordinated body movements ininfants that offer valuable insights into the developing nervous system.Assessed through the Prechtl GM Assessment (GMA), GMs are reliable predictorsfor neurodevelopmental disorders. However, GMA requires specifically trainedclinicians, who are limited in number. To scale up newborn screening, there isa need for an algorithm that can automatically classify GMs from infant videorecordings. This data poses challenges, including variability in recordinglength, device type, and setting, with each video coarsely annotated foroverall movement quality. In this work, we introduce a tool for extractingfeatures from these recordings and explore various machine learning techniquesfor automated GM classification.</description><author>Daphné Chopard, Sonia Laguna, Kieran Chin-Cheong, Annika Dietz, Anna Badura, Sven Wellmann, Julia E. Vogt</author><pubDate>Tue, 19 Nov 2024 14:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.09821v2</guid></item><item><title>MMTryon: Multi-Modal Multi-Reference Control for High-Quality Fashion Generation</title><link>http://arxiv.org/abs/2405.00448v3</link><description>This paper introduces MMTryon, a multi-modal multi-reference VIrtual Try-ON(VITON) framework, which can generate high-quality compositional try-on resultsby taking a text instruction and multiple garment images as inputs. Our MMTryonaddresses three problems overlooked in prior literature: 1) Support of multipletry-on items. Existing methods are commonly designed for single-item try-ontasks (e.g., upper/lower garments, dresses). 2)Specification of dressing style.Existing methods are unable to customize dressing styles based on instructions(e.g., zipped/unzipped, tuck-in/tuck-out, etc.) 3) Segmentation Dependency.They further heavily rely on category-specific segmentation models to identifythe replacement regions, with segmentation errors directly leading tosignificant artifacts in the try-on results. To address the first two issues,our MMTryon introduces a novel multi-modality and multi-reference attentionmechanism to combine the garment information from reference images anddressing-style information from text instructions. Besides, to remove thesegmentation dependency, MMTryon uses a parsing-free garment encoder andleverages a novel scalable data generation pipeline to convert existing VITONdatasets to a form that allows MMTryon to be trained without requiring anyexplicit segmentation. Extensive experiments on high-resolution benchmarks andin-the-wild test sets demonstrate MMTryon's superiority over existing SOTAmethods both qualitatively and quantitatively. MMTryon's impressive performanceon multi-item and style-controllable virtual try-on scenarios and its abilityto try on any outfit in a large variety of scenarios from any source image,opens up a new avenue for future investigation in the fashion community.</description><author>Xujie Zhang, Ente Lin, Xiu Li, Yuxuan Luo, Michael Kampffmeyer, Xin Dong, Xiaodan Liang</author><pubDate>Tue, 19 Nov 2024 14:52:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00448v3</guid></item><item><title>CLIP-VG: Self-paced Curriculum Adapting of CLIP for Visual Grounding</title><link>http://arxiv.org/abs/2305.08685v5</link><description>Visual Grounding (VG) is a crucial topic in the field of vision and language,which involves locating a specific region described by expressions within animage. To reduce the reliance on manually labeled data, unsupervised visualgrounding have been developed to locate regions using pseudo-labels. However,the performance of existing unsupervised methods is highly dependent on thequality of pseudo-labels and these methods always encounter issues with limiteddiversity. In order to utilize vision and language pre-trained models toaddress the grounding problem, and reasonably take advantage of pseudo-labels,we propose CLIP-VG, a novel method that can conduct self-paced curriculumadapting of CLIP with pseudo-language labels. We propose a simple yet efficientend-to-end network architecture to realize the transfer of CLIP to the visualgrounding. Based on the CLIP-based architecture, we further proposesingle-source and multi-source curriculum adapting algorithms, which canprogressively find more reliable pseudo-labels to learn an optimal model,thereby achieving a balance between reliability and diversity for thepseudo-language labels. Our method outperforms the current state-of-the-artunsupervised method by a significant margin on RefCOCO/+/g datasets in bothsingle-source and multi-source scenarios, with improvements ranging from6.78$\%$ to 10.67$\%$ and 11.39$\%$ to 14.87$\%$, respectively. The resultseven outperform existing weakly supervised visual grounding methods.Furthermore, our method is also competitive in fully supervised setting. Thecode and models are available at https://github.com/linhuixiao/CLIP-VG.</description><author>Linhui Xiao, Xiaoshan Yang, Fang Peng, Ming Yan, Yaowei Wang, Changsheng Xu</author><pubDate>Tue, 19 Nov 2024 14:52:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08685v5</guid></item><item><title>Zero-Shot Image Denoising for High-Resolution Electron Microscopy</title><link>http://arxiv.org/abs/2406.14264v2</link><description>High-resolution electron microscopy (HREM) imaging technique is a powerfultool for directly visualizing a broad range of materials in real-space.However, it faces challenges in denoising due to ultra-low signal-to-noiseratio (SNR) and scarce data availability. In this work, we propose Noise2SR, azero-shot self-supervised learning (ZS-SSL) denoising framework for HREM.Within our framework, we propose a super-resolution (SR) based self-supervisedtraining strategy, incorporating the Random Sub-sampler module. The RandomSub-sampler is designed to generate approximate infinite noisy pairs from asingle noisy image, serving as an effective data augmentation in zero-shotdenoising. Noise2SR trains the network with paired noisy images of differentresolutions, which is conducted via SR strategy. The SR-based trainingfacilitates the network adopting more pixels for supervision, and the randomsub-sampling helps compel the network to learn continuous signals enhancing therobustness. Meanwhile, we mitigate the uncertainty caused by random-sampling byadopting minimum mean squared error (MMSE) estimation for the denoised results.With the distinctive integration of training strategy and proposed designs,Noise2SR can achieve superior denoising performance using a single noisy HREMimage. We evaluate the performance of Noise2SR in both simulated and real HREMdenoising tasks. It outperforms state-of-the-art ZS-SSL methods and achievescomparable denoising performance with supervised methods. The success ofNoise2SR suggests its potential for improving the SNR of images in materialimaging domains.</description><author>Xuanyu Tian, Zhuoya Dong, Xiyue Lin, Yue Gao, Hongjiang Wei, Yanhang Ma, Jingyi Yu, Yuyao Zhang</author><pubDate>Tue, 19 Nov 2024 14:51:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14264v2</guid></item></channel></rss>