<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 13 Feb 2025 01:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Pippo: High-Resolution Multi-View Humans from a Single Image</title><link>http://arxiv.org/abs/2502.07785v1</link><description>We present Pippo, a generative model capable of producing 1K resolution denseturnaround videos of a person from a single casually clicked photo. Pippo is amulti-view diffusion transformer and does not require any additional inputs -e.g., a fitted parametric model or camera parameters of the input image. Wepre-train Pippo on 3B human images without captions, and conduct multi-viewmid-training and post-training on studio captured humans. During mid-training,to quickly absorb the studio dataset, we denoise several (up to 48) views atlow-resolution, and encode target cameras coarsely using a shallow MLP. Duringpost-training, we denoise fewer views at high-resolution and use pixel-alignedcontrols (e.g., Spatial anchor and Plucker rays) to enable 3D consistentgenerations. At inference, we propose an attention biasing technique thatallows Pippo to simultaneously generate greater than 5 times as many views asseen during training. Finally, we also introduce an improved metric to evaluate3D consistency of multi-view generations, and show that Pippo outperformsexisting works on multi-view human generation from a single image.</description><author>Yash Kant, Ethan Weber, Jin Kyu Kim, Rawal Khirodkar, Su Zhaoen, Julieta Martinez, Igor Gilitschenski, Shunsuke Saito, Timur Bagautdinov</author><pubDate>Tue, 11 Feb 2025 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07785v1</guid></item><item><title>MatSwap: Light-aware material transfers in images</title><link>http://arxiv.org/abs/2502.07784v1</link><description>We present MatSwap, a method to transfer materials to designated surfaces inan image photorealistically. Such a task is non-trivial due to the largeentanglement of material appearance, geometry, and lighting in a photograph. Inthe literature, material editing methods typically rely on either cumbersometext engineering or extensive manual annotations requiring artist knowledge and3D scene properties that are impractical to obtain. In contrast, we propose todirectly learn the relationship between the input material -- as observed on aflat surface -- and its appearance within the scene, without the need forexplicit UV mapping. To achieve this, we rely on a custom light- andgeometry-aware diffusion model. We fine-tune a large-scale pre-trainedtext-to-image model for material transfer using our synthetic dataset,preserving its strong priors to ensure effective generalization to real images.As a result, our method seamlessly integrates a desired material into thetarget location in the photograph while retaining the identity of the scene. Weevaluate our method on synthetic and real images and show that it comparesfavorably to recent work both qualitatively and quantitatively. We will releaseour code and data upon publication.</description><author>Ivan Lopes, Valentin Deschaintre, Yannick Hold-Geoffroy, Raoul de Charette</author><pubDate>Tue, 11 Feb 2025 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07784v1</guid></item><item><title>Curvature Tuning: Provable Training-free Model Steering From a Single Parameter</title><link>http://arxiv.org/abs/2502.07783v1</link><description>The scaling of model size and data size has reshaped the paradigm of AI. As aresult, the common protocol to leverage the latest models is to steer themtowards a specific downstream task of interest through {\em fine-tuning}.Despite its importance, the main methods for fine-tuning remain limited to fullor low-rank adapters--containing countless hyper-parameters and lackinginterpretability. In this paper, we take a step back and demonstrate how noveland explainable post-training steering solutions can be derived theoreticallyfrom {\em spline operators}, a rich mathematical framing of Deep Networks thatwas recently developed. Our method--coined \textbf{Curvature Tuning (CT)}--hasa single parameter that provably modulates the curvature of the model'sdecision boundary henceforth allowing training-free steering. This makes CTboth more efficient and interpretable than conventional fine-tuning methods. Weempirically validate its effectiveness in improving generalization androbustness of pretrained models. For example, CT improves out-of-distributiontransfer performances of ResNet-18/50 by 2.57\%/1.74\% across seventeendownstream datasets, and improves RobustBench robust accuracy by11.76\%/348.44\%. Additionally, we apply CT to ReLU-based Swin-T/S, improvingtheir generalization on nine downstream datasets by 2.43\%/3.33\%. Our code isavailable at\href{https://github.com/Leon-Leyang/curvature-tuning}{https://github.com/Leon-Leyang/curvature-tuning}.</description><author>Leyang Hu, Randall Balestriero</author><pubDate>Tue, 11 Feb 2025 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07783v1</guid></item><item><title>A Flag Decomposition for Hierarchical Datasets</title><link>http://arxiv.org/abs/2502.07782v1</link><description>Flag manifolds encode hierarchical nested sequences of subspaces and serve aspowerful structures for various computer vision and machine learningapplications. Despite their utility in tasks such as dimensionality reduction,motion averaging, and subspace clustering, current applications are oftenrestricted to extracting flags using common matrix decomposition methods likethe singular value decomposition. Here, we address the need for a generalalgorithm to factorize and work with hierarchical datasets. In particular, wepropose a novel, flag-based method that decomposes arbitrary hierarchicalreal-valued data into a hierarchy-preserving flag representation in Stiefelcoordinates. Our work harnesses the potential of flag manifolds in applicationsincluding denoising, clustering, and few-shot learning.</description><author>Nathan Mankovich, Ignacio Santamaria, Gustau Camps-Valls, Tolga Birdal</author><pubDate>Tue, 11 Feb 2025 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07782v1</guid></item><item><title>Training Language Models on Synthetic Edit Sequences Improves Code Synthesis</title><link>http://arxiv.org/abs/2410.02749v3</link><description>Software engineers mainly write code by editing existing programs. Incontrast, language models (LMs) autoregressively synthesize programs in asingle pass. One explanation for this is the scarcity of sequential edit data.While high-quality instruction data for code synthesis is scarce, edit data forsynthesis is even scarcer. To fill this gap, we develop a synthetic datageneration algorithm called LintSeq. This algorithm refactors programs intosequences of synthetic edits by using a linter to procedurally sample acrossinterdependent lines of source code. Synthetic edits sampled with LintSeqreflect the syntax and semantics of their programming language. To test thealgorithm, we use it to refactor a dataset of instruction + program pairs intoinstruction + program-diff-sequence tuples. Then, we fine-tune a series ofsmaller LMs ranging from 2.6B to 14B parameters on both the re-factored andoriginal versions of this dataset. We perform comprehensive evaluationscomparing edit sequence code LMs against baselines on HumanEval, MBPP(+),CodeContests, DS-1000, and BigCodeBench. We show that models fine-tuned toiteratively synthesize code match or outperform baselines on pass@1, andexhibit better scaling across higher pass@k as a function of total test-timeFLOPs. Finally, we also pretrain our own tiny LMs for code understanding. Weshow that fine-tuning these models to synthesize code edit-by-edit results instrong performance on HumanEval and MBPP(+) compared to existing code languagemodels of similar scale such as CodeT5+, AlphaCode, and Codex.</description><author>Ulyana Piterbarg, Lerrel Pinto, Rob Fergus</author><pubDate>Tue, 11 Feb 2025 18:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02749v3</guid></item><item><title>DarwinLM: Evolutionary Structured Pruning of Large Language Models</title><link>http://arxiv.org/abs/2502.07780v1</link><description>Large Language Models (LLMs) have achieved significant success across variousNLP tasks. However, their massive computational costs limit their widespreaduse, particularly in real-time applications. Structured pruning offers aneffective solution by compressing models and directly providing end-to-endspeed improvements, regardless of the hardware environment. Meanwhile,different components of the model exhibit varying sensitivities towardspruning, calling for \emph{non-uniform} model compression. However, a pruningmethod should not only identify a capable substructure, but also account forpost-compression training. To this end, we propose \sysname, a method for\emph{training-aware} structured pruning. \sysname builds upon an evolutionarysearch process, generating multiple offspring models in each generation throughmutation, and selecting the fittest for survival. To assess the effect ofpost-training, we incorporate a lightweight, multistep training process withinthe offspring population, progressively increasing the number of tokens andeliminating poorly performing models in each selection stage. We validate ourmethod through extensive experiments on Llama-2-7B, Llama-3.1-8B andQwen-2.5-14B-Instruct, achieving state-of-the-art performance for structuredpruning. For instance, \sysname surpasses ShearedLlama while requiring$5\times$ less training data during post-compression training.</description><author>Shengkun Tang, Oliver Sieberling, Eldar Kurtic, Zhiqiang Shen, Dan Alistarh</author><pubDate>Tue, 11 Feb 2025 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07780v1</guid></item><item><title>OLMES: A Standard for Language Model Evaluations</title><link>http://arxiv.org/abs/2406.08446v2</link><description>Progress in AI is often demonstrated by new models claiming improvedperformance on tasks measuring model capabilities. Evaluating language modelscan be particularly challenging, as choices of how a model is evaluated on atask can lead to large changes in measured performance. There is no commonstandard setup, so different models are evaluated on the same tasks indifferent ways, leading to claims about which models perform best not beingreproducible. We propose OLMES, a completely documented, practical, openstandard for reproducible LLM evaluations. In developing this standard, weidentify and review the varying factors in evaluation practices adopted by thecommunity - such as details of prompt formatting, choice of in-contextexamples, probability normalizations, and task formulation. In particular,OLMES supports meaningful comparisons between smaller base models that requirethe unnatural "cloze" formulation of multiple-choice questions against largermodels that can utilize the original formulation. OLMES includeswell-considered, documented recommendations guided by results from existingliterature as well as new experiments resolving open questions.</description><author>Yuling Gu, Oyvind Tafjord, Bailey Kuehl, Dany Haddad, Jesse Dodge, Hannaneh Hajishirzi</author><pubDate>Tue, 11 Feb 2025 18:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08446v2</guid></item><item><title>Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection</title><link>http://arxiv.org/abs/2502.07778v1</link><description>Detecting AI generated images is a challenging yet essential task. A primarydifficulty arises from the detectors tendency to rely on spurious patterns,such as compression artifacts, which can influence its decisions. These issuesoften stem from specific patterns that the detector associates with the realdata distribution, making it difficult to isolate the actual generative traces.We argue that an image should be classified as fake if and only if it containsartifacts introduced by the generative model. Based on this premise, we proposeStay Positive, an algorithm designed to constrain the detectors focus togenerative artifacts while disregarding those associated with real data.Experimental results demonstrate that detectors trained with Stay Positiveexhibit reduced susceptibility to spurious correlations, leading to improvedgeneralization and robustness to post processing. Additionally, unlikedetectors that associate artifacts with real images, those that focus purely onfake artifacts are better at detecting inpainted real images.</description><author>Anirudh Sundara Rajan, Yong Jae Lee</author><pubDate>Tue, 11 Feb 2025 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07778v1</guid></item><item><title>Auditing Prompt Caching in Language Model APIs</title><link>http://arxiv.org/abs/2502.07776v1</link><description>Prompt caching in large language models (LLMs) results in data-dependenttiming variations: cached prompts are processed faster than non-cached prompts.These timing differences introduce the risk of side-channel timing attacks. Forexample, if the cache is shared across users, an attacker could identify cachedprompts from fast API response times to learn information about other users'prompts. Because prompt caching may cause privacy leakage, transparency aroundthe caching policies of API providers is important. To this end, we develop andconduct statistical audits to detect prompt caching in real-world LLM APIproviders. We detect global cache sharing across users in seven API providers,including OpenAI, resulting in potential privacy leakage about users' prompts.Timing variations due to prompt caching can also result in leakage ofinformation about model architecture. Namely, we find evidence that OpenAI'sembedding model is a decoder-only Transformer, which was previously notpublicly known.</description><author>Chenchen Gu, Xiang Lisa Li, Rohith Kuditipudi, Percy Liang, Tatsunori Hashimoto</author><pubDate>Tue, 11 Feb 2025 18:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07776v1</guid></item><item><title>Optimistic Interior Point Methods for Sequential Hypothesis Testing by Betting</title><link>http://arxiv.org/abs/2502.07774v1</link><description>The technique of "testing by betting" frames nonparametric sequentialhypothesis testing as a multiple-round game, where a player bets on futureobservations that arrive in a streaming fashion, accumulates wealth thatquantifies evidence against the null hypothesis, and rejects the null once thewealth exceeds a specified threshold while controlling the false positiveerror. Designing an online learning algorithm that achieves a small regret inthe game can help rapidly accumulate the bettor's wealth, which in turn canshorten the time to reject the null hypothesis under the alternative $H_1$.However, many of the existing works employ the Online Newton Step (ONS) toupdate within a halved decision space to avoid a gradient explosion issue,which is potentially conservative for rapid wealth accumulation. In this paper,we introduce a novel strategy utilizing interior-point methods in optimizationthat allows updates across the entire interior of the decision space withoutthe risk of gradient explosion. Our approach not only maintains strongstatistical guarantees but also facilitates faster null hypothesis rejection incritical scenarios, overcoming the limitations of existing approaches.</description><author>Can Chen, Jun-Kun Wang</author><pubDate>Tue, 11 Feb 2025 18:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07774v1</guid></item><item><title>Breaking Down Bias: On The Limits of Generalizable Pruning Strategies</title><link>http://arxiv.org/abs/2502.07771v1</link><description>We employ model pruning to examine how LLMs conceptualize racial biases, andwhether a generalizable mitigation strategy for such biases appears feasible.Our analysis yields several novel insights. We find that pruning can be aneffective method to reduce bias without significantly increasing anomalousmodel behavior. Neuron-based pruning strategies generally yield better resultsthan approaches pruning entire attention heads. However, our results also showthat the effectiveness of either approach quickly deteriorates as pruningstrategies become more generalized. For instance, a model that is trained onremoving racial biases in the context of financial decision-making poorlygeneralizes to biases in commercial transactions. Overall, our analysissuggests that racial biases are only partially represented as a general conceptwithin language models. The other part of these biases is highlycontext-specific, suggesting that generalizable mitigation strategies may be oflimited effectiveness. Our findings have important implications for legalframeworks surrounding AI. In particular, they suggest that an effectivemitigation strategy should include the allocation of legal responsibility onthose that deploy models in a specific use case.</description><author>Sibo Ma, Alejandro Salinas, Peter Henderson, Julian Nyarko</author><pubDate>Tue, 11 Feb 2025 18:55:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07771v1</guid></item><item><title>Cross-Lingual Transfer Learning for Speech Translation</title><link>http://arxiv.org/abs/2407.01130v3</link><description>There has been increasing interest in building multilingual foundation modelsfor NLP and speech research. This paper examines how to expand the speechtranslation capability of these models with restricted data. Whisper, a speechfoundation model with strong performance on speech recognition and Englishtranslation, is used as the example model. Using speech-to-speech retrieval toanalyse the audio representations generated by the encoder, we show thatutterances from different languages are mapped to a shared semantic space. Thisshared embedding space can then be leveraged for zero-shot cross-lingualtransfer in speech translation. By fine-tuning the Whisper decoder with onlyEnglish-to-Chinese speech translation data, improved performance fortranslation to Chinese can be obtained for multiple languages, in addition toEnglish. Furthermore, for languages related to those seen in training it ispossible to perform speech translation, despite the model never seeing thelanguage in training, or being able to perform transcription.</description><author>Rao Ma, Mengjie Qian, Yassir Fathullah, Siyuan Tang, Mark Gales, Kate Knill</author><pubDate>Tue, 11 Feb 2025 18:55:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01130v3</guid></item><item><title>ENFORCE: Exact Nonlinear Constrained Learning with Adaptive-depth Neural Projection</title><link>http://arxiv.org/abs/2502.06774v2</link><description>Ensuring neural networks adhere to domain-specific constraints is crucial foraddressing safety and ethical concerns while also enhancing predictionaccuracy. Despite the nonlinear nature of most real-world tasks, existingmethods are predominantly limited to affine or convex constraints. We introduceENFORCE, a neural network architecture that guarantees predictions to satisfynonlinear constraints exactly. ENFORCE is trained with standard unconstrainedgradient-based optimizers (e.g., Adam) and leverages autodifferentiation andlocal neural projections to enforce any $\mathcal{C}^1$ constraint to arbitrarytolerance $\epsilon$. We build an adaptive-depth neural projection (AdaNP)module that dynamically adjusts its complexity to suit the specific problem andthe required tolerance levels. ENFORCE guarantees satisfaction of equalityconstraints that are nonlinear in both inputs and outputs of the neural networkwith minimal (and adjustable) computational cost.</description><author>Giacomo Lastrucci, Artur M. Schweidtmann</author><pubDate>Tue, 11 Feb 2025 18:54:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.06774v2</guid></item><item><title>Effect of Adaptive Communication Support on LLM-powered Human-Robot Collaboration</title><link>http://arxiv.org/abs/2412.06808v2</link><description>Effective human-robot collaboration requires robot to adopt their roles andlevels of support based on human needs, task requirements, and complexity.Traditional human-robot teaming often relies on a pre-determined robotcommunication scheme, restricting teamwork adaptability in complex tasks.Leveraging strong communication capabilities of Large Language Models (LLMs),we propose a Human-Robot Teaming Framework with Multi-Modal Language feedback(HRT-ML), a framework designed to enhance human-robot interaction by adjustingthe frequency and content of language-based feedback. HRT-ML framework includestwo core modules: a Coordinator for high-level, low-frequency strategicguidance, and a Manager for subtask-specific, high-frequency instructions,enabling passive and active interactions with human teammates. To assess theimpact of language feedback in collaborative scenarios, we conductedexperiments in an enhanced Overcooked environment with varying levels of taskcomplexity (easy, medium, hard) and feedback frequency (inactive, passive,active, superactive). Our results show that as task complexity increasesrelative to human capabilities, human teammates exhibited a stronger preferencetowards robotic agents that can offer frequent, proactive support. However,when task complexities exceed the LLM's capacity, noisy and inaccurate feedbackfrom superactive robotic agents can instead hinder team performance, as itrequires human teammates to increase their effort to interpret and respond to alarge number of communications, with limited performance return. Our resultsoffer a general principle for robotic agents to dynamically adjust their levelsand frequencies of communications to work seamlessly with humans and achieveimproved teaming performance.</description><author>Shipeng Liu, FNU Shrutika, Boshen Zhang, Zhehui Huang, Gaurav Sukhatme, Feifei Qian</author><pubDate>Tue, 11 Feb 2025 18:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06808v2</guid></item><item><title>Polynomial-Time Approximability of Constrained Reinforcement Learning</title><link>http://arxiv.org/abs/2502.07764v1</link><description>We study the computational complexity of approximating general constrainedMarkov decision processes. Our primary contribution is the design of apolynomial time $(0,\epsilon)$-additive bicriteria approximation algorithm forfinding optimal constrained policies across a broad class of recursivelycomputable constraints, including almost-sure, chance, expectation, and theiranytime variants. Matching lower bounds imply our approximation guarantees areoptimal so long as $P \neq NP$. The generality of our approach results inanswers to several long-standing open complexity questions in the constrainedreinforcement learning literature. Specifically, we are the first to provepolynomial-time approximability for the following settings: policies underchance constraints, deterministic policies under multiple expectationconstraints, policies under non-homogeneous constraints (i.e., constraints ofdifferent types), and policies under constraints for continuous-stateprocesses.</description><author>Jeremy McMahan</author><pubDate>Tue, 11 Feb 2025 18:47:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07764v1</guid></item><item><title>Cache Me If You Must: Adaptive Key-Value Quantization for Large Language Models</title><link>http://arxiv.org/abs/2501.19392v2</link><description>Efficient real-world deployments of large language models (LLMs) rely onKey-Value (KV) caching for processing and generating long outputs, reducing theneed for repetitive computation. For large contexts, Key-Value caches can takeup tens of gigabytes of device memory, as they store vector representations foreach token and layer. Recent work has shown that the cached vectors can becompressed through quantization, pruning or merging, but these techniques oftencompromise quality towards higher compression rates. In this work, we aim toimprove Key &amp; Value compression by exploiting two observations: 1) the inherentdependencies between keys and values across different layers, and 2)high-compression mechanisms for internal network states. We propose AQUA-KV, anadaptive quantization for Key-Value caches that relies on compact adapters toexploit existing dependencies between Keys and Values, and aims to "optimally"compress the information that cannot be predicted. AQUA-KV significantlyimproves compression rates, while maintaining high accuracy on state-of-the-artLLM families. On Llama 3.2 LLMs, we achieve near-lossless inference at 2-2.5bits per value with under $1\%$ relative error in perplexity and LongBenchscores. AQUA-KV is one-shot, simple, and efficient: it can be calibrated on asingle GPU within 1-6 hours, even for 70B models.</description><author>Alina Shutova, Vladimir Malinovskii, Vage Egiazarian, Denis Kuznedelev, Denis Mazur, Nikita Surkov, Ivan Ermakov, Dan Alistarh</author><pubDate>Tue, 11 Feb 2025 18:45:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19392v2</guid></item><item><title>UVGS: Reimagining Unstructured 3D Gaussian Splatting using UV Mapping</title><link>http://arxiv.org/abs/2502.01846v2</link><description>3D Gaussian Splatting (3DGS) has demonstrated superior quality in modeling 3Dobjects and scenes. However, generating 3DGS remains challenging due to theirdiscrete, unstructured, and permutation-invariant nature. In this work, wepresent a simple yet effective method to overcome these challenges. We utilizespherical mapping to transform 3DGS into a structured 2D representation, termedUVGS. UVGS can be viewed as multi-channel images, with feature dimensions as aconcatenation of Gaussian attributes such as position, scale, color, opacity,and rotation. We further find that these heterogeneous features can becompressed into a lower-dimensional (e.g., 3-channel) shared feature spaceusing a carefully designed multi-branch network. The compressed UVGS can betreated as typical RGB images. Remarkably, we discover that typical VAEstrained with latent diffusion models can directly generalize to this newrepresentation without additional training. Our novel representation makes iteffortless to leverage foundational 2D models, such as diffusion models, todirectly model 3DGS. Additionally, one can simply increase the 2D UV resolutionto accommodate more Gaussians, making UVGS a scalable solution compared totypical 3D backbones. This approach immediately unlocks various novelgeneration applications of 3DGS by inherently utilizing the already developedsuperior 2D generation capabilities. In our experiments, we demonstrate variousunconditional, conditional generation, and inpainting applications of 3DGSbased on diffusion models, which were previously non-trivial.</description><author>Aashish Rai, Dilin Wang, Mihir Jain, Nikolaos Sarafianos, Kefan Chen, Srinath Sridhar, Aayush Prakash</author><pubDate>Tue, 11 Feb 2025 18:44:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01846v2</guid></item><item><title>Accessing Vision Foundation Models via ImageNet-1K</title><link>http://arxiv.org/abs/2407.10366v2</link><description>Vision foundation models are renowned for the generalization ability due tomassive training data. Nevertheless, they demand tremendous training resources,and the training data is often inaccessible, e.g., CLIP, DINOv2, posing greatchallenges to developing derivatives that could facilitate the research. Inthis work, we offer a very simple and general solution, named \textit{Proteus},to distill foundation models into smaller equivalents on ImageNet-1K withoutaccess to the original training data. Specifically, we remove the designs fromconventional knowledge distillation settings that result in dataset bias andpresent three levels of training objectives, i.e., token, patch, and feature,to maximize the efficacy of knowledge transfer. In this manner, Proteus istrained at ImageNet-level costs with surprising ability, facilitating theaccessibility of training foundation models for the broader research community.When leveraging DINOv2-g/14 as the teacher, Proteus-L/14 matches theperformance of the Oracle method DINOv2-L/14 (142M training data) across 19benchmarks and outperforms other vision foundation models including CLIP-L/14(400M), OpenCLIP-L/14 (400M/2B) and SynCLR-L/14 (600M) with a significantlysmaller training set of 1.2M images.</description><author>Yitian Zhang, Xu Ma, Yue Bai, Huan Wang, Yun Fu</author><pubDate>Tue, 11 Feb 2025 18:44:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10366v2</guid></item><item><title>Scalable Fingerprinting of Large Language Models</title><link>http://arxiv.org/abs/2502.07760v1</link><description>Model fingerprinting has emerged as a powerful tool for model owners toidentify their shared model given API access. However, to lower false discoveryrate, fight fingerprint leakage, and defend against coalitions of model usersattempting to bypass detection, we argue that {\em scalability} is critical,i.e., scaling up the number of fingerprints one can embed into a model. Hence,we pose scalability as a crucial requirement for fingerprinting schemes. Weexperiment with fingerprint design at a scale significantly larger thanpreviously considered, and introduce a new method, dubbed Perinucleus sampling,to generate scalable, persistent, and harmless fingerprints. We demonstratethat this scheme can add 24,576 fingerprints to a Llama-3.1-8B model -- twoorders of magnitude more than existing schemes -- without degrading the model'sutility. Our inserted fingerprints persist even after supervised fine-tuning onstandard post-training data. We further address security risks forfingerprinting, and theoretically and empirically show how a scalablefingerprinting scheme like ours can mitigate these risks.</description><author>Anshul Nasery, Jonathan Hayase, Creston Brooks, Peiyao Sheng, Himanshu Tyagi, Pramod Viswanath, Sewoong Oh</author><pubDate>Tue, 11 Feb 2025 18:43:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07760v1</guid></item><item><title>Language Model Council: Democratically Benchmarking Foundation Models on Highly Subjective Tasks</title><link>http://arxiv.org/abs/2406.08598v3</link><description>As Large Language Models (LLMs) continue to evolve, evaluating them remains apersistent challenge. Many recent evaluations use LLMs as judges to scoreoutputs from other LLMs, often relying on a single large model like GPT-4o.However, using a single LLM judge is prone to intra-model bias, and many tasks- such as those related to emotional intelligence, creative writing, andpersuasiveness - may be too subjective for a single model to judge fairly. Weintroduce the Language Model Council (LMC), where a group of LLMs collaborateto create tests, respond to them, and evaluate each other's responses toproduce a ranking in a democratic fashion. Unlike previous approaches thatfocus on reducing cost or bias by using a panel of smaller models, our workexamines the benefits and nuances of a fully inclusive LLM evaluation system.In a detailed case study on emotional intelligence, we deploy a council of 20recent LLMs to rank each other on open-ended responses to interpersonalconflicts. Our results show that the LMC produces rankings that are moreseparable and more robust, and through a user study, we show that they are moreconsistent with human evaluations than any individual LLM judge. Using all LLMsfor judging can be costly, however, so we use Monte Carlo simulations andhand-curated sub-councils to study hypothetical council compositions anddiscuss the value of the incremental LLM judge.</description><author>Justin Zhao, Flor Miriam Plaza-del-Arco, Benjie Genchel, Amanda Cercas Curry</author><pubDate>Tue, 11 Feb 2025 18:42:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08598v3</guid></item><item><title>Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras</title><link>http://arxiv.org/abs/2502.07758v1</link><description>Hypercomplex image processing extends conventional techniques in a unifiedparadigm encompassing algebraic and geometric principles. This work leveragesquaternions and the two-dimensional orthogonal planes split framework(splitting of a quaternion - representing a pixel - into pairs of orthogonal 2Dplanes) for natural/biomedical image analysis through the followingcomputational workflows and outcomes: natural/biomedical image re-colorization,natural image de-colorization, natural/biomedical image contrast enhancement,computational re-staining and stain separation in histological images, andperformance gains in machine/deep learning pipelines for histological images.The workflows are analyzed separately for natural and biomedical images toshowcase the effectiveness of the proposed approaches. The proposed workflowscan regulate color appearance (e.g. with alternative renditions and grayscaleconversion) and image contrast, be part of automated image processing pipelines(e.g. isolating stain components, boosting learning models), and assist indigital pathology applications (e.g. enhancing biomarker visibility, enablingcolorblind-friendly renditions). Employing only basic arithmetic and matrixoperations, this work offers a computationally accessible methodology - in thehypercomplex domain - that showcases versatility and consistency across imageprocessing tasks and a range of computer vision and biomedical applications.The proposed non-data-driven methods achieve comparable or better results(particularly in cases involving well-known methods) to those reported in theliterature, showcasing the potential of robust theoretical frameworks withpractical effectiveness. Results, methods, and limitations are detailedalongside discussion of promising extensions, emphasizing the potential offeature-rich mathematical/computational frameworks for natural and biomedicalimages.</description><author>Nektarios A. Valous, Eckhard Hitzer, Dragoş Duşe, Rodrigo Rojas Moraleda, Ferdinand Popp, Meggy Suarez-Carmona, Anna Berthel, Ismini Papageorgiou, Carlo Fremd, Alexander Rölle, Christina C. Westhoff, Bénédicte Lenoir, Niels Halama, Inka Zörnig, Dirk Jäger</author><pubDate>Tue, 11 Feb 2025 18:38:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07758v1</guid></item><item><title>From Fog to Failure: How Dehazing Can Harm Clear Image Object Detection</title><link>http://arxiv.org/abs/2502.02027v3</link><description>This study explores the challenges of integrating human visual cue-baseddehazing into object detection, given the selective nature of human perception.While human vision adapts dynamically to environmental conditions,computational dehazing does not always enhance detection uniformly. We proposea multi-stage framework where a lightweight detector identifies regions ofinterest (RoIs), which are then enhanced via spatial attention-based dehazingbefore final detection by a heavier model. Though effective in foggyconditions, this approach unexpectedly degrades the performance on clearimages. We analyze this phenomenon, investigate possible causes, and offerinsights for designing hybrid pipelines that balance enhancement and detection.Our findings highlight the need for selective preprocessing and challengeassumptions about universal benefits from cascading transformations.</description><author>Ashutosh Kumar, Aman Chadha</author><pubDate>Tue, 11 Feb 2025 18:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.02027v3</guid></item><item><title>An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating</title><link>http://arxiv.org/abs/2502.07755v1</link><description>This paper presents a novel Natural Language Processing (NLP) framework forenhancing medical diagnosis through the integration of advanced techniques indata augmentation, feature extraction, and classification. The proposedapproach employs back-translation to generate diverse paraphrased datasets,improving robustness and mitigating overfitting in classification tasks.Leveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) withDynamic Contextual Positional Gating (DCPG), the model captures fine-grainedcontextual and positional relationships, dynamically adjusting the influence ofpositional information based on semantic context to produce high-quality textembeddings. For classification, an Attention-Based Feedforward Neural Network(ABFNN) is utilized, effectively focusing on the most relevant features toimprove decision-making accuracy. Applied to the classification of symptoms,clinical notes, and other medical texts, this architecture demonstrates itsability to address the complexities of medical data. The combination of dataaugmentation, contextual embedding generation, and advanced classificationmechanisms offers a robust and accurate diagnostic tool, with potentialapplications in automated medical diagnosis and clinical decision support. Thismethod demonstrates the effectiveness of the proposed NLP framework for medicaldiagnosis, achieving remarkable results with an accuracy of 99.78%, recall of99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not onlyunderscore the model's robust performance in classifying medical texts withexceptional precision and reliability but also highlight its superiority overexisting methods, making it a highly promising tool for automated diagnosticsystems.</description><author>Mohammad Ali Labbaf Khaniki, Sahabeh Saadati, Mohammad Manthouri</author><pubDate>Tue, 11 Feb 2025 18:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07755v1</guid></item><item><title>MeshSplats: Mesh-Based Rendering with Gaussian Splatting Initialization</title><link>http://arxiv.org/abs/2502.07754v1</link><description>Gaussian Splatting (GS) is a recent and pivotal technique in 3D computergraphics. GS-based algorithms almost always bypass classical methods such asray tracing, which offers numerous inherent advantages for rendering. Forexample, ray tracing is able to handle incoherent rays for advanced lightingeffects, including shadows and reflections. To address this limitation, weintroduce MeshSplats, a method which converts GS to a mesh-like format.Following the completion of training, MeshSplats transforms Gaussian elementsinto mesh faces, enabling rendering using ray tracing methods with all theirassociated benefits. Our model can be utilized immediately followingtransformation, yielding a mesh of slightly reduced quality without additionaltraining. Furthermore, we can enhance the reconstruction quality through theapplication of a dedicated optimization algorithm that operates on mesh facesrather than Gaussian components. The efficacy of our method is substantiated byexperimental results, underscoring its extensive applications in computergraphics and image processing.</description><author>Rafał Tobiasz, Grzegorz Wilczyński, Marcin Mazur, Sławomir Tadeja, Przemysław Spurek</author><pubDate>Tue, 11 Feb 2025 18:27:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07754v1</guid></item><item><title>Direct Ascent Synthesis: Revealing Hidden Generative Capabilities in Discriminative Models</title><link>http://arxiv.org/abs/2502.07753v1</link><description>We demonstrate that discriminative models inherently contain powerfulgenerative capabilities, challenging the fundamental distinction betweendiscriminative and generative architectures. Our method, Direct AscentSynthesis (DAS), reveals these latent capabilities through multi-resolutionoptimization of CLIP model representations. While traditional inversionattempts produce adversarial patterns, DAS achieves high-quality imagesynthesis by decomposing optimization across multiple spatial scales (1x1 to224x224), requiring no additional training. This approach not only enablesdiverse applications -- from text-to-image generation to style transfer -- butmaintains natural image statistics ($1/f^2$ spectrum) and guides the generationaway from non-robust adversarial patterns. Our results demonstrate thatstandard discriminative models encode substantially richer generative knowledgethan previously recognized, providing new perspectives on modelinterpretability and the relationship between adversarial examples and naturalimage synthesis.</description><author>Stanislav Fort, Jonathan Whitaker</author><pubDate>Tue, 11 Feb 2025 18:27:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07753v1</guid></item><item><title>Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension</title><link>http://arxiv.org/abs/2502.07752v1</link><description>Designing efficient optimizers for large language models (LLMs) withlow-memory requirements and fast convergence is an important and challengingproblem. This paper makes a step towards the systematic design of suchoptimizers through the lens of structured Fisher information matrix (FIM)approximation. We show that many state-of-the-art efficient optimizers can beviewed as solutions to FIM approximation (under the Frobenius norm) withspecific structural assumptions. Building on these insights, we propose twodesign recommendations of practical efficient optimizers for LLMs, involvingthe careful selection of structural assumptions to balance generality andefficiency, and enhancing memory efficiency of optimizers with generalstructures through a novel low-rank extension framework. We demonstrate how touse each design approach by deriving new memory-efficient optimizers: Row andColumn Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation(Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate theeffectiveness, showing faster and better convergence than existingmemory-efficient baselines and Adam with little memory overhead. Notably, Aliceachieves better than 2x faster convergence over Adam, while RACS deliversstrong performance on the 1B model with SGD-like memory.</description><author>Wenbo Gong, Meyer Scetbon, Chao Ma, Edward Meeds</author><pubDate>Tue, 11 Feb 2025 18:27:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07752v1</guid></item><item><title>CausalGeD: Blending Causality and Diffusion for Spatial Gene Expression Generation</title><link>http://arxiv.org/abs/2502.07751v1</link><description>The integration of single-cell RNA sequencing (scRNA-seq) and spatialtranscriptomics (ST) data is crucial for understanding gene expression inspatial context. Existing methods for such integration have limitedperformance, with structural similarity often below 60\%, We attribute thislimitation to the failure to consider causal relationships between genes. Wepresent CausalGeD, which combines diffusion and autoregressive processes toleverage these relationships. By generalizing the Causal Attention Transformerfrom image generation to gene expression data, our model captures regulatorymechanisms without predefined relationships. Across 10 tissue datasets,CausalGeD outperformed state-of-the-art baselines by 5- 32\% in key metrics,including Pearson's correlation and structural similarity, advancing bothtechnical and biological insights.</description><author>Rabeya Tus Sadia, Md Atik Ahamed, Qiang Cheng</author><pubDate>Tue, 11 Feb 2025 18:26:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07751v1</guid></item><item><title>PFedDST: Personalized Federated Learning with Decentralized Selection Training</title><link>http://arxiv.org/abs/2502.07750v1</link><description>Distributed Learning (DL) enables the training of machine learning modelsacross multiple devices, yet it faces challenges like non-IID datadistributions and device capability disparities, which can impede trainingefficiency. Communication bottlenecks further complicate traditional FederatedLearning (FL) setups. To mitigate these issues, we introduce the PersonalizedFederated Learning with Decentralized Selection Training (PFedDST) framework.PFedDST enhances model training by allowing devices to strategically evaluateand select peers based on a comprehensive communication score. This scoreintegrates loss, task similarity, and selection frequency, ensuring optimalpeer connections. This selection strategy is tailored to increase localpersonalization and promote beneficial peer collaborations to strengthen thestability and efficiency of the training process. Our experiments demonstratethat PFedDST not only enhances model accuracy but also accelerates convergence.This approach outperforms state-of-the-art methods in handling dataheterogeneity, delivering both faster and more effective training in diverseand decentralized systems.</description><author>Mengchen Fan, Keren Li, Tianyun Zhang, Qing Tian, Baocheng Geng</author><pubDate>Tue, 11 Feb 2025 18:25:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07750v1</guid></item><item><title>Whole-Genome Phenotype Prediction with Machine Learning: Open Problems in Bacterial Genomics</title><link>http://arxiv.org/abs/2502.07749v1</link><description>How can we identify causal genetic mechanisms that govern bacterial traits?Initial efforts entrusting machine learning models to handle the task ofpredicting phenotype from genotype return high accuracy scores. However,attempts to extract any meaning from the predictive models are found to becorrupted by falsely identified "causal" features. Relying solely on patternrecognition and correlations is unreliable, significantly so in bacterialgenomics settings where high-dimensionality and spurious associations are thenorm. Though it is not yet clear whether we can overcome this hurdle,significant efforts are being made towards discovering potential high-riskbacterial genetic variants. In view of this, we set up open problemssurrounding phenotype prediction from bacterial whole-genome datasets andextending those to learning causal effects, and discuss challenges that impactthe reliability of a machine's decision-making when faced with datasets of thisnature.</description><author>Tamsin James, Ben Williamson, Peter Tino, Nicole Wheeler</author><pubDate>Tue, 11 Feb 2025 18:25:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07749v1</guid></item><item><title>An Efficient Rehearsal Scheme for Catastrophic Forgetting Mitigation during Multi-stage Fine-tuning</title><link>http://arxiv.org/abs/2402.08096v3</link><description>Incrementally fine-tuning foundational models on new tasks or domains is nowthe de facto approach in NLP. A known pitfall of this approach is the\emph{catastrophic forgetting} of prior knowledge that happens duringfine-tuning. A common approach to alleviate such forgetting is to rehearsesamples from prior tasks during fine-tuning. Several existing works assume afixed memory buffer to store prior task examples, while relying on inferences(forward passes) with the model at hand for choosing examples for rehearsalfrom the buffer. However, given the increasing computational cost of modelinference, and decreasing cost of data storage, we focus on the setting torehearse samples with a fixed computational budget instead of a fixed memorybudget. We propose a sampling scheme, \texttt{\bf mix-cd}, that prioritizesrehearsal of ``collateral damage'' samples, which are samples predictedcorrectly by the prior model but forgotten by the incrementally tuned one. Thecrux of our scheme is a procedure to efficiently estimate the density ofcollateral damage samples without incurring additional model inferences. Ourapproach is computationally efficient, easy to implement, and outperformsseveral leading continual learning methods in compute-constrained settings. Allthe code will be publicly available athttps://github.com/jybai/mix-cd-rehearsal.</description><author>Andrew Bai, Chih-Kuan Yeh, Cho-Jui Hsieh, Ankur Taly</author><pubDate>Tue, 11 Feb 2025 18:25:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08096v3</guid></item><item><title>Reinforcement Learning from Human Feedback with Active Queries</title><link>http://arxiv.org/abs/2402.09401v2</link><description>Aligning large language models (LLM) with human preference plays a key rolein building modern generative models and can be achieved by reinforcementlearning from human feedback (RLHF). Despite their superior performance,current RLHF approaches often require a large amount of human-labelledpreference data, which is expensive to collect. In this paper, inspired by thesuccess of active learning, we address this problem by proposingquery-efficient RLHF methods. We first formalize the alignment problem as acontextual dueling bandit problem and design an active-query-based proximalpolicy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$instance-dependent regret bound and an $\tilde{O}(d^2/\Delta^2)$ querycomplexity, where $d$ is the dimension of feature space and $\Delta$ is thesub-optimality gap over all the contexts. We then propose ADPO, a practicalversion of our algorithm based on direct preference optimization (DPO) andapply it to fine-tuning LLMs. Our experiments show that ADPO, while only makingabout half of queries for human preference, matches the performance of thestate-of-the-art DPO method.</description><author>Kaixuan Ji, Jiafan He, Quanquan Gu</author><pubDate>Tue, 11 Feb 2025 18:18:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09401v2</guid></item><item><title>Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models</title><link>http://arxiv.org/abs/2407.05502v3</link><description>Although the multilingual capability of LLMs offers new opportunities toovercome the language barrier, do these capabilities translate into real-lifescenarios where linguistic divide and knowledge conflicts between multilingualsources are known occurrences? In this paper, we studied LLM's linguisticpreference in a cross-language RAG-based information search setting. We foundthat LLMs displayed systemic bias towards information in the same language asthe query language in both document retrieval and answer generation.Furthermore, in scenarios where no information is in the language of the query,LLMs prefer documents in high-resource languages during generation, potentiallyreinforcing the dominant views. Such bias exists for both factual andopinion-based queries. Our results highlight the linguistic divide withinmultilingual LLMs in information search systems. The seemingly beneficialmultilingual capability of LLMs may backfire on information parity byreinforcing language-specific information cocoons or filter bubbles furthermarginalizing low-resource views.</description><author>Nikhil Sharma, Kenton Murray, Ziang Xiao</author><pubDate>Tue, 11 Feb 2025 18:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05502v3</guid></item><item><title>WHODUNIT: Evaluation benchmark for culprit detection in mystery stories</title><link>http://arxiv.org/abs/2502.07747v1</link><description>We present a novel data set, WhoDunIt, to assess the deductive reasoningcapabilities of large language models (LLM) within narrative contexts.Constructed from open domain mystery novels and short stories, the datasetchallenges LLMs to identify the perpetrator after reading and comprehending thestory. To evaluate model robustness, we apply a range of character-level nameaugmentations, including original names, name swaps, and substitutions withwell-known real and/or fictional entities from popular discourse. We furtheruse various prompting styles to investigate the influence of prompting ondeductive reasoning accuracy. We conduct evaluation study with state-of-the-art models, specificallyGPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials withmajority response selection to ensure reliability. The results demonstrate thatwhile LLMs perform reliably on unaltered texts, accuracy diminishes withcertain name substitutions, particularly those with wide recognition. Thisdataset is publicly available here.</description><author>Kshitij Gupta</author><pubDate>Tue, 11 Feb 2025 18:14:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07747v1</guid></item><item><title>HiPoNet: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data</title><link>http://arxiv.org/abs/2502.07746v1</link><description>In this paper, we propose HiPoNet, an end-to-end differentiable neuralnetwork for regression, classification, and representation learning onhigh-dimensional point clouds. Single-cell data can have high dimensionalityexceeding the capabilities of existing methods point cloud tailored for 3Ddata. Moreover, modern single-cell and spatial experiments now yield entirecohorts of datasets (i.e. one on every patient), necessitating models that canprocess large, high-dimensional point clouds at scale. Most current approachesbuild a single nearest-neighbor graph, discarding important geometricinformation. In contrast, HiPoNet forms higher-order simplicial complexesthrough learnable feature reweighting, generating multiple data views thatdisentangle distinct biological processes. It then employs simplicial wavelettransforms to extract multi-scale features - capturing both local and globaltopology. We empirically show that these components preserve topologicalinformation in the learned representations, and that HiPoNet significantlyoutperforms state-of-the-art point-cloud and graph-based models on single cell.We also show an application of HiPoNet on spatial transcriptomics datasetsusing spatial co-ordinates as one of the views. Overall, HiPoNet offers arobust and scalable solution for high-dimensional data analysis.</description><author>Siddharth Viswanath, Hiren Madhu, Dhananjay Bhaskar, Jake Kovalic, Dave Johnson, Rex Ying, Christopher Tape, Ian Adelstein, Michael Perlmutter, Smita Krishnaswamy</author><pubDate>Tue, 11 Feb 2025 18:13:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07746v1</guid></item><item><title>UNSURE: self-supervised learning with Unknown Noise level and Stein's Unbiased Risk Estimate</title><link>http://arxiv.org/abs/2409.01985v4</link><description>Recently, many self-supervised learning methods for image reconstruction havebeen proposed that can learn from noisy data alone, bypassing the need forground-truth references. Most existing methods cluster around two classes: i)Stein's Unbiased Risk Estimate (SURE) and similar approaches that assume fullknowledge of the noise distribution, and ii) Noise2Self and similarcross-validation methods that require very mild knowledge about the noisedistribution. The first class of methods tends to be impractical, as the noiselevel is often unknown in real-world applications, and the second class isoften suboptimal compared to supervised learning. In this paper, we provide atheoretical framework that characterizes this expressivity-robustness trade-offand propose a new approach based on SURE, but unlike the standard SURE, doesnot require knowledge about the noise level. Throughout a series ofexperiments, we show that the proposed estimator outperforms other existingself-supervised methods on various imaging inverse problems.</description><author>Julián Tachella, Mike Davies, Laurent Jacques</author><pubDate>Tue, 11 Feb 2025 18:09:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01985v4</guid></item><item><title>Training Language Models to Reason Efficiently</title><link>http://arxiv.org/abs/2502.04463v2</link><description>Scaling model size and training data has led to great advances in theperformance of Large Language Models (LLMs). However, the diminishing returnsof this approach necessitate alternative methods to improve model capabilities,particularly in tasks requiring advanced reasoning. Large reasoning models,which leverage long chain-of-thoughts, bring unprecedented breakthroughs inproblem-solving capabilities but at a substantial deployment cost associated tolonger generations. Reducing inference costs is crucial for the economicfeasibility, user experience, and environmental sustainability of these models. In this work, we propose to train large reasoning models to reasonefficiently. More precisely, we use reinforcement learning (RL) to trainreasoning models to dynamically allocate inference-time compute based on taskcomplexity. Our method incentivizes models to minimize unnecessarycomputational overhead while maintaining accuracy, thereby achievingsubstantial efficiency gains. It enables the derivation of a family ofreasoning models with varying efficiency levels, controlled via a singlehyperparameter. Experiments on two open-weight large reasoning modelsdemonstrate significant reductions in inference cost while preserving most ofthe accuracy.</description><author>Daman Arora, Andrea Zanette</author><pubDate>Tue, 11 Feb 2025 18:06:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.04463v2</guid></item><item><title>Advancing climate model interpretability: Feature attribution for Arctic melt anomalies</title><link>http://arxiv.org/abs/2502.07741v1</link><description>The focus of our work is improving the interpretability of anomalies inclimate models and advancing our understanding of Arctic melt dynamics. TheArctic and Antarctic ice sheets are experiencing rapid surface melting andincreased freshwater runoff, contributing significantly to global sea levelrise. Understanding the mechanisms driving snowmelt in these regions iscrucial. ERA5, a widely used reanalysis dataset in polar climate studies,offers extensive climate variables and global data assimilation. However, itssnowmelt model employs an energy imbalance approach that may oversimplify thecomplexity of surface melt. In contrast, the Glacier Energy and Mass Balance(GEMB) model incorporates additional physical processes, such as snowaccumulation, firn densification, and meltwater percolation/refreezing,providing a more detailed representation of surface melt dynamics. In thisresearch, we focus on analyzing surface snowmelt dynamics of the Greenland IceSheet using feature attribution for anomalous melt events in ERA5 and GEMBmodels. We present a novel unsupervised attribution method leveragingcounterfactual explanation method to analyze detected anomalies in ERA5 andGEMB. Our anomaly detection results are validated using MEaSUREs ground-truthdata, and the attributions are evaluated against established feature rankingmethods, including XGBoost, Shapley values, and Random Forest. Our attributionframework identifies the physics behind each model and the climate featuresdriving melt anomalies. These findings demonstrate the utility of ourattribution method in enhancing the interpretability of anomalies in climatemodels and advancing our understanding of Arctic melt dynamics.</description><author>Tolulope Ale, Nicole-Jeanne Schlegel, Vandana P. Janeja</author><pubDate>Tue, 11 Feb 2025 18:05:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07741v1</guid></item><item><title>What makes math problems hard for reinforcement learning: a case study</title><link>http://arxiv.org/abs/2408.15332v2</link><description>Using a long-standing conjecture from combinatorial group theory, we explore,from multiple perspectives, the challenges of finding rare instances carryingdisproportionately high rewards. Based on lessons learned in the contextdefined by the Andrews-Curtis conjecture, we propose algorithmic enhancementsand a topological hardness measure with implications for a broad class ofsearch problems. As part of our study, we also address several openmathematical questions. Notably, we demonstrate the length reducibility of allbut two presentations in the Akbulut-Kirby series (1981), and resolve variouspotential counterexamples in the Miller-Schupp series (1991), including threeinfinite subfamilies.</description><author>Ali Shehper, Anibal M. Medina-Mardones, Lucas Fagan, Bartłomiej Lewandowski, Angus Gruen, Yang Qiu, Piotr Kucharski, Zhenghan Wang, Sergei Gukov</author><pubDate>Tue, 11 Feb 2025 18:01:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15332v2</guid></item><item><title>HRP: High-Rank Preheating for Superior LoRA Initialization</title><link>http://arxiv.org/abs/2502.07739v1</link><description>This paper studies the crucial impact of initialization on the convergenceproperties of Low-Rank Adaptation (LoRA). We theoretically demonstrate thatrandom initialization, a widely used schema, will likely lead LoRA to randomlow-rank results, rather than the best low-rank result. While this issue can bemitigated by adjusting initialization towards a well-informed direction, itrelies on prior knowledge of the target, which is typically unknown inreal-world scenarios. To approximate this well-informed initial direction, wepropose High-Rank Preheating (HRP), which fine-tunes high-rank LoRA for a fewsteps and uses the singular value decomposition of the preheated result as asuperior initialization. HRP initialization is theory-supported to combine theconvergence strengths of high-rank LoRA and the generalization strengths oflow-rank LoRA. Extensive experiments demonstrate that HRP significantlyenhances LoRA's effectiveness across various models and tasks, achievingperformance comparable to full-parameter fine-tuning and outperforming otherinitialization strategies.</description><author>Yuzhu Chen, Yingjie Wang, Shi Fu, Li Shen, Yongcheng Jing, Xinmei Tian, Dacheng Tao</author><pubDate>Tue, 11 Feb 2025 17:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07739v1</guid></item><item><title>Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling</title><link>http://arxiv.org/abs/2502.07737v1</link><description>Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR)video generation, but it suffers from suboptimal unidirectional dependenciesand slow inference speed. In this work, we propose a semi-autoregressive(semi-AR) framework, called Next-Block Prediction (NBP), for video generation.By uniformly decomposing video content into equal-sized blocks (e.g., rows orframes), we shift the generation unit from individual tokens to blocks,allowing each token in the current block to simultaneously predict thecorresponding token in the next block. Unlike traditional AR modeling, ourframework employs bidirectional attention within each block, enabling tokens tocapture more robust spatial dependencies. By predicting multiple tokens inparallel, NBP models significantly reduce the number of generation steps,leading to faster and more efficient inference. Our model achieves FVD scoresof 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by anaverage of 4.4. Furthermore, thanks to the reduced number of inference steps,the NBP model generates 8.89 frames (128x128 resolution) per second, achievingan 11x speedup. We also explored model scales ranging from 700M to 3Bparameters, observing significant improvements in generation quality, with FVDscores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600,demonstrating the scalability of our approach.</description><author>Shuhuai Ren, Shuming Ma, Xu Sun, Furu Wei</author><pubDate>Tue, 11 Feb 2025 17:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07737v1</guid></item><item><title>Revisiting Non-Acyclic GFlowNets in Discrete Environments</title><link>http://arxiv.org/abs/2502.07735v1</link><description>Generative Flow Networks (GFlowNets) are a family of generative models thatlearn to sample objects from a given probability distribution, potentiallyknown up to a normalizing constant. Instead of working in the object space,GFlowNets proceed by sampling trajectories in an appropriately constructeddirected acyclic graph environment, greatly relying on the acyclicity of thegraph. In our paper, we revisit the theory that relaxes the acyclicityassumption and present a simpler theoretical framework for non-acyclicGFlowNets in discrete environments. Moreover, we provide various noveltheoretical insights related to training with fixed backward policies, thenature of flow functions, and connections between entropy-regularized RL andnon-acyclic GFlowNets, which naturally generalize the respective concepts andtheoretical results from the acyclic setting. In addition, we experimentallyre-examine the concept of loss stability in non-acyclic GFlowNet training, aswell as validate our own theoretical findings.</description><author>Nikita Morozov, Ian Maksimov, Daniil Tiapkin, Sergey Samsonov</author><pubDate>Tue, 11 Feb 2025 17:55:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07735v1</guid></item><item><title>SpaceMesh: A Continuous Representation for Learning Manifold Surface Meshes</title><link>http://arxiv.org/abs/2409.20562v2</link><description>Meshes are ubiquitous in visual computing and simulation, yet most existingmachine learning techniques represent meshes only indirectly, e.g. as the levelset of a scalar field or deformation of a template, or as a disordered trianglesoup lacking local structure. This work presents a scheme to directly generatemanifold, polygonal meshes of complex connectivity as the output of a neuralnetwork. Our key innovation is to define a continuous latent connectivity spaceat each mesh vertex, which implies the discrete mesh. In particular, our vertexembeddings generate cyclic neighbor relationships in a halfedge meshrepresentation, which gives a guarantee of edge-manifoldness and the ability torepresent general polygonal meshes. This representation is well-suited tomachine learning and stochastic optimization, without restriction onconnectivity or topology. We first explore the basic properties of thisrepresentation, then use it to fit distributions of meshes from large datasets.The resulting models generate diverse meshes with tessellation structurelearned from the dataset population, with concise details and high-quality meshelements. In applications, this approach not only yields high-quality outputsfrom generative models, but also enables directly learning challenging geometryprocessing tasks such as mesh repair.</description><author>Tianchang Shen, Zhaoshuo Li, Marc Law, Matan Atzmon, Sanja Fidler, James Lucas, Jun Gao, Nicholas Sharp</author><pubDate>Tue, 11 Feb 2025 17:53:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.20562v2</guid></item><item><title>EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices</title><link>http://arxiv.org/abs/2502.07734v1</link><description>Ear recognition is a contactless and unobtrusive biometric technique withapplications across various domains. However, deploying high-performing earrecognition models on resource-constrained devices is challenging, limitingtheir applicability and widespread adoption. This paper introduces EdgeEar, alightweight model based on a proposed hybrid CNN-transformer architecture tosolve this problem. By incorporating low-rank approximations into specificlinear layers, EdgeEar reduces its parameter count by a factor of 50 comparedto the current state-of-the-art, bringing it below two million whilemaintaining competitive accuracy. Evaluation on the Unconstrained EarRecognition Challenge (UERC2023) benchmark shows that EdgeEar achieves thelowest EER while significantly reducing computational costs. These findingsdemonstrate the feasibility of efficient and accurate ear recognition, which webelieve will contribute to the wider adoption of ear biometrics.</description><author>Camile Lendering, Bernardo Perrone Ribeiro, Žiga Emeršič, Peter Peer</author><pubDate>Tue, 11 Feb 2025 17:53:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07734v1</guid></item><item><title>Economics of Sourcing Human Data</title><link>http://arxiv.org/abs/2502.07732v1</link><description>Progress in AI has relied on human-generated data, from annotatormarketplaces to the wider Internet. However, the widespread use of largelanguage models now threatens the quality and integrity of human-generated dataon these very platforms. We argue that this issue goes beyond the immediatechallenge of filtering AI-generated content--it reveals deeper flaws in howdata collection systems are designed. Existing systems often prioritize speed,scale, and efficiency at the cost of intrinsic human motivation, leading todeclining engagement and data quality. We propose that rethinking datacollection systems to align with contributors' intrinsic motivations--ratherthan relying solely on external incentives--can help sustain high-quality datasourcing at scale while maintaining contributor trust and long-termparticipation.</description><author>Sebastin Santy, Prasanta Bhattacharya, Manoel Horta Ribeiro, Kelsey Allen, Sewoong Oh</author><pubDate>Tue, 11 Feb 2025 17:51:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07732v1</guid></item><item><title>TopoTune : A Framework for Generalized Combinatorial Complex Neural Networks</title><link>http://arxiv.org/abs/2410.06530v3</link><description>Graph Neural Networks (GNNs) excel in learning from relational datasets,processing node and edge features in a way that preserves the symmetries of thegraph domain. However, many complex systems -- such as biological or socialnetworks--involve multiway complex interactions that are more naturallyrepresented by higher-order topological domains. The emerging field ofTopological Deep Learning (TDL) aims to accommodate and leverage thesehigher-order structures. Combinatorial Complex Neural Networks (CCNNs), fairlygeneral TDL models, have been shown to be more expressive and better performingthan GNNs. However, differently from the GNN ecosystem, TDL lacks a principledand standardized framework for easily defining new architectures, restrictingits accessibility and applicability. To address this issue, we introduceGeneralized CCNNs (GCCNs), a novel simple yet powerful family of TDL modelsthat can be used to systematically transform any (graph) neural network intoits TDL counterpart. We prove that GCCNs generalize and subsume CCNNs, whileextensive experiments on a diverse class of GCCNs show that these architecturesconsistently match or outperform CCNNs, often with less model complexity. In aneffort to accelerate and democratize TDL, we introduce TopoTune, a lightweightsoftware for defining, building, and training GCCNs with unprecedentedflexibility and ease.</description><author>Mathilde Papillon, Guillermo Bernárdez, Claudio Battiloro, Nina Miolane</author><pubDate>Tue, 11 Feb 2025 17:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06530v3</guid></item><item><title>The Benefits of Balance: From Information Projections to Variance Reduction</title><link>http://arxiv.org/abs/2408.15065v2</link><description>Data balancing across multiple modalities and sources appears in variousforms in foundation models in machine learning and AI, e.g. in CLIP and DINO.We show that data balancing across modalities and sources actually offers anunsuspected benefit: variance reduction. We present a non-asymptoticstatistical bound that quantifies this variance reduction effect and relates itto the eigenvalue decay of Markov operators. Furthermore, we describe howvarious forms of data balancing in contrastive multimodal learning andself-supervised clustering can be better understood, and even improved upon,owing to our variance reduction viewpoint.</description><author>Lang Liu, Ronak Mehta, Soumik Pal, Zaid Harchaoui</author><pubDate>Tue, 11 Feb 2025 17:47:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15065v2</guid></item><item><title>The Faiss library</title><link>http://arxiv.org/abs/2401.08281v3</link><description>Vector databases typically manage large collections of embedding vectors.Currently, AI applications are growing rapidly, and so is the number ofembeddings that need to be stored and indexed. The Faiss library is dedicatedto vector similarity search, a core functionality of vector databases. Faiss isa toolkit of indexing methods and related primitives used to search, cluster,compress and transform vectors. This paper describes the trade-off space ofvector search and the design principles of Faiss in terms of structure,approach to optimization and interfacing. We benchmark key features of thelibrary and discuss a few selected applications to highlight its broadapplicability.</description><author>Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, Hervé Jégou</author><pubDate>Tue, 11 Feb 2025 17:43:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08281v3</guid></item><item><title>Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK</title><link>http://arxiv.org/abs/2502.07728v1</link><description>Large language models (LLMs) have demonstrated remarkable code generationcapabilities, but the correctness of the generated code cannot be inherentlytrusted. This paper explores the feasibility of using formal softwareverification, specifically the SPARK framework for Ada, to ensure thereliability of LLM-generated code. We present Marmaragan, a tool that leveragesan LLM in order to generate SPARK annotations for existing programs, enablingformal verification of the code. The tool is benchmarked on a curated set ofSPARK programs, with annotations selectively removed to test specificcapabilities. The performance of Marmaragan with GPT-4o on the benchmark ispromising, with correct annotations having been generated for 50.7% of thebenchmark cases. The results establish a foundation for future work oncombining the power of LLMs with the reliability of formal softwareverification.</description><author>Marcos Cramer, Lucian McIntyre</author><pubDate>Tue, 11 Feb 2025 17:42:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07728v1</guid></item><item><title>Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art</title><link>http://arxiv.org/abs/2403.16527v2</link><description>Autonomous systems are soon to be ubiquitous, spanning manufacturing,agriculture, healthcare, entertainment, and other industries. Most of thesesystems are developed with modular sub-components for decision-making,planning, and control that may be hand-engineered or learning-based. Whilethese approaches perform well under the situations they were specificallydesigned for, they can perform especially poorly in out-of-distributionscenarios that will undoubtedly arise at test-time. The rise of foundationmodels trained on multiple tasks with impressively large datasets has ledresearchers to believe that these models may provide "common sense" reasoningthat existing planners are missing, bridging the gap between algorithmdevelopment and deployment. While researchers have shown promising results indeploying foundation models to decision-making tasks, these models are known tohallucinate and generate decisions that may sound reasonable, but are in factpoor. We argue there is a need to step back and simultaneously design systemsthat can quantify the certainty of a model's decision, and detect when it maybe hallucinating. In this work, we discuss the current use cases of foundationmodels for decision-making tasks, provide a general definition forhallucinations with examples, discuss existing approaches to hallucinationdetection and mitigation with a focus on decision problems, present guidelines,and explore areas for further research in this exciting field.</description><author>Neeloy Chakraborty, Melkior Ornik, Katherine Driggs-Campbell</author><pubDate>Tue, 11 Feb 2025 17:40:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16527v2</guid></item><item><title>Novelty Detection in Reinforcement Learning with World Models</title><link>http://arxiv.org/abs/2310.08731v3</link><description>Reinforcement learning (RL) using world models has found significant recentsuccesses. However, when a sudden change to world mechanics or propertiesoccurs then agent performance and reliability can dramatically decline. Werefer to the sudden change in visual properties or state transitions asnovelties. Implementing novelty detection within generated world modelframeworks is a crucial task for protecting the agent when deployed. In thispaper, we propose straightforward bounding approaches to incorporate noveltydetection into world model RL agents, by utilizing the misalignment of theworld model's hallucinated states and the true observed states as an anomalyscore. We provide effective approaches to detecting novelties in a distributionof transitions learned by an agent in a world model. Finally, we show theadvantage of our work in a novel environment compared to traditional machinelearning novelty detection methods as well as currently accepted RL focusednovelty detection algorithms.</description><author>Geigh Zollicoffer, Kenneth Eaton, Jonathan Balloch, Julia Kim, Wei Zhou, Robert Wright, Mark O. Riedl</author><pubDate>Tue, 11 Feb 2025 17:38:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08731v3</guid></item><item><title>Glinthawk: A Two-Tiered Architecture for Offline LLM Inference</title><link>http://arxiv.org/abs/2501.11779v2</link><description>We introduce Glinthawk, an architecture for offline Large Language Model(LLM) inference. By leveraging a two-tiered structure, Glinthawk optimizes theutilization of the high-end accelerators ("Tier 1") by offloading the attentionmechanism to lower-end compute tier ("Tier 2"). This separation allows thememory demand of the attention, known as the key-value cache, to scaleindependently from the model weights, enabling larger batch sizes and moreefficient accelerator usage. Prototyped with NVIDIA T4 GPUs and standard CPUVMs, Glinthawk improves throughput by $5.9\times$ and reduces cost ofgeneration by $2.8\times$, compared to paged attention baselines. For longsequence lengths, it achieves $16.3\times$ throughput improvement at$2.4\times$ less cost. Our evaluation shows that this architecture can toleratemoderate network latency with minimal performance degradation, making it highlyeffective for latency-tolerant, throughput-focused applications such as batchprocessing. The prototype is publicly available athttps://github.com/microsoft/glinthawk.</description><author>Pouya Hamadanian, Sadjad Fouladi</author><pubDate>Tue, 11 Feb 2025 17:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11779v2</guid></item><item><title>Natural Variational Annealing for Multimodal Optimization</title><link>http://arxiv.org/abs/2501.04667v2</link><description>We introduce a new multimodal optimization approach called NaturalVariational Annealing (NVA) that combines the strengths of three foundationalconcepts to simultaneously search for multiple global and local modes ofblack-box nonconvex objectives. First, it implements a simultaneous search byusing variational posteriors, such as, mixtures of Gaussians. Second, itapplies annealing to gradually trade off exploration for exploitation. Finally,it learns the variational search distribution using natural-gradient learningwhere updates resemble well-known and easy-to-implement algorithms. The threeconcepts come together in NVA giving rise to new algorithms and also allowingus to incorporate "fitness shaping", a core concept from evolutionaryalgorithms. We assess the quality of search on simulations and compare them tomethods using gradient descent and evolution strategies. We also provide anapplication to a real-world inverse problem in planetary science.</description><author>Tâm Le Minh, Julyan Arbel, Thomas Möllenhoff, Mohammad Emtiyaz Khan, Florence Forbes</author><pubDate>Tue, 11 Feb 2025 17:36:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04667v2</guid></item><item><title>TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning</title><link>http://arxiv.org/abs/2502.07721v1</link><description>The prevalence of noisy labels in real-world datasets poses a significantimpediment to the effective deployment of deep learning models. Whilemeta-learning strategies have emerged as a promising approach for addressingthis challenge, existing methods often suffer from limited transferability andtask-specific designs. This paper introduces TMLC-Net, a novel TransferableMeta-Learner for Correcting Noisy Labels, designed to overcome theselimitations. TMLC-Net learns a general-purpose label correction strategy thatcan be readily applied across diverse datasets and model architectures withoutrequiring extensive retraining or fine-tuning. Our approach integrates threecore components: (1) Normalized Noise Perception, which captures and normalizestraining dynamics to handle distribution shifts; (2) Time-Series Encoding,which models the temporal evolution of sample statistics using a recurrentneural network; and (3) Subclass Decoding, which predicts a corrected labeldistribution based on the learned representations. We conduct extensiveexperiments on benchmark datasets with various noise types and levels,demonstrating that TMLC-Net consistently outperforms state-of-the-art methodsin terms of both accuracy and robustness to label noise. Furthermore, weanalyze the transferability of TMLC-Net, showcasing its adaptability to newdatasets and noise conditions, and establishing its potential as a broadlyapplicable solution for robust deep learning in noisy environments.</description><author>Mengyang Li</author><pubDate>Tue, 11 Feb 2025 17:33:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07721v1</guid></item><item><title>Large Continual Instruction Assistant</title><link>http://arxiv.org/abs/2410.10868v2</link><description>Continual Instruction Tuning (CIT) is adopted to continually instruct LargeModels to follow human intent data by data. It is observed that existinggradient update would heavily destroy the performance on previous datasetsduring CIT process. Instead, Exponential Moving Average (EMA), owns the abilityto trace previous parameters, which can aid in decreasing forgetting.Nonetheless, its stable balance weight fails to deal with the ever-changingdatasets, leading to the out-of-balance between plasticity and stability. Inthis paper, we propose a general continual instruction tuning framework toaddress the challenge. Starting from the trade-off prerequisite and EMA update,we propose the plasticity and stability ideal condition. Based on Taylorexpansion in the loss function, we find the optimal balance weight can beautomatically determined by the gradients and learned parameters. Therefore, wepropose a stable-plasticity balanced coefficient to avoid knowledge confusion.Based on the semantic similarity of the instructions, we can determine whetherto retrain or expand the training parameters and allocate the most suitableparameters for the testing instances. Extensive experiments across multiplecontinual instruction tuning benchmarks demonstrate that our approach not onlyenhances anti-forgetting capabilities but also significantly improves overallcontinual tuning performance. For example, based on LLaVA-7B, the forgetting isreduced from 5.42 to 1.93. Our code will be made publicly available soon.</description><author>Jingyang Qiao, Zhizhong Zhang, Xin Tan, Yanyun Qu, Shouhong Ding, Yuan Xie</author><pubDate>Tue, 11 Feb 2025 17:31:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10868v2</guid></item><item><title>Drago: Primal-Dual Coupled Variance Reduction for Faster Distributionally Robust Optimization</title><link>http://arxiv.org/abs/2403.10763v2</link><description>We consider the penalized distributionally robust optimization (DRO) problemwith a closed, convex uncertainty set, a setting that encompasses learningusing $f$-DRO and spectral/$L$-risk minimization. We present Drago, astochastic primal-dual algorithm that combines cyclic and randomized componentswith a carefully regularized primal update to achieve dual variance reduction.Owing to its design, Drago enjoys a state-of-the-art linear convergence rate onstrongly convex-strongly concave DRO problems with a fine-grained dependency onprimal and dual condition numbers. Theoretical results are supported bynumerical benchmarks on regression and classification tasks.</description><author>Ronak Mehta, Jelena Diakonikolas, Zaid Harchaoui</author><pubDate>Tue, 11 Feb 2025 17:28:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.10763v2</guid></item><item><title>DPO Meets PPO: Reinforced Token Optimization for RLHF</title><link>http://arxiv.org/abs/2404.18922v3</link><description>In the classical Reinforcement Learning from Human Feedback (RLHF) framework,Proximal Policy Optimization (PPO) is employed to learn from sparse,sentence-level rewards -- a challenging scenario in traditional deepreinforcement learning. Despite the great successes of PPO in the alignment oflarge language models, its open-source implementation is still largelysub-optimal. To address these issues, we introduce a framework that models RLHFproblems as a Markov decision process (MDP), enabling the capture offine-grained token-wise information. Under this framework, we introduce analgorithm Reinforced Token Optimization (\texttt{RTO}), which learns thetoken-wise reward function from preference data and performs policyoptimization based on this learned token-wise reward signal. Theoretically,\texttt{RTO} is proven to have the capability of finding the near-optimalpolicy sample-efficiently. For its practical implementation, \texttt{RTO}innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO,originally derived from sparse sentence rewards, surprisingly provides us witha token-wise characterization of response quality, which is seamlesslyincorporated into our subsequent PPO training stage. Extensive experimentsdemonstrate that \texttt{RTO} performs better than PPO and other directpreference learning algorithms. In particular, RTO outperforms PPO by 7.5points on the AlpacaEval 2 benchmark and by 4.1 points on Arena-Hard. Our codeand models are available at\href{https://github.com/zkshan2002/RTO}{https://github.com/zkshan2002/RTO}.</description><author>Han Zhong, Zikang Shan, Guhao Feng, Wei Xiong, Xinle Cheng, Li Zhao, Di He, Jiang Bian, Liwei Wang</author><pubDate>Tue, 11 Feb 2025 17:23:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18922v3</guid></item><item><title>Making Language Models Robust Against Negation</title><link>http://arxiv.org/abs/2502.07717v1</link><description>Negation has been a long-standing challenge for language models. Previousstudies have shown that they struggle with negation in many natural languageunderstanding tasks. In this work, we propose a self-supervised method to makelanguage models more robust against negation. We introduce a novel task, NextSentence Polarity Prediction (NSPP), and a variation of the Next SentencePrediction (NSP) task. We show that BERT and RoBERTa further pre-trained on ourtasks outperform the off-the-shelf versions on nine negation-relatedbenchmarks. Most notably, our pre-training tasks yield between 1.8% and 9.1%improvement on CondaQA, a large question-answering corpus requiring reasoningover negation.</description><author>MohammadHossein Rezaei, Eduardo Blanco</author><pubDate>Tue, 11 Feb 2025 17:18:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07717v1</guid></item><item><title>Near-Optimal Sample Complexity in Reward-Free Kernel-Based Reinforcement Learning</title><link>http://arxiv.org/abs/2502.07715v1</link><description>Reinforcement Learning (RL) problems are being considered under increasinglymore complex structures. While tabular and linear models have been thoroughlyexplored, the analytical study of RL under nonlinear function approximation,especially kernel-based models, has recently gained traction for their strongrepresentational capacity and theoretical tractability. In this context, weexamine the question of statistical efficiency in kernel-based RL within thereward-free RL framework, specifically asking: how many samples are required todesign a near-optimal policy? Existing work addresses this question underrestrictive assumptions about the class of kernel functions. We first explorethis question by assuming a generative model, then relax this assumption at thecost of increasing the sample complexity by a factor of H, the length of theepisode. We tackle this fundamental problem using a broad class of kernels anda simpler algorithm compared to prior work. Our approach derives new confidenceintervals for kernel ridge regression, specific to our RL setting, which may beof broader applicability. We further validate our theoretical findings throughsimulations.</description><author>Aya Kayal, Sattar Vakili, Laura Toni, Alberto Bernacchia</author><pubDate>Tue, 11 Feb 2025 17:15:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07715v1</guid></item><item><title>pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning</title><link>http://arxiv.org/abs/2409.05701v3</link><description>Federated Learning (FL) offers a decentralized approach to model training,where data remains local and only model parameters are shared between theclients and the central server. Traditional methods, such as FederatedAveraging (FedAvg), linearly aggregate these parameters which are usuallytrained on heterogeneous data distributions, potentially overlooking thecomplex, high-dimensional nature of the parameter space. This can result indegraded performance of the aggregated model. While personalized FL approachescan mitigate the heterogeneous data issue to some extent, the limitation oflinear aggregation remains unresolved. To alleviate this issue, we investigatethe generative approach of diffusion model and propose a novel generativeparameter aggregation framework for personalized FL, \texttt{pFedGPA}. In thisframework, we deploy a diffusion model on the server to integrate the diverseparameter distributions and propose a parameter inversion method to efficientlygenerate a set of personalized parameters for each client. This inversionmethod transforms the uploaded parameters into a latent code, which is thenaggregated through denoising sampling to produce the final personalizedparameters. By encoding the dependence of a client's model parameters on thespecific data distribution using the high-capacity diffusion model,\texttt{pFedGPA} can effectively decouple the complexity of the overalldistribution of all clients' model parameters from the complexity of eachindividual client's parameter distribution. Our experimental resultsconsistently demonstrate the superior performance of the proposed method acrossmultiple datasets, surpassing baseline approaches.</description><author>Jiahao Lai, Jiaqi Li, Jian Xu, Yanru Wu, Boshi Tang, Siqi Chen, Yongfeng Huang, Wenbo Ding, Yang Li</author><pubDate>Tue, 11 Feb 2025 17:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05701v3</guid></item><item><title>MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces</title><link>http://arxiv.org/abs/2502.07709v1</link><description>Open-ended learning agents must efficiently prioritize goals in vastpossibility spaces, focusing on those that maximize learning progress (LP).When such autotelic exploration is achieved by LLM agents trained with onlineRL in high-dimensional and evolving goal spaces, a key challenge for LPprediction is modeling one's own competence, a form of metacognitivemonitoring. Traditional approaches either require extensive sampling or rely onbrittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitiveframework that lets LLM agents learn to predict their competence and LP online.By capturing semantic relationships between goals, MAGELLAN enablessample-efficient LP estimation and dynamic adaptation to evolving goal spacesthrough generalization. In an interactive learning environment, we show thatMAGELLAN improves LP prediction efficiency and goal prioritization, being theonly method allowing the agent to fully master a large and evolving goal space.These results demonstrate how augmenting LLM agents with a metacognitiveability for LP predictions can effectively scale curriculum learning toopen-ended goal spaces.</description><author>Loris Gaven, Thomas Carta, Clément Romac, Cédric Colas, Sylvain Lamprier, Olivier Sigaud, Pierre-Yves Oudeyer</author><pubDate>Tue, 11 Feb 2025 17:08:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07709v1</guid></item><item><title>(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions</title><link>http://arxiv.org/abs/2311.17165v3</link><description>The concept of rationality is central to the field of artificialintelligence. Whether we are seeking to simulate human reasoning, or the goalis to achieve bounded optimality, we generally seek to make artificial agentsas rational as possible. Despite the centrality of the concept within AI, thereis no unified definition of what constitutes a rational agent. This articleprovides a survey of rationality and irrationality in artificial intelligence,and sets out the open questions in this area. The understanding of rationalityin other fields has influenced its conception within artificial intelligence,in particular work in economics, philosophy and psychology. Focusing on thebehaviour of artificial agents, we consider irrational behaviours that canprove to be optimal in certain scenarios. Some methods have been developed todeal with irrational agents, both in terms of identification and interaction,however work in this area remains limited. Methods that have up to now beendeveloped for other purposes, namely adversarial scenarios, may be adapted tosuit interactions with artificial agents. We further discuss the interplaybetween human and artificial agents, and the role that rationality plays withinthis interaction; many questions remain in this area, relating to potentiallyirrational behaviour of both humans and artificial agents.</description><author>Olivia Macmillan-Scott, Mirco Musolesi</author><pubDate>Tue, 11 Feb 2025 17:06:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17165v3</guid></item><item><title>PRVQL: Progressive Knowledge-guided Refinement for Robust Egocentric Visual Query Localization</title><link>http://arxiv.org/abs/2502.07707v1</link><description>Egocentric visual query localization (EgoVQL) focuses on localizing thetarget of interest in space and time from first-person videos, given a visualquery. Despite recent progressive, existing methods often struggle to handlesevere object appearance changes and cluttering background in the video due tolacking sufficient target cues, leading to degradation. Addressing this, weintroduce PRVQL, a novel Progressive knowledge-guided Refinement framework forEgoVQL. The core is to continuously exploit target-relevant knowledge directlyfrom videos and utilize it as guidance to refine both query and video featuresfor improving target localization. Our PRVQL contains multiple processingstages. The target knowledge from one stage, comprising appearance and spatialknowledge extracted via two specially designed knowledge learning modules, areutilized as guidance to refine the query and videos features for the nextstage, which are used to generate more accurate knowledge for further featurerefinement. With such a progressive process, target knowledge in PRVQL can begradually improved, which, in turn, leads to better refined query and videofeatures for localization in the final stage. Compared to previous methods, ourPRVQL, besides the given object cues, enjoys additional crucial targetinformation from a video as guidance to refine features, and hence enhancesEgoVQL in complicated scenes. In our experiments on challenging Ego4D, PRVQLachieves state-of-the-art result and largely surpasses other methods, showingits efficacy. Our code, model and results will be released athttps://github.com/fb-reps/PRVQL.</description><author>Bing Fan, Yunhe Feng, Yapeng Tian, Yuewei Lin, Yan Huang, Heng Fan</author><pubDate>Tue, 11 Feb 2025 17:04:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07707v1</guid></item><item><title>Magic 1-For-1: Generating One Minute Video Clips within One Minute</title><link>http://arxiv.org/abs/2502.07701v1</link><description>In this technical report, we present Magic 1-For-1 (Magic141), an efficientvideo generation model with optimized memory consumption and inference latency.The key idea is simple: factorize the text-to-video generation task into twoseparate easier tasks for diffusion step distillation, namely text-to-imagegeneration and image-to-video generation. We verify that with the sameoptimization algorithm, the image-to-video task is indeed easier to convergeover the text-to-video task. We also explore a bag of optimization tricks toreduce the computational cost of training the image-to-video (I2V) models fromthree aspects: 1) model convergence speedup by using a multi-modal priorcondition injection; 2) inference latency speed up by applying an adversarialstep distillation, and 3) inference memory cost optimization with parametersparsification. With those techniques, we are able to generate 5-second videoclips within 3 seconds. By applying a test time sliding window, we are able togenerate a minute-long video within one minute with significantly improvedvisual quality and motion dynamics, spending less than 1 second for generating1 second video clips on average. We conduct a series of preliminaryexplorations to find out the optimal tradeoff between computational cost andvideo quality during diffusion step distillation and hope this could be a goodfoundation model for open-source explorations. The code and the model weightsare available at https://github.com/DA-Group-PKU/Magic-1-For-1.</description><author>Hongwei Yi, Shitong Shao, Tian Ye, Jiantong Zhao, Qingyu Yin, Michael Lingelbach, Li Yuan, Yonghong Tian, Enze Xie, Daquan Zhou</author><pubDate>Tue, 11 Feb 2025 16:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07701v1</guid></item><item><title>Amuro and Char: Analyzing the Relationship between Pre-Training and Fine-Tuning of Large Language Models</title><link>http://arxiv.org/abs/2408.06663v4</link><description>The development of large language models leads to the formation of apre-train-then-align paradigm, in which the model is typically pre-trained on alarge text corpus and undergoes a tuning stage to align the model with humanpreference or downstream tasks. In this work, we investigate the relationshipbetween pre-training and fine-tuning by fine-tuning multiple intermediatepre-trained model checkpoints. Our results on 18 datasets suggest that i)continual pre-training improves the model in a latent way that unveils afterfine-tuning; ii) with extra fine-tuning, the datasets that the model does notdemonstrate capability gain much more than those that the model performs wellduring the pre-training stage; iii) although model benefits significantlythrough supervised fine-tuning, it may forget previously known domain knowledgeand the tasks that are not seen during fine-tuning; iv) the model resembleshigh sensitivity to evaluation prompts after supervised fine-tuning, but thissensitivity can be alleviated by more pre-training.</description><author>Kaiser Sun, Mark Dredze</author><pubDate>Tue, 11 Feb 2025 16:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06663v4</guid></item><item><title>Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models</title><link>http://arxiv.org/abs/2412.16247v2</link><description>Dictionary learning (DL) has emerged as a powerful interpretability tool forlarge language models. By extracting known concepts (e.g., Golden-Gate Bridge)from human-interpretable data (e.g., text), sparse DL can elucidate a model'sinner workings. In this work, we ask if DL can also be used to discover unknownconcepts from less human-interpretable scientific data (e.g., cell images),ultimately enabling modern approaches to scientific discovery. As a first step,we use DL algorithms to study microscopy foundation models trained onmulti-cell image data, where little prior knowledge exists regarding whichhigh-level concepts should arise. We show that sparse dictionaries indeedextract biologically-meaningful concepts such as cell type and geneticperturbation type. We also propose Iterative Codebook Feature Learning~(ICFL)and combine it with a pre-processing step which uses PCA whitening from acontrol dataset. In our experiments, we demonstrate that both ICFL and PCAimprove the selectivity of extracted features compared to TopK sparseautoencoders.</description><author>Konstantin Donhauser, Kristina Ulicna, Gemma Elyse Moran, Aditya Ravuri, Kian Kenyon-Dean, Cian Eastwood, Jason Hartford</author><pubDate>Tue, 11 Feb 2025 16:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16247v2</guid></item><item><title>FinTruthQA: A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure</title><link>http://arxiv.org/abs/2406.12009v3</link><description>Accurate and transparent financial information disclosure is essential inaccounting and finance, fostering trust and enabling informed investmentdecisions that drive economic development. Among many information disclosureplatforms, the Chinese stock exchanges' investor interactive platform providesa novel and interactive way for listed firms to disclose information ofinterest to investors through an online question-and-answer (Q&amp;A) format.However, it is common for listed firms to respond to questions with limited orno substantive information, and automatically evaluating the quality offinancial information disclosure on large amounts of Q&amp;A pairs is challenging.In this study, our interdisciplinary team of AI and finance professionalsproposed FinTruthQA, a benchmark designed to evaluate advanced natural languageprocessing (NLP) techniques for the automatic quality assessment of informationdisclosure in financial Q&amp;A data. It comprises 6,000 real-world financial Q&amp;Aentries and each Q&amp;A was manually annotated based on four key evaluationcriteria. We benchmarked various NLP techniques on FinTruthQA, including largelanguage models(LLMs). Experiments showed that existing NLP models have strongpredictive ability for question identification and question relevance tasks,but are suboptimal for answer readability and answer relevance tasks. Byestablishing this benchmark, we provide a robust foundation for the automaticevaluation of information disclosure, demonstrating how AI can be leveraged forsocial good by promoting transparency, fairness, and investor protection infinancial disclosure practices. FinTruthQA can be used by auditors, regulators,and financial analysts for real-time monitoring and data-drivendecision-making, as well as by researchers for advanced studies in accountingand finance, ultimately fostering greater trust and efficiency in the financialmarkets.</description><author>Ziyue Xu, Peilin Zhou, Xinyu Shi, Jiageng Wu, Yikang Jiang, Dading Chong, Bin Ke, Jie Yang</author><pubDate>Tue, 11 Feb 2025 16:49:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12009v3</guid></item><item><title>The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities</title><link>http://arxiv.org/abs/2501.13921v3</link><description>Llama-Breeze2 (hereinafter referred to as Breeze2) is a suite of advancedmulti-modal language models, available in 3B and 8B parameter configurations,specifically designed to enhance Traditional Chinese language representation.Building upon the Llama 3.2 model family, we continue the pre-training ofBreeze2 on an extensive corpus to enhance the linguistic and cultural heritageof Traditional Chinese. In addition to language modeling capabilities, wesignificantly augment the models with function calling and vision understandingcapabilities. At the time of this publication, as far as we are aware, absentreasoning-inducing prompts, Breeze2 are the strongest performing models inTraditional Chinese function calling and image understanding in its size class.The effectiveness of Breeze2 is benchmarked across various tasks, includingTaiwan general knowledge, instruction-following, long context, functioncalling, and vision understanding. We are publicly releasing all Breeze2 modelsunder the Llama 3.2 Community License. We also showcase the capabilities of themodel running on mobile platform with a mobile application which we also opensource.</description><author>MediaTek Research, :, Chan-Jan Hsu, Chia-Sheng Liu, Meng-Hsi Chen, Muxi Chen, Po-Chun Hsu, Yi-Chang Chen, Da-Shan Shiu</author><pubDate>Tue, 11 Feb 2025 16:48:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13921v3</guid></item><item><title>DPCore: Dynamic Prompt Coreset for Continual Test-Time Adaptation</title><link>http://arxiv.org/abs/2406.10737v3</link><description>Continual Test-Time Adaptation (CTTA) seeks to adapt source pre-trainedmodels to continually changing, unseen target domains. While existing CTTAmethods assume structured domain changes with uniform durations, real-worldenvironments often exhibit dynamic patterns where domains recur with varyingfrequencies and durations. Current approaches, which adapt the same parametersacross different domains, struggle in such dynamic conditions-they faceconvergence issues with brief domain exposures, risk forgetting previouslylearned knowledge, or misapplying it to irrelevant domains. To remedy this, wepropose DPCore, a method designed for robust performance across diverse domainchange patterns while ensuring computational efficiency. DPCore integratesthree key components: Visual Prompt Adaptation for efficient domain alignment,a Prompt Coreset for knowledge preservation, and a Dynamic Update mechanismthat intelligently adjusts existing prompts for similar domains while creatingnew ones for substantially different domains. Extensive experiments on fourbenchmarks demonstrate that DPCore consistently outperforms various CTTAmethods, achieving state-of-the-art performance in both structured and dynamicsettings while reducing trainable parameters by 99% and computation time by 64%compared to previous approaches.</description><author>Yunbei Zhang, Akshay Mehra, Shuaicheng Niu, Jihun Hamm</author><pubDate>Tue, 11 Feb 2025 16:47:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10737v3</guid></item><item><title>SoK: A Classification for AI-driven Personalized Privacy Assistants</title><link>http://arxiv.org/abs/2502.07693v1</link><description>To help users make privacy-related decisions, personalized privacy assistantsbased on AI technology have been developed in recent years. These AI-drivenPersonalized Privacy Assistants (AI-driven PPAs) can reap significant benefitsfor users, who may otherwise struggle to make decisions regarding theirpersonal data in environments saturated with privacy-related decision requests.However, no study systematically inquired about the features of these AI-drivenPPAs, their underlying technologies, or the accuracy of their decisions. Tofill this gap, we present a Systematization of Knowledge (SoK) to map theexisting solutions found in the scientific literature. We screened 1697 uniqueresearch papers over the last decade (2013-2023), constructing a classificationfrom 39 included papers. As a result, this SoK reviews several aspects ofexisting research on AI-driven PPAs in terms of types of publications,contributions, methodological quality, and other quantitative insights.Furthermore, we provide a comprehensive classification for AI-driven PPAs,delving into their architectural choices, system contexts, types of AI used,data sources, types of decisions, and control over decisions, among otherfacets. Based on our SoK, we further underline the research gaps and challengesand formulate recommendations for the design and development of AI-driven PPAsas well as avenues for future research.</description><author>Victor Morel, Leonardo Iwaya, Simone Fischer-Hübner</author><pubDate>Tue, 11 Feb 2025 16:46:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07693v1</guid></item><item><title>A statistically consistent measure of Semantic Variability using Language Models</title><link>http://arxiv.org/abs/2502.00507v2</link><description>To address the issue of variability in the output generated by a languagemodel, we present a measure of semantic variability that is statisticallyconsistent under mild assumptions. This measure, denoted as semantic spectralentropy, is a easy to implement algorithm that requires just off the shelflanguage models. We put very few restrictions on the language models and wehave shown in a clear simulation studies that such method can generate accuratemetric despite randomness that arise from the language models.</description><author>Yi Liu</author><pubDate>Tue, 11 Feb 2025 16:39:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.00507v2</guid></item><item><title>Large Language Models as Proxies for Theories of Human Linguistic Cognition</title><link>http://arxiv.org/abs/2502.07687v1</link><description>We consider the possible role of current large language models (LLMs) in thestudy of human linguistic cognition. We focus on the use of such models asproxies for theories of cognition that are relatively linguistically-neutral intheir representations and learning but differ from current LLMs in key ways. Weillustrate this potential use of LLMs as proxies for theories of cognition inthe context of two kinds of questions: (a) whether the target theory accountsfor the acquisition of a given pattern from a given corpus; and (b) whether thetarget theory makes a given typologically-attested pattern easier to acquirethan another, typologically-unattested pattern. For each of the two questionswe show, building on recent literature, how current LLMs can potentially be ofhelp, but we note that at present this help is quite limited.</description><author>Imry Ziv, Nur Lan, Emmanuel Chemla, Roni Katzir</author><pubDate>Tue, 11 Feb 2025 16:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07687v1</guid></item><item><title>Matrix3D: Large Photogrammetry Model All-in-One</title><link>http://arxiv.org/abs/2502.07685v1</link><description>We present Matrix3D, a unified model that performs several photogrammetrysubtasks, including pose estimation, depth prediction, and novel view synthesisusing just the same model. Matrix3D utilizes a multi-modal diffusiontransformer (DiT) to integrate transformations across several modalities, suchas images, camera parameters, and depth maps. The key to Matrix3D's large-scalemulti-modal training lies in the incorporation of a mask learning strategy.This enables full-modality model training even with partially complete data,such as bi-modality data of image-pose and image-depth pairs, thussignificantly increases the pool of available training data. Matrix3Ddemonstrates state-of-the-art performance in pose estimation and novel viewsynthesis tasks. Additionally, it offers fine-grained control throughmulti-round interactions, making it an innovative tool for 3D content creation.Project page: https://nju-3dv.github.io/projects/matrix3d.</description><author>Yuanxun Lu, Jingyang Zhang, Tian Fang, Jean-Daniel Nahmias, Yanghai Tsin, Long Quan, Xun Cao, Yao Yao, Shiwei Li</author><pubDate>Tue, 11 Feb 2025 16:36:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07685v1</guid></item><item><title>Evaluating Evidence Attribution in Generated Fact Checking Explanations</title><link>http://arxiv.org/abs/2406.12645v3</link><description>Automated fact-checking systems often struggle with trustworthiness, as theirgenerated explanations can include hallucinations. In this work, we exploreevidence attribution for fact-checking explanation generation. We introduce anovel evaluation protocol -- citation masking and recovery -- to assessattribution quality in generated explanations. We implement our protocol usingboth human annotators and automatic annotators, and find that LLM annotationcorrelates with human annotation, suggesting that attribution assessment can beautomated. Finally, our experiments reveal that: (1) the best-performing LLMsstill generate explanations with inaccurate attributions; and (2) human-curatedevidence is essential for generating better explanations. Code and data areavailable here: https://github.com/ruixing76/Transparent-FCExp.</description><author>Rui Xing, Timothy Baldwin, Jey Han Lau</author><pubDate>Tue, 11 Feb 2025 16:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12645v3</guid></item><item><title>exHarmony: Authorship and Citations for Benchmarking the Reviewer Assignment Problem</title><link>http://arxiv.org/abs/2502.07683v1</link><description>The peer review process is crucial for ensuring the quality and reliabilityof scholarly work, yet assigning suitable reviewers remains a significantchallenge. Traditional manual methods are labor-intensive and oftenineffective, leading to nonconstructive or biased reviews. This paperintroduces the exHarmony (eHarmony but for connecting experts to manuscripts)benchmark, designed to address these challenges by re-imagining the ReviewerAssignment Problem (RAP) as a retrieval task. Utilizing the extensive data fromOpenAlex, we propose a novel approach that considers a host of signals from theauthors, most similar experts, and the citation relations as potentialindicators for a suitable reviewer for a manuscript. This approach allows us todevelop a standard benchmark dataset for evaluating the reviewer assignmentproblem without needing explicit labels. We benchmark various methods,including traditional lexical matching, static neural embeddings, andcontextualized neural embeddings, and introduce evaluation metrics that assessboth relevance and diversity in the context of RAP. Our results indicate thatwhile traditional methods perform reasonably well, contextualized embeddingstrained on scholarly literature show the best performance. The findingsunderscore the importance of further research to enhance the diversity andeffectiveness of reviewer assignments.</description><author>Sajad Ebrahimi, Sara Salamat, Negar Arabzadeh, Mahdi Bashari, Ebrahim Bagheri</author><pubDate>Tue, 11 Feb 2025 16:35:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07683v1</guid></item><item><title>Multiview Point Cloud Registration Based on Minimum Potential Energy for Free-Form Blade Measurement</title><link>http://arxiv.org/abs/2502.07680v1</link><description>Point cloud registration is an essential step for free-form bladereconstruction in industrial measurement. Nonetheless, measuring defects of the3D acquisition system unavoidably result in noisy and incomplete point clouddata, which renders efficient and accurate registration challenging. In thispaper, we propose a novel global registration method that is based on theminimum potential energy (MPE) method to address these problems. The basicstrategy is that the objective function is defined as the minimum potentialenergy optimization function of the physical registration system. The functiondistributes more weight to the majority of inlier points and less weight to thenoise and outliers, which essentially reduces the influence of perturbations inthe mathematical formulation. We decompose the solution into a globally optimalapproximation procedure and a fine registration process with the trimmediterative closest point algorithm to boost convergence. The approximationprocedure consists of two main steps. First, according to the construction ofthe force traction operator, we can simply compute the position of thepotential energy minimum. Second, to find the MPE point, we propose a newtheory that employs two flags to observe the status of the registrationprocedure. We demonstrate the performance of the proposed algorithm on fourtypes of blades. The proposed method outperforms the other global methods interms of both accuracy and noise resistance.</description><author>Zijie Wu, Yaonan Wang, Yang Mo, Qing Zhu, He Xie, Haotian Wu, Mingtao Feng, Ajmal Mian</author><pubDate>Tue, 11 Feb 2025 16:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07680v1</guid></item><item><title>Paying to Do Better: Games with Payments between Learning Agents</title><link>http://arxiv.org/abs/2405.20880v2</link><description>In repeated games, such as auctions, players typically use learningalgorithms to choose their actions. The use of such autonomous learning agentshas become widespread on online platforms. In this paper, we explore the impactof players incorporating monetary transfer policies into their agents'algorithms, aiming to influence behavior in their favor through the dynamicsbetween the agents. Our focus is on understanding when players have incentivesto make use of monetary transfers, how such payments may affect learningdynamics, and what the implications are for welfare and its distribution amongthe players. We propose a simple and general game-theoretic model to capturesuch scenarios. Our results on general games show that in a very broad class ofgames, self-interested players benefit from letting their learning agents makepayments to other learners during the game dynamics, and that in many cases,this kind of behavior improves welfare for all players. Our results on first-and second-price auctions show that in equilibria of the ``payment policygame,'' the agents' dynamics reach strong collusive outcomes with low revenuefor the auctioneer. These results raise new questions and highlight a challengefor mechanism design in systems where automated learning agents can benefitfrom interacting with their peers in the digital ecosystem and outside theboundaries of the mechanism.</description><author>Yoav Kolumbus, Joe Halpern, Éva Tardos</author><pubDate>Tue, 11 Feb 2025 16:29:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20880v2</guid></item><item><title>Auto-Drafting Police Reports from Noisy ASR Outputs: A Trust-Centered LLM Approach</title><link>http://arxiv.org/abs/2502.07677v1</link><description>Achieving a delicate balance between fostering trust in law en- forcement andprotecting the rights of both officers and civilians continues to emerge as apressing research and product challenge in the world today. In the pursuit offairness and transparency, this study presents an innovative AI-driven systemdesigned to generate police report drafts from complex, noisy, and multi-roledialogue data. Our approach intelligently extracts key elements of lawenforcement interactions and includes them in the draft, producing structurednarratives that are not only high in quality but also reinforce accountabilityand procedural clarity. This frame- work holds the potential to transform thereporting process, ensur- ing greater oversight, consistency, and fairness infuture policing practices. A demonstration video of our system can be accessedat https://drive.google.com/file/d/1kBrsGGR8e3B5xPSblrchRGj-Y-kpCHNO/view?usp=sharing</description><author>Param Kulkarni, Yingchi Liu, Hao-Ming Fu, Shaohua Yang, Isuru Gunasekara, Matt Peloquin, Noah Spitzer-Williams, Xiaotian Zhou, Xiaozhong Liu, Zhengping Ji, Yasser Ibrahim</author><pubDate>Tue, 11 Feb 2025 16:27:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07677v1</guid></item><item><title>Learning from Demonstration with Implicit Nonlinear Dynamics Models</title><link>http://arxiv.org/abs/2409.18768v3</link><description>Learning from Demonstration (LfD) is a useful paradigm for training policiesthat solve tasks involving complex motions, such as those encountered inrobotic manipulation. In practice, the successful application of LfD requiresovercoming error accumulation during policy execution, i.e. the problem ofdrift due to errors compounding over time and the consequentout-of-distribution behaviours. Existing works seek to address this problemthrough scaling data collection, correcting policy errors with ahuman-in-the-loop, temporally ensembling policy predictions or through learninga dynamical system model with convergence guarantees. In this work, we proposeand validate an alternative approach to overcoming this issue. Inspired byreservoir computing, we develop a recurrent neural network layer that includesa fixed nonlinear dynamical system with tunable dynamical properties formodelling temporal dynamics. We validate the efficacy of our neural networklayer on the task of reproducing human handwriting motions using the LASA HumanHandwriting Dataset. Through empirical experiments we demonstrate thatincorporating our layer into existing neural network architectures addressesthe issue of compounding errors in LfD. Furthermore, we perform a comparativeevaluation against existing approaches including a temporal ensemble of policypredictions and an Echo State Network (ESN) implementation. We find that ourapproach yields greater policy precision and robustness on the handwriting taskwhile also generalising to multiple dynamics regimes and maintainingcompetitive latency scores.</description><author>Peter David Fagan, Subramanian Ramamoorthy</author><pubDate>Tue, 11 Feb 2025 16:24:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.18768v3</guid></item><item><title>Revisiting the Initial Steps in Adaptive Gradient Descent Optimization</title><link>http://arxiv.org/abs/2412.02153v2</link><description>Adaptive gradient optimization methods, such as Adam, are prevalent intraining deep neural networks across diverse machine learning tasks due totheir ability to achieve faster convergence. However, these methods oftensuffer from suboptimal generalization compared to stochastic gradient descent(SGD) and exhibit instability, particularly when training Transformer models.In this work, we show the standard initialization of the second-order momentestimation ($v_0 =0$) as a significant factor contributing to theselimitations. We introduce simple yet effective solutions: initializing thesecond-order moment estimation with non-zero values, using either data-drivenor random initialization strategies. Empirical evaluations demonstrate that ourapproach not only stabilizes convergence but also enhances the finalperformance of adaptive gradient optimizers. Furthermore, by adopting theproposed initialization strategies, Adam achieves performance comparable tomany recently proposed variants of adaptive gradient optimization methods. Ourcode is available at https://github.com/Walleclipse/Adam_Initialization.</description><author>Abulikemu Abuduweili, Changliu Liu</author><pubDate>Tue, 11 Feb 2025 16:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.02153v2</guid></item><item><title>MRAnnotator: multi-Anatomy and many-Sequence MRI segmentation of 44 structures</title><link>http://arxiv.org/abs/2402.01031v2</link><description>In this retrospective study, we annotated 44 structures on two datasets: aninternal dataset of 1,518 MRI sequences from 843 patients at the Mount SinaiHealth System, and an external dataset of 397 MRI sequences from 263 patientsfor benchmarking. The internal dataset trained the nnU-Net model MRAnnotator,which demonstrated strong generalizability on the external dataset. MRAnnotatoroutperformed existing models such as TotalSegmentator MRI and MRSegmentator onboth datasets, achieving an overall average Dice score of 0.878 on the internaldataset and 0.875 on the external set. Model weights are available on GitHub,and the external test set can be shared upon request.</description><author>Alexander Zhou, Zelong Liu, Andrew Tieu, Nikhil Patel, Sean Sun, Anthony Yang, Peter Choi, Hao-Chih Lee, Mickael Tordjman, Louisa Deyer, Yunhao Mei, Valentin Fauveau, George Soultanidis, Bachir Taouli, Mingqian Huang, Amish Doshi, Zahi A. Fayad, Timothy Deyer, Xueyan Mei</author><pubDate>Tue, 11 Feb 2025 16:23:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01031v2</guid></item><item><title>Programming Refusal with Conditional Activation Steering</title><link>http://arxiv.org/abs/2409.05907v2</link><description>LLMs have shown remarkable capabilities, but precisely controlling theirresponse behavior remains challenging. Existing activation steering methodsalter LLM behavior indiscriminately, limiting their practical applicability insettings where selective responses are essential, such as content moderation ordomain-specific assistants. In this paper, we propose Conditional ActivationSteering (CAST), which analyzes LLM activation patterns during inference toselectively apply or withhold activation steering based on the input context.Our method is based on the observation that different categories of promptsactivate distinct patterns in the model's hidden states. Using CAST, one cansystematically control LLM behavior with rules like "if input is about hatespeech or adult content, then refuse" or "if input is not about legal advice,then refuse." This allows for selective modification of responses to specificcontent while maintaining normal responses to other content, all withoutrequiring weight optimization. We release an open-source implementation of ourframework at &lt;github.com/IBM/activation-steering&gt;.</description><author>Bruce W. Lee, Inkit Padhi, Karthikeyan Natesan Ramamurthy, Erik Miehling, Pierre Dognin, Manish Nagireddy, Amit Dhurandhar</author><pubDate>Tue, 11 Feb 2025 16:22:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05907v2</guid></item><item><title>Cheap Permutation Testing</title><link>http://arxiv.org/abs/2502.07672v1</link><description>Permutation tests are a popular choice for distinguishing distributions andtesting independence, due to their exact, finite-sample control of falsepositives and their minimax optimality when paired with U-statistics. However,standard permutation tests are also expensive, requiring a test statistic to becomputed hundreds or thousands of times to detect a separation betweendistributions. In this work, we offer a simple approach to accelerate testing:group your datapoints into bins and permute only those bins. For U andV-statistics, we prove that these cheap permutation tests have two remarkableproperties. First, by storing appropriate sufficient statistics, a cheap testcan be run in time comparable to evaluating a single test statistic. Second,cheap permutation power closely approximates standard permutation power. As aresult, cheap tests inherit the exact false positive control and minimaxoptimality of standard permutation tests while running in a fraction of thetime. We complement these findings with improved power guarantees for standardpermutation testing and experiments demonstrating the benefits of cheappermutations over standard maximum mean discrepancy (MMD), Hilbert-Schmidtindependence criterion (HSIC), random Fourier feature, Wilcoxon-Mann-Whitney,cross-MMD, and cross-HSIC tests.</description><author>Carles Domingo-Enrich, Raaz Dwivedi, Lester Mackey</author><pubDate>Tue, 11 Feb 2025 16:19:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07672v1</guid></item><item><title>From Pixels to Components: Eigenvector Masking for Visual Representation Learning</title><link>http://arxiv.org/abs/2502.06314v2</link><description>Predicting masked from visible parts of an image is a powerfulself-supervised approach for visual representation learning. However, thecommon practice of masking random patches of pixels exhibits certain failuremodes, which can prevent learning meaningful high-level features, as requiredfor downstream tasks. We propose an alternative masking strategy that operateson a suitable transformation of the data rather than on the raw pixels.Specifically, we perform principal component analysis and then randomly mask asubset of components, which accounts for a fixed ratio of the data variance.The learning task then amounts to reconstructing the masked components from thevisible ones. Compared to local patches of pixels, the principal components ofimages carry more global information. We thus posit that predicting masked fromvisible components involves more high-level features, allowing our maskingstrategy to extract more useful representations. This is corroborated by ourempirical findings which demonstrate improved image classification performancefor component over pixel masking. Our method thus constitutes a simple androbust data-driven alternative to traditional masked image modeling approaches.</description><author>Alice Bizeul, Thomas Sutter, Alain Ryser, Bernhard Schölkopf, Julius von Kügelgen, Julia E. Vogt</author><pubDate>Tue, 11 Feb 2025 16:04:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.06314v2</guid></item><item><title>A Practical Method for Generating String Counterfactuals</title><link>http://arxiv.org/abs/2402.11355v5</link><description>Interventions targeting the representation space of language models (LMs)have emerged as an effective means to influence model behavior. Such methodsare employed, for example, to eliminate or alter the encoding of demographicinformation such as gender within the model's representations and, in so doing,create a counterfactual representation. However, because the interventionoperates within the representation space, understanding precisely what aspectsof the text it modifies poses a challenge. In this paper, we give a method toconvert representation counterfactuals into string counterfactuals. Wedemonstrate that this approach enables us to analyze the linguistic alterationscorresponding to a given representation space intervention and to interpret thefeatures utilized to encode a specific concept. Moreover, the resultingcounterfactuals can be used to mitigate bias in classification through dataaugmentation.</description><author>Matan Avitan, Ryan Cotterell, Yoav Goldberg, Shauli Ravfogel</author><pubDate>Tue, 11 Feb 2025 16:03:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11355v5</guid></item><item><title>Language Models Largely Exhibit Human-like Constituent Ordering Preferences</title><link>http://arxiv.org/abs/2502.05670v2</link><description>Though English sentences are typically inflexible vis-\`a-vis word order,constituents often show far more variability in ordering. One prominent theorypresents the notion that constituent ordering is directly correlated withconstituent weight: a measure of the constituent's length or complexity. Suchtheories are interesting in the context of natural language processing (NLP),because while recent advances in NLP have led to significant gains in theperformance of large language models (LLMs), much remains unclear about howthese models process language, and how this compares to human languageprocessing. In particular, the question remains whether LLMs display the samepatterns with constituent movement, and may provide insights into existingtheories on when and how the shift occurs in human language. We compare avariety of LLMs with diverse properties to evaluate broad LLM performance onfour types of constituent movement: heavy NP shift, particle movement, dativealternation, and multiple PPs. Despite performing unexpectedly around particlemovement, LLMs generally align with human preferences around constituentordering.</description><author>Ada Defne Tur, Gaurav Kamath, Siva Reddy</author><pubDate>Tue, 11 Feb 2025 16:02:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05670v2</guid></item><item><title>ViSIR: Vision Transformer Single Image Reconstruction Method for Earth System Models</title><link>http://arxiv.org/abs/2502.06741v2</link><description>Purpose: Earth system models (ESMs) integrate the interactions of theatmosphere, ocean, land, ice, and biosphere to estimate the state of regionaland global climate under a wide variety of conditions. The ESMs are highlycomplex, and thus, deep neural network architectures are used to model thecomplexity and store the down-sampled data. In this paper, we propose theVision Transformer Sinusoidal Representation Networks (ViSIR) to improve thesingle image SR (SR) reconstruction task for the ESM data. Methods: ViSIR combines the SR capability of Vision Transformers (ViT) withthe high-frequency detail preservation of the Sinusoidal Representation Network(SIREN) to address the spectral bias observed in SR tasks. Results: The ViSIR outperforms ViT by 4.1 dB, SIREN by 7.5 dB, andSR-Generative Adversarial (SR-GANs) by 7.1dB PSNR on average for threedifferent measurements. Conclusion: The proposed ViSIR is evaluated and compared withstate-of-the-art methods. The results show that the proposed algorithm isoutperforming other methods in terms of Mean Square Error(MSE),Peak-Signal-to-Noise-Ratio(PSNR), and Structural Similarity IndexMeasure(SSIM).</description><author>Ehsan Zeraatkar, Salah Faroughi, Jelena Tešić</author><pubDate>Tue, 11 Feb 2025 16:02:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.06741v2</guid></item><item><title>Learning to Optimize for Mixed-Integer Non-linear Programming</title><link>http://arxiv.org/abs/2410.11061v8</link><description>Mixed-integer nonlinear programs (MINLPs) arise in diverse domains such asenergy systems and transportation but are notoriously difficult to solve,particularly on a large scale. While learning-to-optimize methods have beensuccessful at continuous optimization, extending them to MINLPs is stillchallenging due to the integer constraints. To overcome this, we propose anovel deep-learning approach with two learnable correction layers to ensuresolution integrality and a post-processing step to improve solutionfeasibility. Our experiments show that this is the first general method capableof efficiently solving large-scale MINLPs with up to tens of thousands ofvariables in milliseconds, delivering high-quality solutions even whentraditional solvers and heuristics fail. This is the first general learningmethod for MINLP, successfully solving some of the largest instances reportedto date.</description><author>Bo Tang, Elias B. Khalil, Ján Drgoňa</author><pubDate>Tue, 11 Feb 2025 15:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11061v8</guid></item><item><title>Not All Prompts Are Made Equal: Prompt-based Pruning of Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2406.12042v3</link><description>Text-to-image (T2I) diffusion models have demonstrated impressive imagegeneration capabilities. Still, their computational intensity prohibitsresource-constrained organizations from deploying T2I models after fine-tuningthem on their internal target data. While pruning techniques offer a potentialsolution to reduce the computational burden of T2I models, static pruningmethods use the same pruned model for all input prompts, overlooking thevarying capacity requirements of different prompts. Dynamic pruning addressesthis issue by utilizing a separate sub-network for each prompt, but it preventsbatch parallelism on GPUs. To overcome these limitations, we introduce AdaptivePrompt-Tailored Pruning (APTP), a novel prompt-based pruning method designedfor T2I diffusion models. Central to our approach is a prompt router model,which learns to determine the required capacity for an input text prompt androutes it to an architecture code, given a total desired compute budget forprompts. Each architecture code represents a specialized model tailored to theprompts assigned to it, and the number of codes is a hyperparameter. We trainthe prompt router and architecture codes using contrastive learning, ensuringthat similar prompts are mapped to nearby codes. Further, we employ optimaltransport to prevent the codes from collapsing into a single one. Wedemonstrate APTP's effectiveness by pruning Stable Diffusion (SD) V2.1 usingCC3M and COCO as target datasets. APTP outperforms the single-model pruningbaselines in terms of FID, CLIP, and CMMD scores. Our analysis of the clusterslearned by APTP reveals they are semantically meaningful. We also show thatAPTP can automatically discover previously empirically found challengingprompts for SD, e.g. prompts for generating text images, assigning them tohigher capacity codes.</description><author>Alireza Ganjdanesh, Reza Shirkavand, Shangqian Gao, Heng Huang</author><pubDate>Tue, 11 Feb 2025 15:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12042v3</guid></item><item><title>Human Decision-making is Susceptible to AI-driven Manipulation</title><link>http://arxiv.org/abs/2502.07663v1</link><description>Artificial Intelligence (AI) systems are increasingly intertwined with dailylife, assisting users in executing various tasks and providing guidance ondecision-making. This integration introduces risks of AI-driven manipulation,where such systems may exploit users' cognitive biases and emotionalvulnerabilities to steer them toward harmful outcomes. Through a randomizedcontrolled trial with 233 participants, we examined human susceptibility tosuch manipulation in financial (e.g., purchases) and emotional (e.g., conflictresolution) decision-making contexts. Participants interacted with one of threeAI agents: a neutral agent (NA) optimizing for user benefit without explicitinfluence, a manipulative agent (MA) designed to covertly influence beliefs andbehaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicitpsychological tactics to reach its hidden objectives. By analyzingparticipants' decision patterns and shifts in their preference ratingspost-interaction, we found significant susceptibility to AI-drivenmanipulation. Particularly, across both decision-making domains, participantsinteracting with the manipulative agents shifted toward harmful options atsubstantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA:42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional,12.8%). Notably, our findings reveal that even subtle manipulative objectives(MA) can be as effective as employing explicit psychological strategies (SEMA)in swaying human decision-making. By revealing the potential for covert AIinfluence, this study highlights a critical vulnerability in human-AIinteractions, emphasizing the need for ethical safeguards and regulatoryframeworks to ensure responsible deployment of AI technologies and protecthuman autonomy.</description><author>Sahand Sabour, June M. Liu, Siyang Liu, Chris Z. Yao, Shiyao Cui, Xuanming Zhang, Wen Zhang, Yaru Cao, Advait Bhat, Jian Guan, Wei Wu, Rada Mihalcea, Tim Althoff, Tatia M. C. Lee, Minlie Huang</author><pubDate>Tue, 11 Feb 2025 15:56:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07663v1</guid></item><item><title>mWhisper-Flamingo for Multilingual Audio-Visual Noise-Robust Speech Recognition</title><link>http://arxiv.org/abs/2502.01547v2</link><description>Audio-Visual Speech Recognition (AVSR) combines lip-based video with audioand can improve performance in noise, but most methods are trained only onEnglish data. One limitation is the lack of large-scale multilingual videodata, which makes it hard hard to train models from scratch. In this work, wepropose mWhisper-Flamingo for multilingual AVSR which combines the strengths ofa pre-trained audio model (Whisper) and video model (AV-HuBERT). To enablebetter multi-modal integration and improve the noisy multilingual performance,we introduce decoder modality dropout where the model is trained both on pairedaudio-visual inputs and separate audio/visual inputs. mWhisper-Flamingoachieves state-of-the-art WER on MuAViC, an AVSR dataset of 9 languages.Audio-visual mWhisper-Flamingo consistently outperforms audio-only Whisper onall languages in noisy conditions.</description><author>Andrew Rouditchenko, Samuel Thomas, Hilde Kuehne, Rogerio Feris, James Glass</author><pubDate>Tue, 11 Feb 2025 15:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01547v2</guid></item><item><title>TransRef: Multi-Scale Reference Embedding Transformer for Reference-Guided Image Inpainting</title><link>http://arxiv.org/abs/2306.11528v4</link><description>Image inpainting for completing complicated semantic environments and diversehole patterns of corrupted images is challenging even for state-of-the-artlearning-based inpainting methods trained on large-scale data. A referenceimage capturing the same scene of a corrupted image offers informative guidancefor completing the corrupted image as it shares similar texture and structurepriors to that of the holes of the corrupted image. In this work, we propose atransformer-based encoder-decoder network, named TransRef, for reference-guidedimage inpainting. Specifically, the guidance is conducted progressively througha reference embedding procedure, in which the referencing features aresubsequently aligned and fused with the features of the corrupted image. Forprecise utilization of the reference features for guidance, a reference-patchalignment (Ref-PA) module is proposed to align the patch features of thereference and corrupted images and harmonize their style differences, while areference-patch transformer (Ref-PT) module is proposed to refine the embeddedreference feature. Moreover, to facilitate the research of reference-guidedimage restoration tasks, we construct a publicly accessible benchmark datasetcontaining 50K pairs of input and reference images. Both quantitative andqualitative evaluations demonstrate the efficacy of the reference informationand the proposed method over the state-of-the-art methods in completing complexholes. Code and dataset can be accessed at https://github.com/Cameltr/TransRef.</description><author>Taorong Liu, Liang Liao, Delin Chen, Jing Xiao, Zheng Wang, Chia-Wen Lin, Shin'ichi Satoh</author><pubDate>Tue, 11 Feb 2025 15:55:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11528v4</guid></item><item><title>Partial-Label Learning with Conformal Candidate Cleaning</title><link>http://arxiv.org/abs/2502.07661v1</link><description>Real-world data is often ambiguous; for example, human annotation producesinstances with multiple conflicting class labels. Partial-label learning (PLL)aims at training a classifier in this challenging setting, where each instanceis associated with a set of candidate labels and one correct, but unknown,class label. A multitude of algorithms targeting this setting exists and, toenhance their prediction quality, several extensions that are applicable acrossa wide range of PLL methods have been introduced. While many of theseextensions rely on heuristics, this article proposes a novel enhancing methodthat incrementally prunes candidate sets using conformal prediction. To workaround the missing labeled validation set, which is typically required forconformal prediction, we propose a strategy that alternates between training aPLL classifier to label the validation set, leveraging these predicted classlabels for calibration, and pruning candidate labels that are not part of theresulting conformal sets. In this sense, our method alternates betweenempirical risk minimization and candidate set pruning. We establish that ourpruning method preserves the conformal validity with respect to the unknownground truth. Our extensive experiments on artificial and real-world data showthat the proposed approach significantly improves the test set accuracies ofseveral state-of-the-art PLL classifiers.</description><author>Tobias Fuchs, Florian Kalinke</author><pubDate>Tue, 11 Feb 2025 15:51:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07661v1</guid></item><item><title>Isotonic Mechanism for Exponential Family Estimation in Machine Learning Peer Review</title><link>http://arxiv.org/abs/2304.11160v4</link><description>In 2023, the International Conference on Machine Learning (ICML) requiredauthors with multiple submissions to rank their submissions based on perceivedquality. In this paper, we aim to employ these author-specified rankings toenhance peer review in machine learning and artificial intelligence conferencesby extending the Isotonic Mechanism to exponential family distributions. Thismechanism generates adjusted scores that closely align with the original scoreswhile adhering to author-specified rankings. Despite its applicability to abroad spectrum of exponential family distributions, implementing this mechanismdoes not require knowledge of the specific distribution form. We demonstratethat an author is incentivized to provide accurate rankings when her utilitytakes the form of a convex additive function of the adjusted review scores. Fora certain subclass of exponential family distributions, we prove that theauthor reports truthfully only if the question involves only pairwisecomparisons between her submissions, thus indicating the optimality of rankingin truthful information elicitation. Moreover, we show that the adjusted scoresimprove dramatically the estimation accuracy compared to the original scoresand achieve nearly minimax optimality when the ground-truth scores have boundedtotal variation. We conclude with a numerical analysis of the ICML 2023 rankingdata, showing substantial estimation gains in approximating a proxyground-truth quality of the papers using the Isotonic Mechanism.</description><author>Yuling Yan, Weijie J. Su, Jianqing Fan</author><pubDate>Tue, 11 Feb 2025 15:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11160v4</guid></item><item><title>ProjectTest: A Project-level LLM Unit Test Generation Benchmark and Impact of Error Fixing Mechanisms</title><link>http://arxiv.org/abs/2502.06556v2</link><description>Unit test generation has become a promising and important use case of LLMs.However, existing evaluation benchmarks for assessing LLM unit test generationcapabilities focus on function- or class-level code rather than more practicaland challenging project-level codebases. To address such limitation, we proposeProjectTest, a project-level benchmark for unit test generation coveringPython, Java, and JavaScript. ProjectTest features 20 moderate-sized andhigh-quality projects per language. We evaluate nine frontier LLMs onProjectTest and the results show that all frontier LLMs tested exhibit moderateperformance on ProjectTest on Python and Java, highlighting the difficulty ofProjectTest. We also conduct a thorough error analysis, which shows that evenfrontier LLMs, such as Claude-3.5-Sonnet, have significant simple errors,including compilation and cascade errors. Motivated by this observation, wefurther evaluate all frontier LLMs under manual error-fixing andself-error-fixing scenarios to assess their potential when equipped witherror-fixing mechanisms.</description><author>Yibo Wang, Congying Xia, Wenting Zhao, Jiangshu Du, Chunyu Miao, Zhongfen Deng, Philip S. Yu, Chen Xing</author><pubDate>Tue, 11 Feb 2025 15:48:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.06556v2</guid></item><item><title>NeuPAN: Direct Point Robot Navigation with End-to-End Model-based Learning</title><link>http://arxiv.org/abs/2403.06828v3</link><description>Navigating a nonholonomic robot in a cluttered, unknown environment requiresaccurate perception and precise motion control for real-time collisionavoidance. This paper presents NeuPAN: a real-time, highly accurate, map-free,easy-to-deploy, and environment-invariant robot motion planner. Leveraging atightly coupled perception-to-control framework, NeuPAN has two key innovationscompared to existing approaches: 1) it directly maps raw point cloud data to alatent distance feature space for collision-free motion generation, avoidingerror propagation from the perception to control pipeline; 2) it isinterpretable from an end-to-end model-based learning perspective. The crux ofNeuPAN is solving an end-to-end mathematical model with numerous point-levelconstraints using a plug-and-play (PnP) proximal alternating-minimizationnetwork (PAN), incorporating neurons in the loop. This allows NeuPAN togenerate real-time, physically interpretable motions. It seamlessly integratesdata and knowledge engines, and its network parameters can be fine-tuned viabackpropagation. We evaluate NeuPAN on a ground mobile robot, a wheel-leggedrobot, and an autonomous vehicle, in extensive simulated and real-worldenvironments. Results demonstrate that NeuPAN outperforms existing baselines interms of accuracy, efficiency, robustness, and generalization capabilitiesacross various environments, including the cluttered sandbox, office, corridor,and parking lot. We show that NeuPAN works well in unknown and unstructuredenvironments with arbitrarily shaped objects, transforming impassable pathsinto passable ones.</description><author>Ruihua Han, Shuai Wang, Shuaijun Wang, Zeqing Zhang, Jianjun Chen, Shijie Lin, Chengyang Li, Chengzhong Xu, Yonina C. Eldar, Qi Hao, Jia Pan</author><pubDate>Tue, 11 Feb 2025 15:47:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06828v3</guid></item><item><title>Private Low-Rank Approximation for Covariance Matrices, Dyson Brownian Motion, and Eigenvalue-Gap Bounds for Gaussian Perturbations</title><link>http://arxiv.org/abs/2502.07657v1</link><description>We consider the problem of approximating a $d \times d$ covariance matrix $M$with a rank-$k$ matrix under $(\varepsilon,\delta)$-differential privacy. Wepresent and analyze a complex variant of the Gaussian mechanism and obtainupper bounds on the Frobenius norm of the difference between the matrix outputby this mechanism and the best rank-$k$ approximation to $M$. Our analysisprovides improvements over previous bounds, particularly when the spectrum of$M$ satisfies natural structural assumptions. The novel insight is to view theaddition of Gaussian noise to a matrix as a continuous-time matrix Brownianmotion. This viewpoint allows us to track the evolution of eigenvalues andeigenvectors of the matrix, which are governed by stochastic differentialequations discovered by Dyson. These equations enable us to upper bound theFrobenius distance between the best rank-$k$ approximation of $M$ and that of aGaussian perturbation of $M$ as an integral that involves inverse eigenvaluegaps of the stochastically evolving matrix, as opposed to a sum of perturbationbounds obtained via Davis-Kahan-type theorems. Subsequently, again using theDyson Brownian motion viewpoint, we show that the eigenvalues of the matrix $M$perturbed by Gaussian noise have large gaps with high probability. Theseresults also contribute to the analysis of low-rank approximations underaverage-case perturbations, and to an understanding of eigenvalue gaps forrandom matrices, both of which may be of independent interest.</description><author>Oren Mangoubi, Nisheeth K. Vishnoi</author><pubDate>Tue, 11 Feb 2025 15:46:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07657v1</guid></item><item><title>Enhancing Financial Time-Series Forecasting with Retrieval-Augmented Large Language Models</title><link>http://arxiv.org/abs/2502.05878v2</link><description>Stock movement prediction, a critical task in financial time-seriesforecasting, relies on identifying and retrieving key influencing factors fromvast and complex datasets. However, traditional text-trained or numericsimilarity-based retrieval methods often struggle to handle the intricacies offinancial data. To address this, we propose the first retrieval-augmentedgeneration (RAG) framework specifically designed for financial time-seriesforecasting. Our framework incorporates three key innovations: a fine-tuned 1Blarge language model (StockLLM) as its backbone, a novel candidate selectionmethod enhanced by LLM feedback, and a training objective that maximizes thesimilarity between queries and historically significant sequences. Theseadvancements enable our retriever, FinSeer, to uncover meaningful patternswhile effectively minimizing noise in complex financial datasets. To supportrobust evaluation, we also construct new datasets that integrate financialindicators and historical stock prices. Experimental results demonstrate thatour RAG framework outperforms both the baseline StockLLM and random retrievalmethods, showcasing its effectiveness. FinSeer, as the retriever, achieves an8% higher accuracy on the BIGDATA22 benchmark and retrieves more impactfulsequences compared to existing retrieval methods. This work highlights theimportance of tailored retrieval models in financial forecasting and provides anovel, scalable framework for future research in the field.</description><author>Mengxi Xiao, Zihao Jiang, Lingfei Qian, Zhengyu Chen, Yueru He, Yijing Xu, Yuecheng Jiang, Dong Li, Ruey-Ling Weng, Min Peng, Jimin Huang, Sophia Ananiadou, Qianqian Xie</author><pubDate>Tue, 11 Feb 2025 15:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05878v2</guid></item><item><title>A Unifying Framework for Causal Imitation Learning with Hidden Confounders</title><link>http://arxiv.org/abs/2502.07656v1</link><description>We propose a general and unifying framework for causal Imitation Learning(IL) with hidden confounders that subsumes several existing confounded ILsettings from the literature. Our framework accounts for two types of hiddenconfounders: (a) those observed by the expert, which thus influence theexpert's policy, and (b) confounding noise hidden to both the expert and the ILalgorithm. For additional flexibility, we also introduce a confounding noisehorizon and time-varying expert-observable hidden variables. We show thatcausal IL in our framework can be reduced to a set of Conditional MomentRestrictions (CMRs) by leveraging trajectory histories as instruments to learna history-dependent policy. We propose DML-IL, a novel algorithm that usesinstrumental variable regression to solve these CMRs and learn a policy. Weprovide a bound on the imitation gap for DML-IL, which recovers prior resultsas special cases. Empirical evaluation on a toy environment with continuesstate-action spaces and multiple Mujoco tasks demonstrate that DML-ILoutperforms state-of-the-art causal IL algorithms.</description><author>Daqian Shao, Thomas Kleine Buening, Marta Kwiatkowska</author><pubDate>Tue, 11 Feb 2025 15:43:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07656v1</guid></item><item><title>Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data</title><link>http://arxiv.org/abs/2406.03736v3</link><description>Discrete diffusion models with absorbing processes have shown promise inlanguage modeling. The key quantities to be estimated are the ratios betweenthe marginal probabilities of two transitive states at all timesteps, calledthe concrete score. In this paper, we reveal that the concrete score inabsorbing diffusion can be expressed as conditional probabilities of cleandata, multiplied by a time-dependent scalar in an analytic form. Motivated bythis finding, we propose reparameterized absorbing discrete diffusion (RADD), adedicated diffusion model without time-condition that characterizes thetime-independent conditional probabilities. Besides its simplicity, RADD canreduce the number of function evaluations (NFEs) by caching the output of thetime-independent network when the noisy sample remains unchanged in a samplinginterval, which enables sampling acceleration. Built upon the new perspectiveof conditional distributions, we further unify absorbing discrete diffusion andany-order autoregressive models (AO-ARMs), showing that the upper bound on thenegative log-likelihood for the diffusion model can be interpreted as anexpected negative log-likelihood for AO-ARMs. Further, our RADD models achieveSOTA performance among diffusion models on 5 zero-shot language modelingbenchmarks (measured by perplexity) at the GPT-2 scale. Our code is availableat https://github.com/ML-GSAI/RADD.</description><author>Jingyang Ou, Shen Nie, Kaiwen Xue, Fengqi Zhu, Jiacheng Sun, Zhenguo Li, Chongxuan Li</author><pubDate>Tue, 11 Feb 2025 15:42:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03736v3</guid></item><item><title>Guiding Time-Varying Generative Models with Natural Gradients on Exponential Family Manifold</title><link>http://arxiv.org/abs/2502.07650v1</link><description>Optimising probabilistic models is a well-studied field in statistics.However, its connection with the training of generative models remains largelyunder-explored. In this paper, we show that the evolution of time-varyinggenerative models can be projected onto an exponential family manifold,naturally creating a link between the parameters of a generative model andthose of a probabilistic model. We then train the generative model by movingits projection on the manifold according to the natural gradient descentscheme. This approach also allows us to approximate the natural gradient of theKL divergence efficiently without relying on MCMC for intractable models.Furthermore, we propose particle versions of the algorithm, which featureclosed-form update rules for any parametric model within the exponentialfamily. Through toy and real-world experiments, we validate the effectivenessof the proposed algorithms.</description><author>Song Liu, Leyang Wang, Yakun Wang</author><pubDate>Tue, 11 Feb 2025 15:39:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07650v1</guid></item></channel></rss>