<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 09 Jul 2023 06:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Synthesizing Artistic Cinemagraphs from Text</title><link>http://arxiv.org/abs/2307.03190v1</link><description>We introduce Artistic Cinemagraph, a fully automated method for creatingcinemagraphs from text descriptions - an especially challenging task whenprompts feature imaginary elements and artistic styles, given the complexity ofinterpreting the semantics and motions of these images. Existing single-imageanimation methods fall short on artistic inputs, and recent text-based videomethods frequently introduce temporal inconsistencies, struggling to keepcertain regions static. To address these challenges, we propose an idea ofsynthesizing image twins from a single text prompt - a pair of an artisticimage and its pixel-aligned corresponding natural-looking twin. While theartistic image depicts the style and appearance detailed in our text prompt,the realistic counterpart greatly simplifies layout and motion analysis.Leveraging existing natural image and video datasets, we can accurately segmentthe realistic image and predict plausible motion given the semanticinformation. The predicted motion can then be transferred to the artistic imageto create the final cinemagraph. Our method outperforms existing approaches increating cinemagraphs for natural landscapes as well as artistic andother-worldly scenes, as validated by automated metrics and user studies.Finally, we demonstrate two extensions: animating existing paintings andcontrolling motion directions using text.</description><author>Aniruddha Mahapatra, Aliaksandr Siarohin, Hsin-Ying Lee, Sergey Tulyakov, Jun-Yan Zhu</author><pubDate>Thu, 06 Jul 2023 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03190v1</guid></item><item><title>TGRL: An Algorithm for Teacher Guided Reinforcement Learning</title><link>http://arxiv.org/abs/2307.03186v1</link><description>Learning from rewards (i.e., reinforcement learning or RL) and learning toimitate a teacher (i.e., teacher-student learning) are two establishedapproaches for solving sequential decision-making problems. To combine thebenefits of these different forms of learning, it is common to train a policyto maximize a combination of reinforcement and teacher-student learningobjectives. However, without a principled method to balance these objectives,prior work used heuristics and problem-specific hyperparameter searches tobalance the two objectives. We present a $\textit{principled}$ approach, alongwith an approximate implementation for $\textit{dynamically}$ and$\textit{automatically}$ balancing when to follow the teacher and when to userewards. The main idea is to adjust the importance of teacher supervision bycomparing the agent's performance to the counterfactual scenario of the agentlearning without teacher supervision and only from rewards. If using teachersupervision improves performance, the importance of teacher supervision isincreased and otherwise it is decreased. Our method, $\textit{Teacher GuidedReinforcement Learning}$ (TGRL), outperforms strong baselines across diversedomains without hyper-parameter tuning.</description><author>Idan Shenfeld, Zhang-Wei Hong, Aviv Tamar, Pulkit Agrawal</author><pubDate>Thu, 06 Jul 2023 18:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03186v1</guid></item><item><title>IPO-LDM: Depth-aided 360-degree Indoor RGB Panorama Outpainting via Latent Diffusion Model</title><link>http://arxiv.org/abs/2307.03177v1</link><description>Generating complete 360-degree panoramas from narrow field of view images isongoing research as omnidirectional RGB data is not readily available. ExistingGAN-based approaches face some barriers to achieving higher quality output, andhave poor generalization performance over different mask types. In this paper,we present our 360-degree indoor RGB panorama outpainting model using latentdiffusion models (LDM), called IPO-LDM. We introduce a new bi-modal latentdiffusion structure that utilizes both RGB and depth panoramic data duringtraining, but works surprisingly well to outpaint normal depth-free RGB imagesduring inference. We further propose a novel technique of introducingprogressive camera rotations during each diffusion denoising step, which leadsto substantial improvement in achieving panorama wraparound consistency.Results show that our IPO-LDM not only significantly outperformsstate-of-the-art methods on RGB panorama outpainting, but can also producemultiple and diverse well-structured results for different types of masks.</description><author>Tianhao Wu, Chuanxia Zheng, Tat-Jen Cham</author><pubDate>Thu, 06 Jul 2023 18:57:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03177v1</guid></item><item><title>Learning Curves for Heterogeneous Feature-Subsampled Ridge Ensembles</title><link>http://arxiv.org/abs/2307.03176v1</link><description>Feature bagging is a well-established ensembling method which aims to reduceprediction variance by training estimators in an ensemble on random subsamplesor projections of features. Typically, ensembles are chosen to be homogeneous,in the sense the the number of feature dimensions available to an estimator isuniform across the ensemble. Here, we introduce heterogeneous featureensembling, with estimators built on varying number of feature dimensions, andconsider its performance in a linear regression setting. We study an ensembleof linear predictors, each fit using ridge regression on a subset of theavailable features. We allow the number of features included in these subsetsto vary. Using the replica trick from statistical physics, we derive learningcurves for ridge ensembles with deterministic linear masks. We obtain explicitexpressions for the learning curves in the case of equicorrelated data with anisotropic feature noise. Using the derived expressions, we investigate theeffect of subsampling and ensembling, finding sharp transitions in the optimalensembling strategy in the parameter space of noise level, data correlations,and data-task alignment. Finally, we suggest variable-dimension feature baggingas a strategy to mitigate double descent for robust machine learning inpractice.</description><author>Benjamin S. Ruben, Cengiz Pehlevan</author><pubDate>Thu, 06 Jul 2023 18:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03176v1</guid></item><item><title>Push Past Green: Learning to Look Behind Plant Foliage by Moving It</title><link>http://arxiv.org/abs/2307.03175v1</link><description>Autonomous agriculture applications (e.g., inspection, phenotyping, pluckingfruits) require manipulating the plant foliage to look behind the leaves andthe branches. Partial visibility, extreme clutter, thin structures, and unknowngeometry and dynamics for plants make such manipulation challenging. We tacklethese challenges through data-driven methods. We use self-supervision to trainSRPNet, a neural network that predicts what space is revealed on execution of acandidate action on a given plant. We use SRPNet with the cross-entropy methodto predict actions that are effective at revealing space beneath plant foliage.Furthermore, as SRPNet does not just predict how much space is revealed butalso where it is revealed, we can execute a sequence of actions thatincrementally reveal more and more space beneath the plant foliage. Weexperiment with a synthetic (vines) and a real plant (Dracaena) on a physicaltest-bed across 5 settings including 2 settings that test generalization tonovel plant configurations. Our experiments reveal the effectiveness of ouroverall method, PPG, over a competitive hand-crafted exploration method, andthe effectiveness of SRPNet over a hand-crafted dynamics model and relevantablations.</description><author>Xiaoyu Zhang, Saurabh Gupta</author><pubDate>Thu, 06 Jul 2023 18:55:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03175v1</guid></item><item><title>Lost in the Middle: How Language Models Use Long Contexts</title><link>http://arxiv.org/abs/2307.03172v1</link><description>While recent language models have the ability to take long contexts as input,relatively little is known about how well the language models use longercontext. We analyze language model performance on two tasks that requireidentifying relevant information within their input contexts: multi-documentquestion answering and key-value retrieval. We find that performance is oftenhighest when relevant information occurs at the beginning or end of the inputcontext, and significantly degrades when models must access relevantinformation in the middle of long contexts. Furthermore, performancesubstantially decreases as the input context grows longer, even for explicitlylong-context models. Our analysis provides a better understanding of howlanguage models use their input context and provides new evaluation protocolsfor future long-context models.</description><author>Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang</author><pubDate>Thu, 06 Jul 2023 18:54:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03172v1</guid></item><item><title>LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams</title><link>http://arxiv.org/abs/2307.03171v1</link><description>Approaches based on Binary decision diagrams (BDDs) have recently achievedstate-of-the-art results for multiobjective integer programming problems. Thevariable ordering used in constructing BDDs can have a significant impact ontheir size and on the quality of bounds derived from relaxed or restricted BDDsfor single-objective optimization problems. We first showcase a similar impactof variable ordering on the Pareto frontier (PF) enumeration time for themultiobjective knapsack problem, suggesting the need for deriving variableordering methods that improve the scalability of the multiobjective BDDapproach. To that end, we derive a novel parameter configuration space based onvariable scoring functions which are linear in a small set of interpretable andeasy-to-compute variable features. We show how the configuration space can beefficiently explored using black-box optimization, circumventing the curse ofdimensionality (in the number of variables and objectives), and finding goodorderings that reduce the PF enumeration time. However, black-box optimizationapproaches incur a computational overhead that outweighs the reduction in timedue to good variable ordering. To alleviate this issue, we propose LEO, asupervised learning approach for finding efficient variable orderings thatreduce the enumeration time. Experiments on benchmark sets from the knapsackproblem with 3-7 objectives and up to 80 variables show that LEO is ~30-300%and ~10-200% faster at PF enumeration than common ordering strategies andalgorithm configuration. Our code and instances are available athttps://github.com/khalil-research/leo.</description><author>Rahul Patel, Elias B. Khalil</author><pubDate>Thu, 06 Jul 2023 18:52:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03171v1</guid></item><item><title>Focused Transformer: Contrastive Training for Context Scaling</title><link>http://arxiv.org/abs/2307.03170v1</link><description>Large language models have an exceptional capability to incorporate newinformation in a contextual manner. However, the full potential of such anapproach is often restrained due to a limitation in the effective contextlength. One solution to this issue is to endow an attention layer with accessto an external memory, which comprises of (key, value) pairs. Yet, as thenumber of documents increases, the proportion of relevant keys to irrelevantones decreases, leading the model to focus more on the irrelevant keys. Weidentify a significant challenge, dubbed the distraction issue, where keyslinked to different semantic values might overlap, making them hard todistinguish. To tackle this problem, we introduce the Focused Transformer(FoT), a technique that employs a training process inspired by contrastivelearning. This novel approach enhances the structure of the (key, value) space,enabling an extension of the context length. Our method allows for fine-tuningpre-existing, large-scale models to lengthen their effective context. This isdemonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. Theresulting models, which we name LongLLaMA, exhibit advancements in tasksrequiring a long context. We further illustrate that our LongLLaMA modelsadeptly manage a $256 k$ context length for passkey retrieval.</description><author>Szymon Tworkowski, Konrad Staniszewski, Mikołaj Pacek, Yuhuai Wu, Henryk Michalewski, Piotr Miłoś</author><pubDate>Thu, 06 Jul 2023 18:52:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03170v1</guid></item><item><title>VideoGLUE: Video General Understanding Evaluation of Foundation Models</title><link>http://arxiv.org/abs/2307.03166v1</link><description>We evaluate existing foundation models video understanding capabilities usinga carefully designed experiment protocol consisting of three hallmark tasks(action recognition, temporal localization, and spatiotemporal localization),eight datasets well received by the community, and four adaptation methodstailoring a foundation model (FM) for a downstream task. Moreover, we propose ascalar VideoGLUE score (VGS) to measure an FMs efficacy and efficiency whenadapting to general video understanding tasks. Our main findings are asfollows. First, task-specialized models significantly outperform the six FMsstudied in this work, in sharp contrast to what FMs have achieved in naturallanguage and image understanding. Second,video-native FMs, whose pretrainingdata contains the video modality, are generally better than image-native FMs inclassifying motion-rich videos, localizing actions in time, and understanding avideo of more than one action. Third, the video-native FMs can perform well onvideo tasks under light adaptations to downstream tasks(e.g., freezing the FMbackbones), while image-native FMs win in full end-to-end finetuning. The firsttwo observations reveal the need and tremendous opportunities to conductresearch on video-focused FMs, and the last confirms that both tasks andadaptation methods matter when it comes to the evaluation of FMs.</description><author>Liangzhe Yuan, Nitesh Bharadwaj Gundavarapu, Long Zhao, Hao Zhou, Yin Cui, Lu Jiang, Xuan Yang, Menglin Jia, Tobias Weyand, Luke Friedman, Mikhail Sirotenko, Huisheng Wang, Florian Schroff, Hartwig Adam, Ming-Hsuan Yang, Ting Liu, Boqing Gong</author><pubDate>Thu, 06 Jul 2023 18:47:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03166v1</guid></item><item><title>BrickPal: Augmented Reality-based Assembly Instructions for Brick Models</title><link>http://arxiv.org/abs/2307.03162v1</link><description>The assembly instruction is a mandatory component of Lego-like brick sets.Theconventional production of assembly instructions requires a considerable amountof manual fine-tuning, which is intractable for casual users and customizedbrick sets.Moreover, the traditional paper-based instructions lackexpressiveness and interactivity.To tackle the two problems above, we presentBrickPal, an augmented reality-based system, which visualizes assemblyinstructions in an augmented reality head-mounted display. It utilizes NaturalLanguage Processing (NLP) techniques to generate plausible assembly sequences,and provide real-time guidance in the AR headset.Our user study demonstratesBrickPal's effectiveness at assisting users in brick assembly compared totraditional assembly methods. Additionally, the NLP algorithm-generatedassembly sequences achieve the same usability with manually adapted sequences.</description><author>Yao Shi, Xiaofeng Zhang, Ran zhang, Zhou Yang, Xiao Tang, Hongni Ye, Yi Wu</author><pubDate>Thu, 06 Jul 2023 18:42:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03162v1</guid></item><item><title>Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?</title><link>http://arxiv.org/abs/2307.03157v1</link><description>Deep learning-based diagnostic system has demonstrated potential inclassifying skin cancer conditions when labeled training example are abundant.However, skin lesion analysis often suffers from a scarcity of labeled data,hindering the development of an accurate and reliable diagnostic system. Inthis work, we leverage multiple skin lesion datasets and investigate thefeasibility of various unsupervised domain adaptation (UDA) methods in binaryand multi-class skin lesion classification. In particular, we assess three UDAtraining schemes: single-, combined-, and multi-source. Our experiment resultsshow that UDA is effective in binary classification, with further improvementbeing observed when imbalance is mitigated. In multi-class task, itsperformance is less prominent, and imbalance problem again needs to beaddressed to achieve above-baseline accuracy. Through our quantitativeanalysis, we find that the test error of multi-class tasks is stronglycorrelated with label shift, and feature-level UDA methods have limitationswhen handling imbalanced datasets. Finally, our study reveals that UDA caneffectively reduce bias against minority groups and promote fairness, evenwithout the explicit use of fairness-focused techniques.</description><author>Janet Wang, Yunbei Zhang, Zhengming Ding, Jihun Hamm</author><pubDate>Thu, 06 Jul 2023 18:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03157v1</guid></item><item><title>On the Noise Sensitivity of the Randomized SVD</title><link>http://arxiv.org/abs/2305.17435v2</link><description>The randomized singular value decomposition (R-SVD) is a popularsketching-based algorithm for efficiently computing the partial SVD of a largematrix. When the matrix is low-rank, the R-SVD produces its partial SVDexactly; but when the rank is large, it only yields an approximation. Motivated by applications in data science and principal component analysis(PCA), we analyze the R-SVD under a low-rank signal plus noise measurementmodel; specifically, when its input is a spiked random matrix. The singularvalues produced by the R-SVD are shown to exhibit a BBP-like phase transition:when the SNR exceeds a certain detectability threshold, that depends on thedimension reduction factor, the largest singular value is an outlier; below thethreshold, no outlier emerges from the bulk of singular values. We furthercompute asymptotic formulas for the overlap between the ground truth signalsingular vectors and the approximations produced by the R-SVD. Dimensionality reduction has the adverse affect of amplifying the noise in ahighly nonlinear manner. Our results demonstrate the statistical advantage --in both signal detection and estimation -- of the R-SVD over more naivesketched PCA variants; the advantage is especially dramatic when the sketchingdimension is small. Our analysis is asymptotically exact, and substantiallymore fine-grained than existing operator-norm error bounds for the R-SVD, whichlargely fail to give meaningful error estimates in the moderate SNR regime. Itapplies for a broad family of sketching matrices previously considered in theliterature, including Gaussian i.i.d. sketches, random projections, and thesub-sampled Hadamard transform, among others. Lastly, we derive an optimal singular value shrinker for singular values andvectors obtained through the R-SVD, which may be useful for applications inmatrix denoising.</description><author>Elad Romanov</author><pubDate>Thu, 06 Jul 2023 18:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17435v2</guid></item><item><title>MultiVENT: Multilingual Videos of Events with Aligned Natural Text</title><link>http://arxiv.org/abs/2307.03153v1</link><description>Everyday news coverage has shifted from traditional broadcasts towards a widerange of presentation formats such as first-hand, unedited video footage.Datasets that reflect the diverse array of multimodal, multilingual newssources available online could be used to teach models to benefit from thisshift, but existing news video datasets focus on traditional news broadcastsproduced for English-speaking audiences. We address this limitation byconstructing MultiVENT, a dataset of multilingual, event-centric videosgrounded in text documents across five target languages. MultiVENT includesboth news broadcast videos and non-professional event footage, which we use toanalyze the state of online news videos and how they can be leveraged to buildrobust, factually accurate models. Finally, we provide a model for complex,multilingual video retrieval to serve as a baseline for information retrievalusing MultiVENT.</description><author>Kate Sanders, David Etter, Reno Kriz, Benjamin Van Durme</author><pubDate>Thu, 06 Jul 2023 18:29:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03153v1</guid></item><item><title>An Automatic Guidance and Quality Assessment System for Doppler Imaging of Umbilical Artery</title><link>http://arxiv.org/abs/2304.05463v2</link><description>Examination of the umbilical artery with Doppler ultrasonography is performedto investigate blood supply to the fetus through the umbilical cord, which isvital for the monitoring of fetal health. Such examination involves severalsteps that must be performed correctly: identifying suitable sites on theumbilical artery for the measurement, acquiring the blood flow curve in theform of a Doppler spectrum, and ensuring compliance to a set of qualitystandards. These steps rely heavily on the operator's skill, and the shortageof experienced sonographers has thus created a demand for machine assistance.In this work, we propose an automatic system to fill the gap. By using amodified Faster R-CNN network, we obtain an algorithm that can suggestlocations suitable for Doppler measurement. Meanwhile, we have also developed amethod for assessment of the Doppler spectrum's quality. The proposed system isvalidated on 657 images from a national ultrasound screening database, withresults demonstrating its potential as a guidance system.</description><author>Chun Kit Wong, Manxi Lin, Alberto Raheli, Zahra Bashir, Morten Bo Søndergaard Svendsen, Martin Grønnebæk Tolsgaard, Aasa Feragen, Anders Nymark Christensen</author><pubDate>Thu, 06 Jul 2023 18:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05463v2</guid></item><item><title>SLPerf: a Unified Framework for Benchmarking Split Learning</title><link>http://arxiv.org/abs/2304.01502v2</link><description>Data privacy concerns has made centralized training of data, which isscattered across silos, infeasible, leading to the need for collaborativelearning frameworks. To address that, two prominent frameworks emerged, i.e.,federated learning (FL) and split learning (SL). While FL has establishedvarious benchmark frameworks and research libraries,SL currently lacks aunified library despite its diversity in terms of label sharing, modelaggregation, and cut layer choice. This lack of standardization makes comparingSL paradigms difficult. To address this, we propose SLPerf, a unified researchframework and open research library for SL, and conduct extensive experimentson four widely-used datasets under both IID and Non-IID data settings. Ourcontributions include a comprehensive survey of recently proposed SL paradigms,a detailed benchmark comparison of different SL paradigms in differentsituations, and rich engineering take-away messages and research insights forimproving SL paradigms. SLPerf can facilitate SL algorithm development and fairperformance comparisons. The code is available athttps://github.com/Rainysponge/Split-learning-Attacks .</description><author>Tianchen Zhou, Zhanyi Hu, Bingzhe Wu, Cen Chen</author><pubDate>Thu, 06 Jul 2023 18:21:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.01502v2</guid></item><item><title>Topology-Aware Loss for Aorta and Great Vessel Segmentation in Computed Tomography Images</title><link>http://arxiv.org/abs/2307.03137v1</link><description>Segmentation networks are not explicitly imposed to learn global invariantsof an image, such as the shape of an object and the geometry between multipleobjects, when they are trained with a standard loss function. On the otherhand, incorporating such invariants into network training may help improveperformance for various segmentation tasks when they are the intrinsiccharacteristics of the objects to be segmented. One example is segmentation ofaorta and great vessels in computed tomography (CT) images where vessels arefound in a particular geometry in the body due to the human anatomy and theymostly seem as round objects on a 2D CT image. This paper addresses this issueby introducing a new topology-aware loss function that penalizes topologydissimilarities between the ground truth and prediction through persistenthomology. Different from the previously suggested segmentation network designs,which apply the threshold filtration on a likelihood function of the predictionmap and the Betti numbers of the ground truth, this paper proposes to apply theVietoris-Rips filtration to obtain persistence diagrams of both ground truthand prediction maps and calculate the dissimilarity with the Wassersteindistance between the corresponding persistence diagrams. The use of thisfiltration has advantage of modeling shape and geometry at the same time, whichmay not happen when the threshold filtration is applied. Our experiments on4327 CT images of 24 subjects reveal that the proposed topology-aware lossfunction leads to better results than its counterparts, indicating theeffectiveness of this use.</description><author>Seher Ozcelik, Sinan Unver, Ilke Ali Gurses, Rustu Turkay, Cigdem Gunduz-Demir</author><pubDate>Thu, 06 Jul 2023 18:06:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03137v1</guid></item><item><title>Multiplicative Updates for Online Convex Optimization over Symmetric Cones</title><link>http://arxiv.org/abs/2307.03136v1</link><description>We study online convex optimization where the possible actions are trace-oneelements in a symmetric cone, generalizing the extensively-studied expertssetup and its quantum counterpart. Symmetric cones provide a unifying frameworkfor some of the most important optimization models, including linear,second-order cone, and semidefinite optimization. Using tools from the field ofEuclidean Jordan Algebras, we introduce the Symmetric-Cone MultiplicativeWeights Update (SCMWU), a projection-free algorithm for online optimizationover the trace-one slice of an arbitrary symmetric cone. We show that SCMWU isequivalent to Follow-the-Regularized-Leader and Online Mirror Descent withsymmetric-cone negative entropy as regularizer. Using this structural result weshow that SCMWU is a no-regret algorithm, and verify our theoretical resultswith extensive experiments. Our results unify and generalize the analysis forthe Multiplicative Weights Update method over the probability simplex and theMatrix Multiplicative Weights Update method over the set of density matrices.</description><author>Ilayda Canyakmaz, Wayne Lin, Georgios Piliouras, Antonios Varvitsiotis</author><pubDate>Thu, 06 Jul 2023 18:06:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03136v1</guid></item><item><title>Distilling Large Vision-Language Model with Out-of-Distribution Generalizability</title><link>http://arxiv.org/abs/2307.03135v1</link><description>Large vision-language models have achieved outstanding performance, but theirsize and computational requirements make their deployment onresource-constrained devices and time-sensitive tasks impractical. Modeldistillation, the process of creating smaller, faster models that maintain theperformance of larger models, is a promising direction towards the solution.This paper investigates the distillation of visual representations in largeteacher vision-language models into lightweight student models using a small-or mid-scale dataset. Notably, this study focuses on open-vocabularyout-of-distribution (OOD) generalization, a challenging problem that has beenoverlooked in previous model distillation literature. We propose two principlesfrom vision and language modality perspectives to enhance student's OODgeneralization: (1) by better imitating teacher's visual representation space,and carefully promoting better coherence in vision-language alignment with theteacher; (2) by enriching the teacher's language representations withinformative and finegrained semantic attributes to effectively distinguishbetween different labels. We propose several metrics and conduct extensiveexperiments to investigate their techniques. The results demonstratesignificant improvements in zero-shot and few-shot student performance onopen-vocabulary out-of-distribution classification, highlighting theeffectiveness of our proposed approaches. Our code will be released athttps://github.com/xuanlinli17/large_vlm_distillation_ood</description><author>Xuanlin Li, Yunhao Fang, Minghua Liu, Zhan Ling, Zhuowen Tu, Hao Su</author><pubDate>Thu, 06 Jul 2023 18:05:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03135v1</guid></item><item><title>LLM Calibration and Automatic Hallucination Detection via Pareto Optimal Self-supervision</title><link>http://arxiv.org/abs/2306.16564v2</link><description>Large language models (LLMs) have demonstrated remarkable capabilities out ofbox for a wide range of applications, yet accuracy still remains a major growtharea, especially in mission-critical domains such as biomedicine. An effectivemethod to calibrate the confidence level on LLM responses is essential toautomatically detect errors and facilitate human-in-the-loop verification. Animportant source of calibration signals stems from expert-stipulatedprogrammatic supervision, which is often available at low cost but has its ownlimitations such as noise and coverage. In this paper, we introduce a Paretooptimal self-supervision framework that can leverage available programmaticsupervision to systematically calibrate LLM responses by producing a risk scorefor every response, without any additional manual efforts. This is accomplishedby learning a harmonizer model to align LLM output with other availablesupervision sources, which would assign higher risk scores to more uncertainLLM responses and facilitate error correction. Experiments on standard relationextraction tasks in biomedical and general domains demonstrate the promise ofthis approach, with our proposed risk scores highly correlated with the realerror rate of LLMs. For the most uncertain test instances, dynamic promptingbased on our proposed risk scores results in significant accuracy improvementfor off-the-shelf LLMs, boosting GPT-3 results past state-of-the-art (SOTA)weak supervision and GPT-4 results past SOTA supervised results on challengingevaluation datasets.</description><author>Theodore Zhao, Mu Wei, J. Samuel Preston, Hoifung Poon</author><pubDate>Thu, 06 Jul 2023 18:03:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16564v2</guid></item><item><title>Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification</title><link>http://arxiv.org/abs/2307.03133v1</link><description>Test-time adaptation (TTA) is a technique aimed at enhancing thegeneralization performance of models by leveraging unlabeled samples solelyduring prediction. Given the need for robustness in neural network systems whenfaced with distribution shifts, numerous TTA methods have recently beenproposed. However, evaluating these methods is often done under differentsettings, such as varying distribution shifts, backbones, and designingscenarios, leading to a lack of consistent and fair benchmarks to validatetheir effectiveness. To address this issue, we present a benchmark thatsystematically evaluates 13 prominent TTA methods and their variants on fivewidely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C,DomainNet, and Office-Home. These methods encompass a wide range of adaptationscenarios (e.g. online adaptation v.s. offline adaptation, instance adaptationv.s. batch adaptation v.s. domain adaptation). Furthermore, we explore thecompatibility of different TTA methods with diverse network backbones. Toimplement this benchmark, we have developed a unified framework in PyTorch,which allows for consistent evaluation and comparison of the TTA methods acrossthe different datasets and network architectures. By establishing thisbenchmark, we aim to provide researchers and practitioners with a reliablemeans of assessing and comparing the effectiveness of TTA methods in improvingmodel robustness and generalization performance. Our code is available athttps://github.com/yuyongcan/Benchmark-TTA.</description><author>Yongcan Yu, Lijun Sheng, Ran He, Jian Liang</author><pubDate>Thu, 06 Jul 2023 17:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03133v1</guid></item><item><title>T-MARS: Improving Visual Representations by Circumventing Text Feature Learning</title><link>http://arxiv.org/abs/2307.03132v1</link><description>Large web-sourced multimodal datasets have powered a slew of new methods forlearning general-purpose visual representations, advancing the state of the artin computer vision and revolutionizing zero- and few-shot recognition. Onecrucial decision facing practitioners is how, if at all, to curate theseever-larger datasets. For example, the creators of the LAION-5B dataset choseto retain only image-caption pairs whose CLIP similarity score exceeded adesignated threshold. In this paper, we propose a new state-of-the-art datafiltering approach motivated by our observation that nearly 40% of LAION'simages contain text that overlaps significantly with the caption. Intuitively,such data could be wasteful as it incentivizes models to perform opticalcharacter recognition rather than learning visual features. However, naivelyremoving all such data could also be wasteful, as it throws away images thatcontain visual features (in addition to overlapping text). Our simple andscalable approach, T-MARS (Text Masking and Re-Scoring), filters out only thosepairs where the text dominates the remaining visual features -- by firstmasking out the text and then filtering out those with a low CLIP similarityscore of the masked image. Experimentally, T-MARS outperforms the top-rankedmethod on the "medium scale" of DataComp (a data filtering benchmark) by amargin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematicevaluation on various data pool sizes from 2M to 64M shows that the accuracygains enjoyed by T-MARS linearly increase as data and compute are scaledexponentially. Code is available at https://github.com/locuslab/T-MARS.</description><author>Pratyush Maini, Sachin Goyal, Zachary C. Lipton, J. Zico Kolter, Aditi Raghunathan</author><pubDate>Thu, 06 Jul 2023 17:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03132v1</guid></item><item><title>BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training</title><link>http://arxiv.org/abs/2307.03131v1</link><description>Automatic metrics play a crucial role in machine translation. Despite thewidespread use of n-gram-based metrics, there has been a recent surge in thedevelopment of pre-trained model-based metrics that focus on measuring sentencesemantics. However, these neural metrics, while achieving higher correlationswith human evaluations, are often considered to be black boxes with potentialbiases that are difficult to detect. In this study, we systematically analyzeand compare various mainstream and cutting-edge automatic metrics from theperspective of their guidance for training machine translation systems. ThroughMinimum Risk Training (MRT), we find that certain metrics exhibit robustnessdefects, such as the presence of universal adversarial translations in BLEURTand BARTScore. In-depth analysis suggests two main causes of these robustnessdeficits: distribution biases in the training datasets, and the tendency of themetric paradigm. By incorporating token-level constraints, we enhance therobustness of evaluation metrics, which in turn leads to an improvement in theperformance of machine translation systems. Codes are available at\url{https://github.com/powerpuffpomelo/fairseq_mrt}.</description><author>Yiming Yan, Tao Wang, Chengqi Zhao, Shujian Huang, Jiajun Chen, Mingxuan Wang</author><pubDate>Thu, 06 Jul 2023 17:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03131v1</guid></item><item><title>VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge Base Question Answering</title><link>http://arxiv.org/abs/2307.03130v1</link><description>We present Visual Knowledge oriented Programming platform (VisKoP), aknowledge base question answering (KBQA) system that integrates human into theloop to edit and debug the knowledge base (KB) queries. VisKoP not onlyprovides a neural program induction module, which converts natural languagequestions into knowledge oriented program language (KoPL), but also maps KoPLprograms into graphical elements. KoPL programs can be edited with simplegraphical operators, such as dragging to add knowledge operators and slotfilling to designate operator arguments. Moreover, VisKoP providesauto-completion for its knowledge base schema and users can easily debug theKoPL program by checking its intermediate results. To facilitate the practicalKBQA on a million-entity-level KB, we design a highly efficient KoPL executionengine for the back-end. Experiment results show that VisKoP is highlyefficient and user interaction can fix a large portion of wrong KoPL programsto acquire the correct answer. The VisKoP online demohttps://demoviskop.xlore.cn (Stable release of this paper) andhttps://viskop.xlore.cn (Beta release with new features), highly efficient KoPLengine https://pypi.org/project/kopl-engine, and screencast videohttps://youtu.be/zAbJtxFPTXo are now publicly available.</description><author>Zijun Yao, Yuanyong Chen, Xin Lv, Shulin Cao, Amy Xin, Jifan Yu, Hailong Jin, Jianjun Xu, Peng Zhang, Lei Hou, Juanzi Li</author><pubDate>Thu, 06 Jul 2023 17:58:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03130v1</guid></item><item><title>Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection</title><link>http://arxiv.org/abs/2306.04637v2</link><description>Neural sequence models based on the transformer architecture havedemonstrated remarkable \emph{in-context learning} (ICL) abilities, where theycan perform new tasks when prompted with training and test examples, withoutany parameter update to the model. This work first provides a comprehensivestatistical theory for transformers to perform ICL. Concretely, we show thattransformers can implement a broad class of standard machine learningalgorithms in context, such as least squares, ridge regression, Lasso, learninggeneralized linear models, and gradient descent on two-layer neural networks,with near-optimal predictive power on various in-context data distributions.Using an efficient implementation of in-context gradient descent as theunderlying mechanism, our transformer constructions admit mild size bounds, andcan be learned with polynomially many pretraining sequences. Building on these ``base'' ICL algorithms, intriguingly, we show thattransformers can implement more complex ICL procedures involving\emph{in-context algorithm selection}, akin to what a statistician can do inreal life -- A \emph{single} transformer can adaptively select different baseICL algorithms -- or even perform qualitatively different tasks -- on differentinput sequences, without any explicit prompting of the right algorithm or task.We both establish this in theory by explicit constructions, and also observethis phenomenon experimentally. In theory, we construct two general mechanismsfor algorithm selection with concrete examples: pre-ICL testing, and post-ICLvalidation. As an example, we use the post-ICL validation mechanism toconstruct a transformer that can perform nearly Bayes-optimal ICL on achallenging task -- noisy linear models with mixed noise levels.Experimentally, we demonstrate the strong in-context algorithm selectioncapabilities of standard transformer architectures.</description><author>Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei</author><pubDate>Thu, 06 Jul 2023 17:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04637v2</guid></item><item><title>Principal subbundles for dimension reduction</title><link>http://arxiv.org/abs/2307.03128v1</link><description>In this paper we demonstrate how sub-Riemannian geometry can be used formanifold learning and surface reconstruction by combining local linearapproximations of a point cloud to obtain lower dimensional bundles. Localapproximations obtained by local PCAs are collected into a rank $k$ tangentsubbundle on $\mathbb{R}^d$, $k&lt;d$, which we call a principal subbundle. Thisdetermines a sub-Riemannian metric on $\mathbb{R}^d$. We show thatsub-Riemannian geodesics with respect to this metric can successfully beapplied to a number of important problems, such as: explicit construction of anapproximating submanifold $M$, construction of a representation of thepoint-cloud in $\mathbb{R}^k$, and computation of distances betweenobservations, taking the learned geometry into account. The reconstruction isguaranteed to equal the true submanifold in the limit case where tangent spacesare estimated exactly. Via simulations, we show that the framework is robustwhen applied to noisy data. Furthermore, the framework generalizes toobservations on an a priori known Riemannian manifold.</description><author>Morten Akhøj, James Benn, Erlend Grong, Stefan Sommer, Xavier Pennec</author><pubDate>Thu, 06 Jul 2023 17:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03128v1</guid></item><item><title>Context-Aware Configuration and Management of WiFi Direct Groups for Real Opportunistic Networks</title><link>http://arxiv.org/abs/2307.03126v1</link><description>Wi-Fi Direct is a promising technology for the support of device-to-devicecommunications (D2D) on commercial mobile devices. However, the standardas-it-is is not sufficient to support the real deployment of networkingsolutions entirely based on D2D such as opportunistic networks. In fact, WiFiDirect presents some characteristics that could limit the autonomous creationof D2D connections among users' personal devices. Specifically, the standardexplicitly requires the user's authorization to establish a connection betweentwo or more devices, and it provides a limited support for inter-groupcommunication. In some cases, this might lead to the creation of isolatedgroups of nodes which cannot communicate among each other. In this paper, wepropose a novel middleware-layer protocol for the efficient configuration andmanagement of WiFi Direct groups (WiFi Direct Group Manager, WFD-GM) to enableautonomous connections and inter-group communication. This enablesopportunistic networks in real conditions (e.g., variable mobility and networksize). WFD-GM defines a context function that takes into account heterogeneousparameters for the creation of the best group configuration in a specific timewindow, including an index of nodes' stability and power levels. We evaluatethe protocol performances by simulating three reference scenarios includingdifferent mobility models, geographical areas and number of nodes. Simulationsare also supported by experimental results related to the evaluation in a realtestbed of the involved context parameters. We compare WFD-GM with thestate-of-the-art solutions and we show that it performs significantly betterthan a Baseline approach in scenarios with medium/low mobility, and it iscomparable with it in case of high mobility, without introducing additionaloverhead.</description><author>Valerio Arnaboldi, Mattia Giovanni Campana, Franca Delmastro</author><pubDate>Thu, 06 Jul 2023 17:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03126v1</guid></item><item><title>Convolutional Filtering and Neural Networks with Non Commutative Algebras</title><link>http://arxiv.org/abs/2108.09923v3</link><description>In this paper we introduce and study the algebraic generalization of noncommutative convolutional neural networks. We leverage the theory of algebraicsignal processing to model convolutional non commutative architectures, and wederive concrete stability bounds that extend those obtained in the literaturefor commutative convolutional neural networks. We show that non commutativeconvolutional architectures can be stable to deformations on the space ofoperators. We develop the spectral representation of non commutative signalmodels to show that non commutative filters process Fourier componentsindependently of each other. In particular we prove that although the spectraldecompositions of signals in non commutative models are associated toeigenspaces of dimension larger than one, there exists a trade-off betweenstability and selectivity, which is controlled by matrix polynomial functionsin spaces of matrices of low dimension. This tradeoff shows how when thefilters in the algebra are restricted to be stable, there is a loss indiscriminability that is compensated in the network by the pointwisenonlinearities. The results derived in this paper have direct applications andimplications in non commutative convolutional architectures such as groupneural networks, multigraph neural networks, and quaternion neural networks,for which we provide a set of numerical experiments showing their behavior whenperturbations are present.</description><author>Alejandro Parada-Mayorga, Landon Butler, Alejandro Ribeiro</author><pubDate>Thu, 06 Jul 2023 17:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.09923v3</guid></item><item><title>Extracting Multi-valued Relations from Language Models</title><link>http://arxiv.org/abs/2307.03122v1</link><description>The widespread usage of latent language representations via pre-trainedlanguage models (LMs) suggests that they are a promising source of structuredknowledge. However, existing methods focus only on a single object persubject-relation pair, even though often multiple objects are correct. Toovercome this limitation, we analyze these representations for their potentialto yield materialized multi-object relational knowledge. We formulate theproblem as a rank-then-select task. For ranking candidate objects, we evaluateexisting prompting techniques and propose new ones incorporating domainknowledge. Among the selection methods, we find that choosing objects with alikelihood above a learned relation-specific threshold gives a 49.5% F1 score.Our results highlight the difficulty of employing LMs for the multi-valuedslot-filling task and pave the way for further research on extractingrelational knowledge from latent language representations.</description><author>Sneha Singhania, Simon Razniewski, Gerhard Weikum</author><pubDate>Thu, 06 Jul 2023 17:48:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03122v1</guid></item><item><title>Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations</title><link>http://arxiv.org/abs/2206.04779v3</link><description>Offline reinforcement learning has shown great promise in leveraging largepre-collected datasets for policy learning, allowing agents to forgooften-expensive online data collection. However, offline reinforcement learningfrom visual observations with continuous action spaces remains under-explored,with a limited understanding of the key challenges in this complex domain. Inthis paper, we establish simple baselines for continuous control in the visualdomain and introduce a suite of benchmarking tasks for offline reinforcementlearning from visual observations designed to better represent the datadistributions present in real-world offline RL problems and guided by a set ofdesiderata for offline RL from visual observations, including robustness tovisual distractions and visually identifiable changes in dynamics. Using thissuite of benchmarking tasks, we show that simple modifications to two popularvision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2,suffice to outperform existing offline RL methods and establish competitivebaselines for continuous control in the visual domain. We rigorously evaluatethese algorithms and perform an empirical evaluation of the differences betweenstate-of-the-art model-based and model-free offline RL methods for continuouscontrol from visual observations. All code and data used in this evaluation areopen-sourced to facilitate progress in this domain.</description><author>Cong Lu, Philip J. Ball, Tim G. J. Rudner, Jack Parker-Holder, Michael A. Osborne, Yee Whye Teh</author><pubDate>Thu, 06 Jul 2023 17:46:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.04779v3</guid></item><item><title>Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance</title><link>http://arxiv.org/abs/2307.03119v1</link><description>Order execution is a fundamental task in quantitative finance, aiming atfinishing acquisition or liquidation for a number of trading orders of thespecific assets. Recent advance in model-free reinforcement learning (RL)provides a data-driven solution to the order execution problem. However, theexisting works always optimize execution for an individual order, overlookingthe practice that multiple orders are specified to execute simultaneously,resulting in suboptimality and bias. In this paper, we first present amulti-agent RL (MARL) method for multi-order execution considering practicalconstraints. Specifically, we treat every agent as an individual operator totrade one specific order, while keeping communicating with each other andcollaborating for maximizing the overall profits. Nevertheless, the existingMARL algorithms often incorporate communication among agents by exchanging onlythe information of their partial observations, which is inefficient incomplicated financial market. To improve collaboration, we then propose alearnable multi-round communication protocol, for the agents communicating theintended actions with each other and refining accordingly. It is optimizedthrough a novel action value attribution method which is provably consistentwith the original learning objective yet more efficient. The experiments on thedata from two real-world markets have illustrated superior performance withsignificantly better collaboration effectiveness achieved by our method.</description><author>Yuchen Fang, Zhenggang Tang, Kan Ren, Weiqing Liu, Li Zhao, Jiang Bian, Dongsheng Li, Weinan Zhang, Yong Yu, Tie-Yan Liu</author><pubDate>Thu, 06 Jul 2023 17:45:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03119v1</guid></item><item><title>Quantum Solutions to the Privacy vs. Utility Tradeoff</title><link>http://arxiv.org/abs/2307.03118v1</link><description>In this work, we propose a novel architecture (and several variants thereof)based on quantum cryptographic primitives with provable privacy and securityguarantees regarding membership inference attacks on generative models. Ourarchitecture can be used on top of any existing classical or quantum generativemodels. We argue that the use of quantum gates associated with unitaryoperators provides inherent advantages compared to standard DifferentialPrivacy based techniques for establishing guaranteed security from allpolynomial-time adversaries.</description><author>Sagnik Chatterjee, Vyacheslav Kungurtsev</author><pubDate>Thu, 06 Jul 2023 17:43:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03118v1</guid></item><item><title>KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text Understanding</title><link>http://arxiv.org/abs/2307.03115v1</link><description>Deep text understanding, which requires the connections between a givendocument and prior knowledge beyond its text, has been highlighted by manybenchmarks in recent years. However, these benchmarks have encountered twomajor limitations. On the one hand, most of them require human annotation ofknowledge, which leads to limited knowledge coverage. On the other hand, theyusually use choices or spans in the texts as the answers, which results innarrow answer space. To overcome these limitations, we build a new challengingbenchmark named KoRc in this paper. Compared with previous benchmarks, KoRC hastwo advantages, i.e., broad knowledge coverage and flexible answer format.Specifically, we utilize massive knowledge bases to guide annotators or largelanguage models (LLMs) to construct knowledgable questions. Moreover, we uselabels in knowledge bases rather than spans or choices as the final answers. Wetest state-of-the-art models on KoRC and the experimental results show that thestrongest baseline only achieves 68.3% and 30.0% F1 measure in thein-distribution and out-of-distribution test set, respectively. These resultsindicate that deep text understanding is still an unsolved challenge. Thebenchmark dataset, leaderboard, and baseline methods are released inhttps://github.com/THU-KEG/KoRC.</description><author>Zijun Yao, Yantao Liu, Xin Lv, Shulin Cao, Jifan Yu, Lei Hou, Juanzi Li</author><pubDate>Thu, 06 Jul 2023 17:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03115v1</guid></item><item><title>LISSNAS: Locality-based Iterative Search Space Shrinkage for Neural Architecture Search</title><link>http://arxiv.org/abs/2307.03110v1</link><description>Search spaces hallmark the advancement of Neural Architecture Search (NAS).Large and complex search spaces with versatile building operators andstructures provide more opportunities to brew promising architectures, yet posesevere challenges on efficient exploration and exploitation. Subsequently,several search space shrinkage methods optimize by selecting a singlesub-region that contains some well-performing networks. Small performance andefficiency gains are observed with these methods but such techniques leave roomfor significantly improved search performance and are ineffective at retainingarchitectural diversity. We propose LISSNAS, an automated algorithm thatshrinks a large space into a diverse, small search space with SOTA searchperformance. Our approach leverages locality, the relationship betweenstructural and performance similarity, to efficiently extract many pockets ofwell-performing networks. We showcase our method on an array of search spacesspanning various sizes and datasets. We accentuate the effectiveness of ourshrunk spaces when used in one-shot search by achieving the best Top-1 accuracyin two different search spaces. Our method achieves a SOTA Top-1 accuracy of77.6\% in ImageNet under mobile constraints, best-in-class Kendal-Tau,architectural diversity, and search space size.</description><author>Bhavna Gopal, Arjun Sridhar, Tunhou Zhang, Yiran Chen</author><pubDate>Thu, 06 Jul 2023 17:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03110v1</guid></item><item><title>A Survey on Evaluation of Large Language Models</title><link>http://arxiv.org/abs/2307.03109v1</link><description>Large language models (LLMs) are gaining increasing popularity in bothacademia and industry, owing to their unprecedented performance in variousapplications. As LLMs continue to play a vital role in both research and dailyuse, their evaluation becomes increasingly critical, not only at the tasklevel, but also at the society level for better understanding of theirpotential risks. Over the past years, significant efforts have been made toexamine LLMs from various perspectives. This paper presents a comprehensivereview of these evaluation methods for LLMs, focusing on three key dimensions:what to evaluate, where to evaluate, and how to evaluate. Firstly, we providean overview from the perspective of evaluation tasks, encompassing generalnatural language processing tasks, reasoning, medical usage, ethics,educations, natural and social sciences, agent applications, and other areas.Secondly, we answer the `where' and `how' questions by diving into theevaluation methods and benchmarks, which serve as crucial components inassessing performance of LLMs. Then, we summarize the success and failure casesof LLMs in different tasks. Finally, we shed light on several future challengesthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights toresearchers in the realm of LLMs evaluation, thereby aiding the development ofmore proficient LLMs. Our key point is that evaluation should be treated as anessential discipline to better assist the development of LLMs. We consistentlymaintain the related open-source materials at:https://github.com/MLGroupJLU/LLM-eval-survey.</description><author>Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, Xing Xie</author><pubDate>Thu, 06 Jul 2023 17:28:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03109v1</guid></item><item><title>How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models</title><link>http://arxiv.org/abs/2307.03108v1</link><description>Recent text-to-image diffusion models have shown surprising performance ingenerating high-quality images. However, concerns have arisen regarding theunauthorized usage of data during the training process. One example is when amodel trainer collects a set of images created by a particular artist andattempts to train a model capable of generating similar images withoutobtaining permission from the artist. To address this issue, it becomes crucialto detect unauthorized data usage. In this paper, we propose a method fordetecting such unauthorized data usage by planting injected memorization intothe text-to-image diffusion models trained on the protected dataset.Specifically, we modify the protected image dataset by adding unique contentson the images such as stealthy image wrapping functions that are imperceptibleto human vision but can be captured and memorized by diffusion models. Byanalyzing whether the model has memorization for the injected content (i.e.,whether the generated images are processed by the chosen post-processingfunction), we can detect models that had illegally utilized the unauthorizeddata. Our experiments conducted on Stable Diffusion and LoRA model demonstratethe effectiveness of the proposed method in detecting unauthorized data usages.</description><author>Zhenting Wang, Chen Chen, Yuchen Liu, Lingjuan Lyu, Dimitris Metaxas, Shiqing Ma</author><pubDate>Thu, 06 Jul 2023 17:27:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03108v1</guid></item><item><title>Efficient Domain Adaptation of Sentence Embeddings using Adapters</title><link>http://arxiv.org/abs/2307.03104v1</link><description>Sentence embeddings enable us to capture the semantic similarity of shorttexts. Most sentence embedding models are trained for general semantic textualsimilarity (STS) tasks. Therefore, to use sentence embeddings in a particulardomain, the model must be adapted to it in order to achieve good results.Usually, this is done by fine-tuning the entire sentence embedding model forthe domain of interest. While this approach yields state-of-the-art results,all of the model's weights are updated during fine-tuning, making this methodresource-intensive. Therefore, instead of fine-tuning entire sentence embeddingmodels for each target domain individually, we propose to train lightweightadapters. These domain-specific adapters do not require fine-tuning allunderlying sentence embedding model parameters. Instead, we only train a smallnumber of additional parameters while keeping the weights of the underlyingsentence embedding model fixed. Training domain-specific adapters allows alwaysusing the same base model and only exchanging the domain-specific adapters toadapt sentence embeddings to a specific domain. We show that using adapters forparameter-efficient domain adaptation of sentence embeddings yields competitiveperformance within 1% of a domain-adapted, entirely fine-tuned sentenceembedding model while only training approximately 3.6% of the parameters.</description><author>Tim Schopf, Dennis Schneider, Florian Matthes</author><pubDate>Thu, 06 Jul 2023 17:26:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03104v1</guid></item><item><title>Statistical-Computational Tradeoffs in Mixed Sparse Linear Regression</title><link>http://arxiv.org/abs/2303.02118v2</link><description>We consider the problem of mixed sparse linear regression with twocomponents, where two real $k$-sparse signals $\beta_1, \beta_2$ are to berecovered from $n$ unlabelled noisy linear measurements. The sparsity isallowed to be sublinear in the dimension, and additive noise is assumed to beindependent Gaussian with variance $\sigma^2$. Prior work has shown that theproblem suffers from a $\frac{k}{SNR^2}$-to-$\frac{k^2}{SNR^2}$statistical-to-computational gap, resembling other computationally challenginghigh-dimensional inference problems such as Sparse PCA and Robust Sparse MeanEstimation; here $SNR$ is the signal-to-noise ratio. We establish the existenceof a more extensive computational barrier for this problem through the methodof low-degree polynomials, but show that the problem is computationally hardonly in a very narrow symmetric parameter regime. We identify a smoothinformation-computation tradeoff between the sample complexity $n$ and runtimefor any randomized algorithm in this hard regime. Via a simple reduction, thisprovides novel rigorous evidence for the existence of a computational barrierto solving exact support recovery in sparse phase retrieval with samplecomplexity $n = \tilde{o}(k^2)$. Our second contribution is to analyze a simplethresholding algorithm which, outside of the narrow regime where the problem ishard, solves the associated mixed regression detection problem in $O(np)$ timewith square-root the number of samples and matches the sample complexityrequired for (non-mixed) sparse linear regression; this allows the recoveryproblem to be subsequently solved by state-of-the-art techniques from the densecase. As a special case of our results, we show that this simple algorithm isorder-optimal among a large family of algorithms in solving exact signedsupport recovery in sparse linear regression.</description><author>Gabriel Arpino, Ramji Venkataramanan</author><pubDate>Thu, 06 Jul 2023 17:21:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02118v2</guid></item><item><title>Contextual Affinity Distillation for Image Anomaly Detection</title><link>http://arxiv.org/abs/2307.03101v1</link><description>Previous works on unsupervised industrial anomaly detection mainly focus onlocal structural anomalies such as cracks and color contamination. Whileachieving significantly high detection performance on this kind of anomaly,they are faced with logical anomalies that violate the long-range dependenciessuch as a normal object placed in the wrong position. In this paper, based onprevious knowledge distillation works, we propose to use two students (localand global) to better mimic the teacher's behavior. The local student, which isused in previous studies mainly focuses on structural anomaly detection whilethe global student pays attention to logical anomalies. To further encouragethe global student's learning to capture long-range dependencies, we design theglobal context condensing block (GCCB) and propose a contextual affinity lossfor the student training and anomaly scoring. Experimental results show theproposed method doesn't need cumbersome training techniques and achieves a newstate-of-the-art performance on the MVTec LOCO AD dataset.</description><author>Jie Zhang, Masanori Suganuma, Takayuki Okatani</author><pubDate>Thu, 06 Jul 2023 17:18:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03101v1</guid></item><item><title>Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2210.12669v2</link><description>Physics-informed neural networks (PINNs) are emerging as popular mesh-freesolvers for partial differential equations (PDEs). Recent extensions decomposethe domain, apply different PINNs to solve the problem in each subdomain, andstitch the subdomains at the interface. Thereby, they can further alleviate theproblem complexity, reduce the computational cost, and allow parallelization.However, the performance of multi-domain PINNs is sensitive to the choice ofthe interface conditions. While quite a few conditions have been proposed,there is no suggestion about how to select the conditions according to specificproblems. To address this gap, we propose META Learning of Interface Conditions(METALIC), a simple, efficient yet powerful approach to dynamically determineappropriate interface conditions for solving a family of parametric PDEs.Specifically, we develop two contextual multi-arm bandit (MAB) models. Thefirst one applies to the entire training course, and online updates a Gaussianprocess (GP) reward that given the PDE parameters and interface conditionspredicts the performance. We prove a sub-linear regret bound for both UCB andThompson sampling, which in theory guarantees the effectiveness of our MAB. Thesecond one partitions the training into two stages, one is the stochastic phaseand the other deterministic phase; we update a GP reward for each phase toenable different condition selections at the two stages to further bolster theflexibility and performance. We have shown the advantage of METALIC on fourbench-mark PDE families.</description><author>Shibo Li, Michael Penwarden, Yiming Xu, Conor Tillinghast, Akil Narayan, Robert M. Kirby, Shandian Zhe</author><pubDate>Thu, 06 Jul 2023 17:13:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.12669v2</guid></item><item><title>Beyond Intuition, a Framework for Applying GPs to Real-World Data</title><link>http://arxiv.org/abs/2307.03093v1</link><description>Gaussian Processes (GPs) offer an attractive method for regression oversmall, structured and correlated datasets. However, their deployment ishindered by computational costs and limited guidelines on how to apply GPsbeyond simple low-dimensional datasets. We propose a framework to identify thesuitability of GPs to a given problem and how to set up a robust andwell-specified GP model. The guidelines formalise the decisions of experiencedGP practitioners, with an emphasis on kernel design and options forcomputational scalability. The framework is then applied to a case study ofglacier elevation change yielding more accurate results at test time.</description><author>Kenza Tazi, Jihao Andreas Lin, Ross Viljoen, Alex Gardner, Ti John, Hong Ge, Richard E. Turner</author><pubDate>Thu, 06 Jul 2023 17:08:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03093v1</guid></item><item><title>Learning Disentangled Representations in Signed Directed Graphs without Social Assumptions</title><link>http://arxiv.org/abs/2307.03077v1</link><description>Signed graphs are complex systems that represent trust relationships orpreferences in various domains. Learning node representations in such graphs iscrucial for many mining tasks. Although real-world signed relationships can beinfluenced by multiple latent factors, most existing methods often oversimplifythe modeling of signed relationships by relying on social theories and treatingthem as simplistic factors. This limits their expressiveness and their abilityto capture the diverse factors that shape these relationships. In this paper,we propose DINES, a novel method for learning disentangled node representationsin signed directed graphs without social assumptions. We adopt a disentangledframework that separates each embedding into distinct factors, allowing forcapturing multiple latent factors. We also explore lightweight graphconvolutions that focus solely on sign and direction, without depending onsocial theories. Additionally, we propose a decoder that effectively classifiesan edge's sign by considering correlations between the factors. To furtherenhance disentanglement, we jointly train a self-supervised factordiscriminator with our encoder and decoder. Throughout extensive experiments onreal-world signed directed graphs, we show that DINES effectively learnsdisentangled node representations, and significantly outperforms itscompetitors in the sign prediction task.</description><author>Geonwoo Ko, Jinhong Jung</author><pubDate>Thu, 06 Jul 2023 16:45:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03077v1</guid></item><item><title>Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning</title><link>http://arxiv.org/abs/2307.03073v1</link><description>We propose a novel framework for few-shot learning by leveraging large-scalevision-language models such as CLIP. Motivated by the unimodal prototypicalnetworks for few-shot learning, we introduce PROTO-CLIP that utilizes imageprototypes and text prototypes for few-shot learning. Specifically, PROTO-CLIPadapts the image encoder and text encoder in CLIP in a joint fashion usingfew-shot examples. The two encoders are used to compute prototypes of imageclasses for classification. During adaptation, we propose aligning the imageand text prototypes of corresponding classes. Such a proposed alignment isbeneficial for few-shot classification due to the contributions from both typesof prototypes. We demonstrate the effectiveness of our method by conductingexperiments on benchmark datasets for few-shot learning as well as in the realworld for robot perception.</description><author>Jishnu Jaykumar P, Kamalesh Palanisamy, Yu-Wei Chao, Xinya Du, Yu Xiang</author><pubDate>Thu, 06 Jul 2023 16:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03073v1</guid></item><item><title>Biomedical Language Models are Robust to Sub-optimal Tokenization</title><link>http://arxiv.org/abs/2306.17649v2</link><description>As opposed to general English, many concepts in biomedical terminology havebeen designed in recent history by biomedical professionals with the goal ofbeing precise and concise. This is often achieved by concatenating meaningfulbiomedical morphemes to create new semantic units. Nevertheless, most modernbiomedical language models (LMs) are pre-trained using standard domain-specifictokenizers derived from large scale biomedical corpus statistics withoutexplicitly leveraging the agglutinating nature of biomedical language. In thiswork, we first find that standard open-domain and biomedical tokenizers arelargely unable to segment biomedical terms into meaningful components.Therefore, we hypothesize that using a tokenizer which segments biomedicalterminology more accurately would enable biomedical LMs to improve theirperformance on downstream biomedical NLP tasks, especially ones which involvebiomedical terms directly such as named entity recognition (NER) and entitylinking. Surprisingly, we find that pre-training a biomedical LM using a moreaccurate biomedical tokenizer does not improve the entity representationquality of a language model as measured by several intrinsic and extrinsicmeasures such as masked language modeling prediction (MLM) accuracy as well asNER and entity linking performance. These quantitative findings, along with acase study which explores entity representation quality more directly, suggestthat the biomedical pre-training process is quite robust to instances ofsub-optimal tokenization.</description><author>Bernal Jiménez Gutiérrez, Huan Sun, Yu Su</author><pubDate>Thu, 06 Jul 2023 16:35:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17649v2</guid></item><item><title>A Hybrid End-to-End Spatio-Temporal Attention Neural Network with Graph-Smooth Signals for EEG Emotion Recognition</title><link>http://arxiv.org/abs/2307.03068v1</link><description>Recently, physiological data such as electroencephalography (EEG) signalshave attracted significant attention in affective computing. In this context,the main goal is to design an automated model that can assess emotional states.Lately, deep neural networks have shown promising performance in emotionrecognition tasks. However, designing a deep architecture that can extractpractical information from raw data is still a challenge. Here, we introduce adeep neural network that acquires interpretable physiological representationsby a hybrid structure of spatio-temporal encoding and recurrent attentionnetwork blocks. Furthermore, a preprocessing step is applied to the raw datausing graph signal processing tools to perform graph smoothing in the spatialdomain. We demonstrate that our proposed architecture exceeds state-of-the-artresults for emotion classification on the publicly available DEAP dataset. Toexplore the generality of the learned model, we also evaluate the performanceof our architecture towards transfer learning (TL) by transferring the modelparameters from a specific source to other target domains. Using DEAP as thesource dataset, we demonstrate the effectiveness of our model in performingcross-modality TL and improving emotion classification accuracy on DREAMER andthe Emotional English Word (EEWD) datasets, which involve EEG-based emotionclassification tasks with different stimuli.</description><author>Shadi Sartipi, Mastaneh Torkamani-Azar, Mujdat Cetin</author><pubDate>Thu, 06 Jul 2023 16:35:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03068v1</guid></item><item><title>DeepOnto: A Python Package for Ontology Engineering with Deep Learning</title><link>http://arxiv.org/abs/2307.03067v1</link><description>Applying deep learning techniques, particularly language models (LMs), inontology engineering has raised widespread attention. However, deep learningframeworks like PyTorch and Tensorflow are predominantly developed for Pythonprogramming, while widely-used ontology APIs, such as the OWL API and Jena, areprimarily Java-based. To facilitate seamless integration of these frameworksand APIs, we present Deeponto, a Python package designed for ontologyengineering. The package encompasses a core ontology processing module foundedon the widely-recognised and reliable OWL API, encapsulating its fundamentalfeatures in a more "Pythonic" manner and extending its capabilities to includeother essential components including reasoning, verbalisation, normalisation,projection, and more. Building on this module, Deeponto offers a suite oftools, resources, and algorithms that support various ontology engineeringtasks, such as ontology alignment and completion, by harnessing deep learningmethodologies, primarily pre-trained LMs. In this paper, we also demonstratethe practical utility of Deeponto through two use-cases: the Digital HealthCoaching in Samsung Research UK and the Bio-ML track of the Ontology AlignmentEvaluation Initiative (OAEI).</description><author>Yuan He, Jiaoyan Chen, Hang Dong, Ian Horrocks, Carlo Allocca, Taehun Kim, Brahmananda Sapkota</author><pubDate>Thu, 06 Jul 2023 16:35:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03067v1</guid></item><item><title>Capturing Emerging Complexity in Lenia</title><link>http://arxiv.org/abs/2305.09378v2</link><description>This research project investigates Lenia, an artificial life platform thatsimulates ecosystems of digital creatures. Lenia's ecosystem consists ofsimple, artificial organisms that can move, consume, grow, and reproduce. Theplatform is important as a tool for studying artificial life and evolution, asit provides a scalable and flexible environment for creating a diverse range oforganisms with varying abilities and behaviors. Measuring complexity in Leniais a key aspect of the study, which identifies the metrics for measuringlong-term complex emerging behavior of rules, with the aim of evolving betterLenia behaviors which are yet not discovered. The Genetic Algorithm usesneighborhoods or kernels as genotype while keeping the rest of the parametersof Lenia as fixed, for example growth function, to produce different behaviorsrespective to the population and then measures fitness value to decide thecomplexity of the resulting behavior. First, we use Variation over Time as afitness function where higher variance between the frames are rewarded. Second,we use Auto-encoder based fitness where variation of the list of reconstructionloss for the frames is rewarded. Third, we perform combined fitness wherehigher variation of the pixel density of reconstructed frames is rewarded. Allthree experiments are tweaked with pixel alive threshold and frames used.Finally, after performing nine experiments of each fitness for 500 generations,we pick configurations from all experiments such that there is a scope offurther evolution, and run it for 2500 generations. Results show that thekernel's center of mass increases with a specific set of pixels and togetherwith borders the kernel try to achieve a Gaussian distribution.</description><author>Sanyam Jain, Aarati Shrestha, Stefano Nichele</author><pubDate>Thu, 06 Jul 2023 16:28:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09378v2</guid></item><item><title>Generalizing Backpropagation for Gradient-Based Interpretability</title><link>http://arxiv.org/abs/2307.03056v1</link><description>Many popular feature-attribution methods for interpreting deep neuralnetworks rely on computing the gradients of a model's output with respect toits inputs. While these methods can indicate which input features may beimportant for the model's prediction, they reveal little about the innerworkings of the model itself. In this paper, we observe that the gradientcomputation of a model is a special case of a more general formulation usingsemirings. This observation allows us to generalize the backpropagationalgorithm to efficiently compute other interpretable statistics about thegradient graph of a neural network, such as the highest-weighted path andentropy. We implement this generalized algorithm, evaluate it on syntheticdatasets to better understand the statistics it computes, and apply it to studyBERT's behavior on the subject-verb number agreement task (SVA). With thismethod, we (a) validate that the amount of gradient flow through a component ofa model reflects its importance to a prediction and (b) for SVA, identify whichpathways of the self-attention mechanism are most important.</description><author>Kevin Du, Lucas Torroba Hennigen, Niklas Stoehr, Alexander Warstadt, Ryan Cotterell</author><pubDate>Thu, 06 Jul 2023 16:19:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03056v1</guid></item><item><title>Oriented Object Detection in Optical Remote Sensing Images using Deep Learning: A Survey</title><link>http://arxiv.org/abs/2302.10473v2</link><description>Oriented object detection is one of the most fundamental and challengingtasks in remote sensing, aiming at locating the oriented objects of numerouspredefined object categories. Recently, deep learning based methods haveachieved remarkable performance in detecting oriented objects in optical remotesensing imagery. However, a thorough review of the literature in remote sensinghas not yet emerged. Therefore, we give a comprehensive survey of recentadvances and cover many aspects of oriented object detection, including problemdefinition, commonly used datasets, evaluation protocols, detection frameworks,oriented object representations, and feature representations. Besides, thestate-of-the-art methods are analyzed and discussed. We finally discuss futureresearch directions to put forward some useful research guidance. We believethat this survey shall be valuable to researchers across academia and industry</description><author>Kun Wang, Zi Wang, Zhang Lia, Ang Sua, Xichao Tenga, Minhao Liua, Qifeng Yua</author><pubDate>Thu, 06 Jul 2023 16:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10473v2</guid></item><item><title>Origin-Destination Travel Time Oracle for Map-based Services</title><link>http://arxiv.org/abs/2307.03048v1</link><description>Given an origin (O), a destination (D), and a departure time (T), anOrigin-Destination (OD) travel time oracle~(ODT-Oracle) returns an estimate ofthe time it takes to travel from O to D when departing at T. ODT-Oracles serveimportant purposes in map-based services. To enable the construction of suchoracles, we provide a travel-time estimation (TTE) solution that leverageshistorical trajectories to estimate time-varying travel times for OD pairs. The problem is complicated by the fact that multiple historical trajectorieswith different travel times may connect an OD pair, while trajectories may varyfrom one another. To solve the problem, it is crucial to remove outliertrajectories when doing travel time estimation for future queries. We propose a novel, two-stage framework called Diffusion-basedOrigin-destination Travel Time Estimation (DOT), that solves the problem.First, DOT employs a conditioned Pixelated Trajectories (PiT) denoiser thatenables building a diffusion-based PiT inference process by learningcorrelations between OD pairs and historical trajectories. Specifically, givenan OD pair and a departure time, we aim to infer a PiT. Next, DOT encompasses aMasked Vision Transformer~(MViT) that effectively and efficiently estimates atravel time based on the inferred PiT. We report on extensive experiments ontwo real-world datasets that offer evidence that DOT is capable ofoutperforming baseline methods in terms of accuracy, scalability, andexplainability.</description><author>Yan Lin, Huaiyu Wan, Jilin Hu, Shengnan Guo, Bin Yang, Youfang Lin, Christian S. Jensen</author><pubDate>Thu, 06 Jul 2023 16:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03048v1</guid></item><item><title>Track Mix Generation on Music Streaming Services using Transformers</title><link>http://arxiv.org/abs/2307.03045v1</link><description>This paper introduces Track Mix, a personalized playlist generation systemreleased in 2022 on the music streaming service Deezer. Track Mix automaticallygenerates "mix" playlists inspired by initial music tracks, allowing users todiscover music similar to their favorite content. To generate these mixes, weconsider a Transformer model trained on millions of track sequences from userplaylists. In light of the growing popularity of Transformers in recent years,we analyze the advantages, drawbacks, and technical challenges of using such amodel for mix generation on the service, compared to a more traditionalcollaborative filtering approach. Since its release, Track Mix has beengenerating playlists for millions of users daily, enhancing their musicdiscovery experience on Deezer.</description><author>Walid Bendada, Théo Bontempelli, Mathieu Morlon, Benjamin Chapus, Thibault Cador, Thomas Bouabça, Guillaume Salha-Galvan</author><pubDate>Thu, 06 Jul 2023 16:10:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03045v1</guid></item><item><title>A Near-Linear Time Algorithm for the Chamfer Distance</title><link>http://arxiv.org/abs/2307.03043v1</link><description>For any two point sets $A,B \subset \mathbb{R}^d$ of size up to $n$, theChamfer distance from $A$ to $B$ is defined as $\text{CH}(A,B)=\sum_{a \in A}\min_{b \in B} d_X(a,b)$, where $d_X$ is the underlying distance measure (e.g.,the Euclidean or Manhattan distance). The Chamfer distance is a popular measureof dissimilarity between point clouds, used in many machine learning, computervision, and graphics applications, and admits a straightforward $O(d n^2)$-timebrute force algorithm. Further, the Chamfer distance is often used as a proxyfor the more computationally demanding Earth-Mover (Optimal Transport)Distance. However, the \emph{quadratic} dependence on $n$ in the running timemakes the naive approach intractable for large datasets. We overcome this bottleneck and present the first $(1+\epsilon)$-approximatealgorithm for estimating the Chamfer distance with a near-linear running time.Specifically, our algorithm runs in time $O(nd \log (n)/\varepsilon^2)$ and isimplementable. Our experiments demonstrate that it is both accurate and fast onlarge high-dimensional datasets. We believe that our algorithm will open newavenues for analyzing large high-dimensional point clouds. We also giveevidence that if the goal is to \emph{report} a $(1+\varepsilon)$-approximatemapping from $A$ to $B$ (as opposed to just its value), then any sub-quadratictime algorithm is unlikely to exist.</description><author>Ainesh Bakshi, Piotr Indyk, Rajesh Jayaram, Sandeep Silwal, Erik Waingarten</author><pubDate>Thu, 06 Jul 2023 16:07:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03043v1</guid></item><item><title>Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain</title><link>http://arxiv.org/abs/2307.03042v1</link><description>Adapting pretrained language models to novel domains, such as clinicalapplications, traditionally involves retraining their entire set of parameters.However, this approach is increasingly proven to be impractical owing to thesubstantial computational requirements associated with training such largelanguage models. To address this issue, Parameter-Efficient Fine-Tuning (PEFT)techniques offer a viable solution by selectively fine-tuning a small subset ofadditional parameters, significantly reducing the computational requirementsfor domain adaptation. In this study, we propose Clinical LLaMA-LoRA, a PEFTadapter layer built upon the open-sourced LLaMA model. Clinical LLaMA-LoRA istrained using clinical notes obtained from the MIMIC-IV database, therebycreating a specialised adapter designed for the clinical domain. Additionally,we propose a two-step PEFT framework which fuses Clinical LLaMA-LoRA withDownstream LLaMA-LoRA, another PEFT adapter specialised for downstream tasks.We evaluate this framework on multiple clinical outcome prediction datasets,comparing it to clinically trained language models. Our proposed frameworkachieves a state-of-the-art AUROC score averaged across all clinical downstreamtasks. We observe substantial improvements of 6-9% AUROC score in thelarge-scale multilabel classification tasks, such as diagnoses and proceduresclassification.</description><author>Aryo Gema, Luke Daines, Pasquale Minervini, Beatrice Alex</author><pubDate>Thu, 06 Jul 2023 16:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03042v1</guid></item><item><title>Art Authentication with Vision Transformers</title><link>http://arxiv.org/abs/2307.03039v1</link><description>In recent years, Transformers, initially developed for language, have beensuccessfully applied to visual tasks. Vision Transformers have been shown topush the state-of-the-art in a wide range of tasks, including imageclassification, object detection, and semantic segmentation. While ampleresearch has shown promising results in art attribution and art authenticationtasks using Convolutional Neural Networks, this paper examines if thesuperiority of Vision Transformers extends to art authentication, improving,thus, the reliability of computer-based authentication of artworks. Using acarefully compiled dataset of authentic paintings by Vincent van Gogh and twocontrast datasets, we compare the art authentication performances of SwinTransformers with those of EfficientNet. Using a standard contrast setcontaining imitations and proxies (works by painters with styles closelyrelated to van Gogh), we find that EfficientNet achieves the best performanceoverall. With a contrast set that only consists of imitations, we find the SwinTransformer to be superior to EfficientNet by achieving an authenticationaccuracy of over 85%. These results lead us to conclude that VisionTransformers represent a strong and promising contender in art authentication,particularly in enhancing the computer-based ability to detect artisticimitations.</description><author>Ludovica Schaerf, Carina Popovici, Eric Postma</author><pubDate>Thu, 06 Jul 2023 16:04:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03039v1</guid></item><item><title>Duality in Multi-View Restricted Kernel Machines</title><link>http://arxiv.org/abs/2305.17251v2</link><description>We propose a unifying setting that combines existing restricted kernelmachine methods into a single primal-dual multi-view framework for kernelprincipal component analysis in both supervised and unsupervised settings. Wederive the primal and dual representations of the framework and relatedifferent training and inference algorithms from a theoretical perspective. Weshow how to achieve full equivalence in primal and dual formulations byrescaling primal variables. Finally, we experimentally validate the equivalenceand provide insight into the relationships between different methods on anumber of time series data sets by recursively forecasting unseen test data andvisualizing the learned features.</description><author>Sonny Achten, Arun Pandey, Hannes De Meulemeester, Bart De Moor, Johan A. K. Suykens</author><pubDate>Thu, 06 Jul 2023 15:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17251v2</guid></item><item><title>PCL-Indexability and Whittle Index for Restless Bandits with General Observation Models</title><link>http://arxiv.org/abs/2307.03034v1</link><description>In this paper, we consider a general observation model for restlessmulti-armed bandit problems. The operation of the player needs to be based oncertain feedback mechanism that is error-prone due to resource constraints orenvironmental or intrinsic noises. By establishing a general probabilisticmodel for dynamics of feedback/observation, we formulate the problem as arestless bandit with a countable belief state space starting from an arbitraryinitial belief (a priori information). We apply the achievable region methodwith partial conservation law (PCL) to the infinite-state problem and analyzeits indexability and priority index (Whittle index). Finally, we propose anapproximation process to transform the problem into which the AG algorithm ofNi\~no-Mora and Bertsimas for finite-state problems can be applied to.Numerical experiments show that our algorithm has an excellent performance.</description><author>Keqin Liu, Chengzhong Zhang</author><pubDate>Thu, 06 Jul 2023 15:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03034v1</guid></item><item><title>The Impact of ChatGPT and LLMs on Medical Imaging Stakeholders: Perspectives and Use Cases</title><link>http://arxiv.org/abs/2306.06767v2</link><description>This study investigates the transformative potential of Large Language Models(LLMs), such as OpenAI ChatGPT, in medical imaging. With the aid of publicdata, these models, which possess remarkable language understanding andgeneration capabilities, are augmenting the interpretive skills ofradiologists, enhancing patient-physician communication, and streamliningclinical workflows. The paper introduces an analytic framework for presentingthe complex interactions between LLMs and the broader ecosystem of medicalimaging stakeholders, including businesses, insurance entities, governments,research institutions, and hospitals (nicknamed BIGR-H). Through detailedanalyses, illustrative use cases, and discussions on the broader implicationsand future directions, this perspective seeks to raise discussion in strategicplanning and decision-making in the era of AI-enabled healthcare.</description><author>Jiancheng Yang, Hongwei Bran Li, Donglai Wei</author><pubDate>Thu, 06 Jul 2023 15:54:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06767v2</guid></item><item><title>UTRNet: High-Resolution Urdu Text Recognition In Printed Documents</title><link>http://arxiv.org/abs/2306.15782v2</link><description>In this paper, we propose a novel approach to address the challenges ofprinted Urdu text recognition using high-resolution, multi-scale semanticfeature extraction. Our proposed UTRNet architecture, a hybrid CNN-RNN model,demonstrates state-of-the-art performance on benchmark datasets. To address thelimitations of previous works, which struggle to generalize to the intricaciesof the Urdu script and the lack of sufficient annotated real-world data, wehave introduced the UTRSet-Real, a large-scale annotated real-world datasetcomprising over 11,000 lines and UTRSet-Synth, a synthetic dataset with 20,000lines closely resembling real-world and made corrections to the ground truth ofthe existing IIITH dataset, making it a more reliable resource for futureresearch. We also provide UrduDoc, a benchmark dataset for Urdu text linedetection in scanned documents. Additionally, we have developed an online toolfor end-to-end Urdu OCR from printed documents by integrating UTRNet with atext detection model. Our work not only addresses the current limitations ofUrdu OCR but also paves the way for future research in this area andfacilitates the continued advancement of Urdu OCR technology. The project pagewith source code, datasets, annotations, trained models, and online tool isavailable at abdur75648.github.io/UTRNet.</description><author>Abdur Rahman, Arjun Ghosh, Chetan Arora</author><pubDate>Thu, 06 Jul 2023 15:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15782v2</guid></item><item><title>Improving Retrieval-Augmented Large Language Models via Data Importance Learning</title><link>http://arxiv.org/abs/2307.03027v1</link><description>Retrieval augmentation enables large language models to take advantage ofexternal knowledge, for example on tasks like question answering and dataimputation. However, the performance of such retrieval-augmented models islimited by the data quality of their underlying retrieval corpus. In thispaper, we propose an algorithm based on multilinear extension for evaluatingthe data importance of retrieved data points. There are exponentially manyterms in the multilinear extension, and one key contribution of this paper is apolynomial time algorithm that computes exactly, given a retrieval-augmentedmodel with an additive utility function and a validation set, the dataimportance of data points in the retrieval corpus using the multilinearextension of the model's utility function. We further proposed an even moreefficient ({\epsilon}, {\delta})-approximation algorithm. Our experimentalresults illustrate that we can enhance the performance of large language modelsby only pruning or reweighting the retrieval corpus, without requiring furthertraining. For some tasks, this even allows a small model (e.g., GPT-JT),augmented with a search engine API, to outperform GPT-3.5 (without retrievalaugmentation). Moreover, we show that weights based on multilinear extensioncan be computed efficiently in practice (e.g., in less than ten minutes for acorpus with 100 million elements).</description><author>Xiaozhong Lyu, Stefan Grafberger, Samantha Biegel, Shaopeng Wei, Meng Cao, Sebastian Schelter, Ce Zhang</author><pubDate>Thu, 06 Jul 2023 15:44:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03027v1</guid></item><item><title>Normal Transformer: Extracting Surface Geometry from LiDAR Points Enhanced by Visual Semantics</title><link>http://arxiv.org/abs/2211.10580v2</link><description>High-quality estimation of surface normal can help reduce ambiguity in manygeometry understanding problems, such as collision avoidance and occlusioninference. This paper presents a technique for estimating the normal from 3Dpoint clouds and 2D colour images. We have developed a transformer neuralnetwork that learns to utilise the hybrid information of visual semantic and 3Dgeometric data, as well as effective learning strategies. Compared to existingmethods, the information fusion of the proposed method is more effective, whichis supported by experiments. We have also built a simulation environment ofoutdoor traffic scenes in a 3D rendering engine to obtain annotated data totrain the normal estimator. The model trained on synthetic data is tested onthe real scenes in the KITTI dataset. And subsequent tasks built upon theestimated normal directions in the KITTI dataset show that the proposedestimator has advantage over existing methods.</description><author>Ancheng Lin, Jun Li</author><pubDate>Thu, 06 Jul 2023 15:43:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.10580v2</guid></item><item><title>Style Over Substance: Evaluation Biases for Large Language Models</title><link>http://arxiv.org/abs/2307.03025v1</link><description>As large language models (LLMs) continue to advance, accurately andcomprehensively evaluating their performance becomes increasingly challenging.Conventionally, human evaluations are considered the gold standard in naturallanguage generation. Recent advancements incorporate state-of-the-art LLMs asproxies for human judges in evaluation processes. Nonetheless, the extent towhich humans and LLMs are capable evaluators remains uncertain. This study aimsto investigate the behavior of both crowd-sourced human and LLM-based judgeswhen comparing outputs from different models. To accomplish this, we curate adataset comprising intentionally flawed machine-generated answers. Our findingsindicate that despite the potentially greater danger posed by factual errors,answers with factual errors were still rated more favorably compared to answersthat were too short or contained grammatical errors. This highlights aconcerning bias in the evaluation process. To address this issue, we propose toindependently evaluate machine-generated text across multiple dimensions,rather than merging all the evaluation aspects into a single score. Weinstantiate this idea with the Elo rating system, resulting in the Multi-EloRating System. Empirical results from our study reveal that this proposedapproach significantly enhances the quality of LLM-based evaluations,particularly in terms of factual accuracy. However, notable improvement is notobserved in crowd-sourced-based evaluations, suggesting the need for furtherinvestigation and refinement.</description><author>Minghao Wu, Alham Fikri Aji</author><pubDate>Thu, 06 Jul 2023 15:42:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03025v1</guid></item><item><title>EffLiFe: Efficient Light Field Generation via Hierarchical Sparse Gradient Descent</title><link>http://arxiv.org/abs/2307.03017v1</link><description>With the rise of Extended Reality (XR) technology, there is a growing needfor real-time light field generation from sparse view inputs. Existing methodscan be classified into offline techniques, which can generate high-qualitynovel views but at the cost of long inference/training time, and onlinemethods, which either lack generalizability or produce unsatisfactory results.However, we have observed that the intrinsic sparse manifold of Multi-planeImages (MPI) enables a significant acceleration of light field generation whilemaintaining rendering quality. Based on this insight, we introduce EffLiFe, anovel light field optimization method, which leverages the proposedHierarchical Sparse Gradient Descent (HSGD) to produce high-quality lightfields from sparse view images in real time. Technically, the coarse MPI of ascene is first generated using a 3D CNN, and it is further sparsely optimizedby focusing only on important MPI gradients in a few iterations. Nevertheless,relying solely on optimization can lead to artifacts at occlusion boundaries.Therefore, we propose an occlusion-aware iterative refinement module thatremoves visual artifacts in occluded regions by iteratively filtering theinput. Extensive experiments demonstrate that our method achieves comparablevisual quality while being 100x faster on average than state-of-the-art offlinemethods and delivering better performance (about 2 dB higher in PSNR) comparedto other online approaches.</description><author>Yijie Deng, Lei Han, Tianpeng Lin, Lin Li, Jinzhi Zhang, Lu Fang</author><pubDate>Thu, 06 Jul 2023 15:31:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03017v1</guid></item><item><title>Sequential Neural Barriers for Scalable Dynamic Obstacle Avoidance</title><link>http://arxiv.org/abs/2307.03015v1</link><description>There are two major challenges for scaling up robot navigation around dynamicobstacles: the complex interaction dynamics of the obstacles can be hard tomodel analytically, and the complexity of planning and control growsexponentially in the number of obstacles. Data-driven and learning-basedmethods are thus particularly valuable in this context. However, data-drivenmethods are sensitive to distribution drift, making it hard to train andgeneralize learned models across different obstacle densities. We propose anovel method for compositional learning of Sequential Neural Control Barriermodels (SNCBFs) to achieve scalability. Our approach exploits an importantobservation: the spatial interaction patterns of multiple dynamic obstacles canbe decomposed and predicted through temporal sequences of states for eachobstacle. Through decomposition, we can generalize control policies trainedonly with a small number of obstacles, to environments where the obstacledensity can be 100x higher. We demonstrate the benefits of the proposed methodsin improving dynamic collision avoidance in comparison with existing methodsincluding potential fields, end-to-end reinforcement learning, andmodel-predictive control. We also perform hardware experiments and show thepractical effectiveness of the approach in the supplementary video.</description><author>Hongzhan Yu, Chiaki Hirayama, Chenning Yu, Sylvia Herbert, Sicun Gao</author><pubDate>Thu, 06 Jul 2023 15:24:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03015v1</guid></item><item><title>Self-supervised learning via inter-modal reconstruction and feature projection networks for label-efficient 3D-to-2D segmentation</title><link>http://arxiv.org/abs/2307.03008v1</link><description>Deep learning has become a valuable tool for the automation of certainmedical image segmentation tasks, significantly relieving the workload ofmedical specialists. Some of these tasks require segmentation to be performedon a subset of the input dimensions, the most common case being 3D-to-2D.However, the performance of existing methods is strongly conditioned by theamount of labeled data available, as there is currently no data efficientmethod, e.g. transfer learning, that has been validated on these tasks. In thiswork, we propose a novel convolutional neural network (CNN) and self-supervisedlearning (SSL) method for label-efficient 3D-to-2D segmentation. The CNN iscomposed of a 3D encoder and a 2D decoder connected by novel 3D-to-2D blocks.The SSL method consists of reconstructing image pairs of modalities withdifferent dimensionality. The approach has been validated in two tasks withclinical relevance: the en-face segmentation of geographic atrophy andreticular pseudodrusen in optical coherence tomography. Results on differentdatasets demonstrate that the proposed CNN significantly improves the state ofthe art in scenarios with limited labeled data by up to 8% in Dice score.Moreover, the proposed SSL method allows further improvement of thisperformance by up to 23%, and we show that the SSL is beneficial regardless ofthe network architecture.</description><author>José Morano, Guilherme Aresta, Dmitrii Lachinov, Julia Mai, Ursula Schmidt-Erfurth, Hrvoje Bogunović</author><pubDate>Thu, 06 Jul 2023 15:16:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03008v1</guid></item><item><title>Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching</title><link>http://arxiv.org/abs/2205.03447v7</link><description>Ontology Matching (OM) plays an important role in many domains such asbioinformatics and the Semantic Web, and its research is becoming increasinglypopular, especially with the application of machine learning (ML) techniques.Although the Ontology Alignment Evaluation Initiative (OAEI) represents animpressive effort for the systematic evaluation of OM systems, it still suffersfrom several limitations including limited evaluation of subsumption mappings,suboptimal reference mappings, and limited support for the evaluation ofML-based systems. To tackle these limitations, we introduce five new biomedicalOM tasks involving ontologies extracted from Mondo and UMLS. Each task includesboth equivalence and subsumption matching; the quality of reference mappings isensured by human curation, ontology pruning, etc.; and a comprehensiveevaluation framework is proposed to measure OM performance from variousperspectives for both ML-based and non-ML-based OM systems. We reportevaluation results for OM systems of different types to demonstrate the usageof these resources, all of which are publicly available as part of the newBioML track at OAEI 2022.</description><author>Yuan He, Jiaoyan Chen, Hang Dong, Ernesto Jiménez-Ruiz, Ali Hadian, Ian Horrocks</author><pubDate>Thu, 06 Jul 2023 15:14:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.03447v7</guid></item><item><title>Dual Arbitrary Scale Super-Resolution for Multi-Contrast MRI</title><link>http://arxiv.org/abs/2307.02334v2</link><description>Limited by imaging systems, the reconstruction of Magnetic Resonance Imaging(MRI) images from partial measurement is essential to medical imaging research.Benefiting from the diverse and complementary information of multi-contrast MRimages in different imaging modalities, multi-contrast Super-Resolution (SR)reconstruction is promising to yield SR images with higher quality. In themedical scenario, to fully visualize the lesion, radiologists are accustomed tozooming the MR images at arbitrary scales rather than using a fixed scale, asused by most MRI SR methods. In addition, existing multi-contrast MRI SRmethods often require a fixed resolution for the reference image, which makesacquiring reference images difficult and imposes limitations on arbitrary scaleSR tasks. To address these issues, we proposed an implicit neuralrepresentations based dual-arbitrary multi-contrast MRI super-resolutionmethod, called Dual-ArbNet. First, we decouple the resolution of the target andreference images by a feature encoder, enabling the network to input target andreference images at arbitrary scales. Then, an implicit fusion decoder fusesthe multi-contrast features and uses an Implicit Decoding Function~(IDF) toobtain the final MRI SR results. Furthermore, we introduce a curriculumlearning strategy to train our network, which improves the generalization andperformance of our Dual-ArbNet. Extensive experiments in two public MRIdatasets demonstrate that our method outperforms state-of-the-art approachesunder different scale factors and has great potential in clinical practice.</description><author>Jiamiao Zhang, Yichen Chi, Jun Lyu, Wenming Yang, Yapeng Tian</author><pubDate>Thu, 06 Jul 2023 15:14:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02334v2</guid></item><item><title>Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning</title><link>http://arxiv.org/abs/2307.03007v1</link><description>Manual assembly workers face increasing complexity in their work.Human-centered assistance systems could help, but object recognition as anenabling technology hinders sophisticated human-centered design of thesesystems. At the same time, activity recognition based on hand poses suffersfrom poor pose estimation in complex usage scenarios, such as wearing gloves.This paper presents a self-supervised pipeline for adapting hand poseestimation to specific use cases with minimal human interaction. This enablescheap and robust hand posebased activity recognition. The pipeline consists ofa general machine learning model for hand pose estimation trained on ageneralized dataset, spatial and temporal filtering to account for anatomicalconstraints of the hand, and a retraining step to improve the model. Differentparameter combinations are evaluated on a publicly available and annotateddataset. The best parameter and model combination is then applied to unlabelledvideos from a manual assembly scenario. The effectiveness of the pipeline isdemonstrated by training an activity recognition as a downstream task in themanual assembly scenario.</description><author>Christian Jauch, Timo Leitritz, Marco F. Huber</author><pubDate>Thu, 06 Jul 2023 15:13:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03007v1</guid></item><item><title>A Simple and Effective Baseline for Attentional Generative Adversarial Networks</title><link>http://arxiv.org/abs/2306.14708v2</link><description>Synthesising a text-to-image model of high-quality images by guiding thegenerative model through the Text description is an innovative and challengingtask. In recent years, AttnGAN based on the Attention mechanism to guide GANtraining has been proposed, SD-GAN, which adopts a self-distillation techniqueto improve the performance of the generator and the quality of imagegeneration, and Stack-GAN++, which gradually improves the details and qualityof the image by stacking multiple generators and discriminators. However, thisseries of improvements to GAN all have redundancy to a certain extent, whichaffects the generation performance and complexity to a certain extent. We usethe popular simple and effective idea (1) to remove redundancy structure andimprove the backbone network of AttnGAN. (2) to integrate and reconstructmultiple losses of DAMSM. Our improvements have significantly improved themodel size and training efficiency while ensuring that the model's performanceis unchanged and finally proposed our SEAttnGAN. Code is avalilable athttps://github.com/jmyissb/SEAttnGAN.</description><author>Mingyu Jin, Chong Zhang, Qinkai Yu, Haochen Xue, Xiaobo Jin, Xi Yang</author><pubDate>Thu, 06 Jul 2023 15:07:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14708v2</guid></item><item><title>Improving the Efficiency of Human-in-the-Loop Systems: Adding Artificial to Human Experts</title><link>http://arxiv.org/abs/2307.03003v1</link><description>Information systems increasingly leverage artificial intelligence (AI) andmachine learning (ML) to generate value from vast amounts of data. However, MLmodels are imperfect and can generate incorrect classifications. Hence,human-in-the-loop (HITL) extensions to ML models add a human review forinstances that are difficult to classify. This study argues that continuouslyrelying on human experts to handle difficult model classifications leads to astrong increase in human effort, which strains limited resources. To addressthis issue, we propose a hybrid system that creates artificial experts thatlearn to classify data instances from unknown classes previously reviewed byhuman experts. Our hybrid system assesses which artificial expert is suitablefor classifying an instance from an unknown class and automatically assigns it.Over time, this reduces human effort and increases the efficiency of thesystem. Our experiments demonstrate that our approach outperforms traditionalHITL systems for several benchmarks on image classification.</description><author>Johannes Jakubik, Daniel Weber, Patrick Hemmer, Michael Vössing, Gerhard Satzger</author><pubDate>Thu, 06 Jul 2023 15:06:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03003v1</guid></item><item><title>Fourier-Net+: Leveraging Band-Limited Representation for Efficient 3D Medical Image Registration</title><link>http://arxiv.org/abs/2307.02997v1</link><description>U-Net style networks are commonly utilized in unsupervised image registrationto predict dense displacement fields, which for high-resolution volumetricimage data is a resource-intensive and time-consuming task. To tackle thischallenge, we first propose Fourier-Net, which replaces the costly U-Net styleexpansive path with a parameter-free model-driven decoder. Instead of directlypredicting a full-resolution displacement field, our Fourier-Net learns alow-dimensional representation of the displacement field in the band-limitedFourier domain which our model-driven decoder converts to a full-resolutiondisplacement field in the spatial domain. Expanding upon Fourier-Net, we thenintroduce Fourier-Net+, which additionally takes the band-limited spatialrepresentation of the images as input and further reduces the number ofconvolutional layers in the U-Net style network's contracting path. Finally, toenhance the registration performance, we propose a cascaded version ofFourier-Net+. We evaluate our proposed methods on three datasets, on which ourproposed Fourier-Net and its variants achieve comparable results with currentstate-of-the art methods, while exhibiting faster inference speeds, lowermemory footprint, and fewer multiply-add operations. With such smallcomputational cost, our Fourier-Net+ enables the efficient training oflarge-scale 3D registration on low-VRAM GPUs. Our code is publicly available at\url{https://github.com/xi-jia/Fourier-Net}.</description><author>Xi Jia, Alexander Thorley, Alberto Gomez, Wenqi Lu, Dipak Kotecha, Jinming Duan</author><pubDate>Thu, 06 Jul 2023 14:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02997v1</guid></item><item><title>Co-design Hardware and Algorithm for Vector Search</title><link>http://arxiv.org/abs/2306.11182v3</link><description>Vector search has emerged as the foundation for large-scale informationretrieval and machine learning systems, with search engines like Google andBing processing tens of thousands of queries per second on petabyte-scaledocument datasets by evaluating vector similarities between encoded query textsand web documents. As performance demands for vector search systems surge,accelerated hardware offers a promising solution in the post-Moore's Law era.We introduce \textit{FANNS}, an end-to-end and scalable vector search frameworkon FPGAs. Given a user-provided recall requirement on a dataset and a hardwareresource budget, \textit{FANNS} automatically co-designs hardware andalgorithm, subsequently generating the corresponding accelerator. The frameworkalso supports scale-out by incorporating a hardware TCP/IP stack in theaccelerator. \textit{FANNS} attains up to 23.0$\times$ and 37.2$\times$ speedupcompared to FPGA and CPU baselines, respectively, and demonstrates superiorscalability to GPUs, achieving 5.5$\times$ and 7.6$\times$ speedup in medianand 95\textsuperscript{th} percentile (P95) latency within an eight-acceleratorconfiguration. The remarkable performance of \textit{FANNS} lays a robustgroundwork for future FPGA integration in data centers and AI supercomputers.</description><author>Wenqi Jiang, Shigang Li, Yu Zhu, Johannes de Fine Licht, Zhenhao He, Runbin Shi, Cedric Renggli, Shuai Zhang, Theodoros Rekatsinas, Torsten Hoefler, Gustavo Alonso</author><pubDate>Thu, 06 Jul 2023 14:52:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11182v3</guid></item><item><title>Caption Anything: Interactive Image Description with Diverse Multimodal Controls</title><link>http://arxiv.org/abs/2305.02677v3</link><description>Controllable image captioning is an emerging multimodal topic that aims todescribe the image with natural language following human purpose,$\textit{e.g.}$, looking at the specified regions or telling in a particulartext style. State-of-the-art methods are trained on annotated pairs of inputcontrols and output captions. However, the scarcity of such well-annotatedmultimodal data largely limits their usability and scalability for interactiveAI systems. Leveraging unimodal instruction-following foundation models is apromising alternative that benefits from broader sources of data. In thispaper, we present Caption AnyThing (CAT), a foundation model augmented imagecaptioning framework supporting a wide range of multimodel controls: 1) visualcontrols, including points, boxes, and trajectories; 2) language controls, suchas sentiment, length, language, and factuality. Powered by Segment AnythingModel (SAM) and ChatGPT, we unify the visual and language prompts into amodularized framework, enabling the flexible combination between differentcontrols. Extensive case studies demonstrate the user intention alignmentcapabilities of our framework, shedding light on effective user interactionmodeling in vision-language applications. Our code is publicly available athttps://github.com/ttengwang/Caption-Anything.</description><author>Teng Wang, Jinrui Zhang, Junjie Fei, Hao Zheng, Yunlong Tang, Zhe Li, Mingqi Gao, Shanshan Zhao</author><pubDate>Thu, 06 Jul 2023 14:47:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02677v3</guid></item><item><title>Fourier-Net: Fast Image Registration with Band-limited Deformation</title><link>http://arxiv.org/abs/2211.16342v2</link><description>Unsupervised image registration commonly adopts U-Net style networks topredict dense displacement fields in the full-resolution spatial domain. Forhigh-resolution volumetric image data, this process is howeverresource-intensive and time-consuming. To tackle this problem, we propose theFourier-Net, replacing the expansive path in a U-Net style network with aparameter-free model-driven decoder. Specifically, instead of our Fourier-Netlearning to output a full-resolution displacement field in the spatial domain,we learn its low-dimensional representation in a band-limited Fourier domain.This representation is then decoded by our devised model-driven decoder(consisting of a zero padding layer and an inverse discrete Fourier transformlayer) to the dense, full-resolution displacement field in the spatial domain.These changes allow our unsupervised Fourier-Net to contain fewer parametersand computational operations, resulting in faster inference speeds. Fourier-Netis then evaluated on two public 3D brain datasets against variousstate-of-the-art approaches. For example, when compared to a recenttransformer-based method, named TransMorph, our Fourier-Net, which only uses2.2\% of its parameters and 6.66\% of the multiply-add operations, achieves a0.5\% higher Dice score and an 11.48 times faster inference speed. Code isavailable at \url{https://github.com/xi-jia/Fourier-Net}.</description><author>Xi Jia, Joseph Bartlett, Wei Chen, Siyang Song, Tianyang Zhang, Xinxing Cheng, Wenqi Lu, Zhaowen Qiu, Jinming Duan</author><pubDate>Thu, 06 Jul 2023 14:46:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.16342v2</guid></item><item><title>ContainerGym: A Real-World Reinforcement Learning Benchmark for Resource Allocation</title><link>http://arxiv.org/abs/2307.02991v1</link><description>We present ContainerGym, a benchmark for reinforcement learning inspired by areal-world industrial resource allocation task. The proposed benchmark encodesa range of challenges commonly encountered in real-world sequential decisionmaking problems, such as uncertainty. It can be configured to instantiateproblems of varying degrees of difficulty, e.g., in terms of variabledimensionality. Our benchmark differs from other reinforcement learningbenchmarks, including the ones aiming to encode real-world difficulties, inthat it is directly derived from a real-world industrial problem, whichunderwent minimal simplification and streamlining. It is sufficiently versatileto evaluate reinforcement learning algorithms on any real-world problem thatfits our resource allocation framework. We provide results of standard baselinemethods. Going beyond the usual training reward curves, our results and thestatistical tools used to interpret them allow to highlight interestinglimitations of well-known deep reinforcement learning algorithms, namely PPO,TRPO and DQN.</description><author>Abhijeet Pendyala, Justin Dettmer, Tobias Glasmachers, Asma Atamna</author><pubDate>Thu, 06 Jul 2023 14:44:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02991v1</guid></item><item><title>Self-supervised representations in speech-based depression detection</title><link>http://arxiv.org/abs/2305.12263v2</link><description>This paper proposes handling training data sparsity in speech-based automaticdepression detection (SDD) using foundation models pre-trained withself-supervised learning (SSL). An analysis of SSL representations derived fromdifferent layers of pre-trained foundation models is first presented for SDD,which provides insight to suitable indicator for depression detection.Knowledge transfer is then performed from automatic speech recognition (ASR)and emotion recognition to SDD by fine-tuning the foundation models. Resultsshow that the uses of oracle and ASR transcriptions yield similar SDDperformance when the hidden representations of the ASR model is incorporatedalong with the ASR textual information. By integrating representations frommultiple foundation models, state-of-the-art SDD results based on real ASR wereachieved on the DAIC-WOZ dataset.</description><author>Wen Wu, Chao Zhang, Philip C. Woodland</author><pubDate>Thu, 06 Jul 2023 14:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12263v2</guid></item><item><title>Time Series Clustering With Random Convolutional Kernels</title><link>http://arxiv.org/abs/2305.10457v2</link><description>Time series data, spanning applications ranging from climatology to financeto healthcare, presents significant challenges in data mining due to its sizeand complexity. One open issue lies in time series clustering, which is crucialfor processing large volumes of unlabeled time series data and unlockingvaluable insights. Traditional and modern analysis methods, however, oftenstruggle with these complexities. To address these limitations, we introduceR-Clustering, a novel method that utilizes convolutional architectures withrandomly selected parameters. Through extensive evaluations, R-Clusteringdemonstrates superior performance over existing methods in terms of clusteringaccuracy, computational efficiency and scalability. Empirical results obtainedusing the UCR archive demonstrate the effectiveness of our approach acrossdiverse time series datasets. The findings highlight the significance ofR-Clustering in various domains and applications, contributing to theadvancement of time series data mining.</description><author>Jorge Marco-Blanco, Rubén Cuevas</author><pubDate>Thu, 06 Jul 2023 14:36:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10457v2</guid></item><item><title>A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications</title><link>http://arxiv.org/abs/2307.02984v1</link><description>Generative Adversarial Networks (GANs) have demonstrated their ability togenerate synthetic samples that match a target distribution. However, from aprivacy perspective, using GANs as a proxy for data sharing is not a safesolution, as they tend to embed near-duplicates of real samples in the latentspace. Recent works, inspired by k-anonymity principles, address this issuethrough sample aggregation in the latent space, with the drawback of reducingthe dataset by a factor of k. Our work aims to mitigate this problem byproposing a latent space navigation strategy able to generate diverse syntheticsamples that may support effective training of deep models, while addressingprivacy concerns in a principled way. Our approach leverages an auxiliaryidentity classifier as a guide to non-linearly walk between points in thelatent space, minimizing the risk of collision with near-duplicates of realsamples. We empirically demonstrate that, given any random pair of points inthe latent space, our walking strategy is safer than linear interpolation. Wethen test our path-finding strategy combined to k-same methods and demonstrate,on two benchmarks for tuberculosis and diabetic retinopathy classification,that training a model using samples generated by our approach mitigate drops inperformance, while keeping privacy preservation.</description><author>Matteo Pennisi, Federica Proietto Salanitri, Giovanni Bellitto, Simone Palazzo, Ulas Bagci, Concetto Spampinato</author><pubDate>Thu, 06 Jul 2023 14:35:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02984v1</guid></item><item><title>Efficient Semiring-Weighted Earley Parsing</title><link>http://arxiv.org/abs/2307.02982v1</link><description>This paper provides a reference description, in the form of a deductionsystem, of Earley's (1970) context-free parsing algorithm with variousspeed-ups. Our presentation includes a known worst-case runtime improvementfrom Earley's $O (N^3|G||R|)$, which is unworkable for the large grammars thatarise in natural language processing, to $O (N^3|G|)$, which matches theruntime of CKY on a binarized version of the grammar $G$. Here $N$ is thelength of the sentence, $|R|$ is the number of productions in $G$, and $|G|$ isthe total length of those productions. We also provide a version that achievesruntime of $O (N^3|M|)$ with $|M| \leq |G|$ when the grammar is representedcompactly as a single finite-state automaton $M$ (this is partly novel). Wecarefully treat the generalization to semiring-weighted deduction,preprocessing the grammar like Stolcke (1995) to eliminate deduction cycles,and further generalize Stolcke's method to compute the weights of sentenceprefixes. We also provide implementation details for efficient execution,ensuring that on a preprocessed grammar, the semiring-weighted versions of ourmethods have the same asymptotic runtime and space requirements as theunweighted methods, including sub-cubic runtime on some grammars.</description><author>Andreas Opedal, Ran Zmigrod, Tim Vieira, Ryan Cotterell, Jason Eisner</author><pubDate>Thu, 06 Jul 2023 14:33:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02982v1</guid></item><item><title>Multi-modal multi-class Parkinson disease classification using CNN and decision level fusion</title><link>http://arxiv.org/abs/2307.02978v1</link><description>Parkinson disease is the second most common neurodegenerative disorder, asreported by the World Health Organization. In this paper, we propose a directthree-Class PD classification using two different modalities, namely, MRI andDTI. The three classes used for classification are PD, Scans Without Evidenceof Dopamine Deficit and Healthy Control. We use white matter and gray matterfrom the MRI and fractional anisotropy and mean diffusivity from the DTI toachieve our goal. We train four separate CNNs on the above four types of data.At the decision level, the outputs of the four CNN models are fused with anoptimal weighted average fusion technique. We achieve an accuracy of 95.53percentage for the direct three class classification of PD, HC and SWEDD on thepublicly available PPMI database. Extensive comparisons including a series ofablation studies clearly demonstrate the effectiveness of our proposedsolution.</description><author>Sushanta Kumar Sahu, Ananda S. Chowdhury</author><pubDate>Thu, 06 Jul 2023 14:25:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02978v1</guid></item><item><title>Transfer Learning for the Efficient Detection of COVID-19 from Smartphone Audio Data</title><link>http://arxiv.org/abs/2307.02975v1</link><description>Disease detection from smartphone data represents an open research challengein mobile health (m-health) systems. COVID-19 and its respiratory symptoms arean important case study in this area and their early detection is a potentialreal instrument to counteract the pandemic situation. The efficacy of thissolution mainly depends on the performances of AI algorithms applied to thecollected data and their possible implementation directly on the users' mobiledevices. Considering these issues, and the limited amount of available data, inthis paper we present the experimental evaluation of 3 different deep learningmodels, compared also with hand-crafted features, and of two main approaches oftransfer learning in the considered scenario: both feature extraction andfine-tuning. Specifically, we considered VGGish, YAMNET, andL\textsuperscript{3}-Net (including 12 different configurations) evaluatedthrough user-independent experiments on 4 different datasets (13,447 samples intotal). Results clearly show the advantages of L\textsuperscript{3}-Net in allthe experimental settings as it overcomes the other solutions by 12.3\% interms of Precision-Recall AUC as features extractor, and by 10\% when the modelis fine-tuned. Moreover, we note that to fine-tune only the fully-connectedlayers of the pre-trained models generally leads to worse performances, with anaverage drop of 6.6\% with respect to feature extraction. %highlighting theneed for further investigations. Finally, we evaluate the memory footprints ofthe different models for their possible applications on commercial mobiledevices.</description><author>Mattia Giovanni Campana, Franca Delmastro, Elena Pagani</author><pubDate>Thu, 06 Jul 2023 14:19:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02975v1</guid></item><item><title>Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network for Remote Sensing Image Super-Resolution</title><link>http://arxiv.org/abs/2307.02974v1</link><description>Remote sensing image super-resolution (RSISR) plays a vital role in enhancingspatial detials and improving the quality of satellite imagery. Recently,Transformer-based models have shown competitive performance in RSISR. Tomitigate the quadratic computational complexity resulting from globalself-attention, various methods constrain attention to a local window,enhancing its efficiency. Consequently, the receptive fields in a singleattention layer are inadequate, leading to insufficient context modeling.Furthermore, while most transform-based approaches reuse shallow featuresthrough skip connections, relying solely on these connections treats shallowand deep features equally, impeding the model's ability to characterize them.To address these issues, we propose a novel transformer architecture calledCross-Spatial Pixel Integration and Cross-Stage Feature Fusion BasedTransformer Network (SPIFFNet) for RSISR. Our proposed model effectivelyenhances global cognition and understanding of the entire image, facilitatingefficient integration of features cross-stages. The model incorporatescross-spatial pixel integration attention (CSPIA) to introduce contextualinformation into a local window, while cross-stage feature fusion attention(CSFFA) adaptively fuses features from the previous stage to improve featureexpression in line with the requirements of the current stage. We conductedcomprehensive experiments on multiple benchmark datasets, demonstrating thesuperior performance of our proposed SPIFFNet in terms of both quantitativemetrics and visual quality when compared to state-of-the-art methods.</description><author>Yuting Lu, Lingtong Min, Binglu Wang, Le Zheng, Xiaoxu Wang, Yongqiang Zhao, Teng Long</author><pubDate>Thu, 06 Jul 2023 14:19:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02974v1</guid></item><item><title>Pruning vs Quantization: Which is Better?</title><link>http://arxiv.org/abs/2307.02973v1</link><description>Neural network pruning and quantization techniques are almost as old asneural networks themselves. However, to date only ad-hoc comparisons betweenthe two have been published. In this paper, we set out to answer the questionon which is better: neural network quantization or pruning? By answering thisquestion, we hope to inform design decisions made on neural network hardwaregoing forward. We provide an extensive comparison between the two techniquesfor compressing deep neural networks. First, we give an analytical comparisonof expected quantization and pruning error for general data distributions.Then, we provide lower bounds for the per-layer pruning and quantization errorin trained networks, and compare these to empirical error after optimization.Finally, we provide an extensive experimental comparison for training 8large-scale models on 3 tasks. Our results show that in most cases quantizationoutperforms pruning. Only in some scenarios with very high compression ratio,pruning might be beneficial from an accuracy standpoint.</description><author>Andrey Kuzmin, Markus Nagel, Mart van Baalen, Arash Behboodi, Tijmen Blankevoort</author><pubDate>Thu, 06 Jul 2023 14:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02973v1</guid></item><item><title>On the Cultural Gap in Text-to-Image Generation</title><link>http://arxiv.org/abs/2307.02971v1</link><description>One challenge in text-to-image (T2I) generation is the inadvertent reflectionof culture gaps present in the training data, which signifies the disparity ingenerated image quality when the cultural elements of the input text are rarelycollected in the training set. Although various T2I models have shownimpressive but arbitrary examples, there is no benchmark to systematicallyevaluate a T2I model's ability to generate cross-cultural images. To bridge thegap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensiveevaluation criteria, which can assess how well-suited a model is to a targetculture. By analyzing the flawed images generated by the Stable Diffusion modelon the C3 benchmark, we find that the model often fails to generate certaincultural objects. Accordingly, we propose a novel multi-modal metric thatconsiders object-text alignment to filter the fine-tuning data in the targetculture, which is used to fine-tune a T2I model to improve cross-culturalgeneration. Experimental results show that our multi-modal metric providesstronger data selection performance on the C3 benchmark than existing metrics,in which the object-text alignment is crucial. We release the benchmark, data,code, and generated images to facilitate future research on culturally diverseT2I generation (https://github.com/longyuewangdcu/C3-Bench).</description><author>Bingshuai Liu, Longyue Wang, Chenyang Lyu, Yong Zhang, Jinsong Su, Shuming Shi, Zhaopeng Tu</author><pubDate>Thu, 06 Jul 2023 14:17:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02971v1</guid></item><item><title>DPM: Clustering Sensitive Data through Separation</title><link>http://arxiv.org/abs/2307.02969v1</link><description>Privacy-preserving clustering groups data points in an unsupervised mannerwhilst ensuring that sensitive information remains protected. Previousprivacy-preserving clustering focused on identifying concentration of pointclouds. In this paper, we take another path and focus on identifyingappropriate separators that split a data set. We introduce the noveldifferentially private clustering algorithm DPM that searches for accurate datapoint separators in a differentially private manner. DPM addresses two keychallenges for finding accurate separators: identifying separators that arelarge gaps between clusters instead of small gaps within a cluster and, toefficiently spend the privacy budget, prioritising separators that split thedata into large subparts. Using the differentially private ExponentialMechanism, DPM randomly chooses cluster separators with provably high utility:For a data set $D$, if there is a wide low-density separator in the central$60\%$ quantile, DPM finds that separator with probability $1 -\exp(-\sqrt{|D|})$. Our experimental evaluation demonstrates that DPM achievessignificant improvements in terms of the clustering metric inertia. With theinertia results of the non-private KMeans++ as a baseline, for $\varepsilon =1$ and $\delta=10^{-5}$ DPM improves upon the difference to the baseline by upto $50\%$ for a synthetic data set and by up to $62\%$ for a real-world dataset compared to a state-of-the-art clustering algorithm by Chang and Kamath.</description><author>Yara Schütt, Johannes Liebenow, Tanya Braun, Marcel Gehrke, Florian Thaeter, Esfandiar Mohammadi</author><pubDate>Thu, 06 Jul 2023 14:12:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02969v1</guid></item><item><title>Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL</title><link>http://arxiv.org/abs/2306.04220v3</link><description>Offline reinforcement learning (RL) offers an appealing approach toreal-world tasks by learning policies from pre-collected datasets withoutinteracting with the environment. However, the performance of existing offlineRL algorithms heavily depends on the scale and state-action space coverage ofdatasets. Real-world data collection is often expensive and uncontrollable,leading to small and narrowly covered datasets and posing significantchallenges for practical deployments of offline RL. In this paper, we provide anew insight that leveraging the fundamental symmetry of system dynamics cansubstantially enhance offline RL performance under small datasets.Specifically, we propose a Time-reversal symmetry (T-symmetry) enforcedDynamics Model (TDM), which establishes consistency between a pair of forwardand reverse latent dynamics. TDM provides both well-behaved representations forsmall datasets and a new reliability measure for OOD samples based oncompliance with the T-symmetry. These can be readily used to construct a newoffline RL algorithm (TSRL) with less conservative policy constraints and areliable latent space data augmentation procedure. Based on extensiveexperiments, we find TSRL achieves great performance on small benchmarkdatasets with as few as 1% of the original samples, which significantlyoutperforms the recent offline RL algorithms in terms of data efficiency andgeneralizability.</description><author>Peng Cheng, Xianyuan Zhan, Zhihao Wu, Wenjia Zhang, Shoucheng Song, Han Wang, Youfang Lin, Li Jiang</author><pubDate>Thu, 06 Jul 2023 14:05:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04220v3</guid></item><item><title>SegNetr: Rethinking the local-global interactions and skip connections in U-shaped networks</title><link>http://arxiv.org/abs/2307.02953v1</link><description>Recently, U-shaped networks have dominated the field of medical imagesegmentation due to their simple and easily tuned structure. However, existingU-shaped segmentation networks: 1) mostly focus on designing complexself-attention modules to compensate for the lack of long-term dependence basedon convolution operation, which increases the overall number of parameters andcomputational complexity of the network; 2) simply fuse the features of encoderand decoder, ignoring the connection between their spatial locations. In thispaper, we rethink the above problem and build a lightweight medical imagesegmentation network, called SegNetr. Specifically, we introduce a novelSegNetr block that can perform local-global interactions dynamically at anystage and with only linear complexity. At the same time, we design a generalinformation retention skip connection (IRSC) to preserve the spatial locationinformation of encoder features and achieve accurate fusion with the decoderfeatures. We validate the effectiveness of SegNetr on four mainstream medicalimage segmentation datasets, with 59\% and 76\% fewer parameters and GFLOPsthan vanilla U-Net, while achieving segmentation performance comparable tostate-of-the-art methods. Notably, the components proposed in this paper can beapplied to other U-shaped networks to improve their segmentation performance.</description><author>Junlong Cheng, Chengrui Gao, Fengjie Wang, Min Zhu</author><pubDate>Thu, 06 Jul 2023 13:39:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02953v1</guid></item><item><title>A Neuromorphic Architecture for Reinforcement Learning from Real-Valued Observations</title><link>http://arxiv.org/abs/2307.02947v1</link><description>Reinforcement Learning (RL) provides a powerful framework for decision-makingin complex environments. However, implementing RL in hardware-efficient andbio-inspired ways remains a challenge. This paper presents a novel SpikingNeural Network (SNN) architecture for solving RL problems with real-valuedobservations. The proposed model incorporates multi-layered event-basedclustering, with the addition of Temporal Difference (TD)-error modulation andeligibility traces, building upon prior work. An ablation study confirms thesignificant impact of these components on the proposed model's performance. Atabular actor-critic algorithm with eligibility traces and a state-of-the-artProximal Policy Optimization (PPO) algorithm are used as benchmarks. Ournetwork consistently outperforms the tabular approach and successfullydiscovers stable control policies on classic RL environments: mountain car,cart-pole, and acrobot. The proposed model offers an appealing trade-off interms of computational and hardware implementation requirements. The model doesnot require an external memory buffer nor a global error gradient computation,and synaptic updates occur online, driven by local learning rules and abroadcasted TD-error signal. Thus, this work contributes to the development ofmore hardware-efficient RL solutions.</description><author>Sergio F. Chevtchenko, Yeshwanth Bethi, Teresa B. Ludermir, Saeed Afshar</author><pubDate>Thu, 06 Jul 2023 13:33:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02947v1</guid></item><item><title>Trainable Weight Averaging: A General Approach for Subspace Training</title><link>http://arxiv.org/abs/2205.13104v2</link><description>Training deep neural networks (DNNs) in low-dimensional subspaces is apromising direction for achieving efficient training and better generalizationperformance. Previous works extract the subspaces by using random projection orperforming dimensionality reduction method on the training trajectory, butthese methods can be inefficient or unstable in terms of dimensionality andnumerical operations. In this paper, we connect subspace training to weightaveraging and propose Trainable Weight Averaging (TWA), a general approach forsubspace training that generalizes the previous efforts. TWA is efficient interms of dimensionality and also easy to use, making it a promising new methodfor subspace training. We further design an efficient scheme for subspacetraining to cope with large-scale problems, which allows parallel trainingacross multiple nodes and evenly distributing the memory and computation burdento each node. We apply TWA to efficient neural network training and improvingfine-tuning performance tasks to demonstrate the great efficiency andeffectiveness of our approach. We conduct extensive experiments that covervarious benchmark computer vision and neural language processing tasks withvarious architectures. The code of implementation is available athttps://github.com/nblt/TWA.</description><author>Tao Li, Zhehao Huang, Qinghua Tao, Yingwen Wu, Xiaolin Huang</author><pubDate>Thu, 06 Jul 2023 13:32:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.13104v2</guid></item><item><title>A Time Leap Challenge for SAT Solving</title><link>http://arxiv.org/abs/2008.02215v2</link><description>We compare the impact of hardware advancement and algorithm advancement forSAT solving over the last two decades. In particular, we compare 20-year-oldSAT-solvers on new computer hardware with modern SAT-solvers on 20-year-oldhardware. Our findings show that the progress on the algorithmic side has atleast as much impact as the progress on the hardware side.</description><author>Johannes K. Fichte, Markus Hecher, Stefan Szeider</author><pubDate>Thu, 06 Jul 2023 13:28:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2008.02215v2</guid></item><item><title>Descriptive vs. inferential community detection in networks: pitfalls, myths, and half-truths</title><link>http://arxiv.org/abs/2112.00183v7</link><description>Community detection is one of the most important methodological fields ofnetwork science, and one which has attracted a significant amount of attentionover the past decades. This area deals with the automated division of a networkinto fundamental building blocks, with the objective of providing a summary ofits large-scale structure. Despite its importance and widespread adoption,there is a noticeable gap between what is arguably the state-of-the-art and themethods that are actually used in practice in a variety of fields. Here weattempt to address this discrepancy by dividing existing methods according towhether they have a "descriptive" or an "inferential" goal. While descriptivemethods find patterns in networks based on context-dependent notions ofcommunity structure, inferential methods articulate generative models, andattempt to fit them to data. In this way, they are able to provide insightsinto the mechanisms of network formation, and separate structure fromrandomness in a manner supported by statistical evidence. We review howemploying descriptive methods with inferential aims is riddled with pitfallsand misleading answers, and thus should be in general avoided. We argue thatinferential methods are more typically aligned with clearer scientificquestions, yield more robust results, and should be in many cases preferred. Weattempt to dispel some myths and half-truths often believed when communitydetection is employed in practice, in an effort to improve both the use of suchmethods as well as the interpretation of their results.</description><author>Tiago P. Peixoto</author><pubDate>Thu, 06 Jul 2023 13:20:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.00183v7</guid></item><item><title>OSPC: Online Sequential Photometric Calibration</title><link>http://arxiv.org/abs/2305.17673v2</link><description>Photometric calibration is essential to many computer vision applications.One of its key benefits is enhancing the performance of Visual SLAM, especiallywhen it depends on a direct method for tracking, such as the standard KLTalgorithm. Another advantage could be in retrieving the sensor irradiancevalues from measured intensities, as a pre-processing step for some visionalgorithms, such as shape-from-shading. Current photometric calibration systemsrely on a joint optimization problem and encounter an ambiguity in theestimates, which can only be resolved using ground truth information. Wepropose a novel method that solves for photometric parameters using asequential estimation approach. Our proposed method achieves high accuracy inestimating all parameters; furthermore, the formulations are linear and convex,which makes the solution fast and suitable for online applications. Experimentson a Visual Odometry system validate the proposed method and demonstrate itsadvantages.</description><author>Jawad Haidar, Douaa Khalil, Daniel Asmar</author><pubDate>Thu, 06 Jul 2023 13:08:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17673v2</guid></item><item><title>LOANet: A Lightweight Network Using Object Attention for Extracting Buildings and Roads from UAV Aerial Remote Sensing Images</title><link>http://arxiv.org/abs/2212.08490v6</link><description>Semantic segmentation for extracting buildings and roads from uncrewed aerialvehicle (UAV) remote sensing images by deep learning becomes a more efficientand convenient method than traditional manual segmentation in surveying andmapping fields. In order to make the model lightweight and improve the modelaccuracy, a Lightweight Network Using Object Attention (LOANet) for Buildingsand Roads from UAV Aerial Remote Sensing Images is proposed. The proposednetwork adopts an encoder-decoder architecture in which a Lightweight DenselyConnected Network (LDCNet) is developed as the encoder. In the decoder part,the dual multi-scale context modules which consist of the Atrous SpatialPyramid Pooling module (ASPP) and the Object Attention Module (OAM) aredesigned to capture more context information from feature maps of UAV remotesensing images. Between ASPP and OAM, a Feature Pyramid Network (FPN) module isused to fuse multi-scale features extracted from ASPP. A private dataset ofremote sensing images taken by UAV which contains 2431 training sets, 945validation sets, and 475 test sets is constructed. The proposed basic modelperforms well on this dataset, with only 1.4M parameters and 5.48G floatingpoint operations (FLOPs), achieving excellent mean Intersection-over-Union(mIoU). Further experiments on the publicly available LoveDA and CITY-OSMdatasets have been conducted to further validate the effectiveness of theproposed basic and large model, and outstanding mIoU results have beenachieved. All codes are available on https://github.com/GtLinyer/LOANet.</description><author>Xiaoxiang Han, Yiman Liu, Gang Liu, Yuanjie Lin, Qiaohong Liu</author><pubDate>Thu, 06 Jul 2023 13:06:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08490v6</guid></item><item><title>DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models</title><link>http://arxiv.org/abs/2210.14896v4</link><description>With recent advancements in diffusion models, users can generate high-qualityimages by writing text prompts in natural language. However, generating imageswith desired details requires proper prompts, and it is often unclear how amodel reacts to different prompts or what the best prompts are. To helpresearchers tackle these critical challenges, we introduce DiffusionDB, thefirst large-scale text-to-image prompt dataset totaling 6.5TB, containing 14million images generated by Stable Diffusion, 1.8 million unique prompts, andhyperparameters specified by real users. We analyze the syntactic and semanticcharacteristics of prompts. We pinpoint specific hyperparameter values andprompt styles that can lead to model errors and present evidence of potentiallyharmful model usage, such as the generation of misinformation. Theunprecedented scale and diversity of this human-actuated dataset provideexciting research opportunities in understanding the interplay between promptsand generative models, detecting deepfakes, and designing human-AI interactiontools to help users more easily use these models. DiffusionDB is publiclyavailable at: https://poloclub.github.io/diffusiondb.</description><author>Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, Duen Horng Chau</author><pubDate>Thu, 06 Jul 2023 12:53:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.14896v4</guid></item><item><title>DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms using Self-adversarial Learning</title><link>http://arxiv.org/abs/2307.02935v1</link><description>Asymmetry is a crucial characteristic of bilateral mammograms (Bi-MG) whenabnormalities are developing. It is widely utilized by radiologists fordiagnosis. The question of 'what the symmetrical Bi-MG would look like when theasymmetrical abnormalities have been removed ?' has not yet received strongattention in the development of algorithms on mammograms. Addressing thisquestion could provide valuable insights into mammographic anatomy and aid indiagnostic interpretation. Hence, we propose a novel framework, DisAsymNet,which utilizes asymmetrical abnormality transformer guided self-adversariallearning for disentangling abnormalities and symmetric Bi-MG. At the same time,our proposed method is partially guided by randomly synthesized abnormalities.We conduct experiments on three public and one in-house dataset, anddemonstrate that our method outperforms existing methods in abnormalityclassification, segmentation, and localization tasks. Additionally,reconstructed normal mammograms can provide insights toward betterinterpretable visual cues for clinical diagnosis. The code will be accessibleto the public.</description><author>Xin Wang, Tao Tan, Yuan Gao, Luyi Han, Tianyu Zhang, Chunyao Lu, Regina Beets-Tan, Ruisheng Su, Ritse Mann</author><pubDate>Thu, 06 Jul 2023 12:52:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02935v1</guid></item><item><title>In Time and Space: Towards Usable Adaptive Control for Assistive Robotic Arms</title><link>http://arxiv.org/abs/2307.02933v1</link><description>Robotic solutions, in particular robotic arms, are becoming more frequentlydeployed for close collaboration with humans, for example in manufacturing ordomestic care environments. These robotic arms require the user to controlseveral Degrees-of-Freedom (DoFs) to perform tasks, primarily involvinggrasping and manipulating objects. Standard input devices predominantly havetwo DoFs, requiring time-consuming and cognitively demanding mode switches toselect individual DoFs. Contemporary Adaptive DoF Mapping Controls (ADMCs) haveshown to decrease the necessary number of mode switches but were up to now notable to significantly reduce the perceived workload. Users still bear themental workload of incorporating abstract mode switching into their workflow.We address this by providing feed-forward multimodal feedback using updatedrecommendations of ADMC, allowing users to visually compare the current and thesuggested mapping in real-time. We contrast the effectiveness of two newapproaches that a) continuously recommend updated DoF combinations or b) usediscrete thresholds between current robot movements and new recommendations.Both are compared in a Virtual Reality (VR) in-person study against a classiccontrol method. Significant results for lowered task completion time, fewermode switches, and reduced perceived workload conclusively establish that incombination with feedforward, ADMC methods can indeed outperform classic modeswitching. A lack of apparent quantitative differences between Continuous andThreshold reveals the importance of user-centered customization options.Including these implications in the development process will improve usability,which is essential for successfully implementing robotic technologies with highuser acceptance.</description><author>Max Pascher, Kirill Kronhardt, Felix Ferdinand Goldau, Udo Frese, Jens Gerken</author><pubDate>Thu, 06 Jul 2023 12:51:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02933v1</guid></item><item><title>Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings</title><link>http://arxiv.org/abs/2302.07729v2</link><description>Nowadays many research articles are prefaced with research highlights tosummarize the main findings of the paper. Highlights not only help researchersprecisely and quickly identify the contributions of a paper, they also enhancethe discoverability of the article via search engines. We aim to automaticallyconstruct research highlights given certain segments of a research paper. Weuse a pointer-generator network with coverage mechanism and a contextualembedding layer at the input that encodes the input tokens into SciBERTembeddings. We test our model on a benchmark dataset, CSPubSum, and alsopresent MixSub, a new multi-disciplinary corpus of papers for automaticresearch highlight generation. For both CSPubSum and MixSub, we have observedthat the proposed model achieves the best performance compared to relatedvariants and other models proposed in the literature. On the CSPubSum dataset,our model achieves the best performance when the input is only the abstract ofa paper as opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2and ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR score of32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On thenew MixSub dataset, where only the abstract is the input, our proposed model(when trained on the whole training corpus without distinguishing between thesubject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,9.76 and 29.3, respectively, METEOR score of 24.00, and BERTScore F1 of 85.25.</description><author>Tohida Rehman, Debarshi Kumar Sanyal, Samiran Chattopadhyay, Plaban Kumar Bhowmick, Partha Pratim Das</author><pubDate>Thu, 06 Jul 2023 12:46:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.07729v2</guid></item><item><title>When No-Rejection Learning is Optimal for Regression with Rejection</title><link>http://arxiv.org/abs/2307.02932v1</link><description>Learning with rejection is a prototypical model for studying the interactionbetween humans and AI on prediction tasks. The model has two components, apredictor and a rejector. Upon the arrival of a sample, the rejector firstdecides whether to accept it; if accepted, the predictor fulfills theprediction task, and if rejected, the prediction will be deferred to humans.The learning problem requires learning a predictor and a rejectorsimultaneously. This changes the structure of the conventional loss functionand often results in non-convexity and inconsistency issues. For theclassification with rejection problem, several works develop surrogate lossesfor the jointly learning with provable consistency guarantees; in parallel,there has been less work for the regression counterpart. We study theregression with rejection (RwR) problem and investigate the no-rejectionlearning strategy which treats the RwR problem as a standard regression task tolearn the predictor. We establish that the suboptimality of the no-rejectionlearning strategy observed in the literature can be mitigated by enlarging thefunction class of the predictor. Then we introduce the truncated loss to singleout the learning for the predictor and we show that a consistent surrogateproperty can be established for the predictor individually in an easier waythan for the predictor and the rejector jointly. Our findings advocate for atwo-step learning procedure that first uses all the data to learn the predictorand then calibrates the prediction loss for the rejector. It is better alignedwith the common intuition that more data samples will lead to a betterpredictor and it calls for more efforts on a better design of calibrationalgorithms for learning the rejector. While our discussions mainly focus on theregression problem, the theoretical results and insights generalize to theclassification problem as well.</description><author>Xiaocheng Li, Shang Liu, Chunlin Sun, Hanzhao Wang</author><pubDate>Thu, 06 Jul 2023 12:43:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02932v1</guid></item><item><title>FederatedTrust: A Solution for Trustworthy Federated Learning</title><link>http://arxiv.org/abs/2302.09844v2</link><description>The rapid expansion of the Internet of Things (IoT) and Edge Computing haspresented challenges for centralized Machine and Deep Learning (ML/DL) methodsdue to the presence of distributed data silos that hold sensitive information.To address concerns regarding data privacy, collaborative andprivacy-preserving ML/DL techniques like Federated Learning (FL) have emerged.However, ensuring data privacy and performance alone is insufficient sincethere is a growing need to establish trust in model predictions. Existingliterature has proposed various approaches on trustworthy ML/DL (excluding dataprivacy), identifying robustness, fairness, explainability, and accountabilityas important pillars. Nevertheless, further research is required to identifytrustworthiness pillars and evaluation metrics specifically relevant to FLmodels, as well as to develop solutions that can compute the trustworthinesslevel of FL models. This work examines the existing requirements for evaluatingtrustworthiness in FL and introduces a comprehensive taxonomy consisting of sixpillars (privacy, robustness, fairness, explainability, accountability, andfederation), along with over 30 metrics for computing the trustworthiness of FLmodels. Subsequently, an algorithm named FederatedTrust is designed based onthe pillars and metrics identified in the taxonomy to compute thetrustworthiness score of FL models. A prototype of FederatedTrust isimplemented and integrated into the learning process of FederatedScope, awell-established FL framework. Finally, five experiments are conducted usingdifferent configurations of FederatedScope to demonstrate the utility ofFederatedTrust in computing the trustworthiness of FL models. Three experimentsemploy the FEMNIST dataset, and two utilize the N-BaIoT dataset considering areal-world IoT security use case.</description><author>Pedro Miguel Sánchez Sánchez, Alberto Huertas Celdrán, Ning Xie, Gérôme Bovet, Gregorio Martínez Pérez, Burkhard Stiller</author><pubDate>Thu, 06 Jul 2023 12:35:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09844v2</guid></item><item><title>Effects of data time lag in a decision-making system using machine learning for pork price prediction</title><link>http://arxiv.org/abs/2305.05677v2</link><description>Spain is the third-largest producer of pork meat in the world, and many farmsin several regions depend on the evolution of this market. However, the currentpricing system is unfair, as some actors have better market information thanothers. In this context, historical pricing is an easy-to-find and affordabledata source that can help all agents to be better informed. However, the timelag in data acquisition can affect their pricing decisions. In this paper, westudy the effect that data acquisition delay has on a price prediction systemusing multiple prediction algorithms. We describe the integration of the bestproposal into a decision support system prototype and test it in a real-casescenario. Specifically, we use public data from the most important regionalpork meat markets in Spain published by the Ministry of Agriculture with atwo-week delay and subscription-based data of the same markets obtained on thesame day. The results show that the error difference between the best publicand data subscription models is 0.6 Euro cents in favor of the data withoutdelay. The market dimension makes these differences significant in the supplychain, giving pricing agents a better tool to negotiate market prices.</description><author>Mario Suaza-Medina, F. Javier Zarazaga-Soria, Jorge Pinilla-Lopez, Francisco J. López-Pellicer, Javier Lacasta</author><pubDate>Thu, 06 Jul 2023 12:27:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05677v2</guid></item><item><title>Adapting Neural Link Predictors for Complex Query Answering</title><link>http://arxiv.org/abs/2301.12313v2</link><description>Answering complex queries on incomplete knowledge graphs is a challengingtask where a model needs to answer complex logical queries in the presence ofmissing knowledge. Recently, Arakelyan et al. (2021); Minervini et al. (2022)showed that neural link predictors could also be used for answering complexqueries: their Continuous Query Decomposition (CQD) method works by decomposingcomplex queries into atomic sub-queries, answers them using neural linkpredictors and aggregates their scores via t-norms for ranking the answers toeach complex query. However, CQD does not handle negations and only uses thetraining signal from atomic training queries: neural link prediction scores arenot calibrated to interact together via fuzzy logic t-norms during complexquery answering. In this work, we propose to address this problem by training aparameter-efficient score adaptation model to re-calibrate neural linkprediction scores: this new component is trained on complex queries byback-propagating through the complex query-answering process. Our method,CQD$^{A}$, produces significantly more accurate results than currentstate-of-the-art methods, improving from $34.4$ to $35.1$ Mean Reciprocal Rankvalues averaged across all datasets and query types while using $\leq 35\%$ ofthe available training query types. We further show that CQD$^{A}$ isdata-efficient, achieving competitive results with only $1\%$ of the trainingdata, and robust in out-of-domain evaluations.</description><author>Erik Arakelyan, Pasquale Minervini, Isabelle Augenstein</author><pubDate>Thu, 06 Jul 2023 12:20:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12313v2</guid></item><item><title>Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection</title><link>http://arxiv.org/abs/2307.00209v2</link><description>Hyperbole, or exaggeration, is a common linguistic phenomenon. The detectionof hyperbole is an important part of understanding human expression. There havebeen several studies on hyperbole detection, but most of which focus on textmodality only. However, with the development of social media, people can createhyperbolic expressions with various modalities, including text, images, videos,etc. In this paper, we focus on multimodal hyperbole detection. We create amultimodal detection dataset\footnote{The dataset will be released to thecommunity.} from Weibo (a Chinese social media) and carry out some studies onit. We treat the text and image from a piece of weibo as two modalities andexplore the role of text and image for hyperbole detection. Differentpre-trained multimodal encoders are also evaluated on this downstream task toshow their performance. Besides, since this dataset is constructed from fivedifferent topics, we also evaluate the cross-domain performance of differentmodels. These studies can serve as a benchmark and point out the direction offurther study on multimodal hyperbole detection.</description><author>Huixuan Zhang, Xiaojun Wan</author><pubDate>Thu, 06 Jul 2023 12:19:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00209v2</guid></item></channel></rss>