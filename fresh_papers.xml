<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 22 Feb 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Coercing LLMs to do and reveal (almost) anything</title><link>http://arxiv.org/abs/2402.14020v1</link><description>It has recently been shown that adversarial attacks on large language models(LLMs) can "jailbreak" the model into making harmful statements. In this work,we argue that the spectrum of adversarial attacks on LLMs is much larger thanmerely jailbreaking. We provide a broad overview of possible attack surfacesand attack goals. Based on a series of concrete examples, we discuss,categorize and systematize attacks that coerce varied unintended behaviors,such as misdirection, model control, denial-of-service, or data extraction. We analyze these attacks in controlled experiments, and find that many ofthem stem from the practice of pre-training LLMs with coding capabilities, aswell as the continued existence of strange "glitch" tokens in common LLMvocabularies that should be removed for security reasons.</description><author>Jonas Geiping, Alex Stein, Manli Shu, Khalid Saifullah, Yuxin Wen, Tom Goldstein</author><pubDate>Wed, 21 Feb 2024 18:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14020v1</guid></item><item><title>Learning Optimal Control with Stochastic Models of Hamiltonian Dynamics</title><link>http://arxiv.org/abs/2111.08108v2</link><description>Optimal control problems can be solved by applying the Pontryagin maximumprinciple and then solving for a Hamiltonian dynamical system. In this paper,we propose novel learning frameworks to tackle optimal control problems. Byapplying the Pontryagin maximum principle to the original optimal controlproblem, the learning focus shifts to reduced Hamiltonian dynamics andcorresponding adjoint variables. The reduced Hamiltonian networks can belearned by going backward in time and then minimizing loss function deducedfrom the Pontryagin maximum principle's conditions. The learning process isfurther improved by progressively learning a posterior distribution of reducedHamiltonians, utilizing a variational autoencoder which leads to more effectivepath exploration process. We apply our learning frameworks to control tasks andobtain competitive results.</description><author>Chandrajit Bajaj, Minh Nguyen</author><pubDate>Wed, 21 Feb 2024 18:58:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.08108v2</guid></item><item><title>D-Flow: Differentiating through Flows for Controlled Generation</title><link>http://arxiv.org/abs/2402.14017v1</link><description>Taming the generation outcome of state of the art Diffusion and Flow-Matching(FM) models without having to re-train a task-specific model unlocks a powerfultool for solving inverse problems, conditional generation, and controlledgeneration in general. In this work we introduce D-Flow, a simple framework forcontrolling the generation process by differentiating through the flow,optimizing for the source (noise) point. We motivate this framework by our keyobservation stating that for Diffusion/FM models trained with Gaussianprobability paths, differentiating through the generation process projectsgradient on the data manifold, implicitly injecting the prior into theoptimization process. We validate our framework on linear and non-linearcontrolled generation problems including: image and audio inverse problems andconditional molecule generation reaching state of the art performance acrossall.</description><author>Heli Ben-Hamu, Omri Puny, Itai Gat, Brian Karrer, Uriel Singer, Yaron Lipman</author><pubDate>Wed, 21 Feb 2024 18:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14017v1</guid></item><item><title>Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment</title><link>http://arxiv.org/abs/2402.14016v1</link><description>Large Language Models (LLMs) are powerful zero-shot assessors and areincreasingly used in real-world situations such as for written exams orbenchmarking systems. Despite this, no existing work has analyzed thevulnerability of judge-LLMs against adversaries attempting to manipulateoutputs. This work presents the first study on the adversarial robustness ofassessment LLMs, where we search for short universal phrases that when appendedto texts can deceive LLMs to provide high assessment scores. Experiments onSummEval and TopicalChat demonstrate that both LLM-scoring and pairwiseLLM-comparative assessment are vulnerable to simple concatenation attacks,where in particular LLM-scoring is very susceptible and can yield maximumassessment scores irrespective of the input text quality. Interestingly, suchattacks are transferable and phrases learned on smaller open-source LLMs can beapplied to larger closed-source models, such as GPT3.5. This highlights thepervasive nature of the adversarial vulnerabilities across different judge-LLMsizes, families and methods. Our findings raise significant concerns on thereliability of LLMs-as-a-judge methods, and underscore the importance ofaddressing vulnerabilities in LLM assessment methods before deployment inhigh-stakes real-world scenarios.</description><author>Vyas Raina, Adian Liusie, Mark Gales</author><pubDate>Wed, 21 Feb 2024 18:55:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14016v1</guid></item><item><title>Corrective Machine Unlearning</title><link>http://arxiv.org/abs/2402.14015v1</link><description>Machine Learning models increasingly face data integrity challenges due tothe use of large-scale training datasets drawn from the internet. We study whatmodel developers can do if they detect that some data was manipulated orincorrect. Such manipulated data can cause adverse effects like vulnerabilityto backdoored samples, systematic biases, and in general, reduced accuracy oncertain input domains. Often, all manipulated training samples are not known,and only a small, representative subset of the affected data is flagged. We formalize "Corrective Machine Unlearning" as the problem of mitigating theimpact of data affected by unknown manipulations on a trained model, possiblyknowing only a subset of impacted samples. We demonstrate that the problem ofcorrective unlearning has significantly different requirements from traditionalprivacy-oriented unlearning. We find most existing unlearning methods,including the gold-standard retraining-from-scratch, require most of themanipulated data to be identified for effective corrective unlearning. However,one approach, SSD, achieves limited success in unlearning adverse effects withjust a small portion of the manipulated samples, showing the tractability ofthis setting. We hope our work spurs research towards developing better methodsfor corrective unlearning and offers practitioners a new strategy to handledata integrity challenges arising from web-scale training.</description><author>Shashwat Goel, Ameya Prabhu, Philip Torr, Ponnurangam Kumaraguru, Amartya Sanyal</author><pubDate>Wed, 21 Feb 2024 18:54:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14015v1</guid></item><item><title>Misalignment, Learning, and Ranking: Harnessing Users Limited Attention</title><link>http://arxiv.org/abs/2402.14013v1</link><description>In digital health and EdTech, recommendation systems face a significantchallenge: users often choose impulsively, in ways that conflict with theplatform's long-term payoffs. This misalignment makes it difficult toeffectively learn to rank items, as it may hinder exploration of items withgreater long-term payoffs. Our paper tackles this issue by utilizing users'limited attention spans. We propose a model where a platform presents itemswith unknown payoffs to the platform in a ranked list to $T$ users over time.Each user selects an item by first considering a prefix window of these rankeditems and then picking the highest preferred item in that window (and theplatform observes its payoff for this item). We study the design of onlinebandit algorithms that obtain vanishing regret against hindsight optimalbenchmarks. We first consider adversarial window sizes and stochastic iid payoffs. Wedesign an active-elimination-based algorithm that achieves an optimalinstance-dependent regret bound of $O(\log(T))$, by showing matching regretupper and lower bounds. The key idea is using the combinatorial structure ofthe problem to either obtain a large payoff from each item or to explore bygetting a sample from that item. This method systematically narrows down theitem choices to enhance learning efficiency and payoff. Second, we consider adversarial payoffs and stochastic iid window sizes. Westart from the full-information problem of finding the permutation thatmaximizes the expected payoff. By a novel combinatorial argument, wecharacterize the polytope of admissible item selection probabilities by apermutation and show it has a polynomial-size representation. Using thisrepresentation, we show how standard algorithms for adversarial online linearoptimization in the space of admissible probabilities can be used to obtain apolynomial-time algorithm with $O(\sqrt{T})$ regret.</description><author>Arpit Agarwal, Rad Niazadeh, Prathamesh Patil</author><pubDate>Wed, 21 Feb 2024 18:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14013v1</guid></item><item><title>Chasing Convex Functions with Long-term Constraints</title><link>http://arxiv.org/abs/2402.14012v1</link><description>We introduce and study a family of online metric problems with long-termconstraints. In these problems, an online player makes decisions $\mathbf{x}_t$in a metric space $(X,d)$ to simultaneously minimize their hitting cost$f_t(\mathbf{x}_t)$ and switching cost as determined by the metric. Over thetime horizon $T$, the player must satisfy a long-term demand constraint$\sum_{t} c(\mathbf{x}_t) \geq 1$, where $c(\mathbf{x}_t)$ denotes the fractionof demand satisfied at time $t$. Such problems can find a wide array ofapplications to online resource allocation in sustainable energy and computingsystems. We devise optimal competitive and learning-augmented algorithms forspecific instantiations of these problems, and further show that our proposedalgorithms perform well in numerical experiments.</description><author>Adam Lechowicz, Nicolas Christianson, Bo Sun, Noman Bashir, Mohammad Hajiesmaili, Adam Wierman, Prashant Shenoy</author><pubDate>Wed, 21 Feb 2024 18:51:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14012v1</guid></item><item><title>LAC: Latent Action Composition for Skeleton-based Action Segmentation</title><link>http://arxiv.org/abs/2308.14500v4</link><description>Skeleton-based action segmentation requires recognizing composable actions inuntrimmed videos. Current approaches decouple this problem by first extractinglocal visual features from skeleton sequences and then processing them by atemporal model to classify frame-wise actions. However, their performancesremain limited as the visual features cannot sufficiently express composableactions. In this context, we propose Latent Action Composition (LAC), a novelself-supervised framework aiming at learning from synthesized composablemotions for skeleton-based action segmentation. LAC is composed of a novelgeneration module towards synthesizing new sequences. Specifically, we design alinear latent space in the generator to represent primitive motion. Newcomposed motions can be synthesized by simply performing arithmetic operationson latent representations of multiple input skeleton sequences. LAC leveragessuch synthesized sequences, which have large diversity and complexity, forlearning visual representations of skeletons in both sequence and frame spacesvia contrastive learning. The resulting visual encoder has a high expressivepower and can be effectively transferred onto action segmentation tasks byend-to-end fine-tuning without the need for additional temporal models. Weconduct a study focusing on transfer-learning and we show that representationslearned from pre-trained LAC outperform the state-of-the-art by a large marginon TSU, Charades, PKU-MMD datasets.</description><author>Di Yang, Yaohui Wang, Antitza Dantcheva, Quan Kong, Lorenzo Garattoni, Gianpiero Francesca, Francois Bremond</author><pubDate>Wed, 21 Feb 2024 18:50:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14500v4</guid></item><item><title>Geometry-Informed Neural Networks</title><link>http://arxiv.org/abs/2402.14009v1</link><description>We introduce the concept of geometry-informed neural networks (GINNs), whichencompass (i) learning under geometric constraints, (ii) neural fields as asuitable representation, and (iii) generating diverse solutions tounder-determined systems often encountered in geometric tasks. Notably, theGINN formulation does not require training data, and as such can be consideredgenerative modeling driven purely by constraints. We add an explicit diversityloss to mitigate mode collapse. We consider several constraints, in particular,the connectedness of components which we convert to a differentiable lossthrough Morse theory. Experimentally, we demonstrate the efficacy of the GINNlearning paradigm across a range of two and three-dimensional scenarios withincreasing levels of complexity.</description><author>Arturs Berzins, Andreas Radler, Sebastian Sanokowski, Sepp Hochreiter, Johannes Brandstetter</author><pubDate>Wed, 21 Feb 2024 18:50:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14009v1</guid></item><item><title>Rethinking Scaling Laws for Learning in Strategic Environments</title><link>http://arxiv.org/abs/2402.07588v2</link><description>The deployment of ever-larger machine learning models reflects a growingconsensus that the more expressive the model$\unicode{x2013}$and the more dataone has access to$\unicode{x2013}$the more one can improve performance. Asmodels get deployed in a variety of real world scenarios, they inevitably facestrategic environments. In this work, we consider the natural question of howthe interplay of models and strategic interactions affects scaling laws. Wefind that strategic interactions can break the conventional view of scalinglaws$\unicode{x2013}$meaning that performance does not necessarilymonotonically improve as models get larger and/ or more expressive (even withinfinite data). We show the implications of this phenomenon in several contextsincluding strategic regression, strategic classification, and multi-agentreinforcement learning through examples of strategic environments inwhich$\unicode{x2013}$by simply restricting the expressivity of one's model orpolicy class$\unicode{x2013}$one can achieve strictly better equilibriumoutcomes. Motivated by these examples, we then propose a new paradigm formodel-selection in games wherein an agent seeks to choose amongst differentmodel classes to use as their action set in a game.</description><author>Tinashe Handina, Eric Mazumdar</author><pubDate>Wed, 21 Feb 2024 18:49:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07588v2</guid></item><item><title>OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems</title><link>http://arxiv.org/abs/2402.14008v1</link><description>Recent advancements have seen Large Language Models (LLMs) and LargeMultimodal Models (LMMs) surpassing general human capabilities in varioustasks, approaching the proficiency level of human experts across multipledomains. With traditional benchmarks becoming less challenging for thesemodels, new rigorous challenges are essential to gauge their advancedabilities. In this work, we present OlympiadBench, an Olympiad-level bilingualmultimodal scientific benchmark, featuring 8,952 problems from Olympiad-levelmathematics and physics competitions, including the Chinese college entranceexam. Each problem is detailed with expert-level annotations for step-by-stepreasoning. Evaluating top-tier models on OlympiadBench, we implement acomprehensive assessment methodology to accurately evaluate model responses.Notably, the best-performing model, GPT-4V, attains an average score of 17.23%on OlympiadBench, with a mere 11.28% in physics, highlighting the benchmarkrigor and the intricacy of physical reasoning. Our analysis orienting GPT-4Vpoints out prevalent issues with hallucinations, knowledge omissions, andlogical fallacies. We hope that our challenging benchmark can serve as avaluable resource for helping future AGI research endeavors.</description><author>Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen Leng Thai, Junhao Shen, Jinyi Hu, Xu Han, Yujie Huang, Yuxiang Zhang, Jie Liu, Lei Qi, Zhiyuan Liu, Maosong Sun</author><pubDate>Wed, 21 Feb 2024 18:49:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14008v1</guid></item><item><title>Motor Imagery Decoding Using Ensemble Curriculum Learning and Collaborative Training</title><link>http://arxiv.org/abs/2211.11460v2</link><description>In this work, we study the problem of cross-subject motor imagery (MI)decoding from electroencephalography (EEG) data. Multi-subject EEG datasetspresent several kinds of domain shifts due to various inter-individualdifferences (e.g. brain anatomy, personality and cognitive profile). Thesedomain shifts render multi-subject training a challenging task and also impederobust cross-subject generalization. Inspired by the importance of domaingeneralization techniques for tackling such issues, we propose a two-stagemodel ensemble architecture built with multiple feature extractors (firststage) and a shared classifier (second stage), which we train end-to-end withtwo novel loss terms. The first loss applies curriculum learning, forcing eachfeature extractor to specialize to a subset of the training subjects andpromoting feature diversity. The second loss is an intra-ensemble distillationobjective that allows collaborative exchange of knowledge between the models ofthe ensemble. We compare our method against several state-of-the-arttechniques, conducting subject-independent experiments on two large MIdatasets, namely PhysioNet and OpenBMI. Our algorithm outperforms all of themethods in both 5-fold cross-validation and leave-one-subject-out evaluationsettings, using a substantially lower number of trainable parameters. Wedemonstrate that our model ensembling approach combining the powers ofcurriculum learning and collaborative training, leads to high learning capacityand robust performance. Our work addresses the issue of domain shifts inmulti-subject EEG datasets, paving the way for calibration-free brain-computerinterfaces. We make our code publicly available at:https://github.com/gzoumpourlis/Ensemble-MI</description><author>Georgios Zoumpourlis, Ioannis Patras</author><pubDate>Wed, 21 Feb 2024 18:49:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11460v2</guid></item><item><title>Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models</title><link>http://arxiv.org/abs/2402.14007v1</link><description>Text watermarking technology aims to tag and identify content produced bylarge language models (LLMs) to prevent misuse. In this study, we introduce theconcept of ''cross-lingual consistency'' in text watermarking, which assessesthe ability of text watermarks to maintain their effectiveness after beingtranslated into other languages. Preliminary empirical results from two LLMsand three watermarking methods reveal that current text watermarkingtechnologies lack consistency when texts are translated into various languages.Based on this observation, we propose a Cross-lingual Watermark Removal Attack(CWRA) to bypass watermarking by first obtaining a response from an LLM in apivot language, which is then translated into the target language. CWRA caneffectively remove watermarks by reducing the Area Under the Curve (AUC) from0.95 to 0.67 without performance loss. Furthermore, we analyze two key factorsthat contribute to the cross-lingual consistency in text watermarking andpropose a defense method that increases the AUC from 0.67 to 0.88 under CWRA.</description><author>Zhiwei He, Binglin Zhou, Hongkun Hao, Aiwei Liu, Xing Wang, Zhaopeng Tu, Zhuosheng Zhang, Rui Wang</author><pubDate>Wed, 21 Feb 2024 18:48:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14007v1</guid></item><item><title>Effective and Efficient Conversation Retrieval for Dialogue State Tracking with Implicit Text Summaries</title><link>http://arxiv.org/abs/2402.13043v2</link><description>Few-shot dialogue state tracking (DST) with Large Language Models (LLM)relies on an effective and efficient conversation retriever to find similarin-context examples for prompt learning. Previous works use raw dialoguecontext as search keys and queries, and a retriever is fine-tuned withannotated dialogues to achieve superior performance. However, the approach isless suited for scaling to new domains or new annotation languages, wherefine-tuning data is unavailable. To address this problem, we handle the task ofconversation retrieval based on text summaries of the conversations. ALLM-based conversation summarizer is adopted for query and key generation,which enables effective maximum inner product search. To avoid the extrainference cost brought by LLM-based conversation summarization, we furtherdistill a light-weight conversation encoder which produces query embeddingswithout decoding summaries for test conversations. We validate our retrievalapproach on MultiWOZ datasets with GPT-Neo-2.7B and LLaMA-7B/30B. Theexperimental results show a significant improvement over relevant baselines inreal few-shot DST settings.</description><author>Seanie Lee, Jianpeng Cheng, Joris Driesen, Alexandru Coca, Anders Johannsen</author><pubDate>Wed, 21 Feb 2024 18:45:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13043v2</guid></item><item><title>Rotational Equilibrium: How Weight Decay Balances Learning Across Neural Networks</title><link>http://arxiv.org/abs/2305.17212v3</link><description>This study investigates how weight decay affects the update behavior ofindividual neurons in deep neural networks through a combination of appliedanalysis and experimentation. Weight decay can cause the expected magnitude andangular updates of a neuron's weight vector to converge to a steady state wecall rotational equilibrium. These states can be highly homogeneous,effectively balancing the average rotation -- a proxy for the effectivelearning rate -- across different layers and neurons. Our work analyzes thesedynamics across optimizers like Adam, Lion, and SGD with momentum, offering anew simple perspective on training that elucidates the efficacy of widely usedbut poorly understood methods in deep learning. We demonstrate how balancedrotation plays a key role in the effectiveness of normalization like WeightStandardization, as well as that of AdamW over Adam with L2-regularization.Finally, we show that explicitly controlling the rotation provides the benefitsof weight decay while substantially reducing the need for learning rate warmup.</description><author>Atli Kosson, Bettina Messmer, Martin Jaggi</author><pubDate>Wed, 21 Feb 2024 18:44:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17212v3</guid></item><item><title>Hallucinations or Attention Misdirection? The Path to Strategic Value Extraction in Business Using Large Language Models</title><link>http://arxiv.org/abs/2402.14002v1</link><description>Large Language Models with transformer architecture have revolutionized thedomain of text generation, setting unprecedented benchmarks. Despite theirimpressive capabilities, LLMs have been criticized for generating outcomes thatdeviate from factual accuracy or display logical inconsistencies, phenomenacommonly referred to as hallucinations. This term, however, has often beenmisapplied to any results deviating from the instructor's expectations, whichthis paper defines as attention misdirection rather than true hallucinations.Understanding the distinction between hallucinations and attention misdirectionbecomes increasingly relevant in business contexts, where the ramifications ofsuch errors can significantly impact the value extraction from these inherentlypre-trained models. This paper highlights the best practices of the PGI,Persona, Grouping, and Intelligence, method, a strategic framework thatachieved a remarkable error rate of only 3,15 percent across 4,000 responsesgenerated by GPT in response to a real business challenge. It emphasizes thatby equipping experimentation with knowledge, businesses can unlockopportunities for innovation through the use of these natively pre-trainedmodels. This reinforces the notion that strategic application grounded in askilled team can maximize the benefits of emergent technologies such as theLLMs.</description><author>Aline Ioste</author><pubDate>Wed, 21 Feb 2024 18:40:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14002v1</guid></item><item><title>PARCv2: Physics-aware Recurrent Convolutional Neural Networks for Spatiotemporal Dynamics Modeling</title><link>http://arxiv.org/abs/2402.12503v2</link><description>Modeling unsteady, fast transient, and advection-dominated physics problemsis a pressing challenge for physics-aware deep learning (PADL). The physics ofcomplex systems is governed by large systems of partial differential equations(PDEs) and ancillary constitutive models with nonlinear structures, as well asevolving state fields exhibiting sharp gradients and rapidly deforming materialinterfaces. Here, we investigate an inductive bias approach that is versatileand generalizable to model generic nonlinear field evolution problems. Ourstudy focuses on the recent physics-aware recurrent convolutions (PARC), whichincorporates a differentiator-integrator architecture that inductively modelsthe spatiotemporal dynamics of generic physical systems. We extend thecapabilities of PARC to simulate unsteady, transient, and advection-dominantsystems. The extended model, referred to as PARCv2, is equipped withdifferential operators to model advection-reaction-diffusion equations, as wellas a hybrid integral solver for stable, long-time predictions. PARCv2 is testedon both standard benchmark problems in fluid dynamics, namely Burgers andNavier-Stokes equations, and then applied to more complex shock-inducedreaction problems in energetic materials. We evaluate the behavior of PARCv2 incomparison to other physics-informed and learning bias models and demonstrateits potential to model unsteady and advection-dominant dynamics regimes.</description><author>Phong C. H. Nguyen, Xinlun Cheng, Shahab Azarfar, Pradeep Seshadri, Yen T. Nguyen, Munho Kim, Sanghun Choi, H. S. Udaykumar, Stephen Baek</author><pubDate>Wed, 21 Feb 2024 18:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12503v2</guid></item><item><title>Real-time 3D-aware Portrait Editing from a Single Image</title><link>http://arxiv.org/abs/2402.14000v1</link><description>This work presents 3DPE, a practical tool that can efficiently edit a faceimage following given prompts, like reference images or text descriptions, inthe 3D-aware manner. To this end, a lightweight module is distilled from a 3Dportrait generator and a text-to-image model, which provide prior knowledge offace geometry and open-vocabulary editing capability, respectively. Such adesign brings two compelling advantages over existing approaches. First, oursystem achieves real-time editing with a feedforward network (i.e., ~0.04s perimage), over 100x faster than the second competitor. Second, thanks to thepowerful priors, our module could focus on the learning of editing-relatedvariations, such that it manages to handle various types of editingsimultaneously in the training phase and further supports fast adaptation touser-specified novel types of editing during inference (e.g., with ~5minfine-tuning per case). The code, the model, and the interface will be madepublicly available to facilitate future research.</description><author>Qingyan Bai, Yinghao Xu, Zifan Shi, Hao Ouyang, Qiuyu Wang, Ceyuan Yang, Xuan Wang, Gordon Wetzstein, Yujun Shen, Qifeng Chen</author><pubDate>Wed, 21 Feb 2024 18:36:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14000v1</guid></item><item><title>Progress in artificial intelligence applications based on the combination of self-driven sensors and deep learning</title><link>http://arxiv.org/abs/2402.09442v2</link><description>In the era of Internet of Things, how to develop a smart sensor system withsustainable power supply, easy deployment and flexible use has become adifficult problem to be solved. The traditional power supply has problems suchas frequent replacement or charging when in use, which limits the developmentof wearable devices. The contact-to-separate friction nanogenerator (TENG) wasprepared by using polychotomy thy lene (PTFE) and aluminum (AI) foils. Humanmotion energy was collected by human body arrangement, and human motion posturewas monitored according to the changes of output electrical signals. In 2012,Academician Wang Zhong lin and his team invented the triboelectricnanogenerator (TENG), which uses Maxwell displacement current as a drivingforce to directly convert mechanical stimuli into electrical signals, so it canbe used as a self-driven sensor. Teng-based sensors have the advantages ofsimple structure and high instantaneous power density, which provides animportant means for building intelligent sensor systems. At the same time,machine learning, as a technology with low cost, short development cycle,strong data processing ability and prediction ability, has a significant effecton the processing of a large number of electrical signals generated by TENG,and the combination with TENG sensors will promote the rapid development ofintelligent sensor networks in the future. Therefore, this paper is based onthe intelligent sound monitoring and recognition system of TENG, which has goodsound recognition capability, and aims to evaluate the feasibility of the soundperception module architecture in ubiquitous sensor networks.</description><author>Weixiang Wan, Wenjian Sun, Qiang Zeng, Linying Pan, Jingyu Xu, Bo Liu</author><pubDate>Wed, 21 Feb 2024 18:36:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09442v2</guid></item><item><title>Asymptotics of Learning with Deep Structured (Random) Features</title><link>http://arxiv.org/abs/2402.13999v1</link><description>For a large class of feature maps we provide a tight asymptoticcharacterisation of the test error associated with learning the readout layer,in the high-dimensional limit where the input dimension, hidden layer widths,and number of training samples are proportionally large. This characterizationis formulated in terms of the population covariance of the features. Our workis partially motivated by the problem of learning with Gaussian rainbow neuralnetworks, namely deep non-linear fully-connected networks with random butstructured weights, whose row-wise covariances are further allowed to depend onthe weights of previous layers. For such networks we also derive a closed-formformula for the feature covariance in terms of the weight matrices. We furtherfind that in some cases our results can capture feature maps learned by deep,finite-width neural networks trained under gradient descent.</description><author>Dominik Schröder, Daniil Dmitriev, Hugo Cui, Bruno Loureiro</author><pubDate>Wed, 21 Feb 2024 18:35:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13999v1</guid></item><item><title>Large Language Models Streamline Automated Machine Learning for Clinical Studies</title><link>http://arxiv.org/abs/2308.14120v5</link><description>A knowledge gap persists between machine learning (ML) developers (e.g., datascientists) and practitioners (e.g., clinicians), hampering the fullutilization of ML for clinical data analysis. We investigated the potential ofthe ChatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge thisgap and perform ML analyses efficiently. Real-world clinical datasets and studydetails from large trials across various medical specialties were presented toChatGPT ADA without specific guidance. ChatGPT ADA autonomously developedstate-of-the-art ML models based on the original study's training data topredict clinical outcomes such as cancer development, cancer progression,disease complications, or biomarkers such as pathogenic gene sequences.Following the re-implementation and optimization of the published models, thehead-to-head comparison of the ChatGPT ADA-crafted ML models and theirrespective manually crafted counterparts revealed no significant differences intraditional performance metrics (P&gt;0.071). Strikingly, the ChatGPT ADA-craftedML models often outperformed their counterparts. In conclusion, ChatGPT ADAoffers a promising avenue to democratize ML in medicine by simplifying complexdata analyses, yet should enhance, not replace, specialized training andresources, to promote broader applications in medical research and practice.</description><author>Soroosh Tayebi Arasteh, Tianyu Han, Mahshad Lotfinia, Christiane Kuhl, Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung</author><pubDate>Wed, 21 Feb 2024 18:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14120v5</guid></item><item><title>A Review of Driver Gaze Estimation and Application in Gaze Behavior Understanding</title><link>http://arxiv.org/abs/2307.01470v2</link><description>Driver gaze plays an important role in different gaze-based applications suchas driver attentiveness detection, visual distraction detection, gaze behaviorunderstanding, and building driver assistance system. The main objective ofthis study is to perform a comprehensive summary of driver gaze fundamentals,methods to estimate driver gaze, and it's applications in real world drivingscenarios. We first discuss the fundamentals related to driver gaze, involvinghead-mounted and remote setup based gaze estimation and the terminologies usedfor each of these data collection methods. Next, we list out the existingbenchmark driver gaze datasets, highlighting the collection methodology and theequipment used for such data collection. This is followed by a discussion ofthe algorithms used for driver gaze estimation, which primarily involvestraditional machine learning and deep learning based techniques. The estimateddriver gaze is then used for understanding gaze behavior while maneuveringthrough intersections, on-ramps, off-ramps, lane changing, and determining theeffect of roadside advertising structures. Finally, we have discussed thelimitations in the existing literature, challenges, and the future scope indriver gaze estimation and gaze-based applications.</description><author>Pavan Kumar Sharma, Pranamesh Chakraborty</author><pubDate>Wed, 21 Feb 2024 18:28:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01470v2</guid></item><item><title>Analysing The Impact of Sequence Composition on Language Model Pre-Training</title><link>http://arxiv.org/abs/2402.13991v1</link><description>Most language model pre-training frameworks concatenate multiple documentsinto fixed-length sequences and use causal masking to compute the likelihood ofeach token given its context; this strategy is widely adopted due to itssimplicity and efficiency. However, to this day, the influence of thepre-training sequence composition strategy on the generalisation properties ofthe model remains under-explored. In this work, we find that applying causalmasking can lead to the inclusion of distracting information from previousdocuments during pre-training, which negatively impacts the performance of themodels on language modelling and downstream tasks. In intra-document causalmasking, the likelihood of each token is only conditioned on the previoustokens in the same document, eliminating potential distracting information fromprevious documents and significantly improving performance. Furthermore, wefind that concatenating related documents can reduce some potentialdistractions during pre-training, and our proposed efficient retrieval-basedsequence construction method, BM25Chunk, can improve in-context learning(+11.6\%), knowledge memorisation (+9.8\%), and context utilisation (+7.2\%)abilities of language models without sacrificing efficiency.</description><author>Yu Zhao, Yuanbin Qu, Konrad Staniszewski, Szymon Tworkowski, Wei Liu, Piotr Miłoś, Yuxiang Wu, Pasquale Minervini</author><pubDate>Wed, 21 Feb 2024 18:23:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13991v1</guid></item><item><title>FedADMM-InSa: An Inexact and Self-Adaptive ADMM for Federated Learning</title><link>http://arxiv.org/abs/2402.13989v1</link><description>Federated learning (FL) is a promising framework for learning fromdistributed data while maintaining privacy. The development of efficient FLalgorithms encounters various challenges, including heterogeneous data andsystems, limited communication capacities, and constrained local computationalresources. Recently developed FedADMM methods show great resilience to bothdata and system heterogeneity. However, they still suffer from performancedeterioration if the hyperparameters are not carefully tuned. To address thisissue, we propose an inexact and self-adaptive FedADMM algorithm, termedFedADMM-InSa. First, we design an inexactness criterion for the clients' localupdates to eliminate the need for empirically setting the local trainingaccuracy. This inexactness criterion can be assessed by each clientindependently based on its unique condition, thereby reducing the localcomputational cost and mitigating the undesirable straggle effect. Theconvergence of the resulting inexact ADMM is proved under the assumption ofstrongly convex loss functions. Additionally, we present a self-adaptive schemethat dynamically adjusts each client's penalty parameter, enhancing algorithmrobustness by mitigating the need for empirical penalty parameter choices foreach client. Extensive numerical experiments on both synthetic and real-worlddatasets are conducted. As validated by some numerical tests, our proposedalgorithm can reduce the clients' local computational load significantly andalso accelerate the learning process compared to the vanilla FedADMM.</description><author>Yongcun Song, Ziqi Wang, Enrique Zuazua</author><pubDate>Wed, 21 Feb 2024 18:19:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13989v1</guid></item><item><title>A Simple and Yet Fairly Effective Defense for Graph Neural Networks</title><link>http://arxiv.org/abs/2402.13987v1</link><description>Graph Neural Networks (GNNs) have emerged as the dominant approach formachine learning on graph-structured data. However, concerns have arisenregarding the vulnerability of GNNs to small adversarial perturbations.Existing defense methods against such perturbations suffer from high timecomplexity and can negatively impact the model's performance on clean graphs.To address these challenges, this paper introduces NoisyGNNs, a novel defensemethod that incorporates noise into the underlying model's architecture. Weestablish a theoretical connection between noise injection and the enhancementof GNN robustness, highlighting the effectiveness of our approach. We furtherconduct extensive empirical evaluations on the node classification task tovalidate our theoretical findings, focusing on two popular GNNs: the GCN andGIN. The results demonstrate that NoisyGNN achieves superior or comparabledefense performance to existing methods while minimizing added time complexity.The NoisyGNN approach is model-agnostic, allowing it to be integrated withdifferent GNN architectures. Successful combinations of our NoisyGNN approachwith existing defense techniques demonstrate even further improved adversarialdefense results. Our code is publicly available at:https://github.com/Sennadir/NoisyGNN.</description><author>Sofiane Ennadir, Yassine Abbahaddou, Johannes F. Lutzeyer, Michalis Vazirgiannis, Henrik Boström</author><pubDate>Wed, 21 Feb 2024 18:16:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13987v1</guid></item><item><title>Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment</title><link>http://arxiv.org/abs/2311.08596v2</link><description>The interactive nature of Large Language Models (LLMs) theoretically allowsmodels to refine and improve their answers, yet systematic analysis of themulti-turn behavior of LLMs remains limited. In this paper, we propose theFlipFlop experiment: in the first round of the conversation, an LLM completes aclassification task. In a second round, the LLM is challenged with a follow-upphrase like "Are you sure?", offering an opportunity for the model to reflecton its initial answer, and decide whether to confirm or flip its answer. Asystematic study of ten LLMs on seven classification tasks reveals that modelsflip their answers on average 46% of the time and that all models see adeterioration of accuracy between their first and final prediction, with anaverage drop of 17% (the FlipFlop effect). We conduct finetuning experiments onan open-source LLM and find that finetuning on synthetically created data canmitigate - reducing performance deterioration by 60% - but not resolvesycophantic behavior entirely. The FlipFlop experiment illustrates theuniversality of sycophantic behavior in LLMs and provides a robust framework toanalyze model behavior and evaluate future models.</description><author>Philippe Laban, Lidiya Murakhovs'ka, Caiming Xiong, Chien-Sheng Wu</author><pubDate>Wed, 21 Feb 2024 18:15:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08596v2</guid></item><item><title>Stability-Aware Training of Neural Network Interatomic Potentials with Differentiable Boltzmann Estimators</title><link>http://arxiv.org/abs/2402.13984v1</link><description>Neural network interatomic potentials (NNIPs) are an attractive alternativeto ab-initio methods for molecular dynamics (MD) simulations. However, they canproduce unstable simulations which sample unphysical states, limiting theirusefulness for modeling phenomena occurring over longer timescales. To addressthese challenges, we present Stability-Aware Boltzmann Estimator (StABlE)Training, a multi-modal training procedure which combines conventionalsupervised training from quantum-mechanical energies and forces with referencesystem observables, to produce stable and accurate NNIPs. StABlE Trainingiteratively runs MD simulations to seek out unstable regions, and corrects theinstabilities via supervision with a reference observable. The trainingprocedure is enabled by the Boltzmann Estimator, which allows efficientcomputation of gradients required to train neural networks to systemobservables, and can detect both global and local instabilities. We demonstrateour methodology across organic molecules, tetrapeptides, and condensed phasesystems, along with using three modern NNIP architectures. In all three cases,StABlE-trained models achieve significant improvements in simulation stabilityand recovery of structural and dynamic observables. In some cases,StABlE-trained models outperform conventional models trained on datasets 50times larger. As a general framework applicable across NNIP architectures andsystems, StABlE Training is a powerful tool for training stable and accurateNNIPs, particularly in the absence of large reference datasets.</description><author>Sanjeev Raja, Ishan Amin, Fabian Pedregosa, Aditi S. Krishnapriyan</author><pubDate>Wed, 21 Feb 2024 18:12:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13984v1</guid></item><item><title>The Importance of Architecture Choice in Deep Learning for Climate Applications</title><link>http://arxiv.org/abs/2402.13979v1</link><description>Machine Learning has become a pervasive tool in climate science applications.However, current models fail to address nonstationarity induced byanthropogenic alterations in greenhouse emissions and do not routinely quantifythe uncertainty of proposed projections. In this paper, we model the AtlanticMeridional Overturning Circulation (AMOC) which is of major importance toclimate in Europe and the US East Coast by transporting warm water to theseregions, and has the potential for abrupt collapse. We can generate arbitrarilyextreme climate scenarios through arbitrary time scales which we then predictusing neural networks. Our analysis shows that the AMOC is predictable usingneural networks under a diverse set of climate scenarios. Further experimentsreveal that MLPs and Deep Ensembles can learn the physics of the AMOC insteadof imitating its progression through autocorrelation. With quantifieduncertainty, an intriguing pattern of "spikes" before critical points ofcollapse in the AMOC casts doubt on previous analyses that predicted an AMOCcollapse within this century. Our results show that Bayesian Neural Networksperform poorly compared to more dense architectures and care should be takenwhen applying neural networks to nonstationary scenarios such as climateprojections. Further, our results highlight that big NN models might havedifficulty in modeling global Earth System dynamics accurately and besuccessfully applied in nonstationary climate scenarios due to the physicsbeing challenging for neural networks to capture.</description><author>Simon Dräger, Maike Sonnewald</author><pubDate>Wed, 21 Feb 2024 18:09:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13979v1</guid></item><item><title>NeuralFuse: Learning to Recover the Accuracy of Access-Limited Neural Network Inference in Low-Voltage Regimes</title><link>http://arxiv.org/abs/2306.16869v2</link><description>Deep neural networks (DNNs) have become ubiquitous in machine learning, buttheir energy consumption remains a notable issue. Lowering the supply voltageis an effective strategy for reducing energy consumption. However, aggressivelyscaling down the supply voltage can lead to accuracy degradation due to randombit flips in static random access memory (SRAM) where model parameters arestored. To address this challenge, we introduce NeuralFuse, a novel add-onmodule that addresses the accuracy-energy tradeoff in low-voltage regimes bylearning input transformations to generate error-resistant datarepresentations. NeuralFuse protects DNN accuracy in both nominal andlow-voltage scenarios. Moreover, NeuralFuse is easy to implement and can bereadily applied to DNNs with limited access, such as non-configurable hardwareor remote access to cloud-based APIs. Experimental results demonstrate that, ata 1% bit error rate, NeuralFuse can reduce SRAM memory access energy by up to24% while recovering accuracy by up to 57%. To the best of our knowledge, thisis the first model-agnostic approach (i.e., no model retraining) to addresslow-voltage-induced bit errors. The source code is available athttps://github.com/IBM/NeuralFuse.</description><author>Hao-Lun Sun, Lei Hsiung, Nandhini Chandramoorthy, Pin-Yu Chen, Tsung-Yi Ho</author><pubDate>Wed, 21 Feb 2024 18:06:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16869v2</guid></item><item><title>Convergence of variational Monte Carlo simulation and scale-invariant pre-training</title><link>http://arxiv.org/abs/2303.11602v3</link><description>We provide theoretical convergence bounds for the variational Monte Carlo(VMC) method as applied to optimize neural network wave functions for theelectronic structure problem. We study both the energy minimization phase andthe supervised pre-training phase that is commonly used prior to energyminimization. For the energy minimization phase, the standard algorithm isscale-invariant by design, and we provide a proof of convergence for thisalgorithm without modifications. The pre-training stage typically does notfeature such scale-invariance. We propose using a scale-invariant loss for thepretraining phase and demonstrate empirically that it leads to fasterpre-training.</description><author>Nilin Abrahamsen, Zhiyan Ding, Gil Goldshlager, Lin Lin</author><pubDate>Wed, 21 Feb 2024 18:02:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11602v3</guid></item><item><title>Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions</title><link>http://arxiv.org/abs/2402.09384v2</link><description>A principal designs an algorithm that generates a publicly observableprediction of a binary state. She must decide whether to act directly based onthe prediction or to delegate the decision to an agent with private informationbut potential misalignment. We study the optimal design of the predictionalgorithm and the delegation rule in such environments. Three key findingsemerge: (1) Delegation is optimal if and only if the principal would make thesame binary decision as the agent had she observed the agent's information. (2)Providing the most informative algorithm may be suboptimal even if theprincipal can act on the algorithm's prediction. Instead, the optimal algorithmmay provide more information about one state and restrict information about theother. (3) Well-intentioned policies aiming to provide more information, suchas keeping a "human-in-the-loop" or requiring maximal prediction accuracy,could strictly worsen decision quality compared to systems with no human or noalgorithmic assistance. These findings predict the underperformance ofhuman-machine collaborations if no measures are taken to mitigate commonpreference misalignment between algorithms and human decision-makers.</description><author>Ruqing Xu</author><pubDate>Wed, 21 Feb 2024 18:01:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09384v2</guid></item><item><title>Linear-Time Graph Neural Networks for Scalable Recommendations</title><link>http://arxiv.org/abs/2402.13973v1</link><description>In an era of information explosion, recommender systems are vital tools todeliver personalized recommendations for users. The key of recommender systemsis to forecast users' future behaviors based on previous user-iteminteractions. Due to their strong expressive power of capturing high-orderconnectivities in user-item interaction data, recent years have witnessed arising interest in leveraging Graph Neural Networks (GNNs) to boost theprediction performance of recommender systems. Nonetheless, classic MatrixFactorization (MF) and Deep Neural Network (DNN) approaches still play animportant role in real-world large-scale recommender systems due to theirscalability advantages. Despite the existence of GNN-acceleration solutions, itremains an open question whether GNN-based recommender systems can scale asefficiently as classic MF and DNN methods. In this paper, we propose aLinear-Time Graph Neural Network (LTGNN) to scale up GNN-based recommendersystems to achieve comparable scalability as classic MF approaches whilemaintaining GNNs' powerful expressiveness for superior prediction accuracy.Extensive experiments and ablation studies are presented to validate theeffectiveness and scalability of the proposed algorithm. Our implementationbased on PyTorch is available.</description><author>Jiahao Zhang, Rui Xue, Wenqi Fan, Xin Xu, Qing Li, Jian Pei, Xiaorui Liu</author><pubDate>Wed, 21 Feb 2024 17:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13973v1</guid></item><item><title>Feature-Conditioned Cascaded Video Diffusion Models for Precise Echocardiogram Synthesis</title><link>http://arxiv.org/abs/2303.12644v3</link><description>Image synthesis is expected to provide value for the translation of machinelearning methods into clinical practice. Fundamental problems like modelrobustness, domain transfer, causal modelling, and operator training becomeapproachable through synthetic data. Especially, heavily operator-dependantmodalities like Ultrasound imaging require robust frameworks for image andvideo generation. So far, video generation has only been possible by providinginput data that is as rich as the output data, e.g., image sequence plusconditioning in, video out. However, clinical documentation is usually scarceand only single images are reported and stored, thus retrospectivepatient-specific analysis or the generation of rich training data becomesimpossible with current approaches. In this paper, we extend elucidateddiffusion models for video modelling to generate plausible video sequences fromsingle images and arbitrary conditioning with clinical parameters. We explorethis idea within the context of echocardiograms by looking into the variationof the Left Ventricle Ejection Fraction, the most essential clinical metricgained from these examinations. We use the publicly available EchoNet-Dynamicdataset for all our experiments. Our image to sequence approach achieves an$R^2$ score of 93%, which is 38 points higher than recently proposed sequenceto sequence generation methods. Code and models will be available at:https://github.com/HReynaud/EchoDiffusion.</description><author>Hadrien Reynaud, Mengyun Qiao, Mischa Dombrowski, Thomas Day, Reza Razavi, Alberto Gomez, Paul Leeson, Bernhard Kainz</author><pubDate>Wed, 21 Feb 2024 17:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12644v3</guid></item><item><title>Tree of Attacks: Jailbreaking Black-Box LLMs Automatically</title><link>http://arxiv.org/abs/2312.02119v2</link><description>While Large Language Models (LLMs) display versatile functionality, theycontinue to generate harmful, biased, and toxic content, as demonstrated by theprevalence of human-designed jailbreaks. In this work, we present Tree ofAttacks with Pruning (TAP), an automated method for generating jailbreaks thatonly requires black-box access to the target LLM. TAP utilizes an LLM toiteratively refine candidate (attack) prompts using tree-of-thought reasoninguntil one of the generated prompts jailbreaks the target. Crucially, beforesending prompts to the target, TAP assesses them and prunes the ones unlikelyto result in jailbreaks. Using tree-of-thought reasoning allows TAP to navigatea large search space of prompts and pruning reduces the total number of queriessent to the target. In empirical evaluations, we observe that TAP generatesprompts that jailbreak state-of-the-art LLMs (including GPT4 and GPT4-Turbo)for more than 80% of the prompts using only a small number of queries.Interestingly, TAP is also capable of jailbreaking LLMs protected bystate-of-the-art guardrails, e.g., LlamaGuard. This significantly improves uponthe previous state-of-the-art black-box method for generating jailbreaks.</description><author>Anay Mehrotra, Manolis Zampetakis, Paul Kassianik, Blaine Nelson, Hyrum Anderson, Yaron Singer, Amin Karbasi</author><pubDate>Wed, 21 Feb 2024 17:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02119v2</guid></item><item><title>Unsupervised Layer-wise Score Aggregation for Textual OOD Detection</title><link>http://arxiv.org/abs/2302.09852v3</link><description>Out-of-distribution (OOD) detection is a rapidly growing field due to newrobustness and security requirements driven by an increased number of AI-basedsystems. Existing OOD textual detectors often rely on an anomaly score (e.g.,Mahalanobis distance) computed on the embedding output of the last layer of theencoder. In this work, we observe that OOD detection performance varies greatlydepending on the task and layer output. More importantly, we show that theusual choice (the last layer) is rarely the best one for OOD detection and thatfar better results could be achieved if the best layer were picked. To leveragethis observation, we propose a data-driven, unsupervised method to combinelayer-wise anomaly scores. In addition, we extend classical textual OODbenchmarks by including classification tasks with a greater number of classes(up to 77), which reflects more realistic settings. On this augmentedbenchmark, we show that the proposed post-aggregation methods achieve robustand consistent results while removing manual feature selection altogether.Their performance achieves near oracle's best layer performance.</description><author>Maxime Darrin, Guillaume Staerman, Eduardo Dadalto Câmara Gomes, Jackie CK Cheung, Pablo Piantanida, Pierre Colombo</author><pubDate>Wed, 21 Feb 2024 17:47:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09852v3</guid></item><item><title>Towards Building Multilingual Language Model for Medicine</title><link>http://arxiv.org/abs/2402.13963v1</link><description>In this paper, we aim to develop an open-source, multilingual language modelfor medicine, that the benefits a wider, linguistically diverse audience fromdifferent regions. In general, we present the contribution from the followingaspects: first, for multilingual medical-specific adaptation, we construct anew multilingual medical corpus, that contains approximately 25.5B tokensencompassing 6 main languages, termed as MMedC, that enables auto-regressivetraining for existing general LLMs. second, to monitor the development ofmultilingual LLMs in medicine, we propose a new multilingual medicalmulti-choice question-answering benchmark with rationale, termed as MMedBench;third, we have assessed a number of popular, opensource large language models(LLMs) on our benchmark, along with those further auto-regressive trained onMMedC, as a result, our final model, termed as MMedLM 2, with only 7Bparameters, achieves superior performance compared to all other open-sourcemodels, even rivaling GPT-4 on MMedBench. We will make the resources publiclyavailable, including code, model weights, and datasets.</description><author>Pengcheng Qiu, Chaoyi Wu, Xiaoman Zhang, Weixiong Lin, Haicheng Wang, Ya Zhang, Yanfeng Wang, Weidi Xie</author><pubDate>Wed, 21 Feb 2024 17:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13963v1</guid></item><item><title>LASER: LLM Agent with State-Space Exploration for Web Navigation</title><link>http://arxiv.org/abs/2309.08172v2</link><description>Large language models (LLMs) have been successfully adapted for interactivedecision-making tasks like web navigation. While achieving decent performance,previous methods implicitly assume a forward-only execution mode for the model,where they only provide oracle trajectories as in-context examples to guide themodel on how to reason in the environment. Consequently, the model could nothandle more challenging scenarios not covered in the in-context examples, e.g.,mistakes, leading to sub-optimal performance. To address this issue, we proposeto model the interactive task as state space exploration, where the LLM agenttransitions among a pre-defined set of states by performing actions to completethe task. This formulation enables flexible backtracking, allowing the model torecover from errors easily. We evaluate our proposed LLM Agent with State-SpaceExploRation (LASER) on both the WebShop task and amazon.com. Experimentalresults show that LASER significantly outperforms previous methods and closesthe gap with human performance on the web navigation task.</description><author>Kaixin Ma, Hongming Zhang, Hongwei Wang, Xiaoman Pan, Wenhao Yu, Dong Yu</author><pubDate>Wed, 21 Feb 2024 17:42:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08172v2</guid></item><item><title>Advancing Audio Fingerprinting Accuracy Addressing Background Noise and Distortion Challenges</title><link>http://arxiv.org/abs/2402.13957v1</link><description>Audio fingerprinting, exemplified by pioneers like Shazam, has transformeddigital audio recognition. However, existing systems struggle with accuracy inchallenging conditions, limiting broad applicability. This research proposes anAI and ML integrated audio fingerprinting algorithm to enhance accuracy. Builton the Dejavu Project's foundations, the study emphasizes real-world scenariosimulations with diverse background noises and distortions. Signal processing,central to Dejavu's model, includes the Fast Fourier Transform, spectrograms,and peak extraction. The "constellation" concept and fingerprint hashing enableunique song identification. Performance evaluation attests to 100% accuracywithin a 5-second audio input, with a system showcasing predictable matchingspeed for efficiency. Storage analysis highlights the critical space-speedtrade-off for practical implementation. This research advances audiofingerprinting's adaptability, addressing challenges in varied environments andapplications.</description><author>Navin Kamuni, Sathishkumar Chintala, Naveen Kunchakuri, Jyothi Swaroop Arlagadda Narasimharaju, Venkat Kumar</author><pubDate>Wed, 21 Feb 2024 17:37:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13957v1</guid></item><item><title>Can You Learn Semantics Through Next-Word Prediction? The Case of Entailment</title><link>http://arxiv.org/abs/2402.13956v1</link><description>Do LMs infer the semantics of text from co-occurrence patterns in theirtraining data? Merrill et al. (2022) argue that, in theory, probabilitiespredicted by an optimal LM encode semantic information about entailmentrelations, but it is unclear whether neural LMs trained on corpora learnentailment in this way because of strong idealizing assumptions made by Merrillet al. In this work, we investigate whether their theory can be used to decodeentailment judgments from neural LMs. We find that a test similar to theirs candecode entailment relations between natural sentences, well above randomchance, though not perfectly, across many datasets and LMs. This suggests LMsimplicitly model aspects of semantics to predict semantic effects on sentenceco-occurrence patterns. However, we find the test that predicts entailment inpractice works in the opposite direction to the theoretical test. We thusrevisit the assumptions underlying the original test, finding its derivationdid not adequately account for redundancy in human-written text. We argue thatcorrectly accounting for redundancy related to explanations might derive theobserved flipped test and, more generally, improve linguistic theories of humanspeakers.</description><author>William Merrill, Zhaofeng Wu, Norihito Naka, Yoon Kim, Tal Linzen</author><pubDate>Wed, 21 Feb 2024 17:36:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13956v1</guid></item><item><title>BEE-NET: A deep neural network to identify in-the-wild Bodily Expression of Emotions</title><link>http://arxiv.org/abs/2402.13955v1</link><description>In this study, we investigate how environmental factors, specifically thescenes and objects involved, can affect the expression of emotions through bodylanguage. To this end, we introduce a novel multi-stream deep convolutionalneural network named BEE-NET. We also propose a new late fusion strategy thatincorporates meta-information on places and objects as prior knowledge in thelearning process. Our proposed probabilistic pooling model leverages thisinformation to generate a joint probability distribution of both available andanticipated non-available contextual information in latent space. Importantly,our fusion strategy is differentiable, allowing for end-to-end training andcapturing of hidden associations among data points without requiring furtherpost-processing or regularisation. To evaluate our deep model, we use the BodyLanguage Database (BoLD), which is currently the largest available database forthe Automatic Identification of the in-the-wild Bodily Expression of Emotions(AIBEE). Our experimental results demonstrate that our proposed approachsurpasses the current state-of-the-art in AIBEE by a margin of 2.07%, achievingan Emotional Recognition Score of 66.33%.</description><author>Mohammad Mahdi Dehshibi, David Masip</author><pubDate>Wed, 21 Feb 2024 17:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13955v1</guid></item><item><title>ChemReasoner: Heuristic Search over a Large Language Model's Knowledge Space using Quantum-Chemical Feedback</title><link>http://arxiv.org/abs/2402.10980v2</link><description>The discovery of new catalysts is essential for the design of new and moreefficient chemical processes in order to transition to a sustainable future. Weintroduce an AI-guided computational screening framework unifying linguisticreasoning with quantum-chemistry based feedback from 3D atomisticrepresentations. Our approach formulates catalyst discovery as an uncertainenvironment where an agent actively searches for highly effective catalysts viathe iterative combination of large language model (LLM)-derived hypotheses andatomistic graph neural network (GNN)-derived feedback. Identified catalysts inintermediate search steps undergo structural evaluation based on spatialorientation, reaction pathways, and stability. Scoring functions based onadsorption energies and barriers steer the exploration in the LLM's knowledgespace toward energetically favorable, high-efficiency catalysts. We introduceplanning methods that automatically guide the exploration without human input,providing competitive performance against expert-enumerated chemicaldescriptor-based implementations. By integrating language-guided reasoning withcomputational chemistry feedback, our work pioneers AI-accelerated, trustworthycatalyst discovery.</description><author>Henry W. Sprueill, Carl Edwards, Khushbu Agarwal, Mariefel V. Olarte, Udishnu Sanyal, Conrad Johnston, Hongbin Liu, Heng Ji, Sutanay Choudhury</author><pubDate>Wed, 21 Feb 2024 17:34:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10980v2</guid></item><item><title>Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality</title><link>http://arxiv.org/abs/2402.13954v1</link><description>Social and political scientists often aim to discover and measure distinctbiases from text data representations (embeddings). Innovativetransformer-based language models produce contextually-aware token embeddingsand have achieved state-of-the-art performance for a variety of naturallanguage tasks, but have been shown to encode unwanted biases for downstreamapplications. In this paper, we evaluate the social biases encoded bytransformers trained with the masked language modeling objective using proposedproxy functions within an iterative masking experiment to measure the qualityof transformer models' predictions, and assess the preference of MLMs towardsdisadvantaged and advantaged groups. We compare bias estimations with thoseproduced by other evaluation methods using two benchmark datasets, findingrelatively high religious and disability biases across considered MLMs and lowgender bias in one dataset relative to the other. Our measures outperformothers in their agreement with human annotators. We extend on previous work byevaluating social biases introduced after re-training an MLM under the maskedlanguage modeling objective (w.r.t. the model's pre-trained base), and findthat proposed measures produce more accurate estimations of relative preferencefor biased sentences between transformers than others based on our methods.</description><author>Rahul Zalkikar, Kanchan Chandra</author><pubDate>Wed, 21 Feb 2024 17:33:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13954v1</guid></item><item><title>Tactile-based Object Retrieval From Granular Media</title><link>http://arxiv.org/abs/2402.04536v2</link><description>We introduce GEOTACT, a robotic manipulation method capable of retrievingobjects buried in granular media. This is a challenging task due to the need tointeract with granular media, and doing so based exclusively on tactilefeedback, since a buried object can be completely hidden from vision. Tactilefeedback is in itself challenging in this context, due to ubiquitous contactwith the surrounding media, and the inherent noise level induced by the tactilereadings. To address these challenges, we use a learning method trainedend-to-end with simulated sensor noise. We show that our problem formulationleads to the natural emergence of learned pushing behaviors that themanipulator uses to reduce uncertainty and funnel the object to a stable graspdespite spurious and noisy tactile readings. We also introduce a trainingcurriculum that enables learning these behaviors in simulation, followed byzero-shot transfer to real hardware. To the best of our knowledge, GEOTACT isthe first method to reliably retrieve a number of different objects from agranular environment, doing so on real hardware and with integrated tactilesensing. Videos and additional information can be found athttps://jxu.ai/geotact.</description><author>Jingxi Xu, Yinsen Jia, Dongxiao Yang, Patrick Meng, Xinyue Zhu, Zihan Guo, Shuran Song, Matei Ciocarlie</author><pubDate>Wed, 21 Feb 2024 17:31:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04536v2</guid></item><item><title>Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2402.13950v1</link><description>Large language models (LLMs) have been shown to perform better when asked toreason step-by-step before answering a question. However, it is unclear to whatdegree the model's final answer is faithful to the stated reasoning steps. Inthis paper, we perform a causal mediation analysis on twelve LLMs to examinehow intermediate reasoning steps generated by the LLM influence the finaloutcome and find that LLMs do not reliably use their intermediate reasoningsteps when generating an answer. To address this issue, we introduce FRODO, aframework to tailor small-sized LMs to generate correct reasoning steps androbustly reason over these steps. FRODO consists of an inference module thatlearns to generate correct reasoning steps using an implicit causal rewardfunction and a reasoning module that learns to faithfully reason over theseintermediate inferences using a counterfactual and causal preference objective.Our experiments show that FRODO significantly outperforms four competitivebaselines. Furthermore, FRODO improves the robustness and generalizationability of the reasoning LM, yielding higher performance on out-of-distributiontest sets. Finally, we find that FRODO's rationales are more faithful to itsfinal answer predictions than standard supervised fine-tuning.</description><author>Debjit Paul, Robert West, Antoine Bosselut, Boi Faltings</author><pubDate>Wed, 21 Feb 2024 17:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13950v1</guid></item><item><title>AttackGNN: Red-Teaming GNNs in Hardware Security Using Reinforcement Learning</title><link>http://arxiv.org/abs/2402.13946v1</link><description>Machine learning has shown great promise in addressing several criticalhardware security problems. In particular, researchers have developed novelgraph neural network (GNN)-based techniques for detecting intellectual property(IP) piracy, detecting hardware Trojans (HTs), and reverse engineeringcircuits, to name a few. These techniques have demonstrated outstandingaccuracy and have received much attention in the community. However, sincethese techniques are used for security applications, it is imperative toevaluate them thoroughly and ensure they are robust and do not compromise thesecurity of integrated circuits. In this work, we propose AttackGNN, the first red-team attack on GNN-basedtechniques in hardware security. To this end, we devise a novel reinforcementlearning (RL) agent that generates adversarial examples, i.e., circuits,against the GNN-based techniques. We overcome three challenges related toeffectiveness, scalability, and generality to devise a potent RL agent. Wetarget five GNN-based techniques for four crucial classes of problems inhardware security: IP piracy, detecting/localizing HTs, reverse engineering,and hardware obfuscation. Through our approach, we craft circuits that fool allGNNs considered in this work. For instance, to evade IP piracy detection, wegenerate adversarial pirated circuits that fool the GNN-based defense intoclassifying our crafted circuits as not pirated. For attacking HT localizationGNN, our attack generates HT-infested circuits that fool the defense on alltested circuits. We obtain a similar 100% success rate against GNNs for allclasses of problems.</description><author>Vasudev Gohil, Satwik Patnaik, Dileep Kalathil, Jeyavijayan Rajendran</author><pubDate>Wed, 21 Feb 2024 17:18:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13946v1</guid></item><item><title>Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty in Scientific Machine Learning</title><link>http://arxiv.org/abs/2402.13945v1</link><description>This paper investigates the use of probabilistic neural networks (PNNs) tomodel aleatoric uncertainty, which refers to the inherent variability in theinput-output relationships of a system, often characterized by unequal varianceor heteroscedasticity. Unlike traditional neural networks that producedeterministic outputs, PNNs generate probability distributions for the targetvariable, allowing the determination of both predicted means and intervals inregression scenarios. Contributions of this paper include the development of aprobabilistic distance metric to optimize PNN architecture, and the deploymentof PNNs in controlled data sets as well as a practical material science caseinvolving fiber-reinforced composites. The findings confirm that PNNseffectively model aleatoric uncertainty, proving to be more appropriate thanthe commonly employed Gaussian process regression for this purpose.Specifically, in a real-world scientific machine learning context, PNNs yieldremarkably accurate output mean estimates with R-squared scores approaching0.97, and their predicted intervals exhibit a high correlation coefficient ofnearly 0.80, closely matching observed data intervals. Hence, this researchcontributes to the ongoing exploration of leveraging the sophisticatedrepresentational capacity of neural networks to delineate complex input-outputrelationships in scientific problems.</description><author>Farhad Pourkamali-Anaraki, Jamal F. Husseini, Scott E. Stapleton</author><pubDate>Wed, 21 Feb 2024 17:15:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13945v1</guid></item><item><title>The ODE Method for Asymptotic Statistics in Stochastic Approximation and Reinforcement Learning</title><link>http://arxiv.org/abs/2110.14427v4</link><description>The paper concerns the stochastic approximation recursion, \[ \theta_{n+1}=\theta_n + \alpha_{n + 1} f(\theta_n, \Phi_{n+1}) \,,\quad n\ge 0, \] where the {\em estimates} $\theta_n\in\Re^d$ and $ \{\Phi_n \}$ is a Markov chain on a general state space. In addition to standardLipschitz assumptions and conditions on the vanishing step-size sequence, it isassumed that the associated \textit{mean flow} $ \tfrac{d}{dt} \vartheta_t =\bar{f}(\vartheta_t)$, is globally asymptotically stable with stationary pointdenoted $\theta^*$, where $\bar{f}(\theta)=\text{ E}[f(\theta,\Phi)]$ with$\Phi$ having the stationary distribution of the chain. The main results areestablished under additional conditions on the mean flow and a version of theDonsker-Varadhan Lyapunov drift condition known as (DV3) for the chain: (i) An appropriate Lyapunov function is constructed that implies convergenceof the estimates in $L_4$. (ii) A functional CLT is established, as well as the usual one-dimensionalCLT for the normalized error. Moment bounds combined with the CLT implyconvergence of the normalized covariance $\text{ E} [ z_n z_n^T ]$ to theasymptotic covariance $\Sigma^\Theta$ in the CLT, where $z_n=(\theta_n-\theta^*)/\sqrt{\alpha_n}$. (iii) The CLT holds for the normalized version $z^{\text{ PR}}_n$ of theaveraged parameters $\theta^{\text{ PR}}_n$, subject to standard assumptions onthe step-size. Moreover, the normalized covariance of both $\theta^{\text{PR}}_n$ and $z^{\text{ PR}}_n$ converge to $\Sigma^{\text{ PR}}$, the minimalcovariance of Polyak and Ruppert. (iv)} An example is given where $f$ and $\bar{f}$ are linear in $\theta$, andthe Markov chain is geometrically ergodic but does not satisfy (DV3). While thealgorithm is convergent, the second moment of $\theta_n$ is unbounded and infact diverges.</description><author>Vivek Borkar, Shuhang Chen, Adithya Devraj, Ioannis Kontoyiannis, Sean Meyn</author><pubDate>Wed, 21 Feb 2024 17:11:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.14427v4</guid></item><item><title>Verifying message-passing neural networks via topology-based bounds tightening</title><link>http://arxiv.org/abs/2402.13937v1</link><description>Since graph neural networks (GNNs) are often vulnerable to attack, we need toknow when we can trust them. We develop a computationally effective approachtowards providing robust certificates for message-passing neural networks(MPNNs) using a Rectified Linear Unit (ReLU) activation function. Because ourwork builds on mixed-integer optimization, it encodes a wide variety ofsubproblems, for example it admits (i) both adding and removing edges, (ii)both global and local budgets, and (iii) both topological perturbations andfeature modifications. Our key technology, topology-based bounds tightening,uses graph structure to tighten bounds. We also experiment with aggressivebounds tightening to dynamically change the optimization constraints bytightening variable bounds. To demonstrate the effectiveness of thesestrategies, we implement an extension to the open-source branch-and-cut solverSCIP. We test on both node and graph classification problems and considertopological attacks that both add and remove edges.</description><author>Christopher Hojny, Shiqiang Zhang, Juan S. Campos, Ruth Misener</author><pubDate>Wed, 21 Feb 2024 17:05:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13937v1</guid></item><item><title>Distinctive Image Captioning: Leveraging Ground Truth Captions in CLIP Guided Reinforcement Learning</title><link>http://arxiv.org/abs/2402.13936v1</link><description>Training image captioning models using teacher forcing results in verygeneric samples, whereas more distinctive captions can be very useful inretrieval applications or to produce alternative texts describing images foraccessibility. Reinforcement Learning (RL) allows to use cross-modal retrievalsimilarity score between the generated caption and the input image as reward toguide the training, leading to more distinctive captions. Recent studies showthat pre-trained cross-modal retrieval models can be used to provide thisreward, completely eliminating the need for reference captions. However, weargue in this paper that Ground Truth (GT) captions can still be useful in thisRL framework. We propose a new image captioning model training strategy thatmakes use of GT captions in different ways. Firstly, they can be used to traina simple MLP discriminator that serves as a regularization to prevent rewardhacking and ensures the fluency of generated captions, resulting in a textualGAN setup extended for multimodal inputs. Secondly, they can serve asadditional trajectories in the RL strategy, resulting in a teacher forcing lossweighted by the similarity of the GT to the image. This objective acts as anadditional learning signal grounded to the distribution of the GT captions.Thirdly, they can serve as strong baselines when added to the pool of captionsused to compute the proposed contrastive reward to reduce the variance ofgradient estimate. Experiments on MS-COCO demonstrate the interest of theproposed training strategy to produce highly distinctive captions whilemaintaining high writing quality.</description><author>Antoine Chaffin, Ewa Kijak, Vincent Claveau</author><pubDate>Wed, 21 Feb 2024 17:05:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13936v1</guid></item><item><title>Do Efficient Transformers Really Save Computation?</title><link>http://arxiv.org/abs/2402.13934v1</link><description>As transformer-based language models are trained on increasingly largedatasets and with vast numbers of parameters, finding more efficientalternatives to the standard Transformer has become very valuable. While manyefficient Transformers and Transformer alternatives have been proposed, noneprovide theoretical guarantees that they are a suitable replacement for thestandard Transformer. This makes it challenging to identify when to use aspecific model and what directions to prioritize for further investigation. Inthis paper, we aim to understand the capabilities and limitations of efficientTransformers, specifically the Sparse Transformer and the Linear Transformer.We focus on their reasoning capability as exhibited by Chain-of-Thought (CoT)prompts and follow previous works to model them as Dynamic Programming (DP)problems. Our results show that while these models are expressive enough tosolve general DP tasks, contrary to expectations, they require a model sizethat scales with the problem size. Nonetheless, we identify a class of DPproblems for which these models can be more efficient than the standardTransformer. We confirm our theoretical results through experiments onrepresentative DP tasks, adding to the understanding of efficient Transformers'practical strengths and weaknesses.</description><author>Kai Yang, Jan Ackermann, Zhenyu He, Guhao Feng, Bohang Zhang, Yunzhen Feng, Qiwei Ye, Di He, Liwei Wang</author><pubDate>Wed, 21 Feb 2024 17:00:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13934v1</guid></item><item><title>MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction</title><link>http://arxiv.org/abs/2402.03762v3</link><description>Neural implicit representations have recently been demonstrated in manyfields including Simultaneous Localization And Mapping (SLAM). Current neuralSLAM can achieve ideal results in reconstructing bounded scenes, but thisrelies on the input of RGB-D images. Neural-based SLAM based only on RGB imagesis unable to reconstruct the scale of the scene accurately, and it also suffersfrom scale drift due to errors accumulated during tracking. To overcome theselimitations, we present MoD-SLAM, a monocular dense mapping method that allowsglobal pose optimization and 3D reconstruction in real-time in unboundedscenes. Optimizing scene reconstruction by monocular depth estimation and usingloop closure detection to update camera pose enable detailed and precisereconstruction on large scenes. Compared to previous work, our approach is morerobust, scalable and versatile. Our experiments demonstrate that MoD-SLAM hasmore excellent mapping performance than prior neural SLAM methods, especiallyin large borderless scenes.</description><author>Heng Zhou, Zhetao Guo, Shuhong Liu, Lechen Zhang, Qihao Wang, Yuxiang Ren, Mingrui Li</author><pubDate>Wed, 21 Feb 2024 17:00:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03762v3</guid></item><item><title>Tumor segmentation on whole slide images: training or prompting?</title><link>http://arxiv.org/abs/2402.13932v1</link><description>Tumor segmentation stands as a pivotal task in cancer diagnosis. Given theimmense dimensions of whole slide images (WSI) in histology, deep learningapproaches for WSI classification mainly operate at patch-wise orsuperpixel-wise level. However, these solutions often struggle to captureglobal WSI information and cannot directly generate the binary mask.Downsampling the WSI and performing semantic segmentation is another possibleapproach. While this method offers computational efficiency, it necessitates alarge amount of annotated data since resolution reduction may lead toinformation loss. Visual prompting is a novel paradigm that allows the model toperform new tasks by making subtle modifications to the input space, ratherthan adapting the model itself. Such approach has demonstrated promisingresults on many computer vision tasks. In this paper, we show the efficacy ofvisual prompting in the context of tumor segmentation for three distinctorgans. In comparison to classical methods trained for this specific task, ourfindings reveal that, with appropriate prompt examples, visual prompting canachieve comparable or better performance without extensive fine-tuning.</description><author>Huaqian Wu, Clara Brémond-Martin, Kévin Bouaou, Cédric Clouchoux</author><pubDate>Wed, 21 Feb 2024 16:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13932v1</guid></item><item><title>Speech Self-Supervised Representations Benchmarking: a Case for Larger Probing Heads</title><link>http://arxiv.org/abs/2308.14456v2</link><description>Self-supervised learning (SSL) leverages large datasets of unlabeled speechto reach impressive performance with reduced amounts of annotated data. Thehigh number of proposed approaches fostered the emergence of comprehensivebenchmarks that evaluate their performance on a set of downstream tasksexploring various aspects of the speech signal. However, while the number ofconsidered tasks has been growing, most proposals rely upon a single downstreamarchitecture that maps the frozen SSL representations to the task labels. Thisstudy examines how benchmarking results are affected by changes in the probinghead architecture. Interestingly, we found that altering the downstreamarchitecture structure leads to significant fluctuations in the performanceranking of the evaluated models. Against common practices in speech SSLbenchmarking, we evaluate larger-capacity probing heads, showing their impacton performance, inference costs, generalization and multi-level featureexploitation.</description><author>Salah Zaiem, Youcef Kemiche, Titouan Parcollet, Slim Essid, Mirco Ravanelli</author><pubDate>Wed, 21 Feb 2024 16:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14456v2</guid></item><item><title>Retrieval-Enhanced Contrastive Vision-Text Models</title><link>http://arxiv.org/abs/2306.07196v2</link><description>Contrastive image-text models such as CLIP form the building blocks of manystate-of-the-art systems. While they excel at recognizing common genericconcepts, they still struggle on fine-grained entities which are rare, or evenabsent from the pre-training dataset. Hence, a key ingredient to their successhas been the use of large-scale curated pre-training data aiming at expandingthe set of concepts that they can memorize during the pre-training stage. Inthis work, we explore an alternative to encoding fine-grained knowledgedirectly into the model's parameters: we instead train the model to retrievethis knowledge from an external memory. Specifically, we propose to equipexisting vision-text models with the ability to refine their embedding withcross-modal retrieved information from a memory at inference time, whichgreatly improves their zero-shot predictions. Remarkably, we show that this canbe done with a light-weight, single-layer, fusion transformer on top of afrozen CLIP. Our experiments validate that our retrieval-enhanced contrastive(RECO) training improves CLIP performance substantially on several challengingfine-grained tasks: for example +10.9 on Stanford Cars, +10.2 on CUB-2011 and+7.3 on the recent OVEN benchmark, where we even outperform the fine-tunedmodels on unseen classes.</description><author>Ahmet Iscen, Mathilde Caron, Alireza Fathi, Cordelia Schmid</author><pubDate>Wed, 21 Feb 2024 16:55:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07196v2</guid></item><item><title>Evaluating Gender Bias of Pre-trained Language Models in Natural Language Inference by Considering All Labels</title><link>http://arxiv.org/abs/2309.09697v2</link><description>Discriminatory gender biases have been found in Pre-trained Language Models(PLMs) for multiple languages. In Natural Language Inference (NLI), existingbias evaluation methods have focused on the prediction results of a specificlabel out of three labels, such as neutral. However, such evaluation methodscan be inaccurate since unique biased inferences are associated with uniqueprediction labels. Addressing this limitation, we propose a bias evaluationmethod for PLMs that considers all the three labels of NLI task. We createthree evaluation data groups that represent different types of biases. Then, wedefine a bias measure based on the corresponding label output of each datagroup. In the experiments, we introduce a meta-evaluation technique for NLIbias measures and use it to confirm that our bias measure can distinguishbiased, incorrect inferences from non-biased incorrect inferences better thanthe baseline, resulting in a more accurate bias evaluation. As we create thedatasets in English, Japanese, and Chinese, we also validate the compatibilityof our bias measure across multiple languages. Lastly, we observe the biastendencies in PLMs of each language. To our knowledge, we are the first toconstruct evaluation datasets and measure PLMs' bias from NLI in Japanese andChinese.</description><author>Panatchakorn Anantaprayoon, Masahiro Kaneko, Naoaki Okazaki</author><pubDate>Wed, 21 Feb 2024 16:54:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09697v2</guid></item><item><title>Hidden yet quantifiable: A lower bound for confounding strength using randomized trials</title><link>http://arxiv.org/abs/2312.03871v2</link><description>In the era of fast-paced precision medicine, observational studies play amajor role in properly evaluating new treatments in clinical practice. Yet,unobserved confounding can significantly compromise causal conclusions drawnfrom non-randomized data. We propose a novel strategy that leverages randomizedtrials to quantify unobserved confounding. First, we design a statistical testto detect unobserved confounding with strength above a given threshold. Then,we use the test to estimate an asymptotically valid lower bound on theunobserved confounding strength. We evaluate the power and validity of ourstatistical test on several synthetic and semi-synthetic datasets. Further, weshow how our lower bound can correctly identify the absence and presence ofunobserved confounding in a real-world setting.</description><author>Piersilvio De Bartolomeis, Javier Abad, Konstantin Donhauser, Fanny Yang</author><pubDate>Wed, 21 Feb 2024 16:53:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03871v2</guid></item><item><title>InstructIE: A Bilingual Instruction-based Information Extraction Dataset</title><link>http://arxiv.org/abs/2305.11527v2</link><description>Traditional information extraction (IE) methodologies, constrained bypre-defined classes and static training paradigms, often falter inadaptability, especially in the dynamic world. To bridge this gap, we explorean instruction-based IE paradigm in this paper, leveraging the substantialcross-task generalization capabilities of Large Language Models (LLMs). Weobserve that most existing IE datasets tend to be overly redundant in theirlabel sets, which leads to the inclusion of numerous labels not directlyrelevant to the extraction content when constructing instructions. To tacklethis issue, we introduce a bilingual theme-centric IE instruction dataset(Chinese and English), InstructIE, and for the first time, incorporate a themescheme design that effectively simplifies the label structure. Furthermore, wedevelop an innovative framework named KG2Instruction, which is specificallydesigned for the automatic generation of such datasets. Experimentalevaluations based on InstructIE reveal that while current models show promisein Instruction-based IE tasks, opportunities for their potential optimizationalso emerge. The dataset is available athttps://huggingface.co/datasets/zjunlp/InstructIE.</description><author>Honghao Gui, Shuofei Qiao, Jintian Zhang, Hongbin Ye, Mengshu Sun, Lei Liang, Huajun Chen, Ningyu Zhang</author><pubDate>Wed, 21 Feb 2024 16:52:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11527v2</guid></item><item><title>MeMOTR: Long-Term Memory-Augmented Transformer for Multi-Object Tracking</title><link>http://arxiv.org/abs/2307.15700v3</link><description>As a video task, Multiple Object Tracking (MOT) is expected to capturetemporal information of targets effectively. Unfortunately, most existingmethods only explicitly exploit the object features between adjacent frames,while lacking the capacity to model long-term temporal information. In thispaper, we propose MeMOTR, a long-term memory-augmented Transformer formulti-object tracking. Our method is able to make the same object's trackembedding more stable and distinguishable by leveraging long-term memoryinjection with a customized memory-attention layer. This significantly improvesthe target association ability of our model. Experimental results on DanceTrackshow that MeMOTR impressively surpasses the state-of-the-art method by 7.9% and13.0% on HOTA and AssA metrics, respectively. Furthermore, our model alsooutperforms other Transformer-based methods on association performance on MOT17and generalizes well on BDD100K. Code is available athttps://github.com/MCG-NJU/MeMOTR.</description><author>Ruopeng Gao, Limin Wang</author><pubDate>Wed, 21 Feb 2024 16:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15700v3</guid></item><item><title>Enhancing Reinforcement Learning Agents with Local Guides</title><link>http://arxiv.org/abs/2402.13930v1</link><description>This paper addresses the problem of integrating local guide policies into aReinforcement Learning agent. For this, we show how to adapt existingalgorithms to this setting before introducing a novel algorithm based on anoisy policy-switching procedure. This approach builds on a proper ApproximatePolicy Evaluation (APE) scheme to provide a perturbation that carefully leadsthe local guides towards better actions. We evaluated our method on a set ofclassical Reinforcement Learning problems, including safety-critical systemswhere the agent cannot enter some areas at the risk of triggering catastrophicconsequences. In all the proposed environments, our agent proved to beefficient at leveraging those policies to improve the performance of anyAPE-based Reinforcement Learning algorithm, especially in its first learningstages.</description><author>Paul Daoudi, Bogdan Robu, Christophe Prieur, Ludovic Dos Santos, Merwan Barlier</author><pubDate>Wed, 21 Feb 2024 16:52:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13930v1</guid></item><item><title>SDXL-Lightning: Progressive Adversarial Diffusion Distillation</title><link>http://arxiv.org/abs/2402.13929v1</link><description>We propose a diffusion distillation method that achieves new state-of-the-artin one-step/few-step 1024px text-to-image generation based on SDXL. Our methodcombines progressive and adversarial distillation to achieve a balance betweenquality and mode coverage. In this paper, we discuss the theoretical analysis,discriminator design, model formulation, and training techniques. Weopen-source our distilled SDXL-Lightning models both as LoRA and full UNetweights.</description><author>Shanchuan Lin, Anran Wang, Xiao Yang</author><pubDate>Wed, 21 Feb 2024 16:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13929v1</guid></item><item><title>The Delusional Hedge Algorithm as a Model of Human Learning from Diverse Opinions</title><link>http://arxiv.org/abs/2402.13927v1</link><description>Whereas cognitive models of learning often assume direct experience with boththe features of an event and with a true label or outcome, much of everydaylearning arises from hearing the opinions of others, without direct access toeither the experience or the ground truth outcome. We consider how people canlearn which opinions to trust in such scenarios by extending the hedgealgorithm: a classic solution for learning from diverse information sources. Wefirst introduce a semi-supervised variant we call the delusional hedge capableof learning from both supervised and unsupervised experiences. In twoexperiments, we examine the alignment between human judgments and predictionsfrom the standard hedge, the delusional hedge, and a heuristic baseline model.Results indicate that humans effectively incorporate both labeled and unlabeledinformation in a manner consistent with the delusional hedge algorithm --suggesting that human learners not only gauge the accuracy of informationsources but also their consistency with other reliable sources. The findingsadvance our understanding of human learning from diverse opinions, withimplications for the development of algorithms that better capture how peoplelearn to weigh conflicting information sources.</description><author>Yun-Shiuan Chuang, Jerry Zhu, Timothy T. Rogers</author><pubDate>Wed, 21 Feb 2024 16:48:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13927v1</guid></item><item><title>Large Language Models are Vulnerable to Bait-and-Switch Attacks for Generating Harmful Content</title><link>http://arxiv.org/abs/2402.13926v1</link><description>The risks derived from large language models (LLMs) generating deceptive anddamaging content have been the subject of considerable research, but even safegenerations can lead to problematic downstream impacts. In our study, we shiftthe focus to how even safe text coming from LLMs can be easily turned intopotentially dangerous content through Bait-and-Switch attacks. In such attacks,the user first prompts LLMs with safe questions and then employs a simplefind-and-replace post-hoc technique to manipulate the outputs into harmfulnarratives. The alarming efficacy of this approach in generating toxic contenthighlights a significant challenge in developing reliable safety guardrails forLLMs. In particular, we stress that focusing on the safety of the verbatim LLMoutputs is insufficient and that we also need to consider post-hoctransformations.</description><author>Federico Bianchi, James Zou</author><pubDate>Wed, 21 Feb 2024 16:46:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13926v1</guid></item><item><title>Dual-Activated Lightweight Attention ResNet50 for Automatic Histopathology Breast Cancer Image Classification</title><link>http://arxiv.org/abs/2308.13150v7</link><description>Automatic breast cancer classification in histopathology images is crucialfor precise diagnosis and treatment planning. Recently, classificationapproaches based on the ResNet architecture have gained popularity forsignificantly improving accuracy by using skip connections to mitigatevanishing gradient problems, thereby integrating low-level and high-levelfeature information. Nevertheless, the conventional ResNet architecture faceschallenges such as data imbalance and limited interpretability, necessitatingcross-domain knowledge and collaboration among medical experts. This studyeffectively addresses these challenges by introducing a novel method for breastcancer classification, the Dual-Activated Lightweight Attention ResNet50(DALAResNet50). It integrates a pre-trained ResNet50 model with a lightweightattention mechanism, embedding an attention module in the fourth layer ofResNet50 and incorporating two fully connected layers with LeakyReLU and ReLUactivation functions to enhance feature learning capabilities. The DALAResNet50method was tested on breast cancer histopathology images from the BreakHisDatabase across magnification factors of 40X, 100X, 200X, and 400X, achievingaccuracies of 98.5%, 98.7%, 97.9%, and 94.3%, respectively. It was alsocompared with established deep learning models such as SEResNet50, DenseNet121,VGG16, VGG16Inception, ViT, Swin-Transformer, Dinov2_Vitb14, and ResNet50. Theresults demonstrate that DALAResNet50 surpasses these models in precision,accuracy, recall, F1 score, and GMean, proving its robustness and applicabilityacross various magnifications and handling imbalanced breast cancer datasets.</description><author>Suxing Liu, Anusha Achuthan, Ali Fawzi, Galib Muhammad Shahriar Himel</author><pubDate>Wed, 21 Feb 2024 16:36:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13150v7</guid></item><item><title>mCL-NER: Cross-Lingual Named Entity Recognition via Multi-view Contrastive Learning</title><link>http://arxiv.org/abs/2308.09073v2</link><description>Cross-lingual named entity recognition (CrossNER) faces challenges stemmingfrom uneven performance due to the scarcity of multilingual corpora, especiallyfor non-English data. While prior efforts mainly focus on data-driven transfermethods, a significant aspect that has not been fully explored is aligning bothsemantic and token-level representations across diverse languages. In thispaper, we propose Multi-view Contrastive Learning for Cross-lingual NamedEntity Recognition (mCL-NER). Specifically, we reframe the CrossNER task into aproblem of recognizing relationships between pairs of tokens. This approachtaps into the inherent contextual nuances of token-to-token connections withinentities, allowing us to align representations across different languages. Amulti-view contrastive learning framework is introduced to encompass semanticcontrasts between source, codeswitched, and target sentences, as well ascontrasts among token-to-token relations. By enforcing agreement within bothsemantic and relational spaces, we minimize the gap between source sentencesand their counterparts of both codeswitched and target sentences. Thisalignment extends to the relationships between diverse tokens, enhancing theprojection of entities across languages. We further augment CrossNER bycombining self-training with labeled source data and unlabeled target data. Ourexperiments on the XTREME benchmark, spanning 40 languages, demonstrate thesuperiority of mCL-NER over prior data-driven and model-based approaches. Itachieves a substantial increase of nearly +2.0 $F_1$ scores across a broadspectrum and establishes itself as the new state-of-the-art performer.</description><author>Ying Mo, Jian Yang, Jiahao Liu, Qifan Wang, Ruoyu Chen, Jingang Wang, Zhoujun Li</author><pubDate>Wed, 21 Feb 2024 16:35:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09073v2</guid></item><item><title>Graph Contrastive Learning with Cohesive Subgraph Awareness</title><link>http://arxiv.org/abs/2401.17580v2</link><description>Graph contrastive learning (GCL) has emerged as a state-of-the-art strategyfor learning representations of diverse graphs including social and biomedicalnetworks. GCL widely uses stochastic graph topology augmentation, such asuniform node dropping, to generate augmented graphs. However, such stochasticaugmentations may severely damage the intrinsic properties of a graph anddeteriorate the following representation learning process. We argue thatincorporating an awareness of cohesive subgraphs during the graph augmentationand learning processes has the potential to enhance GCL performance. To thisend, we propose a novel unified framework called CTAug, to seamlessly integratecohesion awareness into various existing GCL mechanisms. In particular, CTAugcomprises two specialized modules: topology augmentation enhancement and graphlearning enhancement. The former module generates augmented graphs thatcarefully preserve cohesion properties, while the latter module bolsters thegraph encoder's ability to discern subgraph patterns. Theoretical analysisshows that CTAug can strictly improve existing GCL mechanisms. Empiricalexperiments verify that CTAug can achieve state-of-the-art performance forgraph representation learning, especially for graphs with high degrees. Thecode is available at https://doi.org/10.5281/zenodo.10594093, orhttps://github.com/wuyucheng2002/CTAug.</description><author>Yucheng Wu, Leye Wang, Xiao Han, Han-Jia Ye</author><pubDate>Wed, 21 Feb 2024 16:33:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17580v2</guid></item><item><title>SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization</title><link>http://arxiv.org/abs/2402.13919v1</link><description>Large Language Models (LLMs) such as GPT and Llama have demonstratedsignificant achievements in summarization tasks but struggle with factualinaccuracies, a critical issue in clinical NLP applications where errors couldlead to serious consequences. To counter the high costs and limitedavailability of expert-annotated data for factual alignment, this studyintroduces an innovative pipeline that utilizes GPT-3.5 and GPT-4 to generatehigh-quality feedback aimed at enhancing factual consistency in clinical notesummarization. Our research primarily focuses on edit feedback, mirroring thepractical scenario in which medical professionals refine AI system outputswithout the need for additional annotations. Despite GPT's proven expertise invarious clinical NLP tasks, such as the Medical Licensing Examination, there isscant research on its capacity to deliver expert-level edit feedback forimproving weaker LMs or LLMs generation quality. This work leverages GPT'sadvanced capabilities in clinical NLP to offer expert-level edit feedback.Through the use of two distinct alignment algorithms (DPO and SALT) based onGPT edit feedback, our goal is to reduce hallucinations and align closely withmedical facts, endeavoring to narrow the divide between AI-generated contentand factual accuracy. This highlights the substantial potential of GPT edits inenhancing the alignment of clinical factuality.</description><author>Prakamya Mishra, Zonghai Yao, Parth Vashisht, Feiyun Ouyang, Beining Wang, Vidhi Dhaval Mody, Hong Yu</author><pubDate>Wed, 21 Feb 2024 16:33:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13919v1</guid></item><item><title>BenchCloudVision: A Benchmark Analysis of Deep Learning Approaches for Cloud Detection and Segmentation in Remote Sensing Imagery</title><link>http://arxiv.org/abs/2402.13918v1</link><description>Satellites equipped with optical sensors capture high-resolution imagery,providing valuable insights into various environmental phenomena. In recentyears, there has been a surge of research focused on addressing some challengesin remote sensing, ranging from water detection in diverse landscapes to thesegmentation of mountainous and terrains. Ongoing investigations goals toenhance the precision and efficiency of satellite imagery analysis. Especially,there is a growing emphasis on developing methodologies for accurate water bodydetection, snow and clouds, important for environmental monitoring, resourcemanagement, and disaster response. Within this context, this paper focus on thecloud segmentation from remote sensing imagery. Accurate remote sensing dataanalysis can be challenging due to the presence of clouds in opticalsensor-based applications. The quality of resulting products such asapplications and research is directly impacted by cloud detection, which playsa key role in the remote sensing data processing pipeline. This paper examinesseven cutting-edge semantic segmentation and detection algorithms applied toclouds identification, conducting a benchmark analysis to evaluate theirarchitectural approaches and identify the most performing ones. To increase themodel's adaptability, critical elements including the type of imagery and theamount of spectral bands used during training are analyzed. Additionally, thisresearch tries to produce machine learning algorithms that can perform cloudsegmentation using only a few spectral bands, including RGB and RGBN-IRcombinations. The model's flexibility for a variety of applications and userscenarios is assessed by using imagery from Sentinel-2 and Landsat-8 asdatasets. This benchmark can be reproduced using the material from this githublink: \url{https://github.com/toelt-llc/cloud\_segmentation\_comparative}.</description><author>Loddo Fabio, Dario Piga, Michelucci Umberto, El Ghazouali Safouane</author><pubDate>Wed, 21 Feb 2024 16:32:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13918v1</guid></item><item><title>What Linguistic Features and Languages are Important in LLM Translation?</title><link>http://arxiv.org/abs/2402.13917v1</link><description>Large Language Models (LLMs) demonstrate strong capability across multipletasks, including machine translation. Our study focuses on evaluating Llama2'smachine translation capabilities and exploring how translation depends onlanguages in its training data. Our experiments show that the 7B Llama2 modelyields above 10 BLEU score for all languages it has seen, but not always forlanguages it has not seen. Most gains for those unseen languages are observedthe most with the model scale compared to using chat versions or adding shotcount. Furthermore, our linguistic distance analysis reveals that syntacticsimilarity is not always the primary linguistic factor in determiningtranslation quality. Interestingly, we discovered that under specificcircumstances, some languages, despite having significantly less training datathan English, exhibit strong correlations comparable to English. Ourdiscoveries here give new perspectives for the current landscape of LLMs,raising the possibility that LLMs centered around languages other than Englishmay offer a more effective foundation for a multilingual model.</description><author>Ryandito Diandaru, Lucky Susanto, Zilu Tang, Ayu Purwarianti, Derry Wijaya</author><pubDate>Wed, 21 Feb 2024 16:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13917v1</guid></item><item><title>Bias correction of wind power forecasts with SCADA data and continuous learning</title><link>http://arxiv.org/abs/2402.13916v1</link><description>Wind energy plays a critical role in the transition towards renewable energysources. However, the uncertainty and variability of wind can impede its fullpotential and the necessary growth of wind power capacity. To mitigate thesechallenges, wind power forecasting methods are employed for applications inpower management, energy trading, or maintenance scheduling. In this work, wepresent, evaluate, and compare four machine learning-based wind powerforecasting models. Our models correct and improve 48-hour forecasts extractedfrom a numerical weather prediction (NWP) model. The models are evaluated ondatasets from a wind park comprising 65 wind turbines. The best improvement inforecasting error and mean bias was achieved by a convolutional neural network,reducing the average NRMSE down to 22%, coupled with a significant reduction inmean bias, compared to a NRMSE of 35% from the strongly biased baseline modelusing uncorrected NWP forecasts. Our findings further indicate that changes toneural network architectures play a minor role in affecting the forecastingperformance, and that future research should rather investigate changes in themodel pipeline. Moreover, we introduce a continuous learning strategy, which isshown to achieve the highest forecasting performance improvements when new datais made available.</description><author>Stefan Jonas, Kevin Winter, Bernhard Brodbeck, Angela Meyer</author><pubDate>Wed, 21 Feb 2024 16:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13916v1</guid></item><item><title>Explain to Question not to Justify</title><link>http://arxiv.org/abs/2402.13914v1</link><description>Explainable Artificial Intelligence (XAI) is a young but very promising fieldof research. Unfortunately, the progress in this field is currently slowed downby divergent and incompatible goals. In this paper, we separate various threadstangled within the area of XAI into two complementary cultures ofhuman/value-oriented explanations (BLUE XAI) and model/validation-orientedexplanations (RED XAI). We also argue that the area of RED XAI is currentlyunder-explored and hides great opportunities and potential for importantresearch necessary to ensure the safety of AI systems. We conclude this paperby presenting promising challenges in this area.</description><author>Przemyslaw Biecek, Wojciech Samek</author><pubDate>Wed, 21 Feb 2024 16:30:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13914v1</guid></item><item><title>Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!</title><link>http://arxiv.org/abs/2402.12343v2</link><description>Large language models (LLMs) need to undergo safety alignment to ensure safeconversations with humans. However, in this work, we introduce aninference-time attack framework, demonstrating that safety alignment can alsounintentionally facilitate harmful outcomes under adversarial manipulation.This framework, named Emulated Disalignment (ED), adversely combines a pair ofopen-source pre-trained and safety-aligned language models in the output spaceto produce a harmful language model without additional training. Ourexperiments with ED across three datasets and four model families (Llama-1,Llama-2, Mistral, and Alpaca) show that ED doubles the harmfulness ofpre-trained models and outperforms strong baselines, achieving the highestharmful rate in 43 out of 48 evaluation subsets by a large margin. Crucially,our findings highlight the importance of reevaluating the practice ofopen-sourcing language models even after safety alignment.</description><author>Zhanhui Zhou, Jie Liu, Zhichen Dong, Jiaheng Liu, Chao Yang, Wanli Ouyang, Yu Qiao</author><pubDate>Wed, 21 Feb 2024 16:29:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12343v2</guid></item><item><title>Replication Study: Enhancing Hydrological Modeling with Physics-Guided Machine Learning</title><link>http://arxiv.org/abs/2402.13911v1</link><description>Current hydrological modeling methods combine data-driven Machine Learning(ML) algorithms and traditional physics-based models to address theirrespective limitations incorrect parameter estimates from rigid physics-basedmodels and the neglect of physical process constraints by ML algorithms.Despite the accuracy of ML in outcome prediction, the integration of scientificknowledge is crucial for reliable predictions. This study introduces a PhysicsInformed Machine Learning (PIML) model, which merges the process understandingof conceptual hydrological models with the predictive efficiency of MLalgorithms. Applied to the Anandapur sub-catchment, the PIML model demonstratessuperior performance in forecasting monthly streamflow and actualevapotranspiration over both standalone conceptual models and ML algorithms,ensuring physical consistency of the outputs. This study replicates themethodologies of Bhasme, P., Vagadiya, J., &amp; Bhatia, U. (2022) from theirpivotal work on Physics Informed Machine Learning for hydrological processes,utilizing their shared code and datasets to further explore the predictivecapabilities in hydrological modeling.</description><author>Mostafa Esmaeilzadeh, Melika Amirzadeh</author><pubDate>Wed, 21 Feb 2024 16:26:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13911v1</guid></item><item><title>Drive&amp;Segment: Unsupervised Semantic Segmentation of Urban Scenes via Cross-modal Distillation</title><link>http://arxiv.org/abs/2203.11160v2</link><description>This work investigates learning pixel-wise semantic image segmentation inurban scenes without any manual annotation, just from the raw non-curated datacollected by cars which, equipped with cameras and LiDAR sensors, drive arounda city. Our contributions are threefold. First, we propose a novel method forcross-modal unsupervised learning of semantic image segmentation by leveragingsynchronized LiDAR and image data. The key ingredient of our method is the useof an object proposal module that analyzes the LiDAR point cloud to obtainproposals for spatially consistent objects. Second, we show that these 3Dobject proposals can be aligned with the input images and reliably clusteredinto semantically meaningful pseudo-classes. Finally, we develop a cross-modaldistillation approach that leverages image data partially annotated with theresulting pseudo-classes to train a transformer-based model for image semanticsegmentation. We show the generalization capabilities of our method by testingon four different testing datasets (Cityscapes, Dark Zurich, Nighttime Drivingand ACDC) without any finetuning, and demonstrate significant improvementscompared to the current state of the art on this problem. See project webpagehttps://vobecant.github.io/DriveAndSegment/ for the code and more.</description><author>Antonin Vobecky, David Hurych, Oriane Siméoni, Spyros Gidaris, Andrei Bursuc, Patrick Pérez, Josef Sivic</author><pubDate>Wed, 21 Feb 2024 16:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.11160v2</guid></item><item><title>Leveraging Collection-Wide Similarities for Unsupervised Document Structure Extraction</title><link>http://arxiv.org/abs/2402.13906v1</link><description>Document collections of various domains, e.g., legal, medical, or financial,often share some underlying collection-wide structure, which capturesinformation that can aid both human users and structure-aware models. Wepropose to identify the typical structure of document within a collection,which requires to capture recurring topics across the collection, whileabstracting over arbitrary header paraphrases, and ground each topic torespective document locations. These requirements pose several challenges:headers that mark recurring topics frequently differ in phrasing, certainsection headers are unique to individual documents and do not reflect thetypical structure, and the order of topics can vary between documents.Subsequently, we develop an unsupervised graph-based method which leveragesboth inter- and intra-document similarities, to extract the underlyingcollection-wide structure. Our evaluations on three diverse domains in bothEnglish and Hebrew indicate that our method extracts meaningful collection-widestructure, and we hope that future work will leverage our method formulti-document applications and structure-aware models.</description><author>Gili Lior, Yoav Goldberg, Gabriel Stanovsky</author><pubDate>Wed, 21 Feb 2024 16:22:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13906v1</guid></item><item><title>Double Robust Bayesian Inference on Average Treatment Effects</title><link>http://arxiv.org/abs/2211.16298v4</link><description>We propose a double robust Bayesian inference procedure on the averagetreatment effect (ATE) under unconfoundedness. Our robust Bayesian approachinvolves two important modifications: first, we adjust the prior distributionsof the conditional mean function; second, we correct the posterior distributionof the resulting ATE. Both adjustments make use of pilot estimators motivatedby the semiparametric influence function for ATE estimation. We proveasymptotic equivalence of our Bayesian procedure and efficient frequentist ATEestimators by establishing a new semiparametric Bernstein-von Mises theoremunder double robustness; i.e., the lack of smoothness of conditional meanfunctions can be compensated by high regularity of the propensity score andvice versa. Consequently, the resulting Bayesian credible sets form confidenceintervals with asymptotically exact coverage probability. In simulations, ourdouble robust Bayesian procedure leads to significant bias reduction of pointestimation over conventional Bayesian methods and more accurate coverage ofconfidence intervals compared to existing frequentist methods. We illustrateour method in an application to the National Supported Work Demonstration.</description><author>Christoph Breunig, Ruixuan Liu, Zhengfei Yu</author><pubDate>Wed, 21 Feb 2024 16:19:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.16298v4</guid></item><item><title>The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images</title><link>http://arxiv.org/abs/2401.08865v3</link><description>This paper investigates discrepancies in how neural networks learn fromdifferent imaging domains, which are commonly overlooked when adopting computervision techniques from the domain of natural images to other specializeddomains such as medical images. Recent works have found that the generalizationerror of a trained network typically increases with the intrinsic dimension($d_{data}$) of its training set. Yet, the steepness of this relationshipvaries significantly between medical (radiological) and natural imagingdomains, with no existing theoretical explanation. We address this gap inknowledge by establishing and empirically validating a generalization scalinglaw with respect to $d_{data}$, and propose that the substantial scalingdiscrepancy between the two considered domains may be at least partiallyattributed to the higher intrinsic ``label sharpness'' ($K_\mathcal{F}$) ofmedical imaging datasets, a metric which we propose. Next, we demonstrate anadditional benefit of measuring the label sharpness of a training set: it isnegatively correlated with the trained model's adversarial robustness, whichnotably leads to models for medical images having a substantially highervulnerability to adversarial attack. Finally, we extend our $d_{data}$formalism to the related metric of learned representation intrinsic dimension($d_{repr}$), derive a generalization scaling law with respect to $d_{repr}$,and show that $d_{data}$ serves as an upper bound for $d_{repr}$. Ourtheoretical results are supported by thorough experiments with six models andeleven natural and medical imaging datasets over a range of training set sizes.Our findings offer insights into the influence of intrinsic dataset propertieson generalization, representation learning, and robustness in deep neuralnetworks. Code link: https://github.com/mazurowski-lab/intrinsic-properties</description><author>Nicholas Konz, Maciej A. Mazurowski</author><pubDate>Wed, 21 Feb 2024 16:17:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08865v3</guid></item><item><title>VitalLens: Take A Vital Selfie</title><link>http://arxiv.org/abs/2312.06892v3</link><description>This report introduces VitalLens, an app that estimates vital signs such asheart rate and respiration rate from selfie video in real time. VitalLens usesa computer vision model trained on a diverse dataset of video and physiologicalsensor data. We benchmark performance on several diverse datasets, includingVV-Medium, which consists of 289 unique participants. VitalLens outperformsseveral existing methods including POS and MTTS-CAN on all datasets whilemaintaining a fast inference speed. On VV-Medium, VitalLens achieves meanabsolute errors of 0.71 bpm for heart rate estimation, and 0.76 bpm forrespiratory rate estimation.</description><author>Philipp V. Rouast</author><pubDate>Wed, 21 Feb 2024 16:17:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06892v3</guid></item><item><title>Reconstruction of Sound Field through Diffusion Models</title><link>http://arxiv.org/abs/2312.08821v2</link><description>Reconstructing the sound field in a room is an important task for severalapplications, such as sound control and augmented (AR) or virtual reality (VR).In this paper, we propose a data-driven generative model for reconstructing themagnitude of acoustic fields in rooms with a focus on the modal frequencyrange. We introduce, for the first time, the use of a conditional DenoisingDiffusion Probabilistic Model (DDPM) trained in order to reconstruct the soundfield (SF-Diff) over an extended domain. The architecture is devised in orderto be conditioned on a set of limited available measurements at differentfrequencies and generate the sound field in target, unknown, locations. Theresults show that SF-Diff is able to provide accurate reconstructions,outperforming a state-of-the-art baseline based on kernel interpolation.</description><author>Federico Miotello, Luca Comanducci, Mirco Pezzoli, Alberto Bernardini, Fabio Antonacci, Augusto Sarti</author><pubDate>Wed, 21 Feb 2024 16:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08821v2</guid></item><item><title>Calibrating Large Language Models with Sample Consistency</title><link>http://arxiv.org/abs/2402.13904v1</link><description>Accurately gauging the confidence level of Large Language Models' (LLMs)predictions is pivotal for their reliable application. However, LLMs are oftenuncalibrated inherently and elude conventional calibration techniques due totheir proprietary nature and massive scale. In this work, we explore thepotential of deriving confidence from the distribution of multiple randomlysampled model generations, via three measures of consistency. We perform anextensive evaluation across various open and closed-source models on ninereasoning datasets. Results show that consistency-based calibration methodsoutperform existing post-hoc approaches. Meanwhile, we find that factors suchas intermediate explanations, model scaling, and larger sample sizes enhancecalibration, while instruction-tuning makes calibration more difficult.Moreover, confidence scores obtained from consistency have the potential toenhance model performance. Finally, we offer practical guidance on choosingsuitable consistency metrics for calibration, tailored to the characteristicsof various LMs.</description><author>Qing Lyu, Kumar Shridhar, Chaitanya Malaviya, Li Zhang, Yanai Elazar, Niket Tandon, Marianna Apidianaki, Mrinmaya Sachan, Chris Callison-Burch</author><pubDate>Wed, 21 Feb 2024 16:15:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13904v1</guid></item><item><title>Dealing with unbounded gradients in stochastic saddle-point optimization</title><link>http://arxiv.org/abs/2402.13903v1</link><description>We study the performance of stochastic first-order methods for finding saddlepoints of convex-concave functions. A notorious challenge faced by such methodsis that the gradients can grow arbitrarily large during optimization, which mayresult in instability and divergence. In this paper, we propose a simple andeffective regularization technique that stabilizes the iterates and yieldsmeaningful performance guarantees even if the domain and the gradient noisescales linearly with the size of the iterates (and is thus potentiallyunbounded). Besides providing a set of general results, we also apply ouralgorithm to a specific problem in reinforcement learning, where it leads toperformance guarantees for finding near-optimal policies in an average-rewardMDP without prior knowledge of the bias span.</description><author>Gergely Neu, Nneka Okolo</author><pubDate>Wed, 21 Feb 2024 16:13:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13903v1</guid></item><item><title>Non-asymptotic Convergence of Discrete-time Diffusion Models: New Approach and Improved Rate</title><link>http://arxiv.org/abs/2402.13901v1</link><description>The denoising diffusion model emerges recently as a powerful generativetechnique that converts noise into data. Theoretical convergence guarantee hasbeen mainly studied for continuous-time diffusion models, and has been obtainedfor discrete-time diffusion models only for distributions with bounded supportin the literature. In this paper, we establish the convergence guarantee forsubstantially larger classes of distributions under discrete-time diffusionmodels and further improve the convergence rate for distributions with boundedsupport. In particular, we first establish the convergence rates for bothsmooth and general (possibly non-smooth) distributions having finite secondmoment. We then specialize our results to a number of interesting classes ofdistributions with explicit parameter dependencies, including distributionswith Lipschitz scores, Gaussian mixture distributions, and distributions withbounded support. We further propose a novel accelerated sampler and show thatit improves the convergence rates of the corresponding regular sampler byorders of magnitude with respect to all system parameters. For distributionswith bounded support, our result improves the dimensional dependence of theprevious convergence rate by orders of magnitude. Our study features a novelanalysis technique that constructs tilting factor representation of theconvergence error and exploits Tweedie's formula for handling Taylor expansionpower terms.</description><author>Yuchen Liang, Peizhong Ju, Yingbin Liang, Ness Shroff</author><pubDate>Wed, 21 Feb 2024 16:11:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13901v1</guid></item><item><title>Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning</title><link>http://arxiv.org/abs/2402.13897v1</link><description>Information retrieval is a rapidly evolving field. However it still facessignificant limitations in the scientific and industrial vast amounts ofinformation, such as semantic divergence and vocabulary gaps in sparseretrieval, low precision and lack of interpretability in semantic search, orhallucination and outdated information in generative models. In this paper, weintroduce a two-block approach to tackle these hurdles for long documents. Thefirst block enhances language understanding in sparse retrieval by queryexpansion to retrieve relevant documents. The second block deepens the resultby providing comprehensive and informative answers to the complex questionusing only the information spread in the long document, enabling bidirectionalengagement. At various stages of the pipeline, intermediate results arepresented to users to facilitate understanding of the system's reasoning. Webelieve this bidirectional approach brings significant advancements in terms oftransparency, logical thinking, and comprehensive understanding in the field ofscientific information retrieval.</description><author>Loïc Rakotoson, Sylvain Massip, Fréjus A. A. Laleye</author><pubDate>Wed, 21 Feb 2024 16:09:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13897v1</guid></item><item><title>Fixing confirmation bias in feature attribution methods via semantic match</title><link>http://arxiv.org/abs/2307.00897v2</link><description>Feature attribution methods have become a staple method to disentangle thecomplex behavior of black box models. Despite their success, some scholars haveargued that such methods suffer from a serious flaw: they do not allow areliable interpretation in terms of human concepts. Simply put, visualizing anarray of feature contributions is not enough for humans to conclude somethingabout a model's internal representations, and confirmation bias can trick usersinto false beliefs about model behavior. We argue that a structured approach isrequired to test whether our hypotheses on the model are confirmed by thefeature attributions. This is what we call the "semantic match" between humanconcepts and (sub-symbolic) explanations. Building on the conceptual frameworkput forward in Cin\`a et al. [2023], we propose a structured approach toevaluate semantic match in practice. We showcase the procedure in a suite ofexperiments spanning tabular and image data, and show how the assessment ofsemantic match can give insight into both desirable (e.g., focusing on anobject relevant for prediction) and undesirable model behaviors (e.g., focusingon a spurious correlation). We couple our experimental results with an analysison the metrics to measure semantic match, and argue that this approachconstitutes the first step towards resolving the issue of confirmation bias inXAI.</description><author>Giovanni Cinà, Daniel Fernandez-Llaneza, Nishant Mishra, Tabea E. Röber, Sandro Pezzelle, Iacer Calixto, Rob Goedhart, Ş. İlker Birbil</author><pubDate>Wed, 21 Feb 2024 16:05:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00897v2</guid></item><item><title>Playing Large Games with Oracles and AI Debate</title><link>http://arxiv.org/abs/2312.04792v3</link><description>We consider regret minimization in repeated games with a very large number ofactions. Such games are inherent in the setting of AI safety via debate, andmore generally games whose actions are language-based. Existing algorithms foronline game playing require per-iteration computation polynomial in the numberof actions, which can be prohibitive for large games. We thus consider oracle-based algorithms, as oracles naturally model accessto AI agents. With oracle access, we characterize when internal and externalregret can be minimized efficiently. We give a novel efficient algorithm forinternal regret minimization whose regret and per-iteration computation dependlogarithmically on the number of actions. We conclude with experiments in the setting of AI Safety via Debate thatshows the benefit of insights from our algorithmic analysis.</description><author>Xinyi Chen, Angelica Chen, Dean Foster, Elad Hazan</author><pubDate>Wed, 21 Feb 2024 16:03:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04792v3</guid></item><item><title>Overcoming Saturation in Density Ratio Estimation by Iterated Regularization</title><link>http://arxiv.org/abs/2402.13891v1</link><description>Estimating the ratio of two probability densities from finitely many samples,is a central task in machine learning and statistics. In this work, we showthat a large class of kernel methods for density ratio estimation suffers fromerror saturation, which prevents algorithms from achieving fast errorconvergence rates on highly regular learning problems. To resolve saturation,we introduce iterated regularization in density ratio estimation to achievefast error rates. Our methods outperform its non-iteratively regularizedversions on benchmarks for density ratio estimation as well as on large-scaleevaluations for importance-weighted ensembling of deep unsupervised domainadaptation models.</description><author>Lukas Gruber, Markus Holzleitner, Johannes Lehner, Sepp Hochreiter, Werner Zellinger</author><pubDate>Wed, 21 Feb 2024 16:02:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13891v1</guid></item><item><title>A unified Bayesian framework for interval hypothesis testing in clinical trials</title><link>http://arxiv.org/abs/2402.13890v1</link><description>The American Statistical Association (ASA) statement on statisticalsignificance and P-values \cite{wasserstein2016asa} cautioned statisticiansagainst making scientific decisions solely on the basis of traditionalP-values. The statement delineated key issues with P-values, including a lackof transparency, an inability to quantify evidence in support of the nullhypothesis, and an inability to measure the size of an effect or the importanceof a result. In this article, we demonstrate that the interval null hypothesisframework (instead of the point null hypothesis framework), when used in tandemwith Bayes factor-based tests, is instrumental in circumnavigating the keyissues of P-values. Further, we note that specifying prior densities for Bayesfactors is challenging and has been a reason for criticism of Bayesianhypothesis testing in existing literature. We address this by adapting Bayesfactors directly based on common test statistics. We demonstrate, throughnumerical experiments and real data examples, that the proposed Bayesianinterval hypothesis testing procedures can be calibrated to ensure frequentisterror control while retaining their inherent interpretability. Finally, weillustrate the improved flexibility and applicability of the proposed methodsby providing coherent frameworks for competitive landscape analysis andend-to-end Bayesian hypothesis tests in the context of reporting clinical trialoutcomes.</description><author>Abhisek Chakraborty, Megan H. Murray, Ilya Lipkovich, Yu Du</author><pubDate>Wed, 21 Feb 2024 16:01:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13890v1</guid></item><item><title>Beyond Probabilities: Unveiling the Misalignment in Evaluating Large Language Models</title><link>http://arxiv.org/abs/2402.13887v1</link><description>Large Language Models (LLMs) have demonstrated remarkable capabilities acrossvarious applications, fundamentally reshaping the landscape of natural languageprocessing (NLP) research. However, recent evaluation frameworks often rely onthe output probabilities of LLMs for predictions, primarily due tocomputational constraints, diverging from real-world LLM usage scenarios. Whilewidely employed, the efficacy of these probability-based evaluation strategiesremains an open research question. This study aims to scrutinize the validityof such probability-based evaluation methods within the context of using LLMsfor Multiple Choice Questions (MCQs), highlighting their inherent limitations.Our empirical investigation reveals that the prevalent probability-basedevaluation method inadequately aligns with generation-based prediction.Furthermore, current evaluation frameworks typically assess LLMs throughpredictive tasks based on output probabilities rather than directly generatingresponses, owing to computational limitations. We illustrate that theseprobability-based approaches do not effectively correspond with generativepredictions. The outcomes of our study can enhance the understanding of LLMevaluation methodologies and provide insights for future research in thisdomain.</description><author>Chenyang Lyu, Minghao Wu, Alham Fikri Aji</author><pubDate>Wed, 21 Feb 2024 15:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13887v1</guid></item><item><title>GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction</title><link>http://arxiv.org/abs/2310.03668v4</link><description>Large Language Models (LLMs) combined with instruction tuning have madesignificant progress when generalizing to unseen tasks. However, they have beenless successful in Information Extraction (IE), lagging behind task-specificmodels. Typically, IE tasks are characterized by complex annotation guidelineswhich describe the task and give examples to humans. Previous attempts toleverage such information have failed, even with the largest models, as theyare not able to follow the guidelines out-of-the-box. In this paper we proposeGoLLIE Guideline-following Large Language Model for IE), a model able toimprove zero-shot results on unseen IE tasks by virtue of being fine-tuned tocomply with annotation guidelines.</description><author>Oscar Sainz, Iker García-Ferrero, Rodrigo Agerri, Oier Lopez de Lacalle, German Rigau, Eneko Agirre</author><pubDate>Wed, 21 Feb 2024 15:51:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03668v4</guid></item><item><title>MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer</title><link>http://arxiv.org/abs/2303.14389v2</link><description>Despite its success in image synthesis, we observe that diffusionprobabilistic models (DPMs) often lack contextual reasoning ability to learnthe relations among object parts in an image, leading to a slow learningprocess. To solve this issue, we propose a Masked Diffusion Transformer (MDT)that introduces a mask latent modeling scheme to explicitly enhance the DPMs'ability to contextual relation learning among object semantic parts in animage. During training, MDT operates in the latent space to mask certaintokens. Then, an asymmetric diffusion transformer is designed to predict maskedtokens from unmasked ones while maintaining the diffusion generation process.Our MDT can reconstruct the full information of an image from its incompletecontextual input, thus enabling it to learn the associated relations amongimage tokens. We further improve MDT with a more efficient macro networkstructure and training strategy, named MDTv2. Experimental results show thatMDTv2 achieves superior image synthesis performance, e.g., a new SOTA FID scoreof 1.58 on the ImageNet dataset, and has more than 10x faster learning speedthan the previous SOTA DiT. The source code is released athttps://github.com/sail-sg/MDT.</description><author>Shanghua Gao, Pan Zhou, Ming-Ming Cheng, Shuicheng Yan</author><pubDate>Wed, 21 Feb 2024 15:45:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14389v2</guid></item><item><title>Accelerating Semi-Asynchronous Federated Learning</title><link>http://arxiv.org/abs/2402.10991v2</link><description>Federated Learning (FL) is a distributed machine learning paradigm thatallows clients to train models on their data while preserving their privacy. FLalgorithms, such as Federated Averaging (FedAvg) and its variants, have beenshown to converge well in many scenarios. However, these methods requireclients to upload their local updates to the server in a synchronous manner,which can be slow and unreliable in realistic FL settings. To address thisissue, researchers have developed asynchronous FL methods that allow clients tocontinue training on their local data using a stale global model. However, mostof these methods simply aggregate all of the received updates withoutconsidering their relative contributions, which can slow down convergence. Inthis paper, we propose a contribution-aware asynchronous FL method that takesinto account the staleness and statistical heterogeneity of the receivedupdates. Our method dynamically adjusts the contribution of each update basedon these factors, which can speed up convergence compared to existing methods.</description><author>Changxin Xu, Yuxin Qiao, Zhanxin Zhou, Fanghao Ni, Jize Xiong</author><pubDate>Wed, 21 Feb 2024 15:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10991v2</guid></item><item><title>Scene Prior Filtering for Depth Map Super-Resolution</title><link>http://arxiv.org/abs/2402.13876v1</link><description>Multi-modal fusion is vital to the success of super-resolution of depthimages. However, commonly used fusion strategies, such as addition andconcatenation, fall short of effectively bridging the modal gap. As a result,guided image filtering methods have been introduced to mitigate this issue.Nevertheless, it is observed that their filter kernels usually encountersignificant texture interference and edge inaccuracy. To tackle these twochallenges, we introduce a Scene Prior Filtering network, SPFNet, whichutilizes the priors surface normal and semantic map from large-scale models.Specifically, we design an All-in-one Prior Propagation that computes thesimilarity between multi-modal scene priors, \textit{i.e.}, RGB, normal,semantic, and depth, to reduce the texture interference. In addition, wepresent a One-to-one Prior Embedding that continuously embeds each single-modalprior into depth using Mutual Guided Filtering, further alleviating the textureinterference while enhancing edges. Our SPFNet has been extensively evaluatedon both real and synthetic datasets, achieving state-of-the-art performance.</description><author>Zhengxue Wang, Zhiqiang Yan, Ming-Hsuan Yang, Jinshan Pan, Jian Yang, Ying Tai, Guangwei Gao</author><pubDate>Wed, 21 Feb 2024 15:35:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13876v1</guid></item><item><title>$\texttt{Se}^2$: $\textit{Se}$quential Example $\textit{Se}$lection for In-Context Learning</title><link>http://arxiv.org/abs/2402.13874v1</link><description>The remarkable capability of large language models (LLMs) for in-contextlearning (ICL) needs to be activated by demonstration examples. Prior work hasextensively explored the selection of examples for ICL, predominantly followingthe "select then organize" paradigm, such approaches often neglect the internalrelationships between examples and exist an inconsistency between the trainingand inference. In this paper, we formulate the problem as a$\textit{se}$quential $\textit{se}$lection problem and introduce$\texttt{Se}^2$, a sequential-aware method that leverages the LLM's feedback onvarying context, aiding in capturing inter-relationships and sequentialinformation among examples, significantly enriching the contextuality andrelevance of ICL prompts. Meanwhile, we utilize beam search to seek andconstruct example sequences, enhancing both quality and diversity. Extensiveexperiments across 23 NLP tasks from 8 distinct categories illustrate that$\texttt{Se}^2$ markedly surpasses competitive baselines and achieves 42%relative improvement over random selection. Further in-depth analysis show theeffectiveness of proposed strategies, highlighting $\texttt{Se}^2$'sexceptional stability and adaptability across various scenarios. Our code willbe released to facilitate future research.</description><author>Haoyu Liu, Jianfeng Liu, Shaohan Huang, Yuefeng Zhan, Hao Sun, Weiwei Deng, Furu Wei, Qi Zhang</author><pubDate>Wed, 21 Feb 2024 15:35:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13874v1</guid></item><item><title>Beyond Fidelity: Explaining Vulnerability Localization of Learning-based Detectors</title><link>http://arxiv.org/abs/2401.02686v2</link><description>Vulnerability detectors based on deep learning (DL) models have proven theireffectiveness in recent years. However, the shroud of opacity surrounding thedecision-making process of these detectors makes it difficult for securityanalysts to comprehend. To address this, various explanation approaches havebeen proposed to explain the predictions by highlighting important features,which have been demonstrated effective in other domains such as computer visionand natural language processing. Unfortunately, an in-depth evaluation ofvulnerability-critical features, such as fine-grained vulnerability-relatedcode lines, learned and understood by these explanation approaches remainslacking. In this study, we first evaluate the performance of ten explanationapproaches for vulnerability detectors based on graph and sequencerepresentations, measured by two quantitative metrics including fidelity andvulnerability line coverage rate. Our results show that fidelity alone is notsufficient for evaluating these approaches, as fidelity incurs significantfluctuations across different datasets and detectors. We subsequently check theprecision of the vulnerability-related code lines reported by the explanationapproaches, and find poor accuracy in this task among all of them. This can beattributed to the inefficiency of explainers in selecting important featuresand the presence of irrelevant artifacts learned by DL-based detectors.</description><author>Baijun Cheng, Shengming Zhao, Kailong Wang, Meizhen Wang, Guangdong Bai, Ruitao Feng, Yao Guo, Lei Ma, Haoyu Wang</author><pubDate>Wed, 21 Feb 2024 15:32:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02686v2</guid></item><item><title>Simple, unified analysis of Johnson-Lindenstrauss with applications</title><link>http://arxiv.org/abs/2402.10232v2</link><description>In this work, we present a simple and unified analysis of theJohnson-Lindenstrauss (JL) lemma, a cornerstone in the field of dimensionalityreduction critical for managing high-dimensional data. Our approach not onlysimplifies the understanding but also unifies various constructions under theJL framework, including spherical, binary-coin, sparse JL, Gaussian andsub-Gaussian models. This simplification and unification make significantstrides in preserving the intrinsic geometry of data, essential across diverseapplications from streaming algorithms to reinforcement learning. Notably, wedeliver the first rigorous proof of the spherical construction's effectivenessand provide a general class of sub-Gaussian constructions within thissimplified framework. At the heart of our contribution is an innovativeextension of the Hanson-Wright inequality to high dimensions, complete withexplicit constants, marking a substantial leap in the literature. By employingsimple yet powerful probabilistic tools and analytical techniques, such as anenhanced diagonalization process, our analysis not only solidifies the JLlemma's theoretical foundation but also extends its practical reach, showcasingits adaptability and importance in contemporary computational algorithms.</description><author>Yingru Li</author><pubDate>Wed, 21 Feb 2024 15:30:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10232v2</guid></item><item><title>Generative Probabilistic Time Series Forecasting and Applications in Grid Operations</title><link>http://arxiv.org/abs/2402.13870v1</link><description>Generative probabilistic forecasting produces future time series samplesaccording to the conditional probability distribution given past time seriesobservations. Such techniques are essential in risk-based decision-making andplanning under uncertainty with broad applications in grid operations,including electricity price forecasting, risk-based economic dispatch, andstochastic optimizations. Inspired by Wiener and Kallianpur's innovationrepresentation, we propose a weak innovation autoencoder architecture and alearning algorithm to extract independent and identically distributedinnovation sequences from nonparametric stationary time series. We show thatthe weak innovation sequence is Bayesian sufficient, which makes the proposedweak innovation autoencoder a canonical architecture for generativeprobabilistic forecasting. The proposed technique is applied to forecastinghighly volatile real-time electricity prices, demonstrating superiorperformance across multiple forecasting measures over leading probabilistic andpoint forecasting techniques.</description><author>Xinyi Wang, Lang Tong, Qing Zhao</author><pubDate>Wed, 21 Feb 2024 15:23:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13870v1</guid></item><item><title>An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach</title><link>http://arxiv.org/abs/2402.13871v1</link><description>Phishing email is a serious cyber threat that tries to deceive users bysending false emails with the intention of stealing confidential information orcausing financial harm. Attackers, often posing as trustworthy entities,exploit technological advancements and sophistication to make detection andprevention of phishing more challenging. Despite extensive academic research,phishing detection remains an ongoing and formidable challenge in thecybersecurity landscape. Large Language Models (LLMs) and Masked LanguageModels (MLMs) possess immense potential to offer innovative solutions toaddress long-standing challenges. In this research paper, we present anoptimized, fine-tuned transformer-based DistilBERT model designed for thedetection of phishing emails. In the detection process, we work with a phishingemail dataset and utilize the preprocessing techniques to clean and solve theimbalance class issues. Through our experiments, we found that our modeleffectively achieves high accuracy, demonstrating its capability to performwell. Finally, we demonstrate our fine-tuned model using Explainable-AI (XAI)techniques such as Local Interpretable Model-Agnostic Explanations (LIME) andTransformer Interpret to explain how our model makes predictions in the contextof text classification for phishing emails.</description><author>Mohammad Amaz Uddin, Iqbal H. Sarker</author><pubDate>Wed, 21 Feb 2024 15:23:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13871v1</guid></item><item><title>LSTSVR-PI: Least square twin support vector regression with privileged information</title><link>http://arxiv.org/abs/2312.02596v2</link><description>In an educational setting, a teacher plays a crucial role in variousclassroom teaching patterns. Similarly, mirroring this aspect of humanlearning, the learning using privileged information (LUPI) paradigm introducesadditional information to instruct learning models during the training stage. Adifferent approach to train the twin variant of the regression model isprovided by the new least square twin support vector regression usingprivileged information (LSTSVR-PI), which integrates the LUPI paradigm toutilize additional sources of information into the least square twin supportvector regression. The proposed LSTSVR-PI solves system of linear equationswhich adds up to the efficiency of the model. Further, we also establish ageneralization error bound based on the Rademacher complexity of the proposedmodel and incorporate the structural risk minimization principle. The proposedLSTSVR-PI fills the gap between the contemporary paradigm of LUPI and classicalLSTSVR. Further, to assess the performance of the proposed model, we conductnumerical experiments along with the baseline models across variousartificially generated and real-world datasets. The various experiments andstatistical analysis infer the superiority of the proposed model. Moreover, asan application, we conduct experiments on time series datasets, which resultsin the superiority of the proposed LSTSVR-PI.</description><author>Anuradha Kumari, M. Tanveer</author><pubDate>Wed, 21 Feb 2024 15:22:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02596v2</guid></item><item><title>RFI-DRUnet: Restoring dynamic spectra corrupted by radio frequency interference -- Application to pulsar observations</title><link>http://arxiv.org/abs/2402.13867v1</link><description>Radio frequency interference (RFI) have been an enduring concern in radioastronomy, particularly for the observations of pulsars which require hightiming precision and data sensitivity. In most works of the literature, RFImitigation has been formulated as a detection task that consists of localizingpossible RFI in dynamic spectra. This strategy inevitably leads to a potentialloss of information since parts of the signal identified as possiblyRFI-corrupted are generally not considered in the subsequent data processingpipeline. Conversely, this work proposes to tackle RFI mitigation as a jointdetection and restoration that allows parts of the dynamic spectrum affected byRFI to be not only identified but also recovered. The proposed supervisedmethod relies on a deep convolutional network whose architecture inherits theperformance reached by a recent yet popular image-denoising network. To trainthis network, a whole simulation framework is built to generate large data setsaccording to physics-inspired and statistical models of the pulsar signals andof the RFI. The relevance of the proposed approach is quantitatively assessedby conducting extensive experiments. In particular, the results show that therestored dynamic spectra are sufficiently reliable to estimate pulsartimes-of-arrivals with an accuracy close to the one that would be obtained fromRFI-free signals.</description><author>Xiao Zhang, Ismaël Cognard, Nicolas Dobigeon</author><pubDate>Wed, 21 Feb 2024 15:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13867v1</guid></item><item><title>Approximation of optimization problems with constraints through kernel Sum-Of-Squares</title><link>http://arxiv.org/abs/2301.06339v2</link><description>Handling an infinite number of inequality constraints in infinite-dimensionalspaces occurs in many fields, from global optimization to optimal transport.These problems have been tackled individually in several previous articlesthrough kernel Sum-Of-Squares (kSoS) approximations. We propose here a unifiedtheorem to prove convergence guarantees for these schemes. Pointwiseinequalities are turned into equalities within a class of nonnegative kSoSfunctions. Assuming further that the functions appearing in the problem aresmooth, focusing on pointwise equality constraints enables the use ofscattering inequalities to mitigate the curse of dimensionality in sampling theconstraints. Our approach is illustrated in learning vector fields with sideinformation, here the invariance of a set.</description><author>Pierre-Cyril Aubin-Frankowski, Alessandro Rudi</author><pubDate>Wed, 21 Feb 2024 15:14:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06339v2</guid></item><item><title>Kuaiji: the First Chinese Accounting Large Language Model</title><link>http://arxiv.org/abs/2402.13866v1</link><description>Large Language Models (LLMs) like ChatGPT and GPT-4 have demonstratedimpressive proficiency in comprehending and generating natural language.However, they encounter difficulties when tasked with adapting to specializeddomains such as accounting. To address this challenge, we introduce Kuaiji, atailored Accounting Large Language Model. Kuaiji is meticulously fine-tunedusing the Baichuan framework, which encompasses continuous pre-training andsupervised fine-tuning processes. Supported by CAtAcctQA, a dataset containinglarge genuine accountant-client dialogues, Kuaiji exhibits exceptional accuracyand response speed. Our contributions encompass the creation of the firstChinese accounting dataset, the establishment of Kuaiji as a leadingopen-source Chinese accounting LLM, and the validation of its efficacy throughreal-world accounting scenarios.</description><author>Jiayuan Luo, Songhua Yang, Xiaoling Qiu, Panyu Chen, Yufei Nai, Wenxuan Zeng, Wentao Zhang, Xinke Jiang</author><pubDate>Wed, 21 Feb 2024 15:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13866v1</guid></item></channel></rss>