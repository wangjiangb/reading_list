<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 02 Jul 2024 06:00:25 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Framing image registration as a landmark detection problem for label-noise-aware task representation (HitR)</title><link>http://arxiv.org/abs/2308.01318v2</link><description>Accurate image registration is pivotal in biomedical image analysis, whereselecting suitable registration algorithms demands careful consideration. Whilenumerous algorithms are available, the evaluation metrics to assess theirperformance have remained relatively static. This study addresses thischallenge by introducing a novel evaluation metric termed Landmark Hit Rate(HitR), which focuses on the clinical relevance of image registration accuracy.Unlike traditional metrics such as Target Registration Error, which emphasizesubresolution differences, HitR considers whether registration algorithmssuccessfully position landmarks within defined confidence zones. This paradigmshift acknowledges the inherent annotation noise in medical images, allowingfor more meaningful assessments. To equip HitR with label-noise-awareness, wepropose defining these confidence zones based on an Inter-rater Varianceanalysis. Consequently, hit rate curves are computed for varying landmark zonesizes, enabling performance measurement for a task-specific level of accuracy.Our approach offers a more realistic and meaningful assessment of imageregistration algorithms, reflecting their suitability for clinical andbiomedical applications.</description><author>Diana Waldmannstetter, Ivan Ezhov, Benedikt Wiestler, Francesco Campi, Ivan Kukuljan, Stefan Ehrlich, Shankeeth Vinayahalingam, Bhakti Baheti, Satrajit Chakrabarty, Ujjwal Baid, Spyridon Bakas, Julian Schwarting, Marie Metz, Jan S. Kirschke, Daniel Rueckert, Rolf A. Heckemann, Marie Piraud, Bjoern H. Menze, Florian Kofler</author><pubDate>Mon, 01 Jul 2024 18:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01318v2</guid></item><item><title>Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP</title><link>http://arxiv.org/abs/2307.09233v3</link><description>Image-text contrastive models like CLIP have wide applications in zero-shotclassification, image-text retrieval, and transfer learning. However, theyoften struggle on compositional visio-linguistic tasks (e.g., attribute-bindingor object-relationships) where their performance is no better than randomchance. To address this, we introduce SDS-CLIP, a lightweight andsample-efficient distillation method to enhance CLIP's compositionalvisio-linguistic reasoning. Our approach fine-tunes CLIP using a distillationobjective borrowed from large text-to-image generative models likeStable-Diffusion, which are known for their strong visio-linguistic reasoningabilities. On the challenging Winoground benchmark, SDS-CLIP improves thevisio-linguistic performance of various CLIP models by up to 7%, while on theARO dataset, it boosts performance by up to 3%. This work underscores thepotential of well-designed distillation objectives from generative models toenhance contrastive image-text models with improved visio-linguistic reasoningcapabilities.</description><author>Samyadeep Basu, Shell Xu Hu, Maziar Sanjabi, Daniela Massiceti, Soheil Feizi</author><pubDate>Mon, 01 Jul 2024 18:48:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09233v3</guid></item><item><title>Adam-mini: Use Fewer Learning Rates To Gain More</title><link>http://arxiv.org/abs/2406.16793v4</link><description>We propose Adam-mini, an optimizer that achieves on-par or better performancethan AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory bycutting down the learning rate resources in Adam (i.e., $1/\sqrt{v}$). We findthat $\geq$ 90% of these learning rates in $v$ could be harmlessly removed ifwe (1) carefully partition the parameters into blocks following our proposedprinciple on Hessian structure; (2) assign a single but good learning rate toeach parameter block. We further find that, for each of these parameter blocks,there exists a single high-quality learning rate that can outperform Adam,provided that sufficient resources are available to search it out. We thenprovide one cost-effective way to find good learning rates and proposeAdam-mini. Empirically, we verify that Adam-mini performs on par or better thanAdamW on various language models sized from 125M to 7B for pre-training,supervised fine-tuning, and RLHF. The reduced memory footprint of Adam-minialso alleviates communication overheads among GPUs and CPUs, thereby increasingthroughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamWwhen pre-training Llama2-7B on $2\times$ A800-80GB GPUs, which saves 33%wall-clock time for pre-training.</description><author>Yushun Zhang, Congliang Chen, Ziniu Li, Tian Ding, Chenwei Wu, Yinyu Ye, Zhi-Quan Luo, Ruoyu Sun</author><pubDate>Mon, 01 Jul 2024 18:46:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16793v4</guid></item><item><title>Scaling SNNs Trained Using Equilibrium Propagation to Convolutional Architectures</title><link>http://arxiv.org/abs/2405.02546v2</link><description>Equilibrium Propagation (EP) is a biologically plausible local learningalgorithm initially developed for convergent recurrent neural networks (RNNs),where weight updates rely solely on the connecting neuron states across twophases. The gradient calculations in EP have been shown to approximate thegradients computed by Backpropagation Through Time (BPTT) when aninfinitesimally small nudge factor is used. This property makes EP a powerfulcandidate for training Spiking Neural Networks (SNNs), which are commonlytrained by BPTT. However, in the spiking domain, previous studies on EP havebeen limited to architectures involving few linear layers. In this work, forthe first time we provide a formulation for training convolutional spikingconvergent RNNs using EP, bridging the gap between spiking and non-spikingconvergent RNNs. We demonstrate that for spiking convergent RNNs, there is amismatch in the maximum pooling and its inverse operation, leading toinaccurate gradient estimation in EP. Substituting this with average poolingresolves this issue and enables accurate gradient estimation for spikingconvergent RNNs. We also highlight the memory efficiency of EP compared toBPTT. In the regime of SNNs trained by EP, our experimental results indicatestate-of-the-art performance on the MNIST and FashionMNIST datasets, with testerrors of 0.97% and 8.89%, respectively. These results are comparable to thoseof convergent RNNs and SNNs trained by BPTT. These findings underscore EP as anoptimal choice for on-chip training and a biologically-plausible method forcomputing error gradients.</description><author>Jiaqi Lin, Malyaban Bal, Abhronil Sengupta</author><pubDate>Mon, 01 Jul 2024 18:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02546v2</guid></item><item><title>Safe and Responsible Large Language Model : Can We Balance Bias Reduction and Language Understanding in Large Language Models?</title><link>http://arxiv.org/abs/2404.01399v3</link><description>Large Language Models (LLMs) have significantly advanced various NLP tasks.However, these models often risk generating unsafe text that perpetuatesbiases. Current approaches to produce unbiased outputs from LLMs can reducebiases but at the expense of knowledge retention. In this research, we addressthe question of whether producing safe (unbiased) outputs through LLMs canretain knowledge and language understanding. In response, we developed theSafety and Responsible Large Language Model (\textbf{SR}$_{\text{LLM}}$), anLLM that has been instruction fine-tuned on top of already safe LLMs (e.g.,Llama2 or related) to diminish biases in generated text. To achieve our goals,we compiled a specialized dataset designed to train our model in identifyingand correcting biased text. We conduct experiments, both on this custom dataand out-of-distribution test sets, to show the bias reduction and knowledgeretention. The results confirm that \textbf{SR}$_{\text{LLM}}$ outperformstraditional fine-tuning and prompting methods in both reducing biases andpreserving the integrity of language knowledge. The significance of ourfindings lies in demonstrating that instruction fine-tuning can provide a morerobust solution for bias reduction in LLMs. We have made our code and dataavailable at\href{https://github.com/shainarazavi/Safe-Responsible-LLM}{Safe-LLM}.</description><author>Shaina Raza, Oluwanifemi Bamgbose, Shardul Ghuge, Fatemeh Tavakol, Deepak John Reji, Syed Raza Bashir</author><pubDate>Mon, 01 Jul 2024 18:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01399v3</guid></item><item><title>Exploring Extreme Quantization in Spiking Language Models</title><link>http://arxiv.org/abs/2405.02543v3</link><description>Despite the growing prevalence of large language model (LLM) architectures, acrucial concern persists regarding their energy and power consumption, whichstill lags far behind the remarkable energy efficiency of the human brain.Recent strides in spiking language models (LM) and transformer architecturesaim to address this concern by harnessing the spiking activity of biologicalneurons to enhance energy/power efficiency. Doubling down on the principles ofmodel quantization and energy efficiency, this paper proposes the developmentof a novel binary/ternary (1/1.58-bit) spiking LM architecture. Achievingscalability comparable to a deep spiking LM architecture is facilitated by anefficient knowledge distillation technique, wherein knowledge from anon-spiking full-precision "teacher" model is transferred to an extremelyweight quantized spiking "student" LM. Our proposed model represents asignificant advancement as the first-of-its-kind 1/1.58-bit spiking LM, and itsperformance is rigorously evaluated on multiple text classification tasks ofthe GLUE benchmark.</description><author>Malyaban Bal, Yi Jiang, Abhronil Sengupta</author><pubDate>Mon, 01 Jul 2024 18:38:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02543v3</guid></item><item><title>Stochastic Spiking Neural Networks with First-to-Spike Coding</title><link>http://arxiv.org/abs/2404.17719v3</link><description>Spiking Neural Networks (SNNs), recognized as the third generation of neuralnetworks, are known for their bio-plausibility and energy efficiency,especially when implemented on neuromorphic hardware. However, the majority ofexisting studies on SNNs have concentrated on deterministic neurons with ratecoding, a method that incurs substantial computational overhead due to lengthyinformation integration times and fails to fully harness the brain'sprobabilistic inference capabilities and temporal dynamics. In this work, weexplore the merger of novel computing and information encoding schemes in SNNarchitectures where we integrate stochastic spiking neuron models with temporalcoding techniques. Through extensive benchmarking with other deterministic SNNsand rate-based coding, we investigate the tradeoffs of our proposal in terms ofaccuracy, inference latency, spiking sparsity, energy consumption, androbustness. Our work is the first to extend the scalability of direct trainingapproaches of stochastic SNNs with temporal encoding to VGG architectures andbeyond-MNIST datasets.</description><author>Yi Jiang, Sen Lu, Abhronil Sengupta</author><pubDate>Mon, 01 Jul 2024 18:35:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17719v3</guid></item><item><title>Large Language Models Assume People are More Rational than We Really are</title><link>http://arxiv.org/abs/2406.17055v2</link><description>In order for AI systems to communicate effectively with people, they mustunderstand how we make decisions. However, people's decisions are not alwaysrational, so the implicit internal models of human decision-making in LargeLanguage Models (LLMs) must account for this. Previous empirical evidence seemsto suggest that these implicit models are accurate -- LLMs offer believableproxies of human behavior, acting how we expect humans would in everydayinteractions. However, by comparing LLM behavior and predictions to a largedataset of human decisions, we find that this is actually not the case: whenboth simulating and predicting people's choices, a suite of cutting-edge LLMs(GPT-4o &amp; 4-Turbo, Llama-3-8B &amp; 70B, Claude 3 Opus) assume that people are morerational than we really are. Specifically, these models deviate from humanbehavior and align more closely with a classic model of rational choice --expected value theory. Interestingly, people also tend to assume that otherpeople are rational when interpreting their behavior. As a consequence, when wecompare the inferences that LLMs and people draw from the decisions of othersusing another psychological dataset, we find that these inferences are highlycorrelated. Thus, the implicit decision-making models of LLMs appear to bealigned with the human expectation that other people will act rationally,rather than with how people actually act.</description><author>Ryan Liu, Jiayi Geng, Joshua C. Peterson, Ilia Sucholutsky, Thomas L. Griffiths</author><pubDate>Mon, 01 Jul 2024 18:29:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17055v2</guid></item><item><title>Unmasking Bias in AI: A Systematic Review of Bias Detection and Mitigation Strategies in Electronic Health Record-based Models</title><link>http://arxiv.org/abs/2310.19917v3</link><description>Objectives: Leveraging artificial intelligence (AI) in conjunction withelectronic health records (EHRs) holds transformative potential to improvehealthcare. Yet, addressing bias in AI, which risks worsening healthcaredisparities, cannot be overlooked. This study reviews methods to detect andmitigate diverse forms of bias in AI models developed using EHR data. Methods:We conducted a systematic review following the Preferred Reporting Items forSystematic Reviews and Meta-analyses (PRISMA) guidelines, analyzing articlesfrom PubMed, Web of Science, and IEEE published between January 1, 2010, andDec 17, 2023. The review identified key biases, outlined strategies fordetecting and mitigating bias throughout the AI model development process, andanalyzed metrics for bias assessment. Results: Of the 450 articles retrieved,20 met our criteria, revealing six major bias types: algorithmic, confounding,implicit, measurement, selection, and temporal. The AI models were primarilydeveloped for predictive tasks in healthcare settings. Four studiesconcentrated on the detection of implicit and algorithmic biases employingfairness metrics like statistical parity, equal opportunity, and predictiveequity. Sixty proposed various strategies for mitigating biases, especiallytargeting implicit and selection biases. These strategies, evaluated throughboth performance (e.g., accuracy, AUROC) and fairness metrics, predominantlyinvolved data collection and preprocessing techniques like resampling,reweighting, and transformation. Discussion: This review highlights the variedand evolving nature of strategies to address bias in EHR-based AI models,emphasizing the urgent needs for the establishment of standardized,generalizable, and interpretable methodologies to foster the creation ofethical AI systems that promote fairness and equity in healthcare.</description><author>Feng Chen, Liqin Wang, Julie Hong, Jiaqi Jiang, Li Zhou</author><pubDate>Mon, 01 Jul 2024 18:26:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19917v3</guid></item><item><title>Comparing AI Algorithms for Optimizing Elliptic Curve Cryptography Parameters in e-Commerce Integrations: A Pre-Quantum Analysis</title><link>http://arxiv.org/abs/2310.06752v2</link><description>This paper presents a comparative analysis between the Genetic Algorithm (GA)and Particle Swarm Optimization (PSO), two vital artificial intelligencealgorithms, focusing on optimizing Elliptic Curve Cryptography (ECC)parameters. These encompass the elliptic curve coefficients, prime number,generator point, group order, and cofactor. The study provides insights intowhich of the bio-inspired algorithms yields better optimization results for ECCconfigurations, examining performances under the same fitness function. Thisfunction incorporates methods to ensure robust ECC parameters, includingassessing for singular or anomalous curves and applying Pollard's rho attackand Hasse's theorem for optimization precision. The optimized parametersgenerated by GA and PSO are tested in a simulated e-commerce environment,contrasting with well-known curves like secp256k1 during the transmission oforder messages using Elliptic Curve-Diffie Hellman (ECDH) and Hash-basedMessage Authentication Code (HMAC). Focusing on traditional computing in thepre-quantum era, this research highlights the efficacy of GA and PSO in ECCoptimization, with implications for enhancing cybersecurity in third-partye-commerce integrations. We recommend the immediate consideration of thesefindings before quantum computing's widespread adoption.</description><author>Felipe Tellez, Jorge Ortiz</author><pubDate>Mon, 01 Jul 2024 18:19:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06752v2</guid></item><item><title>Fine-tuning can cripple your foundation model; preserving features may be the solution</title><link>http://arxiv.org/abs/2308.13320v3</link><description>Pre-trained foundation models, due to their enormous capacity and exposure tovast amounts of data during pre-training, are known to have learned plenty ofreal-world concepts. An important step in making these pre-trained modelseffective on downstream tasks is to fine-tune them on related datasets. Whilevarious fine-tuning methods have been devised and have been shown to be highlyeffective, we observe that a fine-tuned model's ability to recognize conceptson tasks $\textit{different}$ from the downstream one is reduced significantlycompared to its pre-trained counterpart. This is an undesirable effect offine-tuning as a substantial amount of resources was used to learn thesepre-trained concepts in the first place. We call this phenomenon ''conceptforgetting'' and via experiments show that most end-to-end fine-tuningapproaches suffer heavily from this side effect. To this end, we propose asimple fix to this problem by designing a new fine-tuning method called$\textit{LDIFS}$ (short for $\ell_2$ distance in feature space) that, whilelearning new concepts related to the downstream task, allows a model topreserve its pre-trained knowledge as well. Through extensive experiments on 10fine-tuning tasks we show that $\textit{LDIFS}$ significantly reduces conceptforgetting. Additionally, we show that LDIFS is highly effective in performingcontinual fine-tuning on a sequence of tasks as well, in comparison with bothfine-tuning as well as continual learning baselines.</description><author>Jishnu Mukhoti, Yarin Gal, Philip H. S. Torr, Puneet K. Dokania</author><pubDate>Mon, 01 Jul 2024 18:14:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13320v3</guid></item><item><title>Entrywise Inference for Missing Panel Data: A Simple and Instance-Optimal Approach</title><link>http://arxiv.org/abs/2401.13665v2</link><description>Longitudinal or panel data can be represented as a matrix with rows indexedby units and columns indexed by time. We consider inferential questionsassociated with the missing data version of panel data induced by staggeredadoption. We propose a computationally efficient procedure for estimation,involving only simple matrix algebra and singular value decomposition, andprove non-asymptotic and high-probability bounds on its error in estimatingeach missing entry. By controlling proximity to a suitably scaled Gaussianvariable, we develop and analyze a data-driven procedure for constructingentrywise confidence intervals with pre-specified coverage. Despite itssimplicity, our procedure turns out to be instance-optimal: we prove that thewidth of our confidence intervals match a non-asymptotic instance-wise lowerbound derived via a Bayesian Cram\'{e}r-Rao argument. We illustrate thesharpness of our theoretical characterization on a variety of numericalexamples. Our analysis is based on a general inferential toolbox for SVD-basedalgorithm applied to the matrix denoising model, which might be of independentinterest.</description><author>Yuling Yan, Martin J. Wainwright</author><pubDate>Mon, 01 Jul 2024 18:10:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13665v2</guid></item><item><title>BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration</title><link>http://arxiv.org/abs/2406.20041v2</link><description>Autonomous agents driven by Large Language Models (LLMs) offer enormouspotential for automation. Early proof of this technology can be found invarious demonstrations of agents solving complex tasks, interacting withexternal systems to augment their knowledge, and triggering actions. Inparticular, workflows involving multiple agents solving complex tasks in acollaborative fashion exemplify their capacity to operate in less strict andless well-defined environments. Thus, a multi-agent approach has greatpotential for serving as a backbone in many industrial applications, rangingfrom complex knowledge retrieval systems to next generation robotic processautomation. Given the reasoning abilities within the current generation ofLLMs, complex processes require a multi-step approach that includes a plan ofwell-defined and modular tasks. Depending on the level of complexity, thesetasks can be executed either by a single agent or a group of agents. In thiswork, we focus on designing a flexible agent engineering framework with carefulattention to planning and execution, capable of handling complex use caseapplications across various domains. The proposed framework providesreliability in industrial applications and presents techniques to ensure ascalable, flexible, and collaborative workflow for multiple autonomous agentsworking together towards solving tasks.</description><author>Noel Crawford, Edward B. Duffy, Iman Evazzade, Torsten Foehr, Gregory Robbins, Debbrata Kumar Saha, Jiya Varma, Marcin Ziolkowski</author><pubDate>Mon, 01 Jul 2024 17:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20041v2</guid></item><item><title>Predicting Text Preference Via Structured Comparative Reasoning</title><link>http://arxiv.org/abs/2311.08390v2</link><description>Comparative reasoning plays a crucial role in text preference prediction;however, large language models (LLMs) often demonstrate inconsistencies intheir reasoning. While approaches like Chain-of-Thought improve accuracy inmany other settings, they struggle to consistently distinguish the similaritiesand differences of complex texts. We introduce SC, a prompting approach thatpredicts text preferences by generating structured intermediate comparisons. SCbegins by proposing aspects of comparison, followed by generating textualcomparisons under each aspect. We select consistent comparisons with a pairwiseconsistency comparator that ensures each aspect's comparisons clearlydistinguish differences between texts, significantly reducing hallucination andimproving consistency. Our comprehensive evaluations across various NLP tasks,including summarization, retrieval, and automatic rating, demonstrate that SCequips LLMs to achieve state-of-the-art performance in text preferenceprediction.</description><author>Jing Nathan Yan, Tianqi Liu, Justin T Chiu, Jiaming Shen, Zhen Qin, Yue Yu, Yao Zhao, Charu Lakshmanan, Yair Kurzion, Alexander M. Rush, Jialu Liu, Michael Bendersky</author><pubDate>Mon, 01 Jul 2024 17:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08390v2</guid></item><item><title>Proceedings of The second international workshop on eXplainable AI for the Arts (XAIxArts)</title><link>http://arxiv.org/abs/2406.14485v3</link><description>This second international workshop on explainable AI for the Arts (XAIxArts)brought together a community of researchers in HCI, Interaction Design, AI,explainable AI (XAI), and digital arts to explore the role of XAI for the Arts.Workshop held at the 16th ACM Conference on Creativity and Cognition (C&amp;C2024), Chicago, USA.</description><author>Nick Bryan-Kinns, Corey Ford, Shuoyang Zheng, Helen Kennedy, Alan Chamberlain, Makayla Lewis, Drew Hemment, Zijin Li, Qiong Wu, Lanxi Xiao, Gus Xia, Jeba Rezwana, Michael Clemens, Gabriel Vigliensoni</author><pubDate>Mon, 01 Jul 2024 17:49:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14485v3</guid></item><item><title>Does Writing with Language Models Reduce Content Diversity?</title><link>http://arxiv.org/abs/2309.05196v3</link><description>Large language models (LLMs) have led to a surge in collaborative writingwith model assistance. As different users incorporate suggestions from the samemodel, there is a risk of decreased diversity in the produced content,potentially limiting diverse perspectives in public discourse. In this work, wemeasure the impact of co-writing on diversity via a controlled experiment,where users write argumentative essays in three setups -- using a base LLM(GPT3), a feedback-tuned LLM (InstructGPT), and writing without model help. Wedevelop a set of diversity metrics and find that writing with InstructGPT (butnot the GPT3) results in a statistically significant reduction in diversity.Specifically, it increases the similarity between the writings of differentauthors and reduces the overall lexical and content diversity. We additionallyfind that this effect is mainly attributable to InstructGPT contributing lessdiverse text to co-written essays. In contrast, the user-contributed textremains unaffected by model collaboration. This suggests that the recentimprovement in generation quality from adapting models to human feedback mightcome at the cost of more homogeneous and less diverse content.</description><author>Vishakh Padmakumar, He He</author><pubDate>Mon, 01 Jul 2024 17:36:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05196v3</guid></item><item><title>Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging</title><link>http://arxiv.org/abs/2311.02115v2</link><description>Artificial intelligence (AI) models trained using medical images for clinicaltasks often exhibit bias in the form of disparities in performance betweensubgroups. Since not all sources of biases in real-world medical imaging dataare easily identifiable, it is challenging to comprehensively assess how thosebiases are encoded in models, and how capable bias mitigation methods are atameliorating performance disparities. In this article, we introduce a novelanalysis framework for systematically and objectively investigating the impactof biases in medical images on AI models. We developed and tested thisframework for conducting controlled in silico trials to assess bias in medicalimaging AI using a tool for generating synthetic magnetic resonance images withknown disease effects and sources of bias. The feasibility is showcased byusing three counterfactual bias scenarios to measure the impact of simulatedbias effects on a convolutional neural network (CNN) classifier and theefficacy of three bias mitigation strategies. The analysis revealed that thesimulated biases resulted in expected subgroup performance disparities when theCNN was trained on the synthetic datasets. Moreover, reweighing was identifiedas the most successful bias mitigation strategy for this setup, and wedemonstrated how explainable AI methods can aid in investigating themanifestation of bias in the model using this framework. Developing fair AImodels is a considerable challenge given that many and often unknown sources ofbiases can be present in medical imaging datasets. In this work, we present anovel methodology to objectively study the impact of biases and mitigationstrategies on deep learning pipelines, which can support the development ofclinical AI that is robust and responsible.</description><author>Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert</author><pubDate>Mon, 01 Jul 2024 17:30:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02115v2</guid></item><item><title>Evaluation of Deep Learning Semantic Segmentation for Land Cover Mapping on Multispectral, Hyperspectral and High Spatial Aerial Imagery</title><link>http://arxiv.org/abs/2406.14220v2</link><description>In the rise of climate change, land cover mapping has become such an urgentneed in environmental monitoring. The accuracy of land cover classification hasgotten increasingly based on the improvement of remote sensing data. Land coverclassification using satellite imageries has been explored and become moreprevalent in recent years, but the methodologies remain some drawbacks ofsubjective and time-consuming. Some deep learning techniques have been utilizedto overcome these limitations. However, most studies implemented just one imagetype to evaluate algorithms for land cover mapping. Therefore, our studyconducted deep learning semantic segmentation in multispectral, hyperspectral,and high spatial aerial image datasets for landcover mapping. This researchimplemented a semantic segmentation method such as Unet, Linknet, FPN, andPSPnet for categorizing vegetation, water, and others (i.e., soil andimpervious surface). The LinkNet model obtained high accuracy in IoU(Intersection Over Union) at 0.92 in all datasets, which is comparable withother mentioned techniques. In evaluation with different image types, themultispectral images showed higher performance with the IoU, and F1-score are0.993 and 0.997, respectively. Our outcome highlighted the efficiency and broadapplicability of LinkNet and multispectral image on land cover classification.This research contributes to establishing an approach on landcover segmentationvia open source for long-term future application.</description><author>Ilham Adi Panuntun, Ying-Nong Chen, Ilham Jamaluddin, Thi Linh Chi Tran</author><pubDate>Mon, 01 Jul 2024 17:30:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14220v2</guid></item><item><title>Predicting Fairness of ML Software Configurations</title><link>http://arxiv.org/abs/2404.19100v2</link><description>This paper investigates the relationships between hyperparameters of machinelearning and fairness. Data-driven solutions are increasingly used in criticalsocio-technical applications where ensuring fairness is important. Rather thanexplicitly encoding decision logic via control and data structures, the MLdevelopers provide input data, perform some pre-processing, choose MLalgorithms, and tune hyperparameters (HPs) to infer a program that encodes thedecision logic. Prior works report that the selection of HPs can significantlyinfluence fairness. However, tuning HPs to find an ideal trade-off betweenaccuracy, precision, and fairness has remained an expensive and tedious task.Can we predict fairness of HP configuration for a given dataset? Are thepredictions robust to distribution shifts? We focus on group fairness notions and investigate the HP space of 5 trainingalgorithms. We first find that tree regressors and XGBoots significantlyoutperformed deep neural networks and support vector machines in accuratelypredicting the fairness of HPs. When predicting the fairness of MLhyperparameters under temporal distribution shift, the tree regressorsoutperforms the other algorithms with reasonable accuracy. However, theprecision depends on the ML training algorithm, dataset, and protectedattributes. For example, the tree regressor model was robust for training datashift from 2014 to 2018 on logistic regression and discriminant analysis HPswith sex as the protected attribute; but not for race and other trainingalgorithms. Our method provides a sound framework to efficiently performfine-tuning of ML training algorithms and understand the relationships betweenHPs and fairness.</description><author>Salvador Robles Herrera, Verya Monjezi, Vladik Kreinovich, Ashutosh Trivedi, Saeid Tizpaz-Niari</author><pubDate>Mon, 01 Jul 2024 17:16:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19100v2</guid></item><item><title>Embedded FPGA Developments in 130nm and 28nm CMOS for Machine Learning in Particle Detector Readout</title><link>http://arxiv.org/abs/2404.17701v2</link><description>Embedded field programmable gate array (eFPGA) technology allows theimplementation of reconfigurable logic within the design of anapplication-specific integrated circuit (ASIC). This approach offers the lowpower and efficiency of an ASIC along with the ease of FPGA configuration,particularly beneficial for the use case of machine learning in the datapipeline of next-generation collider experiments. An open-source frameworkcalled "FABulous" was used to design eFPGAs using 130 nm and 28 nm CMOStechnology nodes, which were subsequently fabricated and verified throughtesting. The capability of an eFPGA to act as a front-end readout chip wasassessed using simulation of high energy particles passing through a siliconpixel sensor. A machine learning-based classifier, designed for reduction ofsensor data at the source, was synthesized and configured onto the eFPGA. Asuccessful proof-of-concept was demonstrated through reproduction of theexpected algorithm result on the eFPGA with perfect accuracy. Furtherdevelopment of the eFPGA technology and its application to collider detectorreadout is discussed.</description><author>Julia Gonski, Aseem Gupta, Haoyi Jia, Hyunjoon Kim, Lorenzo Rota, Larry Ruckman, Angelo Dragone, Ryan Herbst</author><pubDate>Mon, 01 Jul 2024 17:07:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17701v2</guid></item><item><title>Video-Language Understanding: A Survey from Model Architecture, Model Training, and Data Perspectives</title><link>http://arxiv.org/abs/2406.05615v2</link><description>Humans use multiple senses to comprehend the environment. Vision and languageare two of the most vital senses since they allow us to easily communicate ourthoughts and perceive the world around us. There has been a lot of interest increating video-language understanding systems with human-like senses since avideo-language pair can mimic both our linguistic medium and visual environmentwith temporal dynamics. In this survey, we review the key tasks of thesesystems and highlight the associated challenges. Based on the challenges, wesummarize their methods from model architecture, model training, and dataperspectives. We also conduct performance comparison among the methods, anddiscuss promising directions for future research.</description><author>Thong Nguyen, Yi Bin, Junbin Xiao, Leigang Qu, Yicong Li, Jay Zhangjie Wu, Cong-Duy Nguyen, See-Kiong Ng, Luu Anh Tuan</author><pubDate>Mon, 01 Jul 2024 17:05:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05615v2</guid></item><item><title>Explainability of machine learning approaches in forensic linguistics: a case study in geolinguistic authorship profiling</title><link>http://arxiv.org/abs/2404.18510v2</link><description>Forensic authorship profiling uses linguistic markers to infercharacteristics about an author of a text. This task is paralleled in dialectclassification, where a prediction is made about the linguistic variety of atext based on the text itself. While there have been significant advances inrecent years in variety classification, forensic linguistics rarely relies onthese approaches due to their lack of transparency, among other reasons. Inthis paper we therefore explore the explainability of machine learningapproaches considering the forensic context. We focus on variety classificationas a means of geolinguistic profiling of unknown texts based on social mediadata from the German-speaking area. For this, we identify the lexical itemsthat are the most impactful for the variety classification. We find that theextracted lexical features are indeed representative of their respectivevarieties and note that the trained models also rely on place names forclassifications.</description><author>Dana Roemling, Yves Scherrer, Aleksandra Miletic</author><pubDate>Mon, 01 Jul 2024 16:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18510v2</guid></item><item><title>Cutting through buggy adversarial example defenses: fixing 1 line of code breaks Sabre</title><link>http://arxiv.org/abs/2405.03672v3</link><description>Sabre is a defense to adversarial examples that was accepted at IEEE S&amp;P2024. We first reveal significant flaws in the evaluation that point to clearsigns of gradient masking. We then show the cause of this gradient masking: abug in the original evaluation code. By fixing a single line of code in theoriginal repository, we reduce Sabre's robust accuracy to 0%. In response tothis, the authors modify the defense and introduce a new defense component notdescribed in the original paper. But this fix contains a second bug; modifyingone more line of code reduces robust accuracy to below baseline levels. Afterwe released the first version of our paper online, the authors introducedanother change to the defense; by commenting out one line of code during attackwe reduce the robust accuracy to 0% again.</description><author>Nicholas Carlini</author><pubDate>Mon, 01 Jul 2024 16:57:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03672v3</guid></item><item><title>A Convex Hull Cheapest Insertion Heuristic for the Non-Euclidean TSP</title><link>http://arxiv.org/abs/2302.06582v4</link><description>The convex hull cheapest insertion heuristic is known to produce goodsolutions to the Traveling Salesperson Problem in Euclidean spaces, but it hasnever been extended to the non-Euclidean problem. This paper proposes anadaptation that uses multidimensional scaling to first project the points froma non-Euclidean space into a Euclidean equivalent space, thereby enabling thegeneration of a convex hull that initializes the algorithm. To evaluate theproposed algorithm, non-Euclidean spaces are created by adding separators tothe Euclidean TSPLIB benchmark data-set, or by using the L1 norm as a metric.This adapted heuristic is demonstrated to outperform the commonly used NearestNeighbor heuristic and Nearest Insertion heuristic in 88% and 99% of the casesstudied, respectively. When compared with metaheuristic algorithms, theproposed heuristic's tour costs are lower than the solutions found by thegenetic algorithm and ant colony optimization algorithm in 87% and 95% of theinstances, respectively.</description><author>Mithun Goutham, Meghna Menon, Sarah Garrow, Stephanie Stockar</author><pubDate>Mon, 01 Jul 2024 16:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06582v4</guid></item><item><title>Affine Invariant Ensemble Transform Methods to Improve Predictive Uncertainty in Neural Networks</title><link>http://arxiv.org/abs/2309.04742v2</link><description>We consider the problem of performing Bayesian inference for logisticregression using appropriate extensions of the ensemble Kalman filter. Twointeracting particle systems are proposed that sample from an approximateposterior and prove quantitative convergence rates of these interactingparticle systems to their mean-field limit as the number of particles tends toinfinity. Furthermore, we apply these techniques and examine theireffectiveness as methods of Bayesian approximation for quantifying predictiveuncertainty in neural networks.</description><author>Diksha Bhandari, Jakiw Pidstrigach, Sebastian Reich</author><pubDate>Mon, 01 Jul 2024 16:55:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04742v2</guid></item><item><title>Bytes Are All You Need: Transformers Operating Directly On File Bytes</title><link>http://arxiv.org/abs/2306.00238v2</link><description>Modern deep learning approaches usually utilize modality-specific processing.For example, the most common deep learning approach to image classificationinvolves decoding image file bytes into an RGB tensor which is passed into aneural network. Instead, we investigate modality-independent representationlearning by performing classification directly on file bytes, without the needfor decoding files at inference time. This enables models to operate on variousmodalities without any hand-designed, modality-specific processing. Our model,ByteFormer, improves ImageNet Top-1 classification accuracy by $5\%$ (from$72.2\%$ to $77.33\%$) relative to DeIT models of similar size. Compared toPerceiver IO, our model requires absolutely no modality-specific processing atinference time, and uses an order of magnitude fewer parameters at equivalentaccuracy on ImageNet. We demonstrate that the same ByteFormer architecture canperform audio classification without modifications or modality-specificpreprocessing. We achieve $95.42\%$ classification accuracy on the SpeechCommands V2 dataset (comparable to the state-of-the-art accuracy of $98.7\%$).Additionally, we demonstrate that ByteFormer can operate jointly on images andaudio, handling joint classification without explicit knowledge of the inputmodality. We release our code athttps://github.com/apple/corenet/tree/main/projects/byteformer.</description><author>Maxwell Horton, Sachin Mehta, Ali Farhadi, Mohammad Rastegari</author><pubDate>Mon, 01 Jul 2024 16:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00238v2</guid></item><item><title>A Geometric Algorithm for Tubular Shape Reconstruction from Skeletal Representation</title><link>http://arxiv.org/abs/2402.12797v3</link><description>We introduce a novel approach for the reconstruction of tubular shapes fromskeletal representations. Our method processes all skeletal points as a whole,eliminating the need for splitting input structure into multiple segments. Werepresent the tubular shape as a truncated signed distance function (TSDF) in avoxel hashing manner, in which the signed distance between a voxel center andthe object is computed through a simple geometric algorithm. Our method doesnot involve any surface sampling scheme or solving large matrix equations, andtherefore is a faster and more elegant solution for tubular shapereconstruction compared to other approaches. Experiments demonstrate theefficiency and effectiveness of the proposed method. Code is avaliable athttps://github.com/wlsdzyzl/Dragon.</description><author>Guoqing Zhang, Yang Li</author><pubDate>Mon, 01 Jul 2024 16:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12797v3</guid></item><item><title>Are LLMs Rational Investors? A Study on Detecting and Reducing the Financial Bias in LLMs</title><link>http://arxiv.org/abs/2402.12713v2</link><description>Large Language Models (LLMs) are increasingly adopted in financial analysisfor interpreting complex market data and trends. However, their use ischallenged by intrinsic biases (e.g., risk-preference bias) and a superficialunderstanding of market intricacies, necessitating a thorough assessment oftheir financial insight. To address these issues, we introduce Financial BiasIndicators (FBI), a framework with components like Bias Unveiler, BiasDetective, Bias Tracker, and Bias Antidote to identify, detect, analyze, andeliminate irrational biases in LLMs. By combining behavioral finance principleswith bias examination, we evaluate 23 leading LLMs and propose a de-biasingmethod based on financial causal knowledge. Results show varying degrees offinancial irrationality among models, influenced by their design and training.Models trained specifically on financial datasets may exhibit moreirrationality, and even larger financial language models (FinLLMs) can showmore bias than smaller, general models. We utilize four prompt-based methodsincorporating causal debiasing, effectively reducing financial biases in thesemodels. This work enhances the understanding of LLMs' bias in financialapplications, laying the foundation for developing more reliable and rationalfinancial analysis tools.</description><author>Yuhang Zhou, Yuchen Ni, Yunhui Gan, Zhangyue Yin, Xiang Liu, Jian Zhang, Sen Liu, Xipeng Qiu, Guangnan Ye, Hongfeng Chai</author><pubDate>Mon, 01 Jul 2024 16:42:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12713v2</guid></item><item><title>Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?</title><link>http://arxiv.org/abs/2308.15399v2</link><description>Making moral judgments is an essential step toward developing ethical AIsystems. Prevalent approaches are mostly implemented in a bottom-up manner,which uses a large set of annotated data to train models based on crowd-sourcedopinions about morality. These approaches have been criticized forovergeneralizing the moral stances of a limited group of annotators and lackingexplainability. This work proposes a flexible top-down framework to steer(Large) Language Models (LMs) to perform moral reasoning with well-establishedmoral theories from interdisciplinary research. The theory-guided top-downframework can incorporate various moral theories. Our experiments demonstratethe effectiveness of the proposed framework on datasets derived from moraltheories. Furthermore, we show the alignment between different moral theoriesand existing morality datasets. Our analysis exhibits the potential and flawsin existing resources (models and datasets) in developing explainable moraljudgment-making systems.</description><author>Jingyan Zhou, Minda Hu, Junan Li, Xiaoying Zhang, Xixin Wu, Irwin King, Helen Meng</author><pubDate>Mon, 01 Jul 2024 16:33:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15399v2</guid></item><item><title>Patch-Prompt Aligned Bayesian Prompt Tuning for Vision-Language Models</title><link>http://arxiv.org/abs/2303.09100v2</link><description>For downstream applications of vision-language pre-trained models, there hasbeen significant interest in constructing effective prompts. Existing works onprompt engineering, which either require laborious manual designs or optimizethe prompt tuning as a point estimation problem, may fail to describe diversecharacteristics of categories and limit their applications. We introduce aBayesian probabilistic resolution to prompt tuning, where the label-specificstochastic prompts are generated hierarchically by first sampling a latentvector from an underlying distribution and then employing a lightweightgenerative model. Importantly, we semantically regularize the tuning process byminimizing the statistical distance between the visual patches and linguisticprompts, which pushes the stochastic label representations to faithfullycapture diverse visual concepts, instead of overfitting the trainingcategories. We evaluate the effectiveness of our approach on four tasks:few-shot image recognition, base-to-new generalization, dataset transferlearning, and domain shifts. Extensive results over 15 datasets show promisingtransferability and generalization performance of our proposed model, bothquantitatively and qualitatively.</description><author>Xinyang Liu, Dongsheng Wang, Bowei Fang, Miaoge Li, Zhibin Duan, Yishi Xu, Bo Chen, Mingyuan Zhou</author><pubDate>Mon, 01 Jul 2024 16:29:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09100v2</guid></item><item><title>Unleashing the Power of Meta-tuning for Few-shot Generalization Through Sparse Interpolated Experts</title><link>http://arxiv.org/abs/2403.08477v3</link><description>Recent successes suggest that parameter-efficient fine-tuning of foundationmodels as the state-of-the-art method for transfer learning in vision,replacing the rich literature of alternatives such as meta-learning. In tryingto harness the best of both worlds, meta-tuning introduces a subsequentoptimization stage of foundation models but has so far only shown limitedsuccess and crucially tends to underperform on out-of-distribution (OOD) tasks.In this paper, we introduce Sparse MetA-Tuning (SMAT), a method inspired bysparse mixture-of-experts approaches and trained to isolate subsets ofpre-trained parameters automatically for meta-tuning on each task. SMATsuccessfully overcomes OOD sensitivity and delivers on the promise of enhancingthe transfer abilities of vision foundation models beyond parameter-efficientfine-tuning. We establish new state-of-the-art results on a challengingcombination of Meta-Dataset augmented with additional OOD tasks in bothzero-shot and gradient-based adaptation settings. In addition, we provide athorough analysis of the superiority of learned over hand-designed sparsitypatterns for sparse expert methods and the pivotal importance of the sparsitylevel in balancing between in-distribution and out-of-distributiongeneralization. Our code is publicly available.</description><author>Shengzhuang Chen, Jihoon Tack, Yunqiao Yang, Yee Whye Teh, Jonathan Richard Schwarz, Ying Wei</author><pubDate>Mon, 01 Jul 2024 16:29:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08477v3</guid></item><item><title>Learning the boundary-to-domain mapping using Lifting Product Fourier Neural Operators for partial differential equations</title><link>http://arxiv.org/abs/2406.16740v2</link><description>Neural operators such as the Fourier Neural Operator (FNO) have been shown toprovide resolution-independent deep learning models that can learn mappingsbetween function spaces. For example, an initial condition can be mapped to thesolution of a partial differential equation (PDE) at a future time-step using aneural operator. Despite the popularity of neural operators, their use topredict solution functions over a domain given only data over the boundary(such as a spatially varying Dirichlet boundary condition) remains unexplored.In this paper, we refer to such problems as boundary-to-domain problems; theyhave a wide range of applications in areas such as fluid mechanics, solidmechanics, heat transfer etc. We present a novel FNO-based architecture, namedLifting Product FNO (or LP-FNO) which can map arbitrary boundary functionsdefined on the lower-dimensional boundary to a solution in the entire domain.Specifically, two FNOs defined on the lower-dimensional boundary are liftedinto the higher dimensional domain using our proposed lifting product layer. Wedemonstrate the efficacy and resolution independence of the proposed LP-FNO forthe 2D Poisson equation.</description><author>Aditya Kashi, Arka Daw, Muralikrishnan Gopalakrishnan Meena, Hao Lu</author><pubDate>Mon, 01 Jul 2024 16:27:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16740v2</guid></item><item><title>Safe Linear Bandits over Unknown Polytopes</title><link>http://arxiv.org/abs/2209.13694v3</link><description>The safe linear bandit problem (SLB) is an online approach to linearprogramming with unknown objective and unknown roundwise constraints, understochastic bandit feedback of rewards and safety risks of actions. We study thetradeoffs between efficacy and smooth safety costs of SLBs over polytopes, andthe role of aggressive doubly-optimistic play in avoiding the strongassumptions made by extant pessimistic-optimistic approaches. We first elucidate an inherent hardness in SLBs due the lack of knowledge ofconstraints: there exist `easy' instances, for which suboptimal extreme pointshave large `gaps', but on which SLB methods must still incur $\Omega(\sqrt{T})$regret or safety violations, due to an inability to resolve unknown optima toarbitrary precision. We then analyse a natural doubly-optimistic strategy forthe safe linear bandit problem, DOSS, which uses optimistic estimates of bothreward and safety risks to select actions, and show that despite the lack ofknowledge of constraints or feasible points, DOSS simultaneously obtains tightinstance-dependent $O(\log^2 T)$ bounds on efficacy regret, and $\tildeO(\sqrt{T})$ bounds on safety violations. Further, when safety is demanded to afinite precision, violations improve to $O(\log^2 T).$ These results rely on anovel dual analysis of linear bandits: we argue that \algoname proceeds byactivating noisy versions of at least $d$ constraints in each round, whichallows us to separately analyse rounds where a `poor' set of constraints isactivated, and rounds where `good' sets of constraints are activated. The costsin the former are controlled to $O(\log^2 T)$ by developing new dual notions ofgaps, based on global sensitivity analyses of linear programs, that quantifythe suboptimality of each such set of constraints. The latter costs arecontrolled to $O(1)$ by explicitly analysing the solutions of optimistic play.</description><author>Aditya Gangrade, Tianrui Chen, Venkatesh Saligrama</author><pubDate>Mon, 01 Jul 2024 16:26:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.13694v3</guid></item><item><title>ViANLI: Adversarial Natural Language Inference for Vietnamese</title><link>http://arxiv.org/abs/2406.17716v2</link><description>The development of Natural Language Processing (NLI) datasets and models hasbeen inspired by innovations in annotation design. With the rapid developmentof machine learning models today, the performance of existing machine learningmodels has quickly reached state-of-the-art results on a variety of tasksrelated to natural language processing, including natural language inferencetasks. By using a pre-trained model during the annotation process, it ispossible to challenge current NLI models by having humans producepremise-hypothesis combinations that the machine model cannot correctlypredict. To remain attractive and challenging in the research of naturallanguage inference for Vietnamese, in this paper, we introduce the adversarialNLI dataset to the NLP research community with the name ViANLI. This data setcontains more than 10K premise-hypothesis pairs and is built by a continuouslyadjusting process to obtain the most out of the patterns generated by theannotators. ViANLI dataset has brought many difficulties to many current SOTAmodels when the accuracy of the most powerful model on the test set onlyreached 48.4%. Additionally, the experimental results show that the modelstrained on our dataset have significantly improved the results on otherVietnamese NLI datasets.</description><author>Tin Van Huynh, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen</author><pubDate>Mon, 01 Jul 2024 16:19:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17716v2</guid></item><item><title>BeHonest: Benchmarking Honesty of Large Language Models</title><link>http://arxiv.org/abs/2406.13261v2</link><description>Previous works on Large Language Models (LLMs) have mainly focused onevaluating their helpfulness or harmlessness. However, honesty, another crucialalignment criterion, has received relatively less attention. Dishonestbehaviors in LLMs, such as spreading misinformation and defrauding users,eroding user trust, and causing real-world harm, present severe risks thatintensify as these models approach superintelligence levels. Enhancing honestyin LLMs addresses critical deficiencies and helps uncover latent capabilitiesthat are not readily expressed. This underscores the urgent need for reliablemethods and benchmarks to effectively ensure and evaluate the honesty of LLMs. In this paper, we introduce BeHonest, a pioneering benchmark specificallydesigned to assess honesty in LLMs comprehensively. BeHonest evaluates threeessential aspects of honesty: awareness of knowledge boundaries, avoidance ofdeceit, and consistency in responses. Building on this foundation, we designed10 scenarios to evaluate and analyze 9 popular LLMs on the market, includingboth closed-source and open-source models from different model families withvaried model sizes. Our findings indicate that there is still significant roomfor improvement in the honesty of LLMs. We also encourage the AI community toprioritize honesty alignment in LLMs. Our benchmark and code can be found at:\url{https://github.com/GAIR-NLP/BeHonest}.</description><author>Steffi Chern, Zhulin Hu, Yuqing Yang, Ethan Chern, Yuan Guo, Jiahe Jin, Binjie Wang, Pengfei Liu</author><pubDate>Mon, 01 Jul 2024 16:18:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13261v2</guid></item><item><title>Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text</title><link>http://arxiv.org/abs/2401.12070v2</link><description>Detecting text generated by modern large language models is thought to behard, as both LLMs and humans can exhibit a wide range of complex behaviors.However, we find that a score based on contrasting two closely related languagemodels is highly accurate at separating human-generated and machine-generatedtext. Based on this mechanism, we propose a novel LLM detector that onlyrequires simple calculations using a pair of pre-trained LLMs. The method,called Binoculars, achieves state-of-the-art accuracy without any trainingdata. It is capable of spotting machine text from a range of modern LLMswithout any model-specific modifications. We comprehensively evaluateBinoculars on a number of text sources and in varied situations. Over a widerange of document types, Binoculars detects over 90% of generated samples fromChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not beingtrained on any ChatGPT data.</description><author>Abhimanyu Hans, Avi Schwarzschild, Valeriia Cherepanova, Hamid Kazemi, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein</author><pubDate>Mon, 01 Jul 2024 16:17:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12070v2</guid></item><item><title>An Efficient Instance Segmentation Framework Based on Oriented Bounding Boxes</title><link>http://arxiv.org/abs/2401.08174v3</link><description>Instance segmentation for completely occluded objects and dense objects inrobot vision measurement are two challenging tasks. To uniformly deal withthem, this paper proposes a unified coarse-to-fine instance segmentationframework, CFNet, which uses box prompt-based segmentation foundation models(BSMs), e.g., Segment Anything Model. Specifically, CFNet first detectsoriented bounding boxes (OBBs) to distinguish instances and provide coarselocalization information. Then, it predicts OBB prompt-related masks for finesegmentation. CFNet performs instance segmentation with OBBs that only containpartial object boundaries on occluders to predict occluded object instances,which overcomes the difficulty of existing amodal instance segmentation methodsin directly predicting occluded objects. In addition, since OBBs only serve asprompts, CFNet alleviates the over-dependence on bounding box detectionperformance of current instance segmentation methods using OBBs for denseobjects. Moreover, to enable BSMs to handle OBB prompts, we propose a novel OBBprompt encoder. To make CFNet more lightweight, we perform knowledgedistillation on it and introduce a Gaussian label smoothing method for teachermodel outputs. Experiments demonstrate that CFNet outperforms current instancesegmentation methods on both industrial and public datasets. The code isavailable at https://github.com/zhen6618/OBBInstanceSegmentation.</description><author>Zhen Zhou, Junfeng Fan, Yunkai Ma, Sihan Zhao, Fengshui Jing, Min Tan</author><pubDate>Mon, 01 Jul 2024 16:16:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08174v3</guid></item><item><title>$R^3$-NL2GQL: A Model Coordination and Knowledge Graph Alignment Approach for NL2GQL</title><link>http://arxiv.org/abs/2311.01862v2</link><description>While current tasks of converting natural language to SQL (NL2SQL) usingFoundation Models have shown impressive achievements, adapting these approachesfor converting natural language to Graph Query Language (NL2GQL) encountershurdles due to the distinct nature of GQL compared to SQL, alongside thediverse forms of GQL. Moving away from traditional rule-based and slot-fillingmethodologies, we introduce a novel approach, $R^3$-NL2GQL, integrating bothsmall and large Foundation Models for ranking, rewriting, and refining tasks.This method leverages the interpretative strengths of smaller models forinitial ranking and rewriting stages, while capitalizing on the superiorgeneralization and query generation prowess of larger models for the finaltransformation of natural language queries into GQL formats. Addressing thescarcity of datasets in this emerging field, we have developed a bilingualdataset, sourced from graph database manuals and selected open-source KnowledgeGraphs (KGs). Our evaluation of this methodology on this dataset demonstratesits promising efficacy and robustness.</description><author>Yuhang Zhou, Yu He, Siyu Tian, Yuchen Ni, Zhangyue Yin, Xiang Liu, Chuanjun Ji, Sen Liu, Xipeng Qiu, Guangnan Ye, Hongfeng Chai</author><pubDate>Mon, 01 Jul 2024 15:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01862v2</guid></item><item><title>SCAR: Efficient Instruction-Tuning for Large Language Models via Style Consistency-Aware Response Ranking</title><link>http://arxiv.org/abs/2406.10882v2</link><description>Recent studies have shown that maintaining a consistent response style byhuman experts and enhancing data quality in training sets can significantlyimprove the performance of fine-tuned Large Language Models (LLMs) whilereducing the number of training examples needed. However, the precisedefinition of style and the relationship between style, data quality, and LLMperformance remains unclear. This research decomposes response style intopresentation and composition styles and finds that, among training data ofsimilar quality, those with higher style consistency lead to better LLMperformance. Inspired by this, we introduce Style Consistency-Aware ResponseRanking (SCAR), which automatically prioritizes instruction-response pairs inthe training set based on their response stylistic consistency. By selectingthe most style-consistent examples, ranging from the top 25% to 0.7% of thefull dataset, the fine-tuned LLMs can match or even surpass the performance ofmodels trained on the entire dataset in coding and open-endedquestion-answering benchmarks. Code and data are available athttps://github.com/zhuang-li/SCAR .</description><author>Zhuang Li, Yuncheng Hua, Thuy-Trang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari</author><pubDate>Mon, 01 Jul 2024 15:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10882v2</guid></item><item><title>Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces II: non-compact symmetric spaces</title><link>http://arxiv.org/abs/2301.13088v3</link><description>Gaussian processes are arguably the most important class of spatiotemporalmodels within machine learning. They encode prior information about the modeledfunction and can be used for exact or approximate Bayesian learning. In manyapplications, particularly in physical sciences and engineering, but also inareas such as geostatistics and neuroscience, invariance to symmetries is oneof the most fundamental forms of prior information one can consider. Theinvariance of a Gaussian process' covariance to such symmetries gives rise tothe most natural generalization of the concept of stationarity to such spaces.In this work, we develop constructive and practical techniques for buildingstationary Gaussian processes on a very large class of non-Euclidean spacesarising in the context of symmetries. Our techniques make it possible to (i)calculate covariance kernels and (ii) sample from prior and posterior Gaussianprocesses defined on such spaces, both in a practical manner. This work issplit into two parts, each involving different technical considerations: part Istudies compact spaces, while part II studies non-compact spaces possessingcertain structure. Our contributions make the non-Euclidean Gaussian processmodels we study compatible with well-understood computational techniquesavailable in standard Gaussian process software packages, thereby making themaccessible to practitioners.</description><author>Iskander Azangulov, Andrei Smolensky, Alexander Terenin, Viacheslav Borovitskiy</author><pubDate>Mon, 01 Jul 2024 15:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13088v3</guid></item><item><title>Inverse Evolution Layers: Physics-informed Regularizers for Deep Neural Networks</title><link>http://arxiv.org/abs/2307.07344v2</link><description>Traditional image processing methods employing partial differential equations(PDEs) offer a multitude of meaningful regularizers, along with valuabletheoretical foundations for a wide range of image-related tasks. This makestheir integration into neural networks a promising avenue. In this paper, weintroduce a novel regularization approach inspired by the reverse process ofPDE-based evolution models. Specifically, we propose inverse evolution layers(IELs), which serve as bad property amplifiers to penalize neural networks ofwhich outputs have undesired characteristics. Using IELs, one can achievespecific regularization objectives and endow neural networks' outputs withcorresponding properties of the PDE models. Our experiments, focusing onsemantic segmentation tasks using heat-diffusion IELs, demonstrate theireffectiveness in mitigating noisy label effects. Additionally, we developcurve-motion IELs to enforce convex shape regularization in neuralnetwork-based segmentation models for preventing the generation of concaveoutputs. Theoretical analysis confirms the efficacy of IELs as an effectiveregularization mechanism, particularly in handling training with label issues.</description><author>Chaoyu Liu, Zhonghua Qiao, Chao Li, Carola-Bibiane Schönlieb</author><pubDate>Mon, 01 Jul 2024 15:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07344v2</guid></item><item><title>On the Convergence of Multi-objective Optimization under Generalized Smoothness</title><link>http://arxiv.org/abs/2405.19440v3</link><description>Multi-objective optimization (MOO) is receiving more attention in variousfields such as multi-task learning. Recent works provide some effectivealgorithms with theoretical analysis but they are limited by the standard$L$-smooth or bounded-gradient assumptions, which are typically unsatisfactoryfor neural networks, such as recurrent neural networks (RNNs) and transformers.In this paper, we study a more general and realistic class of $\ell$-smoothloss functions, where $\ell$ is a general non-decreasing function of gradientnorm. We develop two novel single-loop algorithms for $\ell$-smooth MOOproblems, Generalized Smooth Multi-objective Gradient descent (GSMGrad) and itsstochastic variant, Stochastic Generalized Smooth Multi-objective Gradientdescent (SGSMGrad), which approximate the conflict-avoidant (CA) direction thatmaximizes the minimum improvement among objectives. We provide a comprehensiveconvergence analysis of both algorithms and show that they converge to an$\epsilon$-accurate Pareto stationary point with a guaranteed $\epsilon$-levelaverage CA distance (i.e., the gap between the updating direction and the CAdirection) over all iterations, where totally $\mathcal{O}(\epsilon^{-2})$ and$\mathcal{O}(\epsilon^{-4})$ samples are needed for deterministic andstochastic settings, respectively. Our algorithms can also guarantee a tighter$\epsilon$-level CA distance in each iteration using more samples. Moreover, wepropose a practical variant of GSMGrad named GSMGrad-FA using onlyconstant-level time and space, while achieving the same performance guaranteeas GSMGrad. Our experiments validate our theory and demonstrate theeffectiveness of the proposed methods.</description><author>Qi Zhang, Peiyao Xiao, Kaiyi Ji, Shaofeng Zou</author><pubDate>Mon, 01 Jul 2024 15:43:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19440v3</guid></item><item><title>DreamPBR: Text-driven Generation of High-resolution SVBRDF with Multi-modal Guidance</title><link>http://arxiv.org/abs/2404.14676v2</link><description>Prior material creation methods had limitations in producing diverse resultsmainly because reconstruction-based methods relied on real-world measurementsand generation-based methods were trained on relatively small materialdatasets. To address these challenges, we propose DreamPBR, a noveldiffusion-based generative framework designed to create spatially-varyingappearance properties guided by text and multi-modal controls, providing highcontrollability and diversity in material generation. Key to achieving diverseand high-quality PBR material generation lies in integrating the capabilitiesof recent large-scale vision-language models trained on billions of text-imagepairs, along with material priors derived from hundreds of PBR materialsamples. We utilize a novel material Latent Diffusion Model (LDM) to establishthe mapping between albedo maps and the corresponding latent space. The latentrepresentation is then decoded into full SVBRDF parameter maps using arendering-aware PBR decoder. Our method supports tileable generation throughconvolution with circular padding. Furthermore, we introduce a multi-modalguidance module, which includes pixel-aligned guidance, style image guidance,and 3D shape guidance, to enhance the control capabilities of the material LDM.We demonstrate the effectiveness of DreamPBR in material creation, showcasingits versatility and user-friendliness on a wide range of controllablegeneration and editing applications.</description><author>Linxuan Xin, Zheng Zhang, Jinfu Wei, Wei Gao, Duan Gao</author><pubDate>Mon, 01 Jul 2024 15:43:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14676v2</guid></item><item><title>Rethinking LLM Memorization through the Lens of Adversarial Compression</title><link>http://arxiv.org/abs/2404.15146v2</link><description>Large language models (LLMs) trained on web-scale datasets raise substantialconcerns regarding permissible data usage. One major question is whether thesemodels "memorize" all their training data or they integrate many data sourcesin some way more akin to how a human would learn and synthesize information.The answer hinges, to a large degree, on how we define memorization. In thiswork, we propose the Adversarial Compression Ratio (ACR) as a metric forassessing memorization in LLMs. A given string from the training data isconsidered memorized if it can be elicited by a prompt (much) shorter than thestring itself -- in other words, if these strings can be "compressed" with themodel by computing adversarial prompts of fewer tokens. The ACR overcomes thelimitations of existing notions of memorization by (i) offering an adversarialview of measuring memorization, especially for monitoring unlearning andcompliance; and (ii) allowing for the flexibility to measure memorization forarbitrary strings at a reasonably low compute. Our definition serves as apractical tool for determining when model owners may be violating terms arounddata usage, providing a potential legal tool and a critical lens through whichto address such scenarios.</description><author>Avi Schwarzschild, Zhili Feng, Pratyush Maini, Zachary C. Lipton, J. Zico Kolter</author><pubDate>Mon, 01 Jul 2024 15:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15146v2</guid></item><item><title>From Alexnet to Transformers: Measuring the Non-linearity of Deep Neural Networks with Affine Optimal Transport</title><link>http://arxiv.org/abs/2310.11439v3</link><description>In the last decade, we have witnessed the introduction of several novel deepneural network (DNN) architectures exhibiting ever-increasing performanceacross diverse tasks. Explaining the upward trend of their performance,however, remains difficult as different DNN architectures of comparable depthand width -- common factors associated with their expressive power -- mayexhibit a drastically different performance even when trained on the samedataset. In this paper, we introduce the concept of the non-linearity signatureof DNN, the first theoretically sound solution for approximately measuring thenon-linearity of deep neural networks. Built upon a score derived fromclosed-form optimal transport mappings, this signature provides a betterunderstanding of the inner workings of a wide range of DNN architectures andlearning paradigms, with a particular emphasis on the computer vision task. Weprovide extensive experimental results that highlight the practical usefulnessof the proposed non-linearity signature and its potential for long-reachingimplications. The code for our work is available athttps://github.com/qbouniot/AffScoreDeep</description><author>Quentin Bouniot, Ievgen Redko, Anton Mallasto, Charlotte Laclau, Karol Arndt, Oliver Struckmeier, Markus Heinonen, Ville Kyrki, Samuel Kaski</author><pubDate>Mon, 01 Jul 2024 15:39:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11439v3</guid></item><item><title>$Classi|Q\rangle$ Towards a Translation Framework To Bridge The Classical-Quantum Programming Gap</title><link>http://arxiv.org/abs/2406.06764v3</link><description>Quantum computing, albeit readily available as hardware or emulated on thecloud, is still far from being available in general regarding complexprogramming paradigms and learning curves. This vision paper introduces$Classi|Q\rangle$, a translation framework idea to bridge Classical and QuantumComputing by translating high-level programming languages, e.g., Python or C++,into a low-level language, e.g., Quantum Assembly. Our idea paper serves as ablueprint for ongoing efforts in quantum software engineering, offering aroadmap for further $Classi|Q\rangle$ development to meet the diverse needs ofresearchers and practitioners. $Classi|Q\rangle$ is designed to empowerresearchers and practitioners with no prior quantum experience to harness thepotential of hybrid quantum computation. We also discuss future enhancements to$Classi|Q\rangle$, including support for additional quantum languages, improvedoptimization strategies, and integration with emerging quantum computingplatforms.</description><author>Matteo Esposito, Maryam Tavassoli Sabzevari, Boshuai Ye, Davide Falessi, Arif Ali Khan, Davide Taibi</author><pubDate>Mon, 01 Jul 2024 15:37:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06764v3</guid></item><item><title>Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion</title><link>http://arxiv.org/abs/2405.11464v2</link><description>Prompt tuning is a promising method to fine-tune a pre-trained language modelwithout retraining its large-scale parameters. Instead, it attaches a softprompt to the input text, whereby downstream tasks can be well adapted bymerely learning the embeddings of prompt tokens. Nevertheless, existing methodsstill suffer from two challenges: (i) they are hard to balance accuracy andefficiency. A longer (shorter) soft prompt generally leads to a better(worse)accuracy but at the cost of more (less) training time. (ii)The performance maynot be consistent when adapting to different downstream tasks. We attribute itto the same embedding space but responsible for different requirements ofdownstream tasks. To address these issues, we propose an Efficient PromptTuning method (EPT) by multi-space projection and prompt fusion. Specifically,it decomposes a given soft prompt into a shorter prompt and two low-rankmatrices, significantly reducing the training time. Accuracy is also enhancedby leveraging low-rank matrices and the short prompt as additional knowledgesources to enrich the semantics of the original short prompt. In addition, weproject the soft prompt into multiple subspaces to improve the performanceconsistency, and then adaptively learn the combination weights of differentspaces through a gating network. Experiments on 13 natural language processingdownstream tasks show that our method significantly and consistentlyoutperforms 11 comparison methods with the relative percentage of improvementsup to 12.9%, and training time decreased by 14%.</description><author>Pengxiang Lan, Enneng Yang, Yuting Liu, Guibing Guo, Linying Jiang, Jianzhe Zhao, Xingwei Wang</author><pubDate>Mon, 01 Jul 2024 15:27:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11464v2</guid></item><item><title>Decomposing Global Feature Effects Based on Feature Interactions</title><link>http://arxiv.org/abs/2306.00541v2</link><description>Global feature effect methods, such as partial dependence plots, provide anintelligible visualization of the expected marginal feature effect. However,such global feature effect methods can be misleading, as they do not representlocal feature effects of single observations well when feature interactions arepresent. We formally introduce generalized additive decomposition of globaleffects (GADGET), which is a new framework based on recursive partitioning tofind interpretable regions in the feature space such that theinteraction-related heterogeneity of local feature effects is minimized. Weprovide a mathematical foundation of the framework and show that it isapplicable to the most popular methods to visualize marginal feature effects,namely partial dependence, accumulated local effects, and Shapley additiveexplanations (SHAP) dependence. Furthermore, we introduce and validate a newpermutation-based interaction test to detect significant feature interactionsthat is applicable to any feature effect method that fits into our proposedframework. We empirically evaluate the theoretical characteristics of theproposed methods based on various feature effect methods in differentexperimental settings. Moreover, we apply our introduced methodology to threereal-world examples to showcase their usefulness.</description><author>Julia Herbinger, Marvin N. Wright, Thomas Nagler, Bernd Bischl, Giuseppe Casalicchio</author><pubDate>Mon, 01 Jul 2024 15:26:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00541v2</guid></item><item><title>Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt</title><link>http://arxiv.org/abs/2406.04031v2</link><description>In the realm of large vision language models (LVLMs), jailbreak attacks serveas a red-teaming approach to bypass guardrails and uncover safety implications.Existing jailbreaks predominantly focus on the visual modality, perturbingsolely visual inputs in the prompt for attacks. However, they fall short whenconfronted with aligned models that fuse visual and textual featuressimultaneously for generation. To address this limitation, this paperintroduces the Bi-Modal Adversarial Prompt Attack (BAP), which executesjailbreaks by optimizing textual and visual prompts cohesively. Initially, weadversarially embed universally harmful perturbations in an image, guided by afew-shot query-agnostic corpus (e.g., affirmative prefixes and negativeinhibitions). This process ensures that image prompt LVLMs to respondpositively to any harmful queries. Subsequently, leveraging the adversarialimage, we optimize textual prompts with specific harmful intent. In particular,we utilize a large language model to analyze jailbreak failures and employchain-of-thought reasoning to refine textual prompts through afeedback-iteration manner. To validate the efficacy of our approach, weconducted extensive evaluations on various datasets and LVLMs, demonstratingthat our method significantly outperforms other methods by large margins(+29.03% in attack success rate on average). Additionally, we showcase thepotential of our attacks on black-box commercial LVLMs, such as Gemini andChatGLM.</description><author>Zonghao Ying, Aishan Liu, Tianyuan Zhang, Zhengmin Yu, Siyuan Liang, Xianglong Liu, Dacheng Tao</author><pubDate>Mon, 01 Jul 2024 15:25:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04031v2</guid></item><item><title>Topo4D: Topology-Preserving Gaussian Splatting for High-Fidelity 4D Head Capture</title><link>http://arxiv.org/abs/2406.00440v2</link><description>4D head capture aims to generate dynamic topological meshes and correspondingtexture maps from videos, which is widely utilized in movies and games for itsability to simulate facial muscle movements and recover dynamic textures inpore-squeezing. The industry often adopts the method involving multi-viewstereo and non-rigid alignment. However, this approach is prone to errors andheavily reliant on time-consuming manual processing by artists. To simplifythis process, we propose Topo4D, a novel framework for automatic geometry andtexture generation, which optimizes densely aligned 4D heads and 8K texturemaps directly from calibrated multi-view time-series images. Specifically, wefirst represent the time-series faces as a set of dynamic 3D Gaussians withfixed topology in which the Gaussian centers are bound to the mesh vertices.Afterward, we perform alternative geometry and texture optimizationframe-by-frame for high-quality geometry and texture learning while maintainingtemporal topology stability. Finally, we can extract dynamic facial meshes inregular wiring arrangement and high-fidelity textures with pore-level detailsfrom the learned Gaussians. Extensive experiments show that our method achievessuperior results than the current SOTA face reconstruction methods both in thequality of meshes and textures. Project page:https://xuanchenli.github.io/Topo4D/.</description><author>Xuanchen Li, Yuhao Cheng, Xingyu Ren, Haozhe Jia, Di Xu, Wenhan Zhu, Yichao Yan</author><pubDate>Mon, 01 Jul 2024 15:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.00440v2</guid></item><item><title>Federated Temporal Difference Learning with Linear Function Approximation under Environmental Heterogeneity</title><link>http://arxiv.org/abs/2302.02212v2</link><description>We initiate the study of federated reinforcement learning under environmentalheterogeneity by considering a policy evaluation problem. Our setup involves$N$ agents interacting with environments that share the same state and actionspace but differ in their reward functions and state transition kernels.Assuming agents can communicate via a central server, we ask: Does exchanginginformation expedite the process of evaluating a common policy? To answer thisquestion, we provide the first comprehensive finite-time analysis of afederated temporal difference (TD) learning algorithm with linear functionapproximation, while accounting for Markovian sampling, heterogeneity in theagents' environments, and multiple local updates to save communication. Ouranalysis crucially relies on several novel ingredients: (i) derivingperturbation bounds on TD fixed points as a function of the heterogeneity inthe agents' underlying Markov decision processes (MDPs); (ii) introducing avirtual MDP to closely approximate the dynamics of the federated TD algorithm;and (iii) using the virtual MDP to make explicit connections to federatedoptimization. Putting these pieces together, we rigorously prove that in alow-heterogeneity regime, exchanging model estimates leads to linearconvergence speedups in the number of agents.</description><author>Han Wang, Aritra Mitra, Hamed Hassani, George J. Pappas, James Anderson</author><pubDate>Mon, 01 Jul 2024 15:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02212v2</guid></item><item><title>Instruction-Guided Scene Text Recognition</title><link>http://arxiv.org/abs/2401.17851v2</link><description>Multi-modal models show appealing performance in visual recognition tasksrecently, as free-form text-guided training evokes the ability to understandfine-grained visual content. However, current models are either inefficient orcannot be trivially upgraded to scene text recognition (STR) due to thecomposition difference between natural and text images. We propose a novelinstruction-guided scene text recognition (IGTR) paradigm that formulates STRas an instruction learning problem and understands text images by predictingcharacter attributes, e.g., character frequency, position, etc. IGTR firstdevises $\left \langle condition,question,answer\right \rangle$ instructiontriplets, providing rich and diverse descriptions of character attributes. Toeffectively learn these attributes through question-answering, IGTR developslightweight instruction encoder, cross-modal feature fusion module andmulti-task answer head, which guides nuanced text image understanding.Furthermore, IGTR realizes different recognition pipelines simply by usingdifferent instructions, enabling a character-understanding-based text reasoningparadigm that considerably differs from current methods. Experiments on Englishand Chinese benchmarks show that IGTR outperforms existing models bysignificant margins, while maintaining a small model size and efficientinference speed. Moreover, by adjusting the sampling of instructions, IGTRoffers an elegant way to tackle the recognition of both rarely appearing andmorphologically similar characters, which were previous challenges. Code at\href{https://github.com/Topdu/OpenOCR}{this http URL}.</description><author>Yongkun Du, Zhineng Chen, Yuchen Su, Caiyan Jia, Yu-Gang Jiang</author><pubDate>Mon, 01 Jul 2024 15:06:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17851v2</guid></item><item><title>Text2Robot: Evolutionary Robot Design from Text Descriptions</title><link>http://arxiv.org/abs/2406.19963v2</link><description>Robot design has traditionally been costly and labor-intensive. Despiteadvancements in automated processes, it remains challenging to navigate a vastdesign space while producing physically manufacturable robots. We introduceText2Robot, a framework that converts user text specifications and performancepreferences into physical quadrupedal robots. Within minutes, Text2Robot canuse text-to-3D models to provide strong initializations of diversemorphologies. Within a day, our geometric processing algorithms andbody-control co-optimization produce a walking robot by explicitly consideringreal-world electronics and manufacturability. Text2Robot enables rapidprototyping and opens new opportunities for robot design with generativemodels.</description><author>Ryan P. Ringel, Zachary S. Charlick, Jiaxun Liu, Boxi Xia, Boyuan Chen</author><pubDate>Mon, 01 Jul 2024 15:05:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19963v2</guid></item><item><title>DCSI -- An improved measure of cluster separability based on separation and connectedness</title><link>http://arxiv.org/abs/2310.12806v2</link><description>Whether class labels in a given data set correspond to meaningful clusters iscrucial for the evaluation of clustering algorithms using real-world data sets.This property can be quantified by separability measures. The central aspectsof separability for density-based clustering are between-class separation andwithin-class connectedness, and neither classification-based complexitymeasures nor cluster validity indices (CVIs) adequately incorporate them. Anewly developed measure (density cluster separability index, DCSI) aims toquantify these two characteristics and can also be used as a CVI. Extensiveexperiments on synthetic data indicate that DCSI correlates strongly with theperformance of DBSCAN measured via the adjusted Rand index (ARI) but lacksrobustness when it comes to multi-class data sets with overlapping classes thatare ill-suited for density-based hard clustering. Detailed evaluation onfrequently used real-world data sets shows that DCSI can correctly identifytouching or overlapping classes that do not correspond to meaningfuldensity-based clusters.</description><author>Jana Gauss, Fabian Scheipl, Moritz Herrmann</author><pubDate>Mon, 01 Jul 2024 15:04:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12806v2</guid></item><item><title>Local-Aware Global Attention Network for Person Re-Identification Based on Body and Hand Images</title><link>http://arxiv.org/abs/2209.04821v3</link><description>Learning representative, robust and discriminative information from images isessential for effective person re-identification (Re-Id). In this paper, wepropose a compound approach for end-to-end discriminative deep feature learningfor person Re-Id based on both body and hand images. We carefully design theLocal-Aware Global Attention Network (LAGA-Net), a multi-branch deep networkarchitecture consisting of one branch for spatial attention, one branch forchannel attention, one branch for global feature representations and anotherbranch for local feature representations. The attention branches focus on therelevant features of the image while suppressing the irrelevant backgrounds. Inorder to overcome the weakness of the attention mechanisms, equivariant topixel shuffling, we integrate relative positional encodings into the spatialattention module to capture the spatial positions of pixels. The global branchintends to preserve the global context or structural information. For the thelocal branch, which intends to capture the fine-grained information, we performuniform partitioning to generate stripes on the conv-layer horizontally. Weretrieve the parts by conducting a soft partition without explicitlypartitioning the images or requiring external cues such as pose estimation. Aset of ablation study shows that each component contributes to the increasedperformance of the LAGA-Net. Extensive evaluations on four popular body-basedperson Re-Id benchmarks and two publicly available hand datasets demonstratethat our proposed method consistently outperforms existing state-of-the-artmethods.</description><author>Nathanael L. Baisa</author><pubDate>Mon, 01 Jul 2024 14:50:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.04821v3</guid></item><item><title>Assessing Logical Reasoning Capabilities of Encoder-Only Transformer Models</title><link>http://arxiv.org/abs/2312.11720v2</link><description>Logical reasoning is central to complex human activities, such as thinking,debating, and planning; it is also a central component of many AI systems aswell. In this paper, we investigate the extent to which encoder-onlytransformer language models (LMs) can reason according to logical rules. We askwhether those LMs can deduce theorems in propositional calculus and first-orderlogic; if their relative success in these problems reflects general logicalcapabilities; and which layers contribute the most to the task. First, we showfor several encoder-only LMs that they can be trained, to a reasonable degree,to determine logical validity on various datasets. Next, by cross-probingfine-tuned models on these datasets, we show that LMs have difficulty intransferring their putative logical reasoning ability, which suggests that theymay have learned dataset-specific features, instead of a general capability.Finally, we conduct a layerwise probing experiment, which shows that thehypothesis classification task is mostly solved through higher layers.</description><author>Paulo Pirozelli, Marcos M. José, Paulo de Tarso P. Filho, Anarosa A. F. Brandão, Fabio G. Cozman</author><pubDate>Mon, 01 Jul 2024 14:49:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11720v2</guid></item><item><title>Biology-inspired joint distribution neurons based on Hierarchical Correlation Reconstruction allowing for multidirectional neural networks</title><link>http://arxiv.org/abs/2405.05097v3</link><description>Biological neural networks seem qualitatively superior (e.g. in learning,flexibility, robustness) from current artificial like Multi-Layer Perceptron(MLP) or Kolmogorov-Arnold Network (KAN). Simultaneously, in contrast to them:have fundamentally multidirectional signal propagation~\cite{axon}, also ofprobability distributions e.g. for uncertainty estimation, and are believed notbeing able to use standard backpropagation training~\cite{backprop}. There areproposed novel artificial neurons based on HCR (Hierarchical CorrelationReconstruction) removing the above low level differences: with neuronscontaining local joint distribution model (of its connections), representingjoint density on normalized variables as just linear combination among$(f_\mathbf{j})$ orthonormal polynomials: $\rho(\mathbf{x})=\sum_{\mathbf{j}\inB} a_\mathbf{j} f_\mathbf{j}(\mathbf{x})$ for $\mathbf{x} \in [0,1]^d$ and $B$some chosen basis, with basis growth approaching complete description of jointdistribution. By various index summations of such $(a_\mathbf{j})$ tensor asneuron parameters, we get simple formulas for e.g. conditional expected valuesfor propagation in any direction, like $E[x|y,z]$, $E[y|x]$, which degenerateto KAN-like parametrization if restricting to pairwise dependencies. Such HCRnetwork can also propagate probability distributions (also joint) like$\rho(y,z|x)$. It also allows for additional training approaches, like direct$(a_\mathbf{j})$ estimation, through tensor decomposition, or more biologicallyplausible information bottleneck training: layers directly influencing onlyneighbors, optimizing content to maximize information about the next layer, andminimizing about the previous to minimize the noise.</description><author>Jarek Duda</author><pubDate>Mon, 01 Jul 2024 14:46:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05097v3</guid></item><item><title>On the Hardness of Faithful Chain-of-Thought Reasoning in Large Language Models</title><link>http://arxiv.org/abs/2406.10625v2</link><description>As Large Language Models (LLMs) are increasingly being employed in real-worldapplications in critical domains such as healthcare, it is important to ensurethat the Chain-of-Thought (CoT) reasoning generated by these models faithfullycaptures their underlying behavior. While LLMs are known to generate CoT reasoning that is appealing to humans,prior studies have shown that these explanations do not accurately reflect theactual behavior of the underlying LLMs. In this work, we explore the promise ofthree broad approaches commonly employed to steer the behavior of LLMs toenhance the faithfulness of the CoT reasoning generated by LLMs: in-contextlearning, fine-tuning, and activation editing. Specifically, we introduce novelstrategies for in-context learning, fine-tuning, and activation editing aimedat improving the faithfulness of the CoT reasoning. We then carry out extensiveempirical analyses with multiple benchmark datasets to explore the promise ofthese strategies. Our analyses indicate that these strategies offer limitedsuccess in improving the faithfulness of the CoT reasoning, with only slightperformance enhancements in controlled scenarios. Activation editingdemonstrated minimal success, while fine-tuning and in-context learningachieved marginal improvements that failed to generalize across diversereasoning and truthful question-answering benchmarks. In summary, our workunderscores the inherent difficulty in eliciting faithful CoT reasoning fromLLMs, suggesting that the current array of approaches may not be sufficient toaddress this complex challenge.</description><author>Sree Harsha Tanneru, Dan Ley, Chirag Agarwal, Himabindu Lakkaraju</author><pubDate>Mon, 01 Jul 2024 14:36:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10625v2</guid></item><item><title>Robust Model-Based Reinforcement Learning with an Adversarial Auxiliary Model</title><link>http://arxiv.org/abs/2406.09976v2</link><description>Reinforcement learning has demonstrated impressive performance in variouschallenging problems such as robotics, board games, and classical arcade games.However, its real-world applications can be hindered by the absence ofrobustness and safety in the learned policies. More specifically, an RL agentthat trains in a certain Markov decision process (MDP) often struggles toperform well in nearly identical MDPs. To address this issue, we employ theframework of Robust MDPs (RMDPs) in a model-based setting and introduce a novellearned transition model. Our method specifically incorporates an auxiliarypessimistic model, updated adversarially, to estimate the worst-case MDP withina Kullback-Leibler uncertainty set. In comparison to several existing works,our work does not impose any additional conditions on the training environment,such as the need for a parametric simulator. To test the effectiveness of theproposed pessimistic model in enhancing policy robustness, we integrate it intoa practical RL algorithm, called Robust Model-Based Policy Optimization(RMBPO). Our experimental results indicate a notable improvement in policyrobustness on high-dimensional MuJoCo control tasks, with the auxiliary modelenhancing the performance of the learned policy in distorted MDPs. We furtherexplore the learned deviation between the proposed auxiliary world model andthe nominal model, to examine how pessimism is achieved. By learning apessimistic world model and demonstrating its role in improving policyrobustness, our research contributes towards making (model-based) RL morerobust.</description><author>Siemen Herremans, Ali Anwar, Siegfried Mercelis</author><pubDate>Mon, 01 Jul 2024 14:35:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09976v2</guid></item><item><title>CILF-CIAE: CLIP-driven Image-Language Fusion for Correcting Inverse Age Estimation</title><link>http://arxiv.org/abs/2312.01758v2</link><description>The age estimation task aims to predict the age of an individual by analyzingfacial features in an image. The development of age estimation can improve theefficiency and accuracy of various applications (e.g., age verification andsecure access control, etc.). In recent years, contrastive language-imagepre-training (CLIP) has been widely used in various multimodal tasks and hasmade some progress in the field of age estimation. However, existing CLIP-basedage estimation methods require high memory usage (quadratic complexity) whenglobally modeling images, and lack an error feedback mechanism to prompt themodel about the quality of age prediction results. To tackle the above issues,we propose a novel CLIP-driven Image-Language Fusion for Correcting Inverse AgeEstimation (CILF-CIAE). Specifically, we first introduce the CLIP model toextract image features and text semantic information respectively, and map theminto a highly semantically aligned high-dimensional feature space. Next, wedesigned a new Transformer architecture (i.e., FourierFormer) to achievechannel evolution and spatial interaction of images, and to fuse image and textsemantic information. Compared with the quadratic complexity of the attentionmechanism, the proposed Fourierformer is of linear log complexity. To furthernarrow the semantic gap between image and text features, we utilize anefficient contrastive multimodal learning module that supervises the multimodalfusion process of FourierFormer through contrastive loss for image-textmatching, thereby improving the interaction effect between differentmodalities. Finally, we introduce reversible age estimation, which usesend-to-end error feedback to reduce the error rate of age predictions. Throughextensive experiments on multiple data sets, CILF-CIAE has achieved better ageprediction results.</description><author>Yuntao Shou, Wei Ai, Tao Meng, Keqin Li</author><pubDate>Mon, 01 Jul 2024 14:31:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01758v2</guid></item><item><title>First-Step Advantage: Importance of Starting Right in Multi-Step Math Reasoning</title><link>http://arxiv.org/abs/2311.07945v3</link><description>Language models can solve complex reasoning tasks better by learning togenerate rationales for their predictions. Often these models know how to solvea task but their auto-regressive decoding nature leads to incorrect results ifthey start incorrectly. We observe that smaller models in particular whencorrected, can solve a task that they would have otherwise struggled with. Wedemonstrate this phenomenon by using a larger model to guide smaller models,which leads to significantly improved performance (up to +24 points on theGSM8K dataset by 7B models). To assist smaller models in initiating thestarting step, we propose QuestCoT, where a smaller model first asks itself howto start, before proceeding with a chain of reasoning. On various multistepmathematical reasoning datasets over multiple smaller models, we show thatgetting the right start can lead to significant performance gains across allmodels (gains of up to +6 points on GSM8K, +9 on SVAMP, +5 on ASDiv, and +7 onMultiArith).</description><author>Kushal Jain, Moritz Miller, Niket Tandon, Kumar Shridhar</author><pubDate>Mon, 01 Jul 2024 14:25:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07945v3</guid></item><item><title>Connectivity Oracles for Predictable Vertex Failures</title><link>http://arxiv.org/abs/2312.08489v3</link><description>The problem of designing connectivity oracles supporting vertex failures isone of the basic data structures problems for undirected graphs. It is alreadywell understood: previous works [Duan--Pettie STOC'10; Long--Saranurak FOCS'22]achieve query time linear in the number of failed vertices, and it isconditionally optimal as long as we require preprocessing time polynomial inthe size of the graph and update time polynomial in the number of failedvertices. We revisit this problem in the paradigm of algorithms with predictions: weask if the query time can be improved if the set of failed vertices can bepredicted beforehand up to a small number of errors. More specifically, wedesign a data structure that, given a graph $G=(V,E)$ and a set of verticespredicted to fail $\widehat{D} \subseteq V$ of size $d=|\widehat{D}|$,preprocesses it in time $\tilde{O}(d|E|)$ and then can receive an update givenas the symmetric difference between the predicted and the actual set of failedvertices $\widehat{D} \triangle D = (\widehat{D} \setminus D) \cup (D \setminus\widehat{D})$ of size $\eta = |\widehat{D} \triangle D|$, process it in time$\tilde{O}(\eta^4)$, and after that answer connectivity queries in $G \setminusD$ in time $O(\eta)$. Viewed from another perspective, our data structureprovides an improvement over the state of the art for the \emph{fully dynamicsubgraph connectivity problem} in the \emph{sensitivity setting}[Henzinger--Neumann ESA'16]. We argue that the preprocessing time and query time of our data structure areconditionally optimal under standard fine-grained complexity assumptions.</description><author>Bingbing Hu, Evangelos Kosinas, Adam Polak</author><pubDate>Mon, 01 Jul 2024 14:24:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08489v3</guid></item><item><title>Efficient Estimation for Longitudinal Networks via Adaptive Merging</title><link>http://arxiv.org/abs/2211.07866v5</link><description>Longitudinal network consists of a sequence of temporal edges among multiplenodes, where the temporal edges are observed in real time. It has becomeubiquitous with the rise of online social platform and e-commerce, but largelyunder-investigated in literature. In this paper, we propose an efficientestimation framework for longitudinal network, leveraging strengths of adaptivenetwork merging, tensor decomposition and point process. It merges neighboringsparse networks so as to enlarge the number of observed edges and reduceestimation variance, whereas the estimation bias introduced by network mergingis controlled by exploiting local temporal structures for adaptive networkneighborhood. A projected gradient descent algorithm is proposed to facilitateestimation, where the upper bound of the estimation error in each iteration isestablished. A thorough analysis is conducted to quantify the asymptoticbehavior of the proposed method, which shows that it can significantly reducethe estimation error and also provides guideline for network merging undervarious scenarios. We further demonstrate the advantage of the proposed methodthrough extensive numerical experiments on synthetic datasets and a militarizedinterstate dispute dataset.</description><author>Haoran Zhang, Junhui Wang</author><pubDate>Mon, 01 Jul 2024 14:17:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.07866v5</guid></item><item><title>Model Generation with LLMs: From Requirements to UML Sequence Diagrams</title><link>http://arxiv.org/abs/2404.06371v2</link><description>Complementing natural language (NL) requirements with graphical models canimprove stakeholders' communication and provide directions for system design.However, creating models from requirements involves manual effort. The adventof generative large language models (LLMs), ChatGPT being a notable example,offers promising avenues for automated assistance in model generation. Thispaper investigates the capability of ChatGPT to generate a specific type ofmodel, i.e., UML sequence diagrams, from NL requirements. We conduct aqualitative study in which we examine the sequence diagrams generated byChatGPT for 28 requirements documents of various types and from differentdomains. Observations from the analysis of the generated diagrams havesystematically been captured through evaluation logs, and categorized throughthematic analysis. Our results indicate that, although the models generallyconform to the standard and exhibit a reasonable level of understandability,their completeness and correctness with respect to the specified requirementsoften present challenges. This issue is particularly pronounced in the presenceof requirements smells, such as ambiguity and inconsistency. The insightsderived from this study can influence the practical utilization of LLMs in theRE process, and open the door to novel RE-specific prompting strategiestargeting effective model generation.</description><author>Alessio Ferrari, Sallam Abualhaija, Chetan Arora</author><pubDate>Mon, 01 Jul 2024 14:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06371v2</guid></item><item><title>WIA-LD2ND: Wavelet-based Image Alignment for Self-supervised Low-Dose CT Denoising</title><link>http://arxiv.org/abs/2403.11672v3</link><description>In clinical examinations and diagnoses, low-dose computed tomography (LDCT)is crucial for minimizing health risks compared with normal-dose computedtomography (NDCT). However, reducing the radiation dose compromises thesignal-to-noise ratio, leading to degraded quality of CT images. To addressthis, we analyze LDCT denoising task based on experimental results from thefrequency perspective, and then introduce a novel self-supervised CT imagedenoising method called WIA-LD2ND, only using NDCT data. The proposed WIA-LD2NDcomprises two modules: Wavelet-based Image Alignment (WIA) and Frequency-AwareMulti-scale Loss (FAM). First, WIA is introduced to align NDCT with LDCT bymainly adding noise to the high-frequency components, which is the maindifference between LDCT and NDCT. Second, to better capture high-frequencycomponents and detailed information, Frequency-Aware Multi-scale Loss (FAM) isproposed by effectively utilizing multi-scale feature space. Extensiveexperiments on two public LDCT denoising datasets demonstrate that ourWIA-LD2ND, only uses NDCT, outperforms existing several state-of-the-artweakly-supervised and self-supervised methods. Source code is available athttps://github.com/zhaohaoyu376/WI-LD2ND.</description><author>Haoyu Zhao, Yuliang Gu, Zhou Zhao, Bo Du, Yongchao Xu, Rui Yu</author><pubDate>Mon, 01 Jul 2024 13:56:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11672v3</guid></item><item><title>MoreStyle: Relax Low-frequency Constraint of Fourier-based Image Reconstruction in Generalizable Medical Image Segmentation</title><link>http://arxiv.org/abs/2403.11689v3</link><description>The task of single-source domain generalization (SDG) in medical imagesegmentation is crucial due to frequent domain shifts in clinical imagedatasets. To address the challenge of poor generalization across differentdomains, we introduce a Plug-and-Play module for data augmentation calledMoreStyle. MoreStyle diversifies image styles by relaxing low-frequencyconstraints in Fourier space, guiding the image reconstruction network. Withthe help of adversarial learning, MoreStyle further expands the style range andpinpoints the most intricate style combinations within latent features. Tohandle significant style variations, we introduce an uncertainty-weighted loss.This loss emphasizes hard-to-classify pixels resulting only from style shiftswhile mitigating true hard-to-classify pixels in both MoreStyle-generated andoriginal images. Extensive experiments on two widely used benchmarksdemonstrate that the proposed MoreStyle effectively helps to achieve gooddomain generalization ability, and has the potential to further boost theperformance of some state-of-the-art SDG methods. Source code is available athttps://github.com/zhaohaoyu376/morestyle.</description><author>Haoyu Zhao, Wenhui Dong, Rui Yu, Zhou Zhao, Du Bo, Yongchao Xu</author><pubDate>Mon, 01 Jul 2024 13:52:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11689v3</guid></item><item><title>Recovering the Pre-Fine-Tuning Weights of Generative Models</title><link>http://arxiv.org/abs/2402.10208v2</link><description>The dominant paradigm in generative modeling consists of two steps: i)pre-training on a large-scale but unsafe dataset, ii) aligning the pre-trainedmodel with human values via fine-tuning. This practice is considered safe, asno current method can recover the unsafe, pre-fine-tuning model weights. Inthis paper, we demonstrate that this assumption is often false. Concretely, wepresent Spectral DeTuning, a method that can recover the weights of thepre-fine-tuning model using a few low-rank (LoRA) fine-tuned models. Incontrast to previous attacks that attempt to recover pre-fine-tuningcapabilities, our method aims to recover the exact pre-fine-tuning weights. Ourapproach exploits this new vulnerability against large-scale models such as apersonalized Stable Diffusion and an aligned Mistral.</description><author>Eliahu Horwitz, Jonathan Kahana, Yedid Hoshen</author><pubDate>Mon, 01 Jul 2024 13:48:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10208v2</guid></item><item><title>Probabilistic Test-Time Generalization by Variational Neighbor-Labeling</title><link>http://arxiv.org/abs/2307.04033v3</link><description>This paper strives for domain generalization, where models are trainedexclusively on source domains before being deployed on unseen target domains.We follow the strict separation of source training and target testing, butexploit the value of the unlabeled target data itself during inference. We makethree contributions. First, we propose probabilistic pseudo-labeling of targetsamples to generalize the source-trained model to the target domain at testtime. We formulate the generalization at test time as a variational inferenceproblem, by modeling pseudo labels as distributions, to consider theuncertainty during generalization and alleviate the misleading signal ofinaccurate pseudo labels. Second, we learn variational neighbor labels thatincorporate the information of neighboring target samples to generate morerobust pseudo labels. Third, to learn the ability to incorporate morerepresentative target information and generate more precise and robustvariational neighbor labels, we introduce a meta-generalization stage duringtraining to simulate the generalization procedure. Experiments on sevenwidely-used datasets demonstrate the benefits, abilities, and effectiveness ofour proposal.</description><author>Sameer Ambekar, Zehao Xiao, Jiayi Shen, Xiantong Zhen, Cees G. M. Snoek</author><pubDate>Mon, 01 Jul 2024 13:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.04033v3</guid></item><item><title>IID Relaxation by Logical Expressivity: A Research Agenda for Fitting Logics to Neurosymbolic Requirements</title><link>http://arxiv.org/abs/2404.19485v2</link><description>Neurosymbolic background knowledge and the expressivity required of its logiccan break Machine Learning assumptions about data Independence and IdenticalDistribution. In this position paper we propose to analyze IID relaxation in ahierarchy of logics that fit different use case requirements. We discuss thebenefits of exploiting known data dependencies and distribution constraints forNeurosymbolic use cases and argue that the expressivity required for thisknowledge has implications for the design of underlying ML routines. This opensa new research agenda with general questions about Neurosymbolic backgroundknowledge and the expressivity required of its logic.</description><author>Maarten C. Stol, Alessandra Mileo</author><pubDate>Mon, 01 Jul 2024 13:44:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19485v2</guid></item><item><title>Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation</title><link>http://arxiv.org/abs/2406.13663v2</link><description>Ensuring the verifiability of model answers is a fundamental challenge forretrieval-augmented generation (RAG) in the question answering (QA) domain.Recently, self-citation prompting was proposed to make large language models(LLMs) generate citations to supporting documents along with their answers.However, self-citing LLMs often struggle to match the required format, refer tonon-existent sources, and fail to faithfully reflect LLMs' context usagethroughout the generation. In this work, we present MIRAGE --ModelInternals-based RAG Explanations -- a plug-and-play approach using modelinternals for faithful answer attribution in RAG applications. MIRAGE detectscontext-sensitive answer tokens and pairs them with retrieved documentscontributing to their prediction via saliency methods. We evaluate our proposedapproach on a multilingual extractive QA dataset, finding high agreement withhuman answer attribution. On open-ended QA, MIRAGE achieves citation qualityand efficiency comparable to self-citation while also allowing for afiner-grained control of attribution parameters. Our qualitative evaluationhighlights the faithfulness of MIRAGE's attributions and underscores thepromising application of model internals for RAG answer attribution.</description><author>Jirui Qi, Gabriele Sarti, Raquel Fernández, Arianna Bisazza</author><pubDate>Mon, 01 Jul 2024 13:39:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13663v2</guid></item><item><title>Bayesian Regression Markets</title><link>http://arxiv.org/abs/2310.14992v3</link><description>Although machine learning tasks are highly sensitive to the quality of inputdata, relevant datasets can often be challenging for firms to acquire,especially when held privately by a variety of owners. For instance, if theseowners are competitors in a downstream market, they may be reluctant to shareinformation. Focusing on supervised learning for regression tasks, we develop aregression market to provide a monetary incentive for data sharing. Ourmechanism adopts a Bayesian framework, allowing us to consider a more generalclass of regression tasks. We present a thorough exploration of the marketproperties, and show that similar proposals in literature expose the marketagents to sizeable financial risks, which can be mitigated in our setup.</description><author>Thomas Falconer, Jalal Kazempour, Pierre Pinson</author><pubDate>Mon, 01 Jul 2024 13:36:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14992v3</guid></item><item><title>Paraphrase Types for Generation and Detection</title><link>http://arxiv.org/abs/2310.14863v2</link><description>Current approaches in paraphrase generation and detection heavily rely on asingle general similarity score, ignoring the intricate linguistic propertiesof language. This paper introduces two new tasks to address this shortcoming byconsidering paraphrase types - specific linguistic perturbations at particulartext positions. We name these tasks Paraphrase Type Generation and ParaphraseType Detection. Our results suggest that while current techniques perform wellin a binary classification scenario, i.e., paraphrased or not, the inclusion offine-grained paraphrase types poses a significant challenge. While mostapproaches are good at generating and detecting general semantic similarcontent, they fail to understand the intrinsic linguistic variables theymanipulate. Models trained in generating and identifying paraphrase types alsoshow improvements in tasks without them. In addition, scaling these modelsfurther improves their ability to understand paraphrase types. We believeparaphrase types can unlock a new paradigm for developing paraphrase models andsolving tasks in the future.</description><author>Jan Philip Wahle, Bela Gipp, Terry Ruas</author><pubDate>Mon, 01 Jul 2024 13:32:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14863v2</guid></item><item><title>We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields</title><link>http://arxiv.org/abs/2310.14870v2</link><description>Natural Language Processing (NLP) is poised to substantially influence theworld. However, significant progress comes hand-in-hand with substantial risks.Addressing them requires broad engagement with various fields of study. Yet,little empirical work examines the state of such engagement (past or current).In this paper, we quantify the degree of influence between 23 fields of studyand NLP (on each other). We analyzed ~77k NLP papers, ~3.1m citations from NLPpapers to other papers, and ~1.8m citations from other papers to NLP papers. Weshow that, unlike most fields, the cross-field engagement of NLP, measured byour proposed Citation Field Diversity Index (CFDI), has declined from 0.58 in1980 to 0.31 in 2022 (an all-time low). In addition, we find that NLP has grownmore insular -- citing increasingly more NLP papers and having fewer papersthat act as bridges between fields. NLP citations are dominated by computerscience; Less than 8% of NLP citations are to linguistics, and less than 3% areto math and psychology. These findings underscore NLP's urgent need to reflecton its engagement with various fields.</description><author>Jan Philip Wahle, Terry Ruas, Mohamed Abdalla, Bela Gipp, Saif M. Mohammad</author><pubDate>Mon, 01 Jul 2024 13:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14870v2</guid></item><item><title>The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research</title><link>http://arxiv.org/abs/2305.02797v3</link><description>Recent advances in deep learning methods for natural language processing(NLP) have created new business opportunities and made NLP research criticalfor industry development. As one of the big players in the field of NLP,together with governments and universities, it is important to track theinfluence of industry on research. In this study, we seek to quantify andcharacterize industry presence in the NLP community over time. Using a corpuswith comprehensive metadata of 78,187 NLP publications and 701 resumes of NLPpublication authors, we explore the industry presence in the field since theearly 90s. We find that industry presence among NLP authors has been steadybefore a steep increase over the past five years (180% growth from 2017 to2022). A few companies account for most of the publications and provide fundingto academic researchers through grants and internships. Our study shows thatthe presence and impact of the industry on natural language processing researchare significant and fast-growing. This work calls for increased transparency ofindustry influence in the field.</description><author>Mohamed Abdalla, Jan Philip Wahle, Terry Ruas, Aurélie Névéol, Fanny Ducel, Saif M. Mohammad, Karën Fort</author><pubDate>Mon, 01 Jul 2024 13:30:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02797v3</guid></item><item><title>In-Context Reinforcement Learning for Variable Action Spaces</title><link>http://arxiv.org/abs/2312.13327v6</link><description>Recently, it has been shown that transformers pre-trained on diverse datasetswith multi-episode contexts can generalize to new reinforcement learning tasksin-context. A key limitation of previously proposed models is their reliance ona predefined action space size and structure. The introduction of a new actionspace often requires data re-collection and model re-training, which can becostly for some applications. In our work, we show that it is possible tomitigate this issue by proposing the Headless-AD model that, despite beingtrained only once, is capable of generalizing to discrete action spaces ofvariable size, semantic content and order. By experimenting with Bernoulli andcontextual bandits, as well as a gridworld environment, we show thatHeadless-AD exhibits significant capability to generalize to action spaces ithas never encountered, even outperforming specialized models trained for aspecific set of actions on several environment configurations. Implementationis available at: https://github.com/corl-team/headless-ad.</description><author>Viacheslav Sinii, Alexander Nikulin, Vladislav Kurenkov, Ilya Zisman, Sergey Kolesnikov</author><pubDate>Mon, 01 Jul 2024 13:29:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13327v6</guid></item><item><title>Training-Free Deepfake Voice Recognition by Leveraging Large-Scale Pre-Trained Models</title><link>http://arxiv.org/abs/2405.02179v3</link><description>Generalization is a main issue for current audio deepfake detectors, whichstruggle to provide reliable results on out-of-distribution data. Given thespeed at which more and more accurate synthesis methods are developed, it isvery important to design techniques that work well also on data they were nottrained for. In this paper we study the potential of large-scale pre-trainedmodels for audio deepfake detection, with special focus on generalizationability. To this end, the detection problem is reformulated in a speakerverification framework and fake audios are exposed by the mismatch between thevoice sample under test and the voice of the claimed identity. With thisparadigm, no fake speech sample is necessary in training, cutting off any linkwith the generation method at the root, and ensuring full generalizationability. Features are extracted by general-purpose large pre-trained models,with no need for training or fine-tuning on specific fake detection or speakerverification datasets. At detection time only a limited set of voice fragmentsof the identity under test is required. Experiments on several datasetswidespread in the community show that detectors based on pre-trained modelsachieve excellent performance and show strong generalization ability, rivalingsupervised methods on in-distribution data and largely overcoming them onout-of-distribution data.</description><author>Alessandro Pianese, Davide Cozzolino, Giovanni Poggi, Luisa Verdoliva</author><pubDate>Mon, 01 Jul 2024 13:25:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02179v3</guid></item><item><title>A Policy Gradient Primal-Dual Algorithm for Constrained MDPs with Uniform PAC Guarantees</title><link>http://arxiv.org/abs/2401.17780v3</link><description>We study a primal-dual (PD) reinforcement learning (RL) algorithm for onlineconstrained Markov decision processes (CMDPs). Despite its widespread practicaluse, the existing theoretical literature on PD-RL algorithms for this problemonly provides sublinear regret guarantees and fails to ensure convergence tooptimal policies. In this paper, we introduce a novel policy gradient PDalgorithm with uniform probably approximate correctness (Uniform-PAC)guarantees, simultaneously ensuring convergence to optimal policies, sublinearregret, and polynomial sample complexity for any target accuracy. Notably, thisrepresents the first Uniform-PAC algorithm for the online CMDP problem. Inaddition to the theoretical guarantees, we empirically demonstrate in a simpleCMDP that our algorithm converges to optimal policies, while baselinealgorithms exhibit oscillatory performance and constraint violation.</description><author>Toshinori Kitamura, Tadashi Kozuno, Masahiro Kato, Yuki Ichihara, Soichiro Nishimori, Akiyoshi Sannai, Sho Sonoda, Wataru Kumagai, Yutaka Matsuo</author><pubDate>Mon, 01 Jul 2024 13:08:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17780v3</guid></item><item><title>Robust Low-Cost Drone Detection and Classification in Low SNR Environments</title><link>http://arxiv.org/abs/2406.18624v2</link><description>The proliferation of drones, or unmanned aerial vehicles (UAVs), has raisedsignificant safety concerns due to their potential misuse in activities such asespionage, smuggling, and infrastructure disruption. This paper addresses thecritical need for effective drone detection and classification systems thatoperate independently of UAV cooperation. We evaluate various convolutionalneural networks (CNNs) for their ability to detect and classify drones usingspectrogram data derived from consecutive Fourier transforms of signalcomponents. The focus is on model robustness in low signal-to-noise ratio (SNR)environments, which is critical for real-world applications. A comprehensivedataset is provided to support future model development. In addition, wedemonstrate a low-cost drone detection system using a standard computer,software-defined radio (SDR) and antenna, validated through real-world fieldtesting. On our development dataset, all models consistently achieved anaverage balanced classification accuracy of &gt;= 85% at SNR &gt; -12dB. In the fieldtest, these models achieved an average balance accuracy of &gt; 80%, depending ontransmitter distance and antenna direction. Our contributions include: apublicly available dataset for model development, a comparative analysis of CNNfor drone detection under low SNR conditions, and the deployment and fieldevaluation of a practical, low-cost detection system.</description><author>Stefan Glüge, Matthias Nyfeler, Ahmad Aghaebrahimian, Nicola Ramagnano, Christof Schüpbach</author><pubDate>Mon, 01 Jul 2024 13:07:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18624v2</guid></item><item><title>Adaptively Bypassing Vision Transformer Blocks for Efficient Visual Tracking</title><link>http://arxiv.org/abs/2406.08037v2</link><description>Empowered by transformer-based models, visual tracking has advancedsignificantly. However, the slow speed of current trackers limits theirapplicability on devices with constrained computational resources. To addressthis challenge, we introduce ABTrack, an adaptive computation framework thatadaptively bypassing transformer blocks for efficient visual tracking. Therationale behind ABTrack is rooted in the observation that semantic features orrelations do not uniformly impact the tracking task across all abstractionlevels. Instead, this impact varies based on the characteristics of the targetand the scene it occupies. Consequently, disregarding insignificant semanticfeatures or relations at certain abstraction levels may not significantlyaffect the tracking accuracy. We propose a Bypass Decision Module (BDM) todetermine if a transformer block should be bypassed, which adaptivelysimplifies the architecture of ViTs and thus speeds up the inference process.To counteract the time cost incurred by the BDMs and further enhance theefficiency of ViTs, we introduce a novel ViT pruning method to reduce thedimension of the latent representation of tokens in each transformer block.Extensive experiments on multiple tracking benchmarks validate theeffectiveness and generality of the proposed method and show that it achievesstate-of-the-art performance. Code is released at:https://github.com/xyyang317/ABTrack.</description><author>Xiangyang Yang, Dan Zeng, Xucheng Wang, You Wu, Hengzhou Ye, Qijun Zhao, Shuiwang Li</author><pubDate>Mon, 01 Jul 2024 13:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08037v2</guid></item><item><title>AdaCL:Adaptive Continual Learning</title><link>http://arxiv.org/abs/2303.13113v3</link><description>Class-Incremental Learning aims to update a deep classifier to learn newcategories while maintaining or improving its accuracy on previously observedclasses. Common methods to prevent forgetting previously learned classesinclude regularizing the neural network updates and storing exemplars inmemory, which come with hyperparameters such as the learning rate,regularization strength, or the number of exemplars. However, thesehyperparameters are usually only tuned at the start and then kept fixedthroughout the learning sessions, ignoring the fact that newly encounteredtasks may have varying levels of novelty or difficulty. This study investigatesthe necessity of hyperparameter `adaptivity' in Class-Incremental Learning: theability to dynamically adjust hyperparameters such as the learning rate,regularization strength, and memory size according to the properties of the newtask at hand. We propose AdaCL, a Bayesian Optimization-based approach toautomatically and efficiently determine the optimal values for those parameterswith each learning task. We show that adapting hyperpararmeters on each newtask leads to improvement in accuracy, forgetting and memory. Code is availableat https://github.com/ElifCerenGokYildirim/AdaCL.</description><author>Elif Ceren Gok Yildirim, Murat Onur Yildirim, Mert Kilickaya, Joaquin Vanschoren</author><pubDate>Mon, 01 Jul 2024 12:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.13113v3</guid></item><item><title>Energy-based Epistemic Uncertainty for Graph Neural Networks</title><link>http://arxiv.org/abs/2406.04043v2</link><description>In domains with interdependent data, such as graphs, quantifying theepistemic uncertainty of a Graph Neural Network (GNN) is challenging asuncertainty can arise at different structural scales. Existing techniquesneglect this issue or only distinguish between structure-aware andstructure-agnostic uncertainty without combining them into a single measure. Wepropose GEBM, an energy-based model (EBM) that provides high-qualityuncertainty estimates by aggregating energy at different structural levels thatnaturally arise from graph diffusion. In contrast to logit-based EBMs, weprovably induce an integrable density in the data space by regularizing theenergy function. We introduce an evidential interpretation of our EBM thatsignificantly improves the predictive robustness of the GNN. Our framework is asimple and effective post hoc method applicable to any pre-trained GNN that issensitive to various distribution shifts. It consistently achieves the bestseparation of in-distribution and out-of-distribution data on 6 out of 7anomaly types while having the best average rank over shifts on \emph{all}datasets.</description><author>Dominik Fuchsgruber, Tom Wollschläger, Stephan Günnemann</author><pubDate>Mon, 01 Jul 2024 12:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04043v2</guid></item><item><title>Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles</title><link>http://arxiv.org/abs/2307.04679v3</link><description>In this paper, our aim is to analyse the generalization capabilities offirst-order methods for statistical learning in multiple, different yetrelated, scenarios including supervised learning, transfer learning, robustlearning and federated learning. To do so, we provide sharp upper and lowerbounds for the minimax excess risk of strongly convex and smooth statisticallearning when the gradient is accessed through partial observations given by adata-dependent oracle. This novel class of oracles can query the gradient withany given data distribution, and is thus well suited to scenarios in which thetraining data distribution does not match the target (or test) distribution. Inparticular, our upper and lower bounds are proportional to the smallest meansquare error achievable by gradient estimators, thus allowing us to easilyderive multiple sharp bounds in the aforementioned scenarios using theextensive literature on parameter estimation.</description><author>Kevin Scaman, Mathieu Even, Batiste Le Bars, Laurent Massoulié</author><pubDate>Mon, 01 Jul 2024 12:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.04679v3</guid></item><item><title>Woven Fabric Capture with a Reflection-Transmission Photo Pair</title><link>http://arxiv.org/abs/2406.19398v2</link><description>Digitizing woven fabrics would be valuable for many applications, fromdigital humans to interior design. Previous work introduces a lightweight wovenfabric acquisition approach by capturing a single reflection image andestimating the fabric parameters with a differentiable geometric and shadingmodel. The renderings of the estimated fabric parameters can closely match thephoto; however, the captured reflection image is insufficient to fullycharacterize the fabric sample reflectance. For instance, fabrics withdifferent thicknesses might have similar reflection images but lead tosignificantly different transmission. We propose to recover the woven fabricparameters from two captured images: reflection and transmission. At the coreof our method is a differentiable bidirectional scattering distributionfunction (BSDF) model, handling reflection and transmission, including singleand multiple scattering. We propose a two-layer model, where the singlescattering uses an SGGX phase function as in previous work, and multiplescattering uses a new azimuthally-invariant microflake definition, which weterm ASGGX. This new fabric BSDF model closely matches real woven fabrics inboth reflection and transmission. We use a simple setup for capturingreflection and transmission photos with a cell phone camera and two pointlights, and estimate the fabric parameters via a lightweight network, togetherwith a differentiable optimization. We also model the out-of-focus effectsexplicitly with a simple solution to match the thin-lens camera better. As aresult, the renderings of the estimated parameters can agree with the inputimages on both reflection and transmission for the first time. The code forthis paper is at https://github.com/lxtyin/FabricBTDF-Recovery.</description><author>Yingjie Tang, Zixuan Li, Miloš Hašan, Jian Yang, Beibei Wang</author><pubDate>Mon, 01 Jul 2024 12:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19398v2</guid></item><item><title>Performance of large language models in numerical vs. semantic medical knowledge: Benchmarking on evidence-based Q&amp;As</title><link>http://arxiv.org/abs/2406.03855v2</link><description>Clinical problem-solving requires processing of semantic medical knowledgesuch as illness scripts and numerical medical knowledge of diagnostic tests forevidence-based decision-making. As large language models (LLMs) show promisingresults in many aspects of language-based clinical practice, their ability togenerate non-language evidence-based answers to clinical questions isinherently limited by tokenization. Therefore, we evaluated LLMs' performanceon two question types: numeric (correlating findings) and semantic(differentiating entities) while examining differences within and between LLMsin medical aspects and comparing their performance to humans. To generatestraightforward multi-choice questions and answers (QAs) based onevidence-based medicine (EBM), we used a comprehensive medical knowledge graph(encompassed data from more than 50,00 peer-reviewed articles) and created the"EBMQA". EBMQA contains 105,000 QAs labeled with medical and non-medical topicsand classified into numerical or semantic questions. We benchmarked thisdataset using more than 24,500 QAs on two state-of-the-art LLMs: Chat-GPT4 andClaude3-Opus. We evaluated the LLMs accuracy on semantic and numerical questiontypes and according to sub-labeled topics. For validation, six medical expertswere tested on 100 numerical EBMQA questions. We found that both LLMs excelledmore in semantic than numerical QAs, with Claude3 surpassing GPT4 in numericalQAs. However, both LLMs showed inter and intra gaps in different medicalaspects and remained inferior to humans. Thus, their medical advice should beaddressed carefully.</description><author>Eden Avnat, Michal Levy, Daniel Herstain, Elia Yanko, Daniel Ben Joya, Michal Tzuchman Katz, Dafna Eshel, Sahar Laros, Yael Dagan, Shahar Barami, Joseph Mermelstein, Shahar Ovadia, Noam Shomron, Varda Shalev, Raja-Elie E. Abdulnour</author><pubDate>Mon, 01 Jul 2024 12:36:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03855v2</guid></item><item><title>ProTrix: Building Models for Planning and Reasoning over Tables with Sentence Context</title><link>http://arxiv.org/abs/2403.02177v2</link><description>Tables play a crucial role in conveying information in various domains. Wepropose a Plan-then-Reason framework to answer different types of user queriesover tables with sentence context. The framework first plans the reasoningpaths over the context, then assigns each step to program-based or textualreasoning to reach the final answer. This framework enhances the tablereasoning abilities for both in-context learning and fine-tuning methods.GPT-3.5-Turbo following Plan-then-Reason framework surpasses other promptingbaselines without self-consistency while using less API calls and in-contextdemonstrations. We also construct an instruction tuning set TrixInstruct toevaluate the effectiveness of fine-tuning with this framework. We presentProTrix model family by finetuning models on TrixInstruct. Our experiments showthat ProTrix family generalizes to diverse unseen tabular tasks with only 6ktraining instances. We further demonstrate that ProTrix can generate accurateand faithful explanations to answer complex free-form questions. Our workunderscores the importance of the planning and reasoning abilities towards amodel over tabular tasks with generalizability and interpretability. Weopen-source our dataset and models at https://github.com/WilliamZR/ProTrix.</description><author>Zirui Wu, Yansong Feng</author><pubDate>Mon, 01 Jul 2024 12:31:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02177v2</guid></item><item><title>Fast and Efficient 2-bit LLM Inference on GPU: 2/4/16-bit in a Weight Matrix with Asynchronous Dequantization</title><link>http://arxiv.org/abs/2311.16442v3</link><description>Large language models (LLMs) have demonstrated impressive abilities invarious domains while the inference cost is expensive. Many previous studiesexploit quantization methods to reduce LLM inference cost by reducing latencyand memory consumption. Applying 2-bit single-precision weight quantizationbrings &gt;3% accuracy loss, so the state-of-the-art methods use mixed-precisionmethods for LLMs (e.g. Llama2-7b, etc.) to improve the accuracy. However,challenges still exist: (1) Uneven distribution in weight matrix. (2) Largespeed degradation by adding sparse outliers. (3) Time-consuming dequantizationoperations on GPUs. To tackle these challenges and enable fast and efficientLLM inference on GPUs, we propose the following techniques in this paper. (1)Intra-weight mixed-precision quantization. (2) Exclusive 2-bit sparse outlierwith minimum speed degradation. (3) Asynchronous dequantization. We conductextensive experiments on different model families (e.g. Llama3, etc.) and modelsizes. We achieve 2.91-bit for each weight considering all scales/zeros fordifferent models with negligible loss. As a result, with our 2/4/16mixed-precision quantization for each weight matrix and asynchronousdequantization during inference, our design achieves an end-to-end speedup forLlama2-7b is 1.74x over the original model, and we reduce both runtime cost andtotal cost by up to 2.53x and 2.29x with less GPU requirements.</description><author>Jinhao Li, Jiaming Xu, Shiyao Li, Shan Huang, Jun Liu, Yaoxiu Lian, Guohao Dai</author><pubDate>Mon, 01 Jul 2024 12:13:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16442v3</guid></item><item><title>Remote sensing framework for geological mapping via stacked autoencoders and clustering</title><link>http://arxiv.org/abs/2404.02180v2</link><description>Supervised machine learning methods for geological mapping via remote sensingface limitations due to the scarcity of accurately labelled training data thatcan be addressed by unsupervised learning, such as dimensionality reduction andclustering. Dimensionality reduction methods have the potential to play acrucial role in improving the accuracy of geological maps. Althoughconventional dimensionality reduction methods may struggle with nonlinear data,unsupervised deep learning models such as autoencoders can model non-linearrelationships. Stacked autoencoders feature multiple interconnected layers tocapture hierarchical data representations useful for remote sensing data. Thisstudy presents an unsupervised machine learning-based framework for processingremote sensing data using stacked autoencoders for dimensionality reduction andk-means clustering for mapping geological units. We use Landsat 8, ASTER, andSentinel-2 datasets to evaluate the framework for geological mapping of theMutawintji region in Western New South Wales, Australia. We also comparestacked autoencoders with principal component analysis and canonicalautoencoders. Our results reveal that the framework produces accurate andinterpretable geological maps, efficiently discriminating rock units. We findthat the accuracy of stacked autoencoders ranges from 86.6 % to 90 %, dependingon the remote sensing data type, which is superior to their counterparts. Wealso find that the generated maps align with prior geological knowledge of thestudy area while providing novel insights into geological structures.</description><author>Sandeep Nagar, Ehsan Farahbakhsh, Joseph Awange, Rohitash Chandra</author><pubDate>Mon, 01 Jul 2024 12:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02180v2</guid></item><item><title>A General Verification Framework for Dynamical and Control Models via Certificate Synthesis</title><link>http://arxiv.org/abs/2309.06090v2</link><description>An emerging branch of control theory specialises in certificate learning,concerning the specification of a desired (possibly complex) system behaviourfor an autonomous or control model, which is then analytically verified bymeans of a function-based proof. However, the synthesis of controllers abidingby these complex requirements is in general a non-trivial task and may eludethe most expert control engineers. This results in a need for automatictechniques that are able to design controllers and to analyse a wide range ofelaborate specifications. In this paper, we provide a general framework toencode system specifications and define corresponding certificates, and wepresent an automated approach to formally synthesise controllers andcertificates. Our approach contributes to the broad field of safe learning forcontrol, exploiting the flexibility of neural networks to provide candidatecontrol and certificate functions, whilst using SMT-solvers to offer a formalguarantee of correctness. We test our framework by developing a prototypesoftware tool, and assess its efficacy at verification via control andcertificate synthesis over a large and varied suite of benchmarks.</description><author>Alec Edwards, Andrea Peruffo, Alessandro Abate</author><pubDate>Mon, 01 Jul 2024 12:08:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06090v2</guid></item><item><title>Contextualized Hybrid Ensemble Q-learning: Learning Fast with Control Priors</title><link>http://arxiv.org/abs/2406.19768v2</link><description>Combining Reinforcement Learning (RL) with a prior controller can yield thebest out of two worlds: RL can solve complex nonlinear problems, while thecontrol prior ensures safer exploration and speeds up training. Prior worklargely blends both components with a fixed weight, neglecting that the RLagent's performance varies with the training progress and across regions in thestate space. Therefore, we advocate for an adaptive strategy that dynamicallyadjusts the weighting based on the RL agent's current capabilities. We proposea new adaptive hybrid RL algorithm, Contextualized Hybrid Ensemble Q-learning(CHEQ). CHEQ combines three key ingredients: (i) a time-invariant formulationof the adaptive hybrid RL problem treating the adaptive weight as a contextvariable, (ii) a weight adaption mechanism based on the parametric uncertaintyof a critic ensemble, and (iii) ensemble-based acceleration for data-efficientRL. Evaluating CHEQ on a car racing task reveals substantially stronger dataefficiency, exploration safety, and transferability to unknown scenarios thanstate-of-the-art adaptive hybrid RL methods.</description><author>Emma Cramer, Bernd Frauenknecht, Ramil Sabirov, Sebastian Trimpe</author><pubDate>Mon, 01 Jul 2024 12:02:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19768v2</guid></item><item><title>Explaining the Explainers in Graph Neural Networks: a Comparative Study</title><link>http://arxiv.org/abs/2210.15304v3</link><description>Following a fast initial breakthrough in graph based learning, Graph NeuralNetworks (GNNs) have reached a widespread application in many science andengineering fields, prompting the need for methods to understand their decisionprocess. GNN explainers have started to emerge in recent years, with a multitude ofmethods both novel or adapted from other domains. To sort out this plethora ofalternative approaches, several studies have benchmarked the performance ofdifferent explainers in terms of various explainability metrics. However, theseearlier works make no attempts at providing insights into why different GNNarchitectures are more or less explainable, or which explainer should bepreferred in a given setting. In this survey, we fill these gaps by devising a systematic experimentalstudy, which tests ten explainers on eight representative architectures trainedon six carefully designed graph and node classification datasets. With ourresults we provide key insights on the choice and applicability of GNNexplainers, we isolate key components that make them usable and successful andprovide recommendations on how to avoid common interpretation pitfalls. Weconclude by highlighting open questions and directions of possible futureresearch.</description><author>Antonio Longa, Steve Azzolin, Gabriele Santin, Giulia Cencetti, Pietro Liò, Bruno Lepri, Andrea Passerini</author><pubDate>Mon, 01 Jul 2024 11:48:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.15304v3</guid></item><item><title>Climate Change from Large Language Models</title><link>http://arxiv.org/abs/2312.11985v3</link><description>Climate change poses grave challenges, demanding widespread understanding andlow-carbon lifestyle awareness. Large language models (LLMs) offer a powerfultool to address this crisis, yet comprehensive evaluations of theirclimate-crisis knowledge are lacking. This paper proposes an automatedevaluation framework to assess climate-crisis knowledge within LLMs. We adopt ahybrid approach for data acquisition, combining data synthesis and manualcollection, to compile a diverse set of questions encompassing various aspectsof climate change. Utilizing prompt engineering based on the compiledquestions, we evaluate the model's knowledge by analyzing its generatedanswers. Furthermore, we introduce a comprehensive set of metrics to assessclimate-crisis knowledge, encompassing indicators from 10 distinctperspectives. These metrics provide a multifaceted evaluation, enabling anuanced understanding of the LLMs' climate crisis comprehension. Theexperimental results demonstrate the efficacy of our proposed method. In ourevaluation utilizing diverse high-performing LLMs, we discovered that whileLLMs possess considerable climate-related knowledge, there are shortcomings interms of timeliness, indicating a need for continuous updating and refinementof their climate-related content.</description><author>Hongyin Zhu, Prayag Tiwari</author><pubDate>Mon, 01 Jul 2024 11:40:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11985v3</guid></item><item><title>Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts</title><link>http://arxiv.org/abs/2404.02022v2</link><description>In the era of large language models, applying techniques such as RetrievalAugmented Generation can better address Open-Domain Question-Answeringproblems. Due to constraints including model sizes and computing resources, thelength of context is often limited, and it becomes challenging to empower themodel to cover overlong contexts while answering questions from open domains.This paper proposes a general and convenient method to covering longer contextsin Open-Domain Question-Answering tasks. It leverages a small encoder languagemodel that effectively encodes contexts, and the encoding appliescross-attention with origin inputs. With our method, the origin language modelscan cover several times longer contexts while keeping the computingrequirements close to the baseline. Our experiments demonstrate that afterfine-tuning, there is improved performance across two held-in datasets, fourheld-out datasets, and also in two In Context Learning settings.</description><author>Zhuo Chen, Xinyu Wang, Yong Jiang, Pengjun Xie, Fei Huang, Kewei Tu</author><pubDate>Mon, 01 Jul 2024 11:38:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02022v2</guid></item><item><title>Towards Robust Physical-world Backdoor Attacks on Lane Detection</title><link>http://arxiv.org/abs/2405.05553v3</link><description>Deep learning-based lane detection (LD) plays a critical role in autonomousdriving systems, such as adaptive cruise control. However, it is vulnerable tobackdoor attacks. Existing backdoor attack methods on LD exhibit limitedeffectiveness in dynamic real-world scenarios, primarily because they fail toconsider dynamic scene factors, including changes in driving perspectives(e.g., viewpoint transformations) and environmental conditions (e.g., weatheror lighting changes). To tackle this issue, this paper introduces BadLANE, adynamic scene adaptation backdoor attack for LD designed to withstand changesin real-world dynamic scene factors. To address the challenges posed bychanging driving perspectives, we propose an amorphous trigger pattern composedof shapeless pixels. This trigger design allows the backdoor to be activated byvarious forms or shapes of mud spots or pollution on the road or lens, enablingadaptation to changes in vehicle observation viewpoints during driving. Tomitigate the effects of environmental changes, we design a meta-learningframework to train meta-generators tailored to different environmentalconditions. These generators produce meta-triggers that incorporate diverseenvironmental information, such as weather or lighting conditions, as theinitialization of the trigger patterns for backdoor implantation, thus enablingadaptation to dynamic environments. Extensive experiments on various commonlyused LD models in both digital and physical domains validate the effectivenessof our attacks, outperforming other baselines significantly (+25.15% on averagein Attack Success Rate). Our codes will be available upon paper publication.</description><author>Xinwei Zhang, Aishan Liu, Tianyuan Zhang, Siyuan Liang, Xianglong Liu</author><pubDate>Mon, 01 Jul 2024 11:27:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05553v3</guid></item><item><title>Mimicking User Data: On Mitigating Fine-Tuning Risks in Closed Large Language Models</title><link>http://arxiv.org/abs/2406.10288v2</link><description>Fine-tuning large language models on small, high-quality datasets can enhancetheir performance on specific downstream tasks. Recent research shows thatfine-tuning on benign, instruction-following data can inadvertently undo thesafety alignment process and increase a model's propensity to comply withharmful queries. Although critical, understanding and mitigating safety risksin well-defined tasks remains distinct from the instruction-following contextdue to structural differences in the data. Our work addresses the gap in ourunderstanding of these risks across diverse types of data in closed models -where providers control how user data is utilized in the fine-tuning process.We demonstrate how malicious actors can subtly manipulate the structure ofalmost any task-specific dataset to foster significantly more dangerous modelbehaviors, while maintaining an appearance of innocuity and reasonabledownstream task performance. To address this issue, we propose a novelmitigation strategy that mixes in safety data which mimics the task format andprompting style of the user data, showing this is more effective than existingbaselines at re-establishing safety alignment while maintaining similar taskperformance.</description><author>Francisco Eiras, Aleksandar Petrov, Phillip H. S. Torr, M. Pawan Kumar, Adel Bibi</author><pubDate>Mon, 01 Jul 2024 11:17:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10288v2</guid></item><item><title>Training-Free Acceleration of ViTs with Delayed Spatial Merging</title><link>http://arxiv.org/abs/2303.02331v2</link><description>Token merging has emerged as a new paradigm that can accelerate the inferenceof Vision Transformers (ViTs) without any retraining or fine-tuning. To pushthe frontier of training-free acceleration in ViTs, we improve token merging byadding the perspectives of 1) activation outliers and 2) hierarchicalrepresentations. Through a careful analysis of the attention behavior in ViTs,we characterize a delayed onset of the convergent attention phenomenon, whichmakes token merging undesirable in the bottom blocks of ViTs. Moreover, weaugment token merging with a hierarchical processing scheme to capturemulti-scale redundancy between visual tokens. Combining these two insights, webuild a unified inference framework called DSM: Delayed Spatial Merging. Weextensively evaluate DSM on various ViT model scales (Tiny to Huge) and tasks(ImageNet-1k and transfer learning), achieving up to 1.8$\times$ FLOP reductionand 1.6$\times$ throughput speedup at a negligible loss while being two ordersof magnitude faster than existing methods.</description><author>Jung Hwan Heo, Seyedarmin Azizi, Arash Fayyazi, Massoud Pedram</author><pubDate>Mon, 01 Jul 2024 11:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02331v2</guid></item><item><title>The Potential and Challenges of Evaluating Attitudes, Opinions, and Values in Large Language Models</title><link>http://arxiv.org/abs/2406.11096v2</link><description>Recent advances in Large Language Models (LLMs) have sparked wide interest invalidating and comprehending the human-like cognitive-behavioral traits LLMsmay have. These cognitive-behavioral traits include typically Attitudes,Opinions, Values (AOV). However, measuring AOV embedded within LLMs remainsopaque, and different evaluation methods may yield different results. This hasled to a lack of clarity on how different studies are related to each other andhow they can be interpreted. This paper aims to bridge this gap by providing anoverview of recent works on the evaluation of AOV in LLMs. Moreover, we surveyrelated approaches in different stages of the evaluation pipeline in theseworks. By doing so, we address the potential and challenges with respect tounderstanding the model, human-AI alignment, and downstream application insocial sciences. Finally, we provide practical insights into evaluationmethods, model enhancement, and interdisciplinary collaboration, therebycontributing to the evolving landscape of evaluating AOV in LLMs.</description><author>Bolei Ma, Xinpeng Wang, Tiancheng Hu, Anna-Carolina Haensch, Michael A. Hedderich, Barbara Plank, Frauke Kreuter</author><pubDate>Mon, 01 Jul 2024 11:04:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11096v2</guid></item><item><title>CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay</title><link>http://arxiv.org/abs/2402.04858v2</link><description>Large language models are increasingly solving tasks that are commonlybelieved to require human-level reasoning ability. However, these models stillperform very poorly on benchmarks of general intelligence such as theAbstraction and Reasoning Corpus (ARC). In this paper, we approach ARC as aprogramming-by-examples problem, and introduce a novel and scalable method forlanguage model self-improvement called Code Iteration (CodeIt). Our methoditerates between 1) program sampling and hindsight relabeling, and 2) learningfrom prioritized experience replay. By relabeling the goal of an episode (i.e.,the target program output given input) to the realized output produced by thesampled program, our method effectively deals with the extreme sparsity ofrewards in program synthesis. Applying CodeIt to the ARC dataset, wedemonstrate that prioritized hindsight replay, along with pre-training anddata-augmentation, leads to successful inter-task generalization. CodeIt is thefirst neuro-symbolic approach that scales to the full ARC evaluation dataset.Our method solves 15% of ARC evaluation tasks, achieving state-of-the-artperformance and outperforming existing neural and symbolic baselines. Our codeis available at https://github.com/Qualcomm-AI-research/codeit .</description><author>Natasha Butt, Blazej Manczak, Auke Wiggers, Corrado Rainone, David W. Zhang, Michaël Defferrard, Taco Cohen</author><pubDate>Mon, 01 Jul 2024 11:03:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04858v2</guid></item><item><title>CoCoST: Automatic Complex Code Generation with Online Searching and Correctness Testing</title><link>http://arxiv.org/abs/2403.13583v2</link><description>Large Language Models have revolutionized code generation ability byconverting natural language descriptions into executable code. However,generating complex code within real-world scenarios remains challenging due tointricate structures, subtle bugs, understanding of advanced data types, andlack of supplementary contents. To address these challenges, we introduce theCoCoST framework, which enhances complex code generation by online searchingfor more information with planned queries and correctness testing for coderefinement. Moreover, CoCoST serializes the complex inputs and outputs toimprove comprehension and generates test cases to ensure the adaptability forreal-world applications. CoCoST is validated through rigorous experiments onthe DS-1000 and ClassEval datasets. Experimental results show that CoCoSTsubstantially improves the quality of complex code generation, highlighting itspotential to enhance the practicality of LLMs in generating complex code.</description><author>Xinyi He, Jiaru Zou, Yun Lin, Mengyu Zhou, Shi Han, Zejian Yuan, Dongmei Zhang</author><pubDate>Mon, 01 Jul 2024 10:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13583v2</guid></item><item><title>Towards a fully declarative neuro-symbolic language</title><link>http://arxiv.org/abs/2405.09521v2</link><description>Neuro-symbolic systems (NeSy), which claim to combine the best of bothlearning and reasoning capabilities of artificial intelligence, are missing acore property of reasoning systems: Declarativeness. The lack ofdeclarativeness is caused by the functional nature of neural predicatesinherited from neural networks. We propose and implement a general frameworkfor fully declarative neural predicates, which hence extends to fullydeclarative NeSy frameworks. We first show that the declarative extensionpreserves the learning and reasoning capabilities while being able to answerarbitrary queries while only being trained on a single query type.</description><author>Tilman Hinnerichs, Robin Manhaeve, Giuseppe Marra, Sebastijan Dumancic</author><pubDate>Mon, 01 Jul 2024 10:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09521v2</guid></item><item><title>Multimodal Learning With Intraoperative CBCT &amp; Variably Aligned Preoperative CT Data To Improve Segmentation</title><link>http://arxiv.org/abs/2406.11650v2</link><description>Cone-beam computed tomography (CBCT) is an important tool facilitatingcomputer aided interventions, despite often suffering from artifacts that posechallenges for accurate interpretation. While the degraded image quality canaffect downstream segmentation, the availability of high quality, preoperativescans represents potential for improvements. Here we consider a setting wherepreoperative CT and intraoperative CBCT scans are available, however, thealignment (registration) between the scans is imperfect. We propose amultimodal learning method that fuses roughly aligned CBCT and CT scans andinvestigate the effect of CBCT quality and misalignment on the finalsegmentation performance. For that purpose, we make use of a syntheticallygenerated data set containing real CT and synthetic CBCT volumes. As anapplication scenario, we focus on liver and liver tumor segmentation. We showthat the fusion of preoperative CT and simulated, intraoperative CBCT mostlyimproves segmentation performance (compared to using intraoperative CBCT only)and that even clearly misaligned preoperative data has the potential to improvesegmentation performance.</description><author>Maximilian E. Tschuchnig, Philipp Steininger, Michael Gadermayr</author><pubDate>Mon, 01 Jul 2024 10:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11650v2</guid></item></channel></rss>