<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 29 Aug 2024 01:00:53 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>HER2 and FISH Status Prediction in Breast Biopsy H&amp;E-Stained Images Using Deep Learning</title><link>http://arxiv.org/abs/2408.13818v2</link><description>The current standard for detecting human epidermal growth factor receptor 2(HER2) status in breast cancer patients relies on HER2 amplification,identified through fluorescence in situ hybridization (FISH) orimmunohistochemistry (IHC). However, hematoxylin and eosin (H\&amp;E) tumor stainsare more widely available, and accurately predicting HER2 status using H\&amp;Ecould reduce costs and expedite treatment selection. Deep Learning algorithmsfor H&amp;E have shown effectiveness in predicting various cancer features andclinical outcomes, including moderate success in HER2 status prediction. Inthis work, we employed a customized weak supervision classification techniquecombined with MoCo-v2 contrastive learning to predict HER2 status. We trainedour pipeline on 182 publicly available H&amp;E Whole Slide Images (WSIs) from TheCancer Genome Atlas (TCGA), for which annotations by the pathology team at YaleSchool of Medicine are publicly available. Our pipeline achieved an Area Underthe Curve (AUC) of 0.85 across four different test folds. Additionally, wetested our model on 44 H&amp;E slides from the TCGA-BRCA dataset, which had an HER2score of 2+ and included corresponding HER2 status and FISH test results. Thesecases are considered equivocal for IHC, requiring an expensive FISH test ontheir IHC slides for disambiguation. Our pipeline demonstrated an AUC of 0.81on these challenging H&amp;E slides. Reducing the need for FISH test can havesignificant implications in cancer treatment equity for underservedpopulations.</description><author>Ardhendu Sekhar, Vrinda Goel, Garima Jain, Abhijeet Patil, Ravi Kant Gupta, Amit Sethi</author><pubDate>Wed, 28 Aug 2024 17:19:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13818v2</guid></item><item><title>Halfway Escape Optimization: A Quantum-Inspired Solution for General Optimization Problems</title><link>http://arxiv.org/abs/2405.02850v5</link><description>This paper first proposes the Halfway Escape Optimization (HEO) algorithm, aquantum-inspired metaheuristic designed to address general optimizationproblems characterized by rugged landscapes and high-dimensionality with anefficient convergence rate. The study presents a comprehensive comparativeevaluation of HEO's performance against established optimization algorithms,including Particle Swarm Optimization (PSO), Genetic Algorithm (GA), ArtificialFish Swarm Algorithm (AFSA), Grey Wolf Optimizer (GWO), and Quantum behavedParticle Swarm Optimization (QPSO). The primary analysis encompasses 14benchmark functions with dimension 30, demonstrating HEO's effectiveness andadaptability in navigating general optimization problems and providing valuableinsights into its performance. The test of HEO in Pressure Vessel Design andTubular Column Design infers its feasibility and potential in real-timeapplications. Further validation in Osmancik-97 and Cammeo Rice Classificationproves the effectiveness of HEO and achieves a higher accuracy record.</description><author>Jiawen Li, Anwar PP Abdul Majeed, Pascal Lefevre</author><pubDate>Wed, 28 Aug 2024 17:19:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02850v5</guid></item><item><title>GINN-KAN: Interpretability pipelining with applications in Physics Informed Neural Networks</title><link>http://arxiv.org/abs/2408.14780v2</link><description>Neural networks are powerful function approximators, yet their ``black-box"nature often renders them opaque and difficult to interpret. While manypost-hoc explanation methods exist, they typically fail to capture theunderlying reasoning processes of the networks. A truly interpretable neuralnetwork would be trained similarly to conventional models using techniques suchas backpropagation, but additionally provide insights into the learnedinput-output relationships. In this work, we introduce the concept ofinterpretability pipelineing, to incorporate multiple interpretabilitytechniques to outperform each individual technique. To this end, we firstevaluate several architectures that promise such interpretability, with aparticular focus on two recent models selected for their potential toincorporate interpretability into standard neural network architectures whilestill leveraging backpropagation: the Growing Interpretable Neural Network(GINN) and Kolmogorov Arnold Networks (KAN). We analyze the limitations andstrengths of each and introduce a novel interpretable neural network GINN-KANthat synthesizes the advantages of both models. When tested on the Feynmansymbolic regression benchmark datasets, GINN-KAN outperforms both GINN and KAN.To highlight the capabilities and the generalizability of this approach, weposition GINN-KAN as an alternative to conventional black-box networks inPhysics-Informed Neural Networks (PINNs). We expect this to have far-reachingimplications in the application of deep learning pipelines in the naturalsciences. Our experiments with this interpretable PINN on 15 different partialdifferential equations demonstrate that GINN-KAN augmented PINNs outperformPINNs with black-box networks in solving differential equations and surpass thecapabilities of both GINN and KAN.</description><author>Nisal Ranasinghe, Yu Xia, Sachith Seneviratne, Saman Halgamuge</author><pubDate>Wed, 28 Aug 2024 15:48:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14780v2</guid></item><item><title>AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha Factors</title><link>http://arxiv.org/abs/2406.18394v4</link><description>The complexity of financial data, characterized by its variability and lowsignal-to-noise ratio, necessitates advanced methods in quantitative investmentthat prioritize both performance and interpretability.Transitioning from earlymanual extraction to genetic programming, the most advanced approach in thealpha factor mining domain currently employs reinforcement learning to mine aset of combination factors with fixed weights. However, the performance ofresultant alpha factors exhibits inconsistency, and the inflexibility of fixedfactor weights proves insufficient in adapting to the dynamic nature offinancial markets. To address this issue, this paper proposes a two-stageformulaic alpha generating framework AlphaForge, for alpha factor mining andfactor combination. This framework employs a generative-predictive neuralnetwork to generate factors, leveraging the robust spatial explorationcapabilities inherent in deep learning while concurrently preserving diversity.The combination model within the framework incorporates the temporalperformance of factors for selection and dynamically adjusts the weightsassigned to each component alpha factor. Experiments conducted on real-worlddatasets demonstrate that our proposed model outperforms contemporarybenchmarks in formulaic alpha factor mining. Furthermore, our model exhibits anotable enhancement in portfolio returns within the realm of quantitativeinvestment and real money investment.</description><author>Hao Shi, Weili Song, Xinting Zhang, Jiahe Shi, Cuicui Luo, Xiang Ao, Hamid Arian, Luis Seco</author><pubDate>Wed, 28 Aug 2024 15:21:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18394v4</guid></item><item><title>Unveiling the Statistical Foundations of Chain-of-Thought Prompting Methods</title><link>http://arxiv.org/abs/2408.14511v2</link><description>Chain-of-Thought (CoT) prompting and its variants have gained popularity aseffective methods for solving multi-step reasoning problems using pretrainedlarge language models (LLMs). In this work, we analyze CoT prompting from astatistical estimation perspective, providing a comprehensive characterizationof its sample complexity. To this end, we introduce a multi-step latentvariable model that encapsulates the reasoning process, where the latentvariable encodes the task information. Under this framework, we demonstratethat when the pretraining dataset is sufficiently large, the estimator formedby CoT prompting is equivalent to a Bayesian estimator. This estimatoreffectively solves the multi-step reasoning problem by aggregating a posteriordistribution inferred from the demonstration examples in the prompt. Moreover,we prove that the statistical error of the CoT estimator can be decomposed intotwo main components: (i) a prompting error, which arises from inferring thetrue task using CoT prompts, and (ii) the statistical error of the pretrainedLLM. We establish that, under appropriate assumptions, the prompting errordecays exponentially to zero as the number of demonstrations increases.Additionally, we explicitly characterize the approximation and generalizationerrors of the pretrained LLM. Notably, we construct a transformer model thatapproximates the target distribution of the multi-step reasoning problem withan error that decreases exponentially in the number of transformer blocks. Ouranalysis extends to other variants of CoT, including Self-Consistent CoT,Tree-of-Thought, and Selection-Inference, offering a broad perspective on theefficacy of these methods. We also provide numerical experiments to validatethe theoretical findings.</description><author>Xinyang Hu, Fengzhuo Zhang, Siyu Chen, Zhuoran Yang</author><pubDate>Wed, 28 Aug 2024 14:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14511v2</guid></item><item><title>Evaluating Large Language Models on Spatial Tasks: A Multi-Task Benchmarking Study</title><link>http://arxiv.org/abs/2408.14438v2</link><description>The advent of large language models such as ChatGPT, Gemini, and others hasunderscored the importance of evaluating their diverse capabilities, rangingfrom natural language understanding to code generation. However, theirperformance on spatial tasks has not been comprehensively assessed. This studyaddresses this gap by introducing a novel multi-task spatial evaluationdataset, designed to systematically explore and compare the performance ofseveral advanced models on spatial tasks. The dataset encompasses twelvedistinct task types, including spatial understanding and path planning, eachwith verified, accurate answers. We evaluated multiple models, includingOpenAI's gpt-3.5-turbo, gpt-4o, and ZhipuAI's glm-4, through a two-phasetesting approach. Initially, we conducted zero-shot testing, followed bycategorizing the dataset by difficulty and performing prompt tuning tests.Results indicate that gpt-4o achieved the highest overall accuracy in the firstphase, with an average of 71.3%. Although moonshot-v1-8k slightlyunderperformed overall, it surpassed gpt-4o in place name recognition tasks.The study also highlights the impact of prompt strategies on model performancein specific tasks. For example, the Chain-of-Thought (COT) strategy increasedgpt-4o's accuracy in path planning from 12.4% to 87.5%, while a one-shotstrategy enhanced moonshot-v1-8k's accuracy in mapping tasks from 10.1% to76.3%.</description><author>Liuchang Xu, Shuo Zhao, Qingming Lin, Luyao Chen, Qianqian Luo, Sensen Wu, Xinyue Ye, Hailin Feng, Zhenhong Du</author><pubDate>Wed, 28 Aug 2024 13:19:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14438v2</guid></item><item><title>Research on the Spatial Data Intelligent Foundation Model</title><link>http://arxiv.org/abs/2405.19730v5</link><description>This report focuses on spatial data intelligent large models, delving intothe principles, methods, and cutting-edge applications of these models. Itprovides an in-depth discussion on the definition, development history, currentstatus, and trends of spatial data intelligent large models, as well as thechallenges they face. The report systematically elucidates the key technologiesof spatial data intelligent large models and their applications in urbanenvironments, aerospace remote sensing, geography, transportation, and otherscenarios. Additionally, it summarizes the latest application cases of spatialdata intelligent large models in themes such as urban development, multimodalsystems, remote sensing, smart transportation, and resource environments.Finally, the report concludes with an overview and outlook on the developmentprospects of spatial data intelligent large models.</description><author>Shaohua Wang, Xing Xie, Yong Li, Danhuai Guo, Zhi Cai, Yu Liu, Yang Yue, Xiao Pan, Feng Lu, Huayi Wu, Zhipeng Gui, Zhiming Ding, Bolong Zheng, Fuzheng Zhang, Jingyuan Wang, Zhengchao Chen, Hao Lu, Jiayi Li, Peng Yue, Wenhao Yu, Yao Yao, Leilei Sun, Yong Zhang, Longbiao Chen, Xiaoping Du, Xiang Li, Xueying Zhang, Kun Qin, Zhaoya Gong, Weihua Dong, Xiaofeng Meng</author><pubDate>Wed, 28 Aug 2024 13:05:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19730v5</guid></item><item><title>Contextual Bandit with Herding Effects: Algorithms and Recommendation Applications</title><link>http://arxiv.org/abs/2408.14432v2</link><description>Contextual bandits serve as a fundamental algorithmic framework foroptimizing recommendation decisions online. Though extensive attention has beenpaid to tailoring contextual bandits for recommendation applications, the"herding effects" in user feedback have been ignored. These herding effectsbias user feedback toward historical ratings, breaking down the assumption ofunbiased feedback inherent in contextual bandits. This paper develops a novelvariant of the contextual bandit that is tailored to address the feedback biascaused by the herding effects. A user feedback model is formulated to capturethis feedback bias. We design the TS-Conf (Thompson Sampling under Conformity)algorithm, which employs posterior sampling to balance the exploration andexploitation tradeoff. We prove an upper bound for the regret of the algorithm,revealing the impact of herding effects on learning speed. Extensiveexperiments on datasets demonstrate that TS-Conf outperforms four benchmarkalgorithms. Analysis reveals that TS-Conf effectively mitigates the negativeimpact of herding effects, resulting in faster learning and improvedrecommendation accuracy.</description><author>Luyue Xu, Liming Wang, Hong Xie, Mingqiang Zhou</author><pubDate>Wed, 28 Aug 2024 12:39:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14432v2</guid></item><item><title>Language-specific Calibration for Pruning Multilingual Language Models</title><link>http://arxiv.org/abs/2408.14398v2</link><description>Recent advances in large language model (LLM) pruning have shownstate-of-the-art compression results in post-training and retraining-freesettings while maintaining high predictive performance. However, such researchmainly considers calibrating pruning using English text, despite themultilingual nature of modern LLMs and their frequent uses in non-Englishlanguages. In this paper, we set out to explore effective strategies forcalibrating the pruning of multilingual language models. We present the firstcomprehensive empirical study, comparing different calibration languages forpruning multilingual models across diverse tasks, models, and state-of-the-artpruning techniques. Our results present practical suggestions, for example,calibrating in the target language can efficiently yield lower perplexity, butdoes not necessarily benefit downstream tasks. Our further analysis experimentsunveil that calibration in the target language mainly contributes to preservinglanguage-specific features related to fluency and coherence, but might notcontribute to capturing language-agnostic features such as languageunderstanding and reasoning. Last, we provide practical recommendations forfuture practitioners.</description><author>Simon Kurz, Jian-Jia Chen, Lucie Flek, Zhixue Zhao</author><pubDate>Wed, 28 Aug 2024 12:03:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14398v2</guid></item><item><title>FAST-LIVO2: Fast, Direct LiDAR-Inertial-Visual Odometry</title><link>http://arxiv.org/abs/2408.14035v2</link><description>This paper proposes FAST-LIVO2: a fast, direct LiDAR-inertial-visual odometryframework to achieve accurate and robust state estimation in SLAM tasks andprovide great potential in real-time, onboard robotic applications. FAST-LIVO2fuses the IMU, LiDAR and image measurements efficiently through an ESIKF. Toaddress the dimension mismatch between the heterogeneous LiDAR and imagemeasurements, we use a sequential update strategy in the Kalman filter. Toenhance the efficiency, we use direct methods for both the visual and LiDARfusion, where the LiDAR module registers raw points without extracting edge orplane features and the visual module minimizes direct photometric errorswithout extracting ORB or FAST corner features. The fusion of both visual andLiDAR measurements is based on a single unified voxel map where the LiDARmodule constructs the geometric structure for registering new LiDAR scans andthe visual module attaches image patches to the LiDAR points. To enhance theaccuracy of image alignment, we use plane priors from the LiDAR points in thevoxel map (and even refine the plane prior) and update the reference patchdynamically after new images are aligned. Furthermore, to enhance therobustness of image alignment, FAST-LIVO2 employs an on-demanding raycastoperation and estimates the image exposure time in real time. Lastly, we detailthree applications of FAST-LIVO2: UAV onboard navigation demonstrating thesystem's computation efficiency for real-time onboard navigation, airbornemapping showcasing the system's mapping accuracy, and 3D model rendering(mesh-based and NeRF-based) underscoring the suitability of our reconstructeddense map for subsequent rendering tasks. We open source our code, dataset andapplication on GitHub to benefit the robotics community.</description><author>Chunran Zheng, Wei Xu, Zuhao Zou, Tong Hua, Chongjian Yuan, Dongjiao He, Bingyang Zhou, Zheng Liu, Jiarong Lin, Fangcheng Zhu, Yunfan Ren, Rong Wang, Fanle Meng, Fu Zhang</author><pubDate>Wed, 28 Aug 2024 12:03:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14035v2</guid></item><item><title>CMTA: Cross-Modal Temporal Alignment for Event-guided Video Deblurring</title><link>http://arxiv.org/abs/2408.14930v2</link><description>Video deblurring aims to enhance the quality of restored results inmotion-blurred videos by effectively gathering information from adjacent videoframes to compensate for the insufficient data in a single blurred frame.However, when faced with consecutively severe motion blur situations,frame-based video deblurring methods often fail to find accurate temporalcorrespondence among neighboring video frames, leading to diminishedperformance. To address this limitation, we aim to solve the video deblurringtask by leveraging an event camera with micro-second temporal resolution. Tofully exploit the dense temporal resolution of the event camera, we propose twomodules: 1) Intra-frame feature enhancement operates within the exposure timeof a single blurred frame, iteratively enhancing cross-modality features in arecurrent manner to better utilize the rich temporal information of events, 2)Inter-frame temporal feature alignment gathers valuable long-range temporalinformation to target frames, aggregating sharp features leveraging theadvantages of the events. In addition, we present a novel dataset composed ofreal-world blurred RGB videos, corresponding sharp videos, and event data. Thisdataset serves as a valuable resource for evaluating event-guided deblurringmethods. We demonstrate that our proposed methods outperform state-of-the-artframe-based and event-based motion deblurring methods through extensiveexperiments conducted on both synthetic and real-world deblurring datasets. Thecode and dataset are available at https://github.com/intelpro/CMTA.</description><author>Taewoo Kim, Hoonhee Cho, Kuk-Jin Yoon</author><pubDate>Wed, 28 Aug 2024 09:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14930v2</guid></item><item><title>Urdu Digital Text Word Optical Character Recognition Using Permuted Auto Regressive Sequence Modeling</title><link>http://arxiv.org/abs/2408.15119v2</link><description>This research paper presents a novel word-level Optical Character Recognition(OCR) model developed specifically for digital Urdu text. The model utilizestransformer-based architectures and attention mechanisms to address the uniquechallenges of recognizing Urdu script, which includes handling a diverse rangeof text styles, fonts, and variations. Trained on a comprehensive dataset ofapproximately 160,000 Urdu text images, the model incorporates a permutedautoregressive sequence (PARSeq) architecture. This design enablescontext-aware inference and iterative refinement by leveraging bidirectionalcontext information, significantly enhancing its ability to accuratelyrecognize Urdu characters. The model achieves a character error rate (CER) of0.178, highlighting its effectiveness and precision in real-world applications.However, the model has some limitations, such as difficulties with blurredimages, non-horizontal orientations, and the presence of trailing punctuationmarks, which can introduce noise into the recognition process. Addressing thesechallenges will be a key focus of future work. Future research will aim tofurther refine the model through advanced data augmentation techniques,optimization of hyperparameters, and the integration of context-aware languagemodels, ultimately enhancing the model's performance and robustness in Urdutext recognition.</description><author>Ahmed Mustafa, Muhammad Tahir Rafique, Muhammad Ijlal Baig, Hasan Sajid, Muhammad Jawad Khan, Karam Dad Kallu</author><pubDate>Wed, 28 Aug 2024 09:11:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15119v2</guid></item><item><title>Domain-decoupled Physics-informed Neural Networks with Closed-form Gradients for Fast Model Learning of Dynamical Systems</title><link>http://arxiv.org/abs/2408.14951v2</link><description>Physics-informed neural networks (PINNs) are trained using physical equationsand can also incorporate unmodeled effects by learning from data. PINNs forcontrol (PINCs) of dynamical systems are gaining interest due to theirprediction speed compared to classical numerical integration methods fornonlinear state-space models, making them suitable for real-time controlapplications. We introduce the domain-decoupled physics-informed neural network(DD-PINN) to address current limitations of PINC in handling large and complexnonlinear dynamical systems. The time domain is decoupled from the feed-forwardneural network to construct an Ansatz function, allowing for calculation ofgradients in closed form. This approach significantly reduces training times,especially for large dynamical systems, compared to PINC, which relies ongraph-based automatic differentiation. Additionally, the DD-PINN inherentlyfulfills the initial condition and supports higher-order excitation inputs,simplifying the training process and enabling improved prediction accuracy.Validation on three systems - a nonlinear mass-spring-damper, afive-mass-chain, and a two-link robot - demonstrates that the DD-PINN achievessignificantly shorter training times. In cases where the PINC's predictiondiverges, the DD-PINN's prediction remains stable and accurate due to higherphysics loss reduction or use of a higher-order excitation input. The DD-PINNallows for fast and accurate learning of large dynamical systems previously outof reach for the PINC.</description><author>Henrik Krauss, Tim-Lukas Habich, Max Bartholdt, Thomas Seel, Moritz Schappler</author><pubDate>Wed, 28 Aug 2024 09:08:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14951v2</guid></item><item><title>DocLayLLM: An Efficient and Effective Multi-modal Extension of Large Language Models for Text-rich Document Understanding</title><link>http://arxiv.org/abs/2408.15045v2</link><description>Text-rich document understanding (TDU) refers to analyzing and comprehendingdocuments containing substantial textual content. With the rapid evolution oflarge language models (LLMs), they have been widely leveraged for TDU due totheir remarkable versatility and generalization. In this paper, we introduceDocLayLLM, an efficient and effective multi-modal extension of LLMsspecifically designed for TDU. By integrating visual patch tokens and 2Dpositional tokens into LLMs and encoding the document content using the LLMsthemselves, we fully take advantage of the document comprehension capability ofLLMs and enhance their perception of OCR information. We have also deeplyconsidered the role of the chain-of-thought (CoT) and innovatively proposed thetechniques of CoT Pre-training and CoT Annealing. Our DocLayLLM can achieveremarkable performances with lightweight training settings, showcasing itsefficiency and effectiveness. Experimental results demonstrate that ourDocLayLLM surpasses existing OCR-dependent methods and also outperformsOCR-free competitors.</description><author>Wenhui Liao, Jiapeng Wang, Hongliang Li, Chengyu Wang, Jun Huang, Lianwen Jin</author><pubDate>Wed, 28 Aug 2024 08:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15045v2</guid></item><item><title>Research Advances and New Paradigms for Biology-inspired Spiking Neural Networks</title><link>http://arxiv.org/abs/2408.13996v2</link><description>Spiking neural networks (SNNs) are gaining popularity in the computationalsimulation and artificial intelligence fields owing to their biologicalplausibility and computational efficiency. This paper explores the historicaldevelopment of SNN and concludes that these two fields are intersecting andmerging rapidly. Following the successful application of Dynamic Vision Sensors(DVS) and Dynamic Audio Sensors (DAS), SNNs have found some proper paradigms,such as continuous visual signal tracking, automatic speech recognition, andreinforcement learning for continuous control, that have extensively supportedtheir key features, including spike encoding, neuronal heterogeneity, specificfunctional circuits, and multiscale plasticity. Compared to these real-worldparadigms, the brain contains a spiking version of the biology-world paradigm,which exhibits a similar level of complexity and is usually considered a mirrorof the real world. Considering the projected rapid development of invasive andparallel Brain-Computer Interface (BCI), as well as the new BCI-based paradigmsthat include online pattern recognition and stimulus control of biologicalspike trains, SNNs naturally leverage their advantages in energy efficiency,robustness, and flexibility. The biological brain has inspired the presentstudy of SNNs and effective SNN machine-learning algorithms, which can helpenhance neuroscience discoveries in the brain by applying them to the new BCIparadigm. Such two-way interactions with positive feedback can accelerate brainscience research and brain-inspired intelligence technology.</description><author>Tianyu Zheng, Liyuan Han, Tielin Zhang</author><pubDate>Wed, 28 Aug 2024 08:28:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13996v2</guid></item><item><title>Adapting Segment Anything Model to Multi-modal Salient Object Detection with Semantic Feature Fusion Guidance</title><link>http://arxiv.org/abs/2408.15063v2</link><description>Although most existing multi-modal salient object detection (SOD) methodsdemonstrate effectiveness through training models from scratch, the limitedmulti-modal data hinders these methods from reaching optimality. In this paper,we propose a novel framework to explore and exploit the powerful featurerepresentation and zero-shot generalization ability of the pre-trained SegmentAnything Model (SAM) for multi-modal SOD. Despite serving as a recent visionfundamental model, driving the class-agnostic SAM to comprehend and detectsalient objects accurately is non-trivial, especially in challenging scenes. Tothis end, we develop \underline{SAM} with se\underline{m}anticf\underline{e}ature fu\underline{s}ion guidanc\underline{e} (Sammese), whichincorporates multi-modal saliency-specific knowledge into SAM to adapt SAM tomulti-modal SOD tasks. However, it is difficult for SAM trained on single-modaldata to directly mine the complementary benefits of multi-modal inputs andcomprehensively utilize them to achieve accurate saliency prediction.To addressthese issues, we first design a multi-modal complementary fusion module toextract robust multi-modal semantic features by integrating information fromvisible and thermal or depth image pairs. Then, we feed the extractedmulti-modal semantic features into both the SAM image encoder and mask decoderfor fine-tuning and prompting, respectively. Specifically, in the imageencoder, a multi-modal adapter is proposed to adapt the single-modal SAM tomulti-modal information. In the mask decoder, a semantic-geometric promptgeneration strategy is proposed to produce corresponding embeddings withvarious saliency cues. Extensive experiments on both RGB-D and RGB-T SODbenchmarks show the effectiveness of the proposed framework.</description><author>Kunpeng Wang, Danying Lin, Chenglong Li, Zhengzheng Tu, Bin Luo</author><pubDate>Wed, 28 Aug 2024 08:28:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15063v2</guid></item><item><title>Symplectic Bregman divergences</title><link>http://arxiv.org/abs/2408.12961v3</link><description>We present a generalization of Bregman divergences in symplectic vectorspaces that we term symplectic Bregman divergences. Symplectic Bregmandivergences are derived from a symplectic generalization of the Fenchel-Younginequality which relies on the notion of symplectic subdifferentials. Thesymplectic Fenchel-Young inequality is obtained using the symplectic Fencheltransform which is defined with respect to the symplectic form. Sincesymplectic forms can be generically built from pairings of dual systems, we geta generalization of Bregman divergences in dual systems obtained by equivalentsymplectic Bregman divergences. In particular, when the symplectic form isderived from an inner product, we show that the corresponding symplecticBregman divergences amount to ordinary Bregman divergences with respect tocomposite inner products. Some potential applications of symplectic divergencesin geometric mechanics, information geometry, and learning dynamics in machinelearning are touched upon.</description><author>Frank Nielsen</author><pubDate>Wed, 28 Aug 2024 08:15:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12961v3</guid></item><item><title>DualAnoDiff: Dual-Interrelated Diffusion Model for Few-Shot Anomaly Image Generation</title><link>http://arxiv.org/abs/2408.13509v2</link><description>The performance of anomaly inspection in industrial manufacturing isconstrained by the scarcity of anomaly data. To overcome this challenge,researchers have started employing anomaly generation approaches to augment theanomaly dataset. However, existing anomaly generation methods suffer fromlimited diversity in the generated anomalies and struggle to achieve a seamlessblending of this anomaly with the original image. In this paper, we overcomethese challenges from a new perspective, simultaneously generating a pair ofthe overall image and the corresponding anomaly part. We propose DualAnoDiff, anovel diffusion-based few-shot anomaly image generation model, which cangenerate diverse and realistic anomaly images by using a dual-interrelateddiffusion model, where one of them is employed to generate the whole imagewhile the other one generates the anomaly part. Moreover, we extract backgroundand shape information to mitigate the distortion and blurriness phenomenon infew-shot image generation. Extensive experiments demonstrate the superiority ofour proposed model over state-of-the-art methods in terms of both realism anddiversity. Overall, our approach significantly improves the performance ofdownstream anomaly detection tasks, including anomaly detection, anomalylocalization, and anomaly classification tasks.</description><author>Ying Jin, Jinlong Peng, Qingdong He, Teng Hu, Hao Chen, Jiafu Wu, Wenbing Zhu, Mingmin Chi, Jun Liu, Yabiao Wang, Chengjie Wang</author><pubDate>Wed, 28 Aug 2024 06:53:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13509v2</guid></item><item><title>Geo-Llama: Leveraging LLMs for Human Mobility Trajectory Generation with Spatiotemporal Constraints</title><link>http://arxiv.org/abs/2408.13918v2</link><description>Simulating human mobility data is essential for various application domains,including transportation, urban planning, and epidemic control, since real dataare often inaccessible to researchers due to expensive costs and privacyissues. Several existing deep generative solutions propose learning from realtrajectories to generate synthetic ones. Despite the progress, most of themsuffer from training stability issues and scale poorly with growing data size.More importantly, they generally lack control mechanisms to steer the generatedtrajectories based on spatiotemporal constraints such as fixing specificvisits. To address such limitations, we formally define the controlledtrajectory generation problem with spatiotemporal constraints and proposeGeo-Llama. This novel LLM-inspired framework enforces explicit visitconstraints in a contextually coherent way. It fine-tunes pre-trained LLMs ontrajectories with a visit-wise permutation strategy where each visitcorresponds to a time and location. This enables the model to capture thespatiotemporal patterns regardless of visit orders and allows flexible andin-context constraint integration through prompts during generation. Extensiveexperiments on real-world and synthetic datasets validate the effectiveness ofGeo-Llama, demonstrating its versatility and robustness in handling a broadrange of constraints to generate more realistic trajectories compared toexisting methods.</description><author>Siyu Li, Toan Tran, Haowen Lin, John Krumm, Cyrus Shahabi, Li Xiong</author><pubDate>Wed, 28 Aug 2024 06:16:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13918v2</guid></item><item><title>Classification Matters: Improving Video Action Detection with Class-Specific Attention</title><link>http://arxiv.org/abs/2407.19698v3</link><description>Video action detection (VAD) aims to detect actors and classify their actionsin a video. We figure that VAD suffers more from classification rather thanlocalization of actors. Hence, we analyze how prevailing methods form featuresfor classification and find that they prioritize actor regions, yet oftenoverlooking the essential contextual information necessary for accurateclassification. Accordingly, we propose to reduce the bias toward actor andencourage paying attention to the context that is relevant to each actionclass. By assigning a class-dedicated query to each action class, our model candynamically determine where to focus for effective classification. The proposedmodel demonstrates superior performance on three challenging benchmarks withsignificantly fewer parameters and less computation.</description><author>Jinsung Lee, Taeoh Kim, Inwoong Lee, Minho Shim, Dongyoon Wee, Minsu Cho, Suha Kwak</author><pubDate>Wed, 28 Aug 2024 04:41:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19698v3</guid></item><item><title>A Survey of Large Language Models for European Languages</title><link>http://arxiv.org/abs/2408.15040v2</link><description>Large Language Models (LLMs) have gained significant attention due to theirhigh performance on a wide range of natural language tasks since the release ofChatGPT. The LLMs learn to understand and generate language by trainingbillions of model parameters on vast volumes of text data. Despite being arelatively new field, LLM research is rapidly advancing in various directions.In this paper, we present an overview of LLM families, including LLaMA, PaLM,GPT, and MoE, and the methods developed to create and enhance LLMs for officialEuropean Union (EU) languages. We provide a comprehensive summary of commonmonolingual and multilingual datasets used for pretraining large languagemodels.</description><author>Wazir Ali, Sampo Pyysalo</author><pubDate>Wed, 28 Aug 2024 03:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15040v2</guid></item><item><title>Physics-Informed Neural Network for Concrete Manufacturing Process Optimization</title><link>http://arxiv.org/abs/2408.14502v2</link><description>Concrete manufacturing projects are one of the most common ones forconsulting agencies. Because of the highly non-linear dependency of inputmaterials like ash, water, cement, superplastic, etc; with the resultantstrength of concrete, it gets difficult for machine learning models tosuccessfully capture this relation and perform cost optimizations. This paperhighlights how PINNs (Physics Informed Neural Networks) can be useful in thegiven situation. This state-of-the-art model shall also get compared withtraditional models like Linear Regression, Random Forest, Gradient Boosting,and Deep Neural Network. Results of the research highlights how well PINNsperformed even with reduced dataset, thus resolving one of the biggest issuesof limited data availability for ML models. On an average, PINN got the lossvalue reduced by 26.3% even with 40% lesser data compared to the Deep NeuralNetwork. In addition to predicting strength of the concrete given the quantityof raw materials, the paper also highlights the use of heuristic optimizationmethod like Particle Swarm Optimization (PSO) in predicting quantity of rawmaterials required to manufacture concrete of given strength with least cost.</description><author>Sam Varghese, Rahul Anand, Dr. Gaurav Paliwal</author><pubDate>Wed, 28 Aug 2024 03:22:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14502v2</guid></item><item><title>VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities</title><link>http://arxiv.org/abs/2408.14895v2</link><description>Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data(e.g., images and videos) into symbols, have attracted attention as resourcesenabling knowledge processing and machine learning across modalities. However,the construction of MMKGs for videos consisting of multiple events, such asdaily activities, is still in the early stages. In this paper, we construct anMMKG based on synchronized multi-view simulated videos of daily activities.Besides representing the content of daily life videos as event-centricknowledge, our MMKG also includes frame-by-frame fine-grained changes, such asbounding boxes within video frames. In addition, we provide support tools forquerying our MMKG. As an application example, we demonstrate that our MMKGfacilitates benchmarking vision-language models by providing the necessaryvision-language datasets for a tailored task.</description><author>Shusaku Egami, Takahiro Ugai, Swe Nwe Nwe Htun, Ken Fukuda</author><pubDate>Wed, 28 Aug 2024 01:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14895v2</guid></item><item><title>Customize-A-Video: One-Shot Motion Customization of Text-to-Video Diffusion Models</title><link>http://arxiv.org/abs/2402.14780v3</link><description>Image customization has been extensively studied in text-to-image (T2I)diffusion models, leading to impressive outcomes and applications. With theemergence of text-to-video (T2V) diffusion models, its temporal counterpart,motion customization, has not yet been well investigated. To address thechallenge of one-shot video motion customization, we propose Customize-A-Videothat models the motion from a single reference video and adapts it to newsubjects and scenes with both spatial and temporal varieties. It leverageslow-rank adaptation (LoRA) on temporal attention layers to tailor thepre-trained T2V diffusion model for specific motion modeling. To disentanglethe spatial and temporal information during training, we introduce a novelconcept of appearance absorbers that detach the original appearance from thereference video prior to motion learning. The proposed modules are trained in astaged pipeline and inferred in a plug-and-play fashion, enabling easyextensions to various downstream tasks such as custom video generation andediting, video appearance customization and multiple motion combination. Ourproject page can be found at https://customize-a-video.github.io.</description><author>Yixuan Ren, Yang Zhou, Jimei Yang, Jing Shi, Difan Liu, Feng Liu, Mingi Kwon, Abhinav Shrivastava</author><pubDate>Wed, 28 Aug 2024 01:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14780v3</guid></item><item><title>Quantum-machine-assisted Drug Discovery: Survey and Perspective</title><link>http://arxiv.org/abs/2408.13479v2</link><description>Drug discovery and development is a highly complex and costly endeavor,typically requiring over a decade and substantial financial investment to bringa new drug to market. Traditional computer-aided drug design (CADD) has madesignificant progress in accelerating this process, but the development ofquantum computing offers potential due to its unique capabilities. This paperdiscusses the integration of quantum computing into drug discovery anddevelopment, focusing on how quantum technologies might accelerate and enhancevarious stages of the drug development cycle. Specifically, we explore theapplication of quantum computing in addressing challenges related to drugdiscovery, such as molecular simulation and the prediction of drug-targetinteractions, as well as the optimization of clinical trial outcomes. Byleveraging the inherent capabilities of quantum computing, we might be able toreduce the time and cost associated with bringing new drugs to market,ultimately benefiting public health.</description><author>Yidong Zhou, Jintai Chen, Jinglei Cheng, Gopal Karemore, Marinka Zitnik, Frederic T. Chong, Junyu Liu, Tianfan Fu, Zhiding Liang</author><pubDate>Wed, 28 Aug 2024 00:19:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13479v2</guid></item><item><title>Submodular Maximization Approaches for Equitable Client Selection in Federated Learning</title><link>http://arxiv.org/abs/2408.13683v2</link><description>In a conventional Federated Learning framework, client selection for trainingtypically involves the random sampling of a subset of clients in eachiteration. However, this random selection often leads to disparate performanceamong clients, raising concerns regarding fairness, particularly inapplications where equitable outcomes are crucial, such as in medical orfinancial machine learning tasks. This disparity typically becomes morepronounced with the advent of performance-centric client sampling techniques.This paper introduces two novel methods, namely SUBTRUNC and UNIONFL, designedto address the limitations of random client selection. Both approaches utilizesubmodular function maximization to achieve more balanced models. By modifyingthe facility location problem, they aim to mitigate the fairness concernsassociated with random selection. SUBTRUNC leverages client loss information todiversify solutions, while UNIONFL relies on historical client selection datato ensure a more equitable performance of the final model. Moreover, thesealgorithms are accompanied by robust theoretical guarantees regardingconvergence under reasonable assumptions. The efficacy of these methods isdemonstrated through extensive evaluations across heterogeneous scenarios,revealing significant improvements in fairness as measured by a clientdissimilarity metric.</description><author>Andrés Catalino Castillo Jiménez, Ege C. Kaya, Lintao Ye, Abolfazl Hashemi</author><pubDate>Tue, 27 Aug 2024 19:27:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13683v2</guid></item><item><title>Splatt3R: Zero-shot Gaussian Splatting from Uncalibrated Image Pairs</title><link>http://arxiv.org/abs/2408.13912v2</link><description>In this paper, we introduce Splatt3R, a pose-free, feed-forward method forin-the-wild 3D reconstruction and novel view synthesis from stereo pairs. Givenuncalibrated natural images, Splatt3R can predict 3D Gaussian Splats withoutrequiring any camera parameters or depth information. For generalizability, webuild Splatt3R upon a ``foundation'' 3D geometry reconstruction method, MASt3R,by extending it to deal with both 3D structure and appearance. Specifically,unlike the original MASt3R which reconstructs only 3D point clouds, we predictthe additional Gaussian attributes required to construct a Gaussian primitivefor each point. Hence, unlike other novel view synthesis methods, Splatt3R isfirst trained by optimizing the 3D point cloud's geometry loss, and then anovel view synthesis objective. By doing this, we avoid the local minimapresent in training 3D Gaussian Splats from stereo views. We also propose anovel loss masking strategy that we empirically find is critical for strongperformance on extrapolated viewpoints. We train Splatt3R on the ScanNet++dataset and demonstrate excellent generalisation to uncalibrated, in-the-wildimages. Splatt3R can reconstruct scenes at 4FPS at 512 x 512 resolution, andthe resultant splats can be rendered in real-time.</description><author>Brandon Smart, Chuanxia Zheng, Iro Laina, Victor Adrian Prisacariu</author><pubDate>Tue, 27 Aug 2024 19:06:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13912v2</guid></item><item><title>Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty</title><link>http://arxiv.org/abs/2408.15242v1</link><description>Robust and realistic rendering for large-scale road scenes is essential inautonomous driving simulation. Recently, 3D Gaussian Splatting (3D-GS) has madegroundbreaking progress in neural rendering, but the general fidelity oflarge-scale road scene renderings is often limited by the input imagery, whichusually has a narrow field of view and focuses mainly on the street-level localarea. Intuitively, the data from the drone's perspective can provide acomplementary viewpoint for the data from the ground vehicle's perspective,enhancing the completeness of scene reconstruction and rendering. However,training naively with aerial and ground images, which exhibit large viewdisparity, poses a significant convergence challenge for 3D-GS, and does notdemonstrate remarkable improvements in performance on road views. In order toenhance the novel view synthesis of road views and to effectively use theaerial information, we design an uncertainty-aware training method that allowsaerial images to assist in the synthesis of areas where ground images have poorlearning outcomes instead of weighting all pixels equally in 3D-GS traininglike prior work did. We are the first to introduce the cross-view uncertaintyto 3D-GS by matching the car-view ensemble-based rendering uncertainty toaerial images, weighting the contribution of each pixel to the trainingprocess. Additionally, to systematically quantify evaluation metrics, weassemble a high-quality synthesized dataset comprising both aerial and groundimages for road scenes.</description><author>Saining Zhang, Baijun Ye, Xiaoxue Chen, Yuantao Chen, Zongzheng Zhang, Cheng Peng, Yongliang Shi, Hao Zhao</author><pubDate>Tue, 27 Aug 2024 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15242v1</guid></item><item><title>GenRec: Unifying Video Generation and Recognition with Diffusion Models</title><link>http://arxiv.org/abs/2408.15241v1</link><description>Video diffusion models are able to generate high-quality videos by learningstrong spatial-temporal priors on large-scale datasets. In this paper, we aimto investigate whether such priors derived from a generative process aresuitable for video recognition, and eventually joint optimization of generationand recognition. Building upon Stable Video Diffusion, we introduce GenRec, thefirst unified framework trained with a random-frame conditioning process so asto learn generalized spatial-temporal representations. The resulting frameworkcan naturally supports generation and recognition, and more importantly isrobust even when visual inputs contain limited information. Extensiveexperiments demonstrate the efficacy of GenRec for both recognition andgeneration. In particular, GenRec achieves competitive recognition performance,offering 75.8% and 87.2% accuracy on SSV2 and K400, respectively. GenRec alsoperforms the best class-conditioned image-to-video generation results,achieving 46.5 and 49.3 FVD scores on SSV2 and EK-100 datasets. Furthermore,GenRec demonstrates extraordinary robustness in scenarios that only limitedframes can be observed.</description><author>Zejia Weng, Xitong Yang, Zhen Xing, Zuxuan Wu, Yu-Gang Jiang</author><pubDate>Tue, 27 Aug 2024 17:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15241v1</guid></item><item><title>Generative Verifiers: Reward Modeling as Next-Token Prediction</title><link>http://arxiv.org/abs/2408.15240v1</link><description>Verifiers or reward models are often used to enhance the reasoningperformance of large language models (LLMs). A common approach is the Best-of-Nmethod, where N candidate solutions generated by the LLM are ranked by averifier, and the best one is selected. While LLM-based verifiers are typicallytrained as discriminative classifiers to score solutions, they do not utilizethe text generation capabilities of pretrained LLMs. To overcome thislimitation, we instead propose training verifiers using the ubiquitousnext-token prediction objective, jointly on verification and solutiongeneration. Compared to standard verifiers, such generative verifiers (GenRM)can benefit from several advantages of LLMs: they integrate seamlessly withinstruction tuning, enable chain-of-thought reasoning, and can utilizeadditional inference-time compute via majority voting for better verification.We demonstrate that when using Gemma-based verifiers on algorithmic andgrade-school math reasoning tasks, GenRM outperforms discriminative verifiersand LLM-as-a-Judge, showing a 16-64% improvement in the percentage of problemssolved with Best-of-N. Furthermore, we show that GenRM scales favorably acrossdataset size, model capacity, and inference-time compute.</description><author>Lunjun Zhang, Arian Hosseini, Hritik Bansal, Mehran Kazemi, Aviral Kumar, Rishabh Agarwal</author><pubDate>Tue, 27 Aug 2024 17:57:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15240v1</guid></item><item><title>Generative Inbetweening: Adapting Image-to-Video Models for Keyframe Interpolation</title><link>http://arxiv.org/abs/2408.15239v1</link><description>We present a method for generating video sequences with coherent motionbetween a pair of input key frames. We adapt a pretrained large-scaleimage-to-video diffusion model (originally trained to generate videos movingforward in time from a single input image) for key frame interpolation, i.e.,to produce a video in between two input frames. We accomplish this adaptationthrough a lightweight fine-tuning technique that produces a version of themodel that instead predicts videos moving backwards in time from a single inputimage. This model (along with the original forward-moving model) issubsequently used in a dual-directional diffusion sampling process thatcombines the overlapping model estimates starting from each of the twokeyframes. Our experiments show that our method outperforms both existingdiffusion-based methods and traditional frame interpolation techniques.</description><author>Xiaojuan Wang, Boyang Zhou, Brian Curless, Ira Kemelmacher-Shlizerman, Aleksander Holynski, Steven M. Seitz</author><pubDate>Tue, 27 Aug 2024 17:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15239v1</guid></item><item><title>SelectLLM: Can LLMs Select Important Instructions to Annotate?</title><link>http://arxiv.org/abs/2401.16553v7</link><description>Instruction tuning benefits from large and diverse datasets; however,creating such datasets involves a high cost of human labeling. While syntheticdatasets generated by large language models (LLMs) have partly solved thisissue, they often contain low-quality data. One effective solution isselectively annotating unlabelled instructions, especially given the relativeease of acquiring unlabeled instructions or texts from various sources.However, how to select unlabelled instructions is not well-explored, especiallyin the context of LLMs. Therefore, we introduce SelectLLM, an alternativeframework that leverages the capabilities of LLMs to select unlabeledinstructions more effectively. Specifically, SelectLLM consists of two keysteps: Coreset-based clustering of unlabelled instructions for enlargingdiversity and prompting of LLM to identify the most beneficial instructionswithin each cluster. We evaluate SelectLLM on AlpacaEval2 and MT-Bench,demonstrating its ability to outperform state-of-the-art methods likeAlpagasus. In addition, we compare the performance and compatibility ofSelectLLM with various LLMs, such as ChatGPT, LLaMA-3.1-70B, and Gemma-2-27b.SelectLLM's adaptability and robustness are further evidenced by its ability tomaintain high performance across both human and synthetic datasets. All codeand data are publicly available (https://github.com/minnesotanlp/select-llm).</description><author>Ritik Sachin Parkar, Jaehyung Kim, Jong Inn Park, Dongyeop Kang</author><pubDate>Tue, 27 Aug 2024 17:57:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16553v7</guid></item><item><title>The Mamba in the Llama: Distilling and Accelerating Hybrid Models</title><link>http://arxiv.org/abs/2408.15237v1</link><description>Linear RNN architectures, like Mamba, can be competitive with Transformermodels in language modeling while having advantageous deploymentcharacteristics. Given the focus on training large-scale Transformer models, weconsider the challenge of converting these pretrained models for deployment. Wedemonstrate that it is feasible to distill large Transformers into linear RNNsby reusing the linear projection weights from attention layers with academicGPU resources. The resulting hybrid model, which incorporates a quarter of theattention layers, achieves performance comparable to the original Transformerin chat benchmarks and outperforms open-source hybrid Mamba models trained fromscratch with trillions of tokens in both chat benchmarks and generalbenchmarks. Moreover, we introduce a hardware-aware speculative decodingalgorithm that accelerates the inference speed of Mamba and hybrid models.Overall we show how, with limited computation resources, we can remove many ofthe original attention layers and generate from the resulting model moreefficiently. Our top-performing model, distilled from Llama3-8B-Instruct,achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and7.35 on MT-Bench, surpassing the best instruction-tuned linear RNN model.</description><author>Junxiong Wang, Daniele Paliotta, Avner May, Alexander M. Rush, Tri Dao</author><pubDate>Tue, 27 Aug 2024 17:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15237v1</guid></item><item><title>Learning-based Multi-View Stereo: A Survey</title><link>http://arxiv.org/abs/2408.15235v1</link><description>3D reconstruction aims to recover the dense 3D structure of a scene. It playsan essential role in various applications such as Augmented/Virtual Reality(AR/VR), autonomous driving and robotics. Leveraging multiple views of a scenecaptured from different viewpoints, Multi-View Stereo (MVS) algorithmssynthesize a comprehensive 3D representation, enabling precise reconstructionin complex environments. Due to its efficiency and effectiveness, MVS hasbecome a pivotal method for image-based 3D reconstruction. Recently, with thesuccess of deep learning, many learning-based MVS methods have been proposed,achieving impressive performance against traditional methods. We categorizethese learning-based methods as: depth map-based, voxel-based, NeRF-based, 3DGaussian Splatting-based, and large feed-forward methods. Among these, we focussignificantly on depth map-based methods, which are the main family of MVS dueto their conciseness, flexibility and scalability. In this survey, we provide acomprehensive review of the literature at the time of this writing. Weinvestigate these learning-based methods, summarize their performances onpopular benchmarks, and discuss promising future research directions in thisarea.</description><author>Fangjinhua Wang, Qingtian Zhu, Di Chang, Quankai Gao, Junlin Han, Tong Zhang, Richard Hartley, Marc Pollefeys</author><pubDate>Tue, 27 Aug 2024 17:53:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15235v1</guid></item><item><title>Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations</title><link>http://arxiv.org/abs/2408.15232v1</link><description>While language model (LM)-powered chatbots and generative search enginesexcel at answering concrete queries, discovering information in the terrain ofunknown unknowns remains challenging for users. To emulate the commoneducational scenario where children/students learn by listening to andparticipating in conversations of their parents/teachers, we createCollaborative STORM (Co-STORM). Unlike QA systems that require users to ask allthe questions, Co-STORM lets users observe and occasionally steer the discourseamong several LM agents. The agents ask questions on the user's behalf,allowing the user to discover unknown unknowns serendipitously. To facilitateuser interaction, Co-STORM assists users in tracking the discourse byorganizing the uncovered information into a dynamic mind map, ultimatelygenerating a comprehensive report as takeaways. For automatic evaluation, weconstruct the WildSeek dataset by collecting real information-seeking recordswith user goals. Co-STORM outperforms baseline methods on both discourse traceand report quality. In a further human evaluation, 70% of participants preferCo-STORM over a search engine, and 78% favor it over a RAG chatbot.</description><author>Yucheng Jiang, Yijia Shao, Dekun Ma, Sina J. Semnani, Monica S. Lam</author><pubDate>Tue, 27 Aug 2024 17:50:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15232v1</guid></item><item><title>DCT-CryptoNets: Scaling Private Inference in the Frequency Domain</title><link>http://arxiv.org/abs/2408.15231v1</link><description>The convergence of fully homomorphic encryption (FHE) and machine learningoffers unprecedented opportunities for private inference of sensitive data. FHEenables computation directly on encrypted data, safeguarding the entire machinelearning pipeline, including data and model confidentiality. However, existingFHE-based implementations for deep neural networks face significant challengesin computational cost, latency, and scalability, limiting their practicaldeployment. This paper introduces DCT-CryptoNets, a novel approach thatleverages frequency-domain learning to tackle these issues. Our method operatesdirectly in the frequency domain, utilizing the discrete cosine transform (DCT)commonly employed in JPEG compression. This approach is inherently compatiblewith remote computing services, where images are usually transmitted and storedin compressed formats. DCT-CryptoNets reduces the computational burden ofhomomorphic operations by focusing on perceptually relevant low-frequencycomponents. This is demonstrated by substantial latency reduction of up to5.3$\times$ compared to prior work on image classification tasks, including anovel demonstration of ImageNet inference within 2.5 hours, down from 12.5hours compared to prior work on equivalent compute resources. Moreover,DCT-CryptoNets improves the reliability of encrypted accuracy by reducingvariability (e.g., from $\pm$2.5\% to $\pm$1.0\% on ImageNet). This studydemonstrates a promising avenue for achieving efficient and practicalprivacy-preserving deep learning on high resolution images seen in real-worldapplications.</description><author>Arjun Roy, Kaushik Roy</author><pubDate>Tue, 27 Aug 2024 17:48:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15231v1</guid></item><item><title>DIVERSE: A Dataset of YouTube Video Comment Stances with a Data Programming Model</title><link>http://arxiv.org/abs/2403.03334v2</link><description>Stance detection of social media text is a key component of many real-worldapplications like evaluating marketing campaigns, evaluating political policiesor candidates, or evaluating information environments. However, creatingautomatic stance labeling systems requires the manual annotation of stances,which is both tedious and resource-intensive. This paper introduces a stancelabeling method that makes use of weak signals of sentence tone, thenconsolidating these signals with a Data Programmingmodel for the final stancelabel. In a time of international conflict, understanding the public opiniontowards the country's military is crucial for recruitment. We present DIVERSE,a dataset involve stances towards YouTube videos of the US military (Datasetavailable at https://doi.org/10.5281/zenodo.10493803). On average, the videoshave 200 comments each, and the stances skew slightly towards the "against"characterization for both the US army and the video.</description><author>Iain J. Cruickshank, Amir Soofi, Lynnette Hui Xian Ng</author><pubDate>Tue, 27 Aug 2024 17:46:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03334v2</guid></item><item><title>SAM &amp; SAM 2 in 3D Slicer: SegmentWithSAM Extension for Annotating Medical Images</title><link>http://arxiv.org/abs/2408.15224v1</link><description>Creating annotations for 3D medical data is time-consuming and often requireshighly specialized expertise. Various tools have been implemented to aid thisprocess. Segment Anything Model 2 (SAM 2) offers a general-purpose prompt-basedsegmentation algorithm designed to annotate videos. In this paper, we adaptthis model to the annotation of 3D medical images and offer our implementationin the form of an extension to the popular annotation software: 3D Slicer. Ourextension allows users to place point prompts on 2D slices to generateannotation masks and propagate these annotations across entire volumes ineither single-directional or bi-directional manners. Our code is publiclyavailable on https://github.com/mazurowski-lab/SlicerSegmentWithSAM and can beeasily installed directly from the Extension Manager of 3D Slicer as well.</description><author>Zafer Yildiz, Yuwen Chen, Maciej A. Mazurowski</author><pubDate>Tue, 27 Aug 2024 17:39:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15224v1</guid></item><item><title>LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet</title><link>http://arxiv.org/abs/2408.15221v1</link><description>Recent large language model (LLM) defenses have greatly improved models'ability to refuse harmful queries, even when adversarially attacked. However,LLM defenses are primarily evaluated against automated adversarial attacks in asingle turn of conversation, an insufficient threat model for real-worldmalicious use. We demonstrate that multi-turn human jailbreaks uncoversignificant vulnerabilities, exceeding 70% attack success rate (ASR) onHarmBench against defenses that report single-digit ASRs with automatedsingle-turn attacks. Human jailbreaks also reveal vulnerabilities in machineunlearning defenses, successfully recovering dual-use biosecurity knowledgefrom unlearned models. We compile these results into Multi-Turn HumanJailbreaks (MHJ), a dataset of 2,912 prompts across 537 multi-turn jailbreaks.We publicly release MHJ alongside a compendium of jailbreak tactics developedacross dozens of commercial red teaming engagements, supporting researchtowards stronger LLM defenses.</description><author>Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, Summer Yue</author><pubDate>Tue, 27 Aug 2024 17:33:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15221v1</guid></item><item><title>MPC-Pipe: an Efficient Pipeline Scheme for Secure Multi-party Machine Learning Inference</title><link>http://arxiv.org/abs/2209.13643v2</link><description>Multi-party computing (MPC) has been gaining popularity as a secure computingmodel over the past few years. However, prior works have demonstrated that MPCprotocols still pay substantial performance penalties compared to plaintext,particularly when applied to ML algorithms. The overhead is due to addedcomputation and communication costs. Prior studies, as well as our ownanalysis, found that most MPC protocols today sequentially performcommunication and computation. The participating parties must compute on theirshares first and then perform data communication to allow the distribution ofnew secret shares before proceeding to the next computation step. In this work,we show that serialization is unnecessary, particularly in the context of MLcomputations (both in Convolutional neural networks and in Transformer-basedmodels). We demonstrate that it is possible to carefully orchestrate thecomputation and communication steps to overlap. We propose MPC-Pipe, an efficient MPC system for both training and inferenceof ML workloads, which pipelines computations and communications in an MPCprotocol during the online phase. MPC-Pipe proposes three pipeline schemes tooptimize the online phase of ML in the semi-honest majority adversary setting.We implement MPC-Pipe by augmenting a modified version of CrypTen, whichseparates online and offline phases. We evaluate the end-to-end systemperformance benefits of the online phase of MPC using deep neural networks(VGG16, ResNet50) and Transformers using different network settings. We showthat MPC-Pipe can improve the throughput and latency of ML workloads.</description><author>Yongqin Wang, Rachit Rajat, Murali Annavaram</author><pubDate>Tue, 27 Aug 2024 17:32:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.13643v2</guid></item><item><title>Histo-Diffusion: A Diffusion Super-Resolution Method for Digital Pathology with Comprehensive Quality Assessment</title><link>http://arxiv.org/abs/2408.15218v1</link><description>Digital pathology has advanced significantly over the last decade, with WholeSlide Images (WSIs) encompassing vast amounts of data essential for accuratedisease diagnosis. High-resolution WSIs are essential for precise diagnosis buttechnical limitations in scanning equipment and variablity in slide preparationcan hinder obtaining these images. Super-resolution techniques can enhancelow-resolution images; while Generative Adversarial Networks (GANs) have beeneffective in natural image super-resolution tasks, they often struggle withhistopathology due to overfitting and mode collapse. Traditional evaluationmetrics fall short in assessing the complex characteristics of histopathologyimages, necessitating robust histology-specific evaluation methods. We introduce Histo-Diffusion, a novel diffusion-based method speciallydesigned for generating and evaluating super-resolution images in digitalpathology. It includes a restoration module for histopathology prior and acontrollable diffusion module for generating high-quality images. We havecurated two histopathology datasets and proposed a comprehensive evaluationstrategy which incorporates both full-reference and no-reference metrics tothoroughly assess the quality of digital pathology images. Comparative analyses on multiple datasets with state-of-the-art methodsreveal that Histo-Diffusion outperforms GANs. Our method offers a versatilesolution for histopathology image super-resolution, capable of handlingmulti-resolution generation from varied input sizes, providing valuable supportin diagnostic processes.</description><author>Xuan Xu, Saarthak Kapse, Prateek Prasanna</author><pubDate>Tue, 27 Aug 2024 17:31:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15218v1</guid></item><item><title>Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography with Clinical Knowledge Guidance</title><link>http://arxiv.org/abs/2408.15217v1</link><description>Fundus Fluorescein Angiography (FFA) is a critical tool for assessing retinalvascular dynamics and aiding in the diagnosis of eye diseases. However, itsinvasive nature and less accessibility compared to Color Fundus (CF) imagespose significant challenges. Current CF to FFA translation methods are limitedto static generation. In this work, we pioneer dynamic FFA video generationfrom static CF images. We introduce an autoregressive GAN for smooth,memory-saving frame-by-frame FFA synthesis. To enhance the focus on dynamiclesion changes in FFA regions, we design a knowledge mask based on clinicalexperience. Leveraging this mask, our approach integrates innovative knowledgemask-guided techniques, including knowledge-boosted attention, knowledge-awarediscriminators, and mask-enhanced patchNCE loss, aimed at refining generationin critical areas and addressing the pixel misalignment challenge. Our methodachieves the best FVD of 1503.21 and PSNR of 11.81 compared to other commonvideo generation approaches. Human assessment by an ophthalmologist confirmsits high generation quality. Notably, our knowledge mask surpasses supervisedlesion segmentation masks, offering a promising non-invasive alternative totraditional FFA for research and clinical applications. The code is availableat https://github.com/Michi-3000/Fundus2Video.</description><author>Weiyi Zhang, Siyu Huang, Jiancheng Yang, Ruoyu Chen, Zongyuan Ge, Yingfeng Zheng, Danli Shi, Mingguang He</author><pubDate>Tue, 27 Aug 2024 17:30:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15217v1</guid></item><item><title>Assessing Lower Limb Strength using Internet-of-Things Enabled Chair</title><link>http://arxiv.org/abs/2209.04042v3</link><description>This project describes the application of the technologies of MachineLearning and Internet-of-Things to assess the lower limb strength ofindividuals undergoing rehabilitation or therapy. Specifically, it seeks tomeasure and assess the progress of individuals by sensors attached to chairsand processing the data through Google GPU Tensorflow CoLab. Pressure sensorsare attached to various locations on a chair, including but not limited to theseating area, backrest, hand rests, and legs. Sensor data from the individualperforming both sit-to-stand transition and stand-to-sit transition provides atime series dataset regarding the pressure distribution and vibratory motion onthe chair. The dataset and timing information can then be fed into a machinelearning model to estimate the relative strength and weakness during variousphases of the movement.</description><author>Chelsea Yeh, Hanna Kaitlin Dy, Phillip Schodinger, Hudson Kaleb Dy</author><pubDate>Tue, 27 Aug 2024 17:24:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.04042v3</guid></item><item><title>Classifying populist language in American presidential and governor speeches using automatic text analysis</title><link>http://arxiv.org/abs/2408.15213v1</link><description>Populism is a concept that is often used but notoriously difficult tomeasure. Common qualitative measurements like holistic grading or contentanalysis require great amounts of time and labour, making it difficult toquickly scope out which politicians should be classified as populist and whichshould not, while quantitative methods show mixed results when it comes toclassifying populist rhetoric. In this paper, we develop a pipeline to trainand validate an automated classification model to estimate the use of populistlanguage. We train models based on sentences that were identified as populistand pluralist in 300 US governors' speeches from 2010 to 2018 and in 45speeches of presidential candidates in 2016. We find that these models classifymost speeches correctly, including 84% of governor speeches and 89% ofpresidential speeches. These results extend to different time periods (with 92%accuracy on more recent American governors), different amounts of data (with asfew as 70 training sentences per category achieving similar results), and whenclassifying politicians instead of individual speeches. This pipeline is thusan effective tool that can optimise the systematic and swift classification ofthe use of populist language in politicians' speeches.</description><author>Olaf van der Veen, Semir Dzebo, Levi Littvay, Kirk Hawkins, Oren Dar</author><pubDate>Tue, 27 Aug 2024 17:19:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15213v1</guid></item><item><title>On Newton's Method to Unlearn Neural Networks</title><link>http://arxiv.org/abs/2406.14507v2</link><description>With the widespread applications of neural networks (NNs) trained on personaldata, machine unlearning has become increasingly important for enablingindividuals to exercise their personal data ownership, particularly the "rightto be forgotten" from trained NNs. Since retraining is computationallyexpensive, we seek approximate unlearning algorithms for NNs that returnidentical models to the retrained oracle. While Newton's method has beensuccessfully used to approximately unlearn linear models, we observe thatadapting it for NN is challenging due to degenerate Hessians that makecomputing Newton's update impossible. Additionally, we show that when coupledwith popular techniques to resolve the degeneracy, Newton's method often incursoffensively large norm updates and empirically degrades model performancepost-unlearning. To address these challenges, we propose CureNewton's method, aprinciple approach that leverages cubic regularization to handle the Hessiandegeneracy effectively. The added regularizer eliminates the need for manualfinetuning and affords a natural interpretation within the unlearning context.Experiments across different models and datasets show that our method canachieve competitive unlearning performance to the state-of-the-art algorithm inpractical unlearning settings, while being theoretically justified andefficient in running time.</description><author>Nhung Bui, Xinyang Lu, Rachael Hwee Ling Sim, See-Kiong Ng, Bryan Kian Hsiang Low</author><pubDate>Tue, 27 Aug 2024 17:19:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14507v2</guid></item><item><title>TAPVid-3D: A Benchmark for Tracking Any Point in 3D</title><link>http://arxiv.org/abs/2407.05921v2</link><description>We introduce a new benchmark, TAPVid-3D, for evaluating the task oflong-range Tracking Any Point in 3D (TAP-3D). While point tracking in twodimensions (TAP) has many benchmarks measuring performance on real-worldvideos, such as TAPVid-DAVIS, three-dimensional point tracking has none. Tothis end, leveraging existing footage, we build a new benchmark for 3D pointtracking featuring 4,000+ real-world videos, composed of three different datasources spanning a variety of object types, motion patterns, and indoor andoutdoor environments. To measure performance on the TAP-3D task, we formulate acollection of metrics that extend the Jaccard-based metric used in TAP tohandle the complexities of ambiguous depth scales across models, occlusions,and multi-track spatio-temporal smoothness. We manually verify a large sampleof trajectories to ensure correct video annotations, and assess the currentstate of the TAP-3D task by constructing competitive baselines using existingtracking models. We anticipate this benchmark will serve as a guidepost toimprove our ability to understand precise 3D motion and surface deformationfrom monocular video. Code for dataset download, generation, and modelevaluation is available at https://tapvid3d.github.io</description><author>Skanda Koppula, Ignacio Rocco, Yi Yang, Joe Heyward, João Carreira, Andrew Zisserman, Gabriel Brostow, Carl Doersch</author><pubDate>Tue, 27 Aug 2024 17:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05921v2</guid></item><item><title>Leveraging Hallucinations to Reduce Manual Prompt Dependency in Promptable Segmentation</title><link>http://arxiv.org/abs/2408.15205v1</link><description>Promptable segmentation typically requires instance-specific manual promptsto guide the segmentation of each desired object. To minimize such a need,task-generic promptable segmentation has been introduced, which employs asingle task-generic prompt to segment various images of different objects inthe same task. Current methods use Multimodal Large Language Models (MLLMs) toreason detailed instance-specific prompts from a task-generic prompt forimproving segmentation accuracy. The effectiveness of this segmentation heavilydepends on the precision of these derived prompts. However, MLLMs often sufferhallucinations during reasoning, resulting in inaccurate prompting. Whileexisting methods focus on eliminating hallucinations to improve a model, weargue that MLLM hallucinations can reveal valuable contextual insights whenleveraged correctly, as they represent pre-trained large-scale knowledge beyondindividual images. In this paper, we utilize hallucinations to minetask-related information from images and verify its accuracy for enhancingprecision of the generated prompts. Specifically, we introduce an iterativePrompt-Mask Cycle generation framework (ProMaC) with a prompt generator and amask generator.The prompt generator uses a multi-scale chain of thoughtprompting, initially exploring hallucinations for extracting extendedcontextual knowledge on a test image.These hallucinations are then reduced toformulate precise instance-specific prompts, directing the mask generator toproduce masks that are consistent with task semantics by mask semanticalignment. The generated masks iteratively induce the prompt generator to focusmore on task-relevant image areas and reduce irrelevant hallucinations,resulting jointly in better prompts and masks. Experiments on 5 benchmarksdemonstrate the effectiveness of ProMaC. Code given inhttps://lwpyh.github.io/ProMaC/.</description><author>Jian Hu, Jiayi Lin, Junchi Yan, Shaogang Gong</author><pubDate>Tue, 27 Aug 2024 17:06:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15205v1</guid></item><item><title>Can Unconfident LLM Annotations Be Used for Confident Conclusions?</title><link>http://arxiv.org/abs/2408.15204v1</link><description>Large language models (LLMs) have shown high agreement with human ratersacross a variety of tasks, demonstrating potential to ease the challenges ofhuman data collection. In computational social science (CSS), researchers areincreasingly leveraging LLM annotations to complement slow and expensive humanannotations. Still, guidelines for collecting and using LLM annotations,without compromising the validity of downstream conclusions, remain limited. Weintroduce Confidence-Driven Inference: a method that combines LLM annotationsand LLM confidence indicators to strategically select which human annotationsshould be collected, with the goal of producing accurate statistical estimatesand provably valid confidence intervals while reducing the number of humanannotations needed. Our approach comes with safeguards against LLM annotationsof poor quality, guaranteeing that the conclusions will be both valid and noless accurate than if we only relied on human annotations. We demonstrate theeffectiveness of Confidence-Driven Inference over baselines in statisticalestimation tasks across three CSS settings--text politeness, stance, andbias--reducing the needed number of human annotations by over 25% in each.Although we use CSS settings for demonstration, Confidence-Driven Inference canbe used to estimate most standard quantities across a broad range of NLPproblems.</description><author>Kristina Gligorić, Tijana Zrnic, Cinoo Lee, Emmanuel J. Candès, Dan Jurafsky</author><pubDate>Tue, 27 Aug 2024 17:03:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15204v1</guid></item><item><title>Revisiting LARS for Large Batch Training Generalization of Neural Networks</title><link>http://arxiv.org/abs/2309.14053v5</link><description>This paper explores Large Batch Training techniques using layer-wise adaptivescaling ratio (LARS) across diverse settings, uncovering insights. LARSalgorithms with warm-up tend to be trapped in sharp minimizers early on due toredundant ratio scaling. Additionally, a fixed steep decline in the latterphase restricts deep neural networks from effectively navigating early-phasesharp minimizers. Building on these findings, we propose Time Varying LARS(TVLARS), a novel algorithm that replaces warm-up with a configurablesigmoid-like function for robust training in the initial phase. TVLARS promotesgradient exploration early on, surpassing sharp optimizers and graduallytransitioning to LARS for robustness in later phases. Extensive experimentsdemonstrate that TVLARS consistently outperforms LARS and LAMB in most cases,with up to 2\% improvement in classification scenarios. Notably, in allself-supervised learning cases, TVLARS dominates LARS and LAMB with performanceimprovements of up to 10\%.</description><author>Khoi Do, Duong Nguyen, Hoa Nguyen, Long Tran-Thanh, Nguyen-Hoang Tran, Quoc-Viet Pham</author><pubDate>Tue, 27 Aug 2024 17:03:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14053v5</guid></item><item><title>PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods</title><link>http://arxiv.org/abs/2407.06985v3</link><description>In domain-specific applications, GPT-4, augmented with precise prompts orRetrieval-Augmented Generation (RAG), shows notable potential but faces thecritical tri-lemma of performance, cost, and data privacy. High performancerequires sophisticated processing techniques, yet managing multiple agentswithin a complex workflow often proves costly and challenging. To address this,we introduce the PEER (Plan, Execute, Express, Review) multi-agent framework.This systematizes domain-specific tasks by integrating precise questiondecomposition, advanced information retrieval, comprehensive summarization, andrigorous self-assessment. Given the concerns of cost and data privacy,enterprises are shifting from proprietary models like GPT-4 to custom models,striking a balance between cost, security, and performance. We developedindustrial practices leveraging online data and user feedback for efficientmodel tuning. This study provides best practice guidelines for applyingmulti-agent systems in domain-specific problem-solving and implementingeffective agent tuning strategies. Our empirical studies, particularly in thefinancial question-answering domain, demonstrate that our approach achieves95.0% of GPT-4's performance, while effectively managing costs and ensuringdata privacy.</description><author>Yiying Wang, Xiaojing Li, Binzhu Wang, Yueyang Zhou, Yingru Lin, Han Ji, Hong Chen, Jinshi Zhang, Fei Yu, Zewei Zhao, Song Jin, Renji Gong, Wanqing Xu</author><pubDate>Tue, 27 Aug 2024 17:02:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06985v3</guid></item><item><title>An Investigation on The Position Encoding in Vision-Based Dynamics Prediction</title><link>http://arxiv.org/abs/2408.15201v1</link><description>Despite the success of vision-based dynamics prediction models, which predictobject states by utilizing RGB images and simple object descriptions, they werechallenged by environment misalignments. Although the literature hasdemonstrated that unifying visual domains with both environment context andobject abstract, such as semantic segmentation and bounding boxes, caneffectively mitigate the visual domain misalignment challenge, discussions werefocused on the abstract of environment context, and the insight of usingbounding box as the object abstract is under-explored. Furthermore, we noticethat, as empirical results shown in the literature, even when the visualappearance of objects is removed, object bounding boxes alone, instead of beingdirectly fed into the network, can indirectly provide sufficient positioninformation via the Region of Interest Pooling operation for dynamicsprediction. However, previous literature overlooked discussions regarding howsuch position information is implicitly encoded in the dynamics predictionmodel. Thus, in this paper, we provide detailed studies to investigate theprocess and necessary conditions for encoding position information via usingthe bounding box as the object abstract into output features. Furthermore, westudy the limitation of solely using object abstracts, such that the dynamicsprediction performance will be jeopardized when the environment context varies.</description><author>Jiageng Zhu, Hanchen Xie, Jiazhi Li, Mahyar Khayatkhoei, Wael AbdAlmageed</author><pubDate>Tue, 27 Aug 2024 17:02:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15201v1</guid></item><item><title>Automatic 8-tissue Segmentation for 6-month Infant Brains</title><link>http://arxiv.org/abs/2408.15198v1</link><description>Numerous studies have highlighted that atypical brain development,particularly during infancy and toddlerhood, is linked to an increasedlikelihood of being diagnosed with a neurodevelopmental condition, such asautism. Accurate brain tissue segmentations for morphological analysis areessential in numerous infant studies. However, due to ongoing white matter (WM)myelination changing tissue contrast in T1- and T2-weighted images, automatictissue segmentation in 6-month infants is particularly difficult. On the otherhand, manual labelling by experts is time-consuming and labor-intensive. Inthis study, we propose the first 8-tissue segmentation pipeline forsix-month-old infant brains. This pipeline utilizes domain adaptation (DA)techniques to leverage our longitudinal data, including neonatal imagessegmented with the neonatal Developing Human Connectome Project structuralpipeline. Our pipeline takes raw 6-month images as inputs and generates the8-tissue segmentation as outputs, forming an end-to-end segmentation pipeline.The segmented tissues include WM, gray matter (GM), cerebrospinal fluid (CSF),ventricles, cerebellum, basal ganglia, brainstem, and hippocampus/amygdala.Cycle-Consistent Generative Adversarial Network (CycleGAN) and Attention U-Netwere employed to achieve the image contrast transformation between neonatal and6-month images and perform tissue segmentation on the synthesized 6-monthimages (neonatal images with 6-month intensity contrast), respectively.Moreover, we incorporated the segmentation outputs from Infant Brain Extractionand Analysis Toolbox (iBEAT) and another Attention U-Net to further enhance theperformance and construct the end-to-end segmentation pipeline. Our evaluationwith real 6-month images achieved a DICE score of 0.92, an HD95 of 1.6, and anASSD of 0.42.</description><author>Yilan Dong, Vanessa Kyriakopoulou, Irina Grigorescu, Grainne McAlonan, Dafnis Batalle, Maria Deprez</author><pubDate>Tue, 27 Aug 2024 16:58:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15198v1</guid></item><item><title>KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving</title><link>http://arxiv.org/abs/2408.02088v3</link><description>Accurate 3D object detection in autonomous driving is critical yetchallenging due to occlusions, varying object sizes, and complex urbanenvironments. This paper introduces the KAN-RCBEVDepth method, an innovativeapproach aimed at enhancing 3D object detection by fusing multimodal sensordata from cameras, LiDAR, and millimeter-wave radar. Our unique Bird's EyeView-based approach significantly improves detection accuracy and efficiency byseamlessly integrating diverse sensor inputs, refining spatial relationshipunderstanding, and optimizing computational procedures. Experimental resultsshow that the proposed method outperforms existing techniques across multipledetection metrics, achieving a higher Mean Distance AP (0.389, 23\%improvement), a better ND Score (0.485, 17.1\% improvement), and a fasterEvaluation Time (71.28s, 8\% faster). Additionally, the KAN-RCBEVDepth methodsignificantly reduces errors compared to BEVDepth, with lower TransformationError (0.6044, 13.8\% improvement), Scale Error (0.2780, 2.6\% improvement),Orientation Error (0.5830, 7.6\% improvement), Velocity Error (0.4244, 28.3\%improvement), and Attribute Error (0.2129, 3.2\% improvement). These findingssuggest that our method offers enhanced accuracy, reliability, and efficiency,making it well-suited for dynamic and demanding autonomous driving scenarios.The code will be released in \url{https://github.com/laitiamo/RCBEVDepth-KAN}.</description><author>Zhihao Lai, Chuanhao Liu, Shihui Sheng, Zhiqiang Zhang</author><pubDate>Tue, 27 Aug 2024 16:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02088v3</guid></item><item><title>Infusing Acoustic Pause Context into Text-Based Dementia Assessment</title><link>http://arxiv.org/abs/2408.15188v1</link><description>Speech pauses, alongside content and structure, offer a valuable andnon-invasive biomarker for detecting dementia. This work investigates the useof pause-enriched transcripts in transformer-based language models todifferentiate the cognitive states of subjects with no cognitive impairment,mild cognitive impairment, and Alzheimer's dementia based on their speech froma clinical assessment. We address three binary classification tasks: Onset,monitoring, and dementia exclusion. The performance is evaluated throughexperiments on a German Verbal Fluency Test and a Picture Description Test,comparing the model's effectiveness across different speech productioncontexts. Starting from a textual baseline, we investigate the effect ofincorporation of pause information and acoustic context. We show the testshould be chosen depending on the task, and similarly, lexical pauseinformation and acoustic cross-attention contribute differently.</description><author>Franziska Braun, Sebastian P. Bayerl, Florian Hönig, Hartmut Lehfeld, Thomas Hillemacher, Tobias Bocklet, Korbinian Riedhammer</author><pubDate>Tue, 27 Aug 2024 16:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15188v1</guid></item><item><title>A domain decomposition-based autoregressive deep learning model for unsteady and nonlinear partial differential equations</title><link>http://arxiv.org/abs/2408.14461v2</link><description>In this paper, we propose a domain-decomposition-based deep learning (DL)framework, named transient-CoMLSim, for accurately modeling unsteady andnonlinear partial differential equations (PDEs). The framework consists of twokey components: (a) a convolutional neural network (CNN)-based autoencoderarchitecture and (b) an autoregressive model composed of fully connectedlayers. Unlike existing state-of-the-art methods that operate on the entirecomputational domain, our CNN-based autoencoder computes a lower-dimensionalbasis for solution and condition fields represented on subdomains. Timesteppingis performed entirely in the latent space, generating embeddings of thesolution variables from the time history of embeddings of solution andcondition variables. This approach not only reduces computational complexitybut also enhances scalability, making it well-suited for large-scalesimulations. Furthermore, to improve the stability of our rollouts, we employ acurriculum learning (CL) approach during the training of the autoregressivemodel. The domain-decomposition strategy enables scaling to out-of-distributiondomain sizes while maintaining the accuracy of predictions -- a feature noteasily integrated into popular DL-based approaches for physics simulations. Webenchmark our model against two widely-used DL architectures, Fourier NeuralOperator (FNO) and U-Net, and demonstrate that our framework outperforms themin terms of accuracy, extrapolation to unseen timesteps, and stability for awide range of use cases.</description><author>Sheel Nidhan, Haoliang Jiang, Lalit Ghule, Clancy Umphrey, Rishikesh Ranade, Jay Pathak</author><pubDate>Tue, 27 Aug 2024 16:43:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14461v2</guid></item><item><title>Creating Image Datasets in Agricultural Environments using DALL.E: Generative AI-Powered Large Language Model</title><link>http://arxiv.org/abs/2307.08789v4</link><description>This research investigated the role of artificial intelligence (AI),specifically the DALL.E model by OpenAI, in advancing data generation andvisualization techniques in agriculture. DALL.E, an advanced AI imagegenerator, works alongside ChatGPT's language processing to transform textdescriptions and image clues into realistic visual representations of thecontent. The study used both approaches of image generation: text-to-image andimage-to image (variation). Six types of datasets depicting fruit cropenvironment were generated. These AI-generated images were then comparedagainst ground truth images captured by sensors in real agricultural fields.The comparison was based on Peak Signal-to-Noise Ratio (PSNR) and FeatureSimilarity Index (FSIM) metrics. The image-to-image generation exhibited a5.78% increase in average PSNR over text-to-image methods, signifying superiorimage clarity and quality. However, this method also resulted in a 10.23%decrease in average FSIM, indicating a diminished structural and texturalsimilarity to the original images. Similar to these measures, human evaluationalso showed that images generated using image-to-image-based method were morerealistic compared to those generated with text-to-image approach. The resultshighlighted DALL.E's potential in generating realistic agricultural imagedatasets and thus accelerating the development and adoption of imaging-basedprecision agricultural solutions.</description><author>Ranjan Sapkota, Manoj Karkee</author><pubDate>Tue, 27 Aug 2024 16:43:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08789v4</guid></item><item><title>Frustrated Random Walks: A Fast Method to Compute Node Distances on Hypergraphs</title><link>http://arxiv.org/abs/2401.13054v3</link><description>A hypergraph is a generalization of a graph that arises naturally whenattribute-sharing among entities is considered. Compared to graphs, hypergraphshave the distinct advantage that they contain explicit communities and are moreconvenient to manipulate. An open problem in hypergraph research is how toaccurately and efficiently calculate node distances on hypergraphs. Estimatingnode distances enables us to find a node's nearest neighbors, which hasimportant applications in such areas as recommender system, targetedadvertising, etc. In this paper, we propose using expected hitting times ofrandom walks to compute hypergraph node distances. We note that simple randomwalks (SRW) cannot accurately compute node distances on highly complexreal-world hypergraphs, which motivates us to introduce frustrated random walks(FRW) for this task. We further benchmark our method against DeepWalk, and showthat while the latter can achieve comparable results, FRW has a distinctcomputational advantage in cases where the number of targets is fairly small.For such cases, we show that FRW runs in significantly shorter time thanDeepWalk. Finally, we analyze the time complexity of our method, and show thatfor large and sparse hypergraphs, the complexity is approximately linear,rendering it superior to the DeepWalk alternative.</description><author>Enzhi Li, Scott Nickleach, Bilal Fadlallah</author><pubDate>Tue, 27 Aug 2024 16:42:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13054v3</guid></item><item><title>PoseWatch: A Transformer-based Architecture for Human-centric Video Anomaly Detection Using Spatio-temporal Pose Tokenization</title><link>http://arxiv.org/abs/2408.15185v1</link><description>Video Anomaly Detection (VAD) presents a significant challenge in computervision, particularly due to the unpredictable and infrequent nature ofanomalous events, coupled with the diverse and dynamic environments in whichthey occur. Human-centric VAD, a specialized area within this domain, facesadditional complexities, including variations in human behavior, potentialbiases in data, and substantial privacy concerns related to human subjects.These issues complicate the development of models that are both robust andgeneralizable. To address these challenges, recent advancements have focused onpose-based VAD, which leverages human pose as a high-level feature to mitigateprivacy concerns, reduce appearance biases, and minimize backgroundinterference. In this paper, we introduce PoseWatch, a novel transformer-basedarchitecture designed specifically for human-centric pose-based VAD. PoseWatchfeatures an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP)tokenization method that enhances the representation of human motion over time,which is also beneficial for broader human behavior analysis tasks. Thearchitecture's core, a Unified Encoder Twin Decoders (UETD) transformer,significantly improves the detection of anomalous behaviors in video data.Extensive evaluations across multiple benchmark datasets demonstrate thatPoseWatch consistently outperforms existing methods, establishing a newstate-of-the-art in pose-based VAD. This work not only demonstrates theefficacy of PoseWatch but also highlights the potential of integrating NaturalLanguage Processing techniques with computer vision to advance human behavioranalysis.</description><author>Ghazal Alinezhad Noghre, Armin Danesh Pazho, Hamed Tabkhi</author><pubDate>Tue, 27 Aug 2024 16:40:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15185v1</guid></item><item><title>On latent dynamics learning in nonlinear reduced order modeling</title><link>http://arxiv.org/abs/2408.15183v1</link><description>In this work, we present the novel mathematical framework of latent dynamicsmodels (LDMs) for reduced order modeling of parameterized nonlineartime-dependent PDEs. Our framework casts this latter task as a nonlineardimensionality reduction problem, while constraining the latent state to evolveaccordingly to an (unknown) dynamical system. A time-continuous setting isemployed to derive error and stability estimates for the LDM approximation ofthe full order model (FOM) solution. We analyze the impact of using an explicitRunge-Kutta scheme in the time-discrete setting, resulting in the$\Delta\text{LDM}$ formulation, and further explore the learnable setting,$\Delta\text{LDM}_\theta$, where deep neural networks approximate the discreteLDM components, while providing a bounded approximation error with respect tothe FOM. Moreover, we extend the concept of parameterized Neural ODE - recentlyproposed as a possible way to build data-driven dynamical systems with varyinginput parameters - to be a convolutional architecture, where the inputparameters information is injected by means of an affine modulation mechanism,while designing a convolutional autoencoder neural network able to retainspatial-coherence, thus enhancing interpretability at the latent level.Numerical experiments, including the Burgers' and theadvection-reaction-diffusion equations, demonstrate the framework's ability toobtain, in a multi-query context, a time-continuous approximation of the FOMsolution, thus being able to query the LDM approximation at any given timeinstance while retaining a prescribed level of accuracy. Our findings highlightthe remarkable potential of the proposed LDMs, representing a mathematicallyrigorous framework to enhance the accuracy and approximation capabilities ofreduced order modeling for time-dependent parameterized PDEs.</description><author>Nicola Farenga, Stefania Fresca, Simone Brivio, Andrea Manzoni</author><pubDate>Tue, 27 Aug 2024 16:35:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15183v1</guid></item><item><title>Comprehensive Performance Evaluation of YOLOv10, YOLOv9 and YOLOv8 on Detecting and Counting Fruitlet in Complex Orchard Environments</title><link>http://arxiv.org/abs/2407.12040v3</link><description>This study performed an extensive evaluation of the performances of allconfigurations of YOLOv8, YOLOv9, and YOLOv10 object detection algorithms forfruitlet (of green fruit) detection in commercial orchards. Additionally, thisresearch performed and validated in-field counting of fruitlets using an iPhoneand machine vision sensors in 5 different apple varieties (Scifresh, Scilate,Honeycrisp, Cosmic crisp &amp; Golden delicious). This comprehensive investigationof total 17 different configurations (5 for YOLOv8, 6 for YOLOv9 and 6 forYOLOv10) revealed that YOLOv9 outperforms YOLOv10 and YOLOv8 in terms ofmAP@50, while YOLOv10x outperformed all 17 configurations tested in terms ofprecision and recall. Specifically, YOLOv9 Gelan-e achieved the highest mAP@50of 0.935, outperforming YOLOv10n's 0.921 and YOLOv8s's 0.924. In terms ofprecision, YOLOv10x achieved the highest precision of 0.908, indicatingsuperior object identification accuracy compared to other configurations tested(e.g. YOLOv9 Gelan-c with a precision of 0.903 and YOLOv8m with 0.897. In termsof recall, YOLOv10s achieved the highest in its series (0.872), while YOLOv9Gelan m performed the best among YOLOv9 configurations (0.899), and YOLOv8nperformed the best among the YOLOv8 configurations (0.883). Meanwhile, threeconfigurations of YOLOv10: YOLOv10b, YOLOv10l, and YOLOv10x achieved superiorpost-processing speeds of 1.5 milliseconds, outperforming all otherconfigurations within the YOLOv9 and YOLOv8 families. Specifically, YOLOv9Gelan-e recorded a post-processing speed of 1.9 milliseconds, and YOLOv8machieved 2.1 milliseconds. Furthermore, YOLOv8n exhibited the highest inferencespeed among all configurations tested, achieving a processing time of 4.1milliseconds while YOLOv9 Gelan-t and YOLOv10n also demonstrated comparativelyslower inference speeds of 9.3 ms and 5.5 ms, respectively.</description><author>Ranjan Sapkota, Zhichao Meng, Martin Churuvija, Xiaoqiang Du, Zenghong Ma, Manoj Karkee</author><pubDate>Tue, 27 Aug 2024 16:25:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12040v3</guid></item><item><title>A Review of Transformer-Based Models for Computer Vision Tasks: Capturing Global Context and Spatial Relationships</title><link>http://arxiv.org/abs/2408.15178v1</link><description>Transformer-based models have transformed the landscape of natural languageprocessing (NLP) and are increasingly applied to computer vision tasks withremarkable success. These models, renowned for their ability to capturelong-range dependencies and contextual information, offer a promisingalternative to traditional convolutional neural networks (CNNs) in computervision. In this review paper, we provide an extensive overview of varioustransformer architectures adapted for computer vision tasks. We delve into howthese models capture global context and spatial relationships in images,empowering them to excel in tasks such as image classification, objectdetection, and segmentation. Analyzing the key components, trainingmethodologies, and performance metrics of transformer-based models, wehighlight their strengths, limitations, and recent advancements. Additionally,we discuss potential research directions and applications of transformer-basedmodels in computer vision, offering insights into their implications for futureadvancements in the field.</description><author>Gracile Astlin Pereira, Muhammad Hussain</author><pubDate>Tue, 27 Aug 2024 16:22:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15178v1</guid></item><item><title>UWF-RI2FA: Generating Multi-frame Ultrawide-field Fluorescein Angiography from Ultrawide-field Retinal Imaging Improves Diabetic Retinopathy Stratification</title><link>http://arxiv.org/abs/2408.10636v2</link><description>Ultrawide-field fluorescein angiography (UWF-FA) facilitates diabeticretinopathy (DR) detection by providing a clear visualization of peripheralretinal lesions. However, the intravenous dye injection with potential riskshamper its application. We aim to acquire dye-free UWF-FA images fromnoninvasive UWF retinal imaging (UWF-RI) using generative artificialintelligence (GenAI) and evaluate its effectiveness in DR screening. A total of18,321 UWF-FA images of different phases were registered with correspondingUWF-RI images and fed into a generative adversarial networks (GAN)-based modelfor training. The quality of generated UWF-FA images was evaluated throughquantitative metrics and human evaluation. The DeepDRiD dataset was used toexternally assess the contribution of generated UWF-FA images to DRclassification, using area under the receiver operating characteristic curve(AUROC) as outcome metrics. The generated early, mid, and late phase UWF-FAimages achieved high authenticity, with multi-scale similarity scores rangingfrom 0.70 to 0.91 and qualitative visual scores ranging from 1.64 to 1.98(1=real UWF-FA quality). In fifty randomly selected images, 56% to 76% of thegenerated images were difficult to distinguish from real images in the Turingtest. Moreover, adding these generated UWF-FA images for DR classificationsignificantly increased the AUROC from 0.869 to 0.904 compared to the baselinemodel using UWF-RI images (P &lt; .001). The model successfully generatesrealistic multi-frame UWF-FA images for enhancing DR stratification withoutintravenous dye injection.</description><author>Ruoyu Chen, Kezheng Xu, Kangyan Zheng, Weiyi Zhang, Yan Lu, Danli Shi, Mingguang He</author><pubDate>Tue, 27 Aug 2024 16:19:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10636v2</guid></item><item><title>Unlocking Potential in Pre-Trained Music Language Models for Versatile Multi-Track Music Arrangement</title><link>http://arxiv.org/abs/2408.15176v1</link><description>Large language models have shown significant capabilities across variousdomains, including symbolic music generation. However, leveraging thesepre-trained models for controllable music arrangement tasks, each requiringdifferent forms of musical information as control, remains a novel challenge.In this paper, we propose a unified sequence-to-sequence framework that enablesthe fine-tuning of a symbolic music language model for multiple multi-trackarrangement tasks, including band arrangement, piano reduction, drumarrangement, and voice separation. Our experiments demonstrate that theproposed approach consistently achieves higher musical quality compared totask-specific baselines across all four tasks. Furthermore, through additionalexperiments on probing analysis, we show the pre-training phase equips themodel with essential knowledge to understand musical conditions, which is hardto acquired solely through task-specific fine-tuning.</description><author>Longshen Ou, Jingwei Zhao, Ziyu Wang, Gus Xia, Ye Wang</author><pubDate>Tue, 27 Aug 2024 16:18:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15176v1</guid></item><item><title>CNN-Transformer Rectified Collaborative Learning for Medical Image Segmentation</title><link>http://arxiv.org/abs/2408.13698v2</link><description>Automatic and precise medical image segmentation (MIS) is of vital importancefor clinical diagnosis and analysis. Current MIS methods mainly rely on theconvolutional neural network (CNN) or self-attention mechanism (Transformer)for feature modeling. However, CNN-based methods suffer from the inaccuratelocalization owing to the limited global dependency while Transformer-basedmethods always present the coarse boundary for the lack of local emphasis.Although some CNN-Transformer hybrid methods are designed to synthesize thecomplementary local and global information for better performance, thecombination of CNN and Transformer introduces numerous parameters and increasesthe computation cost. To this end, this paper proposes a CNN-Transformerrectified collaborative learning (CTRCL) framework to learn stronger CNN-basedand Transformer-based models for MIS tasks via the bi-directional knowledgetransfer between them. Specifically, we propose a rectified logit-wisecollaborative learning (RLCL) strategy which introduces the ground truth toadaptively select and rectify the wrong regions in student soft labels foraccurate knowledge transfer in the logit space. We also propose a class-awarefeature-wise collaborative learning (CFCL) strategy to achieve effectiveknowledge transfer between CNN-based and Transformer-based models in thefeature space by granting their intermediate features the similar capability ofcategory perception. Extensive experiments on three popular MIS benchmarksdemonstrate that our CTRCL outperforms most state-of-the-art collaborativelearning methods under different evaluation metrics.</description><author>Lanhu Wu, Miao Zhang, Yongri Piao, Zhenyan Yao, Weibing Sun, Feng Tian, Huchuan Lu</author><pubDate>Tue, 27 Aug 2024 16:11:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13698v2</guid></item><item><title>Exploiting Approximate Symmetry for Efficient Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2408.15173v1</link><description>Mean-field games (MFG) have become significant tools for solving large-scalemulti-agent reinforcement learning problems under symmetry. However, theassumption of exact symmetry limits the applicability of MFGs, as real-worldscenarios often feature inherent heterogeneity. Furthermore, most works on MFGassume access to a known MFG model, which might not be readily available forreal-world finite-agent games. In this work, we broaden the applicability ofMFGs by providing a methodology to extend any finite-player, possiblyasymmetric, game to an "induced MFG". First, we prove that $N$-player dynamicgames can be symmetrized and smoothly extended to the infinite-player continuumvia explicit Kirszbraun extensions. Next, we propose the notion of$\alpha,\beta$-symmetric games, a new class of dynamic population games thatincorporate approximate permutation invariance. For $\alpha,\beta$-symmetricgames, we establish explicit approximation bounds, demonstrating that a Nashpolicy of the induced MFG is an approximate Nash of the $N$-player dynamicgame. We show that TD learning converges up to a small bias using trajectoriesof the $N$-player game with finite-sample guarantees, permitting symmetrizedlearning without building an explicit MFG model. Finally, for certain gamessatisfying monotonicity, we prove a sample complexity of$\widetilde{\mathcal{O}}(\varepsilon^{-6})$ for the $N$-agent game to learn an$\varepsilon$-Nash up to symmetrization bias. Our theory is supported byevaluations on MARL benchmarks with thousands of agents.</description><author>Batuhan Yardim, Niao He</author><pubDate>Tue, 27 Aug 2024 16:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15173v1</guid></item><item><title>X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation</title><link>http://arxiv.org/abs/2408.15172v1</link><description>Large Language Models (LLMs) and Large Multimodal Models (LMMs) have beenshown to enhance the effectiveness of enriching item descriptions, therebyimproving the accuracy of recommendation systems. However, most existingapproaches either rely on text-only prompting or employ basic multimodalstrategies that do not fully exploit the complementary information availablefrom both textual and visual modalities. This paper introduces a novelframework, Cross-Reflection Prompting, termed X-Reflect, designed to addressthese limitations by prompting LMMs to explicitly identify and reconcilesupportive and conflicting information between text and images. By capturingnuanced insights from both modalities, this approach generates morecomprehensive and contextually richer item representations. Extensiveexperiments conducted on two widely used benchmarks demonstrate that our methodoutperforms existing prompting baselines in downstream recommendation accuracy.Additionally, we evaluate the generalizability of our framework acrossdifferent LMM backbones and the robustness of the prompting strategies,offering insights for optimization. This work underscores the importance ofintegrating multimodal information and presents a novel solution for improvingitem understanding in multimodal recommendation systems.</description><author>Hanjia Lyu, Ryan Rossi, Xiang Chen, Md Mehrab Tanjim, Stefano Petrangeli, Somdeb Sarkhel, Jiebo Luo</author><pubDate>Tue, 27 Aug 2024 16:10:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15172v1</guid></item><item><title>Measuring text summarization factuality using atomic facts entailment metrics in the context of retrieval augmented generation</title><link>http://arxiv.org/abs/2408.15171v1</link><description>The use of large language models (LLMs) has significantly increased since theintroduction of ChatGPT in 2022, demonstrating their value across variousapplications. However, a major challenge for enterprise and commercial adoptionof LLMs is their tendency to generate inaccurate information, a phenomenonknown as "hallucination." This project proposes a method for estimating thefactuality of a summary generated by LLMs when compared to a source text. Ourapproach utilizes Naive Bayes classification to assess the accuracy of thecontent produced.</description><author>N. E. Kriman</author><pubDate>Tue, 27 Aug 2024 16:09:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15171v1</guid></item><item><title>Latent Ewald summation for machine learning of long-range interactions</title><link>http://arxiv.org/abs/2408.15165v1</link><description>Machine learning interatomic potentials (MLIPs) often neglect long-rangeinteractions, such as electrostatic and dispersion forces. In this work, weintroduce a straightforward and efficient method to account for long-rangeinteractions by learning a latent variable from local atomic descriptors andapplying an Ewald summation to this variable. We demonstrate that in systemsincluding charged, polar, or apolar molecular dimers, bulk water, andwater-vapor interface, standard short-ranged MLIPs can lead to unphysicalpredictions even when employing message passing. The long-range modelseffectively eliminate these artifacts, with only about twice the computationalcost of short-range MLIPs.</description><author>Bingqing Cheng</author><pubDate>Tue, 27 Aug 2024 16:03:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15165v1</guid></item><item><title>The virtual CAT: A tool for algorithmic thinking assessment in Swiss compulsory education</title><link>http://arxiv.org/abs/2408.01263v2</link><description>In today's digital era, holding algorithmic thinking (AT) skills is crucial,not only in computer science-related fields. These abilities enable individualsto break down complex problems into more manageable steps and create a sequenceof actions to solve them. To address the increasing demand for AT assessmentsin educational settings and the limitations of current methods, this paperintroduces the virtual Cross Array Task (CAT), a digital adaptation of anunplugged assessment activity designed to evaluate algorithmic skills in Swisscompulsory education. This tool offers scalable and automated assessment,reducing human involvement and mitigating potential data collection errors. Theplatform features gesture-based and visual block-based programming interfaces,ensuring its usability for diverse learners, further supported by multilingualcapabilities. To evaluate the virtual CAT platform, we conducted a pilotevaluation in Switzerland involving a heterogeneous group of students. Thefindings show the platform's usability, proficiency and suitability forassessing AT skills among students of diverse ages, development stages, andeducational backgrounds, as well as the feasibility of large-scale datacollection.</description><author>Giorgia Adorni, Alberto Piatti</author><pubDate>Tue, 27 Aug 2024 16:02:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01263v2</guid></item><item><title>Zero-Shot Character Identification and Speaker Prediction in Comics via Iterative Multimodal Fusion</title><link>http://arxiv.org/abs/2404.13993v3</link><description>Recognizing characters and predicting speakers of dialogue are critical forcomic processing tasks, such as voice generation or translation. However,because characters vary by comic title, supervised learning approaches liketraining character classifiers which require specific annotations for eachcomic title are infeasible. This motivates us to propose a novel zero-shotapproach, allowing machines to identify characters and predict speaker namesbased solely on unannotated comic images. In spite of their importance inreal-world applications, these task have largely remained unexplored due tochallenges in story comprehension and multimodal integration. Recent largelanguage models (LLMs) have shown great capability for text understanding andreasoning, while their application to multimodal content analysis is still anopen problem. To address this problem, we propose an iterative multimodalframework, the first to employ multimodal information for both characteridentification and speaker prediction tasks. Our experiments demonstrate theeffectiveness of the proposed framework, establishing a robust baseline forthese tasks. Furthermore, since our method requires no training data orannotations, it can be used as-is on any comic series.</description><author>Yingxuan Li, Ryota Hinami, Kiyoharu Aizawa, Yusuke Matsui</author><pubDate>Tue, 27 Aug 2024 15:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.13993v3</guid></item><item><title>Empowering Sign Language Communication: Integrating Sentiment and Semantics for Facial Expression Synthesis</title><link>http://arxiv.org/abs/2408.15159v1</link><description>Translating written sentences from oral languages to a sequence of manual andnon-manual gestures plays a crucial role in building a more inclusive societyfor deaf and hard-of-hearing people. Facial expressions (non-manual), inparticular, are responsible for encoding the grammar of the sentence to bespoken, applying punctuation, pronouns, or emphasizing signs. These non-manualgestures are closely related to the semantics of the sentence being spoken andalso to the utterance of the speaker's emotions. However, most Sign LanguageProduction (SLP) approaches are centered on synthesizing manual gestures and donot focus on modeling the speakers expression. This paper introduces a newmethod focused in synthesizing facial expressions for sign language. Our goalis to improve sign language production by integrating sentiment information infacial expression generation. The approach leverages a sentence sentiment andsemantic features to sample from a meaningful representation space, integratingthe bias of the non-manual components into the sign language productionprocess. To evaluate our method, we extend the Frechet Gesture Distance (FGD)and propose a new metric called Frechet Expression Distance (FED) and apply anextensive set of metrics to assess the quality of specific regions of the face.The experimental results showed that our method achieved state of the art,being superior to the competitors on How2Sign and PHOENIX14T datasets.Moreover, our architecture is based on a carefully designed graph pyramid thatmakes it simpler, easier to train, and capable of leveraging emotions toproduce facial expressions.</description><author>Rafael Azevedo, Thiago Coutinho, João Ferreira, Thiago Gomes, Erickson Nascimento</author><pubDate>Tue, 27 Aug 2024 15:55:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15159v1</guid></item><item><title>Delay as Payoff in MAB</title><link>http://arxiv.org/abs/2408.15158v1</link><description>In this paper, we investigate a variant of the classical stochasticMulti-armed Bandit (MAB) problem, where the payoff received by an agent (eithercost or reward) is both delayed, and directly corresponds to the magnitude ofthe delay. This setting models faithfully many real world scenarios such as thetime it takes for a data packet to traverse a network given a choice of route(where delay serves as the agent's cost); or a user's time spent on a web pagegiven a choice of content (where delay serves as the agent's reward). Our main contributions are tight upper and lower bounds for both the cost andreward settings. For the case that delays serve as costs, which we are thefirst to consider, we prove optimal regret that scales as $\sum_{i:\Delta_i &gt;0}\frac{\log T}{\Delta_i} + d^*$, where $T$ is the maximal number of steps,$\Delta_i$ are the sub-optimality gaps and $d^*$ is the minimal expected delayamongst arms. For the case that delays serves as rewards, we show optimalregret of $\sum_{i:\Delta_i &gt; 0}\frac{\log T}{\Delta_i} + \bar{d}$, where $\bard$ is the second maximal expected delay. These improve over the regret in thegeneral delay-dependent payoff setting, which scales as $\sum_{i:\Delta_i &gt;0}\frac{\log T}{\Delta_i} + D$, where $D$ is the maximum possible delay. Ourregret bounds highlight the difference between the cost and reward scenarios,showing that the improvement in the cost scenario is more significant than forthe reward. Finally, we accompany our theoretical results with an empiricalevaluation.</description><author>Ofir Schlisselberg, Ido Cohen, Tal Lancewicki, Yishay Mansour</author><pubDate>Tue, 27 Aug 2024 15:52:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15158v1</guid></item><item><title>A Comprehensive Survey on Kolmogorov Arnold Networks (KAN)</title><link>http://arxiv.org/abs/2407.11075v4</link><description>Through this comprehensive survey of Kolmogorov-Arnold Networks(KAN), we havegained a thorough understanding of its theoretical foundation, architecturaldesign, application scenarios, and current research progress. KAN, with itsunique architecture and flexible activation functions, excels in handlingcomplex data patterns and nonlinear relationships, demonstrating wide-rangingapplication potential. While challenges remain, KAN is poised to pave the wayfor innovative solutions in various fields, potentially revolutionizing how weapproach complex computational problems.</description><author>Yuntian Hou, Di Zhang</author><pubDate>Tue, 27 Aug 2024 15:39:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11075v4</guid></item><item><title>Deep Reinforcement Learning for Multi-Truck Vehicle Routing Problems with Multi-Leg Demand Routes</title><link>http://arxiv.org/abs/2401.08669v2</link><description>Deep reinforcement learning (RL) has been shown to be effective in producingapproximate solutions to some vehicle routing problems (VRPs), especially whenusing policies generated by encoder-decoder attention mechanisms. While thesetechniques have been quite successful for relatively simple problem instances,there are still under-researched and highly complex VRP variants for which noeffective RL method has been demonstrated. In this work we focus on one suchVRP variant, which contains multiple trucks and multi-leg routing requirements.In these problems, demand is required to move along sequences of nodes, insteadof just from a start node to an end node. With the goal of making deep RL aviable strategy for real-world industrial-scale supply chain logistics, wedevelop new extensions to existing encoder-decoder attention models which allowthem to handle multiple trucks and multi-leg routing requirements. Our modelshave the advantage that they can be trained for a small number of trucks andnodes, and then embedded into a large supply chain to yield solutions forlarger numbers of trucks and nodes. We test our approach on a real supply chainenvironment arising in the operations of Japanese automotive parts manufacturerAisin Corporation, and find that our algorithm outperforms Aisin's previousbest solution.</description><author>Joshua Levin, Randall Correll, Takanori Ide, Takafumi Suzuki, Takaho Saito, Alan Arai</author><pubDate>Tue, 27 Aug 2024 15:36:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08669v2</guid></item><item><title>NoRA: Nested Low-Rank Adaptation for Efficient Fine-Tuning Large Models</title><link>http://arxiv.org/abs/2408.10280v2</link><description>In this paper, we introduce Nested Low-Rank Adaptation (NoRA), a novelapproach to parameter-efficient fine-tuning that extends the capabilities ofLow-Rank Adaptation (LoRA) techniques. Vanilla LoRA overlooks pre-trainedweight inheritance and still requires fine-tuning numerous parameters. Toaddresses these issues, our NoRA adopts a dual-layer nested structure withSingular Value Decomposition (SVD), effectively leveraging original matrixknowledge while reducing tunable parameters. Specifically, NoRA freezes theouter LoRA weights and utilizes an inner LoRA design, providing enhancedcontrol over model optimization. This approach allows the model to moreprecisely adapt to specific tasks while maintaining a compact parameter space.By freezing outer LoRA weights and using an inner LoRA design, NoRA enablesprecise task adaptation with a compact parameter space. Evaluations on tasksincluding commonsense reasoning with large language models, fine-tuningvision-language models, and subject-driven generation demonstrate NoRA'ssuperiority over LoRA and its variants. Code will be released upon acceptance.</description><author>Cheng Lin, Lujun Li, Dezhi Li, Jie Zou, Wei Xue, Yike Guo</author><pubDate>Tue, 27 Aug 2024 15:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10280v2</guid></item><item><title>Graph GOSPA metric: a metric to measure the discrepancy between graphs of different sizes</title><link>http://arxiv.org/abs/2311.07596v2</link><description>This paper proposes a metric to measure the dissimilarity between graphs thatmay have a different number of nodes. The proposed metric extends thegeneralised optimal subpattern assignment (GOSPA) metric, which is a metric forsets, to graphs. The proposed graph GOSPA metric includes costs associated withnode attribute errors for properly assigned nodes, missed and false nodes andedge mismatches between graphs. The computation of this metric is based onfinding the optimal assignments between nodes in the two graphs, with thepossibility of leaving some of the nodes unassigned. We also propose a lowerbound for the metric, which is also a metric for graphs and is computable inpolynomial time using linear programming. The metric is first derived forundirected unweighted graphs and it is then extended to directed and weightedgraphs. The properties of the metric are demonstrated via simulated andempirical datasets.</description><author>Jinhao Gu, Ángel F. García-Fernández, Robert E. Firth, Lennart Svensson</author><pubDate>Tue, 27 Aug 2024 15:34:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07596v2</guid></item><item><title>A Preliminary Exploration Towards General Image Restoration</title><link>http://arxiv.org/abs/2408.15143v1</link><description>Despite the tremendous success of deep models in various individual imagerestoration tasks, there are at least two major technical challenges preventingthese works from being applied to real-world usages: (1) the lack ofgeneralization ability and (2) the complex and unknown degradations inreal-world scenarios. Existing deep models, tailored for specific individualimage restoration tasks, often fall short in effectively addressing thesechallenges. In this paper, we present a new problem called general imagerestoration (GIR) which aims to address these challenges within a unifiedmodel. GIR covers most individual image restoration tasks (\eg, imagedenoising, deblurring, deraining and super-resolution) and their combinationsfor general purposes. This paper proceeds to delineate the essential aspects ofGIR, including problem definition and the overarching significance ofgeneralization performance. Moreover, the establishment of new datasets and athorough evaluation framework for GIR models is discussed. We conduct acomprehensive evaluation of existing approaches for tackling the GIR challenge,illuminating their strengths and pragmatic challenges. By analyzing theseapproaches, we not only underscore the effectiveness of GIR but also highlightthe difficulties in its practical implementation. At last, we also try tounderstand and interpret these models' behaviors to inspire the futuredirection. Our work can open up new valuable research directions and contributeto the research of general vision.</description><author>Xiangtao Kong, Jinjin Gu, Yihao Liu, Wenlong Zhang, Xiangyu Chen, Yu Qiao, Chao Dong</author><pubDate>Tue, 27 Aug 2024 15:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15143v1</guid></item><item><title>Local Causal Discovery for Structural Evidence of Direct Discrimination</title><link>http://arxiv.org/abs/2405.14848v2</link><description>Identifying the causal pathways of unfairness is a critical objective inimproving policy design and algorithmic decision-making. Prior work in causalfairness analysis often requires knowledge of the causal graph, hinderingpractical applications in complex or low-knowledge domains. Moreover, globaldiscovery methods that learn causal structure from data can result in unstableperformance with finite samples, potentially leading to contradictory fairnessconclusions. To mitigate these issues, we introduce local discovery for directdiscrimination (LD3): a method that uncovers structural evidence of directdiscrimination by identifying the causal parents of an outcome variable. LD3performs a linear number of conditional independence tests relative to variableset size, and allows for latent confounding under the sufficient condition thatno parent of the outcome is latent. We show that LD3 returns a valid adjustmentset (VAS) under a new graphical criterion for the weighted controlled directeffect, a qualitative indicator of direct discrimination. LD3 limitsunnecessary adjustment, providing interpretable VAS for assessing unfairness.We use LD3 to analyze causal fairness in two complex decision systems: criminalrecidivism prediction and liver transplant allocation. LD3 was moretime-efficient and returned more plausible results on real-world data thanbaselines, which took 46x to 5870x longer to execute.</description><author>Jacqueline Maasch, Kyra Gan, Violet Chen, Agni Orfanoudaki, Nil-Jana Akpinar, Fei Wang</author><pubDate>Tue, 27 Aug 2024 15:28:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14848v2</guid></item><item><title>How transformers learn structured data: insights from hierarchical filtering</title><link>http://arxiv.org/abs/2408.15138v1</link><description>We introduce a hierarchical filtering procedure for generative models ofsequences on trees, enabling control over the range of positional correlationsin the data. Leveraging this controlled setting, we provide evidence thatvanilla encoder-only transformer architectures can implement the optimal BeliefPropagation algorithm on both root classification and masked language modelingtasks. Correlations at larger distances corresponding to increasing layers ofthe hierarchy are sequentially included as the network is trained. We analyzehow the transformer layers succeed by focusing on attention maps from modelstrained with varying degrees of filtering. These attention maps show clearevidence for iterative hierarchical reconstruction of correlations, and we canrelate these observations to a plausible implementation of the exact inferencealgorithm for the network sizes considered.</description><author>Jerome Garnier-Brun, Marc Mézard, Emanuele Moscato, Luca Saglietti</author><pubDate>Tue, 27 Aug 2024 15:23:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15138v1</guid></item><item><title>Human Perception of Audio Deepfakes</title><link>http://arxiv.org/abs/2107.09667v7</link><description>The recent emergence of deepfakes has brought manipulated and generatedcontent to the forefront of machine learning research. Automatic detection ofdeepfakes has seen many new machine learning techniques, however, humandetection capabilities are far less explored. In this paper, we present resultsfrom comparing the abilities of humans and machines for detecting audiodeepfakes used to imitate someone's voice. For this, we use a web-basedapplication framework formulated as a game. Participants were asked todistinguish between real and fake audio samples. In our experiment, 472 uniqueusers competed against a state-of-the-art AI deepfake detection algorithm for14912 total of rounds of the game. We find that humans and deepfake detectionalgorithms share similar strengths and weaknesses, both struggling to detectcertain types of attacks. This is in contrast to the superhuman performance ofAI in many application areas such as object detection or face recognition.Concerning human success factors, we find that IT professionals have noadvantage over non-professionals but native speakers have an advantage overnon-native speakers. Additionally, we find that older participants tend to bemore susceptible than younger ones. These insights may be helpful whendesigning future cybersecurity training for humans as well as developing betterdetection algorithms.</description><author>Nicolas M. Müller, Karla Pizzi, Jennifer Williams</author><pubDate>Tue, 27 Aug 2024 15:19:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.09667v7</guid></item><item><title>Low-Budget Simulation-Based Inference with Bayesian Neural Networks</title><link>http://arxiv.org/abs/2408.15136v1</link><description>Simulation-based inference methods have been shown to be inaccurate in thedata-poor regime, when training simulations are limited or expensive. Underthese circumstances, the inference network is particularly prone tooverfitting, and using it without accounting for the computational uncertaintyarising from the lack of identifiability of the network weights can lead tounreliable results. To address this issue, we propose using Bayesian neuralnetworks in low-budget simulation-based inference, thereby explicitlyaccounting for the computational uncertainty of the posterior approximation. Wedesign a family of Bayesian neural network priors that are tailored forinference and show that they lead to well-calibrated posteriors on testedbenchmarks, even when as few as $O(10)$ simulations are available. This opensup the possibility of performing reliable simulation-based inference using veryexpensive simulators, as we demonstrate on a problem from the field ofcosmology where single simulations are computationally expensive. We show thatBayesian neural networks produce informative and well-calibrated posteriorestimates with only a few hundred simulations.</description><author>Arnaud Delaunoy, Maxence de la Brassinne Bonardeaux, Siddharth Mishra-Sharma, Gilles Louppe</author><pubDate>Tue, 27 Aug 2024 15:19:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15136v1</guid></item><item><title>Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments</title><link>http://arxiv.org/abs/2408.07531v2</link><description>Emergency department (ED) overcrowding and the complexity of rapiddecision-making in critical care settings pose significant challenges tohealthcare systems worldwide. While clinical decision support systems (CDSS)have shown promise, the integration of large language models (LLMs) offers newpossibilities for enhancing triage accuracy and clinical decision-making. Thisstudy presents an LLM-driven CDSS designed to assist ED physicians and nursesin patient triage, treatment planning, and overall emergency care management. We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,orchestrated by CrewAI and Langchain. The system comprises four AI agentsemulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and EDCoordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) fortriage assessment and integrates with the RxNorm API for medication management. The model was evaluated using the Asclepius dataset, with performanceassessed by a clinical emergency medicine specialist. The CDSS demonstratedhigh accuracy in triage decision-making compared to the baseline of asingle-agent system. Furthermore, the system exhibited strong performance incritical areas, including primary diagnosis, critical findings identification,disposition decision-making, treatment planning, and resource allocation. Our multi-agent CDSS demonstrates significant potential for supportingcomprehensive emergency care management. By leveraging state-of-the-art AItechnologies, this system offers a scalable and adaptable tool that couldenhance emergency medical care delivery, potentially alleviating EDovercrowding and improving patient outcomes. This work contributes to thegrowing field of AI applications in emergency medicine and offers a promisingdirection for future research and clinical implementation.</description><author>Seungjun Han, Wongyung Choi</author><pubDate>Tue, 27 Aug 2024 15:16:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07531v2</guid></item><item><title>Using LLMs for Explaining Sets of Counterfactual Examples to Final Users</title><link>http://arxiv.org/abs/2408.15133v1</link><description>Causality is vital for understanding true cause-and-effect relationshipsbetween variables within predictive models, rather than relying on merecorrelations, making it highly relevant in the field of Explainable AI. In anautomated decision-making scenario, causal inference methods can analyze theunderlying data-generation process, enabling explanations of a model's decisionby manipulating features and creating counterfactual examples. Thesecounterfactuals explore hypothetical scenarios where a minimal number offactors are altered, providing end-users with valuable information on how tochange their situation. However, interpreting a set of multiple counterfactualscan be challenging for end-users who are not used to analyzing raw datarecords. In our work, we propose a novel multi-step pipeline that usescounterfactuals to generate natural language explanations of actions that willlead to a change in outcome in classifiers of tabular data using LLMs. Thispipeline is designed to guide the LLM through smaller tasks that mimic humanreasoning when explaining a decision based on counterfactual cases. Weconducted various experiments using a public dataset and proposed a method ofclosed-loop evaluation to assess the coherence of the final explanation withthe counterfactuals, as well as the quality of the content. Results arepromising, although further experiments with other datasets and humanevaluations should be carried out.</description><author>Arturo Fredes, Jordi Vitria</author><pubDate>Tue, 27 Aug 2024 15:13:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15133v1</guid></item><item><title>RT-Attack: Jailbreaking Text-to-Image Models via Random Token</title><link>http://arxiv.org/abs/2408.13896v2</link><description>Recently, Text-to-Image(T2I) models have achieved remarkable success in imagegeneration and editing, yet these models still have many potential issues,particularly in generating inappropriate or Not-Safe-For-Work(NSFW) content.Strengthening attacks and uncovering such vulnerabilities can advance thedevelopment of reliable and practical T2I models. Most of the previous workstreat T2I models as white-box systems, using gradient optimization to generateadversarial prompts. However, accessing the model's gradient is oftenimpossible in real-world scenarios. Moreover, existing defense methods, thoseusing gradient masking, are designed to prevent attackers from obtainingaccurate gradient information. While some black-box jailbreak attacks have beenexplored, these typically rely on simply replacing sensitive words, leading tosuboptimal attack performance. To address this issue, we introduce a two-stagequery-based black-box attack method utilizing random search. In the firststage, we establish a preliminary prompt by maximizing the semantic similaritybetween the adversarial and target harmful prompts. In the second stage, we usethis initial prompt to refine our approach, creating a detailed adversarialprompt aimed at jailbreaking and maximizing the similarity in image featuresbetween the images generated from this prompt and those produced by the targetharmful prompt. Extensive experiments validate the effectiveness of our methodin attacking the latest prompt checkers, post-hoc image checkers, securelytrained T2I models, and online commercial models.</description><author>Sensen Gao, Xiaojun Jia, Yihao Huang, Ranjie Duan, Jindong Gu, Yang Liu, Qing Guo</author><pubDate>Tue, 27 Aug 2024 15:13:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13896v2</guid></item><item><title>Trust and ethical considerations in a multi-modal, explainable AI-driven chatbot tutoring system: The case of collaboratively solving Rubik's Cube</title><link>http://arxiv.org/abs/2402.01760v2</link><description>Artificial intelligence (AI) has the potential to transform education withits power of uncovering insights from massive data about student learningpatterns. However, ethical and trustworthy concerns of AI have been raised butare unsolved. Prominent ethical issues in high school AI education include dataprivacy, information leakage, abusive language, and fairness. This paperdescribes technological components that were built to address ethical andtrustworthy concerns in a multi-modal collaborative platform (called ALLUREchatbot) for high school students to collaborate with AI to solve the Rubik'scube. In data privacy, we want to ensure that the informed consent of children,parents, and teachers, is at the center of any data that is managed. Sincechildren are involved, language, whether textual, audio, or visual, isacceptable both from users and AI and the system can steer interaction awayfrom dangerous situations. In information management, we also want to ensurethat the system, while learning to improve over time, does not leak informationabout users from one group to another.</description><author>Kausik Lakkaraju, Vedant Khandelwal, Biplav Srivastava, Forest Agostinelli, Hengtao Tang, Prathamjeet Singh, Dezhi Wu, Matt Irvin, Ashish Kundu</author><pubDate>Tue, 27 Aug 2024 15:09:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01760v2</guid></item><item><title>Evaluating the Energy Consumption of Machine Learning: Systematic Literature Review and Experiments</title><link>http://arxiv.org/abs/2408.15128v1</link><description>Monitoring, understanding, and optimizing the energy consumption of MachineLearning (ML) are various reasons why it is necessary to evaluate the energyusage of ML. However, there exists no universal tool that can answer thisquestion for all use cases, and there may even be disagreement on how toevaluate energy consumption for a specific use case. Tools and methods arebased on different approaches, each with their own advantages and drawbacks,and they need to be mapped out and explained in order to select the mostsuitable one for a given situation. We address this challenge through twoapproaches. First, we conduct a systematic literature review of all tools andmethods that permit to evaluate the energy consumption of ML (both at trainingand at inference), irrespective of whether they were originally designed formachine learning or general software. Second, we develop and use anexperimental protocol to compare a selection of these tools and methods. Thecomparison is both qualitative and quantitative on a range of ML tasks ofdifferent nature (vision, language) and computational complexity. Thesystematic literature review serves as a comprehensive guide for understandingthe array of tools and methods used in evaluating energy consumption of ML, forvarious use cases going from basic energy monitoring to consumptionoptimization. Two open-source repositories are provided for furtherexploration. The first one contains tools that can be used to replicate thiswork or extend the current review. The second repository houses theexperimental protocol, allowing users to augment the protocol with new MLcomputing tasks and additional energy evaluation tools.</description><author>Charlotte Rodriguez, Laura Degioanni, Laetitia Kameni, Richard Vidal, Giovanni Neglia</author><pubDate>Tue, 27 Aug 2024 15:08:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15128v1</guid></item><item><title>T-FAKE: Synthesizing Thermal Images for Facial Landmarking</title><link>http://arxiv.org/abs/2408.15127v1</link><description>Facial analysis is a key component in a wide range of applications such assecurity, autonomous driving, entertainment, and healthcare. Despite theavailability of various facial RGB datasets, the thermal modality, which playsa crucial role in life sciences, medicine, and biometrics, has been largelyoverlooked. To address this gap, we introduce the T-FAKE dataset, a newlarge-scale synthetic thermal dataset with sparse and dense landmarks. Tofacilitate the creation of the dataset, we propose a novel RGB2Thermal lossfunction, which enables the transfer of thermal style to RGB faces. Byutilizing the Wasserstein distance between thermal and RGB patches and thestatistical analysis of clinical temperature distributions on faces, we ensurethat the generated thermal images closely resemble real samples. UsingRGB2Thermal style transfer based on our RGB2Thermal loss function, we createthe T-FAKE dataset, a large-scale synthetic thermal dataset of faces.Leveraging our novel T-FAKE dataset, probabilistic landmark prediction, andlabel adaptation networks, we demonstrate significant improvements in landmarkdetection methods on thermal images across different landmark conventions. Ourmodels show excellent performance with both sparse 70-point landmarks and dense478-point landmark annotations. Our code and models are available athttps://github.com/phflot/tfake.</description><author>Philipp Flotho, Moritz Piening, Anna Kukleva, Gabriele Steidl</author><pubDate>Tue, 27 Aug 2024 15:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15127v1</guid></item><item><title>Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems</title><link>http://arxiv.org/abs/2407.16828v2</link><description>This work introduces MultiTRON, an approach that adapts Pareto frontapproximation techniques to multi-objective session-based recommender systemsusing a transformer neural network. Our approach optimizes trade-offs betweenkey metrics such as click-through and conversion rates by training on sampledpreference vectors. A significant advantage is that after training, a singlemodel can access the entire Pareto front, allowing it to be tailored to meetthe specific requirements of different stakeholders by adjusting an additionalinput vector that weights the objectives. We validate the model's performancethrough extensive offline and online evaluation. For broader application andresearch, the source code is made available athttps://github.com/otto-de/MultiTRON. The results confirm the model's abilityto manage multiple recommendation objectives effectively, offering a flexibletool for diverse business needs.</description><author>Timo Wilm, Philipp Normann, Felix Stepprath</author><pubDate>Tue, 27 Aug 2024 15:07:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16828v2</guid></item><item><title>Force-Guided Bridge Matching for Full-Atom Time-Coarsened Dynamics of Peptides</title><link>http://arxiv.org/abs/2408.15126v1</link><description>Molecular Dynamics (MD) simulations are irreplaceable and ubiquitous infields of materials science, chemistry, pharmacology just to name a few.Conventional MD simulations are plagued by numerical stability as well as longequilibration time issues, which limits broader applications of MD simulations.Recently, a surge of deep learning approaches have been devised fortime-coarsened dynamics, which learns the state transition mechanism over muchlarger time scales to overcome these limitations. However, only a few methodstarget the underlying Boltzmann distribution by resampling techniques, whereproposals are rarely accepted as new states with low efficiency. In this work,we propose a force-guided bridge matching model, FBM, a novel framework thatfirst incorporates physical priors into bridge matching for full-atomtime-coarsened dynamics. With the guidance of our well-designed intermediateforce field, FBM is feasible to target the Boltzmann-like distribution bydirect inference without extra steps. Experiments on small peptides verify oursuperiority in terms of comprehensive metrics and demonstrate transferabilityto unseen peptide systems.</description><author>Ziyang Yu, Wenbing Huang, Yang Liu</author><pubDate>Tue, 27 Aug 2024 15:07:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15126v1</guid></item><item><title>Time Series Analysis for Education: Methods, Applications, and Future Directions</title><link>http://arxiv.org/abs/2408.13960v2</link><description>Recent advancements in the collection and analysis of sequential educationaldata have brought time series analysis to a pivotal position in educationalresearch, highlighting its essential role in facilitating data-drivendecision-making. However, there is a lack of comprehensive summaries thatconsolidate these advancements. To the best of our knowledge, this paper is thefirst to provide a comprehensive review of time series analysis techniquesspecifically within the educational context. We begin by exploring thelandscape of educational data analytics, categorizing various data sources andtypes relevant to education. We then review four prominent time seriesmethods-forecasting, classification, clustering, and anomalydetection-illustrating their specific application points in educationalsettings. Subsequently, we present a range of educational scenarios andapplications, focusing on how these methods are employed to address diverseeducational tasks, which highlights the practical integration of multiple timeseries methods to solve complex educational problems. Finally, we conclude witha discussion on future directions, including personalized learning analytics,multimodal data fusion, and the role of large language models (LLMs) ineducational time series. The contributions of this paper include a detailedtaxonomy of educational data, a synthesis of time series techniques withspecific educational applications, and a forward-looking perspective onemerging trends and future research opportunities in educational analysis. Therelated papers and resources are available and regularly updated at the projectpage.</description><author>Shengzhong Mao, Chaoli Zhang, Yichi Song, Jindong Wang, Xiao-Jun Zeng, Zenglin Xu, Qingsong Wen</author><pubDate>Tue, 27 Aug 2024 15:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13960v2</guid></item><item><title>Machine Learning for Methane Detection and Quantification from Space - A survey</title><link>http://arxiv.org/abs/2408.15122v1</link><description>Methane ($CH_4$) is a potent anthropogenic greenhouse gas, contributing 86times more to global warming than Carbon Dioxide ($CO_2$) over 20 years, and italso acts as an air pollutant. Given its high radiative forcing potential andrelatively short atmospheric lifetime (9$\pm$1 years), methane has importantimplications for climate change, therefore, cutting methane emissions iscrucial for effective climate change mitigation. This work expands existinginformation on operational methane point source detection sensors in theShort-Wave Infrared (SWIR) bands. It reviews the state-of-the-art fortraditional as well as Machine Learning (ML) approaches. The architecture anddata used in such ML models will be discussed separately for methane plumesegmentation and emission rate estimation. Traditionally, experts rely onlabor-intensive manually adjusted methods for methane detection. However, MLapproaches offer greater scalability. Our analysis reveals that ML modelsoutperform traditional methods, particularly those based on convolutionalneural networks (CNN), which are based on the U-net and transformerarchitectures. These ML models extract valuable information frommethane-sensitive spectral data, enabling a more accurate detection. Challengesarise when comparing these methods due to variations in data, sensorspecifications, and evaluation metrics. To address this, we discuss existingdatasets and metrics, providing an overview of available resources andidentifying open research problems. Finally, we explore potential futureadvances in ML, emphasizing approaches for model comparability, large datasetcreation, and the European Union's forthcoming methane strategy.</description><author>Enno Tiemann, Shanyu Zhou, Alexander Kläser, Konrad Heidler, Rochelle Schneider, Xiao Xiang Zhu</author><pubDate>Tue, 27 Aug 2024 15:03:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15122v1</guid></item><item><title>Polyp SAM 2: Advancing Zero shot Polyp Segmentation in Colorectal Cancer Detection</title><link>http://arxiv.org/abs/2408.05892v3</link><description>Polyp segmentation plays a crucial role in the early detection and diagnosisof colorectal cancer. However, obtaining accurate segmentations often requireslabor-intensive annotations and specialized models. Recently, Meta AI Researchreleased a general Segment Anything Model 2 (SAM 2), which has demonstratedpromising performance in several segmentation tasks. In this manuscript, weevaluate the performance of SAM 2 in segmenting polyps under various promptedsettings. We hope this report will provide insights to advance the field ofpolyp segmentation and promote more interesting work in the future. Thisproject is publicly available at https://github.com/ sajjad-sh33/Polyp-SAM-2.</description><author>Mobina Mansoori, Sajjad Shahabodini, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi</author><pubDate>Tue, 27 Aug 2024 15:00:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05892v3</guid></item><item><title>Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis</title><link>http://arxiv.org/abs/2408.15121v1</link><description>Significant investment and development have gone into integrating ArtificialIntelligence (AI) in medical and healthcare applications, leading to advancedcontrol systems in medical technology. However, the opacity of AI systemsraises concerns about essential characteristics needed in such sensitiveapplications, like transparency and trustworthiness. Our study addresses theseconcerns by investigating a process for selecting the most adequate ExplainableAI (XAI) methods to comply with the explanation requirements of key EUregulations in the context of smart bioelectronics for medical devices. Theadopted methodology starts with categorising smart devices by their controlmechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delvinginto their technology. Then, we analyse these regulations to define theirexplainability requirements for the various devices and related goals.Simultaneously, we classify XAI methods by their explanatory objectives. Thisallows for matching legal explainability requirements with XAI explanatorygoals and determining the suitable XAI algorithms for achieving them. Ourfindings provide a nuanced understanding of which XAI algorithms align betterwith EU regulations for different types of medical devices. We demonstrate thisthrough practical case studies on different neural implants, from chronicdisease management to advanced prosthetics. This study fills a crucial gap inaligning XAI applications in bioelectronics with stringent provisions of EUregulations. It provides a practical framework for developers and researchers,ensuring their AI innovations advance healthcare technology and adhere to legaland ethical standards.</description><author>Francesco Sovrano, Michael Lognoul, Giulia Vilone</author><pubDate>Tue, 27 Aug 2024 14:59:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15121v1</guid></item><item><title>EX-DRL: Hedging Against Heavy Losses with EXtreme Distributional Reinforcement Learning</title><link>http://arxiv.org/abs/2408.12446v2</link><description>Recent advancements in Distributional Reinforcement Learning (DRL) formodeling loss distributions have shown promise in developing hedging strategiesin derivatives markets. A common approach in DRL involves learning thequantiles of loss distributions at specified levels using Quantile Regression(QR). This method is particularly effective in option hedging due to its directquantile-based risk assessment, such as Value at Risk (VaR) and ConditionalValue at Risk (CVaR). However, these risk measures depend on the accurateestimation of extreme quantiles in the loss distribution's tail, which can beimprecise in QR-based DRL due to the rarity and extremity of tail data, ashighlighted in the literature. To address this issue, we propose EXtreme DRL(EX-DRL), which enhances extreme quantile prediction by modeling the tail ofthe loss distribution with a Generalized Pareto Distribution (GPD). This methodintroduces supplementary data to mitigate the scarcity of extreme quantileobservations, thereby improving estimation accuracy through QR. Comprehensiveexperiments on gamma hedging options demonstrate that EX-DRL improves existingQR-based models by providing more precise estimates of extreme quantiles,thereby improving the computation and reliability of risk metrics for complexfinancial risk management.</description><author>Parvin Malekzadeh, Zissis Poulos, Jacky Chen, Zeyu Wang, Konstantinos N. Plataniotis</author><pubDate>Tue, 27 Aug 2024 14:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12446v2</guid></item><item><title>Urdu Digital Text Word Optical Character Recognition Using Permuted Auto Regressive Sequence Modeling</title><link>http://arxiv.org/abs/2408.15119v1</link><description>This research paper introduces an innovative word-level Optical CharacterRecognition (OCR) model specifically designed for digital Urdu textrecognition. Utilizing transformer-based architectures and attentionmechanisms, the model was trained on a comprehensive dataset of approximately160,000 Urdu text images, achieving a character error rate (CER) of 0.178,which highlights its superior accuracy in recognizing Urdu characters. Themodel's strength lies in its unique architecture, incorporating the permutedautoregressive sequence (PARSeq) model, which allows for context-awareinference and iterative refinement by leveraging bidirectional contextinformation to enhance recognition accuracy. Furthermore, its capability tohandle a diverse range of Urdu text styles, fonts, and variations enhances itsapplicability in real-world scenarios. Despite its promising results, the modelhas some limitations, such as difficulty with blurred images, non-horizontalorientations, and overlays of patterns, lines, or other text, which canoccasionally lead to suboptimal performance. Additionally, trailing orfollowing punctuation marks can introduce noise into the recognition process.Addressing these challenges will be a focus of future research, aiming torefine the model further, explore data augmentation techniques, optimizehyperparameters, and integrate contextual improvements for more accurate andefficient Urdu text recognition.</description><author>Ahmed Mustafa, Ijlal Baig, Hasan Sajid</author><pubDate>Tue, 27 Aug 2024 14:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15119v1</guid></item><item><title>DIFR3CT: Latent Diffusion for Probabilistic 3D CT Reconstruction from Few Planar X-Rays</title><link>http://arxiv.org/abs/2408.15118v1</link><description>Computed Tomography (CT) scans are the standard-of-care for the visualizationand diagnosis of many clinical ailments, and are needed for the treatmentplanning of external beam radiotherapy. Unfortunately, the availability of CTscanners in low- and mid-resource settings is highly variable. Planar x-rayradiography units, in comparison, are far more prevalent, but can only providelimited 2D observations of the 3D anatomy. In this work we propose DIFR3CT, a3D latent diffusion model, that can generate a distribution of plausible CTvolumes from one or few (&lt;10) planar x-ray observations. DIFR3CT works byfusing 2D features from each x-ray into a joint 3D space, and performingdiffusion conditioned on these fused features in a low-dimensional latentspace. We conduct extensive experiments demonstrating that DIFR3CT is betterthan recent sparse CT reconstruction baselines in terms of standard pixel-level(PSNR, SSIM) on both the public LIDC and in-house post-mastectomy CT datasets.We also show that DIFR3CT supports uncertainty quantification via Monte Carlosampling, which provides an opportunity to measure reconstruction reliability.Finally, we perform a preliminary pilot study evaluating DIFR3CT for automatedbreast radiotherapy contouring and planning -- and demonstrate promisingfeasibility. Our code is available at https://github.com/yransun/DIFR3CT.</description><author>Yiran Sun, Hana Baroudi, Tucker Netherton, Laurence Court, Osama Mawlawi, Ashok Veeraraghavan, Guha Balakrishnan</author><pubDate>Tue, 27 Aug 2024 14:58:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15118v1</guid></item><item><title>Evaluating Stability of Unreflective Alignment</title><link>http://arxiv.org/abs/2408.15116v1</link><description>Many theoretical obstacles to AI alignment are consequences of reflectivestability - the problem of designing alignment mechanisms that the AI would notdisable if given the option. However, problems stemming from reflectivestability are not obviously present in current LLMs, leading to disagreementover whether they will need to be solved to enable safe delegation of cognitivelabor. In this paper, we propose Counterfactual Priority Change (CPC)destabilization as a mechanism by which reflective stability problems may arisein future LLMs. We describe two risk factors for CPC-destabilization: 1)CPC-based stepping back and 2) preference instability. We develop preliminaryevaluations for each of these risk factors, and apply them to frontier LLMs.Our findings indicate that in current LLMs, increased scale and capability areassociated with increases in both CPC-based stepping back and preferenceinstability, suggesting that CPC-destabilization may cause reflective stabilityproblems in future LLMs.</description><author>James Lucassen, Mark Henry, Philippa Wright, Owen Yeung</author><pubDate>Tue, 27 Aug 2024 14:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15116v1</guid></item><item><title>Few-Shot Unsupervised Implicit Neural Shape Representation Learning with Spatial Adversaries</title><link>http://arxiv.org/abs/2408.15114v1</link><description>Implicit Neural Representations have gained prominence as a powerfulframework for capturing complex data modalities, encompassing a wide range from3D shapes to images and audio. Within the realm of 3D shape representation,Neural Signed Distance Functions (SDF) have demonstrated remarkable potentialin faithfully encoding intricate shape geometry. However, learning SDFs fromsparse 3D point clouds in the absence of ground truth supervision remains avery challenging task. While recent methods rely on smoothness priors toregularize the learning, our method introduces a regularization term thatleverages adversarial samples around the shape to improve the learned SDFs.Through extensive experiments and evaluations, we illustrate the efficacy ofour proposed method, highlighting its capacity to improve SDF learning withrespect to baselines and the state-of-the-art using synthetic and real data.</description><author>Amine Ouasfi, Adnane Boukhayma</author><pubDate>Tue, 27 Aug 2024 14:54:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15114v1</guid></item><item><title>Localising the Seizure Onset Zone from Single-Pulse Electrical Stimulation Responses with a CNN Transformer</title><link>http://arxiv.org/abs/2403.20324v3</link><description>Epilepsy is one of the most common neurological disorders, often requiringsurgical intervention when medication fails to control seizures. For effectivesurgical outcomes, precise localisation of the epileptogenic focus - oftenapproximated through the Seizure Onset Zone (SOZ) - is critical yet remains achallenge. Active probing through electrical stimulation is already standardclinical practice for identifying epileptogenic areas. Our study advances theapplication of deep learning for SOZ localisation using Single-Pulse ElectricalStimulation (SPES) responses, with two key contributions. Firstly, we implementan existing deep learning model to compare two SPES analysis paradigms:divergent and convergent. These paradigms evaluate outward and inward effectiveconnections, respectively. We assess the generalisability of these models tounseen patients and electrode placements using held-out test sets. Our findingsreveal a notable improvement in moving from a divergent (AUROC: 0.574) to aconvergent approach (AUROC: 0.666), marking the first application of the latterin this context. Secondly, we demonstrate the efficacy of CNN Transformers withcross-channel attention in handling heterogeneous electrode placements,increasing the AUROC to 0.730. These findings represent a significant step inmodelling patient-specific intracranial EEG electrode placements in SPES.Future work will explore integrating these models into clinical decision-makingprocesses to bridge the gap between deep learning research and practicalhealthcare applications.</description><author>Jamie Norris, Aswin Chari, Dorien van Blooijs, Gerald Cooray, Karl Friston, Martin Tisdall, Richard Rosch</author><pubDate>Tue, 27 Aug 2024 14:53:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20324v3</guid></item><item><title>AnomalousPatchCore: Exploring the Use of Anomalous Samples in Industrial Anomaly Detection</title><link>http://arxiv.org/abs/2408.15113v1</link><description>Visual inspection, or industrial anomaly detection, is one of the most commonquality control types in manufacturing. The task is to identify the presence ofan anomaly given an image, e.g., a missing component on an image of a circuitboard, for subsequent manual inspection. While industrial anomaly detection hasseen a surge in recent years, most anomaly detection methods still utilizeknowledge only from normal samples, failing to leverage the information fromthe frequently available anomalous samples. Additionally, they heavily rely onvery general feature extractors pre-trained on common image classificationdatasets. In this paper, we address these shortcomings and propose the newanomaly detection system AnomalousPatchCore~(APC) based on a feature extractorfine-tuned with normal and anomalous in-domain samples and a subsequent memorybank for identifying unusual features. To fine-tune the feature extractor inAPC, we propose three auxiliary tasks that address the different aspects ofanomaly detection~(classification vs. localization) and mitigate the effect ofthe imbalance between normal and anomalous samples. Our extensive evaluation onthe MVTec dataset shows that APC outperforms state-of-the-art systems indetecting anomalies, which is especially important in industrial anomalydetection given the subsequent manual inspection. In detailed ablation studies,we further investigate the properties of our APC.</description><author>Mykhailo Koshil, Tilman Wegener, Detlef Mentrup, Simone Frintrop, Christian Wilms</author><pubDate>Tue, 27 Aug 2024 14:51:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15113v1</guid></item></channel></rss>