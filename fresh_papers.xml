<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 10 Jan 2024 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>A Simple Baseline for Spoken Language to Sign Language Translation with 3D Avatars</title><link>http://arxiv.org/abs/2401.04730v1</link><description>The objective of this paper is to develop a functional system for translatingspoken languages into sign languages, referred to as Spoken2Sign translation.The Spoken2Sign task is orthogonal and complementary to traditional signlanguage to spoken language (Sign2Spoken) translation. To enable Spoken2Signtranslation, we present a simple baseline consisting of three steps: 1)creating a gloss-video dictionary using existing Sign2Spoken benchmarks; 2)estimating a 3D sign for each sign video in the dictionary; 3) training aSpoken2Sign model, which is composed of a Text2Gloss translator, a signconnector, and a rendering module, with the aid of the yielded gloss-3D signdictionary. The translation results are then displayed through a sign avatar.As far as we know, we are the first to present the Spoken2Sign task in anoutput format of 3D signs. In addition to its capability of Spoken2Signtranslation, we also demonstrate that two by-products of our approach-3Dkeypoint augmentation and multi-view understanding-can assist in keypoint-basedsign language understanding. Code and models will be available athttps://github.com/FangyunWei/SLRT</description><author>Ronglai Zuo, Fangyun Wei, Zenggui Chen, Brian Mak, Jiaolong Yang, Xin Tong</author><pubDate>Tue, 09 Jan 2024 18:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04730v1</guid></item><item><title>On the Effect of Contextual Information on Human Delegation Behavior in Human-AI collaboration</title><link>http://arxiv.org/abs/2401.04729v1</link><description>The constantly increasing capabilities of artificial intelligence (AI) opennew possibilities for human-AI collaboration. One promising approach toleverage existing complementary capabilities is allowing humans to delegateindividual instances to the AI. However, enabling humans to delegate instanceseffectively requires them to assess both their own and the AI's capabilities inthe context of the given task. In this work, we explore the effects ofproviding contextual information on human decisions to delegate instances to anAI. We find that providing participants with contextual informationsignificantly improves the human-AI team performance. Additionally, we showthat the delegation behavior changes significantly when participants receivevarying types of contextual information. Overall, this research advances theunderstanding of human-AI interaction in human delegation and providesactionable insights for designing more effective collaborative systems.</description><author>Philipp Spitzer, Joshua Holstein, Patrick Hemmer, Michael Vössing, Niklas Kühl, Dominik Martin, Gerhard Satzger</author><pubDate>Tue, 09 Jan 2024 18:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04729v1</guid></item><item><title>Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation</title><link>http://arxiv.org/abs/2401.04728v1</link><description>Recent advances in generative diffusion models have enabled the previouslyunfeasible capability of generating 3D assets from a single input image or atext prompt. In this work, we aim to enhance the quality and functionality ofthese models for the task of creating controllable, photorealistic humanavatars. We achieve this by integrating a 3D morphable model into thestate-of-the-art multiview-consistent diffusion approach. We demonstrate thataccurate conditioning of a generative pipeline on the articulated 3D modelenhances the baseline model performance on the task of novel view synthesisfrom a single image. More importantly, this integration facilitates a seamlessand accurate incorporation of facial expression and body pose control into thegeneration process. To the best of our knowledge, our proposed framework is thefirst diffusion model to enable the creation of fully 3D-consistent,animatable, and photorealistic human avatars from a single image of an unseensubject; extensive quantitative and qualitative evaluations demonstrate theadvantages of our approach over existing state-of-the-art avatar creationmodels on both novel view and novel expression synthesis tasks.</description><author>Xiyi Chen, Marko Mihajlovic, Shaofei Wang, Sergey Prokudin, Siyu Tang</author><pubDate>Tue, 09 Jan 2024 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04728v1</guid></item><item><title>Revisiting Adversarial Training at Scale</title><link>http://arxiv.org/abs/2401.04727v1</link><description>The machine learning community has witnessed a drastic change in the trainingpipeline, pivoted by those ''foundation models'' with unprecedented scales.However, the field of adversarial training is lagging behind, predominantlycentered around small model sizes like ResNet-50, and tiny and low-resolutiondatasets like CIFAR-10. To bridge this transformation gap, this paper providesa modern re-examination with adversarial training, investigating its potentialbenefits when applied at scale. Additionally, we introduce an efficient andeffective training strategy to enable adversarial training with giant modelsand web-scale data at an affordable computing cost. We denote this newlyintroduced framework as AdvXL. Empirical results demonstrate that AdvXL establishes new state-of-the-artrobust accuracy records under AutoAttack on ImageNet-1K. For example, bytraining on DataComp-1B dataset, our AdvXL empowers a vanilla ViT-g model tosubstantially surpass the previous records of $l_{\infty}$-, $l_{2}$-, and$l_{1}$-robust accuracy by margins of 11.4%, 14.2% and 12.9%, respectively.This achievement posits AdvXL as a pioneering approach, charting a newtrajectory for the efficient training of robust visual representations atsignificantly larger scales. Our code is available athttps://github.com/UCSC-VLAA/AdvXL.</description><author>Zeyu Wang, Xianhang Li, Hongru Zhu, Cihang Xie</author><pubDate>Tue, 09 Jan 2024 18:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04727v1</guid></item><item><title>The Tactician's Web of Large-Scale Formal Knowledge</title><link>http://arxiv.org/abs/2401.02950v2</link><description>The Tactician's Web is a platform offering a large web of stronglyinterconnected, machine-checked, formal mathematical knowledge convenientlypackaged for machine learning, analytics, and proof engineering. Built on topof the Coq proof assistant, the platform exports a dataset containing a widevariety of formal theories, presented as a web of definitions, theorems, proofterms, tactics, and proof states. Theories are encoded both as a semantic graph(rendered below) and as human-readable text, each with a unique set ofadvantages and disadvantages. Proving agents may interact with Coq through thesame rich data representation and can be automatically benchmarked on a set oftheorems. Tight integration with Coq provides the unique possibility to makeagents available to proof engineers as practical tools.</description><author>Lasse Blaauwbroek</author><pubDate>Tue, 09 Jan 2024 18:56:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02950v2</guid></item><item><title>CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation</title><link>http://arxiv.org/abs/2401.01275v2</link><description>Recently, the advent of large language models (LLMs) has revolutionizedgenerative agents. Among them, Role-Playing Conversational Agents (RPCAs)attract considerable attention due to their ability to emotionally engageusers. However, the absence of a comprehensive benchmark impedes progress inthis field. To bridge this gap, we introduce CharacterEval, a Chinese benchmarkfor comprehensive RPCA assessment, complemented by a tailored high-qualitydataset. The dataset comprises 1,785 multi-turn role-playing dialogues,encompassing 23,020 examples and featuring 77 characters derived from Chinesenovels and scripts. It was carefully constructed, beginning with initialdialogue extraction via GPT-4, followed by rigorous human-led quality control,and enhanced with in-depth character profiles sourced from Baidu Baike.CharacterEval employs a multifaceted evaluation approach, encompassing thirteentargeted metrics on four dimensions. Comprehensive experiments on CharacterEvaldemonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 inChinese role-playing conversation. Source code, data source and reward modelwill be publicly accessible at https://github.com/morecry/CharacterEval.</description><author>Quan Tu, Shilong Fan, Zihang Tian, Rui Yan</author><pubDate>Tue, 09 Jan 2024 18:54:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01275v2</guid></item><item><title>U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation</title><link>http://arxiv.org/abs/2401.04722v1</link><description>Convolutional Neural Networks (CNNs) and Transformers have been the mostpopular architectures for biomedical image segmentation, but both of them havelimited ability to handle long-range dependencies because of inherent localityor computational complexity. To address this challenge, we introduce U-Mamba, ageneral-purpose network for biomedical image segmentation. Inspired by theState Space Sequence Models (SSMs), a new family of deep sequence models knownfor their strong capability in handling long sequences, we design a hybridCNN-SSM block that integrates the local feature extraction power ofconvolutional layers with the abilities of SSMs for capturing the long-rangedependency. Moreover, U-Mamba enjoys a self-configuring mechanism, allowing itto automatically adapt to various datasets without manual intervention. Weconduct extensive experiments on four diverse tasks, including the 3D abdominalorgan segmentation in CT and MR images, instrument segmentation in endoscopyimages, and cell segmentation in microscopy images. The results reveal thatU-Mamba outperforms state-of-the-art CNN-based and Transformer-basedsegmentation networks across all tasks. This opens new avenues for efficientlong-range dependency modeling in biomedical image analysis. The code, models,and data are publicly available at https://wanglab.ai/u-mamba.html.</description><author>Jun Ma, Feifei Li, Bo Wang</author><pubDate>Tue, 09 Jan 2024 18:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04722v1</guid></item><item><title>Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving</title><link>http://arxiv.org/abs/2401.02949v2</link><description>Concepts abound in mathematics and its applications. They vary greatlybetween subject areas, and new ones are introduced in each mathematical paperor application. A formal theory builds a hierarchy of definitions, theorems andproofs that reference each other. When an AI agent is proving a new theorem,most of the mathematical concepts and lemmas relevant to that theorem may havenever been seen during training. This is especially true in the Coq proofassistant, which has a diverse library of Coq projects, each with its owndefinitions, lemmas, and even custom tactic procedures used to prove thoselemmas. It is essential for agents to incorporate such new information intotheir knowledge base on the fly. We work towards this goal by utilizing a new,large-scale, graph-based dataset for machine learning in Coq. We leverage afaithful graph-representation of Coq terms that induces a directed graph ofdependencies between definitions to create a novel graph neural network,Graph2Tac (G2T), that takes into account not only the current goal, but alsothe entire hierarchy of definitions that led to the current goal. G2T is anonline model that is deeply integrated into the users' workflow and can adaptin real time to new Coq projects and their definitions. It complements wellwith other online models that learn in real time from new proof scripts. Ournovel definition embedding task, which is trained to compute representations ofmathematical concepts not seen during training, boosts the performance of theneural network to rival state-of-the-art k-nearest neighbor predictors.</description><author>Jason Rute, Miroslav Olšák, Lasse Blaauwbroek, Fidel Ivan Schaposnik Massolo, Jelle Piepenbrock, Vasily Pestun</author><pubDate>Tue, 09 Jan 2024 18:53:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02949v2</guid></item><item><title>Low-resource finetuning of foundation models beats state-of-the-art in histopathology</title><link>http://arxiv.org/abs/2401.04720v1</link><description>To handle the large scale of whole slide images in computational pathology,most approaches first tessellate the images into smaller patches, extractfeatures from these patches, and finally aggregate the feature vectors withweakly-supervised learning. The performance of this workflow strongly dependson the quality of the extracted features. Recently, foundation models incomputer vision showed that leveraging huge amounts of data through supervisedor self-supervised learning improves feature quality and generalizability for avariety of tasks. In this study, we benchmark the most popular visionfoundation models as feature extractors for histopathology data. We evaluatethe models in two settings: slide-level classification and patch-levelclassification. We show that foundation models are a strong baseline. Ourexperiments demonstrate that by finetuning a foundation model on a single GPUfor only two hours or three days depending on the dataset, we can match oroutperform state-of-the-art feature extractors for computational pathology.These findings imply that even with little resources one can finetune a featureextractor tailored towards a specific downstream task and dataset. This is aconsiderable shift from the current state, where only few institutions withlarge amounts of resources and datasets are able to train a feature extractor.We publish all code used for training and evaluation as well as the finetunedmodels.</description><author>Benedikt Roth, Valentin Koch, Sophia J. Wagner, Julia A. Schnabel, Carsten Marr, Tingying Peng</author><pubDate>Tue, 09 Jan 2024 18:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04720v1</guid></item><item><title>Jump Cut Smoothing for Talking Heads</title><link>http://arxiv.org/abs/2401.04718v1</link><description>A jump cut offers an abrupt, sometimes unwanted change in the viewingexperience. We present a novel framework for smoothing these jump cuts, in thecontext of talking head videos. We leverage the appearance of the subject fromthe other source frames in the video, fusing it with a mid-level representationdriven by DensePose keypoints and face landmarks. To achieve motion, weinterpolate the keypoints and landmarks between the end frames around the cut.We then use an image translation network from the keypoints and source frames,to synthesize pixels. Because keypoints can contain errors, we propose across-modal attention scheme to select and pick the most appropriate sourceamongst multiple options for each key point. By leveraging this mid-levelrepresentation, our method can achieve stronger results than a strong videointerpolation baseline. We demonstrate our method on various jump cuts in thetalking head videos, such as cutting filler words, pauses, and even randomcuts. Our experiments show that we can achieve seamless transitions, even inthe challenging cases where the talking head rotates or moves drastically inthe jump cut.</description><author>Xiaojuan Wang, Taesung Park, Yang Zhou, Eli Shechtman, Richard Zhang</author><pubDate>Tue, 09 Jan 2024 18:44:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04718v1</guid></item><item><title>Low-Resource Vision Challenges for Foundation Models</title><link>http://arxiv.org/abs/2401.04716v1</link><description>Low-resource settings are well-established in natural language processing,where many languages lack sufficient data for machine learning at scale.However, low-resource problems are under-explored in computer vision. In thispaper, we strive to address this gap and explore the challenges of low-resourceimage tasks with vision foundation models. Thus, we first collect a benchmarkof genuinely low-resource image data, covering historic maps, circuit diagrams,and mechanical drawings. These low-resource settings all share the threechallenges of data scarcity, fine-grained differences, and the distributionshift from natural images to the specialized domain of interest. While existingfoundation models have shown impressive generalizability, we find they cannottransfer well to our low-resource tasks. To begin to tackle the challenges oflow-resource vision, we introduce one simple baseline per challenge.Specifically, we propose to i) enlarge the data space by generative models, ii)adopt the best sub-kernels to encode local regions for fine-grained differencediscovery and iii) learn attention for specialized domains. Experiments on thethree low-resource data sources in our benchmark demonstrate our proposalsalready provide a better baseline than common transfer learning, dataaugmentation, and fine-grained methods. This highlights the uniquecharacteristics and challenges of low-resource vision for foundation modelsthat warrant further investigation. Project website:https://xiaobai1217.github.io/Low-Resource-Vision/.</description><author>Yunhua Zhang, Hazel Doughty, Cees G. M. Snoek</author><pubDate>Tue, 09 Jan 2024 18:40:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04716v1</guid></item><item><title>GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning</title><link>http://arxiv.org/abs/2401.01990v2</link><description>We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), ageneral method to inject a priori knowledge into Self-Supervised Learning (SSL)positive samples selection. Current SSL methods leverage Data-Augmentations(DA) for generating positive samples and incorporate prior knowledge - anincorrect, or too weak DA will drastically reduce the quality of the learnedrepresentation. GPS-SSL proposes instead to design a metric space whereEuclidean distances become a meaningful proxy for semantic relationship. Inthat space, it is now possible to generate positive samples from nearestneighbor sampling. Any prior knowledge can now be embedded into that metricspace independently from the employed DA. From its simplicity, GPS-SSL isapplicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL isin reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. Wetherefore move a step forward towards the goal of making SSL less reliant onDA. We also show that even when using strong DAs, GPS-SSL outperforms thebaselines on under-studied domains. We evaluate GPS-SSL along with multiplebaseline SSL methods on numerous downstream datasets from different domainswhen the models use strong or minimal data augmentations. We hope that GPS-SSLwill open new avenues in studying how to inject a priori knowledge into SSL ina principled manner.</description><author>Aarash Feizi, Randall Balestriero, Adriana Romero-Soriano, Reihaneh Rabbany</author><pubDate>Tue, 09 Jan 2024 18:24:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01990v2</guid></item><item><title>A Comparative Study of Filters and Deep Learning Models to predict Diabetic Retinopathy</title><link>http://arxiv.org/abs/2309.15216v3</link><description>The retina is an essential component of the visual system, and maintainingeyesight depends on the timely and accurate detection of disorders. Theearly-stage detection and severity classification of Diabetic Retinopathy (DR),a significant risk to the public's health is the primary goal of this work.This study compares the outcomes of various deep learning models, includingInceptionNetV3, DenseNet121, and other CNN-based models, utilizing a variety ofimage filters, including Gaussian, grayscale, and Gabor. These models coulddetect subtle pathological alterations and use that information to estimate therisk of retinal illnesses. The objective is to improve the diagnostic processesfor DR, the primary cause of diabetes-related blindness, by utilizing deeplearning models. A comparative analysis between Greyscale, Gaussian and Gaborfilters has been provided after applying these filters on the retinal images.The Gaussian filter has been identified as the most promising filter byresulting in 96% accuracy using InceptionNetV3.</description><author>Roshan Vasu Muddaluru, Sharvaani Ravikumar Thoguluva, Shruti Prabha, Tanuja Konda Reddy, Dr. Suja Palaniswamy</author><pubDate>Tue, 09 Jan 2024 18:08:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15216v3</guid></item><item><title>Model Editing Can Hurt General Abilities of Large Language Models</title><link>http://arxiv.org/abs/2401.04700v1</link><description>Recent advances in large language models (LLMs) have opened up new paradigmsfor accessing the knowledge stored in their parameters. One critical challengethat has emerged is the presence of hallucinations in LLM outputs due to falseor outdated knowledge. Since retraining LLMs with updated information isresource-intensive, there has been a growing interest in model editing.However, many model editing methods, while effective in various scenarios, tendto overemphasize aspects such as efficacy, generalization, and locality inediting performance, often overlooking potential side effects on the generalabilities of LLMs. In this paper, we raise concerns that the improvement ofmodel factuality may come at the cost of a significant degradation of thesegeneral abilities, which is not conducive to the sustainable development ofLLMs. Systematically, we analyze side effects by evaluating four popularediting methods on two LLMs across eight representative task categories.Extensive empirical research reveals that model editing does improve modelfactuality but at the expense of substantially impairing general abilities.Therefore, we advocate for more research efforts to minimize the loss ofgeneral abilities acquired during LLM pre-training and to ultimately preservethem during model editing.</description><author>Jia-Chen Gu, Hao-Xiang Xu, Jun-Yu Ma, Pan Lu, Zhen-Hua Ling, Kai-Wei Chang, Nanyun Peng</author><pubDate>Tue, 09 Jan 2024 18:03:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04700v1</guid></item><item><title>PHPQ: Pyramid Hybrid Pooling Quantization for Efficient Fine-Grained Image Retrieval</title><link>http://arxiv.org/abs/2109.05206v2</link><description>Deep hashing approaches, including deep quantization and deep binary hashing,have become a common solution to large-scale image retrieval due to their highcomputation and storage efficiency. Most existing hashing methods cannotproduce satisfactory results for fine-grained retrieval, because they usuallyadopt the outputs of the last CNN layer to generate binary codes. Since deeperlayers tend to summarize visual clues, e.g., texture, into abstract semantics,e.g., dogs and cats, the feature produced by the last CNN layer is lesseffective in capturing subtle but discriminative visual details that mostlyexist in shallow layers. To improve fine-grained image hashing, we proposePyramid Hybrid Pooling Quantization (PHPQ). Specifically, we propose a PyramidHybrid Pooling (PHP) module to capture and preserve fine-grained semanticinformation from multi-level features, which emphasizes the subtlediscrimination of different sub-categories. Besides, we propose a learnablequantization module with a partial codebook attention mechanism, which helps tooptimize the most relevant codewords and improves the quantization.Comprehensive experiments on two widely-used public benchmarks, i.e.,CUB-200-2011 and Stanford Dogs, demonstrate that PHPQ outperformsstate-of-the-art methods.</description><author>Ziyun Zeng, Jinpeng Wang, Bin Chen, Tao Dai, Shu-Tao Xia, Zhi Wang</author><pubDate>Tue, 09 Jan 2024 17:56:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.05206v2</guid></item><item><title>InteraSSort: Interactive Assortment Planning Using Large Language Models</title><link>http://arxiv.org/abs/2311.12241v2</link><description>Assortment planning, integral to multiple commercial offerings, is a keyproblem studied in e-commerce and retail settings. Numerous variants of theproblem along with their integration into business solutions have beenthoroughly investigated in the existing literature. However, the nuancedcomplexities of in-store planning and a lack of optimization proficiency amongstore planners with strong domain expertise remain largely overlooked. Thesechallenges frequently necessitate collaborative efforts with multiplestakeholders which often lead to prolonged decision-making processes andsignificant delays. To mitigate these challenges and capitalize on theadvancements of Large Language Models (LLMs), we propose an interactiveassortment planning framework, InteraSSort that augments LLMs with optimizationtools to assist store planners in making decisions through interactiveconversations. Specifically, we develop a solution featuring a user-friendlyinterface that enables users to express their optimization objectives as inputtext prompts to InteraSSort and receive tailored optimized solutions as output.Our framework extends beyond basic functionality by enabling the inclusion ofadditional constraints through interactive conversation, facilitating preciseand highly customized decision-making. Extensive experiments demonstrate theeffectiveness of our framework and potential extensions to a broad range ofoperations management challenges.</description><author>Saketh Reddy Karra, Theja Tulabandhula</author><pubDate>Tue, 09 Jan 2024 17:53:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12241v2</guid></item><item><title>Data Augmentations for Improved (Large) Language Model Generalization</title><link>http://arxiv.org/abs/2310.12803v2</link><description>The reliance of text classifiers on spurious correlations can lead to poorgeneralization at deployment, raising concerns about their use insafety-critical domains such as healthcare. In this work, we propose to usecounterfactual data augmentation, guided by knowledge of the causal structureof the data, to simulate interventions on spurious features and to learn morerobust text classifiers. We show that this strategy is appropriate inprediction problems where the label is spuriously correlated with an attribute.Under the assumptions of such problems, we discuss the favorable samplecomplexity of counterfactual data augmentation, compared to importancere-weighting. Pragmatically, we match examples using auxiliary data, based ondiff-in-diff methodology, and use a large language model (LLM) to represent aconditional probability of text. Through extensive experimentation on learningcaregiver-invariant predictors of clinical diagnoses from medical narrativesand on semi-synthetic data, we demonstrate that our method for simulatinginterventions improves out-of-distribution (OOD) accuracy compared to baselineinvariant learning algorithms.</description><author>Amir Feder, Yoav Wald, Claudia Shi, Suchi Saria, David Blei</author><pubDate>Tue, 09 Jan 2024 17:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12803v2</guid></item><item><title>Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers</title><link>http://arxiv.org/abs/2401.04695v1</link><description>Factual questions typically can be answered correctly at different levels ofgranularity. For example, both ``August 4, 1961'' and ``1961'' are correctanswers to the question ``When was Barack Obama born?''. Standard questionanswering (QA) evaluation protocols, however, do not explicitly take this intoaccount and compare a predicted answer against answers of a single granularitylevel. In this work, we propose GRANOLA QA, a novel evaluation setting where apredicted answer is evaluated in terms of accuracy and informativeness againsta set of multi-granularity answers. We present a simple methodology forenriching existing datasets with multi-granularity answers, and createGRANOLA-EQ, a multi-granularity version of the EntityQuestions dataset. Weevaluate a range of decoding methods on GRANOLA-EQ, including a new algorithm,called Decoding with Response Aggregation (DRAG), that is geared towardsaligning the response granularity with the model's uncertainty. Our experimentsshow that large language models with standard decoding tend to generatespecific answers, which are often incorrect. In contrast, when evaluated onmulti-granularity answers, DRAG yields a nearly 20 point increase in accuracyon average, which further increases for rare entities. Overall, this revealsthat standard evaluation and decoding schemes may significantly underestimatethe knowledge encapsulated in LMs.</description><author>Gal Yona, Roee Aharoni, Mor Geva</author><pubDate>Tue, 09 Jan 2024 17:44:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04695v1</guid></item><item><title>AI-based Mapping of the Conservation Status of Orchid Assemblages at Global Scale</title><link>http://arxiv.org/abs/2401.04691v1</link><description>Although increasing threats on biodiversity are now widely recognised, thereare no accurate global maps showing whether and where species assemblages areat risk. We hereby assess and map at kilometre resolution the conservationstatus of the iconic orchid family, and discuss the insights conveyed atmultiple scales. We introduce a new Deep Species Distribution Model trained on1M occurrences of 14K orchid species to predict their assemblages at globalscale and at kilometre resolution. We propose two main indicators of theconservation status of the assemblages: (i) the proportion of threatenedspecies, and (ii) the status of the most threatened species in the assemblage.We show and analyze the variation of these indicators at World scale and inrelation to currently protected areas in Sumatra island. Global and interactivemaps available online show the indicators of conservation status of orchidassemblages, with sharp spatial variations at all scales. The highest level ofthreat is found at Madagascar and the neighbouring islands. In Sumatra, wefound good correspondence of protected areas with our indicators, butsupplementing current IUCN assessments with status predictions results inalarming levels of species threat across the island. Recent advances in deeplearning enable reliable mapping of the conservation status of speciesassemblages on a global scale. As an umbrella taxon, orchid family provides areference for identifying vulnerable ecosystems worldwide, and prioritisingconservation actions both at international and local levels.</description><author>Joaquim Estopinan, Maximilien Servajean, Pierre Bonnet, Alexis Joly, François Munoz</author><pubDate>Tue, 09 Jan 2024 17:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04691v1</guid></item><item><title>Attention to Entropic Communication</title><link>http://arxiv.org/abs/2307.11423v2</link><description>The concept of attention, numerical weights that emphasize the importance ofparticular data, has proven to be very relevant in artificial intelligence.Relative entropy (RE, aka Kullback-Leibler divergence) plays a central role incommunication theory. Here we combine these concepts, attention and RE. REguides optimal encoding of messages in bandwidth-limited communication as wellas optimal message decoding via the maximum entropy principle (MEP). In thecoding scenario, RE can be derived from four requirements, namely beinganalytical, local, proper, and calibrated. Weighted RE, used for attentionsteering in communications, turns out to be improper. To see how properattention communication can emerge, we analyze a scenario of a message senderwho wants to ensure that the receiver of the message can perform well-informedactions. If the receiver decodes the message using the MEP, the sender onlyneeds to know the receiver's utility function to inform optimally, but not thereceiver's initial knowledge state. In case only the curvature of the utilityfunction maxima are known, it becomes desirable to accurately communicate anattention function, in this case a by this curvature weighted and re-normalizedprobability function. Entropic attention communication is here proposed as thedesired generalization of entropic communication that permits weighting whilebeing proper, thereby aiding the design of optimal communication protocols intechnical applications and helping to understand human communication. Forexample, our analysis shows how to derive the level of cooperation expectedunder misaligned interests of otherwise honest communication partners.</description><author>Torsten Enßlin, Carolin Weidinger, Philipp Frank</author><pubDate>Tue, 09 Jan 2024 17:31:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11423v2</guid></item><item><title>Mixture of multilayer stochastic block models for multiview clustering</title><link>http://arxiv.org/abs/2401.04682v1</link><description>In this work, we propose an original method for aggregating multipleclustering coming from different sources of information. Each partition isencoded by a co-membership matrix between observations. Our approach uses amixture of multilayer Stochastic Block Models (SBM) to group co-membershipmatrices with similar information into components and to partition observationsinto different clusters, taking into account their specificities within thecomponents. The identifiability of the model parameters is established and avariational Bayesian EM algorithm is proposed for the estimation of theseparameters. The Bayesian framework allows for selecting an optimal number ofclusters and components. The proposed approach is compared using synthetic datawith consensus clustering and tensor-based algorithms for community detectionin large-scale complex networks. Finally, the method is utilized to analyzeglobal food trading networks, leading to structures of interest.</description><author>Kylliann De Santiago, Marie Szafranski, Christophe Ambroise</author><pubDate>Tue, 09 Jan 2024 17:15:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04682v1</guid></item><item><title>CoordGate: Efficiently Computing Spatially-Varying Convolutions in Convolutional Neural Networks</title><link>http://arxiv.org/abs/2401.04680v1</link><description>Optical imaging systems are inherently limited in their resolution due to thepoint spread function (PSF), which applies a static, yet spatially-varying,convolution to the image. This degradation can be addressed via ConvolutionalNeural Networks (CNNs), particularly through deblurring techniques. However,current solutions face certain limitations in efficiently computingspatially-varying convolutions. In this paper we propose CoordGate, a novellightweight module that uses a multiplicative gate and a coordinate encodingnetwork to enable efficient computation of spatially-varying convolutions inCNNs. CoordGate allows for selective amplification or attenuation of filtersbased on their spatial position, effectively acting like a locally connectedneural network. The effectiveness of the CoordGate solution is demonstratedwithin the context of U-Nets and applied to the challenging problem of imagedeblurring. The experimental results show that CoordGate outperformsconventional approaches, offering a more robust and spatially aware solutionfor CNNs in various computer vision applications.</description><author>Sunny Howard, Peter Norreys, Andreas Döpp</author><pubDate>Tue, 09 Jan 2024 17:13:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04680v1</guid></item><item><title>Weakly Supervised 3D Open-vocabulary Segmentation</title><link>http://arxiv.org/abs/2305.14093v4</link><description>Open-vocabulary segmentation of 3D scenes is a fundamental function of humanperception and thus a crucial objective in computer vision research. However,this task is heavily impeded by the lack of large-scale and diverse 3Dopen-vocabulary segmentation datasets for training robust and generalizablemodels. Distilling knowledge from pre-trained 2D open-vocabulary segmentationmodels helps but it compromises the open-vocabulary feature as the 2D modelsare mostly finetuned with close-vocabulary datasets. We tackle the challengesin 3D open-vocabulary segmentation by exploiting pre-trained foundation modelsCLIP and DINO in a weakly supervised manner. Specifically, given only theopen-vocabulary text descriptions of the objects in a scene, we distill theopen-vocabulary multimodal knowledge and object reasoning capability of CLIPand DINO into a neural radiance field (NeRF), which effectively lifts 2Dfeatures into view-consistent 3D segmentation. A notable aspect of our approachis that it does not require any manual segmentation annotations for either thefoundation models or the distillation process. Extensive experiments show thatour method even outperforms fully supervised models trained with segmentationannotations in certain scenes, suggesting that 3D open-vocabulary segmentationcan be effectively learned from 2D images and text-image pairs. Code isavailable at \url{https://github.com/Kunhao-Liu/3D-OVS}.</description><author>Kunhao Liu, Fangneng Zhan, Jiahui Zhang, Muyu Xu, Yingchen Yu, Abdulmotaleb El Saddik, Christian Theobalt, Eric Xing, Shijian Lu</author><pubDate>Tue, 09 Jan 2024 17:09:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14093v4</guid></item><item><title>RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation</title><link>http://arxiv.org/abs/2401.04679v1</link><description>We investigate parameter-efficient fine-tuning (PEFT) methods that canprovide good accuracy under limited computational and memory budgets in thecontext of large language models (LLMs). We present a new PEFT method calledRobust Adaptation (RoSA) inspired by robust principal component analysis (PCA)that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ componentson top of a set of fixed pretrained weights to efficiently approximate theperformance of a full-fine-tuning (FFT) solution. Across a series ofchallenging generative tasks such as grade-school math and SQL querygeneration, which require fine-tuning for good performance, we show that RoSAoutperforms both LoRA and pure sparse fine-tuning, at the same parameterbudget. We provide system support for RoSA to complement the trainingalgorithm, specifically in the form of sparse GPU kernels which enable memory-and computationally-efficient training. Our code will be made available athttps://github.com/IST-DASLab/RoSA}{\texttt{https://github.com/IST-DASLab/RoSA</description><author>Mahdi Nikdan, Soroush Tabesh, Dan Alistarh</author><pubDate>Tue, 09 Jan 2024 17:09:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04679v1</guid></item><item><title>Transfer-Learning-Based Autotuning Using Gaussian Copula</title><link>http://arxiv.org/abs/2401.04669v1</link><description>As diverse high-performance computing (HPC) systems are built, manyopportunities arise for applications to solve larger problems than ever before.Given the significantly increased complexity of these HPC systems andapplication tuning, empirical performance tuning, such as autotuning, hasemerged as a promising approach in recent years. Despite its effectiveness,autotuning is often a computationally expensive approach. Transfer learning(TL)-based autotuning seeks to address this issue by leveraging the data fromprior tuning. Current TL methods for autotuning spend significant time modelingthe relationship between parameter configurations and performance, which isineffective for few-shot (that is, few empirical evaluations) tuning on newtasks. We introduce the first generative TL-based autotuning approach based onthe Gaussian copula (GC) to model the high-performing regions of the searchspace from prior data and then generate high-performing configurations for newtasks. This allows a sampling-based approach that maximizes few-shotperformance and provides the first probabilistic estimation of the few-shotbudget for effective TL-based autotuning. We compare our generative TL approachwith state-of-the-art autotuning techniques on several benchmarks. We find thatthe GC is capable of achieving 64.37% of peak few-shot performance in its firstevaluation. Furthermore, the GC model can determine a few-shot transfer budgetthat yields up to 33.39$\times$ speedup, a dramatic improvement over the20.58$\times$ speedup using prior techniques.</description><author>Thomas Randall, Jaehoon Koo, Brice Videau, Michael Kruse, Xingfu Wu, Paul Hovland, Mary Hall, Rong Ge, Prasanna Balaprakash</author><pubDate>Tue, 09 Jan 2024 16:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04669v1</guid></item><item><title>Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA Cats and Dogs Dataset</title><link>http://arxiv.org/abs/2401.04666v1</link><description>As the most basic application and implementation of deep learning, imageclassification has grown in popularity. Various datasets are provided byrenowned data science communities for benchmarking machine learning algorithmsand pre-trained models. The ASSIRA Cats &amp; Dogs dataset is one of them and isbeing used in this research for its overall acceptance and benchmark standards.A comparison of various pre-trained models is demonstrated by using differenttypes of optimizers and loss functions. Hyper-parameters are changed to gainthe best result from a model. By applying this approach, we have got higheraccuracy without major changes in the training model. To run the experiment, weused three different computer architectures: a laptop equipped with NVIDIAGeForce GTX 1070, a laptop equipped with NVIDIA GeForce RTX 3080Ti, and adesktop equipped with NVIDIA GeForce RTX 3090. The acquired results demonstratesupremacy in terms of accuracy over the previously done experiments on thisdataset. From this experiment, the highest accuracy which is 99.65% is gainedusing the NASNet Large.</description><author>Galib Muhammad Shahriar Himel, Md. Masudul Islam</author><pubDate>Tue, 09 Jan 2024 16:48:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04666v1</guid></item><item><title>A Data-Driven Gaussian Process Filter for Electrocardiogram Denoising</title><link>http://arxiv.org/abs/2301.02607v2</link><description>Objective: Gaussian Processes (GP)-based filters, which have been effectivelyused for various applications including electrocardiogram (ECG) filtering canbe computationally demanding and the choice of their hyperparameters istypically ad hoc. Methods: We develop a data-driven GP filter to address bothissues, using the notion of the ECG phase domain -- a time-warpedrepresentation of the ECG beats onto a fixed number of samples and alignedR-peaks, which is assumed to follow a Gaussian distribution. Under thisassumption, the computation of the sample mean and covariance matrix issimplified, enabling an efficient implementation of the GP filter in adata-driven manner, with no ad hoc hyperparameters. The proposed filter isevaluated and compared with a state-of-the-art wavelet-based filter, on thePhysioNet QT Database. The performance is evaluated by measuring thesignal-to-noise ratio (SNR) improvement of the filter at SNR levels rangingfrom -5 to 30dB, in 5dB steps, using additive noise. For a clinical evaluation,the error between the estimated QT-intervals of the original and filteredsignals is measured and compared with the benchmark filter. Results: It isshown that the proposed GP filter outperforms the benchmark filter for all thetested noise levels. It also outperforms the state-of-the-art filter in termsof QT-interval estimation error bias and variance. Conclusion: The proposed GPfilter is a versatile technique for preprocessing the ECG in clinical andresearch applications, is applicable to ECG of arbitrary lengths and samplingfrequencies, and provides confidence intervals for its performance.</description><author>Mircea Dumitru, Qiao Li, Erick Andres Perez Alday, Ali Bahrami Rad, Gari D. Clifford, Reza Sameni</author><pubDate>Tue, 09 Jan 2024 16:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.02607v2</guid></item><item><title>FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning</title><link>http://arxiv.org/abs/2309.08420v6</link><description>Cross-domain Sequential Recommendation (CSR) which leverages user sequencedata from multiple domains has received extensive attention in recent years.However, the existing CSR methods require sharing origin user data acrossdomains, which violates the General Data Protection Regulation (GDPR). Thus, itis necessary to combine federated learning (FL) and CSR to fully utilizeknowledge from different domains while preserving data privacy. Nonetheless,the sequence feature heterogeneity across different domains significantlyimpacts the overall performance of FL. In this paper, we propose FedDCSR, anovel federated cross-domain sequential recommendation framework viadisentangled representation learning. Specifically, to address the sequencefeature heterogeneity across domains, we introduce an approach calledinter-intra domain sequence representation disentanglement (SRD) to disentanglethe user sequence features into domain-shared and domain-exclusive features. Inaddition, we design an intra domain contrastive infomax (CIM) strategy to learnricher domain-exclusive features of users by performing data augmentation onuser sequences. Extensive experiments on three real-world scenarios demonstratethat FedDCSR achieves significant improvements over existing baselines.</description><author>Hongyu Zhang, Dongyi Zheng, Xu Yang, Jiyuan Feng, Qing Liao</author><pubDate>Tue, 09 Jan 2024 16:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08420v6</guid></item><item><title>Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models</title><link>http://arxiv.org/abs/2401.04658v1</link><description>Linear attention is an efficient attention mechanism that has recentlyemerged as a promising alternative to conventional softmax attention. With itsability to process tokens in linear computational complexities, linearattention, in theory, can handle sequences of unlimited length withoutsacrificing speed, i.e., maintaining a constant training speed for varioussequence lengths with a fixed memory consumption. However, due to the issuewith cumulative summation (cumsum), current linear attention algorithms cannotdemonstrate their theoretical advantage in a causal setting. In this paper, wepresent Lightning Attention-2, the first linear attention implementation thatenables linear attention to realize its theoretical computational benefits. Toachieve this, we leverage the thought of tiling, separately handling theintra-block and inter-block components in linear attention calculation.Specifically, we utilize the conventional attention computation mechanism forthe intra-blocks and apply linear attention kernel tricks for the inter-blocks.A tiling technique is adopted through both forward and backward procedures totake full advantage of the GPU hardware. We implement our algorithm in Tritonto make it IO-aware and hardware-friendly. Various experiments are conducted ondifferent model sizes and sequence lengths. Lightning Attention-2 retainsconsistent training and inference speed regardless of input sequence length andis significantly faster than other attention mechanisms. The source code isavailable at https://github.com/OpenNLPLab/lightning-attention.</description><author>Zhen Qin, Weigao Sun, Dong Li, Xuyang Shen, Weixuan Sun, Yiran Zhong</author><pubDate>Tue, 09 Jan 2024 16:27:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04658v1</guid></item><item><title>DepressionEmo: A novel dataset for multilabel classification of depression emotions</title><link>http://arxiv.org/abs/2401.04655v1</link><description>Emotions are integral to human social interactions, with diverse responseselicited by various situational contexts. Particularly, the prevalence ofnegative emotional states has been correlated with negative outcomes for mentalhealth, necessitating a comprehensive analysis of their occurrence and impacton individuals. In this paper, we introduce a novel dataset named DepressionEmodesigned to detect 8 emotions associated with depression by 6037 examples oflong Reddit user posts. This dataset was created through a majority vote overinputs by zero-shot classifications from pre-trained models and validating thequality by annotators and ChatGPT, exhibiting an acceptable level of interraterreliability between annotators. The correlation between emotions, theirdistribution over time, and linguistic analysis are conducted on DepressionEmo.Besides, we provide several text classification methods classified into twogroups: machine learning methods such as SVM, XGBoost, and Light GBM; and deeplearning methods such as BERT, GAN-BERT, and BART. The pretrained BART model,bart-base allows us to obtain the highest F1- Macro of 0.76, showing itsoutperformance compared to other methods evaluated in our analysis. Across allemotions, the highest F1-Macro value is achieved by suicide intent, indicatinga certain value of our dataset in identifying emotions in individuals withdepression symptoms through text analysis. The curated dataset is publiclyavailable at: https://github.com/abuBakarSiddiqurRahman/DepressionEmo.</description><author>Abu Bakar Siddiqur Rahman, Hoang-Thang Ta, Lotfollah Najjar, Azad Azadmanesh, Ali Saffet Gönül</author><pubDate>Tue, 09 Jan 2024 16:25:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04655v1</guid></item><item><title>Learning to Prompt Segment Anything Models</title><link>http://arxiv.org/abs/2401.04651v1</link><description>Segment Anything Models (SAMs) like SEEM and SAM have demonstrated greatpotential in learning to segment anything. The core design of SAMs lies withPromptable Segmentation, which takes a handcrafted prompt as input and returnsthe expected segmentation mask. SAMs work with two types of prompts includingspatial prompts (e.g., points) and semantic prompts (e.g., texts), which worktogether to prompt SAMs to segment anything on downstream datasets. Despite theimportant role of prompts, how to acquire suitable prompts for SAMs is largelyunder-explored. In this work, we examine the architecture of SAMs and identifytwo challenges for learning effective prompts for SAMs. To this end, we proposespatial-semantic prompt learning (SSPrompt) that learns effective semantic andspatial prompts for better SAMs. Specifically, SSPrompt introduces spatialprompt learning and semantic prompt learning, which optimize spatial promptsand semantic prompts directly over the embedding space and selectively leveragethe knowledge encoded in pre-trained prompt encoders. Extensive experimentsshow that SSPrompt achieves superior image segmentation performanceconsistently across multiple widely adopted datasets.</description><author>Jiaxing Huang, Kai Jiang, Jingyi Zhang, Han Qiu, Lewei Lu, Shijian Lu, Eric Xing</author><pubDate>Tue, 09 Jan 2024 16:24:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04651v1</guid></item><item><title>Multigrid-Augmented Deep Learning Preconditioners for the Helmholtz Equation using Compact Implicit Layers</title><link>http://arxiv.org/abs/2306.17486v2</link><description>We present a deep learning-based iterative approach to solve the discreteheterogeneous Helmholtz equation for high wavenumbers. Combining classicaliterative multigrid solvers and convolutional neural networks (CNNs) viapreconditioning, we obtain a learned neural solver that is faster and scalesbetter than a standard multigrid solver. Our approach offers three maincontributions over previous neural methods of this kind. First, we construct amultilevel U-Net-like encoder-solver CNN with an implicit layer on the coarsestgrid of the U-Net, where convolution kernels are inverted. This alleviates thefield of view problem in CNNs and allows better scalability. Second, we improveupon the previous CNN preconditioner in terms of the number of parameters,computation time, and convergence rates. Third, we propose a multiscaletraining approach that enables the network to scale to problems of previouslyunseen dimensions while still maintaining a reasonable training procedure. Ourencoder-solver architecture can be used to generalize over different slownessmodels of various difficulties and is efficient at solving for many right-handsides per slowness model. We demonstrate the benefits of our novel architecturewith numerical experiments on a variety of heterogeneous two-dimensionalproblems at high wavenumbers.</description><author>Bar Lerer, Ido Ben-Yair, Eran Treister</author><pubDate>Tue, 09 Jan 2024 16:23:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17486v2</guid></item><item><title>Unpaired Image Translation to Mitigate Domain Shift in Liquid Argon Time Projection Chamber Detector Responses</title><link>http://arxiv.org/abs/2304.12858v3</link><description>Deep learning algorithms often are trained and deployed on differentdatasets. Any systematic difference between the training and a test dataset maydegrade the algorithm performance--what is known as the domain shift problem.This issue is prevalent in many scientific domains where algorithms are trainedon simulated data but applied to real-world datasets. Typically, the domainshift problem is solved through various domain adaptation methods. However,these methods are often tailored for a specific downstream task and may noteasily generalize to different tasks. This work explores the feasibility ofusing an alternative way to solve the domain shift problem that is not specificto any downstream algorithm. The proposed approach relies on modern UnpairedImage-to-Image translation techniques, designed to find translations betweendifferent image domains in a fully unsupervised fashion. In this study, theapproach is applied to a domain shift problem commonly encountered in LiquidArgon Time Projection Chamber (LArTPC) detector research when seeking a way totranslate samples between two differently distributed detector datasetsdeterministically. This translation allows for mapping real-world data into thesimulated data domain where the downstream algorithms can be run with much lessdomain-shift-related degradation. Conversely, using the translation from thesimulated data in a real-world domain can increase the realism of the simulateddataset and reduce the magnitude of any systematic uncertainties. We adaptedseveral UI2I translation algorithms to work on scientific data and demonstratedthe viability of these techniques for solving the domain shift problem withLArTPC detector data. To facilitate further development of domain adaptationtechniques for scientific datasets, the "Simple Liquid-Argon Track Samples"dataset used in this study also is published.</description><author>Yi Huang, Dmitrii Torbunov, Brett Viren, Haiwang Yu, Jin Huang, Meifeng Lin, Yihui Ren</author><pubDate>Tue, 09 Jan 2024 16:22:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12858v3</guid></item><item><title>Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination</title><link>http://arxiv.org/abs/2311.02960v2</link><description>Over the past decade, deep learning has proven to be a highly effective toolfor learning meaningful features from raw data. However, it remains an openquestion how deep networks perform hierarchical feature learning across layers.In this work, we attempt to unveil this mystery by investigating the structuresof intermediate features. Motivated by our empirical findings that linearlayers mimic the roles of deep layers in nonlinear networks for featurelearning, we explore how deep linear networks transform input data into outputby investigating the output (i.e., features) of each layer after training inthe context of multi-class classification problems. Toward this goal, we firstdefine metrics to measure within-class compression and between-classdiscrimination of intermediate features, respectively. Through theoreticalanalysis of these two metrics, we show that the evolution of features follows asimple and quantitative pattern from shallow to deep layers when the input datais nearly orthogonal and the network weights are minimum-norm, balanced, andapproximate low-rank: Each layer of the linear network progressively compresseswithin-class features at a geometric rate and discriminates between-classfeatures at a linear rate with respect to the number of layers that data havepassed through. To the best of our knowledge, this is the first quantitativecharacterization of feature evolution in hierarchical representations of deeplinear networks. Empirically, our extensive experiments not only validate ourtheoretical results numerically but also reveal a similar pattern in deepnonlinear networks which aligns well with recent empirical studies. Moreover,we demonstrate the practical implications of our results in transfer learning.Our code is available at \url{https://github.com/Heimine/PNC_DLN}.</description><author>Peng Wang, Xiao Li, Can Yaras, Zhihui Zhu, Laura Balzano, Wei Hu, Qing Qu</author><pubDate>Tue, 09 Jan 2024 16:16:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02960v2</guid></item><item><title>A novel framework for generalization of deep hidden physics models</title><link>http://arxiv.org/abs/2401.04648v1</link><description>Modelling of systems where the full system information is unknown is an oftencountered problem for various engineering and industrial applications, asit's either impossible to consider all the complex physics involved or simplermodels are considered to keep within the limits of the available resources.Recent advances in greybox modelling like the deep hidden physics modelsaddress this space by combining data and physics. However, for most real-lifeapplications, model generalizability is a key issue, as retraining a model forevery small change in system inputs and parameters or modification in domainconfiguration can render the model economically unviable. In this work wepresent a novel enhancement to the idea of hidden physics models which cangeneralize for changes in system inputs, parameters and domains. We also showthat this approach holds promise in system discovery as well and helps learnthe hidden physics for the changed system inputs, parameters and domainconfiguration.</description><author>Vijay Kag, Birupaksha Pal</author><pubDate>Tue, 09 Jan 2024 16:16:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04648v1</guid></item><item><title>Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks</title><link>http://arxiv.org/abs/2401.04647v1</link><description>This paper presents a novel concept learning framework for enhancing modelinterpretability and performance in visual classification tasks. Our approachappends an unsupervised explanation generator to the primary classifier networkand makes use of adversarial training. During training, the explanation moduleis optimized to extract visual concepts from the classifier's latentrepresentations, while the GAN-based module aims to discriminate imagesgenerated from concepts, from true images. This joint training scheme enablesthe model to implicitly align its internally learned concepts withhuman-interpretable visual properties. Comprehensive experiments demonstratethe robustness of our approach, while producing coherent concept activations.We analyse the learned concepts, showing their semantic concordance with objectparts and visual attributes. We also study how perturbations in the adversarialtraining protocol impact both classification and concept acquisition. Insummary, this work presents a significant step towards building inherentlyinterpretable deep vision models with task-aligned concept representations - akey enabler for developing trustworthy AI for real-world perception tasks.</description><author>Tanmay Garg, Deepika Vemuri, Vineeth N Balasubramanian</author><pubDate>Tue, 09 Jan 2024 16:16:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04647v1</guid></item><item><title>Clarify Confused Nodes Through Separated Learning</title><link>http://arxiv.org/abs/2306.02285v2</link><description>Graph neural networks (GNNs) have achieved remarkable advances ingraph-oriented tasks. However, real-world graphs invariably contain a certainproportion of heterophilous nodes, challenging the homophily assumption ofclassical GNNs and hindering their performance. Most existing studies continueto design generic models with shared weights between heterophilous andhomophilous nodes. Despite the incorporation of high-order messages ormulti-channel architectures, these efforts often fall short. A minority ofstudies attempt to train different node groups separately but suffer frominappropriate separation metrics and low efficiency. In this paper, we firstpropose a new metric, termed Neighborhood Confusion (NC), to facilitate a morereliable separation of nodes. We observe that node groups with different levelsof NC values exhibit certain differences in intra-group accuracy and visualizedembeddings. These pave the way for Neighborhood Confusion-guided GraphConvolutional Network (NCGCN), in which nodes are grouped by their NC valuesand accept intra-group weight sharing and message passing. Extensiveexperiments on both homophilous and heterophilous benchmarks demonstrate thatour framework can effectively separate nodes and yield significant performanceimprovement compared to the latest methods. The source code will be releasedsoon.</description><author>Jiajun Zhou, Shengbo Gong, Chenxuan Xie, Shanqing Yu, Qi Xuan, Xiaoniu Yang</author><pubDate>Tue, 09 Jan 2024 16:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02285v2</guid></item><item><title>Masked Modeling for Self-supervised Representation Learning on Vision and Beyond</title><link>http://arxiv.org/abs/2401.00897v2</link><description>As the deep learning revolution marches on, self-supervised learning hasgarnered increasing attention in recent years thanks to its remarkablerepresentation learning ability and the low dependence on labeled data. Amongthese varied self-supervised techniques, masked modeling has emerged as adistinctive approach that involves predicting parts of the original data thatare proportionally masked during training. This paradigm enables deep models tolearn robust representations and has demonstrated exceptional performance inthe context of computer vision, natural language processing, and othermodalities. In this survey, we present a comprehensive review of the maskedmodeling framework and its methodology. We elaborate on the details oftechniques within masked modeling, including diverse masking strategies,recovering targets, network architectures, and more. Then, we systematicallyinvestigate its wide-ranging applications across domains. Furthermore, we alsoexplore the commonalities and differences between masked modeling methods indifferent fields. Toward the end of this paper, we conclude by discussing thelimitations of current techniques and point out several potential avenues foradvancing masked modeling research. A paper list project with this survey isavailable at \url{https://github.com/Lupin1998/Awesome-MIM}.</description><author>Siyuan Li, Luyuan Zhang, Zedong Wang, Di Wu, Lirong Wu, Zicheng Liu, Jun Xia, Cheng Tan, Yang Liu, Baigui Sun, Stan Z. Li</author><pubDate>Tue, 09 Jan 2024 16:09:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00897v2</guid></item><item><title>Applying Large Language Models API to Issue Classification Problem</title><link>http://arxiv.org/abs/2401.04637v1</link><description>Effective prioritization of issue reports is crucial in software engineeringto optimize resource allocation and address critical problems promptly.However, the manual classification of issue reports for prioritization islaborious and lacks scalability. Alternatively, many open source software (OSS)projects employ automated processes for this task, albeit relying onsubstantial datasets for adequate training. This research seeks to devise anautomated approach that ensures reliability in issue prioritization, even whentrained on smaller datasets. Our proposed methodology harnesses the power ofGenerative Pre-trained Transformers (GPT), recognizing their potential toefficiently handle this task. By leveraging the capabilities of such models, weaim to develop a robust system for prioritizing issue reports accurately,mitigating the necessity for extensive training data while maintainingreliability. In our research, we have developed a reliable GPT-based approachto accurately label and prioritize issue reports with a reduced trainingdataset. By reducing reliance on massive data requirements and focusing onfew-shot fine-tuning, our methodology offers a more accessible and efficientsolution for issue prioritization in software engineering. Our model predictedissue types in individual projects up to 93.2% in precision, 95% in recall, and89.3% in F1-score.</description><author>Gabriel Aracena, Kyle Luster, Fabio Santos, Igor Steinmacher, Marco A. Gerosa</author><pubDate>Tue, 09 Jan 2024 16:05:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04637v1</guid></item><item><title>Convergence of stochastic gradient descent schemes for Lojasiewicz-landscapes</title><link>http://arxiv.org/abs/2102.09385v3</link><description>In this article, we consider convergence of stochastic gradient descentschemes (SGD), including momentum stochastic gradient descent (MSGD), underweak assumptions on the underlying landscape. More explicitly, we show that onthe event that the SGD stays bounded we have convergence of the SGD if there isonly a countable number of critical points or if the objective functionsatisfies Lojasiewicz-inequalities around all critical levels as all analyticfunctions do. In particular, we show that for neural networks with analyticactivation function such as softplus, sigmoid and the hyperbolic tangent, SGDconverges on the event of staying bounded, if the random variables modellingthe signal and response in the training are compactly supported.</description><author>Steffen Dereich, Sebastian Kassing</author><pubDate>Tue, 09 Jan 2024 16:01:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2102.09385v3</guid></item><item><title>Hypercomplex neural network in time series forecasting of stock data</title><link>http://arxiv.org/abs/2401.04632v1</link><description>The three classes of architectures for time series prediction were tested.They differ by input layers which contain either convolutional, LSTM, or densehypercomplex layers for 4D algebras. The input was four related Stock Markettime series, and the prediction of one of them is expected. The optimization ofhyperparameters related to the classes of architectures was performed in orderto compare the best neural networks within the class. The results show that inmost cases, the architecture with a hypercomplex dense layer provides similarMAE accuracy to other architectures, however, with considerably less trainableparameters. Thanks to it, hypercomplex neural networks can be learned andprocess data faster than the other tested architectures. Moreover, the order ofthe input time series has an impact on effectively.</description><author>Radosław Kycia, Agnieszka Niemczynowicz</author><pubDate>Tue, 09 Jan 2024 15:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04632v1</guid></item><item><title>Deep Reinforcement Multi-agent Learning framework for Information Gathering with Local Gaussian Processes for Water Monitoring</title><link>http://arxiv.org/abs/2401.04631v1</link><description>The conservation of hydrological resources involves continuously monitoringtheir contamination. A multi-agent system composed of autonomous surfacevehicles is proposed in this paper to efficiently monitor the water quality. Toachieve a safe control of the fleet, the fleet policy should be able to actbased on measurements and to the the fleet state. It is proposed to use LocalGaussian Processes and Deep Reinforcement Learning to jointly obtain effectivemonitoring policies. Local Gaussian processes, unlike classical global Gaussianprocesses, can accurately model the information in a dissimilar spatialcorrelation which captures more accurately the water quality information. ADeep convolutional policy is proposed, that bases the decisions on theobservation on the mean and variance of this model, by means of an informationgain reward. Using a Double Deep Q-Learning algorithm, agents are trained tominimize the estimation error in a safe manner thanks to a Consensus-basedheuristic. Simulation results indicate an improvement of up to 24% in terms ofthe mean absolute error with the proposed models. Also, training results with1-3 agents indicate that our proposed approach returns 20% and 24% smalleraverage estimation errors for, respectively, monitoring water quality variablesand monitoring algae blooms, as compared to state-of-the-art approaches</description><author>Samuel Yanes Luis, Dmitriy Shutin, Juan Marchal Gómez, Daniel Gutiérrez Reina, Sergio Toral Marín</author><pubDate>Tue, 09 Jan 2024 15:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04631v1</guid></item><item><title>Multi-Neuron Representations of Hierarchical Concepts in Spiking Neural Networks</title><link>http://arxiv.org/abs/2401.04628v1</link><description>We describe how hierarchical concepts can be represented in three types oflayered neural networks. The aim is to support recognition of the concepts whenpartial information about the concepts is presented, and also when some of theneurons in the network might fail. Our failure model involves initial randomfailures. The three types of networks are: feed-forward networks with highconnectivity, feed-forward networks with low connectivity, and layered networkswith low connectivity and with both forward edges and "lateral" edges withinlayers. In order to achieve fault-tolerance, the representations all usemultiple representative neurons for each concept. We show how recognition canwork in all three of these settings, and quantify how the probability ofcorrect recognition depends on several parameters, including the number ofrepresentatives and the neuron failure probability. We also discuss how theserepresentations might be learned, in all three types of networks. For thefeed-forward networks, the learning algorithms are similar to ones used in [4],whereas for networks with lateral edges, the algorithms are generally inspiredby work on the assembly calculus [3, 6, 7].</description><author>Nancy A. Lynch</author><pubDate>Tue, 09 Jan 2024 15:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04628v1</guid></item><item><title>Online Laplace Model Selection Revisited</title><link>http://arxiv.org/abs/2307.06093v2</link><description>The Laplace approximation provides a closed-form model selection objectivefor neural networks (NN). Online variants, which optimise NN parameters jointlywith hyperparameters, like weight decay strength, have seen renewed interest inthe Bayesian deep learning community. However, these methods violate Laplace'smethod's critical assumption that the approximation is performed around a modeof the loss, calling into question their soundness. This work re-derives onlineLaplace methods, showing them to target a variational bound on a mode-correctedvariant of the Laplace evidence which does not make stationarity assumptions.Online Laplace and its mode-corrected counterpart share stationary points where1. the NN parameters are a maximum a posteriori, satisfying the Laplacemethod's assumption, and 2. the hyperparameters maximise the Laplace evidence,motivating online methods. We demonstrate that these optima are roughlyattained in practise by online algorithms using full-batch gradient descent onUCI regression datasets. The optimised hyperparameters prevent overfitting andoutperform validation-based early stopping.</description><author>Jihao Andreas Lin, Javier Antorán, José Miguel Hernández-Lobato</author><pubDate>Tue, 09 Jan 2024 15:49:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06093v2</guid></item><item><title>A Primer on Temporal Graph Learning</title><link>http://arxiv.org/abs/2401.03988v2</link><description>This document aims to familiarize readers with temporal graph learning (TGL)through a concept-first approach. We have systematically presented vitalconcepts essential for understanding the workings of a TGL framework. Inaddition to qualitative explanations, we have incorporated mathematicalformulations where applicable, enhancing the clarity of the text. Since TGLinvolves temporal and spatial learning, we introduce relevant learningarchitectures ranging from recurrent and convolutional neural networks totransformers and graph neural networks. We also discuss classical time seriesforecasting methods to inspire interpretable learning solutions for TGL.</description><author>Aniq Ur Rahman, Justin P. Coon</author><pubDate>Tue, 09 Jan 2024 15:47:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03988v2</guid></item><item><title>DebugBench: Evaluating Debugging Capability of Large Language Models</title><link>http://arxiv.org/abs/2401.04621v1</link><description>Large Language Models (LLMs) have demonstrated exceptional coding capability.However, as another critical component of programming proficiency, thedebugging capability of LLMs remains relatively unexplored. Previousevaluations of LLMs' debugging ability are significantly limited by the risk ofdata leakage, the scale of the dataset, and the variety of tested bugs. Toovercome these deficiencies, we introduce `DebugBench', an LLM debuggingbenchmark consisting of 4,253 instances. It covers four major bug categoriesand 18 minor types in C++, Java, and Python. To construct DebugBench, wecollect code snippets from the LeetCode community, implant bugs into sourcedata with GPT-4, and assure rigorous quality checks. We evaluate two commercialand three open-source models in a zero-shot scenario. We find that (1) whileclosed-source models like GPT-4 exhibit inferior debugging performance comparedto humans, open-source models such as Code Llama fail to attain any pass ratescores; (2) the complexity of debugging notably fluctuates depending on the bugcategory; (3) incorporating runtime feedback has a clear impact on debuggingperformance which is not always helpful. As an extension, we also compare LLMdebugging and code generation, revealing a strong correlation between them forclosed-source models. These findings will benefit the development of LLMs indebugging.</description><author>Runchu Tian, Yining Ye, Yujia Qin, Xin Cong, Yankai Lin, Zhiyuan Liu, Maosong Sun</author><pubDate>Tue, 09 Jan 2024 15:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04621v1</guid></item><item><title>Agent Alignment in Evolving Social Norms</title><link>http://arxiv.org/abs/2401.04620v1</link><description>Agents based on Large Language Models (LLMs) are increasingly permeatingvarious domains of human production and life, highlighting the importance ofaligning them with human values. The current alignment of AI systems primarilyfocuses on passively aligning LLMs through human intervention. However, agentspossess characteristics like receiving environmental feedback andself-evolution, rendering the LLM alignment methods inadequate. In response, wepropose an evolutionary framework for agent evolution and alignment, namedEvolutionaryAgent, which transforms agent alignment into a process of evolutionand selection under the principle of survival of the fittest. In an environmentwhere social norms continuously evolve, agents better adapted to the currentsocial norms will have a higher probability of survival and proliferation,while those inadequately aligned dwindle over time. Experimental resultsassessing the agents from multiple perspectives in aligning with social normsdemonstrate that EvolutionaryAgent possesses the capability to alignprogressively better with the evolving social norms while maintaining itsproficiency in general tasks. Effectiveness tests conducted on various open andclosed-source LLMs as the foundation for agents also prove the applicability ofour approach.</description><author>Shimin Li, Tianxiang Sun, Xipeng Qiu</author><pubDate>Tue, 09 Jan 2024 15:44:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04620v1</guid></item><item><title>Language Detection for Transliterated Content</title><link>http://arxiv.org/abs/2401.04619v1</link><description>In the contemporary digital era, the Internet functions as an unparalleledcatalyst, dismantling geographical and linguistic barriers particularly evidentin texting. This evolution facilitates global communication, transcendingphysical distances and fostering dynamic cultural exchange. A notable trend isthe widespread use of transliteration, where the English alphabet is employedto convey messages in native languages, posing a unique challenge for languagetechnology in accurately detecting the source language. This paper addressesthis challenge through a dataset of phone text messages in Hindi and Russiantransliterated into English utilizing BERT for language classification andGoogle Translate API for transliteration conversion. The research pioneersinnovative approaches to identify and convert transliterated text, navigatingchallenges in the diverse linguistic landscape of digital communication.Emphasizing the pivotal role of comprehensive datasets for training LargeLanguage Models LLMs like BERT, our model showcases exceptional proficiency inaccurately identifying and classifying languages from transliterated text. Witha validation accuracy of 99% our models robust performance underscores itsreliability. The comprehensive exploration of transliteration dynamicssupported by innovative approaches and cutting edge technologies like BERT,positions our research at the forefront of addressing unique challenges in thelinguistic landscape of digital communication. Beyond contributing to languageidentification and transliteration capabilities this work holds promise forapplications in content moderation, analytics and fostering a globallyconnected community engaged in meaningful dialogue.</description><author>Selva Kumar S, Afifah Khan Mohammed Ajmal Khan, Chirag Manjeshwar, Imadh Ajaz Banday</author><pubDate>Tue, 09 Jan 2024 15:40:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04619v1</guid></item><item><title>Generic Knowledge Boosted Pre-training For Remote Sensing Images</title><link>http://arxiv.org/abs/2401.04614v1</link><description>Deep learning models are essential for scene classification, changedetection, land cover segmentation, and other remote sensing imageunderstanding tasks. Most backbones of existing remote sensing deep learningmodels are typically initialized by pre-trained weights obtained from ImageNetpre-training (IMP). However, domain gaps exist between remote sensing imagesand natural images (e.g., ImageNet), making deep learning models initialized bypre-trained weights of IMP perform poorly for remote sensing imageunderstanding. Although some pre-training methods are studied in the remotesensing community, current remote sensing pre-training methods face the problemof vague generalization by only using remote sensing images. In this paper, wepropose a novel remote sensing pre-training framework, Generic KnowledgeBoosted Remote Sensing Pre-training (GeRSP), to learn robust representationsfrom remote sensing and natural images for remote sensing understanding tasks.GeRSP contains two pre-training branches: (1) A self-supervised pre-trainingbranch is adopted to learn domain-related representations from unlabeled remotesensing images. (2) A supervised pre-training branch is integrated into GeRSPfor general knowledge learning from labeled natural images. Moreover, GeRSPcombines two pre-training branches using a teacher-student architecture tosimultaneously learn representations with general and special knowledge, whichgenerates a powerful pre-trained model for deep learning model initialization.Finally, we evaluate GeRSP and other remote sensing pre-training methods onthree downstream tasks, i.e., object detection, semantic segmentation, andscene classification. The extensive experimental results consistentlydemonstrate that GeRSP can effectively learn robust representations in aunified manner, improving the performance of remote sensing downstream tasks.</description><author>Ziyue Huang, Mingming Zhang, Yuan Gong, Qingjie Liu, Yunhong Wang</author><pubDate>Tue, 09 Jan 2024 15:36:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04614v1</guid></item><item><title>A Comprehensive Study of Knowledge Editing for Large Language Models</title><link>http://arxiv.org/abs/2401.01286v3</link><description>Large Language Models (LLMs) have shown extraordinary capabilities inunderstanding and generating text that closely mirrors human communication.However, a primary limitation lies in the significant computational demandsduring training, arising from their extensive parameterization. This challengeis further intensified by the dynamic nature of the world, necessitatingfrequent updates to LLMs to correct outdated information or integrate newknowledge, thereby ensuring their continued relevance. Note that manyapplications demand continual model adjustments post-training to addressdeficiencies or undesirable behaviors. There is an increasing interest inefficient, lightweight methods for on-the-fly model modifications. To this end,recent years have seen a burgeoning in the techniques of knowledge editing forLLMs, which aim to efficiently modify LLMs' behaviors within specific domainswhile preserving overall performance across various inputs. In this paper, wefirst define the knowledge editing problem and then provide a comprehensivereview of cutting-edge approaches. Drawing inspiration from educational andcognitive research theories, we propose a unified categorization criterion thatclassifies knowledge editing methods into three groups: resorting to externalknowledge, merging knowledge into the model, and editing intrinsic knowledge.Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensiveempirical evaluation of representative knowledge editing approaches.Additionally, we provide an in-depth analysis of knowledge location, which cangive a deeper understanding of the knowledge structures inherent within LLMs.Finally, we discuss several potential applications of knowledge editing,outlining its broad and impactful implications.</description><author>Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, Siyuan Cheng, Ziwen Xu, Xin Xu, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, Huajun Chen</author><pubDate>Tue, 09 Jan 2024 15:34:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01286v3</guid></item><item><title>Distribution-Free Conformal Joint Prediction Regions for Neural Marked Temporal Point Processes</title><link>http://arxiv.org/abs/2401.04612v1</link><description>Sequences of labeled events observed at irregular intervals in continuoustime are ubiquitous across various fields. Temporal Point Processes (TPPs)provide a mathematical framework for modeling these sequences, enablinginferences such as predicting the arrival time of future events and theirassociated label, called mark. However, due to model misspecification or lackof training data, these probabilistic models may provide a poor approximationof the true, unknown underlying process, with prediction regions extracted fromthem being unreliable estimates of the underlying uncertainty. This paperdevelops more reliable methods for uncertainty quantification in neural TPPmodels via the framework of conformal prediction. A primary objective is togenerate a distribution-free joint prediction region for the arrival time andmark, with a finite-sample marginal coverage guarantee. A key challenge is tohandle both a strictly positive, continuous response and a categoricalresponse, without distributional assumptions. We first consider a simple butoverly conservative approach that combines individual prediction regions forthe event arrival time and mark. Then, we introduce a more effective methodbased on bivariate highest density regions derived from the joint predictivedensity of event arrival time and mark. By leveraging the dependencies betweenthese two variables, this method exclude unlikely combinations of the two,resulting in sharper prediction regions while still attaining the pre-specifiedcoverage level. We also explore the generation of individual univariateprediction regions for arrival times and marks through conformal regression andclassification techniques. Moreover, we investigate the stronger notion ofconditional coverage. Finally, through extensive experimentation on bothsimulated and real-world datasets, we assess the validity and efficiency ofthese methods.</description><author>Victor Dheur, Tanguy Bosser, Rafael Izbicki, Souhaib Ben Taieb</author><pubDate>Tue, 09 Jan 2024 15:28:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04612v1</guid></item><item><title>EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2401.04608v1</link><description>Recent years have witnessed remarkable progress in image generation task,where users can create visually astonishing images with high-quality. However,existing text-to-image diffusion models are proficient in generating concreteconcepts (dogs) but encounter challenges with more abstract ones (emotions).Several efforts have been made to modify image emotions with color and styleadjustments, facing limitations in effectively conveying emotions with fixedimage contents. In this work, we introduce Emotional Image Content Generation(EICG), a new task to generate semantic-clear and emotion-faithful images givenemotion categories. Specifically, we propose an emotion space and construct amapping network to align it with the powerful Contrastive Language-ImagePre-training (CLIP) space, providing a concrete interpretation of abstractemotions. Attribute loss and emotion confidence are further proposed to ensurethe semantic diversity and emotion fidelity of the generated images. Our methodoutperforms the state-of-the-art text-to-image approaches both quantitativelyand qualitatively, where we derive three custom metrics, i.e., emotionaccuracy, semantic clarity and semantic diversity. In addition to generation,our method can help emotion understanding and inspire emotional art design.</description><author>Jingyuan Yang, Jiawei Feng, Hui Huang</author><pubDate>Tue, 09 Jan 2024 15:23:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04608v1</guid></item><item><title>Adaptive FSS: A Novel Few-Shot Segmentation Framework via Prototype Enhancement</title><link>http://arxiv.org/abs/2312.15731v4</link><description>The Few-Shot Segmentation (FSS) aims to accomplish the novel classsegmentation task with a few annotated images. Current FSS research based onmeta-learning focus on designing a complex interaction mechanism between thequery and support feature. However, unlike humans who can rapidly learn newthings from limited samples, the existing approach relies solely on fixedfeature matching to tackle new tasks, lacking adaptability. In this paper, wepropose a novel framework based on the adapter mechanism, namely Adaptive FSS,which can efficiently adapt the existing FSS model to the novel classes. Indetail, we design the Prototype Adaptive Module (PAM), which utilizes accuratecategory information provided by the support set to derive class prototypes,enhancing class-specific information in the multi-stage representation. Inaddition, our approach is compatible with diverse FSS methods with differentbackbones by simply inserting PAM between the layers of the encoder.Experiments demonstrate that our method effectively improves the performance ofthe FSS models (e.g., MSANet, HDMNet, FPTrans, and DCAMA) and achieve newstate-of-the-art (SOTA) results (i.e., 72.4\% and 79.1\% mIoU on PASCAL-5$^i$1-shot and 5-shot settings, 52.7\% and 60.0\% mIoU on COCO-20$^i$ 1-shot and5-shot settings). Our code can be available athttps://github.com/jingw193/AdaptiveFSS.</description><author>Jing Wang, Jinagyun Li, Chen Chen, Yisi Zhang, Haoran Shen, Tianxiang Zhang</author><pubDate>Tue, 09 Jan 2024 14:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15731v4</guid></item><item><title>An Assessment on Comprehending Mental Health through Large Language Models</title><link>http://arxiv.org/abs/2401.04592v1</link><description>Mental health challenges pose considerable global burdens on individuals andcommunities. Recent data indicates that more than 20% of adults may encounterat least one mental disorder in their lifetime. On the one hand, theadvancements in large language models have facilitated diverse applications,yet a significant research gap persists in understanding and enhancing thepotential of large language models within the domain of mental health. On theother hand, across various applications, an outstanding question involves thecapacity of large language models to comprehend expressions of human mentalhealth conditions in natural language. This study presents an initialevaluation of large language models in addressing this gap. Due to this, wecompare the performance of Llama-2 and ChatGPT with classical Machine as wellas Deep learning models. Our results on the DAIC-WOZ dataset show thattransformer-based models, like BERT or XLNet, outperform the large languagemodels.</description><author>Mihael Arcan, Paul-David Niland, Fionn Delahunty</author><pubDate>Tue, 09 Jan 2024 14:50:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04592v1</guid></item><item><title>WidthFormer: Toward Efficient Transformer-based BEV View Transformation</title><link>http://arxiv.org/abs/2401.03836v2</link><description>In this work, we present WidthFormer, a novel transformer-basedBird's-Eye-View (BEV) 3D detection method tailored for real-timeautonomous-driving applications. WidthFormer is computationally efficient,robust and does not require any special engineering effort to deploy. In thiswork, we propose a novel 3D positional encoding mechanism capable of accuratelyencapsulating 3D geometric information, which enables our model to generatehigh-quality BEV representations with only a single transformer decoder layer.This mechanism is also beneficial for existing sparse 3D object detectors.Inspired by the recently-proposed works, we further improve our model'sefficiency by vertically compressing the image features when serving asattention keys and values. We also introduce two modules to compensate forpotential information loss due to feature compression. Experimental evaluationon the widely-used nuScenes 3D object detection benchmark demonstrates that ourmethod outperforms previous approaches across different 3D detectionarchitectures. More importantly, our model is highly efficient. For example,when using $256\times 704$ input images, it achieves 1.5 ms and 2.8 ms latencyon NVIDIA 3090 GPU and Horizon Journey-5 edge computing chips, respectively.Furthermore, WidthFormer also exhibits strong robustness to different degreesof camera perturbations. Our study offers valuable insights into the deploymentof BEV transformation methods in real-world, complex road environments. Code isavailable at https://github.com/ChenhongyiYang/WidthFormer .</description><author>Chenhongyi Yang, Tianwei Lin, Lichao Huang, Elliot J. Crowley</author><pubDate>Tue, 09 Jan 2024 14:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03836v2</guid></item><item><title>Enhanced Distribution Alignment for Post-Training Quantization of Diffusion Models</title><link>http://arxiv.org/abs/2401.04585v1</link><description>Diffusion models have achieved great success in image generation tasksthrough iterative noise estimation. However, the heavy denoising process andcomplex neural networks hinder their low-latency applications in real-worldscenarios. Quantization can effectively reduce model complexity, andpost-training quantization (PTQ), which does not require fine-tuning, is highlypromising in accelerating the denoising process. Unfortunately, we find thatdue to the highly dynamic distribution of activations in different denoisingsteps, existing PTQ methods for diffusion models suffer from distributionmismatch issues at both calibration sample level and reconstruction outputlevel, which makes the performance far from satisfactory, especially in low-bitcases. In this paper, we propose Enhanced Distribution Alignment forPost-Training Quantization of Diffusion Models (EDA-DM) to address the aboveissues. Specifically, at the calibration sample level, we select calibrationsamples based on the density and diversity in the latent space, thusfacilitating the alignment of their distribution with the overall samples; andat the reconstruction output level, we propose Fine-grained BlockReconstruction, which can align the outputs of the quantized model and thefull-precision model at different network granularity. Extensive experimentsdemonstrate that EDA-DM outperforms the existing post-training quantizationframeworks in both unconditional and conditional generation scenarios. Atlow-bit precision, the quantized models with our method even outperform thefull-precision models on most datasets.</description><author>Xuewen Liu, Zhikai Li, Junrui Xiao, Qingyi Gu</author><pubDate>Tue, 09 Jan 2024 14:42:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04585v1</guid></item><item><title>Risk Assessment and Statistical Significance in the Age of Foundation Models</title><link>http://arxiv.org/abs/2310.07132v2</link><description>We propose a distributional framework for assessing socio-technical risks offoundation models with quantified statistical significance. Our approach hingeson a new statistical relative testing based on first and second orderstochastic dominance of real random variables. We show that the second orderstatistics in this test are linked to mean-risk models commonly used ineconometrics and mathematical finance to balance risk and utility when choosingbetween alternatives. Using this framework, we formally develop a risk-awareapproach for foundation model selection given guardrails quantified byspecified metrics. Inspired by portfolio optimization and selection theory inmathematical finance, we define a metrics portfolio for each model as a meansto aggregate a collection of metrics, and perform model selection based on thestochastic dominance of these portfolios. The statistical significance of ourtests is backed theoretically by an asymptotic analysis via central limittheorems instantiated in practice via a bootstrap variance estimate. We use ourframework to compare various large language models regarding risks related todrifting from instructions and outputting toxic content.</description><author>Apoorva Nitsure, Youssef Mroueh, Mattia Rigotti, Kristjan Greenewald, Brian Belgodere, Mikhail Yurochkin, Jiri Navratil, Igor Melnyk, Jerret Ross</author><pubDate>Tue, 09 Jan 2024 14:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07132v2</guid></item><item><title>A Deep Network for Explainable Prediction of Non-Imaging Phenotypes using Anatomical Multi-View Data</title><link>http://arxiv.org/abs/2401.04579v1</link><description>Large datasets often contain multiple distinct feature sets, or views, thatoffer complementary information that can be exploited by multi-view learningmethods to improve results. We investigate anatomical multi-view data, whereeach brain anatomical structure is described with multiple feature sets. Inparticular, we focus on sets of white matter microstructure and connectivityfeatures from diffusion MRI, as well as sets of gray matter area and thicknessfeatures from structural MRI. We investigate machine learning methodology thatapplies multi-view approaches to improve the prediction of non-imagingphenotypes, including demographics (age), motor (strength), and cognition(picture vocabulary). We present an explainable multi-view network (EMV-Net)that can use different anatomical views to improve prediction performance. Inthis network, each individual anatomical view is processed by a view-specificfeature extractor and the extracted information from each view is fused using alearnable weight. This is followed by a wavelet transform-based module toobtain complementary information across views which is then applied tocalibrate the view-specific information. Additionally, the calibrator producesan attention-based calibration score to indicate anatomical structures'importance for interpretation.</description><author>Yuxiang Wei, Yuqian Chen, Tengfei Xue, Leo Zekelman, Nikos Makris, Yogesh Rathi, Weidong Cai, Fan Zhang, Lauren J. O' Donnell</author><pubDate>Tue, 09 Jan 2024 14:33:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04579v1</guid></item><item><title>Effective pruning of web-scale datasets based on complexity of concept clusters</title><link>http://arxiv.org/abs/2401.04578v1</link><description>Utilizing massive web-scale datasets has led to unprecedented performancegains in machine learning models, but also imposes outlandish computerequirements for their training. In order to improve training and dataefficiency, we here push the limits of pruning large-scale multimodal datasetsfor training CLIP-style models. Today's most effective pruning method onImageNet clusters data samples into separate concepts according to theirembedding and prunes away the most prototypical samples. We scale this approachto LAION and improve it by noting that the pruning rate should beconcept-specific and adapted to the complexity of the concept. Using a simpleand intuitive complexity measure, we are able to reduce the training cost to aquarter of regular training. By filtering from the LAION dataset, we find thattraining on a smaller set of high-quality data can lead to higher performancewith significantly lower training costs. More specifically, we are able tooutperform the LAION-trained OpenCLIP-ViT-B32 model on ImageNet zero-shotaccuracy by 1.1p.p. while only using 27.7% of the data and training compute.Despite a strong reduction in training cost, we also see improvements onImageNet dist. shifts, retrieval tasks and VTAB. On the DataComp Mediumbenchmark, we achieve a new state-of-the-art ImageNet zero-shot accuracy and acompetitive average zero-shot accuracy on 38 evaluation tasks.</description><author>Amro Abbas, Evgenia Rusak, Kushal Tirumala, Wieland Brendel, Kamalika Chaudhuri, Ari S. Morcos</author><pubDate>Tue, 09 Jan 2024 14:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04578v1</guid></item><item><title>Masked Audio Generation using a Single Non-Autoregressive Transformer</title><link>http://arxiv.org/abs/2401.04577v1</link><description>We introduce MAGNeT, a masked generative sequence modeling method thatoperates directly over several streams of audio tokens. Unlike prior work,MAGNeT is comprised of a single-stage, non-autoregressive transformer. Duringtraining, we predict spans of masked tokens obtained from a masking scheduler,while during inference we gradually construct the output sequence using severaldecoding steps. To further enhance the quality of the generated audio, weintroduce a novel rescoring method in which, we leverage an externalpre-trained model to rescore and rank predictions from MAGNeT, which will bethen used for later decoding steps. Lastly, we explore a hybrid version ofMAGNeT, in which we fuse between autoregressive and non-autoregressive modelsto generate the first few seconds in an autoregressive manner while the rest ofthe sequence is being decoded in parallel. We demonstrate the efficiency ofMAGNeT for the task of text-to-music and text-to-audio generation and conductan extensive empirical evaluation, considering both objective metrics and humanstudies. The proposed approach is comparable to the evaluated baselines, whilebeing significantly faster (x7 faster than the autoregressive baseline).Through ablation studies and analysis, we shed light on the importance of eachof the components comprising MAGNeT, together with pointing to the trade-offsbetween autoregressive and non-autoregressive modeling, considering latency,throughput, and generation quality. Samples are available on our demo pagehttps://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT.</description><author>Alon Ziv, Itai Gat, Gael Le Lan, Tal Remez, Felix Kreuk, Alexandre Défossez, Jade Copet, Gabriel Synnaeve, Yossi Adi</author><pubDate>Tue, 09 Jan 2024 14:29:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04577v1</guid></item><item><title>Diverse super-resolution with pretrained deep hiererarchical VAEs</title><link>http://arxiv.org/abs/2205.10347v4</link><description>We investigate the problem of producing diverse solutions to an imagesuper-resolution problem. From a probabilistic perspective, this can be done bysampling from the posterior distribution of an inverse problem, which requiresthe definition of a prior distribution on the high-resolution images. In thiswork, we propose to use a pretrained hierarchical variational autoencoder(HVAE) as a prior. We train a lightweight stochastic encoder to encodelow-resolution images in the latent space of a pretrained HVAE. At inference,we combine the low-resolution encoder and the pretrained generative model tosuper-resolve an image. We demonstrate on the task of face super-resolutionthat our method provides an advantageous trade-off between the computationalefficiency of conditional normalizing flows techniques and the sample qualityof diffusion based methods.</description><author>Jean Prost, Antoine Houdard, Andrés Almansa, Nicolas Papadakis</author><pubDate>Tue, 09 Jan 2024 14:27:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.10347v4</guid></item><item><title>Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding</title><link>http://arxiv.org/abs/2401.04575v1</link><description>Vision and vision-language applications of neural networks, such as imageclassification and captioning, rely on large-scale annotated datasets thatrequire non-trivial data-collecting processes. This time-consuming endeavorhinders the emergence of large-scale datasets, limiting researchers andpractitioners to a small number of choices. Therefore, we seek more efficientways to collect and annotate images. Previous initiatives have gatheredcaptions from HTML alt-texts and crawled social media postings, but these datasources suffer from noise, sparsity, or subjectivity. For this reason, we turnto commercial shopping websites whose data meet three criteria: cleanliness,informativeness, and fluency. We introduce the Let's Go Shopping (LGS) dataset,a large-scale public dataset with 15 million image-caption pairs from publiclyavailable e-commerce websites. When compared with existing general-domaindatasets, the LGS images focus on the foreground object and have less complexbackgrounds. Our experiments on LGS show that the classifiers trained onexisting benchmark datasets do not readily generalize to e-commerce data, whilespecific self-supervised visual feature extractors can better generalize.Furthermore, LGS's high-quality e-commerce-focused images and bimodal naturemake it advantageous for vision-language bi-modal tasks: LGS enablesimage-captioning models to generate richer captions and helps text-to-imagegeneration models achieve e-commerce style transfer.</description><author>Yatong Bai, Utsav Garg, Apaar Shanker, Haoming Zhang, Samyak Parajuli, Erhan Bas, Isidora Filipovic, Amelia N. Chu, Eugenia D Fomitcheva, Elliot Branson, Aerin Kim, Somayeh Sojoudi, Kyunghyun Cho</author><pubDate>Tue, 09 Jan 2024 14:24:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04575v1</guid></item><item><title>Robust Imitation Learning for Automated Game Testing</title><link>http://arxiv.org/abs/2401.04572v1</link><description>Game development is a long process that involves many stages before a productis ready for the market. Human play testing is among the most time consuming,as testers are required to repeatedly perform tasks in the search for errors inthe code. Therefore, automated testing is seen as a key technology for thegaming industry, as it would dramatically improve development costs andefficiency. Toward this end, we propose EVOLUTE, a novel imitationlearning-based architecture that combines behavioural cloning (BC) with energybased models (EBMs). EVOLUTE is a two-stream ensemble model that splits theaction space of autonomous agents into continuous and discrete tasks. The EBMstream handles the continuous tasks, to have a more refined and adaptivecontrol, while the BC stream handles discrete actions, to ease training. Weevaluate the performance of EVOLUTE in a shooting-and-driving game, where theagent is required to navigate and continuously identify targets to attack. Theproposed model has higher generalisation capabilities than standard BCapproaches, showing a wider range of behaviours and higher performances. Also,EVOLUTE is easier to train than a pure end-to-end EBM model, as discrete taskscan be quite sparse in the dataset and cause model training to explore a muchwider set of possible actions while training.</description><author>Pierluigi Vito Amadori, Timothy Bradley, Ryan Spick, Guy Moss</author><pubDate>Tue, 09 Jan 2024 14:18:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04572v1</guid></item><item><title>An Automatic Cascaded Model for Hemorrhagic Stroke Segmentation and Hemorrhagic Volume Estimation</title><link>http://arxiv.org/abs/2401.04570v1</link><description>Hemorrhagic Stroke (HS) has a rapid onset and is a serious condition thatposes a great health threat. Promptly and accurately delineating the bleedingregion and estimating the volume of bleeding in Computer Tomography (CT) imagescan assist clinicians in treatment planning, leading to improved treatmentoutcomes for patients. In this paper, a cascaded 3D model is constructed basedon UNet to perform a two-stage segmentation of the hemorrhage area in CT imagesfrom rough to fine, and the hemorrhage volume is automatically calculated fromthe segmented area. On a dataset with 341 cases of hemorrhagic stroke CT scans,the proposed model provides high-quality segmentation outcome with higheraccuracy (DSC 85.66%) and better computation efficiency (6.2 second per sample)when compared to the traditional Tada formula with respect to hemorrhage volumeestimation.</description><author>Weijin Xu, Zhuang Sha, Huihua Yang, Rongcai Jiang, Zhanying Li, Wentao Liu, Ruisheng Su</author><pubDate>Tue, 09 Jan 2024 14:15:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04570v1</guid></item><item><title>A Discrete Particle Swarm Optimizer for the Design of Cryptographic Boolean Functions</title><link>http://arxiv.org/abs/2401.04567v1</link><description>A Particle Swarm Optimizer for the search of balanced Boolean functions withgood cryptographic properties is proposed in this paper. The algorithm is amodified version of the permutation PSO by Hu, Eberhart and Shi which preservesthe Hamming weight of the particles positions, coupled with the Hill Climbingmethod devised by Millan, Clark and Dawson to improve the nonlinearity anddeviation from correlation immunity of Boolean functions. The parameters forthe PSO velocity equation are tuned by means of two meta-optimizationtechniques, namely Local Unimodal Sampling (LUS) and Continuous GeneticAlgorithms (CGA), finding that CGA produces better results. Using theCGA-evolved parameters, the PSO algorithm is then run on the spaces of Booleanfunctions from $n=7$ to $n=12$ variables. The results of the experiments arereported, observing that this new PSO algorithm generates Boolean functionsfeaturing similar or better combinations of nonlinearity, correlation immunityand propagation criterion with respect to the ones obtained by otheroptimization methods.</description><author>Luca Mariot, Alberto Leporati, Luca Manzoni</author><pubDate>Tue, 09 Jan 2024 14:08:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04567v1</guid></item><item><title>Where Would I Go Next? Large Language Models as Human Mobility Predictors</title><link>http://arxiv.org/abs/2308.15197v2</link><description>Accurate human mobility prediction underpins many important applicationsacross a variety of domains, including epidemic modelling, transport planning,and emergency responses. Due to the sparsity of mobility data and thestochastic nature of people's daily activities, achieving precise predictionsof people's locations remains a challenge. While recently developed largelanguage models (LLMs) have demonstrated superior performance across numerouslanguage-related tasks, their applicability to human mobility studies remainsunexplored. Addressing this gap, this article delves into the potential of LLMsfor human mobility prediction tasks. We introduce a novel method, LLM-Mob,which leverages the language understanding and reasoning capabilities of LLMsfor analysing human mobility data. We present concepts of historical stays andcontext stays to capture both long-term and short-term dependencies in humanmovement and enable time-aware prediction by using time information of theprediction target. Additionally, we design context-inclusive prompts thatenable LLMs to generate more accurate predictions. Comprehensive evaluations ofour method reveal that LLM-Mob excels in providing accurate and interpretablepredictions, highlighting the untapped potential of LLMs in advancing humanmobility prediction techniques. We posit that our research marks a significantparadigm shift in human mobility modelling, transitioning from building complexdomain-specific models to harnessing general-purpose LLMs that yield accuratepredictions through language instructions. The code for this work is availableat https://github.com/xlwang233/LLM-Mob.</description><author>Xinglei Wang, Meng Fang, Zichao Zeng, Tao Cheng</author><pubDate>Tue, 09 Jan 2024 14:08:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15197v2</guid></item><item><title>Phase-shifted remote photoplethysmography for estimating heart rate and blood pressure from facial video</title><link>http://arxiv.org/abs/2401.04560v1</link><description>Human health can be critically affected by cardiovascular diseases, such ashypertension, arrhythmias, and stroke. Heart rate and blood pressure areimportant biometric information for the monitoring of cardiovascular system andearly diagnosis of cardiovascular diseases. Existing methods for estimating theheart rate are based on electrocardiography and photoplethyomography, whichrequire contacting the sensor to the skin surface. Moreover, catheter andcuff-based methods for measuring blood pressure cause inconvenience and havelimited applicability. Therefore, in this thesis, we propose a vision-basedmethod for estimating the heart rate and blood pressure. This thesis proposes a2-stage deep learning framework consisting of a dual remotephotoplethysmography network (DRP-Net) and bounded blood pressure network(BBP-Net). In the first stage, DRP-Net infers remote photoplethysmography(rPPG) signals for the acral and facial regions, and these phase-shifted rPPGsignals are utilized to estimate the heart rate. In the second stage, BBP-Netintegrates temporal features and analyzes phase discrepancy between the acraland facial rPPG signals to estimate SBP and DBP values. To improve the accuracyof estimating the heart rate, we employed a data augmentation method based on aframe interpolation model. Moreover, we designed BBP-Net to infer bloodpressure within a predefined range by incorporating a scaled sigmoid function.Our method resulted in estimating the heart rate with the mean absolute error(MAE) of 1.78 BPM, reducing the MAE by 34.31 % compared to the recent method,on the MMSE-HR dataset. The MAE for estimating the systolic blood pressure(SBP) and diastolic blood pressure (DBP) were 10.19 mmHg and 7.09 mmHg. On theV4V dataset, the MAE for the heart rate, SBP, and DBP were 3.83 BPM, 13.64mmHg, and 9.4 mmHg, respectively.</description><author>Gyutae Hwang, Sang Jun Lee</author><pubDate>Tue, 09 Jan 2024 13:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04560v1</guid></item><item><title>HyperGANStrument: Instrument Sound Synthesis and Editing with Pitch-Invariant Hypernetworks</title><link>http://arxiv.org/abs/2401.04558v1</link><description>GANStrument, exploiting GANs with a pitch-invariant feature extractor andinstance conditioning technique, has shown remarkable capabilities insynthesizing realistic instrument sounds. To further improve the reconstructionability and pitch accuracy to enhance the editability of user-provided sound,we propose HyperGANStrument, which introduces a pitch-invariant hypernetwork tomodulate the weights of a pre-trained GANStrument generator, given a one-shotsound as input. The hypernetwork modulation provides feedback for the generatorin the reconstruction of the input sound. In addition, we take advantage of anadversarial fine-tuning scheme for the hypernetwork to improve thereconstruction fidelity and generation diversity of the generator. Experimentalresults show that the proposed model not only enhances the generationcapability of GANStrument but also significantly improves the editability ofsynthesized sounds. Audio examples are available at the online demo page.</description><author>Zhe Zhang, Taketo Akama</author><pubDate>Tue, 09 Jan 2024 13:54:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04558v1</guid></item><item><title>Enhancing SMT-based Weighted Model Integration by Structure Awareness</title><link>http://arxiv.org/abs/2302.06188v2</link><description>The development of efficient exact and approximate algorithms forprobabilistic inference is a long-standing goal of artificial intelligenceresearch. Whereas substantial progress has been made in dealing with purelydiscrete or purely continuous domains, adapting the developed solutions totackle hybrid domains, characterised by discrete and continuous variables andtheir relationships, is highly non-trivial. Weighted Model Integration (WMI)recently emerged as a unifying formalism for probabilistic inference in hybriddomains. Despite a considerable amount of recent work, allowing WMI algorithmsto scale with the complexity of the hybrid problem is still a challenge. Inthis paper we highlight some substantial limitations of existingstate-of-the-art solutions, and develop an algorithm that combines SMT-basedenumeration, an efficient technique in formal verification, with an effectiveencoding of the problem structure. This allows our algorithm to avoidgenerating redundant models, resulting in drastic computational savings.Additionally, we show how SMT-based approaches can seamlessly deal withdifferent integration techniques, both exact and approximate, significantlyexpanding the set of problems that can be tackled by WMI technology. Anextensive experimental evaluation on both synthetic and real-world datasetsconfirms the substantial advantage of the proposed solution over existingalternatives. The application potential of this technology is further showcasedon a prototypical task aimed at verifying the fairness of probabilisticprograms.</description><author>Giuseppe Spallitta, Gabriele Masina, Paolo Morettin, Andrea Passerini, Roberto Sebastiani</author><pubDate>Tue, 09 Jan 2024 13:47:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06188v2</guid></item><item><title>Linear Recursive Feature Machines provably recover low-rank matrices</title><link>http://arxiv.org/abs/2401.04553v1</link><description>A fundamental problem in machine learning is to understand how neuralnetworks make accurate predictions, while seemingly bypassing the curse ofdimensionality. A possible explanation is that common training algorithms forneural networks implicitly perform dimensionality reduction - a process calledfeature learning. Recent work posited that the effects of feature learning canbe elicited from a classical statistical estimator called the average gradientouter product (AGOP). The authors proposed Recursive Feature Machines (RFMs) asan algorithm that explicitly performs feature learning by alternating between(1) reweighting the feature vectors by the AGOP and (2) learning the predictionfunction in the transformed space. In this work, we develop the firsttheoretical guarantees for how RFM performs dimensionality reduction byfocusing on the class of overparametrized problems arising in sparse linearregression and low-rank matrix recovery. Specifically, we show that RFMrestricted to linear models (lin-RFM) generalizes the well-studied IterativelyReweighted Least Squares (IRLS) algorithm. Our results shed light on theconnection between feature learning in neural networks and classical sparserecovery algorithms. In addition, we provide an implementation of lin-RFM thatscales to matrices with millions of missing entries. Our implementation isfaster than the standard IRLS algorithm as it is SVD-free. It also outperformsdeep linear networks for sparse linear regression and low-rank matrixcompletion.</description><author>Adityanarayanan Radhakrishnan, Mikhail Belkin, Dmitriy Drusvyatskiy</author><pubDate>Tue, 09 Jan 2024 13:44:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04553v1</guid></item><item><title>WaveletFormerNet: A Transformer-based Wavelet Network for Real-world Non-homogeneous and Dense Fog Removal</title><link>http://arxiv.org/abs/2401.04550v1</link><description>Although deep convolutional neural networks have achieved remarkable successin removing synthetic fog, it is essential to be able to process images takenin complex foggy conditions, such as dense or non-homogeneous fog, in the realworld. However, the haze distribution in the real world is complex, anddownsampling can lead to color distortion or loss of detail in the outputresults as the resolution of a feature map or image resolution decreases. Inaddition to the challenges of obtaining sufficient training data, overfittingcan also arise in deep learning techniques for foggy image processing, whichcan limit the generalization abilities of the model, posing challenges for itspractical applications in real-world scenarios. Considering these issues, thispaper proposes a Transformer-based wavelet network (WaveletFormerNet) forreal-world foggy image recovery. We embed the discrete wavelet transform intothe Vision Transformer by proposing the WaveletFormer and IWaveletFormerblocks, aiming to alleviate texture detail loss and color distortion in theimage due to downsampling. We introduce parallel convolution in the Transformerblock, which allows for the capture of multi-frequency information in alightweight mechanism. Additionally, we have implemented a feature aggregationmodule (FAM) to maintain image resolution and enhance the feature extractioncapacity of our model, further contributing to its impressive performance inreal-world foggy image recovery tasks. Extensive experiments demonstrate thatour WaveletFormerNet performs better than state-of-the-art methods, as shownthrough quantitative and qualitative evaluations of minor model complexity.Additionally, our satisfactory results on real-world dust removal andapplication tests showcase the superior generalization ability and improvedperformance of WaveletFormerNet in computer vision-related applications.</description><author>Shengli Zhang, Zhiyong Tao, Sen Lin</author><pubDate>Tue, 09 Jan 2024 13:42:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04550v1</guid></item><item><title>DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework</title><link>http://arxiv.org/abs/2310.12081v3</link><description>Graph matching is one of the most significant graph analytic tasks inpractice, which aims to find the node correspondence across different graphs.Most existing approaches rely on adjacency matrices or node embeddings whenmatching graphs, whose performances are often sub-optimal because of not fullyleveraging the multi-modal information hidden in graphs, such as nodeattributes, subgraph structures, etc. In this study, we propose a novel andeffective graph matching method based on a differentiable hierarchical optimaltransport (HOT) framework, called DHOT-GM. Essentially, our method representseach graph as a set of relational matrices corresponding to the information ofdifferent modalities. Given two graphs, we enumerate all relational matrixpairs and obtain their matching results, and accordingly, infer the nodecorrespondence by the weighted averaging of the matching results. This methodcan be implemented as computing the HOT distance between the two graphs -- eachmatching result is an optimal transport plan associated with theGromov-Wasserstein (GW) distance between two relational matrices, and theweights of all matching results are the elements of an upper-level optimaltransport plan defined on the matrix sets. We propose a bi-level optimizationalgorithm to compute the HOT distance in a differentiable way, making thesignificance of the relational matrices adjustable. Experiments on variousgraph matching tasks demonstrate the superiority and robustness of our methodcompared to state-of-the-art approaches.</description><author>Haoran Cheng, Dixin Luo, Hongteng Xu</author><pubDate>Tue, 09 Jan 2024 13:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12081v3</guid></item><item><title>General-Purpose In-Context Learning by Meta-Learning Transformers</title><link>http://arxiv.org/abs/2212.04458v2</link><description>Modern machine learning requires system designers to specify aspects of thelearning pipeline, such as losses, architectures, and optimizers.Meta-learning, or learning-to-learn, instead aims to learn those aspects, andpromises to unlock greater capabilities with less manual effort. Oneparticularly ambitious goal of meta-learning is to train general-purposein-context learning algorithms from scratch, using only black-box models withminimal inductive bias. Such a model takes in training data, and producestest-set predictions across a wide range of problems, without any explicitdefinition of an inference model, training loss, or optimization algorithm. Inthis paper we show that Transformers and other black-box models can bemeta-trained to act as general-purpose in-context learners. We characterizetransitions between algorithms that generalize, algorithms that memorize, andalgorithms that fail to meta-train at all, induced by changes in model size,number of tasks, and meta-optimization. We further show that the capabilitiesof meta-trained algorithms are bottlenecked by the accessible state size(memory) determining the next prediction, unlike standard models which arethought to be bottlenecked by parameter count. Finally, we propose practicalinterventions such as biasing the training distribution that improve themeta-training and meta-generalization of general-purpose in-context learningalgorithms.</description><author>Louis Kirsch, James Harrison, Jascha Sohl-Dickstein, Luke Metz</author><pubDate>Tue, 09 Jan 2024 13:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.04458v2</guid></item><item><title>Lifelong Ensemble Learning based on Multiple Representations for Few-Shot Object Recognition</title><link>http://arxiv.org/abs/2205.01982v5</link><description>Service robots are integrating more and more into our daily lives to help uswith various tasks. In such environments, robots frequently face new objectswhile working in the environment and need to learn them in an open-endedfashion. Furthermore, such robots must be able to recognize a wide range ofobject categories. In this paper, we present a lifelong ensemble learningapproach based on multiple representations to address the few-shot objectrecognition problem. In particular, we form ensemble methods based on deeprepresentations and handcrafted 3D shape descriptors. To facilitate lifelonglearning, each approach is equipped with a memory unit for storing andretrieving object information instantly. The proposed model is suitable foropen-ended learning scenarios where the number of 3D object categories is notfixed and can grow over time. We have performed extensive sets of experimentsto assess the performance of the proposed approach in offline, and open-endedscenarios. For the evaluation purpose, in addition to real object datasets, wegenerate a large synthetic household objects dataset consisting of 27000 viewsof 90 objects. Experimental results demonstrate the effectiveness of theproposed method on online few-shot 3D object recognition tasks, as well as itssuperior performance over the state-of-the-art open-ended learning approaches.Furthermore, our results show that while ensemble learning is modestlybeneficial in offline settings, it is significantly beneficial in lifelongfew-shot learning situations. Additionally, we demonstrated the effectivenessof our approach in both simulated and real-robot settings, where the robotrapidly learned new categories from limited examples.</description><author>Hamidreza Kasaei, Songsong Xiong</author><pubDate>Tue, 09 Jan 2024 13:21:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.01982v5</guid></item><item><title>Evaluating Language Model Agency through Negotiations</title><link>http://arxiv.org/abs/2401.04536v1</link><description>Companies, organizations, and governments increasingly exploit LanguageModels' (LM) remarkable capability to display agent-like behavior. As LMs areadopted to perform tasks with growing autonomy, there exists an urgent need forreliable and scalable evaluation benchmarks. Current, predominantly static LMbenchmarks are ill-suited to evaluate such dynamic applications. Thus, wepropose jointly evaluating LM performance and alignment through the lenses ofnegotiation games. We argue that this common task better reflects real-worlddeployment conditions while offering insights into LMs' decision-makingprocesses. Crucially, negotiation games allow us to study multi-turn, andcross-model interactions, modulate complexity, and side-step accidental dataleakage in evaluation. We report results for six publicly accessible LMs fromseveral major providers on a variety of negotiation games, evaluating bothself-play and cross-play performance. Noteworthy findings include: (i)open-source models are currently unable to complete these tasks; (ii)cooperative bargaining games prove challenging; and (iii) the most powerfulmodels do not always "win".</description><author>Tim R. Davidson, Veniamin Veselovsky, Martin Josifoski, Maxime Peyrard, Antoine Bosselut, Michal Kosinski, Robert West</author><pubDate>Tue, 09 Jan 2024 13:19:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04536v1</guid></item><item><title>Semi-Supervised Deep Sobolev Regression: Estimation, Variable Selection and Beyond</title><link>http://arxiv.org/abs/2401.04535v1</link><description>We propose SDORE, a semi-supervised deep Sobolev regressor, for thenonparametric estimation of the underlying regression function and itsgradient. SDORE employs deep neural networks to minimize empirical risk withgradient norm regularization, allowing computation of the gradient norm onunlabeled data. We conduct a comprehensive analysis of the convergence rates ofSDORE and establish a minimax optimal rate for the regression function.Crucially, we also derive a convergence rate for the associated plug-ingradient estimator, even in the presence of significant domain shift. Thesetheoretical findings offer valuable prior guidance for selecting regularizationparameters and determining the size of the neural network, while showcasing theprovable advantage of leveraging unlabeled data in semi-supervised learning. Tothe best of our knowledge, SDORE is the first provable neural network-basedapproach that simultaneously estimates the regression function and itsgradient, with diverse applications including nonparametric variable selectionand inverse problems. The effectiveness of SDORE is validated through anextensive range of numerical simulations and real data analysis.</description><author>Zhao Ding, Chenguang Duan, Yuling Jiao, Jerry Zhijian Yang</author><pubDate>Tue, 09 Jan 2024 13:10:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04535v1</guid></item><item><title>Perceptual Video Coding for Machines via Satisfied Machine Ratio Modeling</title><link>http://arxiv.org/abs/2211.06797v3</link><description>Video Coding for Machines (VCM) aims to compress visual signals for machineanalysis. However, existing methods only consider a few machines, neglectingthe majority. Moreover, the machine's perceptual characteristics are notleveraged effectively, resulting in suboptimal compression efficiency. Toovercome these limitations, this paper introduces Satisfied Machine Ratio(SMR), a metric that statistically evaluates the perceptual quality ofcompressed images and videos for machines by aggregating satisfaction scoresfrom them. Each score is derived from machine perceptual differences betweenoriginal and compressed images. Targeting image classification and objectdetection tasks, we build two representative machine libraries for SMRannotation and create a large-scale SMR dataset to facilitate SMR studies. Wethen propose an SMR prediction model based on the correlation between deepfeature differences and SMR. Furthermore, we introduce an auxiliary task toincrease the prediction accuracy by predicting the SMR difference between twoimages in different quality. Extensive experiments demonstrate that SMR modelssignificantly improve compression performance for machines and exhibit robustgeneralizability on unseen machines, codecs, datasets, and frame types. SMRenables perceptual coding for machines and propels VCM from specificity togenerality. Code is available at https://github.com/ywwynm/SMR.</description><author>Qi Zhang, Shanshe Wang, Xinfeng Zhang, Chuanmin Jia, Zhao Wang, Siwei Ma, Wen Gao</author><pubDate>Tue, 09 Jan 2024 13:02:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.06797v3</guid></item><item><title>MERA: A Comprehensive LLM Evaluation in Russian</title><link>http://arxiv.org/abs/2401.04531v1</link><description>Over the past few years, one of the most notable advancements in AI researchhas been in foundation models (FMs), headlined by the rise of language models(LMs). As the models' size increases, LMs demonstrate enhancements inmeasurable aspects and the development of new qualitative features. However,despite researchers' attention and the rapid growth in LM application, thecapabilities, limitations, and associated risks still need to be betterunderstood. To address these issues, we introduce an open Multimodal Evaluationof Russian-language Architectures (MERA), a new instruction benchmark forevaluating foundation models oriented towards the Russian language. Thebenchmark encompasses 21 evaluation tasks for generative models in 11 skilldomains and is designed as a black-box test to ensure the exclusion of dataleakage. The paper introduces a methodology to evaluate FMs and LMs in zero-and few-shot fixed instruction settings that can be extended to othermodalities. We propose an evaluation methodology, an open-source code base forthe MERA assessment, and a leaderboard with a submission system. We evaluateopen LMs as baselines and find that they are still far behind the human level.We publicly release MERA to guide forthcoming research, anticipategroundbreaking model features, standardize the evaluation procedure, andaddress potential societal drawbacks.</description><author>Alena Fenogenova, Artem Chervyakov, Nikita Martynov, Anastasia Kozlova, Maria Tikhonova, Albina Akhmetgareeva, Anton Emelyanov, Denis Shevelev, Pavel Lebedev, Leonid Sinev, Ulyana Isaeva, Katerina Kolomeytseva, Daniil Moskovskiy, Elizaveta Goncharova, Nikita Savushkin, Polina Mikhailova, Denis Dimitrov, Alexander Panchenko, Sergei Markov</author><pubDate>Tue, 09 Jan 2024 12:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04531v1</guid></item><item><title>CSRX: A novel Crossover Operator for a Genetic Algorithm applied to the Traveling Salesperson Problem</title><link>http://arxiv.org/abs/2303.12447v2</link><description>In this paper, we revisit the application of Genetic Algorithm (GA) to theTraveling Salesperson Problem (TSP) and introduce a family of novel crossoveroperators that outperform the previous state of the art. The novel crossoveroperators aim to exploit symmetries in the solution space, which allows us tomore effectively preserve well-performing individuals, namely the fitnessinvariance to circular shifts and reversals of solutions. These symmetries aregeneral and not limited to or tailored to TSP specifically.</description><author>Martin Uray, Stefan Wintersteller, Stefan Huber</author><pubDate>Tue, 09 Jan 2024 12:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12447v2</guid></item><item><title>Stepwise functional refoundation of relational concept analysis</title><link>http://arxiv.org/abs/2310.06441v3</link><description>Relational concept analysis (RCA) is an extension of formal concept analysisallowing to deal with several related contexts simultaneously. It has beendesigned for learning description logic theories from data and used withinvarious applications. A puzzling observation about RCA is that it returns asingle family of concept lattices although, when the data feature circulardependencies, other solutions may be considered acceptable. The semantics ofRCA, provided in an operational way, does not shed light on this issue. In thisreport, we define these acceptable solutions as those families of conceptlattices which belong to the space determined by the initial contexts(well-formed), cannot scale new attributes (saturated), and refer only toconcepts of the family (self-supported). We adopt a functional view on the RCAprocess by defining the space of well-formed solutions and two functions onthat space: one expansive and the other contractive. We show that theacceptable solutions are the common fixed points of both functions. This isachieved step-by-step by starting from a minimal version of RCA that considersonly one single context defined on a space of contexts and a space of lattices.These spaces are then joined into a single space of context-lattice pairs,which is further extended to a space of indexed families of context-latticepairs representing the objects manippulated by RCA. We show that RCA returnsthe least element of the set of acceptable solutions. In addition, it ispossible to build dually an operation that generates its greatest element. Theset of acceptable solutions is a complete sublattice of the interval betweenthese two elements. Its structure and how the defined functions traverse it arestudied in detail.</description><author>Jérôme Euzenat</author><pubDate>Tue, 09 Jan 2024 12:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06441v3</guid></item><item><title>Advanced Large Language Model (LLM)-Driven Verilog Development: Enhancing Power, Performance, and Area Optimization in Code Synthesis</title><link>http://arxiv.org/abs/2312.01022v2</link><description>The increasing use of Advanced Language Models (ALMs) in diverse sectors,particularly due to their impressive capability to generate top-tier contentfollowing linguistic instructions, forms the core of this investigation. Thisstudy probes into ALMs' deployment in electronic hardware design, with aspecific emphasis on the synthesis and enhancement of Verilog programming. Weintroduce an innovative framework, crafted to assess and amplify ALMs'productivity in this niche. The methodology commences with the initial craftingof Verilog programming via ALMs, succeeded by a distinct dual-stage refinementprotocol. The premier stage prioritizes augmenting the code's operational andlinguistic precision, while the latter stage is dedicated to aligning the codewith Power-Performance-Area (PPA) benchmarks, a pivotal component in proficienthardware design. This bifurcated strategy, merging error remediation with PPAenhancement, has yielded substantial upgrades in the caliber of ALM-createdVerilog programming. Our framework achieves an 81.37% rate in linguisticaccuracy and 62.0% in operational efficacy in programming synthesis, surpassingcurrent leading-edge techniques, such as 73% in linguistic accuracy and 46% inoperational efficacy. These findings illuminate ALMs' aptitude in tacklingcomplex technical domains and signal a positive shift in the mechanization ofhardware design operations.</description><author>Kiran Thorat, Jiahui Zhao, Yaotian Liu, Hongwu Peng, Xi Xie, Bin Lei, Jeff Zhang, Caiwen Ding</author><pubDate>Tue, 09 Jan 2024 12:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01022v2</guid></item><item><title>Lessons Learned: Reproducibility, Replicability, and When to Stop</title><link>http://arxiv.org/abs/2401.03736v2</link><description>While extensive guidance exists for ensuring the reproducibility of one's ownstudy, there is little discussion regarding the reproduction and replication ofexternal studies within one's own research. To initiate this discussion,drawing lessons from our experience reproducing an operational product forpredicting tropical cyclogenesis, we present a two-dimensional framework tooffer guidance on reproduction and replication. Our framework, representingmodel fitting on one axis and its use in inference on the other, builds uponthree key aspects: the dataset, the metrics, and the model itself. By assessingthe trajectories of our studies on this 2D plane, we can better inform theclaims made using our research. Additionally, we use this framework tocontextualize the utility of benchmark datasets in the atmospheric sciences.Our two-dimensional framework provides a tool for researchers, especially earlycareer researchers, to incorporate prior work in their own research and toinform the claims they can make in this context.</description><author>Milton S. Gomez, Tom Beucler</author><pubDate>Tue, 09 Jan 2024 12:35:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03736v2</guid></item><item><title>LUNA: A Framework for Language Understanding and Naturalness Assessment</title><link>http://arxiv.org/abs/2401.04522v1</link><description>The evaluation of Natural Language Generation (NLG) models has gainedincreased attention, urging the development of metrics that evaluate variousaspects of generated text. LUNA addresses this challenge by introducing aunified interface for 20 NLG evaluation metrics. These metrics are categorizedbased on their reference-dependence and the type of text representation theyemploy, from string-based n-gram overlap to the utilization of staticembeddings and pre-trained language models. The straightforward design of LUNA allows for easy extension with novelmetrics, requiring just a few lines of code. LUNA offers a user-friendly toolfor evaluating generated texts.</description><author>Marat Saidov, Aleksandra Bakalova, Ekaterina Taktasheva, Vladislav Mikhailov, Ekaterina Artemova</author><pubDate>Tue, 09 Jan 2024 12:31:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04522v1</guid></item><item><title>The Critique of Critique</title><link>http://arxiv.org/abs/2401.04518v1</link><description>Critique, as a natural language description for assessing the quality ofmodel-generated content, has been proven to play an essential role in thetraining, evaluation, and refinement of Large Language Models (LLMs). However,there is a lack of principled understanding in evaluating the quality of thecritique itself. In this paper, we pioneer the critique of critique, termedMetaCritique, which is a framework to evaluate the critique from two aspects,i.e., factuality as precision score and comprehensiveness as recall score. Wecalculate the harmonic mean of precision and recall as the overall ratingcalled F1 score. To obtain a reliable evaluation outcome, we propose AtomicInformation Units (AIUs), which describe the critique in a more fine-grainedmanner. MetaCritique takes each AIU into account and aggregates each AIU'sjudgment for the overall score. Moreover, given the evaluation process involvesintricate reasoning, our MetaCritique provides a natural language rationale tosupport each judgment. We construct a meta-evaluation dataset containing 300critiques (2653 AIUs) across four tasks (question answering, reasoning,entailment, and summarization), and we conduct a comparative study todemonstrate the feasibility and effectiveness. Experiments also show superiorcritique judged by MetaCritique leads to better refinement, indicatinggenerative artificial intelligence indeed has the potential to be significantlyadvanced with our MetaCritique. We will release relevant code andmeta-evaluation datasets at https://github.com/GAIR-NLP/MetaCritique.</description><author>Shichao Sun, Junlong Li, Weizhe Yuan, Ruifeng Yuan, Wenjie Li, Pengfei Liu</author><pubDate>Tue, 09 Jan 2024 12:20:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04518v1</guid></item><item><title>Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models</title><link>http://arxiv.org/abs/2401.04515v1</link><description>This article investigates a zero-shot approach to hypernymy prediction usinglarge language models (LLMs). The study employs a method based on textprobability calculation, applying it to various generated prompts. Theexperiments demonstrate a strong correlation between the effectiveness oflanguage model prompts and classic patterns, indicating that preliminary promptselection can be carried out using smaller models before moving to larger ones.We also explore prompts for predicting co-hyponyms and improving hypernymypredictions by augmenting prompts with additional information throughautomatically identified co-hyponyms. An iterative approach is developed forpredicting higher-level concepts, which further improves the quality on theBLESS dataset (MAP = 0.8).</description><author>Mikhail Tikhomirov, Natalia Loukachevitch</author><pubDate>Tue, 09 Jan 2024 12:13:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04515v1</guid></item><item><title>Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search</title><link>http://arxiv.org/abs/2401.04514v1</link><description>In code search, the Generation-Augmented Retrieval (GAR) framework, whichgenerates exemplar code snippets to augment queries, has emerged as a promisingstrategy to address the principal challenge of modality misalignment betweencode snippets and natural language queries, particularly with the demonstratedcode generation capabilities of Large Language Models (LLMs). Nevertheless, ourpreliminary investigations indicate that the improvements conferred by such anLLM-augmented framework are somewhat constrained. This limitation couldpotentially be ascribed to the fact that the generated codes, albeitfunctionally accurate, frequently display a pronounced stylistic deviation fromthe ground truth code in the codebase. In this paper, we extend thefoundational GAR framework and propose a simple yet effective method thatadditionally Rewrites the Code (ReCo) within the codebase for stylenormalization. Experimental results demonstrate that ReCo significantly boostsretrieval accuracy across sparse (up to 35.7%), zero-shot dense (up to 27.6%),and fine-tuned dense (up to 23.6%) retrieval settings in diverse searchscenarios. To further elucidate the advantages of ReCo and stimulate researchin code style normalization, we introduce Code Style Similarity, the firstmetric tailored to quantify stylistic similarities in code. Notably, ourempirical findings reveal the inadequacy of existing metrics in capturingstylistic nuances.</description><author>Haochen Li, Xin Zhou, Zhiqi Shen</author><pubDate>Tue, 09 Jan 2024 12:12:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04514v1</guid></item><item><title>Zero Shot Audio to Audio Emotion Transfer With Speaker Disentanglement</title><link>http://arxiv.org/abs/2401.04511v1</link><description>The problem of audio-to-audio (A2A) style transfer involves replacing thestyle features of the source audio with those from the target audio whilepreserving the content related attributes of the source audio. In this paper,we propose an efficient approach, termed as Zero-shot Emotion Style Transfer(ZEST), that allows the transfer of emotional content present in the givensource audio with the one embedded in the target audio while retaining thespeaker and speech content from the source. The proposed system builds upondecomposing speech into semantic tokens, speaker representations and emotionembeddings. Using these factors, we propose a framework to reconstruct thepitch contour of the given speech signal and train a decoder that reconstructsthe speech signal. The model is trained using a self-supervision basedreconstruction loss. During conversion, the emotion embedding is alone derivedfrom the target audio, while rest of the factors are derived from the sourceaudio. In our experiments, we show that, even without using parallel trainingdata or labels from the source or target audio, we illustrate zero shot emotiontransfer capabilities of the proposed ZEST model using objective and subjectivequality evaluations.</description><author>Soumya Dutta, Sriram Ganapathy</author><pubDate>Tue, 09 Jan 2024 12:10:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04511v1</guid></item><item><title>mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large Language Model</title><link>http://arxiv.org/abs/2311.18248v2</link><description>Recently, the strong text creation ability of Large Language Models(LLMs) hasgiven rise to many tools for assisting paper reading or even writing. However,the weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limittheir application scenarios, especially for scientific academic paper writing.In this work, towards a more versatile copilot for academic paper writing, wemainly focus on strengthening the multi-modal diagram analysis ability ofMultimodal LLMs. By parsing Latex source files of high-quality papers, wecarefully build a multi-modal diagram understanding dataset M-Paper. Byaligning diagrams in the paper with related paragraphs, we constructprofessional diagram analysis samples for training and evaluation. M-Paper isthe first dataset to support joint comprehension of multiple scientificdiagrams, including figures and tables in the format of images or Latex codes.Besides, to better align the copilot with the user's intention, we introducethe `outline' as the control signal, which could be directly given by the useror revised based on auto-generated ones. Comprehensive experiments with astate-of-the-art Mumtimodal LLM demonstrate that training on our dataset showsstronger scientific diagram understanding performance, including diagramcaptioning, diagram analysis, and outline recommendation. The dataset, code,and model are available athttps://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.</description><author>Anwen Hu, Yaya Shi, Haiyang Xu, Jiabo Ye, Qinghao Ye, Ming Yan, Chenliang Li, Qi Qian, Ji Zhang, Fei Huang</author><pubDate>Tue, 09 Jan 2024 12:07:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18248v2</guid></item><item><title>DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection</title><link>http://arxiv.org/abs/2401.02032v2</link><description>Limited by the encoder-decoder architecture, learning-based edge detectorsusually have difficulty predicting edge maps that satisfy both correctness andcrispness. With the recent success of the diffusion probabilistic model (DPM),we found it is especially suitable for accurate and crisp edge detection sincethe denoising process is directly applied to the original image size.Therefore, we propose the first diffusion model for the task of general edgedetection, which we call DiffusionEdge. To avoid expensive computationalresources while retaining the final performance, we apply DPM in the latentspace and enable the classic cross-entropy loss which is uncertainty-aware inpixel level to directly optimize the parameters in latent space in adistillation manner. We also adopt a decoupled architecture to speed up thedenoising process and propose a corresponding adaptive Fourier filter to adjustthe latent features of specific frequencies. With all the technical designs,DiffusionEdge can be stably trained with limited resources, predicting crispand accurate edge maps with much fewer augmentation strategies. Extensiveexperiments on four edge detection benchmarks demonstrate the superiority ofDiffusionEdge both in correctness and crispness. On the NYUDv2 dataset,compared to the second best, we increase the ODS, OIS (without post-processing)and AC by 30.2%, 28.1% and 65.1%, respectively. Code:https://github.com/GuHuangAI/DiffusionEdge.</description><author>Yunfan Ye, Kai Xu, Yuhang Huang, Renjiao Yi, Zhiping Cai</author><pubDate>Tue, 09 Jan 2024 12:00:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02032v2</guid></item><item><title>Data-driven Nonlinear Model Reduction using Koopman Theory: Integrated Control Form and NMPC Case Study</title><link>http://arxiv.org/abs/2401.04508v1</link><description>We use Koopman theory for data-driven model reduction of nonlinear dynamicalsystems with controls. We propose generic model structures combiningdelay-coordinate encoding of measurements and full-state decoding to integratereduced Koopman modeling and state estimation. We present a deep-learningapproach to train the proposed models. A case study demonstrates that ourapproach provides accurate control models and enables real-time capablenonlinear model predictive control of a high-purity cryogenic distillationcolumn.</description><author>Jan C. Schulze, Alexander Mitsos</author><pubDate>Tue, 09 Jan 2024 11:54:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04508v1</guid></item><item><title>TechGPT-2.0: A large language model project to solve the task of knowledge graph construction</title><link>http://arxiv.org/abs/2401.04507v1</link><description>Large language models have exhibited robust performance across diversenatural language processing tasks. This report introduces TechGPT-2.0, aproject designed to enhance the capabilities of large language modelsspecifically in knowledge graph construction tasks, including named entityrecognition (NER) and relationship triple extraction (RTE) tasks in NLPapplications. Additionally, it serves as a LLM accessible for research withinthe Chinese open-source model community. We offer two 7B large language modelweights and a QLoRA weight specialized for processing lengthy texts.Notably,TechGPT-2.0 is trained on Huawei's Ascend server. Inheriting allfunctionalities from TechGPT-1.0, it exhibits robust text processingcapabilities, particularly in the domains of medicine and law. Furthermore, weintroduce new capabilities to the model, enabling it to process texts invarious domains such as geographical areas, transportation, organizations,literary works, biology, natural sciences, astronomical objects, andarchitecture. These enhancements also fortified the model's adeptness inhandling hallucinations, unanswerable queries, and lengthy texts. This reportprovides a comprehensive and detailed introduction to the full fine-tuningprocess on Huawei's Ascend servers, encompassing experiences in Ascend serverdebugging, instruction fine-tuning data processing, and model training. Ourcode is available at https://github.com/neukg/TechGPT-2.0</description><author>Jiaqi Wang, Yuying Chang, Zhong Li, Ning An, Qi Ma, Lei Hei, Haibo Luo, Yifei Lu, Feiliang Ren</author><pubDate>Tue, 09 Jan 2024 11:52:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04507v1</guid></item><item><title>VKIE: The Application of Key Information Extraction on Video Text</title><link>http://arxiv.org/abs/2310.11650v2</link><description>Extracting structured information from videos is critical for numerousdownstream applications in the industry. In this paper, we define a significanttask of extracting hierarchical key information from visual texts on videos. Tofulfill this task, we decouple it into four subtasks and introduce twoimplementation solutions called PipVKIE and UniVKIE. PipVKIE sequentiallycompletes the four subtasks in continuous stages, while UniVKIE is improved byunifying all the subtasks into one backbone. Both PipVKIE and UniVKIE leveragemultimodal information from vision, text, and coordinates for featurerepresentation. Extensive experiments on one well-defined dataset demonstratethat our solutions can achieve remarkable performance and efficient inferencespeed.</description><author>Siyu An, Ye Liu, Haoyuan Peng, Di Yin</author><pubDate>Tue, 09 Jan 2024 11:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11650v2</guid></item><item><title>HCAM -- Hierarchical Cross Attention Model for Multi-modal Emotion Recognition</title><link>http://arxiv.org/abs/2304.06910v2</link><description>Emotion recognition in conversations is challenging due to the multi-modalnature of the emotion expression. We propose a hierarchical cross-attentionmodel (HCAM) approach to multi-modal emotion recognition using a combination ofrecurrent and co-attention neural network models. The input to the modelconsists of two modalities, i) audio data, processed through a learnablewav2vec approach and, ii) text data represented using a bidirectional encoderrepresentations from transformers (BERT) model. The audio and textrepresentations are processed using a set of bi-directional recurrent neuralnetwork layers with self-attention that converts each utterance in a givenconversation to a fixed dimensional embedding. In order to incorporatecontextual knowledge and the information across the two modalities, the audioand text embeddings are combined using a co-attention layer that attempts toweigh the utterance level embeddings relevant to the task of emotionrecognition. The neural network parameters in the audio layers, text layers aswell as the multi-modal co-attention layers, are hierarchically trained for theemotion classification task. We perform experiments on three establisheddatasets namely, IEMOCAP, MELD and CMU-MOSI, where we illustrate that theproposed model improves significantly over other benchmarks and helps achievestate-of-art results on all these datasets.</description><author>Soumya Dutta, Sriram Ganapathy</author><pubDate>Tue, 09 Jan 2024 11:45:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06910v2</guid></item><item><title>Foundation Model for Endoscopy Video Analysis via Large-scale Self-supervised Pre-train</title><link>http://arxiv.org/abs/2306.16741v4</link><description>Foundation models have exhibited remarkable success in various applications,such as disease diagnosis and text report generation. To date, a foundationmodel for endoscopic video analysis is still lacking. In this paper, we proposeEndo-FM, a foundation model specifically developed using massive endoscopicvideo data. First, we build a video transformer, which captures both local andglobal long-range dependencies across spatial and temporal dimensions. Second,we pre-train our transformer model using global and local views via aself-supervised manner, aiming to make it robust to spatial-temporal variationsand discriminative across different scenes. To develop the foundation model, weconstruct a large-scale endoscopy video dataset by combining 9 publiclyavailable datasets and a privately collected dataset from Baoshan Branch ofRenji Hospital in Shanghai, China. Our dataset overall consists of over 33Kvideo clips with up to 5 million frames, encompassing various protocols, targetorgans, and disease types. Our pre-trained Endo-FM can be easily adopted for agiven downstream task via fine-tuning by serving as the backbone. Withexperiments on 3 different types of downstream tasks, including classification,segmentation, and detection, our Endo-FM surpasses the current state-of-the-art(SOTA) self-supervised pre-training and adapter-based transfer learning methodsby a significant margin, such as VCL (3.1% F1, 4.8% Dice, and 5.5% F1 forclassification, segmentation, and detection) and ST-Adapter (5.9% F1, 9.6%Dice, and 9.9% F1 for classification, segmentation, and detection). Code,datasets, and models are released at https://github.com/med-air/Endo-FM.</description><author>Zhao Wang, Chang Liu, Shaoting Zhang, Qi Dou</author><pubDate>Tue, 09 Jan 2024 11:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16741v4</guid></item><item><title>Variational Classification</title><link>http://arxiv.org/abs/2305.10406v5</link><description>We present a latent variable model for classification that provides a novelprobabilistic interpretation of neural network softmax classifiers. We derive avariational objective to train the model, analogous to the evidence lower bound(ELBO) used to train variational auto-encoders, that generalises the softmaxcross-entropy loss. Treating inputs to the softmax layer as samples of a latentvariable, our abstracted perspective reveals a potential inconsistency betweentheir anticipated distribution, required for accurate label predictions, andtheir empirical distribution found in practice. We augment the variationalobjective to mitigate such inconsistency and induce a chosen latentdistribution, instead of the implicit assumption found in a standard softmaxlayer. Overall, we provide new theoretical insight into the inner workings ofwidely-used softmax classifiers. Empirical evaluation on image and textclassification datasets demonstrates that our proposed approach, variationalclassification, maintains classification accuracy while the reshaped latentspace improves other desirable properties of a classifier, such as calibration,adversarial robustness, robustness to distribution shift and sample efficiencyuseful in low data settings.</description><author>Shehzaad Dhuliawala, Mrinmaya Sachan, Carl Allen</author><pubDate>Tue, 09 Jan 2024 11:25:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10406v5</guid></item><item><title>Generalized Lagrangian Neural Networks</title><link>http://arxiv.org/abs/2401.03728v2</link><description>Incorporating neural networks for the solution of Ordinary DifferentialEquations (ODEs) represents a pivotal research direction within computationalmathematics. Within neural network architectures, the integration of theintrinsic structure of ODEs offers advantages such as enhanced predictivecapabilities and reduced data utilization. Among these structural ODE forms,the Lagrangian representation stands out due to its significant physicalunderpinnings. Building upon this framework, Bhattoo introduced the concept ofLagrangian Neural Networks (LNNs). Then in this article, we introduce agroundbreaking extension (Genralized Lagrangian Neural Networks) to LagrangianNeural Networks (LNNs), innovatively tailoring them for non-conservativesystems. By leveraging the foundational importance of the Lagrangian withinLagrange's equations, we formulate the model based on the generalizedLagrange's equation. This modification not only enhances prediction accuracybut also guarantees Lagrangian representation in non-conservative systems.Furthermore, we perform various experiments, encompassing 1-dimensional and2-dimensional examples, along with an examination of the impact of networkparameters, which proved the superiority of Generalized Lagrangian NeuralNetworks(GLNNs).</description><author>Shanshan Xiao, Jiawei Zhang, Yifa Tang</author><pubDate>Tue, 09 Jan 2024 11:24:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03728v2</guid></item><item><title>SpiNNaker2: A Large-Scale Neuromorphic System for Event-Based and Asynchronous Machine Learning</title><link>http://arxiv.org/abs/2401.04491v1</link><description>The joint progress of artificial neural networks (ANNs) and domain specifichardware accelerators such as GPUs and TPUs took over many domains of machinelearning research. This development is accompanied by a rapid growth of therequired computational demands for larger models and more data. Concurrently,emerging properties of foundation models such as in-context learning drive newopportunities for machine learning applications. However, the computationalcost of such applications is a limiting factor of the technology in datacenters, and more importantly in mobile devices and edge systems. To mediatethe energy footprint and non-trivial latency of contemporary systems,neuromorphic computing systems deeply integrate computational principles ofneurobiological systems by leveraging low-power analog and digitaltechnologies. SpiNNaker2 is a digital neuromorphic chip developed for scalablemachine learning. The event-based and asynchronous design of SpiNNaker2 allowsthe composition of large-scale systems involving thousands of chips. This workfeatures the operating principles of SpiNNaker2 systems, outlining theprototype of novel machine learning applications. These applications range fromANNs over bio-inspired spiking neural networks to generalized event-basedneural networks. With the successful development and deployment of SpiNNaker2,we aim to facilitate the advancement of event-based and asynchronous algorithmsfor future generations of machine learning systems.</description><author>Hector A. Gonzalez, Jiaxin Huang, Florian Kelber, Khaleelulla Khan Nazeer, Tim Langer, Chen Liu, Matthias Lohrmann, Amirhossein Rostami, Mark Schöne, Bernhard Vogginger, Timo C. Wunderlich, Yexin Yan, Mahmoud Akl, Christian Mayr</author><pubDate>Tue, 09 Jan 2024 11:07:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04491v1</guid></item><item><title>Auditing and Generating Synthetic Data with Controllable Trust Trade-offs</title><link>http://arxiv.org/abs/2304.10819v3</link><description>Real-world data often exhibits bias, imbalance, and privacy risks. Syntheticdatasets have emerged to address these issues. This paradigm relies ongenerative AI models to generate unbiased, privacy-preserving data whilemaintaining fidelity to the original data. However, assessing thetrustworthiness of synthetic datasets and models is a critical challenge. Weintroduce a holistic auditing framework that comprehensively evaluatessynthetic datasets and AI models. It focuses on preventing bias anddiscrimination, ensures fidelity to the source data, assesses utility,robustness, and privacy preservation. We demonstrate the framework'seffectiveness by auditing various generative models across diverse use caseslike education, healthcare, banking, and human resources, spanning differentdata modalities such as tabular, time-series, vision, and natural language.This holistic assessment is essential for compliance with regulatorysafeguards. We introduce a trustworthiness index to rank synthetic datasetsbased on their safeguards trade-offs. Furthermore, we present atrustworthiness-driven model selection and cross-validation process duringtraining, exemplified with "TrustFormers" across various data types. Thisapproach allows for controllable trustworthiness trade-offs in synthetic datacreation. Our auditing framework fosters collaboration among stakeholders,including data scientists, governance experts, internal reviewers, externalcertifiers, and regulators. This transparent reporting should become a standardpractice to prevent bias, discrimination, and privacy violations, ensuringcompliance with policies and providing accountability, safety, and performanceguarantees.</description><author>Brian Belgodere, Pierre Dognin, Adam Ivankay, Igor Melnyk, Youssef Mroueh, Aleksandra Mojsilovic, Jiri Navratil, Apoorva Nitsure, Inkit Padhi, Mattia Rigotti, Jerret Ross, Yair Schiff, Radhika Vedpathak, Richard A. Young</author><pubDate>Tue, 09 Jan 2024 11:05:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10819v3</guid></item><item><title>Optimal Survival Trees: A Dynamic Programming Approach</title><link>http://arxiv.org/abs/2401.04489v1</link><description>Survival analysis studies and predicts the time of death, or other singularunrepeated events, based on historical data, while the true time of death forsome instances is unknown. Survival trees enable the discovery of complexnonlinear relations in a compact human comprehensible model, by recursivelysplitting the population and predicting a distinct survival distribution ineach leaf node. We use dynamic programming to provide the first survival treemethod with optimality guarantees, enabling the assessment of the optimalitygap of heuristics. We improve the scalability of our method through a specialalgorithm for computing trees up to depth two. The experiments show that ourmethod's run time even outperforms some heuristics for realistic cases whileobtaining similar out-of-sample performance with the state-of-the-art.</description><author>Tim Huisman, Jacobus G. M. van der Linden, Emir Demirović</author><pubDate>Tue, 09 Jan 2024 11:01:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04489v1</guid></item><item><title>Take A Shortcut Back: Mitigating the Gradient Vanishing for Training Spiking Neural Networks</title><link>http://arxiv.org/abs/2401.04486v1</link><description>The Spiking Neural Network (SNN) is a biologically inspired neural networkinfrastructure that has recently garnered significant attention. It utilizesbinary spike activations to transmit information, thereby replacingmultiplications with additions and resulting in high energy efficiency.However, training an SNN directly poses a challenge due to the undefinedgradient of the firing spike process. Although prior works have employedvarious surrogate gradient training methods that use an alternative function toreplace the firing process during back-propagation, these approaches ignore anintrinsic problem: gradient vanishing. To address this issue, we propose ashortcut back-propagation method in our paper, which advocates for transmittingthe gradient directly from the loss to the shallow layers. This enables us topresent the gradient to the shallow layers directly, thereby significantlymitigating the gradient vanishing problem. Additionally, this method does notintroduce any burden during the inference phase. To strike a balance betweenfinal accuracy and ease of training, we also propose an evolutionary trainingframework and implement it by inducing a balance coefficient that dynamicallychanges with the training epoch, which further improves the network'sperformance. Extensive experiments conducted over static and dynamic datasetsusing several popular network structures reveal that our method consistentlyoutperforms state-of-the-art methods.</description><author>Yufei Guo, Yuanpei Chen</author><pubDate>Tue, 09 Jan 2024 10:54:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04486v1</guid></item></channel></rss>