<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 24 May 2024 06:00:09 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Federated Online Adaptation for Deep Stereo</title><link>http://arxiv.org/abs/2405.14873v1</link><description>We introduce a novel approach for adapting deep stereo networks in acollaborative manner. By building over principles of federated learning, wedevelop a distributed framework allowing for demanding the optimization processto a number of clients deployed in different environments. This makes itpossible, for a deep stereo network running on resourced-constrained devices,to capitalize on the adaptation process carried out by other instances of thesame architecture, and thus improve its accuracy in challenging environmentseven when it cannot carry out adaptation on its own. Experimental results showhow federated adaptation performs equivalently to on-device adaptation, andeven better when dealing with challenging environments.</description><author>Matteo Poggi, Fabio Tosi</author><pubDate>Thu, 23 May 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14873v1</guid></item><item><title>An Empirical Study of Training State-of-the-Art LiDAR Segmentation Models</title><link>http://arxiv.org/abs/2405.14870v1</link><description>In the rapidly evolving field of autonomous driving, precise segmentation ofLiDAR data is crucial for understanding complex 3D environments. Traditionalapproaches often rely on disparate, standalone codebases, hindering unifiedadvancements and fair benchmarking across models. To address these challenges,we introduce MMDetection3D-lidarseg, a comprehensive toolbox designed for theefficient training and evaluation of state-of-the-art LiDAR segmentationmodels. We support a wide range of segmentation models and integrate advanceddata augmentation techniques to enhance robustness and generalization.Additionally, the toolbox provides support for multiple leading sparseconvolution backends, optimizing computational efficiency and performance. Byfostering a unified framework, MMDetection3D-lidarseg streamlines developmentand benchmarking, setting new standards for research and application. Ourextensive benchmark experiments on widely-used datasets demonstrate theeffectiveness of the toolbox. The codebase and trained models have beenpublicly available, promoting further research and innovation in the field ofLiDAR segmentation for autonomous driving.</description><author>Jiahao Sun, Xiang Xu, Lingdong Kong, Youquan Liu, Li Li, Chenming Zhu, Jingwei Zhang, Zeqi Xiao, Runnan Chen, Tai Wang, Wenwei Zhang, Kai Chen, Chunmei Qing</author><pubDate>Thu, 23 May 2024 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14870v1</guid></item><item><title>NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections</title><link>http://arxiv.org/abs/2405.14871v1</link><description>Neural Radiance Fields (NeRFs) typically struggle to reconstruct and renderhighly specular objects, whose appearance varies quickly with changes inviewpoint. Recent works have improved NeRF's ability to render detailedspecular appearance of distant environment illumination, but are unable tosynthesize consistent reflections of closer content. Moreover, these techniquesrely on large computationally-expensive neural networks to model outgoingradiance, which severely limits optimization and rendering speed. We addressthese issues with an approach based on ray tracing: instead of querying anexpensive neural network for the outgoing view-dependent radiance at pointsalong each camera ray, our model casts reflection rays from these points andtraces them through the NeRF representation to render feature vectors which aredecoded into color using a small inexpensive network. We demonstrate that ourmodel outperforms prior methods for view synthesis of scenes containing shinyobjects, and that it is the only existing NeRF method that can synthesizephotorealistic specular appearance and reflections in real-world scenes, whilerequiring comparable optimization time to current state-of-the-art viewsynthesis models.</description><author>Dor Verbin, Pratul P. Srinivasan, Peter Hedman, Ben Mildenhall, Benjamin Attal, Richard Szeliski, Jonathan T. Barron</author><pubDate>Thu, 23 May 2024 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14871v1</guid></item><item><title>PuzzleAvatar: Assembling 3D Avatars from Personal Albums</title><link>http://arxiv.org/abs/2405.14869v1</link><description>Generating personalized 3D avatars is crucial for AR/VR. However, recenttext-to-3D methods that generate avatars for celebrities or fictionalcharacters, struggle with everyday people. Methods for faithful reconstructiontypically require full-body images in controlled settings. What if a user couldjust upload their personal "OOTD" (Outfit Of The Day) photo collection and geta faithful avatar in return? The challenge is that such casual photocollections contain diverse poses, challenging viewpoints, cropped views, andocclusion (albeit with a consistent outfit, accessories and hairstyle). Weaddress this novel "Album2Human" task by developing PuzzleAvatar, a novel modelthat generates a faithful 3D avatar (in a canonical pose) from a personal OOTDalbum, while bypassing the challenging estimation of body and camera pose. Tothis end, we fine-tune a foundational vision-language model (VLM) on suchphotos, encoding the appearance, identity, garments, hairstyles, andaccessories of a person into (separate) learned tokens and instilling thesecues into the VLM. In effect, we exploit the learned tokens as "puzzle pieces"from which we assemble a faithful, personalized 3D avatar. Importantly, we cancustomize avatars by simply inter-changing tokens. As a benchmark for this newtask, we collect a new dataset, called PuzzleIOI, with 41 subjects in a totalof nearly 1K OOTD configurations, in challenging partial photos with pairedground-truth 3D bodies. Evaluation shows that PuzzleAvatar not only has highreconstruction accuracy, outperforming TeCH and MVDreamBooth, but also a uniquescalability to album photos, and strong robustness. Our model and data will bepublic.</description><author>Yuliang Xiu, Yufei Ye, Zhen Liu, Dimitrios Tzionas, Michael J. Black</author><pubDate>Thu, 23 May 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14869v1</guid></item><item><title>Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis</title><link>http://arxiv.org/abs/2405.14868v1</link><description>Accurate reconstruction of complex dynamic scenes from just a singleviewpoint continues to be a challenging task in computer vision. Currentdynamic novel view synthesis methods typically require videos from manydifferent camera viewpoints, necessitating careful recording setups, andsignificantly restricting their utility in the wild as well as in terms ofembodied AI applications. In this paper, we propose $\textbf{GCD}$, acontrollable monocular dynamic view synthesis pipeline that leverageslarge-scale diffusion priors to, given a video of any scene, generate asynchronous video from any other chosen perspective, conditioned on a set ofrelative camera pose parameters. Our model does not require depth as input, anddoes not explicitly model 3D scene geometry, instead performing end-to-endvideo-to-video translation in order to achieve its goal efficiently. Despitebeing trained on synthetic multi-view video data only, zero-shot real-worldgeneralization experiments show promising results in multiple domains,including robotics, object permanence, and driving environments. We believe ourframework can potentially unlock powerful applications in rich dynamic sceneunderstanding, perception for robotics, and interactive 3D video viewingexperiences for virtual reality.</description><author>Basile Van Hoorick, Rundi Wu, Ege Ozguroglu, Kyle Sargent, Ruoshi Liu, Pavel Tokmakov, Achal Dave, Changxi Zheng, Carl Vondrick</author><pubDate>Thu, 23 May 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14868v1</guid></item><item><title>Improved Distribution Matching Distillation for Fast Image Synthesis</title><link>http://arxiv.org/abs/2405.14867v1</link><description>Recent approaches have shown promises distilling diffusion models intoefficient one-step generators. Among them, Distribution Matching Distillation(DMD) produces one-step generators that match their teacher in distribution,without enforcing a one-to-one correspondence with the sampling trajectories oftheir teachers. However, to ensure stable training, DMD requires an additionalregression loss computed using a large set of noise-image pairs generated bythe teacher with many steps of a deterministic sampler. This is costly forlarge-scale text-to-image synthesis and limits the student's quality, tying ittoo closely to the teacher's original sampling paths. We introduce DMD2, a setof techniques that lift this limitation and improve DMD training. First, weeliminate the regression loss and the need for expensive dataset construction.We show that the resulting instability is due to the fake critic not estimatingthe distribution of generated samples accurately and propose a two time-scaleupdate rule as a remedy. Second, we integrate a GAN loss into the distillationprocedure, discriminating between generated samples and real images. This letsus train the student model on real data, mitigating the imperfect real scoreestimation from the teacher model, and enhancing quality. Lastly, we modify thetraining procedure to enable multi-step sampling. We identify and address thetraining-inference input mismatch problem in this setting, by simulatinginference-time generator samples during training time. Taken together, ourimprovements set new benchmarks in one-step image generation, with FID scoresof 1.28 on ImageNet-64x64 and 8.35 on zero-shot COCO 2014, surpassing theoriginal teacher despite a 500X reduction in inference cost. Further, we showour approach can generate megapixel images by distilling SDXL, demonstratingexceptional visual quality among few-step methods.</description><author>Tianwei Yin, Michaël Gharbi, Taesung Park, Richard Zhang, Eli Shechtman, Fredo Durand, William T. Freeman</author><pubDate>Thu, 23 May 2024 18:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14867v1</guid></item><item><title>Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using Sparse RGB Cameras</title><link>http://arxiv.org/abs/2405.14866v1</link><description>In this paper, we present a low-budget and high-authenticity bidirectionaltelepresence system, Tele-Aloha, targeting peer-to-peer communicationscenarios. Compared to previous systems, Tele-Aloha utilizes only four sparseRGB cameras, one consumer-grade GPU, and one autostereoscopic screen to achievehigh-resolution (2048x2048), real-time (30 fps), low-latency (less than 150ms)and robust distant communication. As the core of Tele-Aloha, we propose anefficient novel view synthesis algorithm for upper-body. Firstly, we design acascaded disparity estimator for obtaining a robust geometry cue. Additionallya neural rasterizer via Gaussian Splatting is introduced to project latentfeatures onto target view and to decode them into a reduced resolution.Further, given the high-quality captured data, we leverage weighted blendingmechanism to refine the decoded image into the final resolution of 2K.Exploiting world-leading autostereoscopic display and low-latency iristracking, users are able to experience a strong three-dimensional sense evenwithout any wearable head-mounted display device. Altogether, our telepresencesystem demonstrates the sense of co-presence in real-life experiments,inspiring the next generation of communication.</description><author>Hanzhang Tu, Ruizhi Shao, Xue Dong, Shunyuan Zheng, Hao Zhang, Lili Chen, Meili Wang, Wenyu Li, Siyan Ma, Shengping Zhang, Boyao Zhou, Yebin Liu</author><pubDate>Thu, 23 May 2024 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14866v1</guid></item><item><title>Video Diffusion Models are Training-free Motion Interpreter and Controller</title><link>http://arxiv.org/abs/2405.14864v1</link><description>Video generation primarily aims to model authentic and customized motionacross frames, making understanding and controlling the motion a crucial topic.Most diffusion-based studies on video motion focus on motion customization withtraining-based paradigms, which, however, demands substantial trainingresources and necessitates retraining for diverse models. Crucially, theseapproaches do not explore how video diffusion models encode cross-frame motioninformation in their features, lacking interpretability and transparency intheir effectiveness. To answer this question, this paper introduces a novelperspective to understand, localize, and manipulate motion-aware features invideo diffusion models. Through analysis using Principal Component Analysis(PCA), our work discloses that robust motion-aware feature already exists invideo diffusion models. We present a new MOtion FeaTure (MOFT) by eliminatingcontent correlation information and filtering motion channels. MOFT provides adistinct set of benefits, including the ability to encode comprehensive motioninformation with clear interpretability, extraction without the need fortraining, and generalizability across diverse architectures. Leveraging MOFT,we propose a novel training-free video motion control framework. Our methoddemonstrates competitive performance in generating natural and faithful motion,providing architecture-agnostic insights and applicability in a variety ofdownstream tasks.</description><author>Zeqi Xiao, Yifan Zhou, Shuai Yang, Xingang Pan</author><pubDate>Thu, 23 May 2024 18:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14864v1</guid></item><item><title>A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns</title><link>http://arxiv.org/abs/2405.14863v1</link><description>Cross-domain alignment refers to the task of mapping a concept from onedomain to another. For example, ``If a \textit{doctor} were a \textit{color},what color would it be?''. This seemingly peculiar task is designed toinvestigate how people represent concrete and abstract concepts through theirmappings between categories and their reasoning processes over those mappings.In this paper, we adapt this task from cognitive science to evaluate theconceptualization and reasoning abilities of large language models (LLMs)through a behavioral study. We examine several LLMs by prompting them with across-domain mapping task and analyzing their responses at both the populationand individual levels. Additionally, we assess the models' ability to reasonabout their predictions by analyzing and categorizing their explanations forthese mappings. The results reveal several similarities between humans' andmodels' mappings and explanations, suggesting that models represent conceptssimilarly to humans. This similarity is evident not only in the modelrepresentation but also in their behavior. Furthermore, the models mostlyprovide valid explanations and deploy reasoning paths that are similar to thoseof humans.</description><author>Asaf Yehudai, Taelin Karidi, Gabriel Stanovsky, Ariel Goldstein, Omri Abend</author><pubDate>Thu, 23 May 2024 18:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14863v1</guid></item><item><title>Bitune: Bidirectional Instruction-Tuning</title><link>http://arxiv.org/abs/2405.14862v1</link><description>We introduce Bitune, a method that improves instruction-tuning of pretraineddecoder-only large language models, leading to consistent gains on downstreamtasks. Bitune applies both causal and bidirectional attention to the prompt, toobtain a better representation of the query or instruction. We realize this byintroducing two sets of parameters, for which we apply parameter-efficientfinetuning techniques. These causal and bidirectional features are thencombined into a weighted average with trainable coefficients, which issubsequently used to generate new tokens. We demonstrate significantimprovements in zero-shot performance on commonsense reasoning, arithmetic, andlanguage understanding tasks, while extensive ablation studies validate therole of each component and demonstrate the method's agnosticism to differentPEFT techniques.</description><author>Dawid J. Kopiczko, Tijmen Blankevoort, Yuki M. Asano</author><pubDate>Thu, 23 May 2024 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14862v1</guid></item><item><title>Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models</title><link>http://arxiv.org/abs/2405.14861v1</link><description>This paper investigates score-based diffusion models when the underlyingtarget distribution is concentrated on or near low-dimensional manifolds withinthe higher-dimensional space in which they formally reside, a commoncharacteristic of natural image distributions. Despite previous efforts tounderstand the data generation process of diffusion models, existingtheoretical support remains highly suboptimal in the presence oflow-dimensional structure, which we strengthen in this paper. For the popularDenoising Diffusion Probabilistic Model (DDPM), we find that the dependency ofthe error incurred within each denoising step on the ambient dimension $d$ isin general unavoidable. We further identify a unique design of coefficientsthat yields a converges rate at the order of $O(k^{2}/\sqrt{T})$ (up to logfactors), where $k$ is the intrinsic dimension of the target distribution and$T$ is the number of steps. This represents the first theoretical demonstrationthat the DDPM sampler can adapt to unknown low-dimensional structures in thetarget distribution, highlighting the critical importance of coefficientdesign. All of this is achieved by a novel set of analysis tools thatcharacterize the algorithmic dynamics in a more deterministic manner.</description><author>Gen Li, Yuling Yan</author><pubDate>Thu, 23 May 2024 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14861v1</guid></item><item><title>Not All Language Model Features Are Linear</title><link>http://arxiv.org/abs/2405.14860v1</link><description>Recent work has proposed the linear representation hypothesis: that languagemodels perform computation by manipulating one-dimensional representations ofconcepts ("features") in activation space. In contrast, we explore whether somelanguage model representations may be inherently multi-dimensional. We begin bydeveloping a rigorous definition of irreducible multi-dimensional featuresbased on whether they can be decomposed into either independent ornon-co-occurring lower-dimensional features. Motivated by these definitions, wedesign a scalable method that uses sparse autoencoders to automatically findmulti-dimensional features in GPT-2 and Mistral 7B. These auto-discoveredfeatures include strikingly interpretable examples, e.g. circular featuresrepresenting days of the week and months of the year. We identify tasks wherethese exact circles are used to solve computational problems involving modulararithmetic in days of the week and months of the year. Finally, we provideevidence that these circular features are indeed the fundamental unit ofcomputation in these tasks with intervention experiments on Mistral 7B andLlama 3 8B, and we find further circular representations by breaking down thehidden states for these tasks into interpretable components.</description><author>Joshua Engels, Isaac Liao, Eric J. Michaud, Wes Gurnee, Max Tegmark</author><pubDate>Thu, 23 May 2024 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14860v1</guid></item><item><title>Mamba-R: Vision Mamba ALSO Needs Registers</title><link>http://arxiv.org/abs/2405.14858v1</link><description>Similar to Vision Transformers, this paper identifies artifacts also presentwithin the feature maps of Vision Mamba. These artifacts, corresponding tohigh-norm tokens emerging in low-information background areas of images, appearmuch more severe in Vision Mamba -- they exist prevalently even with thetiny-sized model and activate extensively across background regions. Tomitigate this issue, we follow the prior solution of introducing registertokens into Vision Mamba. To better cope with Mamba blocks' uni-directionalinference paradigm, two key modifications are introduced: 1) evenly insertingregisters throughout the input token sequence, and 2) recycling registers forfinal decision predictions. We term this new architecture Mamba-R. Qualitativeobservations suggest, compared to vanilla Vision Mamba, Mamba-R's feature mapsappear cleaner and more focused on semantically meaningful regions.Quantitatively, Mamba-R attains stronger performance and scales better. Forexample, on the ImageNet benchmark, our base-size Mamba-R attains 82.9%accuracy, significantly outperforming Vim-B's 81.8%; furthermore, we providethe first successful scaling to the large model size (i.e., with 341Mparameters), attaining a competitive accuracy of 83.2% (84.5% if finetuned with384x384 inputs). Additional validation on the downstream semantic segmentationtask also supports Mamba-R's efficacy.</description><author>Feng Wang, Jiahao Wang, Sucheng Ren, Guoyizhe Wei, Jieru Mei, Wei Shao, Yuyin Zhou, Alan Yuille, Cihang Xie</author><pubDate>Thu, 23 May 2024 18:58:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14858v1</guid></item><item><title>Self-Play Probabilistic Preference Optimization for Language Model Alignment</title><link>http://arxiv.org/abs/2405.00675v2</link><description>Traditional reinforcement learning from human feedback (RLHF) approachesrelying on parametric models like the Bradley-Terry model fall short incapturing the intransitivity and irrationality in human preferences. Recentadvancements suggest that directly working with preference probabilities canyield a more accurate reflection of human preferences, enabling more flexibleand accurate language model alignment. In this paper, we propose aself-play-based method for language model alignment, which treats the problemas a constant-sum two-player game aimed at identifying the Nash equilibriumpolicy. Our approach, dubbed \textit{Self-play Probabilistic PreferenceOptimization} (SPPO), approximates the Nash equilibrium through iterativepolicy updates and enjoys a theoretical convergence guarantee. Our method caneffectively increase the log-likelihood of the chosen response and decreasethat of the rejected response, which cannot be trivially achieved by symmetricpairwise loss such as Direct Preference Optimization (DPO) and IdentityPreference Optimization (IPO). In our experiments, using only 60k prompts(without responses) from the UltraFeedback dataset and without any promptaugmentation, by leveraging a pre-trained preference model PairRM with only0.4B parameters, SPPO can obtain a model from fine-tuningMistral-7B-Instruct-v0.2 that achieves the state-of-the-art length-controlledwin-rate of 28.53\% against GPT-4-Turbo on AlpacaEval 2.0. It also outperformsthe (iterative) DPO and IPO on MT-Bench and the Open LLM Leaderboard. Notably,the strong performance of SPPO is achieved without additional externalsupervision (e.g., responses, preferences, etc.) from GPT-4 or other strongerlanguage models.</description><author>Yue Wu, Zhiqing Sun, Huizhuo Yuan, Kaixuan Ji, Yiming Yang, Quanquan Gu</author><pubDate>Thu, 23 May 2024 18:58:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00675v2</guid></item><item><title>Semantica: An Adaptable Image-Conditioned Diffusion Model</title><link>http://arxiv.org/abs/2405.14857v1</link><description>We investigate the task of adapting image generative models to differentdatasets without finetuneing. To this end, we introduce Semantica, animage-conditioned diffusion model capable of generating images based on thesemantics of a conditioning image. Semantica is trained exclusively onweb-scale image pairs, that is it receives a random image from a webpage asconditional input and models another random image from the same webpage. Ourexperiments highlight the expressivity of pretrained image encoders andnecessity of semantic-based data filtering in achieving high-quality imagegeneration. Once trained, it can adaptively generate new images from a datasetby simply using images from that dataset as input. We study the transferproperties of Semantica on ImageNet, LSUN Churches, LSUN Bedroom and SUN397.</description><author>Manoj Kumar, Neil Houlsby, Emiel Hoogeboom</author><pubDate>Thu, 23 May 2024 18:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14857v1</guid></item><item><title>Synergistic Global-space Camera and Human Reconstruction from Videos</title><link>http://arxiv.org/abs/2405.14855v1</link><description>Remarkable strides have been made in reconstructing static scenes or humanbodies from monocular videos. Yet, the two problems have largely beenapproached independently, without much synergy. Most visual SLAM methods canonly reconstruct camera trajectories and scene structures up to scale, whilemost HMR methods reconstruct human meshes in metric scale but fall short inreasoning with cameras and scenes. This work introduces Synergistic Camera andHuman Reconstruction (SynCHMR) to marry the best of both worlds. Specifically,we design Human-aware Metric SLAM to reconstruct metric-scale camera poses andscene point clouds using camera-frame HMR as a strong prior, addressing depth,scale, and dynamic ambiguities. Conditioning on the dense scene recovered, wefurther learn a Scene-aware SMPL Denoiser to enhance world-frame HMR byincorporating spatio-temporal coherency and dynamic scene constraints.Together, they lead to consistent reconstructions of camera trajectories, humanmeshes, and dense scene point clouds in a common world frame. Project page:https://paulchhuang.github.io/synchmr</description><author>Yizhou Zhao, Tuanfeng Y. Wang, Bhiksha Raj, Min Xu, Jimei Yang, Chun-Hao Paul Huang</author><pubDate>Thu, 23 May 2024 18:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14855v1</guid></item><item><title>TerDiT: Ternary Diffusion Models with Transformers</title><link>http://arxiv.org/abs/2405.14854v1</link><description>Recent developments in large-scale pre-trained text-to-image diffusion modelshave significantly improved the generation of high-fidelity images,particularly with the emergence of diffusion models based on transformerarchitecture (DiTs). Among these diffusion models, diffusion transformers havedemonstrated superior image generation capabilities, boosting lower FID scoresand higher scalability. However, deploying large-scale DiT models can beexpensive due to their extensive parameter numbers. Although existing researchhas explored efficient deployment techniques for diffusion models such as modelquantization, there is still little work concerning DiT-based models. To tacklethis research gap, in this paper, we propose TerDiT, a quantization-awaretraining (QAT) and efficient deployment scheme for ternary diffusion modelswith transformers. We focus on the ternarization of DiT networks and scalemodel sizes from 600M to 4.2B. Our work contributes to the exploration ofefficient deployment strategies for large-scale DiT models, demonstrating thefeasibility of training extremely low-bit diffusion transformer models fromscratch while maintaining competitive image generation capacities compared tofull-precision models. Code will be available athttps://github.com/Lucky-Lance/TerDiT.</description><author>Xudong Lu, Aojun Zhou, Ziyi Lin, Qi Liu, Yuhui Xu, Renrui Zhang, Yafei Wen, Shuai Ren, Peng Gao, Junchi Yan, Hongsheng Li</author><pubDate>Thu, 23 May 2024 18:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14854v1</guid></item><item><title>Privileged Sensing Scaffolds Reinforcement Learning</title><link>http://arxiv.org/abs/2405.14853v1</link><description>We need to look at our shoelaces as we first learn to tie them but havingmastered this skill, can do it from touch alone. We call this phenomenon"sensory scaffolding": observation streams that are not needed by a mastermight yet aid a novice learner. We consider such sensory scaffolding setups fortraining artificial agents. For example, a robot arm may need to be deployedwith just a low-cost, robust, general-purpose camera; yet its performance mayimprove by having privileged training-time-only access to informative albeitexpensive and unwieldy motion capture rigs or fragile tactile sensors. Forthese settings, we propose "Scaffolder", a reinforcement learning approachwhich effectively exploits privileged sensing in critics, world models, rewardestimators, and other such auxiliary components that are only used at trainingtime, to improve the target policy. For evaluating sensory scaffolding agents,we design a new "S3" suite of ten diverse simulated robotic tasks that explorea wide range of practical sensor setups. Agents must use privileged camerasensing to train blind hurdlers, privileged active visual perception to helprobot arms overcome visual occlusions, privileged touch sensors to train robothands, and more. Scaffolder easily outperforms relevant prior baselines andfrequently performs comparably even to policies that have test-time access tothe privileged sensors. Website: https://penn-pal-lab.github.io/scaffolder/</description><author>Edward S. Hu, James Springer, Oleh Rybkin, Dinesh Jayaraman</author><pubDate>Thu, 23 May 2024 18:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14853v1</guid></item><item><title>PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression</title><link>http://arxiv.org/abs/2405.14852v1</link><description>There has been significant interest in "extreme" compression of largelanguage models (LLMs), i.e., to 1-2 bits per parameter, which allows suchmodels to be executed efficiently on resource-constrained devices. Existingwork focused on improved one-shot quantization techniques and weightrepresentations; yet, purely post-training approaches are reaching diminishingreturns in terms of the accuracy-vs-bit-width trade-off. State-of-the-artquantization methods such as QuIP# and AQLM include fine-tuning (part of) thecompressed parameters over a limited amount of calibration data; however, suchfine-tuning techniques over compressed weights often make exclusive use ofstraight-through estimators (STE), whose performance is not well-understood inthis setting. In this work, we question the use of STE for extreme LLMcompression, showing that it can be sub-optimal, and perform a systematic studyof quantization-aware fine-tuning strategies for LLMs. We propose PV-Tuning - arepresentation-agnostic framework that generalizes and improves upon existingfine-tuning strategies, and provides convergence guarantees in restrictedcases. On the practical side, when used for 1-2 bit vector quantization,PV-Tuning outperforms prior techniques for highly-performant models such asLlama and Mistral. Using PV-Tuning, we achieve the first Pareto-optimalquantization for Llama 2 family models at 2 bits per parameter.</description><author>Vladimir Malinovskii, Denis Mazur, Ivan Ilin, Denis Kuznedelev, Konstantin Burlachenko, Kai Yi, Dan Alistarh, Peter Richtarik</author><pubDate>Thu, 23 May 2024 18:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14852v1</guid></item><item><title>Domain Wall Magnetic Tunnel Junction Reliable Integrate and Fire Neuron</title><link>http://arxiv.org/abs/2405.14851v1</link><description>In spiking neural networks, neuron dynamics are described by the biologicallyrealistic integrate-and-fire model that captures membrane potentialaccumulation and above-threshold firing behaviors. Among the hardwareimplementations of integrate-and-fire neuron devices, one important feature,reset, has been largely ignored. Here, we present the design and fabrication ofa magnetic domain wall and magnetic tunnel junction based artificialintegrate-and-fire neuron device that achieves reliable reset at the end of theintegrate-fire cycle. We demonstrate the domain propagation in the domain wallracetrack (integration), reading using a magnetic tunnel junction (fire), andreset as the domain is ejected from the racetrack, showing the artificialneuron can be operated continuously over 100 integrate-fire-reset cycles. Bothpulse amplitude and pulse number encoding is demonstrated. The device data isapplied on an image classification task using a spiking neural network andshown to have comparable performance to an ideal leaky, integrate-and-fireneural network. These results achieve the first demonstration of reliableintegrate-fire-reset in domain wall-magnetic tunnel junction-based neurondevices and shows the promise of spintronics for neuromorphic computing.</description><author>Can Cui1, Sam Liu, Jaesuk Kwon, Jean Anne C. Incorvia</author><pubDate>Thu, 23 May 2024 18:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14851v1</guid></item><item><title>Local Causal Discovery for Structural Evidence of Direct Discrimination</title><link>http://arxiv.org/abs/2405.14848v1</link><description>Fairness is a critical objective in policy design and algorithmicdecision-making. Identifying the causal pathways of unfairness requiresknowledge of the underlying structural causal model, which may be incomplete orunavailable. This limits the practicality of causal fairness analysis incomplex or low-knowledge domains. To mitigate this practicality gap, weadvocate for developing efficient causal discovery methods for fairnessapplications. To this end, we introduce local discovery for directdiscrimination (LD3): a polynomial-time algorithm that recovers structuralevidence of direct discrimination. LD3 performs a linear number of conditionalindependence tests with respect to variable set size. Moreover, we propose agraphical criterion for identifying the weighted controlled direct effect(CDE), a qualitative measure of direct discrimination. We prove that thiscriterion is satisfied by the knowledge returned by LD3, increasing theaccessibility of the weighted CDE as a causal fairness measure. Taking livertransplant allocation as a case study, we highlight the potential impact of LD3for modeling fairness in complex decision systems. Results on real-world datademonstrate more plausible causal relations than baselines, which took 197x to5870x longer to execute.</description><author>Jacqueline Maasch, Kyra Gan, Violet Chen, Agni Orfanoudaki, Nil-Jana Akpinar, Fei Wang</author><pubDate>Thu, 23 May 2024 18:56:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14848v1</guid></item><item><title>Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling</title><link>http://arxiv.org/abs/2405.14847v1</link><description>Novel-view synthesis of specular objects like shiny metals or glossy paintsremains a significant challenge. Not only the glossy appearance but also globalillumination effects, including reflections of other objects in theenvironment, are critical components to faithfully reproduce a scene. In thispaper, we present Neural Directional Encoding (NDE), a view-dependentappearance encoding of neural radiance fields (NeRF) for rendering specularobjects. NDE transfers the concept of feature-grid-based spatial encoding tothe angular domain, significantly improving the ability to model high-frequencyangular signals. In contrast to previous methods that use encoding functionswith only angular input, we additionally cone-trace spatial features to obtaina spatially varying directional encoding, which addresses the challenginginterreflection effects. Extensive experiments on both synthetic and realdatasets show that a NeRF model with NDE (1) outperforms the state of the arton view synthesis of specular objects, and (2) works with small networks toallow fast (real-time) inference. The project webpage and source code areavailable at: \url{https://lwwu2.github.io/nde/}.</description><author>Liwen Wu, Sai Bi, Zexiang Xu, Fujun Luan, Kai Zhang, Iliyan Georgiev, Kalyan Sunkavalli, Ravi Ramamoorthi</author><pubDate>Thu, 23 May 2024 18:56:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14847v1</guid></item><item><title>Learning to Detect and Segment Mobile Objects from Unlabeled Videos</title><link>http://arxiv.org/abs/2405.14841v1</link><description>Embodied agents must detect and localize objects of interest, e.g. trafficparticipants for self-driving cars. Supervision in the form of bounding boxesfor this task is extremely expensive. As such, prior work has looked atunsupervised object segmentation, but in the absence of annotated boxes, it isunclear how pixels must be grouped into objects and which objects are ofinterest. This results in over- / under-segmentation and irrelevant objects.Inspired both by the human visual system and by practical applications, weposit that the key missing cue is motion: objects of interest are typicallymobile objects. We propose MOD-UV, a Mobile Object Detector learned fromUnlabeled Videos only. We begin with pseudo-labels derived from motionsegmentation, but introduce a novel training paradigm to progressively discoversmall objects and static-but-mobile objects that are missed by motionsegmentation. As a result, though only learned from unlabeled videos, MOD-UVcan detect and segment mobile objects from a single static image. Empirically,we achieve state-of-the-art performance in unsupervised mobile object detectionon Waymo Open, nuScenes, and KITTI Dataset without using any external data orsupervised models. Code is publicly available athttps://github.com/YihongSun/MOD-UV.</description><author>Yihong Sun, Bharath Hariharan</author><pubDate>Thu, 23 May 2024 18:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14841v1</guid></item><item><title>Differentiable Annealed Importance Sampling Minimizes The Jensen-Shannon Divergence Between Initial and Target Distribution</title><link>http://arxiv.org/abs/2405.14840v1</link><description>Differentiable annealed importance sampling (DAIS), proposed by Geffner &amp;Domke (2021) and Zhang et al. (2021), allows optimizing, among others, over theinitial distribution of AIS. In this paper, we show that, in the limit of manytransitions, DAIS minimizes the symmetrized KL divergence (Jensen-Shannondivergence) between the initial and target distribution. Thus, DAIS can be seenas a form of variational inference (VI) in that its initial distribution is aparametric fit to an intractable target distribution. We empirically evaluatethe usefulness of the initial distribution as a variational distribution onsynthetic and real-world data, observing that it often provides more accurateuncertainty estimates than standard VI (optimizing the reverse KL divergence),importance weighted VI, and Markovian score climbing (optimizing the forward KLdivergence).</description><author>Johannes Zenn, Robert Bamler</author><pubDate>Thu, 23 May 2024 18:55:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14840v1</guid></item><item><title>A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis</title><link>http://arxiv.org/abs/2405.14839v1</link><description>While deep networks have achieved broad success in analyzing natural images,when applied to medical scans, they often fail in unexcepted situations. Weinvestigate this challenge and focus on model sensitivity to domain shifts,such as data sampled from different hospitals or data confounded by demographicvariables such as sex, race, etc, in the context of chest X-rays and skinlesion images. A key finding we show empirically is that existing visualbackbones lack an appropriate prior from the architecture for reliablegeneralization in these settings. Taking inspiration from medical training, wepropose giving deep networks a prior grounded in explicit medical knowledgecommunicated in natural language. To this end, we introduce Knowledge-enhancedBottlenecks (KnoBo), a class of concept bottleneck models that incorporatesknowledge priors that constrain it to reason with clinically relevant factorsfound in medical textbooks or PubMed. KnoBo uses retrieval-augmented languagemodels to design an appropriate concept space paired with an automatic trainingprocedure for recognizing the concept. We evaluate different resources ofknowledge and recognition architectures on a broad range of domain shiftsacross 20 datasets. In our comprehensive evaluation with two imagingmodalities, KnoBo outperforms fine-tuned models on confounded datasets by 32.4%on average. Finally, evaluations reveal that PubMed is a promising resource formaking medical models less sensitive to domain shift, outperforming otherresources on both diversity of information and final prediction performance.</description><author>Yue Yang, Mona Gandhi, Yufei Wang, Yifan Wu, Michael S. Yao, Chris Callison-Burch, James C. Gee, Mark Yatskar</author><pubDate>Thu, 23 May 2024 18:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14839v1</guid></item><item><title>From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step</title><link>http://arxiv.org/abs/2405.14838v1</link><description>When leveraging language models for reasoning tasks, generating explicitchain-of-thought (CoT) steps often proves essential for achieving high accuracyin final outputs. In this paper, we investigate if models can be taught tointernalize these CoT steps. To this end, we propose a simple yet effectivemethod for internalizing CoT steps: starting with a model trained for explicitCoT reasoning, we gradually remove the intermediate steps and finetune themodel. This process allows the model to internalize the intermediate reasoningsteps, thus simplifying the reasoning process while maintaining highperformance. Our approach enables a GPT-2 Small model to solve 9-by-9multiplication with up to 99% accuracy, whereas standard training cannot solvebeyond 4-by-4 multiplication. Furthermore, our method proves effective onlarger language models, such as Mistral 7B, achieving over 50% accuracy onGSM8K without producing any intermediate steps.</description><author>Yuntian Deng, Yejin Choi, Stuart Shieber</author><pubDate>Thu, 23 May 2024 18:54:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14838v1</guid></item><item><title>Analysis of Atom-level pretraining with QM data for Graph Neural Networks Molecular property models</title><link>http://arxiv.org/abs/2405.14837v1</link><description>Despite the rapid and significant advancements in deep learning forQuantitative Structure-Activity Relationship (QSAR) models, the challenge oflearning robust molecular representations that effectively generalize inreal-world scenarios to novel compounds remains an elusive and unresolved task.This study examines how atom-level pretraining with quantum mechanics (QM) datacan mitigate violations of assumptions regarding the distributional similaritybetween training and test data and therefore improve performance andgeneralization in downstream tasks. In the public dataset Therapeutics DataCommons (TDC), we show how pretraining on atom-level QM improves performanceoverall and makes the activation of the features distributes more Gaussian-likewhich results in a representation that is more robust to distribution shifts.To the best of our knowledge, this is the first time that hidden statemolecular representations are analyzed to compare the effects of molecule-leveland atom-level pretraining on QM data.</description><author>Jose Arjona-Medina, Ramil Nugmanov</author><pubDate>Thu, 23 May 2024 18:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14837v1</guid></item><item><title>NormAd: A Benchmark for Measuring the Cultural Adaptability of Large Language Models</title><link>http://arxiv.org/abs/2404.12464v2</link><description>The integration of Large Language Models (LLMs) into various global culturesfundamentally presents a cultural challenge: LLMs must navigate interactions,respect social norms, and avoid transgressing cultural boundaries. However, itis still unclear if LLMs can adapt their outputs to diverse cultural norms. Ourstudy focuses on this aspect. We introduce NormAd, a novel dataset, whichincludes 2.6k stories that represent social and cultural norms from 75countries, to assess the ability of LLMs to adapt to different granular levelsof socio-cultural contexts such as the country of origin, its associatedcultural values, and prevalent social norms. Our study reveals that LLMsstruggle with cultural reasoning across all contextual granularities, showingstronger adaptability to English-centric cultures over those from the GlobalSouth. Even with explicit social norms, the top-performing model,Mistral-7b-Instruct, achieves only 81.8\% accuracy, lagging behind the 95.6\%achieved by humans. Evaluation on NormAd further reveals that LLMs struggle toadapt to stories involving gift-giving across cultures. Due to inherentagreement or sycophancy biases, LLMs find it considerably easier to assess thesocial acceptability of stories that adhere to cultural norms than those thatdeviate from them. Our benchmark measures the cultural adaptability (or lackthereof) of LLMs, emphasizing the potential to make these technologies moreequitable and useful for global audiences. We release the NormAd dataset andits associated code on GitHub.</description><author>Abhinav Rao, Akhila Yerukola, Vishwa Shah, Katharina Reinecke, Maarten Sap</author><pubDate>Thu, 23 May 2024 18:49:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12464v2</guid></item><item><title>Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion Transformer</title><link>http://arxiv.org/abs/2405.14832v1</link><description>Generating high-quality 3D assets from text and images has long beenchallenging, primarily due to the absence of scalable 3D representationscapable of capturing intricate geometry distributions. In this work, weintroduce Direct3D, a native 3D generative model scalable to in-the-wild inputimages, without requiring a multiview diffusion model or SDS optimization. Ourapproach comprises two primary components: a Direct 3D Variational Auto-Encoder(D3D-VAE) and a Direct 3D Diffusion Transformer (D3D-DiT). D3D-VAE efficientlyencodes high-resolution 3D shapes into a compact and continuous latent triplanespace. Notably, our method directly supervises the decoded geometry using asemi-continuous surface sampling strategy, diverging from previous methodsrelying on rendered images as supervision signals. D3D-DiT models thedistribution of encoded 3D latents and is specifically designed to fusepositional information from the three feature maps of the triplane latent,enabling a native 3D generative model scalable to large-scale 3D datasets.Additionally, we introduce an innovative image-to-3D generation pipelineincorporating semantic and pixel-level image conditions, allowing the model toproduce 3D shapes consistent with the provided conditional image input.Extensive experiments demonstrate the superiority of our large-scalepre-trained Direct3D over previous image-to-3D approaches, achievingsignificantly better generation quality and generalization ability, thusestablishing a new state-of-the-art for 3D content creation. Project page:https://nju-3dv.github.io/projects/Direct3D/.</description><author>Shuang Wu, Youtian Lin, Feihu Zhang, Yifei Zeng, Jingxi Xu, Philip Torr, Xun Cao, Yao Yao</author><pubDate>Thu, 23 May 2024 18:49:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14832v1</guid></item><item><title>HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models</title><link>http://arxiv.org/abs/2405.14831v1</link><description>In order to thrive in hostile and ever-changing natural environments,mammalian brains evolved to store large amounts of knowledge about the worldand continually integrate new information while avoiding catastrophicforgetting. Despite the impressive accomplishments, large language models(LLMs), even with retrieval-augmented generation (RAG), still struggle toefficiently and effectively integrate a large amount of new experiences afterpre-training. In this work, we introduce HippoRAG, a novel retrieval frameworkinspired by the hippocampal indexing theory of human long-term memory to enabledeeper and more efficient knowledge integration over new experiences. HippoRAGsynergistically orchestrates LLMs, knowledge graphs, and the PersonalizedPageRank algorithm to mimic the different roles of neocortex and hippocampus inhuman memory. We compare HippoRAG with existing RAG methods on multi-hopquestion answering and show that our method outperforms the state-of-the-artmethods remarkably, by up to 20%. Single-step retrieval with HippoRAG achievescomparable or better performance than iterative retrieval like IRCoT whilebeing 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG intoIRCoT brings further substantial gains. Finally, we show that our method cantackle new types of scenarios that are out of reach of existing methods. Codeand data are available at https://github.com/OSU-NLP-Group/HippoRAG.</description><author>Bernal Jiménez Gutiérrez, Yiheng Shu, Yu Gu, Michihiro Yasunaga, Yu Su</author><pubDate>Thu, 23 May 2024 18:47:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14831v1</guid></item><item><title>Deep learning lattice gauge theories</title><link>http://arxiv.org/abs/2405.14830v1</link><description>Monte Carlo methods have led to profound insights into the strong-couplingbehaviour of lattice gauge theories and produced remarkable results such asfirst-principles computations of hadron masses. Despite tremendous progressover the last four decades, fundamental challenges such as the sign problem andthe inability to simulate real-time dynamics remain. Neural network quantumstates have emerged as an alternative method that seeks to overcome thesechallenges. In this work, we use gauge-invariant neural network quantum statesto accurately compute the ground state of $\mathbb{Z}_N$ lattice gauge theoriesin $2+1$ dimensions. Using transfer learning, we study the distinct topologicalphases and the confinement phase transition of these theories. For$\mathbb{Z}_2$, we identify a continuous transition and compute criticalexponents, finding excellent agreement with existing numerics for the expectedIsing universality class. In the $\mathbb{Z}_3$ case, we observe a weaklyfirst-order transition and identify the critical coupling. Our findings suggestthat neural network quantum states are a promising method for precise studiesof lattice gauge theory.</description><author>Anuj Apte, Anthony Ashmore, Clay Cordova, Tzu-Chen Huang</author><pubDate>Thu, 23 May 2024 18:46:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14830v1</guid></item><item><title>Good Seed Makes a Good Crop: Discovering Secret Seeds in Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2405.14828v1</link><description>Recent advances in text-to-image (T2I) diffusion models have facilitatedcreative and photorealistic image synthesis. By varying the random seeds, wecan generate various images for a fixed text prompt. Technically, the seedcontrols the initial noise and, in multi-step diffusion inference, the noiseused for reparameterization at intermediate timesteps in the reverse diffusionprocess. However, the specific impact of the random seed on the generatedimages remains relatively unexplored. In this work, we conduct a large-scalescientific study into the impact of random seeds during diffusion inference.Remarkably, we reveal that the best 'golden' seed achieved an impressive FID of21.60, compared to the worst 'inferior' seed's FID of 31.97. Additionally, aclassifier can predict the seed number used to generate an image with over99.9% accuracy in just a few epochs, establishing that seeds are highlydistinguishable based on generated images. Encouraged by these findings, weexamined the influence of seeds on interpretable visual dimensions. We findthat certain seeds consistently produce grayscale images, prominent skyregions, or image borders. Seeds also affect image composition, includingobject location, size, and depth. Moreover, by leveraging these 'golden' seeds,we demonstrate improved image generation such as high-fidelity inference anddiversified sampling. Our investigation extends to inpainting tasks, where weuncover some seeds that tend to insert unwanted text artifacts. Overall, ourextensive analyses highlight the importance of selecting good seeds and offerpractical utility for image generation.</description><author>Katherine Xu, Lingzhi Zhang, Jianbo Shi</author><pubDate>Thu, 23 May 2024 18:46:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14828v1</guid></item><item><title>Camera Relocalization in Shadow-free Neural Radiance Fields</title><link>http://arxiv.org/abs/2405.14824v1</link><description>Camera relocalization is a crucial problem in computer vision and robotics.Recent advancements in neural radiance fields (NeRFs) have shown promise insynthesizing photo-realistic images. Several works have utilized NeRFs forrefining camera poses, but they do not account for lighting changes that canaffect scene appearance and shadow regions, causing a degraded poseoptimization process. In this paper, we propose a two-staged pipeline thatnormalizes images with varying lighting and shadow conditions to improve camerarelocalization. We implement our scene representation upon a hash-encoded NeRFwhich significantly boosts up the pose optimization process. To account for thenoisy image gradient computing problem in grid-based NeRFs, we further proposea re-devised truncated dynamic low-pass filter (TDLF) and a numerical gradientaveraging technique to smoothen the process. Experimental results on severaldatasets with varying lighting conditions demonstrate that our method achievesstate-of-the-art results in camera relocalization under varying lightingconditions. Code and data will be made publicly available.</description><author>Shiyao Xu, Caiyun Liu, Yuantao Chen, Zhenxin Zhu, Zike Yan, Yongliang Shi, Hao Zhao, Guyue Zhou</author><pubDate>Thu, 23 May 2024 18:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14824v1</guid></item><item><title>PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher</title><link>http://arxiv.org/abs/2405.14822v1</link><description>To accelerate sampling, diffusion models (DMs) are often distilled intogenerators that directly map noise to data in a single step. In this approach,the resolution of the generator is fundamentally limited by that of the teacherDM. To overcome this limitation, we propose Progressive Growing of DiffusionAutoencoder (PaGoDA), a technique to progressively grow the resolution of thegenerator beyond that of the original teacher DM. Our key insight is that apre-trained, low-resolution DM can be used to deterministically encodehigh-resolution data to a structured latent space by solving the PF-ODE forwardin time (data-to-noise), starting from an appropriately down-sampled image.Using this frozen encoder in an auto-encoder framework, we train a decoder byprogressively growing its resolution. From the nature of progressively growingdecoder, PaGoDA avoids re-training teacher/student models when we upsample thestudent model, making the whole training pipeline much cheaper. In experiments,we used our progressively growing decoder to upsample from the pre-trainedmodel's 64x64 resolution to generate 512x512 samples, achieving 2x fasterinference compared to single-step distilled Stable Diffusion like LCM. PaGoDAalso achieved state-of-the-art FIDs on ImageNet across all resolutions from64x64 to 512x512. Additionally, we demonstrated PaGoDA's effectiveness insolving inverse problems and enabling controllable generation.</description><author>Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon</author><pubDate>Thu, 23 May 2024 18:39:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14822v1</guid></item><item><title>Conformal Validity Guarantees Exist for Any Data Distribution</title><link>http://arxiv.org/abs/2405.06627v2</link><description>As machine learning (ML) gains widespread adoption, practitioners areincreasingly seeking means to quantify and control the risk these systemsincur. This challenge is especially salient when ML systems have autonomy tocollect their own data, such as in black-box optimization and active learning,where their actions induce sequential feedback-loop shifts in the datadistribution. Conformal prediction has emerged as a promising approach touncertainty and risk quantification, but prior variants' validity guaranteeshave assumed some form of ``quasi-exchangeability'' on the data distribution,thereby excluding many types of sequential shifts. In this paper we prove thatconformal prediction can theoretically be extended to \textit{any} joint datadistribution, not just exchangeable or quasi-exchangeable ones, although it isexceedingly impractical to compute in the most general case. For practicalapplications, we outline a procedure for deriving specific conformal algorithmsfor any data distribution, and we use this procedure to derive tractablealgorithms for a series of ML-agent-induced covariate shifts. We evaluate theproposed algorithms empirically on synthetic black-box optimization and activelearning tasks.</description><author>Drew Prinster, Samuel Stanton, Anqi Liu, Suchi Saria</author><pubDate>Thu, 23 May 2024 18:34:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06627v2</guid></item><item><title>A First Look at GPT Apps: Landscape and Vulnerability</title><link>http://arxiv.org/abs/2402.15105v2</link><description>Following OpenAI's introduction of GPTs, a surge in GPT apps has led to thelaunch of dedicated LLM app stores. Nevertheless, given its debut, there is alack of sufficient understanding of this new ecosystem. To fill this gap, thispaper presents a first comprehensive longitudinal (5-month) study of theevolution, landscape, and vulnerability of the emerging LLM app ecosystem,focusing on two GPT app stores: \textit{GPTStore.AI} and the official\textit{OpenAI GPT Store}. Specifically, we develop two automated tools and aTriLevel configuration extraction strategy to efficiently gather metadata (\ienames, creators, descriptions, \etc) and user feedback for all GPT apps acrossthese two stores, as well as configurations (\ie system prompts, knowledgefiles, and APIs) for the top 10,000 popular apps. Our extensive analysisreveals: (1) the user enthusiasm for GPT apps consistently rises, whereascreator interest plateaus within three months of GPTs' launch; (2) nearly 90\%system prompts can be easily accessed due to widespread failure to secure GPTapp configurations, leading to considerable plagiarism and duplication amongapps. Our findings highlight the necessity of enhancing the LLM app ecosystemby the app stores, creators, and users.</description><author>Zejun Zhang, Li Zhang, Xin Yuan, Anlan Zhang, Mengwei Xu, Feng Qian</author><pubDate>Thu, 23 May 2024 18:30:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15105v2</guid></item><item><title>Designing A Sustainable Marine Debris Clean-up Framework without Human Labels</title><link>http://arxiv.org/abs/2405.14815v1</link><description>Marine debris poses a significant ecological threat to birds, fish, and otheranimal life. Traditional methods for assessing debris accumulation involvelabor-intensive and costly manual surveys. This study introduces a frameworkthat utilizes aerial imagery captured by drones to conduct remote trashsurveys. Leveraging computer vision techniques, our approach detects,classifies, and maps marine debris distributions. The framework uses GroundingDINO, a transformer-based zero-shot object detector, and CLIP, avision-language model for zero-shot object classification, enabling thedetection and classification of debris objects based on material type withoutthe need for training labels. To mitigate over-counting due to different viewsof the same object, Scale-Invariant Feature Transform (SIFT) is employed forduplicate matching using local object features. Additionally, we have developeda user-friendly web application that facilitates end-to-end analysis of droneimages, including object detection, classification, and visualization on a mapto support cleanup efforts. Our method achieves competitive performance indetection (0.69 mean IoU) and classification (0.74 F1 score) across sevendebris object classes without labeled data, comparable to state-of-the-artsupervised methods. This framework has the potential to streamline automatedtrash sampling surveys, fostering efficient and sustainable community-ledcleanup initiatives.</description><author>Raymond Wang, Nicholas R. Record, D. Whitney King, Tahiya Chowdhury</author><pubDate>Thu, 23 May 2024 18:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14815v1</guid></item><item><title>Overview of the EHRSQL 2024 Shared Task on Reliable Text-to-SQL Modeling on Electronic Health Records</title><link>http://arxiv.org/abs/2405.06673v2</link><description>Electronic Health Records (EHRs) are relational databases that store theentire medical histories of patients within hospitals. They record numerousaspects of patients' medical care, from hospital admission and diagnosis totreatment and discharge. While EHRs are vital sources of clinical data,exploring them beyond a predefined set of queries requires skills in querylanguages like SQL. To make information retrieval more accessible, one strategyis to build a question-answering system, possibly leveraging text-to-SQL modelsthat can automatically translate natural language questions into correspondingSQL queries and use these queries to retrieve the answers. The EHRSQL 2024shared task aims to advance and promote research in developing aquestion-answering system for EHRs using text-to-SQL modeling, capable ofreliably providing requested answers to various healthcare professionals toimprove their clinical work processes and satisfy their needs. Among more than100 participants who applied to the shared task, eight teams were formed andcompleted the entire shared task requirement and demonstrated a wide range ofmethods to effectively solve this task. In this paper, we describe the task ofreliable text-to-SQL modeling, the dataset, and the methods and results of theparticipants. We hope this shared task will spur further research and insightsinto developing reliable question-answering systems for EHRs.</description><author>Gyubok Lee, Sunjun Kweon, Seongsu Bae, Edward Choi</author><pubDate>Thu, 23 May 2024 18:25:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06673v2</guid></item><item><title>Scalable Optimization in the Modular Norm</title><link>http://arxiv.org/abs/2405.14813v1</link><description>To improve performance in contemporary deep learning, one is interested inscaling up the neural network in terms of both the number and the size of thelayers. When ramping up the width of a single layer, graceful scaling oftraining has been linked to the need to normalize the weights and their updatesin the "natural norm" particular to that layer. In this paper, we significantlygeneralize this idea by defining the modular norm, which is the natural norm onthe full weight space of any neural network architecture. The modular norm isdefined recursively in tandem with the network architecture itself. We showthat the modular norm has several promising applications. On the practicalside, the modular norm can be used to normalize the updates of any baseoptimizer so that the learning rate becomes transferable across width anddepth. This means that the user does not need to compute optimizer-specificscale factors in order to scale training. On the theoretical side, we show thatfor any neural network built from "well-behaved" atomic modules, the gradientof the network is Lipschitz-continuous in the modular norm, with the Lipschitzconstant admitting a simple recursive formula. This characterization opens thedoor to porting standard ideas in optimization theory over to deep learning. Wehave created a Python package called Modula that automatically normalizesweight updates in the modular norm of the architecture. The package isavailable via "pip install modula" with source code athttps://github.com/jxbz/modula.</description><author>Tim Large, Yang Liu, Minyoung Huh, Hyojin Bahng, Phillip Isola, Jeremy Bernstein</author><pubDate>Thu, 23 May 2024 18:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14813v1</guid></item><item><title>Implicit Personalization in Language Models: A Systematic Study</title><link>http://arxiv.org/abs/2405.14808v1</link><description>Implicit Personalization (IP) is a phenomenon of language models inferring auser's background from the implicit cues in the input prompts and tailoring theresponse based on this inference. While previous work has touched upon variousinstances of this problem, there lacks a unified framework to study thisbehavior. This work systematically studies IP through a rigorous mathematicalformulation, a multi-perspective moral reasoning framework, and a set of casestudies. Our theoretical foundation for IP relies on a structural causal modeland introduces a novel method, indirect intervention, to estimate the causaleffect of a mediator variable that cannot be directly intervened upon. Beyondthe technical approach, we also introduce a set of moral reasoning principlesbased on three schools of moral philosophy to study when IP may or may not beethically appropriate. Equipped with both mathematical and ethical insights, wepresent three diverse case studies illustrating the varied nature of the IPproblem and offer recommendations for future research. Our code and data are athttps://github.com/jiarui-liu/IP.</description><author>Zhijing Jin, Nils Heil, Jiarui Liu, Shehzaad Dhuliawala, Yahang Qi, Bernhard Schölkopf, Rada Mihalcea, Mrinmaya Sachan</author><pubDate>Thu, 23 May 2024 18:18:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14808v1</guid></item><item><title>Efficient Encoder-Decoder Transformer Decoding for Decomposable Tasks</title><link>http://arxiv.org/abs/2403.13112v2</link><description>Transformer-based NLP models are powerful but have high computational coststhat limit deployment. Finetuned encoder-decoder models are popular inspecialized domains and can outperform larger more generalized decoder-onlymodels, such as GPT-4. We introduce a new configuration for encoder-decodermodels that improves efficiency on structured output and decomposable taskswhere multiple outputs are required for a single shared input. Our method,prompt-in-decoder (PiD), encodes the input once and decodes the output inparallel, boosting both training and inference efficiency by avoiding duplicateinput encoding and increasing the operational intensity (ratio of numbers ofarithmetic operation to memory access) of decoding process by sharing the inputkey-value cache. We achieve computation reduction that roughly scales with thenumber of subtasks, gaining up to 4.6x speed-up over state-of-the-art modelsfor dialogue state tracking, summarization, and question-answering tasks, withcomparable or better performance.</description><author>Bo-Ru Lu, Nikita Haduong, Chien-Yu Lin, Hao Cheng, Noah A. Smith, Mari Ostendorf</author><pubDate>Thu, 23 May 2024 18:17:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13112v2</guid></item><item><title>Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics</title><link>http://arxiv.org/abs/2405.14806v1</link><description>Extracting scientific understanding from particle-physics experimentsrequires solving diverse learning problems with high precision and good dataefficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), anew multi-purpose architecture for high-energy physics. L-GATr representshigh-energy data in a geometric algebra over four-dimensional space-time and isequivariant under Lorentz transformations, the symmetry group of relativistickinematics. At the same time, the architecture is a Transformer, which makes itversatile and scalable to large systems. L-GATr is first demonstrated onregression and classification tasks from particle physics. We then constructthe first Lorentz-equivariant generative model: a continuous normalizing flowbased on an L-GATr network, trained with Riemannian flow matching. Across ourexperiments, L-GATr is on par with or outperforms strong domain-specificbaselines.</description><author>Jonas Spinner, Victor Bresó, Pim de Haan, Tilman Plehn, Jesse Thaler, Johann Brehmer</author><pubDate>Thu, 23 May 2024 18:15:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14806v1</guid></item><item><title>Can LLMs Solve longer Math Word Problems Better?</title><link>http://arxiv.org/abs/2405.14804v1</link><description>Math Word Problems (MWPs) are crucial for evaluating the capability of LargeLanguage Models (LLMs), with current research primarily focusing on questionswith concise contexts. However, as real-world math problems often involvecomplex circumstances, LLMs' ability to solve long MWPs is vital for theirapplications in these scenarios, yet remains under-explored. This studypioneers the exploration of Context Length Generalizability (CoLeG), theability of LLMs to solve long MWPs. We introduce Extended Grade-School Math(E-GSM), a collection of MWPs with lengthy narratives. Two novel metrics areproposed to assess the efficacy and resilience of LLMs in solving theseproblems. Our examination of existing zero-shot prompting techniques and bothproprietary and open-source LLMs reveals a general deficiency in CoLeG. Toalleviate these challenges, we propose distinct approaches for differentcategories of LLMs. For proprietary LLMs, a new instructional prompt isproposed to mitigate the influence of long context. For open-source LLMs, a newdata augmentation task is developed to improve CoLeG. Our comprehensive resultsdemonstrate the effectiveness of our proposed methods, showing not onlyimproved performance on E-GSM but also generalizability across several otherMWP benchmarks. Our findings pave the way for future research in employing LLMsfor complex, real-world applications, offering practical solutions to currentlimitations and opening avenues for further exploration of modelgeneralizability and training methodologies.</description><author>Xin Xu, Tong Xiao, Zitong Chao, Zhenya Huang, Can Yang, Yang Wang</author><pubDate>Thu, 23 May 2024 18:13:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14804v1</guid></item><item><title>Fast Denoising Diffusion Probabilistic Models for Medical Image-to-Image Generation</title><link>http://arxiv.org/abs/2405.14802v1</link><description>Denoising diffusion probabilistic models (DDPMs) have achieved unprecedentedsuccess in computer vision. However, they remain underutilized in medicalimaging, a field crucial for disease diagnosis and treatment planning. This isprimarily due to the high computational cost associated with (1) the use oflarge number of time steps (e.g., 1,000) in diffusion processes and (2) theincreased dimensionality of medical images, which are often 3D or 4D. Traininga diffusion model on medical images typically takes days to weeks, whilesampling each image volume takes minutes to hours. To address this challenge,we introduce Fast-DDPM, a simple yet effective approach capable of improvingtraining speed, sampling speed, and generation quality simultaneously. UnlikeDDPM, which trains the image denoiser across 1,000 time steps, Fast-DDPM trainsand samples using only 10 time steps. The key to our method lies in aligningthe training and sampling procedures. We introduced two efficient noiseschedulers with 10 time steps: one with uniform time step sampling and anotherwith non-uniform sampling. We evaluated Fast-DDPM across three medicalimage-to-image generation tasks: multi-image super-resolution, image denoising,and image-to-image translation. Fast-DDPM outperformed DDPM and currentstate-of-the-art methods based on convolutional networks and generativeadversarial networks in all tasks. Additionally, Fast-DDPM reduced trainingtime by a factor of 5 and sampling time by a factor of 100 compared to DDPM.Our code is publicly available at: https://github.com/mirthAI/Fast-DDPM.</description><author>Hongxu Jiang, Muhammad Imran, Linhai Ma, Teng Zhang, Yuyin Zhou, Muxuan Liang, Kuang Gong, Wei Shao</author><pubDate>Thu, 23 May 2024 18:12:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14802v1</guid></item><item><title>Chain of Thought Empowers Transformers to Solve Inherently Serial Problems</title><link>http://arxiv.org/abs/2402.12875v3</link><description>Instructing the model to generate a sequence of intermediate steps, a.k.a., achain of thought (CoT), is a highly effective method to improve the accuracy oflarge language models (LLMs) on arithmetics and symbolic reasoning tasks.However, the mechanism behind CoT remains unclear. This work provides atheoretical understanding of the power of CoT for decoder-only transformersthrough the lens of expressiveness. Conceptually, CoT empowers the model withthe ability to perform inherently serial computation, which is otherwiselacking in transformers, especially when depth is low. Given input length $n$,previous works have shown that constant-depth transformers with finiteprecision $\mathsf{poly}(n)$ embedding size can only solve problems in$\mathsf{TC}^0$ without CoT. We first show an even tighter expressiveness upperbound for constant-depth transformers with constant-bit precision, which canonly solve problems in $\mathsf{AC}^0$, a proper subset of $ \mathsf{TC}^0$.However, with $T$ steps of CoT, constant-depth transformers using constant-bitprecision and $O(\log n)$ embedding size can solve any problem solvable byboolean circuits of size $T$. Empirically, enabling CoT dramatically improvesthe accuracy for tasks that are hard for parallel computation, including thecomposition of permutation groups, iterated squaring, and circuit valueproblems, especially for low-depth transformers.</description><author>Zhiyuan Li, Hong Liu, Denny Zhou, Tengyu Ma</author><pubDate>Thu, 23 May 2024 18:10:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12875v3</guid></item><item><title>Membership Inference on Text-to-Image Diffusion Models via Conditional Likelihood Discrepancy</title><link>http://arxiv.org/abs/2405.14800v1</link><description>Text-to-image diffusion models have achieved tremendous success in the fieldof controllable image generation, while also coming along with issues ofprivacy leakage and data copyrights. Membership inference arises in thesecontexts as a potential auditing method for detecting unauthorized data usage.While some efforts have been made on diffusion models, they are not applicableto text-to-image diffusion models due to the high computation overhead andenhanced generalization capabilities. In this paper, we first identify aconditional overfitting phenomenon in text-to-image diffusion models,indicating that these models tend to overfit the conditional distribution ofimages given the text rather than the marginal distribution of images. Based onthis observation, we derive an analytical indicator, namely ConditionalLikelihood Discrepancy (CLiD), to perform membership inference. This indicatorreduces the stochasticity in estimating the memorization of individual samples.Experimental results demonstrate that our method significantly outperformsprevious methods across various data distributions and scales. Additionally,our method shows superior resistance to overfitting mitigation strategies suchas early stopping and data augmentation.</description><author>Shengfang Zhai, Huanran Chen, Yinpeng Dong, Jiajun Li, Qingni Shen, Yansong Gao, Hang Su, Yang Liu</author><pubDate>Thu, 23 May 2024 18:09:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14800v1</guid></item><item><title>Generative Plant Growth Simulation from Sequence-Informed Environmental Conditions</title><link>http://arxiv.org/abs/2405.14796v1</link><description>A plant growth simulation can be characterized as a reconstructed visualrepresentation of a plant or plant system. The phenotypic characteristics andplant structures are controlled by the scene environment and other contextualattributes. Considering the temporal dependencies and compounding effects ofvarious factors on growth trajectories, we formulate a probabilistic approachto the simulation task by solving a frame synthesis and pattern recognitionproblem. We introduce a Sequence-Informed Plant Growth Simulation framework(SI-PGS) that employs a conditional generative model to implicitly learn adistribution of possible plant representations within a dynamic scene from afusion of low dimensional temporal sensor and context data. Methods such ascontrolled latent sampling and recurrent output connections are used to improvecoherence in plant structures between frames of predictions. In this work, wedemonstrate that SI-PGS is able to capture temporal dependencies andcontinuously generate realistic frames of a plant scene.</description><author>Mohamed Debbagh, Yixue Liu, Zhouzhou Zheng, Xintong Jiang, Shangpeng Sun, Mark Lefsrud</author><pubDate>Thu, 23 May 2024 18:06:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14796v1</guid></item><item><title>Image Classification in High-Energy Physics: A Comprehensive Survey of Applications to Jet Analysis</title><link>http://arxiv.org/abs/2403.11934v2</link><description>Nowadays, there has been a growing trend in the fields of high-energy physics(HEP) in its both parts experimental and phenomenological studies, toincorporate machine learning (ML) and its specialized branch, deep learning(DL). This review paper provides a thorough illustration of these applicationsusing different DL approaches. The first part of the paper examines the basicsof various particle physics types and sets up guidelines for assessing particlephysics alongside the available learning models. Next, a detailedclassification is provided for representing the jet images that arereconstructed in high energy collisions mainly with proton-proton collisions atwell defined beam energies, covering various datasets, preprocessingtechniques, and feature extraction and selection methods. The presentedtechniques can be applied to future hadron-hadron colliders (HLC) such as highluminosity LHC (HL-HLC) and future circular collider-hadron-hadron (FCC-hh).Next, the authors explore a number of AI models analysis designed specificallyfor images in HEP. We additionally undertake a closer look at theclassification associated with images in hadron collisions, with an emphasis onJets. In this review, we look into various state-of-the-art (SOTA) techniquesin ML and DL, examining their implications for HEP demands. More precisely,this discussion tackles various applications in extensive detail, such as Jettagging, Jet tracking, particle classification, and more. The review concludeswith an analysis of the current state of HEP, using DL methodologies. It coversthe challenges and potential areas for future research that will be illustratedfor each application.</description><author>Hamza Kheddar, Yassine Himeur, Abbes Amira, Rachik Soualah</author><pubDate>Thu, 23 May 2024 18:06:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11934v2</guid></item><item><title>SEA-RAFT: Simple, Efficient, Accurate RAFT for Optical Flow</title><link>http://arxiv.org/abs/2405.14793v1</link><description>We introduce SEA-RAFT, a more simple, efficient, and accurate RAFT foroptical flow. Compared with RAFT, SEA-RAFT is trained with a new loss (mixtureof Laplace). It directly regresses an initial flow for faster convergence initerative refinements and introduces rigid-motion pre-training to improvegeneralization. SEA-RAFT achieves state-of-the-art accuracy on the Springbenchmark with a 3.69 endpoint-error (EPE) and a 0.36 1-pixel outlier rate(1px), representing 22.9% and 17.8% error reduction from best publishedresults. In addition, SEA-RAFT obtains the best cross-dataset generalization onKITTI and Spring. With its high efficiency, SEA-RAFT operates at least 2.3xfaster than existing methods while maintaining competitive performance. Thecode is publicly available at https://github.com/princeton-vl/SEA-RAFT.</description><author>Yihan Wang, Lahav Lipson, Jia Deng</author><pubDate>Thu, 23 May 2024 18:04:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14793v1</guid></item><item><title>Recurrent Early Exits for Federated Learning with Heterogeneous Clients</title><link>http://arxiv.org/abs/2405.14791v1</link><description>Federated learning (FL) has enabled distributed learning of a model acrossmultiple clients in a privacy-preserving manner. One of the main challenges ofFL is to accommodate clients with varying hardware capacities; clients havediffering compute and memory requirements. To tackle this challenge, recentstate-of-the-art approaches leverage the use of early exits. Nonetheless, theseapproaches fall short of mitigating the challenges of joint learning multipleexit classifiers, often relying on hand-picked heuristic solutions forknowledge distillation among classifiers and/or utilizing additional layers forweaker classifiers. In this work, instead of utilizing multiple classifiers, wepropose a recurrent early exit approach named ReeFL that fuses features fromdifferent sub-models into a single shared classifier. Specifically, we use atransformer-based early-exit module shared among sub-models to i) betterexploit multi-layer feature representations for task-specific prediction andii) modulate the feature representation of the backbone model for subsequentpredictions. We additionally present a per-client self-distillation approachwhere the best sub-model is automatically selected as the teacher of the othersub-models at each client. Our experiments on standard image and speechclassification benchmarks across various emerging federated fine-tuningbaselines demonstrate ReeFL's effectiveness over previous works.</description><author>Royson Lee, Javier Fernandez-Marques, Shell Xu Hu, Da Li, Stefanos Laskaridis, Łukasz Dudziak, Timothy Hospedales, Ferenc Huszár, Nicholas D. Lane</author><pubDate>Thu, 23 May 2024 18:01:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14791v1</guid></item><item><title>DIDI: Diffusion-Guided Diversity for Offline Behavioral Generation</title><link>http://arxiv.org/abs/2405.14790v1</link><description>In this paper, we propose a novel approach called DIffusion-guided DIversity(DIDI) for offline behavioral generation. The goal of DIDI is to learn adiverse set of skills from a mixture of label-free offline data. We achievethis by leveraging diffusion probabilistic models as priors to guide thelearning process and regularize the policy. By optimizing a joint objectivethat incorporates diversity and diffusion-guided regularization, we encouragethe emergence of diverse behaviors while maintaining the similarity to theoffline data. Experimental results in four decision-making domains (Push,Kitchen, Humanoid, and D4RL tasks) show that DIDI is effective in discoveringdiverse and discriminative skills. We also introduce skill stitching and skillinterpolation, which highlight the generalist nature of the learned skillspace. Further, by incorporating an extrinsic reward function, DIDI enablesreward-guided behavior generation, facilitating the learning of diverse andoptimal behaviors from sub-optimal data.</description><author>Jinxin Liu, Xinghong Guo, Zifeng Zhuang, Donglin Wang</author><pubDate>Thu, 23 May 2024 18:00:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14790v1</guid></item><item><title>Masked Image Modelling for retinal OCT understanding</title><link>http://arxiv.org/abs/2405.14788v1</link><description>This work explores the effectiveness of masked image modelling for learningrepresentations of retinal OCT images. To this end, we leverage MaskedAutoencoders (MAE), a simple and scalable method for self-supervised learning,to obtain a powerful and general representation for OCT images by training on700K OCT images from 41K patients collected under real world clinical settings.We also provide the first extensive evaluation for a model of OCT on achallenging battery of 6 downstream tasks. Our model achieves strongperformance when fully finetuned but can also serve as a versatile frozenfeature extractor for many tasks using lightweight adapters. Furthermore, wepropose an extension of the MAE pretraining to fuse OCT with an auxiliarymodality, namely, IR fundus images and learn a joint model for both. Wedemonstrate our approach improves performance on a multimodal downstreamapplication. Our experiments utilize most publicly available OCT datasets, thusenabling future comparisons. Our code and model weights are publicly availablehttps://github.com/TheoPis/MIM_OCT.</description><author>Theodoros Pissas, Pablo Márquez-Neila, Sebastian Wolf, Martin Zinkernagel, Raphael Sznitman</author><pubDate>Thu, 23 May 2024 17:57:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14788v1</guid></item><item><title>EditWorld: Simulating World Dynamics for Instruction-Following Image Editing</title><link>http://arxiv.org/abs/2405.14785v1</link><description>Diffusion models have significantly improved the performance of imageediting. Existing methods realize various approaches to achieve high-qualityimage editing, including but not limited to text control, dragging operation,and mask-and-inpainting. Among these, instruction-based editing stands out forits convenience and effectiveness in following human instructions acrossdiverse scenarios. However, it still focuses on simple editing operations likeadding, replacing, or deleting, and falls short of understanding aspects ofworld dynamics that convey the realistic dynamic nature in the physical world.Therefore, this work, EditWorld, introduces a new editing task, namelyworld-instructed image editing, which defines and categorizes the instructionsgrounded by various world scenarios. We curate a new image editing dataset withworld instructions using a set of large pretrained models (e.g., GPT-3.5,Video-LLava and SDXL). To enable sufficient simulation of world dynamics forimage editing, our EditWorld trains model in the curated dataset, and improvesinstruction-following ability with designed post-edit strategy. Extensiveexperiments demonstrate our method significantly outperforms existing editingmethods in this new task. Our dataset and code will be available athttps://github.com/YangLing0818/EditWorld</description><author>Ling Yang, Bohan Zeng, Jiaming Liu, Hong Li, Minghao Xu, Wentao Zhang, Shuicheng Yan</author><pubDate>Thu, 23 May 2024 17:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14785v1</guid></item><item><title>Conformal prediction for multi-dimensional time series by ellipsoidal sets</title><link>http://arxiv.org/abs/2403.03850v2</link><description>Conformal prediction (CP) has been a popular method for uncertaintyquantification because it is distribution-free, model-agnostic, andtheoretically sound. For forecasting problems in supervised learning, most CPmethods focus on building prediction intervals for univariate responses. Inthis work, we develop a sequential CP method called $\texttt{MultiDimSPCI}$that builds prediction $\textit{regions}$ for a multivariate response,especially in the context of multivariate time series, which are notexchangeable. Theoretically, we estimate $\textit{finite-sample}$high-probability bounds on the conditional coverage gap. Empirically, wedemonstrate that $\texttt{MultiDimSPCI}$ maintains valid coverage on a widerange of multivariate time series while producing smaller prediction regionsthan CP and non-CP baselines.</description><author>Chen Xu, Hanyang Jiang, Yao Xie</author><pubDate>Thu, 23 May 2024 17:51:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03850v2</guid></item><item><title>SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 13 Languages</title><link>http://arxiv.org/abs/2402.08638v4</link><description>Exploring and quantifying semantic relatedness is central to representinglanguage and holds significant implications across various NLP tasks. Whileearlier NLP research primarily focused on semantic similarity, often within theEnglish language context, we instead investigate the broader phenomenon ofsemantic relatedness. In this paper, we present \textit{SemRel}, a new semanticrelatedness dataset collection annotated by native speakers across 13languages: \textit{Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi,Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic,Spanish,} and \textit{Telugu}. These languages originate from five distinctlanguage families and are predominantly spoken in Africa and Asia -- regionscharacterised by a relatively limited availability of NLP resources. Eachinstance in the SemRel datasets is a sentence pair associated with a score thatrepresents the degree of semantic textual relatedness between the twosentences. The scores are obtained using a comparative annotation framework. Wedescribe the data collection and annotation processes, challenges when buildingthe datasets, baseline experiments, and their impact and utility in NLP.</description><author>Nedjma Ousidhoum, Shamsuddeen Hassan Muhammad, Mohamed Abdalla, Idris Abdulmumin, Ibrahim Said Ahmad, Sanchit Ahuja, Alham Fikri Aji, Vladimir Araujo, Abinew Ali Ayele, Pavan Baswani, Meriem Beloucif, Chris Biemann, Sofia Bourhim, Christine De Kock, Genet Shanko Dekebo, Oumaima Hourrane, Gopichand Kanumolu, Lokesh Madasu, Samuel Rutunda, Manish Shrivastava, Thamar Solorio, Nirmal Surange, Hailegnaw Getaneh Tilaye, Krishnapriya Vishnubhotla, Genta Winata, Seid Muhie Yimam, Saif M. Mohammad</author><pubDate>Thu, 23 May 2024 17:51:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08638v4</guid></item><item><title>Lessons from the Trenches on Reproducible Evaluation of Language Models</title><link>http://arxiv.org/abs/2405.14782v1</link><description>Effective evaluation of language models remains an open challenge in NLP.Researchers and engineers face methodological issues such as the sensitivity ofmodels to evaluation setup, difficulty of proper comparisons across methods,and the lack of reproducibility and transparency. In this paper we draw onthree years of experience in evaluating large language models to provideguidance and lessons for researchers. First, we provide an overview of commonchallenges faced in language model evaluation. Second, we delineate bestpractices for addressing or lessening the impact of these challenges onresearch. Third, we present the Language Model Evaluation Harness (lm-eval): anopen source library for independent, reproducible, and extensible evaluation oflanguage models that seeks to address these issues. We describe the features ofthe library as well as case studies in which the library has been used toalleviate these methodological concerns.</description><author>Stella Biderman, Hailey Schoelkopf, Lintang Sutawika, Leo Gao, Jonathan Tow, Baber Abbasi, Alham Fikri Aji, Pawan Sasanka Ammanamanchi, Sidney Black, Jordan Clive, Anthony DiPofi, Julen Etxaniz, Benjamin Fattori, Jessica Zosa Forde, Charles Foster, Mimansa Jaiswal, Wilson Y. Lee, Haonan Li, Charles Lovering, Niklas Muennighoff, Ellie Pavlick, Jason Phang, Aviya Skowron, Samson Tan, Xiangru Tang, Kevin A. Wang, Genta Indra Winata, François Yvon, Andy Zou</author><pubDate>Thu, 23 May 2024 17:50:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14782v1</guid></item><item><title>Prediction-Powered Ranking of Large Language Models</title><link>http://arxiv.org/abs/2402.17826v2</link><description>Large language models are often ranked according to their level of alignmentwith human preferences -- a model is better than other models if its outputsare more frequently preferred by humans. One of the popular ways to elicithuman preferences utilizes pairwise comparisons between the outputs provided bydifferent models to the same inputs. However, since gathering pairwisecomparisons by humans is costly and time-consuming, it has become a commonpractice to gather pairwise comparisons by a strong large language model -- amodel strongly aligned with human preferences. Surprisingly, practitionerscannot currently measure the uncertainty that any mismatch between human andmodel preferences may introduce in the constructed rankings. In this work, wedevelop a statistical framework to bridge this gap. Given a (small) set ofpairwise comparisons by humans and a large set of pairwise comparisons by amodel, our framework provides a rank-set -- a set of possible ranking positions-- for each of the models under comparison. Moreover, it guarantees that, witha probability greater than or equal to a user-specified value, the rank-setscover the true ranking consistent with the distribution of human pairwisepreferences asymptotically. Using pairwise comparisons made by humans in theLMSYS Chatbot Arena platform and pairwise comparisons made by three stronglarge language models, we empirically demonstrate the effectivity of ourframework and show that the rank-sets constructed using only pairwisecomparisons by the strong large language models are often inconsistent with(the distribution of) human pairwise preferences.</description><author>Ivi Chatzi, Eleni Straitouri, Suhas Thejaswi, Manuel Gomez Rodriguez</author><pubDate>Thu, 23 May 2024 17:50:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17826v2</guid></item><item><title>Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning</title><link>http://arxiv.org/abs/2405.14781v1</link><description>The application of deep neural network models in various security-criticalapplications has raised significant security concerns, particularly the risk ofbackdoor attacks. Neural backdoors pose a serious security threat as they allowattackers to maliciously alter model behavior. While many defenses have beenexplored, existing approaches are often bounded by model-specific constraints,or necessitate complex alterations to the training process, or fall shortagainst diverse backdoor attacks. In this work, we introduce a novel method forcomprehensive and effective elimination of backdoors, called ULRL (short forUnLearn and ReLearn for backdoor removal). ULRL requires only a small set ofclean samples and works effectively against all kinds of backdoors. It firstapplies unlearning for identifying suspicious neurons and then targeted neuralweight tuning for backdoor mitigation (i.e., by promoting significant weightdeviation on the suspicious neurons). Evaluated against 12 different types ofbackdoors, ULRL is shown to significantly outperform state-of-the-art methodsin eliminating backdoors whilst preserving the model utility.</description><author>Nay Myat Min, Long H. Pham, Jun Sun</author><pubDate>Thu, 23 May 2024 17:49:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14781v1</guid></item><item><title>Metric Flow Matching for Smooth Interpolations on the Data Manifold</title><link>http://arxiv.org/abs/2405.14780v1</link><description>Matching objectives underpin the success of modern generative models and relyon constructing conditional paths that transform a source distribution into atarget distribution. Despite being a fundamental building block, conditionalpaths have been designed principally under the assumption of Euclideangeometry, resulting in straight interpolations. However, this can beparticularly restrictive for tasks such as trajectory inference, where straightpaths might lie outside the data manifold, thus failing to capture theunderlying dynamics giving rise to the observed marginals. In this paper, wepropose Metric Flow Matching (MFM), a novel simulation-free framework forconditional flow matching where interpolants are approximate geodesics learnedby minimizing the kinetic energy of a data-induced Riemannian metric. This way,the generative model matches vector fields on the data manifold, whichcorresponds to lower uncertainty and more meaningful interpolations. Weprescribe general metrics to instantiate MFM, independent of the task, and testit on a suite of challenging problems including LiDAR navigation, unpairedimage translation, and modeling cellular dynamics. We observe that MFMoutperforms the Euclidean baselines, particularly achieving SOTA on single-celltrajectory prediction.</description><author>Kacper Kapusniak, Peter Potaptchik, Teodora Reu, Leo Zhang, Alexander Tong, Michael Bronstein, Avishek Joey Bose, Francesco Di Giovanni</author><pubDate>Thu, 23 May 2024 17:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14780v1</guid></item><item><title>Smart Bilingual Focused Crawling of Parallel Documents</title><link>http://arxiv.org/abs/2405.14779v1</link><description>Crawling parallel texts $\unicode{x2014}$texts that are mutualtranslations$\unicode{x2014}$ from the Internet is usually done following abrute-force approach: documents are massively downloaded in an unguidedprocess, and only a fraction of them end up leading to actual parallel content.In this work we propose a smart crawling method that guides the crawl towardsfinding parallel content more rapidly. Our approach builds on two differentmodels: one that infers the language of a document from its URL, and anotherthat infers whether a pair of URLs link to parallel documents. We evaluate bothmodels in isolation and their integration into a crawling tool. The resultsdemonstrate the individual effectiveness of both models and highlight thattheir combination enables the early discovery of parallel content duringcrawling, leading to a reduction in the amount of downloaded documents deemeduseless, and yielding a greater quantity of parallel documents compared toconventional crawling approaches.</description><author>Cristian García-Romero, Miquel Esplà-Gomis, Felipe Sánchez-Martínez</author><pubDate>Thu, 23 May 2024 17:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14779v1</guid></item><item><title>Optimal Rates for Vector-Valued Spectral Regularization Learning Algorithms</title><link>http://arxiv.org/abs/2405.14778v1</link><description>We study theoretical properties of a broad class of regularized algorithmswith vector-valued output. These spectral algorithms include kernel ridgeregression, kernel principal component regression, various implementations ofgradient descent and many more. Our contributions are twofold. First, werigorously confirm the so-called saturation effect for ridge regression withvector-valued output by deriving a novel lower bound on learning rates; thisbound is shown to be suboptimal when the smoothness of the regression functionexceeds a certain level. Second, we present the upper bound for the finitesample risk general vector-valued spectral algorithms, applicable to bothwell-specified and misspecified scenarios (where the true regression functionlies outside of the hypothesis space) which is minimax optimal in variousregimes. All of our results explicitly allow the case of infinite-dimensionaloutput variables, proving consistency of recent practical applications.</description><author>Dimitri Meunier, Zikai Shen, Mattes Mollenhauer, Arthur Gretton, Zhu Li</author><pubDate>Thu, 23 May 2024 17:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14778v1</guid></item><item><title>Sample Complexity of Algorithm Selection Using Neural Networks and Its Applications to Branch-and-Cut</title><link>http://arxiv.org/abs/2402.02328v2</link><description>Data-driven algorithm design is a paradigm that uses statistical and machinelearning techniques to select from a class of algorithms for a computationalproblem an algorithm that has the best expected performance with respect tosome (unknown) distribution on the instances of the problem. We build uponrecent work in this line of research by considering the setup where, instead ofselecting a single algorithm that has the best performance, we allow thepossibility of selecting an algorithm based on the instance to be solved, usingneural networks. In particular, given a representative sample of instances, welearn a neural network that maps an instance of the problem to the mostappropriate algorithm for that instance. We formalize this idea and deriverigorous sample complexity bounds for this learning problem, in the spirit ofrecent work in data-driven algorithm design. We then apply this approach to theproblem of making good decisions in the branch-and-cut framework formixed-integer optimization (e.g., which cut to add?). In other words, theneural network will take as input a mixed-integer optimization instance andoutput a decision that will result in a small branch-and-cut tree for thatinstance. Our computational results provide evidence that our particular way ofusing neural networks for cut selection can make a significant impact inreducing branch-and-cut tree sizes, compared to previous data-drivenapproaches.</description><author>Hongyu Cheng, Sammy Khalife, Barbara Fiedorowicz, Amitabh Basu</author><pubDate>Thu, 23 May 2024 17:45:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02328v2</guid></item><item><title>Kinetics of orbital ordering in cooperative Jahn-Teller models: Machine-learning enabled large-scale simulations</title><link>http://arxiv.org/abs/2405.14776v1</link><description>We present a scalable machine learning (ML) force-field model for theadiabatic dynamics of cooperative Jahn-Teller (JT) systems. Large scaledynamical simulations of the JT model also shed light on the orbital orderingdynamics in colossal magnetoresistance manganites. The JT effect in thesematerials describes the distortion of local oxygen octahedra driven by acoupling to the orbital degrees of freedom of $e_g$ electrons. An effectiveelectron-mediated interaction between the local JT modes leads to a structuraltransition and the emergence of long-range orbital order at low temperatures.Assuming the principle of locality, a deep-learning neural-network model isdeveloped to accurately and efficiently predict the electron-induced forcesthat drive the dynamical evolution of JT phonons. A group-theoretical method isutilized to develop a descriptor that incorporates the combined orbital andlattice symmetry into the ML model. Large-scale Langevin dynamics simulations,enabled by the ML force-field models, are performed to investigate thecoarsening dynamics of the composite JT distortion and orbital order after athermal quench. The late-stage coarsening of orbital domains exhibitspronounced freezing behaviors which are likely related to the unusualmorphology of the domain structures. Our work highlights a promising avenue formulti-scale dynamical modeling of correlated electron systems.</description><author>Supriyo Ghosh, Sheng Zhang, Chen Cheng, Gia-Wei Chern</author><pubDate>Thu, 23 May 2024 17:44:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14776v1</guid></item><item><title>SpaceByte: Towards Deleting Tokenization from Large Language Modeling</title><link>http://arxiv.org/abs/2404.14408v2</link><description>Tokenization is widely used in large language models because it significantlyimproves performance. However, tokenization imposes several disadvantages, suchas performance biases, increased adversarial vulnerability, decreasedcharacter-level modeling performance, and increased modeling complexity. Toaddress these disadvantages without sacrificing performance, we proposeSpaceByte, a novel byte-level decoder architecture that closes the performancegap between byte-level and subword autoregressive language modeling. SpaceByteconsists of a byte-level Transformer model, but with extra larger transformerblocks inserted in the middle of the layers. We find that performance issignificantly improved by applying these larger blocks only after certainbytes, such as space characters, which typically denote word boundaries. Ourexperiments show that for a fixed training and inference compute budget,SpaceByte outperforms other byte-level architectures and roughly matches theperformance of tokenized Transformer architectures.</description><author>Kevin Slagle</author><pubDate>Thu, 23 May 2024 17:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14408v2</guid></item><item><title>Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from Human Input</title><link>http://arxiv.org/abs/2405.14769v1</link><description>Humans use social context to specify preferences over behaviors, i.e. theirreward functions. Yet, algorithms for inferring reward models from preferencedata do not take this social learning view into account. Inspired by pragmatichuman communication, we study how to extract fine-grained data regarding why anexample is preferred that is useful for learning more accurate reward models.We propose to enrich binary preference queries to ask both (1) which featuresof a given example are preferable in addition to (2) comparisons betweenexamples themselves. We derive an approach for learning from thesefeature-level preferences, both for cases where users specify which featuresare reward-relevant, and when users do not. We evaluate our approach on linearbandit settings in both vision- and language-based domains. Results support theefficiency of our approach in quickly converging to accurate rewards with fewercomparisons vs. example-only labels. Finally, we validate the real-worldapplicability with a behavioral experiment on a mushroom foraging task. Ourfindings suggest that incorporating pragmatic feature preferences is apromising approach for more efficient user-aligned reward learning.</description><author>Andi Peng, Yuying Sun, Tianmin Shu, David Abel</author><pubDate>Thu, 23 May 2024 17:36:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14769v1</guid></item><item><title>WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models</title><link>http://arxiv.org/abs/2405.14768v1</link><description>Large language models (LLMs) need knowledge updates to meet the ever-growingworld facts and correct the hallucinated responses, facilitating the methods oflifelong model editing. Where the updated knowledge resides in memories is afundamental question for model editing. In this paper, we find that editingeither long-term memory (direct model parameters) or working memory(non-parametric knowledge of neural network activations/representations byretrieval) will result in an impossible triangle -- reliability,generalization, and locality can not be realized together in the lifelongediting settings. For long-term memory, directly editing the parameters willcause conflicts with irrelevant pretrained knowledge or previous edits (poorreliability and locality). For working memory, retrieval-based activations canhardly make the model understand the edits and generalize (poorgeneralization). Therefore, we propose WISE to bridge the gap between memories.In WISE, we design a dual parametric memory scheme, which consists of the mainmemory for the pretrained knowledge and a side memory for the edited knowledge.We only edit the knowledge in the side memory and train a router to decidewhich memory to go through when given a query. For continual editing, we devisea knowledge-sharding mechanism where different sets of edits reside in distinctsubspaces of parameters, and are subsequently merged into a shared memorywithout conflicts. Extensive experiments show that WISE can outperform previousmodel editing methods and overcome the impossible triangle under lifelong modelediting of question answering, hallucination, and out-of-distribution settingsacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code will bereleased at https://github.com/zjunlp/EasyEdit.</description><author>Peng Wang, Zexi Li, Ningyu Zhang, Ziwen Xu, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</author><pubDate>Thu, 23 May 2024 17:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14768v1</guid></item><item><title>FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models</title><link>http://arxiv.org/abs/2405.14767v1</link><description>As financial institutions and professionals increasingly incorporate LargeLanguage Models (LLMs) into their workflows, substantial barriers, includingproprietary data and specialized knowledge, persist between the finance sectorand the AI community. These challenges impede the AI community's ability toenhance financial tasks effectively. Acknowledging financial analysis'scritical role, we aim to devise financial-specialized LLM-based toolchains anddemocratize access to them through open-source initiatives, promoting wider AIadoption in financial decision-making. In this paper, we introduce FinRobot, a novel open-source AI agent platformsupporting multiple financially specialized AI agents, each powered by LLM.Specifically, the platform consists of four major layers: 1) the Financial AIAgents layer that formulates Financial Chain-of-Thought (CoT) by breakingsophisticated financial problems down into logical sequences; 2) the FinancialLLM Algorithms layer dynamically configures appropriate model applicationstrategies for specific tasks; 3) the LLMOps and DataOps layer producesaccurate models by applying training/fine-tuning techniques and usingtask-relevant data; 4) the Multi-source LLM Foundation Models layer thatintegrates various LLMs and enables the above layers to access them directly.Finally, FinRobot provides hands-on for both professional-grade analysts andlaypersons to utilize powerful AI techniques for advanced financial analysis.We open-source FinRobot at\url{https://github.com/AI4Finance-Foundation/FinRobot}.</description><author>Hongyang Yang, Boyu Zhang, Neng Wang, Cheng Guo, Xiaoli Zhang, Likun Lin, Junlin Wang, Tianyu Zhou, Mao Guan, Runjia Zhang, Christina Dan Wang</author><pubDate>Thu, 23 May 2024 17:35:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14767v1</guid></item><item><title>MAmmoTH2: Scaling Instructions from the Web</title><link>http://arxiv.org/abs/2405.03548v4</link><description>Instruction tuning improves the reasoning abilities of large language models(LLMs), with data quality and scalability being the crucial factors. Mostinstruction tuning data come from human crowd-sourcing or GPT-4 distillation.We propose a paradigm to efficiently harvest 10 million naturally existinginstruction data from the pre-training web corpus to enhance LLM reasoning. Ourapproach involves (1) recalling relevant documents, (2) extractinginstruction-response pairs, and (3) refining the extracted pairs usingopen-source LLMs. Fine-tuning base LLMs on this dataset, we build MAmmoTH2models, which significantly boost performance on reasoning benchmarks. Notably,MAmmoTH2-7B's (Mistral) performance increases from 11% to 36.7% on MATH andfrom 36% to 68.4% on GSM8K without training on any in-domain data. Furthertraining MAmmoTH2 on public instruction tuning datasets yields MAmmoTH2-Plus,achieving state-of-the-art performance on several reasoning and chatbotbenchmarks. Our work demonstrates how to harvest large-scale, high-qualityinstruction data without costly human annotation or GPT-4 distillation,providing a new paradigm for building better instruction tuning data.</description><author>Xiang Yue, Tuney Zheng, Ge Zhang, Wenhu Chen</author><pubDate>Thu, 23 May 2024 17:34:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03548v4</guid></item><item><title>Evaluating Large Language Models for Public Health Classification and Extraction Tasks</title><link>http://arxiv.org/abs/2405.14766v1</link><description>Advances in Large Language Models (LLMs) have led to significant interest intheir potential to support human experts across a range of domains, includingpublic health. In this work we present automated evaluations of LLMs for publichealth tasks involving the classification and extraction of free text. Wecombine six externally annotated datasets with seven new internally annotateddatasets to evaluate LLMs for processing text related to: health burden,epidemiological risk factors, and public health interventions. We initiallyevaluate five open-weight LLMs (7-70 billion parameters) across all tasks usingzero-shot in-context learning. We find that Llama-3-70B-Instruct is the highestperforming model, achieving the best results on 15/17 tasks (using micro-F1scores). We see significant variation across tasks with all open-weight LLMsscoring below 60% micro-F1 on some challenging tasks, such as ContactClassification, while all LLMs achieve greater than 80% micro-F1 on others,such as GI Illness Classification. For a subset of 12 tasks, we also evaluateGPT-4 and find comparable results to Llama-3-70B-Instruct, which scores equallyor outperforms GPT-4 on 6 of the 12 tasks. Overall, based on these initialresults we find promising signs that LLMs may be useful tools for public healthexperts to extract information from a wide variety of free text sources, andsupport public health surveillance, research, and interventions.</description><author>Joshua Harris, Timothy Laurence, Leo Loman, Fan Grayson, Toby Nonnenmacher, Harry Long, Loes WalsGriffith, Amy Douglas, Holly Fountain, Stelios Georgiou, Jo Hardstaff, Kathryn Hopkins, Y-Ling Chi, Galena Kuyumdzhieva, Lesley Larkin, Samuel Collins, Hamish Mohammed, Thomas Finnie, Luke Hounsome, Steven Riley</author><pubDate>Thu, 23 May 2024 17:33:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14766v1</guid></item><item><title>Neural Pfaffians: Solving Many Many-Electron Schrödinger Equations</title><link>http://arxiv.org/abs/2405.14762v1</link><description>Neural wave functions accomplished unprecedented accuracies in approximatingthe ground state of many-electron systems, though at a high computational cost.Recent works proposed amortizing the cost by learning generalized wavefunctions across different structures and compounds instead of solving eachproblem independently. Enforcing the permutation antisymmetry of electrons insuch generalized neural wave functions remained challenging as existing methodsrequire discrete orbital selection via non-learnable hand-crafted algorithms.This work tackles the problem by defining overparametrized, fully learnableneural wave functions suitable for generalization across molecules. We achievethis by relying on Pfaffians rather than Slater determinants. The Pfaffianallows us to enforce the antisymmetry on arbitrary electronic systems withoutany constraint on electronic spin configurations or molecular structure. Ourempirical evaluation finds that a single neural Pfaffian calculates the groundstate and ionization energies with chemical accuracy across various systems. Onthe TinyMol dataset, we outperform the `gold-standard' CCSD(T) CBS referenceenergies by 1.9m$E_h$ and reduce energy errors compared to previous generalizedneural wave functions by up to an order of magnitude.</description><author>Nicholas Gao, Stephan Günnemann</author><pubDate>Thu, 23 May 2024 17:30:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14762v1</guid></item><item><title>Fault Tolerant ML: Efficient Meta-Aggregation and Synchronous Training</title><link>http://arxiv.org/abs/2405.14759v1</link><description>In this paper, we investigate the challenging framework of Byzantine-robusttraining in distributed machine learning (ML) systems, focusing on enhancingboth efficiency and practicality. As distributed ML systems become integral forcomplex ML tasks, ensuring resilience against Byzantine failures-where workersmay contribute incorrect updates due to malice or error-gains paramountimportance. Our first contribution is the introduction of the Centered TrimmedMeta Aggregator (CTMA), an efficient meta-aggregator that upgrades baselineaggregators to optimal performance levels, while requiring low computationaldemands. Additionally, we propose harnessing a recently developed gradientestimation technique based on a double-momentum strategy within the Byzantinecontext. Our paper highlights its theoretical and practical advantages forByzantine-robust training, especially in simplifying the tuning process andreducing the reliance on numerous hyperparameters. The effectiveness of thistechnique is supported by theoretical insights within the stochastic convexoptimization (SCO) framework.</description><author>Tehila Dahan, Kfir Y. Levy</author><pubDate>Thu, 23 May 2024 17:29:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14759v1</guid></item><item><title>Axioms for AI Alignment from Human Feedback</title><link>http://arxiv.org/abs/2405.14758v1</link><description>In the context of reinforcement learning from human feedback (RLHF), thereward function is generally derived from maximum likelihood estimation of arandom utility model based on pairwise comparisons made by humans. The problemof learning a reward function is one of preference aggregation that, we argue,largely falls within the scope of social choice theory. From this perspective,we can evaluate different aggregation methods via established axioms, examiningwhether these methods meet or fail well-known standards. We demonstrate thatboth the Bradley-Terry-Luce Model and its broad generalizations fail to meetbasic axioms. In response, we develop novel rules for learning reward functionswith strong axiomatic guarantees. A key innovation from the standpoint ofsocial choice is that our problem has a linear structure, which greatlyrestricts the space of feasible rules and leads to a new paradigm that we calllinear social choice.</description><author>Luise Ge, Daniel Halpern, Evi Micha, Ariel D. Procaccia, Itai Shapira, Yevgeniy Vorobeychik, Junlin Wu</author><pubDate>Thu, 23 May 2024 17:29:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14758v1</guid></item><item><title>Optimal Multi-Distribution Learning</title><link>http://arxiv.org/abs/2312.05134v4</link><description>Multi-distribution learning (MDL), which seeks to learn a shared model thatminimizes the worst-case risk across $k$ distinct data distributions, hasemerged as a unified framework in response to the evolving demand forrobustness, fairness, multi-group collaboration, etc. Achieving data-efficientMDL necessitates adaptive sampling, also called on-demand sampling, throughoutthe learning process. However, there exist substantial gaps between thestate-of-the-art upper and lower bounds on the optimal sample complexity.Focusing on a hypothesis class of Vapnik-Chervonenkis (VC) dimension d, wepropose a novel algorithm that yields an varepsilon-optimal randomizedhypothesis with a sample complexity on the order of (d+k)/varepsilon^2 (modulosome logarithmic factor), matching the best-known lower bound. Our algorithmicideas and theory are further extended to accommodate Rademacher classes. Theproposed algorithms are oracle-efficient, which access the hypothesis classsolely through an empirical risk minimization oracle. Additionally, we establish the necessity of randomization, revealing a largesample size barrier when only deterministic hypotheses are permitted. Thesefindings resolve three open problems presented in COLT 2023 (i.e.,citet[Problems 1, 3 and 4]{awasthi2023sample}).</description><author>Zihan Zhang, Wenhao Zhan, Yuxin Chen, Simon S. Du, Jason D. Lee</author><pubDate>Thu, 23 May 2024 17:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05134v4</guid></item><item><title>DreamScene4D: Dynamic Multi-Object Scene Generation from Monocular Videos</title><link>http://arxiv.org/abs/2405.02280v2</link><description>View-predictive generative models provide strong priors for liftingobject-centric images and videos into 3D and 4D through rendering and scoredistillation objectives. A question then remains: what about lifting completemulti-object dynamic scenes? There are two challenges in this direction: First,rendering error gradients are often insufficient to recover fast object motion,and second, view predictive generative models work much better for objects thanwhole scenes, so, score distillation objectives cannot currently be applied atthe scene level directly. We present DreamScene4D, the first approach togenerate 3D dynamic scenes of multiple objects from monocular videos via360-degree novel view synthesis. Our key insight is a "decompose-recompose"approach that factorizes the video scene into the background and object tracks,while also factorizing object motion into 3 components: object-centricdeformation, object-to-world-frame transformation, and camera motion. Suchdecomposition permits rendering error gradients and object view-predictivemodels to recover object 3D completions and deformations while bounding boxtracks guide the large object movements in the scene. We show extensive resultson challenging DAVIS, Kubric, and self-captured videos with quantitativecomparisons and a user preference study. Besides 4D scene generation,DreamScene4D obtains accurate 2D persistent point track by projecting theinferred 3D trajectories to 2D. We will release our code and hope our work willstimulate more research on fine-grained 4D understanding from videos.</description><author>Wen-Hsuan Chu, Lei Ke, Katerina Fragkiadaki</author><pubDate>Thu, 23 May 2024 17:27:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02280v2</guid></item><item><title>Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers</title><link>http://arxiv.org/abs/2402.13380v2</link><description>In this study, we introduce an innovative deep learning framework thatemploys a transformer model to address the challenges of mixed-integerprograms, specifically focusing on the Capacitated Lot Sizing Problem (CLSP).Our approach, to our knowledge, is the first to utilize transformers to predictthe binary variables of a mixed-integer programming (MIP) problem.Specifically, our approach harnesses the encoder decoder transformer's abilityto process sequential data, making it well-suited for predicting binaryvariables indicating production setup decisions in each period of the CLSP.This problem is inherently dynamic, and we need to handle sequential decisionmaking under constraints. We present an efficient algorithm in which CLSPsolutions are learned through a transformer neural network. The proposedpost-processed transformer algorithm surpasses the state-of-the-art solver,CPLEX and Long Short-Term Memory (LSTM) in solution time, optimal gap, andpercent infeasibility over 240K benchmark CLSP instances tested. After the MLmodel is trained, conducting inference on the model, reduces the MIP into alinear program (LP). This transforms the ML-based algorithm, combined with anLP solver, into a polynomial-time approximation algorithm to solve a well-knownNP-Hard problem, with almost perfect solution quality.</description><author>Joshua F. Cooper, Seung Jin Choi, I. Esra Buyuktahtakin</author><pubDate>Thu, 23 May 2024 17:24:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13380v2</guid></item><item><title>Large language models can be zero-shot anomaly detectors for time series?</title><link>http://arxiv.org/abs/2405.14755v1</link><description>Recent studies have shown the ability of large language models to perform avariety of tasks, including time series forecasting. The flexible nature ofthese models allows them to be used for many applications. In this paper, wepresent a novel study of large language models used for the challenging task oftime series anomaly detection. This problem entails two aspects novel for LLMs:the need for the model to identify part of the input sequence (or multipleparts) as anomalous; and the need for it to work with time series data ratherthan the traditional text input. We introduce sigllm, a framework for timeseries anomaly detection using large language models. Our framework includes atime-series-to-text conversion module, as well as end-to-end pipelines thatprompt language models to perform time series anomaly detection. We investigatetwo paradigms for testing the abilities of large language models to perform thedetection task. First, we present a prompt-based detection method that directlyasks a language model to indicate which elements of the input are anomalies.Second, we leverage the forecasting capability of a large language model toguide the anomaly detection process. We evaluated our framework on 11 datasetsspanning various sources and 10 pipelines. We show that the forecasting methodsignificantly outperformed the prompting method in all 11 datasets with respectto the F1 score. Moreover, while large language models are capable of findinganomalies, state-of-the-art deep learning models are still superior inperformance, achieving results 30% better than large language models.</description><author>Sarah Alnegheimish, Linh Nguyen, Laure Berti-Equille, Kalyan Veeramachaneni</author><pubDate>Thu, 23 May 2024 17:21:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14755v1</guid></item><item><title>Applied Machine Learning to Anomaly Detection in Enterprise Purchase Processes</title><link>http://arxiv.org/abs/2405.14754v1</link><description>In a context of a continuous digitalisation of processes, organisations mustdeal with the challenge of detecting anomalies that can reveal suspiciousactivities upon an increasing volume of data. To pursue this goal, auditengagements are carried out regularly, and internal auditors and purchasespecialists are constantly looking for new methods to automate these processes.This work proposes a methodology to prioritise the investigation of the casesdetected in two large purchase datasets from real data. The goal is tocontribute to the effectiveness of the companies' control efforts and toincrease the performance of carrying out such tasks. A comprehensiveExploratory Data Analysis is carried out before using unsupervised MachineLearning techniques addressed to detect anomalies. A univariate approach hasbeen applied through the z-Score index and the DBSCAN algorithm, while amultivariate analysis is implemented with the k-Means and Isolation Forestalgorithms, and the Silhouette index, resulting in each method having atransaction candidates' proposal to be reviewed. An ensemble prioritisation ofthe candidates is provided jointly with a proposal of explicability methods(LIME, Shapley, SHAP) to help the company specialists in their understanding.</description><author>A. Herreros-Martínez, R. Magdalena-Benedicto, J. Vila-Francés, A. J. Serrano-López, S. Pérez-Díaz</author><pubDate>Thu, 23 May 2024 17:21:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14754v1</guid></item><item><title>A Transformer-Based Approach for Smart Invocation of Automatic Code Completion</title><link>http://arxiv.org/abs/2405.14753v1</link><description>Transformer-based language models are highly effective for code completion,with much research dedicated to enhancing the content of these completions.Despite their effectiveness, these models come with high operational costs andcan be intrusive, especially when they suggest too often and interruptdevelopers who are concentrating on their work. Current research largelyoverlooks how these models interact with developers in practice and neglects toaddress when a developer should receive completion suggestions. To tackle thisissue, we developed a machine learning model that can accurately predict whento invoke a code completion tool given the code context and available telemetrydata. To do so, we collect a dataset of 200k developer interactions with ourcross-IDE code completion plugin and train several invocation filtering models.Our results indicate that our small-scale transformer model significantlyoutperforms the baseline while maintaining low enough latency. We furtherexplore the search space for integrating additional telemetry data into apre-trained transformer directly and obtain promising results. To furtherdemonstrate our approach's practical potential, we deployed the model in anonline environment with 34 developers and provided real-world insights based on74k actual invocations.</description><author>Aral de Moor, Arie van Deursen, Maliheh Izadi</author><pubDate>Thu, 23 May 2024 17:19:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14753v1</guid></item><item><title>AGILE: A Novel Framework of LLM Agents</title><link>http://arxiv.org/abs/2405.14751v1</link><description>We introduce a novel framework of LLM agents named AGILE (AGent thatInteracts and Learns from Environments) designed to perform complexconversational tasks with users, leveraging LLMs, memory, tools, andinteractions with experts. The agent's abilities include not only conversationbut also reflection, utilization of tools, and consultation with experts. Weformulate the construction of such an LLM agent as a reinforcement learningproblem, in which the LLM serves as the policy model. We fine-tune the LLMusing labeled data of actions and the PPO algorithm. We focus on questionanswering and release a dataset for agents called ProductQA, comprisingchallenging questions in online shopping. Our extensive experiments onProductQA and MedMCQA show that AGILE agents based on 13B and 7B LLMs trainedwith PPO can outperform GPT-4 agents. Our ablation study highlights theindispensability of memory, tools, consultation, reflection, and reinforcementlearning in achieving the agent's strong performance.</description><author>Peiyuan Feng, Yichen He, Guanhua Huang, Yuan Lin, Hanchong Zhang, Yuchen Zhang, Hang Li</author><pubDate>Thu, 23 May 2024 17:17:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14751v1</guid></item><item><title>Extreme Solar Flare Prediction Using Residual Networks with HMI Magnetograms and Intensitygrams</title><link>http://arxiv.org/abs/2405.14750v1</link><description>Solar flares, especially C, M, and X class, pose significant risks tosatellite operations, communication systems, and power grids. We present anovel approach for predicting extreme solar flares using HMI intensitygrams andmagnetograms. By detecting sunspots from intensitygrams and extracting magneticfield patches from magnetograms, we train a Residual Network (ResNet) toclassify extreme class flares. Our model demonstrates high accuracy, offering arobust tool for predicting extreme solar flares and improving space weatherforecasting. Additionally, we show that HMI magnetograms provide more usefuldata for deep learning compared to other SDO AIA images by better capturingfeatures critical for predicting flare magnitudes. This study underscores theimportance of identifying magnetic fields in solar flare prediction, marking asignificant advancement in solar activity prediction with practicalimplications for mitigating space weather impacts.</description><author>Juyoung Yun, Jungmin Shin</author><pubDate>Thu, 23 May 2024 17:17:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14750v1</guid></item><item><title>Policy Gradient Methods for Risk-Sensitive Distributional Reinforcement Learning with Provable Convergence</title><link>http://arxiv.org/abs/2405.14749v1</link><description>Risk-sensitive reinforcement learning (RL) is crucial for maintainingreliable performance in many high-stakes applications. While most RL methodsaim to learn a point estimate of the random cumulative cost, distributional RL(DRL) seeks to estimate the entire distribution of it. The distributionprovides all necessary information about the cost and leads to a unifiedframework for handling various risk measures in a risk-sensitive setting.However, developing policy gradient methods for risk-sensitive DRL isinherently more complex as it pertains to finding the gradient of a probabilitymeasure. This paper introduces a policy gradient method for risk-sensitive DRLwith general coherent risk measures, where we provide an analytical form of theprobability measure's gradient. We further prove the local convergence of theproposed algorithm under mild smoothness assumptions. For practical use, wealso design a categorical distributional policy gradient algorithm (CDPG) basedon categorical distributional policy evaluation and trajectory-based gradientestimation. Through experiments on a stochastic cliff-walking environment, weillustrate the benefits of considering a risk-sensitive setting in DRL.</description><author>Minheng Xiao, Xian Yu, Lei Ying</author><pubDate>Thu, 23 May 2024 17:16:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14749v1</guid></item><item><title>MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs</title><link>http://arxiv.org/abs/2405.14748v1</link><description>Predicting future values in multivariate time series is vital across variousdomains. This work explores the use of large language models (LLMs) for thistask. However, LLMs typically handle one-dimensional data. We introduceMultiCast, a zero-shot LLM-based approach for multivariate time seriesforecasting. It allows LLMs to receive multivariate time series as input,through three novel token multiplexing solutions that effectively reducedimensionality while preserving key repetitive patterns. Additionally, aquantization scheme helps LLMs to better learn these patterns, whilesignificantly reducing token use for practical applications. We showcase theperformance of our approach in terms of RMSE and execution time againststate-of-the-art approaches on three real-world datasets.</description><author>Georgios Chatzigeorgakidis, Konstantinos Lentzos, Dimitrios Skoutas</author><pubDate>Thu, 23 May 2024 17:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14748v1</guid></item><item><title>TopoLogic: An Interpretable Pipeline for Lane Topology Reasoning on Driving Scenes</title><link>http://arxiv.org/abs/2405.14747v1</link><description>As an emerging task that integrates perception and reasoning, topologyreasoning in autonomous driving scenes has recently garnered widespreadattention. However, existing work often emphasizes "perception over reasoning":they typically boost reasoning performance by enhancing the perception of lanesand directly adopt MLP to learn lane topology from lane query. This paradigmoverlooks the geometric features intrinsic to the lanes themselves and areprone to being influenced by inherent endpoint shifts in lane detection. To tackle this issue, we propose an interpretable method for lane topologyreasoning based on lane geometric distance and lane query similarity, namedTopoLogic. This method mitigates the impact of endpoint shifts in geometric space, andintroduces explicit similarity calculation in semantic space as a complement.By integrating results from both spaces, our methods provides morecomprehensive information for lane topology. Ultimately, our approach significantly outperforms the existingstate-of-the-art methods on the mainstream benchmark OpenLane-V2 (23.9 v.s.10.9 in TOP$_{ll}$ and 44.1 v.s. 39.8 in OLS on subset_A. Additionally, ourproposed geometric distance topology reasoning method can be incorporated intowell-trained models without re-training, significantly boost the performance oflane topology reasoning. The code is released athttps://github.com/Franpin/TopoLogic.</description><author>Yanping Fu, Wenbin Liao, Xinyuan Liu, Hang xu, Yike Ma, Feng Dai, Yucheng Zhang</author><pubDate>Thu, 23 May 2024 17:15:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14747v1</guid></item><item><title>AnyLoss: Transforming Classification Metrics into Loss Functions</title><link>http://arxiv.org/abs/2405.14745v1</link><description>Many evaluation metrics can be used to assess the performance of models inbinary classification tasks. However, most of them are derived from a confusionmatrix in a non-differentiable form, making it very difficult to generate adifferentiable loss function that could directly optimize them. The lack ofsolutions to bridge this challenge not only hinders our ability to solvedifficult tasks, such as imbalanced learning, but also requires the deploymentof computationally expensive hyperparameter search processes in modelselection. In this paper, we propose a general-purpose approach that transformsany confusion matrix-based metric into a loss function, \textit{AnyLoss}, thatis available in optimization processes. To this end, we use an approximationfunction to make a confusion matrix represented in a differentiable form, andthis approach enables any confusion matrix-based metric to be directly used asa loss function. The mechanism of the approximation function is provided toensure its operability and the differentiability of our loss functions isproved by suggesting their derivatives. We conduct extensive experiments underdiverse neural networks with many datasets, and we demonstrate their generalavailability to target any confusion matrix-based metrics. Our method,especially, shows outstanding achievements in dealing with imbalanced datasets,and its competitive learning speed, compared to multiple baseline models,underscores its efficiency.</description><author>Doheon Han, Nuno Moniz, Nitesh V Chawla</author><pubDate>Thu, 23 May 2024 17:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14745v1</guid></item><item><title>Iterative Causal Segmentation: Filling the Gap between Market Segmentation and Marketing Strategy</title><link>http://arxiv.org/abs/2405.14743v1</link><description>The field of causal Machine Learning (ML) has made significant strides inrecent years. Notable breakthroughs include methods such as meta learners(arXiv:1706.03461v6) and heterogeneous doubly robust estimators(arXiv:2004.14497) introduced in the last five years. Despite theseadvancements, the field still faces challenges, particularly in managingtightly coupled systems where both the causal treatment variable and aconfounding covariate must serve as key decision-making indicators. Thisscenario is common in applications of causal ML for marketing, such asmarketing segmentation and incremental marketing uplift. In this work, wepresent our formally proven algorithm, iterative causal segmentation, toaddress this issue.</description><author>Kaihua Ding, Jingsong Cui, Mohammad Soltani, Jing Jin</author><pubDate>Thu, 23 May 2024 17:12:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14743v1</guid></item><item><title>HC-GAE: The Hierarchical Cluster-based Graph Auto-Encoder for Graph Representation Learning</title><link>http://arxiv.org/abs/2405.14742v1</link><description>Graph Auto-Encoders (GAEs) are powerful tools for graph representationlearning. In this paper, we develop a novel Hierarchical Cluster-based GAE(HC-GAE), that can learn effective structural characteristics for graph dataanalysis. To this end, during the encoding process, we commence by utilizingthe hard node assignment to decompose a sample graph into a family of separatedsubgraphs. We compress each subgraph into a coarsened node, transforming theoriginal graph into a coarsened graph. On the other hand, during the decodingprocess, we adopt the soft node assignment to reconstruct the original graphstructure by expanding the coarsened nodes. By hierarchically performing theabove compressing procedure during the decoding process as well as theexpanding procedure during the decoding process, the proposed HC-GAE caneffectively extract bidirectionally hierarchical structural features of theoriginal sample graph. Furthermore, we re-design the loss function that canintegrate the information from either the encoder or the decoder. Since theassociated graph convolution operation of the proposed HC-GAE is restricted ineach individual separated subgraph and cannot propagate the node informationbetween different subgraphs, the proposed HC-GAE can significantly reduce theover-smoothing problem arising in the classical convolution-based GAEs. Theproposed HC-GAE can generate effective representations for either nodeclassification or graph classification, and the experiments demonstrate theeffectiveness on real-world datasets.</description><author>Zhuo Xu, Lu Bai, Lixin Cui, Ming Li, Yue Wang, Edwin R. Hancock</author><pubDate>Thu, 23 May 2024 17:08:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14742v1</guid></item><item><title>Bagging Improves Generalization Exponentially</title><link>http://arxiv.org/abs/2405.14741v1</link><description>Bagging is a popular ensemble technique to improve the accuracy of machinelearning models. It hinges on the well-established rationale that, byrepeatedly retraining on resampled data, the aggregated model exhibits lowervariance and hence higher stability, especially for discontinuous baselearners. In this paper, we provide a new perspective on bagging: By suitablyaggregating the base learners at the parametrization instead of the outputlevel, bagging improves generalization performances exponentially, a strengththat is significantly more powerful than variance reduction. More precisely, weshow that for general stochastic optimization problems that suffer from slowly(i.e., polynomially) decaying generalization errors, bagging can effectivelyreduce these errors to an exponential decay. Moreover, this power of bagging isagnostic to the solution schemes, including common empirical risk minimization,distributionally robust optimization, and various regularizations. Wedemonstrate how bagging can substantially improve generalization performancesin a range of examples involving heavy-tailed data that suffer fromintrinsically slow rates.</description><author>Huaqian Jie, Donghao Ying, Henry Lam, Wotao Yin</author><pubDate>Thu, 23 May 2024 17:05:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14741v1</guid></item><item><title>FLoRA: Low-Rank Core Space for N-dimension</title><link>http://arxiv.org/abs/2405.14739v1</link><description>Adapting pre-trained foundation models for various downstream tasks has beenprevalent in artificial intelligence. Due to the vast number of tasks and highcosts, adjusting all parameters becomes unfeasible. To mitigate this, severalfine-tuning techniques have been developed to update the pre-trained modelweights in a more resource-efficient manner, such as through low-rankadjustments. Yet, almost all of these methods focus on linear weights,neglecting the intricacies of parameter spaces in higher dimensions like 4D.Alternatively, some methods can be adapted for high-dimensional parameter spaceby compressing changes in the original space into two dimensions and thenemploying low-rank matrix decomposition. However, these approaches destructsthe structural integrity of the involved high-dimensional spaces. To tackle thediversity of dimensional spaces across different foundation models and providea more precise representation of the changes within these spaces, this paperintroduces a generalized parameter-efficient fine-tuning framework, FLoRA,designed for various dimensional parameter space. Specifically, utilizingTucker decomposition, FLoRA asserts that changes in each dimensional parameterspace are based on a low-rank core space which maintains the consistenttopological structure with the original space. It then models the changesthrough this core space alongside corresponding weights to reconstructalterations in the original space. FLoRA effectively preserves the structuralintegrity of the change of original N-dimensional parameter space, meanwhiledecomposes it via low-rank tensor decomposition. Extensive experiments oncomputer vision, natural language processing and multi-modal tasks validateFLoRA's effectiveness. Codes are available athttps://github.com/SJTU-DeepVisionLab/FLoRA.</description><author>Chongjie Si, Xuehui Wang, Xue Yang, Zhengqin Xu, Qingyun Li, Jifeng Dai, Yu Qiao, Xiaokang Yang, Wei Shen</author><pubDate>Thu, 23 May 2024 17:04:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14739v1</guid></item><item><title>CLIPScope: Enhancing Zero-Shot OOD Detection with Bayesian Scoring</title><link>http://arxiv.org/abs/2405.14737v1</link><description>Detection of out-of-distribution (OOD) samples is crucial for safe real-worlddeployment of machine learning models. Recent advances in vision languagefoundation models have made them capable of detecting OOD samples withoutrequiring in-distribution (ID) images. However, these zero-shot methods oftenunderperform as they do not adequately consider ID class likelihoods in theirdetection confidence scoring. Hence, we introduce CLIPScope, a zero-shot OODdetection approach that normalizes the confidence score of a sample by classlikelihoods, akin to a Bayesian posterior update. Furthermore, CLIPScopeincorporates a novel strategy to mine OOD classes from a large lexicaldatabase. It selects class labels that are farthest and nearest to ID classesin terms of CLIP embedding distance to maximize coverage of OOD samples. Weconduct extensive ablation studies and empirical evaluations, demonstratingstate of the art performance of CLIPScope across various OOD detectionbenchmarks.</description><author>Hao Fu, Naman Patel, Prashanth Krishnamurthy, Farshad Khorrami</author><pubDate>Thu, 23 May 2024 17:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14737v1</guid></item><item><title>PhyloLM : Inferring the Phylogeny of Large Language Models and Predicting their Performances in Benchmarks</title><link>http://arxiv.org/abs/2404.04671v2</link><description>This paper introduces PhyloLM, a method adapting phylogenetic algorithms toLarge Language Models (LLMs) to explore whether and how they relate to eachother and to predict their performance characteristics. Our method calculates aphylogenetic distance metrics based on the similarity of LLMs' output. Theresulting metric is then used to construct dendrograms, which satisfactorilycapture known relationships across a set of 111 open-source and 45 closedmodels. Furthermore, our phylogenetic distance predicts performance in standardbenchmarks, thus demonstrating its functional validity and paving the way for atime and cost-effective estimation of LLM capabilities. To sum up, bytranslating population genetic concepts to machine learning, we propose andvalidate a tool to evaluate LLM development, relationships and capabilities,even in the absence of transparent training information.</description><author>Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri</author><pubDate>Thu, 23 May 2024 17:03:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04671v2</guid></item><item><title>GIFT: Unlocking Full Potential of Labels in Distilled Dataset at Near-zero Cost</title><link>http://arxiv.org/abs/2405.14736v1</link><description>Recent advancements in dataset distillation have demonstrated the significantbenefits of employing soft labels generated by pre-trained teacher models. Inthis paper, we introduce a novel perspective by emphasizing the fullutilization of labels. We first conduct a comprehensive comparison of variousloss functions for soft label utilization in dataset distillation, revealingthat the model trained on the synthetic dataset exhibits high sensitivity tothe choice of loss function for soft label utilization. This finding highlightsthe necessity of a universal loss function for training models on syntheticdatasets. Building on these insights, we introduce an extremely simple yetsurprisingly effective plug-and-play approach, GIFT, which encompasses softlabel refinement and a cosine similarity-based loss function to efficientlyleverage full label information. Extensive experiments demonstrate that GIFTconsistently enhances the state-of-the-art dataset distillation methods acrossvarious scales datasets without incurring additional computational costs. Forinstance, on ImageNet-1K with IPC = 10, GIFT improves the SOTA method RDED by3.9% and 1.8% on ConvNet and ResNet-18, respectively. Code:https://github.com/LINs-lab/GIFT.</description><author>Xinyi Shang, Peng Sun, Tao Lin</author><pubDate>Thu, 23 May 2024 17:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14736v1</guid></item><item><title>SimPO: Simple Preference Optimization with a Reference-Free Reward</title><link>http://arxiv.org/abs/2405.14734v1</link><description>Direct Preference Optimization (DPO) is a widely used offline preferenceoptimization algorithm that reparameterizes reward functions in reinforcementlearning from human feedback (RLHF) to enhance simplicity and trainingstability. In this work, we propose SimPO, a simpler yet more effectiveapproach. The effectiveness of SimPO is attributed to a key design: using theaverage log probability of a sequence as the implicit reward. This rewardformulation better aligns with model generation and eliminates the need for areference model, making it more compute and memory efficient. Additionally, weintroduce a target reward margin to the Bradley-Terry objective to encourage alarger margin between the winning and losing responses, further enhancing thealgorithm's performance. We compare SimPO to DPO and its latest variants acrossvarious state-of-the-art training setups, including both base andinstruction-tuned models like Mistral and Llama3. We evaluated on extensiveinstruction-following benchmarks, including AlpacaEval 2, MT-Bench, and therecent challenging Arena-Hard benchmark. Our results demonstrate that SimPOconsistently and significantly outperforms existing approaches withoutsubstantially increasing response length. Specifically, SimPO outperforms DPOby up to 6.4 points on AlpacaEval 2 and by up to 7.5 points on Arena-Hard. Ourtop-performing model, built on Llama3-8B-Instruct, achieves a remarkable 44.7length-controlled win rate on AlpacaEval 2 -- surpassing Claude 3 Opus on theleaderboard, and a 33.8 win rate on Arena-Hard -- making it the strongest 8Bopen-source model.</description><author>Yu Meng, Mengzhou Xia, Danqi Chen</author><pubDate>Thu, 23 May 2024 17:01:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14734v1</guid></item><item><title>CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments</title><link>http://arxiv.org/abs/2405.14731v1</link><description>In the past decade, although single-robot perception has made significantadvancements, the exploration of multi-robot collaborative perception remainslargely unexplored. This involves fusing compressed, intermittent, limited,heterogeneous, and asynchronous environmental information across multiplerobots to enhance overall perception, despite challenges like sensor noise,occlusions, and sensor failures. One major hurdle has been the lack ofreal-world datasets. This paper presents a pioneering and comprehensivereal-world multi-robot collaborative perception dataset to boost research inthis area. Our dataset leverages the untapped potential of air-ground robotcollaboration featuring distinct spatial viewpoints, complementary robotmobilities, coverage ranges, and sensor modalities. It features raw sensorinputs, pose estimation, and optional high-level perception annotation, thusaccommodating diverse research interests. Compared to existing datasetspredominantly designed for Simultaneous Localization and Mapping (SLAM), oursetup ensures a diverse range and adequate overlap of sensor views tofacilitate the study of multi-robot collaborative perception algorithms. Wedemonstrate the value of this dataset qualitatively through multiplecollaborative perception tasks. We believe this work will unlock the potentialresearch of high-level scene understanding through multi-modal collaborativeperception in multi-robot settings.</description><author>Yang Zhou, Long Quang, Carlos Nieto-Granda, Giuseppe Loianno</author><pubDate>Thu, 23 May 2024 16:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14731v1</guid></item><item><title>Embedding Compression for Efficient Re-Identification</title><link>http://arxiv.org/abs/2405.14730v1</link><description>Real world re-identfication (ReID) algorithms aim to map new observations ofan object to previously recorded instances. These systems are often constrainedby quantity and size of the stored embeddings. To combat this scaling problem,we attempt to shrink the size of these vectors by using a variety ofcompression techniques. In this paper, we benchmark quantization-aware-trainingalong with three different dimension reduction methods: iterative structuredpruning, slicing the embeddings at initialize, and using low rank embeddings.We find that ReID embeddings can be compressed by up to 96x with minimal dropin performance. This implies that modern re-identification paradigms do notfully leverage the high dimensional latent space, opening up further researchto increase the capabilities of these systems.</description><author>Luke McDermott</author><pubDate>Thu, 23 May 2024 16:57:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14730v1</guid></item><item><title>Adaptive Interventions with User-Defined Goals for Health Behavior Change</title><link>http://arxiv.org/abs/2311.09483v4</link><description>Promoting healthy lifestyle behaviors remains a major public health concern,particularly due to their crucial role in preventing chronic conditions such ascancer, heart disease, and type 2 diabetes. Mobile health applications presenta promising avenue for low-cost, scalable health behavior change promotion.Researchers are increasingly exploring adaptive algorithms that personalizeinterventions to each person's unique context. However, in empirical studies,mobile health applications often suffer from small effect sizes and lowadherence rates, particularly in comparison to human coaching. Tailoring adviceto a person's unique goals, preferences, and life circumstances is a criticalcomponent of health coaching that has been underutilized in adaptive algorithmsfor mobile health interventions. To address this, we introduce a new Thompsonsampling algorithm that can accommodate personalized reward functions (i.e.,goals, preferences, and constraints), while also leveraging data sharing acrossindividuals to more quickly be able to provide effective recommendations. Weprove that our modification incurs only a constant penalty on cumulative regretwhile preserving the sample complexity benefits of data sharing. We presentempirical results on synthetic and semi-synthetic physical activity simulators,where in the latter we conducted an online survey to solicit preference datarelating to physical activity, which we use to construct realistic rewardmodels that leverages historical data from another study. Our algorithmachieves substantial performance improvements compared to baselines that do notshare data or do not optimize for individualized rewards.</description><author>Aishwarya Mandyam, Matthew Jörke, William Denton, Barbara E. Engelhardt, Emma Brunskill</author><pubDate>Thu, 23 May 2024 16:56:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09483v4</guid></item><item><title>Intervention and Conditioning in Causal Bayesian Networks</title><link>http://arxiv.org/abs/2405.14728v1</link><description>Causal models are crucial for understanding complex systems and identifyingcausal relationships among variables. Even though causal models are extremelypopular, conditional probability calculation of formulas involvinginterventions pose significant challenges. In case of Causal Bayesian Networks(CBNs), Pearl assumes autonomy of mechanisms that determine interventions tocalculate a range of probabilities. We show that by making simple yet oftenrealistic independence assumptions, it is possible to uniquely estimate theprobability of an interventional formula (including the well-studied notions ofprobability of sufficiency and necessity). We discuss when these assumptionsare appropriate. Importantly, in many cases of interest, when the assumptionsare appropriate, these probability estimates can be evaluated usingobservational data, which carries immense significance in scenarios whereconducting experiments is impractical or unfeasible.</description><author>Sainyam Galhotra, Joseph Y. Halpern</author><pubDate>Thu, 23 May 2024 16:55:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14728v1</guid></item><item><title>Distilling Vision-Language Pretraining for Efficient Cross-Modal Retrieval</title><link>http://arxiv.org/abs/2405.14726v1</link><description>``Learning to hash'' is a practical solution for efficient retrieval,offering fast search speed and low storage cost. It is widely applied invarious applications, such as image-text cross-modal search. In this paper, weexplore the potential of enhancing the performance of learning to hash with theproliferation of powerful large pre-trained models, such as Vision-LanguagePre-training (VLP) models. We introduce a novel method named Distillation forCross-Modal Quantization (DCMQ), which leverages the rich semantic knowledge ofVLP models to improve hash representation learning. Specifically, we use theVLP as a `teacher' to distill knowledge into a `student' hashing model equippedwith codebooks. This process involves the replacement of supervised labels,which are composed of multi-hot vectors and lack semantics, with the richsemantics of VLP. In the end, we apply a transformation termed Normalizationwith Paired Consistency (NPC) to achieve a discriminative target fordistillation. Further, we introduce a new quantization method, ProductQuantization with Gumbel (PQG) that promotes balanced codebook learning,thereby improving the retrieval performance. Extensive benchmark testingdemonstrates that DCMQ consistently outperforms existing supervised cross-modalhashing approaches, showcasing its significant potential.</description><author>Young Kyun Jang, Donghyun Kim, Ser-nam Lim</author><pubDate>Thu, 23 May 2024 16:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14726v1</guid></item><item><title>A Systematic and Formal Study of the Impact of Local Differential Privacy on Fairness: Preliminary Results</title><link>http://arxiv.org/abs/2405.14725v1</link><description>Machine learning (ML) algorithms rely primarily on the availability oftraining data, and, depending on the domain, these data may include sensitiveinformation about the data providers, thus leading to significant privacyissues. Differential privacy (DP) is the predominant solution forprivacy-preserving ML, and the local model of DP is the preferred choice whenthe server or the data collector are not trusted. Recent experimental studieshave shown that local DP can impact ML prediction for different subgroups ofindividuals, thus affecting fair decision-making. However, the results areconflicting in the sense that some studies show a positive impact of privacy onfairness while others show a negative one. In this work, we conduct asystematic and formal study of the effect of local DP on fairness.Specifically, we perform a quantitative study of how the fairness of thedecisions made by the ML model changes under local DP for different levels ofprivacy and data distributions. In particular, we provide bounds in terms ofthe joint distributions and the privacy level, delimiting the extent to whichlocal DP can impact the fairness of the model. We characterize the cases inwhich privacy reduces discrimination and those with the opposite effect. Wevalidate our theoretical findings on synthetic and real-world datasets. Ourresults are preliminary in the sense that, for now, we study only the case ofone sensitive attribute, and only statistical disparity, conditionalstatistical disparity, and equal opportunity difference.</description><author>Karima Makhlouf, Tamara Stefanovic, Heber H. Arcolezi, Catuscia Palamidessi</author><pubDate>Thu, 23 May 2024 16:54:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14725v1</guid></item><item><title>MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection</title><link>http://arxiv.org/abs/2403.19888v2</link><description>Recent advances in deep learning have mainly relied on Transformers due totheir data dependency and ability to learn at scale. The attention module inthese architectures, however, exhibits quadratic time and space in input size,limiting their scalability for long-sequence modeling. State Space Models(SSMs), and more specifically Selective SSMs (S6), with efficienthardware-aware implementation, have shown promising potential for long causalsequence modeling. They, however, use separate blocks for each channel and failto filter irrelevant channels and capture inter-channel dependencies. Naturalattempt to mix information across channels using MLP, attention, or SSMsresults in further instability in the training of SSMs for large networksand/or nearly double the number of parameters. We present the MambaMixer block,a new SSM-based architecture with data-dependent weights that uses a dualselection mechanism across tokens and channels-called Selective Token andChannel Mixer. To mitigate doubling the number of parameters, we present a newnon-causal heuristic of the S6 block using quasi-separable kernels with ahardware-friendly implementation. We further present an efficient variant ofMambaMixer, called QSMixer, that mixes information along both sequence andembedding dimensions. As a proof of concept, we design Vision MambaMixer (ViM2)and Vision QSMixer (ViQS) architectures. To enhance their ability to capturespatial information in images, we present Switch of Scans (SoS) thatdynamically uses a set of useful image scans to traverse image patches. Weevaluate the performance of our methods in image classification, segmentation,and object detection. Our results underline the importance of selectivelymixing across both tokens and channels and show the competitive (resp.superior) performance of our methods with well-established vision models (resp.SSM-based models).</description><author>Ali Behrouz, Michele Santacatterina, Ramin Zabih</author><pubDate>Thu, 23 May 2024 16:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19888v2</guid></item><item><title>Equivariant plug-and-play image reconstruction</title><link>http://arxiv.org/abs/2312.01831v2</link><description>Plug-and-play algorithms constitute a popular framework for solving inverseimaging problems that rely on the implicit definition of an image prior via adenoiser. These algorithms can leverage powerful pre-trained denoisers to solvea wide range of imaging tasks, circumventing the necessity to train models on aper-task basis. Unfortunately, plug-and-play methods often show unstablebehaviors, hampering their promise of versatility and leading to suboptimalquality of reconstructed images. In this work, we show that enforcingequivariance to certain groups of transformations (rotations, reflections,and/or translations) on the denoiser strongly improves the stability of thealgorithm as well as its reconstruction quality. We provide a theoreticalanalysis that illustrates the role of equivariance on better performance andstability. We present a simple algorithm that enforces equivariance on anyexisting denoiser by simply applying a random transformation to the input ofthe denoiser and the inverse transformation to the output at each iteration ofthe algorithm. Experiments on multiple imaging modalities and denoisingnetworks show that the equivariant plug-and-play algorithm improves both thereconstruction performance and the stability compared to their non-equivariantcounterparts.</description><author>Matthieu Terris, Thomas Moreau, Nelly Pustelnik, Julian Tachella</author><pubDate>Thu, 23 May 2024 16:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01831v2</guid></item></channel></rss>