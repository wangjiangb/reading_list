<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 06 Nov 2023 06:00:40 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision</title><link>http://arxiv.org/abs/2311.02077v1</link><description>We present EmerNeRF, a simple yet powerful approach for learningspatial-temporal representations of dynamic driving scenes. Grounded in neuralfields, EmerNeRF simultaneously captures scene geometry, appearance, motion,and semantics via self-bootstrapping. EmerNeRF hinges upon two core components:First, it stratifies scenes into static and dynamic fields. This decompositionemerges purely from self-supervision, enabling our model to learn from general,in-the-wild data sources. Second, EmerNeRF parameterizes an induced flow fieldfrom the dynamic field and uses this flow field to further aggregatemulti-frame features, amplifying the rendering precision of dynamic objects.Coupling these three fields (static, dynamic, and flow) enables EmerNeRF torepresent highly-dynamic scenes self-sufficiently, without relying on groundtruth object annotations or pre-trained models for dynamic object segmentationor optical flow estimation. Our method achieves state-of-the-art performance insensor simulation, significantly outperforming previous methods whenreconstructing static (+2.93 PSNR) and dynamic (+3.70 PSNR) scenes. Inaddition, to bolster EmerNeRF's semantic generalization, we lift 2D visualfoundation model features into 4D space-time and address a general positionalbias in modern Transformers, significantly boosting 3D perception performance(e.g., 37.50% relative improvement in occupancy prediction accuracy onaverage). Finally, we construct a diverse and challenging 120-sequence datasetto benchmark neural fields under extreme and highly-dynamic settings.</description><author>Jiawei Yang, Boris Ivanovic, Or Litany, Xinshuo Weng, Seung Wook Kim, Boyi Li, Tong Che, Danfei Xu, Sanja Fidler, Marco Pavone, Yue Wang</author><pubDate>Fri, 03 Nov 2023 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02077v1</guid></item><item><title>Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos</title><link>http://arxiv.org/abs/2311.02076v1</link><description>In gradient descent dynamics of neural networks, the top eigenvalue of theHessian of the loss (sharpness) displays a variety of robust phenomenathroughout training. This includes early time regimes where the sharpness maydecrease during early periods of training (sharpness reduction), and later timebehavior such as progressive sharpening and edge of stability. We demonstratethat a simple $2$-layer linear network (UV model) trained on a single trainingexample exhibits all of the essential sharpness phenomenology observed inreal-world scenarios. By analyzing the structure of dynamical fixed points infunction space and the vector field of function updates, we uncover theunderlying mechanisms behind these sharpness trends. Our analysis reveals (i)the mechanism behind early sharpness reduction and progressive sharpening, (ii)the required conditions for edge of stability, and (iii) a period-doublingroute to chaos on the edge of stability manifold as learning rate is increased.Finally, we demonstrate that various predictions from this simplified modelgeneralize to real-world scenarios and discuss its limitations.</description><author>Dayal Singh Kalra, Tianyu He, Maissam Barkeshli</author><pubDate>Fri, 03 Nov 2023 18:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02076v1</guid></item><item><title>On minimizers and convolutional filters: theoretical connections and applications to genome analysis</title><link>http://arxiv.org/abs/2111.08452v5</link><description>Minimizers and convolutional neural networks (CNNs) are two quite distinctpopular techniques that have both been employed to analyze categoricalbiological sequences. At face value, the methods seem entirely dissimilar.Minimizers use min-wise hashing on a rolling window to extract a singleimportant k-mer feature per window. CNNs start with a wide array of randomlyinitialized convolutional filters, paired with a pooling operation, and thenmultiple additional neural layers to learn both the filters themselves and howthey can be used to classify the sequence. Here, our main result is a careful mathematical analysis of hash functionproperties showing that for sequences over a categorical alphabet, randomGaussian initialization of convolutional filters with max-pooling is equivalentto choosing a minimizer ordering such that selected k-mers are (in Hammingdistance) far from the k-mers within the sequence but close to otherminimizers. In empirical experiments, we find that this property manifests asdecreased density in repetitive regions, both in simulation and on real humantelomeres. We additionally train from scratch a CNN embedding of syntheticshort-reads from the SARS-CoV-2 genome into 3D Euclidean space that locallyrecapitulates the linear sequence distance of the read origins, a modest steptowards building a deep learning assembler, though it is at present too slow tobe practical. In total, this manuscript provides a partial explanation for theeffectiveness of CNNs in categorical sequence analysis.</description><author>Yun William Yu</author><pubDate>Fri, 03 Nov 2023 18:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.08452v5</guid></item><item><title>Learning Historical Status Prompt for Accurate and Robust Visual Tracking</title><link>http://arxiv.org/abs/2311.02072v1</link><description>Most trackers perform template and search region similarity matching to findthe most similar object to the template during tracking. However, they struggleto make prediction when the target appearance changes due to the limitedhistorical information introduced by roughly cropping the current search regionbased on the predicted result of previous frame. In this paper, we identifythat the central impediment to improving the performance of existing trackersis the incapacity to integrate abundant and effective historical information.To address this issue, we propose a Historical Information Prompter (HIP) toenhance the provision of historical information. We also build HIPTrack uponHIP module. HIP is a plug-and-play module that make full use of search regionfeatures to introduce historical appearance information. It also incorporateshistorical position information by constructing refined mask of the target. HIPis a lightweight module to generate historical information prompts. Byintegrating historical information prompts, HIPTrack significantly enhances thetracking performance without the need to retrain the backbone. Experimentalresults demonstrate that our method outperforms all state-of-the-art approacheson LaSOT, LaSOT ext, GOT10k and NfS. Futhermore, HIP module exhibits stronggenerality and can be seamlessly integrated into trackers to improve trackingperformance. The source code and models will be released for further research.</description><author>Wenrui Cai, Qingjie Liu, Yunhong Wang</author><pubDate>Fri, 03 Nov 2023 18:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02072v1</guid></item><item><title>Grounded Intuition of GPT-Vision's Abilities with Scientific Images</title><link>http://arxiv.org/abs/2311.02069v1</link><description>GPT-Vision has impressed us on a range of vision-language tasks, but it comeswith the familiar new challenge: we have little idea of its capabilities andlimitations. In our study, we formalize a process that many have instinctivelybeen trying already to develop "grounded intuition" of this new model. Inspiredby the recent movement away from benchmarking in favor of example-drivenqualitative evaluation, we draw upon grounded theory and thematic analysis insocial science and human-computer interaction to establish a rigorous frameworkfor qualitative evaluation in natural language processing. We use our techniqueto examine alt text generation for scientific figures, finding that GPT-Visionis particularly sensitive to prompting, counterfactual text in images, andrelative spatial relationships. Our method and analysis aim to help researchersramp up their own grounded intuitions of new models while exposing howGPT-Vision can be applied to make information more accessible.</description><author>Alyssa Hwang, Andrew Head, Chris Callison-Burch</author><pubDate>Fri, 03 Nov 2023 18:53:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02069v1</guid></item><item><title>Active Learning-Based Species Range Estimation</title><link>http://arxiv.org/abs/2311.02061v1</link><description>We propose a new active learning approach for efficiently estimating thegeographic range of a species from a limited number of on the groundobservations. We model the range of an unmapped species of interest as theweighted combination of estimated ranges obtained from a set of differentspecies. We show that it is possible to generate this candidate set of rangesby using models that have been trained on large weakly supervised communitycollected observation data. From this, we develop a new active queryingapproach that sequentially selects geographic locations to visit that bestreduce our uncertainty over an unmapped species' range. We conduct a detailedevaluation of our approach and compare it to existing active learning methodsusing an evaluation dataset containing expert-derived ranges for one thousandspecies. Our results demonstrate that our method outperforms alternative activelearning methods and approaches the performance of end-to-end trained models,even when only using a fraction of the data. This highlights the utility ofactive learning via transfer learned spatial representations for species rangeestimation. It also emphasizes the value of leveraging emerging large-scalecrowdsourced datasets, not only for modeling a species' range, but also foractively discovering them.</description><author>Christian Lange, Elijah Cole, Grant Van Horn, Oisin Mac Aodha</author><pubDate>Fri, 03 Nov 2023 18:45:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02061v1</guid></item><item><title>Graph Neural Networks with polynomial activations have limited expressivity</title><link>http://arxiv.org/abs/2310.13139v2</link><description>The expressivity of Graph Neural Networks (GNNs) can be entirelycharacterized by appropriate fragments of the first-order logic. Namely, anyquery of the two variable fragment of graded modal logic (GC2) interpreted overlabeled graphs can be expressed using a GNN whose size depends only on thedepth of the query. As pointed out by [Barcelo &amp; Al., 2020, Grohe, 2021], thisdescription holds for a family of activation functions, leaving the possibilityfor a hierarchy of logics expressible by GNNs depending on the chosenactivation function. In this article, we show that such hierarchy indeed existsby proving that GC2 queries cannot be expressed by GNNs with polynomialactivation functions. This implies a separation between polynomial and popularnon-polynomial activations (such as ReLUs, sigmoid and hyperbolic tan andothers) and answers an open question formulated by [Grohe, 2021].</description><author>Sammy Khalife</author><pubDate>Fri, 03 Nov 2023 18:43:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13139v2</guid></item><item><title>The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large Language Models</title><link>http://arxiv.org/abs/2305.13669v2</link><description>Large language models often necessitate grounding on external knowledge togenerate faithful and reliable answers. Yet even with the correct groundings inthe reference, they can ignore them and rely on wrong groundings or theirinherent biases to hallucinate when users, being largely unaware of thespecifics of the stored information, pose questions that might not directlycorrelate with the retrieved groundings. In this work, we formulate thisknowledge alignment problem and introduce MixAlign, a framework that interactswith both the human user and the knowledge base to obtain and integrateclarifications on how the user question relates to the stored information.MixAlign employs a language model to achieve automatic knowledge alignment and,if necessary, further enhances this alignment through human userclarifications. Experimental results highlight the crucial role of knowledgealignment in boosting model performance and mitigating hallucination, withimprovements noted up to 22.2% and 27.1% respectively. We also demonstrate theeffectiveness of MixAlign in improving knowledge alignment by producinghigh-quality, user-centered clarifications.</description><author>Shuo Zhang, Liangming Pan, Junzhou Zhao, William Yang Wang</author><pubDate>Fri, 03 Nov 2023 18:40:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13669v2</guid></item><item><title>LOTUS: Continual Imitation Learning for Robot Manipulation Through Unsupervised Skill Discovery</title><link>http://arxiv.org/abs/2311.02058v1</link><description>We introduce LOTUS, a continual imitation learning algorithm that empowers aphysical robot to continuously and efficiently learn to solve new manipulationtasks throughout its lifespan. The core idea behind LOTUS is constructing anever-growing skill library from a sequence of new tasks with a small number ofhuman demonstrations. LOTUS starts with a continual skill discovery processusing an open-vocabulary vision model, which extracts skills as recurringpatterns presented in unsegmented demonstrations. Continual skill discoveryupdates existing skills to avoid catastrophic forgetting of previous tasks andadds new skills to solve novel tasks. LOTUS trains a meta-controller thatflexibly composes various skills to tackle vision-based manipulation tasks inthe lifelong learning process. Our comprehensive experiments show that LOTUSoutperforms state-of-the-art baselines by over 11% in success rate, showing itssuperior knowledge transfer ability compared to prior methods. More results andvideos can be found on the project website:https://ut-austin-rpl.github.io/Lotus/.</description><author>Weikang Wan, Yifeng Zhu, Rutav Shah, Yuke Zhu</author><pubDate>Fri, 03 Nov 2023 18:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02058v1</guid></item><item><title>Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schrödinger Bridges</title><link>http://arxiv.org/abs/2307.01050v3</link><description>This paper explores the connections between optimal transport and variationalinference, with a focus on forward and reverse time stochastic differentialequations and Girsanov transformations.We present a principled and systematicframework for sampling and generative modelling centred around divergences onpath space. Our work culminates in the development of a novel score-basedannealed flow technique (with connections to Jarzynski and Crooks identitiesfrom statistical physics) and a regularised iterative proportional fitting(IPF)-type objective, departing from the sequential nature of standard IPF.Through a series of generative modelling examples and a double-well-based rareevent task, we showcase the potential of the proposed methods.</description><author>Francisco Vargas, Nikolas Nüsken</author><pubDate>Fri, 03 Nov 2023 18:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01050v3</guid></item><item><title>Post Turing: Mapping the landscape of LLM Evaluation</title><link>http://arxiv.org/abs/2311.02049v1</link><description>In the rapidly evolving landscape of Large Language Models (LLMs),introduction of well-defined and standardized evaluation methodologies remainsa crucial challenge. This paper traces the historical trajectory of LLMevaluations, from the foundational questions posed by Alan Turing to the modernera of AI research. We categorize the evolution of LLMs into distinct periods,each characterized by its unique benchmarks and evaluation criteria. As LLMsincreasingly mimic human-like behaviors, traditional evaluation proxies, suchas the Turing test, have become less reliable. We emphasize the pressing needfor a unified evaluation system, given the broader societal implications ofthese models. Through an analysis of common evaluation methodologies, weadvocate for a qualitative shift in assessment approaches, underscoring theimportance of standardization and objective criteria. This work serves as acall for the AI community to collaboratively address the challenges of LLMevaluation, ensuring their reliability, fairness, and societal benefit.</description><author>Alexey Tikhonov, Ivan P. Yamshchikov</author><pubDate>Fri, 03 Nov 2023 18:24:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02049v1</guid></item><item><title>Clustered Saliency Prediction</title><link>http://arxiv.org/abs/2207.02205v2</link><description>We present a new method for image salience prediction, Clustered SaliencyPrediction. This method divides subjects into clusters based on their personalfeatures and their known saliency maps, and generates an image salience modelconditioned on the cluster label. We test our approach on a public dataset ofpersonalized saliency maps and cluster the subjects using selected importanceweights for personal feature factors. We propose the Multi-Domain SaliencyTranslation model which uses image stimuli and universal saliency maps topredict saliency maps for each cluster. For obtaining universal saliency maps,we applied various state-of-the-art methods, DeepGaze IIE, ML-Net and SalGAN,and compared their effectiveness in our system. We show that our ClusteredSaliency Prediction technique outperforms the universal saliency predictionmodels. Also, we demonstrate the effectiveness of our clustering method bycomparing the results of Clustered Saliency Prediction using clusters obtainedby our algorithm with some baseline methods. Finally, we propose an approach toassign new people to their most appropriate cluster and prove its usefulness inthe experiments.</description><author>Rezvan Sherkati, James J. Clark</author><pubDate>Fri, 03 Nov 2023 18:22:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.02205v2</guid></item><item><title>Multilayer hypergraph clustering using the aggregate similarity matrix</title><link>http://arxiv.org/abs/2301.11657v3</link><description>We consider the community recovery problem on a multilayer variant of thehypergraph stochastic block model (HSBM). Each layer is associated with anindependent realization of a d-uniform HSBM on N vertices. Given the similaritymatrix containing the aggregated number of hyperedges incident to each pair ofvertices, the goal is to obtain a partition of the N vertices into disjointcommunities. In this work, we investigate a semidefinite programming (SDP)approach and obtain information-theoretic conditions on the model parametersthat guarantee exact recovery both in the assortative and the disassortativecases.</description><author>Kalle Alaluusua, Konstantin Avrachenkov, B. R. Vinay Kumar, Lasse Leskelä</author><pubDate>Fri, 03 Nov 2023 18:22:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11657v3</guid></item><item><title>Occlusion-Aware 2D and 3D Centerline Detection for Urban Driving via Automatic Label Generation</title><link>http://arxiv.org/abs/2311.02044v1</link><description>This research work seeks to explore and identify strategies that candetermine road topology information in 2D and 3D under highly dynamic urbandriving scenarios. To facilitate this exploration, we introduce a substantialdataset comprising nearly one million automatically labeled data frames. A keycontribution of our research lies in developing an automatic label-generationprocess and an occlusion handling strategy. This strategy is designed to modela wide range of occlusion scenarios, from mild disruptions to severe blockages.Furthermore, we present a comprehensive ablation study wherein multiplecenterline detection methods are developed and evaluated. This analysis notonly benchmarks the performance of various approaches but also providesvaluable insights into the interpretability of these methods. Finally, wedemonstrate the practicality of our methods and assess their adaptabilityacross different sensor configurations, highlighting their versatility andrelevance in real-world scenarios. Our dataset and experimental models arepublicly available.</description><author>David Paz, Narayanan E. Ranganatha, Srinidhi K. Srinivas, Yunchao Yao, Henrik I. Christensen</author><pubDate>Fri, 03 Nov 2023 18:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02044v1</guid></item><item><title>Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective</title><link>http://arxiv.org/abs/2311.02043v1</link><description>Quantile regression is a powerful tool for inferring how covariates affectspecific percentiles of the response distribution. Existing methods eitherestimate conditional quantiles separately for each quantile of interest orestimate the entire conditional distribution using semi- or non-parametricmodels. The former often produce inadequate models for real data and do notshare information across quantiles, while the latter are characterized bycomplex and constrained models that can be difficult to interpret andcomputationally inefficient. Further, neither approach is well-suited forquantile-specific subset selection. Instead, we pose the fundamental problemsof linear quantile estimation, uncertainty quantification, and subset selectionfrom a Bayesian decision analysis perspective. For any Bayesian regressionmodel, we derive optimal and interpretable linear estimates and uncertaintyquantification for each model-based conditional quantile. Our approachintroduces a quantile-focused squared error loss, which enables efficient,closed-form computing and maintains a close relationship with Wasserstein-baseddensity estimation. In an extensive simulation study, our methods demonstratesubstantial gains in quantile estimation accuracy, variable selection, andinference over frequentist and Bayesian competitors. We apply these tools toidentify the quantile-specific impacts of social and environmental stressors oneducational outcomes for a large cohort of children in North Carolina.</description><author>Joseph Feldman, Daniel Kowal</author><pubDate>Fri, 03 Nov 2023 18:19:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02043v1</guid></item><item><title>Quantum circuit synthesis with diffusion models</title><link>http://arxiv.org/abs/2311.02041v1</link><description>Quantum computing has recently emerged as a transformative technology. Yet,its promised advantages rely on efficiently translating quantum operations intoviable physical realizations. In this work, we use generative machine learningmodels, specifically denoising diffusion models (DMs), to facilitate thistransformation. Leveraging text-conditioning, we steer the model to producedesired quantum operations within gate-based quantum circuits. Notably, DMsallow to sidestep during training the exponential overhead inherent in theclassical simulation of quantum dynamics -- a consistent bottleneck inpreceding ML techniques. We demonstrate the model's capabilities across twotasks: entanglement generation and unitary compilation. The model excels atgenerating new circuits and supports typical DM extensions such as masking andediting to, for instance, align the circuit generation to the constraints ofthe targeted quantum device. Given their flexibility and generalizationabilities, we envision DMs as pivotal in quantum circuit synthesis, enhancingboth practical applications but also insights into theoretical quantumcomputation.</description><author>Florian Fürrutter, Gorka Muñoz-Gil, Hans J. Briegel</author><pubDate>Fri, 03 Nov 2023 18:17:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02041v1</guid></item><item><title>ChatGPT for GTFS: Benchmarking LLMs on GTFS Understanding and Retrieval</title><link>http://arxiv.org/abs/2308.02618v2</link><description>The General Transit Feed Specification (GTFS) standard for publishing transitdata is ubiquitous. GTFS being tabular data, with information spread acrossdifferent files, necessitates specialized tools or packages to retrieveinformation. Concurrently, the use of Large Language Models(LLMs) for text andinformation retrieval is growing. The idea of this research is to see if thecurrent widely adopted LLMs (ChatGPT) are able to understand GTFS and retrieveinformation from GTFS using natural language instructions without explicitlyproviding information. In this research, we benchmark OpenAI's GPT-3.5-Turboand GPT-4 LLMs which are the backbone of ChatGPT. ChatGPT demonstrates areasonable understanding of GTFS by answering 59.7% (GPT-3.5-Turbo) and 73.3%(GPT-4) of our multiple-choice questions (MCQ) correctly. Furthermore, weevaluated the LLMs on information extraction tasks using a filtered GTFS feedcontaining four routes. We found that program synthesis techniques outperformedzero-shot approaches, achieving up to 93% (90%) accuracy for simple queries and61% (41%) for complex ones using GPT-4 (GPT-3.5-Turbo).</description><author>Saipraneeth Devunuri, Shirin Qiam, Lewis Lehe</author><pubDate>Fri, 03 Nov 2023 18:09:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02618v2</guid></item><item><title>VQPy: An Object-Oriented Approach to Modern Video Analytics</title><link>http://arxiv.org/abs/2311.01623v1</link><description>Video analytics is widely used in contemporary systems and services. At theforefront of video analytics are video queries that users develop to findobjects of particular interest. Building upon the insight that video objects(e.g., human, animals, cars, etc.), the center of video analytics, are similarin spirit to objects modeled by traditional object-oriented languages, wepropose to develop an object-oriented approach to video analytics. Thisapproach, named VQPy, consists of a frontend$\unicode{x2015}$a Python variantwith constructs that make it easy for users to express video objects and theirinteractions$\unicode{x2015}$as well as an extensible backend that canautomatically construct and optimize pipelines based on video objects. We haveimplemented and open-sourced VQPy, which has been productized in Cisco as partof its DeepVision framework.</description><author>Shan Yu, Zhenting Zhu, Yu Chen, Hanchen Xu, Pengzhan Zhao, Yang Wang, Arthi Padmanabhan, Hugo Latapie, Harry Xu</author><pubDate>Fri, 03 Nov 2023 17:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01623v1</guid></item><item><title>Differentially Private Topological Data Analysis</title><link>http://arxiv.org/abs/2305.03609v2</link><description>This paper is the first to attempt differentially private (DP) topologicaldata analysis (TDA), producing near-optimal private persistence diagrams. Weanalyze the sensitivity of persistence diagrams in terms of the bottleneckdistance, and we show that the commonly used \v{C}ech complex has sensitivitythat does not decrease as the sample size $n$ increases. This makes itchallenging for the persistence diagrams of \v{C}ech complexes to beprivatized. As an alternative, we show that the persistence diagram obtained bythe $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on thesensitivity analysis, we propose using the exponential mechanism whose utilityfunction is defined in terms of the bottleneck distance of the $L^1$-DTMpersistence diagrams. We also derive upper and lower bounds of the accuracy ofour privacy mechanism; the obtained bounds indicate that the privacy error ofour mechanism is near-optimal. We demonstrate the performance of our privatizedpersistence diagrams through simulations as well as on a real dataset trackinghuman movement.</description><author>Taegyu Kang, Sehwan Kim, Jinwon Sohn, Jordan Awan</author><pubDate>Fri, 03 Nov 2023 17:55:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03609v2</guid></item><item><title>APRICOT: Acuity Prediction in Intensive Care Unit (ICU): Predicting Stability, Transitions, and Life-Sustaining Therapies</title><link>http://arxiv.org/abs/2311.02026v1</link><description>The acuity state of patients in the intensive care unit (ICU) can quicklychange from stable to unstable, sometimes leading to life-threateningconditions. Early detection of deteriorating conditions can result in providingmore timely interventions and improved survival rates. Current approaches relyon manual daily assessments. Some data-driven approaches have been developed,that use mortality as a proxy of acuity in the ICU. However, these methods donot integrate acuity states to determine the stability of a patient or the needfor life-sustaining therapies. In this study, we propose APRICOT (AcuityPrediction in Intensive Care Unit), a Transformer-based neural network topredict acuity state in real-time in ICU patients. We develop and extensivelyvalidate externally, temporally, and prospectively the APRICOT model on threelarge datasets: University of Florida Health (UFH), eICU Collaborative ResearchDatabase (eICU), and Medical Information Mart for Intensive Care (MIMIC)-IV.The performance of APRICOT shows comparable results to state-of-the-artmortality prediction models (external AUROC 0.93-0.93, temporal AUROC0.96-0.98, and prospective AUROC 0.98) as well as acuity prediction models(external AUROC 0.80-0.81, temporal AUROC 0.77-0.78, and prospective AUROC0.87). Furthermore, APRICOT can make predictions for the need forlife-sustaining therapies, showing comparable results to state-of-the-artventilation prediction models (external AUROC 0.80-0.81, temporal AUROC0.87-0.88, and prospective AUROC 0.85), and vasopressor prediction models(external AUROC 0.82-0.83, temporal AUROC 0.73-0.75, prospective AUROC 0.87).This tool allows for real-time acuity monitoring of a patient and can providehelpful information to clinicians to make timely interventions. Furthermore,the model can suggest life-sustaining therapies that the patient might need inthe next hours in the ICU.</description><author>Miguel Contreras, Brandon Silva, Benjamin Shickel, Tezcan Ozrazgat Baslanti, Yuanfang Ren, Ziyuan Guan, Sabyasachi Bandyopadhyay, Kia Khezeli, Azra Bihorac, Parisa Rashidi</author><pubDate>Fri, 03 Nov 2023 17:52:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02026v1</guid></item><item><title>Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive Language Detection</title><link>http://arxiv.org/abs/2311.02025v1</link><description>Cross-lingual transfer learning from high-resource to medium and low-resourcelanguages has shown encouraging results. However, the scarcity of resources intarget languages remains a challenge. In this work, we resort to dataaugmentation and continual pre-training for domain adaptation to improvecross-lingual abusive language detection. For data augmentation, we analyze twoexisting techniques based on vicinal risk minimization and propose MIXAG, anovel data augmentation method which interpolates pairs of instances based onthe angle of their representations. Our experiments involve seven languagestypologically distinct from English and three different domains. The resultsreveal that the data augmentation strategies can enhance few-shot cross-lingualabusive language detection. Specifically, we observe that consistently in alltarget languages, MIXAG improves significantly in multidomain and multilingualenvironments. Finally, we show through an error analysis how the domainadaptation can favour the class of abusive texts (reducing false negatives),but at the same time, declines the precision of the abusive language detectionmodel.</description><author>Gretel Liz De la Peña Sarracén, Paolo Rosso, Robert Litschko, Goran Glavaš, Simone Paolo Ponzetto</author><pubDate>Fri, 03 Nov 2023 17:51:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02025v1</guid></item><item><title>On the effect of curriculum learning with developmental data for grammar acquisition</title><link>http://arxiv.org/abs/2311.00128v2</link><description>This work explores the degree to which grammar acquisition is driven bylanguage `simplicity' and the source modality (speech vs. text) of data. UsingBabyBERTa as a probe, we find that grammar acquisition is largely driven byexposure to speech data, and in particular through exposure to two of theBabyLM training corpora: AO-Childes and Open Subtitles. We arrive at thisfinding by examining various ways of presenting input data to our model. First,we assess the impact of various sequence-level complexity based curricula. Wethen examine the impact of learning over `blocks' -- covering spans of textthat are balanced for the number of tokens in each of the source corpora(rather than number of lines). Finally, we explore curricula that vary thedegree to which the model is exposed to different corpora. In all cases, wefind that over-exposure to AO-Childes and Open Subtitles significantly drivesperformance. We verify these findings through a comparable control dataset inwhich exposure to these corpora, and speech more generally, is limited bydesign. Our findings indicate that it is not the proportion of tokens occupiedby high-utility data that aids acquisition, but rather the proportion oftraining steps assigned to such data. We hope this encourages future researchinto the use of more developmentally plausible linguistic data (which tends tobe more scarce) to augment general purpose pre-training regimes.</description><author>Mattia Opper, J. Morrison, N. Siddharth</author><pubDate>Fri, 03 Nov 2023 17:42:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00128v2</guid></item><item><title>High-performance real-world optical computing trained by in situ model-free optimization</title><link>http://arxiv.org/abs/2307.11957v3</link><description>Optical computing systems can provide high-speed and low-energy dataprocessing but face deficiencies in computationally demanding training andsimulation-to-reality gap. We propose a model-free solution for lightweight insitu optimization of optical computing systems based on the score gradientestimation algorithm. This approach treats the system as a black box andback-propagates loss directly to the optical weights' probabilisticdistributions, hence circumventing the need for computation-heavy and biasedsystem simulation. We demonstrate a superior classification accuracy on theMNIST and FMNIST datasets through experiments on a single-layer diffractiveoptical computing system. Furthermore, we show its potential for image-free andhigh-speed cell analysis. The inherent simplicity of our proposed method,combined with its low demand for computational resources, expedites thetransition of optical computing from laboratory demonstrations to real-worldapplications.</description><author>Guangyuan Zhao, Xin Shu</author><pubDate>Fri, 03 Nov 2023 17:36:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11957v3</guid></item><item><title>Navigating the Pitfalls of Active Learning Evaluation: A Systematic Framework for Meaningful Performance Assessment</title><link>http://arxiv.org/abs/2301.10625v3</link><description>Active Learning (AL) aims to reduce the labeling burden by interactivelyselecting the most informative samples from a pool of unlabeled data. Whilethere has been extensive research on improving AL query methods in recentyears, some studies have questioned the effectiveness of AL compared toemerging paradigms such as semi-supervised (Semi-SL) and self-supervisedlearning (Self-SL), or a simple optimization of classifier configurations.Thus, today's AL literature presents an inconsistent and contradictorylandscape, leaving practitioners uncertain about whether and how to use AL intheir tasks. In this work, we make the case that this inconsistency arises froma lack of systematic and realistic evaluation of AL methods. Specifically, weidentify five key pitfalls in the current literature that reflect the delicateconsiderations required for AL evaluation. Further, we present an evaluationframework that overcomes these pitfalls and thus enables meaningful statementsabout the performance of AL methods. To demonstrate the relevance of ourprotocol, we present a large-scale empirical study and benchmark for imageclassification spanning various data sets, query methods, AL settings, andtraining paradigms. Our findings clarify the inconsistent picture in theliterature and enable us to give hands-on recommendations for practitioners.The benchmark is hosted at https://github.com/IML-DKFZ/realistic-al .</description><author>Carsten T. Lüth, Till J. Bungert, Lukas Klein, Paul F. Jaeger</author><pubDate>Fri, 03 Nov 2023 17:35:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.10625v3</guid></item><item><title>Reproducible Parameter Inference Using Bagged Posteriors</title><link>http://arxiv.org/abs/2311.02019v1</link><description>Under model misspecification, it is known that Bayesian posteriors often donot properly quantify uncertainty about true or pseudo-true parameters. Evenmore fundamentally, misspecification leads to a lack of reproducibility in thesense that the same model will yield contradictory posteriors on independentdata sets from the true distribution. To define a criterion for reproducibleuncertainty quantification under misspecification, we consider the probabilitythat two confidence sets constructed from independent data sets have nonemptyoverlap, and we establish a lower bound on this overlap probability that holdsfor any valid confidence sets. We prove that credible sets from the standardposterior can strongly violate this bound, particularly in high-dimensionalsettings (i.e., with dimension increasing with sample size), indicating that itis not internally coherent under misspecification. To improve reproducibilityin an easy-to-use and widely applicable way, we propose to apply bagging to theBayesian posterior ("BayesBag"'); that is, to use the average of posteriordistributions conditioned on bootstrapped datasets. We motivate BayesBag fromfirst principles based on Jeffrey conditionalization and show that the baggedposterior typically satisfies the overlap lower bound. Further, we prove aBernstein--Von Mises theorem for the bagged posterior, establishing itsasymptotic normal distribution. We demonstrate the benefits of BayesBag viasimulation experiments and an application to crime rate prediction.</description><author>Jonathan H. Huggins, Jeffrey W. Miller</author><pubDate>Fri, 03 Nov 2023 17:28:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02019v1</guid></item><item><title>Grammar Prompting for Domain-Specific Language Generation with Large Language Models</title><link>http://arxiv.org/abs/2305.19234v3</link><description>Large language models (LLMs) can learn to perform a wide range of naturallanguage tasks from just a handful of in-context examples. However, forgenerating strings from highly structured languages (e.g., semantic parsing tocomplex domain-specific languages), it is challenging for the LLM to generalizefrom just a few exemplars. We propose \emph{grammar prompting}, a simpleapproach to enable LLMs to use external knowledge and domain-specificconstraints, expressed through a grammar in Backus--Naur Form (BNF), duringin-context learning. Grammar prompting augments each demonstration example witha specialized grammar that is minimally sufficient for generating theparticular output example, where the specialized grammar is a subset of thefull DSL grammar. For inference, the LLM first predicts a BNF grammar given atest input, and then generates the output according to the rules of thegrammar. Experiments demonstrate that grammar prompting can enable LLMs toperform competitively on a diverse set of DSL generation tasks, includingsemantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, andSMILES-based molecule generation.</description><author>Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A. Saurous, Yoon Kim</author><pubDate>Fri, 03 Nov 2023 17:25:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19234v3</guid></item><item><title>Active Reasoning in an Open-World Environment</title><link>http://arxiv.org/abs/2311.02018v1</link><description>Recent advances in vision-language learning have achieved notable success oncomplete-information question-answering datasets through the integration ofextensive world knowledge. Yet, most models operate passively, responding toquestions based on pre-stored knowledge. In stark contrast, humans possess theability to actively explore, accumulate, and reason using both newfound andexisting information to tackle incomplete-information questions. In response tothis gap, we introduce $Conan$, an interactive open-world environment devisedfor the assessment of active reasoning. $Conan$ facilitates active explorationand promotes multi-round abductive inference, reminiscent of rich, open-worldsettings like Minecraft. Diverging from previous works that lean primarily onsingle-round deduction via instruction following, $Conan$ compels agents toactively interact with their surroundings, amalgamating new evidence with priorknowledge to elucidate events from incomplete observations. Our analysis on$Conan$ underscores the shortcomings of contemporary state-of-the-art models inactive exploration and understanding complex scenarios. Additionally, weexplore Abduction from Deduction, where agents harness Bayesian rules to recastthe challenge of abduction as a deductive process. Through $Conan$, we aim togalvanize advancements in active reasoning and set the stage for the nextgeneration of artificial intelligence agents adept at dynamically engaging inenvironments.</description><author>Manjie Xu, Guangyuan Jiang, Wei Liang, Chi Zhang, Yixin Zhu</author><pubDate>Fri, 03 Nov 2023 17:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02018v1</guid></item><item><title>DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network for Food Deliveries</title><link>http://arxiv.org/abs/2311.02017v1</link><description>Delivery of items from the producer to the consumer has experiencedsignificant growth over the past decade and has been greatly fueled by therecent pandemic. Amazon Fresh, Shopify, UberEats, InstaCart, and DoorDash arerapidly growing and are sharing the same business model of consumer items orfood delivery. Existing food delivery methods are sub-optimal because eachdelivery is individually optimized to go directly from the producer to theconsumer via the shortest time path. We observe a significant scope forreducing the costs associated with completing deliveries under the currentmodel. We model our food delivery problem as a multi-objective optimization,where consumer satisfaction and delivery costs, both, need to be optimized.Taking inspiration from the success of ride-sharing in the taxi industry, wepropose DeliverAI - a reinforcement learning-based path-sharing algorithm.Unlike previous attempts for path-sharing, DeliverAI can provide real-time,time-efficient decision-making using a Reinforcement learning-enabled agentsystem. Our novel agent interaction scheme leverages path-sharing amongdeliveries to reduce the total distance traveled while keeping the deliverycompletion time under check. We generate and test our methodology vigorously ona simulation setup using real data from the city of Chicago. Our results showthat DeliverAI can reduce the delivery fleet size by 12\%, the distancetraveled by 13%, and achieve 50% higher fleet utilization compared to thebaselines.</description><author>Ashman Mehra, Snehanshu Saha, Vaskar Raychoudhury, Archana Mathur</author><pubDate>Fri, 03 Nov 2023 17:23:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02017v1</guid></item><item><title>Score Models for Offline Goal-Conditioned Reinforcement Learning</title><link>http://arxiv.org/abs/2311.02013v1</link><description>Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked withlearning to achieve multiple goals in an environment purely from offlinedatasets using sparse reward functions. Offline GCRL is pivotal for developinggeneralist agents capable of leveraging pre-existing datasets to learn diverseand reusable skills without hand-engineering reward functions. However,contemporary approaches to GCRL based on supervised learning and contrastivelearning are often suboptimal in the offline setting. An alternativeperspective on GCRL optimizes for occupancy matching, but necessitates learninga discriminator, which subsequently serves as a pseudo-reward for downstreamRL. Inaccuracies in the learned discriminator can cascade, negativelyinfluencing the resulting policy. We present a novel approach to GCRL under anew lens of mixture-distribution matching, leading to our discriminator-freemethod: SMORe. The key insight is combining the occupancy matching perspectiveof GCRL with a convex dual formulation to derive a learning objective that canbetter leverage suboptimal offline data. SMORe learns scores or unnormalizeddensities representing the importance of taking an action at a state forreaching a particular goal. SMORe is principled and our extensive experimentson the fully offline GCRL benchmark composed of robot manipulation andlocomotion tasks, including high-dimensional observations, show that SMORe canoutperform state-of-the-art baselines by a significant margin.</description><author>Harshit Sikchi, Rohan Chitnis, Ahmed Touati, Alborz Geramifard, Amy Zhang, Scott Niekum</author><pubDate>Fri, 03 Nov 2023 17:19:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02013v1</guid></item><item><title>Fairness Improvement with Multiple Protected Attributes: How Far Are We?</title><link>http://arxiv.org/abs/2308.01923v2</link><description>Existing research mostly improves the fairness of Machine Learning (ML)software regarding a single protected attribute at a time, but this isunrealistic given that many users have multiple protected attributes. Thispaper conducts an extensive study of fairness improvement regarding multipleprotected attributes, covering 11 state-of-the-art fairness improvementmethods. We analyze the effectiveness of these methods with different datasets,metrics, and ML models when considering multiple protected attributes. Theresults reveal that improving fairness for a single protected attribute canlargely decrease fairness regarding unconsidered protected attributes. Thisdecrease is observed in up to 88.3% of scenarios (57.5% on average). Moresurprisingly, we find little difference in accuracy loss when consideringsingle and multiple protected attributes, indicating that accuracy can bemaintained in the multiple-attribute paradigm. However, the effect on precisionand recall when handling multiple protected attributes is about 5 times and 8times that of a single attribute. This has important implications for futurefairness research: reporting only accuracy as the ML performance metric, whichis currently common in the literature, is inadequate.</description><author>Zhenpeng Chen, Jie M. Zhang, Federica Sarro, Mark Harman</author><pubDate>Fri, 03 Nov 2023 17:16:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01923v2</guid></item><item><title>Towards Unsupervised Object Detection From LiDAR Point Clouds</title><link>http://arxiv.org/abs/2311.02007v1</link><description>In this paper, we study the problem of unsupervised object detection from 3Dpoint clouds in self-driving scenes. We present a simple yet effective methodthat exploits (i) point clustering in near-range areas where the point cloudsare dense, (ii) temporal consistency to filter out noisy unsuperviseddetections, (iii) translation equivariance of CNNs to extend the auto-labels tolong range, and (iv) self-supervision for improving on its own. Our approach,OYSTER (Object Discovery via Spatio-Temporal Refinement), does not imposeconstraints on data collection (such as repeated traversals of the samelocation), is able to detect objects in a zero-shot manner without supervisedfinetuning (even in sparse, distant regions), and continues to self-improvegiven more rounds of iterative self-training. To better measure modelperformance in self-driving scenarios, we propose a new planning-centricperception metric based on distance-to-collision. We demonstrate that ourunsupervised object detector significantly outperforms unsupervised baselineson PandaSet and Argoverse 2 Sensor dataset, showing promise thatself-supervision combined with object priors can enable object discovery in thewild. For more information, visit the project website:https://waabi.ai/research/oyster</description><author>Lunjun Zhang, Anqi Joyce Yang, Yuwen Xiong, Sergio Casas, Bin Yang, Mengye Ren, Raquel Urtasun</author><pubDate>Fri, 03 Nov 2023 17:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02007v1</guid></item><item><title>Realistic Noise Synthesis with Diffusion Models</title><link>http://arxiv.org/abs/2305.14022v3</link><description>Deep image denoising models often rely on large amount of training data forthe high quality performance. However, it is challenging to obtain sufficientamount of data under real-world scenarios for the supervised training. As such,synthesizing realistic noise becomes an important solution. However, existingtechniques have limitations in modeling complex noise distributions, resultingin residual noise and edge artifacts in denoising methods relying on syntheticdata. To overcome these challenges, we propose a novel method that synthesizesrealistic noise using diffusion models, namely Realistic Noise SynthesizeDiffusor (RNSD). In particular, the proposed time-aware controlling module cansimulate various environmental conditions under given camera settings. RNSD canincorporate guided multiscale content, such that more realistic noise withspatial correlations can be generated at multiple frequencies. In addition, weconstruct an inversion mechanism to predict the unknown camera setting, whichenables the extension of RNSD to datasets without setting information.Extensive experiments demonstrate that our RNSD method significantlyoutperforms the existing methods not only in the synthesized noise undermultiple realism metrics, but also in the single image denoising performances.</description><author>Qi Wu, Mingyan Han, Ting Jiang, Haoqiang Fan, Bing Zeng, Shuaicheng Liu</author><pubDate>Fri, 03 Nov 2023 17:06:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14022v3</guid></item><item><title>A Structured Pruning Algorithm for Model-based Deep Learning</title><link>http://arxiv.org/abs/2311.02003v1</link><description>There is a growing interest in model-based deep learning (MBDL) for solvingimaging inverse problems. MBDL networks can be seen as iterative algorithmsthat estimate the desired image using a physical measurement model and alearned image prior specified using a convolutional neural net (CNNs). Theiterative nature of MBDL networks increases the test-time computationalcomplexity, which limits their applicability in certain large-scaleapplications. We address this issue by presenting structured pruning algorithmfor model-based deep learning (SPADE) as the first structured pruning algorithmfor MBDL networks. SPADE reduces the computational complexity of CNNs usedwithin MBDL networks by pruning its non-essential weights. We propose threedistinct strategies to fine-tune the pruned MBDL networks to minimize theperformance loss. Each fine-tuning strategy has a unique benefit that dependson the presence of a pre-trained model and a high-quality ground truth. Wevalidate SPADE on two distinct inverse problems, namely compressed sensing MRIand image super-resolution. Our results highlight that MBDL models pruned bySPADE can achieve substantial speed up in testing time while maintainingcompetitive performance.</description><author>Chicago Park, Weijie Gan, Zihao Zou, Yuyang Hu, Zhixin Sun, Ulugbek S. Kamilov</author><pubDate>Fri, 03 Nov 2023 17:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02003v1</guid></item><item><title>A Variational Perspective on High-Resolution ODEs</title><link>http://arxiv.org/abs/2311.02002v1</link><description>We consider unconstrained minimization of smooth convex functions. We proposea novel variational perspective using forced Euler-Lagrange equation thatallows for studying high-resolution ODEs. Through this, we obtain a fasterconvergence rate for gradient norm minimization using Nesterov's acceleratedgradient method. Additionally, we show that Nesterov's method can beinterpreted as a rate-matching discretization of an appropriately chosenhigh-resolution ODE. Finally, using the results from the new variationalperspective, we propose a stochastic method for noisy gradients. Severalnumerical experiments compare and illustrate our stochastic algorithm withstate of the art methods.</description><author>Hoomaan Maskan, Konstantinos C. Zygalakis, Alp Yurtsever</author><pubDate>Fri, 03 Nov 2023 17:00:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02002v1</guid></item><item><title>Cost-aware Generalized $α$-investing for Multiple Hypothesis Testing</title><link>http://arxiv.org/abs/2210.17514v3</link><description>We consider the problem of sequential multiple hypothesis testing withnontrivial data collection costs. This problem appears, for example, whenconducting biological experiments to identify differentially expressed genes ofa disease process. This work builds on the generalized $\alpha$-investingframework which enables control of the false discovery rate in a sequentialtesting setting. We make a theoretical analysis of the long term asymptoticbehavior of $\alpha$-wealth which motivates a consideration of sample size inthe $\alpha$-investing decision rule. Posing the testing process as a game withnature, we construct a decision rule that optimizes the expected$\alpha$-wealth reward (ERO) and provides an optimal sample size for each test.Empirical results show that a cost-aware ERO decision rule correctly rejectsmore false null hypotheses than other methods for $n=1$ where $n$ is the samplesize. When the sample size is not fixed cost-aware ERO uses a prior on the nullhypothesis to adaptively allocate of the sample budget to each test. We extendcost-aware ERO investing to finite-horizon testing which enables the decisionrule to allocate samples in a non-myopic manner. Finally, empirical tests onreal data sets from biological experiments show that cost-aware ERO balancesthe allocation of samples to an individual test against the allocation ofsamples across multiple tests.</description><author>Thomas Cook, Harsh Vardhan Dubey, Ji Ah Lee, Guangyu Zhu, Tingting Zhao, Patrick Flaherty</author><pubDate>Fri, 03 Nov 2023 16:55:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.17514v3</guid></item><item><title>High Probability Convergence of Adam Under Unbounded Gradients and Affine Variance Noise</title><link>http://arxiv.org/abs/2311.02000v1</link><description>In this paper, we study the convergence of the Adaptive Moment Estimation(Adam) algorithm under unconstrained non-convex smooth stochasticoptimizations. Despite the widespread usage in machine learning areas, itstheoretical properties remain limited. Prior researches primarily investigatedAdam's convergence from an expectation view, often necessitating strongassumptions like uniformly stochastic bounded gradients or problem-dependentknowledge in prior. As a result, the applicability of these findings inpractical real-world scenarios has been constrained. To overcome theselimitations, we provide a deep analysis and show that Adam could converge tothe stationary point in high probability with a rate of $\mathcal{O}\left({\rmpoly}(\log T)/\sqrt{T}\right)$ under coordinate-wise "affine" variance noise,not requiring any bounded gradient assumption and any problem-dependentknowledge in prior to tune hyper-parameters. Additionally, it is revealed thatAdam confines its gradients' magnitudes within an order of$\mathcal{O}\left({\rm poly}(\log T)\right)$. Finally, we also investigate asimplified version of Adam without one of the corrective terms and obtain aconvergence rate that is adaptive to the noise level.</description><author>Yusu Hong, Junhong Lin</author><pubDate>Fri, 03 Nov 2023 16:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02000v1</guid></item><item><title>LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning</title><link>http://arxiv.org/abs/2307.02345v3</link><description>Modern reinforcement learning (RL) can be categorized into online and offlinevariants. As a pivotal aspect of both online and offline RL, current researchon the Bellman equation revolves primarily around optimization techniques andperformance enhancement rather than exploring the inherent structuralproperties of the Bellman error, such as its distribution characteristics. Thisstudy investigates the distribution of the Bellman approximation error in bothonline and offline settings through iterative exploration of the Bellmanequation. We observed that both in online RL and offline RL, the Bellman errorconforms to a Logistic distribution. Building upon this discovery, this studyemployed the Logistics maximum likelihood function (LLoss) as an alternative tothe commonly used MSE Loss, assuming that Bellman errors adhere to a normaldistribution. We validated our hypotheses through extensive numericalexperiments across diverse online and offline environments. In particular, weapplied corrections to the loss function across various baseline algorithms andconsistently observed that the loss function with Logistic correctionsoutperformed the MSE counterpart significantly. Additionally, we conductedKolmogorov-Smirnov tests to confirm the reliability of the Logisticdistribution. This study's theoretical and empirical insights provide valuablegroundwork for future investigations and enhancements centered on thedistribution of Bellman errors.</description><author>Outongyi Lv, Bingxin Zhou</author><pubDate>Fri, 03 Nov 2023 16:55:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02345v3</guid></item><item><title>Detection of keratoconus Diseases using deep Learning</title><link>http://arxiv.org/abs/2311.01996v1</link><description>One of the most serious corneal disorders, keratoconus is difficult todiagnose in its early stages and can result in blindness. This illness, whichoften appears in the second decade of life, affects people of all sexes andraces. Convolutional neural networks (CNNs), one of the deep learningapproaches, have recently come to light as particularly promising tools for theaccurate and timely diagnosis of keratoconus. The purpose of this study was toevaluate how well different D-CNN models identified keratoconus-relateddiseases. To be more precise, we compared five different CNN-based deeplearning architectures (DenseNet201, InceptionV3, MobileNetV2, VGG19,Xception). In our comprehensive experimental analysis, the DenseNet201-basedmodel performed very well in keratoconus disease identification in ourextensive experimental research. This model outperformed its D-CNN equivalents,with an astounding accuracy rate of 89.14% in three crucial classes:Keratoconus, Normal, and Suspect. The results demonstrate not only thestability and robustness of the model but also its practical usefulness inreal-world applications for accurate and dependable keratoconus identification.In addition, D-CNN DenseNet201 performs extraordinarily well in terms ofprecision, recall rates, and F1 scores in addition to accuracy. These measuresvalidate the model's usefulness as an effective diagnostic tool by highlightingits capacity to reliably detect instances of keratoconus and to reduce falsepositives and negatives.</description><author>AKM Enzam-Ul Haque, Golam Rabbany, Md. Siam</author><pubDate>Fri, 03 Nov 2023 16:49:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01996v1</guid></item><item><title>Obtaining Explainable Classification Models using Distributionally Robust Optimization</title><link>http://arxiv.org/abs/2311.01994v1</link><description>Model explainability is crucial for human users to be able to interpret how aproposed classifier assigns labels to data based on its feature values. Westudy generalized linear models constructed using sets of feature value rules,which can capture nonlinear dependencies and interactions. An inherenttrade-off exists between rule set sparsity and its prediction accuracy. It iscomputationally expensive to find the right choice of sparsity -- e.g., viacross-validation -- with existing methods. We propose a new formulation tolearn an ensemble of rule sets that simultaneously addresses these competingfactors. Good generalization is ensured while keeping computational costs lowby utilizing distributionally robust optimization. The formulation utilizescolumn generation to efficiently search the space of rule sets and constructs asparse ensemble of rule sets, in contrast with techniques like random forestsor boosting and their variants. We present theoretical results that motivateand justify the use of our distributionally robust formulation. Extensivenumerical experiments establish that our method improves over competing methods-- on a large set of publicly available binary classification problem instances-- with respect to one or more of the following metrics: generalizationquality, computational cost, and explainability.</description><author>Sanjeeb Dash, Soumyadip Ghosh, Joao Goncalves, Mark S. Squillante</author><pubDate>Fri, 03 Nov 2023 16:45:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01994v1</guid></item><item><title>Conditions on Preference Relations that Guarantee the Existence of Optimal Policies</title><link>http://arxiv.org/abs/2311.01990v1</link><description>Learning from Preferential Feedback (LfPF) plays an essential role intraining Large Language Models, as well as certain types of interactivelearning agents. However, a substantial gap exists between the theory andapplication of LfPF algorithms. Current results guaranteeing the existence ofoptimal policies in LfPF problems assume that both the preferences andtransition dynamics are determined by a Markov Decision Process. We introducethe Direct Preference Process, a new framework for analyzing LfPF problems inpartially-observable, non-Markovian environments. Within this framework, weestablish conditions that guarantee the existence of optimal policies byconsidering the ordinal structure of the preferences. Using the vonNeumann-Morgenstern Expected Utility Theorem, we show that the DirectPreference Process generalizes the standard reinforcement learning problem. Ourfindings narrow the gap between the empirical success and theoreticalunderstanding of LfPF algorithms and provide future practitioners with thetools necessary for a more principled design of LfPF agents.</description><author>Jonathan Colaco Carr, Prakash Panangaden, Doina Precup</author><pubDate>Fri, 03 Nov 2023 16:42:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01990v1</guid></item><item><title>Leveraging Large-Scale Pretrained Vision Foundation Models for Label-Efficient 3D Point Cloud Segmentation</title><link>http://arxiv.org/abs/2311.01989v1</link><description>Recently, large-scale pre-trained models such as Segment-Anything Model (SAM)and Contrastive Language-Image Pre-training (CLIP) have demonstrated remarkablesuccess and revolutionized the field of computer vision. These foundationvision models effectively capture knowledge from a large-scale broad data withtheir vast model parameters, enabling them to perform zero-shot segmentation onpreviously unseen data without additional training. While they showcasecompetence in 2D tasks, their potential for enhancing 3D scene understandingremains relatively unexplored. To this end, we present a novel framework thatadapts various foundational models for the 3D point cloud segmentation task.Our approach involves making initial predictions of 2D semantic masks usingdifferent large vision models. We then project these mask predictions fromvarious frames of RGB-D video sequences into 3D space. To generate robust 3Dsemantic pseudo labels, we introduce a semantic label fusion strategy thateffectively combines all the results via voting. We examine diverse scenarios,like zero-shot learning and limited guidance from sparse 2D point labels, toassess the pros and cons of different vision foundation models. Our approach isexperimented on ScanNet dataset for 3D indoor scenes, and the resultsdemonstrate the effectiveness of adopting general 2D foundation models onsolving 3D point cloud segmentation tasks.</description><author>Shichao Dong, Fayao Liu, Guosheng Lin</author><pubDate>Fri, 03 Nov 2023 16:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01989v1</guid></item><item><title>Multi-Task Learning to Enhance Generalizability of Neural Network Equalizers in Coherent Optical Systems</title><link>http://arxiv.org/abs/2307.05374v3</link><description>For the first time, multi-task learning is proposed to improve theflexibility of NN-based equalizers in coherent systems. A "single" NN-basedequalizer improves Q-factor by up to 4 dB compared to CDC, without re-training,even with variations in launch power, symbol rate, or transmission distance.</description><author>Sasipim Srivallapanondh, Pedro J. Freire, Ashraful Alam, Nelson Costa, Bernhard Spinnler, Antonio Napoli, Egor Sedov, Sergei K. Turitsyn, Jaroslaw E. Prilepsky</author><pubDate>Fri, 03 Nov 2023 16:38:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05374v3</guid></item><item><title>Optimal Image Transport on Sparse Dictionaries</title><link>http://arxiv.org/abs/2311.01984v1</link><description>In this paper, we derive a novel optimal image transport algorithm oversparse dictionaries by taking advantage of Sparse Representation (SR) andOptimal Transport (OT). Concisely, we design a unified optimization frameworkin which the individual image features (color, textures, styles, etc.) areencoded using sparse representation compactly, and an optimal transport plan isthen inferred between two learned dictionaries in accordance with the encodingprocess. This paradigm gives rise to a simple but effective way forsimultaneous image representation and transformation, which is also empiricallysolvable because of the moderate size of sparse coding and optimal transportsub-problems. We demonstrate its versatility and many benefits to differentimage-to-image translation tasks, in particular image color transform andartistic style transfer, and show the plausible results for photo-realistictransferred effects.</description><author>Junqing Huang, Haihui Wang, Andreas Weiermann, Michael Ruzhansky</author><pubDate>Fri, 03 Nov 2023 16:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01984v1</guid></item><item><title>Deep Learning for blind spectral unmixing of LULC classes with MODIS multispectral time series and ancillary data</title><link>http://arxiv.org/abs/2310.07223v2</link><description>Remotely sensed data are dominated by mixed Land Use and Land Cover (LULC)types. Spectral unmixing is a technique to extract information from mixedpixels into their constituent LULC types and corresponding abundance fractions.Traditionally, solving this task has relied on either classical methods thatrequire prior knowledge of endmembers or machine learning methods that avoidexplicit endmembers calculation, also known as blind spectral unmixing (BSU).Most BSU studies based on Deep Learning (DL) focus on one time-stephyperspectral or multispectral data. To our knowledge, here we provide thefirst study on BSU of LULC classes using MODIS multispectral time series, inpresence of missing data, with end-to-end DL models. We further boost theperformance of a Long-Short Term Memory (LSTM)-based model by incorporatinggeographic plus topographic (geo-topographic) and climatic ancillaryinformation. Our experiments show that combining spectral-temporal input datatogether with geo-topographic and climatic information substantially improvesthe abundance estimation of LULC classes in mixed pixels. To carry out thisstudy, we built a new labeled dataset of the region of Andalusia (Spain) withmonthly multispectral time series of pixels for the year 2013 from MODIS at460m resolution, for two hierarchical levels of LULC classes, named AndalusiaMultiSpectral MultiTemporal Unmixing (Andalusia-MSMTU). This dataset provides,at the pixel level, a multispectral time series plus ancillary informationannotated with the abundance of each LULC class inside each pixel. The dataset(https://zenodo.org/record/7752348##.ZBmkkezMLdo) and code(https://github.com/jrodriguezortega/MSMTU) are available to the public.</description><author>José Rodríguez-Ortega, Rohaifa Khaldi, Domingo Alcaraz-Segura, Siham Tabik</author><pubDate>Fri, 03 Nov 2023 16:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07223v2</guid></item><item><title>ProSG: Using Prompt Synthetic Gradients to Alleviate Prompt Forgetting of RNN-like Language Models</title><link>http://arxiv.org/abs/2311.01981v1</link><description>RNN-like language models are getting renewed attention from NLP researchersin recent years and several models have made significant progress, whichdemonstrates performance comparable to traditional transformers. However, dueto the recurrent nature of RNNs, this kind of language model can only storeinformation in a set of fixed-length state vectors. As a consequence, theystill suffer from forgetfulness though after a lot of improvements andoptimizations, when given complex instructions or prompts. As the promptedgeneration is the main and most concerned function of LMs, solving the problemof forgetting in the process of generation is no wonder of vital importance. Inthis paper, focusing on easing the prompt forgetting during generation, weproposed an architecture to teach the model memorizing prompt during generationby synthetic gradient. To force the model to memorize the prompt, we derive thestates that encode the prompt, then transform it into model parametermodification using low-rank gradient approximation, which hard-codes the promptinto model parameters temporarily. We construct a dataset for experiments, andthe results have demonstrated the effectiveness of our method in solving theproblem of forgetfulness in the process of prompted generation. We will releaseall the code upon acceptance.</description><author>Haotian Luo, Kunming Wu, Cheng Dai, Sixian Ding, Xinhao Chen</author><pubDate>Fri, 03 Nov 2023 16:34:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01981v1</guid></item><item><title>RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches</title><link>http://arxiv.org/abs/2311.01977v1</link><description>Generalization remains one of the most important desiderata for robust robotlearning systems. While recently proposed approaches show promise ingeneralization to novel objects, semantic concepts, or visual distributionshifts, generalization to new tasks remains challenging. For example, alanguage-conditioned policy trained on pick-and-place tasks will not be able togeneralize to a folding task, even if the arm trajectory of folding is similarto pick-and-place. Our key insight is that this kind of generalization becomesfeasible if we represent the task through rough trajectory sketches. We proposea policy conditioning method using such rough trajectory sketches, which wecall RT-Trajectory, that is practical, easy to specify, and allows the policyto effectively perform new tasks that would otherwise be challenging toperform. We find that trajectory sketches strike a balance between beingdetailed enough to express low-level motion-centric guidance while being coarseenough to allow the learned policy to interpret the trajectory sketch in thecontext of situational visual observations. In addition, we show how trajectorysketches can provide a useful interface to communicate with robotic policies:they can be specified through simple human inputs like drawings or videos, orthrough automated methods such as modern image-generating orwaypoint-generating methods. We evaluate RT-Trajectory at scale on a variety ofreal-world robotic tasks, and find that RT-Trajectory is able to perform awider range of tasks compared to language-conditioned and goal-conditionedpolicies, when provided the same training data.</description><author>Jiayuan Gu, Sean Kirmani, Paul Wohlhart, Yao Lu, Montserrat Gonzalez Arenas, Kanishka Rao, Wenhao Yu, Chuyuan Fu, Keerthana Gopalakrishnan, Zhuo Xu, Priya Sundaresan, Peng Xu, Hao Su, Karol Hausman, Chelsea Finn, Quan Vuong, Ted Xiao</author><pubDate>Fri, 03 Nov 2023 16:31:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01977v1</guid></item><item><title>Adaptive Algorithms for Relaxed Pareto Set Identification</title><link>http://arxiv.org/abs/2307.00424v2</link><description>In this paper we revisit the fixed-confidence identification of the Paretooptimal set in a multi-objective multi-armed bandit model. As the samplecomplexity to identify the exact Pareto set can be very large, a relaxationallowing to output some additional near-optimal arms has been studied. In thiswork we also tackle alternative relaxations that allow instead to identify arelevant subset of the Pareto set. Notably, we propose a single samplingstrategy, called Adaptive Pareto Exploration, that can be used in conjunctionwith different stopping rules to take into account different relaxations of thePareto Set Identification problem. We analyze the sample complexity of thesedifferent combinations, quantifying in particular the reduction in samplecomplexity that occurs when one seeks to identify at most $k$ Pareto optimalarms. We showcase the good practical performance of Adaptive Pareto Explorationon a real-world scenario, in which we adaptively explore several vaccinationstrategies against Covid-19 in order to find the optimal ones when multipleimmunogenicity criteria are taken into account.</description><author>Cyrille Kone, Emilie Kaufmann, Laura Richert</author><pubDate>Fri, 03 Nov 2023 16:28:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00424v2</guid></item><item><title>Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO</title><link>http://arxiv.org/abs/2311.01057v2</link><description>Smart glasses are rapidly gaining advanced functionality thanks tocutting-edge computing technologies, accelerated hardware architectures, andtiny AI algorithms. Integrating AI into smart glasses featuring a small formfactor and limited battery capacity is still challenging when targetingfull-day usage for a satisfactory user experience. This paper illustrates thedesign and implementation of tiny machine-learning algorithms exploiting novellow-power processors to enable prolonged continuous operation in smart glasses.We explore the energy- and latency-efficient of smart glasses in the case ofreal-time object detection. To this goal, we designed a smart glasses prototypeas a research platform featuring two microcontrollers, including a novelmilliwatt-power RISC-V parallel processor with a hardware accelerator forvisual AI, and a Bluetooth low-power module for communication. The smartglasses integrate power cycling mechanisms, including image and audio sensinginterfaces. Furthermore, we developed a family of novel tiny deep-learningmodels based on YOLO with sub-million parameters customized formicrocontroller-based inference dubbed TinyissimoYOLO v1.3, v5, and v8, aimingat benchmarking object detection with smart glasses for energy and latency.Evaluations on the prototype of the smart glasses demonstrate TinyissimoYOLO's17ms inference latency and 1.59mJ energy consumption per inference whileensuring acceptable detection accuracy. Further evaluation reveals anend-to-end latency from image capturing to the algorithm's prediction of 56msor equivalently 18 fps, with a total power consumption of 62.9mW, equivalent toa 9.3 hours of continuous run time on a 154mAh battery. These resultsoutperform MCUNet (TinyNAS+TinyEngine), which runs a simpler task (imageclassification) at just 7.3 fps per second.</description><author>Julian Moosmann, Pietro Bonazzi, Yawei Li, Sizhen Bian, Philipp Mayer, Luca Benini, Michele Magno</author><pubDate>Fri, 03 Nov 2023 16:25:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01057v2</guid></item><item><title>OpenAGI: When LLM Meets Domain Experts</title><link>http://arxiv.org/abs/2304.04370v6</link><description>Human Intelligence (HI) excels at combining basic skills to solve complextasks. This capability is vital for Artificial Intelligence (AI) and should beembedded in comprehensive AI Agents, enabling them to harness expert models forcomplex task-solving towards Artificial General Intelligence (AGI). LargeLanguage Models (LLMs) show promising learning and reasoning abilities, and caneffectively use external models, tools, plugins, or APIs to tackle complexproblems. In this work, we introduce OpenAGI, an open-source AGI research anddevelopment platform designed for solving multi-step, real-world tasks.Specifically, OpenAGI uses a dual strategy, integrating standard benchmarktasks for benchmarking and evaluation, and open-ended tasks including moreexpandable models, tools, plugins, or APIs for creative problem-solving. Tasksare presented as natural language queries to the LLM, which then selects andexecutes appropriate models. We also propose a Reinforcement Learning from TaskFeedback (RLTF) mechanism that uses task results to improve the LLM'stask-solving ability, which creates a self-improving AI feedback loop. While weacknowledge that AGI is a broad and multifaceted research challenge with nosingularly defined solution path, the integration of LLMs with domain-specificexpert models, inspired by mirroring the blend of general and specializedintelligence in humans, offers a promising approach towards AGI. We areopen-sourcing the OpenAGI project's code, dataset, benchmarks, evaluationmethods, and the UI demo to foster community involvement in AGI advancement:https://github.com/agiresearch/OpenAGI.</description><author>Yingqiang Ge, Wenyue Hua, Kai Mei, Jianchao Ji, Juntao Tan, Shuyuan Xu, Zelong Li, Yongfeng Zhang</author><pubDate>Fri, 03 Nov 2023 16:24:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04370v6</guid></item><item><title>Feature-Attending Recurrent Modules for Generalization in Reinforcement Learning</title><link>http://arxiv.org/abs/2112.08369v3</link><description>Many important tasks are defined in terms of object. To generalize acrossthese tasks, a reinforcement learning (RL) agent needs to exploit the structurethat the objects induce. Prior work has either hard-coded object-centricfeatures, used complex object-centric generative models, or updated state usinglocal spatial features. However, these approaches have had limited success inenabling general RL agents. Motivated by this, we introduce "Feature-AttendingRecurrent Modules" (FARM), an architecture for learning state representationsthat relies on simple, broadly applicable inductive biases for capturingspatial and temporal regularities. FARM learns a state representation that isdistributed across multiple modules that each attend to spatiotemporal featureswith an expressive feature attention mechanism. We show that this improves anRL agent's ability to generalize across object-centric tasks. We study tasksuites in both 2D and 3D environments and find that FARM better generalizescompared to competing architectures that leverage attention or multiplemodules.</description><author>Wilka Carvalho, Andrew Lampinen, Kyriacos Nikiforou, Felix Hill, Murray Shanahan</author><pubDate>Fri, 03 Nov 2023 16:12:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.08369v3</guid></item><item><title>Tracr: Compiled Transformers as a Laboratory for Interpretability</title><link>http://arxiv.org/abs/2301.05062v5</link><description>We show how to "compile" human-readable programs into standard decoder-onlytransformer models. Our compiler, Tracr, generates models with known structure.This structure can be used to design experiments. For example, we use it tostudy "superposition" in transformers that execute multi-step algorithms.Additionally, the known structure of Tracr-compiled models can serve asground-truth for evaluating interpretability methods. Commonly, because the"programs" learned by transformers are unknown it is unclear whether aninterpretation succeeded. We demonstrate our approach by implementing andexamining programs including computing token frequencies, sorting, andparenthesis checking. We provide an open-source implementation of Tracr athttps://github.com/google-deepmind/tracr.</description><author>David Lindner, János Kramár, Sebastian Farquhar, Matthew Rahtz, Thomas McGrath, Vladimir Mikulik</author><pubDate>Fri, 03 Nov 2023 16:11:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.05062v5</guid></item><item><title>Latent Diffusion Model for Conditional Reservoir Facies Generation</title><link>http://arxiv.org/abs/2311.01968v1</link><description>Creating accurate and geologically realistic reservoir facies based onlimited measurements is crucial for field development and reservoir management,especially in the oil and gas sector. Traditional two-point geostatistics,while foundational, often struggle to capture complex geological patterns.Multi-point statistics offers more flexibility, but comes with its ownchallenges. With the rise of Generative Adversarial Networks (GANs) and theirsuccess in various fields, there has been a shift towards using them for faciesgeneration. However, recent advances in the computer vision domain have shownthe superiority of diffusion models over GANs. Motivated by this, a novelLatent Diffusion Model is proposed, which is specifically designed forconditional generation of reservoir facies. The proposed model produceshigh-fidelity facies realizations that rigorously preserve conditioning data.It significantly outperforms a GAN-based alternative.</description><author>Daesoo Lee, Oscar Ovanger, Jo Eidsvik, Erlend Aune, Jacob Skauvold, Ragnar Hauge</author><pubDate>Fri, 03 Nov 2023 16:10:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01968v1</guid></item><item><title>The language of prompting: What linguistic properties make a prompt successful?</title><link>http://arxiv.org/abs/2311.01967v1</link><description>The latest generation of LLMs can be prompted to achieve impressive zero-shotor few-shot performance in many NLP tasks. However, since performance is highlysensitive to the choice of prompts, considerable effort has been devoted tocrowd-sourcing prompts or designing methods for prompt optimisation. Yet, westill lack a systematic understanding of how linguistic properties of promptscorrelate with task performance. In this work, we investigate how LLMs ofdifferent sizes, pre-trained and instruction-tuned, perform on prompts that aresemantically equivalent, but vary in linguistic structure. We investigate bothgrammatical properties such as mood, tense, aspect and modality, as well aslexico-semantic variation through the use of synonyms. Our findings contradictthe common assumption that LLMs achieve optimal performance on lower perplexityprompts that reflect language use in pretraining or instruction-tuning data.Prompts transfer poorly between datasets or models, and performance cannotgenerally be explained by perplexity, word frequency, ambiguity or promptlength. Based on our results, we put forward a proposal for a more robust andcomprehensive evaluation standard for prompting research.</description><author>Alina Leidinger, Robert van Rooij, Ekaterina Shutova</author><pubDate>Fri, 03 Nov 2023 16:03:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01967v1</guid></item><item><title>Depth-guided Free-space Segmentation for a Mobile Robot</title><link>http://arxiv.org/abs/2311.01966v1</link><description>Accurate indoor free-space segmentation is a challenging task due to thecomplexity and the dynamic nature that indoor environments exhibit. We proposean indoors free-space segmentation method that associates large depth valueswith navigable regions. Our method leverages an unsupervised masking techniquethat, using positive instances, generates segmentation labels based on texturalhomogeneity and depth uniformity. Moreover, we generate superpixelscorresponding to areas of higher depth and align them with features extractedfrom a Dense Prediction Transformer (DPT). Using the estimated free-space masksand the DPT feature representation, a SegFormer model is fine-tuned on ourcustom-collected indoor dataset. Our experiments demonstrate sufficientperformance in intricate scenarios characterized by cluttered obstacles andchallenging identification of free space.</description><author>Christos Sevastopoulos, Joey Hussain, Stasinos Konstantopoulos, Vangelis Karkaletsis, Fillia Makedon</author><pubDate>Fri, 03 Nov 2023 16:02:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01966v1</guid></item><item><title>Don't Make Your LLM an Evaluation Benchmark Cheater</title><link>http://arxiv.org/abs/2311.01964v1</link><description>Large language models~(LLMs) have greatly advanced the frontiers ofartificial intelligence, attaining remarkable improvement in model capacity. Toassess the model performance, a typical approach is to construct evaluationbenchmarks for measuring the ability level of LLMs in different aspects.Despite that a number of high-quality benchmarks have been released, theconcerns about the appropriate use of these benchmarks and the fair comparisonof different models are increasingly growing. Considering these concerns, inthis paper, we discuss the potential risk and impact of inappropriately usingevaluation benchmarks and misleadingly interpreting the evaluation results.Specially, we focus on a special issue that would lead to inappropriateevaluation, \ie \emph{benchmark leakage}, referring that the data related toevaluation sets is occasionally used for model training. This phenomenon nowbecomes more common since pre-training data is often prepared ahead of modeltest. We conduct extensive experiments to study the effect of benchmarkleverage, and find that it can dramatically boost the evaluation results, whichwould finally lead to an unreliable assessment of model performance. To improvethe use of existing evaluation benchmarks, we finally present severalguidelines for both LLM developers and benchmark maintainers. We hope this workcan draw attention to appropriate training and evaluation of LLMs.</description><author>Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne Xin Zhao, Xu Chen, Yankai Lin, Ji-Rong Wen, Jiawei Han</author><pubDate>Fri, 03 Nov 2023 15:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01964v1</guid></item><item><title>FlashDecoding++: Faster Large Language Model Inference on GPUs</title><link>http://arxiv.org/abs/2311.01282v2</link><description>As the Large Language Model (LLM) becomes increasingly important in variousdomains. However, the following challenges still remain unsolved inaccelerating LLM inference: (1) Synchronized partial softmax update. Thesoftmax operation requires a synchronized update operation among each partialsoftmax result, leading to ~20% overheads for the attention computation inLLMs. (2) Under-utilized computation of flat GEMM. The shape of matricesperforming GEMM in LLM inference is flat, leading to under-utilized computationand &gt;50% performance loss after padding zeros in previous designs. (3)Performance loss due to static dataflow. Kernel performance in LLM depends onvaried input data features, hardware configurations, etc. A single and staticdataflow may lead to a 50.25% performance loss for GEMMs of different shapes inLLM inference. We present FlashDecoding++, a fast LLM inference engine supporting mainstreamLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++creatively proposes: (1) Asynchronized softmax with unified max value.FlashDecoding++ introduces a unified max value technique for different partialsoftmax computations to avoid synchronization. (2) Flat GEMM optimization withdouble buffering. FlashDecoding++ points out that flat GEMMs with differentshapes face varied bottlenecks. Then, techniques like double buffering areintroduced. (3) Heuristic dataflow with hardware resource adaptation.FlashDecoding++ heuristically optimizes dataflow using different hardwareresource considering input dynamics. Due to the versatility of optimizations inFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup onboth NVIDIA and AMD GPUs compared to Hugging Face implementations.FlashDecoding++ also achieves an average speedup of 1.37x compared tostate-of-the-art LLM inference engines on mainstream LLMs.</description><author>Ke Hong, Guohao Dai, Jiaming Xu, Qiuli Mao, Xiuhong Li, Jun Liu, Kangdi Chen, Hanyu Dong, Yu Wang</author><pubDate>Fri, 03 Nov 2023 15:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01282v2</guid></item><item><title>Assessing Fidelity in XAI post-hoc techniques: A Comparative Study with Ground Truth Explanations Datasets</title><link>http://arxiv.org/abs/2311.01961v1</link><description>The evaluation of the fidelity of eXplainable Artificial Intelligence (XAI)methods to their underlying models is a challenging task, primarily due to theabsence of a ground truth for explanations. However, assessing fidelity is anecessary step for ensuring a correct XAI methodology. In this study, weconduct a fair and objective comparison of the current state-of-the-art XAImethods by introducing three novel image datasets with reliable ground truthfor explanations. The primary objective of this comparison is to identifymethods with low fidelity and eliminate them from further research, therebypromoting the development of more trustworthy and effective XAI techniques. Ourresults demonstrate that XAI methods based on the backpropagation of outputinformation to input yield higher accuracy and reliability compared to methodsrelying on sensitivity analysis or Class Activation Maps (CAM). However, thebackpropagation method tends to generate more noisy saliency maps. Thesefindings have significant implications for the advancement of XAI methods,enabling the elimination of erroneous explanations and fostering thedevelopment of more robust and reliable XAI.</description><author>M. Miró-Nicolau, A. Jaume-i-Capó, G. Moyà-Alcover</author><pubDate>Fri, 03 Nov 2023 15:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01961v1</guid></item><item><title>Hardness of Low Rank Approximation of Entrywise Transformed Matrix Products</title><link>http://arxiv.org/abs/2311.01960v1</link><description>Inspired by fast algorithms in natural language processing, we study low rankapproximation in the entrywise transformed setting where we want to find a goodrank $k$ approximation to $f(U \cdot V)$, where $U, V^\top \in \mathbb{R}^{n\times r}$ are given, $r = O(\log(n))$, and $f(x)$ is a general scalarfunction. Previous work in sublinear low rank approximation has shown that ifboth (1) $U = V^\top$ and (2) $f(x)$ is a PSD kernel function, then there is an$O(nk^{\omega-1})$ time constant relative error approximation algorithm, where$\omega \approx 2.376$ is the exponent of matrix multiplication. We give thefirst conditional time hardness results for this problem, demonstrating thatboth conditions (1) and (2) are in fact necessary for getting better than$n^{2-o(1)}$ time for a relative error low rank approximation for a wide classof functions. We give novel reductions from the Strong Exponential TimeHypothesis (SETH) that rely on lower bounding the leverage scores of flatsparse vectors and hold even when the rank of the transformed matrix $f(UV)$and the target rank are $n^{o(1)}$, and when $U = V^\top$. Furthermore, evenwhen $f(x) = x^p$ is a simple polynomial, we give runtime lower bounds in thecase when $U \neq V^\top$ of the form $\Omega(\min(n^{2-o(1)}, \Omega(2^p)))$.Lastly, we demonstrate that our lower bounds are tight by giving an $O(n \cdot\text{poly}(k, 2^p, 1/\epsilon))$ time relative error approximation algorithmand a fast $O(n \cdot \text{poly}(k, p, 1/\epsilon))$ additive errorapproximation using fast tensor-based sketching. Additionally, since our lowrank algorithms rely on matrix-vector product subroutines, our lower boundsextend to show that computing $f(UV)W$, for even a small matrix $W$, requires$\Omega(n^{2-o(1)})$ time.</description><author>Tamas Sarlos, Xingyou Song, David Woodruff, Qiuyi, Zhang</author><pubDate>Fri, 03 Nov 2023 15:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01960v1</guid></item><item><title>When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment</title><link>http://arxiv.org/abs/2307.03864v4</link><description>Reinforcement learning (RL) algorithms face two distinct challenges: learningeffective representations of past and present observations, and determining howactions influence future returns. Both challenges involve modeling long-termdependencies. The Transformer architecture has been very successful to solveproblems that involve long-term dependencies, including in the RL domain.However, the underlying reason for the strong performance of Transformer-basedRL methods remains unclear: is it because they learn effective memory, orbecause they perform effective credit assignment? After introducing formaldefinitions of memory length and credit assignment length, we design simpleconfigurable tasks to measure these distinct quantities. Our empirical resultsreveal that Transformers can enhance the memory capability of RL algorithms,scaling up to tasks that require memorizing observations $1500$ steps ago.However, Transformers do not improve long-term credit assignment. In summary,our results provide an explanation for the success of Transformers in RL, whilealso highlighting an important area for future research and benchmark design.Our code is open-sourced at https://github.com/twni2016/Memory-RL</description><author>Tianwei Ni, Michel Ma, Benjamin Eysenbach, Pierre-Luc Bacon</author><pubDate>Fri, 03 Nov 2023 15:54:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03864v4</guid></item><item><title>How a student becomes a teacher: learning and forgetting through Spectral methods</title><link>http://arxiv.org/abs/2310.12612v2</link><description>In theoretical ML, the teacher-student paradigm is often employed as aneffective metaphor for real-life tuition. The above scheme proves particularlyrelevant when the student network is overparameterized as compared to theteacher network. Under these operating conditions, it is tempting to speculatethat the student ability to handle the given task could be eventually stored ina sub-portion of the whole network. This latter should be to some extentreminiscent of the frozen teacher structure, according to suitable metrics,while being approximately invariant across different architectures of thestudent candidate network. Unfortunately, state-of-the-art conventionallearning techniques could not help in identifying the existence of such aninvariant subnetwork, due to the inherent degree of non-convexity thatcharacterizes the examined problem. In this work, we take a leap forward byproposing a radically different optimization scheme which builds on a spectralrepresentation of the linear transfer of information between layers. Thegradient is hence calculated with respect to both eigenvalues and eigenvectorswith negligible increase in terms of computational and complexity load, ascompared to standard training algorithms. Working in this framework, we couldisolate a stable student substructure, that mirrors the true complexity of theteacher in terms of computing neurons, path distribution and topologicalattributes. When pruning unimportant nodes of the trained student, as follows aranking that reflects the optimized eigenvalues, no degradation in the recordedperformance is seen above a threshold that corresponds to the effective teachersize. The observed behavior can be pictured as a genuine second-order phasetransition that bears universality traits.</description><author>Lorenzo Giambagli, Lorenzo Buffoni, Lorenzo Chicchi, Duccio Fanelli</author><pubDate>Fri, 03 Nov 2023 15:53:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12612v2</guid></item><item><title>Architecture of Smart Certificates for Web3 Applications Against Cyberthreats in Financial Industry</title><link>http://arxiv.org/abs/2311.01956v1</link><description>This study addresses the security challenges associated with the currentinternet transformations, specifically focusing on emerging technologies suchas blockchain and decentralized storage. It also investigates the role of Web3applications in shaping the future of the internet. The primary objective is topropose a novel design for 'smart certificates,' which are digital certificatesthat can be programmatically enforced. Utilizing such certificates, anenterprise can better protect itself from cyberattacks and ensure the securityof its data and systems. Web3 recent security solutions by companies andprojects like Certik, Forta, Slither, and Securify are the equivalent of codescanning tool that were originally developed for Web1 and Web2 applications,and definitely not like certificates to help enterprises feel safe againstcyberthreats. We aim to improve the resilience of enterprises' digitalinfrastructure by building on top of Web3 application and put methodologies inplace for vulnerability analysis and attack correlation, focusing onarchitecture of different layers, Wallet/Client, Application and SmartContract, where specific components are provided to identify and predictthreats and risks. Furthermore, Certificate Transparency is used for enhancingthe security, trustworthiness and decentralized management of the certificates,and detecting misuses, compromises, and malfeasances.</description><author>Stefan Kambiz Behfar, Jon Crowcroft</author><pubDate>Fri, 03 Nov 2023 15:51:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01956v1</guid></item><item><title>Too Much Information: Keeping Training Simple for BabyLMs</title><link>http://arxiv.org/abs/2311.01955v1</link><description>This paper details the work of the University of Groningen for the BabyLMChallenge. We follow the idea that, like babies, language models should beintroduced to simpler concepts first and build off of that knowledge tounderstand more complex concepts. We examine this strategy ofsimple-then-complex through a variety of lenses, namely context size,vocabulary, and overall linguistic complexity of the data. We find that onlyone, context size, is truly beneficial to training a language model. Howeverthis simple change to context size gives us improvements of 2 points on averageon (Super)GLUE tasks, 1 point on MSGS tasks, and 12\% on average on BLiMPtasks. Our context-limited model outperforms the baseline that was trained on10$\times$ the amount of data.</description><author>Lukas Edman, Lisa Bylinina</author><pubDate>Fri, 03 Nov 2023 15:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01955v1</guid></item><item><title>Optimistic Multi-Agent Policy Gradient for Cooperative Tasks</title><link>http://arxiv.org/abs/2311.01953v1</link><description>\textit{Relative overgeneralization} (RO) occurs in cooperative multi-agentlearning tasks when agents converge towards a suboptimal joint policy due tooverfitting to suboptimal behavior of other agents. In early work, optimism hasbeen shown to mitigate the \textit{RO} problem when using tabular Q-learning.However, with function approximation optimism can amplify overestimation andthus fail on complex tasks. On the other hand, recent deep multi-agent policygradient (MAPG) methods have succeeded in many complex tasks but may fail withsevere \textit{RO}. We propose a general, yet simple, framework to enableoptimistic updates in MAPG methods and alleviate the RO problem. Specifically,we employ a \textit{Leaky ReLU} function where a single hyperparameter selectsthe degree of optimism to reshape the advantages when updating the policy.Intuitively, our method remains optimistic toward individual actions with lowerreturns which are potentially caused by other agents' sub-optimal behaviorduring learning. The optimism prevents the individual agents from quicklyconverging to a local optimum. We also provide a formal analysis from anoperator view to understand the proposed advantage transformation. In extensiveevaluations on diverse sets of tasks, including illustrative matrix games,complex \textit{Multi-agent MuJoCo} and \textit{Overcooked} benchmarks, theproposed method\footnote{Code can be found at\url{https://github.com/wenshuaizhao/optimappo}.} outperforms strong baselineson 13 out of 19 tested tasks and matches the performance on the rest.</description><author>Wenshuai Zhao, Yi Zhao, Zhiyuan Li, Juho Kannala, Joni Pajarinen</author><pubDate>Fri, 03 Nov 2023 15:47:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01953v1</guid></item><item><title>Image-based Geolocalization by Ground-to-2.5D Map Matching</title><link>http://arxiv.org/abs/2308.05993v2</link><description>We study the image-based geolocalization problem, aiming to localizeground-view query images on cartographic maps. Current methods often utilizecross-view localization techniques to match ground-view query images with 2Dmaps. However, the performance of these methods is unsatisfactory due tosignificant cross-view appearance differences. In this paper, we liftcross-view matching to a 2.5D space, where heights of structures (e.g., treesand buildings) provide geometric information to guide the cross-view matching.We propose a new approach to learning representative embeddings frommulti-modal data. Specifically, we establish a projection relationship between2.5D space and 2D aerial-view space. The projection is further used to combinemulti-modal features from the 2.5D and 2D maps using an effectivepixel-to-point fusion method. By encoding crucial geometric cues, our methodlearns discriminative location embeddings for matching panoramic images andmaps. Additionally, we construct the first large-scale ground-to-2.5D mapgeolocalization dataset to validate our method and facilitate future research.Both single-image based and route based localization experiments are conductedto test our method. Extensive experiments demonstrate that the proposed methodachieves significantly higher localization accuracy and faster convergence thanprevious 2D map-based approaches.</description><author>Mengjie Zhou, Liu Liu, Yiran Zhong, Andrew Calway</author><pubDate>Fri, 03 Nov 2023 15:41:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05993v2</guid></item><item><title>Hard View Selection for Contrastive Learning</title><link>http://arxiv.org/abs/2310.03940v2</link><description>Many Contrastive Learning (CL) methods train their models to be invariant todifferent "views" of an image input for which a good data augmentation pipelineis crucial. While considerable efforts were directed towards improving pre-texttasks, architectures, or robustness (e.g., Siamese networks or teacher-softmaxcentering), the majority of these methods remain strongly reliant on the randomsampling of operations within the image augmentation pipeline, such as therandom resized crop or color distortion operation. In this paper, we argue thatthe role of the view generation and its effect on performance has so farreceived insufficient attention. To address this, we propose an easy,learning-free, yet powerful Hard View Selection (HVS) strategy designed toextend the random view generation to expose the pretrained model to hardersamples during CL training. It encompasses the following iterative steps: 1)randomly sample multiple views and create pairs of two views, 2) run forwardpasses for each view pair on the currently trained model, 3) adversariallyselect the pair yielding the worst loss, and 4) run the backward pass with theselected pair. In our empirical analysis we show that under the hood, HVSincreases task difficulty by controlling the Intersection over Union of viewsduring pretraining. With only 300-epoch pretraining, HVS is able to closelyrival the 800-epoch DINO baseline which remains very favorable even whenfactoring in the slowdown induced by the additional forwards of HVS.Additionally, HVS consistently achieves accuracy improvements on ImageNetbetween 0.4% and 1.9% on linear evaluation and similar improvements on transfertasks across multiple CL methods, such as DINO, SimSiam, and SimCLR.</description><author>Fabio Ferreira, Ivo Rapant, Frank Hutter</author><pubDate>Fri, 03 Nov 2023 15:41:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03940v2</guid></item><item><title>Hint-enhanced In-Context Learning wakes Large Language Models up for knowledge-intensive tasks</title><link>http://arxiv.org/abs/2311.01949v1</link><description>In-context learning (ICL) ability has emerged with the increasing scale oflarge language models (LLMs), enabling them to learn input-label mappings fromdemonstrations and perform well on downstream tasks. However, under thestandard ICL setting, LLMs may sometimes neglect query-related information indemonstrations, leading to incorrect predictions. To address this limitation,we propose a new paradigm called Hint-enhanced In-Context Learning (HICL) toexplore the power of ICL in open-domain question answering, an important formin knowledge-intensive tasks. HICL leverages LLMs' reasoning ability to extractquery-related knowledge from demonstrations, then concatenates the knowledge toprompt LLMs in a more explicit way. Furthermore, we track the source of thisknowledge to identify specific examples, and introduce a Hint-related ExampleRetriever (HER) to select informative examples for enhanced demonstrations. Weevaluate HICL with HER on 3 open-domain QA benchmarks, and observe averageperformance gains of 2.89 EM score and 2.52 F1 score on gpt-3.5-turbo, 7.62 EMscore and 7.27 F1 score on LLaMA-2-Chat-7B compared with standard setting.</description><author>Yifan Wang, Qingyan Guo, Xinzhe Ni, Chufan Shi, Lemao Liu, Haiyun Jiang, Yujiu Yang</author><pubDate>Fri, 03 Nov 2023 15:39:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01949v1</guid></item><item><title>The Impact of Missing Data on Causal Discovery: A Multicentric Clinical Study</title><link>http://arxiv.org/abs/2305.10050v2</link><description>Causal inference for testing clinical hypotheses from observational datapresents many difficulties because the underlying data-generating model and theassociated causal graph are not usually available. Furthermore, observationaldata may contain missing values, which impact the recovery of the causal graphby causal discovery algorithms: a crucial issue often ignored in clinicalstudies. In this work, we use data from a multi-centric study on endometrialcancer to analyze the impact of different missingness mechanisms on therecovered causal graph. This is achieved by extending state-of-the-art causaldiscovery algorithms to exploit expert knowledge without sacrificingtheoretical soundness. We validate the recovered graph with expert physicians,showing that our approach finds clinically-relevant solutions. Finally, wediscuss the goodness of fit of our graph and its consistency from a clinicaldecision-making perspective using graphical separation to validate causalpathways.</description><author>Alessio Zanga, Alice Bernasconi, Peter J. F. Lucas, Hanny Pijnenborg, Casper Reijnen, Marco Scutari, Fabio Stella</author><pubDate>Fri, 03 Nov 2023 15:37:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10050v2</guid></item><item><title>LLMDet: A Third Party Large Language Models Generated Text Detection Tool</title><link>http://arxiv.org/abs/2305.15004v3</link><description>Generated texts from large language models (LLMs) are remarkably close tohigh-quality human-authored text, raising concerns about their potential misusein spreading false information and academic misconduct. Consequently, there isan urgent need for a highly practical detection tool capable of accuratelyidentifying the source of a given text. However, existing detection toolstypically rely on access to LLMs and can only differentiate betweenmachine-generated and human-authored text, failing to meet the requirements offine-grained tracing, intermediary judgment, and rapid detection. Therefore, wepropose LLMDet, a model-specific, secure, efficient, and extendable detectiontool, that can source text from specific LLMs, such as GPT-2, OPT, LLaMA, andothers. In LLMDet, we record the next-token probabilities of salient n-grams asfeatures to calculate proxy perplexity for each LLM. By jointly analyzing theproxy perplexities of LLMs, we can determine the source of the generated text.Experimental results show that LLMDet yields impressive detection performancewhile ensuring speed and security, achieving 98.54% precision and x5.0 fasterfor recognizing human-authored text. Additionally, LLMDet can effortlesslyextend its detection capabilities to a new open-source model. We will providean open-source tool at https://github.com/TrustedLLM/LLMDet.</description><author>Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, Tat-Seng Chua</author><pubDate>Fri, 03 Nov 2023 15:31:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15004v3</guid></item><item><title>A Quantitative Autonomy Quantification Framework for Fully Autonomous Robotic Systems</title><link>http://arxiv.org/abs/2311.01939v1</link><description>Although autonomous functioning facilitates deployment of robotic systems indomains that admit limited human oversight on our planet and beyond, findingcorrespondence between task requirements and autonomous capability is still anopen challenge. Consequently, a number of methods for quantifying autonomy havebeen proposed over the last three decades, but to our knowledge all these haveno discernment of sub-mode features of variation of autonomy and some are basedon metrics that violet the Goodhart's law. This paper focuses on the fullautonomous mode and proposes a task-requirements based autonomy assessmentframework. The framework starts by establishing robot task characteristics fromwhich three autonomy metrics, namely requisite capability, reliability andresponsiveness, and functions for determining autonomy as a two-part measure,namely of level of autonomy and degree of autonomy are derived. Thesecharacteristics are founded on the realization that robots ultimately replacehuman skilled workers, to find a mapping between human job and robot taskcharacteristics. The distinction between level and degree of autonomy stemmedfrom the acknowledgment that autonomy is not just a question of existence, butalso one of performance of requisite capability. When continuously monitored,the proposed metrics provide a means of monitoring the integrity of a system.The framework has been demonstrated on two case studies, namely autonomousvehicle at an on-road dynamic driving task and the DARPA subT challenge rulesanalysis. The framework provides not only a tool for quantifying autonomy, butalso a regulatory interface and common language for autonomous systemsdevelopers and users.</description><author>Nasser Gyagenda, Hubert Roth</author><pubDate>Fri, 03 Nov 2023 15:26:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01939v1</guid></item><item><title>Distill Gold from Massive Ores: Efficient Dataset Distillation via Critical Samples Selection</title><link>http://arxiv.org/abs/2305.18381v2</link><description>Data-efficient learning has drawn significant attention, especially given thecurrent trend of large multi-modal models, where dataset distillation can be aneffective solution. However, the dataset distillation process itself is stillvery inefficient. In this work, we model the distillation problem withreference to information transport. Observing that severe data redundancyexists in dataset distillation, we argue to put more emphasis on the utility ofthe training samples. We propose a family of methods to exploit the mostvaluable samples, which is validated by our comprehensive analysis of theoptimal data selection. The new strategy significantly reduces the trainingcost and extends a variety of existing distillation algorithms to larger andmore diversified datasets, e.g., in some cases only 0.04% training data issufficient for comparable distillation performance. Moreover, our strategyconsistently enhances the performance, which may open up new analyses on thedynamics of distillation and networks. Our method is able to extend thedistillation algorithms to much larger-scale datasets and more heterogeneousdatasets, e.g., ImageNet-1K and Kinetics-400. Our code is available onhttps://github.com/silicx/GoldFromOres.</description><author>Yue Xu, Yong-Lu Li, Kaitong Cui, Ziyu Wang, Cewu Lu, Yu-Wing Tai, Chi-Keung Tang</author><pubDate>Fri, 03 Nov 2023 15:24:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18381v2</guid></item><item><title>Supermind Ideator: Exploring generative AI to support creative problem-solving</title><link>http://arxiv.org/abs/2311.01937v1</link><description>Previous efforts to support creative problem-solving have included (a)techniques (such as brainstorming and design thinking) to stimulate creativeideas, and (b) software tools to record and share these ideas. Now, generativeAI technologies can suggest new ideas that might never have occurred to theusers, and users can then select from these ideas or use them to stimulate evenmore ideas. Here, we describe such a system, Supermind Ideator. The system usesa large language model (GPT 3.5) and adds prompting, fine tuning, and a userinterface specifically designed to help people use creative problem-solvingtechniques. Some of these techniques can be applied to any problem; others arespecifically intended to help generate innovative ideas about how to designgroups of people and/or computers ("superminds"). We also describe our earlyexperiences with using this system and suggest ways it could be extended tosupport additional techniques for other specific problem-solving domains.</description><author>Steven R. Rick, Gianni Giacomelli, Haoran Wen, Robert J. Laubacher, Nancy Taubenslag, Jennifer L. Heyman, Max Sina Knicker, Younes Jeddi, Hendrik Maier, Stephen Dwyer, Pranav Ragupathy, Thomas W. Malone</author><pubDate>Fri, 03 Nov 2023 15:21:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01937v1</guid></item><item><title>ForecastPFN: Synthetically-Trained Zero-Shot Forecasting</title><link>http://arxiv.org/abs/2311.01933v1</link><description>The vast majority of time-series forecasting approaches require a substantialtraining dataset. However, many real-life forecasting applications have verylittle initial observations, sometimes just 40 or fewer. Thus, theapplicability of most forecasting methods is restricted in data-sparsecommercial applications. While there is recent work in the setting of verylimited initial data (so-called `zero-shot' forecasting), its performance isinconsistent depending on the data used for pretraining. In this work, we takea different approach and devise ForecastPFN, the first zero-shot forecastingmodel trained purely on a novel synthetic data distribution. ForecastPFN is aprior-data fitted network, trained to approximate Bayesian inference, which canmake predictions on a new time series dataset in a single forward pass. Throughextensive experiments, we show that zero-shot predictions made by ForecastPFNare more accurate and faster compared to state-of-the-art forecasting methods,even when the other methods are allowed to train on hundreds of additionalin-distribution data points.</description><author>Samuel Dooley, Gurnoor Singh Khurana, Chirag Mohapatra, Siddartha Naidu, Colin White</author><pubDate>Fri, 03 Nov 2023 15:17:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01933v1</guid></item><item><title>Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders</title><link>http://arxiv.org/abs/2310.08571v2</link><description>Machine Learning as a Service (MLaaS) APIs provide ready-to-use andhigh-utility encoders that generate vector representations for given inputs.Since these encoders are very costly to train, they become lucrative targetsfor model stealing attacks during which an adversary leverages query access tothe API to replicate the encoder locally at a fraction of the original trainingcosts. We propose Bucks for Buckets (B4B), the first active defense thatprevents stealing while the attack is happening without degradingrepresentation quality for legitimate API users. Our defense relies on theobservation that the representations returned to adversaries who try to stealthe encoder's functionality cover a significantly larger fraction of theembedding space than representations of legitimate users who utilize theencoder to solve a particular downstream task.vB4B leverages this to adaptivelyadjust the utility of the returned representations according to a user'scoverage of the embedding space. To prevent adaptive adversaries from eludingour defense by simply creating multiple user accounts (sybils), B4B alsoindividually transforms each user's representations. This prevents theadversary from directly aggregating representations over multiple accounts tocreate their stolen encoder copy. Our active defense opens a new path towardssecurely sharing and democratizing encoders over public APIs.</description><author>Jan Dubiński, Stanisław Pawlak, Franziska Boenisch, Tomasz Trzciński, Adam Dziedzic</author><pubDate>Fri, 03 Nov 2023 15:12:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08571v2</guid></item><item><title>ProS: Facial Omni-Representation Learning via Prototype-based Self-Distillation</title><link>http://arxiv.org/abs/2311.01929v1</link><description>This paper presents a novel approach, called Prototype-basedSelf-Distillation (ProS), for unsupervised face representation learning. Theexisting supervised methods heavily rely on a large amount of annotatedtraining facial data, which poses challenges in terms of data collection andprivacy concerns. To address these issues, we propose ProS, which leverages avast collection of unlabeled face images to learn a comprehensive facialomni-representation. In particular, ProS consists of two vision-transformers(teacher and student models) that are trained with different augmented images(cropping, blurring, coloring, etc.). Besides, we build a face-aware retrievalsystem along with augmentations to obtain the curated images comprisingpredominantly facial areas. To enhance the discrimination of learned features,we introduce a prototype-based matching loss that aligns the similaritydistributions between features (teacher or student) and a set of learnableprototypes. After pre-training, the teacher vision transformer serves as abackbone for downstream tasks, including attribute estimation, expressionrecognition, and landmark alignment, achieved through simple fine-tuning withadditional layers. Extensive experiments demonstrate that our method achievesstate-of-the-art performance on various tasks, both in full and few-shotsettings. Furthermore, we investigate pre-training with synthetic face images,and ProS exhibits promising performance in this scenario as well.</description><author>Xing Di, Yiyu Zheng, Xiaoming Liu, Yu Cheng</author><pubDate>Fri, 03 Nov 2023 15:10:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01929v1</guid></item><item><title>Constructing Temporal Dynamic Knowledge Graphs from Interactive Text-based Games</title><link>http://arxiv.org/abs/2311.01928v1</link><description>In natural language processing, interactive text-based games serve as a testbed for interactive AI systems. Prior work has proposed to play text-basedgames by acting based on discrete knowledge graphs constructed by the DiscreteGraph Updater (DGU) to represent the game state from the natural languagedescription. While DGU has shown promising results with high interpretability,it suffers from lower knowledge graph accuracy due to its lack of temporalityand limited generalizability to complex environments with objects with the samelabel. In order to address DGU's weaknesses while preserving its highinterpretability, we propose the Temporal Discrete Graph Updater (TDGU), anovel neural network model that represents dynamic knowledge graphs as asequence of timestamped graph events and models them using a temporal pointbased graph neural network. Through experiments on the dataset collected from atext-based game TextWorld, we show that TDGU outperforms the baseline DGU. Wefurther show the importance of temporal information for TDGU's performancethrough an ablation study and demonstrate that TDGU has the ability togeneralize to more complex environments with objects with the same label. Allthe relevant code can be found at\url{https://github.com/yukw777/temporal-discrete-graph-updater}.</description><author>Keunwoo Peter Yu</author><pubDate>Fri, 03 Nov 2023 15:09:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01928v1</guid></item><item><title>GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling</title><link>http://arxiv.org/abs/2311.01927v1</link><description>Linear Recurrence has proven to be a powerful tool for modeling longsequences efficiently. In this work, we show that existing models fail to takefull advantage of its potential. Motivated by this finding, we developGateLoop, a foundational sequence model that generalizes linear recurrentmodels such as S4, S5, LRU and RetNet, by employing data-controlled statetransitions. Utilizing this theoretical advance, GateLoop empiricallyoutperforms existing models for auto-regressive language modeling. Our methodcomes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \log_{2} l)$parallel mode making use of highly optimized associative scan implementations.Furthermore, we derive an $O(l^2)$ surrogate attention mode, revealingremarkable implications for Transformer and recently proposed architectures.Specifically, we prove that our approach can be interpreted as providingdata-controlled relative-positional information to Attention. While manyexisting models solely rely on data-controlled cumulative sums for contextaggregation, our findings suggest that incorporating data-controlled complexcumulative products may be a crucial step towards more powerful sequencemodels.</description><author>Tobias Katsch</author><pubDate>Fri, 03 Nov 2023 15:08:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01927v1</guid></item><item><title>PMT-IQA: Progressive Multi-task Learning for Blind Image Quality Assessment</title><link>http://arxiv.org/abs/2301.01182v2</link><description>Blind image quality assessment (BIQA) remains challenging due to thediversity of distortion and image content variation, which complicate thedistortion patterns crossing different scales and aggravate the difficulty ofthe regression problem for BIQA. However, existing BIQA methods often fail toconsider multi-scale distortion patterns and image content, and little researchhas been done on learning strategies to make the regression model producebetter performance. In this paper, we propose a simple yet effectiveProgressive Multi-Task Image Quality Assessment (PMT-IQA) model, which containsa multi-scale feature extraction module (MS) and a progressive multi-tasklearning module (PMT), to help the model learn complex distortion patterns andbetter optimize the regression issue to align with the law of human learningprocess from easy to hard. To verify the effectiveness of the proposed PMT-IQAmodel, we conduct experiments on four widely used public datasets, and theexperimental results indicate that the performance of PMT-IQA is superior tothe comparison approaches, and both MS and PMT modules improve the model'sperformance.</description><author>Qingyi Pan, Ning Guo, Letu Qingge, Jingyi Zhang, Pei Yang</author><pubDate>Fri, 03 Nov 2023 15:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.01182v2</guid></item><item><title>Meta Learning for Multi-View Visuomotor Systems</title><link>http://arxiv.org/abs/2310.20414v2</link><description>This paper introduces a new approach for quickly adapting a multi-viewvisuomotor system for robots to varying camera configurations from the baselinesetup. It utilises meta-learning to fine-tune the perceptual network whilekeeping the policy network fixed. Experimental results demonstrate asignificant reduction in the number of new training episodes needed to attainbaseline performance.</description><author>Benji Alwis</author><pubDate>Fri, 03 Nov 2023 14:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20414v2</guid></item><item><title>Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review</title><link>http://arxiv.org/abs/2311.01918v1</link><description>With the rapid development of artificial intelligence, large language models(LLMs) have shown promising capabilities in mimicking human-level languagecomprehension and reasoning. This has sparked significant interest in applyingLLMs to enhance various aspects of healthcare, ranging from medical educationto clinical decision support. However, medicine involves multifaceted datamodalities and nuanced reasoning skills, presenting challenges for integratingLLMs. This paper provides a comprehensive review on the applications andimplications of LLMs in medicine. It begins by examining the fundamentalapplications of general-purpose and specialized LLMs, demonstrating theirutilities in knowledge retrieval, research support, clinical workflowautomation, and diagnostic assistance. Recognizing the inherent multimodalityof medicine, the review then focuses on multimodal LLMs, investigating theirability to process diverse data types like medical imaging and EHRs to augmentdiagnostic accuracy. To address LLMs' limitations regarding personalization andcomplex clinical reasoning, the paper explores the emerging development ofLLM-powered autonomous agents for healthcare. Furthermore, it summarizes theevaluation methodologies for assessing LLMs' reliability and safety in medicalcontexts. Overall, this review offers an extensive analysis on thetransformative potential of LLMs in modern medicine. It also highlights thepivotal need for continuous optimizations and ethical oversight before thesemodels can be effectively integrated into clinical practice. Visithttps://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanyingGitHub repository containing latest papers.</description><author>Mingze Yuan, Peng Bao, Jiajia Yuan, Yunhao Shen, Zifan Chen, Yi Xie, Jie Zhao, Yang Chen, Li Zhang, Lin Shen, Bin Dong</author><pubDate>Fri, 03 Nov 2023 14:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01918v1</guid></item><item><title>General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Societal Implications and Responsible Governance</title><link>http://arxiv.org/abs/2307.14283v2</link><description>Most applications of Artificial Intelligence (AI) are designed for a confinedand specific task. However, there are many scenarios that call for a moregeneral AI, capable of solving a wide array of tasks without being specificallydesigned for them. The term General-Purpose Artificial Intelligence Systems(GPAIS) has been defined to refer to these AI systems. To date, the possibilityof an Artificial General Intelligence, powerful enough to perform anyintellectual task as if it were human, or even improve it, has remained anaspiration, fiction, and considered a risk for our society. Whilst we mightstill be far from achieving that, GPAIS is a reality and sitting at theforefront of AI research. This work discusses existing definitions for GPAISand proposes a new definition that allows for a gradual differentiation amongtypes of GPAIS according to their properties and limitations. We distinguishbetween closed-world and open-world GPAIS, characterising their degree ofautonomy and ability based on several factors such as adaptation to new tasks,competence in domains not intentionally trained for, ability to learn from fewdata, or proactive acknowledgment of their own limitations. We propose ataxonomy of approaches to realise GPAIS, describing research trends such as theuse of AI techniques to improve another AI (AI-powered AI) or (single)foundation models. As a prime example, we delve into GenAI, aligning them withthe concepts presented in the taxonomy. We explore multi-modality, whichinvolves fusing various types of data sources to expand the capabilities ofGPAIS. Through the proposed definition and taxonomy, our aim is to facilitateresearch collaboration across different areas that are tackling general purposetasks, as they share many common aspects. Finally, we discuss the state ofGPAIS, prospects, societal implications, and the need for regulation andgovernance.</description><author>Isaac Triguero, Daniel Molina, Javier Poyatos, Javier Del Ser, Francisco Herrera</author><pubDate>Fri, 03 Nov 2023 14:51:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14283v2</guid></item><item><title>On some limitations of data-driven weather forecasting models</title><link>http://arxiv.org/abs/2309.08473v2</link><description>As in many other areas of engineering and applied science, Machine Learning(ML) is having a profound impact in the domain of Weather and ClimatePrediction. A very recent development in this area has been the emergence offully data-driven ML prediction models which routinely claim superiorperformance to that of traditional physics-based models. In this work, weexamine some aspects of the forecasts produced by an exemplar of the currentgeneration of ML models, Pangu-Weather, with a focus on the fidelity andphysical consistency of those forecasts and how these characteristics relate toperceived forecast performance. The main conclusion is that Pangu-Weatherforecasts, and possibly those of similar ML models, do not have the fidelityand physical consistency of physics-based models and their advantage inaccuracy on traditional deterministic metrics of forecast skill can be at leastpartly attributed to these peculiarities. Balancing forecast skill and physicalconsistency of ML-driven predictions will be an important consideration forfuture ML models. However, and similarly to other modern post-processingtechnologies, the current ML models appear to be already able to add value tostandard NWP output for specific forecast applications and combined with theirextremely low computational cost during deployment, are set to provide anadditional, useful source of forecast information. .</description><author>Massimo Bonavita</author><pubDate>Fri, 03 Nov 2023 14:50:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08473v2</guid></item><item><title>Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization</title><link>http://arxiv.org/abs/2310.20033v2</link><description>Large Language Models (LLMs) like the GPT and LLaMA families havedemonstrated exceptional capabilities in capturing and condensing criticalcontextual information and achieving state-of-the-art performance in thesummarization task. However, community concerns about these models'hallucination issues continue to rise. LLMs sometimes generate factuallyhallucinated summaries, which can be extremely harmful in the clinical domainNLP tasks (e.g., clinical note summarization), where factually incorrectstatements can lead to critically erroneous diagnoses. Fine-tuning LLMs usinghuman feedback has shown the promise of aligning LLMs to be factuallyconsistent during generation, but such training procedure requires high-qualityhuman-annotated data, which can be extremely expensive to get in the clinicaldomain. In this work, we propose a new pipeline using ChatGPT instead of humanexperts to generate high-quality feedback data for improving factualconsistency in the clinical note summarization task. We focus specifically onedit feedback because recent work discusses the shortcomings of human alignmentvia preference feedback in complex situations (such as clinical NLP tasks thatrequire extensive expert knowledge), as well as some advantages of collectingedit feedback from domain experts. In addition, although GPT has reached theexpert level in many clinical NLP tasks (e.g., USMLE QA), there is not muchprevious work discussing whether GPT can generate expert-level edit feedbackfor LMs in the clinical note summarization task. We hope to fill this gap.Finally, our evaluations demonstrate the potential use of GPT edits in humanalignment, especially from a factuality perspective.</description><author>Prakamya Mishra, Zonghai Yao, Shuwei Chen, Beining Wang, Rohan Mittal, Hong Yu</author><pubDate>Fri, 03 Nov 2023 14:49:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20033v2</guid></item><item><title>Contrast-Agnostic Groupwise Registration by Robust PCA for Quantitative Cardiac MRI</title><link>http://arxiv.org/abs/2311.01916v1</link><description>Quantitative cardiac magnetic resonance imaging (MRI) is an increasinglyimportant diagnostic tool for cardiovascular diseases. Yet, co-registration ofall baseline images within the quantitative MRI sequence is essential for theaccuracy and precision of quantitative maps. However, co-registering allbaseline images from a quantitative cardiac MRI sequence remains a nontrivialtask because of the simultaneous changes in intensity and contrast, incombination with cardiac and respiratory motion. To address the challenge, wepropose a novel motion correction framework based on robust principle componentanalysis (rPCA) that decomposes quantitative cardiac MRI into low-rank andsparse components, and we integrate the groupwise CNN-based registrationbackbone within the rPCA framework. The low-rank component of rPCA correspondsto the quantitative mapping (i.e. limited degree of freedom in variation),while the sparse component corresponds to the residual motion, making it easierto formulate and solve the groupwise registration problem. We evaluated ourproposed method on cardiac T1 mapping by the modified Look-Locker inversionrecovery (MOLLI) sequence, both before and after the Gadolinium contrast agentadministration. Our experiments showed that our method effectively improvedregistration performance over baseline methods without introducing rPCA, andreduced quantitative mapping error in both in-domain (pre-contrast MOLLI) andout-of-domain (post-contrast MOLLI) inference. The proposed rPCA framework isgeneric and can be integrated with other registration backbones.</description><author>Xinqi Li, Yi Zhang, Yidong Zhao, Jan van Gemert, Qian Tao</author><pubDate>Fri, 03 Nov 2023 14:48:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01916v1</guid></item><item><title>Ensemble models outperform single model uncertainties and predictions for operator-learning of hypersonic flows</title><link>http://arxiv.org/abs/2311.00060v2</link><description>High-fidelity computational simulations and physical experiments ofhypersonic flows are resource intensive. Training scientific machine learning(SciML) models on limited high-fidelity data offers one approach to rapidlypredict behaviors for situations that have not been seen before. However,high-fidelity data is itself in limited quantity to validate all outputs of theSciML model in unexplored input space. As such, an uncertainty-aware SciMLmodel is desired. The SciML model's output uncertainties could then be used toassess the reliability and confidence of the model's predictions. In thisstudy, we extend a DeepONet using three different uncertainty quantificationmechanisms: mean-variance estimation, evidential uncertainty, and ensembling.The uncertainty aware DeepONet models are trained and evaluated on thehypersonic flow around a blunt cone object with data generated viacomputational fluid dynamics over a wide range of Mach numbers and altitudes.We find that ensembling outperforms the other two uncertainty models in termsof minimizing error and calibrating uncertainty in both interpolative andextrapolative regimes.</description><author>Victor J. Leon, Noah Ford, Honest Mrema, Jeffrey Gilbert, Alexander New</author><pubDate>Fri, 03 Nov 2023 14:43:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00060v2</guid></item><item><title>End-to-End assessment of AR-assisted neurosurgery systems</title><link>http://arxiv.org/abs/2311.01912v1</link><description>Augmented Reality (AR) has emerged as a significant advancement in surgicalprocedures, offering a solution to the challenges posed by traditionalneuronavigation methods. These conventional techniques often necessitatesurgeons to split their focus between the surgical site and a separate monitorthat displays guiding images. Over the years, many systems have been developedto register and track the hologram at the targeted locations, each employed itsown evaluation technique. On the other hand, hologram displacement measurementis not a straightforward task because of various factors such as occlusion,Vengence-Accomodation Conflict, and unstable holograms in space. In this study,we explore and classify different techniques for assessing an AR-assistedneurosurgery system and propose a new technique to systematize the assessmentprocedure. Moreover, we conduct a deeper investigation to assess surgeon errorin the pre- and intra-operative phases of the surgery based on the respectivefeedback given. We found that although the system can undergo registration andtracking errors, physical feedback can significantly reduce the error caused byhologram displacement. However, the lack of visual feedback on the hologramdoes not have a significant effect on the user 3D perception.</description><author>Mahdi Bagheri, Farhad Piri, Hadi Digale, Saem Sattarzadeh, Mohammad Reza Mohammadi</author><pubDate>Fri, 03 Nov 2023 14:41:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01912v1</guid></item><item><title>LLM-driven Multimodal Target Volume Contouring in Radiation Oncology</title><link>http://arxiv.org/abs/2311.01908v1</link><description>Target volume contouring for radiation therapy is considered significantlymore challenging than the normal organ segmentation tasks as it necessitatesthe utilization of both image and text-based clinical information. Inspired bythe recent advancement of large language models (LLMs) that can facilitate theintegration of the textural information and images, here we present a novelLLM-driven multi-modal AI that utilizes the clinical text information and isapplicable to the challenging task of target volume contouring for radiationtherapy, and validate it within the context of breast cancer radiation therapytarget volume contouring. Using external validation and data-insufficientenvironments, which attributes highly conducive to real-world applications, wedemonstrate that the proposed model exhibits markedly improved performancecompared to conventional vision-only AI models, particularly exhibiting robustgeneralization performance and data-efficiency. To our best knowledge, this isthe first LLM-driven multimodal AI model that integrates the clinical textinformation into target volume delineation for radiation oncology.</description><author>Yujin Oh, Sangjoon Park, Hwa Kyung Byun, Jin Sung Kim, Jong Chul Ye</author><pubDate>Fri, 03 Nov 2023 14:38:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01908v1</guid></item><item><title>From Understanding Genetic Drift to a Smart-Restart Mechanism for Estimation-of-Distribution Algorithms</title><link>http://arxiv.org/abs/2206.09090v5</link><description>Estimation-of-distribution algorithms (EDAs) are optimization algorithms thatlearn a distribution on the search space from which good solutions can besampled easily. A key parameter of most EDAs is the sample size (populationsize). If the population size is too small, the update of the probabilisticmodel builds on few samples, leading to the undesired effect of genetic drift.Too large population sizes avoid genetic drift, but slow down the process. Building on a recent quantitative analysis of how the population size leadsto genetic drift, we design a smart-restart mechanism for EDAs. By stoppingruns when the risk for genetic drift is high, it automatically runs the EDA ingood parameter regimes. Via a mathematical runtime analysis, we prove a general performance guaranteefor this smart-restart scheme. This in particular shows that in many situationswhere the optimal (problem-specific) parameter values are known, the restartscheme automatically finds these, leading to the asymptotically optimalperformance. We also conduct an extensive experimental analysis. On four classic benchmarkproblems, we clearly observe the critical influence of the population size onthe performance, and we find that the smart-restart scheme leads to aperformance close to the one obtainable with optimal parameter values. Ourresults also show that previous theory-based suggestions for the optimalpopulation size can be far from the optimal ones, leading to a performanceclearly inferior to the one obtained via the smart-restart scheme. We alsoconduct experiments with PBIL (cross-entropy algorithm) on two combinatorialoptimization problems from the literature, the max-cut problem and thebipartition problem. Again, we observe that the smart-restart mechanism findsmuch better values for the population size than those suggested in theliterature, leading to a much better performance.</description><author>Weijie Zheng, Benjamin Doerr</author><pubDate>Fri, 03 Nov 2023 14:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.09090v5</guid></item><item><title>BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural Sentence Simplification</title><link>http://arxiv.org/abs/2311.01907v1</link><description>Automatic simplification can help laypeople to comprehend complex scientifictext. Language models are frequently applied to this task by translating fromcomplex to simple language. In this paper, we describe our system based onLlama 2, which ranked first in the PLABA shared task addressing thesimplification of biomedical text. We find that the large portion of sharedtokens between input and output leads to weak training signals andconservatively editing models. To mitigate these issues, we proposesentence-level and token-level loss weights. They give higher weight tomodified tokens, indicated by edit distance and edit operations, respectively.We conduct an empirical evaluation on the PLABA dataset and find that bothapproaches lead to simplifications closer to those created by human annotators(+1.8% / +3.5% SARI), simpler language (-1 / -1.1 FKGL) and more edits (1.6x /1.8x edit distance) compared to the same model fine-tuned with standard crossentropy. We furthermore show that the hyperparameter $\lambda$ in token-levelloss weights can be used to control the edit distance and the simplicity level(FKGL).</description><author>Valentin Knappich, Simon Razniewski, Annemarie Friedrich</author><pubDate>Fri, 03 Nov 2023 14:34:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01907v1</guid></item><item><title>Rebuild City Buildings from Off-Nadir Aerial Images with Offset-Building Model (OBM)</title><link>http://arxiv.org/abs/2310.16717v2</link><description>Accurate measurement of the offset from roof-to-footprint invery-high-resolution remote sensing imagery is crucial for urban informationextraction tasks. With the help of deep learning, existing methods typicallyrely on two-stage CNN models to extract regions of interest on building featuremaps. At the first stage, a Region Proposal Network (RPN) is applied to extractthousands of ROIs (Region of Interests) which will post-imported into aRegion-based Convolutional Neural Networks (RCNN) to extract wantedinformation. However, because of inflexible RPN, these methods often lackeffective user interaction, encounter difficulties in instance correspondence,and struggle to keep up with the advancements in general artificialintelligence. This paper introduces an interactive Transformer model combinedwith a prompt encoder to precisely extract building segmentation as well as theoffset vectors from roofs to footprints. In our model, a powerful module,namely ROAM, was tailored for common problems in predicting roof-to-footprintoffsets. We tested our model's feasibility on the publicly available BONAIdataset, achieving a significant reduction in Prompt-Instance-Level offseterrors ranging from 14.6% to 16.3%. Additionally, we developed a Distance-NMSalgorithm tailored for large-scale building offsets, significantly enhancingthe accuracy of predicted building offset angles and lengths in astraightforward and efficient manner. To further validate the model'srobustness, we created a new test set using 0.5m remote sensing imagery fromHuizhou, China, for inference testing. Our code, training methods, and theupdated dataset will be accessable at https://github.com/likaiucas.</description><author>Kai Li, Yupeng Deng, Yunlong Kong, Diyou Liu, Jingbo Chen, Yu Meng, Junxian Ma</author><pubDate>Fri, 03 Nov 2023 14:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16717v2</guid></item><item><title>Simplifying Transformer Blocks</title><link>http://arxiv.org/abs/2311.01906v1</link><description>A simple design recipe for deep Transformers is to compose identical buildingblocks. But standard transformer blocks are far from simple, interweavingattention and MLP sub-blocks with skip connections &amp; normalisation layers inprecise arrangements. This complexity leads to brittle architectures, whereseemingly minor changes can significantly reduce training speed, or rendermodels untrainable. In this work, we ask to what extent the standard transformer block can besimplified? Combining signal propagation theory and empirical observations, wemotivate modifications that allow many block components to be removed with noloss of training speed, including skip connections, projection or valueparameters, sequential sub-blocks and normalisation layers. In experiments onboth autoregressive decoder-only and BERT encoder-only models, our simplifiedtransformers emulate the per-update training speed and performance of standardtransformers, while enjoying 15% faster training throughput, and using 15%fewer parameters.</description><author>Bobby He, Thomas Hofmann</author><pubDate>Fri, 03 Nov 2023 14:30:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01906v1</guid></item><item><title>From Chaos to Calibration: A Geometric Mutual Information Approach to Target-Free Camera LiDAR Extrinsic Calibration</title><link>http://arxiv.org/abs/2311.01905v1</link><description>Sensor fusion is vital for the safe and robust operation of autonomousvehicles. Accurate extrinsic sensor to sensor calibration is necessary toaccurately fuse multiple sensor's data in a common spatial reference frame. Inthis paper, we propose a target free extrinsic calibration algorithm thatrequires no ground truth training data, artificially constrained motiontrajectories, hand engineered features or offline optimization and that isaccurate, precise and extremely robust to initialization error. Most current research on online camera-LiDAR extrinsic calibration requiresground truth training data which is impossible to capture at scale. We revisitanalytical mutual information based methods first proposed in 2012 anddemonstrate that geometric features provide a robust information metric forcamera-LiDAR extrinsic calibration. We demonstrate our proposed improvementusing the KITTI and KITTI-360 fisheye data set.</description><author>Jack Borer, Jeremy Tschirner, Florian Ölsner, Stefan Milz</author><pubDate>Fri, 03 Nov 2023 14:30:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01905v1</guid></item><item><title>GRANDE: Gradient-Based Decision Tree Ensembles</title><link>http://arxiv.org/abs/2309.17130v2</link><description>Despite the success of deep learning for text and image data, tree-basedensemble models are still state-of-the-art for machine learning withheterogeneous tabular data. However, there is a significant need fortabular-specific gradient-based methods due to their high flexibility. In thispaper, we propose $\text{GRANDE}$, $\text{GRA}$die$\text{N}$t-Based$\text{D}$ecision Tree $\text{E}$nsembles, a novel approach for learning hard,axis-aligned decision tree ensembles using end-to-end gradient descent. GRANDEis based on a dense representation of tree ensembles, which affords to usebackpropagation with a straight-through operator to jointly optimize all modelparameters. Our method combines axis-aligned splits, which is a usefulinductive bias for tabular data, with the flexibility of gradient-basedoptimization. Furthermore, we introduce an advanced instance-wise weightingthat facilitates learning representations for both, simple and complexrelations, within a single model. We conducted an extensive evaluation on apredefined benchmark with 19 classification datasets and demonstrate that ourmethod outperforms existing gradient-boosting and deep learning frameworks onmost datasets. The method is available under:https://github.com/s-marton/GRANDE</description><author>Sascha Marton, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt</author><pubDate>Fri, 03 Nov 2023 14:28:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17130v2</guid></item><item><title>GradTree: Learning Axis-Aligned Decision Trees with Gradient Descent</title><link>http://arxiv.org/abs/2305.03515v4</link><description>Decision Trees (DTs) are commonly used for many machine learning tasks due totheir high degree of interpretability. However, learning a DT from data is adifficult optimization problem, as it is non-convex and non-differentiable.Therefore, common approaches learn DTs using a greedy growth algorithm thatminimizes the impurity locally at each internal node. Unfortunately, thisgreedy procedure can lead to inaccurate trees. In this paper, we present anovel approach for learning hard, axis-aligned DTs with gradient descent. Theproposed method uses backpropagation with a straight-through operator on adense DT representation, to jointly optimize all tree parameters. Our approachoutperforms existing methods on binary classification benchmarks and achievescompetitive results for multi-class tasks. The method is available under:https://github.com/s-marton/GradTree</description><author>Sascha Marton, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt</author><pubDate>Fri, 03 Nov 2023 14:27:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03515v4</guid></item><item><title>High Precision Causal Model Evaluation with Conditional Randomization</title><link>http://arxiv.org/abs/2311.01902v1</link><description>The gold standard for causal model evaluation involves comparing modelpredictions with true effects estimated from randomized controlled trials(RCT). However, RCTs are not always feasible or ethical to perform. Incontrast, conditionally randomized experiments based on inverse probabilityweighting (IPW) offer a more realistic approach but may suffer from highestimation variance. To tackle this challenge and enhance causal modelevaluation in real-world conditional randomization settings, we introduce anovel low-variance estimator for causal error, dubbed as the pairs estimator.By applying the same IPW estimator to both the model and true experimentaleffects, our estimator effectively cancels out the variance due to IPW andachieves a smaller asymptotic variance. Empirical studies demonstrate theimproved of our estimator, highlighting its potential on achieving near-RCTperformance. Our method offers a simple yet powerful solution to evaluatecausal inference models in conditional randomization settings withoutcomplicated modification of the IPW estimator itself, paving the way for morerobust and reliable model assessments.</description><author>Chao Ma, Cheng Zhang</author><pubDate>Fri, 03 Nov 2023 14:22:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01902v1</guid></item><item><title>Numerical influence of ReLU'(0) on backpropagation</title><link>http://arxiv.org/abs/2106.12915v4</link><description>In theory, the choice of ReLU(0) in [0, 1] for a neural network has anegligible influence both on backpropagation and training. Yet, in the realworld, 32 bits default precision combined with the size of deep learningproblems makes it a hyperparameter of training methods. We investigate theimportance of the value of ReLU'(0) for several precision levels (16, 32, 64bits), on various networks (fully connected, VGG, ResNet) and datasets (MNIST,CIFAR10, SVHN, ImageNet). We observe considerable variations of backpropagationoutputs which occur around half of the time in 32 bits precision. The effectdisappears with double precision, while it is systematic at 16 bits. Forvanilla SGD training, the choice ReLU'(0) = 0 seems to be the most efficient.For our experiments on ImageNet the gain in test accuracy over ReLU'(0) = 1 wasmore than 10 points (two runs). We also evidence that reconditioning approachesas batch-norm or ADAM tend to buffer the influence of ReLU'(0)'s value.Overall, the message we convey is that algorithmic differentiation of nonsmoothproblems potentially hides parameters that could be tuned advantageously.</description><author>David Bertoin, Jérôme Bolte, Sébastien Gerchinovitz, Edouard Pauwels</author><pubDate>Fri, 03 Nov 2023 14:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.12915v4</guid></item><item><title>Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization</title><link>http://arxiv.org/abs/2311.01900v1</link><description>Quantifying the difference between two probability density functions, $p$ and$q$, using available data, is a fundamental problem in Statistics and MachineLearning. A usual approach for addressing this problem is the likelihood-ratioestimation (LRE) between $p$ and $q$, which -- to our best knowledge -- hasbeen investigated mainly for the offline case. This paper contributes byintroducing a new framework for online non-parametric LRE (OLRE) for thesetting where pairs of iid observations $(x_t \sim p, x'_t \sim q)$ areobserved over time. The non-parametric nature of our approach has the advantageof being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on therecent advances in Kernel Methods and functional minimization to develop anestimator that can be efficiently updated online. We provide theoreticalguarantees for the performance of the OLRE method along with empiricalvalidation in synthetic experiments.</description><author>Alejandro de la Concha, Nicolas Vayatis, Argyris Kalogeratos</author><pubDate>Fri, 03 Nov 2023 14:20:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01900v1</guid></item><item><title>A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement</title><link>http://arxiv.org/abs/2301.08880v3</link><description>Film, a classic image style, is culturally significant to the wholephotographic industry since it marks the birth of photography. However, filmphotography is time-consuming and expensive, necessitating a more efficientmethod for collecting film-style photographs. Numerous datasets that haveemerged in the field of image enhancement so far are not film-specific. Inorder to facilitate film-based image stylization research, we constructFilmSet, a large-scale and high-quality film style dataset. Our datasetincludes three different film types and more than 5000 in-the-wild highresolution images. Inspired by the features of FilmSet images, we propose anovel framework called FilmNet based on Laplacian Pyramid for stylizing imagesacross frequency bands and achieving film style outcomes. Experiments revealthat the performance of our model is superior than state-of-the-art techniques.The link of code and data is \url{https://github.com/CXH-Research/FilmNet}.</description><author>Zinuo Li, Xuhang Chen, Shuqiang Wang, Chi-Man Pun</author><pubDate>Fri, 03 Nov 2023 14:18:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08880v3</guid></item><item><title>Improving Interpersonal Communication by Simulating Audiences with Language Models</title><link>http://arxiv.org/abs/2311.00687v2</link><description>How do we communicate with others to achieve our goals? We use our priorexperience or advice from others, or construct a candidate utterance bypredicting how it will be received. However, our experiences are limited andbiased, and reasoning about potential outcomes can be difficult and cognitivelychallenging. In this paper, we explore how we can leverage Large Language Model(LLM) simulations to help us communicate better. We propose theExplore-Generate-Simulate (EGS) framework, which takes as input any scenariowhere an individual is communicating to an audience with a goal they want toachieve. EGS (1) explores the solution space by producing a diverse set ofadvice relevant to the scenario, (2) generates communication candidatesconditioned on subsets of the advice, and (3) simulates the reactions fromvarious audiences to determine both the best candidate and advice to use. Weevaluate the framework on eight scenarios spanning the ten fundamentalprocesses of interpersonal communication. For each scenario, we collect adataset of human evaluations across candidates and baselines, and showcase thatour framework's chosen candidate is preferred over popular generationmechanisms including Chain-of-Thought. We also find that audience simulationsachieve reasonably high agreement with human raters across 5 of the 8scenarios. Finally, we demonstrate the generality of our framework by applyingit to real-world scenarios described by users on web forums. Throughevaluations and demonstrations, we show that EGS enhances the effectiveness andoutcomes of goal-oriented communication across a variety of situations, thusopening up new possibilities for the application of large language models inrevolutionizing communication and decision-making processes.</description><author>Ryan Liu, Howard Yen, Raja Marjieh, Thomas L. Griffiths, Ranjay Krishna</author><pubDate>Fri, 03 Nov 2023 14:17:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00687v2</guid></item><item><title>3D Multiple Object Tracking on Autonomous Driving: A Literature Review</title><link>http://arxiv.org/abs/2309.15411v3</link><description>3D multi-object tracking (3D MOT) stands as a pivotal domain withinautonomous driving, experiencing a surge in scholarly interest and commercialpromise over recent years. Despite its paramount significance, 3D MOT confrontsa myriad of formidable challenges, encompassing abrupt alterations in objectappearances, pervasive occlusion, the presence of diminutive targets, datasparsity, missed detections, and the unpredictable initiation and terminationof object motion trajectories. Countless methodologies have emerged to grapplewith these issues, yet 3D MOT endures as a formidable problem that warrantsfurther exploration. This paper undertakes a comprehensive examination,assessment, and synthesis of the research landscape in this domain, remainingattuned to the latest developments in 3D MOT while suggesting prospectiveavenues for future investigation. Our exploration commences with a systematicexposition of key facets of 3D MOT and its associated domains, includingproblem delineation, classification, methodological approaches, fundamentalprinciples, and empirical investigations. Subsequently, we categorize thesemethodologies into distinct groups, dissecting each group meticulously withregard to its challenges, underlying rationale, progress, merits, and demerits.Furthermore, we present a concise recapitulation of experimental metrics andoffer an overview of prevalent datasets, facilitating a quantitative comparisonfor a more intuitive assessment. Lastly, our deliberations culminate in adiscussion of the prevailing research landscape, highlighting extant challengesand charting possible directions for 3D MOT research. We present a structuredand lucid road-map to guide forthcoming endeavors in this field.</description><author>Peng Zhang, Xin Li, Liang He, Xin Lin</author><pubDate>Fri, 03 Nov 2023 14:15:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15411v3</guid></item><item><title>Simulation of acquisition shifts in T2 Flair MR images to stress test AI segmentation networks</title><link>http://arxiv.org/abs/2311.01894v1</link><description>Purpose: To provide a simulation framework for routine neuroimaging testdata, which allows for "stress testing" of deep segmentation networks againstacquisition shifts that commonly occur in clinical practice for T2 weighted(T2w) fluid attenuated inversion recovery (FLAIR) Magnetic Resonance Imaging(MRI) protocols. Approach: The approach simulates "acquisition shift derivatives" of MR imagesbased on MR signal equations. Experiments comprise the validation of thesimulated images by real MR scans and example stress tests on state-of-the-artMS lesion segmentation networks to explore a generic model function to describethe F1 score in dependence of the contrast-affecting sequence parameters echotime (TE) and inversion time (TI). Results: The differences between real and simulated images range up to 19 %in gray and white matter for extreme parameter settings. For the segmentationnetworks under test the F1 score dependency on TE and TI can be well describedby quadratic model functions (R^2 &gt; 0.9). The coefficients of the modelfunctions indicate that changes of TE have more influence on the modelperformance than TI. Conclusions: We show that these deviations are in the range of values as maybe caused by erroneous or individual differences of relaxation times asdescribed by literature. The coefficients of the F1 model function allow forquantitative comparison of the influences of TE and TI. Limitations arisemainly from tissues with the low baseline signal (like CSF) and when theprotocol contains contrast-affecting measures that cannot be modelled due tomissing information in the DICOM header.</description><author>Christiane Posselt, Mehmet Yigit Avci, Mehmet Yigitsoy, Patrick Schünke, Christoph Kolbitsch, Tobias Schäffter, Stefanie Remmele</author><pubDate>Fri, 03 Nov 2023 14:10:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01894v1</guid></item></channel></rss>