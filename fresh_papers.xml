<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 11 Jan 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Towards Online Sign Language Recognition and Translation</title><link>http://arxiv.org/abs/2401.05336v1</link><description>The objective of sign language recognition is to bridge the communication gapbetween the deaf and the hearing. Numerous previous works train their modelsusing the well-established connectionist temporal classification (CTC) loss.During the inference stage, the CTC-based models typically take the entire signvideo as input to make predictions. This type of inference scheme is referredto as offline recognition. In contrast, while mature speech recognition systemscan efficiently recognize spoken words on the fly, sign language recognitionstill falls short due to the lack of practical online solutions. In this work,we take the first step towards filling this gap. Our approach comprises threephases: 1) developing a sign language dictionary encompassing all glossespresent in a target sign language dataset; 2) training an isolated signlanguage recognition model on augmented signs using both conventionalclassification loss and our novel saliency loss; 3) employing a sliding windowapproach on the input sign sequence and feeding each sign clip to thewell-optimized model for online recognition. Furthermore, our onlinerecognition model can be extended to boost the performance of any offlinemodel, and to support online translation by appending a gloss-to-text networkonto the recognition model. By integrating our online framework with thepreviously best-performing offline model, TwoStream-SLR, we achieve newstate-of-the-art performance on three benchmarks: Phoenix-2014, Phoenix-2014T,and CSL-Daily. Code and models will be available athttps://github.com/FangyunWei/SLRT</description><author>Ronglai Zuo, Fangyun Wei, Brian Mak</author><pubDate>Wed, 10 Jan 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05336v1</guid></item><item><title>InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes</title><link>http://arxiv.org/abs/2401.05335v1</link><description>We introduce InseRF, a novel method for generative object insertion in theNeRF reconstructions of 3D scenes. Based on a user-provided textual descriptionand a 2D bounding box in a reference viewpoint, InseRF generates new objects in3D scenes. Recently, methods for 3D scene editing have been profoundlytransformed, owing to the use of strong priors of text-to-image diffusionmodels in 3D generative modeling. Existing methods are mostly effective inediting 3D scenes via style and appearance changes or removing existingobjects. Generating new objects, however, remains a challenge for such methods,which we address in this study. Specifically, we propose grounding the 3Dobject insertion to a 2D object insertion in a reference view of the scene. The2D edit is then lifted to 3D using a single-view object reconstruction method.The reconstructed object is then inserted into the scene, guided by the priorsof monocular depth estimation methods. We evaluate our method on various 3Dscenes and provide an in-depth analysis of the proposed components. Ourexperiments with generative insertion of objects in several 3D scenes indicatethe effectiveness of our method compared to the existing methods. InseRF iscapable of controllable and 3D-consistent object insertion without requiringexplicit 3D information as input. Please visit our project page athttps://mohamad-shahbazi.github.io/inserf.</description><author>Mohamad Shahbazi, Liesbeth Claessens, Michael Niemeyer, Edo Collins, Alessio Tonioni, Luc Van Gool, Federico Tombari</author><pubDate>Wed, 10 Jan 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05335v1</guid></item><item><title>URHand: Universal Relightable Hands</title><link>http://arxiv.org/abs/2401.05334v1</link><description>Existing photorealistic relightable hand models require extensiveidentity-specific observations in different views, poses, and illuminations,and face challenges in generalizing to natural illuminations and novelidentities. To bridge this gap, we present URHand, the first universalrelightable hand model that generalizes across viewpoints, poses,illuminations, and identities. Our model allows few-shot personalization usingimages captured with a mobile phone, and is ready to be photorealisticallyrendered under novel illuminations. To simplify the personalization processwhile retaining photorealism, we build a powerful universal relightable priorbased on neural relighting from multi-view images of hands captured in a lightstage with hundreds of identities. The key challenge is scaling thecross-identity training while maintaining personalized fidelity and sharpdetails without compromising generalization under natural illuminations. Tothis end, we propose a spatially varying linear lighting model as the neuralrenderer that takes physics-inspired shading as input feature. By removingnon-linear activations and bias, our specifically designed lighting modelexplicitly keeps the linearity of light transport. This enables single-stagetraining from light-stage data while generalizing to real-time rendering underarbitrary continuous illuminations across diverse identities. In addition, weintroduce the joint learning of a physically based model and our neuralrelighting model, which further improves fidelity and generalization. Extensiveexperiments show that our approach achieves superior performance over existingmethods in terms of both quality and generalizability. We also demonstratequick personalization of URHand from a short phone scan of an unseen identity.</description><author>Zhaoxi Chen, Gyeongsik Moon, Kaiwen Guo, Chen Cao, Stanislav Pidhorskyi, Tomas Simon, Rohan Joshi, Yuan Dong, Yichen Xu, Bernardo Pires, He Wen, Lucas Evans, Bo Peng, Julia Buffalini, Autumn Trimble, Kevyn McPhail, Melissa Schoeller, Shoou-I Yu, Javier Romero, Michael Zollh√∂fer, Yaser Sheikh, Ziwei Liu, Shunsuke Saito</author><pubDate>Wed, 10 Jan 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05334v1</guid></item><item><title>KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models</title><link>http://arxiv.org/abs/2310.15872v2</link><description>In this paper, we exploit a fundamental principle of analog electroniccircuitry, Kirchhoff's current law, to introduce a unique class of neuralnetwork models that we refer to as KirchhoffNet. KirchhoffNet establishes closeconnections with message passing neural networks and continuous-depth networks.We demonstrate that even in the absence of any traditional layers (such asconvolution, pooling, or linear layers), KirchhoffNet attains 98.86% testaccuracy on the MNIST dataset, comparable with state of the art (SOTA) results.What makes KirchhoffNet more intriguing is its potential in the realm ofhardware. Contemporary deep neural networks are conventionally deployed onGPUs. In contrast, KirchhoffNet can be physically realized by an analogelectronic circuit. Moreover, we justify that irrespective of the number ofparameters within a KirchhoffNet, its forward calculation can always becompleted within 1/f seconds, with f representing the hardware's clockfrequency. This characteristic introduces a promising technology forimplementing ultra-large-scale neural networks.</description><author>Zhengqi Gao, Fan-Keng Sun, Duane S. Boning</author><pubDate>Wed, 10 Jan 2024 18:59:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15872v2</guid></item><item><title>Hierarchical Causal Models</title><link>http://arxiv.org/abs/2401.05330v1</link><description>Scientists often want to learn about cause and effect from hierarchical data,collected from subunits nested inside units. Consider students in schools,cells in patients, or cities in states. In such settings, unit-level variables(e.g. each school's budget) may affect subunit-level variables (e.g. the testscores of each student in each school) and vice versa. To address causalquestions with hierarchical data, we propose hierarchical causal models, whichextend structural causal models and causal graphical models by adding innerplates. We develop a general graphical identification technique forhierarchical causal models that extends do-calculus. We find many situations inwhich hierarchical data can enable causal identification even when it would beimpossible with non-hierarchical data, that is, if we had only unit-levelsummaries of subunit-level variables (e.g. the school's average test score,rather than each student's score). We develop estimation techniques forhierarchical causal models, using methods including hierarchical Bayesianmodels. We illustrate our results in simulation and via a reanalysis of theclassic "eight schools" study.</description><author>Eli N. Weinstein, David M. Blei</author><pubDate>Wed, 10 Jan 2024 18:56:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05330v1</guid></item><item><title>Arrival Time Prediction for Autonomous Shuttle Services in the Real World: Evidence from Five Cities</title><link>http://arxiv.org/abs/2401.05322v1</link><description>Urban mobility is on the cusp of transformation with the emergence of shared,connected, and cooperative automated vehicles. Yet, for them to be accepted bycustomers, trust in their punctuality is vital. Many pilot initiatives operatewithout a fixed schedule, thus enhancing the importance of reliable arrivaltime (AT) predictions. This study presents an AT prediction system forautonomous shuttles, utilizing separate models for dwell and running timepredictions, validated on real-world data from five cities. Alongsideestablished methods such as XGBoost, we explore the benefits of integratingspatial data using graph neural networks (GNN). To accurately handle the caseof a shuttle bypassing a stop, we propose a hierarchical model combining arandom forest classifier and a GNN. The results for the final AT prediction arepromising, showing low errors even when predicting several stops ahead. Yet, nosingle model emerges as universally superior, and we provide insights into thecharacteristics of pilot sites that influence the model selection process.Finally, we identify dwell time prediction as the key determinant in overall ATprediction accuracy when autonomous shuttles are deployed in low-traffic areasor under regulatory speed limits. This research provides insights into thecurrent state of autonomous public transport prediction models and paves theway for more data-informed decision-making as the field advances.</description><author>Carolin Schmidt, Mathias Tygesen, Filipe Rodrigues</author><pubDate>Wed, 10 Jan 2024 18:41:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05322v1</guid></item><item><title>Leveraging Print Debugging to Improve Code Generation in Large Language Models</title><link>http://arxiv.org/abs/2401.05319v1</link><description>Large language models (LLMs) have made significant progress in codegeneration tasks, but their performance in tackling programming problems withcomplex data structures and algorithms remains suboptimal. To address thisissue, we propose an in-context learning approach that guides LLMs to debug byusing a "print debugging" method, which involves inserting print statements totrace and analysing logs for fixing the bug. We collect a Leetcode problemdataset and evaluate our method using the Leetcode online judging system.Experiments with GPT-4 demonstrate the effectiveness of our approach,outperforming rubber duck debugging in easy and medium-level Leetcode problemsby 1.5% and 17.9%.</description><author>Xueyu Hu, Kun Kuang, Jiankai Sun, Hongxia Yang, Fei Wu</author><pubDate>Wed, 10 Jan 2024 18:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05319v1</guid></item><item><title>FedZero: Leveraging Renewable Excess Energy in Federated Learning</title><link>http://arxiv.org/abs/2305.15092v3</link><description>Federated Learning (FL) is an emerging machine learning technique thatenables distributed model training across data silos or edge devices withoutdata sharing. Yet, FL inevitably introduces inefficiencies compared tocentralized model training, which will further increase the already high energyusage and associated carbon emissions of machine learning in the future. Oneidea to reduce FL's carbon footprint is to schedule training jobs based on theavailability of renewable excess energy that can occur at certain times andplaces in the grid. However, in the presence of such volatile and unreliableresources, existing FL schedulers cannot always ensure fast, efficient, andfair training. We propose FedZero, an FL system that operates exclusively on renewableexcess energy and spare capacity of compute infrastructure to effectivelyreduce a training's operational carbon emissions to zero. Using energy and loadforecasts, FedZero leverages the spatio-temporal availability of excessresources by selecting clients for fast convergence and fair participation. Ourevaluation, based on real solar and load traces, shows that FedZero convergessignificantly faster than existing approaches under the mentioned constraintswhile consuming less energy. Furthermore, it is robust to forecasting errorsand scalable to tens of thousands of clients.</description><author>Philipp Wiesner, Ramin Khalili, Dennis Grinwald, Pratik Agrawal, Lauritz Thamsen, Odej Kao</author><pubDate>Wed, 10 Jan 2024 18:37:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15092v3</guid></item><item><title>ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video</title><link>http://arxiv.org/abs/2401.05314v1</link><description>The Internet's wealth of content, with up to 60% published in English,starkly contrasts the global population, where only 18.8% are English speakers,and just 5.1% consider it their native language, leading to disparities inonline information access. Unfortunately, automated processes for dubbing ofvideo - replacing the audio track of a video with a translated alternative -remains a complex and challenging task due to pipelines, necessitating precisetiming, facial movement synchronization, and prosody matching. While end-to-enddubbing offers a solution, data scarcity continues to impede the progress ofboth end-to-end and pipeline-based methods. In this work, we introduceAnim-400K, a comprehensive dataset of over 425K aligned animated video segmentsin Japanese and English supporting various video-related tasks, includingautomated dubbing, simultaneous translation, guided video summarization, andgenre/theme/style classification. Our dataset is made publicly available forresearch purposes at https://github.com/davidmchan/Anim400K.</description><author>Kevin Cai, Chonghua Liu, David M. Chan</author><pubDate>Wed, 10 Jan 2024 18:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05314v1</guid></item><item><title>Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL Networks</title><link>http://arxiv.org/abs/2401.05308v1</link><description>The deployment of federated learning (FL) within vertical heterogeneousnetworks, such as those enabled by high-altitude platform station (HAPS),offers the opportunity to engage a wide array of clients, each endowed withdistinct communication and computational capabilities. This diversity not onlyenhances the training accuracy of FL models but also hastens their convergence.Yet, applying FL in these expansive networks presents notable challenges,particularly the significant non-IIDness in client data distributions. Suchdata heterogeneity often results in slower convergence rates and reducedeffectiveness in model training performance. Our study introduces a clientselection strategy tailored to address this issue, leveraging user networktraffic behaviour. This strategy involves the prediction and classification ofclients based on their network usage patterns while prioritizing user privacy.By strategically selecting clients whose data exhibit similar patterns forparticipation in FL training, our approach fosters a more uniform andrepresentative data distribution across the network. Our simulationsdemonstrate that this targeted client selection methodology significantlyreduces the training loss of FL models in HAPS networks, thereby effectivelytackling a crucial challenge in implementing large-scale FL systems.</description><author>Amin Farajzadeh, Animesh Yadav, Halim Yanikomeroglu</author><pubDate>Wed, 10 Jan 2024 18:22:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05308v1</guid></item><item><title>Can Probabilistic Feedback Drive User Impacts in Online Platforms?</title><link>http://arxiv.org/abs/2401.05304v1</link><description>A common explanation for negative user impacts of content recommender systemsis misalignment between the platform's objective and user welfare. In thiswork, we show that misalignment in the platform's objective is not the onlypotential cause of unintended impacts on users: even when the platform'sobjective is fully aligned with user welfare, the platform's learning algorithmcan induce negative downstream impacts on users. The source of these userimpacts is that different pieces of content may generate observable userreactions (feedback information) at different rates; these feedback rates maycorrelate with content properties, such as controversiality or demographicsimilarity of the creator, that affect the user experience. Since differencesin feedback rates can impact how often the learning algorithm engages withdifferent content, the learning algorithm may inadvertently promote contentwith certain such properties. Using the multi-armed bandit framework withprobabilistic feedback, we examine the relationship between feedback rates anda learning algorithm's engagement with individual arms for different no-regretalgorithms. We prove that no-regret algorithms can exhibit a wide range ofdependencies: if the feedback rate of an arm increases, some no-regretalgorithms engage with the arm more, some no-regret algorithms engage with thearm less, and other no-regret algorithms engage with the arm approximately thesame number of times. From a platform design perspective, our results highlightthe importance of looking beyond regret when measuring an algorithm'sperformance, and assessing the nature of a learning algorithm's engagement withdifferent types of content as well as their resulting downstream impacts.</description><author>Jessica Dai, Bailey Flanigan, Nika Haghtalab, Meena Jagadeesan, Chara Podimata</author><pubDate>Wed, 10 Jan 2024 18:12:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05304v1</guid></item><item><title>Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?</title><link>http://arxiv.org/abs/2401.05302v1</link><description>Large Language Models have shown exceptional generative abilities in variousnatural language and generation tasks. However, possible anthropomorphizationand leniency towards failure cases have propelled discussions on emergentabilities of Large Language Models especially on Theory of Mind (ToM) abilitiesin Large Language Models. While several false-belief tests exists to verify theability to infer and maintain mental models of another entity, we study aspecial application of ToM abilities that has higher stakes and possiblyirreversible consequences : Human Robot Interaction. In this work, we explorethe task of Perceived Behavior Recognition, where a robot employs a LargeLanguage Model (LLM) to assess the robot's generated behavior in a mannersimilar to human observer. We focus on four behavior types, namely -explicable, legible, predictable, and obfuscatory behavior which have beenextensively used to synthesize interpretable robot behaviors. The LLMs goal is,therefore to be a human proxy to the agent, and to answer how a certain agentbehavior would be perceived by the human in the loop, for example "Given arobot's behavior X, would the human observer find it explicable?". We conduct ahuman subject study to verify that the users are able to correctly answer sucha question in the curated situations (robot setting and plan) across fivedomains. A first analysis of the belief test yields extremely positive resultsinflating ones expectations of LLMs possessing ToM abilities. We then proposeand perform a suite of perturbation tests which breaks this illusion, i.e.Inconsistent Belief, Uninformative Context and Conviction Test. We concludethat, the high score of LLMs on vanilla prompts showcases its potential use inHRI settings, however to possess ToM demands invariance to trivial orirrelevant perturbations in the context which LLMs lack.</description><author>Mudit Verma, Siddhant Bhambri, Subbarao Kambhampati</author><pubDate>Wed, 10 Jan 2024 18:09:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05302v1</guid></item><item><title>I am a Strange Dataset: Metalinguistic Tests for Language Models</title><link>http://arxiv.org/abs/2401.05300v1</link><description>Statements involving metalinguistic self-reference ("This paper has sixsections.") are prevalent in many domains. Can large language models (LLMs)handle such language? In this paper, we present "I am a Strange Dataset", a newdataset for addressing this question. There are two subtasks: generation andverification. In generation, models continue statements like "The penultimateword in this sentence is" (where a correct continuation is "is"). Inverification, models judge the truth of statements like "The penultimate wordin this sentence is sentence." (false). We also provide minimally differentmetalinguistic non-self-reference examples to complement the main dataset byprobing for whether models can handle metalinguistic language at all. Thedataset is hand-crafted by experts and validated by non-expert annotators. Wetest a variety of open-source LLMs (7B to 70B parameters) as well asclosed-source LLMs through APIs. All models perform close to chance across bothsubtasks and even on the non-self-referential metalinguistic control data,though we find some steady improvement with model scale. GPT 4 is the onlymodel to consistently do significantly better than chance, and it is still onlyin the 60% range, while our untrained human annotators score well in the 89-93%range. The dataset and evaluation toolkit are available athttps://github.com/TristanThrush/i-am-a-strange-dataset.</description><author>Tristan Thrush, Jared Moore, Miguel Monares, Christopher Potts, Douwe Kiela</author><pubDate>Wed, 10 Jan 2024 18:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05300v1</guid></item><item><title>Memory-adaptive Depth-wise Heterogenous Federated Learning</title><link>http://arxiv.org/abs/2303.04887v2</link><description>Federated learning is a promising paradigm that allows multiple clients tocollaboratively train a model without sharing the local data. However, thepresence of heterogeneous devices in federated learning, such as mobile phonesand IoT devices with varying memory capabilities, would limit the scale andhence the performance of the model could be trained. The mainstream approachesto address memory limitations focus on width-slimming techniques, wheredifferent clients train subnetworks with reduced widths locally and then theserver aggregates the subnetworks. The global model produced from these methodssuffers from performance degradation due to the negative impact of the actionstaken to handle the varying subnetwork widths in the aggregation phase. In thispaper, we introduce a memory-adaptive depth-wise learning solution in FL calledFeDepth, which adaptively decomposes the full model into blocks according tothe memory budgets of each client and trains blocks sequentially to obtain afull inference model. Our method outperforms state-of-the-art approaches,achieving 5% and more than 10% improvements in top-1 accuracy on CIFAR-10 andCIFAR-100, respectively. We also demonstrate the effectiveness of depth-wisefine-tuning on ViT. Our findings highlight the importance of memory-awaretechniques for federated learning with heterogeneous devices and the success ofdepth-wise training strategy in improving the global model's performance.</description><author>Kai Zhang, Yutong Dai, Hongyi Wang, Eric Xing, Xun Chen, Lichao Sun</author><pubDate>Wed, 10 Jan 2024 18:03:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04887v2</guid></item><item><title>Synthesis of pulses from particle detectors with a Generative Adversarial Network (GAN)</title><link>http://arxiv.org/abs/2401.05295v1</link><description>To address the possible lack or total absence of pulses from particledetectors during the development of its associate electronics, we propose amodel that can generate them without losing the features of the real ones. Thismodel is based on artificial neural networks, namely Generative AdversarialNetworks (GAN). We describe the proposed network architecture, its trainingmethodology and the approach to train the GAN with real pulses from ascintillator receiving radiation from sources of ${}^{137}$Cs and ${}^{22}$Na.The Generator was installed in a Xilinx's System-On-Chip (SoC). We show how thenetwork is capable of generating pulses with the same shape as the real onesthat even match the data distributions in the original pulse-height histogramdata.</description><author>Alberto Regad√≠o, Luis Esteban, Sebasti√°n S√°nchez-Prieto</author><pubDate>Wed, 10 Jan 2024 17:54:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05295v1</guid></item><item><title>Enhanced Muscle and Fat Segmentation for CT-Based Body Composition Analysis: A Comparative Study</title><link>http://arxiv.org/abs/2401.05294v1</link><description>Purpose: Body composition measurements from routine abdominal CT can yieldpersonalized risk assessments for asymptomatic and diseased patients. Inparticular, attenuation and volume measures of muscle and fat are associatedwith important clinical outcomes, such as cardiovascular events, fractures, anddeath. This study evaluates the reliability of an Internal tool for thesegmentation of muscle and fat (subcutaneous and visceral) as compared to thewell-established public TotalSegmentator tool. Methods: We assessed the tools across 900 CT series from the publiclyavailable SAROS dataset, focusing on muscle, subcutaneous fat, and visceralfat. The Dice score was employed to assess accuracy in subcutaneous fat andmuscle segmentation. Due to the lack of ground truth segmentations for visceralfat, Cohen's Kappa was utilized to assess segmentation agreement between thetools. Results: Our Internal tool achieved a 3% higher Dice (83.8 vs. 80.8) forsubcutaneous fat and a 5% improvement (87.6 vs. 83.2) for muscle segmentationrespectively. A Wilcoxon signed-rank test revealed that our results werestatistically different with p&lt;0.01. For visceral fat, the Cohen's kappa scoreof 0.856 indicated near-perfect agreement between the two tools. Our internaltool also showed very strong correlations for muscle volume (R^2=0.99), muscleattenuation (R^2=0.93), and subcutaneous fat volume (R^2=0.99) with a moderatecorrelation for subcutaneous fat attenuation (R^2=0.45). Conclusion: Our findings indicated that our Internal tool outperformedTotalSegmentator in measuring subcutaneous fat and muscle. The high Cohen'sKappa score for visceral fat suggests a reliable level of agreement between thetwo tools. These results demonstrate the potential of our tool in advancing theaccuracy of body composition analysis.</description><author>Benjamin Hou, Tejas Sudharshan Mathai, Jianfei Liu, Christopher Parnell, Ronald M. Summers</author><pubDate>Wed, 10 Jan 2024 17:53:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05294v1</guid></item><item><title>Score Distillation Sampling with Learned Manifold Corrective</title><link>http://arxiv.org/abs/2401.05293v1</link><description>Score Distillation Sampling (SDS) is a recent but already widely popularmethod that relies on an image diffusion model to control optimization problemsusing text prompts. In this paper, we conduct an in-depth analysis of the SDSloss function, identify an inherent problem with its formulation, and propose asurprisingly easy but effective fix. Specifically, we decompose the loss intodifferent factors and isolate the component responsible for noisy gradients. Inthe original formulation, high text guidance is used to account for the noise,leading to unwanted side effects. Instead, we train a shallow network mimickingthe timestep-dependent denoising deficiency of the image diffusion model inorder to effectively factor it out. We demonstrate the versatility and theeffectiveness of our novel loss formulation through several qualitative andquantitative experiments, including optimization-based image synthesis andediting, zero-shot image translation network training, and text-to-3Dsynthesis.</description><author>Thiemo Alldieck, Nikos Kolotouros, Cristian Sminchisescu</author><pubDate>Wed, 10 Jan 2024 17:51:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05293v1</guid></item><item><title>A Reinforcement Learning Approach to Sensing Design in Resource-Constrained Wireless Networked Control Systems</title><link>http://arxiv.org/abs/2204.00703v5</link><description>In this paper, we consider a wireless network of smart sensors (agents) thatmonitor a dynamical process and send measurements to a base station thatperforms global monitoring and decision-making. Smart sensors are equipped withboth sensing and computation, and can either send raw measurements or processthem prior to transmission. Constrained agent resources raise a fundamentallatency-accuracy trade-off. On the one hand, raw measurements are inaccuratebut fast to produce. On the other hand, data processing on resource-constrainedplatforms generates accurate measurements at the cost of non-negligiblecomputation latency. Further, if processed data are also compressed, latencycaused by wireless communication might be higher for raw measurements. Hence,it is challenging to decide when and where sensors in the network shouldtransmit raw measurements or leverage time-consuming local processing. Totackle this design problem, we propose a Reinforcement Learning approach tolearn an efficient policy that dynamically decides when measurements are to beprocessed at each sensor. Effectiveness of our proposed approach is validatedthrough a numerical simulation with case study on smart sensing motivated bythe Internet of Drones.</description><author>Luca Ballotta, Giovanni Peserico, Francesco Zanini</author><pubDate>Wed, 10 Jan 2024 17:50:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.00703v5</guid></item><item><title>Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking</title><link>http://arxiv.org/abs/2306.12245v3</link><description>Entity Linking (EL) is a fundamental task for Information Extraction andKnowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to firstfind mentions in the given input document and then link the mentions tocorresponding entities in a specific knowledge base. Recently, the paradigm ofretriever-reader promotes the progress of end-to-end EL, benefiting from theadvantages of dense entity retrieval and machine reading comprehension.However, the existing study only trains the retriever and the reader separatelyin a pipeline manner, which ignores the benefit that the interaction betweenthe retriever and the reader can bring to the task. To advance theretriever-reader paradigm to perform more perfectly on end-to-end EL, wepropose BEER$^2$, a Bidirectional End-to-End training framework for Retrieverand Reader. Through our designed bidirectional end-to-end training, BEER$^2$guides the retriever and the reader to learn from each other, make progresstogether, and ultimately improve EL performance. Extensive experiments onbenchmarks of multiple domains demonstrate the effectiveness of our proposedBEER$^2$.</description><author>Yinghui Li, Yong Jiang, Shen Huang, Xingyu Lu, Yangning Li, Pengjun Xie, Fei Huang, Hai-Tao Zheng, Ying Shen</author><pubDate>Wed, 10 Jan 2024 17:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12245v3</guid></item><item><title>Cheetah: Natural Language Generation for 517 African Languages</title><link>http://arxiv.org/abs/2401.01053v3</link><description>Low-resource African languages pose unique challenges for natural languageprocessing (NLP) tasks, including natural language generation (NLG). In thispaper, we develop Cheetah, a massively multilingual NLG language model forAfrican languages. Cheetah supports 517 African languages and languagevarieties, allowing us to address the scarcity of NLG resources and provide asolution to foster linguistic diversity. We demonstrate the effectiveness ofCheetah through comprehensive evaluations across six generation downstreamtasks. In five of the six tasks, Cheetah significantly outperforms othermodels, showcasing its remarkable performance for generating coherent andcontextually appropriate text in a wide range of African languages. Weadditionally conduct a detailed human evaluation to delve deeper into thelinguistic capabilities of Cheetah. The introduction of Cheetah hasfar-reaching benefits for linguistic diversity. By leveraging pretrained modelsand adapting them to specific languages, our approach facilitates thedevelopment of practical NLG applications for African communities. The findingsof this study contribute to advancing NLP research in low-resource settings,enabling greater accessibility and inclusion for African languages in a rapidlyexpanding digital landscape. We publicly release our models for research.</description><author>Ife Adebara, AbdelRahim Elmadany, Muhammad Abdul-Mageed</author><pubDate>Wed, 10 Jan 2024 17:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01053v3</guid></item><item><title>INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges</title><link>http://arxiv.org/abs/2401.05273v1</link><description>This paper introduces INACIA (Instru\c{c}\~ao Assistida com Intelig\^enciaArtificial), a groundbreaking system designed to integrate Large LanguageModels (LLMs) into the operational framework of Brazilian Federal Court ofAccounts (TCU). The system automates various stages of case analysis, includingbasic information extraction, admissibility examination, Periculum in mora andFumus boni iuris analyses, and recommendations generation. Through a series ofexperiments, we demonstrate INACIA's potential in extracting relevantinformation from case documents, evaluating its legal plausibility, andgenerating judicial recommendations. Utilizing a validation dataset alongsideLLMs, our evaluation methodology presents an innovative approach to assessingsystem performance, correlating highly with human judgment. The resultshighlight INACIA's proficiency in handling complex legal tasks, indicating itssuitability for augmenting efficiency and judicial fairness within legalsystems. The paper also discusses potential enhancements and futureapplications, positioning INACIA as a model for worldwide AI integration inlegal domains.</description><author>Jayr Pereira, Andre Assumpcao, Julio Trecenti, Luiz Airosa, Caio Lente, Jhonatan Cl√©to, Guilherme Dobins, Rodrigo Nogueira, Luis Mitchell, Roberto Lotufo</author><pubDate>Wed, 10 Jan 2024 17:13:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05273v1</guid></item><item><title>SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly</title><link>http://arxiv.org/abs/2305.12520v2</link><description>Decompilation is a well-studied area with numerous high-quality toolsavailable. These are frequently used for security tasks and to port legacycode. However, they regularly generate difficult-to-read programs and require alarge amount of engineering effort to support new programming languages andISAs. Recent interest in neural approaches has produced portable tools thatgenerate readable code. However, to-date such techniques are usually restrictedto synthetic programs without optimization, and no models have evaluated theirportability. Furthermore, while the code generated may be more readable, it isusually incorrect. This paper presents SLaDe, a Small Language model Decompilerbased on a sequence-to-sequence transformer trained over real-world code. Wedevelop a novel tokenizer and exploit no-dropout training to producehigh-quality code. We utilize type-inference to generate programs that are morereadable and accurate than standard analytic and recent neural approaches.Unlike standard approaches, SLaDe can infer out-of-context types and unlikeneural approaches, it generates correct code. We evaluate SLaDe on over 4,000functions from AnghaBench on two ISAs and at two optimizations levels. SLaDe isup to 6 times more accurate than Ghidra, a state-of-the-art,industrial-strength decompiler and up to 4 times more accurate than the largelanguage model ChatGPT and generates significantly more readable code thanboth.</description><author>Jordi Armengol-Estap√©, Jackson Woodruff, Chris Cummins, Michael F. P. O'Boyle</author><pubDate>Wed, 10 Jan 2024 17:12:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12520v2</guid></item><item><title>Improving Automatic VQA Evaluation Using Large Language Models</title><link>http://arxiv.org/abs/2310.02567v2</link><description>8 years after the visual question answering (VQA) task was proposed, accuracyremains the primary metric for automatic evaluation. VQA Accuracy has beeneffective so far in the IID evaluation setting. However, our community isundergoing a shift towards open-ended generative models and OOD evaluation. Inthis new paradigm, the existing VQA Accuracy metric is overly stringent andunderestimates the performance of VQA systems. Thus, there is a need to developmore robust automatic VQA metrics that serve as a proxy for human judgment. Inthis work, we propose to leverage the in-context learning capabilities ofinstruction-tuned large language models (LLMs) to build a better VQA metric. Weformulate VQA evaluation as an answer-rating task where the LLM is instructedto score the accuracy of a candidate answer given a set of reference answers.We demonstrate the proposed metric better correlates with human judgmentcompared to existing metrics across several VQA models and benchmarks. We hopewide adoption of our metric will contribute to better estimating the researchprogress on the VQA task. We plan to release the evaluation code and collectedhuman judgments.</description><author>Oscar Ma√±as, Benno Krojer, Aishwarya Agrawal</author><pubDate>Wed, 10 Jan 2024 17:00:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02567v2</guid></item><item><title>AUTOACT: Automatic Agent Learning from Scratch via Self-Planning</title><link>http://arxiv.org/abs/2401.05268v1</link><description>Language agents have achieved considerable performance on various complextasks. Despite the incessant exploration in this field, existing language agentsystems still struggle with costly, non-reproducible data reliance and face thechallenge of compelling a single model for multiple functions. To this end, weintroduce AutoAct, an automatic agent learning framework that does not rely onlarge-scale annotated data and synthetic trajectories from closed-source models(e.g., GPT-4). Given limited data with a tool library, AutoAct firstautomatically synthesizes planning trajectories without any assistance fromhumans or strong closed-source models. Then, AutoAct leverages adivision-of-labor strategy to automatically differentiate based on the targettask information and synthesized trajectories, producing a sub-agent group tocomplete the task. We conduct comprehensive experiments with different LLMs,which demonstrates that AutoAct yields better or parallel performance comparedto various strong baselines. We even notice that AutoAct, when using theLlama-2-13b model, can achieve performance comparable to that of theGPT-3.5-Turbo agent. Code will be available athttps://github.com/zjunlp/AutoAct.</description><author>Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen</author><pubDate>Wed, 10 Jan 2024 16:57:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05268v1</guid></item><item><title>A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic Artificial Intelligence</title><link>http://arxiv.org/abs/2401.03188v2</link><description>Neurosymbolic artificial intelligence (AI) is an emerging branch of AI thatcombines the strengths of symbolic AI and sub-symbolic AI. A major drawback ofsub-symbolic AI is that it acts as a "black box", meaning that predictions aredifficult to explain, making the testing &amp; evaluation (T&amp;E) and validation &amp;verification (V&amp;V) processes of a system that uses sub-symbolic AI a challenge.Since neurosymbolic AI combines the advantages of both symbolic andsub-symbolic AI, this survey explores how neurosymbolic applications can easethe V&amp;V process. This survey considers two taxonomies of neurosymbolic AI,evaluates them, and analyzes which algorithms are commonly used as the symbolicand sub-symbolic components in current applications. Additionally, an overviewof current techniques for the T&amp;E and V&amp;V processes of these components isprovided. Furthermore, it is investigated how the symbolic part is used for T&amp;Eand V&amp;V purposes in current neurosymbolic applications. Our research shows thatneurosymbolic AI as great potential to ease the T&amp;E and V&amp;V processes ofsub-symbolic AI by leveraging the possibilities of symbolic AI. Additionally,the applicability of current T&amp;E and V&amp;V methods to neurosymbolic AI isassessed, and how different neurosymbolic architectures can impact thesemethods is explored. It is found that current T&amp;E and V&amp;V techniques are partlysufficient to test, evaluate, verify, or validate the symbolic and sub-symbolicpart of neurosymbolic applications independently, while some of them useapproaches where current T&amp;E and V&amp;V methods are not applicable by default, andadjustments or even new approaches are needed. Our research shows that there isgreat potential in using symbolic AI to test, evaluate, verify, or validate thepredictions of a sub-symbolic model, making neurosymbolic AI an interestingresearch direction for safe, secure, and trustworthy AI.</description><author>Justus Renkhoff, Ke Feng, Marc Meier-Doernberg, Alvaro Velasquez, Houbing Herbert Song</author><pubDate>Wed, 10 Jan 2024 16:54:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03188v2</guid></item><item><title>Evidence Networks: simple losses for fast, amortized, neural Bayesian model comparison</title><link>http://arxiv.org/abs/2305.11241v2</link><description>Evidence Networks can enable Bayesian model comparison when state-of-the-artmethods (e.g. nested sampling) fail and even when likelihoods or priors areintractable or unknown. Bayesian model comparison, i.e. the computation ofBayes factors or evidence ratios, can be cast as an optimization problem.Though the Bayesian interpretation of optimal classification is well-known,here we change perspective and present classes of loss functions that result infast, amortized neural estimators that directly estimate convenient functionsof the Bayes factor. This mitigates numerical inaccuracies associated withestimating individual model probabilities. We introduce the leaky parity-oddpower (l-POP) transform, leading to the novel ``l-POP-Exponential'' lossfunction. We explore neural density estimation for data probability indifferent models, showing it to be less accurate and scalable than EvidenceNetworks. Multiple real-world and synthetic examples illustrate that EvidenceNetworks are explicitly independent of dimensionality of the parameter spaceand scale mildly with the complexity of the posterior probability densityfunction. This simple yet powerful approach has broad implications for modelinference tasks. As an application of Evidence Networks to real-world data wecompute the Bayes factor for two models with gravitational lensing data of theDark Energy Survey. We briefly discuss applications of our methods to other,related problems of model comparison and evaluation in implicit inferencesettings.</description><author>Niall Jeffrey, Benjamin D. Wandelt</author><pubDate>Wed, 10 Jan 2024 16:45:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11241v2</guid></item><item><title>Language-based Valence and Arousal Expressions between the United States and China: a Cross-Cultural Examination</title><link>http://arxiv.org/abs/2401.05254v1</link><description>Although affective expressions of individuals have been extensively studiedusing social media, research has primarily focused on the Western context.There are substantial differences among cultures that contribute to theiraffective expressions. This paper examines the differences between Twitter (X)in the United States and Sina Weibo posts in China on two primary dimensions ofaffect - valence and arousal. We study the difference in the functionalrelationship between arousal and valence (so-called V-shaped) among individualsin the US and China and explore the associated content differences.Furthermore, we correlate word usage and topics in both platforms to interprettheir differences. We observe that for Twitter users, the variation inemotional intensity is less distinct between negative and positive emotionscompared to Weibo users, and there is a sharper escalation in arousalcorresponding with heightened emotions. From language features, we discoverthat affective expressions are associated with personal life and feelings onTwitter, while on Weibo such discussions are about socio-political topics inthe society. These results suggest a West-East difference in the V-shapedrelationship between valence and arousal of affective expressions on socialmedia influenced by content differences. Our findings have implications forapplications and theories related to cultural differences in affectiveexpressions.</description><author>Young-Min Cho, Dandan Pang, Stuti Thapa, Garrick Sherman, Lyle Ungar, Louis Tay, Sharath Chandra Guntuku</author><pubDate>Wed, 10 Jan 2024 16:32:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05254v1</guid></item><item><title>Empowering CAM-based Methods with Capability to Generate Fine-Grained and High-Faithfulness Explanations</title><link>http://arxiv.org/abs/2303.09171v2</link><description>Recently, the explanation of neural network models has garnered considerableresearch attention. In computer vision, CAM (Class Activation Map)-basedmethods and LRP (Layer-wise Relevance Propagation) method are two commonexplanation methods. However, since most CAM-based methods can only generateglobal weights, they can only generate coarse-grained explanations at a deeplayer. LRP and its variants, on the other hand, can generate fine-grainedexplanations. But the faithfulness of the explanations is too low. To addressthese challenges, in this paper, we propose FG-CAM (Fine-Grained CAM), whichextends CAM-based methods to enable generating fine-grained andhigh-faithfulness explanations. FG-CAM uses the relationship between twoadjacent layers of feature maps with resolution differences to graduallyincrease the explanation resolution, while finding the contributing pixels andfiltering out the pixels that do not contribute. Our method not only solves theshortcoming of CAM-based methods without changing their characteristics, butalso generates fine-grained explanations that have higher faithfulness than LRPand its variants. We also present FG-CAM with denoising, which is a variant ofFG-CAM and is able to generate less noisy explanations with almost no change inexplanation faithfulness. Experimental results show that the performance ofFG-CAM is almost unaffected by the explanation resolution. FG-CAM outperformsexisting CAM-based methods significantly in both shallow and intermediatelayers, and outperforms LRP and its variations significantly in the inputlayer. Our code is available at https://github.com/dongmo-qcq/FG-CAM.</description><author>Changqing Qiu, Fusheng Jin, Yining Zhang</author><pubDate>Wed, 10 Jan 2024 16:30:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09171v2</guid></item><item><title>ChartAssisstant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning</title><link>http://arxiv.org/abs/2401.02384v2</link><description>Charts play a vital role in data visualization, understanding data patterns,and informed decision-making. However, their unique combination of graphicalelements (e.g., bars, lines) and textual components (e.g., labels, legends)poses challenges for general-purpose multimodal models. While vision-languagemodels trained on chart data excel in comprehension, they struggle withgeneralization and require task-specific fine-tuning. To address thesechallenges, we propose ChartAssistant, a chart-based vision-language model foruniversal chart comprehension and reasoning. ChartAssistant leverages ChartSFT,a comprehensive dataset covering diverse chart-related tasks with basic andspecialized chart types. It undergoes a two-stage training process, startingwith pre-training on chart-to-table parsing to align chart and text, followedby multitask instruction-following fine-tuning. This approach enablesChartAssistant to achieve competitive performance across various chart taskswithout task-specific fine-tuning. Experimental results demonstrate significantperformance gains over the state-of-the-art UniChart method, outperformingOpenAI's GPT-4V(ision) on real-world chart data. The code and data areavailable at https://github.com/OpenGVLab/ChartAst.</description><author>Fanqing Meng, Wenqi Shao, Quanfeng Lu, Peng Gao, Kaipeng Zhang, Yu Qiao, Ping Luo</author><pubDate>Wed, 10 Jan 2024 16:27:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02384v2</guid></item><item><title>PIXART-Œ¥: Fast and Controllable Image Generation with Latent Consistency Models</title><link>http://arxiv.org/abs/2401.05252v1</link><description>This technical report introduces PIXART-{\delta}, a text-to-image synthesisframework that integrates the Latent Consistency Model (LCM) and ControlNetinto the advanced PIXART-{\alpha} model. PIXART-{\alpha} is recognized for itsability to generate high-quality images of 1024px resolution through aremarkably efficient training process. The integration of LCM inPIXART-{\delta} significantly accelerates the inference speed, enabling theproduction of high-quality images in just 2-4 steps. Notably, PIXART-{\delta}achieves a breakthrough 0.5 seconds for generating 1024x1024 pixel images,marking a 7x improvement over the PIXART-{\alpha}. Additionally,PIXART-{\delta} is designed to be efficiently trainable on 32GB V100 GPUswithin a single day. With its 8-bit inference capability (von Platen et al.,2023), PIXART-{\delta} can synthesize 1024px images within 8GB GPU memoryconstraints, greatly enhancing its usability and accessibility. Furthermore,incorporating a ControlNet-like module enables fine-grained control overtext-to-image diffusion models. We introduce a novel ControlNet-Transformerarchitecture, specifically tailored for Transformers, achieving explicitcontrollability alongside high-quality image generation. As a state-of-the-art,open-source image generation model, PIXART-{\delta} offers a promisingalternative to the Stable Diffusion family of models, contributingsignificantly to text-to-image synthesis.</description><author>Junsong Chen, Yue Wu, Simian Luo, Enze Xie, Sayak Paul, Ping Luo, Hang Zhao, Zhenguo Li</author><pubDate>Wed, 10 Jan 2024 16:27:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05252v1</guid></item><item><title>ReACT: Reinforcement Learning for Controller Parametrization using B-Spline Geometries</title><link>http://arxiv.org/abs/2401.05251v1</link><description>Robust and performant controllers are essential for industrial applications.However, deriving controller parameters for complex and nonlinear systems ischallenging and time-consuming. To facilitate automatic controllerparametrization, this work presents a novel approach using deep reinforcementlearning (DRL) with N-dimensional B-spline geometries (BSGs). We focus on thecontrol of parameter-variant systems, a class of systems with complex behaviorwhich depends on the operating conditions. For this system class,gain-scheduling control structures are widely used in applications acrossindustries due to well-known design principles. Facilitating the expensivecontroller parametrization task regarding these control structures, we deployan DRL agent. Based on control system observations, the agent autonomouslydecides how to adapt the controller parameters. We make the adaptation processmore efficient by introducing BSGs to map the controller parameters which maydepend on numerous operating conditions. To preprocess time-series data andextract a fixed-length feature vector, we use a long short-term memory (LSTM)neural networks. Furthermore, this work contributes actor regularizations thatare relevant to real-world environments which differ from training.Accordingly, we apply dropout layer normalization to the actor and criticnetworks of the truncated quantile critic (TQC) algorithm. To show ourapproach's working principle and effectiveness, we train and evaluate the DRLagent on the parametrization task of an industrial control structure withparameter lookup tables.</description><author>Thomas Rudolf, Daniel Fl√∂gel, Tobias Sch√ºrmann, Simon S√º√ü, Stefan Schwab, S√∂ren Hohmann</author><pubDate>Wed, 10 Jan 2024 16:27:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05251v1</guid></item><item><title>CenTime: Event-Conditional Modelling of Censoring in Survival Analysis</title><link>http://arxiv.org/abs/2309.03851v3</link><description>Survival analysis is a valuable tool for estimating the time until specificevents, such as death or cancer recurrence, based on baseline observations.This is particularly useful in healthcare to prognostically predict clinicallyimportant events based on patient data. However, existing approaches often havelimitations; some focus only on ranking patients by survivability, neglectingto estimate the actual event time, while others treat the problem as aclassification task, ignoring the inherent time-ordered structure of theevents. Furthermore, the effective utilization of censored samples - trainingdata points where the exact event time is unknown - is essential for improvingthe predictive accuracy of the model. In this paper, we introduce CenTime, anovel approach to survival analysis that directly estimates the time to event.Our method features an innovative event-conditional censoring mechanism thatperforms robustly even when uncensored data is scarce. We demonstrate that ourapproach forms a consistent estimator for the event model parameters, even inthe absence of uncensored data. Furthermore, CenTime is easily integrated withdeep learning models with no restrictions on batch size or the number ofuncensored samples. We compare our approach with standard survival analysismethods, including the Cox proportional-hazard model and DeepHit. Our resultsindicate that CenTime offers state-of-the-art performance in predictingtime-to-death while maintaining comparable ranking performance. Ourimplementation is publicly available athttps://github.com/ahmedhshahin/CenTime.</description><author>Ahmed H. Shahin, An Zhao, Alexander C. Whitehead, Daniel C. Alexander, Joseph Jacob, David Barber</author><pubDate>Wed, 10 Jan 2024 16:25:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03851v3</guid></item><item><title>CASA: Causality-driven Argument Sufficiency Assessment</title><link>http://arxiv.org/abs/2401.05249v1</link><description>The argument sufficiency assessment task aims to determine if the premises ofa given argument support its conclusion. To tackle this task, existing worksoften train a classifier on data annotated by humans. However, annotating datais laborious, and annotations are often inconsistent due to subjectivecriteria. Motivated by the probability of sufficiency (PS) definition in thecausal literature, we propose CASA, a zero-shot causality-driven argumentsufficiency assessment framework. PS measures how likely introducing thepremise event would lead to the conclusion, when both the premise andconclusion events are absent. To estimate this probability, we propose to uselarge language models (LLMs) to generate contexts that are inconsistent withthe premise and conclusion, and revise them by injecting the premise event.Experiments on two logical fallacy detection datasets demonstrate that CASAaccurately identifies insufficient arguments. We further deploy CASA in awriting assistance application, and find that suggestions generated by CASAenhance the sufficiency of student-written arguments. Code and data areavailable at https://github.com/xxxiaol/CASA.</description><author>Xiao Liu, Yansong Feng, Kai-Wei Chang</author><pubDate>Wed, 10 Jan 2024 16:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05249v1</guid></item><item><title>Asynchronous Decentralized Federated Lifelong Learning for Landmark Localization in Medical Imaging</title><link>http://arxiv.org/abs/2303.06783v2</link><description>Federated learning is a recent development in the machine learning area thatallows a system of devices to train on one or more tasks without sharing theirdata to a single location or device. However, this framework still requires acentralized global model to consolidate individual models into one, and thedevices train synchronously, which both can be potential bottlenecks for usingfederated learning. In this paper, we propose a novel method of asynchronousdecentralized federated lifelong learning (ADFLL) method that inherits themerits of federated learning and can train on multiple tasks simultaneouslywithout the need for a central node or synchronous training. Thus, overcomingthe potential drawbacks of conventional federated learning. We demonstrateexcellent performance on the brain tumor segmentation (BRATS) dataset forlocalizing the left ventricle on multiple image sequences and imageorientation. Our framework allows agents to achieve the best performance with amean distance error of 7.81, better than the conventional all-knowing agent'smean distance error of 11.78, and significantly (p=0.01) better than aconventional lifelong learning agent with a distance error of 15.17 after eightrounds of training. In addition, all ADFLL agents have comparable or betterperformance than a conventional LL agent. In conclusion, we developed an ADFLLframework with excellent performance and speed-up compared to conventional RLagents.</description><author>Guangyao Zheng, Michael A. Jacobs, Vladimir Braverman, Vishwa S. Parekh</author><pubDate>Wed, 10 Jan 2024 16:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06783v2</guid></item><item><title>Reliability Analysis of Complex Systems using Subset Simulations with Hamiltonian Neural Networks</title><link>http://arxiv.org/abs/2401.05244v1</link><description>We present a new Subset Simulation approach using Hamiltonian neuralnetwork-based Monte Carlo sampling for reliability analysis. The proposedstrategy combines the superior sampling of the Hamiltonian Monte Carlo methodwith computationally efficient gradient evaluations using Hamiltonian neuralnetworks. This combination is especially advantageous because the neuralnetwork architecture conserves the Hamiltonian, which defines the acceptancecriteria of the Hamiltonian Monte Carlo sampler. Hence, this strategy achieveshigh acceptance rates at low computational cost. Our approach estimates smallfailure probabilities using Subset Simulations. However, in low-probabilitysample regions, the gradient evaluation is particularly challenging. Theremarkable accuracy of the proposed strategy is demonstrated on differentreliability problems, and its efficiency is compared to the traditionalHamiltonian Monte Carlo method. We note that this approach can reach itslimitations for gradient estimations in low-probability regions of complex andhigh-dimensional distributions. Thus, we propose techniques to improve gradientprediction in these particular situations and enable accurate estimations ofthe probability of failure. The highlight of this study is the reliabilityanalysis of a system whose parameter distributions must be inferred withBayesian inference problems. In such a case, the Hamiltonian Monte Carlo methodrequires a full model evaluation for each gradient evaluation and, therefore,comes at a very high cost. However, using Hamiltonian neural networks in thisframework replaces the expensive model evaluation, resulting in tremendousimprovements in computational efficiency.</description><author>Denny Thaler, Somayajulu L. N. Dhulipala, Franz Bamer, Bernd Markert, Michael D. Shields</author><pubDate>Wed, 10 Jan 2024 16:15:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05244v1</guid></item><item><title>Decoupling Decision-Making in Fraud Prevention through Classifier Calibration for Business Logic Action</title><link>http://arxiv.org/abs/2401.05240v1</link><description>Machine learning models typically focus on specific targets like creatingclassifiers, often based on known population feature distributions in abusiness context. However, models calculating individual features adapt overtime to improve precision, introducing the concept of decoupling: shifting frompoint evaluation to data distribution. We use calibration strategies asstrategy for decoupling machine learning (ML) classifiers from score-basedactions within business logic frameworks. To evaluate these strategies, weperform a comparative analysis using a real-world business scenario andmultiple ML models. Our findings highlight the trade-offs and performanceimplications of the approach, offering valuable insights for practitionersseeking to optimize their decoupling efforts. In particular, the Isotonic andBeta calibration methods stand out for scenarios in which there is shiftbetween training and testing data.</description><author>Emanuele Luzio, Moacir Antonelli Ponti, Christian Ramirez Arevalo, Luis Argerich</author><pubDate>Wed, 10 Jan 2024 16:13:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05240v1</guid></item><item><title>A density estimation perspective on learning from pairwise human preferences</title><link>http://arxiv.org/abs/2311.14115v3</link><description>Learning from human feedback (LHF) -- and in particular learning frompairwise preferences -- has recently become a crucial ingredient in traininglarge language models (LLMs), and has been the subject of much research. Mostrecent works frame it as a reinforcement learning problem, where a rewardfunction is learned from pairwise preference data and the LLM is treated as apolicy which is adapted to maximize the rewards, often under additionalregularization constraints. We propose an alternative interpretation whichcenters on the generative process for pairwise preferences and treats LHF as adensity estimation problem. We provide theoretical and empirical resultsshowing that for a family of generative processes defined via preferencebehavior distribution equations, training a reward function on pairwisepreferences effectively models an annotator's implicit preference distribution.Finally, we discuss and present findings on "annotator misspecification" --failure cases where wrong modeling assumptions are made about annotatorbehavior, resulting in poorly-adapted models -- suggesting that approaches thatlearn from pairwise human preferences could have trouble learning from apopulation of annotators with diverse viewpoints.</description><author>Vincent Dumoulin, Daniel D. Johnson, Pablo Samuel Castro, Hugo Larochelle, Yann Dauphin</author><pubDate>Wed, 10 Jan 2024 16:11:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14115v3</guid></item><item><title>Structure from Duplicates: Neural Inverse Graphics from a Pile of Objects</title><link>http://arxiv.org/abs/2401.05236v1</link><description>Our world is full of identical objects (\emphe.g., cans of coke, cars of samemodel). These duplicates, when seen together, provide additional and strongcues for us to effectively reason about 3D. Inspired by this observation, weintroduce Structure from Duplicates (SfD), a novel inverse graphics frameworkthat reconstructs geometry, material, and illumination from a single imagecontaining multiple identical objects. SfD begins by identifying multipleinstances of an object within an image, and then jointly estimates the 6DoFpose for all instances.An inverse graphics pipeline is subsequently employed tojointly reason about the shape, material of the object, and the environmentlight, while adhering to the shared geometry and material constraint acrossinstances. Our primary contributions involve utilizing object duplicates as arobust prior for single-image inverse graphics and proposing an in-planerotation-robust Structure from Motion (SfM) formulation for joint 6-DoF objectpose estimation. By leveraging multi-view cues from a single image, SfDgenerates more realistic and detailed 3D reconstructions, significantlyoutperforming existing single image reconstruction models and multi-viewreconstruction approaches with a similar or greater number of observations.</description><author>Tianhang Cheng, Wei-Chiu Ma, Kaiyu Guan, Antonio Torralba, Shenlong Wang</author><pubDate>Wed, 10 Jan 2024 16:07:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05236v1</guid></item><item><title>Analysis of the Memorization and Generalization Capabilities of AI Agents: Are Continual Learners Robust?</title><link>http://arxiv.org/abs/2309.10149v2</link><description>In continual learning (CL), an AI agent (e.g., autonomous vehicles orrobotics) learns from non-stationary data streams under dynamic environments.For the practical deployment of such applications, it is important to guaranteerobustness to unseen environments while maintaining past experiences. In thispaper, a novel CL framework is proposed to achieve robust generalization todynamic environments while retaining past knowledge. The considered CL agentuses a capacity-limited memory to save previously observed environmentalinformation to mitigate forgetting issues. Then, data points are sampled fromthe memory to estimate the distribution of risks over environmental change soas to obtain predictors that are robust with unseen changes. The generalizationand memorization performance of the proposed framework are theoreticallyanalyzed. This analysis showcases the tradeoff between memorization andgeneralization with the memory size. Experiments show that the proposedalgorithm outperforms memory-based CL baselines across all environments whilesignificantly improving the generalization performance on unseen targetenvironments.</description><author>Minsu Kim, Walid Saad</author><pubDate>Wed, 10 Jan 2024 16:07:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10149v2</guid></item><item><title>Taming "data-hungry" reinforcement learning? Stability in continuous state-action spaces</title><link>http://arxiv.org/abs/2401.05233v1</link><description>We introduce a novel framework for analyzing reinforcement learning (RL) incontinuous state-action spaces, and use it to prove fast rates of convergencein both off-line and on-line settings. Our analysis highlights two keystability properties, relating to how changes in value functions and/orpolicies affect the Bellman operator and occupation measures. We argue thatthese properties are satisfied in many continuous state-action Markov decisionprocesses, and demonstrate how they arise naturally when using linear functionapproximation methods. Our analysis offers fresh perspectives on the roles ofpessimism and optimism in off-line and on-line RL, and highlights theconnection between off-line RL and transfer learning.</description><author>Yaqi Duan, Martin J. Wainwright</author><pubDate>Wed, 10 Jan 2024 16:01:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05233v1</guid></item><item><title>Measuring Natural Scenes SFR of Automotive Fisheye Cameras</title><link>http://arxiv.org/abs/2401.05232v1</link><description>The Modulation Transfer Function (MTF) is an important image quality metrictypically used in the automotive domain. However, despite the fact that opticalquality has an impact on the performance of computer vision in vehicleautomation, for many public datasets, this metric is unknown. Additionally,wide field-of-view (FOV) cameras have become increasingly popular, particularlyfor low-speed vehicle automation applications. To investigate image quality indatasets, this paper proposes an adaptation of the Natural Scenes SpatialFrequency Response (NS-SFR) algorithm to suit cameras with a widefield-of-view.</description><author>Daniel Jakab, Eoin Martino Grua, Brian Micheal Deegan, Anthony Scanlan, Pepijn Van De Ven, Ciar√°n Eising</author><pubDate>Wed, 10 Jan 2024 15:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05232v1</guid></item><item><title>Learning effective good variables from physical data</title><link>http://arxiv.org/abs/2401.05226v1</link><description>We assume that a sufficiently large database is available, where a physicalproperty of interest and a number of associated ruling primitive variables orobservables are stored. We introduce and test two machine learning approachesto discover possible groups or combinations of primitive variables: The firstapproach is based on regression models whereas the second on classificationmodels. The variable group (here referred to as the new effective goodvariable) can be considered as successfully found, when the physical propertyof interest is characterized by the following effective invariant behaviour: Inthe first method, invariance of the group implies invariance of the property upto a given accuracy; in the other method, upon partition of the physicalproperty values into two or more classes, invariance of the group impliesinvariance of the class. For the sake of illustration, the two methods aresuccessfully applied to two popular empirical correlations describing theconvective heat transfer phenomenon and to the Newton's law of universalgravitation.</description><author>Giulio Barletta, Giovanni Trezza, Eliodoro Chiavazzo</author><pubDate>Wed, 10 Jan 2024 15:52:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05226v1</guid></item><item><title>QuantNAS for super resolution: searching for efficient quantization-friendly architectures against quantization noise</title><link>http://arxiv.org/abs/2208.14839v4</link><description>There is a constant need for high-performing and computationally efficientneural network models for image super-resolution: computationally efficientmodels can be used via low-capacity devices and reduce carbon footprints. Oneway to obtain such models is to compress models, e.g. quantization. Another wayis a neural architecture search that automatically discovers new, moreefficient solutions. We propose a novel quantization-aware procedure, theQuantNAS that combines pros of these two approaches. To make QuantNAS work, theprocedure looks for quantization-friendly super-resolution models. The approachutilizes entropy regularization, quantization noise, and Adaptive Deviation forQuantization (ADQ) module to enhance the search procedure. The entropyregularization technique prioritizes a single operation within each block ofthe search space. Adding quantization noise to parameters and activationsapproximates model degradation after quantization, resulting in a morequantization-friendly architectures. ADQ helps to alleviate problems caused byBatch Norm blocks in super-resolution models. Our experimental results showthat the proposed approximations are better for search procedure than directmodel quantization. QuantNAS discovers architectures with better PSNR/BitOpstrade-off than uniform or mixed precision quantization of fixed architectures.We showcase the effectiveness of our method through its application to twosearch spaces inspired by the state-of-the-art SR models and RFDN. Thus, anyonecan design a proper search space based on an existing architecture and applyour method to obtain better quality and efficiency. The proposed procedure is 30\% faster than direct weight quantization and ismore stable.</description><author>Egor Shvetsov, Dmitry Osin, Alexey Zaytsev, Ivan Koryakovskiy, Valentin Buchnev, Ilya Trofimov, Evgeny Burnaev</author><pubDate>Wed, 10 Jan 2024 15:52:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.14839v4</guid></item><item><title>Do Vision and Language Encoders Represent the World Similarly?</title><link>http://arxiv.org/abs/2401.05224v1</link><description>Aligned text-image encoders such as CLIP have become the de facto model forvision-language tasks. Furthermore, modality-specific encoders achieveimpressive performances in their respective domains. This raises a centralquestion: does an alignment exist between uni-modal vision and languageencoders since they fundamentally represent the same physical world? Analyzingthe latent spaces structure of vision and language models on image-captionbenchmarks using the Centered Kernel Alignment (CKA), we find that therepresentation spaces of unaligned and aligned encoders are semanticallysimilar. In the absence of statistical similarity in aligned encoders likeCLIP, we show that a possible matching of unaligned encoders exists without anytraining. We frame this as a seeded graph-matching problem exploiting thesemantic similarity between graphs and propose two methods - a Fast QuadraticAssignment Problem optimization, and a novel localized CKA metric-basedmatching/retrieval. We demonstrate the effectiveness of this on severaldownstream tasks including cross-lingual, cross-domain caption matching andimage classification.</description><author>Mayug Maniparambil, Raiymbek Akshulakov, Yasser Abdelaziz Dahou Djilali, Sanath Narayan, Mohamed El Amine Seddik, Karttikeya Mangalam, Noel E. O'Connor</author><pubDate>Wed, 10 Jan 2024 15:51:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05224v1</guid></item><item><title>Rethinking Detection Based Table Structure Recognition for Visually Rich Document Images</title><link>http://arxiv.org/abs/2312.00699v2</link><description>Table Structure Recognition (TSR) is a widely discussed task aiming attransforming unstructured table images into structured formats, such as HTMLsequences, to make text-only models, such as ChatGPT, that can further processthese tables. One type of solution is using detection models to detect tablecomponents, such as columns and rows, then applying a rule-basedpost-processing method to convert detection results into HTML sequences.However, existing detection-based models usually cannot perform as well asother types of solutions regarding cell-level TSR metrics, such as TEDS, andthe underlying reasons limiting the performance of these models on the TSR taskare also not well-explored. Therefore, we revisit existing detection-basedmodels comprehensively and explore the underlying reasons hindering thesemodels' performance, including the improper problem definition, the mismatchissue of detection and TSR metrics, the characteristics of detection models,and the impact of local and long-range features extraction. Based on ouranalysis and findings, we apply simple methods to tailor a typical two-stagedetection model, Cascade R-CNN, for the TSR task. The experimental results showthat the tailored Cascade R-CNN based model can improve the base Cascade R-CNNmodel by 16.35\% on the FinTabNet dataset regarding the structure-only TEDS,outperforming other types of state-of-the-art methods, demonstrating that ourfindings can be a guideline for improving detection-based TSR models and that apurely detection-based solution is competitive with other types of solutions,such as graph-based and image-to-sequence solutions.</description><author>Bin Xiao, Murat Simsek, Burak Kantarci, Ala Abu Alkheir</author><pubDate>Wed, 10 Jan 2024 15:51:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00699v2</guid></item><item><title>Optimizing Ego Vehicle Trajectory Prediction: The Graph Enhancement Approach</title><link>http://arxiv.org/abs/2312.13104v2</link><description>Predicting the trajectory of an ego vehicle is a critical component ofautonomous driving systems. Current state-of-the-art methods typically rely onDeep Neural Networks (DNNs) and sequential models to process front-view imagesfor future trajectory prediction. However, these approaches often struggle withperspective issues affecting object features in the scene. To address this, weadvocate for the use of Bird's Eye View (BEV) perspectives, which offer uniqueadvantages in capturing spatial relationships and object homogeneity. In ourwork, we leverage Graph Neural Networks (GNNs) and positional encoding torepresent objects in a BEV, achieving competitive performance compared totraditional DNN-based methods. While the BEV-based approach loses some detailedinformation inherent to front-view images, we balance this by enriching the BEVdata by representing it as a graph where relationships between the objects in ascene are captured effectively.</description><author>Sushil Sharma, Aryan Singh, Ganesh Sistu, Mark Halton, Ciar√°n Eising</author><pubDate>Wed, 10 Jan 2024 15:50:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13104v2</guid></item><item><title>Improving generalization by mimicking the human visual diet</title><link>http://arxiv.org/abs/2206.07802v2</link><description>We present a new perspective on bridging the generalization gap betweenbiological and computer vision -- mimicking the human visual diet. Whilecomputer vision models rely on internet-scraped datasets, humans learn fromlimited 3D scenes under diverse real-world transformations with objects innatural context. Our results demonstrate that incorporating variations andcontextual cues ubiquitous in the human visual training data (visual diet)significantly improves generalization to real-world transformations such aslighting, viewpoint, and material changes. This improvement also extends togeneralizing from synthetic to real-world data -- all models trained with ahuman-like visual diet outperform specialized architectures by large marginswhen tested on natural image data. These experiments are enabled by our two keycontributions: a novel dataset capturing scene context and diverse real-worldtransformations to mimic the human visual diet, and a transformer modeltailored to leverage these aspects of the human visual diet. All data andsource code can be accessed athttps://github.com/Spandan-Madan/human_visual_diet.</description><author>Spandan Madan, You Li, Mengmi Zhang, Hanspeter Pfister, Gabriel Kreiman</author><pubDate>Wed, 10 Jan 2024 15:48:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.07802v2</guid></item><item><title>Distributed Monitoring for Data Distribution Shifts in Edge-ML Fraud Detection</title><link>http://arxiv.org/abs/2401.05219v1</link><description>The digital era has seen a marked increase in financial fraud. edge MLemerged as a promising solution for smartphone payment services frauddetection, enabling the deployment of ML models directly on edge devices. Thisapproach enables a more personalized real-time fraud detection. However, asignificant gap in current research is the lack of a robust system formonitoring data distribution shifts in these distributed edge ML applications.Our work bridges this gap by introducing a novel open-source framework designedfor continuous monitoring of data distribution shifts on a network of edgedevices. Our system includes an innovative calculation of theKolmogorov-Smirnov (KS) test over a distributed network of edge devices,enabling efficient and accurate monitoring of users behavior shifts. Wecomprehensively evaluate the proposed framework employing both real-world andsynthetic financial transaction datasets and demonstrate the framework'seffectiveness.</description><author>Nader Karayanni, Robert J. Shahla, Chieh-Lien Hsiao</author><pubDate>Wed, 10 Jan 2024 15:38:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05219v1</guid></item><item><title>LinK3D: Linear Keypoints Representation for 3D LiDAR Point Cloud</title><link>http://arxiv.org/abs/2206.05927v3</link><description>Feature extraction and matching are the basic parts of many robotic visiontasks, such as 2D or 3D object detection, recognition, and registration. As isknown, 2D feature extraction and matching have already achieved great success.Unfortunately, in the field of 3D, the current methods may fail to support theextensive application of 3D LiDAR sensors in robotic vision tasks due to theirpoor descriptiveness and inefficiency. To address this limitation, we propose anovel 3D feature representation method: Linear Keypoints representation for 3DLiDAR point cloud, called LinK3D. The novelty of LinK3D lies in that it fullyconsiders the characteristics (such as the sparsity and complexity) of LiDARpoint clouds and represents the keypoint with its robust neighbor keypoints,which provide strong constraints in the description of the keypoint. Theproposed LinK3D has been evaluated on three public datasets, and theexperimental results show that our method achieves great matching performance.More importantly, LinK3D also shows excellent real-time performance, fasterthan the sensor frame rate at 10 Hz of a typical rotating LiDAR sensor. LinK3Donly takes an average of 30 milliseconds to extract features from the pointcloud collected by a 64-beam LiDAR and takes merely about 20 milliseconds tomatch two LiDAR scans when executed on a computer with an Intel Core i7processor. Moreover, our method can be extended to LiDAR odometry task, andshows good scalability. We release the implementation of our method athttps://github.com/YungeCui/LinK3D.</description><author>Yunge Cui, Yinlong Zhang, Jiahua Dong, Haibo Sun, Xieyuanli Chen, Feng Zhu</author><pubDate>Wed, 10 Jan 2024 15:36:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.05927v3</guid></item><item><title>Invariant Causal Prediction with Locally Linear Models</title><link>http://arxiv.org/abs/2401.05218v1</link><description>We consider the task of identifying the causal parents of a target variableamong a set of candidate variables from observational data. Our main assumptionis that the candidate variables are observed in different environments whichmay, for example, correspond to different settings of a machine or differenttime intervals in a dynamical process. Under certain assumptions differentenvironments can be regarded as interventions on the observed system. We assumea linear relationship between target and covariates, which can be different ineach environment with the only restriction that the causal structure isinvariant across environments. This is an extension of the ICP($\textbf{I}$nvariant $\textbf{C}$ausal $\textbf{P}$rediction) principle byPeters et al. [2016], who assumed a fixed linear relationship across allenvironments. Within our proposed setting we provide sufficient conditions foridentifiability of the causal parents and introduce a practical method calledLoLICaP ($\textbf{Lo}$cally $\textbf{L}$inear $\textbf{I}$nvariant$\textbf{Ca}$usal $\textbf{P}$rediction), which is based on a hypothesis testfor parent identification using a ratio of minimum and maximum statistics. Wethen show in a simplified setting that the statistical power of LoLICaPconverges exponentially fast in the sample size, and finally we analyze thebehavior of LoLICaP experimentally in more general settings.</description><author>Alexander Mey, Rui Manuel Castro</author><pubDate>Wed, 10 Jan 2024 15:34:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05218v1</guid></item><item><title>Exploring Vulnerabilities of No-Reference Image Quality Assessment Models: A Query-Based Black-Box Method</title><link>http://arxiv.org/abs/2401.05217v1</link><description>No-Reference Image Quality Assessment (NR-IQA) aims to predict image qualityscores consistent with human perception without relying on pristine referenceimages, serving as a crucial component in various visual tasks. Ensuring therobustness of NR-IQA methods is vital for reliable comparisons of differentimage processing techniques and consistent user experiences in recommendations.The attack methods for NR-IQA provide a powerful instrument to test therobustness of NR-IQA. However, current attack methods of NR-IQA heavily rely onthe gradient of the NR-IQA model, leading to limitations when the gradientinformation is unavailable. In this paper, we present a pioneering query-basedblack box attack against NR-IQA methods. We propose the concept of \emph{scoreboundary} and leverage an adaptive iterative approach with multiple scoreboundaries. Meanwhile, the initial attack directions are also designed toleverage the characteristics of the Human Visual System (HVS). Experiments showour attack method outperforms all compared state-of-the-art methods and is farahead of previous black-box methods. The effective DBCNN model suffers aSpearman rank-order correlation coefficient (SROCC) decline of $0.6972$attacked by our method, revealing the vulnerability of NR-IQA to black-boxattacks. The proposed attack method also provides a potent tool for furtherexploration into NR-IQA robustness.</description><author>Chenxi Yang, Yujia Liu, Dingquan Li, Tingting jiang</author><pubDate>Wed, 10 Jan 2024 15:30:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05217v1</guid></item><item><title>Pre-trained Large Language Models for Financial Sentiment Analysis</title><link>http://arxiv.org/abs/2401.05215v1</link><description>Financial sentiment analysis refers to classifying financial text contentsinto sentiment categories (e.g. positive, negative, and neutral). In thispaper, we focus on the classification of financial news title, which is achallenging task due to a lack of large amount of training samples. To overcomethis difficulty, we propose to adapt the pretrained large language models(LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from hugeamount of text corpora,have an advantage in text understanding and can beeffectively adapted to domain-specific task while requiring very few amount oftraining samples. In particular, we adapt the open-source Llama2-7B model(2023) with the supervised fine-tuning (SFT) technique [4]. Experimentalevaluation shows that even with the 7B model (which is relatively small forLLMs), our approach significantly outperforms the previous state-of-the-artalgorithms.</description><author>Wei Luo, Dihong Gong</author><pubDate>Wed, 10 Jan 2024 15:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05215v1</guid></item><item><title>Blockwise Principal Component Analysis for monotone missing data imputation and dimensionality reduction</title><link>http://arxiv.org/abs/2305.06042v2</link><description>Monotone missing data is a common problem in data analysis. However,imputation combined with dimensionality reduction can be computationallyexpensive, especially with the increasing size of datasets. To address thisissue, we propose a Blockwise principal component analysis Imputation (BPI)framework for dimensionality reduction and imputation of monotone missing data.The framework conducts Principal Component Analysis (PCA) on the observed partof each monotone block of the data and then imputes on merging the obtainedprincipal components using a chosen imputation technique. BPI can work withvarious imputation techniques and can significantly reduce imputation timecompared to conducting dimensionality reduction after imputation. This makes ita practical and efficient approach for large datasets with monotone missingdata. Our experiments validate the improvement in speed. In addition, ourexperiments also show that while applying MICE imputation directly on missingdata may not yield convergence, applying BPI with MICE for the data may lead toconvergence.</description><author>Tu T. Do, Mai Anh Vu, Tuan L. Vo, Hoang Thien Ly, Thu Nguyen, Steven A. Hicks, Michael A. Riegler, P√•l Halvorsen, Binh T. Nguyen</author><pubDate>Wed, 10 Jan 2024 15:25:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06042v2</guid></item><item><title>I-CEE: Tailoring Explanations of Image Classification Models to User Expertise</title><link>http://arxiv.org/abs/2312.12102v2</link><description>Effectively explaining decisions of black-box machine learning models iscritical to responsible deployment of AI systems that rely on them. Recognizingtheir importance, the field of explainable AI (XAI) provides several techniquesto generate these explanations. Yet, there is relatively little emphasis on theuser (the explainee) in this growing body of work and most XAI techniquesgenerate "one-size-fits-all" explanations. To bridge this gap and achieve astep closer towards human-centered XAI, we present I-CEE, a framework thatprovides Image Classification Explanations tailored to User Expertise. Informedby existing work, I-CEE explains the decisions of image classification modelsby providing the user with an informative subset of training data (i.e.,example images), corresponding local explanations, and model decisions.However, unlike prior work, I-CEE models the informativeness of the exampleimages to depend on user expertise, resulting in different examples fordifferent users. We posit that by tailoring the example set to user expertise,I-CEE can better facilitate users' understanding and simulatability of themodel. To evaluate our approach, we conduct detailed experiments in bothsimulation and with human participants (N = 100) on multiple datasets.Experiments with simulated users show that I-CEE improves users' ability toaccurately predict the model's decisions (simulatability) compared tobaselines, providing promising preliminary results. Experiments with humanparticipants demonstrate that our method significantly improves usersimulatability accuracy, highlighting the importance of human-centered XAI</description><author>Yao Rong, Peizhu Qian, Vaibhav Unhelkar, Enkelejda Kasneci</author><pubDate>Wed, 10 Jan 2024 15:22:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12102v2</guid></item><item><title>Non-Euclidean Spatial Graph Neural Network</title><link>http://arxiv.org/abs/2312.10808v2</link><description>Spatial networks are networks whose graph topology is constrained by theirembedded spatial space. Understanding the coupled spatial-graph properties iscrucial for extracting powerful representations from spatial networks.Therefore, merely combining individual spatial and network representationscannot reveal the underlying interaction mechanism of spatial networks.Besides, existing spatial network representation learning methods can onlyconsider networks embedded in Euclidean space, and can not well exploit therich geometric information carried by irregular and non-uniform non-Euclideanspace. In order to address this issue, in this paper we propose a novel genericframework to learn the representation of spatial networks that are embedded innon-Euclidean manifold space. Specifically, a novel message-passing-basedneural network is proposed to combine graph topology and spatial geometry,where spatial geometry is extracted as messages on the edges. We theoreticallyguarantee that the learned representations are provably invariant to importantsymmetries such as rotation or translation, and simultaneously maintainsufficient ability in distinguishing different geometric structures. Thestrength of our proposed method is demonstrated through extensive experimentson both synthetic and real-world datasets.</description><author>Zheng Zhang, Sirui Li, Jingcheng Zhou, Junxiang Wang, Abhinav Angirekula, Allen Zhang, Liang Zhao</author><pubDate>Wed, 10 Jan 2024 15:22:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10808v2</guid></item><item><title>Error estimation for physics-informed neural networks with implicit Runge-Kutta methods</title><link>http://arxiv.org/abs/2401.05211v1</link><description>The ability to accurately approximate trajectories of dynamical systemsenables their analysis, prediction, and control. Neural network (NN)-basedapproximations have attracted significant interest due to fast evaluation withgood accuracy over long integration time steps. In contrast to establishednumerical approximation schemes such as Runge-Kutta methods, the estimation ofthe error of the NN-based approximations proves to be difficult. In this work,we propose to use the NN's predictions in a high-order implicit Runge-Kutta(IRK) method. The residuals in the implicit system of equations can be relatedto the NN's prediction error, hence, we can provide an error estimate atseveral points along a trajectory. We find that this error estimate highlycorrelates with the NN's prediction error and that increasing the order of theIRK method improves this estimate. We demonstrate this estimation methodologyfor Physics-Informed Neural Network (PINNs) on the logistic equation as anillustrative example and then apply it to a four-state electric generator modelthat is regularly used in power system modelling.</description><author>Jochen Stiasny, Spyros Chatzivasileiadis</author><pubDate>Wed, 10 Jan 2024 15:18:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05211v1</guid></item><item><title>Semantic segmentation of sparse irregular point clouds for leaf/wood discrimination</title><link>http://arxiv.org/abs/2305.16963v3</link><description>LiDAR (Light Detection and Ranging) has become an essential part of theremote sensing toolbox used for biosphere monitoring. In particular, LiDARprovides the opportunity to map forest leaf area with unprecedented accuracy,while leaf area has remained an important source of uncertainty affectingmodels of gas exchanges between the vegetation and the atmosphere. UnmannedAerial Vehicles (UAV) are easy to mobilize and therefore allow frequentrevisits to track the response of vegetation to climate change. However,miniature sensors embarked on UAVs usually provide point clouds of limiteddensity, which are further affected by a strong decrease in density from top tobottom of the canopy due to progressively stronger occlusion. In such acontext, discriminating leaf points from wood points presents a significantchallenge due in particular to strong class imbalance and spatially irregularsampling intensity. Here we introduce a neural network model based on thePointnet ++ architecture which makes use of point geometry only (excluding anyspectral information). To cope with local data sparsity, we propose aninnovative sampling scheme which strives to preserve local important geometricinformation. We also propose a loss function adapted to the severe classimbalance. We show that our model outperforms state-of-the-art alternatives onUAV point clouds. We discuss future possible improvements, particularlyregarding much denser point clouds acquired from below the canopy.</description><author>Yuchen Bai, Jean-Baptiste Durand, Gr√©goire Vincent, Florence Forbes</author><pubDate>Wed, 10 Jan 2024 15:13:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16963v3</guid></item><item><title>Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving</title><link>http://arxiv.org/abs/2308.05194v2</link><description>In this paper, we assess the state of the art in pedestrian trajectoryprediction within the context of generating single trajectories, a criticalaspect aligning with the requirements in autonomous systems. The evaluation isconducted on the widely-used ETH/UCY dataset where the Average DisplacementError (ADE) and the Final Displacement Error (FDE) are reported. Alongsidethis, we perform an ablation study to investigate the impact of the observedmotion history on prediction performance. To evaluate the scalability of eachapproach when confronted with varying amounts of agents, the inference time ofeach model is measured. Following a quantitative analysis, the resultingpredictions are compared in a qualitative manner, giving insight into thestrengths and weaknesses of current approaches. The results demonstrate thatalthough a constant velocity model (CVM) provides a good approximation of theoverall dynamics in the majority of cases, additional features need to beincorporated to reflect common pedestrian behavior observed. Therefore, thisstudy presents a data-driven analysis with the intent to guide the futuredevelopment of pedestrian trajectory prediction algorithms.</description><author>Nico Uhlemann, Felix Fent, Markus Lienkamp</author><pubDate>Wed, 10 Jan 2024 15:12:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05194v2</guid></item><item><title>BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark for Short-Term Load Forecasting</title><link>http://arxiv.org/abs/2307.00142v3</link><description>Short-term forecasting of residential and commercial building energyconsumption is widely used in power systems and continues to grow inimportance. Data-driven short-term load forecasting (STLF), although promising,has suffered from a lack of open, large-scale datasets with high buildingdiversity. This has hindered exploring the pretrain-then-fine-tune paradigm forSTLF. To help address this, we present BuildingsBench, which consists of: 1)Buildings-900K, a large-scale dataset of 900K simulated buildings representingthe U.S. building stock; and 2) an evaluation platform with over 1,900 realresidential and commercial buildings from 7 open datasets. BuildingsBenchbenchmarks two under-explored tasks: zero-shot STLF, where a pretrained modelis evaluated on unseen buildings without fine-tuning, and transfer learning,where a pretrained model is fine-tuned on a target building. The main findingof our benchmark analysis is that synthetically pretrained models generalizesurprisingly well to real commercial buildings. An exploration of the effect ofincreasing dataset size and diversity on zero-shot commercial buildingperformance reveals a power-law with diminishing returns. We also show thatfine-tuning pretrained models on real commercial and residential buildingsimproves performance for a majority of target buildings. We hope thatBuildingsBench encourages and facilitates future research on generalizableSTLF. All datasets and code can be accessed fromhttps://github.com/NREL/BuildingsBench.</description><author>Patrick Emami, Abhijeet Sahu, Peter Graf</author><pubDate>Wed, 10 Jan 2024 15:07:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00142v3</guid></item><item><title>A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer</title><link>http://arxiv.org/abs/2401.05204v1</link><description>The verbalizer, which serves to map label words to class labels, is anessential component of prompt-tuning. In this paper, we present a novelapproach to constructing verbalizers. While existing methods for verbalizerconstruction mainly rely on augmenting and refining sets of synonyms or relatedwords based on class names, this paradigm suffers from a narrow perspective andlack of abstraction, resulting in limited coverage and high bias in thelabel-word space. To address this issue, we propose a label-word constructionprocess that incorporates scenario-specific concepts. Specifically, we extractrich concepts from task-specific scenarios as label-word candidates and thendevelop a novel cascade calibration module to refine the candidates into a setof label words for each class. We evaluate the effectiveness of our proposedapproach through extensive experiments on {five} widely used datasets forzero-shot text classification. The results demonstrate that our methodoutperforms existing methods and achieves state-of-the-art results.</description><author>Yong Ma, Senlin Luo, Yu-Ming Shang, Zhengjun Li, Yong Liu</author><pubDate>Wed, 10 Jan 2024 15:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05204v1</guid></item><item><title>Video-based Automatic Lameness Detection of Dairy Cows using Pose Estimation and Multiple Locomotion Traits</title><link>http://arxiv.org/abs/2401.05202v1</link><description>This study presents an automated lameness detection system that usesdeep-learning image processing techniques to extract multiple locomotion traitsassociated with lameness. Using the T-LEAP pose estimation model, the motion ofnine keypoints was extracted from videos of walking cows. The videos wererecorded outdoors, with varying illumination conditions, and T-LEAP extracted99.6% of correct keypoints. The trajectories of the keypoints were then used tocompute six locomotion traits: back posture measurement, head bobbing, trackingdistance, stride length, stance duration, and swing duration. The three mostimportant traits were back posture measurement, head bobbing, and trackingdistance. For the ground truth, we showed that a thoughtful merging of thescores of the observers could improve intra-observer reliability and agreement.We showed that including multiple locomotion traits improves the classificationaccuracy from 76.6% with only one trait to 79.9% with the three most importanttraits and to 80.1% with all six locomotion traits.</description><author>Helena Russello, Rik van der Tol, Menno Holzhauer, Eldert J. van Henten, Gert Kootstra</author><pubDate>Wed, 10 Jan 2024 14:56:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05202v1</guid></item><item><title>A Unified Framework for U-Net Design and Analysis</title><link>http://arxiv.org/abs/2305.19638v2</link><description>U-Nets are a go-to, state-of-the-art neural architecture across numeroustasks for continuous signals on a square such as images and PartialDifferential Equations (PDE), however their design and architecture isunderstudied. In this paper, we provide a framework for designing and analysinggeneral U-Net architectures. We present theoretical results which characterisethe role of the encoder and decoder in a U-Net, their high-resolution scalinglimits and their conjugacy to ResNets via preconditioning. We proposeMulti-ResNets, U-Nets with a simplified, wavelet-based encoder withoutlearnable parameters. Further, we show how to design novel U-Net architectureswhich encode function constraints, natural bases, or the geometry of the data.In diffusion models, our framework enables us to identify that high-frequencyinformation is dominated by noise exponentially faster, and show how U-Netswith average pooling exploit this. In our experiments, we demonstrate howMulti-ResNets achieve competitive and often superior performance compared toclassical U-Nets in image segmentation, PDE surrogate modelling, and generativemodelling with diffusion models. Our U-Net framework paves the way to study thetheoretical properties of U-Nets and design natural, scalable neuralarchitectures for a multitude of problems beyond the square.</description><author>Christopher Williams, Fabian Falck, George Deligiannidis, Chris Holmes, Arnaud Doucet, Saifuddin Syed</author><pubDate>Wed, 10 Jan 2024 14:55:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19638v2</guid></item><item><title>Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking</title><link>http://arxiv.org/abs/2401.05200v1</link><description>Managing knowledge efficiently is crucial for organizational success. Inmanufacturing, operating factories has become increasing knowledge-intensiveputting strain on the factory's capacity to train and support new operators. Inthis paper, we introduce a Large Language Model (LLM)-based system designed touse the extensive knowledge contained in factory documentation. The system aimsto efficiently answer queries from operators and facilitate the sharing of newknowledge. To assess its effectiveness, we conducted an evaluation in a factorysetting. The results of this evaluation demonstrated the system's benefits;namely, in enabling quicker information retrieval and more efficient resolutionof issues. However, the study also highlighted a preference for learning from ahuman expert when such an option is available. Furthermore, we benchmarkedseveral closed and open-sourced LLMs for this system. GPT-4 consistentlyoutperformed its counterparts, with open-source models like StableBeluga2trailing closely, presenting an attractive option given its data privacy andcustomization benefits. Overall, this work offers preliminary insights forfactories considering using LLM-tools for knowledge management.</description><author>Samuel Kernan Freire, Chaofan Wang, Mina Foosherian, Stefan Wellsandt, Santiago Ruiz-Arenas, Evangelos Niforatos</author><pubDate>Wed, 10 Jan 2024 14:53:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05200v1</guid></item><item><title>Monte Carlo Tree Search for Recipe Generation using GPT-2</title><link>http://arxiv.org/abs/2401.05199v1</link><description>Automatic food recipe generation methods provide a creative tool for chefs toexplore and to create new, and interesting culinary delights. Given the recentsuccess of large language models (LLMs), they have the potential to create newrecipes that can meet individual preferences, dietary constraints, and adapt towhat is in your refrigerator. Existing research on using LLMs to generaterecipes has shown that LLMs can be finetuned to generate realistic-soundingrecipes. However, on close examination, these generated recipes often fail tomeet basic requirements like including chicken as an ingredient in chickendishes. In this paper, we propose RecipeMC, a text generation method usingGPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us todefine reward functions to put soft constraints on text generation and thusimprove the credibility of the generated recipes. Our results show that humanevaluators prefer recipes generated with RecipeMC more often than recipesgenerated with other baseline methods when compared with real recipes.</description><author>Karan Taneja, Richard Segal, Richard Goodwin</author><pubDate>Wed, 10 Jan 2024 14:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05199v1</guid></item><item><title>HyperPIE: Hyperparameter Information Extraction from Scientific Publications</title><link>http://arxiv.org/abs/2312.10638v2</link><description>Automatic extraction of information from publications is key to makingscientific knowledge machine readable at a large scale. The extractedinformation can, for example, facilitate academic search, decision making, andknowledge graph construction. An important type of information not covered byexisting approaches is hyperparameters. In this paper, we formalize and tacklehyperparameter information extraction (HyperPIE) as an entity recognition andrelation extraction task. We create a labeled data set covering publicationsfrom a variety of computer science disciplines. Using this data set, we trainand evaluate BERT-based fine-tuned models as well as five large languagemodels: GPT-3.5, GALACTICA, Falcon, Vicuna, and WizardLM. For fine-tunedmodels, we develop a relation extraction approach that achieves an improvementof 29% F1 over a state-of-the-art baseline. For large language models, wedevelop an approach leveraging YAML output for structured data extraction,which achieves an average improvement of 5.5% F1 in entity recognition overusing JSON. With our best performing model we extract hyperparameterinformation from a large number of unannotated papers, and analyze patternsacross disciplines. All our data and source code is publicly available athttps://github.com/IllDepence/hyperpie</description><author>Tarek Saier, Mayumi Ohta, Takuto Asakura, Michael F√§rber</author><pubDate>Wed, 10 Jan 2024 14:44:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10638v2</guid></item><item><title>Modelling, Positioning, and Deep Reinforcement Learning Path Tracking Control of Scaled Robotic Vehicles: Design and Experimental Validation</title><link>http://arxiv.org/abs/2401.05194v1</link><description>Mobile robotic systems are becoming increasingly popular. These systems areused in various indoor applications, raging from warehousing and manufacturingto test benches for assessment of advanced control strategies, such asartificial intelligence (AI)-based control solutions, just to name a few.Scaled robotic cars are commonly equipped with a hierarchical controlacthiecture that includes tasks dedicated to vehicle state estimation andcontrol. This paper covers both aspects by proposing (i) a federeted extendedKalman filter (FEKF), and (ii) a novel deep reinforcement learning (DRL) pathtracking controller trained via an expert demonstrator to expedite the learningphase and increase robustess to the simulation-to-reality gap. The paper alsopresents the formulation of a vehicle model along with an effective yet simpleprocedure for identifying tis paramters. The experimentally validated model isused for (i) supporting the design of the FEKF and (ii) serving as a digitaltwin for training the proposed DRL-based path tracking algorithm. Experimentalresults confirm the ability of the FEKF to improve the estimate of the mobilerobot's position. Furthermore, the effectiveness of the DRL path trackingstrateguy is experimentally tested along manoeuvres not considered duringtraining, showing also the ability of the AI-based solution to outpeformmodel-based control strategies and the demonstrator. The comparison withbenchmraking controllers is quantitavely evalueted through a set of keyperformance indicators.</description><author>Carmine Caponio, Pietro Stano, Raffaele Carli, Ignazio Olivieri, Daniele Ragone, Aldo Sorniotti, Umberto Montanaro</author><pubDate>Wed, 10 Jan 2024 14:40:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05194v1</guid></item><item><title>Experiment Planning with Function Approximation</title><link>http://arxiv.org/abs/2401.05193v1</link><description>We study the problem of experiment planning with function approximation incontextual bandit problems. In settings where there is a significant overheadto deploying adaptive algorithms -- for example, when the execution of the datacollection policies is required to be distributed, or a human in the loop isneeded to implement these policies -- producing in advance a set of policiesfor data collection is paramount. We study the setting where a large dataset ofcontexts but not rewards is available and may be used by the learner to designan effective data collection strategy. Although when rewards are linear thisproblem has been well studied, results are still missing for more complexreward models. In this work we propose two experiment planning strategiescompatible with function approximation. The first is an eluder planning andsampling procedure that can recover optimality guarantees depending on theeluder dimension of the reward function class. For the second, we show that auniform sampler achieves competitive optimality rates in the setting where thenumber of actions is small. We finalize our results introducing a statisticalgap fleshing out the fundamental differences between planning and adaptivelearning and provide results for planning with model selection.</description><author>Aldo Pacchiano, Jonathan N. Lee, Emma Brunskill</author><pubDate>Wed, 10 Jan 2024 14:40:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05193v1</guid></item><item><title>Divide and Conquer for Large Language Models Reasoning</title><link>http://arxiv.org/abs/2401.05190v1</link><description>Large language models (LLMs) have shown impressive performance in variousreasoning benchmarks with the emergence of Chain-of-Thought (CoT) and itsderivative methods, particularly in tasks involving multi-choice questions(MCQs). However, current works all process data uniformly without consideringthe problem-solving difficulty, which means an excessive focus on simplequestions while insufficient to intricate ones. To address this challenge, weinspired by humans using heuristic strategies to categorize tasks and handlethem individually, propose to apply the Divide and Conquer to LLMs reasoning.First, we divide questions into different subsets based on the statisticalconfidence score ($\mathcal{CS}$), then fix nearly resolved sets and conquerdemanding nuanced process ones with elaborately designed methods, includingPrior Knowledge based Reasoning (PKR) and Filter Choices based Reasoning (FCR),as well as their integration variants. Our experiments demonstrate that thisproposed strategy significantly boosts the models' reasoning abilities acrossnine datasets involving arithmetic, commonsense, and logic tasks. For instance,compared to baseline, we make a striking improvement on low confidence subsetsof 8.72\% for AQuA, 15.07\% for ARC Challenge and 7.71\% for RiddleSense. Inaddition, through extensive analysis on length of rationale and number ofoptions, we verify that longer reasoning paths in PKR could prevent models fromreferring infer-harmful shortcuts, and also find that removing irrelevantchoices in FCR would substantially avoid models' confusion. The code is at\url{https://github.com/AiMijie/Divide-and-Conquer}</description><author>Zijie Meng, Yan Zhang, Zhaopeng Feng, Yang Feng, Gaoang Wang, Joey Tianyi Zhou, Jian Wu, Zuozhu Liu</author><pubDate>Wed, 10 Jan 2024 14:38:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05190v1</guid></item><item><title>TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support</title><link>http://arxiv.org/abs/2306.13339v3</link><description>Trust evaluation assesses trust relationships between entities andfacilitates decision-making. Machine Learning (ML) shows great potential fortrust evaluation owing to its learning capabilities. In recent years, GraphNeural Networks (GNNs), as a new ML paradigm, have demonstrated superiority indealing with graph data. This has motivated researchers to explore their use intrust evaluation, as trust relationships among entities can be modeled as agraph. However, current trust evaluation methods that employ GNNs fail to fullysatisfy the dynamic nature of trust, overlook the adverse effects oftrust-related attacks, and cannot provide convincing explanations on evaluationresults. To address these problems, we propose TrustGuard, a GNN-based accuratetrust evaluation model that supports trust dynamicity, is robust againsttypical attacks, and provides explanations through visualization. Specifically,TrustGuard is designed with a layered architecture that contains a snapshotinput layer, a spatial aggregation layer, a temporal aggregation layer, and aprediction layer. Among them, the spatial aggregation layer adopts a defensemechanism to robustly aggregate local trust, and the temporal aggregation layerapplies an attention mechanism for effective learning of temporal patterns.Extensive experiments on two real-world datasets show that TrustGuardoutperforms state-of-the-art GNN-based trust evaluation models with respect totrust prediction across single-timeslot and multi-timeslot, even in thepresence of attacks. In addition, TrustGuard can explain its evaluation resultsby visualizing both spatial and temporal views.</description><author>Jie Wang, Zheng Yan, Jiahe Lan, Elisa Bertino, Witold Pedrycz</author><pubDate>Wed, 10 Jan 2024 14:26:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13339v3</guid></item><item><title>Can ChatGPT Rival Neural Machine Translation? A Comparative Study</title><link>http://arxiv.org/abs/2401.05176v1</link><description>Inspired by the increasing interest in leveraging large language models fortranslation, this paper evaluates the capabilities of large language models(LLMs) represented by ChatGPT in comparison to the mainstream neural machinetranslation (NMT) engines in translating Chinese diplomatic texts into English.Specifically, we examine the translation quality of ChatGPT and NMT engines asmeasured by four automated metrics and human evaluation based on anerror-typology and six analytic rubrics. Our findings show that automatedmetrics yield similar results for ChatGPT under different prompts and NMTsystems, while human annotators tend to assign noticeably higher scores toChatGPT when it is provided an example or contextual information about thetranslation task. Pairwise correlation between automated metrics and dimensionsof human evaluation produces weak and non-significant results, suggesting thedivergence between the two methods of translation quality assessment. Thesefindings provide valuable insights into the potential of ChatGPT as a capablemachine translator, and the influence of prompt engineering on its performance.</description><author>Zhaokun Jiang, Ziyin Zhang</author><pubDate>Wed, 10 Jan 2024 14:20:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05176v1</guid></item><item><title>HomeRobot: Open-Vocabulary Mobile Manipulation</title><link>http://arxiv.org/abs/2306.11565v2</link><description>HomeRobot (noun): An affordable compliant robot that navigates homes andmanipulates a wide range of objects in order to complete everyday tasks.Open-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any objectin any unseen environment, and placing it in a commanded location. This is afoundational challenge for robots to be useful assistants in humanenvironments, because it involves tackling sub-problems from across robotics:perception, language understanding, navigation, and manipulation are allessential to OVMM. In addition, integration of the solutions to thesesub-problems poses its own substantial challenges. To drive research in thisarea, we introduce the HomeRobot OVMM benchmark, where an agent navigateshousehold environments to grasp novel objects and place them on targetreceptacles. HomeRobot has two components: a simulation component, which uses alarge and diverse curated object set in new, high-quality multi-room homeenvironments; and a real-world component, providing a software stack for thelow-cost Hello Robot Stretch to encourage replication of real-world experimentsacross labs. We implement both reinforcement learning and heuristic(model-based) baselines and show evidence of sim-to-real transfer. Ourbaselines achieve a 20% success rate in the real world; our experimentsidentify ways future research work improve performance. See videos on ourwebsite: https://ovmm.github.io/.</description><author>Sriram Yenamandra, Arun Ramachandran, Karmesh Yadav, Austin Wang, Mukul Khanna, Theophile Gervet, Tsung-Yen Yang, Vidhi Jain, Alexander William Clegg, John Turner, Zsolt Kira, Manolis Savva, Angel Chang, Devendra Singh Chaplot, Dhruv Batra, Roozbeh Mottaghi, Yonatan Bisk, Chris Paxton</author><pubDate>Wed, 10 Jan 2024 14:20:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11565v2</guid></item><item><title>Speak Like a Native: Prompting Large Language Models in a Native Style</title><link>http://arxiv.org/abs/2311.13538v2</link><description>In-context learning (ICL) with large language models (LLMs) has become themodern tools of choice for many natural language processing tasks. However, howthe text style of in-context examples influences the performance of LLMs stillremains under-explored. This paper presents a novel and effective approach,named \textbf{AlignedCoT}, to improve the reasoning capability of LLMs byaligning the in-context examples with the native style of LLMs.''Native''refers to the inherent characteristic of LLMs which can be probed by zero-shotscenarios.AlignedCoT is widely applicable to ICL methods, making it easy tocombine with state-of-the-art techniques to further improve the LLMs'performance. We conduct extensive and comprehensive experiments on severalbenchmarks on mathematical question-answering, common-sense reasoning, and textunderstanding. The empirical results demonstrate that our AlignedCoTsignificantly improves performance over the carefully handcrafteddemonstrations. Specifically, with AlignedCoT, we observe an average +3.2\%improvement for \texttt{gpt-3.5-turbo} compared to the carefully handcraftedCoT on multi-step reasoning benchmarks.Furthermore, we use AlignedCoT torewrite the CoT text style in the training set, which improves the performanceof Retrieval Augmented Generation by 3.6\%.The source code and dataset isavailable at https://github.com/yangzhch6/AlignedCoT</description><author>Zhicheng Yang, Yiwei Wang, Yinya Huang, Jing Xiong, Xiaodan Liang, Jing Tang</author><pubDate>Wed, 10 Jan 2024 14:16:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13538v2</guid></item><item><title>Generating artificial digital image correlation data using physics-guided adversarial networks</title><link>http://arxiv.org/abs/2303.15939v3</link><description>Digital image correlation (DIC) has become a valuable tool to monitor andevaluate mechanical experiments of cracked specimen, but the automaticdetection of cracks is often difficult due to inherent noise and artefacts.Machine learning models have been extremely successful in detecting crack pathsand crack tips using DIC-measured, interpolated full-field displacements asinput to a convolution-based segmentation model. Still, big data is needed totrain such models. However, scientific data is often scarce as experiments areexpensive and time-consuming. In this work, we present a method to directlygenerate large amounts of artificial displacement data of cracked specimenresembling real interpolated DIC displacements. The approach is based ongenerative adversarial networks (GANs). During training, the discriminatorreceives physical domain knowledge in the form of the derived von Misesequivalent strain. We show that this physics-guided approach leads to improvedresults in terms of visual quality of samples, sliced Wasserstein distance, andgeometry score when compared to a classical unguided GAN approach.</description><author>David Melching, Erik Schultheis, Eric Breitbarth</author><pubDate>Wed, 10 Jan 2024 14:06:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15939v3</guid></item><item><title>CLIP-guided Source-free Object Detection in Aerial Images</title><link>http://arxiv.org/abs/2401.05168v1</link><description>Domain adaptation is crucial in aerial imagery, as the visual representationof these images can significantly vary based on factors such as geographiclocation, time, and weather conditions. Additionally, high-resolution aerialimages often require substantial storage space and may not be readilyaccessible to the public. To address these challenges, we propose a novelSource-Free Object Detection (SFOD) method. Specifically, our approach is builtupon a self-training framework; however, self-training can lead to inaccuratelearning in the absence of labeled training data. To address this issue, wefurther integrate Contrastive Language-Image Pre-training (CLIP) to guide thegeneration of pseudo-labels, termed CLIP-guided Aggregation. By leveragingCLIP's zero-shot classification capability, we use it to aggregate scores withthe original predicted bounding boxes, enabling us to obtain refined scores forthe pseudo-labels. To validate the effectiveness of our method, we constructedtwo new datasets from different domains based on the DIOR dataset, named DIOR-Cand DIOR-Cloudy. Experiments demonstrate that our method outperforms othercomparative algorithms.</description><author>Nanqing Liu, Xun Xu, Yongyi Su, Chengxin Liu, Peiliang Gong, Heng-Chao Li</author><pubDate>Wed, 10 Jan 2024 14:03:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05168v1</guid></item><item><title>Watermark Text Pattern Spotting in Document Images</title><link>http://arxiv.org/abs/2401.05167v1</link><description>Watermark text spotting in document images can offer access to an oftenunexplored source of information, providing crucial evidence about a record'sscope, audience and sometimes even authenticity. Stemming from the problem oftext spotting, detecting and understanding watermarks in documents inherits thesame hardships - in the wild, writing can come in various fonts, sizes andforms, making generic recognition a very difficult problem. To address the lackof resources in this field and propel further research, we propose a novelbenchmark (K-Watermark) containing 65,447 data samples generated using Wrender,a watermark text patterns rendering procedure. A validity study using humansraters yields an authenticity score of 0.51 against pre-generated watermarkeddocuments. To prove the usefulness of the dataset and rendering technique, wedeveloped an end-to-end solution (Wextract) for detecting the bounding boxinstances of watermark text, while predicting the depicted text. To deal withthis specific task, we introduce a variance minimization loss and ahierarchical self-attention mechanism. To the best of our knowledge, we are thefirst to propose an evaluation benchmark and a complete solution for retrievingwatermarks from documents surpassing baselines by 5 AP points in detection and4 points in character accuracy.</description><author>Mateusz Krubinski, Stefan Matcovici, Diana Grigore, Daniel Voinea, Alin-Ionut Popa</author><pubDate>Wed, 10 Jan 2024 14:02:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05167v1</guid></item><item><title>REACT 2024: the Second Multiple Appropriate Facial Reaction Generation Challenge</title><link>http://arxiv.org/abs/2401.05166v1</link><description>In dyadic interactions, humans communicate their intentions and state of mindusing verbal and non-verbal cues, where multiple different facial reactionsmight be appropriate in response to a specific speaker behaviour. Then, how todevelop a machine learning (ML) model that can automatically generate multipleappropriate, diverse, realistic and synchronised human facial reactions from anpreviously unseen speaker behaviour is a challenging task. Following thesuccessful organisation of the first REACT challenge (REACT 2023), this editionof the challenge (REACT 2024) employs a subset used by the previous challenge,which contains segmented 30-secs dyadic interaction clips originally recordedas part of the NOXI and RECOLA datasets, encouraging participants to developand benchmark Machine Learning (ML) models that can generate multipleappropriate facial reactions (including facial image sequences and theirattributes) given an input conversational partner's stimulus under variousdyadic video conference scenarios. This paper presents: (i) the guidelines ofthe REACT 2024 challenge; (ii) the dataset utilized in the challenge; and (iii)the performance of the baseline systems on the two proposed sub-challenges:Offline Multiple Appropriate Facial Reaction Generation and Online MultipleAppropriate Facial Reaction Generation, respectively. The challenge baselinecode is publicly available athttps://github.com/reactmultimodalchallenge/baseline_react2024.</description><author>Siyang Song, Micol Spitale, Cheng Luo, Cristina Palmero, German Barquero, Hengde Zhu, Sergio Escalera, Michel Valstar, Tobias Baur, Fabien Ringeval, Elisabeth Andre, Hatice Gunes</author><pubDate>Wed, 10 Jan 2024 14:01:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05166v1</guid></item><item><title>MISS: A Generative Pretraining and Finetuning Approach for Med-VQA</title><link>http://arxiv.org/abs/2401.05163v1</link><description>Medical visual question answering (VQA) is a challenging multimodal task,where Vision-Language Pre-training (VLP) models can effectively improve thegeneralization performance. However, most methods in the medical field treatVQA as an answer classification task which is difficult to transfer topractical application scenarios. Additionally, due to the privacy of medicalimages and the expensive annotation process, large-scale medical image-textpairs datasets for pretraining are severely lacking. In this paper, we proposea large-scale MultI-task Self-Supervised learning based framework (MISS) formedical VQA tasks. Unlike existing methods, we treat medical VQA as agenerative task. We unify the text encoder and multimodal encoder and alignimage-text features through multi-task learning. Furthermore, we propose aTransfer-and-Caption method that extends the feature space of single-modalimage datasets using large language models (LLMs), enabling those traditionalmedical vision field task data to be applied to VLP. Experiments show that ourmethod achieves excellent results with fewer multimodal datasets anddemonstrates the advantages of generative VQA models. The code and modelweights will be released upon the paper's acceptance.</description><author>Jiawei Chen, Dingkang Yang, Yue Jiang, Yuxuan Lei, Lihua Zhang</author><pubDate>Wed, 10 Jan 2024 13:56:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05163v1</guid></item><item><title>Human-computer Interaction for Brain-inspired Computing Based on Machine Learning And Deep Learning:A Review</title><link>http://arxiv.org/abs/2312.07213v2</link><description>The continuous development of artificial intelligence has a profound impacton biomedical research and other fields.Brain-inspired computing is animportant intersection of multimodal technology and biomedical field. Thispaper presents a comprehensive review of machine learning (ML) and deeplearning (DL) models applied in human-computer interaction for brain-inspiredcomputing, tracking their evolution, application value, challenges, andpotential research trajectories. First, the basic concepts and developmenthistory are reviewed, and their evolution is divided into two stages: recentmachine learning and current deep learning, emphasizing the importance of eachstage in the research state of human-computer interaction for brain-inspiredcomputing. In addition, the latest progress and key techniques of deep learningin different tasks of human-computer interaction for brain-inspired computingare introduced from six perspectives. Despite significant progress, challengesremain in making full use of its capabilities. This paper aims to provide acomprehensive review of human-computer interaction for brain-inspired computingmodels based on machine learning and deep learning, highlighting theirpotential in various applications and providing a valuable reference for futureacademic research. It can be accessed through the following url:https://github.com/ultracoolHub/brain-inspired-computing</description><author>Bihui Yu, Sibo Zhang, Lili Zhou, Jingxuan Wei, Linzhuang Sun, Liping Bu</author><pubDate>Wed, 10 Jan 2024 13:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07213v2</guid></item><item><title>Derm-T2IM: Harnessing Synthetic Skin Lesion Data via Stable Diffusion Models for Enhanced Skin Disease Classification using ViT and CNN</title><link>http://arxiv.org/abs/2401.05159v1</link><description>This study explores the utilization of Dermatoscopic synthetic data generatedthrough stable diffusion models as a strategy for enhancing the robustness ofmachine learning model training. Synthetic data generation plays a pivotal rolein mitigating challenges associated with limited labeled datasets, therebyfacilitating more effective model training. In this context, we aim toincorporate enhanced data transformation techniques by extending the recentsuccess of few-shot learning and a small amount of data representation intext-to-image latent diffusion models. The optimally tuned model is furtherused for rendering high-quality skin lesion synthetic data with diverse andrealistic characteristics, providing a valuable supplement and diversity to theexisting training data. We investigate the impact of incorporating newlygenerated synthetic data into the training pipeline of state-of-art machinelearning models, assessing its effectiveness in enhancing model performance andgeneralization to unseen real-world data. Our experimental results demonstratethe efficacy of the synthetic data generated through stable diffusion modelshelps in improving the robustness and adaptability of end-to-end CNN and visiontransformer models on two different real-world skin lesion datasets.</description><author>Muhammad Ali Farooq, Wang Yao, Michael Schukat, Mark A Little, Peter Corcoran</author><pubDate>Wed, 10 Jan 2024 13:46:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05159v1</guid></item><item><title>Toward distortion-aware change detection in realistic scenarios</title><link>http://arxiv.org/abs/2401.05157v1</link><description>In the conventional change detection (CD) pipeline, two manually registeredand labeled remote sensing datasets serve as the input of the model fortraining and prediction. However, in realistic scenarios, data from differentperiods or sensors could fail to be aligned as a result of various coordinatesystems. Geometric distortion caused by coordinate shifting remains a thornyissue for CD algorithms. In this paper, we propose a reusable self-supervisedframework for bitemporal geometric distortion in CD tasks. The whole frameworkis composed of Pretext Representation Pre-training, Bitemporal Image Alignment,and Down-stream Decoder Fine-Tuning. With only single-stage pre-training, thekey components of the framework can be reused for assistance in the bitemporalimage alignment, while simultaneously enhancing the performance of the CDdecoder. Experimental results in 2 large-scale realistic scenarios demonstratethat our proposed method can alleviate the bitemporal geometric distortion inCD tasks.</description><author>Yitao Zhao, Heng-Chao Li, Nanqing Liu, Rui Wang</author><pubDate>Wed, 10 Jan 2024 13:43:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05157v1</guid></item><item><title>DualFL: A Duality-based Federated Learning Algorithm with Communication Acceleration in the General Convex Regime</title><link>http://arxiv.org/abs/2305.10294v2</link><description>We propose a new training algorithm, named DualFL (Dualized FederatedLearning), for solving distributed optimization problems in federated learning.DualFL achieves communication acceleration for very general convex costfunctions, thereby providing a solution to an open theoretical problem infederated learning concerning cost functions that may not be smooth norstrongly convex. We provide a detailed analysis for the local iterationcomplexity of DualFL to ensure the overall computational efficiency of DualFL.Furthermore, we introduce a completely new approach for the convergenceanalysis of federated learning based on a dual formulation. This new techniqueenables concise and elegant analysis, which contrasts the complex calculationsused in existing literature on convergence of federated learning algorithms.</description><author>Jongho Park, Jinchao Xu</author><pubDate>Wed, 10 Jan 2024 13:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10294v2</guid></item><item><title>CrossDiff: Exploring Self-Supervised Representation of Pansharpening via Cross-Predictive Diffusion Model</title><link>http://arxiv.org/abs/2401.05153v1</link><description>Fusion of a panchromatic (PAN) image and corresponding multispectral (MS)image is also known as pansharpening, which aims to combine abundant spatialdetails of PAN and spectral information of MS. Due to the absence ofhigh-resolution MS images, available deep-learning-based methods usually followthe paradigm of training at reduced resolution and testing at both reduced andfull resolution. When taking original MS and PAN images as inputs, they alwaysobtain sub-optimal results due to the scale variation. In this paper, wepropose to explore the self-supervised representation of pansharpening bydesigning a cross-predictive diffusion model, named CrossDiff. It has two-stagetraining. In the first stage, we introduce a cross-predictive pretext task topre-train the UNet structure based on conditional DDPM, while in the secondstage, the encoders of the UNets are frozen to directly extract spatial andspectral features from PAN and MS, and only the fusion head is trained to adaptfor pansharpening task. Extensive experiments show the effectiveness andsuperiority of the proposed model compared with state-of-the-art supervised andunsupervised methods. Besides, the cross-sensor experiments also verify thegeneralization ability of proposed self-supervised representation learners forother satellite's datasets. We will release our code for reproducibility.</description><author>Yinghui Xing, Litao Qu, ShiZhou Zhang, Xiuwei Zhang, Yanning Zhang</author><pubDate>Wed, 10 Jan 2024 13:32:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05153v1</guid></item><item><title>Federated Unlearning: A Survey on Methods, Design Guidelines, and Evaluation Metrics</title><link>http://arxiv.org/abs/2401.05146v1</link><description>Federated Learning (FL) enables collaborative training of a Machine Learning(ML) model across multiple parties, facilitating the preservation of users' andinstitutions' privacy by keeping data stored locally. Instead of centralizingraw data, FL exchanges locally refined model parameters to build a global modelincrementally. While FL is more compliant with emerging regulations such as theEuropean General Data Protection Regulation (GDPR), ensuring the right to beforgotten in this context - allowing FL participants to remove their datacontributions from the learned model - remains unclear. In addition, it isrecognized that malicious clients may inject backdoors into the global modelthrough updates, e.g. to generate mispredictions on specially crafted dataexamples. Consequently, there is the need for mechanisms that can guaranteeindividuals the possibility to remove their data and erase maliciouscontributions even after aggregation, without compromising the already acquired"good" knowledge. This highlights the necessity for novel Federated Unlearning(FU) algorithms, which can efficiently remove specific clients' contributionswithout full model retraining. This survey provides background concepts,empirical evidence, and practical guidelines to design/implement efficient FUschemes. Our study includes a detailed analysis of the metrics for evaluatingunlearning in FL and presents an in-depth literature review categorizingstate-of-the-art FU contributions under a novel taxonomy. Finally, we outlinethe most relevant and still open technical challenges, by identifying the mostpromising research directions in the field.</description><author>Nicol√≤ Romandini, Alessio Mora, Carlo Mazzocca, Rebecca Montanari, Paolo Bellavista</author><pubDate>Wed, 10 Jan 2024 13:26:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05146v1</guid></item><item><title>LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack</title><link>http://arxiv.org/abs/2308.00319v2</link><description>Natural language processing models are vulnerable to adversarial examples.Previous textual adversarial attacks adopt gradients or confidence scores tocalculate word importance ranking and generate adversarial examples. However,this information is unavailable in the real world. Therefore, we focus on amore realistic and challenging setting, named hard-label attack, in which theattacker can only query the model and obtain a discrete prediction label.Existing hard-label attack algorithms tend to initialize adversarial examplesby random substitution and then utilize complex heuristic algorithms tooptimize the adversarial perturbation. These methods require a lot of modelqueries and the attack success rate is restricted by adversary initialization.In this paper, we propose a novel hard-label attack algorithm named LimeAttack,which leverages a local explainable method to approximate word importanceranking, and then adopts beam search to find the optimal solution. Extensiveexperiments show that LimeAttack achieves the better attacking performancecompared with existing hard-label attack under the same query budget. Inaddition, we evaluate the effectiveness of LimeAttack on large language models,and results indicate that adversarial examples remain a significant threat tolarge language models. The adversarial examples crafted by LimeAttack arehighly transferable and effectively improve model robustness in adversarialtraining.</description><author>Hai Zhu, Zhaoqing Yang, Weiwei Shang, Yuren Wu</author><pubDate>Wed, 10 Jan 2024 13:26:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00319v2</guid></item><item><title>Machine Learning to Promote Translational Research: Predicting Patent and Clinical Trial Inclusion in Dementia Research</title><link>http://arxiv.org/abs/2401.05145v1</link><description>Projected to impact 1.6 million people in the UK by 2040 and costing{\pounds}25 billion annually, dementia presents a growing challenge to society.This study, a pioneering effort to predict the translational potential ofdementia research using machine learning, hopes to address the slow translationof fundamental discoveries into practical applications despite dementia'ssignificant societal and economic impact. We used the Dimensions database toextract data from 43,091 UK dementia research publications between the years1990-2023, specifically metadata (authors, publication year etc.), conceptsmentioned in the paper, and the paper abstract. To prepare the data for machinelearning we applied methods such as one hot encoding and/or word embeddings. Wetrained a CatBoost Classifier to predict if a publication will be cited in afuture patent or clinical trial. We trained several model variations. The modelcombining metadata, concept, and abstract embeddings yielded the highestperformance: for patent predictions, an Area Under the Receiver OperatingCharacteristic Curve (AUROC) of 0.84 and 77.17% accuracy; for clinical trialpredictions, an AUROC of 0.81 and 75.11% accuracy. The results demonstrate thatintegrating machine learning within current research methodologies can uncoveroverlooked publications, expediting the identification of promising researchand potentially transforming dementia research by predicting real-world impactand guiding translational strategies.</description><author>Matilda Beinat, Julian Beinat, Mohammed Shoaib, Jorge Gomez Magenti</author><pubDate>Wed, 10 Jan 2024 13:25:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05145v1</guid></item><item><title>DISCOVER: 2-D Multiview Summarization of Optical Coherence Tomography Angiography for Automatic Diabetic Retinopathy Diagnosis</title><link>http://arxiv.org/abs/2401.05137v1</link><description>Diabetic Retinopathy (DR), an ocular complication of diabetes, is a leadingcause of blindness worldwide. Traditionally, DR is monitored using Color FundusPhotography (CFP), a widespread 2-D imaging modality. However, DRclassifications based on CFP have poor predictive power, resulting insuboptimal DR management. Optical Coherence Tomography Angiography (OCTA) is arecent 3-D imaging modality offering enhanced structural and functionalinformation (blood flow) with a wider field of view. This paper investigatesautomatic DR severity assessment using 3-D OCTA. A straightforward solution tothis task is a 3-D neural network classifier. However, 3-D architectures havenumerous parameters and typically require many training samples. A lightersolution consists in using 2-D neural network classifiers processing 2-Den-face (or frontal) projections and/or 2-D cross-sectional slices. Such anapproach mimics the way ophthalmologists analyze OCTA acquisitions: 1) en-faceflow maps are often used to detect avascular zones and neovascularization, and2) cross-sectional slices are commonly analyzed to detect macular edemas, forinstance. However, arbitrary data reduction or selection might result ininformation loss. Two complementary strategies are thus proposed to optimallysummarize OCTA volumes with 2-D images: 1) a parametric en-face projectionoptimized through deep learning and 2) a cross-sectional slice selectionprocess controlled through gradient-based attribution. The full summarizationand DR classification pipeline is trained from end to end. The automatic 2-Dsummary can be displayed in a viewer or printed in a report to support thedecision. We show that the proposed 2-D summarization and classificationpipeline outperforms direct 3-D classification with the advantage of improvedinterpretability.</description><author>Mostafa El Habib Daho, Yihao Li, Rachid Zeghlache, Hugo Le Boit√©, Pierre Deman, Laurent Borderie, Hugang Ren, Niranchana Mannivanan, Capucine Lepicard, B√©atrice Cochener, Aude Couturier, Ramin Tadayoni, Pierre-Henri Conze, Mathieu Lamard, Gwenol√© Quellec</author><pubDate>Wed, 10 Jan 2024 13:06:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05137v1</guid></item><item><title>Deep learning in medical image registration: introduction and survey</title><link>http://arxiv.org/abs/2309.00727v2</link><description>Image registration (IR) is a process that deforms images to align them withrespect to a reference space, making it easier for medical practitioners toexamine various medical images in a standardized reference frame, such ashaving the same rotation and scale. This document introduces image registrationusing a simple numeric example. It provides a definition of image registrationalong with a space-oriented symbolic representation. This review covers variousaspects of image transformations, including affine, deformable, invertible, andbidirectional transformations, as well as medical image registration algorithmssuch as Voxelmorph, Demons, SyN, Iterative Closest Point, and SynthMorph. Italso explores atlas-based registration and multistage image registrationtechniques, including coarse-fine and pyramid approaches. Furthermore, thissurvey paper discusses medical image registration taxonomies, datasets,evaluation measures, such as correlation-based metrics, segmentation-basedmetrics, processing time, and model size. It also explores applications inimage-guided surgery, motion tracking, and tumor diagnosis. Finally, thedocument addresses future research directions, including the furtherdevelopment of transformers.</description><author>Ahmad Hammoudeh, St√©phane Dupont</author><pubDate>Wed, 10 Jan 2024 13:01:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00727v2</guid></item><item><title>SemPPL: Predicting pseudo-labels for better contrastive representations</title><link>http://arxiv.org/abs/2301.05158v2</link><description>Learning from large amounts of unsupervised data and a small amount ofsupervision is an important open problem in computer vision. We propose a newsemi-supervised learning method, Semantic Positives via Pseudo-Labels (SemPPL),that combines labelled and unlabelled data to learn informativerepresentations. Our method extends self-supervised contrastive learning --where representations are shaped by distinguishing whether two samplesrepresent the same underlying datum (positives) or not (negatives) -- with anovel approach to selecting positives. To enrich the set of positives, weleverage the few existing ground-truth labels to predict the missing onesthrough a $k$-nearest neighbours classifier by using the learned embeddings ofthe labelled data. We thus extend the set of positives with datapoints havingthe same pseudo-label and call these semantic positives. We jointly learn therepresentation and predict bootstrapped pseudo-labels. This creates areinforcing cycle. Strong initial representations enable better pseudo-labelpredictions which then improve the selection of semantic positives and lead toeven better representations. SemPPL outperforms competing semi-supervisedmethods setting new state-of-the-art performance of $68.5\%$ and $76\%$ top-$1$accuracy when using a ResNet-$50$ and training on $1\%$ and $10\%$ of labels onImageNet, respectively. Furthermore, when using selective kernels, SemPPLsignificantly outperforms previous state-of-the-art achieving $72.3\%$ and$78.3\%$ top-$1$ accuracy on ImageNet with $1\%$ and $10\%$ labels,respectively, which improves absolute $+7.8\%$ and $+6.2\%$ over previous work.SemPPL also exhibits state-of-the-art performance over larger ResNet models aswell as strong robustness, out-of-distribution and transfer performance. Werelease the checkpoints and the evaluation code athttps://github.com/deepmind/semppl .</description><author>Matko Bo≈°njak, Pierre H. Richemond, Nenad Tomasev, Florian Strub, Jacob C. Walker, Felix Hill, Lars Holger Buesing, Razvan Pascanu, Charles Blundell, Jovana Mitrovic</author><pubDate>Wed, 10 Jan 2024 13:00:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.05158v2</guid></item><item><title>Yes, this is what I was looking for! Towards Multi-modal Medical Consultation Concern Summary Generation</title><link>http://arxiv.org/abs/2401.05134v1</link><description>Over the past few years, the use of the Internet for healthcare-related taskshas grown by leaps and bounds, posing a challenge in effectively managing andprocessing information to ensure its efficient utilization. During moments ofemotional turmoil and psychological challenges, we frequently turn to theinternet as our initial source of support, choosing this over discussing ourfeelings with others due to the associated social stigma. In this paper, wepropose a new task of multi-modal medical concern summary (MMCS) generation,which provides a short and precise summary of patients' major concerns broughtup during the consultation. Nonverbal cues, such as patients' gestures andfacial expressions, aid in accurately identifying patients' concerns. Doctorsalso consider patients' personal information, such as age and gender, in orderto describe the medical condition appropriately. Motivated by the potentialefficacy of patients' personal context and visual gestures, we propose atransformer-based multi-task, multi-modal intent-recognition, and medicalconcern summary generation (IR-MMCSG) system. Furthermore, we propose amultitasking framework for intent recognition and medical concern summarygeneration for doctor-patient consultations. We construct the first multi-modalmedical concern summary generation (MM-MediConSummation) corpus, which includespatient-doctor consultations annotated with medical concern summaries, intents,patient personal information, doctor's recommendations, and keywords. Ourexperiments and analysis demonstrate (a) the significant role of patients'expressions/gestures and their personal information in intent identificationand medical concern summary generation, and (b) the strong correlation betweenintent recognition and patients' medical concern summary generation The dataset and source code are available at https://github.com/NLP-RL/MMCSG.</description><author>Abhisek Tiwari, Shreyangshu Bera, Sriparna Saha, Pushpak Bhattacharyya, Samrat Ghosh</author><pubDate>Wed, 10 Jan 2024 12:56:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05134v1</guid></item><item><title>Neural Population Learning beyond Symmetric Zero-sum Games</title><link>http://arxiv.org/abs/2401.05133v1</link><description>We study computationally efficient methods for finding equilibria in n-playergeneral-sum games, specifically ones that afford complex visuomotor skills. Weshow how existing methods would struggle in this setting, eithercomputationally or in theory. We then introduce NeuPL-JPSRO, a neuralpopulation learning algorithm that benefits from transfer learning of skillsand converges to a Coarse Correlated Equilibrium (CCE) of the game. We showempirical convergence in a suite of OpenSpiel games, validated rigorously byexact game solvers. We then deploy NeuPL-JPSRO to complex domains, where ourapproach enables adaptive coordination in a MuJoCo control domain and skilltransfer in capture-the-flag. Our work shows that equilibrium convergentpopulation learning can be implemented at scale and in generality, paving theway towards solving real-world games between heterogeneous players with mixedmotives.</description><author>Siqi Liu, Luke Marris, Marc Lanctot, Georgios Piliouras, Joel Z. Leibo, Nicolas Heess</author><pubDate>Wed, 10 Jan 2024 12:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05133v1</guid></item><item><title>Efficient Fine-Tuning with Domain Adaptation for Privacy-Preserving Vision Transformer</title><link>http://arxiv.org/abs/2401.05126v1</link><description>We propose a novel method for privacy-preserving deep neural networks (DNNs)with the Vision Transformer (ViT). The method allows us not only to trainmodels and test with visually protected images but to also avoid theperformance degradation caused from the use of encrypted images, whereasconventional methods cannot avoid the influence of image encryption. A domainadaptation method is used to efficiently fine-tune ViT with encrypted images.In experiments, the method is demonstrated to outperform conventional methodsin an image classification task on the CIFAR-10 and ImageNet datasets in termsof classification accuracy.</description><author>Teru Nagamori, Sayaka Shiota, Hitoshi Kiya</author><pubDate>Wed, 10 Jan 2024 12:46:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05126v1</guid></item><item><title>BELHD: Improving Biomedical Entity Linking with Homonoym Disambiguation</title><link>http://arxiv.org/abs/2401.05125v1</link><description>Biomedical entity linking (BEL) is the task of grounding entity mentions to aknowledge base (KB). A popular approach to the task are name-based methods,i.e. those identifying the most appropriate name in the KB for a given mention,either via dense retrieval or autoregressive modeling. However, as thesemethods directly return KB names, they cannot cope with homonyms, i.e.different KB entities sharing the exact same name. This significantly affectstheir performance, especially for KBs where homonyms account for a large amountof entity mentions (e.g. UMLS and NCBI Gene). We therefore present BELHD(Biomedical Entity Linking with Homonym Disambiguation), a new name-basedmethod that copes with this challenge. Specifically, BELHD builds upon theBioSyn (Sung et al.,2020) model introducing two crucial extensions. First, itperforms a preprocessing of the KB in which it expands homonyms with anautomatically chosen disambiguating string, thus enforcing unique linkingdecisions. Second, we introduce candidate sharing, a novel strategy to selectcandidates for contrastive learning that enhances the overall training signal.Experiments with 10 corpora and five entity types show that BELHD improves uponstate-of-the-art approaches, achieving the best results in 6 out 10 corporawith an average improvement of 4.55pp recall@1. Furthermore, the KBpreprocessing is orthogonal to the core prediction model and thus can alsoimprove other methods, which we exemplify for GenBioEL (Yuan et al, 2022), agenerative name-based BEL approach. Code is available at: link added uponpublication.</description><author>Samuele Garda, Ulf Leser</author><pubDate>Wed, 10 Jan 2024 12:45:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05125v1</guid></item><item><title>RaTrack: Moving Object Detection and Tracking with 4D Radar Point Cloud</title><link>http://arxiv.org/abs/2309.09737v3</link><description>Mobile autonomy relies on the precise perception of dynamic environments.Robustly tracking moving objects in 3D world thus plays a pivotal role forapplications like trajectory prediction, obstacle avoidance, and path planning.While most current methods utilize LiDARs or cameras for Multiple ObjectTracking (MOT), the capabilities of 4D imaging radars remain largelyunexplored. Recognizing the challenges posed by radar noise and point sparsityin 4D radar data, we introduce RaTrack, an innovative solution tailored forradar-based tracking. Bypassing the typical reliance on specific object typesand 3D bounding boxes, our method focuses on motion segmentation andclustering, enriched by a motion estimation module. Evaluated on theView-of-Delft dataset, RaTrack showcases superior tracking precision of movingobjects, largely surpassing the performance of the state of the art.</description><author>Zhijun Pan, Fangqiang Ding, Hantao Zhong, Chris Xiaoxuan Lu</author><pubDate>Wed, 10 Jan 2024 12:44:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09737v3</guid></item><item><title>Photonics for Sustainable Computing</title><link>http://arxiv.org/abs/2401.05121v1</link><description>Photonic integrated circuits are finding use in a variety of applicationsincluding optical transceivers, LIDAR, bio-sensing, photonic quantum computing,and Machine Learning (ML). In particular, with the exponentially increasingsizes of ML models, photonics-based accelerators are getting special attentionas a sustainable solution because they can perform ML inferences with multipleorders of magnitude higher energy efficiency than CMOS-based accelerators.However, recent studies have shown that hardware manufacturing andinfrastructure contribute significantly to the carbon footprint of computingdevices, even surpassing the emissions generated during their use. For example,the manufacturing process accounts for 74% of the total carbon emissions fromApple in 2019. This prompts us to ask -- if we consider both the embodied(manufacturing) and operational carbon cost of photonics, is it indeed a viableavenue for a sustainable future? So, in this paper, we build a carbon footprintmodel for photonic chips and investigate the sustainability of photonics-basedaccelerators by conducting a case study on ADEPT, a photonics-based acceleratorfor deep neural network inference. Our analysis shows that photonics can reduceboth operational and embodied carbon footprints with its high energy efficiencyand at least 4$\times$ less fabrication carbon cost per unit area than 28 nmCMOS.</description><author>Farbin Fayza, Satyavolu Papa Rao, Darius Bunandar, Udit Gupta, Ajay Joshi</author><pubDate>Wed, 10 Jan 2024 12:37:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05121v1</guid></item><item><title>DC-Net: Divide-and-Conquer for Salient Object Detection</title><link>http://arxiv.org/abs/2305.14955v3</link><description>In this paper, we introduce Divide-and-Conquer into the salient objectdetection (SOD) task to enable the model to learn prior knowledge that is forpredicting the saliency map. We design a novel network, Divide-and-ConquerNetwork (DC-Net) which uses two encoders to solve different subtasks that areconducive to predicting the final saliency map, here is to predict the edgemaps with width 4 and location maps of salient objects and then aggregate thefeature maps with different semantic information into the decoder to predictthe final saliency map. The decoder of DC-Net consists of our newly designedtwo-level Residual nested-ASPP (ResASPP$^{2}$) modules, which have the abilityto capture a large number of different scale features with a small number ofconvolution operations and have the advantages of maintaining high resolutionall the time and being able to obtain a large and compact effective receptivefield (ERF). Based on the advantage of Divide-and-Conquer's parallel computing,we use Parallel Acceleration to speed up DC-Net, allowing it to achievecompetitive performance on six LR-SOD and five HR-SOD datasets under highefficiency (60 FPS and 55 FPS). Codes and results are available:https://github.com/PiggyJerry/DC-Net.</description><author>Jiayi Zhu, Xuebin Qin, Abdulmotaleb Elsaddik</author><pubDate>Wed, 10 Jan 2024 12:35:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14955v3</guid></item><item><title>Agent Alignment in Evolving Social Norms</title><link>http://arxiv.org/abs/2401.04620v2</link><description>Agents based on Large Language Models (LLMs) are increasingly permeatingvarious domains of human production and life, highlighting the importance ofaligning them with human values. The current alignment of AI systems primarilyfocuses on passively aligning LLMs through human intervention. However, agentspossess characteristics like receiving environmental feedback andself-evolution, rendering the LLM alignment methods inadequate. In response, wepropose an evolutionary framework for agent evolution and alignment, namedEvolutionaryAgent, which transforms agent alignment into a process of evolutionand selection under the principle of survival of the fittest. In an environmentwhere social norms continuously evolve, agents better adapted to the currentsocial norms will have a higher probability of survival and proliferation,while those inadequately aligned dwindle over time. Experimental resultsassessing the agents from multiple perspectives in aligning with social normsdemonstrate that EvolutionaryAgent possesses the capability to alignprogressively better with the evolving social norms while maintaining itsproficiency in general tasks. Effectiveness tests conducted on various open andclosed-source LLMs as the foundation for agents also prove the applicability ofour approach.</description><author>Shimin Li, Tianxiang Sun, Xipeng Qiu</author><pubDate>Wed, 10 Jan 2024 12:30:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04620v2</guid></item><item><title>Unpacking Human-AI interactions: From interaction primitives to a design space</title><link>http://arxiv.org/abs/2401.05115v1</link><description>This paper aims to develop a semi-formal design space for Human-AIinteractions, by building a set of interaction primitives which specify thecommunication between users and AI systems during their interaction. We showhow these primitives can be combined into a set of interaction patterns whichcan provide an abstract specification for exchanging messages between humansand AI/ML models to carry out purposeful interactions. The motivation behindthis is twofold: firstly, to provide a compact generalisation of existingpractices, that highlights the similarities and differences between systems interms of their interaction behaviours; and secondly, to support the creation ofnew systems, in particular by opening the space of possibilities forinteractions with models. We present a short literature review on frameworks,guidelines and taxonomies related to the design and implementation of HAIinteractions, including human-in-the-loop, explainable AI, as well as hybridintelligence and collaborative learning approaches. From the literature review,we define a vocabulary for describing information exchanges in terms ofproviding and requesting particular model-specific data types. Based on thisvocabulary, a message passing model for interactions between humans and modelsis presented, which we demonstrate can account for existing systems andapproaches. Finally, we build this into design patterns as mid-level constructsthat capture common interactional structures. We discuss how this approach canbe used towards a design space for Human-AI interactions that creates newpossibilities for designs as well as keeping track of implementation issues andconcerns.</description><author>Kostas Tsiakas, Dave Murray-Rust</author><pubDate>Wed, 10 Jan 2024 12:27:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05115v1</guid></item><item><title>A Theoretical View of Linear Backpropagation and Its Convergence</title><link>http://arxiv.org/abs/2112.11018v2</link><description>Backpropagation (BP) is widely used for calculating gradients in deep neuralnetworks (DNNs). Applied often along with stochastic gradient descent (SGD) orits variants, BP is considered as a de-facto choice in a variety of machinelearning tasks including DNN training and adversarial attack/defense. Recently,a linear variant of BP named LinBP was introduced for generating moretransferable adversarial examples for performing black-box attacks, by Guo etal. Although it has been shown empirically effective in black-box attacks,theoretical studies and convergence analyses of such a method is lacking. Thispaper serves as a complement and somewhat an extension to Guo et al.'s paper,by providing theoretical analyses on LinBP in neural-network-involved learningtasks, including adversarial attack and model training. We demonstrate that,somewhat surprisingly, LinBP can lead to faster convergence in these tasks inthe same hyper-parameter settings, compared to BP. We confirm our theoreticalresults with extensive experiments.</description><author>Ziang Li, Yiwen Guo, Haodi Liu, Changshui Zhang</author><pubDate>Wed, 10 Jan 2024 12:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.11018v2</guid></item><item><title>Noise-robust zero-shot text-to-speech synthesis conditioned on self-supervised speech-representation model with adapters</title><link>http://arxiv.org/abs/2401.05111v1</link><description>The zero-shot text-to-speech (TTS) method, based on speaker embeddingsextracted from reference speech using self-supervised learning (SSL) speechrepresentations, can reproduce speaker characteristics very accurately.However, this approach suffers from degradation in speech synthesis qualitywhen the reference speech contains noise. In this paper, we propose anoise-robust zero-shot TTS method. We incorporated adapters into the SSL model,which we fine-tuned with the TTS model using noisy reference speech. Inaddition, to further improve performance, we adopted a speech enhancement (SE)front-end. With these improvements, our proposed SSL-based zero-shot TTSachieved high-quality speech synthesis with noisy reference speech. Through theobjective and subjective evaluations, we confirmed that the proposed method ishighly robust to noise in reference speech, and effectively works incombination with SE.</description><author>Kenichi Fujita, Hiroshi Sato, Takanori Ashihara, Hiroki Kanagawa, Marc Delcroix, Takafumi Moriya, Yusuke Ijima</author><pubDate>Wed, 10 Jan 2024 12:21:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05111v1</guid></item><item><title>Actor-agnostic Multi-label Action Recognition with Multi-modal Query</title><link>http://arxiv.org/abs/2307.10763v3</link><description>Existing action recognition methods are typically actor-specific due to theintrinsic topological and apparent differences among the actors. This requiresactor-specific pose estimation (e.g., humans vs. animals), leading tocumbersome model design complexity and high maintenance costs. Moreover, theyoften focus on learning the visual modality alone and single-labelclassification whilst neglecting other available information sources (e.g.,class name text) and the concurrent occurrence of multiple actions. To overcomethese limitations, we propose a new approach called 'actor-agnostic multi-modalmulti-label action recognition,' which offers a unified solution for varioustypes of actors, including humans and animals. We further formulate a novelMulti-modal Semantic Query Network (MSQNet) model in a transformer-based objectdetection framework (e.g., DETR), characterized by leveraging visual andtextual modalities to represent the action classes better. The elimination ofactor-specific model designs is a key advantage, as it removes the need foractor pose estimation altogether. Extensive experiments on five publiclyavailable benchmarks show that our MSQNet consistently outperforms the priorarts of actor-specific alternatives on human and animal single- and multi-labelaction recognition tasks by up to 50%. Code is made available athttps://github.com/mondalanindya/MSQNet.</description><author>Anindya Mondal, Sauradip Nag, Joaquin M Prada, Xiatian Zhu, Anjan Dutta</author><pubDate>Wed, 10 Jan 2024 12:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10763v3</guid></item></channel></rss>