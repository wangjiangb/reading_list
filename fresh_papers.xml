<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 14 Jul 2024 13:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding</title><link>http://arxiv.org/abs/2306.06094v2</link><description>Large language models (LLMs) have made significant advancements in naturallanguage understanding. However, through that enormous semantic representationthat the LLM has learnt, is it somehow possible for it to understand images aswell? This work investigates this question. To enable the LLM to processimages, we convert them into a representation given by Scalable Vector Graphics(SVG). To study what the LLM can do with this XML-based textual description ofimages, we test the LLM on three broad computer vision tasks: (i) visualreasoning and question answering, (ii) image classification under distributionshift, few-shot learning, and (iii) generating new images using visualprompting. Even though we do not naturally associate LLMs with any visualunderstanding capabilities, our results indicate that the LLM can often do adecent job in many of these tasks, potentially opening new avenues for researchinto LLMs' ability to understand image data. Our code, data, and models can befound here https://github.com/mu-cai/svg-llm.</description><author>Mu Cai, Zeyi Huang, Yuheng Li, Utkarsh Ojha, Haohan Wang, Yong Jae Lee</author><pubDate>Thu, 11 Jul 2024 17:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06094v2</guid></item><item><title>MAVIS: Mathematical Visual Instruction Tuning</title><link>http://arxiv.org/abs/2407.08739v1</link><description>Multi-modal Large Language Models (MLLMs) have recently emerged as asignificant focus in academia and industry. Despite their proficiency ingeneral multi-modal scenarios, the mathematical problem-solving capabilities invisual contexts remain insufficiently explored. We identify three key areaswithin MLLMs that need to be improved: visual encoding of math diagrams,diagram-language alignment, and mathematical reasoning skills. This draws forthan urgent demand for large-scale, high-quality data and training pipelines invisual mathematics. In this paper, we propose MAVIS, the first MAthematicalVISual instruction tuning paradigm for MLLMs, involving a series ofmathematical visual datasets and specialized MLLMs. Targeting the three issues,MAVIS contains three progressive training stages from scratch. First, we curateMAVIS-Caption, consisting of 558K diagram-caption pairs, to fine-tune amath-specific vision encoder (CLIP-Math) through contrastive learning, tailoredfor improved diagram visual encoding. Second, we utilize MAVIS-Caption to alignthe CLIP-Math with a large language model (LLM) by a projection layer,enhancing vision-language alignment in mathematical domains. Third, weintroduce MAVIS-Instruct, including 900K meticulously collected and annotatedvisual math problems, which is adopted to finally instruct-tune the MLLM forrobust mathematical reasoning skills. In MAVIS-Instruct, we incorporatecomplete chain-of-thought (CoT) rationales for each problem, and minimizetextual redundancy, thereby concentrating the model towards the visualelements. Data and Models are released at https://github.com/ZrrSkywalker/MAVIS</description><author>Renrui Zhang, Xinyu Wei, Dongzhi Jiang, Yichi Zhang, Ziyu Guo, Chengzhuo Tong, Jiaming Liu, Aojun Zhou, Bin Wei, Shanghang Zhang, Peng Gao, Hongsheng Li</author><pubDate>Thu, 11 Jul 2024 17:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08739v1</guid></item><item><title>Video Diffusion Alignment via Reward Gradients</title><link>http://arxiv.org/abs/2407.08737v1</link><description>We have made significant progress towards building foundational videodiffusion models. As these models are trained using large-scale unsuperviseddata, it has become crucial to adapt these models to specific downstream tasks.Adapting these models via supervised fine-tuning requires collecting targetdatasets of videos, which is challenging and tedious. In this work, we utilizepre-trained reward models that are learned via preferences on top of powerfulvision discriminative models to adapt video diffusion models. These modelscontain dense gradient information with respect to generated RGB pixels, whichis critical to efficient learning in complex search spaces, such as videos. Weshow that backpropagating gradients from these reward models to a videodiffusion model can allow for compute and sample efficient alignment of thevideo diffusion model. We show results across a variety of reward models andvideo diffusion models, demonstrating that our approach can learn much moreefficiently in terms of reward queries and computation than prior gradient-freeapproaches. Our code, model weights,and more visualization are available athttps://vader-vid.github.io.</description><author>Mihir Prabhudesai, Russell Mendonca, Zheyang Qin, Katerina Fragkiadaki, Deepak Pathak</author><pubDate>Thu, 11 Jul 2024 17:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08737v1</guid></item><item><title>Real-Time Anomaly Detection and Reactive Planning with Large Language Models</title><link>http://arxiv.org/abs/2407.08735v1</link><description>Foundation models, e.g., large language models (LLMs), trained oninternet-scale data possess zero-shot generalization capabilities that makethem a promising technology towards detecting and mitigatingout-of-distribution failure modes of robotic systems. Fully realizing thispromise, however, poses two challenges: (i) mitigating the considerablecomputational expense of these models such that they may be applied online, and(ii) incorporating their judgement regarding potential anomalies into a safecontrol framework. In this work, we present a two-stage reasoning framework:First is a fast binary anomaly classifier that analyzes observations in an LLMembedding space, which may then trigger a slower fallback selection stage thatutilizes the reasoning capabilities of generative LLMs. These stages correspondto branch points in a model predictive control strategy that maintains thejoint feasibility of continuing along various fallback plans to account for theslow reasoner's latency as soon as an anomaly is detected, thus ensuringsafety. We show that our fast anomaly classifier outperforms autoregressivereasoning with state-of-the-art GPT models, even when instantiated withrelatively small language models. This enables our runtime monitor to improvethe trustworthiness of dynamic robotic systems, such as quadrotors orautonomous vehicles, under resource and time constraints. Videos illustratingour approach in both simulation and real-world experiments are available onthis project page: https://sites.google.com/view/aesop-llm.</description><author>Rohan Sinha, Amine Elhafsi, Christopher Agia, Matthew Foutter, Edward Schmerling, Marco Pavone</author><pubDate>Thu, 11 Jul 2024 17:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08735v1</guid></item><item><title>Transformer Circuit Faithfulness Metrics are not Robust</title><link>http://arxiv.org/abs/2407.08734v1</link><description>Mechanistic interpretability work attempts to reverse engineer the learnedalgorithms present inside neural networks. One focus of this work has been todiscover 'circuits' -- subgraphs of the full model that explain behaviour onspecific tasks. But how do we measure the performance of such circuits? Priorwork has attempted to measure circuit 'faithfulness' -- the degree to which thecircuit replicates the performance of the full model. In this work, we surveymany considerations for designing experiments that measure circuit faithfulnessby ablating portions of the model's computation. Concerningly, we find existingmethods are highly sensitive to seemingly insignificant changes in the ablationmethodology. We conclude that existing circuit faithfulness scores reflect boththe methodological choices of researchers as well as the actual components ofthe circuit - the task a circuit is required to perform depends on the ablationused to test it. The ultimate goal of mechanistic interpretability work is tounderstand neural networks, so we emphasize the need for more clarity in theprecise claims being made about circuits. We open source a library athttps://github.com/UFO-101/auto-circuit that includes highly efficientimplementations of a wide range of ablation methodologies and circuit discoveryalgorithms.</description><author>Joseph Miller, Bilal Chughtai, William Saunders</author><pubDate>Thu, 11 Jul 2024 17:59:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08734v1</guid></item><item><title>Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist</title><link>http://arxiv.org/abs/2407.08733v1</link><description>Exceptional mathematical reasoning ability is one of the key features thatdemonstrate the power of large language models (LLMs). How to comprehensivelydefine and evaluate the mathematical abilities of LLMs, and even reflect theuser experience in real-world scenarios, has emerged as a critical issue.Current benchmarks predominantly concentrate on problem-solving capabilities,which presents a substantial risk of model overfitting and fails to accuratelyrepresent genuine mathematical reasoning abilities. In this paper, we arguethat if a model really understands a problem, it should be robustly and readilyapplied across a diverse array of tasks. Motivated by this, we introduceMATHCHECK, a well-designed checklist for testing task generalization andreasoning robustness, as well as an automatic tool to generate checklistsefficiently. MATHCHECK includes multiple mathematical reasoning tasks androbustness test types to facilitate a comprehensive evaluation of bothmathematical reasoning ability and behavior testing. Utilizing MATHCHECK, wedevelop MATHCHECK-GSM and MATHCHECK-GEO to assess mathematical textualreasoning and multi-modal reasoning capabilities, respectively, serving asupgraded versions of benchmarks including GSM8k, GeoQA, UniGeo, and Geometry3K.We adopt MATHCHECK-GSM and MATHCHECK-GEO to evaluate over 20 LLMs and 11 MLLMs,assessing their comprehensive mathematical reasoning abilities. Our resultsdemonstrate that while frontier LLMs like GPT-4o continue to excel in variousabilities on the checklist, many other model families exhibit a significantdecline. Further experiments indicate that, compared to traditional mathbenchmarks, MATHCHECK better reflects true mathematical abilities andrepresents mathematical intelligence more linearly, thereby supporting ourdesign. On our MATHCHECK, we can easily conduct detailed behavior analysis todeeply investigate models.</description><author>Zihao Zhou, Shudong Liu, Maizhen Ning, Wei Liu, Jindong Wang, Derek F. Wong, Xiaowei Huang, Qiufeng Wang, Kaizhu Huang</author><pubDate>Thu, 11 Jul 2024 17:58:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08733v1</guid></item><item><title>Evaluating Deep Neural Networks in Deployment (A Comparative and Replicability Study)</title><link>http://arxiv.org/abs/2407.08730v1</link><description>As deep neural networks (DNNs) are increasingly used in safety-criticalapplications, there is a growing concern for their reliability. Even highlytrained, high-performant networks are not 100% accurate. However, it is verydifficult to predict their behavior during deployment without ground truth. Inthis paper, we provide a comparative and replicability study on recentapproaches that have been proposed to evaluate the reliability of DNNs indeployment. We find that it is hard to run and reproduce the results for theseapproaches on their replication packages and even more difficult to run them onartifacts other than their own. Further, it is difficult to compare theeffectiveness of the approaches, due to the lack of clearly defined evaluationmetrics. Our results indicate that more effort is needed in our researchcommunity to obtain sound techniques for evaluating the reliability of neuralnetworks in safety-critical domains. To this end, we contribute an evaluationframework that incorporates the considered approaches and enables evaluation oncommon benchmarks, using common metrics.</description><author>Eduard Pinconschi, Divya Gopinath, Rui Abreu, Corina S. Pasareanu</author><pubDate>Thu, 11 Jul 2024 17:58:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08730v1</guid></item><item><title>BiEquiFormer: Bi-Equivariant Representations for Global Point Cloud Registration</title><link>http://arxiv.org/abs/2407.08729v1</link><description>The goal of this paper is to address the problem of \textit{global} pointcloud registration (PCR) i.e., finding the optimal alignment between pointclouds irrespective of the initial poses of the scans. This problem isnotoriously challenging for classical optimization methods due to computationalconstraints. First, we show that state-of-the-art deep learning methods sufferfrom huge performance degradation when the point clouds are arbitrarily placedin space. We propose that \textit{equivariant deep learning} should be utilizedfor solving this task and we characterize the specific type of bi-equivarianceof PCR. Then, we design BiEquiformer a novel and scalable\textit{bi-equivariant} pipeline i.e. equivariant to the independenttransformations of the input point clouds. While a naive approach would processthe point clouds independently we design expressive bi-equivariant layers thatfuse the information from both point clouds. This allows us to extracthigh-quality superpoint correspondences and in turn, robust point-cloudregistration. Extensive comparisons against state-of-the-art methods show thatour method achieves comparable performance in the canonical setting andsuperior performance in the robust setting in both the 3DMatch and thechallenging low-overlap 3DLoMatch dataset.</description><author>Stefanos Pertigkiozoglou, Evangelos Chatzipantazis, Kostas Daniilidis</author><pubDate>Thu, 11 Jul 2024 17:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08729v1</guid></item><item><title>Beyond Aesthetics: Cultural Competence in Text-to-Image Models</title><link>http://arxiv.org/abs/2407.06863v2</link><description>Text-to-Image (T2I) models are being increasingly adopted in diverse globalcommunities where they create visual representations of their unique cultures.Current T2I benchmarks primarily focus on faithfulness, aesthetics, and realismof generated images, overlooking the critical dimension of cultural competence.In this work, we introduce a framework to evaluate cultural competence of T2Imodels along two crucial dimensions: cultural awareness and cultural diversity,and present a scalable approach using a combination of structured knowledgebases and large language models to build a large dataset of cultural artifactsto enable this evaluation. In particular, we apply this approach to build CUBE(CUltural BEnchmark for Text-to-Image models), a first-of-its-kind benchmark toevaluate cultural competence of T2I models. CUBE covers cultural artifactsassociated with 8 countries across different geo-cultural regions and along 3concepts: cuisine, landmarks, and art. CUBE consists of 1) CUBE-1K, a set ofhigh-quality prompts that enable the evaluation of cultural awareness, and 2)CUBE-CSpace, a larger dataset of cultural artifacts that serves as grounding toevaluate cultural diversity. We also introduce cultural diversity as a novelT2I evaluation component, leveraging quality-weighted Vendi score. Ourevaluations reveal significant gaps in the cultural awareness of existingmodels across countries and provide valuable insights into the culturaldiversity of T2I outputs for under-specified prompts. Our methodology isextendable to other cultural regions and concepts, and can facilitate thedevelopment of T2I models that better cater to the global population.</description><author>Nithish Kannen, Arif Ahmad, Marco Andreetto, Vinodkumar Prabhakaran, Utsav Prabhu, Adji Bousso Dieng, Pushpak Bhattacharyya, Shachi Dave</author><pubDate>Thu, 11 Jul 2024 17:57:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06863v2</guid></item><item><title>Map It Anywhere (MIA): Empowering Bird's Eye View Mapping using Large-scale Public Data</title><link>http://arxiv.org/abs/2407.08726v1</link><description>Top-down Bird's Eye View (BEV) maps are a popular representation for groundrobot navigation due to their richness and flexibility for downstream tasks.While recent methods have shown promise for predicting BEV maps fromFirst-Person View (FPV) images, their generalizability is limited to smallregions captured by current autonomous vehicle-based datasets. In this context,we show that a more scalable approach towards generalizable map prediction canbe enabled by using two large-scale crowd-sourced mapping platforms, Mapillaryfor FPV images and OpenStreetMap for BEV semantic maps. We introduce Map ItAnywhere (MIA), a data engine that enables seamless curation and modeling oflabeled map prediction data from existing open-source map platforms. Using ourMIA data engine, we display the ease of automatically collecting a dataset of1.2 million pairs of FPV images &amp; BEV maps encompassing diverse geographies,landscapes, environmental factors, camera models &amp; capture scenarios. Wefurther train a simple camera model-agnostic model on this data for BEV mapprediction. Extensive evaluations using established benchmarks and our datasetshow that the data curated by MIA enables effective pretraining forgeneralizable BEV map prediction, with zero-shot performance far exceedingbaselines trained on existing datasets by 35%. Our analysis highlights thepromise of using large-scale public maps for developing &amp; testing generalizableBEV perception, paving the way for more robust autonomous navigation.</description><author>Cherie Ho, Jiaye Zou, Omar Alama, Sai Mitheran Jagadesh Kumar, Benjamin Chiang, Taneesh Gupta, Chen Wang, Nikhil Keetha, Katia Sycara, Sebastian Scherer</author><pubDate>Thu, 11 Jul 2024 17:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08726v1</guid></item><item><title>MetaUrban: A Simulation Platform for Embodied AI in Urban Spaces</title><link>http://arxiv.org/abs/2407.08725v1</link><description>Public urban spaces like streetscapes and plazas serve residents andaccommodate social life in all its vibrant variations. Recent advances inRobotics and Embodied AI make public urban spaces no longer exclusive tohumans. Food delivery bots and electric wheelchairs have started sharingsidewalks with pedestrians, while diverse robot dogs and humanoids haverecently emerged in the street. Ensuring the generalizability and safety ofthese forthcoming mobile machines is crucial when navigating through thebustling streets in urban spaces. In this work, we present MetaUrban, acompositional simulation platform for Embodied AI research in urban spaces.MetaUrban can construct an infinite number of interactive urban scenes fromcompositional elements, covering a vast array of ground plans, objectplacements, pedestrians, vulnerable road users, and other mobile agents'appearances and dynamics. We design point navigation and social navigationtasks as the pilot study using MetaUrban for embodied AI research and establishvarious baselines of Reinforcement Learning and Imitation Learning. Experimentsdemonstrate that the compositional nature of the simulated environments cansubstantially improve the generalizability and safety of the trained mobileagents. MetaUrban will be made publicly available to provide more researchopportunities and foster safe and trustworthy embodied AI in urban spaces.</description><author>Wayne Wu, Honglin He, Yiran Wang, Chenda Duan, Jack He, Zhizheng Liu, Quanyi Li, Bolei Zhou</author><pubDate>Thu, 11 Jul 2024 17:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08725v1</guid></item><item><title>Topological Generalization Bounds for Discrete-Time Stochastic Optimization Algorithms</title><link>http://arxiv.org/abs/2407.08723v1</link><description>We present a novel set of rigorous and computationally efficienttopology-based complexity notions that exhibit a strong correlation with thegeneralization gap in modern deep neural networks (DNNs). DNNs show remarkablegeneralization properties, yet the source of these capabilities remainselusive, defying the established statistical learning theory. Recent studieshave revealed that properties of training trajectories can be indicative ofgeneralization. Building on this insight, state-of-the-art methods haveleveraged the topology of these trajectories, particularly their fractaldimension, to quantify generalization. Most existing works compute thisquantity by assuming continuous- or infinite-time training dynamics,complicating the development of practical estimators capable of accuratelypredicting generalization without access to test data. In this paper, werespect the discrete-time nature of training trajectories and investigate theunderlying topological quantities that can be amenable to topological dataanalysis tools. This leads to a new family of reliable topological complexitymeasures that provably bound the generalization error, eliminating the need forrestrictive geometric assumptions. These measures are computationally friendly,enabling us to propose simple yet effective algorithms for computinggeneralization indices. Moreover, our flexible framework can be extended todifferent domains, tasks, and architectures. Our experimental resultsdemonstrate that our new complexity measures correlate highly withgeneralization error in industry-standards architectures such as transformersand deep graph networks. Our approach consistently outperforms existingtopological bounds across a wide range of datasets, models, and optimizers,highlighting the practical relevance and effectiveness of our complexitymeasures.</description><author>Rayna Andreeva, Benjamin Dupuis, Rik Sarkar, Tolga Birdal, Umut Şimşekli</author><pubDate>Thu, 11 Jul 2024 17:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08723v1</guid></item><item><title>High-Precision, Fair University Course Scheduling During a Pandemic</title><link>http://arxiv.org/abs/2407.07355v2</link><description>Scheduling university courses is extra challenging when classroom capacitiesare reduced because of social distancing requirements that are implemented inresponse to a pandemic such as COVID-19. In this work, we propose an expandedtaxonomy of course delivery modes, present an integer program, and develop acourse scheduling algorithm to enable all course sections -- even the largest-- to have a significant classroom learning component during a pandemic. Ourapproach is fair by ensuring that a certain fraction of the instruction inevery course section occurs in the classroom. Unlike previous studies, we donot allow rotating attendance and instead require simultaneous attendance inwhich all students in a section meet in 1-5 rooms at the same time but lessoften than in a normal semester. These mass meetings, which createopportunities for in-person midterm exams and group activities, are scheduledat high precision across all days of the semester rather than a single,repeating week. A fast heuristic algorithm makes the schedule in an hour.Results: We consider the 1834 in-person course sections, 172 classrooms, and 96days in the fall 2022 semester at [UniversityXYZ]. If average classroomcapacity is reduced by 75% due to a pandemic, our approach still allows atleast 25% of the instruction in every section, and more than 49% of allinstruction across the entire campus, to be in the classroom. Our method alsoproduces excellent results for regular classroom assignment. Managerialimplications: An algorithm based on the principles of fairness and simultaneousattendance can significantly improve university course schedules during apandemic and in normal times. High-precision schedules that prepare a campusfor various pandemic possibilities can be created with minimal administrativeeffort and activated at a moment's notice before or during a semester if anoutbreak occurs.</description><author>Matthew E. H. Petering, Mohammad Khamechian</author><pubDate>Thu, 11 Jul 2024 17:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07355v2</guid></item><item><title>Unifying 3D Representation and Control of Diverse Robots with a Single Camera</title><link>http://arxiv.org/abs/2407.08722v1</link><description>Mirroring the complex structures and diverse functions of natural organismsis a long-standing challenge in robotics. Modern fabrication techniques havedramatically expanded feasible hardware, yet deploying these systems requirescontrol software to translate desired motions into actuator commands. Whileconventional robots can easily be modeled as rigid links connected via joints,it remains an open challenge to model and control bio-inspired robots that areoften multi-material or soft, lack sensing capabilities, and may change theirmaterial properties with use. Here, we introduce Neural Jacobian Fields, anarchitecture that autonomously learns to model and control robots from visionalone. Our approach makes no assumptions about the robot's materials,actuation, or sensing, requires only a single camera for control, and learns tocontrol the robot without expert intervention by observing the execution ofrandom commands. We demonstrate our method on a diverse set of robotmanipulators, varying in actuation, materials, fabrication, and cost. Ourapproach achieves accurate closed-loop control and recovers the causal dynamicstructure of each robot. By enabling robot control with a generic camera as theonly sensor, we anticipate our work will dramatically broaden the design spaceof robotic systems and serve as a starting point for lowering the barrier torobotic automation.</description><author>Sizhe Lester Li, Annan Zhang, Boyuan Chen, Hanna Matusik, Chao Liu, Daniela Rus, Vincent Sitzmann</author><pubDate>Thu, 11 Jul 2024 17:55:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08722v1</guid></item><item><title>WhisperNetV2: SlowFast Siamese Network For Lip-Based Biometrics</title><link>http://arxiv.org/abs/2407.08717v1</link><description>Lip-based biometric authentication (LBBA) has attracted many researchersduring the last decade. The lip is specifically interesting for biometricresearchers because it is a twin biometric with the potential to function bothas a physiological and a behavioral trait. Although much valuable research wasconducted on LBBA, none of them considered the different emotions of the clientduring the video acquisition step of LBBA, which can potentially affect theclient's facial expressions and speech tempo. We proposed a novel networkstructure called WhisperNetV2, which extends our previously proposed networkcalled WhisperNet. Our proposed network leverages a deep Siamese structure withtriplet loss having three identical SlowFast networks as embedding networks.The SlowFast network is an excellent candidate for our task since the fastpathway extracts motion-related features (behavioral lip movements) with a highframe rate and low channel capacity. The slow pathway extracts visual features(physiological lip appearance) with a low frame rate and high channel capacity.Using an open-set protocol, we trained our network using the CREMA-D datasetand acquired an Equal Error Rate (EER) of 0.005 on the test set. Consideringthat the acquired EER is less than most similar LBBA methods, our method can beconsidered as a state-of-the-art LBBA method.</description><author>Abdollah Zakeri, Hamid Hassanpour, Mohammad Hossein Khosravi, Amir Masoud Nourollah</author><pubDate>Thu, 11 Jul 2024 17:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08717v1</guid></item><item><title>CoR-GS: Sparse-View 3D Gaussian Splatting via Co-Regularization</title><link>http://arxiv.org/abs/2405.12110v2</link><description>3D Gaussian Splatting (3DGS) creates a radiance field consisting of 3DGaussians to represent a scene. With sparse training views, 3DGS easily suffersfrom overfitting, negatively impacting rendering. This paper introduces a newco-regularization perspective for improving sparse-view 3DGS. When training two3D Gaussian radiance fields, we observe that the two radiance fields exhibitpoint disagreement and rendering disagreement that can unsupervisedly predictreconstruction quality, stemming from the randomness of densificationimplementation. We further quantify the two disagreements and demonstrate thenegative correlation between them and accurate reconstruction, which allows usto identify inaccurate reconstruction without accessing ground-truthinformation. Based on the study, we propose CoR-GS, which identifies andsuppresses inaccurate reconstruction based on the two disagreements: (1)Co-pruning considers Gaussians that exhibit high point disagreement ininaccurate positions and prunes them. (2) Pseudo-view co-regularizationconsiders pixels that exhibit high rendering disagreement are inaccurate andsuppress the disagreement. Results on LLFF, Mip-NeRF360, DTU, and Blenderdemonstrate that CoR-GS effectively regularizes the scene geometry,reconstructs the compact representations, and achieves state-of-the-art novelview synthesis quality under sparse training views.</description><author>Jiawei Zhang, Jiahe Li, Xiaohan Yu, Lei Huang, Lin Gu, Jin Zheng, Xiao Bai</author><pubDate>Thu, 11 Jul 2024 17:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12110v2</guid></item><item><title>Defect Spectrum: A Granular Look of Large-Scale Defect Datasets with Rich Semantics</title><link>http://arxiv.org/abs/2310.17316v4</link><description>Defect inspection is paramount within the closed-loop manufacturing system.However, existing datasets for defect inspection often lack precision andsemantic granularity required for practical applications. In this paper, weintroduce the Defect Spectrum, a comprehensive benchmark that offers precise,semantic-abundant, and large-scale annotations for a wide range of industrialdefects. Building on four key industrial benchmarks, our dataset refinesexisting annotations and introduces rich semantic details, distinguishingmultiple defect types within a single image. Furthermore, we introduceDefect-Gen, a two-stage diffusion-based generator designed to createhigh-quality and diverse defective images, even when working with limiteddatasets. The synthetic images generated by Defect-Gen significantly enhancethe efficacy of defect inspection models. Overall, The Defect Spectrum datasetdemonstrates its potential in defect inspection research, offering a solidplatform for testing and refining advanced models.</description><author>Shuai Yang, Zhifei Chen, Pengguang Chen, Xi Fang, Shu Liu, Yingcong Chen</author><pubDate>Thu, 11 Jul 2024 17:50:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17316v4</guid></item><item><title>A Taxonomy for Data Contamination in Large Language Models</title><link>http://arxiv.org/abs/2407.08716v1</link><description>Large language models pretrained on extensive web corpora demonstrateremarkable performance across a wide range of downstream tasks. However, agrowing concern is data contamination, where evaluation datasets may becontained in the pretraining corpus, inflating model performance.Decontamination, the process of detecting and removing such data, is apotential solution; yet these contaminants may originate from altered versionsof the test set, evading detection during decontamination. How different typesof contamination impact the performance of language models on downstream tasksis not fully understood. We present a taxonomy that categorizes the varioustypes of contamination encountered by LLMs during the pretraining phase andidentify which types pose the highest risk. We analyze the impact ofcontamination on two key NLP tasks -- summarization and question answering --revealing how different types of contamination influence task performanceduring evaluation.</description><author>Medha Palavalli, Amanda Bertsch, Matthew R. Gormley</author><pubDate>Thu, 11 Jul 2024 17:50:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08716v1</guid></item><item><title>Sensor-Aware Classifiers for Energy-Efficient Time Series Applications on IoT Devices</title><link>http://arxiv.org/abs/2407.08715v1</link><description>Time-series data processing is an important component of many real-worldapplications, such as health monitoring, environmental monitoring, and digitalagriculture. These applications collect distinct windows of sensor data (e.g.,few seconds) and process them to assess the environment. Machine learning (ML)models are being employed in time-series applications due to theirgeneralization abilities for classification. State-of-the-art time-seriesapplications wait for entire sensor data window to become available beforeprocessing the data using ML algorithms, resulting in high sensor energyconsumption. However, not all situations require processing full sensor windowto make accurate inference. For instance, in activity recognition, sitting andstanding activities can be inferred with partial windows. Using this insight,we propose to employ early exit classifiers with partial sensor windows tominimize energy consumption while maintaining accuracy. Specifically, we firstutilize multiple early exits with successively increasing amount of data asthey become available in a window. If early exits provide inference with highconfidence, we return the label and enter low power mode for sensors. Theproposed approach has potential to enable significant energy savings in timeseries applications. We utilize neural networks and random forest classifiersto evaluate our approach. Our evaluations with six datasets show that theproposed approach enables up to 50-60% energy savings on average without anyimpact on accuracy. The energy savings can enable time-series applications inremote locations with limited energy availability.</description><author>Dina Hussein, Lubah Nelson, Ganapati Bhat</author><pubDate>Thu, 11 Jul 2024 17:50:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08715v1</guid></item><item><title>GTA: A Benchmark for General Tool Agents</title><link>http://arxiv.org/abs/2407.08713v1</link><description>Significant focus has been placed on integrating large language models (LLMs)with various tools in developing general-purpose agents. This poses a challengeto LLMs' tool-use capabilities. However, there are evident gaps betweenexisting tool-use evaluations and real-world scenarios. Current evaluationsoften use AI-generated queries, single-step tasks, dummy tools, and text-onlyinteractions, failing to reveal the agents' real-world problem-solvingabilities effectively. To address this, we propose GTA, a benchmark for GeneralTool Agents, featuring three main aspects: (i) Real user queries: human-writtenqueries with simple real-world objectives but implicit tool-use, requiring theLLM to reason the suitable tools and plan the solution steps. (ii) Realdeployed tools: an evaluation platform equipped with tools across perception,operation, logic, and creativity categories to evaluate the agents' actual taskexecution performance. (iii) Real multimodal inputs: authentic image files,such as spatial scenes, web page screenshots, tables, code snippets, andprinted/handwritten materials, used as the query contexts to align withreal-world scenarios closely. We design 229 real-world tasks and executabletool chains to evaluate mainstream LLMs. Our findings show that real-world userqueries are challenging for existing LLMs, with GPT-4 completing less than 50%of the tasks and most LLMs achieving below 25%. This evaluation reveals thebottlenecks in the tool-use capabilities of current LLMs in real-worldscenarios, which provides future direction for advancing general-purpose toolagents. The code and dataset are available athttps://github.com/open-compass/GTA.</description><author>Jize Wang, Zerun Ma, Yining Li, Songyang Zhang, Cailian Chen, Kai Chen, Xinyi Le</author><pubDate>Thu, 11 Jul 2024 17:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08713v1</guid></item><item><title>OmniNOCS: A unified NOCS dataset and model for 3D lifting of 2D objects</title><link>http://arxiv.org/abs/2407.08711v1</link><description>We propose OmniNOCS, a large-scale monocular dataset with 3D NormalizedObject Coordinate Space (NOCS) maps, object masks, and 3D bounding boxannotations for indoor and outdoor scenes. OmniNOCS has 20 times more objectclasses and 200 times more instances than existing NOCS datasets (NOCS-Real275,Wild6D). We use OmniNOCS to train a novel, transformer-based monocular NOCSprediction model (NOCSformer) that can predict accurate NOCS, instance masksand poses from 2D object detections across diverse classes. It is the firstNOCS model that can generalize to a broad range of classes when prompted with2D boxes. We evaluate our model on the task of 3D oriented bounding boxprediction, where it achieves comparable results to state-of-the-art 3Ddetection methods such as Cube R-CNN. Unlike other 3D detection methods, ourmodel also provides detailed and accurate 3D object shape and segmentation. Wepropose a novel benchmark for the task of NOCS prediction based on OmniNOCS,which we hope will serve as a useful baseline for future work in this area. Ourdataset and code will be at the project website: https://omninocs.github.io.</description><author>Akshay Krishnan, Abhijit Kundu, Kevis-Kokitsi Maninis, James Hays, Matthew Brown</author><pubDate>Thu, 11 Jul 2024 17:49:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08711v1</guid></item><item><title>eyeballvul: a future-proof benchmark for vulnerability detection in the wild</title><link>http://arxiv.org/abs/2407.08708v1</link><description>Long contexts of recent LLMs have enabled a new use case: asking models tofind security vulnerabilities in entire codebases. To evaluate modelperformance on this task, we introduce eyeballvul: a benchmark designed to testthe vulnerability detection capabilities of language models at scale, that issourced and updated weekly from the stream of published vulnerabilities inopen-source repositories. The benchmark consists of a list of revisions indifferent repositories, each associated with the list of known vulnerabilitiespresent at that revision. An LLM-based scorer is used to compare the list ofpossible vulnerabilities returned by a model to the list of knownvulnerabilities for each revision. As of July 2024, eyeballvul contains 24,000+vulnerabilities across 6,000+ revisions and 5,000+ repositories, and is around55GB in size.</description><author>Timothee Chauvin</author><pubDate>Thu, 11 Jul 2024 17:46:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08708v1</guid></item><item><title>Extracting Training Data from Document-Based VQA Models</title><link>http://arxiv.org/abs/2407.08707v1</link><description>Vision-Language Models (VLMs) have made remarkable progress in document-basedVisual Question Answering (i.e., responding to queries about the contents of aninput document provided as an image). In this work, we show these models canmemorize responses for training samples and regurgitate them even when therelevant visual information has been removed. This includes PersonalIdentifiable Information (PII) repeated once in the training set, indicatingthese models could divulge memorised sensitive information and therefore pose aprivacy risk. We quantitatively measure the extractability of information incontrolled experiments and differentiate between cases where it arises fromgeneralization capabilities or from memorization. We further investigate thefactors that influence memorization across multiple state-of-the-art models andpropose an effective heuristic countermeasure that empirically prevents theextractability of PII.</description><author>Francesco Pinto, Nathalie Rauschmayr, Florian Tramèr, Philip Torr, Federico Tombari</author><pubDate>Thu, 11 Jul 2024 17:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08707v1</guid></item><item><title>HiRes-LLaVA: Restoring Fragmentation Input in High-Resolution Large Vision-Language Models</title><link>http://arxiv.org/abs/2407.08706v1</link><description>High-resolution inputs enable Large Vision-Language Models (LVLMs) to discernfiner visual details, enhancing their comprehension capabilities. To reduce thetraining and computation costs caused by high-resolution input, one promisingdirection is to use sliding windows to slice the input into uniform patches,each matching the input size of the well-trained vision encoder. Althoughefficient, this slicing strategy leads to the fragmentation of original input,i.e., the continuity of contextual information and spatial geometry is lostacross patches, adversely affecting performance in cross-patch contextperception and position-specific tasks. To overcome these shortcomings, weintroduce HiRes-LLaVA, a novel framework designed to efficiently process anysize of high-resolution input without altering the original contextual andgeometric information. HiRes-LLaVA comprises two innovative components: (i) aSliceRestore adapter that reconstructs sliced patches into their original form,efficiently extracting both global and local features via down-up-sampling andconvolution layers, and (ii) a Self-Mining Sampler to compresses the visiontokens based on themselves, preserving the original context and positionalinformation while reducing training overhead. To assess the ability of handlingcontext fragmentation, we construct a new benchmark, EntityGrid-QA, consistingof edge-related and position-related tasks. Our comprehensive experimentsdemonstrate the superiority of HiRes-LLaVA on both existing public benchmarksand on EntityGrid-QA, particularly on document-oriented tasks, establishing newstandards for handling high-resolution inputs.</description><author>Runhui Huang, Xinpeng Ding, Chunwei Wang, Jianhua Han, Yulong Liu, Hengshuang Zhao, Hang Xu, Lu Hou, Wei Zhang, Xiaodan Liang</author><pubDate>Thu, 11 Jul 2024 17:42:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08706v1</guid></item><item><title>Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware</title><link>http://arxiv.org/abs/2407.08704v1</link><description>This paper explores the synergistic potential of neuromorphic and edgecomputing to create a versatile machine learning (ML) system tailored forprocessing data captured by dynamic vision sensors. We construct and trainhybrid models, blending spiking neural networks (SNNs) and artificial neuralnetworks (ANNs) using PyTorch and Lava frameworks. Our hybrid architectureintegrates an SNN for temporal feature extraction and an ANN forclassification. We delve into the challenges of deploying such hybridstructures on hardware. Specifically, we deploy individual components onIntel's Neuromorphic Processor Loihi (for SNN) and Jetson Nano (for ANN). Wealso propose an accumulator circuit to transfer data from the spiking to thenon-spiking domain. Furthermore, we conduct comprehensive performance analysesof hybrid SNN-ANN models on a heterogeneous system of neuromorphic and edge AIhardware, evaluating accuracy, latency, power, and energy consumption. Ourfindings demonstrate that the hybrid spiking networks surpass the baseline ANNmodel across all metrics and outperform the baseline SNN model in accuracy andlatency.</description><author>James Seekings, Peyton Chandarana, Mahsa Ardakani, MohammadReza Mohammadi, Ramtin Zand</author><pubDate>Thu, 11 Jul 2024 17:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08704v1</guid></item><item><title>Live2Diff: Live Stream Translation via Uni-directional Attention in Video Diffusion Models</title><link>http://arxiv.org/abs/2407.08701v1</link><description>Large Language Models have shown remarkable efficacy in generating streamingdata such as text and audio, thanks to their temporally uni-directionalattention mechanism, which models correlations between the current token andprevious tokens. However, video streaming remains much less explored, despite agrowing need for live video processing. State-of-the-art video diffusion modelsleverage bi-directional temporal attention to model the correlations betweenthe current frame and all the surrounding (i.e. including future) frames, whichhinders them from processing streaming videos. To address this problem, wepresent Live2Diff, the first attempt at designing a video diffusion model withuni-directional temporal attention, specifically targeting live streaming videotranslation. Compared to previous works, our approach ensures temporalconsistency and smoothness by correlating the current frame with itspredecessors and a few initial warmup frames, without any future frames.Additionally, we use a highly efficient denoising scheme featuring a KV-cachemechanism and pipelining, to facilitate streaming video translation atinteractive framerates. Extensive experiments demonstrate the effectiveness ofthe proposed attention mechanism and pipeline, outperforming previous methodsin terms of temporal smoothness and/or efficiency.</description><author>Zhening Xing, Gereon Fox, Yanhong Zeng, Xingang Pan, Mohamed Elgharib, Christian Theobalt, Kai Chen</author><pubDate>Thu, 11 Jul 2024 17:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08701v1</guid></item><item><title>Flex-TPU: A Flexible TPU with Runtime Reconfigurable Dataflow Architecture</title><link>http://arxiv.org/abs/2407.08700v1</link><description>Tensor processing units (TPUs) are one of the most well-known machinelearning (ML) accelerators utilized at large scale in data centers as well asin tiny ML applications. TPUs offer several improvements and advantages overconventional ML accelerators, like graphical processing units (GPUs), beingdesigned specifically to perform the multiply-accumulate (MAC) operationsrequired in the matrix-matrix and matrix-vector multiplies extensively presentthroughout the execution of deep neural networks (DNNs). Such improvementsinclude maximizing data reuse and minimizing data transfer by leveraging thetemporal dataflow paradigms provided by the systolic array architecture. Whilethis design provides a significant performance benefit, the currentimplementations are restricted to a single dataflow consisting of either input,output, or weight stationary architectures. This can limit the achievableperformance of DNN inference and reduce the utilization of compute units.Therefore, the work herein consists of developing a reconfigurable dataflowTPU, called the Flex-TPU, which can dynamically change the dataflow per layerduring run-time. Our experiments thoroughly test the viability of the Flex-TPUcomparing it to conventional TPU designs across multiple well-known MLworkloads. The results show that our Flex-TPU design achieves a significantperformance increase of up to 2.75x compared to conventional TPU, with onlyminor area and power overheads.</description><author>Mohammed Elbtity, Peyton Chandarana, Ramtin Zand</author><pubDate>Thu, 11 Jul 2024 17:33:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08700v1</guid></item><item><title>Mitigating Catastrophic Forgetting in Language Transfer via Model Merging</title><link>http://arxiv.org/abs/2407.08699v1</link><description>As open-weight large language models (LLMs) achieve ever more impressiveperformances across a wide range of tasks in English, practitioners aim toadapt these models to different languages. However, such language adaptation isoften accompanied by catastrophic forgetting of the base model's capabilities,severely limiting the usefulness of the resulting model. We address this issueby proposing Branch-and-Merge (BaM), a new adaptation method based oniteratively merging multiple models, fine-tuned on a subset of the availabletraining data. BaM is based on the insight that this yields lower magnitude buthigher quality weight changes, reducing forgetting of the source domain whilemaintaining learning on the target domain. We demonstrate in an extensiveempirical study on Bulgarian and German that BaM can significantly reduceforgetting while matching or even improving target domain performance comparedto both standard continued pretraining and instruction finetuning acrossdifferent model architectures.</description><author>Anton Alexandrov, Veselin Raychev, Mark Niklas Müller, Ce Zhang, Martin Vechev, Kristina Toutanova</author><pubDate>Thu, 11 Jul 2024 17:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08699v1</guid></item><item><title>Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight</title><link>http://arxiv.org/abs/2407.08694v1</link><description>Runtime failure and performance degradation is commonplace in modern cloudsystems. For cloud providers, automatically determining the root cause ofincidents is paramount to ensuring high reliability and availability as promptfault localization can enable faster diagnosis and triage for timelyresolution. A compelling solution explored in recent work is causal reasoningusing causal graphs to capture relationships between varied cloud systemperformance metrics. To be effective, however, systems developers mustcorrectly define the causal graph of their system, which is a time-consuming,brittle, and challenging task that increases in difficulty for large anddynamic systems and requires domain expertise. Alternatively, automateddata-driven approaches have limited efficacy for cloud systems due to theinherent rarity of incidents. In this work, we present Atlas, a novel approachto automatically synthesizing causal graphs for cloud systems. Atlas leverageslarge language models (LLMs) to generate causal graphs using systemdocumentation, telemetry, and deployment feedback. Atlas is complementary todata-driven causal discovery techniques, and we further enhance Atlas with adata-driven validation step. We evaluate Atlas across a range of faultlocalization scenarios and demonstrate that Atlas is capable of generatingcausal graphs in a scalable and generalizable manner, with performance that farsurpasses that of data-driven algorithms and is commensurate to theground-truth baseline.</description><author>Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace</author><pubDate>Thu, 11 Jul 2024 17:31:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08694v1</guid></item><item><title>Robotic Control via Embodied Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2407.08693v1</link><description>A key limitation of learned robot control policies is their inability togeneralize outside their training data. Recent works on vision-language-actionmodels (VLAs) have shown that the use of large, internet pre-trainedvision-language models as the backbone of learned robot policies cansubstantially improve their robustness and generalization ability. Yet, one ofthe most exciting capabilities of large vision-language models in other domainsis their ability to reason iteratively through complex problems. Can that samecapability be brought into robotics to allow policies to improve performance byreasoning about a given task before acting? Naive use of "chain-of-thought"(CoT) style prompting is significantly less effective with standard VLAsbecause of the relatively simple training examples that are available to them.Additionally, purely semantic reasoning about sub-tasks, as is common inregular CoT, is insufficient for robot policies that need to ground theirreasoning in sensory observations and the robot state. To this end, weintroduce Embodied Chain-of-Thought Reasoning (ECoT) for VLAs, in which wetrain VLAs to perform multiple steps of reasoning about plans, sub-tasks,motions, and visually grounded features like object bounding boxes and endeffector positions, before predicting the robot action. We design a scalablepipeline for generating synthetic training data for ECoT on large robotdatasets. We demonstrate, that ECoT increases the absolute success rate ofOpenVLA, the current strongest open-source VLA policy, by 28% acrosschallenging generalization tasks, without any additional robot training data.Additionally, ECoT makes it easier for humans to interpret a policy's failuresand correct its behavior using natural language.</description><author>Zawalski Michał, Chen William, Pertsch Karl, Mees Oier, Finn Chelsea, Levine Sergey</author><pubDate>Thu, 11 Jul 2024 17:31:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08693v1</guid></item><item><title>ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions</title><link>http://arxiv.org/abs/2407.08691v1</link><description>Transformers have rapidly overtaken CNN-based architectures as the newstandard in audio classification. Transformer-based models, such as the AudioSpectrogram Transformers (AST), also inherit the fixed-size input paradigm fromCNNs. However, this leads to performance degradation for ASTs in the inferencewhen input lengths vary from the training. This paper introduces an approachthat enables the use of variable-length audio inputs with AST models duringboth training and inference. By employing sequence packing, our methodElasticAST, accommodates any audio length during training, thereby offeringflexibility across all lengths and resolutions at the inference. Thisflexibility allows ElasticAST to maintain evaluation capabilities at variouslengths or resolutions and achieve similar performance to standard ASTs trainedat specific lengths or resolutions. Moreover, experiments demonstrateElasticAST's better performance when trained and evaluated on native-lengthaudio datasets.</description><author>Jiu Feng, Mehmet Hamza Erol, Joon Son Chung, Arda Senocak</author><pubDate>Thu, 11 Jul 2024 17:29:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08691v1</guid></item><item><title>Operationalizing the Blueprint for an AI Bill of Rights: Recommendations for Practitioners, Researchers, and Policy Makers</title><link>http://arxiv.org/abs/2407.08689v1</link><description>As Artificial Intelligence (AI) tools are increasingly employed in diversereal-world applications, there has been significant interest in regulatingthese tools. To this end, several regulatory frameworks have been introduced bydifferent countries worldwide. For example, the European Union recently passedthe AI Act, the White House issued an Executive Order on safe, secure, andtrustworthy AI, and the White House Office of Science and Technology Policyissued the Blueprint for an AI Bill of Rights (AI BoR). Many of theseframeworks emphasize the need for auditing and improving the trustworthiness ofAI tools, underscoring the importance of safety, privacy, explainability,fairness, and human fallback options. Although these regulatory frameworkshighlight the necessity of enforcement, practitioners often lack detailedguidance on implementing them. Furthermore, the extensive research onoperationalizing each of these aspects is frequently buried in technical papersthat are difficult for practitioners to parse. In this write-up, we addressthis shortcoming by providing an accessible overview of existing literaturerelated to operationalizing regulatory principles. We provideeasy-to-understand summaries of state-of-the-art literature and highlightvarious gaps that exist between regulatory guidelines and existing AI research,including the trade-offs that emerge during operationalization. We hope thatthis work not only serves as a starting point for practitioners interested inlearning more about operationalizing the regulatory guidelines outlined in theBlueprint for an AI BoR but also provides researchers with a list of criticalopen problems and gaps between regulations and state-of-the-art AI research.Finally, we note that this is a working paper and we invite feedback in linewith the purpose of this document as described in the introduction.</description><author>Alex Oesterling, Usha Bhalla, Suresh Venkatasubramanian, Himabindu Lakkaraju</author><pubDate>Thu, 11 Jul 2024 17:28:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08689v1</guid></item><item><title>SLEDGE: Synthesizing Driving Environments with Generative Models and Rule-Based Traffic</title><link>http://arxiv.org/abs/2403.17933v2</link><description>SLEDGE is the first generative simulator for vehicle motion planning trainedon real-world driving logs. Its core component is a learned model that is ableto generate agent bounding boxes and lane graphs. The model's outputs serve asan initial state for rule-based traffic simulation. The unique properties ofthe entities to be generated for SLEDGE, such as their connectivity andvariable count per scene, render the naive application of most moderngenerative models to this task non-trivial. Therefore, together with asystematic study of existing lane graph representations, we introduce a novelraster-to-vector autoencoder. It encodes agents and the lane graph intodistinct channels in a rasterized latent map. This facilitates bothlane-conditioned agent generation and combined generation of lanes and agentswith a Diffusion Transformer. Using generated entities in SLEDGE enablesgreater control over the simulation, e.g. upsampling turns or increasingtraffic density. Further, SLEDGE can support 500m long routes, a capability notfound in existing data-driven simulators like nuPlan. It presents newchallenges for planning algorithms, evidenced by failure rates of over 40% forPDM, the winner of the 2023 nuPlan challenge, when tested on hard routes anddense traffic generated by our model. Compared to nuPlan, SLEDGE requires500$\times$ less storage to set up (&lt;4 GB), making it a more accessible optionand helping with democratizing future research in this field.</description><author>Kashyap Chitta, Daniel Dauner, Andreas Geiger</author><pubDate>Thu, 11 Jul 2024 17:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17933v2</guid></item><item><title>Generative Inverse Design of Metamaterials with Functional Responses by Interpretable Learning</title><link>http://arxiv.org/abs/2401.00003v2</link><description>Metamaterials with functional responses, such as wave-based responses ordeformation-induced property variation under external stimuli, can exhibitvarying properties or functionalities under different conditions. Herein, weaim at rapid inverse design of these metamaterials to meet target qualitativefunctional behaviors. This inverse problem is challenging due to itsintractability and the existence of non-unique solutions. Past works mainlyfocus on deep-learning-based methods that are data-demanding, requiretime-consuming training and hyperparameter tuning, and are non-interpretable.To overcome these limitations, we propose the Random-forest-based InterpretableGenerative Inverse Design (RIGID), an iteration-free, single-shot inversedesign method to achieve the fast generation of metamaterial designs withon-demand functional behaviors. Unlike most existing methods, by exploiting theinterpretability of the random forest, we eliminate the need to train aninverse model mapping responses to designs. Based on the likelihood of targetsatisfaction derived from the trained forward model, one can sample designsolutions using Markov chain Monte Carlo methods. The RIGID method thereforefunctions as a generative model that captures the conditional distribution ofsatisfying solutions given a design target. We demonstrate the effectivenessand efficiency of RIGID on both acoustic and optical metamaterial designproblems where only small datasets (less than 250 training samples) areavailable. Synthetic design problems are created to further illustrate andvalidate the mechanism of likelihood estimation in RIGID. This work offers anew perspective on solving on-demand inverse design problems, showcasing thepotential for incorporating interpretable machine learning into generativedesign and eliminating its large data requirement.</description><author>Wei "Wayne" Chen, Rachel Sun, Doksoo Lee, Carlos M. Portela, Wei Chen</author><pubDate>Thu, 11 Jul 2024 17:27:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00003v2</guid></item><item><title>SEED-Story: Multimodal Long Story Generation with Large Language Model</title><link>http://arxiv.org/abs/2407.08683v1</link><description>With the remarkable advancements in image generation and open-form textgeneration, the creation of interleaved image-text content has become anincreasingly intriguing field. Multimodal story generation, characterized byproducing narrative texts and vivid images in an interleaved manner, hasemerged as a valuable and practical task with broad applications. However, thistask poses significant challenges, as it necessitates the comprehension of thecomplex interplay between texts and images, and the ability to generate longsequences of coherent, contextually relevant texts and visuals. In this work,we propose SEED-Story, a novel method that leverages a Multimodal LargeLanguage Model (MLLM) to generate extended multimodal stories. Our model, builtupon the powerful comprehension capability of MLLM, predicts text tokens aswell as visual tokens, which are subsequently processed with an adapted visualde-tokenizer to produce images with consistent characters and styles. Wefurther propose multimodal attention sink mechanism to enable the generation ofstories with up to 25 sequences (only 10 for training) in a highly efficientautoregressive manner. Additionally, we present a large-scale andhigh-resolution dataset named StoryStream for training our model andquantitatively evaluating the task of multimodal story generation in variousaspects.</description><author>Shuai Yang, Yuying Ge, Yang Li, Yukang Chen, Yixiao Ge, Ying Shan, Yingcong Chen</author><pubDate>Thu, 11 Jul 2024 17:21:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08683v1</guid></item><item><title>Hardware Neural Control of CartPole and F1TENTH Race Car</title><link>http://arxiv.org/abs/2407.08681v1</link><description>Nonlinear model predictive control (NMPC) has proven to be an effectivecontrol method, but it is expensive to compute. This work demonstrates the useof hardware FPGA neural network controllers trained to imitate NMPC withsupervised learning. We use these Neural Controllers (NCs) implemented oninexpensive embedded FPGA hardware for high frequency control on physicalcartpole and F1TENTH race car. Our results show that the NCs match the controlperformance of the NMPCs in simulation and outperform it in reality, due to thefaster control rate that is afforded by the quick FPGA NC inference. Wedemonstrate kHz control rates for a physical cartpole and offloading control tothe FPGA hardware on the F1TENTH car. Code and hardware implementation for thispaper are available at https:// github.com/SensorsINI/Neural-Control-Tools.</description><author>Marcin Paluch, Florian Bolli, Xiang Deng, Antonio Rios Navarro, Chang Gao, Tobi Delbruck</author><pubDate>Thu, 11 Jul 2024 17:14:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08681v1</guid></item><item><title>Generalizable Implicit Motion Modeling for Video Frame Interpolation</title><link>http://arxiv.org/abs/2407.08680v1</link><description>Motion modeling is critical in flow-based Video Frame Interpolation (VFI).Existing paradigms either consider linear combinations of bidirectional flowsor directly predict bilateral flows for given timestamps without exploringfavorable motion priors, thus lacking the capability of effectively modelingspatiotemporal dynamics in real-world videos. To address this limitation, inthis study, we introduce Generalizable Implicit Motion Modeling (GIMM), a noveland effective approach to motion modeling for VFI. Specifically, to enable GIMMas an effective motion modeling paradigm, we design a motion encoding pipelineto model spatiotemporal motion latent from bidirectional flows extracted frompre-trained flow estimators, effectively representing input-specific motionpriors. Then, we implicitly predict arbitrary-timestep optical flows within twoadjacent input frames via an adaptive coordinate-based neural network, withspatiotemporal coordinates and motion latent as inputs. Our GIMM can besmoothly integrated with existing flow-based VFI works without furthermodifications. We show that GIMM performs better than the current state of theart on the VFI benchmarks.</description><author>Zujin Guo, Wei Li, Chen Change Loy</author><pubDate>Thu, 11 Jul 2024 17:13:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08680v1</guid></item><item><title>How to beat a Bayesian adversary</title><link>http://arxiv.org/abs/2407.08678v1</link><description>Deep neural networks and other modern machine learning models are oftensusceptible to adversarial attacks. Indeed, an adversary may often be able tochange a model's prediction through a small, directed perturbation of themodel's input - an issue in safety-critical applications. Adversarially robustmachine learning is usually based on a minmax optimisation problem thatminimises the machine learning loss under maximisation-based adversarialattacks. In this work, we study adversaries that determine their attack using aBayesian statistical approach rather than maximisation. The resulting Bayesianadversarial robustness problem is a relaxation of the usual minmax problem. Tosolve this problem, we propose Abram - a continuous-time particle system thatshall approximate the gradient flow corresponding to the underlying learningproblem. We show that Abram approximates a McKean-Vlasov process and justifythe use of Abram by giving assumptions under which the McKean-Vlasov processfinds the minimiser of the Bayesian adversarial robustness problem. We discusstwo ways to discretise Abram and show its suitability in benchmark adversarialdeep learning experiments.</description><author>Zihan Ding, Kexin Jin, Jonas Latz, Chenguang Liu</author><pubDate>Thu, 11 Jul 2024 17:12:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08678v1</guid></item><item><title>Large-Scale Dataset Pruning in Adversarial Training through Data Importance Extrapolation</title><link>http://arxiv.org/abs/2406.13283v2</link><description>Their vulnerability to small, imperceptible attacks limits the adoption ofdeep learning models to real-world systems. Adversarial training has proven tobe one of the most promising strategies against these attacks, at the expenseof a substantial increase in training time. With the ongoing trend ofintegrating large-scale synthetic data this is only expected to increase evenfurther. Thus, the need for data-centric approaches that reduce the number oftraining samples while maintaining accuracy and robustness arises. While datapruning and active learning are prominent research topics in deep learning,they are as of now largely unexplored in the adversarial training literature.We address this gap and propose a new data pruning strategy based onextrapolating data importance scores from a small set of data to a larger set.In an empirical evaluation, we demonstrate that extrapolation-based pruning canefficiently reduce dataset size while maintaining robustness.</description><author>Björn Nieth, Thomas Altstidl, Leo Schwinn, Björn Eskofier</author><pubDate>Thu, 11 Jul 2024 17:10:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13283v2</guid></item><item><title>Korean Aspect-Based Sentiment Analysis via Implicit-Feature Alignment with Corpus Filtering</title><link>http://arxiv.org/abs/2407.00342v2</link><description>Investigations into Aspect-Based Sentiment Analysis (ABSA) for Koreanrestaurant reviews are notably lacking in the existing literature. Our researchproposes an intuitive and effective framework for ABSA in low-resourcelanguages such as Korean. It optimizes prediction labels by integratingtranslated benchmark and unlabeled Korean data. Using a model fine-tuned ontranslated data, we pseudo-labeled the actual Korean NLI set. Subsequently, weapplied LaBSE and MSP-based filtering to this pseudo-NLI set as implicitfeature, enhancing Aspect Category Detection and Polarity determination throughadditional training. Incorporating dual filtering, this model bridged datasetgaps, achieving positive results in Korean ABSA with minimal resources. Throughadditional data injection pipelines, our approach aims to utilize high-resourcedata and construct effective models within communities, whether corporate orindividual, in low-resource language countries. Compared to English ABSA, ourframework showed an approximately 3% difference in F1 scores and accuracy. Werelease the dataset and our code for Korean ABSA, at this link.</description><author>Kibeom Nam</author><pubDate>Thu, 11 Jul 2024 17:08:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00342v2</guid></item><item><title>CAD-Prompted Generative Models: A Pathway to Feasible and Novel Engineering Designs</title><link>http://arxiv.org/abs/2407.08675v1</link><description>Text-to-image generative models have increasingly been used to assistdesigners during concept generation in various creative domains, such asgraphic design, user interface design, and fashion design. However, theirapplications in engineering design remain limited due to the models' challengesin generating images of feasible designs concepts. To address this issue, thispaper introduces a method that improves the design feasibility by prompting thegeneration with feasible CAD images. In this work, the usefulness of thismethod is investigated through a case study with a bike design task using anoff-the-shelf text-to-image model, Stable Diffusion 2.1. A diverse set of bikedesigns are produced in seven different generation settings with varying CADimage prompting weights, and these designs are evaluated on their perceivedfeasibility and novelty. Results demonstrate that the CAD image promptingsuccessfully helps text-to-image models like Stable Diffusion 2.1 createvisibly more feasible design images. While a general tradeoff is observedbetween feasibility and novelty, when the prompting weight is kept low around0.35, the design feasibility is significantly improved while its noveltyremains on par with those generated by text prompts alone. The insights fromthis case study offer some guidelines for selecting the appropriate CAD imageprompting weight for different stages of the engineering design process. Whenutilized effectively, our CAD image prompting method opens doors to a widerrange of applications of text-to-image models in engineering design.</description><author>Leah Chong, Jude Rayan, Steven Dow, Ioanna Lykourentzou, Faez Ahmed</author><pubDate>Thu, 11 Jul 2024 17:07:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08675v1</guid></item><item><title>Still-Moving: Customized Video Generation without Customized Video Data</title><link>http://arxiv.org/abs/2407.08674v1</link><description>Customizing text-to-image (T2I) models has seen tremendous progress recently,particularly in areas such as personalization, stylization, and conditionalgeneration. However, expanding this progress to video generation is still inits infancy, primarily due to the lack of customized video data. In this work,we introduce Still-Moving, a novel generic framework for customizing atext-to-video (T2V) model, without requiring any customized video data. Theframework applies to the prominent T2V design where the video model is builtover a text-to-image (T2I) model (e.g., via inflation). We assume access to acustomized version of the T2I model, trained only on still image data (e.g.,using DreamBooth or StyleDrop). Naively plugging in the weights of thecustomized T2I model into the T2V model often leads to significant artifacts orinsufficient adherence to the customization data. To overcome this issue, wetrain lightweight $\textit{Spatial Adapters}$ that adjust the features producedby the injected T2I layers. Importantly, our adapters are trained on$\textit{"frozen videos"}$ (i.e., repeated images), constructed from imagesamples generated by the customized T2I model. This training is facilitated bya novel $\textit{Motion Adapter}$ module, which allows us to train on suchstatic videos while preserving the motion prior of the video model. At testtime, we remove the Motion Adapter modules and leave in only the trainedSpatial Adapters. This restores the motion prior of the T2V model whileadhering to the spatial prior of the customized T2I model. We demonstrate theeffectiveness of our approach on diverse tasks including personalized,stylized, and conditional generation. In all evaluated scenarios, our methodseamlessly integrates the spatial prior of the customized T2I model with amotion prior supplied by the T2V model.</description><author>Hila Chefer, Shiran Zada, Roni Paiss, Ariel Ephrat, Omer Tov, Michael Rubinstein, Lior Wolf, Tali Dekel, Tomer Michaeli, Inbar Mosseri</author><pubDate>Thu, 11 Jul 2024 17:06:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08674v1</guid></item><item><title>NODE-Adapter: Neural Ordinary Differential Equations for Better Vision-Language Reasoning</title><link>http://arxiv.org/abs/2407.08672v1</link><description>In this paper, we consider the problem of prototype-based vision-languagereasoning problem. We observe that existing methods encounter three majorchallenges: 1) escalating resource demands and prolonging training times, 2)contending with excessive learnable parameters, and 3) fine-tuning based onlyon a single modality. These challenges will hinder their capability to adaptVision-Language Models (VLMs) to downstream tasks. Motivated by this criticalobservation, we propose a novel method called NODE-Adapter, which utilizesNeural Ordinary Differential Equations for better vision-language reasoning. Tofully leverage both visual and textual modalities and estimate class prototypesmore effectively and accurately, we divide our method into two stages:cross-modal prototype construction and cross-modal prototype optimization usingneural ordinary differential equations. Specifically, we exploit VLM to encodehand-crafted prompts into textual features and few-shot support images intovisual features. Then, we estimate the textual prototype and visual prototypeby averaging the textual features and visual features, respectively, andadaptively combine the textual prototype and visual prototype to construct thecross-modal prototype. To alleviate the prototype bias, we then model theprototype optimization process as an initial value problem with Neural ODEs toestimate the continuous gradient flow. Our extensive experimental results,which cover few-shot classification, domain generalization, and visualreasoning on human-object interaction, demonstrate that the proposed methodsignificantly outperforms existing state-of-the-art approaches.</description><author>Yi Zhang, Chun-Wun Cheng, Ke Yu, Zhihai He, Carola-Bibiane Schönlieb, Angelica I. Aviles-Rivero</author><pubDate>Thu, 11 Jul 2024 17:04:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08672v1</guid></item><item><title>High-resolution open-vocabulary object 6D pose estimation</title><link>http://arxiv.org/abs/2406.16384v2</link><description>The generalisation to unseen objects in the 6D pose estimation task is verychallenging. While Vision-Language Models (VLMs) enable using natural languagedescriptions to support 6D pose estimation of unseen objects, these solutionsunderperform compared to model-based methods. In this work we present Horyon,an open-vocabulary VLM-based architecture that addresses relative poseestimation between two scenes of an unseen object, described by a textualprompt only. We use the textual prompt to identify the unseen object in thescenes and then obtain high-resolution multi-scale features. These features areused to extract cross-scene matches for registration. We evaluate our model ona benchmark with a large variety of unseen objects across four datasets, namelyREAL275, Toyota-Light, Linemod, and YCB-Video. Our method achievesstate-of-the-art performance on all datasets, outperforming by 12.6 in AverageRecall the previous best-performing approach.</description><author>Jaime Corsetti, Davide Boscaini, Francesco Giuliari, Changjae Oh, Andrea Cavallaro, Fabio Poiesi</author><pubDate>Thu, 11 Jul 2024 17:03:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16384v2</guid></item><item><title>Segmentation-guided Attention for Visual Question Answering from Remote Sensing Images</title><link>http://arxiv.org/abs/2407.08669v1</link><description>Visual Question Answering for Remote Sensing (RSVQA) is a task that aims atanswering natural language questions about the content of a remote sensingimage. The visual features extraction is therefore an essential step in a VQApipeline. By incorporating attention mechanisms into this process, models gainthe ability to focus selectively on salient regions of the image, prioritizingthe most relevant visual information for a given question. In this work, wepropose to embed an attention mechanism guided by segmentation into a RSVQApipeline. We argue that segmentation plays a crucial role in guiding attentionby providing a contextual understanding of the visual information, underlyingspecific objects or areas of interest. To evaluate this methodology, we providea new VQA dataset that exploits very high-resolution RGB orthophotos annotatedwith 16 segmentation classes and question/answer pairs. Our study showspromising results of our new methodology, gaining almost 10% of overallaccuracy compared to a classical method on the proposed dataset.</description><author>Lucrezia Tosato, Hichem Boussaid, Flora Weissgerber, Camille Kurtz, Laurent Wendling, Sylvain Lobry</author><pubDate>Thu, 11 Jul 2024 16:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08669v1</guid></item><item><title>Estimation of spatio-temporal extremes via generative neural networks</title><link>http://arxiv.org/abs/2407.08668v1</link><description>Recent methods in modeling spatial extreme events have focused on utilizingparametric max-stable processes and their underlying dependence structure. Inthis work, we provide a unified approach for analyzing spatial extremes withlittle available data by estimating the distribution of model parameters or thespatial dependence directly. By employing recent developments in generativeneural networks we predict a full sample-based distribution, allowing fordirect assessment of uncertainty regarding model parameters or other parameterdependent functionals. We validate our method by fitting several simulatedmax-stable processes, showing a high accuracy of the approach, regardingparameter estimation, as well as uncertainty quantification. Additionalrobustness checks highlight the generalization and extrapolation capabilitiesof the model, while an application to precipitation extremes across WesternGermany demonstrates the usability of our approach in real-world scenarios.</description><author>Christopher Bülte, Lisa Leimenstoll, Melanie Schienle</author><pubDate>Thu, 11 Jul 2024 16:57:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08668v1</guid></item><item><title>Uncertainty Estimation of Large Language Models in Medical Question Answering</title><link>http://arxiv.org/abs/2407.08662v1</link><description>Large Language Models (LLMs) show promise for natural language generation inhealthcare, but risk hallucinating factually incorrect information. DeployingLLMs for medical question answering necessitates reliable uncertaintyestimation (UE) methods to detect hallucinations. In this work, we benchmarkpopular UE methods with different model sizes on medical question-answeringdatasets. Our results show that current approaches generally perform poorly inthis domain, highlighting the challenge of UE for medical applications. We alsoobserve that larger models tend to yield better results, suggesting acorrelation between model size and the reliability of UE. To address thesechallenges, we propose Two-phase Verification, a probability-free UncertaintyEstimation approach. First, an LLM generates a step-by-step explanationalongside its initial answer, followed by formulating verification questions tocheck the factual claims in the explanation. The model then answers thesequestions twice: first independently, and then referencing the explanation.Inconsistencies between the two sets of answers measure the uncertainty in theoriginal response. We evaluate our approach on three biomedicalquestion-answering datasets using Llama 2 Chat models and compare it againstthe benchmarked baseline methods. The results show that our Two-phaseVerification method achieves the best overall accuracy and stability acrossvarious datasets and model sizes, and its performance scales as the model sizeincreases.</description><author>Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou</author><pubDate>Thu, 11 Jul 2024 16:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08662v1</guid></item><item><title>BeTAIL: Behavior Transformer Adversarial Imitation Learning from Human Racing Gameplay</title><link>http://arxiv.org/abs/2402.14194v2</link><description>Imitation learning learns a policy from demonstrations without requiringhand-designed reward functions. In many robotic tasks, such as autonomousracing, imitated policies must model complex environment dynamics and humandecision-making. Sequence modeling is highly effective in capturing intricatepatterns of motion sequences but struggles to adapt to new environments ordistribution shifts that are common in real-world robotics tasks. In contrast,Adversarial Imitation Learning (AIL) can mitigate this effect, but struggleswith sample inefficiency and handling complex motion patterns. Thus, we proposeBeTAIL: Behavior Transformer Adversarial Imitation Learning, which combines aBehavior Transformer (BeT) policy from human demonstrations with online AIL.BeTAIL adds an AIL residual policy to the BeT policy to model the sequentialdecision-making process of human experts and correct for out-of-distributionstates or shifts in environment dynamics. We test BeTAIL on three challengeswith expert-level demonstrations of real human gameplay in Gran Turismo Sport.Our proposed residual BeTAIL reduces environment interactions and improvesracing performance and stability, even when the BeT is pretrained on differenttracks than downstream learning. Videos and code available at:https://sites.google.com/berkeley.edu/BeTAIL/home.</description><author>Catherine Weaver, Chen Tang, Ce Hao, Kenta Kawamoto, Masayoshi Tomizuka, Wei Zhan</author><pubDate>Thu, 11 Jul 2024 16:50:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14194v2</guid></item><item><title>Controlling the Fidelity and Diversity of Deep Generative Models via Pseudo Density</title><link>http://arxiv.org/abs/2407.08659v1</link><description>We introduce an approach to bias deep generative models, such as GANs anddiffusion models, towards generating data with either enhanced fidelity orincreased diversity. Our approach involves manipulating the distribution oftraining and generated data through a novel metric for individual samples,named pseudo density, which is based on the nearest-neighbor information fromreal samples. Our approach offers three distinct techniques to adjust thefidelity and diversity of deep generative models: 1) Per-sample perturbation,enabling precise adjustments for individual samples towards either more commonor more unique characteristics; 2) Importance sampling during model inferenceto enhance either fidelity or diversity in the generated data; 3) Fine-tuningwith importance sampling, which guides the generative model to learn anadjusted distribution, thus controlling fidelity and diversity. Furthermore,our fine-tuning method demonstrates the ability to improve the FrechetInception Distance (FID) for pre-trained generative models with minimaliterations.</description><author>Shuangqi Li, Chen Liu, Tong Zhang, Hieu Le, Sabine Süsstrunk, Mathieu Salzmann</author><pubDate>Thu, 11 Jul 2024 16:46:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08659v1</guid></item><item><title>A Distributed ADMM-based Deep Learning Approach for Thermal Control in Multi-Zone Buildings under Demand Response Events</title><link>http://arxiv.org/abs/2312.05073v2</link><description>The increasing electricity use and reliance on intermittent renewable energysources challenge power grid management during peak demand, making DemandResponse programs and energy conservation measures essential. This researchcombines distributed optimization using ADMM with deep learning models to planindoor temperature setpoints effectively. A two-layer hierarchical structure isused, with a central building coordinator at the upper layer and localcontrollers at the thermal zone layer. The coordinator must limit thebuilding's maximum power by translating the building's total power to localpower targets for each zone. Local controllers can modify the temperaturesetpoints to meet the local power targets. While most algorithms are eithercentralized or require prior knowledge about the building's structure, ourapproach is distributed and fully data-driven. The proposed algorithm, calledDistributed Planning Networks, is designed to be both adaptable and scalable tomany types of buildings, tackling two of the main challenges in the developmentof such systems. The proposed approach is tested on an 18-zone building modeledin EnergyPlus. The algorithm successfully manages Demand Response peak events.</description><author>Vincent Taboga, Hanane Dagdougui</author><pubDate>Thu, 11 Jul 2024 16:43:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05073v2</guid></item><item><title>SPOCKMIP: Segmentation of Vessels in MRAs with Enhanced Continuity using Maximum Intensity Projection as Loss</title><link>http://arxiv.org/abs/2407.08655v1</link><description>Identification of vessel structures of different sizes in biomedical imagesis crucial in the diagnosis of many neurodegenerative diseases. However, thesparsity of good-quality annotations of such images makes the task of vesselsegmentation challenging. Deep learning offers an efficient way to segmentvessels of different sizes by learning their high-level feature representationsand the spatial continuity of such features across dimensions. Semi-supervisedpatch-based approaches have been effective in identifying small vessels of oneto two voxels in diameter. This study focuses on improving the segmentationquality by considering the spatial correlation of the features using theMaximum Intensity Projection~(MIP) as an additional loss criterion. Two methodsare proposed with the incorporation of MIPs of label segmentation on thesingle~(z-axis) and multiple perceivable axes of the 3D volume. The proposedMIP-based methods produce segmentations with improved vessel continuity, whichis evident in visual examinations of ROIs. Patch-based training is improved byintroducing an additional loss term, MIP loss, to penalise the predicteddiscontinuity of vessels. A training set of 14 volumes is selected from theStudyForrest dataset comprising of 18 7-Tesla 3D Time-of-Flight~(ToF) MagneticResonance Angiography (MRA) images. The generalisation performance of themethod is evaluated using the other unseen volumes in the dataset. It isobserved that the proposed method with multi-axes MIP loss produces betterquality segmentations with a median Dice of $80.245 \pm 0.129$. Also, themethod with single-axis MIP loss produces segmentations with a median Dice of$79.749 \pm 0.109$. Furthermore, a visual comparison of the ROIs in thepredicted segmentation reveals a significant improvement in the continuity ofthe vessels when MIP loss is incorporated into training.</description><author>Chethan Radhakrishna, Karthikesh Varma Chintalapati, Sri Chandana Hudukula Ram Kumar, Raviteja Sutrave, Hendrik Mattern, Oliver Speck, Andreas Nürnberger, Soumick Chatterjee</author><pubDate>Thu, 11 Jul 2024 16:39:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08655v1</guid></item><item><title>Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?</title><link>http://arxiv.org/abs/2406.12822v2</link><description>Large language models, particularly multilingual ones, are designed, claimed,and expected to cater to native speakers of varied languages. We hypothesisethat the current practices of fine-tuning and evaluating these models may notperfectly align with this objective owing to a heavy reliance on translation,which can introduce translation artefacts and defects. It remains unknownwhether the nature of the instruction data has an impact on the model output;conversely, it is questionable whether translated test sets can capture suchnuances. Due to the often coupled practices of using translated data in bothstages, such imperfections could have been overlooked. This work investigatesthese issues using controlled native or translated data during instructiontuning and evaluation stages. Experiments on eight base models and eightdifferent benchmarks show that native or generation benchmarks reveal a notabledifference between native and translated instruction data especially when modelperformance is high, whereas other types of test sets cannot. The comparisonbetween round-trip and single-pass translations reflects the importance ofknowledge from language-native resources. Finally, we demonstrate thatregularization is beneficial to bridging this gap on structured but notgenerative tasks.</description><author>Pinzhen Chen, Simon Yu, Zhicheng Guo, Barry Haddow</author><pubDate>Thu, 11 Jul 2024 16:37:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12822v2</guid></item><item><title>Adaptive Smooth Non-Stationary Bandits</title><link>http://arxiv.org/abs/2407.08654v1</link><description>We study a $K$-armed non-stationary bandit model where rewards changesmoothly, as captured by H\"{o}lder class assumptions on rewards as functionsof time. Such smooth changes are parametrized by a H\"{o}lder exponent $\beta$and coefficient $\lambda$. While various sub-cases of this general model havebeen studied in isolation, we first establish the minimax dynamic regret rategenerally for all $K,\beta,\lambda$. Next, we show this optimal dynamic regretcan be attained adaptively, without knowledge of $\beta,\lambda$. To contrast,even with parameter knowledge, upper bounds were only previously known forlimited regimes $\beta\leq 1$ and $\beta=2$ (Slivkins, 2014; Krishnamurthy andGopalan, 2021; Manegueu et al., 2021; Jia et al.,2023). Thus, our work resolvesopen questions raised by these disparate threads of the literature. We also study the problem of attaining faster gap-dependent regret rates innon-stationary bandits. While such rates are long known to be impossible ingeneral (Garivier and Moulines, 2011), we show that environments admitting asafe arm (Suk and Kpotufe, 2022) allow for much faster rates than theworst-case scaling with $\sqrt{T}$. While previous works in this directionfocused on attaining the usual logarithmic regret bounds, as summed overstationary periods, our new gap-dependent rates reveal new optimistic regimesof non-stationarity where even the logarithmic bounds are pessimistic. We showour new gap-dependent rate is tight and that its achievability (i.e., as madepossible by a safe arm) has a surprisingly simple and clean characterizationwithin the smooth H\"{o}lder class model.</description><author>Joe Suk</author><pubDate>Thu, 11 Jul 2024 16:37:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08654v1</guid></item><item><title>Large Pre-trained time series models for cross-domain Time series analysis tasks</title><link>http://arxiv.org/abs/2311.11413v2</link><description>Large pre-trained models have been vital in recent advancements in domainslike language and vision, making model training for individual downstream tasksmore efficient and provide superior performance. However, tackling time-seriesanalysis tasks usually involves designing and training a separate model fromscratch leveraging training data and domain expertise specific to the task. Wetackle a significant challenge for pre-training a foundational time-seriesmodel from multi-domain time-series datasets: extracting semantically useful tokenized inputs to the model across heterogenous time-series from different domains. We propose LargePre-trained Time-series Models (LPTM) that introduces a novel method of\textit{adaptive segmentation} that automatically identifies optimaldataset-specific segmentation strategy during pre-training. This enables LPTM to perform similar to or better than domain-specific state-of-art model when fine-tuned to different downstream time-series analysis tasks and underzero-shot settings. LPTM achieves superior forecasting and time-series classification results taking up to 40% less data and 50% less training time compared to state-of-art baselines.</description><author>Harshavardhan Kamarthi, B. Aditya Prakash</author><pubDate>Thu, 11 Jul 2024 16:32:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11413v2</guid></item><item><title>IntrinsicAvatar: Physically Based Inverse Rendering of Dynamic Humans from Monocular Videos via Explicit Ray Tracing</title><link>http://arxiv.org/abs/2312.05210v2</link><description>We present IntrinsicAvatar, a novel approach to recovering the intrinsicproperties of clothed human avatars including geometry, albedo, material, andenvironment lighting from only monocular videos. Recent advancements inhuman-based neural rendering have enabled high-quality geometry and appearancereconstruction of clothed humans from just monocular videos. However, thesemethods bake intrinsic properties such as albedo, material, and environmentlighting into a single entangled neural representation. On the other hand, onlya handful of works tackle the problem of estimating geometry and disentangledappearance properties of clothed humans from monocular videos. They usuallyachieve limited quality and disentanglement due to approximations of secondaryshading effects via learned MLPs. In this work, we propose to model secondaryshading effects explicitly via Monte-Carlo ray tracing. We model the renderingprocess of clothed humans as a volumetric scattering process, and combine raytracing with body articulation. Our approach can recover high-quality geometry,albedo, material, and lighting properties of clothed humans from a singlemonocular video, without requiring supervised pre-training using ground truthmaterials. Furthermore, since we explicitly model the volumetric scatteringprocess and ray tracing, our model naturally generalizes to novel poses,enabling animation of the reconstructed avatar in novel lighting conditions.</description><author>Shaofei Wang, Božidar Antić, Andreas Geiger, Siyu Tang</author><pubDate>Thu, 11 Jul 2024 16:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05210v2</guid></item><item><title>Latent Spaces Enable Transformer-Based Dose Prediction in Complex Radiotherapy Plans</title><link>http://arxiv.org/abs/2407.08650v1</link><description>Evidence is accumulating in favour of using stereotactic ablative bodyradiotherapy (SABR) to treat multiple cancer lesions in the lung. Multi-lesionlung SABR plans are complex and require significant resources to create. Inthis work, we propose a novel two-stage latent transformer framework (LDFormer)for dose prediction of lung SABR plans with varying numbers of lesions. In thefirst stage, patient anatomical information and the dose distribution areencoded into a latent space. In the second stage, a transformer learns topredict the dose latent from the anatomical latents. Causal attention ismodified to adapt to different numbers of lesions. LDFormer outperforms astate-of-the-art generative adversarial network on dose conformality in andaround lesions, and the performance gap widens when considering overlappinglesions. LDFormer generates predictions of 3-D dose distributions in under 30son consumer hardware, and has the potential to assist physicians with clinicaldecision making, reduce resource costs, and accelerate treatment planning.</description><author>Edward Wang, Ryan Au, Pencilla Lang, Sarah A. Mattonen</author><pubDate>Thu, 11 Jul 2024 16:28:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08650v1</guid></item><item><title>Confidence-based Estimators for Predictive Performance in Model Monitoring</title><link>http://arxiv.org/abs/2407.08649v1</link><description>After a machine learning model has been deployed into production, itspredictive performance needs to be monitored. Ideally, such monitoring can becarried out by comparing the model's predictions against ground truth labels.For this to be possible, the ground truth labels must be available relativelysoon after inference. However, there are many use cases where ground truthlabels are available only after a significant delay, or in the worst case, notat all. In such cases, directly monitoring the model's predictive performanceis impossible. Recently, novel methods for estimating the predictive performance of a modelwhen ground truth is unavailable have been developed. Many of these methodsleverage model confidence or other uncertainty estimates and are experimentallycompared against a naive baseline method, namely Average Confidence (AC), whichestimates model accuracy as the average of confidence scores for a given set ofpredictions. However, until now the theoretical properties of the AC methodhave not been properly explored. In this paper, we try to fill this gap byreviewing the AC method and show that under certain general assumptions, it isan unbiased and consistent estimator of model accuracy with many desirableproperties. We also compare this baseline estimator against some more complexestimators empirically and show that in many cases the AC method is able tobeat the others, although the comparative quality of the different estimatorsis heavily case-dependent.</description><author>Juhani Kivimäki, Jakub Białek, Jukka K. Nurminen, Wojtek Kuberski</author><pubDate>Thu, 11 Jul 2024 16:28:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08649v1</guid></item><item><title>BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark</title><link>http://arxiv.org/abs/2407.07788v2</link><description>We introduce BiGym, a new benchmark and learning environment for mobilebi-manual demo-driven robotic manipulation. BiGym features 40 diverse tasks setin home environments, ranging from simple target reaching to complex kitchencleaning. To capture the real-world performance accurately, we providehuman-collected demonstrations for each task, reflecting the diverse modalitiesfound in real-world robot trajectories. BiGym supports a variety ofobservations, including proprioceptive data and visual inputs such as RGB, anddepth from 3 camera views. To validate the usability of BiGym, we thoroughlybenchmark the state-of-the-art imitation learning algorithms and demo-drivenreinforcement learning algorithms within the environment and discuss the futureopportunities.</description><author>Nikita Chernyadev, Nicholas Backshall, Xiao Ma, Yunfan Lu, Younggyo Seo, Stephen James</author><pubDate>Thu, 11 Jul 2024 16:26:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07788v2</guid></item><item><title>CAR-MFL: Cross-Modal Augmentation by Retrieval for Multimodal Federated Learning with Missing Modalities</title><link>http://arxiv.org/abs/2407.08648v1</link><description>Multimodal AI has demonstrated superior performance over unimodal approachesby leveraging diverse data sources for more comprehensive analysis. However,applying this effectiveness in healthcare is challenging due to the limitedavailability of public datasets. Federated learning presents an excitingsolution, allowing the use of extensive databases from hospitals and healthcenters without centralizing sensitive data, thus maintaining privacy andsecurity. Yet, research in multimodal federated learning, particularly inscenarios with missing modalities a common issue in healthcare datasets remainsscarce, highlighting a critical area for future exploration. Toward this, wepropose a novel method for multimodal federated learning with missingmodalities. Our contribution lies in a novel cross-modal data augmentation byretrieval, leveraging the small publicly available dataset to fill the missingmodalities in the clients. Our method learns the parameters in a federatedmanner, ensuring privacy protection and improving performance in multiplechallenging multimodal benchmarks in the medical domain, surpassing severalcompetitive baselines. Code Available: https://github.com/bhattarailab/CAR-MFL</description><author>Pranav Poudel, Prashant Shrestha, Sanskar Amgain, Yash Raj Shrestha, Prashnna Gyawali, Binod Bhattarai</author><pubDate>Thu, 11 Jul 2024 16:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08648v1</guid></item><item><title>MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model</title><link>http://arxiv.org/abs/2405.20222v3</link><description>We present MOFA-Video, an advanced controllable image animation method thatgenerates video from the given image using various additional controllablesignals (such as human landmarks reference, manual trajectories, and anothereven provided video) or their combinations. This is different from previousmethods which only can work on a specific motion domain or show weak controlabilities with diffusion prior. To achieve our goal, we design severaldomain-aware motion field adapters (\ie, MOFA-Adapters) to control thegenerated motions in the video generation pipeline. For MOFA-Adapters, weconsider the temporal motion consistency of the video and generate the densemotion flow from the given sparse control conditions first, and then, themulti-scale features of the given image are wrapped as a guided feature forstable video diffusion generation. We naively train two motion adapters for themanual trajectories and the human landmarks individually since they bothcontain sparse information about the control. After training, the MOFA-Adaptersin different domains can also work together for more controllable videogeneration. Project Page: https://myniuuu.github.io/MOFA_Video/</description><author>Muyao Niu, Xiaodong Cun, Xintao Wang, Yong Zhang, Ying Shan, Yinqiang Zheng</author><pubDate>Thu, 11 Jul 2024 16:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20222v3</guid></item><item><title>From Real to Cloned Singer Identification</title><link>http://arxiv.org/abs/2407.08647v1</link><description>Cloned voices of popular singers sound increasingly realistic and have gainedpopularity over the past few years. They however pose a threat to the industrydue to personality rights concerns. As such, methods to identify the originalsinger in synthetic voices are needed. In this paper, we investigate how singeridentification methods could be used for such a task. We present threeembedding models that are trained using a singer-level contrastive learningscheme, where positive pairs consist of segments with vocals from the samesingers. These segments can be mixtures for the first model, vocals for thesecond, and both for the third. We demonstrate that all three models are highlycapable of identifying real singers. However, their performance deteriorateswhen classifying cloned versions of singers in our evaluation set. This isespecially true for models that use mixtures as an input. These findingshighlight the need to understand the biases that exist within singeridentification systems, and how they can influence the identification of voicedeepfakes in music.</description><author>Dorian Desblancs, Gabriel Meseguer-Brocal, Romain Hennequin, Manuel Moussallam</author><pubDate>Thu, 11 Jul 2024 16:25:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08647v1</guid></item><item><title>BenthicNet: A global compilation of seafloor images for deep learning applications</title><link>http://arxiv.org/abs/2405.05241v2</link><description>Advances in underwater imaging enable the collection of extensive seafloorimage datasets that are necessary for monitoring important benthic ecosystems.The ability to collect seafloor imagery has outpaced our capacity to analyzeit, hindering expedient mobilization of this crucial environmental information.Recent machine learning approaches provide opportunities to increase theefficiency with which seafloor image datasets are analyzed, yet large andconsistent datasets necessary to support development of such approaches arescarce. Here we present BenthicNet: a global compilation of seafloor imagerydesigned to support the training and evaluation of large-scale imagerecognition models. An initial set of over 11.4 million images was collectedand curated to represent a diversity of seafloor environments using arepresentative subset of 1.3 million images. These are accompanied by 2.6million annotations translated to the CATAMI scheme, which span 190,000 of theimages. A large deep learning model was trained on this compilation andpreliminary results suggest it has utility for automating large and small-scaleimage analysis tasks. The compilation and model are made openly available foruse by the scientific community at https://doi.org/10.20383/103.0614.</description><author>Scott C. Lowe, Benjamin Misiuk, Isaac Xu, Shakhboz Abdulazizov, Amit R. Baroi, Alex C. Bastos, Merlin Best, Vicki Ferrini, Ariell Friedman, Deborah Hart, Ove Hoegh-Guldberg, Daniel Ierodiaconou, Julia Mackin-McLaughlin, Kathryn Markey, Pedro S. Menandro, Jacquomo Monk, Shreya Nemani, John O'Brien, Elizabeth Oh, Luba Y. Reshitnyk, Katleen Robert, Chris M. Roelfsema, Jessica A. Sameoto, Alexandre C. G. Schimel, Jordan A. Thomson, Brittany R. Wilson, Melisa C. Wong, Craig J. Brown, Thomas Trappenberg</author><pubDate>Thu, 11 Jul 2024 16:24:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05241v2</guid></item><item><title>Towards Building Specialized Generalist AI with System 1 and System 2 Fusion</title><link>http://arxiv.org/abs/2407.08642v1</link><description>In this perspective paper, we introduce the concept of Specialized GeneralistArtificial Intelligence (SGAI or simply SGI) as a crucial milestone towardArtificial General Intelligence (AGI). Compared to directly scaling generalabilities, SGI is defined as AI that specializes in at least one task,surpassing human experts, while also retaining general abilities. This fusionpath enables SGI to rapidly achieve high-value areas. We categorize SGI intothree stages based on the level of mastery over professional skills andgenerality performance. Additionally, we discuss the necessity of SGI inaddressing issues associated with large language models, such as theirinsufficient generality, specialized capabilities, uncertainty in innovation,and practical applications. Furthermore, we propose a conceptual framework fordeveloping SGI that integrates the strengths of Systems 1 and 2 cognitiveprocessing. This framework comprises three layers and four key components,which focus on enhancing individual abilities and facilitating collaborativeevolution. We conclude by summarizing the potential challenges and suggestingfuture directions. We hope that the proposed SGI will provide insights intofurther research and applications towards achieving AGI.</description><author>Kaiyan Zhang, Biqing Qi, Bowen Zhou</author><pubDate>Thu, 11 Jul 2024 16:23:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08642v1</guid></item><item><title>UP-FacE: User-predictable Fine-grained Face Shape Editing</title><link>http://arxiv.org/abs/2403.13972v3</link><description>We present User-predictable Face Editing (UP-FacE) -- a novel method forpredictable face shape editing. In stark contrast to existing methods for faceediting using trial and error, edits with UP-FacE are predictable by the humanuser. That is, users can control the desired degree of change precisely anddeterministically and know upfront the amount of change required to achieve acertain editing result. Our method leverages facial landmarks to preciselymeasure facial feature values, facilitating the training of UP-FacE withoutmanually annotated attribute labels. At the core of UP-FacE is atransformer-based network that takes as input a latent vector from apre-trained generative model and a facial feature embedding, and predicts asuitable manipulation vector. To enable user-predictable editing, a scalinglayer adjusts the manipulation vector to achieve the precise desired degree ofchange. To ensure that the desired feature is manipulated towards the targetvalue without altering uncorrelated features, we further introduce a novelsemantic face feature loss. Qualitative and quantitative results demonstratethat UP-FacE enables precise and fine-grained control over 23 face shapefeatures.</description><author>Florian Strohm, Mihai Bâce, Andreas Bulling</author><pubDate>Thu, 11 Jul 2024 16:22:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13972v3</guid></item><item><title>How more data can hurt: Instability and regularization in next-generation reservoir computing</title><link>http://arxiv.org/abs/2407.08641v1</link><description>It has been found recently that more data can, counter-intuitively, hurt theperformance of deep neural networks. Here, we show that a more extreme versionof the phenomenon occurs in data-driven models of dynamical systems. Toelucidate the underlying mechanism, we focus on next-generation reservoircomputing (NGRC) -- a popular framework for learning dynamics from data. Wefind that, despite learning a better representation of the flow map with moretraining data, NGRC can adopt an ill-conditioned ``integrator'' and losestability. We link this data-induced instability to the auxiliary dimensionscreated by the delayed states in NGRC. Based on these findings, we proposesimple strategies to mitigate the instability, either by increasingregularization strength in tandem with data size, or by carefully introducingnoise during training. Our results highlight the importance of properregularization in data-driven modeling of dynamical systems.</description><author>Yuanzhao Zhang, Sean P. Cornelius</author><pubDate>Thu, 11 Jul 2024 16:22:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08641v1</guid></item><item><title>Modality Agnostic Heterogeneous Face Recognition with Switch Style Modulators</title><link>http://arxiv.org/abs/2407.08640v1</link><description>Heterogeneous Face Recognition (HFR) systems aim to enhance the capability offace recognition in challenging cross-modal authentication scenarios. However,the significant domain gap between the source and target modalities poses aconsiderable challenge for cross-domain matching. Existing literature primarilyfocuses on developing HFR approaches for specific pairs of face modalities,necessitating the explicit training of models for each source-targetcombination. In this work, we introduce a novel framework designed to train amodality-agnostic HFR method capable of handling multiple modalities duringinference, all without explicit knowledge of the target modality labels. Weachieve this by implementing a computationally efficient automatic routingmechanism called Switch Style Modulation Blocks (SSMB) that trains variousdomain expert modulators which transform the feature maps adaptively reducingthe domain gap. Our proposed SSMB can be trained end-to-end and seamlesslyintegrated into pre-trained face recognition models, transforming them intomodality-agnostic HFR models. We have performed extensive evaluations on HFRbenchmark datasets to demonstrate its effectiveness. The source code andprotocols will be made publicly available.</description><author>Anjith George, Sebastien Marcel</author><pubDate>Thu, 11 Jul 2024 16:21:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08640v1</guid></item><item><title>$β$-DPO: Direct Preference Optimization with Dynamic $β$</title><link>http://arxiv.org/abs/2407.08639v1</link><description>Direct Preference Optimization (DPO) has emerged as a compelling approach fortraining Large Language Models (LLMs) to adhere to human preferences. However,the performance of DPO is sensitive to the fine-tuning of its trade-offparameter $\beta$, as well as to the quality of the preference data. We analyzethe impact of $\beta$ and data quality on DPO, uncovering that optimal $\beta$values vary with the informativeness of pairwise data. Addressing thelimitations of static $\beta$ values, we introduce a novel framework thatdynamically calibrates $\beta$ at the batch level, informed by data qualityconsiderations. Additionally, our method incorporates $\beta$-guided datafiltering to safeguard against the influence of outliers. Through empiricalevaluation, we demonstrate that our dynamic $\beta$ adjustment techniquesignificantly improves DPO's performance across a range of models and datasets,offering a more robust and adaptable training paradigm for aligning LLMs withhuman feedback. The code is available at\url{https://github.com/junkangwu/beta-DPO}.</description><author>Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He</author><pubDate>Thu, 11 Jul 2024 16:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08639v1</guid></item><item><title>Toto: Time Series Optimized Transformer for Observability</title><link>http://arxiv.org/abs/2407.07874v2</link><description>This technical report describes the Time Series Optimized Transformer forObservability (Toto), a new state of the art foundation model for time seriesforecasting developed by Datadog. In addition to advancing the state of the arton generalized time series benchmarks in domains such as electricity andweather, this model is the first general-purpose time series forecastingfoundation model to be specifically tuned for observability metrics. Toto was trained on a dataset of one trillion time series data points, thelargest among all currently published time series foundation models. Alongsidepublicly available time series datasets, 75% of the data used to train Totoconsists of fully anonymous numerical metric data points from the Datadogplatform. In our experiments, Toto outperforms existing time series foundation modelson observability data. It does this while also excelling at general-purposeforecasting tasks, achieving state-of-the-art zero-shot performance on multipleopen benchmark datasets.</description><author>Ben Cohen, Emaad Khwaja, Kan Wang, Charles Masson, Elise Ramé, Youssef Doubli, Othmane Abou-Amal</author><pubDate>Thu, 11 Jul 2024 16:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07874v2</guid></item><item><title>A Clinical Benchmark of Public Self-Supervised Pathology Foundation Models</title><link>http://arxiv.org/abs/2407.06508v3</link><description>The use of self-supervised learning (SSL) to train pathology foundationmodels has increased substantially in the past few years. Notably, severalmodels trained on large quantities of clinical data have been made publiclyavailable in recent months. This will significantly enhance scientific researchin computational pathology and help bridge the gap between research andclinical deployment. With the increase in availability of public foundationmodels of different sizes, trained using different algorithms on differentdatasets, it becomes important to establish a benchmark to compare theperformance of such models on a variety of clinically relevant tasks spanningmultiple organs and diseases. In this work, we present a collection ofpathology datasets comprising clinical slides associated with clinicallyrelevant endpoints including cancer diagnoses and a variety of biomarkersgenerated during standard hospital operation from two medical centers. Weleverage these datasets to systematically assess the performance of publicpathology foundation models and provide insights into best practices fortraining new foundation models and selecting appropriate pretrained models.</description><author>Gabriele Campanella, Shengjia Chen, Ruchika Verma, Jennifer Zeng, Aryeh Stock, Matt Croken, Brandon Veremis, Abdulkadir Elmas, Kuan-lin Huang, Ricky Kwan, Jane Houldsworth, Adam J. Schoenfeld, Chad Vanderbilt</author><pubDate>Thu, 11 Jul 2024 16:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06508v3</guid></item><item><title>RTMW: Real-Time Multi-Person 2D and 3D Whole-body Pose Estimation</title><link>http://arxiv.org/abs/2407.08634v1</link><description>Whole-body pose estimation is a challenging task that requires simultaneousprediction of keypoints for the body, hands, face, and feet. Whole-body poseestimation aims to predict fine-grained pose information for the human body,including the face, torso, hands, and feet, which plays an important role inthe study of human-centric perception and generation and in variousapplications. In this work, we present RTMW (Real-Time Multi-person Whole-bodypose estimation models), a series of high-performance models for 2D/3Dwhole-body pose estimation. We incorporate RTMPose model architecture with FPNand HEM (Hierarchical Encoding Module) to better capture pose information fromdifferent body parts with various scales. The model is trained with a richcollection of open-source human keypoint datasets with manually alignedannotations and further enhanced via a two-stage distillation strategy. RTMWdemonstrates strong performance on multiple whole-body pose estimationbenchmarks while maintaining high inference efficiency and deploymentfriendliness. We release three sizes: m/l/x, with RTMW-l achieving a 70.2 mAPon the COCO-Wholebody benchmark, making it the first open-source model toexceed 70 mAP on this benchmark. Meanwhile, we explored the performance of RTMWin the task of 3D whole-body pose estimation, conducting image-based monocular3D whole-body pose estimation in a coordinate classification manner. We hopethis work can benefit both academic research and industrial applications. Thecode and models have been made publicly available at:https://github.com/open-mmlab/mmpose/tree/main/projects/rtmpose</description><author>Tao Jiang, Xinchen Xie, Yining Li</author><pubDate>Thu, 11 Jul 2024 16:15:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08634v1</guid></item><item><title>A Novel Framework for Automated Warehouse Layout Generation</title><link>http://arxiv.org/abs/2407.08633v1</link><description>Optimizing warehouse layouts is crucial due to its significant impact onefficiency and productivity. We present an AI-driven framework for automatedwarehouse layout generation. This framework employs constrained beam search toderive optimal layouts within given spatial parameters, adhering to allfunctional requirements. The feasibility of the generated layouts is verifiedbased on criteria such as item accessibility, required minimum clearances, andaisle connectivity. A scoring function is then used to evaluate the feasiblelayouts considering the number of storage locations, access points, andaccessibility costs. We demonstrate our method's ability to produce feasible,optimal layouts for a variety of warehouse dimensions and shapes, diverse doorplacements, and interconnections. This approach, currently being prepared fordeployment, will enable human designers to rapidly explore and confirm options,facilitating the selection of the most appropriate layout for their use-case.</description><author>Atefeh Shahroudnejad, Payam Mousavi, Oleksii Perepelytsia, Sahir, David Staszak, Matthew E. Taylor, Brent Bawel</author><pubDate>Thu, 11 Jul 2024 16:15:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08633v1</guid></item><item><title>Generalization Error Matters in Decentralized Learning Under Byzantine Attacks</title><link>http://arxiv.org/abs/2407.08632v1</link><description>Recently, decentralized learning has emerged as a popular peer-to-peer signaland information processing paradigm that enables model training acrossgeographically distributed agents in a scalable manner, without the presence ofany central server. When some of the agents are malicious (also termed asByzantine), resilient decentralized learning algorithms are able to limit theimpact of these Byzantine agents without knowing their number and identities,and have guaranteed optimization errors. However, analysis of thegeneralization errors, which are critical to implementations of the trainedmodels, is still lacking. In this paper, we provide the first analysis of thegeneralization errors for a class of popular Byzantine-resilient decentralizedstochastic gradient descent (DSGD) algorithms. Our theoretical results revealthat the generalization errors cannot be entirely eliminated because of thepresence of the Byzantine agents, even if the number of training samples areinfinitely large. Numerical experiments are conducted to confirm ourtheoretical results.</description><author>Haoxiang Ye, Qing Ling</author><pubDate>Thu, 11 Jul 2024 16:12:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08632v1</guid></item><item><title>RoboMorph: Evolving Robot Morphology using Large Language Models</title><link>http://arxiv.org/abs/2407.08626v1</link><description>We introduce RoboMorph, an automated approach for generating and optimizingmodular robot designs using large language models (LLMs) and evolutionaryalgorithms. In this framework, we represent each robot design as a grammar andleverage the capabilities of LLMs to navigate the extensive robot design space,which is traditionally time-consuming and computationally demanding. Byintegrating automatic prompt design and a reinforcement learning based controlalgorithm, RoboMorph iteratively improves robot designs through feedback loops.Our experimental results demonstrate that RoboMorph can successfully generatenontrivial robots that are optimized for a single terrain while showcasingimprovements in morphology over successive evolutions. Our approachdemonstrates the potential of using LLMs for data-driven and modular robotdesign, providing a promising methodology that can be extended to other domainswith similar design frameworks.</description><author>Kevin Qiu, Krzysztof Ciebiera, Paweł Fijałkowski, Marek Cygan, Łukasz Kuciński</author><pubDate>Thu, 11 Jul 2024 16:05:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08626v1</guid></item><item><title>RAIFLE: Reconstruction Attacks on Interaction-based Federated Learning with Adversarial Data Manipulation</title><link>http://arxiv.org/abs/2310.19163v2</link><description>Federated learning has emerged as a promising privacy-preserving solution formachine learning domains that rely on user interactions, particularlyrecommender systems and online learning to rank. While there has beensubstantial research on the privacy of traditional federated learning, littleattention has been paid to the privacy properties of these interaction-basedsettings. In this work, we show that users face an elevated risk of havingtheir private interactions reconstructed by the central server when the servercan control the training features of the items that users interact with. Weintroduce RAIFLE, a novel optimization-based attack framework where the serveractively manipulates the features of the items presented to users to increasethe success rate of reconstruction. Our experiments with federatedrecommendation and online learning-to-rank scenarios demonstrate that RAIFLE issignificantly more powerful than existing reconstruction attacks like gradientinversion, achieving high performance consistently in most settings. We discussthe pros and cons of several possible countermeasures to defend against RAIFLEin the context of interaction-based federated learning. Our code isopen-sourced at https://github.com/dzungvpham/raifle.</description><author>Dzung Pham, Shreyas Kulkarni, Amir Houmansadr</author><pubDate>Thu, 11 Jul 2024 16:04:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19163v2</guid></item><item><title>Histopathological Image Classification with Cell Morphology Aware Deep Neural Networks</title><link>http://arxiv.org/abs/2407.08625v1</link><description>Histopathological images are widely used for the analysis of diseased (tumor)tissues and patient treatment selection. While the majority of microscopy imageprocessing was previously done manually by pathologists, recent advances incomputer vision allow for accurate recognition of lesion regions with deeplearning-based solutions. Such models, however, usually require extensiveannotated datasets for training, which is often not the case in the consideredtask, where the number of available patient data samples is very limited. Todeal with this problem, we propose a novel DeepCMorph model pre-trained tolearn cell morphology and identify a large number of different cancer types.The model consists of two modules: the first one performs cell nucleisegmentation and annotates each cell type, and is trained on a combination of 8publicly available datasets to ensure its high generalizability and robustness.The second module combines the obtained segmentation map with the originalmicroscopy image and is trained for the downstream task. We pre-trained thismodule on the Pan-Cancer TCGA dataset consisting of over 270K tissue patchesextracted from 8736 diagnostic slides from 7175 patients. The proposed solutionachieved a new state-of-the-art performance on the dataset under consideration,detecting 32 cancer types with over 82% accuracy and outperforming allpreviously proposed solutions by more than 4%. We demonstrate that theresulting pre-trained model can be easily fine-tuned on smaller microscopydatasets, yielding superior results compared to the current top solutions andmodels initialized with ImageNet weights. The codes and pre-trained modelspresented in this paper are available at: https://github.com/aiff22/DeepCMorph</description><author>Andrey Ignatov, Josephine Yates, Valentina Boeva</author><pubDate>Thu, 11 Jul 2024 16:03:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08625v1</guid></item><item><title>Surpassing Cosine Similarity for Multidimensional Comparisons: Dimension Insensitive Euclidean Metric (DIEM)</title><link>http://arxiv.org/abs/2407.08623v1</link><description>The advancement in computational power and hardware efficiency has enabledthe tackling of increasingly complex and high-dimensional problems. Whileartificial intelligence (AI) has achieved remarkable results in variousscientific and technological fields, the interpretability of thesehigh-dimensional solutions remains challenging. A critical issue in thiscontext is the comparison of multidimensional quantities, which is essential intechniques like Principal Component Analysis (PCA), Singular ValueDecomposition (SVD), and k-means clustering. Common metrics such as cosinesimilarity, Euclidean distance, and Manhattan distance are often used for suchcomparisons - for example in muscular synergies of the human motor controlsystem. However, their applicability and interpretability diminish asdimensionality increases. This paper provides a comprehensive analysis of theeffects of dimensionality on these three widely used metrics. Our resultsreveal significant limitations of cosine similarity, particularly itsdependency on the dimensionality of the vectors, leading to biased and lessinterpretable outcomes. To address this, we introduce the Dimension InsensitiveEuclidean Metric (DIEM), derived from the Euclidean distance, whichdemonstrates superior robustness and generalizability across varyingdimensions. DIEM maintains consistent variability and eliminates the biasesobserved in traditional metrics, making it a more reliable tool forhigh-dimensional comparisons. This novel metric has the potential to replacecosine similarity, providing a more accurate and insightful method to analyzemultidimensional data in fields ranging from neuromotor control to machinelearning and deep learning.</description><author>Federico Tessari, Neville Hogan</author><pubDate>Thu, 11 Jul 2024 16:00:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08623v1</guid></item><item><title>AdaGlimpse: Active Visual Exploration with Arbitrary Glimpse Position and Scale</title><link>http://arxiv.org/abs/2404.03482v2</link><description>Active Visual Exploration (AVE) is a task that involves dynamically selectingobservations (glimpses), which is critical to facilitate comprehension andnavigation within an environment. While modern AVE methods have demonstratedimpressive performance, they are constrained to fixed-scale glimpses from rigidgrids. In contrast, existing mobile platforms equipped with optical zoomcapabilities can capture glimpses of arbitrary positions and scales. To addressthis gap between software and hardware capabilities, we introduce AdaGlimpse.It uses Soft Actor-Critic, a reinforcement learning algorithm tailored forexploration tasks, to select glimpses of arbitrary position and scale. Thisapproach enables our model to rapidly establish a general awareness of theenvironment before zooming in for detailed analysis. Experimental resultsdemonstrate that AdaGlimpse surpasses previous methods across various visualtasks while maintaining greater applicability in realistic AVE scenarios.</description><author>Adam Pardyl, Michał Wronka, Maciej Wołczyk, Kamil Adamczewski, Tomasz Trzciński, Bartosz Zieliński</author><pubDate>Thu, 11 Jul 2024 16:00:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03482v2</guid></item><item><title>Particle Swarm Optimization based on Novelty Search</title><link>http://arxiv.org/abs/2203.05674v3</link><description>In this paper we propose a Particle Swarm Optimization algorithm combinedwith Novelty Search. Novelty Search finds novel place to search in the searchdomain and then Particle Swarm Optimization rigorously searches that area forglobal optimum solution. This method is never blocked in local optima becauseit is controlled by Novelty Search which is objective free. For those functionswhere there are many more local optima and second global optimum is far fromtrue optimum, the present method works successfully. The present algorithmnever stops until it searches entire search area. A series of experimentaltrials prove the robustness and effectiveness of the present algorithm oncomplex optimization test functions.</description><author>Mr. Rajesh Misra, Dr. Kumar S Ray</author><pubDate>Thu, 11 Jul 2024 16:00:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.05674v3</guid></item><item><title>Tamil Language Computing: the Present and the Future</title><link>http://arxiv.org/abs/2407.08618v1</link><description>This paper delves into the text processing aspects of Language Computing,which enables computers to understand, interpret, and generate human language.Focusing on tasks such as speech recognition, machine translation, sentimentanalysis, text summarization, and language modelling, language computingintegrates disciplines including linguistics, computer science, and cognitivepsychology to create meaningful human-computer interactions. Recentadvancements in deep learning have made computers more accessible and capableof independent learning and adaptation. In examining the landscape of languagecomputing, the paper emphasises foundational work like encoding, where Tamiltransitioned from ASCII to Unicode, enhancing digital communication. Itdiscusses the development of computational resources, including raw data,dictionaries, glossaries, annotated data, and computational grammars, necessaryfor effective language processing. The challenges of linguistic annotation, thecreation of treebanks, and the training of large language models are alsocovered, emphasising the need for high-quality, annotated data and advancedlanguage models. The paper underscores the importance of building practicalapplications for languages like Tamil to address everyday communication needs,highlighting gaps in current technology. It calls for increased researchcollaboration, digitization of historical texts, and fostering digital usage toensure the comprehensive development of Tamil language processing, ultimatelyenhancing global communication and access to digital services.</description><author>Kengatharaiyer Sarveswaran</author><pubDate>Thu, 11 Jul 2024 15:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08618v1</guid></item><item><title>Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies</title><link>http://arxiv.org/abs/2402.17396v2</link><description>Large Language Models (LLMs) have revolutionized the field of NaturalLanguage Processing thanks to their ability to reuse knowledge acquired onmassive text corpora on a wide variety of downstream tasks, with minimal (ifany) tuning steps. At the same time, it has been repeatedly shown that LLMslack systematic generalization, which allows to extrapolate the learnedstatistical regularities outside the training distribution. In this work, weoffer a systematic benchmarking of GPT-4, one of the most advanced LLMsavailable, on three algorithmic tasks characterized by the possibility tocontrol the problem difficulty with two parameters. We compare the performanceof GPT-4 with that of its predecessor (GPT-3.5) and with a variant of theTransformer-Encoder architecture recently introduced to solve similar tasks,the Neural Data Router. We find that the deployment of advanced promptingtechniques allows GPT-4 to reach superior accuracy on all tasks, demonstratingthat state-of-the-art LLMs constitute a very strong baseline also inchallenging tasks that require systematic generalization.</description><author>Flavio Petruzzellis, Alberto Testolin, Alessandro Sperduti</author><pubDate>Thu, 11 Jul 2024 15:54:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17396v2</guid></item><item><title>The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise</title><link>http://arxiv.org/abs/2401.07844v5</link><description>Stochastic approximation is a class of algorithms that update a vectoriteratively, incrementally, and stochastically, including, e.g., stochasticgradient descent and temporal difference learning. One fundamental challenge inanalyzing a stochastic approximation algorithm is to establish its stability,i.e., to show that the stochastic vector iterates are bounded almost surely. Inthis paper, we extend the celebrated Borkar-Meyn theorem for stability from theMartingale difference noise setting to the Markovian noise setting, whichgreatly improves its applicability in reinforcement learning, especially inthose off-policy reinforcement learning algorithms with linear functionapproximation and eligibility traces. Central to our analysis is thediminishing asymptotic rate of change of a few functions, which is implied byboth a form of strong law of large numbers and a commonly used V4 Lyapunovdrift condition and trivially holds if the Markov chain is finite andirreducible.</description><author>Shuze Liu, Shuhang Chen, Shangtong Zhang</author><pubDate>Thu, 11 Jul 2024 15:51:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07844v5</guid></item><item><title>Semantic GUI Scene Learning and Video Alignment for Detecting Duplicate Video-based Bug Reports</title><link>http://arxiv.org/abs/2407.08610v1</link><description>Video-based bug reports are increasingly being used to document bugs forprograms centered around a graphical user interface (GUI). However, developingautomated techniques to manage video-based reports is challenging as itrequires identifying and understanding often nuanced visual patterns thatcapture key information about a reported bug. In this paper, we aim to overcomethese challenges by advancing the bug report management task of duplicatedetection for video-based reports. To this end, we introduce a new approach,called JANUS, that adapts the scene-learning capabilities of visiontransformers to capture subtle visual and textual patterns that manifest on appUI screens - which is key to differentiating between similar screens foraccurate duplicate report detection. JANUS also makes use of a video alignmenttechnique capable of adaptive weighting of video frames to account for typicalbug manifestation patterns. In a comprehensive evaluation on a benchmarkcontaining 7,290 duplicate detection tasks derived from 270 video-based bugreports from 90 Android app bugs, the best configuration of our approachachieves an overall mRR/mAP of 89.8%/84.7%, and for the large majority ofduplicate detection tasks, outperforms prior work by around 9% to astatistically significant degree. Finally, we qualitatively illustrate how thescene-learning capabilities provided by Janus benefits its performance.</description><author>Yanfu Yan, Nathan Cooper, Oscar Chaparro, Kevin Moran, Denys Poshyvanyk</author><pubDate>Thu, 11 Jul 2024 15:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08610v1</guid></item><item><title>BiasPruner: Debiased Continual Learning for Medical Image Classification</title><link>http://arxiv.org/abs/2407.08609v1</link><description>Continual Learning (CL) is crucial for enabling networks to dynamically adaptas they learn new tasks sequentially, accommodating new data and classeswithout catastrophic forgetting. Diverging from conventional perspectives onCL, our paper introduces a new perspective wherein forgetting could actuallybenefit the sequential learning paradigm. Specifically, we present BiasPruner,a CL framework that intentionally forgets spurious correlations in the trainingdata that could lead to shortcut learning. Utilizing a new bias score thatmeasures the contribution of each unit in the network to learning spuriousfeatures, BiasPruner prunes those units with the highest bias scores to form adebiased subnetwork preserved for a given task. As BiasPruner learns a newtask, it constructs a new debiased subnetwork, potentially incorporating unitsfrom previous subnetworks, which improves adaptation and performance on the newtask. During inference, BiasPruner employs a simple task-agnostic approach toselect the best debiased subnetwork for predictions. We conduct experiments onthree medical datasets for skin lesion classification and chest X-Rayclassification and demonstrate that BiasPruner consistently outperforms SOTA CLmethods in terms of classification performance and fairness. Our code isavailable here.</description><author>Nourhan Bayasi, Jamil Fayyad, Alceu Bissoto, Ghassan Hamarneh, Rafeef Garbi</author><pubDate>Thu, 11 Jul 2024 15:45:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08609v1</guid></item><item><title>FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</title><link>http://arxiv.org/abs/2407.08608v1</link><description>Attention, as a core layer of the ubiquitous Transformer architecture, is thebottleneck for large language models and long-context applications.FlashAttention elaborated an approach to speed up attention on GPUs throughminimizing memory reads/writes. However, it has yet to take advantage of newcapabilities present in recent hardware, with FlashAttention-2 achieving only35% utilization on the H100 GPU. We develop three main techniques to speed upattention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to(1) overlap overall computation and data movement via warp-specialization and(2) interleave block-wise matmul and softmax operations, and (3) blockquantization and incoherent processing that leverages hardware support for FP8low-precision. We demonstrate that our method, FlashAttention-3, achievesspeedup on H100 GPUs by 1.5-2.0$\times$ with FP16 reaching up to 740 TFLOPs/s(75% utilization), and with FP8 reaching close to 1.2 PFLOPs/s. We validatethat FP8 FlashAttention-3 achieves 2.6$\times$ lower numerical error than abaseline FP8 attention.</description><author>Jay Shah, Ganesh Bikshandi, Ying Zhang, Vijay Thakkar, Pradeep Ramani, Tri Dao</author><pubDate>Thu, 11 Jul 2024 15:44:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08608v1</guid></item><item><title>Turn-Level Empathy Prediction Using Psychological Indicators</title><link>http://arxiv.org/abs/2407.08607v1</link><description>For the WASSA 2024 Empathy and Personality Prediction Shared Task, we proposea novel turn-level empathy detection method that decomposes empathy into sixpsychological indicators: Emotional Language, Perspective-Taking, Sympathy andCompassion, Extroversion, Openness, and Agreeableness. A pipeline of textenrichment using a Large Language Model (LLM) followed by DeBERTA fine-tuningdemonstrates a significant improvement in the Pearson Correlation Coefficientand F1 scores for empathy detection, highlighting the effectiveness of ourapproach. Our system officially ranked 7th at the CONV-turn track.</description><author>Shaz Furniturewala, Kokil Jaidka</author><pubDate>Thu, 11 Jul 2024 15:43:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08607v1</guid></item><item><title>Simulacra as Conscious Exotica</title><link>http://arxiv.org/abs/2402.12422v2</link><description>The advent of conversational agents with increasingly human-like behaviourthrows old philosophical questions into new light. Does it, or could it, evermake sense to speak of AI agents built out of generative language models interms of consciousness, given that they are "mere" simulacra of humanbehaviour, and that what they do can be seen as "merely" role play? Drawing onthe later writings of Wittgenstein, this paper attempts to tackle this questionwhile avoiding the pitfalls of dualistic thinking.</description><author>Murray Shanahan</author><pubDate>Thu, 11 Jul 2024 15:42:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12422v2</guid></item><item><title>Strategy Synthesis for Zero-Sum Neuro-Symbolic Concurrent Stochastic Games</title><link>http://arxiv.org/abs/2202.06255v7</link><description>Neuro-symbolic approaches to artificial intelligence, which combine neuralnetworks with classical symbolic techniques, are growing in prominence,necessitating formal approaches to reason about their correctness. We propose anovel modelling formalism called neuro-symbolic concurrent stochastic games(NS-CSGs), which comprise two probabilistic finite-state agents interacting ina shared continuous-state environment. Each agent observes the environmentusing a neural perception mechanism, which converts inputs such as images intosymbolic percepts, and makes decisions symbolically. We focus on the class ofNS-CSGs with Borel state spaces and prove the existence and measurability ofthe value function for zero-sum discounted cumulative rewards underpiecewise-constant restrictions on the components of this class of models. Tocompute values and synthesise strategies, we present, for the first time,practical value iteration (VI) and policy iteration (PI) algorithms to solvethis new subclass of continuous-state CSGs. These require a finitedecomposition of the environment induced by the neural perception mechanisms ofthe agents and rely on finite abstract representations of value functions andstrategies closed under VI or PI. First, we introduce a Borel measurablepiecewise-constant (B-PWC) representation of value functions, extend minimaxbackups to this representation and propose a value iteration algorithm calledB-PWC VI. Second, we introduce two novel representations for the valuefunctions and strategies, constant-piecewise-linear (CON-PWL) andconstant-piecewise-constant (CON-PWC) respectively, and proposeMinimax-action-free PI by extending a recent PI method based on alternatingplayer choices for finite state spaces to Borel state spaces, which does notrequire normal-form games to be solved.</description><author>Rui Yan, Gabriel Santos, Gethin Norman, David Parker, Marta Kwiatkowska</author><pubDate>Thu, 11 Jul 2024 15:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.06255v7</guid></item><item><title>Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition</title><link>http://arxiv.org/abs/2403.00499v2</link><description>Recent advances in LLMs have sparked a debate on whether they understandtext. In this position paper, we argue that opponents in this debate holddifferent definitions for understanding, and particularly differ in their viewon the role of consciousness. To substantiate this claim, we propose a thoughtexperiment involving an open-source chatbot $Z$ which excels on every possiblebenchmark, seemingly without subjective experience. We ask whether $Z$ iscapable of understanding, and show that different schools of thought withinseminal AI research seem to answer this question differently, uncovering theirterminological disagreement. Moving forward, we propose two distinct workingdefinitions for understanding which explicitly acknowledge the question ofconsciousness, and draw connections with a rich literature in philosophy,psychology and neuroscience.</description><author>Ariel Goldstein, Gabriel Stanovsky</author><pubDate>Thu, 11 Jul 2024 15:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.00499v2</guid></item><item><title>On Leakage of Code Generation Evaluation Datasets</title><link>http://arxiv.org/abs/2407.07565v2</link><description>In this paper we consider contamination by code generation test sets, inparticular in their use in modern large language models. We discuss threepossible sources of such contamination and show findings supporting each ofthem: (i) direct data leakage, (ii) indirect data leakage through the use ofsynthetic data and (iii) overfitting to evaluation sets during model selection.Key to our findings is a new dataset of 161 prompts with their associatedpython solutions, dataset which is released athttps://huggingface.co/datasets/CohereForAI/lbpp .</description><author>Alexandre Matton, Tom Sherborne, Dennis Aumiller, Elena Tommasone, Milad Alizadeh, Jingyi He, Raymond Ma, Maxime Voisin, Ellen Gilsenan-McMahon, Matthias Gallé</author><pubDate>Thu, 11 Jul 2024 15:37:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07565v2</guid></item><item><title>Inference-Time Rule Eraser: Fair Recognition via Distilling and Removing Biased Rules</title><link>http://arxiv.org/abs/2404.04814v3</link><description>Machine learning models often make predictions based on biased features suchas gender, race, and other social attributes, posing significant fairnessrisks, especially in societal applications, such as hiring, banking, andcriminal justice. Traditional approaches to addressing this issue involveretraining or fine-tuning neural networks with fairness-aware optimizationobjectives. However, these methods can be impractical due to significantcomputational resources, complex industrial tests, and the associated CO2footprint. Additionally, regular users often fail to fine-tune models becausethey lack access to model parameters In this paper, we introduce theInference-Time Rule Eraser (Eraser), a novel method designed to addressfairness concerns by removing biased decision-making rules from deployed modelsduring inference without altering model weights. We begin by establishing atheoretical foundation for modifying model outputs to eliminate biased rulesthrough Bayesian analysis. Next, we present a specific implementation of Eraserthat involves two stages: (1) distilling the biased rules from the deployedmodel into an additional patch model, and (2) removing these biased rules fromthe output of the deployed model during inference. Extensive experimentsvalidate the effectiveness of our approach, showcasing its superior performancein addressing fairness concerns in AI systems.</description><author>Yi Zhang, Dongyuan Lu, Jitao Sang</author><pubDate>Thu, 11 Jul 2024 15:33:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04814v3</guid></item><item><title>Vision language models are blind</title><link>http://arxiv.org/abs/2407.06581v2</link><description>Large language models with vision capabilities (VLMs), e.g., GPT-4o andGemini 1.5 Pro are powering countless image-text applications and scoring highon many vision-understanding benchmarks. We propose BlindTest, a suite of 7visual tasks absurdly easy to humans such as identifying (a) whether twocircles overlap; (b) whether two lines intersect; (c) which letter is beingcircled in a word; and (d) counting the number of circles in a Olympic-likelogo. Surprisingly, four state-of-the-art VLMs are, on average, only 56.20%accurate on our benchmark, with \newsonnet being the best (73.77% accuracy). OnBlindTest, VLMs struggle with tasks that requires precise spatial informationand counting (from 0 to 10), sometimes providing an impression of a person withmyopia seeing fine details as blurry and making educated guesses. Code isavailable at: https://vlmsareblind.github.io/</description><author>Pooyan Rahmanzadehgervi, Logan Bolton, Mohammad Reza Taesiri, Anh Totti Nguyen</author><pubDate>Thu, 11 Jul 2024 15:33:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06581v2</guid></item><item><title>Accelerating Communication in Deep Learning Recommendation Model Training with Dual-Level Adaptive Lossy Compression</title><link>http://arxiv.org/abs/2407.04272v3</link><description>DLRM is a state-of-the-art recommendation system model that has gainedwidespread adoption across various industry applications. The large size ofDLRM models, however, necessitates the use of multiple devices/GPUs forefficient training. A significant bottleneck in this process is thetime-consuming all-to-all communication required to collect embedding data fromall devices. To mitigate this, we introduce a method that employs error-boundedlossy compression to reduce the communication data size and accelerate DLRMtraining. We develop a novel error-bounded lossy compression algorithm,informed by an in-depth analysis of embedding data features, to achieve highcompression ratios. Moreover, we introduce a dual-level adaptive strategy forerror-bound adjustment, spanning both table-wise and iteration-wise aspects, tobalance the compression benefits with the potential impacts on accuracy. Wefurther optimize our compressor for PyTorch tensors on GPUs, minimizingcompression overhead. Evaluation shows that our method achieves a 1.38$\times$training speedup with a minimal accuracy impact.</description><author>Hao Feng, Boyuan Zhang, Fanjiang Ye, Min Si, Ching-Hsiang Chu, Jiannan Tian, Chunxing Yin, Summer Deng, Yuchen Hao, Pavan Balaji, Tong Geng, Dingwen Tao</author><pubDate>Thu, 11 Jul 2024 15:31:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04272v3</guid></item><item><title>Learning Program Behavioral Models from Synthesized Input-Output Pairs</title><link>http://arxiv.org/abs/2407.08597v1</link><description>We introduce Modelizer - a novel framework that, given a black-box program,learns a _model from its input/output behavior_ using _neural machinetranslation_. The resulting model _mocks_ the original program: Given an input,the model predicts the output that would have been produced by the program.However, the model is also _reversible_ - that is, the model can predict theinput that would have produced a given output. Finally, the model is_differentiable_ and can be efficiently restricted to predict only a certainaspect of the program behavior. Modelizer uses _grammars_ to synthesize inputs and to parse the resultingoutputs, allowing it to learn sequence-to-sequence associations between tokenstreams. Other than input and output grammars, Modelizer only requires theability to execute the program. The resulting models are _small_, requiring fewer than 6.3 million parametersfor languages such as Markdown or HTML; and they are _accurate_, achieving upto 95.4% accuracy and a BLEU score of 0.98 with standard error 0.04 in mockingreal-world applications. We foresee several _applications_ of these models,especially as the output of the program can be any aspect of program behavior.Besides mocking and predicting program behavior, the model can also synthesizeinputs that are likely to produce a particular behavior, such as failures orcoverage.</description><author>Tural Mammadov, Dietrich Klakow, Alexander Koller, Andreas Zeller</author><pubDate>Thu, 11 Jul 2024 15:25:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08597v1</guid></item><item><title>Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models</title><link>http://arxiv.org/abs/2406.02061v3</link><description>Large Language Models (LLMs) are often described as being instances offoundation models - that is, models that transfer strongly across various tasksand conditions in few-show or zero-shot manner, while exhibiting scaling lawsthat predict function improvement when increasing the pre-training scale. Theseclaims of excelling in different functions and tasks rely on measurements takenacross various sets of standardized benchmarks showing high scores for suchmodels. We demonstrate here a dramatic breakdown of function and reasoningcapabilities of state-of-the-art models trained at the largest available scaleswhich claim strong function, using a simple, short, conventional common senseproblem (AIW problem) formulated in concise natural language, easily solvableby humans. The breakdown is dramatic, as models show strong fluctuations acrosseven slight problem variations that should not affect problem solving, alsoexpressing strong overconfidence in the wrong solutions, often backed up byplausible sounding explanation-like confabulations. Various standardinterventions in an attempt to get the right solution, like various type ofenhanced prompting, or urging the models to reconsider the wrong solutionsagain by multi step re-evaluation, fail. We take these initial observations tothe scientific and technological community to stimulate urgent re-assessment ofthe claimed capabilities of current generation of LLMs. Such re-assessment alsorequires common action to create standardized benchmarks that would allowproper detection of such basic reasoning deficits that obviously manage toremain undiscovered by current state-of-the-art evaluation procedures andbenchmarks. Code for reproducing experiments in the paper and raw experimentsdata can be found at https://github.com/LAION-AI/AIW</description><author>Marianna Nezhurina, Lucia Cipolina-Kun, Mehdi Cherti, Jenia Jitsev</author><pubDate>Thu, 11 Jul 2024 15:17:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02061v3</guid></item><item><title>A Review of Nine Physics Engines for Reinforcement Learning Research</title><link>http://arxiv.org/abs/2407.08590v1</link><description>We present a review of popular simulation engines and frameworks used inreinforcement learning (RL) research, aiming to guide researchers in selectingtools for creating simulated physical environments for RL and training setups.It evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo, ODE, PhysX,PyBullet, Webots, and Unity) based on their popularity, feature range, quality,usability, and RL capabilities. We highlight the challenges in selecting andutilizing physics engines for RL research, including the need for detailedcomparisons and an understanding of each framework's capabilities. Key findingsindicate MuJoCo as the leading framework due to its performance andflexibility, despite usability challenges. Unity is noted for its ease of usebut lacks scalability and simulation fidelity. The study calls for furtherdevelopment to improve simulation engines' usability and performance andstresses the importance of transparency and reproducibility in RL research.This review contributes to the RL community by offering insights into theselection process for simulation engines, facilitating informeddecision-making.</description><author>Michael Kaup, Cornelius Wolff, Hyerim Hwang, Julius Mayer, Elia Bruni</author><pubDate>Thu, 11 Jul 2024 15:13:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08590v1</guid></item><item><title>MiDe22: An Annotated Multi-Event Tweet Dataset for Misinformation Detection</title><link>http://arxiv.org/abs/2210.05401v2</link><description>The rapid dissemination of misinformation through online social networksposes a pressing issue with harmful consequences jeopardizing human health,public safety, democracy, and the economy; therefore, urgent action is requiredto address this problem. In this study, we construct a new human-annotateddataset, called MiDe22, having 5,284 English and 5,064 Turkish tweets withtheir misinformation labels for several recent events between 2020 and 2022,including the Russia-Ukraine war, COVID-19 pandemic, and Refugees. The datasetincludes user engagements with the tweets in terms of likes, replies, retweets,and quotes. We also provide a detailed data analysis with descriptivestatistics and the experimental results of a benchmark evaluation formisinformation detection.</description><author>Cagri Toraman, Oguzhan Ozcelik, Furkan Şahinuç, Fazli Can</author><pubDate>Thu, 11 Jul 2024 15:13:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.05401v2</guid></item><item><title>A Latent-Variable Model for Intrinsic Probing</title><link>http://arxiv.org/abs/2201.08214v3</link><description>The success of pre-trained contextualized representations has promptedresearchers to analyze them for the presence of linguistic information. Indeed,it is natural to assume that these pre-trained representations do encode somelevel of linguistic knowledge as they have brought about large empiricalimprovements on a wide variety of NLP tasks, which suggests they are learningtrue linguistic generalization. In this work, we focus on intrinsic probing, ananalysis technique where the goal is not only to identify whether arepresentation encodes a linguistic attribute but also to pinpoint where thisattribute is encoded. We propose a novel latent-variable formulation forconstructing intrinsic probes and derive a tractable variational approximationto the log-likelihood. Our results show that our model is versatile and yieldstighter mutual information estimates than two intrinsic probes previouslyproposed in the literature. Finally, we find empirical evidence thatpre-trained representations develop a cross-lingually entangled notion ofmorphosyntax.</description><author>Karolina Stańczak, Lucas Torroba Hennigen, Adina Williams, Ryan Cotterell, Isabelle Augenstein</author><pubDate>Thu, 11 Jul 2024 15:13:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.08214v3</guid></item><item><title>Advancing Medical Image Segmentation with Mini-Net: A Lightweight Solution Tailored for Efficient Segmentation of Medical Images</title><link>http://arxiv.org/abs/2405.17520v2</link><description>Accurate segmentation of anatomical structures and abnormalities in medicalimages is crucial for computer-aided diagnosis and analysis. While deeplearning techniques excel at this task, their computational demands posechallenges. Additionally, some cutting-edge segmentation methods, thougheffective for general object segmentation, may not be optimised for medicalimages. To address these issues, we propose Mini-Net, a lightweightsegmentation network specifically designed for medical images. With fewer than38,000 parameters, Mini-Net efficiently captures both high- and low-frequencyfeatures, enabling real-time applications in various medical imaging scenarios.We evaluate Mini-Net on various datasets, including DRIVE, STARE, ISIC-2016,ISIC-2018, and MoNuSeg, demonstrating its robustness and good performancecompared to state-of-the-art methods.</description><author>Syed Javed, Tariq M. Khan, Abdul Qayyum, Arcot Sowmya, Imran Razzak</author><pubDate>Thu, 11 Jul 2024 15:13:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17520v2</guid></item><item><title>HACMan++: Spatially-Grounded Motion Primitives for Manipulation</title><link>http://arxiv.org/abs/2407.08585v1</link><description>Although end-to-end robot learning has shown some success for robotmanipulation, the learned policies are often not sufficiently robust tovariations in object pose or geometry. To improve the policy generalization, weintroduce spatially-grounded parameterized motion primitives in our methodHACMan++. Specifically, we propose an action representation consisting of threecomponents: what primitive type (such as grasp or push) to execute, where theprimitive will be grounded (e.g. where the gripper will make contact with theworld), and how the primitive motion is executed, such as parameters specifyingthe push direction or grasp orientation. These three components define a noveldiscrete-continuous action space for reinforcement learning. Our frameworkenables robot agents to learn to chain diverse motion primitives together andselect appropriate primitive parameters to complete long-horizon manipulationtasks. By grounding the primitives on a spatial location in the environment,our method is able to effectively generalize across object shape and posevariations. Our approach significantly outperforms existing methods,particularly in complex scenarios demanding both high-level sequentialreasoning and object generalization. With zero-shot sim-to-real transfer, ourpolicy succeeds in challenging real-world manipulation tasks, withgeneralization to unseen objects. Videos can be found on the project website:https://sgmp-rss2024.github.io.</description><author>Bowen Jiang, Yilin Wu, Wenxuan Zhou, Chris Paxton, David Held</author><pubDate>Thu, 11 Jul 2024 15:10:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08585v1</guid></item><item><title>The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective</title><link>http://arxiv.org/abs/2407.08583v1</link><description>The rapid development of large language models (LLMs) has been witnessed inrecent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend themodality from text to a broader spectrum of domains, attracting widespreadattention due to the broader range of application scenarios. As LLMs and MLLMsrely on vast amounts of model parameters and data to achieve emergentcapabilities, the importance of data is receiving increasingly widespreadattention and recognition. Tracing and analyzing recent data-oriented works forMLLMs, we find that the development of models and data is not two separatepaths but rather interconnected. On the one hand, vaster and higher-qualitydata contribute to better performance of MLLMs, on the other hand, MLLMs canfacilitate the development of data. The co-development of multi-modal data andMLLMs requires a clear view of 1) at which development stage of MLLMs canspecific data-centric approaches be employed to enhance which capabilities, and2) by utilizing which capabilities and acting as which roles can modelscontribute to multi-modal data. To promote the data-model co-development forMLLM community, we systematically review existing works related to MLLMs fromthe data-model co-development perspective. A regularly maintained projectassociated with this survey is accessible athttps://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.</description><author>Zhen Qin, Daoyuan Chen, Wenhao Zhang, Liuyi Yao, Yilun Huang, Bolin Ding, Yaliang Li, Shuiguang Deng</author><pubDate>Thu, 11 Jul 2024 15:08:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08583v1</guid></item></channel></rss>