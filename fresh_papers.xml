<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 29 Oct 2024 13:00:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Enhancing Action Recognition by Leveraging the Hierarchical Structure of Actions and Textual Context</title><link>http://arxiv.org/abs/2410.21275v1</link><description>The sequential execution of actions and their hierarchical structureconsisting of different levels of abstraction, provide features that remainunexplored in the task of action recognition. In this study, we present a novelapproach to improve action recognition by exploiting the hierarchicalorganization of actions and by incorporating contextualized textualinformation, including location and prior actions to reflect the sequentialcontext. To achieve this goal, we introduce a novel transformer architecturetailored for action recognition that utilizes both visual and textual features.Visual features are obtained from RGB and optical flow data, while textembeddings represent contextual information. Furthermore, we define a jointloss function to simultaneously train the model for both coarse andfine-grained action recognition, thereby exploiting the hierarchical nature ofactions. To demonstrate the effectiveness of our method, we extend the ToyotaSmarthome Untrimmed (TSU) dataset to introduce action hierarchies, introducingthe Hierarchical TSU dataset. We also conduct an ablation study to assess theimpact of different methods for integrating contextual and hierarchical data onaction recognition performance. Results show that the proposed approachoutperforms pre-trained SOTA methods when trained with the samehyperparameters. Moreover, they also show a 17.12% improvement in top-1accuracy over the equivalent fine-grained RGB version when using ground-truthcontextual information, and a 5.33% improvement when contextual information isobtained from actual predictions.</description><author>Manuel Benavent-Lledo, David Mulero-PÃ©rez, David Ortiz-Perez, Jose Garcia-Rodriguez, Antonis Argyros</author><pubDate>Mon, 28 Oct 2024 17:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21275v1</guid></item><item><title>High-level hybridization of heuristics and metaheuristics to solve symmetric TSP: a comparative study</title><link>http://arxiv.org/abs/2410.21274v1</link><description>The Travelling Salesman Problem - TSP is one of the most explored problems inthe scientific literature to solve real problems regarding the economy,transportation, and logistics, to cite a few cases. Adapting TSP to solvedifferent problems has originated several variants of the optimization problemwith more complex objectives and different restrictions. Metaheuristics havebeen used to solve the problem in polynomial time. Several studies have triedhybridising metaheuristics with specialised heuristics to improve the qualityof the solutions. However, we have found no study to evaluate whether thesearching mechanism of a particular metaheuristic is more adequate forexploring hybridization. This paper focuses on the solution of the classicalTSP using high-level hybridisations, experimenting with eight metaheuristicsand heuristics derived from k-OPT, SISR, and segment intersection search,resulting in twenty-four combinations. Some combinations allow more than oneset of searching parameters. Problems with 50 to 280 cities are solved.Parameter tuning of the metaheuristics is not carried out, exploiting thedifferent searching patterns of the eight metaheuristics instead. Thesolutions' quality is compared to those presented in the literature.</description><author>Carlos Alberto da Silva Junior, Roberto Yuji Tanaka, Luiz Carlos Farias da Silva, Angelo Passaro</author><pubDate>Mon, 28 Oct 2024 17:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21274v1</guid></item><item><title>On Inductive Biases That Enable Generalization of Diffusion Transformers</title><link>http://arxiv.org/abs/2410.21273v1</link><description>Recent work studying the generalization of diffusion models with UNet-baseddenoisers reveals inductive biases that can be expressed via geometry-adaptiveharmonic bases. However, in practice, more recent denoising networks are oftenbased on transformers, e.g., the diffusion transformer (DiT). This raises thequestion: do transformer-based denoising networks exhibit inductive biases thatcan also be expressed via geometry-adaptive harmonic bases? To our surprise, wefind that this is not the case. This discrepancy motivates our search for theinductive bias that can lead to good generalization in DiT models.Investigating the pivotal attention modules of a DiT, we find that locality ofattention maps are closely associated with generalization. To verify thisfinding, we modify the generalization of a DiT by restricting its attentionwindows. We inject local attention windows to a DiT and observe an improvementin generalization. Furthermore, we empirically find that both the placement andthe effective attention size of these local attention windows are crucialfactors. Experimental results on the CelebA, ImageNet, and LSUN datasets showthat strengthening the inductive bias of a DiT can improve both generalizationand generation quality when less training data is available. Source code willbe released publicly upon paper publication. Project page:dit-generalization.github.io/.</description><author>Jie An, De Wang, Pengsheng Guo, Jiebo Luo, Alexander Schwing</author><pubDate>Mon, 28 Oct 2024 17:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21273v1</guid></item><item><title>Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics</title><link>http://arxiv.org/abs/2410.21272v1</link><description>Do large language models (LLMs) solve reasoning tasks by learning robustgeneralizable algorithms, or do they memorize training data? To investigatethis question, we use arithmetic reasoning as a representative task. Usingcausal analysis, we identify a subset of the model (a circuit) that explainsmost of the model's behavior for basic arithmetic logic and examine itsfunctionality. By zooming in on the level of individual circuit neurons, wediscover a sparse set of important neurons that implement simple heuristics.Each heuristic identifies a numerical input pattern and outputs correspondinganswers. We hypothesize that the combination of these heuristic neurons is themechanism used to produce correct arithmetic answers. To test this, wecategorize each neuron into several heuristic types-such as neurons thatactivate when an operand falls within a certain range-and find that theunordered combination of these heuristic types is the mechanism that explainsmost of the model's accuracy on arithmetic prompts. Finally, we demonstratethat this mechanism appears as the main source of arithmetic accuracy early intraining. Overall, our experimental results across several LLMs show that LLMsperform arithmetic using neither robust algorithms nor memorization; rather,they rely on a "bag of heuristics".</description><author>Yaniv Nikankin, Anja Reusch, Aaron Mueller, Yonatan Belinkov</author><pubDate>Mon, 28 Oct 2024 17:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21272v1</guid></item><item><title>EoRA: Training-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation</title><link>http://arxiv.org/abs/2410.21271v1</link><description>In this work, we re-formulate the model compression problem into thecustomized compensation problem: Given a compressed model, we aim to introduceresidual low-rank paths to compensate for compression errors under customizedrequirements from users (e.g., tasks, compression ratios), resulting in greaterflexibility in adjusting overall capacity without being constrained by specificcompression formats. However, naively applying SVD to derive residual pathscauses suboptimal utilization of the low-rank representation capacity. Instead,we propose Training-free Eigenspace Low-Rank Approximation (EoRA), a methodthat directly minimizes compression-induced errors without requiringgradient-based training, achieving fast optimization in minutes using a smallamount of calibration data. EoRA projects compression errors into theeigenspace of input activations, leveraging eigenvalues to effectivelyprioritize the reconstruction of high-importance error components. Moreover,EoRA can be seamlessly integrated with fine-tuning and quantization to furtherimprove effectiveness and efficiency. EoRA consistently outperforms previousmethods in compensating errors for compressed LLaMA2/3 models on various tasks,such as language generation, commonsense reasoning, and math reasoning tasks(e.g., 31.31%/12.88% and 9.69% improvements on ARC-Easy/ARC-Challenge andMathQA when compensating LLaMA3-8B that is quantized to 4-bit and pruned to 2:4sparsity). EoRA offers a scalable, training-free solution to compensate forcompression errors, making it a powerful tool to deploy LLMs in variouscapacity and efficiency requirements.</description><author>Shih-Yang Liu, Huck Yang, Chein-Yi Wang, Nai Chit Fung, Hongxu Yin, Charbel Sakr, Saurav Muralidharan, Kwang-Ting Cheng, Jan Kautz, Yu-Chiang Frank Wang, Pavlo Molchanov, Min-Hung Chen</author><pubDate>Mon, 28 Oct 2024 17:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21271v1</guid></item><item><title>OmniSep: Unified Omni-Modality Sound Separation with Query-Mixup</title><link>http://arxiv.org/abs/2410.21269v1</link><description>The scaling up has brought tremendous success in the fields of vision andlanguage in recent years. When it comes to audio, however, researchersencounter a major challenge in scaling up the training data, as most naturalaudio contains diverse interfering signals. To address this limitation, weintroduce Omni-modal Sound Separation (OmniSep), a novel framework capable ofisolating clean soundtracks based on omni-modal queries, encompassing bothsingle-modal and multi-modal composed queries. Specifically, we introduce theQuery-Mixup strategy, which blends query features from different modalitiesduring training. This enables OmniSep to optimize multiple modalitiesconcurrently, effectively bringing all modalities under a unified framework forsound separation. We further enhance this flexibility by allowing queries toinfluence sound separation positively or negatively, facilitating the retentionor removal of specific sounds as desired. Finally, OmniSep employs aretrieval-augmented approach known as Query-Aug, which enables open-vocabularysound separation. Experimental evaluations on MUSIC, VGGSOUND-CLEAN+, andMUSIC-CLEAN+ datasets demonstrate effectiveness of OmniSep, achievingstate-of-the-art performance in text-, image-, and audio-queried soundseparation tasks. For samples and further information, please visit the demopage at \url{https://omnisep.github.io/}.</description><author>Xize Cheng, Siqi Zheng, Zehan Wang, Minghui Fang, Ziang Zhang, Rongjie Huang, Ziyang Ma, Shengpeng Ji, Jialong Zuo, Tao Jin, Zhou Zhao</author><pubDate>Mon, 28 Oct 2024 17:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21269v1</guid></item><item><title>Online Weighted Paging with Unknown Weights</title><link>http://arxiv.org/abs/2410.21266v1</link><description>Online paging is a fundamental problem in the field of online algorithms, inwhich one maintains a cache of $k$ slots as requests for fetching pages arriveonline. In the weighted variant of this problem, each page has its own fetchingcost; a substantial line of work on this problem culminated in an (optimal)$O(\log k)$-competitive randomized algorithm, due to Bansal, Buchbinder andNaor (FOCS'07). Existing work for weighted paging assumes that page weights are known inadvance, which is not always the case in practice. For example, in multi-levelcaching architectures, the expected cost of fetching a memory block is afunction of its probability of being in a mid-level cache rather than the mainmemory. This complex property cannot be predicted in advance; over time,however, one may glean information about page weights through sampling theirfetching cost multiple times. We present the first algorithm for online weighted paging that does not knowpage weights in advance, but rather learns from weight samples. In terms oftechniques, this requires providing (integral) samples to a fractional solver,requiring a delicate interface between this solver and the randomized roundingscheme; we believe that our work can inspire online algorithms to otherproblems that involve cost sampling.</description><author>Orin Levy, Noam Touitou, Aviv Rosenberg</author><pubDate>Mon, 28 Oct 2024 17:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21266v1</guid></item><item><title>Modular Duality in Deep Learning</title><link>http://arxiv.org/abs/2410.21265v1</link><description>An old idea in optimization theory says that since the gradient is a dualvector it may not be subtracted from the weights without first being mapped tothe primal space where the weights reside. We take this idea seriously in thispaper and construct such a duality map for general neural networks. Our map,which we call modular dualization, forms a unifying theoretical basis fortraining algorithms that are a) fast and b) scalable. Modular dualizationinvolves first assigning operator norms to layers based on the semantics ofeach layer, and then using these layerwise norms to recursively induce aduality map on the weight space of the full neural architecture. We conclude byderiving GPU-friendly algorithms for dualizing Embed, Linear and Conv2D layers-- the latter two methods are based on a new rectangular Newton-Schulziteration that we propose. Our iteration was recently used to set new speedrecords for training NanoGPT. Overall, we hope that our theory of modularduality will yield a next generation of fast and scalable optimizers forgeneral neural architectures.</description><author>Jeremy Bernstein, Laker Newhouse</author><pubDate>Mon, 28 Oct 2024 17:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21265v1</guid></item><item><title>LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior</title><link>http://arxiv.org/abs/2410.21264v1</link><description>We present LARP, a novel video tokenizer designed to overcome limitations incurrent video tokenization methods for autoregressive (AR) generative models.Unlike traditional patchwise tokenizers that directly encode local visualpatches into discrete tokens, LARP introduces a holistic tokenization schemethat gathers information from the visual content using a set of learnedholistic queries. This design allows LARP to capture more global and semanticrepresentations, rather than being limited to local patch-level information.Furthermore, it offers flexibility by supporting an arbitrary number ofdiscrete tokens, enabling adaptive and efficient tokenization based on thespecific requirements of the task. To align the discrete token space withdownstream AR generation tasks, LARP integrates a lightweight AR transformer asa training-time prior model that predicts the next token on its discrete latentspace. By incorporating the prior model during training, LARP learns a latentspace that is not only optimized for video reconstruction but is alsostructured in a way that is more conducive to autoregressive generation.Moreover, this process defines a sequential order for the discrete tokens,progressively pushing them toward an optimal configuration during training,ensuring smoother and more accurate AR generation at inference time.Comprehensive experiments demonstrate LARP's strong performance, achievingstate-of-the-art FVD on the UCF101 class-conditional video generationbenchmark. LARP enhances the compatibility of AR models with videos and opensup the potential to build unified high-fidelity multimodal large languagemodels (MLLMs).</description><author>Hanyu Wang, Saksham Suri, Yixuan Ren, Hao Chen, Abhinav Shrivastava</author><pubDate>Mon, 28 Oct 2024 17:57:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21264v1</guid></item><item><title>Adaptive Transfer Clustering: A Unified Framework</title><link>http://arxiv.org/abs/2410.21263v1</link><description>We propose a general transfer learning framework for clustering given a maindataset and an auxiliary one about the same subjects. The two datasets mayreflect similar but different latent grouping structures of the subjects. Wepropose an adaptive transfer clustering (ATC) algorithm that automaticallyleverages the commonality in the presence of unknown discrepancy, by optimizingan estimated bias-variance decomposition. It applies to a broad class ofstatistical models including Gaussian mixture models, stochastic block models,and latent class models. A theoretical analysis proves the optimality of ATCunder the Gaussian mixture model and explicitly quantifies the benefit oftransfer. Extensive simulations and real data experiments confirm our method'seffectiveness in various scenarios.</description><author>Yuqi Gu, Zhongyuan Lyu, Kaizheng Wang</author><pubDate>Mon, 28 Oct 2024 17:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21263v1</guid></item><item><title>BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference</title><link>http://arxiv.org/abs/2410.21262v1</link><description>Large-scale foundation models have demonstrated exceptional performance inlanguage and vision tasks. However, the numerous dense matrix-vector operationsinvolved in these large networks pose significant computational challengesduring inference. To address these challenges, we introduce the Block-LevelAdaptive STructured (BLAST) matrix, designed to learn and leverage efficientstructures prevalent in the weight matrices of linear layers within deeplearning models. Compared to existing structured matrices, the BLAST matrixoffers substantial flexibility, as it can represent various types of structuresthat are either learned from data or computed from pre-existing weightmatrices. We demonstrate the efficiency of using the BLAST matrix forcompressing both language and vision tasks, showing that (i) for medium-sizedmodels such as ViT and GPT-2, training with BLAST weights boosts performancewhile reducing complexity by 70\% and 40\%, respectively; and (ii) for largefoundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2xcompression while exhibiting the lowest performance degradation among alltested structured matrices. Our code is available at\url{https://github.com/changwoolee/BLAST}.</description><author>Changwoo Lee, Soo Min Kwon, Qing Qu, Hun-Seok Kim</author><pubDate>Mon, 28 Oct 2024 17:56:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21262v1</guid></item><item><title>Markovian Flow Matching: Accelerating MCMC with Continuous Normalizing Flows</title><link>http://arxiv.org/abs/2405.14392v2</link><description>Continuous normalizing flows (CNFs) learn the probability path between areference distribution and a target distribution by modeling the vector fieldgenerating said path using neural networks. Recently, Lipman et al. (2022)introduced a simple and inexpensive method for training CNFs in generativemodeling, termed flow matching (FM). In this paper, we repurpose this methodfor probabilistic inference by incorporating Markovian sampling methods inevaluating the FM objective, and using the learned CNF to improve Monte Carlosampling. Specifically, we propose an adaptive Markov chain Monte Carlo (MCMC)algorithm, which combines a local Markov transition kernel with a non-local,flow-informed transition kernel, defined using a CNF. This CNF is adaptedon-the-fly using samples from the Markov chain, which are used to specify theprobability path for the FM objective. Our method also includes an adaptivetempering mechanism that allows the discovery of multiple modes in the targetdistribution. Under mild assumptions, we establish convergence of our method toa local optimum of the FM objective. We then benchmark our approach on severalsynthetic and real-world examples, achieving similar performance to otherstate-of-the-art methods, but often at a significantly lower computationalcost.</description><author>Alberto Cabezas, Louis Sharrock, Christopher Nemeth</author><pubDate>Mon, 28 Oct 2024 17:55:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14392v2</guid></item><item><title>AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?</title><link>http://arxiv.org/abs/2410.21259v1</link><description>Large Vision-Language Models (LVLMs) have become essential for advancing theintegration of visual and linguistic information, facilitating a wide range ofcomplex applications and tasks. However, the evaluation of LVLMs presentssignificant challenges as the evaluation benchmark always demands lots of humancost for its construction, and remains static, lacking flexibility onceconstructed. Even though automatic evaluation has been explored in textualmodality, the visual modality remains under-explored. As a result, in thiswork, we address a question: "Can LVLMs serve as a path to automaticbenchmarking?". We introduce AutoBench-V, an automated framework for servingevaluation on demand, i.e., benchmarking LVLMs based on specific aspects ofmodel capability. Upon receiving an evaluation capability, AutoBench-Vleverages text-to-image models to generate relevant image samples and thenutilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completingthe evaluation process efficiently and flexibly. Through an extensiveevaluation of seven popular LVLMs across five demanded user inputs (i.e.,evaluation capabilities), the framework shows effectiveness and reliability. Weobserve the following: (1) Our constructed benchmark accurately reflectsvarying task difficulties; (2) As task difficulty rises, the performance gapbetween models widens; (3) While models exhibit strong performance in abstractlevel understanding, they underperform in details reasoning tasks; and (4)Constructing a dataset with varying levels of difficulties is critical for acomprehensive and exhaustive evaluation. Overall, AutoBench-V not onlysuccessfully utilizes LVLMs for automated benchmarking but also reveals thatLVLMs as judges have significant potential in various domains.</description><author>Han Bao, Yue Huang, Yanbo Wang, Jiayi Ye, Xiangqi Wang, Xiuyin Chen, Mohamed Elhoseiny, Xiangliang Zhang</author><pubDate>Mon, 28 Oct 2024 17:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21259v1</guid></item><item><title>Quantum computing and persistence in topological data analysis</title><link>http://arxiv.org/abs/2410.21258v1</link><description>Topological data analysis (TDA) aims to extract noise-robust features from adata set by examining the number and persistence of holes in its topology. Weshow that a computational problem closely related to a core task in TDA --determining whether a given hole persists across different length scales -- is$\mathsf{BQP}_1$-hard and contained in $\mathsf{BQP}$. This result implies anexponential quantum speedup for this problem under standardcomplexity-theoretic assumptions. Our approach relies on encoding thepersistence of a hole in a variant of the guided sparse Hamiltonian problem,where the guiding state is constructed from a harmonic representative of thehole.</description><author>Casper Gyurik, Alexander Schmidhuber, Robbie King, Vedran Dunjko, Ryu Hayakawa</author><pubDate>Mon, 28 Oct 2024 17:54:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21258v1</guid></item><item><title>One-Step Diffusion Policy: Fast Visuomotor Policies via Diffusion Distillation</title><link>http://arxiv.org/abs/2410.21257v1</link><description>Diffusion models, praised for their success in generative tasks, areincreasingly being applied to robotics, demonstrating exceptional performancein behavior cloning. However, their slow generation process stemming fromiterative denoising steps poses a challenge for real-time applications inresource-constrained robotics setups and dynamically changing environments. Inthis paper, we introduce the One-Step Diffusion Policy (OneDP), a novelapproach that distills knowledge from pre-trained diffusion policies into asingle-step action generator, significantly accelerating response times forrobotic control tasks. We ensure the distilled generator closely aligns withthe original policy distribution by minimizing the Kullback-Leibler (KL)divergence along the diffusion chain, requiring only $2\%$-$10\%$ additionalpre-training cost for convergence. We evaluated OneDP on 6 challengingsimulation tasks as well as 4 self-designed real-world tasks using the Frankarobot. The results demonstrate that OneDP not only achieves state-of-the-artsuccess rates but also delivers an order-of-magnitude improvement in inferencespeed, boosting action prediction frequency from 1.5 Hz to 62 Hz, establishingits potential for dynamic and computationally constrained robotic applications.We share the project page at https://research.nvidia.com/labs/dir/onedp/.</description><author>Zhendong Wang, Zhaoshuo Li, Ajay Mandlekar, Zhenjia Xu, Jiaojiao Fan, Yashraj Narang, Linxi Fan, Yuke Zhu, Yogesh Balaji, Mingyuan Zhou, Ming-Yu Liu, Yu Zeng</author><pubDate>Mon, 28 Oct 2024 17:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21257v1</guid></item><item><title>Multi-modal AI for comprehensive breast cancer prognostication</title><link>http://arxiv.org/abs/2410.21256v1</link><description>Treatment selection in breast cancer is guided by molecular subtypes andclinical characteristics. Recurrence risk assessment plays a crucial role inpersonalizing treatment. Current methods, including genomic assays, havelimited accuracy and clinical utility, leading to suboptimal decisions for manypatients. We developed a test for breast cancer patient stratification based ondigital pathology and clinical characteristics using novel AI methods.Specifically, we utilized a vision transformer-based pan-cancer foundationmodel trained with self-supervised learning to extract features from digitizedH&amp;E-stained slides. These features were integrated with clinical data to form amulti-modal AI test predicting cancer recurrence and death. The test wasdeveloped and evaluated using data from a total of 8,161 breast cancer patientsacross 15 cohorts originating from seven countries. Of these, 3,502 patientsfrom five cohorts were used exclusively for evaluation, while the remainingpatients were used for training. Our test accurately predicted our primaryendpoint, disease-free interval, in the five external cohorts (C-index: 0.71[0.68-0.75], HR: 3.63 [3.02-4.37, p&lt;0.01]). In a direct comparison (N=858), theAI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay,with a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively.Additionally, the AI test added independent information to Oncotype DX in amultivariate analysis (HR: 3.11 [1.91-5.09, p&lt;0.01)]). The test demonstratedrobust accuracy across all major breast cancer subtypes, including TNBC(C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostictools are currently recommended by clinical guidelines. These results suggestthat our AI test can improve accuracy, extend applicability to a wider range ofpatients, and enhance access to treatment selection tools.</description><author>Jan Witowski, Ken Zeng, Joseph Cappadona, Jailan Elayoubi, Elena Diana Chiru, Nancy Chan, Young-Joon Kang, Frederick Howard, Irina Ostrovnaya, Carlos Fernandez-Granda, Freya Schnabel, Ugur Ozerdem, Kangning Liu, Zoe Steinsnyder, Nitya Thakore, Mohammad Sadic, Frank Yeung, Elisa Liu, Theodore Hill, Benjamin Swett, Danielle Rigau, Andrew Clayburn, Valerie Speirs, Marcus Vetter, Lina Sojak, Simone Muenst Soysal, Daniel Baumhoer, Khalil Choucair, Yu Zong, Lina Daoud, Anas Saad, Waleed Abdulsattar, Rafic Beydoun, Jia-Wern Pan, Haslina Makmur, Soo-Hwang Teo, Linda Ma Pak, Victor Angel, Dovile Zilenaite-Petrulaitiene, Arvydas Laurinavicius, Natalie Klar, Brian D. Piening, Carlo Bifulco, Sun-Young Jun, Jae Pak Yi, Su Hyun Lim, Adam Brufsky, Francisco J. Esteva, Lajos Pusztai, Yann LeCun, Krzysztof</author><pubDate>Mon, 28 Oct 2024 17:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21256v1</guid></item><item><title>Assessing Brittleness of Image-Text Retrieval Benchmarks from Vision-Language Models Perspective</title><link>http://arxiv.org/abs/2407.15239v3</link><description>We examine the brittleness of the image-text retrieval (ITR) evaluationpipeline with a focus on concept granularity. We start by analyzing two commonbenchmarks, MS-COCO and Flickr30k, and compare them with augmented,fine-grained versions, MS-COCO-FG and Flickr30k-FG, given a specified set oflinguistic features capturing concept granularity. Flickr30k-FG and MS COCO-FGconsistently give rise to higher scores across all the selected features. Tofurther our understanding of the impact of granularity we consider a noveltaxonomy of query perturbations. We apply these perturbations to the selecteddatasets. We evaluate four diverse state-of-the-art Vision-Language models onboth the standard and fine-grained datasets under zero-shot conditions, withand without the applied perturbations. The results demonstrate that althoughperturbations generally degrade model performance, the fine-grained datasetsexhibit a smaller performance drop than their standard counterparts. Therelative performance drop across all setups is consistent across all models anddatasets, indicating that the issue lies within the benchmarks themselves. Weconclude by providing an agenda for improving ITR evaluation pipelines.</description><author>Mariya Hendriksen, Shuo Zhang, Ridho Reinanda, Mohamed Yahya, Edgar Meij, Maarten de Rijke</author><pubDate>Mon, 28 Oct 2024 17:52:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.15239v3</guid></item><item><title>Are BabyLMs Second Language Learners?</title><link>http://arxiv.org/abs/2410.21254v1</link><description>This paper describes a linguistically-motivated approach to the 2024 editionof the BabyLM Challenge (Warstadt et al. 2023). Rather than pursuing a firstlanguage learning (L1) paradigm, we approach the challenge from a secondlanguage (L2) learning perspective. In L2 learning, there is a stronger focuson learning explicit linguistic information, such as grammatical notions,definitions of words or different ways of expressing a meaning. This makes L2learning potentially more efficient and concise. We approximate this using datafrom Wiktionary, grammar examples either generated by an LLM or sourced fromgrammar books, and paraphrase data. We find that explicit information aboutword meaning (in our case, Wiktionary) does not boost model performance, whilegrammatical information can give a small improvement. The most impactful dataingredient is sentence paraphrases, with our two best models being trained on1) a mix of paraphrase data and data from the BabyLM pretraining dataset, and2) exclusively paraphrase data.</description><author>Lukas Edman, Lisa Bylinina, Faeze Ghorbanpour, Alexander Fraser</author><pubDate>Mon, 28 Oct 2024 17:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21254v1</guid></item><item><title>LongReward: Improving Long-context Large Language Models with AI Feedback</title><link>http://arxiv.org/abs/2410.21252v1</link><description>Though significant advancements have been achieved in developing long-contextlarge language models (LLMs), the compromised quality of LLM-synthesized datafor supervised fine-tuning (SFT) often affects the long-context performance ofSFT models and leads to inherent limitations. In principle, reinforcementlearning (RL) with appropriate reward signals can further enhance models'capacities. However, how to obtain reliable rewards in long-context scenariosremains unexplored. To this end, we propose LongReward, a novel method thatutilizes an off-the-shelf LLM to provide rewards for long-context modelresponses from four human-valued dimensions: helpfulness, logicality,faithfulness, and completeness, each with a carefully designed assessmentpipeline. By combining LongReward and offline RL algorithm DPO, we are able toeffectively improve long-context SFT models. Our experiments indicate thatLongReward not only significantly improves models' long-context performance butalso enhances their ability to follow short instructions. We also find thatlong-context DPO with LongReward and conventional short-context DPO can be usedtogether without hurting either one's performance.</description><author>Jiajie Zhang, Zhongni Hou, Xin Lv, Shulin Cao, Zhenyu Hou, Yilin Niu, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li</author><pubDate>Mon, 28 Oct 2024 17:50:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21252v1</guid></item><item><title>Capacity-Aware Planning and Scheduling in Budget-Constrained Monotonic MDPs: A Meta-RL Approach</title><link>http://arxiv.org/abs/2410.21249v1</link><description>Many real-world sequential repair problems can be effectively modeled usingmonotonic Markov Decision Processes (MDPs), where the system statestochastically decreases and can only be increased by performing a restorativeaction. This work addresses the problem of solving multi-component monotonicMDPs with both budget and capacity constraints. The budget constraint limitsthe total number of restorative actions and the capacity constraint limits thenumber of restorative actions that can be performed simultaneously. While priormethods dealt with budget constraints, including capacity constraints in priormethods leads to an exponential increase in computational complexity as thenumber of components in the MDP grows. We propose a two-step planning approachto address this challenge. First, we partition the components of themulti-component MDP into groups, where the number of groups is determined bythe capacity constraint. We achieve this partitioning by solving a Linear SumAssignment Problem (LSAP). Each group is then allocated a fraction of the totalbudget proportional to its size. This partitioning effectively decouples thelarge multi-component MDP into smaller subproblems, which are computationallyfeasible because the capacity constraint is simplified and the budgetconstraint can be addressed using existing methods. Subsequently, we use ameta-trained PPO agent to obtain an approximately optimal policy for eachgroup. To validate our approach, we apply it to the problem of schedulingrepairs for a large group of industrial robots, constrained by a limited numberof repair technicians and a total repair budget. Our results demonstrate thatthe proposed method outperforms baseline approaches in terms of maximizing theaverage uptime of the robot swarm, particularly for large swarm sizes.</description><author>Manav Vora, Ilan Shomorony, Melkior Ornik</author><pubDate>Mon, 28 Oct 2024 17:48:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21249v1</guid></item><item><title>Securing Multi-turn Conversational Language Models From Distributed Backdoor Triggers</title><link>http://arxiv.org/abs/2407.04151v2</link><description>Large language models (LLMs) have acquired the ability to handle longercontext lengths and understand nuances in text, expanding their dialoguecapabilities beyond a single utterance. A popular user-facing application ofLLMs is the multi-turn chat setting. Though longer chat memory and betterunderstanding may seemingly benefit users, our paper exposes a vulnerabilitythat leverages the multi-turn feature and strong learning ability of LLMs toharm the end-user: the backdoor. We demonstrate that LLMs can capture thecombinational backdoor representation. Only upon presentation of triggerstogether does the backdoor activate. We also verify empirically that thisrepresentation is invariant to the position of the trigger utterance.Subsequently, inserting a single extra token into two utterances of 5%of thedata can cause over 99% Attack Success Rate (ASR). Our results with 3 triggersdemonstrate that this framework is generalizable, compatible with any triggerin an adversary's toolbox in a plug-and-play manner. Defending the backdoor canbe challenging in the chat setting because of the large input and output space.Our analysis indicates that the distributed backdoor exacerbates the currentchallenges by polynomially increasing the dimension of the attacked inputspace. Canonical textual defenses like ONION and BKI leverage auxiliary modelforward passes over individual tokens, scaling exponentially with the inputsequence length and struggling to maintain computational feasibility. To thisend, we propose a decoding time defense - decayed contrastive decoding - thatscales linearly with assistant response sequence length and reduces thebackdoor to as low as 0.35%.</description><author>Terry Tong, Jiashu Xu, Qin Liu, Muhao Chen</author><pubDate>Mon, 28 Oct 2024 17:48:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04151v2</guid></item><item><title>Bayesian-LoRA: LoRA based Parameter Efficient Fine-Tuning using Optimal Quantization levels and Rank Values trough Differentiable Bayesian Gates</title><link>http://arxiv.org/abs/2406.13046v3</link><description>It is a common practice in natural language processing to pre-train a singlemodel on a general domain and then fine-tune it for downstream tasks. However,when it comes to Large Language Models, fine-tuning the entire model can becomputationally expensive, resulting in very intensive energy consumption. As aresult, several Parameter Efficient Fine-Tuning (PEFT) approaches were recentlyproposed. One of the most popular approaches is low-rank adaptation (LoRA),where the key insight is decomposing the update weights of the pre-trainedmodel into two low-rank matrices. However, the proposed approaches either usethe same rank value across all different weight matrices, which has been shownto be a sub-optimal choice, or do not use any quantization technique, one ofthe most important factors when it comes to a model's energy consumption. Inthis work, we propose Bayesian-LoRA which approaches low-rank adaptation andquantization from a Bayesian perspective by employing a prior distribution onboth quantization levels and rank values. As a result, B-LoRA is able tofine-tune a pre-trained model on a specific downstream task, finding theoptimal rank values and quantization levels for every low-rank matrix. Wevalidate the proposed model by fine-tuning a pre-trained DeBERTaV3 on the GLUEbenchmark. Moreover, we compare it to relevant baselines and present bothqualitative and quantitative results, showing how the proposed approach is ableto learn optimal-rank quantized matrices. B-LoRA performs on par with or betterthan the baselines while reducing the total number of bit operations by roughly70% compared to the baseline methods.</description><author>Cristian Meo, Ksenia Sycheva, Anirudh Goyal, Justin Dauwels</author><pubDate>Mon, 28 Oct 2024 17:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13046v3</guid></item><item><title>Large-scale cloze evaluation reveals that token prediction tasks are neither lexically nor semantically aligned</title><link>http://arxiv.org/abs/2410.12057v2</link><description>In this work we compare the generative behavior at the next token predictionlevel in several language models by comparing them to human productions in thecloze task. We find that while large models trained for longer are typicallybetter estimators of human productions, but they reliably under-estimate theprobabilities of human responses, over-rank rare responses, under-rank topresponses, and produce highly distinct semantic spaces. Altogether, this workdemonstrates in a tractable, interpretable domain that LM generations can notbe used as replacements of or models of the cloze task.</description><author>Cassandra L. Jacobs, LoÃ¯c Grobol, Alvin Tsang</author><pubDate>Mon, 28 Oct 2024 17:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12057v2</guid></item><item><title>Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback</title><link>http://arxiv.org/abs/2410.21242v1</link><description>Building effective dense retrieval systems remains difficult when relevancesupervision is not available. Recent work has looked to overcome this challengeby using a Large Language Model (LLM) to generate hypothetical documents thatcan be used to find the closest real document. However, this approach reliessolely on the LLM to have domain-specific knowledge relevant to the query,which may not be practical. Furthermore, generating hypothetical documents canbe inefficient as it requires the LLM to generate a large number of tokens foreach query. To address these challenges, we introduce Real Document Embeddingsfrom Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RFproposes to re-frame hypothetical document generation as a relevance estimationtask, using an LLM to select which documents should be used for nearestneighbor search. Through this re-framing, the LLM no longer needsdomain-specific knowledge but only needs to judge what is relevant.Additionally, relevance estimation only requires the LLM to output a singletoken, thereby improving search latency. Our experiments show that ReDE-RFconsistently surpasses state-of-the-art zero-shot dense retrieval methodsacross a wide range of low-resource retrieval datasets while also makingsignificant improvements in latency per-query.</description><author>Nour Jedidi, Yung-Sung Chuang, Leslie Shing, James Glass</author><pubDate>Mon, 28 Oct 2024 17:40:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21242v1</guid></item><item><title>Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce</title><link>http://arxiv.org/abs/2410.21237v1</link><description>Knowledge Graph (KG) is playing an increasingly important role in various AIsystems. For e-commerce, an efficient and low-cost automated knowledge graphconstruction method is the foundation of enabling various successful downstreamapplications. In this paper, we propose a novel method for constructingstructured product knowledge graphs from raw product images. The methodcooperatively leverages recent advances in the vision-language model (VLM) andlarge language model (LLM), fully automating the process and allowing timelygraph updates. We also present a human-annotated e-commerce product dataset forbenchmarking product property extraction in knowledge graph construction. Ourmethod outperforms our baseline in all metrics and evaluated properties,demonstrating its effectiveness and bright usage potential.</description><author>Zhantao Yang, Han Zhang, Fangyi Chen, Anudeepsekhar Bolimera, Marios Savvides</author><pubDate>Mon, 28 Oct 2024 17:34:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21237v1</guid></item><item><title>RepairAgent: An Autonomous, LLM-Based Agent for Program Repair</title><link>http://arxiv.org/abs/2403.17134v2</link><description>Automated program repair has emerged as a powerful technique to mitigate theimpact of software bugs on system reliability and user experience. This paperintroduces RepairAgent, the first work to address the program repair challengethrough an autonomous agent based on a large language model (LLM). Unlikeexisting deep learning-based approaches, which prompt a model with a fixedprompt or in a fixed feedback loop, our work treats the LLM as an agent capableof autonomously planning and executing actions to fix bugs by invoking suitabletools. RepairAgent freely interleaves gathering information about the bug,gathering repair ingredients, and validating fixes, while deciding which toolsto invoke based on the gathered information and feedback from previous fixattempts. Key contributions that enable RepairAgent include a set of tools thatare useful for program repair, a dynamically updated prompt format that allowsthe LLM to interact with these tools, and a finite state machine that guidesthe agent in invoking the tools. Our evaluation on the popular Defects4Jdataset demonstrates RepairAgent's effectiveness in autonomously repairing 164bugs, including 39 bugs not fixed by prior techniques. Interacting with the LLMimposes an average cost of 270,000 tokens per bug, which, under the currentpricing of OpenAI's GPT-3.5 model, translates to 14 cents of USD per bug. Tothe best of our knowledge, this work is the first to present an autonomous,LLM-based agent for program repair, paving the way for future agent-basedtechniques in software engineering.</description><author>Islem Bouzenia, Premkumar Devanbu, Michael Pradel</author><pubDate>Mon, 28 Oct 2024 17:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17134v2</guid></item><item><title>Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations</title><link>http://arxiv.org/abs/2406.11801v2</link><description>Ensuring the safe alignment of large language models (LLMs) with human valuesis critical as they become integral to applications like translation andquestion answering. Current alignment methods struggle with dynamic userintentions and complex objectives, making models vulnerable to generatingharmful content. We propose Safety Arithmetic, a training-free frameworkenhancing LLM safety across different scenarios: Base models, Supervisedfine-tuned models (SFT), and Edited models. Safety Arithmetic involves HarmDirection Removal to avoid harmful content and Safety Alignment to promote saferesponses. Additionally, we present NoIntentEdit, a dataset highlighting editinstances that could compromise model safety if used unintentionally. Ourexperiments show that Safety Arithmetic significantly improves safety measures,reduces over-safety, and maintains model utility, outperforming existingmethods in ensuring safe content generation.</description><author>Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria</author><pubDate>Mon, 28 Oct 2024 17:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11801v2</guid></item><item><title>Flaming-hot Initiation with Regular Execution Sampling for Large Language Models</title><link>http://arxiv.org/abs/2410.21236v1</link><description>Since the release of ChatGPT, large language models (LLMs) have demonstratedremarkable capabilities across various domains. A key challenge in developingthese general capabilities is efficiently sourcing diverse, high-quality data.This becomes especially critical in reasoning-related tasks with sandboxcheckers, such as math or code, where the goal is to generate correct solutionsto specific problems with higher probability. In this work, we introduceFlaming-hot Initiation with Regular Execution (FIRE) sampling, a simple yethighly effective method to efficiently find good responses. Our empiricalfindings show that FIRE sampling enhances inference-time generation quality andalso benefits training in the alignment stage. Furthermore, we explore how FIREsampling improves performance by promoting diversity and analyze the impact ofemploying FIRE at different positions within a response.</description><author>Weizhe Chen, Zhicheng Zhang, Guanlin Liu, Renjie Zheng, Wenlei Shi, Chen Dun, Zheng Wu, Xing Jin, Lin Yan</author><pubDate>Mon, 28 Oct 2024 17:30:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21236v1</guid></item><item><title>Non-myopic Generation of Language Models for Reasoning and Planning</title><link>http://arxiv.org/abs/2410.17195v3</link><description>Large Language Models have demonstrated remarkable abilities in reasoning andplanning by breaking down complex problems into sequential steps. Despite theirsuccess in various domains like mathematical problem-solving and coding, LLMsface challenges in ensuring reliable and optimal planning due to their inherentmyopic nature of autoregressive decoding. This paper revisits LLM reasoningfrom an optimal-control perspective, proposing a novel method,Predictive-Decoding, that leverages Model Predictive Control to enhanceplanning accuracy. By re-weighting LLM distributions based on foresighttrajectories, Predictive-Decoding aims to mitigate early errors and promotenon-myopic planning. Our experiments show significant improvements in a widerange of tasks for math, coding, and agents. Furthermore, Predictive-Decodingdemonstrates computational efficiency, outperforming search baselines withreduced computational resources. This study provides insights into optimizingLLM planning capabilities.</description><author>Chang Ma, Haiteng Zhao, Junlei Zhang, Junxian He, Lingpeng Kong</author><pubDate>Mon, 28 Oct 2024 17:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17195v3</guid></item><item><title>Better Instruction-Following Through Minimum Bayes Risk</title><link>http://arxiv.org/abs/2410.02902v3</link><description>General-purpose LLM judges capable of human-level evaluation provide not onlya scalable and accurate way of evaluating instruction-following LLMs but alsonew avenues for supervising and improving their performance. One promising wayof leveraging LLM judges for supervision is through Minimum Bayes Risk (MBR)decoding, which uses a reference-based evaluator to select a high-qualityoutput from amongst a set of candidate outputs. In the first part of this work,we explore using MBR decoding as a method for improving the test-timeperformance of instruction-following LLMs. We find that MBR decoding withreference-based LLM judges substantially improves over greedy decoding,best-of-N decoding with reference-free judges and MBR decoding with lexical andembedding-based metrics on AlpacaEval and MT-Bench. These gains are consistentacross LLMs with up to 70B parameters, demonstrating that smaller LLM judgescan be used to supervise much larger LLMs. Then, seeking to retain theimprovements from MBR decoding while mitigating additional test-time costs, weexplore iterative self-training on MBR-decoded outputs. We find thatself-training using Direct Preference Optimisation leads to significantperformance gains, such that the self-trained models with greedy decodinggenerally match and sometimes exceed the performance of their base models withMBR decoding.</description><author>Ian Wu, Patrick Fernandes, Amanda Bertsch, Seungone Kim, Sina Pakazad, Graham Neubig</author><pubDate>Mon, 28 Oct 2024 17:22:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02902v3</guid></item><item><title>$\texttt{skwdro}$: a library for Wasserstein distributionally robust machine learning</title><link>http://arxiv.org/abs/2410.21231v1</link><description>We present skwdro, a Python library for training robust machine learningmodels. The library is based on distributionally robust optimization usingoptimal transport distances. For ease of use, it features both scikit-learncompatible estimators for popular objectives, as well as a wrapper for PyTorchmodules, enabling researchers and practitioners to use it in a wide range ofmodels with minimal code changes. Its implementation relies on an entropicsmoothing of the original robust objective in order to ensure maximal modelflexibility. The library is available at https://github.com/iutzeler/skwdro</description><author>Florian Vincent, WaÃ¯ss Azizian, Franck Iutzeler, JÃ©rÃ´me Malick</author><pubDate>Mon, 28 Oct 2024 17:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21231v1</guid></item><item><title>LoRA vs Full Fine-tuning: An Illusion of Equivalence</title><link>http://arxiv.org/abs/2410.21228v1</link><description>Fine-tuning is a crucial paradigm for adapting pre-trained large languagemodels to downstream tasks. Recently, methods like Low-Rank Adaptation (LoRA)have been shown to match the performance of fully fine-tuned models on varioustasks with an extreme reduction in the number of trainable parameters. Even insettings where both methods learn similarly accurate models, \emph{are theirlearned solutions really equivalent?} We study how different fine-tuningmethods change pre-trained models by analyzing the model's weight matricesthrough the lens of their spectral properties. We find that full fine-tuningand LoRA yield weight matrices whose singular value decompositions exhibit verydifferent structure; moreover, the fine-tuned models themselves show distinctgeneralization behaviors when tested outside the adaptation task'sdistribution. More specifically, we first show that the weight matrices trainedwith LoRA have new, high-ranking singular vectors, which we call \emph{intruderdimensions}. Intruder dimensions do not appear during full fine-tuning. Second,we show that LoRA models with intruder dimensions, despite achieving similarperformance to full fine-tuning on the target task, become worse models of thepre-training distribution and adapt less robustly to multiple taskssequentially. Higher-rank, rank-stabilized LoRA models closely mirror fullfine-tuning, even when performing on par with lower-rank LoRA models on thesame tasks. These results suggest that models updated with LoRA and fullfine-tuning access different parts of parameter space, even when they performequally on the fine-tuned distribution. We conclude by examining why intruderdimensions appear in LoRA fine-tuned models, why they are undesirable, and howtheir effects can be minimized.</description><author>Reece Shuttleworth, Jacob Andreas, Antonio Torralba, Pratyusha Sharma</author><pubDate>Mon, 28 Oct 2024 17:14:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21228v1</guid></item><item><title>Learning to Walk from Three Minutes of Real-World Data with Semi-structured Dynamics Models</title><link>http://arxiv.org/abs/2410.09163v2</link><description>Traditionally, model-based reinforcement learning (MBRL) methods exploitneural networks as flexible function approximators to represent $\textit{apriori}$ unknown environment dynamics. However, training data are typicallyscarce in practice, and these black-box models often fail to generalize.Modeling architectures that leverage known physics can substantially reduce thecomplexity of system-identification, but break down in the face of complexphenomena such as contact. We introduce a novel framework for learningsemi-structured dynamics models for contact-rich systems which seamlesslyintegrates structured first principles modeling techniques with black-boxauto-regressive models. Specifically, we develop an ensemble of probabilisticmodels to estimate external forces, conditioned on historical observations andactions, and integrate these predictions using known Lagrangian dynamics. Withthis semi-structured approach, we can make accurate long-horizon predictionswith substantially less data than prior methods. We leverage this capabilityand propose Semi-Structured Reinforcement Learning ($\texttt{SSRL}$) a simplemodel-based learning framework which pushes the sample complexity boundary forreal-world learning. We validate our approach on a real-world Unitree Go1quadruped robot, learning dynamic gaits -- from scratch -- on both hard andsoft surfaces with just a few minutes of real-world data. Video and code areavailable at: https://sites.google.com/utexas.edu/ssrl</description><author>Jacob Levy, Tyler Westenbroek, David Fridovich-Keil</author><pubDate>Mon, 28 Oct 2024 17:13:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09163v2</guid></item><item><title>Deep linear networks for regression are implicitly regularized towards flat minima</title><link>http://arxiv.org/abs/2405.13456v2</link><description>The largest eigenvalue of the Hessian, or sharpness, of neural networks is akey quantity to understand their optimization dynamics. In this paper, we studythe sharpness of deep linear networks for univariate regression. Minimizers canhave arbitrarily large sharpness, but not an arbitrarily small one. Indeed, weshow a lower bound on the sharpness of minimizers, which grows linearly withdepth. We then study the properties of the minimizer found by gradient flow,which is the limit of gradient descent with vanishing learning rate. We show animplicit regularization towards flat minima: the sharpness of the minimizer isno more than a constant times the lower bound. The constant depends on thecondition number of the data covariance matrix, but not on width or depth. Thisresult is proven both for a small-scale initialization and a residualinitialization. Results of independent interest are shown in both cases. Forsmall-scale initialization, we show that the learned weight matrices areapproximately rank-one and that their singular vectors align. For residualinitialization, convergence of the gradient flow for a Gaussian initializationof the residual network is proven. Numerical experiments illustrate our resultsand connect them to gradient descent with non-vanishing learning rate.</description><author>Pierre Marion, LÃ©naÃ¯c Chizat</author><pubDate>Mon, 28 Oct 2024 17:10:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13456v2</guid></item><item><title>AutoPenBench: Benchmarking Generative Agents for Penetration Testing</title><link>http://arxiv.org/abs/2410.03225v2</link><description>Generative AI agents, software systems powered by Large Language Models(LLMs), are emerging as a promising approach to automate cybersecurity tasks.Among the others, penetration testing is a challenging field due to the taskcomplexity and the diverse strategies to simulate cyber-attacks. Despitegrowing interest and initial studies in automating penetration testing withgenerative agents, there remains a significant gap in the form of acomprehensive and standard framework for their evaluation and development. Thispaper introduces AutoPenBench, an open benchmark for evaluating generativeagents in automated penetration testing. We present a comprehensive frameworkthat includes 33 tasks, each representing a vulnerable system that the agenthas to attack. Tasks are of increasing difficulty levels, including in-vitroand real-world scenarios. We assess the agent performance with generic andspecific milestones that allow us to compare results in a standardised mannerand understand the limits of the agent under test. We show the benefits ofAutoPenBench by testing two agent architectures: a fully autonomous and asemi-autonomous supporting human interaction. We compare their performance andlimitations. For example, the fully autonomous agent performs unsatisfactorilyachieving a 21% Success Rate (SR) across the benchmark, solving 27% of thesimple tasks and only one real-world task. In contrast, the assisted agentdemonstrates substantial improvements, with 64% of SR. AutoPenBench allows usalso to observe how different LLMs like GPT-4o or OpenAI o1 impact the abilityof the agents to complete the tasks. We believe that our benchmark fills thegap with a standard and flexible framework to compare penetration testingagents on a common ground. We hope to extend AutoPenBench along with theresearch community by making it available underhttps://github.com/lucagioacchini/auto-pen-bench.</description><author>Luca Gioacchini, Marco Mellia, Idilio Drago, Alexander Delsanto, Giuseppe Siracusano, Roberto Bifulco</author><pubDate>Mon, 28 Oct 2024 17:05:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03225v2</guid></item><item><title>Reconstructing dynamics from sparse observations with no training on target system</title><link>http://arxiv.org/abs/2410.21222v1</link><description>In applications, an anticipated situation is where the system of interest hasnever been encountered before and sparse observations can be made only once.Can the dynamics be faithfully reconstructed from the limited observationswithout any training data? This problem defies any known traditional methods ofnonlinear time-series analysis as well as existing machine-learning methodsthat typically require extensive data from the target system for training. Weaddress this challenge by developing a hybrid transformer andreservoir-computing machine-learning scheme. The key idea is that, for acomplex and nonlinear target system, the training of the transformer can beconducted not using any data from the target system, but with essentiallyunlimited synthetic data from known chaotic systems. The trained transformer isthen tested with the sparse data from the target system. The output of thetransformer is further fed into a reservoir computer for predicting thelong-term dynamics or the attractor of the target system. The power of theproposed hybrid machine-learning framework is demonstrated using a large numberof prototypical nonlinear dynamical systems, with high reconstruction accuracyeven when the available data is only 20% of that required to faithfullyrepresent the dynamical behavior of the underlying system. The frameworkprovides a paradigm of reconstructing complex and nonlinear dynamics in theextreme situation where training data does not exist and the observations arerandom and sparse.</description><author>Zheng-Meng Zhai, Jun-Yin Huang, Benjamin D. Stern, Ying-Cheng Lai</author><pubDate>Mon, 28 Oct 2024 17:05:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21222v1</guid></item><item><title>Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines</title><link>http://arxiv.org/abs/2410.21220v1</link><description>Search engines enable the retrieval of unknown information with texts.However, traditional methods fall short when it comes to understandingunfamiliar visual content, such as identifying an object that the model hasnever seen before. This challenge is particularly pronounced for largevision-language models (VLMs): if the model has not been exposed to the objectdepicted in an image, it struggles to generate reliable answers to the user'squestion regarding that image. Moreover, as new objects and events continuouslyemerge, frequently updating VLMs is impractical due to heavy computationalburdens. To address this limitation, we propose Vision Search Assistant, anovel framework that facilitates collaboration between VLMs and web agents.This approach leverages VLMs' visual understanding capabilities and web agents'real-time information access to perform open-world Retrieval-AugmentedGeneration via the web. By integrating visual and textual representationsthrough this collaboration, the model can provide informed responses even whenthe image is novel to the system. Extensive experiments conducted on bothopen-set and closed-set QA benchmarks demonstrate that the Vision SearchAssistant significantly outperforms the other models and can be widely appliedto existing VLMs.</description><author>Zhixin Zhang, Yiyuan Zhang, Xiaohan Ding, Xiangyu Yue</author><pubDate>Mon, 28 Oct 2024 17:04:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21220v1</guid></item><item><title>Customizing Text-to-Image Models with a Single Image Pair</title><link>http://arxiv.org/abs/2405.01536v2</link><description>Art reinterpretation is the practice of creating a variation of a referencework, making a paired artwork that exhibits a distinct artistic style. We askif such an image pair can be used to customize a generative model to capturethe demonstrated stylistic difference. We propose Pair Customization, a newcustomization method that learns stylistic difference from a single image pairand then applies the acquired style to the generation process. Unlike existingmethods that learn to mimic a single concept from a collection of images, ourmethod captures the stylistic difference between paired images. This allows usto apply a stylistic change without overfitting to the specific image contentin the examples. To address this new task, we employ a joint optimizationmethod that explicitly separates the style and content into distinct LoRAweight spaces. We optimize these style and content weights to reproduce thestyle and content images while encouraging their orthogonality. Duringinference, we modify the diffusion process via a new style guidance based onour learned weights. Both qualitative and quantitative experiments show thatour method can effectively learn style while avoiding overfitting to imagecontent, highlighting the potential of modeling such stylistic differences froma single image pair.</description><author>Maxwell Jones, Sheng-Yu Wang, Nupur Kumari, David Bau, Jun-Yan Zhu</author><pubDate>Mon, 28 Oct 2024 17:02:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01536v2</guid></item><item><title>HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation</title><link>http://arxiv.org/abs/2410.21216v1</link><description>Many positional encodings (PEs) are designed to exhibit long-term decay,based on an entrenched and long-standing inductive opinion: tokens farther awayfrom the current position carry less relevant information. We argue thatlong-term decay is outdated in the era of LLMs, as LLMs are now applied totasks demanding precise retrieval of in-context information from arbitrarypositions. Firstly, we present empirical analyses on various PEs, demonstratingthat models inherently learn attention with only a local-decay pattern whileforming a U-shape pattern globally, contradicting the principle of long-termdecay. Furthermore, we conduct a detailed analysis of rotary position encoding(RoPE, a prevalent relative positional encoding in LLMs), and found that theU-shape attention is caused by some learned components, which are also the keyfactor limiting RoPE's expressiveness and extrapolation.Inspired by theseinsights, we propose High-frequency rotary Position Encoding (HoPE). HoPEreplaces the specific components in RoPE with position-independent ones,retaining only high-frequency signals, which also breaks the principle oflong-term decay in theory. HoPE achieves two major advantages: (1) Withoutconstraints imposed by long-term decay, contradictory factors that limitspontaneous attention optimization and model extrapolation performance areremoved. (2) Components representing positions and semantics are are optimized.These enhances model's context awareness and extrapolation, as validated byextensive experiments.</description><author>Yuhan Chen, Ang Lv, Jian Luan, Bin Wang, Wei Liu</author><pubDate>Mon, 28 Oct 2024 17:01:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21216v1</guid></item><item><title>MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain</title><link>http://arxiv.org/abs/2405.02144v3</link><description>Medical texts are notoriously challenging to read. Properly measuring theirreadability is the first step towards making them more accessible. In thispaper, we present a systematic study on fine-grained readability measurementsin the medical domain at both sentence-level and span-level. We introduce a newdataset MedReadMe, which consists of manually annotated readability ratings andfine-grained complex span annotation for 4,520 sentences, featuring two novel"Google-Easy" and "Google-Hard" categories. It supports our quantitativeanalysis, which covers 650 linguistic features and automatic complex word andjargon identification. Enabled by our high-quality annotation, we benchmark andimprove several state-of-the-art sentence-level readability metrics for themedical domain specifically, which include unsupervised, supervised, andprompting-based methods using recently developed large language models (LLMs).Informed by our fine-grained complex span annotation, we find that adding asingle feature, capturing the number of jargon spans, into existing readabilityformulas can significantly improve their correlation with human judgments. Thedata is available at tinyurl.com/medreadme-repo</description><author>Chao Jiang, Wei Xu</author><pubDate>Mon, 28 Oct 2024 17:01:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02144v3</guid></item><item><title>On learning higher-order cumulants in diffusion models</title><link>http://arxiv.org/abs/2410.21212v1</link><description>To analyse how diffusion models learn correlations beyond Gaussian ones, westudy the behaviour of higher-order cumulants, or connected n-point functions,under both the forward and backward process. We derive explicit expressions forthe moment- and cumulant-generating functionals, in terms of the distributionof the initial data and properties of forward process. It is shown analyticallythat during the forward process higher-order cumulants are conserved in modelswithout a drift, such as the variance-expanding scheme, and that therefore theendpoint of the forward process maintains nontrivial correlations. Wedemonstrate that since these correlations are encoded in the score function,higher-order cumulants are learnt in the backward process, also when startingfrom a normal prior. We confirm our analytical results in an exactly solvabletoy model with nonzero cumulants and in scalar lattice field theory.</description><author>Gert Aarts, Diaa E. Habibi, Lingxiao Wang, Kai Zhou</author><pubDate>Mon, 28 Oct 2024 16:57:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21212v1</guid></item><item><title>Exploring contextual modeling with linear complexity for point cloud segmentation</title><link>http://arxiv.org/abs/2410.21211v1</link><description>Point cloud segmentation is an important topic in 3D understanding that hastraditionally has been tackled using either the CNN or Transformer. Recently,Mamba has emerged as a promising alternative, offering efficient long-rangecontextual modeling capabilities without the quadratic complexity associatedwith Transformer's attention mechanisms. However, despite Mamba's potential,early efforts have all failed to achieve better performance than the bestCNN-based and Transformer-based methods. In this work, we address thischallenge by identifying the key components of an effective and efficient pointcloud segmentation architecture. Specifically, we show that: 1) Spatiallocality and robust contextual understanding are critical for strongperformance, and 2) Mamba features linear computational complexity, offeringsuperior data and inference efficiency compared to Transformers, while stillbeing capable of delivering strong contextual understanding. Additionally, wefurther enhance the standard Mamba specifically for point cloud segmentation byidentifying its two key shortcomings. First, the enforced causality in theoriginal Mamba is unsuitable for processing point clouds that have no suchdependencies. Second, its unidirectional scanning strategy imposes adirectional bias, hampering its ability to capture the full context ofunordered point clouds in a single pass. To address these issues, we carefullyremove the causal convolutions and introduce a novel Strided Bidirectional SSMto enhance the model's capability to capture spatial relationships. Our effortsculminate in the development of a novel architecture named MEEPO, whicheffectively integrates the strengths of CNN and Mamba. MEEPO surpasses theprevious state-of-the-art method, PTv3, by up to +0.8 mIoU on multiple keybenchmark datasets, while being 42.1% faster and 5.53x more memory efficient.</description><author>Yong Xien Chng, Xuchong Qiu, Yizeng Han, Yifan Pu, Jiewei Cao, Gao Huang</author><pubDate>Mon, 28 Oct 2024 16:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21211v1</guid></item><item><title>SeriesGAN: Time Series Generation via Adversarial and Autoregressive Learning</title><link>http://arxiv.org/abs/2410.21203v1</link><description>Current Generative Adversarial Network (GAN)-based approaches for time seriesgeneration face challenges such as suboptimal convergence, information loss inembedding spaces, and instability. To overcome these challenges, we introducean advanced framework that integrates the advantages of anautoencoder-generated embedding space with the adversarial training dynamics ofGANs. This method employs two discriminators: one to specifically guide thegenerator and another to refine both the autoencoder's and generator's output.Additionally, our framework incorporates a novel autoencoder-based lossfunction and supervision from a teacher-forcing supervisor network, whichcaptures the stepwise conditional distributions of the data. The generatoroperates within the latent space, while the two discriminators work on latentand feature spaces separately, providing crucial feedback to both the generatorand the autoencoder. By leveraging this dual-discriminator approach, weminimize information loss in the embedding space. Through joint training, ourframework excels at generating high-fidelity time series data, consistentlyoutperforming existing state-of-the-art benchmarks both qualitatively andquantitatively across a range of real and synthetic multivariate time seriesdatasets.</description><author>MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi</author><pubDate>Mon, 28 Oct 2024 16:49:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21203v1</guid></item><item><title>The Group Robustness is in the Details: Revisiting Finetuning under Spurious Correlations</title><link>http://arxiv.org/abs/2407.13957v2</link><description>Modern machine learning models are prone to over-reliance on spuriouscorrelations, which can often lead to poor performance on minority groups. Inthis paper, we identify surprising and nuanced behavior of finetuned models onworst-group accuracy via comprehensive experiments on four well-establishedbenchmarks across vision and language tasks. We first show that the commonlyused class-balancing techniques of mini-batch upsampling and loss upweightingcan induce a decrease in worst-group accuracy (WGA) with training epochs,leading to performance no better than without class-balancing. While in somescenarios, removing data to create a class-balanced subset is more effective,we show this depends on group structure and propose a mixture method which canoutperform both techniques. Next, we show that scaling pretrained models isgenerally beneficial for worst-group accuracy, but only in conjunction withappropriate class-balancing. Finally, we identify spectral imbalance infinetuning features as a potential source of group disparities -- minoritygroup covariance matrices incur a larger spectral norm than majority groupsonce conditioned on the classes. Our results show more nuanced interactions ofmodern finetuned models with group robustness than was previously known. Ourcode is available at https://github.com/tmlabonte/revisiting-finetuning.</description><author>Tyler LaBonte, John C. Hill, Xinchen Zhang, Vidya Muthukumar, Abhishek Kumar</author><pubDate>Mon, 28 Oct 2024 16:47:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13957v2</guid></item><item><title>BongLLaMA: LLaMA for Bangla Language</title><link>http://arxiv.org/abs/2410.21200v1</link><description>Bangla (or "Bengali") is a language spoken by approximately 240 millionnative speakers and around 300 million people worldwide. Despite being the 5thlargest spoken language in the world, Bangla is still a "low-resource"language, and existing pretrained language models often struggle to performwell on Bangla Language Processing (BLP) tasks. This work addresses this gap byintroducing BongLLaMA (i.e., Bangla-LLaMA), an open-source large language modelfine-tuned exclusively on large Bangla corpora and instruction-tuning datasets.We present our methodology, data augmentation techniques, fine-tuning details,and comprehensive benchmarking results showcasing the utility of BongLLaMA onBLP tasks. We believe BongLLaMA will serve as the new standard baseline forBangla Language Models and, thus, facilitate future benchmarking studiesfocused on this widely-spoken yet "low-resource" language. All BongLLaMA modelsare available for public use at https://huggingface.co/BanglaLLM.</description><author>Abdullah Khan Zehady, Safi Al Mamun, Naymul Islam, Santu Karmaker</author><pubDate>Mon, 28 Oct 2024 16:44:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21200v1</guid></item><item><title>MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses</title><link>http://arxiv.org/abs/2410.07076v3</link><description>Scientific discovery contributes largely to human society's prosperity, andrecent progress shows that LLMs could potentially catalyze this process.However, it is still unclear whether LLMs can discover novel and validhypotheses in chemistry. In this work, we investigate this central researchquestion: Can LLMs automatically discover novel and valid chemistry researchhypotheses given only a chemistry research background (consisting of a researchquestion and/or a background survey), without limitation on the domain of theresearch question? After extensive discussions with chemistry experts, wepropose an assumption that a majority of chemistry hypotheses can be resultedfrom a research background and several inspirations. With this key insight, webreak the central question into three smaller fundamental questions. In brief,they are: (1) given a background question, whether LLMs can retrieve goodinspirations; (2) with background and inspirations, whether LLMs can lead tohypothesis; and (3) whether LLMs can identify good hypotheses to rank themhigher. To investigate these questions, we construct a benchmark consisting of51 chemistry papers published in Nature, Science, or a similar level in 2024(all papers are only available online since 2024). Every paper is divided bychemistry PhD students into three components: background, inspirations, andhypothesis. The goal is to rediscover the hypothesis, given only the backgroundand a large randomly selected chemistry literature corpus consisting the groundtruth inspiration papers, with LLMs trained with data up to 2023. We alsodevelop an LLM-based multi-agent framework that leverages the assumption,consisting of three stages reflecting the three smaller questions. The proposedmethod can rediscover many hypotheses with very high similarity with the groundtruth ones, covering the main innovations.</description><author>Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, Dongzhan Zhou</author><pubDate>Mon, 28 Oct 2024 16:39:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07076v3</guid></item><item><title>Belief in the Machine: Investigating Epistemological Blind Spots of Language Models</title><link>http://arxiv.org/abs/2410.21195v1</link><description>As language models (LMs) become integral to fields like healthcare, law, andjournalism, their ability to differentiate between fact, belief, and knowledgeis essential for reliable decision-making. Failure to grasp these distinctionscan lead to significant consequences in areas such as medical diagnosis, legaljudgments, and dissemination of fake news. Despite this, current literature haslargely focused on more complex issues such as theory of mind, overlooking morefundamental epistemic challenges. This study systematically evaluates theepistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, andLlama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13tasks. Our results reveal key limitations. First, while LMs achieve 86%accuracy on factual scenarios, their performance drops significantly with falsescenarios, particularly in belief-related tasks. Second, LMs struggle withrecognizing and affirming personal beliefs, especially when those beliefscontradict factual data, which raises concerns for applications in healthcareand counseling, where engaging with a person's beliefs is critical. Third, weidentify a salient bias in how LMs process first-person versus third-personbeliefs, performing better on third-person tasks (80.7%) compared tofirst-person tasks (54.4%). Fourth, LMs lack a robust understanding of thefactive nature of knowledge, namely, that knowledge inherently requires truth.Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass thedeeper reasoning. These findings highlight significant concerns about currentLMs' ability to reason about truth, belief, and knowledge while emphasizing theneed for advancements in these areas before broad deployment in criticalsectors.</description><author>Mirac Suzgun, Tayfun Gur, Federico Bianchi, Daniel E. Ho, Thomas Icard, Dan Jurafsky, James Zou</author><pubDate>Mon, 28 Oct 2024 16:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21195v1</guid></item><item><title>SAM 2: Segment Anything in Images and Videos</title><link>http://arxiv.org/abs/2408.00714v2</link><description>We present Segment Anything Model 2 (SAM 2), a foundation model towardssolving promptable visual segmentation in images and videos. We build a dataengine, which improves model and data via user interaction, to collect thelargest video segmentation dataset to date. Our model is a simple transformerarchitecture with streaming memory for real-time video processing. SAM 2trained on our data provides strong performance across a wide range of tasks.In video segmentation, we observe better accuracy, using 3x fewer interactionsthan prior approaches. In image segmentation, our model is more accurate and 6xfaster than the Segment Anything Model (SAM). We believe that our data, model,and insights will serve as a significant milestone for video segmentation andrelated perception tasks. We are releasing our main model, dataset, as well ascode for model training and our demo.</description><author>Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman RÃ¤dle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr DollÃ¡r, Christoph Feichtenhofer</author><pubDate>Mon, 28 Oct 2024 16:37:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00714v2</guid></item><item><title>Representation noising can prevent harmful fine-tuning on LLMs</title><link>http://arxiv.org/abs/2405.14577v3</link><description>Releasing open-source large language models (LLMs) presents a dual-use risksince bad actors can easily fine-tune these models for harmful purposes. Evenwithout the open release of weights, weight stealing and fine-tuning APIs makeclosed models vulnerable to harmful fine-tuning attacks (HFAs). While safetymeasures like preventing jailbreaks and improving safety guardrails areimportant, such measures can easily be reversed through fine-tuning. In thiswork, we propose Representation Noising (RepNoise), a defence mechanism that iseffective even when attackers have access to the weights. RepNoise works byremoving information about harmful representations such that it is difficult torecover them during fine-tuning. Importantly, our defence is also able togeneralize across different subsets of harm that have not been seen during thedefence process as long as they are drawn from the same distribution of theattack set. Our method does not degrade the general capability of LLMs andretains the ability to train the model on harmless tasks. We provide empiricalevidence that the effectiveness of our defence lies in its "depth": the degreeto which information about harmful representations is removed across all layersof the LLM.</description><author>Domenic Rosati, Jan Wehner, Kai Williams, Åukasz Bartoszcze, David Atanasov, Robie Gonzales, Subhabrata Majumdar, Carsten Maple, Hassan Sajjad, Frank Rudzicz</author><pubDate>Mon, 28 Oct 2024 16:37:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14577v3</guid></item><item><title>SoS Certifiability of Subgaussian Distributions and its Algorithmic Applications</title><link>http://arxiv.org/abs/2410.21194v1</link><description>We prove that there is a universal constant $C&gt;0$ so that for every $d \in\mathbb N$, every centered subgaussian distribution $\mathcal D$ on $\mathbbR^d$, and every even $p \in \mathbb N$, the $d$-variate polynomial $(Cp)^{p/2}\cdot \|v\|_{2}^p - \mathbb E_{X \sim \mathcal D} \langle v,X\rangle^p$ is asum of square polynomials. This establishes that every subgaussian distributionis \emph{SoS-certifiably subgaussian} -- a condition that yields efficientlearning algorithms for a wide variety of high-dimensional statistical tasks.As a direct corollary, we obtain computationally efficient algorithms withnear-optimal guarantees for the following tasks, when given samples from anarbitrary subgaussian distribution: robust mean estimation, list-decodable meanestimation, clustering mean-separated mixture models, robust covariance-awaremean estimation, robust covariance estimation, and robust linear regression.Our proof makes essential use of Talagrand's generic chaining/majorizingmeasures theorem.</description><author>Ilias Diakonikolas, Samuel B. Hopkins, Ankit Pensia, Stefan Tiegel</author><pubDate>Mon, 28 Oct 2024 16:36:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21194v1</guid></item><item><title>On Homomorphic Encryption Based Strategies for Class Imbalance in Federated Learning</title><link>http://arxiv.org/abs/2410.21192v1</link><description>Class imbalance in training datasets can lead to bias and poor generalizationin machine learning models. While pre-processing of training datasets canefficiently address both these issues in centralized learning environments, itis challenging to detect and address these issues in a distributed learningenvironment such as federated learning. In this paper, we propose FLICKER, aprivacy preserving framework to address issues related to global classimbalance in federated learning. At the heart of our contribution lies thepopular CKKS homomorphic encryption scheme, which is used by the clients toprivately share their data attributes, and subsequently balance their datasetsbefore implementing the FL scheme. Extensive experimental results show that ourproposed method significantly improves the FL accuracy numbers when used alongwith popular datasets and relevant baselines.</description><author>Arpit Guleria, J. Harshan, Ranjitha Prasad, B. N. Bharath</author><pubDate>Mon, 28 Oct 2024 16:35:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21192v1</guid></item><item><title>A Comparative Analysis of Wealth Index Predictions in Africa between three Multi-Source Inference Models</title><link>http://arxiv.org/abs/2408.01631v3</link><description>Poverty map inference has become a critical focus of research, utilizing bothtraditional and modern techniques, ranging from regression models toconvolutional neural networks applied to tabular data, satellite imagery, andnetworks. While much attention has been given to validating models during thetraining phase, the final predictions have received less scrutiny. In thisstudy, we analyze the International Wealth Index (IWI) predicted by Lee andBraithwaite (2022) and Esp\'in-Noboa et al. (2023), alongside the RelativeWealth Index (RWI) inferred by Chi et al. (2022), across six Sub-SaharanAfrican countries. Our analysis reveals trends and discrepancies in wealthpredictions between these models. In particular, significant and unexpecteddiscrepancies between the predictions of Lee and Braithwaite and Esp\'in-Noboaet al., even after accounting for differences in training data. In contrast,the shape of the wealth distributions predicted by Esp\'in-Noboa et al. and Chiet al. are more closely aligned, suggesting similar levels of skewness. Thesefindings raise concerns about the validity of certain models and emphasize theimportance of rigorous audits for wealth prediction algorithms used inpolicy-making. Continuous validation and refinement are essential to ensure thereliability of these models, particularly when they inform poverty alleviationstrategies.</description><author>MÃ¡rton Karsai, JÃ¡nos KertÃ©sz, Lisette EspÃ­n-Noboa</author><pubDate>Mon, 28 Oct 2024 16:33:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01631v3</guid></item><item><title>Artificial Generational Intelligence: Cultural Accumulation in Reinforcement Learning</title><link>http://arxiv.org/abs/2406.00392v2</link><description>Cultural accumulation drives the open-ended and diverse progress incapabilities spanning human history. It builds an expanding body of knowledgeand skills by combining individual exploration with inter-generationalinformation transmission. Despite its widespread success among humans, thecapacity for artificial learning agents to accumulate culture remainsunder-explored. In particular, approaches to reinforcement learning typicallystrive for improvements over only a single lifetime. Generational algorithmsthat do exist fail to capture the open-ended, emergent nature of culturalaccumulation, which allows individuals to trade-off innovation and imitation.Building on the previously demonstrated ability for reinforcement learningagents to perform social learning, we find that training setups which balancethis with independent learning give rise to cultural accumulation. Theseaccumulating agents outperform those trained for a single lifetime with thesame cumulative experience. We explore this accumulation by constructing twomodels under two distinct notions of a generation: episodic generations, inwhich accumulation occurs via in-context learning and train-time generations,in which accumulation occurs via in-weights learning. In-context and in-weightscultural accumulation can be interpreted as analogous to knowledge and skillaccumulation, respectively. To the best of our knowledge, this work is thefirst to present general models that achieve emergent cultural accumulation inreinforcement learning, opening up new avenues towards more open-ended learningsystems, as well as presenting new opportunities for modelling human culture.</description><author>Jonathan Cook, Chris Lu, Edward Hughes, Joel Z. Leibo, Jakob Foerster</author><pubDate>Mon, 28 Oct 2024 16:33:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.00392v2</guid></item><item><title>Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?</title><link>http://arxiv.org/abs/2407.01119v2</link><description>It has become routine to report research results where Large Language Models(LLMs) outperform average humans in a wide range of language-related tasks, andcreative text writing is no exception. It seems natural, then, to raise thebid: Are LLMs ready to compete in creative writing skills with a top (ratherthan average) novelist? To provide an initial answer for this question, we havecarried out a contest between Patricio Pron (an awarded novelist, consideredone of the best of his generation) and GPT-4 (one of the top performing LLMs),in the spirit of AI-human duels such as DeepBlue vs Kasparov and AlphaGo vs LeeSidol. We asked Pron and GPT-4 to provide thirty titles each, and then to writeshort stories for both their titles and their opponent's. Then, we prepared anevaluation rubric inspired by Boden's definition of creativity, and wecollected 5,400 manual assessments provided by literature critics and scholars.The results of our experimentation indicate that LLMs are still far fromchallenging a top human creative writer, and that reaching such level ofautonomous creative writing skills probably cannot be reached simply withlarger language models.</description><author>Guillermo Marco, Julio Gonzalo, RamÃ³n del Castillo, MarÃ­a Teresa Mateo Girona</author><pubDate>Mon, 28 Oct 2024 16:32:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01119v2</guid></item><item><title>Aligning Text-to-Image Diffusion Models with Reward Backpropagation</title><link>http://arxiv.org/abs/2310.03739v3</link><description>Text-to-image diffusion models have recently emerged at the forefront ofimage generation, powered by very large-scale unsupervised or weakly supervisedtext-to-image training datasets. Due to their unsupervised training,controlling their behavior in downstream tasks, such as maximizinghuman-perceived image quality, image-text alignment, or ethical imagegeneration, is difficult. Recent works finetune diffusion models to downstreamreward functions using vanilla reinforcement learning, notorious for the highvariance of the gradient estimators. In this paper, we propose AlignProp, amethod that aligns diffusion models to downstream reward functions usingend-to-end backpropagation of the reward gradient through the denoisingprocess. While naive implementation of such backpropagation would requireprohibitive memory resources for storing the partial derivatives of moderntext-to-image models, AlignProp finetunes low-rank adapter weight modules anduses gradient checkpointing, to render its memory usage viable. We testAlignProp in finetuning diffusion models to various objectives, such asimage-text semantic alignment, aesthetics, compressibility and controllabilityof the number of objects present, as well as their combinations. We showAlignProp achieves higher rewards in fewer training steps than alternatives,while being conceptually simpler, making it a straightforward choice foroptimizing diffusion models for differentiable reward functions of interest.Code and Visualization results are available at https://align-prop.github.io/.</description><author>Mihir Prabhudesai, Anirudh Goyal, Deepak Pathak, Katerina Fragkiadaki</author><pubDate>Mon, 28 Oct 2024 16:25:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03739v3</guid></item><item><title>Immunohistochemistry guided segmentation of benign epithelial cells, in situ lesions, and invasive epithelial cells in breast cancer slides</title><link>http://arxiv.org/abs/2311.13261v4</link><description>Digital pathology enables automatic analysis of histopathological sectionsusing artificial intelligence (AI). Automatic evaluation could improvediagnostic efficiency and help find associations between morphological featuresand clinical outcome. For development of such prediction models, identifyinginvasive epithelial cells, and separating these from benign epithelial cellsand in situ lesions would be the first step. In this study, we aimed to developan AI model for segmentation of epithelial cells in sections from breastcancer. We generated epithelial ground truth masks by restaining hematoxylinand eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists'annotations. HE/CK image pairs were used to train a convolutional neuralnetwork, and data augmentation was used to make the model more robust. Tissuemicroarrays (TMAs) from 839 patients, and whole slide images from two patientswere used for training and evaluation of the models. The sections were derivedfrom four cohorts of breast cancer patients. TMAs from 21 patients from a fifthcohort was used as a second test set. In quantitative evaluation, a mean Dicescore of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelialcells, and in situ lesions, respectively, were achieved. In qualitative scoring(0-5) by pathologists, results were best for all epithelium and invasiveepithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and insitu lesions were 3.7 and 2.0. The proposed model segmented epithelial cells inHE stained breast cancer slides well, but further work is needed for accuratedivision between the classes. Immunohistochemistry, together with pathologists'annotations, enabled the creation of accurate ground truths. The model is madefreely available in FastPathology and the code is available athttps://github.com/AICAN-Research/breast-epithelium-segmentation</description><author>Maren HÃ¸ibÃ¸, AndrÃ© Pedersen, Vibeke Grotnes Dale, Sissel Marie Berget, Borgny Ytterhus, Cecilia Lindskog, Elisabeth Wik, Lars A. Akslen, Ingerid Reinertsen, Erik Smistad, Marit Valla</author><pubDate>Mon, 28 Oct 2024 16:24:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13261v4</guid></item><item><title>An Effective Theory of Bias Amplification</title><link>http://arxiv.org/abs/2410.17263v2</link><description>Machine learning models may capture and amplify biases present in data,leading to disparate test performance across social groups. To betterunderstand, evaluate, and mitigate these possible biases, a deeper theoreticalunderstanding of how model design choices and data distribution propertiescould contribute to bias is needed. In this work, we contribute a preciseanalytical theory in the context of ridge regression, both with and withoutrandom projections, where the former models neural networks in a simplifiedregime. Our theory offers a unified and rigorous explanation of machinelearning bias, providing insights into phenomena such as bias amplification andminority-group bias in various feature and parameter regimes. For example, wedemonstrate that there may be an optimal regularization penalty or trainingtime to avoid bias amplification, and there can be fundamental differences intest error between groups that do not vanish with increased parameterization.Importantly, our theoretical predictions align with several empiricalobservations reported in the literature. We extensively empirically validateour theory on diverse synthetic and semi-synthetic datasets.</description><author>Arjun Subramonian, Sam Bell, Levent Sagun, Elvis Dohmatob</author><pubDate>Mon, 28 Oct 2024 16:24:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17263v2</guid></item><item><title>A Probability--Quality Trade-off in Aligned Language Models and its Relation to Sampling Adaptors</title><link>http://arxiv.org/abs/2406.10203v4</link><description>The relationship between the quality of a string, as judged by a humanreader, and its probability, $p(\boldsymbol{y})$ under a language modelundergirds the development of better language models. For example, many popularalgorithms for sampling from a language model have been conceived with the goalof manipulating $p(\boldsymbol{y})$ to place higher probability on strings thathumans deem of high quality. In this article, we examine theprobability--quality relationship in language models explicitly aligned tohuman preferences, e.g., through reinforcement learning through human feedback.We show that, when sampling corpora from an aligned language model, thereexists a trade-off between the strings' average reward and averagelog-likelihood under the prior language model, i.e., the same model beforealignment with human preferences. We provide a formal treatment of thisphenomenon and demonstrate how a choice of sampling adaptor allows for aselection of how much likelihood we exchange for the reward.</description><author>Naaman Tan, Josef Valvoda, Tianyu Liu, Anej Svete, Yanxia Qin, Kan Min-Yen, Ryan Cotterell</author><pubDate>Mon, 28 Oct 2024 16:17:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10203v4</guid></item><item><title>Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks</title><link>http://arxiv.org/abs/2410.21175v1</link><description>For structural health monitoring, continuous and automatic crack detectionhas been a challenging problem. This study is conducted to propose a frameworkof automatic crack segmentation from high-resolution images containing crackinformation about steel box girders of bridges. Considering the multi-scalefeature of cracks, convolutional neural network architecture of Feature PyramidNetworks (FPN) for crack detection is proposed. As for input, 120 raw imagesare processed via two approaches (shrinking the size of images and splittingimages into sub-images). Then, models with the proposed structure of FPN forcrack detection are developed. The result shows all developed models canautomatically detect the cracks at the raw images. By shrinking the images, thecomputation efficiency is improved without decreasing accuracy. Because of theseparable characteristic of crack, models using the splitting method providemore accurate crack segmentations than models using the resizing method.Therefore, for high-resolution images, the FPN structure coupled with thesplitting method is an promising solution for the crack segmentation anddetection.</description><author>Jiawei Zhang, Jun Li, Reachsak Ly, Yunyi Liu, Jiangpeng Shu</author><pubDate>Mon, 28 Oct 2024 16:16:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21175v1</guid></item><item><title>Joint Audio-Visual Idling Vehicle Detection with Streamlined Input Dependencies</title><link>http://arxiv.org/abs/2410.21170v1</link><description>Idling vehicle detection (IVD) can be helpful in monitoring and reducingunnecessary idling and can be integrated into real-time systems to address theresulting pollution and harmful products. The previous approach [13], anon-end-to-end model, requires extra user clicks to specify a part of theinput, making system deployment more error-prone or even not feasible. Incontrast, we introduce an end-to-end joint audio-visual IVD task designed todetect vehicles visually under three states: moving, idling and engine off.Unlike feature co-occurrence task such as audio-visual vehicle tracking, ourIVD task addresses complementary features, where labels cannot be determined bya single modality alone. To this end, we propose AVIVD-Net, a novel networkthat integrates audio and visual features through a bidirectional attentionmechanism. AVIVD-Net streamlines the input process by learning a joint featurespace, reducing the deployment complexity of previous methods. Additionally, weintroduce the AVIVD dataset, which is seven times larger than previousdatasets, offering significantly more annotated samples to study the IVDproblem. Our model achieves performance comparable to prior approaches, makingit suitable for automated deployment. Furthermore, by evaluating AVIVDNet onthe feature co-occurrence public dataset MAVD [23], we demonstrate itspotential for extension to self-driving vehicle video-camera setups.</description><author>Xiwen Li, Rehman Mohammed, Tristalee Mangin, Surojit Saha, Ross T Whitaker, Kerry E. Kelly, Tolga Tasdizen</author><pubDate>Mon, 28 Oct 2024 16:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21170v1</guid></item><item><title>Efficient Certificates of Anti-Concentration Beyond Gaussians</title><link>http://arxiv.org/abs/2405.15084v2</link><description>A set of high dimensional points $X=\{x_1, x_2,\ldots, x_n\} \subset R^d$ inisotropic position is said to be $\delta$-anti concentrated if for everydirection $v$, the fraction of points in $X$ satisfying $|\langle x_i,v \rangle|\leq \delta$ is at most $O(\delta)$. Motivated by applications tolist-decodable learning and clustering, recent works have considered theproblem of constructing efficient certificates of anti-concentration in theaverage case, when the set of points $X$ corresponds to samples from a Gaussiandistribution. Their certificates played a crucial role in several subsequentworks in algorithmic robust statistics on list-decodable learning and settlingthe robust learnability of arbitrary Gaussian mixtures, yet remain limited torotationally invariant distributions. This work presents a new (and arguably the most natural) formulation foranti-concentration. Using this formulation, we give quasi-polynomial timeverifiable sum-of-squares certificates of anti-concentration that hold for awide class of non-Gaussian distributions including anti-concentrated boundedproduct distributions and uniform distributions over $L_p$ balls (and theiraffine transformations). Consequently, our method upgrades and extends resultsin algorithmic robust statistics e.g., list-decodable learning and clustering,to such distributions. Our approach constructs a canonical integer program foranti-concentration and analysis a sum-of-squares relaxation of it, independentof the intended application. We rely on duality and analyze apseudo-expectation on large subsets of the input points that take a small valuein some direction. Our analysis uses the method of polynomial reweightings toreduce the problem to analyzing only analytically dense or sparse directions.</description><author>Ainesh Bakshi, Pravesh Kothari, Goutham Rajendran, Madhur Tulsiani, Aravindan Vijayaraghavan</author><pubDate>Mon, 28 Oct 2024 16:13:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15084v2</guid></item><item><title>Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction</title><link>http://arxiv.org/abs/2410.21169v1</link><description>Document parsing is essential for converting unstructured and semi-structureddocuments-such as contracts, academic papers, and invoices-into structured,machine-readable data. Document parsing extract reliable structured data fromunstructured inputs, providing huge convenience for numerous applications.Especially with recent achievements in Large Language Models, document parsingplays an indispensable role in both knowledge base construction and trainingdata generation. This survey presents a comprehensive review of the currentstate of document parsing, covering key methodologies, from modular pipelinesystems to end-to-end models driven by large vision-language models. Corecomponents such as layout detection, content extraction (including text,tables, and mathematical expressions), and multi-modal data integration areexamined in detail. Additionally, this paper discusses the challenges faced bymodular document parsing systems and vision-language models in handling complexlayouts, integrating multiple modules, and recognizing high-density text. Itemphasizes the importance of developing larger and more diverse datasets andoutlines future research directions.</description><author>Qintong Zhang, Victor Shea-Jay Huang, Bin Wang, Junyuan Zhang, Zhengren Wang, Hao Liang, Shawn Wang, Matthieu Lin, Wentao Zhang, Conghui He</author><pubDate>Mon, 28 Oct 2024 16:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21169v1</guid></item><item><title>Differentially Private Learned Indexes</title><link>http://arxiv.org/abs/2410.21164v1</link><description>In this paper, we address the problem of efficiently answering predicatequeries on encrypted databases, those secured by Trusted Execution Environments(TEEs), which enable untrusted providers to process encrypted user data withoutrevealing its contents. A common strategy in modern databases to acceleratepredicate queries is the use of indexes, which map attribute values (keys) totheir corresponding positions in a sorted data array. This allows for fastlookup and retrieval of data subsets that satisfy specific predicates.Unfortunately, indexes cannot be directly applied to encrypted databases due tostrong data dependent leakages. Recent approaches apply differential privacy(DP) to construct noisy indexes that enable faster access to encrypted datawhile maintaining provable privacy guarantees. However, these methods oftensuffer from large storage costs, with index sizes typically scaling linearlywith the key space. To address this challenge, we propose leveraging learnedindexes, a trending technique that repurposes machine learning models asindexing structures, to build more compact DP indexes.</description><author>Jianzhang Du, Tilak Mudgal, Rutvi Rahul Gadre, Yukui Luo, Chenghong Wang</author><pubDate>Mon, 28 Oct 2024 16:04:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21164v1</guid></item><item><title>Resilience in Knowledge Graph Embeddings</title><link>http://arxiv.org/abs/2410.21163v1</link><description>In recent years, knowledge graphs have gained interest and witnessedwidespread applications in various domains, such as information retrieval,question-answering, recommendation systems, amongst others. Large-scaleknowledge graphs to this end have demonstrated their utility in effectivelyrepresenting structured knowledge. To further facilitate the application ofmachine learning techniques, knowledge graph embedding (KGE) models have beendeveloped. Such models can transform entities and relationships withinknowledge graphs into vectors. However, these embedding models often facechallenges related to noise, missing information, distribution shift,adversarial attacks, etc. This can lead to sub-optimal embeddings and incorrectinferences, thereby negatively impacting downstream applications. While theexisting literature has focused so far on adversarial attacks on KGE models,the challenges related to the other critical aspects remain unexplored. In thispaper, we, first of all, give a unified definition of resilience, encompassingseveral factors such as generalisation, performance consistency, distributionadaption, and robustness. After formalizing these concepts for machine learningin general, we define them in the context of knowledge graphs. To find the gapin the existing works on resilience in the context of knowledge graphs, weperform a systematic survey, taking into account all these aspects mentionedpreviously. Our survey results show that most of the existing works focus on aspecific aspect of resilience, namely robustness. After categorizing such worksbased on their respective aspects of resilience, we discuss the challenges andfuture research directions.</description><author>Arnab Sharma, N'Dah Jean Kouagou, Axel-Cyrille Ngonga Ngomo</author><pubDate>Mon, 28 Oct 2024 16:04:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21163v1</guid></item><item><title>End-To-End Causal Effect Estimation from Unstructured Natural Language Data</title><link>http://arxiv.org/abs/2407.07018v3</link><description>Knowing the effect of an intervention is critical for human decision-making,but current approaches for causal effect estimation rely on manual datacollection and structuring, regardless of the causal assumptions. Thisincreases both the cost and time-to-completion for studies. We show how large,diverse observational text data can be mined with large language models (LLMs)to produce inexpensive causal effect estimates under appropriate causalassumptions. We introduce NATURAL, a novel family of causal effect estimatorsbuilt with LLMs that operate over datasets of unstructured text. Our estimatorsuse LLM conditional distributions (over variables of interest, given the textdata) to assist in the computation of classical estimators of causal effect. Weovercome a number of technical challenges to realize this idea, such asautomating data curation and using LLMs to impute missing information. Weprepare six (two synthetic and four real) observational datasets, paired withcorresponding ground truth in the form of randomized trials, which we used tosystematically evaluate each step of our pipeline. NATURAL estimatorsdemonstrate remarkable performance, yielding causal effect estimates that fallwithin 3 percentage points of their ground truth counterparts, including onreal-world Phase 3/4 clinical trials. Our results suggest that unstructuredtext data is a rich source of causal effect information, and NATURAL is a firststep towards an automated pipeline to tap this resource.</description><author>Nikita Dhawan, Leonardo Cotta, Karen Ullrich, Rahul G. Krishnan, Chris J. Maddison</author><pubDate>Mon, 28 Oct 2024 16:03:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07018v3</guid></item><item><title>Toward Open Vocabulary Aerial Object Detection with CLIP-Activated Student-Teacher Learning</title><link>http://arxiv.org/abs/2311.11646v4</link><description>An increasingly massive number of remote-sensing images spurs the developmentof extensible object detectors that can detect objects beyond trainingcategories without costly collecting new labeled data. In this paper, we aim todevelop open-vocabulary object detection (OVD) technique in aerial images thatscales up object vocabulary size beyond training data. The performance of OVDgreatly relies on the quality of class-agnostic region proposals andpseudo-labels for novel object categories. To simultaneously generatehigh-quality proposals and pseudo-labels, we propose CastDet, a CLIP-activatedstudent-teacher open-vocabulary object Detection framework. Our end-to-endframework following the student-teacher self-learning mechanism employs theRemoteCLIP model as an extra omniscient teacher with rich knowledge. By doingso, our approach boosts not only novel object proposals but alsoclassification. Furthermore, we devise a dynamic label queue strategy tomaintain high-quality pseudo labels during batch training. We conduct extensiveexperiments on multiple existing aerial object detection datasets, which areset up for the OVD task. Experimental results demonstrate our CastDet achievingsuperior open-vocabulary detection performance, e.g., reaching 46.5% mAP onVisDroneZSD novel categories, which outperforms the state-of-the-artopen-vocabulary detectors by 21.0% mAP. To our best knowledge, this is thefirst work to apply and develop the open-vocabulary object detection techniquefor aerial images. The code is available athttps://github.com/lizzy8587/CastDet.</description><author>Yan Li, Weiwei Guo, Xue Yang, Ning Liao, Dunyun He, Jiaqi Zhou, Wenxian Yu</author><pubDate>Mon, 28 Oct 2024 16:01:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11646v4</guid></item><item><title>KaLDeX: Kalman Filter based Linear Deformable Cross Attention for Retina Vessel Segmentation</title><link>http://arxiv.org/abs/2410.21160v1</link><description>Background and Objective: In the realm of ophthalmic imaging, accuratevascular segmentation is paramount for diagnosing and managing various eyediseases. Contemporary deep learning-based vascular segmentation models rivalhuman accuracy but still face substantial challenges in accurately segmentingminuscule blood vessels in neural network applications. Due to the necessity ofmultiple downsampling operations in the CNN models, fine details fromhigh-resolution images are inevitably lost. The objective of this study is todesign a structure to capture the delicate and small blood vessels. Methods: Toaddress these issues, we propose a novel network (KaLDeX) for vascularsegmentation leveraging a Kalman filter based linear deformable cross attention(LDCA) module, integrated within a UNet++ framework. Our approach is based ontwo key components: Kalman filter (KF) based linear deformable convolution (LD)and cross-attention (CA) modules. The LD module is designed to adaptivelyadjust the focus on thin vessels that might be overlooked in standardconvolution. The CA module improves the global understanding of vascularstructures by aggregating the detailed features from the LD module with thehigh level features from the UNet++ architecture. Finally, we adopt atopological loss function based on persistent homology to constrain thetopological continuity of the segmentation. Results: The proposed method isevaluated on retinal fundus image datasets (DRIVE, CHASE_BD1, and STARE) aswell as the 3mm and 6mm of the OCTA-500 dataset, achieving an average accuracy(ACC) of 97.25%, 97.77%, 97.85%, 98.89%, and 98.21%, respectively. Conclusions:Empirical evidence shows that our method outperforms the current best models ondifferent vessel segmentation datasets. Our source code is available at:https://github.com/AIEyeSystem/KalDeX.</description><author>Zhihao Zhao, Shahrooz Faghihroohi, Yinzheng Zhao, Junjie Yang, Shipeng Zhong, Kai Huang, Nassir Navab, Boyang Li, M. Ali Nasseri</author><pubDate>Mon, 28 Oct 2024 16:00:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21160v1</guid></item><item><title>CURATe: Benchmarking Personalised Alignment of Conversational AI Assistants</title><link>http://arxiv.org/abs/2410.21159v1</link><description>We introduce a multi-turn benchmark for evaluating personalised alignment inLLM-based AI assistants, focusing on their ability to handle user-providedsafety-critical contexts. Our assessment of ten leading models across fivescenarios (each with 337 use cases) reveals systematic inconsistencies inmaintaining user-specific consideration, with even top-rated "harmless" modelsmaking recommendations that should be recognised as obviously harmful to theuser given the context provided. Key failure modes include inappropriateweighing of conflicting preferences, sycophancy (prioritising user preferencesabove safety), a lack of attentiveness to critical user information within thecontext window, and inconsistent application of user-specific knowledge. Thesame systematic biases were observed in OpenAI's o1, suggesting that strongreasoning capacities do not necessarily transfer to this kind of personalisedthinking. We find that prompting LLMs to consider safety-critical contextsignificantly improves performance, unlike a generic 'harmless and helpful'instruction. Based on these findings, we propose research directions forembedding self-reflection capabilities, online user modelling, and dynamic riskassessment in AI assistants. Our work emphasises the need for nuanced,context-aware approaches to alignment in systems designed for persistent humaninteraction, aiding the development of safe and considerate AI assistants.</description><author>Lize Alberts, Benjamin Ellis, Andrei Lupu, Jakob Foerster</author><pubDate>Mon, 28 Oct 2024 15:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21159v1</guid></item><item><title>M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation</title><link>http://arxiv.org/abs/2410.21157v1</link><description>Repository-level code completion has drawn great attention in softwareengineering, and several benchmark datasets have been introduced. However,existing repository-level code completion benchmarks usually focus on a limitednumber of languages (&lt;5), which cannot evaluate the general code intelligenceabilities across different languages for existing code Large Language Models(LLMs). Besides, the existing benchmarks usually report overall average scoresof different languages, where the fine-grained abilities in differentcompletion scenarios are ignored. Therefore, to facilitate the research of codeLLMs in multilingual scenarios, we propose a massively multilingualrepository-level code completion benchmark covering 18 programming languages(called M2RC-EVAL), and two types of fine-grained annotations (i.e.,bucket-level and semantic-level) on different completion scenarios areprovided, where we obtain these annotations based on the parsed abstract syntaxtree. Moreover, we also curate a massively multilingual instruction corporaM2RC- INSTRUCT dataset to improve the repository-level code completionabilities of existing code LLMs. Comprehensive experimental results demonstratethe effectiveness of our M2RC-EVAL and M2RC-INSTRUCT.</description><author>Jiaheng Liu, Ken Deng, Congnan Liu, Jian Yang, Shukai Liu, He Zhu, Peng Zhao, Linzheng Chai, Yanan Wu, Ke Jin, Ge Zhang, Zekun Wang, Guoan Zhang, Bangyu Xiang, Wenbo Su, Bo Zheng</author><pubDate>Mon, 28 Oct 2024 15:58:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21157v1</guid></item><item><title>SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents</title><link>http://arxiv.org/abs/2410.21155v1</link><description>Scientific information extraction (SciIE) is critical for convertingunstructured knowledge from scholarly articles into structured data (entitiesand relations). Several datasets have been proposed for training and validatingSciIE models. However, due to the high complexity and cost of annotatingscientific texts, those datasets restrict their annotations to specific partsof paper, such as abstracts, resulting in the loss of diverse entity mentionsand relations in context. In this paper, we release a new entity and relationextraction dataset for entities related to datasets, methods, and tasks inscientific articles. Our dataset contains 106 manually annotated full-textscientific publications with over 24k entities and 12k relations. To capturethe intricate use and interactions among entities in full texts, our datasetcontains a fine-grained tag set for relations. Additionally, we provide anout-of-distribution test set to offer a more realistic evaluation. We conductcomprehensive experiments, including state-of-the-art supervised models and ourproposed LLM-based baselines, and highlight the challenges presented by ourdataset, encouraging the development of innovative models to further the fieldof SciIE.</description><author>Qi Zhang, Zhijia Chen, Huitong Pan, Cornelia Caragea, Longin Jan Latecki, Eduard Dragut</author><pubDate>Mon, 28 Oct 2024 15:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21155v1</guid></item><item><title>Trajectory Flow Matching with Applications to Clinical Time Series Modeling</title><link>http://arxiv.org/abs/2410.21154v1</link><description>Modeling stochastic and irregularly sampled time series is a challengingproblem found in a wide range of applications, especially in medicine. Neuralstochastic differential equations (Neural SDEs) are an attractive modelingtechnique for this problem, which parameterize the drift and diffusion terms ofan SDE with neural networks. However, current algorithms for training NeuralSDEs require backpropagation through the SDE dynamics, greatly limiting theirscalability and stability. To address this, we propose Trajectory Flow Matching(TFM), which trains a Neural SDE in a simulation-free manner, bypassingbackpropagation through the dynamics. TFM leverages the flow matching techniquefrom generative modeling to model time series. In this work we first establishnecessary conditions for TFM to learn time series data. Next, we present areparameterization trick which improves training stability. Finally, we adaptTFM to the clinical time series setting, demonstrating improved performance onthree clinical time series datasets both in terms of absolute performance anduncertainty prediction.</description><author>Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong</author><pubDate>Mon, 28 Oct 2024 15:54:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21154v1</guid></item><item><title>IM-Context: In-Context Learning for Imbalanced Regression Tasks</title><link>http://arxiv.org/abs/2405.18202v2</link><description>Regression models often fail to generalize effectively in regionscharacterized by highly imbalanced label distributions. Previous methods fordeep imbalanced regression rely on gradient-based weight updates, which tend tooverfit in underrepresented regions. This paper proposes a paradigm shifttowards in-context learning as an effective alternative to conventionalin-weight learning methods, particularly for addressing imbalanced regression.In-context learning refers to the ability of a model to condition itself, givena prompt sequence composed of in-context samples (input-label pairs) alongsidea new query input to generate predictions, without requiring any parameterupdates. In this paper, we study the impact of the prompt sequence on the modelperformance from both theoretical and empirical perspectives. We emphasize theimportance of localized context in reducing bias within regions of highimbalance. Empirical evaluations across a variety of real-world datasetsdemonstrate that in-context learning substantially outperforms existingin-weight learning methods in scenarios with high levels of imbalance.</description><author>Ismail Nejjar, Faez Ahmed, Olga Fink</author><pubDate>Mon, 28 Oct 2024 15:53:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18202v2</guid></item><item><title>Synthetica: Large Scale Synthetic Data for Robot Perception</title><link>http://arxiv.org/abs/2410.21153v1</link><description>Vision-based object detectors are a crucial basis for robotics applicationsas they provide valuable information about object localisation in theenvironment. These need to ensure high reliability in different lightingconditions, occlusions, and visual artifacts, all while running in real-time.Collecting and annotating real-world data for these networks is prohibitivelytime consuming and costly, especially for custom assets, such as industrialobjects, making it untenable for generalization to in-the-wild scenarios. Tothis end, we present Synthetica, a method for large-scale synthetic datageneration for training robust state estimators. This paper focuses on the taskof object detection, an important problem which can serve as the front-end formost state estimation problems, such as pose estimation. Leveraging data from aphotorealistic ray-tracing renderer, we scale up data generation, generating2.7 million images, to train highly accurate real-time detection transformers.We present a collection of rendering randomization and training-time dataaugmentation techniques conducive to robust sim-to-real performance for visiontasks. We demonstrate state-of-the-art performance on the task of objectdetection while having detectors that run at 50-100Hz which is 9 times fasterthan the prior SOTA. We further demonstrate the usefulness of our trainingmethodology for robotics applications by showcasing a pipeline for use in thereal world with custom objects for which there do not exist prior datasets. Ourwork highlights the importance of scaling synthetic data generation for robustsim-to-real transfer while achieving the fastest real-time inference speeds.Videos and supplementary information can be found at this URL:https://sites.google.com/view/synthetica-vision.</description><author>Ritvik Singh, Jingzhou Liu, Karl Van Wyk, Yu-Wei Chao, Jean-Francois Lafleche, Florian Shkurti, Nathan Ratliff, Ankur Handa</author><pubDate>Mon, 28 Oct 2024 15:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21153v1</guid></item><item><title>Offline Reinforcement Learning With Combinatorial Action Spaces</title><link>http://arxiv.org/abs/2410.21151v1</link><description>Reinforcement learning problems often involve large action spaces arisingfrom the simultaneous execution of multiple sub-actions, resulting incombinatorial action spaces. Learning in combinatorial action spaces isdifficult due to the exponential growth in action space size with the number ofsub-actions and the dependencies among these sub-actions. In offline settings,this challenge is compounded by limited and suboptimal data. Current methodsfor offline learning in combinatorial spaces simplify the problem by assumingsub-action independence. We propose Branch Value Estimation (BVE), whicheffectively captures sub-action dependencies and scales to large combinatorialspaces by learning to evaluate only a small subset of actions at each timestep.Our experiments show that BVE outperforms state-of-the-art methods across arange of action space sizes.</description><author>Matthew Landers, Taylor W. Killian, Hugo Barnes, Thomas Hartvigsen, Afsaneh Doryab</author><pubDate>Mon, 28 Oct 2024 15:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21151v1</guid></item><item><title>Transforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning</title><link>http://arxiv.org/abs/2408.13399v2</link><description>The Airbnb search system grapples with many unique challenges as it continuesto evolve. We oversee a marketplace that is nuanced by geography, diversity ofhomes, and guests with a variety of preferences. Crafting an efficient searchsystem that can accommodate diverse guest needs, while showcasing relevanthomes lies at the heart of Airbnb's success. Airbnb search has many challengesthat parallel other recommendation and search systems but it has a uniqueinformation retrieval problem, upstream of ranking, called location retrieval.It requires defining a topological map area that is relevant to the searchedquery for homes listing retrieval. The purpose of this paper is to demonstratethe methodology, challenges, and impact of building a machine learning basedlocation retrieval product from the ground up. Despite the lack of suitable,prevalent machine learning based approaches, we tackle cold start,generalization, differentiation and algorithmic bias. We detail the efficacy ofheuristics, statistics, machine learning, and reinforcement learning approachesto solve these challenges, particularly for systems that are often unexploredby current literature.</description><author>Dillon Davis, Huiji Gao, Thomas Legrand, Weiwei Guo, Malay Haldar, Alex Deng, Han Zhao, Liwei He, Sanjeev Katariya</author><pubDate>Mon, 28 Oct 2024 15:48:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13399v2</guid></item><item><title>Palisade -- Prompt Injection Detection Framework</title><link>http://arxiv.org/abs/2410.21146v1</link><description>The advent of Large Language Models LLMs marks a milestone in ArtificialIntelligence, altering how machines comprehend and generate human language.However, LLMs are vulnerable to malicious prompt injection attacks, wherecrafted inputs manipulate the models behavior in unintended ways, compromisingsystem integrity and causing incorrect outcomes. Conventional detection methodsrely on static, rule-based approaches, which often fail against sophisticatedthreats like abnormal token sequences and alias substitutions, leading tolimited adaptability and higher rates of false positives and falsenegatives.This paper proposes a novel NLP based approach for prompt injectiondetection, emphasizing accuracy and optimization through a layered inputscreening process. In this framework, prompts are filtered through threedistinct layers rule-based, ML classifier, and companion LLM before reachingthe target model, thereby minimizing the risk of malicious interaction.Testsshow the ML classifier achieves the highest accuracy among individual layers,yet the multi-layer framework enhances overall detection accuracy by reducingfalse negatives. Although this increases false positives, it minimizes the riskof overlooking genuine injected prompts, thus prioritizing security.Thismulti-layered detection approach highlights LLM vulnerabilities and provides acomprehensive framework for future research, promoting secure interactionsbetween humans and AI systems.</description><author>Sahasra Kokkula, Somanathan R, Nandavardhan R, Aashishkumar, G Divya</author><pubDate>Mon, 28 Oct 2024 15:47:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21146v1</guid></item><item><title>HEALNet: Multimodal Fusion for Heterogeneous Biomedical Data</title><link>http://arxiv.org/abs/2311.09115v3</link><description>Technological advances in medical data collection, such as high-throughputgenomic sequencing and digital high-resolution histopathology, have contributedto the rising requirement for multimodal biomedical modelling, specifically forimage, tabular and graph data. Most multimodal deep learning approaches usemodality-specific architectures that are often trained separately and cannotcapture the crucial cross-modal information that motivates the integration ofdifferent data sources. This paper presents the Hybrid Early-fusion AttentionLearning Network (HEALNet): a flexible multimodal fusion architecture, which a)preserves modality-specific structural information, b) captures the cross-modalinteractions and structural information in a shared latent space, c) caneffectively handle missing modalities during training and inference, and d)enables intuitive model inspection by learning on the raw data input instead ofopaque embeddings. We conduct multimodal survival analysis on Whole SlideImages and Multi-omic data on four cancer datasets from The Cancer Genome Atlas(TCGA). HEALNet achieves state-of-the-art performance compared to otherend-to-end trained fusion models, substantially improving over unimodal andmultimodal baselines whilst being robust in scenarios with missing modalities.</description><author>Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik</author><pubDate>Mon, 28 Oct 2024 15:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09115v3</guid></item><item><title>Enhancing Learned Image Compression via Cross Window-based Attention</title><link>http://arxiv.org/abs/2410.21144v1</link><description>In recent years, learned image compression methods have demonstrated superiorrate-distortion performance compared to traditional image compression methods.Recent methods utilize convolutional neural networks (CNN), variationalautoencoders (VAE), invertible neural networks (INN), and transformers. Despitetheir significant contributions, a main drawback of these models is their poorperformance in capturing local redundancy. Therefore, to leverage globalfeatures along with local redundancy, we propose a CNN-based solutionintegrated with a feature encoding module. The feature encoding module encodesimportant features before feeding them to the CNN and then utilizes cross-scalewindow-based attention, which further captures local redundancy. Cross-scalewindow-based attention is inspired by the attention mechanism in transformersand effectively enlarges the receptive field. Both the feature encoding moduleand the cross-scale window-based attention module in our architecture areflexible and can be incorporated into any other network architecture. Weevaluate our method on the Kodak and CLIC datasets and demonstrate that ourapproach is effective and on par with state-of-the-art methods.</description><author>Priyanka Mudgal, Feng Liu</author><pubDate>Mon, 28 Oct 2024 15:44:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21144v1</guid></item><item><title>LLM-initialized Differentiable Causal Discovery</title><link>http://arxiv.org/abs/2410.21141v1</link><description>The discovery of causal relationships between random variables is animportant yet challenging problem that has applications across many scientificdomains. Differentiable causal discovery (DCD) methods are effective inuncovering causal relationships from observational data; however, theseapproaches often suffer from limited interpretability and face challenges inincorporating domain-specific prior knowledge. In contrast, Large LanguageModels (LLMs)-based causal discovery approaches have recently been showncapable of providing useful priors for causal discovery but struggle withformal causal reasoning. In this paper, we propose LLM-DCD, which uses an LLMto initialize the optimization of the maximum likelihood objective function ofDCD approaches, thereby incorporating strong priors into the discovery method.To achieve this initialization, we design our objective function to depend onan explicitly defined adjacency matrix of the causal graph as its onlyvariational parameter. Directly optimizing the explicitly defined adjacencymatrix provides a more interpretable approach to causal discovery.Additionally, we demonstrate higher accuracy on key benchmarking datasets ofour approach compared to state-of-the-art alternatives, and provide empiricalevidence that the quality of the initialization directly impacts the quality ofthe final output of our DCD approach. LLM-DCD opens up new opportunities fortraditional causal discovery methods like DCD to benefit from futureimprovements in the causal reasoning capabilities of LLMs.</description><author>Shiv Kampani, David Hidary, Constantijn van der Poel, Martin Ganahl, Brenda Miao</author><pubDate>Mon, 28 Oct 2024 15:43:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21141v1</guid></item><item><title>uOttawa at LegalLens-2024: Transformer-based Classification Experiments</title><link>http://arxiv.org/abs/2410.21139v1</link><description>This paper presents the methods used for LegalLens-2024 shared task, whichfocused on detecting legal violations within unstructured textual data andassociating these violations with potentially affected individuals. The sharedtask included two subtasks: A) Legal Named Entity Recognition (L-NER) and B)Legal Natural Language Inference (L-NLI). For subtask A, we utilized the spaCylibrary, while for subtask B, we employed a combined model incorporatingRoBERTa and CNN. Our results were 86.3% in the L-NER subtask and 88.25% in theL-NLI subtask. Overall, our paper demonstrates the effectiveness of transformermodels in addressing complex tasks in the legal domain. The source code for ourimplementation is publicly available athttps://github.com/NimaMeghdadi/uOttawa-at-LegalLens-2024-Transformer-based-Classification</description><author>Nima Meghdadi, Diana Inkpen</author><pubDate>Mon, 28 Oct 2024 15:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21139v1</guid></item><item><title>Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image</title><link>http://arxiv.org/abs/2405.20343v3</link><description>In this work, we introduce Unique3D, a novel image-to-3D framework forefficiently generating high-quality 3D meshes from single-view images,featuring state-of-the-art generation fidelity and strong generalizability.Previous methods based on Score Distillation Sampling (SDS) can producediversified 3D results by distilling 3D knowledge from large 2D diffusionmodels, but they usually suffer from long per-case optimization time withinconsistent issues. Recent works address the problem and generate better 3Dresults either by finetuning a multi-view diffusion model or training a fastfeed-forward model. However, they still lack intricate textures and complexgeometries due to inconsistency and limited generated resolution. Tosimultaneously achieve high fidelity, consistency, and efficiency in singleimage-to-3D, we propose a novel framework Unique3D that includes a multi-viewdiffusion model with a corresponding normal diffusion model to generatemulti-view images with their normal maps, a multi-level upscale process toprogressively improve the resolution of generated orthographic multi-views, aswell as an instant and consistent mesh reconstruction algorithm called ISOMER,which fully integrates the color and geometric priors into mesh results.Extensive experiments demonstrate that our Unique3D significantly outperformsother image-to-3D baselines in terms of geometric and textural details.</description><author>Kailu Wu, Fangfu Liu, Zhihan Cai, Runjie Yan, Hanyang Wang, Yating Hu, Yueqi Duan, Kaisheng Ma</author><pubDate>Mon, 28 Oct 2024 15:41:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20343v3</guid></item><item><title>Amalgam: A Framework for Obfuscated Neural Network Training on the Cloud</title><link>http://arxiv.org/abs/2406.03405v2</link><description>Training a proprietary Neural Network (NN) model with a proprietary dataseton the cloud comes at the risk of exposing the model architecture and thedataset to the cloud service provider. To tackle this problem, in this paper,we present an NN obfuscation framework, called Amalgam, to train NN models in aprivacy-preserving manner in existing cloud-based environments. Amalgamachieves that by augmenting NN models and the datasets to be used for trainingwith well-calibrated noise to "hide" both the original model architectures andtraining datasets from the cloud. After training, Amalgam extracts the originalmodels from the augmented models and returns them to users. Our evaluationresults with different computer vision and natural language processing modelsand datasets demonstrate that Amalgam: (i) introduces modest overheads into thetraining process without impacting its correctness, and (ii) does not affectthe model's accuracy. The prototype implementation is available at:https://github.com/SifatTaj/amalgam</description><author>Sifat Ut Taki, Spyridon Mastorakis</author><pubDate>Mon, 28 Oct 2024 15:39:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03405v2</guid></item><item><title>IncomeSCM: From tabular data set to time-series simulator and causal estimation benchmark</title><link>http://arxiv.org/abs/2405.16069v3</link><description>Evaluating observational estimators of causal effects demands informationthat is rarely available: unconfounded interventions and outcomes from thepopulation of interest, created either by randomization or adjustment. As aresult, it is customary to fall back on simulators when creating benchmarktasks. Simulators offer great control but are often too simplistic to makechallenging tasks, either because they are hand-designed and lack the nuancesof real-world data, or because they are fit to observational data withoutstructural constraints. In this work, we propose a general, repeatable strategyfor turning observational data into sequential structural causal models andchallenging estimation tasks by following two simple principles: 1) fittingreal-world data where possible, and 2) creating complexity by composing simple,hand-designed mechanisms. We implement these ideas in a highly configurablesoftware package and apply it to the well-known Adult income data set toconstruct the IncomeSCM simulator. From this, we devise multiple estimationtasks and sample data sets to compare established estimators of causal effects.The tasks present a suitable challenge, with effect estimates varying greatlyin quality between methods, despite similar performance in the modeling offactual outcomes, highlighting the need for dedicated causal estimators andmodel selection criteria.</description><author>Fredrik D. Johansson</author><pubDate>Mon, 28 Oct 2024 15:39:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16069v3</guid></item><item><title>DisEnvisioner: Disentangled and Enriched Visual Prompt for Customized Image Generation</title><link>http://arxiv.org/abs/2410.02067v2</link><description>In the realm of image generation, creating customized images from visualprompt with additional textual instruction emerges as a promising endeavor.However, existing methods, both tuning-based and tuning-free, struggle withinterpreting the subject-essential attributes from the visual prompt. Thisleads to subject-irrelevant attributes infiltrating the generation process,ultimately compromising the personalization quality in both editability and IDpreservation. In this paper, we present DisEnvisioner, a novel approach foreffectively extracting and enriching the subject-essential features whilefiltering out -irrelevant information, enabling exceptional customizationperformance, in a tuning-free manner and using only a single image.Specifically, the feature of the subject and other irrelevant components areeffectively separated into distinctive visual tokens, enabling a much moreaccurate customization. Aiming to further improving the ID consistency, weenrich the disentangled features, sculpting them into more granularrepresentations. Experiments demonstrate the superiority of our approach overexisting methods in instruction response (editability), ID consistency,inference speed, and the overall image quality, highlighting the effectivenessand efficiency of DisEnvisioner. Project page:https://disenvisioner.github.io/.</description><author>Jing He, Haodong Li, Yongzhe Hu, Guibao Shen, Yingjie Cai, Weichao Qiu, Ying-Cong Chen</author><pubDate>Mon, 28 Oct 2024 15:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02067v2</guid></item><item><title>Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments</title><link>http://arxiv.org/abs/2410.21131v1</link><description>As machine learning models evolve, maintaining transparency demands morehuman-centric explainable AI techniques. Counterfactual explanations, withroots in human reasoning, identify the minimal input changes needed to obtain agiven output and, hence, are crucial for supporting decision-making. Despitetheir importance, the evaluation of these explanations often lacks grounding inuser studies and remains fragmented, with existing metrics not fully capturinghuman perspectives. To address this challenge, we developed a diverse set of 30counterfactual scenarios and collected ratings across 8 evaluation metrics from206 respondents. Subsequently, we fine-tuned different Large Language Models(LLMs) to predict average or individual human judgment across these metrics.Our methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shotevaluations and 85% (over a 3-classes prediction) with fine-tuning across allmetrics. The fine-tuned models predicting human ratings offer bettercomparability and scalability in evaluating different counterfactualexplanation frameworks.</description><author>Marharyta Domnich, Julius Valja, Rasmus Moorits Veski, Giacomo Magnifico, Kadi Tulver, Eduard Barbu, Raul Vicente</author><pubDate>Mon, 28 Oct 2024 15:33:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21131v1</guid></item><item><title>Extrapolating Prospective Glaucoma Fundus Images through Diffusion Model in Irregular Longitudinal Sequences</title><link>http://arxiv.org/abs/2410.21130v1</link><description>The utilization of longitudinal datasets for glaucoma progression predictionoffers a compelling approach to support early therapeutic interventions.Predominant methodologies in this domain have primarily focused on the directprediction of glaucoma stage labels from longitudinal datasets. However, suchmethods may not adequately encapsulate the nuanced developmental trajectory ofthe disease. To enhance the diagnostic acumen of medical practitioners, wepropose a novel diffusion-based model to predict prospective images byextrapolating from existing longitudinal fundus images of patients. Themethodology delineated in this study distinctively leverages sequences ofimages as inputs. Subsequently, a time-aligned mask is employed to select aspecific year for image generation. During the training phase, the time-alignedmask resolves the issue of irregular temporal intervals in longitudinal imagesequence sampling. Additionally, we utilize a strategy of randomly masking aframe in the sequence to establish the ground truth. This methodology aids thenetwork in continuously acquiring knowledge regarding the internalrelationships among the sequences throughout the learning phase. Moreover, theintroduction of textual labels is instrumental in categorizing images generatedwithin the sequence. The empirical findings from the conducted experimentsindicate that our proposed model not only effectively generates longitudinaldata but also significantly improves the precision of downstream classificationtasks.</description><author>Zhihao Zhao, Junjie Yang, Shahrooz Faghihroohi, Yinzheng Zhao, Daniel Zapp, Kai Huang, Nassir Navab, M. Ali Nasseri</author><pubDate>Mon, 28 Oct 2024 15:31:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21130v1</guid></item><item><title>Generalization capabilities and robustness of hybrid machine learning models grounded in flow physics compared to purely deep learning models</title><link>http://arxiv.org/abs/2404.17884v2</link><description>This study investigates the generalization capabilities and robustness ofpurely deep learning (DL) models and hybrid models based on physical principlesin fluid dynamics applications, specifically focusing on iterativelyforecasting the temporal evolution of flow dynamics. Three autoregressivemodels were compared: a convolutional autoencoder combined with a convolutionalLSTM (ConvLSTM), a variational autoencoder (VAE) combined with a ConvLSTM and ahybrid model that combines proper orthogonal decomposition (POD) with a LSTM(POD-DL). These models were tested on two high-dimensional, nonlinear datasetsrepresenting the velocity field of flow past a circular cylinder in bothlaminar and turbulent regimes. The study used latent dimension methods,enabling a bijective reduction of high-dimensional dynamics into a lower-orderspace to facilitate future predictions. While the VAE and ConvLSTM modelsaccurately predicted laminar flow, the hybrid POD-DL model outperformed theothers across both laminar and turbulent flow regimes. This success isattributed to the model's ability to incorporate modal decomposition, reducingthe dimensionality of the data, by a non-parametric method, and simplifying theforecasting component. By leveraging POD, the model not only gained insightinto the underlying physics, improving prediction accuracy with less trainingdata, but also reduce the number of trainable parameters as POD isnon-parametric. The findings emphasize the potential of hybrid models,particularly those integrating modal decomposition and deep learning, inpredicting complex flow dynamics.</description><author>Rodrigo AbadÃ­a-Heredia, AdriÃ¡n Corrochano, Manuel Lopez-Martin, Soledad Le Clainche</author><pubDate>Mon, 28 Oct 2024 15:31:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17884v2</guid></item><item><title>Fast Calibrated Explanations: Efficient and Uncertainty-Aware Explanations for Machine Learning Models</title><link>http://arxiv.org/abs/2410.21129v1</link><description>This paper introduces Fast Calibrated Explanations, a method designed forgenerating rapid, uncertainty-aware explanations for machine learning models.By incorporating perturbation techniques from ConformaSight - a globalexplanation framework - into the core elements of Calibrated Explanations (CE),we achieve significant speedups. These core elements include local featureimportance with calibrated predictions, both of which retain uncertaintyquantification. While the new method sacrifices a small degree of detail, itexcels in computational efficiency, making it ideal for high-stakes, real-timeapplications. Fast Calibrated Explanations are applicable to probabilisticexplanations in classification and thresholded regression tasks, where theyprovide the likelihood of a target being above or below a user-definedthreshold. This approach maintains the versatility of CE for bothclassification and probabilistic regression, making it suitable for a range ofpredictive tasks where uncertainty quantification is crucial.</description><author>Tuwe LÃ¶fstrÃ¶m, Fatima Rabia Yapicioglu, Alessandra Stramiglio, Helena LÃ¶fstrÃ¶m, Fabio Vitali</author><pubDate>Mon, 28 Oct 2024 15:29:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21129v1</guid></item><item><title>Retrieval-Enhanced Mutation Mastery: Augmenting Zero-Shot Prediction of Protein Language Model</title><link>http://arxiv.org/abs/2410.21127v1</link><description>Enzyme engineering enables the modification of wild-type proteins to meetindustrial and research demands by enhancing catalytic activity, stability,binding affinities, and other properties. The emergence of deep learningmethods for protein modeling has demonstrated superior results at lower costscompared to traditional approaches such as directed evolution and rationaldesign. In mutation effect prediction, the key to pre-training deep learningmodels lies in accurately interpreting the complex relationships among proteinsequence, structure, and function. This study introduces a retrieval-enhancedprotein language model for comprehensive analysis of native properties fromsequence and local structural interactions, as well as evolutionary propertiesfrom retrieved homologous sequences. The state-of-the-art performance of theproposed ProtREM is validated on over 2 million mutants across 217 assays froman open benchmark (ProteinGym). We also conducted post-hoc analyses of themodel's ability to improve the stability and binding affinity of a VHHantibody. Additionally, we designed 10 new mutants on a DNA polymerase andconducted wet-lab experiments to evaluate their enhanced activity at highertemperatures. Both in silico and experimental evaluations confirmed that ourmethod provides reliable predictions of mutation effects, offering an auxiliarytool for biologists aiming to evolve existing enzymes. The implementation ispublicly available at https://github.com/tyang816/ProtREM.</description><author>Yang Tan, Ruilin Wang, Banghao Wu, Liang Hong, Bingxin Zhou</author><pubDate>Mon, 28 Oct 2024 15:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21127v1</guid></item><item><title>Current State-of-the-Art of Bias Detection and Mitigation in Machine Translation for African and European Languages: a Review</title><link>http://arxiv.org/abs/2410.21126v1</link><description>Studying bias detection and mitigation methods in natural language processingand the particular case of machine translation is highly relevant, as societalstereotypes might be reflected or reinforced by these systems. In this paper,we analyze the state-of-the-art with a particular focus on European and Africanlanguages. We show how the majority of the work in this field concentrates onfew languages, and that there is potential for future research to cover alsothe less investigated languages to contribute to more diversity in the researchfield.</description><author>Catherine Ikae, Mascha Kurpicz-Briki</author><pubDate>Mon, 28 Oct 2024 15:28:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21126v1</guid></item><item><title>RIO-CPD: A Riemannian Geometric Method for Correlation-aware Online Change Point Detection</title><link>http://arxiv.org/abs/2407.09698v2</link><description>Change point detection aims to identify abrupt shifts occurring at multiplepoints within a data sequence. This task becomes particularly challenging inthe online setting, where different types of changes can occur, includingshifts in both the marginal and joint distributions of the data. In this paper,we address these challenges by tracking the Riemannian geometry of correlationmatrices, allowing Riemannian metrics to compute the geodesic distance as anaccurate measure of correlation dynamics. We introduce Rio-CPD, anon-parametric, correlation-aware online change point detection framework thatintegrates the Riemannian geometry of the manifold of symmetric positivedefinite matrices with the cumulative sum (CUSUM) statistic for detectingchange points. Rio-CPD employs a novel CUSUM design by computing the geodesicdistance between current observations and the Fr\'echet mean of priorobservations. With appropriate choices of Riemannian metrics, Rio-CPD offers asimple yet effective and computationally efficient algorithm. Experimentalresults on both synthetic and real-world datasets demonstrate that Rio-CPDoutperforms existing methods on detection accuracy, average detection delay andefficiency.</description><author>Chengyuan Deng, Zhengzhang Chen, Xujiang Zhao, Haoyu Wang, Junxiang Wang, Haifeng Chen, Jie Gao</author><pubDate>Mon, 28 Oct 2024 15:27:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09698v2</guid></item><item><title>PyGim: An Efficient Graph Neural Network Library for Real Processing-In-Memory Architectures</title><link>http://arxiv.org/abs/2402.16731v5</link><description>Graph Neural Networks (GNNs) are emerging ML models to analyzegraph-structure data. Graph Neural Network (GNN) execution involves bothcompute-intensive and memory-intensive kernels, the latter dominates the totaltime, being significantly bottlenecked by data movement between memory andprocessors. Processing-In-Memory (PIM) systems can alleviate this data movementbottleneck by placing simple processors near or inside to memory arrays. Inthis work, we introduce PyGim, an efficient ML library that accelerates GNNs onreal PIM systems. We propose intelligent parallelization techniques formemory-intensive kernels of GNNs tailored for real PIM systems, and develophandy Python API for them. We provide hybrid GNN execution, in which thecompute-intensive and memory-intensive kernels are executed inprocessor-centric and memory-centric computing systems, respectively. Weextensively evaluate PyGim on a real-world PIM system with 1992 PIM cores usingemerging GNN models, and demonstrate that it outperforms its state-of-the-artCPU counterpart on Intel Xeon by on average 3.04x, and achieves higher resourceutilization than CPU and GPU systems. Our work provides useful recommendationsfor software, system and hardware designers. PyGim is publicly available athttps://github.com/CMU-SAFARI/PyGim.</description><author>Christina Giannoula, Peiming Yang, Ivan Fernandez Vega, Jiacheng Yang, Sankeerth Durvasula, Yu Xin Li, Mohammad Sadrosadati, Juan Gomez Luna, Onur Mutlu, Gennady Pekhimenko</author><pubDate>Mon, 28 Oct 2024 15:25:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16731v5</guid></item><item><title>FusedInf: Efficient Swapping of DNN Models for On-Demand Serverless Inference Services on the Edge</title><link>http://arxiv.org/abs/2410.21120v1</link><description>Edge AI computing boxes are a new class of computing devices that are aimedto revolutionize the AI industry. These compact and robust hardware units bringthe power of AI processing directly to the source of data--on the edge of thenetwork. On the other hand, on-demand serverless inference services arebecoming more and more popular as they minimize the infrastructural costassociated with hosting and running DNN models for small to medium-sizedbusinesses. However, these computing devices are still constrained in terms ofresource availability. As such, the service providers need to load and unloadmodels efficiently in order to meet the growing demand. In this paper, weintroduce FusedInf to efficiently swap DNN models for on-demand serverlessinference services on the edge. FusedInf combines multiple models into a singleDirect Acyclic Graph (DAG) to efficiently load the models into the GPU memoryand make execution faster. Our evaluation of popular DNN models showed thatcreating a single DAG can make the execution of the models up to 14\% fasterwhile reducing the memory requirement by up to 17\%. The prototypeimplementation is available at https://github.com/SifatTaj/FusedInf.</description><author>Sifat Ut Taki, Arthi Padmanabhan, Spyridon Mastorakis</author><pubDate>Mon, 28 Oct 2024 15:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21120v1</guid></item><item><title>A Unified Solution to Diverse Heterogeneities in One-shot Federated Learning</title><link>http://arxiv.org/abs/2410.21119v1</link><description>One-shot federated learning (FL) limits the communication between the serverand clients to a single round, which largely decreases the privacy leakagerisks in traditional FLs requiring multiple communications. However, we findexisting one-shot FL frameworks are vulnerable to distributional heterogeneitydue to their insufficient focus on data heterogeneity while concentratingpredominantly on model heterogeneity. Filling this gap, we propose a unified,data-free, one-shot federated learning framework (FedHydra) that caneffectively address both model and data heterogeneity. Rather than applyingexisting value-only learning mechanisms, a structure-value learning mechanismis proposed in FedHydra. Specifically, a new stratified learning structure isproposed to cover data heterogeneity, and the value of each item duringcomputation reflects model heterogeneity. By this design, the data and modelheterogeneity issues are simultaneously monitored from different aspects duringlearning. Consequently, FedHydra can effectively mitigate both issues byminimizing their inherent conflicts. We compared FedHydra with three SOTAbaselines on four benchmark datasets. Experimental results show that our methodoutperforms the previous one-shot FL methods in both homogeneous andheterogeneous settings.</description><author>Jun Bai, Yiliao Song, Di Wu, Atul Sajjanhar, Yong Xiang, Wei Zhou, Xiaohui Tao, Yan Li</author><pubDate>Mon, 28 Oct 2024 15:20:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21119v1</guid></item><item><title>Robustness and Generalization in Quantum Reinforcement Learning via Lipschitz Regularization</title><link>http://arxiv.org/abs/2410.21117v1</link><description>Quantum machine learning leverages quantum computing to enhance accuracy andreduce model complexity compared to classical approaches, promising significantadvancements in various fields. Within this domain, quantum reinforcementlearning has garnered attention, often realized using variational quantumcircuits to approximate the policy function. This paper addresses therobustness and generalization of quantum reinforcement learning by combiningprinciples from quantum computing and control theory. Leveraging recent resultson robust quantum machine learning, we utilize Lipschitz bounds to propose aregularized version of a quantum policy gradient approach, named the RegQPGalgorithm. We show that training with RegQPG improves the robustness andgeneralization of the resulting policies. Furthermore, we introduce analgorithmic variant that incorporates curriculum learning, which minimizesfailures during training. Our findings are validated through numericalexperiments, demonstrating the practical benefits of our approach.</description><author>Nico Meyer, Julian Berberich, Christopher Mutschler, Daniel D. Scherer</author><pubDate>Mon, 28 Oct 2024 15:20:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21117v1</guid></item><item><title>Zero-Shot Action Recognition in Surveillance Videos</title><link>http://arxiv.org/abs/2410.21113v1</link><description>The growing demand for surveillance in public spaces presents significantchallenges due to the shortage of human resources. Current AI-based videosurveillance systems heavily rely on core computer vision models that requireextensive finetuning, which is particularly difficult in surveillance settingsdue to limited datasets and difficult setting (viewpoint, low quality, etc.).In this work, we propose leveraging Large Vision-Language Models (LVLMs), knownfor their strong zero and few-shot generalization, to tackle videounderstanding tasks in surveillance. Specifically, we explore VideoLLaMA2, astate-of-the-art LVLM, and an improved token-level sampling method,Self-Reflective Sampling (Self-ReS). Our experiments on the UCF-Crime datasetshow that VideoLLaMA2 represents a significant leap in zero-shot performance,with 20% boost over the baseline. Self-ReS additionally increases zero-shotaction recognition performance to 44.6%. These results highlight the potentialof LVLMs, paired with improved sampling techniques, for advancing surveillancevideo analysis in diverse scenarios.</description><author>Joao Pereira, Vasco Lopes, David Semedo, Joao Neves</author><pubDate>Mon, 28 Oct 2024 15:13:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21113v1</guid></item><item><title>Matrix Denoising with Doubly Heteroscedastic Noise: Fundamental Limits and Optimal Spectral Methods</title><link>http://arxiv.org/abs/2405.13912v2</link><description>We study the matrix denoising problem of estimating the singular vectors of arank-$1$ signal corrupted by noise with both column and row correlations.Existing works are either unable to pinpoint the exact asymptotic estimationerror or, when they do so, the resulting approaches (e.g., based on whiteningor singular value shrinkage) remain vastly suboptimal. On top of this, most ofthe literature has focused on the special case of estimating the left singularvector of the signal when the noise only possesses row correlation (one-sidedheteroscedasticity). In contrast, our work establishes theinformation-theoretic and algorithmic limits of matrix denoising with doublyheteroscedastic noise. We characterize the exact asymptotic minimum mean squareerror, and design a novel spectral estimator with rigorous optimalityguarantees: under a technical condition, it attains positive correlation withthe signals whenever information-theoretically possible and, for one-sidedheteroscedasticity, it also achieves the Bayes-optimal error. Numericalexperiments demonstrate the significant advantage of our theoreticallyprincipled method with the state of the art. The proofs draw connections withstatistical physics and approximate message passing, departing drastically fromstandard random matrix theory techniques.</description><author>Yihan Zhang, Marco Mondelli</author><pubDate>Mon, 28 Oct 2024 15:13:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13912v2</guid></item><item><title>LAMA: Stable Dual-Domain Deep Reconstruction For Sparse-View CT</title><link>http://arxiv.org/abs/2410.21111v1</link><description>Inverse problems arise in many applications, especially tomographic imaging.We develop a Learned Alternating Minimization Algorithm (LAMA) to solve suchproblems via two-block optimization by synergizing data-driven and classicaltechniques with proven convergence. LAMA is naturally induced by a variationalmodel with learnable regularizers in both data and image domains, parameterizedas composite functions of neural networks trained with domain-specific data. Weallow these regularizers to be nonconvex and nonsmooth to extract features fromdata effectively. We minimize the overall objective function using Nesterov'ssmoothing technique and residual learning architecture. It is demonstrated thatLAMA reduces network complexity, improves memory efficiency, and enhancesreconstruction accuracy, stability, and interpretability. Extensive experimentsshow that LAMA significantly outperforms state-of-the-art methods on popularbenchmark datasets for Computed Tomography.</description><author>Chi Ding, Qingchao Zhang, Ge Wang, Xiaojing Ye, Yunmei Chen</author><pubDate>Mon, 28 Oct 2024 15:13:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21111v1</guid></item><item><title>Dual-Agent Deep Reinforcement Learning for Dynamic Pricing and Replenishment</title><link>http://arxiv.org/abs/2410.21109v1</link><description>We study the dynamic pricing and replenishment problems under inconsistentdecision frequencies. Different from the traditional demand assumption, thediscreteness of demand and the parameter within the Poisson distribution as afunction of price introduce complexity into analyzing the problem property. Wedemonstrate the concavity of the single-period profit function with respect toproduct price and inventory within their respective domains. The demand modelis enhanced by integrating a decision tree-based machine learning approach,trained on comprehensive market data. Employing a two-timescale stochasticapproximation scheme, we address the discrepancies in decision frequenciesbetween pricing and replenishment, ensuring convergence to local optimum. Wefurther refine our methodology by incorporating deep reinforcement learning(DRL) techniques and propose a fast-slow dual-agent DRL algorithm. In thisapproach, two agents handle pricing and inventory and are updated on differentscales. Numerical results from both single and multiple products scenariosvalidate the effectiveness of our methods.</description><author>Yi Zheng, Zehao Li, Peng Jiang, Yijie Peng</author><pubDate>Mon, 28 Oct 2024 15:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21109v1</guid></item><item><title>LiGAR: LiDAR-Guided Hierarchical Transformer for Multi-Modal Group Activity Recognition</title><link>http://arxiv.org/abs/2410.21108v1</link><description>Group Activity Recognition (GAR) remains challenging in computer vision dueto the complex nature of multi-agent interactions. This paper introduces LiGAR,a LIDAR-Guided Hierarchical Transformer for Multi-Modal Group ActivityRecognition. LiGAR leverages LiDAR data as a structural backbone to guide theprocessing of visual and textual information, enabling robust handling ofocclusions and complex spatial arrangements. Our framework incorporates aMulti-Scale LIDAR Transformer, Cross-Modal Guided Attention, and an AdaptiveFusion Module to integrate multi-modal data at different semantic levelseffectively. LiGAR's hierarchical architecture captures group activities atvarious granularities, from individual actions to scene-level dynamics.Extensive experiments on the JRDB-PAR, Volleyball, and NBA datasets demonstrateLiGAR's superior performance, achieving state-of-the-art results withimprovements of up to 10.6% in F1-score on JRDB-PAR and 5.9% in Mean Per ClassAccuracy on the NBA dataset. Notably, LiGAR maintains high performance evenwhen LiDAR data is unavailable during inference, showcasing its adaptability.Our ablation studies highlight the significant contributions of each componentand the effectiveness of our multi-modal, multi-scale approach in advancing thefield of group activity recognition.</description><author>Naga Venkata Sai Raviteja Chappa, Khoa Luu</author><pubDate>Mon, 28 Oct 2024 15:11:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21108v1</guid></item></channel></rss>