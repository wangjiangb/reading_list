<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 27 Jun 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Situational Awareness Matters in 3D Vision Language Reasoning</title><link>http://arxiv.org/abs/2406.07544v2</link><description>Being able to carry out complicated vision language reasoning tasks in 3Dspace represents a significant milestone in developing household robots andhuman-centered embodied AI. In this work, we demonstrate that a critical anddistinct challenge in 3D vision language reasoning is situational awareness,which incorporates two key components: (1) The autonomous agent grounds itsself-location based on a language prompt. (2) The agent answers open-endedquestions from the perspective of its calculated position. To address thischallenge, we introduce SIG3D, an end-to-end Situation-Grounded model for 3Dvision language reasoning. We tokenize the 3D scene into sparse voxelrepresentation and propose a language-grounded situation estimator, followed bya situated question answering module. Experiments on the SQA3D and ScanQAdatasets show that SIG3D outperforms state-of-the-art models in situationestimation and question answering by a large margin (e.g., an enhancement ofover 30% on situation estimation accuracy). Subsequent analysis corroboratesour architectural design choices, explores the distinct functions of visual andtextual tokens, and highlights the importance of situational awareness in thedomain of 3D question answering.</description><author>Yunze Man, Liang-Yan Gui, Yu-Xiong Wang</author><pubDate>Wed, 26 Jun 2024 18:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07544v2</guid></item><item><title>On Convex Data-Driven Inverse Optimal Control for Nonlinear, Non-stationary and Stochastic Systems</title><link>http://arxiv.org/abs/2306.13928v2</link><description>This paper is concerned with a finite-horizon inverse control problem, whichhas the goal of reconstructing, from observations, the possibly non-convex andnon-stationary cost driving the actions of an agent. In this context, wepresent a result enabling cost reconstruction by solving an optimizationproblem that is convex even when the agent cost is not and when the underlyingdynamics is nonlinear, non-stationary and stochastic. To obtain this result, wealso study a finite-horizon forward control problem that has randomizedpolicies as decision variables. We turn our findings into algorithmicprocedures and show the effectiveness of our approach via in-silico andhardware validations. All experiments confirm the effectiveness of ourapproach.</description><author>Emiland Garrabe, Hozefa Jesawada, Carmen Del Vecchio, Giovanni Russo</author><pubDate>Wed, 26 Jun 2024 18:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13928v2</guid></item><item><title>Towards Compositionality in Concept Learning</title><link>http://arxiv.org/abs/2406.18534v1</link><description>Concept-based interpretability methods offer a lens into the internals offoundation models by decomposing their embeddings into high-level concepts.These concept representations are most useful when they are compositional,meaning that the individual concepts compose to explain the full sample. Weshow that existing unsupervised concept extraction methods find concepts whichare not compositional. To automatically discover compositional conceptrepresentations, we identify two salient properties of such representations,and propose Compositional Concept Extraction (CCE) for finding concepts whichobey these properties. We evaluate CCE on five different datasets over imageand text data. Our evaluation shows that CCE finds more compositional conceptrepresentations than baselines and yields better accuracy on four downstreamclassification tasks. Code and data are available athttps://github.com/adaminsky/compositional_concepts .</description><author>Adam Stein, Aaditya Naik, Yinjun Wu, Mayur Naik, Eric Wong</author><pubDate>Wed, 26 Jun 2024 18:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18534v1</guid></item><item><title>On Scaling Up 3D Gaussian Splatting Training</title><link>http://arxiv.org/abs/2406.18533v1</link><description>3D Gaussian Splatting (3DGS) is increasingly popular for 3D reconstructiondue to its superior visual quality and rendering speed. However, 3DGS trainingcurrently occurs on a single GPU, limiting its ability to handlehigh-resolution and large-scale 3D reconstruction tasks due to memoryconstraints. We introduce Grendel, a distributed system designed to partition3DGS parameters and parallelize computation across multiple GPUs. As eachGaussian affects a small, dynamic subset of rendered pixels, Grendel employssparse all-to-all communication to transfer the necessary Gaussians to pixelpartitions and performs dynamic load balancing. Unlike existing 3DGS systemsthat train using one camera view image at a time, Grendel supports batchedtraining with multiple views. We explore various optimization hyperparameterscaling strategies and find that a simple sqrt(batch size) scaling rule ishighly effective. Evaluations using large-scale, high-resolution scenes showthat Grendel enhances rendering quality by scaling up 3DGS parameters acrossmultiple GPUs. On the Rubble dataset, we achieve a test PSNR of 27.28 bydistributing 40.4 million Gaussians across 16 GPUs, compared to a PSNR of 26.28using 11.2 million Gaussians on a single GPU. Grendel is an open-source projectavailable at: https://github.com/nyu-systems/Grendel-GS</description><author>Hexu Zhao, Haoyang Weng, Daohan Lu, Ang Li, Jinyang Li, Aurojit Panda, Saining Xie</author><pubDate>Wed, 26 Jun 2024 18:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18533v1</guid></item><item><title>Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps</title><link>http://arxiv.org/abs/2406.14539v2</link><description>Diffusion distillation represents a highly promising direction for achievingfaithful text-to-image generation in a few sampling steps. However, despiterecent successes, existing distilled models still do not provide the fullspectrum of diffusion abilities, such as real image inversion, which enablesmany precise image manipulation methods. This work aims to enrich distilledtext-to-image diffusion models with the ability to effectively encode realimages into their latent space. To this end, we introduce invertibleConsistency Distillation (iCD), a generalized consistency distillationframework that facilitates both high-quality image synthesis and accurate imageencoding in only 3-4 inference steps. Though the inversion problem fortext-to-image diffusion models gets exacerbated by high classifier-freeguidance scales, we notice that dynamic guidance significantly reducesreconstruction errors without noticeable degradation in generation performance.As a result, we demonstrate that iCD equipped with dynamic guidance may serveas a highly effective tool for zero-shot text-guided image editing, competingwith more expensive state-of-the-art alternatives.</description><author>Nikita Starodubcev, Mikhail Khoroshikh, Artem Babenko, Dmitry Baranchuk</author><pubDate>Wed, 26 Jun 2024 18:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14539v2</guid></item><item><title>Symbolic Learning Enables Self-Evolving Agents</title><link>http://arxiv.org/abs/2406.18532v1</link><description>The AI community has been exploring a pathway to artificial generalintelligence (AGI) by developing "language agents", which are complex largelanguage models (LLMs) pipelines involving both prompting techniques and toolusage methods. While language agents have demonstrated impressive capabilitiesfor many real-world tasks, a fundamental limitation of current language agentsresearch is that they are model-centric, or engineering-centric. That's to say,the progress on prompts, tools, and pipelines of language agents requiressubstantial manual engineering efforts from human experts rather thanautomatically learning from data. We believe the transition from model-centric,or engineering-centric, to data-centric, i.e., the ability of language agentsto autonomously learn and evolve in environments, is the key for them topossibly achieve AGI. In this work, we introduce agent symbolic learning, a systematic frameworkthat enables language agents to optimize themselves on their own in adata-centric way using symbolic optimizers. Specifically, we consider agents assymbolic networks where learnable weights are defined by prompts, tools, andthe way they are stacked together. Agent symbolic learning is designed tooptimize the symbolic network within language agents by mimicking twofundamental algorithms in connectionist learning: back-propagation and gradientdescent. Instead of dealing with numeric weights, agent symbolic learning workswith natural language simulacrums of weights, loss, and gradients. We conductproof-of-concept experiments on both standard benchmarks and complex real-worldtasks and show that agent symbolic learning enables language agents to updatethemselves after being created and deployed in the wild, resulting in"self-evolving agents".</description><author>Wangchunshu Zhou, Yixin Ou, Shengwei Ding, Long Li, Jialong Wu, Tiannan Wang, Jiamin Chen, Shuai Wang, Xiaohua Xu, Ningyu Zhang, Huajun Chen, Yuchen Eleanor Jiang</author><pubDate>Wed, 26 Jun 2024 18:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18532v1</guid></item><item><title>On the Impact of Voice Anonymization on Speech Diagnostic Applications: a Case Study on COVID-19 Detection</title><link>http://arxiv.org/abs/2304.02181v2</link><description>With advances seen in deep learning, voice-based applications are burgeoning,ranging from personal assistants, affective computing, to remote diseasediagnostics. As the voice contains both linguistic and para-linguisticinformation (e.g., vocal pitch, intonation, speech rate, loudness), there isgrowing interest in voice anonymization to preserve speaker privacy andidentity. Voice privacy challenges have emerged over the last few years andfocus has been placed on removing speaker identity while keeping linguisticcontent intact. For affective computing and disease monitoring applications,however, the para-linguistic content may be more critical. Unfortunately, theeffects that anonymization may have on these systems are still largely unknown.In this paper, we fill this gap and focus on one particular health monitoringapplication: speech-based COVID-19 diagnosis. We test three anonymizationmethods and their impact on five different state-of-the-art COVID-19 diagnosticsystems using three public datasets. We validate the effectiveness of theanonymization methods, compare their computational complexity, and quantify theimpact across different testing scenarios for both within- and across-datasetconditions. Additionally, we provided a comprehensive evaluation of theimportance of different speech aspects for diagnostics and showed how they areaffected by different types of anonymizers. Lastly, we show the benefits ofusing anonymized external data as a data augmentation tool to help recover someof the COVID-19 diagnostic accuracy loss seen with anonymization.</description><author>Yi Zhu, Mohamed Imoussaïne-Aïkous, Carolyn Côté-Lussier, Tiago H. Falk</author><pubDate>Wed, 26 Jun 2024 18:58:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02181v2</guid></item><item><title>MatchTime: Towards Automatic Soccer Game Commentary Generation</title><link>http://arxiv.org/abs/2406.18530v1</link><description>Soccer is a globally popular sport with a vast audience, in this paper, weconsider constructing an automatic soccer game commentary model to improve theaudiences' viewing experience. In general, we make the following contributions:First, observing the prevalent video-text misalignment in existing datasets, wemanually annotate timestamps for 49 matches, establishing a more robustbenchmark for soccer game commentary generation, termed asSN-Caption-test-align; Second, we propose a multi-modal temporal alignmentpipeline to automatically correct and filter the existing dataset at scale,creating a higher-quality soccer game commentary dataset for training, denotedas MatchTime; Third, based on our curated dataset, we train an automaticcommentary generation model, named MatchVoice. Extensive experiments andablation studies have demonstrated the effectiveness of our alignment pipeline,and training model on the curated datasets achieves state-of-the-artperformance for commentary generation, showcasing that better alignment canlead to significant performance improvements in downstream tasks.</description><author>Jiayuan Rao, Haoning Wu, Chang Liu, Yanfeng Wang, Weidi Xie</author><pubDate>Wed, 26 Jun 2024 18:57:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18530v1</guid></item><item><title>Confident Natural Policy Gradient for Local Planning in $q_π$-realizable Constrained MDPs</title><link>http://arxiv.org/abs/2406.18529v1</link><description>The constrained Markov decision process (CMDP) framework emerges as animportant reinforcement learning approach for imposing safety or other criticalobjectives while maximizing cumulative reward. However, the currentunderstanding of how to learn efficiently in a CMDP environment with apotentially infinite number of states remains under investigation, particularlywhen function approximation is applied to the value functions. In this paper,we address the learning problem given linear function approximation with$q_{\pi}$-realizability, where the value functions of all policies are linearlyrepresentable with a known feature map, a setting known to be more general andchallenging than other linear settings. Utilizing a local-access model, wepropose a novel primal-dual algorithm that, after $\tilde{O}(\text{poly}(d)\epsilon^{-3})$ queries, outputs with high probability a policy that strictlysatisfies the constraints while nearly optimizing the value with respect to areward function. Here, $d$ is the feature dimension and $\epsilon &gt; 0$ is agiven error. The algorithm relies on a carefully crafted off-policy evaluationprocedure to evaluate the policy using historical data, which informs policyupdates through policy gradients and conserves samples. To our knowledge, thisis the first result achieving polynomial sample complexity for CMDP in the$q_{\pi}$-realizable setting.</description><author>Tian Tian, Lin F. Yang, Csaba Szepesvári</author><pubDate>Wed, 26 Jun 2024 18:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18529v1</guid></item><item><title>PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation</title><link>http://arxiv.org/abs/2406.18528v1</link><description>Large language models (LLMs) have revolutionized the field of NLP. Notably,their in-context learning capabilities also enable their use as evaluationmetrics for natural language generation, making them particularly advantageousin low-resource scenarios and time-restricted applications. In this work, weintroduce PrExMe, a large-scale prompt exploration for metrics, where weevaluate more than 720 prompt templates for open-source LLM-based metrics onmachine translation (MT) and summarization datasets, totalling over 6.6Mevaluations. This extensive comparison (1) serves as a benchmark of theperformance of recent open-source LLMs as metrics and (2) explores thestability and variability of different prompting strategies. We discover that,on the one hand, there are scenarios for which prompts are stable. Forinstance, some LLMs show idiosyncratic preferences and favor to grade generatedtexts with textual labels while others prefer to return numeric scores. On theother hand, the stability of prompts and model rankings can be susceptible toseemingly innocuous changes. For example, changing the requested output formatfrom "0 to 100" to "-1 to +1" can strongly affect the rankings in ourevaluation. Our study contributes to understanding the impact of differentprompting approaches on LLM-based metrics for MT and summarization evaluation,highlighting the most stable prompting patterns and potential limitations.</description><author>Christoph Leiter, Steffen Eger</author><pubDate>Wed, 26 Jun 2024 18:56:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18528v1</guid></item><item><title>MultiDiff: Consistent Novel View Synthesis from a Single Image</title><link>http://arxiv.org/abs/2406.18524v1</link><description>We introduce MultiDiff, a novel approach for consistent novel view synthesisof scenes from a single RGB image. The task of synthesizing novel views from asingle reference image is highly ill-posed by nature, as there exist multiple,plausible explanations for unobserved areas. To address this issue, weincorporate strong priors in form of monocular depth predictors andvideo-diffusion models. Monocular depth enables us to condition our model onwarped reference images for the target views, increasing geometric stability.The video-diffusion prior provides a strong proxy for 3D scenes, allowing themodel to learn continuous and pixel-accurate correspondences across generatedimages. In contrast to approaches relying on autoregressive image generationthat are prone to drifts and error accumulation, MultiDiff jointly synthesizesa sequence of frames yielding high-quality and multi-view consistent results --even for long-term scene generation with large camera movements, while reducinginference time by an order of magnitude. For additional consistency and imagequality improvements, we introduce a novel, structured noise distribution. Ourexperimental results demonstrate that MultiDiff outperforms state-of-the-artmethods on the challenging, real-world datasets RealEstate10K and ScanNet.Finally, our model naturally supports multi-view consistent editing without theneed for further tuning.</description><author>Norman Müller, Katja Schwarz, Barbara Roessle, Lorenzo Porzi, Samuel Rota Bulò, Matthias Nießner, Peter Kontschieder</author><pubDate>Wed, 26 Jun 2024 18:53:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18524v1</guid></item><item><title>ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of Text-to-Time-lapse Video Generation</title><link>http://arxiv.org/abs/2406.18522v1</link><description>We propose a novel text-to-video (T2V) generation benchmark,ChronoMagic-Bench, to evaluate the temporal and metamorphic capabilities of theT2V models (e.g. Sora and Lumiere) in time-lapse video generation. In contrastto existing benchmarks that focus on the visual quality and textual relevanceof generated videos, ChronoMagic-Bench focuses on the model's ability togenerate time-lapse videos with significant metamorphic amplitude and temporalcoherence. The benchmark probes T2V models for their physics, biology, andchemistry capabilities, in a free-form text query. For these purposes,ChronoMagic-Bench introduces 1,649 prompts and real-world videos as references,categorized into four major types of time-lapse videos: biological,human-created, meteorological, and physical phenomena, which are furtherdivided into 75 subcategories. This categorization comprehensively evaluatesthe model's capacity to handle diverse and complex transformations. Toaccurately align human preference with the benchmark, we introduce two newautomatic metrics, MTScore and CHScore, to evaluate the videos' metamorphicattributes and temporal coherence. MTScore measures the metamorphic amplitude,reflecting the degree of change over time, while CHScore assesses the temporalcoherence, ensuring the generated videos maintain logical progression andcontinuity. Based on the ChronoMagic-Bench, we conduct comprehensive manualevaluations of ten representative T2V models, revealing their strengths andweaknesses across different categories of prompts, and providing a thoroughevaluation framework that addresses current gaps in video generation research.Moreover, we create a large-scale ChronoMagic-Pro dataset, containing 460khigh-quality pairs of 720p time-lapse videos and detailed captions ensuringhigh physical pertinence and large metamorphic amplitude.</description><author>Shenghai Yuan, Jinfa Huang, Yongqi Xu, Yaoyang Liu, Shaofeng Zhang, Yujun Shi, Ruijie Zhu, Xinhua Cheng, Jiebo Luo, Li Yuan</author><pubDate>Wed, 26 Jun 2024 18:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18522v1</guid></item><item><title>CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs</title><link>http://arxiv.org/abs/2406.18521v1</link><description>Chart understanding plays a pivotal role when applying Multimodal LargeLanguage Models (MLLMs) to real-world tasks such as analyzing scientific papersor financial reports. However, existing datasets often focus on oversimplifiedand homogeneous charts with template-based questions, leading to anover-optimistic measure of progress. We demonstrate that although open-sourcemodels can appear to outperform strong proprietary models on these benchmarks,a simple stress test with slightly different charts or questions candeteriorate performance by up to 34.5%. In this work, we propose CharXiv, acomprehensive evaluation suite involving 2,323 natural, challenging, anddiverse charts from arXiv papers. CharXiv includes two types of questions: 1)descriptive questions about examining basic chart elements and 2) reasoningquestions that require synthesizing information across complex visual elementsin the chart. To ensure quality, all charts and questions are handpicked,curated, and verified by human experts. Our results reveal a substantial,previously underestimated gap between the reasoning skills of the strongestproprietary model (i.e., GPT-4o), which achieves 47.1% accuracy, and thestrongest open-source model (i.e., InternVL Chat V1.5), which achieves 29.2%.All models lag far behind human performance of 80.5%, underscoring weaknessesin the chart understanding capabilities of existing MLLMs. We hope CharXivfacilitates future research on MLLM chart understanding by providing a morerealistic and faithful measure of progress. Project page and leaderboard:https://charxiv.github.io/</description><author>Zirui Wang, Mengzhou Xia, Luxi He, Howard Chen, Yitao Liu, Richard Zhu, Kaiqu Liang, Xindi Wu, Haotian Liu, Sadhika Malladi, Alexis Chevalier, Sanjeev Arora, Danqi Chen</author><pubDate>Wed, 26 Jun 2024 18:50:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18521v1</guid></item><item><title>APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets</title><link>http://arxiv.org/abs/2406.18518v1</link><description>The advancement of function-calling agent models requires diverse, reliable,and high-quality datasets. This paper presents APIGen, an automated datageneration pipeline designed to synthesize verifiable high-quality datasets forfunction-calling applications. We leverage APIGen and collect 3,673 executableAPIs across 21 different categories to generate diverse function-callingdatasets in a scalable and structured manner. Each data in our dataset isverified through three hierarchical stages: format checking, actual functionexecutions, and semantic verification, ensuring its reliability andcorrectness. We demonstrate that models trained with our curated datasets, evenwith only 7B parameters, can achieve state-of-the-art performance on theBerkeley Function-Calling Benchmark, outperforming multiple GPT-4 models.Moreover, our 1B model achieves exceptional performance, surpassingGPT-3.5-Turbo and Claude-3 Haiku. We release a dataset containing 60,000high-quality entries, aiming to advance the field of function-calling agentdomains. The dataset is available on Huggingface:https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k and theproject homepage: https://apigen-pipeline.github.io/</description><author>Zuxin Liu, Thai Hoang, Jianguo Zhang, Ming Zhu, Tian Lan, Shirley Kokane, Juntao Tan, Weiran Yao, Zhiwei Liu, Yihao Feng, Rithesh Murthy, Liangwei Yang, Silvio Savarese, Juan Carlos Niebles, Huan Wang, Shelby Heinecke, Caiming Xiong</author><pubDate>Wed, 26 Jun 2024 18:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18518v1</guid></item><item><title>Large Language Models in the Clinic: A Comprehensive Benchmark</title><link>http://arxiv.org/abs/2405.00716v3</link><description>The adoption of large language models (LLMs) to assist clinicians hasattracted remarkable attention. Existing works mainly adopt the close-endedquestion-answering (QA) task with answer options for evaluation. However, manyclinical decisions involve answering open-ended questions without pre-setoptions. To better understand LLMs in the clinic, we construct a benchmarkClinicBench. We first collect eleven existing datasets covering diverseclinical language generation, understanding, and reasoning tasks. Furthermore,we construct six novel datasets and complex clinical tasks that are close toreal-world practice, i.e., referral QA, treatment recommendation,hospitalization (long document) summarization, patient education, pharmacologyQA and drug interaction for emerging drugs. We conduct an extensive evaluationof twenty-two LLMs under both zero-shot and few-shot settings. Finally, weinvite medical experts to evaluate the clinical usefulness of LLMs.</description><author>Andrew Liu, Hongjian Zhou, Yining Hua, Omid Rohanian, Anshul Thakur, Lei Clifton, David A. Clifton</author><pubDate>Wed, 26 Jun 2024 18:48:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00716v3</guid></item><item><title>Large Language Model Enhanced Clustering for News Event Detection</title><link>http://arxiv.org/abs/2406.10552v2</link><description>The news landscape is continuously evolving, with an ever-increasing volumeof information from around the world. Automated event detection within thisvast data repository is essential for monitoring, identifying, and categorizingsignificant news occurrences across diverse platforms. This paper presents anevent detection framework that leverages Large Language Models (LLMs) combinedwith clustering analysis to detect news events from the Global Database ofEvents, Language, and Tone (GDELT). The framework enhances event clusteringthrough both pre-event detection tasks (keyword extraction and text embedding)and post-event detection tasks (event summarization and topic labeling). Wealso evaluate the impact of various textual embeddings on the quality ofclustering outcomes, ensuring robust news categorization. Additionally, weintroduce a novel Cluster Stability Assessment Index (CSAI) to assess thevalidity and robustness of clustering results. CSAI utilizes latent featurevectors to provide a new way of measuring clustering quality. Our experimentsindicate that combining LLM embeddings with clustering algorithms yields thebest results, demonstrating greater robustness in terms of CSAI scores.Moreover, post-event detection tasks generate meaningful insights, facilitatingeffective interpretation of event clustering results. Overall, our experimentalresults indicate that the proposed framework offers valuable insights and couldenhance the accuracy and depth of news reporting.</description><author>Adane Nega Tarekegn</author><pubDate>Wed, 26 Jun 2024 18:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10552v2</guid></item><item><title>Denoising as Adaptation: Noise-Space Domain Adaptation for Image Restoration</title><link>http://arxiv.org/abs/2406.18516v1</link><description>Although deep learning-based image restoration methods have made significantprogress, they still struggle with limited generalization to real-worldscenarios due to the substantial domain gap caused by training on syntheticdata. Existing methods address this issue by improving data synthesispipelines, estimating degradation kernels, employing deep internal learning,and performing domain adaptation and regularization. Previous domain adaptationmethods have sought to bridge the domain gap by learning domain-invariantknowledge in either feature or pixel space. However, these techniques oftenstruggle to extend to low-level vision tasks within a stable and compactframework. In this paper, we show that it is possible to perform domainadaptation via the noise-space using diffusion models. In particular, byleveraging the unique property of how the multi-step denoising process isinfluenced by auxiliary conditional inputs, we obtain meaningful gradients fromnoise prediction to gradually align the restored results of both synthetic andreal-world data to a common clean distribution. We refer to this method asdenoising as adaptation. To prevent shortcuts during training, we presentuseful techniques such as channel shuffling and residual-swapping contrastivelearning. Experimental results on three classical image restoration tasks,namely denoising, deblurring, and deraining, demonstrate the effectiveness ofthe proposed method. Code will be released at:https://github.com/KangLiao929/Noise-DA/.</description><author>Kang Liao, Zongsheng Yue, Zhouxia Wang, Chen Change Loy</author><pubDate>Wed, 26 Jun 2024 18:40:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18516v1</guid></item><item><title>Multimodal and Force-Matched Imitation Learning with a See-Through Visuotactile Sensor</title><link>http://arxiv.org/abs/2311.01248v3</link><description>Contact-rich tasks continue to present a variety of challenges for roboticmanipulation. In this work, we leverage a multimodal visuotactile sensor withinthe framework of imitation learning (IL) to perform contact rich tasks thatinvolve relative motion (slipping/sliding) between the end-effector and object.We introduce two algorithmic contributions, tactile force matching and learnedmode switching, as complimentary methods for improving IL. Tactile forcematching enhances kinesthetic teaching by reading approximate forces during thedemonstration and generating an adapted robot trajectory that recreates therecorded forces. Learned mode switching uses IL to couple visual and tactilesensor modes with the learned motion policy, simplifying the transition fromreaching to contacting. We perform robotic manipulation experiments on fourdoor opening tasks with a variety of observation and method configurations tostudy the utility of our proposed improvements and multimodal visuotactilesensing. Our results show that the inclusion of force matching raises averagepolicy success rates by 62.5%, visuotactile mode switching by 30.3%, andvisuotactile data as a policy input by 42.5%, emphasizing the value ofsee-through tactile sensing for IL, both for data collection to allow forcematching, and for policy execution to allow accurate task feedback.</description><author>Trevor Ablett, Oliver Limoyo, Adam Sigal, Affan Jilani, Jonathan Kelly, Kaleem Siddiqi, Francois Hogan, Gregory Dudek</author><pubDate>Wed, 26 Jun 2024 18:40:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01248v3</guid></item><item><title>AND: Audio Network Dissection for Interpreting Deep Acoustic Models</title><link>http://arxiv.org/abs/2406.16990v2</link><description>Neuron-level interpretations aim to explain network behaviors and propertiesby investigating neurons responsive to specific perceptual or structural inputpatterns. Although there is emerging work in the vision and language domains,none is explored for acoustic models. To bridge the gap, we introduce$\textit{AND}$, the first $\textbf{A}$udio $\textbf{N}$etwork$\textbf{D}$issection framework that automatically establishes natural languageexplanations of acoustic neurons based on highly-responsive audio.$\textit{AND}$ features the use of LLMs to summarize mutual acoustic featuresand identities among audio. Extensive experiments are conducted to verify$\textit{AND}$'s precise and informative descriptions. In addition, wedemonstrate a potential use of $\textit{AND}$ for audio machine unlearning byconducting concept-specific pruning based on the generated descriptions.Finally, we highlight two acoustic model behaviors with analysis by$\textit{AND}$: (i) models discriminate audio with a combination of basicacoustic features rather than high-level abstract concepts; (ii) trainingstrategies affect model behaviors and neuron interpretability -- supervisedtraining guides neurons to gradually narrow their attention, whileself-supervised learning encourages neurons to be polysemantic for exploringhigh-level features.</description><author>Tung-Yu Wu, Yu-Xiang Lin, Tsui-Wei Weng</author><pubDate>Wed, 26 Jun 2024 18:36:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16990v2</guid></item><item><title>"Is ChatGPT a Better Explainer than My Professor?": Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline</title><link>http://arxiv.org/abs/2406.18512v1</link><description>Explanations form the foundation of knowledge sharing and build uponcommunication principles, social dynamics, and learning theories. We focusspecifically on conversational approaches for explanations because the contextis highly adaptive and interactive. Our research leverages previous work onexplanatory acts, a framework for understanding the different strategies thatexplainers and explainees employ in a conversation to both explain, understand,and engage with the other party. We use the 5-Levels dataset was constructedfrom the WIRED YouTube series by Wachsmuth et al., and later annotated byBooshehri et al. with explanatory acts. These annotations provide a frameworkfor understanding how explainers and explainees structure their response whencrafting a response. With the rise of generative AI in the past year, we hope to better understandthe capabilities of Large Language Models (LLMs) and how they can augmentexpert explainer's capabilities in conversational settings. To achieve thisgoal, the 5-Levels dataset (We use Booshehri et al.'s 2023 annotated datasetwith explanatory acts.) allows us to audit the ability of LLMs in engaging inexplanation dialogues. To evaluate the effectiveness of LLMs in generatingexplainer responses, we compared 3 different strategies, we asked humanannotators to evaluate 3 different strategies: human explainer response, GPT4standard response, GPT4 response with Explanation Moves.</description><author>Grace Li, Milad Alshomary, Smaranda Muresan</author><pubDate>Wed, 26 Jun 2024 18:33:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18512v1</guid></item><item><title>WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models</title><link>http://arxiv.org/abs/2406.18510v1</link><description>We introduce WildTeaming, an automatic LLM safety red-teaming framework thatmines in-the-wild user-chatbot interactions to discover 5.7K unique clusters ofnovel jailbreak tactics, and then composes multiple tactics for systematicexploration of novel jailbreaks. Compared to prior work that performedred-teaming via recruited human workers, gradient-based optimization, oriterative revision with LLMs, our work investigates jailbreaks from chatbotusers who were not specifically instructed to break the system. WildTeamingreveals previously unidentified vulnerabilities of frontier LLMs, resulting inup to 4.6x more diverse and successful adversarial attacks compared tostate-of-the-art jailbreak methods. While many datasets exist for jailbreak evaluation, very few open-sourcedatasets exist for jailbreak training, as safety training data has been closedeven when model weights are open. With WildTeaming we create WildJailbreak, alarge-scale open-source synthetic safety dataset with 262K vanilla (directrequest) and adversarial (complex jailbreak) prompt-response pairs. To mitigateexaggerated safety behaviors, WildJailbreak provides two contrastive types ofqueries: 1) harmful queries (vanilla &amp; adversarial) and 2) benign queries thatresemble harmful queries in form but contain no harm. As WildJailbreakconsiderably upgrades the quality and scale of existing safety resources, ituniquely enables us to examine the scaling effects of data and the interplay ofdata properties and model capabilities during safety training. Throughextensive experiments, we identify the training properties that enable an idealbalance of safety behaviors: appropriate safeguarding without over-refusal,effective handling of vanilla and adversarial queries, and minimal, if any,decrease in general capabilities. All components of WildJailbeak contribute toachieving balanced safety behaviors of models.</description><author>Liwei Jiang, Kavel Rao, Seungju Han, Allyson Ettinger, Faeze Brahman, Sachin Kumar, Niloofar Mireshghallah, Ximing Lu, Maarten Sap, Yejin Choi, Nouha Dziri</author><pubDate>Wed, 26 Jun 2024 18:31:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18510v1</guid></item><item><title>BASS: Batched Attention-optimized Speculative Sampling</title><link>http://arxiv.org/abs/2404.15778v2</link><description>Speculative decoding has emerged as a powerful method to improve latency andthroughput in hosting large language models. However, most existingimplementations focus on generating a single sequence. Real-world generative AIapplications often require multiple responses and how to perform speculativedecoding in a batched setting while preserving its latency benefits posesnon-trivial challenges. This paper describes a system of batched speculativedecoding that sets a new state of the art in multi-sequence generation latencyand that demonstrates superior GPU utilization as well as quality ofgenerations within a time budget. For example, for a 7.8B-size model on asingle A100 GPU and with a batch size of 8, each sequence is generated at anaverage speed of 5.8ms per token, the overall throughput being 1.1K tokens persecond. These results represent state-of-the-art latency and a 2.15X speed-upover optimized regular decoding. Within a time budget that regular decodingdoes not finish, our system is able to generate sequences with HumanEvalPass@First of 43% and Pass@All of 61%, far exceeding what's feasible withsingle-sequence speculative decoding. Our peak GPU utilization during decodingreaches as high as 15.8%, more than 3X the highest of that of regular decodingand around 10X of single-sequence speculative decoding.</description><author>Haifeng Qian, Sujan Kumar Gonugondla, Sungsoo Ha, Mingyue Shang, Sanjay Krishna Gouda, Ramesh Nallapati, Sudipta Sengupta, Xiaofei Ma, Anoop Deoras</author><pubDate>Wed, 26 Jun 2024 18:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15778v2</guid></item><item><title>Mental Modeling of Reinforcement Learning Agents by Language Models</title><link>http://arxiv.org/abs/2406.18505v1</link><description>Can emergent language models faithfully model the intelligence ofdecision-making agents? Though modern language models exhibit already somereasoning ability, and theoretically can potentially express any probabledistribution over tokens, it remains underexplored how the world knowledgethese pretrained models have memorized can be utilized to comprehend an agent'sbehaviour in the physical world. This study empirically examines, for the firsttime, how well large language models (LLMs) can build a mental model of agents,termed agent mental modelling, by reasoning about an agent's behaviour and itseffect on states from agent interaction history. This research may unveil thepotential of leveraging LLMs for elucidating RL agent behaviour, addressing akey challenge in eXplainable reinforcement learning (XRL). To this end, wepropose specific evaluation metrics and test them on selected RL task datasetsof varying complexity, reporting findings on agent mental model establishment.Our results disclose that LLMs are not yet capable of fully mental modellingagents through inference alone without further innovations. This work thusprovides new insights into the capabilities and limitations of modern LLMs.</description><author>Wenhao Lu, Xufeng Zhao, Josua Spisak, Jae Hee Lee, Stefan Wermter</author><pubDate>Wed, 26 Jun 2024 18:14:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18505v1</guid></item><item><title>Learning Generalizable Program and Architecture Representations for Performance Modeling</title><link>http://arxiv.org/abs/2310.16792v2</link><description>Performance modeling is an essential tool in many areas, includingperformance characterization/optimization, design space exploration, andresource allocation problems, to name a few. However, existing performancemodeling approaches have limitations, such as high computational cost fordiscrete-event simulators, narrow flexibility of hardware emulators, orrestricted accuracy/generality of analytical/data-driven models. To addressthese limitations, this paper proposes PerfVec, a novel deep learning-basedperformance modeling framework that learns high-dimensional andindependent/orthogonal program and microarchitecture representations. Oncelearned, a program representation can be used to predict its performance on anymicroarchitecture, and likewise, a microarchitecture representation can beapplied in the performance prediction of any program. Additionally, PerfVecyields a foundation model that captures the performance essence ofinstructions, which can be directly used by developers in numerous performancemodeling related tasks without incurring its training cost. The evaluationdemonstrates that PerfVec is more general and efficient than previousapproaches.</description><author>Lingda Li, Thomas Flynn, Adolfy Hoisie</author><pubDate>Wed, 26 Jun 2024 18:12:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16792v2</guid></item><item><title>Is In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming</title><link>http://arxiv.org/abs/2406.18501v1</link><description>Large language models (LLMs) have shown the emergent capability of in-contextlearning (ICL). One line of research has explained ICL as functionallyperforming gradient descent. In this paper, we introduce a new way ofdiagnosing whether ICL is functionally equivalent to gradient-based learning.Our approach is based on the inverse frequency effect (IFE) -- a phenomenon inwhich an error-driven learner is expected to show larger updates when trainedon infrequent examples than frequent ones. The IFE has previously been studiedin psycholinguistics because humans show this effect in the context ofstructural priming (the tendency for people to produce sentence structures theyhave encountered recently); the IFE has been used as evidence that humanstructural priming must involve error-driven learning mechanisms. In ourexperiments, we simulated structural priming within ICL and found that LLMsdisplay the IFE, with the effect being stronger in larger models. We concludethat ICL is indeed a type of gradient-based learning, supporting the hypothesisthat a gradient component is implicitly computed in the forward pass duringICL. Our results suggest that both humans and LLMs make use of gradient-based,error-driven processing mechanisms.</description><author>Zhenghao Zhou, Robert Frank, R. Thomas McCoy</author><pubDate>Wed, 26 Jun 2024 18:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18501v1</guid></item><item><title>BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions</title><link>http://arxiv.org/abs/2406.15877v2</link><description>Automated software engineering has been greatly empowered by the recentadvances in Large Language Models (LLMs) for programming. While currentbenchmarks have shown that LLMs can perform various software engineering taskslike human developers, the majority of their evaluations are limited to shortand self-contained algorithmic tasks. Solving challenging and practicalprogramming tasks requires the capability of utilizing diverse function callsas tools to efficiently implement functionalities like data analysis and webdevelopment. In addition, using multiple tools to solve a task needscompositional reasoning by accurately understanding complex instructions.Fulfilling both of these characteristics can pose a great challenge for LLMs.To assess how well LLMs can solve challenging and practical programming tasks,we introduce Bench, a benchmark that challenges LLMs to invoke multiplefunction calls as tools from 139 libraries and 7 domains for 1,140 fine-grainedprogramming tasks. To evaluate LLMs rigorously, each programming taskencompasses 5.6 test cases with an average branch coverage of 99%. In addition,we propose a natural-language-oriented variant of Bench, Benchi, thatautomatically transforms the original docstrings into short instructions onlywith essential information. Our extensive evaluation of 60 LLMs shows that LLMsare not yet capable of following complex instructions to use function callsprecisely, with scores up to 60%, significantly lower than the humanperformance of 97%. The results underscore the need for further advancements inthis area.</description><author>Terry Yue Zhuo, Minh Chien Vu, Jenny Chim, Han Hu, Wenhao Yu, Ratnadira Widyasari, Imam Nur Bani Yusuf, Haolan Zhan, Junda He, Indraneil Paul, Simon Brunner, Chen Gong, Thong Hoang, Armel Randy Zebaze, Xiaoheng Hong, Wen-Ding Li, Jean Kaddour, Ming Xu, Zhihan Zhang, Prateek Yadav, Naman Jain, Alex Gu, Zhoujun Cheng, Jiawei Liu, Qian Liu, Zijian Wang, David Lo, Binyuan Hui, Niklas Muennighoff, Daniel Fried, Xiaoning Du, Harm de Vries, Leandro Von Werra</author><pubDate>Wed, 26 Jun 2024 18:05:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15877v2</guid></item><item><title>WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs</title><link>http://arxiv.org/abs/2406.18495v1</link><description>We introduce WildGuard -- an open, light-weight moderation tool for LLMsafety that achieves three goals: (1) identifying malicious intent in userprompts, (2) detecting safety risks of model responses, and (3) determiningmodel refusal rate. Together, WildGuard serves the increasing needs forautomatic safety moderation and evaluation of LLM interactions, providing aone-stop tool with enhanced accuracy and broad coverage across 13 riskcategories. While existing open moderation tools such as Llama-Guard2 scorereasonably well in classifying straightforward model interactions, they lag farbehind a prompted GPT-4, especially in identifying adversarial jailbreaks andin evaluating models' refusals, a key measure for evaluating safety behaviorsin model responses. To address these challenges, we construct WildGuardMix, a large-scale andcarefully balanced multi-task safety moderation dataset with 92K labeledexamples that cover vanilla (direct) prompts and adversarial jailbreaks, pairedwith various refusal and compliance responses. WildGuardMix is a combination ofWildGuardTrain, the training data of WildGuard, and WildGuardTest, ahigh-quality human-annotated moderation test set with 5K labeled items coveringbroad risk scenarios. Through extensive evaluations on WildGuardTest and tenexisting public benchmarks, we show that WildGuard establishes state-of-the-artperformance in open-source safety moderation across all the three taskscompared to ten strong existing open-source moderation models (e.g., up to26.4% improvement on refusal detection). Importantly, WildGuard matches andsometimes exceeds GPT-4 performance (e.g., up to 3.9% improvement on promptharmfulness identification). WildGuard serves as a highly effective safetymoderator in an LLM interface, reducing the success rate of jailbreak attacksfrom 79.8% to 2.4%.</description><author>Seungju Han, Kavel Rao, Allyson Ettinger, Liwei Jiang, Bill Yuchen Lin, Nathan Lambert, Yejin Choi, Nouha Dziri</author><pubDate>Wed, 26 Jun 2024 17:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18495v1</guid></item><item><title>Hierarchical Causal Models</title><link>http://arxiv.org/abs/2401.05330v2</link><description>Scientists often want to learn about cause and effect from hierarchical data,collected from subunits nested inside units. Consider students in schools,cells in patients, or cities in states. In such settings, unit-level variables(e.g. each school's budget) may affect subunit-level variables (e.g. the testscores of each student in each school) and vice versa. To address causalquestions with hierarchical data, we propose hierarchical causal models, whichextend structural causal models and causal graphical models by adding innerplates. We develop a general graphical identification technique forhierarchical causal models that extends do-calculus. We find many situations inwhich hierarchical data can enable causal identification even when it would beimpossible with non-hierarchical data, that is, if we had only unit-levelsummaries of subunit-level variables (e.g. the school's average test score,rather than each student's score). We develop estimation techniques forhierarchical causal models, using methods including hierarchical Bayesianmodels. We illustrate our results in simulation and via a reanalysis of theclassic "eight schools" study.</description><author>Eli N. Weinstein, David M. Blei</author><pubDate>Wed, 26 Jun 2024 17:56:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05330v2</guid></item><item><title>Scaling and renormalization in high-dimensional regression</title><link>http://arxiv.org/abs/2405.00592v3</link><description>This paper presents a succinct derivation of the training and generalizationperformance of a variety of high-dimensional ridge regression models using thebasic tools of random matrix theory and free probability. We provide anintroduction and review of recent results on these topics, aimed at readerswith backgrounds in physics and deep learning. Analytic formulas for thetraining and generalization errors are obtained in a few lines of algebradirectly from the properties of the $S$-transform of free probability. Thisallows for a straightforward identification of the sources of power-law scalingin model performance. We compute the generalization error of a broad class ofrandom feature models. We find that in all models, the $S$-transformcorresponds to the train-test generalization gap, and yields an analogue of thegeneralized-cross-validation estimator. Using these techniques, we derivefine-grained bias-variance decompositions for a very general class of randomfeature models with structured covariates. These novel results allow us todiscover a scaling regime for random feature models where the variance due tothe features limits performance in the overparameterized setting. We alsodemonstrate how anisotropic weight structure in random feature models can limitperformance and lead to nontrivial exponents for finite-width corrections inthe overparameterized setting. Our results extend and provide a unifyingperspective on earlier models of neural scaling laws.</description><author>Alexander Atanasov, Jacob A. Zavatone-Veth, Cengiz Pehlevan</author><pubDate>Wed, 26 Jun 2024 17:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00592v3</guid></item><item><title>Enhancing Federated Learning with Adaptive Differential Privacy and Priority-Based Aggregation</title><link>http://arxiv.org/abs/2406.18491v1</link><description>Federated learning (FL), a novel branch of distributed machine learning (ML),develops global models through a private procedure without direct access tolocal datasets. However, it is still possible to access the model updates(gradient updates of deep neural networks) transferred between clients andservers, potentially revealing sensitive local information to adversaries usingmodel inversion attacks. Differential privacy (DP) offers a promising approachto addressing this issue by adding noise to the parameters. On the other hand,heterogeneities in data structure, storage, communication, and computationalcapabilities of devices can cause convergence problems and delays in developingthe global model. A personalized weighted averaging of local parameters basedon the resources of each device can yield a better aggregated model in eachround. In this paper, to efficiently preserve privacy, we propose apersonalized DP framework that injects noise based on clients' relative impactfactors and aggregates parameters while considering heterogeneities andadjusting properties. To fulfill the DP requirements, we first analyze theconvergence boundary of the FL algorithm when impact factors are personalizedand fixed throughout the learning process. We then further study theconvergence property considering time-varying (adaptive) impact factors.</description><author>Mahtab Talaei, Iman Izadi</author><pubDate>Wed, 26 Jun 2024 17:55:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18491v1</guid></item><item><title>Mixtures of Experts Unlock Parameter Scaling for Deep RL</title><link>http://arxiv.org/abs/2402.08609v3</link><description>The recent rapid progress in (self) supervised learning models is in largepart predicted by empirical scaling laws: a model's performance scalesproportionally to its size. Analogous scaling laws remain elusive forreinforcement learning domains, however, where increasing the parameter countof a model often hurts its final performance. In this paper, we demonstratethat incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs(Puigcerver et al., 2023), into value-based networks results in moreparameter-scalable models, evidenced by substantial performance increasesacross a variety of training regimes and model sizes. This work thus providesstrong empirical evidence towards developing scaling laws for reinforcementlearning.</description><author>Johan Obando-Ceron, Ghada Sokar, Timon Willi, Clare Lyle, Jesse Farebrother, Jakob Foerster, Gintare Karolina Dziugaite, Doina Precup, Pablo Samuel Castro</author><pubDate>Wed, 26 Jun 2024 17:50:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08609v3</guid></item><item><title>Robust Surgical Phase Recognition From Annotation Efficient Supervision</title><link>http://arxiv.org/abs/2406.18481v1</link><description>Surgical phase recognition is a key task in computer-assisted surgery, aimingto automatically identify and categorize the different phases within a surgicalprocedure. Despite substantial advancements, most current approaches rely onfully supervised training, requiring expensive and time-consuming frame-levelannotations. Timestamp supervision has recently emerged as a promisingalternative, significantly reducing annotation costs while maintainingcompetitive performance. However, models trained on timestamp annotations canbe negatively impacted by missing phase annotations, leading to a potentialdrawback in real-world scenarios. In this work, we address this issue byproposing a robust method for surgical phase recognition that can handlemissing phase annotations effectively. Furthermore, we introduce the SkipTag@Kannotation approach to the surgical domain, enabling a flexible balance betweenannotation effort and model performance. Our method achieves competitiveresults on two challenging datasets, demonstrating its efficacy in handlingmissing phase annotations and its potential for reducing annotation costs.Specifically, we achieve an accuracy of 85.1\% on the MultiBypass140 datasetusing only 3 annotated frames per video, showcasing the effectiveness of ourmethod and the potential of the SkipTag@K setup. We perform extensiveexperiments to validate the robustness of our method and provide valuableinsights to guide future research in surgical phase recognition. Our workcontributes to the advancement of surgical workflow recognition and paves theway for more efficient and reliable surgical phase recognition systems.</description><author>Or Rubin, Shlomi Laufer</author><pubDate>Wed, 26 Jun 2024 17:47:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18481v1</guid></item><item><title>VADA: a Data-Driven Simulator for Nanopore Sequencing</title><link>http://arxiv.org/abs/2404.08722v2</link><description>Nanopore sequencing offers the ability for real-time analysis of long DNAsequences at a low cost, enabling new applications such as early detection ofcancer. Due to the complex nature of nanopore measurements and the high cost ofobtaining ground truth datasets, there is a need for nanopore simulators.Existing simulators rely on handcrafted rules and parameters and do not learnan internal representation that would allow for analysing underlying biologicalfactors of interest. Instead, we propose VADA, a purely data-driven method forsimulating nanopores based on an autoregressive latent variable model. We embedsubsequences of DNA and introduce a conditional prior to address the challengeof a collapsing conditioning. We introduce an auxiliary regressor on the latentvariable to encourage our model to learn an informative latent representation.We empirically demonstrate that our model achieves competitive simulationperformance on experimental nanopore data. Moreover, we show we have learned aninformative latent representation that is predictive of the DNA labels. Wehypothesize that other biological factors of interest, beyond the DNA labels,can potentially be extracted from such a learned latent representation.</description><author>Jonas Niederle, Simon Koop, Marc Pagès-Gallego, Vlado Menkovski</author><pubDate>Wed, 26 Jun 2024 17:46:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08722v2</guid></item><item><title>Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2406.17294v2</link><description>Large language models (LLMs) have demonstrated impressive reasoningcapabilities, particularly in textual mathematical problem-solving. However,existing open-source image instruction fine-tuning datasets, containing limitedquestion-answer pairs per image, do not fully exploit visual information toenhance the multimodal mathematical reasoning capabilities of Multimodal LLMs(MLLMs). To bridge this gap, we address the lack of high-quality, diversemultimodal mathematical datasets by collecting 40K high-quality images withquestion-answer pairs from 24 existing datasets and synthesizing 320K newpairs, creating the MathV360K dataset, which enhances both the breadth anddepth of multimodal mathematical questions. We introduce Math-LLaVA, aLLaVA-1.5-based model fine-tuned with MathV360K. This novel approachsignificantly improves the multimodal mathematical reasoning capabilities ofLLaVA-1.5, achieving a 19-point increase and comparable performance to GPT-4Von MathVista's minitest split. Furthermore, Math-LLaVA demonstrates enhancedgeneralizability, showing substantial improvements on the MMMU benchmark. Ourresearch highlights the importance of dataset diversity and synthesis inadvancing MLLMs' mathematical reasoning abilities. The code and data areavailable at: \url{https://github.com/HZQ950419/Math-LLaVA}.</description><author>Wenhao Shi, Zhiqiang Hu, Yi Bin, Junhua Liu, Yang Yang, See-Kiong Ng, Lidong Bing, Roy Ka-Wei Lee</author><pubDate>Wed, 26 Jun 2024 17:43:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17294v2</guid></item><item><title>Robustness to Subpopulation Shift with Domain Label Noise via Regularized Annotation of Domains</title><link>http://arxiv.org/abs/2402.11039v2</link><description>Existing methods for last layer retraining that aim to optimize worst-groupaccuracy (WGA) rely heavily on well-annotated groups in the training data. Weshow, both in theory and practice, that annotation-based data augmentationsusing either downsampling or upweighting for WGA are susceptible to domainannotation noise, and in high-noise regimes approach the WGA of a model trainedwith vanilla empirical risk minimization. We introduce Regularized Annotationof Domains (RAD) in order to train robust last layer classifiers without theneed for explicit domain annotations. Our results show that RAD is competitivewith other recently proposed domain annotation-free techniques. Mostimportantly, RAD outperforms state-of-the-art annotation-reliant methods evenwith only 5% noise in the training data for several publicly availabledatasets.</description><author>Nathan Stromberg, Rohan Ayyagari, Monica Welfert, Sanmi Koyejo, Richard Nock, Lalitha Sankar</author><pubDate>Wed, 26 Jun 2024 17:35:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11039v2</guid></item><item><title>ReLU Neural Networks with Linear Layers are Biased Towards Single- and Multi-Index Models</title><link>http://arxiv.org/abs/2305.15598v3</link><description>Neural networks often operate in the overparameterized regime, in which thereare far more parameters than training samples, allowing the training data to befit perfectly. That is, training the network effectively learns aninterpolating function, and properties of the interpolant affect predictionsthe network will make on new samples. This manuscript explores how propertiesof such functions learned by neural networks of depth greater than two layers.Our framework considers a family of networks of varying depths that all havethe same capacity but different representation costs. The representation costof a function induced by a neural network architecture is the minimum sum ofsquared weights needed for the network to represent the function; it reflectsthe function space bias associated with the architecture. Our results show thatadding additional linear layers to the input side of a shallow ReLU networkyields a representation cost favoring functions with low mixed variation - thatis, it has limited variation in directions orthogonal to a low-dimensionalsubspace and can be well approximated by a single- or multi-index model. Suchfunctions may be represented by the composition of a function with lowtwo-layer representation cost and a low-rank linear operator. Our experimentsconfirm this behavior in standard network training regimes. They additionallyshow that linear layers can improve generalization and the learned network iswell-aligned with the true latent low-dimensional linear subspace when data isgenerated using a multi-index model.</description><author>Suzanna Parkinson, Greg Ongie, Rebecca Willett</author><pubDate>Wed, 26 Jun 2024 17:29:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15598v3</guid></item><item><title>UniRec: A Dual Enhancement of Uniformity and Frequency in Sequential Recommendations</title><link>http://arxiv.org/abs/2406.18470v1</link><description>Representation learning in sequential recommendation is critical foraccurately modeling user interaction patterns and improving recommendationprecision. However, existing approaches predominantly emphasize item-to-itemtransitions, often neglecting the time intervals between interactions, whichare closely related to behavior pattern changes. Additionally, broaderinteraction attributes, such as item frequency, are frequently overlooked. Wefound that both sequences with more uniform time intervals and items withhigher frequency yield better prediction performance. Conversely, non-uniformsequences exacerbate user interest drift and less-frequent items are difficultto model due to sparse sampling, presenting unique challenges inadequatelyaddressed by current methods. In this paper, we propose UniRec, a novelbidirectional enhancement sequential recommendation method. UniRec leveragessequence uniformity and item frequency to enhance performance, particularlyimproving the representation of non-uniform sequences and less-frequent items.These two branches mutually reinforce each other, driving comprehensiveperformance optimization in complex sequential recommendation scenarios.Additionally, we present a multidimensional time module to further enhanceadaptability. To the best of our knowledge, UniRec is the first method toutilize the characteristics of uniformity and frequency for featureaugmentation. Comparing with eleven advanced models across four datasets, wedemonstrate that UniRec outperforms SOTA models significantly. The code isavailable at https://github.com/Linxi000/UniRec.</description><author>Yang Liu, Yitong Wang, Chenyue Feng</author><pubDate>Wed, 26 Jun 2024 17:28:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18470v1</guid></item><item><title>Fair, Manipulation-Robust, and Transparent Sortition</title><link>http://arxiv.org/abs/2406.15009v2</link><description>Sortition, the random selection of political representatives, is increasinglybeing used around the world to choose participants of deliberative processeslike Citizens' Assemblies. Motivated by sortition's practical importance, therehas been a recent flurry of research on sortition algorithms, whose task it isto select a panel from among a pool of volunteers. This panel must satisfyquotas enforcing representation of key population subgroups. Past work hascontributed an algorithmic approach for fulfilling this task while ensuringthat volunteers' chances of selection are maximally equal, as measured by anyconvex equality objective. The question, then, is: which equality objective isthe right one? Past work has mainly studied the objectives Minimax and Leximin,which respectively minimize the maximum and maximize the minimum chance ofselection given to any volunteer. Recent work showed that both of theseobjectives have key weaknesses: Minimax is highly robust to manipulation but isarbitrarily unfair; oppositely, Leximin is highly fair but arbitrarilymanipulable. In light of this gap, we propose a new equality objective, Goldilocks, thataims to achieve these ideals simultaneously by ensuring that no volunteerreceives too little or too much chance of selection. We theoretically bound theextent to which Goldilocks achieves these ideals, finding that in an importantsense, Goldilocks recovers among the best available solutions in a giveninstance. We then extend our bounds to the case where the output of Goldilocksis transformed to achieve a third goal, Transparency. Our empirical analysis ofGoldilocks in real data is even more promising: we find that this objectiveachieves nearly instance-optimal minimum and maximum selection probabilitiessimultaneously in most real instances -- an outcome not even guaranteed to bepossible for any algorithm.</description><author>Carmel Baharav, Bailey Flanigan</author><pubDate>Wed, 26 Jun 2024 17:26:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15009v2</guid></item><item><title>Unsupervised Open-Vocabulary Object Localization in Videos</title><link>http://arxiv.org/abs/2309.09858v2</link><description>In this paper, we show that recent advances in video representation learningand pre-trained vision-language models allow for substantial improvements inself-supervised video object localization. We propose a method that firstlocalizes objects in videos via an object-centric approach with slot attentionand then assigns text to the obtained slots. The latter is achieved by anunsupervised way to read localized semantic information from the pre-trainedCLIP model. The resulting video object localization is entirely unsupervisedapart from the implicit annotation contained in CLIP, and it is effectively thefirst unsupervised approach that yields good results on regular videobenchmarks.</description><author>Ke Fan, Zechen Bai, Tianjun Xiao, Dominik Zietlow, Max Horn, Zixu Zhao, Carl-Johann Simon-Gabriel, Mike Zheng Shou, Francesco Locatello, Bernt Schiele, Thomas Brox, Zheng Zhang, Yanwei Fu, Tong He</author><pubDate>Wed, 26 Jun 2024 17:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09858v2</guid></item><item><title>ProFLingo: A Fingerprinting-based Intellectual Property Protection Scheme for Large Language Models</title><link>http://arxiv.org/abs/2405.02466v2</link><description>Large language models (LLMs) have attracted significant attention in recentyears. Due to their "Large" nature, training LLMs from scratch consumes immensecomputational resources. Since several major players in the artificialintelligence (AI) field have open-sourced their original LLMs, an increasingnumber of individual researchers and smaller companies are able to buildderivative LLMs based on these open-sourced models at much lower costs.However, this practice opens up possibilities for unauthorized use orreproduction that may not comply with licensing agreements, and fine-tuning canchange the model's behavior, thus complicating the determination of modelownership. Current intellectual property (IP) protection schemes for LLMs areeither designed for white-box settings or require additional modifications tothe original model, which restricts their use in real-world settings. In this paper, we propose ProFLingo, a black-box fingerprinting-based IPprotection scheme for LLMs. ProFLingo generates queries that elicit specificresponses from an original model, thereby establishing unique fingerprints. Ourscheme assesses the effectiveness of these queries on a suspect model todetermine whether it has been derived from the original model. ProFLingo offersa non-invasive approach, which neither requires knowledge of the suspect modelnor modifications to the base model or its training process. To the best of ourknowledge, our method represents the first black-box fingerprinting techniquefor IP protection for LLMs. Our source code and generated queries are availableat: https://github.com/hengvt/ProFLingo.</description><author>Heng Jin, Chaoyu Zhang, Shanghao Shi, Wenjing Lou, Y. Thomas Hou</author><pubDate>Wed, 26 Jun 2024 17:22:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02466v2</guid></item><item><title>Bayesian inverse Navier-Stokes problems: joint flow field reconstruction and parameter learning</title><link>http://arxiv.org/abs/2406.18464v1</link><description>We formulate and solve a Bayesian inverse Navier-Stokes (N-S) problem thatassimilates velocimetry data in order to jointly reconstruct a 3D flow fieldand learn the unknown N-S parameters, including the boundary position. Byhardwiring a generalised N-S problem, and regularising its unknown parametersusing Gaussian prior distributions, we learn the most likely parameters in acollapsed search space. The most likely flow field reconstruction is then theN-S solution that corresponds to the learned parameters. We develop the methodin the variational setting and use a stabilised Nitsche weak form of the N-Sproblem that permits the control of all N-S parameters. To regularise theinferred the geometry, we use a viscous signed distance field (vSDF) as anauxiliary variable, which is given as the solution of a viscous Eikonalboundary value problem. We devise an algorithm that solves this inverseproblem, and numerically implement it using an adjoint-consistent stabilisedcut-cell finite element method. We then use this method to reconstruct magneticresonance velocimetry (flow-MRI) data of a 3D steady laminar flow through aphysical model of an aortic arch for two different Reynolds numbers andsignal-to-noise ratio (SNR) levels (low/high). We find that the method canaccurately i) reconstruct the low SNR data by filtering out the noise/artefactsand recovering flow features that are obscured by noise, and ii) reproduce thehigh SNR data without overfitting. Although the framework that we developapplies to 3D steady laminar flows in complex geometries, it readily extends totime-dependent laminar and Reynolds-averaged turbulent flows, as well asnon-Newtonian (e.g. viscoelastic) fluids.</description><author>Alexandros Kontogiannis, Scott V. Elgersma, Andrew J. Sederman, Matthew P. Juniper</author><pubDate>Wed, 26 Jun 2024 17:16:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18464v1</guid></item><item><title>Mean-Field Langevin Dynamics for Signed Measures via a Bilevel Approach</title><link>http://arxiv.org/abs/2406.17054v2</link><description>Mean-field Langevin dynamics (MLFD) is a class of interacting particlemethods that tackle convex optimization over probability measures on amanifold, which are scalable, versatile, and enjoy computational guarantees.However, some important problems -- such as risk minimization for infinitewidth two-layer neural networks, or sparse deconvolution -- are originallydefined over the set of signed, rather than probability, measures. In thispaper, we investigate how to extend the MFLD framework to convex optimizationproblems over signed measures. Among two known reductions from signed toprobability measures -- the lifting and the bilevel approaches -- we show thatthe bilevel reduction leads to stronger guarantees and faster rates (at theprice of a higher per-iteration complexity). In particular, we investigate theconvergence rate of MFLD applied to the bilevel reduction in the low-noiseregime and obtain two results. First, this dynamics is amenable to an annealingschedule, adapted from Suzuki et al. (2023), that results in improvedconvergence rates to a fixed multiplicative accuracy. Second, we investigatethe problem of learning a single neuron with the bilevel approach and obtainlocal exponential convergence rates that depend polynomially on the dimensionand noise level (to compare with the exponential dependence that would resultfrom prior analyses).</description><author>Guillaume Wang, Alireza Mousavi-Hosseini, Lénaïc Chizat</author><pubDate>Wed, 26 Jun 2024 17:12:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17054v2</guid></item><item><title>GaussianDreamerPro: Text to Manipulable 3D Gaussians with Highly Enhanced Quality</title><link>http://arxiv.org/abs/2406.18462v1</link><description>Recently, 3D Gaussian splatting (3D-GS) has achieved great success inreconstructing and rendering real-world scenes. To transfer the high renderingquality to generation tasks, a series of research works attempt to generate3D-Gaussian assets from text. However, the generated assets have not achievedthe same quality as those in reconstruction tasks. We observe that Gaussianstend to grow without control as the generation process may cause indeterminacy.Aiming at highly enhancing the generation quality, we propose a novel frameworknamed GaussianDreamerPro. The main idea is to bind Gaussians to reasonablegeometry, which evolves over the whole generation process. Along differentstages of our framework, both the geometry and appearance can be enrichedprogressively. The final output asset is constructed with 3D Gaussians bound tomesh, which shows significantly enhanced details and quality compared withprevious methods. Notably, the generated asset can also be seamlesslyintegrated into downstream manipulation pipelines, e.g. animation, composition,and simulation etc., greatly promoting its potential in wide applications.Demos are available at https://taoranyi.com/gaussiandreamerpro/.</description><author>Taoran Yi, Jiemin Fang, Zanwei Zhou, Junjie Wang, Guanjun Wu, Lingxi Xie, Xiaopeng Zhang, Wenyu Liu, Xinggang Wang, Qi Tian</author><pubDate>Wed, 26 Jun 2024 17:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18462v1</guid></item><item><title>Large Knowledge Model: Perspectives and Challenges</title><link>http://arxiv.org/abs/2312.02706v2</link><description>Humankind's understanding of the world is fundamentally linked to ourperception and cognition, with \emph{human languages} serving as one of themajor carriers of \emph{world knowledge}. In this vein, \emph{Large LanguageModels} (LLMs) like ChatGPT epitomize the pre-training of extensive,sequence-based world knowledge into neural networks, facilitating theprocessing and manipulation of this knowledge in a parametric space. Thisarticle explores large models through the lens of "knowledge". We initiallyinvestigate the role of symbolic knowledge such as Knowledge Graphs (KGs) inenhancing LLMs, covering aspects like knowledge-augmented language model,structure-inducing pre-training, knowledgeable prompts, structured CoT,knowledge editing, semantic tools for LLM and knowledgeable AI agents.Subsequently, we examine how LLMs can boost traditional symbolic knowledgebases, encompassing aspects like using LLM as KG builder and controller,structured knowledge pretraining, and LLM-enhanced symbolic reasoning.Considering the intricate nature of human knowledge, we advocate for thecreation of \emph{Large Knowledge Models} (LKM), specifically engineered tomanage diversified spectrum of knowledge structures. This promising undertakingwould entail several key challenges, such as disentangling knowledge base fromlanguage models, cognitive alignment with human knowledge, integration ofperception and cognition, and building large commonsense models for interactingwith physical world, among others. We finally propose a five-"A" principle todistinguish the concept of LKM.</description><author>Huajun Chen</author><pubDate>Wed, 26 Jun 2024 17:11:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02706v2</guid></item><item><title>Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation</title><link>http://arxiv.org/abs/2406.18460v1</link><description>Recently, various methods have been proposed to create open-domainconversational agents with Large Language Models (LLMs). These models are ableto answer user queries, but in a one-way Q&amp;A format rather than a trueconversation. Fine-tuning on particular datasets is the usual way to modifytheir style to increase conversational ability, but this is expensive andusually only available in a few languages. In this study, we explore role-playzero-shot prompting as an efficient and cost-effective solution for open-domainconversation, using capable multilingual LLMs (Beeching et al., 2023) trainedto obey instructions. We design a prompting system that, when combined with aninstruction-following model - here Vicuna (Chiang et al., 2023) - producesconversational agents that match and even surpass fine-tuned models in humanevaluation in French in two different tasks.</description><author>Ahmed Njifenjou, Virgile Sucal, Bassam Jabaian, Fabrice Lefèvre</author><pubDate>Wed, 26 Jun 2024 17:10:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18460v1</guid></item><item><title>DiffuseHigh: Training-free Progressive High-Resolution Image Synthesis through Structure Guidance</title><link>http://arxiv.org/abs/2406.18459v1</link><description>Recent surge in large-scale generative models has spurred the development ofvast fields in computer vision. In particular, text-to-image diffusion modelshave garnered widespread adoption across diverse domain due to their potentialfor high-fidelity image generation. Nonetheless, existing large-scale diffusionmodels are confined to generate images of up to 1K resolution, which is farfrom meeting the demands of contemporary commercial applications. Directlysampling higher-resolution images often yields results marred by artifacts suchas object repetition and distorted shapes. Addressing the aforementioned issuestypically necessitates training or fine-tuning models on higher resolutiondatasets. However, this undertaking poses a formidable challenge due to thedifficulty in collecting large-scale high-resolution contents and substantialcomputational resources. While several preceding works have proposedalternatives, they often fail to produce convincing results. In this work, weprobe the generative ability of diffusion models at higher resolution beyondits original capability and propose a novel progressive approach that fullyutilizes generated low-resolution image to guide the generation of higherresolution image. Our method obviates the need for additional training orfine-tuning which significantly lowers the burden of computational costs.Extensive experiments and results validate the efficiency and efficacy of ourmethod.</description><author>Younghyun Kim, Geunmin Hwang, Eunbyung Park</author><pubDate>Wed, 26 Jun 2024 17:10:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18459v1</guid></item><item><title>Boundary Detection Algorithm Inspired by Locally Linear Embedding</title><link>http://arxiv.org/abs/2406.18456v1</link><description>In the study of high-dimensional data, it is often assumed that the data setpossesses an underlying lower-dimensional structure. A practical model for thisstructure is an embedded compact manifold with boundary. Since the underlyingmanifold structure is typically unknown, identifying boundary points from thedata distributed on the manifold is crucial for various applications. In thiswork, we propose a method for detecting boundary points inspired by the widelyused locally linear embedding algorithm. We implement this method using twonearest neighborhood search schemes: the $\epsilon$-radius ball scheme and the$K$-nearest neighbor scheme. This algorithm incorporates the geometricinformation of the data structure, particularly through its close relation withthe local covariance matrix. We discuss the selection the key parameter andanalyze the algorithm through our exploration of the spectral properties of thelocal covariance matrix in both neighborhood search schemes. Furthermore, wedemonstrate the algorithm's performance with simulated examples.</description><author>Pei-Cheng Kuo, Nan Wu</author><pubDate>Wed, 26 Jun 2024 17:05:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18456v1</guid></item><item><title>MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate</title><link>http://arxiv.org/abs/2406.14711v2</link><description>Large Language Models (LLMs) have shown exceptional results on currentbenchmarks when working individually. The advancement in their capabilities,along with a reduction in parameter size and inference times, has facilitatedthe use of these models as agents, enabling interactions among multiple modelsto execute complex tasks. Such collaborations offer several advantages,including the use of specialized models (e.g. coding), improved confidencethrough multiple computations, and enhanced divergent thinking, leading to morediverse outputs. Thus, the collaborative use of language models is expected togrow significantly in the coming years. In this work, we evaluate the behaviorof a network of models collaborating through debate under the influence of anadversary. We introduce pertinent metrics to assess the adversary'seffectiveness, focusing on system accuracy and model agreement. Our findingshighlight the importance of a model's persuasive ability in influencing others.Additionally, we explore inference-time methods to generate more compellingarguments and evaluate the potential of prompt-based mitigation as a defensivestrategy.</description><author>Alfonso Amayuelas, Xianjun Yang, Antonis Antoniades, Wenyue Hua, Liangming Pan, William Wang</author><pubDate>Wed, 26 Jun 2024 17:05:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14711v2</guid></item><item><title>Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference</title><link>http://arxiv.org/abs/2406.18453v1</link><description>Humans can easily deduce the relative pose of an unseen object, withoutlabel/training, given only a single query-reference image pair. This isarguably achieved by incorporating (i) 3D/2.5D shape perception from a singleimage, (ii) render-and-compare simulation, and (iii) rich semantic cueawareness to furnish (coarse) reference-query correspondence. Existing methodsimplement (i) by a 3D CAD model or well-calibrated multiple images and (ii) bytraining a network on specific objects, which necessitate laboriousground-truth labeling and tedious training, potentially leading to challengesin generalization. Moreover, (iii) was less exploited in the paradigm of (ii),despite that the coarse correspondence from (iii) enhances the compare processby filtering out non-overlapped parts under substantial posedifferences/occlusions. Motivated by this, we propose a novel 3D generalizablerelative pose estimation method by elaborating (i) with a 2.5D shape from anRGB-D reference, (ii) with an off-the-shelf differentiable renderer, and (iii)with semantic cues from a pretrained model like DINOv2. Specifically, ourdifferentiable renderer takes the 2.5D rotatable mesh textured by the RGB andthe semantic maps (obtained by DINOv2 from the RGB input), then renders new RGBand semantic maps (with back-surface culling) under a novel rotated view. Therefinement loss comes from comparing the rendered RGB and semantic maps withthe query ones, back-propagating the gradients through the differentiablerenderer to refine the 3D relative pose. As a result, our method can be readilyapplied to unseen objects, given only a single RGB-D reference, withoutlabel/training. Extensive experiments on LineMOD, LM-O, and YCB-V show that ourtraining-free method significantly outperforms the SOTA supervised methods,especially under the rigorous Acc@5/10/15{\deg} metrics and the challengingcross-dataset settings.</description><author>Yuan Gao, Yajing Luo, Junhong Wang, Kui Jia, Gui-Song Xia</author><pubDate>Wed, 26 Jun 2024 17:01:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18453v1</guid></item><item><title>Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers</title><link>http://arxiv.org/abs/2406.18451v1</link><description>Despite extensive research on adversarial training strategies to improverobustness, the decisions of even the most robust deep learning models canstill be quite sensitive to imperceptible perturbations, creating serious riskswhen deploying them for high-stakes real-world applications. While detectingsuch cases may be critical, evaluating a model's vulnerability at aper-instance level using adversarial attacks is computationally too intensiveand unsuitable for real-time deployment scenarios. The input space margin isthe exact score to detect non-robust samples and is intractable for deep neuralnetworks. This paper introduces the concept of margin consistency -- a propertythat links the input space margins and the logit margins in robust models --for efficient detection of vulnerable samples. First, we establish that marginconsistency is a necessary and sufficient condition to use a model's logitmargin as a score for identifying non-robust samples. Next, throughcomprehensive empirical analysis of various robustly trained models on CIFAR10and CIFAR100 datasets, we show that they indicate strong margin consistencywith a strong correlation between their input space margins and the logitmargins. Then, we show that we can effectively use the logit margin toconfidently detect brittle decisions with such models and accurately estimaterobust accuracy on an arbitrarily large test set by estimating the inputmargins only on a small subset. Finally, we address cases where the model isnot sufficiently margin-consistent by learning a pseudo-margin from the featurerepresentation. Our findings highlight the potential of leveraging deeprepresentations to efficiently assess adversarial vulnerability in deploymentscenarios.</description><author>Jonas Ngnawé, Sabyasachi Sahoo, Yann Pequignot, Frédéric Precioso, Christian Gagné</author><pubDate>Wed, 26 Jun 2024 17:00:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18451v1</guid></item><item><title>Preference Elicitation for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2406.18450v1</link><description>Applying reinforcement learning (RL) to real-world problems is often madechallenging by the inability to interact with the environment and thedifficulty of designing reward functions. Offline RL addresses the firstchallenge by considering access to an offline dataset of environmentinteractions labeled by the reward function. In contrast, Preference-based RLdoes not assume access to the reward function and learns it from preferences,but typically requires an online interaction with the environment. We bridgethe gap between these frameworks by exploring efficient methods for acquiringpreference feedback in a fully offline setup. We propose Sim-OPRL, an offlinepreference-based reinforcement learning algorithm, which leverages a learnedenvironment model to elicit preference feedback on simulated rollouts. Drawingon insights from both the offline RL and the preference-based RL literature,our algorithm employs a pessimistic approach for out-of-distribution data, andan optimistic approach for acquiring informative preferences about the optimalpolicy. We provide theoretical guarantees regarding the sample complexity ofour approach, dependent on how well the offline data covers the optimal policy.Finally, we demonstrate the empirical performance of Sim-OPRL in differentenvironments.</description><author>Alizée Pace, Bernhard Schölkopf, Gunnar Rätsch, Giorgia Ramponi</author><pubDate>Wed, 26 Jun 2024 16:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18450v1</guid></item><item><title>ToM-LM: Delegating Theory of Mind Reasoning to External Symbolic Executors in Large Language Models</title><link>http://arxiv.org/abs/2404.15515v3</link><description>Theory of Mind (ToM) refers to the ability of individuals to attribute mentalstates to others. While Large Language Models (LLMs) have shown some promisewith ToM ability, they still struggle with complex ToM reasoning. Our approachleverages an external symbolic executor, specifically the SMCDEL model checker,and fine-tuning to improve the ToM reasoning ability of LLMs. In our approach,an LLM is first fine-tuned through pairs of natural language and symbolicformulation representation of ToM problems and is then instructed to generatethe symbolic formulation with a one-shot in-context example. The generatedsymbolic formulation is then executed by the SMCDEL model checker to performtransparent and verifiable ToM reasoning and give the final result. Wedemonstrate that our approach, ToM-LM, shows a significant improvement over allthe constructed baselines. Our study proposes a novel view about externalizinga particular component of ToM reasoning, mainly reasoning about beliefs, andsuggests generalizing it to other aspects of ToM reasoning.</description><author>Weizhi Tang, Vaishak Belle</author><pubDate>Wed, 26 Jun 2024 16:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15515v3</guid></item><item><title>Normalizing Flows for Conformal Regression</title><link>http://arxiv.org/abs/2406.03346v2</link><description>Conformal Prediction (CP) algorithms estimate the uncertainty of a predictionmodel by calibrating its outputs on labeled data. The same calibration schemeusually applies to any model and data without modifications. The obtainedprediction intervals are valid by construction but could be inefficient, i.e.unnecessarily big, if the prediction errors are not uniformly distributed overthe input space. We present a general scheme to localize the intervals by training thecalibration process. The standard prediction error is replaced by an optimizeddistance metric that depends explicitly on the object attributes. Learning theoptimal metric is equivalent to training a Normalizing Flow that acts on thejoint distribution of the errors and the inputs. Unlike the Error ReweightingCP algorithm of Papadopoulos et al. (2008), the framework allows estimating thegap between nominal and empirical conditional validity. The approach iscompatible with existing locally-adaptive CP strategies based on re-weightingthe calibration samples and applies to any point-prediction model withoutretraining.</description><author>Nicolo Colombo</author><pubDate>Wed, 26 Jun 2024 16:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03346v2</guid></item><item><title>Cascading Large Language Models for Salient Event Graph Generation</title><link>http://arxiv.org/abs/2406.18449v1</link><description>Generating event graphs from long documents is challenging due to theinherent complexity of multiple tasks involved such as detecting events,identifying their relationships, and reconciling unstructured input withstructured graphs. Recent studies typically consider all events with equalimportance, failing to distinguish salient events crucial for understandingnarratives. This paper presents CALLMSAE, a CAscading Large Language Modelframework for SAlient Event graph generation, which leverages the capabilitiesof LLMs and eliminates the need for costly human annotations. We first identifysalient events by prompting LLMs to generate summaries, from which salientevents are identified. Next, we develop an iterative code refinement promptingstrategy to generate event relation graphs, removing hallucinated relations andrecovering missing edges. Fine-tuning contextualised graph generation models onthe LLM-generated graphs outperforms the models trained on CAEVO-generateddata. Experimental results on a human-annotated test set show that the proposedmethod generates salient and more accurate graphs, outperforming competitivebaselines.</description><author>Xingwei Tan, Yuxiang Zhou, Gabriele Pergola, Yulan He</author><pubDate>Wed, 26 Jun 2024 16:53:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18449v1</guid></item><item><title>ICTSurF: Implicit Continuous-Time Survival Functions with Neural Networks</title><link>http://arxiv.org/abs/2312.05818v2</link><description>Survival analysis is a widely known method for predicting the likelihood ofan event over time. The challenge of dealing with censored samples stillremains. Traditional methods, such as the Cox Proportional Hazards (CPH) model,hinge on the limitations due to the strong assumptions of proportional hazardsand the predetermined relationships between covariates. The rise of modelsbased on deep neural networks (DNNs) has demonstrated enhanced effectiveness insurvival analysis. This research introduces the Implicit Continuous-TimeSurvival Function (ICTSurF), built on a continuous-time survival model, andconstructs survival distribution through implicit representation. As a result,our method is capable of accepting inputs in continuous-time space andproducing survival probabilities in continuous-time space, independent ofneural network architecture. Comparative assessments with existing methodsunderscore the high competitiveness of our proposed approach. Ourimplementation of ICTSurF is available at https://github.com/44REAM/ICTSurF.</description><author>Chanon Puttanawarut, Panu Looareesuwan, Romen Samuel Wabina, Prut Saowaprut</author><pubDate>Wed, 26 Jun 2024 16:51:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05818v2</guid></item><item><title>An Autotuning-based Optimization Framework for Mixed-kernel SVM Classifications in Smart Pixel Datasets and Heterojunction Transistors</title><link>http://arxiv.org/abs/2406.18445v1</link><description>Support Vector Machine (SVM) is a state-of-the-art classification methodwidely used in science and engineering due to its high accuracy, its ability todeal with high dimensional data, and its flexibility in modeling diversesources of data. In this paper, we propose an autotuning-based optimizationframework to quantify the ranges of hyperparameters in SVMs to identify theiroptimal choices, and apply the framework to two SVMs with the mixed-kernelbetween Sigmoid and Gaussian kernels for smart pixel datasets in high energyphysics (HEP) and mixed-kernel heterojunction transistors (MKH). Ourexperimental results show that the optimal selection of hyperparameters in theSVMs and the kernels greatly varies for different applications and datasets,and choosing their optimal choices is critical for a high classificationaccuracy of the mixed kernel SVMs. Uninformed choices of hyperparameters C andcoef0 in the mixed-kernel SVMs result in severely low accuracy, and theproposed framework effectively quantifies the proper ranges for thehyperparameters in the SVMs to identify their optimal choices to achieve thehighest accuracy 94.6\% for the HEP application and the highest averageaccuracy 97.2\% with far less tuning time for the MKH application.</description><author>Xingfu Wu, Tupendra Oli, ustin H. Qian, Valerie Taylor, Mark C. Hersam, Vinod K. Sangwan</author><pubDate>Wed, 26 Jun 2024 16:50:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18445v1</guid></item><item><title>DiarizationLM: Speaker Diarization Post-Processing with Large Language Models</title><link>http://arxiv.org/abs/2401.03506v6</link><description>In this paper, we introduce DiarizationLM, a framework to leverage largelanguage models (LLM) to post-process the outputs from a speaker diarizationsystem. Various goals can be achieved with the proposed framework, such asimproving the readability of the diarized transcript, or reducing the worddiarization error rate (WDER). In this framework, the outputs of the automaticspeech recognition (ASR) and speaker diarization systems are represented as acompact textual format, which is included in the prompt to an optionallyfinetuned LLM. The outputs of the LLM can be used as the refined diarizationresults with the desired enhancement. As a post-processing step, this frameworkcan be easily applied to any off-the-shelf ASR and speaker diarization systemswithout retraining existing components. Our experiments show that a finetunedPaLM 2-S model can reduce the WDER by rel. 55.5% on the Fisher telephoneconversation dataset, and rel. 44.9% on the Callhome English dataset.</description><author>Quan Wang, Yiling Huang, Guanlong Zhao, Evan Clark, Wei Xia, Hank Liao</author><pubDate>Wed, 26 Jun 2024 16:49:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03506v6</guid></item><item><title>Unveiling the Unknown: Conditional Evidence Decoupling for Unknown Rejection</title><link>http://arxiv.org/abs/2406.18443v1</link><description>In this paper, we focus on training an open-set object detector under thecondition of scarce training samples, which should distinguish the known andunknown categories. Under this challenging scenario, the decision boundaries ofunknowns are difficult to learn and often ambiguous. To mitigate this issue, wedevelop a novel open-set object detection framework, which delves intoconditional evidence decoupling for the unknown rejection. Specifically, weselect pseudo-unknown samples by leveraging the discrepancy in attributiongradients between known and unknown classes, alleviating the inadequate unknowndistribution coverage of training data. Subsequently, we propose a ConditionalEvidence Decoupling Loss (CEDL) based on Evidential Deep Learning (EDL) theory,which decouples known and unknown properties in pseudo-unknown samples to learndistinct knowledge, enhancing separability between knowns and unknowns.Additionally, we propose an Abnormality Calibration Loss (ACL), which serves asa regularization term to adjust the output probability distribution,establishing robust decision boundaries for the unknown rejection. Our methodhas achieved the superiority performance over previous state-of-the-artapproaches, improving the mean recall of unknown class by 7.24% across allshots in VOC10-5-5 dataset settings and 1.38% in VOC-COCO dataset settings. Thecode is available via https://github.com/zjzwzw/CED-FOOD.</description><author>Zhaowei Wu, Binyi Su, Hua Zhang, Zhong Zhou</author><pubDate>Wed, 26 Jun 2024 16:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18443v1</guid></item><item><title>Towards Arbitrary-Scale Histopathology Image Super-resolution: An Efficient Dual-branch Framework via Implicit Self-texture Enhancement</title><link>http://arxiv.org/abs/2401.15613v3</link><description>High-quality whole-slide scanners are expensive, complex, and time-consuming,thus limiting the acquisition and utilization of high-resolution pathologywhole-slide images in daily clinical work. Deep learning-based single-imagesuper-resolution techniques are an effective way to solve this problem bysynthesizing high-resolution images from low-resolution ones. However, theexisting super-resolution models applied in pathology images can only work infixed integer magnifications, significantly decreasing their applicability.Though methods based on implicit neural representation have shown promisingresults in arbitrary-scale super-resolution of natural images, applying themdirectly to pathology images is inadequate because they have uniquefine-grained image textures different from natural images. Thus, we propose anImplicit Self-Texture Enhancement-based dual-branch framework (ISTE) forarbitrary-scale super-resolution of pathology images to address this challenge.ISTE contains a pixel learning branch and a texture learning branch, whichfirst learn pixel features and texture features, respectively. Then, we designa two-stage texture enhancement strategy to fuse the features from the twobranches to obtain the super-resolution results, where the first stage isfeature-based texture enhancement, and the second stage is spatial-domain-basedtexture enhancement. Extensive experiments on three public datasets show thatISTE outperforms existing fixed-scale and arbitrary-scale algorithms atmultiple magnifications and helps to improve downstream task performance. Tothe best of our knowledge, this is the first work to achieve arbitrary-scalesuper-resolution in pathology images. Codes will be available.</description><author>Minghong Duan, Linhao Qu, Zhiwei Yang, Manning Wang, Chenxi Zhang, Zhijian Song</author><pubDate>Wed, 26 Jun 2024 16:47:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15613v3</guid></item><item><title>RL in Latent MDPs is Tractable: Online Guarantees via Off-Policy Evaluation</title><link>http://arxiv.org/abs/2406.01389v2</link><description>In many real-world decision problems there is partially observed, hidden orlatent information that remains fixed throughout an interaction. Such decisionproblems can be modeled as Latent Markov Decision Processes (LMDPs), where alatent variable is selected at the beginning of an interaction and is notdisclosed to the agent. In the last decade, there has been significant progressin solving LMDPs under different structural assumptions. However, for generalLMDPs, there is no known learning algorithm that provably matches the existinglower bound (Kwon et al., 2021). We introduce the first sample-efficientalgorithm for LMDPs without any additional structural assumptions. Our resultbuilds off a new perspective on the role of off-policy evaluation guaranteesand coverage coefficients in LMDPs, a perspective, that has been overlooked inthe context of exploration in partially observed environments. Specifically, weestablish a novel off-policy evaluation lemma and introduce a new coveragecoefficient for LMDPs. Then, we show how these can be used to derivenear-optimal guarantees of an optimistic exploration algorithm. These results,we believe, can be valuable for a wide range of interactive learning problemsbeyond LMDPs, and especially, for partially observed environments.</description><author>Jeongyeol Kwon, Shie Mannor, Constantine Caramanis, Yonathan Efroni</author><pubDate>Wed, 26 Jun 2024 16:42:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01389v2</guid></item><item><title>An unsupervised approach towards promptable defect segmentation in laser-based additive manufacturing by Segment Anything</title><link>http://arxiv.org/abs/2312.04063v3</link><description>Foundation models are currently driving a paradigm shift in computer visiontasks for various fields including biology, astronomy, and robotics amongothers, leveraging user-generated prompts to enhance their performance. In theLaser Additive Manufacturing (LAM) domain, accurate image-based defectsegmentation is imperative to ensure product quality and facilitate real-timeprocess control. However, such tasks are often characterized by multiplechallenges including the absence of labels and the requirement for low latencyinference among others. Porosity is a very common defect in LAM due to lack offusion, entrapped gas, and keyholes, directly affecting mechanical propertieslike tensile strength, stiffness, and hardness, thereby compromising thequality of the final product. To address these issues, we construct a frameworkfor image segmentation using a state-of-the-art Vision Transformer (ViT) basedFoundation model (Segment Anything Model) with a novel multi-point promptgeneration scheme using unsupervised clustering. Utilizing our framework weperform porosity segmentation in a case study of laser-based powder bed fusion(L-PBF) and obtain high accuracy without using any labeled data to guide theprompt tuning process. By capitalizing on lightweight foundation modelinference combined with unsupervised prompt generation, we envisionconstructing a real-time anomaly detection pipeline that could revolutionizecurrent laser additive manufacturing processes, thereby facilitating the shifttowards Industry 4.0 and promoting defect-free production along withoperational efficiency.</description><author>Israt Zarin Era, Imtiaz Ahmed, Zhichao Liu, Srinjoy Das</author><pubDate>Wed, 26 Jun 2024 16:41:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04063v3</guid></item><item><title>InstantGroup: Instant Template Generation for Scalable Group of Brain MRI Registration</title><link>http://arxiv.org/abs/2211.05622v2</link><description>Template generation is a critical step in groupwise image registration, whichinvolves aligning a group of subjects into a common space. While existingmethods can generate high-quality template images, they often incur substantialtime costs or are limited by fixed group scales. In this paper, we presentInstantGroup, an efficient groupwise template generation framework based onvariational autoencoder (VAE) models that leverage latent representations'arithmetic properties, enabling scalability to groups of any size. InstantGroupfeatures a Dual VAEs backbone with shared-weight twin networks to handle pairsof inputs and incorporates a Displacement Inversion Module (DIM) to maintaintemplate unbiasedness and a Subject-Template Alignment Module (STAM) to improvetemplate quality and registration accuracy. Experiments on 3D brain MRI scansfrom the OASIS and ADNI datasets reveal that InstantGroup dramatically reducesruntime, generating templates within seconds for various group sizes whilemaintaining superior performance compared to state-of-the-art baselines onquantitative metrics, including unbiasedness and registration accuracy.</description><author>Ziyi He, Albert C. S. Chung</author><pubDate>Wed, 26 Jun 2024 16:34:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.05622v2</guid></item><item><title>Facial Image Feature Analysis and its Specialization for Fréchet Distance and Neighborhoods</title><link>http://arxiv.org/abs/2406.18430v1</link><description>Assessing distances between images and image datasets is a fundamental taskin vision-based research. It is a challenging open problem in the literatureand despite the criticism it receives, the most ubiquitous method remains theFr\'echet Inception Distance. The Inception network is trained on a specificlabeled dataset, ImageNet, which has caused the core of its criticism in themost recent research. Improvements were shown by moving to self-supervisionlearning over ImageNet, leaving the training data domain as an open question.We make that last leap and provide the first analysis on domain-specificfeature training and its effects on feature distance, on the widely-researchedfacial image domain. We provide our findings and insights on this domainspecialization for Fr\'echet distance and image neighborhoods, supported byextensive experiments and in-depth user studies.</description><author>Doruk Cetin, Benedikt Schesch, Petar Stamenkovic, Niko Benjamin Huber, Fabio Zünd, Majed El Helou</author><pubDate>Wed, 26 Jun 2024 16:27:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18430v1</guid></item><item><title>Benchmarking mortality risk prediction from electrocardiograms</title><link>http://arxiv.org/abs/2406.17002v2</link><description>Several recent high-impact studies leverage large hospital-ownedelectrocardiographic (ECG) databases to model and predict patient mortality.MIMIC-IV, released September 2023, is the first comparable public dataset andincludes 800,000 ECGs from a U.S. hospital system. Previously, the largestpublic ECG dataset was Code-15, containing 345,000 ECGs collected duringroutine care in Brazil. These datasets now provide an excellent resource for abroader audience to explore ECG survival modeling. Here, we benchmark survivalmodel performance on Code-15 and MIMIC-IV with two neural networkarchitectures, compare four deep survival modeling approaches to Coxregressions trained on classifier outputs, and evaluate performance at one toten years. Our results yield AUROC and concordance scores comparable to pastwork (circa 0.8) and reasonable AUPRC scores (MIMIC-IV: 0.4-0.5, Code-15:0.05-0.13) considering the fraction of ECG samples linked to a mortality(MIMIC-IV: 27\%, Code-15: 4\%). When evaluating models on the opposite dataset,AUROC and concordance values drop by 0.1-0.15, which may be due to cohortdifferences. All code and results are made public.</description><author>Platon Lukyanenko, Joshua Mayourian, Mingxuan Liu, John K. Triedman, Sunil J. Ghelani, William G. La Cava</author><pubDate>Wed, 26 Jun 2024 16:27:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17002v2</guid></item><item><title>Cultural Bias and Cultural Alignment of Large Language Models</title><link>http://arxiv.org/abs/2311.14096v2</link><description>Culture fundamentally shapes people's reasoning, behavior, and communication.As people increasingly use generative artificial intelligence (AI) to expediteand automate personal and professional tasks, cultural values embedded in AImodels may bias people's authentic expression and contribute to the dominanceof certain cultures. We conduct a disaggregated evaluation of cultural bias forfive widely used large language models (OpenAI's GPT-4o/4-turbo/4/3.5-turbo/3)by comparing the models' responses to nationally representative survey data.All models exhibit cultural values resembling English-speaking and ProtestantEuropean countries. We test cultural prompting as a control strategy toincrease cultural alignment for each country/territory. For recent models(GPT-4, 4-turbo, 4o), this improves the cultural alignment of the models'output for 71-81% of countries and territories. We suggest using culturalprompting and ongoing evaluation to reduce cultural bias in the output ofgenerative AI.</description><author>Yan Tao, Olga Viberg, Ryan S. Baker, Rene F. Kizilcec</author><pubDate>Wed, 26 Jun 2024 16:26:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14096v2</guid></item><item><title>VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation</title><link>http://arxiv.org/abs/2406.17681v2</link><description>As large language models achieve impressive scores on traditional benchmarks,an increasing number of researchers are becoming concerned about benchmark dataleakage during pre-training, commonly known as the data contamination problem.To ensure fair evaluation, recent benchmarks release only the training andvalidation sets, keeping the test set labels closed-source. They require anyonewishing to evaluate his language model to submit the model's predictions forcentralized processing and then publish the model's result on theirleaderboard. However, this submission process is inefficient and preventseffective error analysis. To address this issue, we propose to variabilizebenchmarks and evaluate language models dynamically. Specifically, we extractvariables from each test case and define a value range for each variable. Foreach evaluation, we sample new values from these value ranges to create uniquetest cases, thus ensuring a fresh evaluation each time. We applied thisvariable perturbation method to four datasets: GSM8K, ARC, CommonsenseQA, andTruthfulQA, which cover mathematical generation and multiple-choice tasks. Ourexperimental results demonstrate that this approach provides a more accurateassessment of the true capabilities of language models, effectively mitigatingthe contamination problem.</description><author>Kun Qian, Shunji Wan, Claudia Tang, Youzhi Wang, Xuanming Zhang, Maximillian Chen, Zhou Yu</author><pubDate>Wed, 26 Jun 2024 16:21:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17681v2</guid></item><item><title>Graph Neural Networks for Emulation of Finite-Element Ice Dynamics in Greenland and Antarctic Ice Sheets</title><link>http://arxiv.org/abs/2406.18423v1</link><description>Although numerical models provide accurate solutions for ice sheet dynamicsbased on physics laws, they accompany intensified computational demands tosolve partial differential equations. In recent years, convolutional neuralnetworks (CNNs) have been widely used as statistical emulators for thosenumerical models. However, since CNNs operate on regular grids, they cannotrepresent the refined meshes and computational efficiency of finite-elementnumerical models. Therefore, instead of CNNs, this study adopts an equivariantgraph convolutional network (EGCN) as an emulator for the ice sheet dynamicsmodeling. EGCN reproduces ice thickness and velocity changes in the HelheimGlacier, Greenland, and Pine Island Glacier, Antarctica, with 260 times and 44times faster computation time, respectively. Compared to the traditional CNNand graph convolutional network, EGCN shows outstanding accuracy in thicknessprediction near fast ice streams by preserving the equivariance to thetranslation and rotation of graphs.</description><author>Younghyun Koo, Maryam Rahnemoonfar</author><pubDate>Wed, 26 Jun 2024 16:18:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18423v1</guid></item><item><title>Repeat and Concatenate: 2D to 3D Image Translation with 3D to 3D Generative Modeling</title><link>http://arxiv.org/abs/2406.18422v1</link><description>This paper investigates a 2D to 3D image translation method with astraightforward technique, enabling correlated 2D X-ray to 3D CT-likereconstruction. We observe that existing approaches, which integrateinformation across multiple 2D views in the latent space, lose valuable signalinformation during latent encoding. Instead, we simply repeat and concatenatethe 2D views into higher-channel 3D volumes and approach the 3D reconstructionchallenge as a straightforward 3D to 3D generative modeling problem,sidestepping several complex modeling issues. This method enables thereconstructed 3D volume to retain valuable information from the 2D inputs,which are passed between channel states in a Swin UNETR backbone. Our approachapplies neural optimal transport, which is fast and stable to train,effectively integrating signal information across multiple views without therequirement for precise alignment; it produces non-collapsed reconstructionsthat are highly faithful to the 2D views, even after limited training. Wedemonstrate correlated results, both qualitatively and quantitatively, havingtrained our model on a single dataset and evaluated its generalization abilityacross six datasets, including out-of-distribution samples.</description><author>Abril Corona-Figueroa, Hubert P. H. Shum, Chris G. Willcocks</author><pubDate>Wed, 26 Jun 2024 16:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18422v1</guid></item><item><title>Mixture of Experts in a Mixture of RL settings</title><link>http://arxiv.org/abs/2406.18420v1</link><description>Mixtures of Experts (MoEs) have gained prominence in (self-)supervisedlearning due to their enhanced inference efficiency, adaptability todistributed training, and modularity. Previous research has illustrated thatMoEs can significantly boost Deep Reinforcement Learning (DRL) performance byexpanding the network's parameter count while reducing dormant neurons, therebyenhancing the model's learning capacity and ability to deal withnon-stationarity. In this work, we shed more light on MoEs' ability to dealwith non-stationarity and investigate MoEs in DRL settings with "amplified"non-stationarity via multi-task training, providing further evidence that MoEsimprove learning capacity. In contrast to previous work, our multi-task resultsallow us to better understand the underlying causes for the beneficial effectof MoE in DRL training, the impact of the various MoE components, and insightsinto how best to incorporate them in actor-critic-based DRL networks. Finally,we also confirm results from previous work.</description><author>Timon Willi, Johan Obando-Ceron, Jakob Foerster, Karolina Dziugaite, Pablo Samuel Castro</author><pubDate>Wed, 26 Jun 2024 16:15:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18420v1</guid></item><item><title>Differential error feedback for communication-efficient decentralized learning</title><link>http://arxiv.org/abs/2406.18418v1</link><description>Communication-constrained algorithms for decentralized learning andoptimization rely on local updates coupled with the exchange of compressedsignals. In this context, differential quantization is an effective techniqueto mitigate the negative impact of compression by leveraging correlationsbetween successive iterates. In addition, the use of error feedback, whichconsists of incorporating the compression error into subsequent steps, is apowerful mechanism to compensate for the bias caused by the compression. Undererror feedback, performance guarantees in the literature have so far focused onalgorithms employing a fusion center or a special class of contractivecompressors that cannot be implemented with a finite number of bits. In thiswork, we propose a new decentralized communication-efficient learning approachthat blends differential quantization with error feedback. The approach isspecifically tailored for decentralized learning problems where agents haveindividual risk functions to minimize subject to subspace constraints thatrequire the minimizers across the network to lie in low-dimensional subspaces.This constrained formulation includes consensus or single-task optimization asspecial cases, and allows for more general task relatedness models such asmultitask smoothness and coupled optimization. We show that, under some generalconditions on the compression noise, and for sufficiently small step-sizes$\mu$, the resulting communication-efficient strategy is stable both in termsof mean-square error and average bit rate: by reducing $\mu$, it is possible tokeep the estimation errors small (on the order of $\mu$) without increasingindefinitely the bit rate as $\mu\rightarrow 0$. The results establish that, inthe small step-size regime and with a finite number of bits, it is possible toattain the performance achievable in the absence of compression.</description><author>Roula Nassif, Stefan Vlaski, Marco Carpentiero, Vincenzo Matta, Ali H. Sayed</author><pubDate>Wed, 26 Jun 2024 16:11:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18418v1</guid></item><item><title>Towards diffusion models for large-scale sea-ice modelling</title><link>http://arxiv.org/abs/2406.18417v1</link><description>We make the first steps towards diffusion models for unconditional generationof multivariate and Arctic-wide sea-ice states. While targeting to reduce thecomputational costs by diffusion in latent space, latent diffusion models alsooffer the possibility to integrate physical knowledge into the generationprocess. We tailor latent diffusion models to sea-ice physics with a censoredGaussian distribution in data space to generate data that follows the physicalbounds of the modelled variables. Our latent diffusion models reach similarscores as the diffusion model trained in data space, but they smooth thegenerated fields as caused by the latent mapping. While enforcing physicalbounds cannot reduce the smoothing, it improves the representation of themarginal ice zone. Therefore, for large-scale Earth system modelling, latentdiffusion models can have many advantages compared to diffusion in data spaceif the significant barrier of smoothing can be resolved.</description><author>Tobias Sebastian Finn, Charlotte Durand, Alban Farchi, Marc Bocquet, Julien Brajard</author><pubDate>Wed, 26 Jun 2024 16:11:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18417v1</guid></item><item><title>BiTrack: Bidirectional Offline 3D Multi-Object Tracking Using Camera-LiDAR Data</title><link>http://arxiv.org/abs/2406.18414v1</link><description>Compared with real-time multi-object tracking (MOT), offline multi-objecttracking (OMOT) has the advantages to perform 2D-3D detection fusion, erroneouslink correction, and full track optimization but has to deal with thechallenges from bounding box misalignment and track evaluation, editing, andrefinement. This paper proposes "BiTrack", a 3D OMOT framework that includesmodules of 2D-3D detection fusion, initial trajectory generation, andbidirectional trajectory re-optimization to achieve optimal tracking resultsfrom camera-LiDAR data. The novelty of this paper includes threefold: (1)development of a point-level object registration technique that employs adensity-based similarity metric to achieve accurate fusion of 2D-3D detectionresults; (2) development of a set of data association and track managementskills that utilizes a vertex-based similarity metric as well as false alarmrejection and track recovery mechanisms to generate reliable bidirectionalobject trajectories; (3) development of a trajectory re-optimization schemethat re-organizes track fragments of different fidelities in a greedy fashion,as well as refines each trajectory with completion and smoothing techniques.The experiment results on the KITTI dataset demonstrate that BiTrack achievesthe state-of-the-art performance for 3D OMOT tasks in terms of accuracy andefficiency.</description><author>Kemiao Huang, Meiying Zhang, Qi Hao</author><pubDate>Wed, 26 Jun 2024 16:09:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18414v1</guid></item><item><title>Active Preference Inference using Language Models and Probabilistic Reasoning</title><link>http://arxiv.org/abs/2312.12009v2</link><description>Actively inferring user preferences, for example by asking good questions, isimportant for any human-facing decision-making system. Active inference allowssuch systems to adapt and personalize themselves to nuanced individualpreferences. To enable this ability for instruction-tuned large language models(LLMs), one may prompt them to ask users questions to infer their preferences,transforming the language models into more robust, interactive systems.However, out of the box, these models are not efficient at extractingpreferences: the questions they generate are not informative, requiring a highnumber of user interactions and impeding the usability of the downstreamsystem. In this work, we introduce an inference-time algorithm that helps LLMsquickly infer preferences by using more informative questions. Our algorithmuses a probabilistic model whose conditional distributions are defined byprompting an LLM, and returns questions that optimize expected entropy andexpected model change. Results in a simplified interactive web shopping settingwith real product items show that an LLM equipped with our entropy reductionalgorithm outperforms baselines with the same underlying LLM on taskperformance while using fewer user interactions.</description><author>Wasu Top Piriyakulkij, Volodymyr Kuleshov, Kevin Ellis</author><pubDate>Wed, 26 Jun 2024 16:00:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12009v2</guid></item><item><title>Efficient Low-rank Identification via Accelerated Iteratively Reweighted Nuclear Norm Minimization</title><link>http://arxiv.org/abs/2406.15713v2</link><description>This paper considers the problem of minimizing the sum of a smooth functionand the Schatten-$p$ norm of the matrix. Our contribution involves proposingaccelerated iteratively reweighted nuclear norm methods designed for solvingthe nonconvex low-rank minimization problem. Two major novelties characterizeour approach. Firstly, the proposed method possesses a rank identificationproperty, enabling the provable identification of the "correct" rank of thestationary point within a finite number of iterations. Secondly, we introducean adaptive updating strategy for smoothing parameters. This strategyautomatically fixes parameters associated with zero singular values asconstants upon detecting the "correct" rank while quickly driving the rest ofthe parameters to zero. This adaptive behavior transforms the algorithm intoone that effectively solves smooth problems after a few iterations, setting ourwork apart from existing iteratively reweighted methods for low-rankoptimization. We prove the global convergence of the proposed algorithm,guaranteeing that every limit point of the iterates is a critical point.Furthermore, a local convergence rate analysis is provided under theKurdyka-{\L}ojasiewicz property. We conduct numerical experiments using bothsynthetic and real data to showcase our algorithm's efficiency and superiorityover existing methods.</description><author>Hao Wang, Ye Wang, Xiangyu Yang</author><pubDate>Wed, 26 Jun 2024 16:00:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15713v2</guid></item><item><title>OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?</title><link>http://arxiv.org/abs/2406.16772v2</link><description>In this report, we pose the following question: Who is the most intelligentAI model to date, as measured by the OlympicArena (an Olympic-level,multi-discipline, multi-modal benchmark for superintelligent AI)? Wespecifically focus on the most recently released models: Claude-3.5-Sonnet,Gemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympicmedal Table approach to rank AI models based on their comprehensive performanceacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnetshows highly competitive overall performance over GPT-4o, even surpassingGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)Gemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o andClaude-3.5-Sonnet, but with a clear performance gap between them. (3) Theperformance of AI models from the open-source community significantly lagsbehind these proprietary models. (4) The performance of these models on thisbenchmark has been less than satisfactory, indicating that we still have a longway to go before achieving superintelligence. We remain committed tocontinuously tracking and evaluating the performance of the latest powerfulmodels on this benchmark (available athttps://github.com/GAIR-NLP/OlympicArena).</description><author>Zhen Huang, Zengzhi Wang, Shijie Xia, Pengfei Liu</author><pubDate>Wed, 26 Jun 2024 16:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16772v2</guid></item><item><title>An Information Theoretic Perspective on Conformal Prediction</title><link>http://arxiv.org/abs/2405.02140v2</link><description>Conformal Prediction (CP) is a distribution-free uncertainty estimationframework that constructs prediction sets guaranteed to contain the true answerwith a user-specified probability. Intuitively, the size of the prediction setencodes a general notion of uncertainty, with larger sets associated withhigher degrees of uncertainty. In this work, we leverage information theory toconnect conformal prediction to other notions of uncertainty. More precisely,we prove three different ways to upper bound the intrinsic uncertainty, asdescribed by the conditional entropy of the target variable given the inputs,by combining CP with information theoretical inequalities. Moreover, wedemonstrate two direct and useful applications of such connection betweenconformal prediction and information theory: (i) more principled and effectiveconformal training objectives that generalize previous approaches and enableend-to-end training of machine learning models from scratch, and (ii) a naturalmechanism to incorporate side information into conformal prediction. Weempirically validate both applications in centralized and federated learningsettings, showing our theoretical results translate to lower inefficiency(average prediction set size) for popular CP methods.</description><author>Alvaro H. C. Correia, Fabio Valerio Massoli, Christos Louizos, Arash Behboodi</author><pubDate>Wed, 26 Jun 2024 15:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02140v2</guid></item><item><title>IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons</title><link>http://arxiv.org/abs/2406.18406v1</link><description>It is widely acknowledged that large language models (LLMs) encode a vastreservoir of knowledge after being trained on mass data. Recent studiesdisclose knowledge conflicts in LLM generation, wherein outdated or incorrectparametric knowledge (i.e., encoded knowledge) contradicts new knowledgeprovided in the context. To mitigate such knowledge conflicts, we propose anovel framework, IRCAN (Identifying and Reweighting Context-Aware Neurons) tocapitalize on neurons that are crucial in processing contextual cues.Specifically, IRCAN first identifies neurons that significantly contribute tocontext processing, utilizing a context-aware attribution score derived fromintegrated gradients. Subsequently, the identified context-aware neurons arestrengthened via reweighting. In doing so, we steer LLMs to generatecontext-sensitive outputs with respect to the new knowledge provided in thecontext. Extensive experiments conducted across a variety of models and tasksdemonstrate that IRCAN not only achieves remarkable improvements in handlingknowledge conflicts but also offers a scalable, plug-andplay solution that canbe integrated seamlessly with existing models.</description><author>Dan Shi, Renren Jin, Tianhao Shen, Weilong Dong, Xinwei Wu, Deyi Xiong</author><pubDate>Wed, 26 Jun 2024 15:57:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18406v1</guid></item><item><title>LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks</title><link>http://arxiv.org/abs/2406.18403v1</link><description>There is an increasing trend towards evaluating NLP models with LLM-generatedjudgments instead of human judgments. In the absence of a comparison againsthuman data, this raises concerns about the validity of these evaluations; incase they are conducted with proprietary models, this also raises concerns overreproducibility. We provide JUDGE-BENCH, a collection of 20 NLP datasets withhuman annotations, and comprehensively evaluate 11 current LLMs, covering bothopen-weight and proprietary models, for their ability to replicate theannotations. Our evaluations show that each LLM exhibits a large varianceacross datasets in its correlation to human judgments. We conclude that LLMsare not yet ready to systematically replace human judges in NLP.</description><author>Anna Bavaresco, Raffaella Bernardi, Leonardo Bertolazzi, Desmond Elliott, Raquel Fernández, Albert Gatt, Esam Ghaleb, Mario Giulianelli, Michael Hanna, Alexander Koller, André F. T. Martins, Philipp Mondorf, Vera Neplenbroek, Sandro Pezzelle, Barbara Plank, David Schlangen, Alessandro Suglia, Aditya K Surikuchi, Ece Takmaz, Alberto Testoni</author><pubDate>Wed, 26 Jun 2024 15:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18403v1</guid></item><item><title>MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation and Fine-grained Classification</title><link>http://arxiv.org/abs/2404.05091v2</link><description>To advance the evaluation of multimodal math reasoning in large multimodalmodels (LMMs), this paper introduces a novel benchmark, MM-MATH. MM-MATHconsists of 5,929 open-ended middle school math problems with visual contexts,with fine-grained classification across difficulty, grade level, and knowledgepoints. Unlike existing benchmarks relying on binary answer comparison, MM-MATHincorporates both outcome and process evaluations. Process evaluation employsLMM-as-a-judge to automatically analyze solution steps, identifying andcategorizing errors into specific error types. Extensive evaluation of tenmodels on MM-MATH reveals significant challenges for existing LMMs,highlighting their limited utilization of visual information and struggles withhigher-difficulty problems. The best-performing model achieves only 31%accuracy on MM-MATH, compared to 82% for humans. This highlights thechallenging nature of our benchmark for existing models and the significant gapbetween the multimodal reasoning capabilities of current models and humans. Ourprocess evaluation reveals that diagram misinterpretation is the most commonerror, accounting for more than half of the total error cases, underscoring theneed for improved image comprehension in multimodal reasoning.</description><author>Kai Sun, Yushi Bai, Ji Qi, Lei Hou, Juanzi Li</author><pubDate>Wed, 26 Jun 2024 15:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05091v2</guid></item><item><title>Do LLMs dream of elephants (when told not to)? Latent concept association and associative memory in transformers</title><link>http://arxiv.org/abs/2406.18400v1</link><description>Large Language Models (LLMs) have the capacity to store and recall facts.Through experimentation with open-source models, we observe that this abilityto retrieve facts can be easily manipulated by changing contexts, even withoutaltering their factual meanings. These findings highlight that LLMs mightbehave like an associative memory model where certain tokens in the contextsserve as clues to retrieving facts. We mathematically explore this property bystudying how transformers, the building blocks of LLMs, can complete suchmemory tasks. We study a simple latent concept association problem with aone-layer transformer and we show theoretically and empirically that thetransformer gathers information using self-attention and uses the value matrixfor associative memory.</description><author>Yibo Jiang, Goutham Rajendran, Pradeep Ravikumar, Bryon Aragam</author><pubDate>Wed, 26 Jun 2024 15:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18400v1</guid></item><item><title>Second Maximum of a Gaussian Random Field and Exact (t-)Spacing test</title><link>http://arxiv.org/abs/2406.18397v1</link><description>In this article, we introduce the novel concept of the second maximum of aGaussian random field on a Riemannian submanifold. This second maximum servesas a powerful tool for characterizing the distribution of the maximum. Byutilizing an ad-hoc Kac Rice formula, we derive the explicit form of themaximum's distribution, conditioned on the second maximum and some regressedcomponent of the Riemannian Hessian. This approach results in an exact test,based on the evaluation of spacing between these maxima, which we refer to asthe spacing test. We investigate the applicability of this test in detecting sparsealternatives within Gaussian symmetric tensors, continuous sparsedeconvolution, and two-layered neural networks with smooth rectifiers. Ourtheoretical results are supported by numerical experiments, which illustratethe calibration and power of the proposed tests. More generally, this test canbe applied to any Gaussian random field on a Riemannian manifold, and weprovide a general framework for the application of the spacing test incontinuous sparse kernel regression. Furthermore, when the variance-covariance function of the Gaussian randomfield is known up to a scaling factor, we derive an exact Studentized versionof our test, coined the $t$-spacing test. This test is perfectly calibratedunder the null hypothesis and has high power for detecting sparse alternatives.</description><author>Azaïs Jean-Marc, Dalmao Federico, De Castro Yohann</author><pubDate>Wed, 26 Jun 2024 15:44:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18397v1</guid></item><item><title>DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution</title><link>http://arxiv.org/abs/2405.17357v3</link><description>Fine-tuning large-scale pre-trained models is inherently a resource-intensivetask. While it can enhance the capabilities of the model, it also incurssubstantial computational costs, posing challenges to the practical applicationof downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methodssuch as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores thedifferential parameter budget requirements across weight matrices, which maylead to suboptimal fine-tuning outcomes. To address this issue, we introducethe Dynamic Low-Rank Adaptation (DoRA) method. DoRA decomposes high-rank LoRAlayers into structured single-rank components, allowing for dynamic pruning ofparameter budget based on their importance to specific tasks during training,which makes the most of the limited parameter budget. Experimental resultsdemonstrate that DoRA can achieve competitive performance compared with LoRAand full model fine-tuning, and outperform various strong baselines with thesame storage parameter budget. Our code is available athttps://github.com/MIkumikumi0116/DoRA</description><author>Yulong Mao, Kaiyu Huang, Changhao Guan, Ganglin Bao, Fengran Mo, Jinan Xu</author><pubDate>Wed, 26 Jun 2024 15:41:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17357v3</guid></item><item><title>SetBERT: Enhancing Retrieval Performance for Boolean Logic and Set Operation Queries</title><link>http://arxiv.org/abs/2406.17282v2</link><description>We introduce SetBERT, a fine-tuned BERT-based model designed to enhance queryembeddings for set operations and Boolean logic queries, such as Intersection(AND), Difference (NOT), and Union (OR). SetBERT significantly improvesretrieval performance for logic-structured queries, an area where bothtraditional and neural retrieval methods typically underperform. We propose aninnovative use of inversed-contrastive loss, focusing on identifying thenegative sentence, and fine-tuning BERT with a dataset generated via promptGPT. Furthermore, we demonstrate that, unlike other BERT-based models,fine-tuning with triplet loss actually degrades performance for this specifictask. Our experiments reveal that SetBERT-base not only significantlyoutperforms BERT-base (up to a 63% improvement in Recall) but also achievesperformance comparable to the much larger BERT-large model, despite being onlyone-third the size.</description><author>Quan Mai, Susan Gauch, Douglas Adams</author><pubDate>Wed, 26 Jun 2024 15:38:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17282v2</guid></item><item><title>AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha Factors</title><link>http://arxiv.org/abs/2406.18394v1</link><description>The variability and low signal-to-noise ratio in financial data, combinedwith the necessity for interpretability, make the alpha factor mining workflowa crucial component of quantitative investment. Transitioning from early manualextraction to genetic programming, the most advanced approach in this domaincurrently employs reinforcement learning to mine a set of combination factorswith fixed weights. However, the performance of resultant alpha factorsexhibits inconsistency, and the inflexibility of fixed factor weights provesinsufficient in adapting to the dynamic nature of financial markets. To addressthis issue, this paper proposes a two-stage formulaic alpha generatingframework AlphaForge, for alpha factor mining and factor combination. Thisframework employs a generative-predictive neural network to generate factors,leveraging the robust spatial exploration capabilities inherent in deeplearning while concurrently preserving diversity. The combination model withinthe framework incorporates the temporal performance of factors for selectionand dynamically adjusts the weights assigned to each component alpha factor.Experiments conducted on real-world datasets demonstrate that our proposedmodel outperforms contemporary benchmarks in formulaic alpha factor mining.Furthermore, our model exhibits a notable enhancement in portfolio returnswithin the realm of quantitative investment.</description><author>Hao Shi, Cuicui Luo, Weili Song, Xinting Zhang, Xiang Ao</author><pubDate>Wed, 26 Jun 2024 15:34:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18394v1</guid></item><item><title>WhaleNet: a Novel Deep Learning Architecture for Marine Mammals Vocalizations on Watkins Marine Mammal Sound Database</title><link>http://arxiv.org/abs/2402.17775v2</link><description>Marine mammal communication is a complex field, hindered by the diversity ofvocalizations and environmental factors. The Watkins Marine Mammal SoundDatabase (WMMD) constitutes a comprehensive labeled dataset employed in machinelearning applications. Nevertheless, the methodologies for data preparation,preprocessing, and classification documented in the literature exhibitconsiderable variability and are typically not applied to the dataset in itsentirety. This study initially undertakes a concise review of thestate-of-the-art benchmarks pertaining to the dataset, with a particular focuson clarifying data preparation and preprocessing techniques. Subsequently, weexplore the utilization of the Wavelet Scattering Transform (WST) and Melspectrogram as preprocessing mechanisms for feature extraction. In this paper,we introduce \textbf{WhaleNet} (Wavelet Highly Adaptive Learning EnsembleNetwork), a sophisticated deep ensemble architecture for the classification ofmarine mammal vocalizations, leveraging both WST and Mel spectrogram forenhanced feature discrimination. By integrating the insights derived from WSTand Mel representations, we achieved an improvement in classification accuracyby $8-10\%$ over existing architectures, corresponding to a classificationaccuracy of $97.61\%$.</description><author>Alessandro Licciardi, Davide Carbone</author><pubDate>Wed, 26 Jun 2024 15:34:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17775v2</guid></item><item><title>SAM: Semi-Active Mechanism for Extensible Continuum Manipulator and Real-time Hysteresis Compensation Control Algorithm</title><link>http://arxiv.org/abs/2406.18388v1</link><description>Cable-Driven Continuum Manipulators (CDCMs) enable scar-free procedures vianatural orifices and improve target lesion accessibility through curved paths.However, CDCMs face limitations in workspace and control accuracy due tonon-linear cable effects causing hysteresis. This paper introduces anextensible CDCM with a Semi-active Mechanism (SAM) to expand the workspace viatranslational motion without additional mechanical elements or actuation. Wecollect a hysteresis dataset using 8 fiducial markers and RGBD sensing. Basedon this dataset, we develop a real-time hysteresis compensation controlalgorithm using the trained Temporal Convolutional Network (TCN) with a 1mstime latency, effectively estimating the manipulator's hysteresis behavior.Performance validation through random trajectory tracking tests and boxpointing tasks shows the proposed controller significantly reduces hysteresisby up to 69.5% in joint space and approximately 26% in the box pointing task.</description><author>Junhyun Park, Seonghyeok Jang, Myeongbo Park, Hyojae Park, Jeonghyeon Yoon, Minho Hwang</author><pubDate>Wed, 26 Jun 2024 15:30:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18388v1</guid></item><item><title>DoubleTake: Geometry Guided Depth Estimation</title><link>http://arxiv.org/abs/2406.18387v1</link><description>Estimating depth from a sequence of posed RGB images is a fundamentalcomputer vision task, with applications in augmented reality, path planningetc. Prior work typically makes use of previous frames in a multi view stereoframework, relying on matching textures in a local neighborhood. In contrast,our model leverages historical predictions by giving the latest 3D geometrydata as an extra input to our network. This self-generated geometric hint canencode information from areas of the scene not covered by the keyframes and itis more regularized when compared to individual predicted depth maps forprevious frames. We introduce a Hint MLP which combines cost volume featureswith a hint of the prior geometry, rendered as a depth map from the currentcamera location, together with a measure of the confidence in the priorgeometry. We demonstrate that our method, which can run at interactive speeds,achieves state-of-the-art estimates of depth and 3D scene reconstruction inboth offline and incremental evaluation scenarios.</description><author>Mohamed Sayed, Filippo Aleotti, Jamie Watson, Zawar Qureshi, Guillermo Garcia-Hernando, Gabriel Brostow, Sara Vicente, Michael Firman</author><pubDate>Wed, 26 Jun 2024 15:29:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18387v1</guid></item><item><title>Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task</title><link>http://arxiv.org/abs/2210.13382v5</link><description>Language models show a surprising range of capabilities, but the source oftheir apparent competence is unclear. Do these networks just memorize acollection of surface statistics, or do they rely on internal representationsof the process that generates the sequences they see? We investigate thisquestion by applying a variant of the GPT model to the task of predicting legalmoves in a simple board game, Othello. Although the network has no a prioriknowledge of the game or its rules, we uncover evidence of an emergentnonlinear internal representation of the board state. Interventionalexperiments indicate this representation can be used to control the output ofthe network and create "latent saliency maps" that can help explain predictionsin human terms.</description><author>Kenneth Li, Aspen K. Hopkins, David Bau, Fernanda Viégas, Hanspeter Pfister, Martin Wattenberg</author><pubDate>Wed, 26 Jun 2024 15:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.13382v5</guid></item><item><title>Adversarial Search Engine Optimization for Large Language Models</title><link>http://arxiv.org/abs/2406.18382v1</link><description>Large Language Models (LLMs) are increasingly used in applications where themodel selects from competing third-party content, such as in LLM-powered searchengines or chatbot plugins. In this paper, we introduce Preference ManipulationAttacks, a new class of attacks that manipulate an LLM's selections to favorthe attacker. We demonstrate that carefully crafted website content or plugindocumentations can trick an LLM to promote the attacker products and discreditcompetitors, thereby increasing user traffic and monetization. We show thisleads to a prisoner's dilemma, where all parties are incentivized to launchattacks, but the collective effect degrades the LLM's outputs for everyone. Wedemonstrate our attacks on production LLM search engines (Bing and Perplexity)and plugin APIs (for GPT-4 and Claude). As LLMs are increasingly used to rankthird-party content, we expect Preference Manipulation Attacks to emerge as asignificant threat.</description><author>Fredrik Nestaas, Edoardo Debenedetti, Florian Tramèr</author><pubDate>Wed, 26 Jun 2024 15:24:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18382v1</guid></item><item><title>CHIRON: Rich Character Representations in Long-Form Narratives</title><link>http://arxiv.org/abs/2406.10190v2</link><description>Characters are integral to long-form narratives, but are poorly understood byexisting story analysis and generation systems. While prior work has simplifiedcharacters via graph-based methods and brief character descriptions, we aim tobetter tackle the problem of representing complex characters by takinginspiration from advice given to professional writers. We propose CHIRON, a new`character sheet' based representation that organizes and filters textualinformation about characters. We construct CHIRON sheets in two steps: aGeneration Module that prompts an LLM for character information viaquestion-answering and a Validation Module that uses automated reasoning and adomain-specific entailment model to eliminate false facts about a character. Wevalidate CHIRON via the downstream task of masked-character prediction, whereour experiments show CHIRON is better and more flexible than comparablesummary-based baselines. We also show that metrics derived from CHIRON can beused to automatically infer character-centricity in stories, and that thesemetrics align with human judgments.</description><author>Alexander Gurung, Mirella Lapata</author><pubDate>Wed, 26 Jun 2024 15:22:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10190v2</guid></item><item><title>KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning</title><link>http://arxiv.org/abs/2406.18380v1</link><description>In recent years, Graph Neural Networks (GNNs) have become the de facto toolfor learning node and graph representations. Most GNNs typically consist of asequence of neighborhood aggregation (a.k.a., message passing) layers. Withineach of these layers, the representation of each node is updated from anaggregation and transformation of its neighbours representations at theprevious layer. The upper bound for the expressive power of message passingGNNs was reached through the use of MLPs as a transformation, due to theiruniversal approximation capabilities. However, MLPs suffer from well-knownlimitations, which recently motivated the introduction of Kolmogorov-ArnoldNetworks (KANs). KANs rely on the Kolmogorov-Arnold representation theorem,rendering them a promising alternative to MLPs. In this work, we compare theperformance of KANs against that of MLPs in graph learning tasks. We performextensive experiments on node classification, graph classification and graphregression datasets. Our preliminary results indicate that while KANs areon-par with MLPs in classification tasks, they seem to have a clear advantagein the graph regression tasks.</description><author>Roman Bresson, Giannis Nikolentzos, George Panagopoulos, Michail Chatzianastasis, Jun Pang, Michalis Vazirgiannis</author><pubDate>Wed, 26 Jun 2024 15:21:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18380v1</guid></item><item><title>MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization</title><link>http://arxiv.org/abs/2406.18379v1</link><description>Binary malware summarization aims to automatically generate human-readabledescriptions of malware behaviors from executable files, facilitating taskslike malware cracking and detection. Previous methods based on Large LanguageModels (LLMs) have shown great promise. However, they still face significantissues, including poor usability, inaccurate explanations, and incompletesummaries, primarily due to the obscure pseudocode structure and the lack ofmalware training summaries. Further, calling relationships between functions,which involve the rich interactions within a binary malware, remain largelyunderexplored. To this end, we propose MALSIGHT, a novel code summarizationframework that can iteratively generate descriptions of binary malware byexploring malicious source code and benign pseudocode. Specifically, weconstruct the first malware summaries, MalS and MalP, using an LLM and manuallyrefine this dataset with human effort. At the training stage, we tune ourproposed MalT5, a novel LLM-based code model, on the MalS dataset and a benignpseudocode dataset. Then, at the test stage, we iteratively feed the pseudocodefunctions into MalT5 to obtain the summary. Such a procedure facilitates theunderstanding of pseudocode structure and captures the intricate interactionsbetween functions, thereby benefiting the usability, accuracy, and completenessof summaries. Additionally, we propose a novel evaluation benchmark,BLEURT-sum, to measure the quality of summaries. Experiments on three datasetsshow the effectiveness of the proposed MALSIGHT. Notably, our proposed MalT5,with only 0.77B parameters, delivers comparable performance to much largerChatGPT3.5.</description><author>Haolang Lu, Hongrui Peng, Guoshun Nan, Jiaoyang Cui, Cheng Wang, Weifei Jin</author><pubDate>Wed, 26 Jun 2024 15:21:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18379v1</guid></item><item><title>From Majority to Minority: A Diffusion-based Augmentation for Underrepresented Groups in Skin Lesion Analysis</title><link>http://arxiv.org/abs/2406.18375v1</link><description>AI-based diagnoses have demonstrated dermatologist-level performance inclassifying skin cancer. However, such systems are prone to under-performingwhen tested on data from minority groups that lack sufficient representation inthe training sets. Although data collection and annotation offer the best meansfor promoting minority groups, these processes are costly and time-consuming.Prior works have suggested that data from majority groups may serve as avaluable information source to supplement the training of diagnosis tools forminority groups. In this work, we propose an effective diffusion-basedaugmentation framework that maximizes the use of rich information from majoritygroups to benefit minority groups. Using groups with different skin types as acase study, our results show that the proposed framework can generate syntheticimages that improve diagnostic results for the minority groups, even when thereis little or no reference data from these target groups. The practical value ofour work is evident in medical imaging analysis, where under-diagnosis persistsas a problem for certain groups due to insufficient representation.</description><author>Janet Wang, Yunsung Chung, Zhengming Ding, Jihun Hamm</author><pubDate>Wed, 26 Jun 2024 15:19:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18375v1</guid></item><item><title>The Fundamental Limits of Least-Privilege Learning</title><link>http://arxiv.org/abs/2402.12235v2</link><description>The promise of least-privilege learning -- to find feature representationsthat are useful for a learning task but prevent inference of any sensitiveinformation unrelated to this task -- is highly appealing. However, so far thisconcept has only been stated informally. It thus remains an open questionwhether and how we can achieve this goal. In this work, we provide the firstformalisation of the least-privilege principle for machine learning andcharacterise its feasibility. We prove that there is a fundamental trade-offbetween a representation's utility for a given task and its leakage beyond theintended task: it is not possible to learn representations that have highutility for the intended task but, at the same time prevent inference of anyattribute other than the task label itself. This trade-off holds underrealistic assumptions on the data distribution and regardless of the techniqueused to learn the feature mappings that produce these representations. Weempirically validate this result for a wide range of learning techniques, modelarchitectures, and datasets.</description><author>Theresa Stadler, Bogdan Kulynych, Michael C. Gastpar, Nicolas Papernot, Carmela Troncoso</author><pubDate>Wed, 26 Jun 2024 15:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12235v2</guid></item><item><title>Dynamic Data Pruning for Automatic Speech Recognition</title><link>http://arxiv.org/abs/2406.18373v1</link><description>The recent success of Automatic Speech Recognition (ASR) is largelyattributed to the ever-growing amount of training data. However, this trend hasmade model training prohibitively costly and imposed computational demands.While data pruning has been proposed to mitigate this issue by identifying asmall subset of relevant data, its application in ASR has been barely explored,and existing works often entail significant overhead to achieve meaningfulresults. To fill this gap, this paper presents the first investigation ofdynamic data pruning for ASR, finding that we can reach the full-dataperformance by dynamically selecting 70% of data. Furthermore, we introduceDynamic Data Pruning for ASR (DDP-ASR), which offers several fine-grainedpruning granularities specifically tailored for speech-related datasets, goingbeyond the conventional pruning of entire time sequences. Our intensiveexperiments show that DDP-ASR can save up to 1.6x training time with negligibleperformance loss.</description><author>Qiao Xiao, Pingchuan Ma, Adriana Fernandez-Lopez, Boqian Wu, Lu Yin, Stavros Petridis, Mykola Pechenizkiy, Maja Pantic, Decebal Constantin Mocanu, Shiwei Liu</author><pubDate>Wed, 26 Jun 2024 15:17:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18373v1</guid></item><item><title>Learning pure quantum states (almost) without regret</title><link>http://arxiv.org/abs/2406.18370v1</link><description>We initiate the study of quantum state tomography with minimal regret. Alearner has sequential oracle access to an unknown pure quantum state, and ineach round selects a pure probe state. Regret is incurred if the unknown stateis measured orthogonal to this probe, and the learner's goal is to minimise theexpected cumulative regret over $T$ rounds. The challenge is to find a balancebetween the most informative measurements and measurements incurring minimalregret. We show that the cumulative regret scales as$\Theta(\operatorname{polylog} T)$ using a new tomography algorithm based on amedian of means least squares estimator. This algorithm employs measurementsbiased towards the unknown state and produces online estimates that are optimal(up to logarithmic terms) in the number of observed samples.</description><author>Josep Lumbreras, Mikhail Terekhov, Marco Tomamichel</author><pubDate>Wed, 26 Jun 2024 15:13:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18370v1</guid></item><item><title>Inference-Time Intervention: Eliciting Truthful Answers from a Language Model</title><link>http://arxiv.org/abs/2306.03341v6</link><description>We introduce Inference-Time Intervention (ITI), a technique designed toenhance the "truthfulness" of large language models (LLMs). ITI operates byshifting model activations during inference, following a set of directionsacross a limited number of attention heads. This intervention significantlyimproves the performance of LLaMA models on the TruthfulQA benchmark. On aninstruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness anddemonstrate how to balance it by tuning the intervention strength. ITI isminimally invasive and computationally inexpensive. Moreover, the technique isdata efficient: while approaches like RLHF require extensive annotations, ITIlocates truthful directions using only few hundred examples. Our findingssuggest that LLMs may have an internal representation of the likelihood ofsomething being true, even as they produce falsehoods on the surface.</description><author>Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, Martin Wattenberg</author><pubDate>Wed, 26 Jun 2024 15:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03341v6</guid></item><item><title>Themis: Towards Flexible and Interpretable NLG Evaluation</title><link>http://arxiv.org/abs/2406.18365v1</link><description>The evaluation of natural language generation (NLG) tasks is a significantand longstanding research issue. With the recent emergence of powerful largelanguage models (LLMs), some studies have turned to LLM-based automaticevaluation methods, which demonstrate great potential to become a newevaluation paradigm following traditional string-based and model-based metrics.However, despite the improved performance of existing methods, they stillpossess some deficiencies, such as dependency on references and limitedevaluation flexibility. Therefore, in this paper, we meticulously construct alarge-scale NLG evaluation corpus NLG-Eval with human and GPT-4 annotations toalleviate the lack of relevant data in this field. Furthermore, we proposeThemis, an LLM dedicated to NLG evaluation, which has been trained with ourdesigned multi-perspective consistency and rating-oriented preference alignmentmethods. Themis can conduct flexible and interpretable evaluations withoutreferences, and it exhibits superior evaluation performance on various NLGtasks, simultaneously generalizing well to unseen tasks and surpassing otherevaluation models, including GPT-4.</description><author>Xinyu Hu, Li Lin, Mingqi Gao, Xunjian Yin, Xiaojun Wan</author><pubDate>Wed, 26 Jun 2024 15:04:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18365v1</guid></item><item><title>Research on Information Extraction of LCSTS Dataset Based on an Improved BERTSum-LSTM Model</title><link>http://arxiv.org/abs/2406.18364v1</link><description>With the continuous advancement of artificial intelligence, natural languageprocessing technology has become widely utilized in various fields. At the sametime, there are many challenges in creating Chinese news summaries. First ofall, the semantics of Chinese news is complex, and the amount of information isenormous. Extracting critical information from Chinese news presents asignificant challenge. Second, the news summary should be concise and clear,focusing on the main content and avoiding redundancy. In addition, theparticularity of the Chinese language, such as polysemy, word segmentation,etc., makes it challenging to generate Chinese news summaries. Based on theabove, this paper studies the information extraction method of the LCSTSdataset based on an improved BERTSum-LSTM model. We improve the BERTSum-LSTMmodel to make it perform better in generating Chinese news summaries. Theexperimental results show that the proposed method has a good effect oncreating news summaries, which is of great importance to the construction ofnews summaries.</description><author>Yiming Chen, Haobin Chen, Simin Liu, Yunyun Liu, Fanhao Zhou, Bing Wei</author><pubDate>Wed, 26 Jun 2024 15:04:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18364v1</guid></item><item><title>MindStar: Enhancing Math Reasoning in Pre-trained LLMs at Inference Time</title><link>http://arxiv.org/abs/2405.16265v4</link><description>Although Large Language Models (LLMs) achieve remarkable performance acrossvarious tasks, they often struggle with complex reasoning tasks, such asanswering mathematical questions. Recent efforts to address this issue haveprimarily focused on leveraging mathematical datasets through supervisedfine-tuning or self-improvement techniques. However, these methods often dependon high-quality datasets that are difficult to prepare, or they requiresubstantial computational resources for fine-tuning. Inspired by findings thatLLMs know how to produce the right answer but struggle to select the correctreasoning path, we propose a purely inference-based searching method --MindStar (M*). This method formulates reasoning tasks as searching problems andproposes two search ideas to identify the optimal reasoning paths. We evaluatethe M* framework on both the GSM8K and MATH datasets, comparing its performancewith existing open and closed-source LLMs. Our results demonstrate that M*significantly enhances the reasoning abilities of open-source models, such asLlama-2-13B and Mistral-7B, and achieves comparable performance to GPT-3.5 andGrok-1, but with substantially reduced model size and computational costs.</description><author>Jikun Kang, Xin Zhe Li, Xi Chen, Amirreza Kazemi, Qianyi Sun, Boxing Chen, Dong Li, Xu He, Quan He, Feng Wen, Jianye Hao, Jun Yao</author><pubDate>Wed, 26 Jun 2024 15:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16265v4</guid></item></channel></rss>