<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 15 Feb 2024 06:00:36 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>diff History for Neural Language Agents</title><link>http://arxiv.org/abs/2312.07540v2</link><description>Neural Language Models (LMs) offer an exciting solution for general-purposeembodied control. However, a key technical issue arises when using an LM-basedcontroller: environment observations must be converted to text, which coupledwith history, results in long and verbose textual prompts. As a result, priorwork in LM agents is limited to restricted domains with small observation sizeas well as minimal needs for interaction history or instruction tuning. In thispaper, we introduce diff history, a simple and highly effective solution tothese issues. By applying the Unix diff command on consecutive textobservations in the interaction histories used to prompt LM policies, we canboth abstract away redundant information and focus the content of textualinputs on the salient changes in the environment. On NetHack, an unsolved videogame that requires long-horizon reasoning for decision-making, LMs tuned withdiff history match state-of-the-art performance for neural agents while needing1800x fewer training examples compared to prior work. Even on the simplerBabyAI-Text environment with concise text observations, we find that althoughdiff history increases the length of prompts, the representation it providesoffers a 25% improvement in the efficiency of low-sample instruction tuning.Further, we show that diff history scales favorably across different tuningdataset sizes. We open-source our code and data tohttps://diffhistory.github.io.</description><author>Ulyana Piterbarg, Lerrel Pinto, Rob Fergus</author><pubDate>Wed, 14 Feb 2024 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07540v2</guid></item><item><title>AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability</title><link>http://arxiv.org/abs/2402.09404v1</link><description>This paper introduces AQA-Bench, a novel benchmark to assess the sequentialreasoning capabilities of large language models (LLMs) in algorithmic contexts,such as depth-first search (DFS). The key feature of our evaluation benchmarklies in its interactive evaluation protocol -- for example, in DFS, theavailability of each node's connected edge is contingent upon the model'straversal to that node, thereby necessitating the LLM's ability to effectivelyremember visited nodes and strategize subsequent moves. We comprehensivelybuild AQA-Bench with three different algorithms, namely binary search,depth-first search, and breadth-first search, and to evaluate the sequentialreasoning ability of 12 different LLMs. Our investigations reveal severalinteresting findings: (1) Closed-source models like GPT-4 and Gemini generallyshow strong sequential reasoning ability, significantly outperformingopen-source LLMs. (2) Naively providing interactive examples may inadvertentlyhurt few-shot performance. (3) A very limited number of predecessor stepsfollowing the optimal policy can substantially boost small models' performance.(4) The scaling correlation between performance and model size is not alwayssignificant, sometimes even showcasing an inverse trend. We hope our study cancatalyze future work on advancing the understanding and enhancement of LLMs'capabilities in sequential reasoning. The code is available athttps://github.com/UCSC-VLAA/AQA-Bench.</description><author>Siwei Yang, Bingchen Zhao, Cihang Xie</author><pubDate>Wed, 14 Feb 2024 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09404v1</guid></item><item><title>Reinforcement Learning from Human Feedback with Active Queries</title><link>http://arxiv.org/abs/2402.09401v1</link><description>Aligning large language models (LLM) with human preference plays a key rolein building modern generative models and can be achieved by reinforcementlearning from human feedback (RLHF). Despite their superior performance,current RLHF approaches often require a large amount of human-labelledpreference data, which is expensive to collect. In this paper, inspired by thesuccess of active learning, we address this problem by proposingquery-efficient RLHF methods. We first formalize the alignment problem as acontextual dueling bandit problem and design an active-query-based proximalpolicy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ regretbound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is thedimension of feature space and $\Delta$ is the sub-optimality gap over all thecontexts. We then propose ADPO, a practical version of our algorithm based ondirect preference optimization (DPO) and apply it to fine-tuning LLMs. Ourexperiments show that ADPO, while only making about half of queries for humanpreference, matches the performance of the state-of-the-art DPO method.</description><author>Kaixuan Ji, Jiafan He, Quanquan Gu</author><pubDate>Wed, 14 Feb 2024 18:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09401v1</guid></item><item><title>Continuous Prompt Generation from Linear Combination of Discrete Prompt Embeddings</title><link>http://arxiv.org/abs/2312.10323v2</link><description>The wayward quality of continuous prompts stresses the importance of theirinterpretability as unexpected and unpredictable behaviors appear followingtraining, especially in the context of large language models automatingpeople-sensitive tasks such as resume screening. In this paper we present anovel method of constructing continuous prompts via discrete prompt embeddingsand evaluate improvements to continuous prompt interpretability and inferenceaccuracy. For a set of manually designed discrete prompts $\mathcal{D}$, whichwe tokenize and embed each into tensor form, we train a model to predict theweights such that the linear combinations of those prompts correspond to higherperformance on natural language understanding tasks.</description><author>Pascal Passigan, Kidus Yohannes, Joshua Pereira</author><pubDate>Wed, 14 Feb 2024 18:57:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10323v2</guid></item><item><title>LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers</title><link>http://arxiv.org/abs/2310.15164v2</link><description>Logical reasoning, i.e., deductively inferring the truth value of aconclusion from a set of premises, is an important task for artificialintelligence with wide potential impacts on science, mathematics, and society.While many prompting-based strategies have been proposed to enable LargeLanguage Models (LLMs) to do such reasoning more effectively, they still appearunsatisfactory, often failing in subtle and unpredictable ways. In this work,we investigate the validity of instead reformulating such tasks as modularneurosymbolic programming, which we call LINC: Logical Inference viaNeurosymbolic Computation. In LINC, the LLM acts as a semantic parser,translating premises and conclusions from natural language to expressions infirst-order logic. These expressions are then offloaded to an external theoremprover, which symbolically performs deductive inference. Leveraging thisapproach, we observe significant performance gains on FOLIO and a balancedsubset of ProofWriter for three different models in nearly all experimentalconditions we evaluate. On ProofWriter, augmenting the comparatively smallopen-source StarCoder+ (15.5B parameters) with LINC even outperforms GPT-3.5and GPT-4 with Chain-of-Thought (CoT) prompting by an absolute 38% and 10%,respectively. When used with GPT-4, LINC scores 26% higher than CoT onProofWriter while performing comparatively on FOLIO. Further analysis revealsthat although both methods on average succeed roughly equally often on thisdataset, they exhibit distinct and complementary failure modes. We thus providepromising evidence for how logical reasoning over natural language can betackled through jointly leveraging LLMs alongside symbolic provers. Allcorresponding code is publicly available at https://github.com/benlipkin/linc</description><author>Theo X. Olausson, Alex Gu, Benjamin Lipkin, Cedegao E. Zhang, Armando Solar-Lezama, Joshua B. Tenenbaum, Roger Levy</author><pubDate>Wed, 14 Feb 2024 18:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15164v2</guid></item><item><title>Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference</title><link>http://arxiv.org/abs/2402.09398v1</link><description>Many computational factors limit broader deployment of large language models.In this paper, we focus on a memory bottleneck imposed by the key-value (KV)cache, a computational shortcut that requires storing previous KV pairs duringdecoding. While existing KV cache methods approach this problem by pruning orevicting large swaths of relatively less important KV pairs to dramaticallyreduce the memory footprint of the cache, they can have limited success intasks that require recollecting a majority of previous tokens. To alleviatethis issue, we propose LESS, a simple integration of a (nearly free) constantsized cache with eviction-based cache methods, such that all tokens can bequeried at later decoding steps. Its ability to retain information throughouttime shows merit on a variety of tasks where we demonstrate LESS can helpreduce the performance gap from caching everything, sometimes even matching it,all while being efficient.</description><author>Harry Dong, Xinyu Yang, Zhenyu Zhang, Zhangyang Wang, Yuejie Chi, Beidi Chen</author><pubDate>Wed, 14 Feb 2024 18:54:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09398v1</guid></item><item><title>Hyp-OW: Exploiting Hierarchical Structure Learning with Hyperbolic Distance Enhances Open World Object Detection</title><link>http://arxiv.org/abs/2306.14291v3</link><description>Open World Object Detection (OWOD) is a challenging and realistic task thatextends beyond the scope of standard Object Detection task. It involvesdetecting both known and unknown objects while integrating learned knowledgefor future tasks. However, the level of "unknownness" varies significantlydepending on the context. For example, a tree is typically considered part ofthe background in a self-driving scene, but it may be significant in ahousehold context. We argue that this contextual information should already beembedded within the known classes. In other words, there should be a semanticor latent structure relationship between the known and unknown items to bediscovered. Motivated by this observation, we propose Hyp-OW, a method thatlearns and models hierarchical representation of known items through aSuperClass Regularizer. Leveraging this representation allows us to effectivelydetect unknown objects using a similarity distance-based relabeling module.Extensive experiments on benchmark datasets demonstrate the effectiveness ofHyp-OW, achieving improvement in both known and unknown detection (up to 6percent). These findings are particularly pronounced in our newly designedbenchmark, where a strong hierarchical structure exists between known andunknown objects. Our code can be found athttps://github.com/boschresearch/Hyp-OW</description><author>Thang Doan, Xin Li, Sima Behpour, Wenbin He, Liang Gou, Liu Ren</author><pubDate>Wed, 14 Feb 2024 18:53:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14291v3</guid></item><item><title>Long-form evaluation of model editing</title><link>http://arxiv.org/abs/2402.09394v1</link><description>Evaluations of model editing currently only use the `next few token'completions after a prompt. As a result, the impact of these methods on longernatural language generation is largely unknown. We introduce long-formevaluation of model editing (\textbf{\textit{LEME}}) a novel evaluationprotocol that measures the efficacy and impact of model editing in long-formgenerative settings. Our protocol consists of a machine-rated survey and aclassifier which correlates well with human ratings. Importantly, we find thatour protocol has very little relationship with previous short-form metrics(despite being designed to extend efficacy, generalization, locality, andportability into a long-form setting), indicating that our method introduces anovel set of dimensions for understanding model editing methods. Using thisprotocol, we benchmark a number of model editing techniques and present severalfindings including that, while some methods (ROME and MEMIT) perform well inmaking consistent edits within a limited scope, they suffer much more fromfactual drift than other methods. Finally, we present a qualitative analysisthat illustrates common failure modes in long-form generative settingsincluding internal consistency, lexical cohesion, and locality issues.</description><author>Domenic Rosati, Robie Gonzales, Jinkun Chen, Xuemin Yu, Melis Erkan, Yahya Kayani, Satya Deepika Chavatapalli, Frank Rudzicz, Hassan Sajjad</author><pubDate>Wed, 14 Feb 2024 18:45:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09394v1</guid></item><item><title>Towards Unified Alignment Between Agents, Humans, and Environment</title><link>http://arxiv.org/abs/2402.07744v2</link><description>The rapid progress of foundation models has led to the prosperity ofautonomous agents, which leverage the universal capabilities of foundationmodels to conduct reasoning, decision-making, and environmental interaction.However, the efficacy of agents remains limited when operating in intricate,realistic environments. In this work, we introduce the principles of$\mathbf{U}$nified $\mathbf{A}$lignment for $\mathbf{A}$gents($\mathbf{UA}^2$), which advocate for the simultaneous alignment of agents withhuman intentions, environmental dynamics, and self-constraints such as thelimitation of monetary budgets. From the perspective of $\mathbf{UA}^2$, wereview the current agent research and highlight the neglected factors inexisting agent benchmarks and method candidates. We also conductproof-of-concept studies by introducing realistic features to WebShop,including user profiles to demonstrate intentions, personalized reranking forcomplex environmental dynamics, and runtime cost statistics to reflectself-constraints. We then follow the principles of $\mathbf{UA}^2$ to proposean initial design of our agent, and benchmark its performance with severalcandidate baselines in the retrofitted WebShop. The extensive experimentalresults further prove the importance of the principles of $\mathbf{UA}^2$. Ourresearch sheds light on the next steps of autonomous agent research withimproved general problem-solving abilities.</description><author>Zonghan Yang, An Liu, Zijun Liu, Kaiming Liu, Fangzhou Xiong, Yile Wang, Zeyuan Yang, Qingyuan Hu, Xinrui Chen, Zhenhe Zhang, Fuwen Luo, Zhicheng Guo, Peng Li, Yang Liu</author><pubDate>Wed, 14 Feb 2024 18:43:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07744v2</guid></item><item><title>LL-GABR: Energy Efficient Live Video Streaming Using Reinforcement Learning</title><link>http://arxiv.org/abs/2402.09392v1</link><description>Over the recent years, research and development in adaptive bitrate (ABR)algorithms for live video streaming have been successful in improving users'quality of experience (QoE) by reducing latency to near real-time levels whiledelivering higher bitrate videos with minimal rebuffering time. However, theQoE models used by these ABR algorithms do not take into account that a largeportion of live video streaming clients use mobile devices where a higherbitrate does not necessarily translate into higher perceived quality. Ignoringperceived quality results in playing videos at higher bitrates without asignificant increase in perceptual video quality and becomes a burden forbattery-constrained mobile devices due to higher energy consumption. In thispaper, we propose LL-GABR, a deep reinforcement learning approach that modelsthe QoE using perceived video quality instead of bitrate and uses energyconsumption along with other metrics like latency, rebuffering events, andsmoothness. LL-GABR makes no assumptions about the underlying video,environment, or network settings and can operate flexibly on different videotitles, each having a different bitrate encoding ladder without additionalre-training, unlike existing learning-based ABRs. Trace-driven experimentalresults show that LL-GABR outperforms the state-of-the-art approaches by up to44% in terms of perceptual QoE and a 73% increase in energy efficiency as aresult of reducing net energy consumption by 11%.</description><author>Adithya Raman, Bekir Turkkan, Tevfik Kosar</author><pubDate>Wed, 14 Feb 2024 18:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09392v1</guid></item><item><title>Conditional Generative Modeling for High-dimensional Marked Temporal Point Processes</title><link>http://arxiv.org/abs/2305.12569v3</link><description>Point processes offer a versatile framework for sequential event modeling.However, the computational challenges and constrained representational power ofthe existing point process models have impeded their potential for widerapplications. This limitation becomes especially pronounced when dealing withevent data that is associated with multi-dimensional or high-dimensional markssuch as texts or images. To address this challenge, this study proposes a novelevent-generation framework for modeling point processes with high-dimensionalmarks. We aim to capture the distribution of events without explicitlyspecifying the conditional intensity or probability density function. Instead,we use a conditional generator that takes the history of events as input andgenerates the high-quality subsequent event that is likely to occur given theprior observations. The proposed framework offers a host of benefits, includingconsiderable representational power to capture intricate dynamics in multi- oreven high-dimensional event space, as well as exceptional efficiency inlearning the model and generating samples. Our numerical results demonstratesuperior performance compared to other state-of-the-art baselines.</description><author>Zheng Dong, Zekai Fan, Shixiang Zhu</author><pubDate>Wed, 14 Feb 2024 18:42:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12569v3</guid></item><item><title>LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset</title><link>http://arxiv.org/abs/2402.09391v1</link><description>Chemistry plays a crucial role in many domains, such as drug discovery andmaterial science. While large language models (LLMs) such as GPT-4 exhibitremarkable capabilities on natural language processing tasks, existing workshows their performance on chemistry tasks is discouragingly low. In thispaper, however, we demonstrate that our developed LLMs can achieve very strongresults on a comprehensive set of chemistry tasks, outperforming the mostadvanced GPT-4 across all the tasks by a substantial margin and approaching theSoTA task-specific models. The key to our success is a large-scale,comprehensive, high-quality dataset for instruction tuning named SMolInstruct.It contains 14 meticulously selected chemistry tasks and over three millionhigh-quality samples, laying a solid foundation for training and evaluatingLLMs for chemistry. Based on SMolInstruct, we fine-tune a set of open-sourceLLMs, among which, we find that Mistral serves as the best base model forchemistry tasks. We further conduct analysis on the impact of trainableparameters, providing insights for future research.</description><author>Botao Yu, Frazier N. Baker, Ziqi Chen, Xia Ning, Huan Sun</author><pubDate>Wed, 14 Feb 2024 18:42:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09391v1</guid></item><item><title>HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation</title><link>http://arxiv.org/abs/2402.09390v1</link><description>With the widespread adoption of large language models (LLMs) in numerousapplications, the challenge of factuality and the propensity for hallucinationsraises significant concerns. To address this issue, particularly inretrieval-augmented in-context learning, we introduce the hierarchical graph ofthoughts (HGOT), a structured, multi-layered graph approach designed to enhancethe retrieval of pertinent passages during in-context learning. The frameworkutilizes the emergent planning capabilities of LLMs, employing thedivide-and-conquer strategy to break down complex queries into manageablesub-queries. It refines self-consistency majority voting for answer selection,which incorporates the recently proposed citation recall and precision metricsto assess the quality of thoughts, linking an answer's credibilityintrinsically to the thought's quality. This methodology introduces a weightedsystem in majority voting, prioritizing answers based on the citation qualityof their thoughts. Additionally, we propose a scoring mechanism for evaluatingretrieved passages, considering factors such as citation frequency and quality,self-consistency confidence, and the retrieval module's ranking. Experimentsreveal that HGOT outperforms other retrieval-augmented in-context learningmethods, including Demonstrate-Search-Predict (DSP), ReAct, Self-Ask, andRetrieve-then-Read on different datasets by as much as $7\%$, demonstrating itsefficacy in enhancing the factuality of LLMs.</description><author>Yihao Fang, Stephen W. Thomas, Xiaodan Zhu</author><pubDate>Wed, 14 Feb 2024 18:41:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09390v1</guid></item><item><title>Entropy-regularized Point-based Value Iteration</title><link>http://arxiv.org/abs/2402.09388v1</link><description>Model-based planners for partially observable problems must accommodate bothmodel uncertainty during planning and goal uncertainty during objectiveinference. However, model-based planners may be brittle under these types ofuncertainty because they rely on an exact model and tend to commit to a singleoptimal behavior. Inspired by results in the model-free setting, we propose anentropy-regularized model-based planner for partially observable problems.Entropy regularization promotes policy robustness for planning and objectiveinference by encouraging policies to be no more committed to a single actionthan necessary. We evaluate the robustness and objective inference performanceof entropy-regularized policies in three problem domains. Our results show thatentropy-regularized policies outperform non-entropy-regularized baselines interms of higher expected returns under modeling errors and higher accuracyduring objective inference.</description><author>Harrison Delecki, Marcell Vazquez-Chanlatte, Esen Yel, Kyle Wray, Tomer Arnon, Stefan Witwicki, Mykel J. Kochenderfer</author><pubDate>Wed, 14 Feb 2024 18:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09388v1</guid></item><item><title>Active Disruption Avoidance and Trajectory Design for Tokamak Ramp-downs with Neural Differential Equations and Reinforcement Learning</title><link>http://arxiv.org/abs/2402.09387v1</link><description>The tokamak offers a promising path to fusion energy, but plasma disruptionspose a major economic risk, motivating considerable advances in disruptionavoidance. This work develops a reinforcement learning approach to this problemby training a policy to safely ramp-down the plasma current while avoidinglimits on a number of quantities correlated with disruptions. The policytraining environment is a hybrid physics and machine learning model trained onsimulations of the SPARC primary reference discharge (PRD) ramp-down, anupcoming burning plasma scenario which we use as a testbed. To address physicsuncertainty and model inaccuracies, the simulation environment is massivelyparallelized on GPU with randomized physics parameters during policy training.The trained policy is then successfully transferred to a higher fidelitysimulator where it successfully ramps down the plasma while avoidinguser-specified disruptive limits. We also address the crucial issue of safetycriticality by demonstrating that a constraint-conditioned policy can be usedas a trajectory design assistant to design a library of feed-forwardtrajectories to handle different physics conditions and user settings. As alibrary of trajectories is more interpretable and verifiable offline, we arguesuch an approach is a promising path for leveraging the capabilities ofreinforcement learning in the safety-critical context of burning plasmatokamaks. Finally, we demonstrate how the training environment can be a usefulplatform for other feed-forward optimization approaches by using anevolutionary algorithm to perform optimization of feed-forward trajectoriesthat are robust to physics uncertainty</description><author>Allen M. Wang, Oswin So, Charles Dawson, Darren T. Garnier, Cristina Rea, Chuchu Fan</author><pubDate>Wed, 14 Feb 2024 18:37:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09387v1</guid></item><item><title>Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions</title><link>http://arxiv.org/abs/2402.09384v1</link><description>A principal designs an algorithm that generates a publicly observableprediction of a binary state. She must decide whether to act directly based onthe prediction or to delegate the decision to an agent with private informationbut potential misalignment. We study the optimal design of the predictionalgorithm and the delegation rule in such environments. Three key findingsemerge: (1) Delegation is optimal if and only if the principal would make thesame binary decision as the agent had she observed the agent's information. (2)Providing the most informative algorithm may be suboptimal even if theprincipal can act on the algorithm's prediction. Instead, the optimal algorithmmay provide more information about one state and restrict information about theother. (3) Common restrictions on algorithms, such as keeping a"human-in-the-loop" or requiring maximal prediction accuracy, strictly worsendecision quality in the absence of perfectly aligned agents and state-revealingsignals. These findings predict the underperformance of human-machinecollaborations if no measures are taken to mitigate common preferencemisalignment between algorithms and human decision-makers.</description><author>Ruqing Xu</author><pubDate>Wed, 14 Feb 2024 18:32:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09384v1</guid></item><item><title>Causal Explanations for Sequential Decision-Making in Multi-Agent Systems</title><link>http://arxiv.org/abs/2302.10809v4</link><description>We present CEMA: Causal Explanations in Multi-Agent systems; a framework forcreating causal natural language explanations of an agent's decisions indynamic sequential multi-agent systems to build more trustworthy autonomousagents. Unlike prior work that assumes a fixed causal structure, CEMA onlyrequires a probabilistic model for forward-simulating the state of the system.Using such a model, CEMA simulates counterfactual worlds that identify thesalient causes behind the agent's decisions. We evaluate CEMA on the task ofmotion planning for autonomous driving and test it in diverse simulatedscenarios. We show that CEMA correctly and robustly identifies the causesbehind the agent's decisions, even when a large number of other agents ispresent, and show via a user study that CEMA's explanations have a positiveeffect on participants' trust in autonomous vehicles and are rated as high ashigh-quality baseline explanations elicited from other participants. We releasethe collected explanations with annotations as the HEADD dataset.</description><author>Balint Gyevnar, Cheng Wang, Christopher G. Lucas, Shay B. Cohen, Stefano V. Albrecht</author><pubDate>Wed, 14 Feb 2024 18:28:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10809v4</guid></item><item><title>GraSSRep: Graph-Based Self-Supervised Learning for Repeat Detection in Metagenomic Assembly</title><link>http://arxiv.org/abs/2402.09381v1</link><description>Repetitive DNA (repeats) poses significant challenges for accurate andefficient genome assembly and sequence alignment. This is particularly true formetagenomic data, where genome dynamics such as horizontal gene transfer, geneduplication, and gene loss/gain complicate accurate genome assembly frommetagenomic communities. Detecting repeats is a crucial first step inovercoming these challenges. To address this issue, we propose GraSSRep, anovel approach that leverages the assembly graph's structure through graphneural networks (GNNs) within a self-supervised learning framework to classifyDNA sequences into repetitive and non-repetitive categories. Specifically, weframe this problem as a node classification task within a metagenomic assemblygraph. In a self-supervised fashion, we rely on a high-precision (butlow-recall) heuristic to generate pseudo-labels for a small proportion of thenodes. We then use those pseudo-labels to train a GNN embedding and a randomforest classifier to propagate the labels to the remaining nodes. In this way,GraSSRep combines sequencing features with pre-defined and learned graphfeatures to achieve state-of-the-art performance in repeat detection. Weevaluate our method using simulated and synthetic metagenomic datasets. Theresults on the simulated data highlight our GraSSRep's robustness to repeatattributes, demonstrating its effectiveness in handling the complexity ofrepeated sequences. Additionally, our experiments with synthetic metagenomicdatasets reveal that incorporating the graph structure and the GNN enhances ourdetection performance. Finally, in comparative analyses, GraSSRep outperformsexisting repeat detection tools with respect to precision and recall.</description><author>Ali Azizpour, Advait Balaji, Todd J. Treangen, Santiago Segarra</author><pubDate>Wed, 14 Feb 2024 18:26:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09381v1</guid></item><item><title>Bad Students Make Great Teachers: Active Learning Accelerates Large-Scale Visual Understanding</title><link>http://arxiv.org/abs/2312.05328v3</link><description>Power-law scaling indicates that large-scale training with uniform samplingis prohibitively slow. Active learning methods aim to increase data efficiencyby prioritizing learning on the most relevant examples. Despite their appeal,these methods have yet to be widely adopted since no one algorithm has beenshown to a) generalize across models and tasks b) scale to large datasets andc) yield overall FLOP savings when accounting for the overhead of dataselection. In this work we propose a method which satisfies these threeproperties, leveraging small, cheap proxy models to estimate "learnability"scores for datapoints, which are used to prioritize data for the training ofmuch larger models. As a result, our models require 46% and 51% fewer trainingupdates and up to 25% less total computation to reach the same performance asuniformly trained visual classifiers on JFT and multimodal models on ALIGN.Finally, we find our data-prioritization scheme to be complementary with recentdata-curation and learning objectives, yielding a new state-of-the-art inseveral multimodal transfer tasks.</description><author>Talfan Evans, Shreya Pathak, Hamza Merzic, Jonathan Schwarz, Ryutaro Tanno, Olivier J. Henaff</author><pubDate>Wed, 14 Feb 2024 18:22:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05328v3</guid></item><item><title>Loss Shaping Constraints for Long-Term Time Series Forecasting</title><link>http://arxiv.org/abs/2402.09373v1</link><description>Several applications in time series forecasting require predicting multiplesteps ahead. Despite the vast amount of literature in the topic, both classicaland recent deep learning based approaches have mostly focused on minimisingperformance averaged over the predicted window. We observe that this can leadto disparate distributions of errors across forecasting steps, especially forrecent transformer architectures trained on popular forecasting benchmarks.That is, optimising performance on average can lead to undesirably large errorsat specific time-steps. In this work, we present a Constrained Learningapproach for long-term time series forecasting that aims to find the best modelin terms of average performance that respects a user-defined upper bound on theloss at each time-step. We call our approach loss shaping constraints becauseit imposes constraints on the loss at each time step, and leverage recentduality results to show that despite its non-convexity, the resulting problemhas a bounded duality gap. We propose a practical Primal-Dual algorithm totackle it, and demonstrate that the proposed approach exhibits competitiveaverage performance in time series forecasting benchmarks, while shaping thedistribution of errors across the predicted window.</description><author>Ignacio Hounie, Javier Porras-Valenzuela, Alejandro Ribeiro</author><pubDate>Wed, 14 Feb 2024 18:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09373v1</guid></item><item><title>Deep Rib Fracture Instance Segmentation and Classification from CT on the RibFrac Challenge</title><link>http://arxiv.org/abs/2402.09372v1</link><description>Rib fractures are a common and potentially severe injury that can bechallenging and labor-intensive to detect in CT scans. While there have beenefforts to address this field, the lack of large-scale annotated datasets andevaluation benchmarks has hindered the development and validation of deeplearning algorithms. To address this issue, the RibFrac Challenge wasintroduced, providing a benchmark dataset of over 5,000 rib fractures from 660CT scans, with voxel-level instance mask annotations and diagnosis labels forfour clinical categories (buckle, nondisplaced, displaced, or segmental). Thechallenge includes two tracks: a detection (instance segmentation) trackevaluated by an FROC-style metric and a classification track evaluated by anF1-style metric. During the MICCAI 2020 challenge period, 243 results wereevaluated, and seven teams were invited to participate in the challengesummary. The analysis revealed that several top rib fracture detectionsolutions achieved performance comparable or even better than human experts.Nevertheless, the current rib fracture classification solutions are hardlyclinically applicable, which can be an interesting area in the future. As anactive benchmark and research resource, the data and online evaluation of theRibFrac Challenge are available at the challenge website. As an independentcontribution, we have also extended our previous internal baseline byincorporating recent advancements in large-scale pretrained networks andpoint-based rib segmentation techniques. The resulting FracNet+ demonstratescompetitive performance in rib fracture detection, which lays a foundation forfurther research and development in AI-assisted rib fracture detection anddiagnosis.</description><author>Jiancheng Yang, Rui Shi, Liang Jin, Xiaoyang Huang, Kaiming Kuang, Donglai Wei, Shixuan Gu, Jianying Liu, Pengfei Liu, Zhizhong Chai, Yongjie Xiao, Hao Chen, Liming Xu, Bang Du, Xiangyi Yan, Hao Tang, Adam Alessio, Gregory Holste, Jiapeng Zhang, Xiaoming Wang, Jianye He, Lixuan Che, Hanspeter Pfister, Ming Li, Bingbing Ni</author><pubDate>Wed, 14 Feb 2024 18:18:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09372v1</guid></item><item><title>Transformers Can Achieve Length Generalization But Not Robustly</title><link>http://arxiv.org/abs/2402.09371v1</link><description>Length generalization, defined as the ability to extrapolate from shortertraining sequences to longer test ones, is a significant challenge for languagemodels. This issue persists even with large-scale Transformers handlingrelatively straightforward tasks. In this paper, we test the Transformer'sability of length generalization using the task of addition of two integers. Weshow that the success of length generalization is intricately linked to thedata format and the type of position encoding. Using the right combination ofdata format and position encodings, we show for the first time that standardTransformers can extrapolate to a sequence length that is 2.5x the inputlength. Nevertheless, unlike in-distribution generalization, lengthgeneralization remains fragile, significantly influenced by factors like randomweight initialization and training data order, leading to large variancesacross different random seeds.</description><author>Yongchao Zhou, Uri Alon, Xinyun Chen, Xuezhi Wang, Rishabh Agarwal, Denny Zhou</author><pubDate>Wed, 14 Feb 2024 18:18:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09371v1</guid></item><item><title>Pseudorandom Error-Correcting Codes</title><link>http://arxiv.org/abs/2402.09370v1</link><description>We construct pseudorandom error-correcting codes (or simply pseudorandomcodes), which are error-correcting codes with the property that any polynomialnumber of codewords are pseudorandom to any computationally-bounded adversary.Efficient decoding of corrupted codewords is possible with the help of adecoding key. We build pseudorandom codes that are robust to substitution and deletionerrors, where pseudorandomness rests on standard cryptographic assumptions.Specifically, pseudorandomness is based on either $2^{O(\sqrt{n})}$-hardness ofLPN, or polynomial hardness of LPN and the planted XOR problem at low density. As our primary application of pseudorandom codes, we present an undetectablewatermarking scheme for outputs of language models that is robust to croppingand a constant rate of random substitutions and deletions. The watermark isundetectable in the sense that any number of samples of watermarked text arecomputationally indistinguishable from text output by the original model. Thisis the first undetectable watermarking scheme that can tolerate a constant rateof errors. Our second application is to steganography, where a secret message is hiddenin innocent-looking content. We present a constant-rate stateless steganographyscheme with robustness to a constant rate of substitutions. Ours is the firststateless steganography scheme with provable steganographic security and anyrobustness to errors.</description><author>Miranda Christ, Sam Gunn</author><pubDate>Wed, 14 Feb 2024 18:17:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09370v1</guid></item><item><title>Massively Multi-Cultural Knowledge Acquisition &amp; LM Benchmarking</title><link>http://arxiv.org/abs/2402.09369v1</link><description>Pretrained large language models have revolutionized many applications butstill face challenges related to cultural bias and a lack of culturalcommonsense knowledge crucial for guiding cross-culture communication andinteractions. Recognizing the shortcomings of existing methods in capturing thediverse and rich cultures across the world, this paper introduces a novelapproach for massively multicultural knowledge acquisition. Specifically, ourmethod strategically navigates from densely informative Wikipedia documents oncultural topics to an extensive network of linked pages. Leveraging thisvaluable source of data collection, we construct the CultureAtlas dataset,which covers a wide range of sub-country level geographical regions andethnolinguistic groups, with data cleaning and preprocessing to ensure textualassertion sentence self-containment, as well as fine-grained cultural profileinformation extraction. Our dataset not only facilitates the evaluation oflanguage model performance in culturally diverse contexts but also serves as afoundational tool for the development of culturally sensitive and awarelanguage models. Our work marks an important step towards deeper understandingand bridging the gaps of cultural disparities in AI, to promote a moreinclusive and balanced representation of global cultures in the digital domain.</description><author>Yi Fung, Ruining Zhao, Jae Doo, Chenkai Sun, Heng Ji</author><pubDate>Wed, 14 Feb 2024 18:16:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09369v1</guid></item><item><title>Magic-Me: Identity-Specific Video Customized Diffusion</title><link>http://arxiv.org/abs/2402.09368v1</link><description>Creating content for a specific identity (ID) has shown significant interestin the field of generative models. In the field of text-to-image generation(T2I), subject-driven content generation has achieved great progress with theID in the images controllable. However, extending it to video generation is notwell explored. In this work, we propose a simple yet effective subject identitycontrollable video generation framework, termed Video Custom Diffusion (VCD).With a specified subject ID defined by a few images, VCD reinforces theidentity information extraction and injects frame-wise correlation at theinitialization stage for stable video outputs with identity preserved to alarge extent. To achieve this, we propose three novel components that areessential for high-quality ID preservation: 1) an ID module trained with thecropped identity by prompt-to-segmentation to disentangle the ID informationand the background noise for more accurate ID token learning; 2) atext-to-video (T2V) VCD module with 3D Gaussian Noise Prior for betterinter-frame consistency and 3) video-to-video (V2V) Face VCD and Tiled VCDmodules to deblur the face and upscale the video for higher resolution. Despite its simplicity, we conducted extensive experiments to verify that VCDis able to generate stable and high-quality videos with better ID over theselected strong baselines. Besides, due to the transferability of the IDmodule, VCD is also working well with finetuned text-to-image models availablepublically, further improving its usability. The codes are available athttps://github.com/Zhen-Dong/Magic-Me.</description><author>Ze Ma, Daquan Zhou, Chun-Hsiao Yeh, Xue-She Wang, Xiuyu Li, Huanrui Yang, Zhen Dong, Kurt Keutzer, Jiashi Feng</author><pubDate>Wed, 14 Feb 2024 18:13:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09368v1</guid></item><item><title>Prediction of Activated Sludge Settling Characteristics from Microscopy Images with Deep Convolutional Neural Networks and Transfer Learning</title><link>http://arxiv.org/abs/2402.09367v1</link><description>Microbial communities play a key role in biological wastewater treatmentprocesses. Activated sludge settling characteristics, for example, are affectedby microbial community composition, varying by changes in operating conditionsand influent characteristics of wastewater treatment plants (WWTPs). Timelyassessment and prediction of changes in microbial composition leading tosettling problems, such as filamentous bulking (FB), can prevent operationalchallenges, reductions in treatment efficiency, and adverse environmentalimpacts. This study presents an innovative computer vision-based approach toassess activated sludge-settling characteristics based on the morphologicalproperties of flocs and filaments in microscopy images. Implementing thetransfer learning of deep convolutional neural network (CNN) models, thisapproach aims to overcome the limitations of existing quantitative imageanalysis techniques. The offline microscopy image dataset was collected overtwo years, with weekly sampling at a full-scale industrial WWTP in Belgium.Multiple data augmentation techniques were employed to enhance thegeneralizability of the CNN models. Various CNN architectures, includingInception v3, ResNet18, ResNet152, ConvNeXt-nano, and ConvNeXt-S, were testedto evaluate their performance in predicting sludge settling characteristics.The sludge volume index was used as the final prediction variable, but themethod can easily be adjusted to predict any other settling metric of choice.The results showed that the suggested CNN-based approach provides lesslabour-intensive, objective, and consistent assessments, while transferlearning notably minimises the training phase, resulting in a generalizablesystem that can be employed in real-time applications.</description><author>Sina Borzooei, Leonardo Scabini, Gisele Miranda, Saba Daneshgar, Lukas Deblieck, Piet De Langhe, Odemir Bruno, Bernard De Baets, Ingmar Nopens, Elena Torfs</author><pubDate>Wed, 14 Feb 2024 18:13:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09367v1</guid></item><item><title>Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks</title><link>http://arxiv.org/abs/2312.14440v2</link><description>The widespread use of Text-to-Image (T2I) models in content generationrequires careful examination of their safety, including their robustness toadversarial attacks. Despite extensive research on adversarial attacks, thereasons for their effectiveness remain underexplored. This paper presents anempirical study on adversarial attacks against T2I models, focusing onanalyzing factors associated with attack success rates (ASR). We introduce anew attack objective - entity swapping using adversarial suffixes and twogradient-based attack algorithms. Human and automatic evaluations reveal theasymmetric nature of ASRs on entity swap: for example, it is easier to replace"human" with "robot" in the prompt "a human dancing in the rain." with anadversarial suffix, but the reverse replacement is significantly harder. Wefurther propose probing metrics to establish indicative signals from themodel's beliefs to the adversarial ASR. We identify conditions that result in asuccess probability of 60% for adversarial attacks and others where thislikelihood drops below 5%.</description><author>Haz Sameen Shahgir, Xianghao Kong, Greg Ver Steeg, Yue Dong</author><pubDate>Wed, 14 Feb 2024 18:09:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14440v2</guid></item><item><title>Copyright Traps for Large Language Models</title><link>http://arxiv.org/abs/2402.09363v1</link><description>Questions of fair use of copyright-protected content to train Large LanguageModels (LLMs) are being very actively debated. Document-level inference hasbeen proposed as a new task: inferring from black-box access to the trainedmodel whether a piece of content has been seen during training. SOTA methodshowever rely on naturally occurring memorization of (part of) the content.While very effective against models that memorize a lot, we hypothesize--andlater confirm--that they will not work against models that do not naturallymemorize, e.g. medium-size 1B models. We here propose to use copyright traps,the inclusion of fictitious entries in original content, to detect the use ofcopyrighted materials in LLMs with a focus on models where memorization doesnot naturally occur. We carefully design an experimental setup, randomlyinserting traps into original content (books) and train a 1.3B LLM. We firstvalidate that the use of content in our target model would be undetectableusing existing methods. We then show, contrary to intuition, that evenmedium-length trap sentences repeated a significant number of times (100) arenot detectable using existing methods. However, we show that longer sequencesrepeated a large number of times can be reliably detected (AUC=0.75) and usedas copyright traps. We further improve these results by studying how the numberof times a sequence is seen improves detectability, how sequences with higherperplexity tend to be memorized more, and how taking context into accountfurther improves detectability.</description><author>Matthieu Meeus, Igor Shilov, Manuel Faysse, Yves-Alexandre de Montjoye</author><pubDate>Wed, 14 Feb 2024 18:09:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09363v1</guid></item><item><title>HiRE: High Recall Approximate Top-$k$ Estimation for Efficient LLM Inference</title><link>http://arxiv.org/abs/2402.09360v1</link><description>Autoregressive decoding with generative Large Language Models (LLMs) onaccelerators (GPUs/TPUs) is often memory-bound where most of the time is spenton transferring model parameters from high bandwidth memory (HBM) to cache. Onthe other hand, recent works show that LLMs can maintain quality withsignificant sparsity/redundancy in the feedforward (FFN) layers byappropriately training the model to operate on a top-$k$ fraction ofrows/columns (where $k \approx 0.05$), there by suggesting a way to reduce thetransfer of model parameters, and hence latency. However, exploiting thissparsity for improving latency is hindered by the fact that identifying toprows/columns is data-dependent and is usually performed using full matrixoperations, severely limiting potential gains. To address these issues, weintroduce HiRE (High Recall Approximate Top-k Estimation). HiRE comprises oftwo novel components: (i) a compression scheme to cheaply predict top-$k$rows/columns with high recall, followed by full computation restricted to thepredicted subset, and (ii) DA-TOP-$k$: an efficient multi-device approximatetop-$k$ operator. We demonstrate that on a one billion parameter model, HiREapplied to both the softmax as well as feedforward layers, achieves almostmatching pretraining and downstream accuracy, and speeds up inference latencyby $1.47\times$ on a single TPUv5e device.</description><author>Yashas Samaga B L, Varun Yerram, Chong You, Srinadh Bhojanapalli, Sanjiv Kumar, Prateek Jain, Praneeth Netrapalli</author><pubDate>Wed, 14 Feb 2024 18:04:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09360v1</guid></item><item><title>Pruning Sparse Tensor Neural Networks Enables Deep Learning for 3D Ultrasound Localization Microscopy</title><link>http://arxiv.org/abs/2402.09359v1</link><description>Ultrasound Localization Microscopy (ULM) is a non-invasive technique thatallows for the imaging of micro-vessels in vivo, at depth and with a resolutionon the order of ten microns. ULM is based on the sub-resolution localization ofindividual microbubbles injected in the bloodstream. Mapping the wholeangioarchitecture requires the accumulation of microbubbles trajectories fromthousands of frames, typically acquired over a few minutes. ULM acquisitiontimes can be reduced by increasing the microbubble concentration, but requiresmore advanced algorithms to detect them individually. Several deep learningapproaches have been proposed for this task, but they remain limited to 2Dimaging, in part due to the associated large memory requirements. Herein, wepropose to use sparse tensor neural networks to reduce memory usage in 2D andto improve the scaling of the memory requirement for the extension of deeplearning architecture to 3D. We study several approaches to efficiently convertultrasound data into a sparse format and study the impact of the associatedloss of information. When applied in 2D, the sparse formulation reduces thememory requirements by a factor 2 at the cost of a small reduction ofperformance when compared against dense networks. In 3D, the proposed approachreduces memory requirements by two order of magnitude while largelyoutperforming conventional ULM in high concentration settings. We show thatSparse Tensor Neural Networks in 3D ULM allow for the same benefits as densedeep learning based method in 2D ULM i.e. the use of higher concentration insilico and reduced acquisition time.</description><author>Brice Rauby, Paul Xing, Jonathan Porée, Maxime Gasse, Jean Provost</author><pubDate>Wed, 14 Feb 2024 18:03:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09359v1</guid></item><item><title>Integrating ChatGPT into Secure Hospital Networks: A Case Study on Improving Radiology Report Analysis</title><link>http://arxiv.org/abs/2402.09358v1</link><description>This study demonstrates the first in-hospital adaptation of a cloud-based AI,similar to ChatGPT, into a secure model for analyzing radiology reports,prioritizing patient data privacy. By employing a unique sentence-levelknowledge distillation method through contrastive learning, we achieve over 95%accuracy in detecting anomalies. The model also accurately flags uncertaintiesin its predictions, enhancing its reliability and interpretability forphysicians with certainty indicators. These advancements represent significantprogress in developing secure and efficient AI tools for healthcare, suggestinga promising future for in-hospital AI applications with minimal supervision.</description><author>Kyungsu Kim, Junhyun Park, Saul Langarica, Adham Mahmoud Alkhadrawi, Synho Do</author><pubDate>Wed, 14 Feb 2024 18:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09358v1</guid></item><item><title>LongForm: Effective Instruction Tuning with Reverse Instructions</title><link>http://arxiv.org/abs/2304.08460v2</link><description>Instruction tuning enables language models to more effectively generalize andbetter follow user intent. However, obtaining instruction data is costly andchallenging. Prior work employs methods such as expensive human annotation,crowd-sourced datasets with alignment issues, and generating noisy examples viaLLMs. We introduce the LongForm-C dataset, which is created by reverseinstructions. We generate instructions via LLMs for human-written corpusexamples using reverse instructions. First we select a diverse set ofhuman-written documents from corpora such as C4 and Wikipedia; then we generateinstructions for these documents via LLMs. This approach provides a cheaper andcleaner instruction-tuning dataset with natural output and one suitable forlong text generation. Our models outperform 10x larger language models withoutinstruction tuning on tasks such as story/recipe generation and long-formquestion answering. Moreover, LongForm models outperform priorinstruction-tuned models such as FLAN-T5 and Alpaca by a large margin, andimprove language understanding capabilities further. Finally, our models caneffectively follow and answer multilingual instructions; we demonstrate thisfor news generation. We publicly release our data and models:https://github.com/akoksal/LongForm.</description><author>Abdullatif Köksal, Timo Schick, Anna Korhonen, Hinrich Schütze</author><pubDate>Wed, 14 Feb 2024 18:00:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08460v2</guid></item><item><title>Single-Reset Divide &amp; Conquer Imitation Learning</title><link>http://arxiv.org/abs/2402.09355v1</link><description>Demonstrations are commonly used to speed up the learning process of DeepReinforcement Learning algorithms. To cope with the difficulty of accessingmultiple demonstrations, some algorithms have been developed to learn from asingle demonstration. In particular, the Divide &amp; Conquer Imitation Learningalgorithms leverage a sequential bias to learn a control policy for complexrobotic tasks using a single state-based demonstration. The latest version,DCIL-II demonstrates remarkable sample efficiency. This novel method operateswithin an extended Goal-Conditioned Reinforcement Learning framework, ensuringcompatibility between intermediate and subsequent goals extracted from thedemonstration. However, a fundamental limitation arises from the assumptionthat the system can be reset to specific states along the demonstratedtrajectory, confining the application to simulated systems. In response, weintroduce an extension called Single-Reset DCIL (SR-DCIL), designed to overcomethis constraint by relying on a single initial state reset rather thansequential resets. To address this more challenging setting, we integrate twomechanisms inspired by the Learning from Demonstrations literature, including aDemo-Buffer and Value Cloning, to guide the agent toward compatible successstates. In addition, we introduce Approximate Goal Switching to facilitatetraining to reach goals distant from the reset state. Our paper makes severalcontributions, highlighting the importance of the reset assumption in DCIL-II,presenting the mechanisms of SR-DCIL variants and evaluating their performancein challenging robotic tasks compared to DCIL-II. In summary, this work offersinsights into the significance of reset assumptions in the framework of DCILand proposes SR-DCIL, a first step toward a versatile algorithm capable oflearning control policies under a weaker reset assumption.</description><author>Alexandre Chenu, Olivier Serris, Olivier Sigaud, Nicolas Perrin-Gilbert</author><pubDate>Wed, 14 Feb 2024 17:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09355v1</guid></item><item><title>DoRA: Weight-Decomposed Low-Rank Adaptation</title><link>http://arxiv.org/abs/2402.09353v1</link><description>Among the widely used parameter-efficient finetuning (PEFT) methods, LoRA andits variants have gained considerable popularity because of avoiding additionalinference costs. However, there still often exists an accuracy gap betweenthese methods and full fine-tuning (FT). In this work, we first introduce anovel weight decomposition analysis to investigate the inherent differencesbetween FT and LoRA. Aiming to resemble the learning capacity of FT from thefindings, we propose Weight-Decomposed LowRank Adaptation (DoRA). DoRAdecomposes the pre-trained weight into two components, magnitude and direction,for fine-tuning, specifically employing LoRA for directional updates toefficiently minimize the number of trainable parameters. By employing DoRA, weenhance both the learning capacity and training stability of LoRA whileavoiding any additional inference overhead. DoRA consistently outperforms LoRAon fine-tuning LLaMA, LLaVA, and VL-BART on various downstream tasks, such ascommonsense reasoning, visual instruction tuning, and image/video-textunderstanding.</description><author>Shih-Yang Liu, Chien-Yi Wang, Hongxu Yin, Pavlo Molchanov, Yu-Chiang Frank Wang, Kwang-Ting Cheng, Min-Hung Chen</author><pubDate>Wed, 14 Feb 2024 17:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09353v1</guid></item><item><title>Intriguing properties of generative classifiers</title><link>http://arxiv.org/abs/2309.16779v2</link><description>What is the best paradigm to recognize objects -- discriminative inference(fast but potentially prone to shortcut learning) or using a generative model(slow but potentially more robust)? We build on recent advances in generativemodeling that turn text-to-image models into classifiers. This allows us tostudy their behavior and to compare them against discriminative models andhuman psychophysical data. We report four intriguing emergent properties ofgenerative classifiers: they show a record-breaking human-like shape bias (99%for Imagen), near human-level out-of-distribution accuracy, state-of-the-artalignment with human classification errors, and they understand certainperceptual illusions. Our results indicate that while the current dominantparadigm for modeling human object recognition is discriminative inference,zero-shot generative models approximate human object recognition datasurprisingly well.</description><author>Priyank Jaini, Kevin Clark, Robert Geirhos</author><pubDate>Wed, 14 Feb 2024 17:54:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16779v2</guid></item><item><title>Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions</title><link>http://arxiv.org/abs/2402.08082v2</link><description>While score-based generative models (SGMs) have achieved remarkable successin enormous image generation tasks, their mathematical foundations are stilllimited. In this paper, we analyze the approximation and generalization of SGMsin learning a family of sub-Gaussian probability distributions. We introduce anotion of complexity for probability distributions in terms of their relativedensity with respect to the standard Gaussian measure. We prove that if thelog-relative density can be locally approximated by a neural network whoseparameters can be suitably bounded, then the distribution generated byempirical score matching approximates the target distribution in totalvariation with a dimension-independent rate. We illustrate our theory throughexamples, which include certain mixtures of Gaussians. An essential ingredientof our proof is to derive a dimension-free deep neural network approximationrate for the true score function associated with the forward process, which isinteresting in its own right.</description><author>Frank Cole, Yulong Lu</author><pubDate>Wed, 14 Feb 2024 17:53:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08082v2</guid></item><item><title>Addressing cognitive bias in medical language models</title><link>http://arxiv.org/abs/2402.08113v2</link><description>The integration of large language models (LLMs) into the medical field hasgained significant attention due to their promising accuracy in simulatedclinical decision-making settings. However, clinical decision-making is morecomplex than simulations because physicians' decisions are shaped by manyfactors, including the presence of cognitive bias. However, the degree to whichLLMs are susceptible to the same cognitive biases that affect human cliniciansremains unexplored. Our hypothesis posits that when LLMs are confronted withclinical questions containing cognitive biases, they will yield significantlyless accurate responses compared to the same questions presented without suchbiases. In this study, we developed BiasMedQA, a novel benchmark for evaluatingcognitive biases in LLMs applied to medical tasks. Using BiasMedQA we evaluatedsix LLMs, namely GPT-4, Mixtral-8x70B, GPT-3.5, PaLM-2, Llama 2 70B-chat, andthe medically specialized PMC Llama 13B. We tested these models on 1,273questions from the US Medical Licensing Exam (USMLE) Steps 1, 2, and 3,modified to replicate common clinically-relevant cognitive biases. Our analysisrevealed varying effects for biases on these LLMs, with GPT-4 standing out forits resilience to bias, in contrast to Llama 2 70B-chat and PMC Llama 13B,which were disproportionately affected by cognitive bias. Our findingshighlight the critical need for bias mitigation in the development of medicalLLMs, pointing towards safer and more reliable applications in healthcare.</description><author>Samuel Schmidgall, Carl Harris, Ime Essien, Daniel Olshvang, Tawsifur Rahman, Ji Woong Kim, Rojin Ziaei, Jason Eshraghian, Peter Abadir, Rama Chellappa</author><pubDate>Wed, 14 Feb 2024 17:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08113v2</guid></item><item><title>Developing a Framework for Auditing Large Language Models Using Human-in-the-Loop</title><link>http://arxiv.org/abs/2402.09346v1</link><description>As LLMs become more pervasive across various users and scenarios, identifyingpotential issues when using these models becomes essential. Examples includebias, inconsistencies, and hallucination. Although auditing the LLM for theseproblems is desirable, it is far from being easy or solved. An effective methodis to probe the LLM using different versions of the same question. This couldexpose inconsistencies in its knowledge or operation, indicating potential forbias or hallucination. However, to operationalize this auditing method atscale, we need an approach to create those probes reliably and automatically.In this paper we propose an automatic and scalable solution, where one uses adifferent LLM along with human-in-the-loop. This approach offers verifiabilityand transparency, while avoiding circular reliance on the same LLMs, andincreasing scientific rigor and generalizability. Specifically, we present anovel methodology with two phases of verification using humans: standardizedevaluation criteria to verify responses, and a structured prompt template togenerate desired probes. Experiments on a set of questions from TruthfulQAdataset show that we can generate a reliable set of probes from one LLM thatcan be used to audit inconsistencies in a different LLM. The criteria forgenerating and applying auditing probes is generalizable to various LLMsregardless of the underlying structure or training mechanism.</description><author>Maryam Amirizaniani, Jihan Yao, Adrian Lavergne, Elizabeth Snell Okada, Aman Chadha, Tanya Roosta, Chirag Shah</author><pubDate>Wed, 14 Feb 2024 17:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09346v1</guid></item><item><title>Mitigating Reward Hacking via Information-Theoretic Reward Modeling</title><link>http://arxiv.org/abs/2402.09345v1</link><description>Despite the success of reinforcement learning from human feedback (RLHF) inaligning language models with human values, reward hacking, also termed rewardoveroptimization, remains a critical challenge, which primarily stems fromlimitations in reward modeling, i.e., generalizability of the reward model andinconsistency in the preference dataset. In this work, we tackle this problemfrom an information theoretic-perspective, and propose a generalizable androbust framework for reward modeling, namely InfoRM, by introducing avariational information bottleneck objective to filter out irrelevantinformation and developing a mechanism for model complexity modulation.Notably, we further identify a correlation between overoptimization andoutliers in the latent space, establishing InfoRM as a promising tool fordetecting reward overoptimization. Inspired by this finding, we propose theIntegrated Cluster Deviation Score (ICDS), which quantifies deviations in thelatent space, as an indicator of reward overoptimization to facilitate thedevelopment of online mitigation strategies. Extensive experiments on a widerange of settings and model scales (70M, 440M, 1.4B, and 7B) support theeffectiveness of InfoRM. Further analyses reveal that InfoRM's overoptimizationdetection mechanism is effective, potentially signifying a notable advancementin the field of RLHF. Code will be released upon acceptance.</description><author>Yuchun Miao, Sen Zhang, Liang Ding, Rong Bao, Lefei Zhang, Dacheng Tao</author><pubDate>Wed, 14 Feb 2024 17:49:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09345v1</guid></item><item><title>Deep Stochastic Mechanics</title><link>http://arxiv.org/abs/2305.19685v3</link><description>This paper introduces a novel deep-learning-based approach for numericalsimulation of a time-evolving Schr\"odinger equation inspired by stochasticmechanics and generative diffusion models. Unlike existing approaches, whichexhibit computational complexity that scales exponentially in the problemdimension, our method allows us to adapt to the latent low-dimensionalstructure of the wave function by sampling from the Markovian diffusion.Depending on the latent dimension, our method may have far lower computationalcomplexity in higher dimensions. Moreover, we propose novel equations forstochastic quantum mechanics, resulting in linear computational complexity withrespect to the number of dimensions. Numerical simulations verify ourtheoretical findings and show a significant advantage of our method compared toother deep-learning-based approaches used for quantum mechanics.</description><author>Elena Orlova, Aleksei Ustimenko, Ruoxi Jiang, Peter Y. Lu, Rebecca Willett</author><pubDate>Wed, 14 Feb 2024 17:48:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19685v3</guid></item><item><title>Generating Diverse Translation with Perturbed kNN-MT</title><link>http://arxiv.org/abs/2402.09344v1</link><description>Generating multiple translation candidates would enable users to choose theone that satisfies their needs. Although there has been work on diversifiedgeneration, there exists room for improving the diversity mainly because theprevious methods do not address the overcorrection problem -- the modelunderestimates a prediction that is largely different from the training data,even if that prediction is likely. This paper proposes methods that generatemore diverse translations by introducing perturbed k-nearest neighbor machinetranslation (kNN-MT). Our methods expand the search space of kNN-MT and helpincorporate diverse words into candidates by addressing the overcorrectionproblem. Our experiments show that the proposed methods drastically improvecandidate diversity and control the degree of diversity by tuning theperturbation's magnitude.</description><author>Yuto Nishida, Makoto Morishita, Hidetaka Kamigaito, Taro Watanabe</author><pubDate>Wed, 14 Feb 2024 17:46:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09344v1</guid></item><item><title>$\texttt{causalAssembly}$: Generating Realistic Production Data for Benchmarking Causal Discovery</title><link>http://arxiv.org/abs/2306.10816v2</link><description>Algorithms for causal discovery have recently undergone rapid advances andincreasingly draw on flexible nonparametric methods to process complex data.With these advances comes a need for adequate empirical validation of thecausal relationships learned by different algorithms. However, for most realdata sources true causal relations remain unknown. This issue is furthercompounded by privacy concerns surrounding the release of suitable high-qualitydata. To help address these challenges, we gather a complex dataset comprisingmeasurements from an assembly line in a manufacturing context. This lineconsists of numerous physical processes for which we are able to provide groundtruth causal relationships on the basis of a detailed study of the underlyingphysics. We use the assembly line data and associated ground truth informationto build a system for generation of semisynthetic manufacturing data thatsupports benchmarking of causal discovery methods. To accomplish this, weemploy distributional random forests in order to flexibly estimate andrepresent conditional distributions that may be combined into jointdistributions that strictly adhere to a causal model over the observedvariables. The estimated conditionals and tools for data generation are madeavailable in our Python library $\texttt{causalAssembly}$. Using the library,we showcase how to benchmark several well-known causal discovery algorithms.</description><author>Konstantin Göbler, Tobias Windisch, Mathias Drton, Tim Pychynski, Steffen Sonntag, Martin Roth</author><pubDate>Wed, 14 Feb 2024 17:45:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10816v2</guid></item><item><title>David helps Goliath: Inference-Time Collaboration Between Small Specialized and Large General Diffusion LMs</title><link>http://arxiv.org/abs/2305.14771v2</link><description>Diffusion-based language models are emerging as a promising alternative toautoregressive LMs: they approach the competence of autoregressive LMs whileoffering nuanced controllability at inference time. While autoregressive LMshave benefited immensely from scaling and instruction-based learning, existingstudies of diffusion LMs have been conducted on a smaller scale. Starting witha recently proposed diffusion model SSD-LM, in this work we first exploremethods to scale it from 0.4B to 13B parameters, proposing techniques toimprove its training and inference efficiency, and to finetune the model tofollow instructions. Armed with a more powerful, general purpose diffusion LM,we introduce the primary contribution of this work -- SSD-2 -- an approach toeasily ensemble at inference time a large general-purpose diffusion LM withsmaller, but specialized and contextualized diffusion LMs. We show that SSD-2facilitates novel ensembles with 100x smaller models that can be customized anddeployed by individual users. We find that compared to autoregressive models,the collaboration between diffusion LMs is more effective, leading tohigher-quality model responses due to their ability to dynamically incorporatebi-directional contexts.</description><author>Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, Marjan Ghazvininejad</author><pubDate>Wed, 14 Feb 2024 17:45:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14771v2</guid></item><item><title>Optimal Horizon-Free Reward-Free Exploration for Linear Mixture MDPs</title><link>http://arxiv.org/abs/2303.10165v2</link><description>We study reward-free reinforcement learning (RL) with linear functionapproximation, where the agent works in two phases: (1) in the explorationphase, the agent interacts with the environment but cannot access the reward;and (2) in the planning phase, the agent is given a reward function and isexpected to find a near-optimal policy based on samples collected in theexploration phase. The sample complexities of existing reward-free algorithmshave a polynomial dependence on the planning horizon, which makes themintractable for long planning horizon RL problems. In this paper, we propose anew reward-free algorithm for learning linear mixture Markov decision processes(MDPs), where the transition probability can be parameterized as a linearcombination of known feature mappings. At the core of our algorithm isuncertainty-weighted value-targeted regression with exploration-drivenpseudo-reward and a high-order moment estimator for the aleatoric and epistemicuncertainties. When the total reward is bounded by $1$, we show that ouralgorithm only needs to explore $\tilde O( d^2\varepsilon^{-2})$ episodes tofind an $\varepsilon$-optimal policy, where $d$ is the dimension of the featuremapping. The sample complexity of our algorithm only has a polylogarithmicdependence on the planning horizon and therefore is "horizon-free". Inaddition, we provide an $\Omega(d^2\varepsilon^{-2})$ sample complexity lowerbound, which matches the sample complexity of our algorithm up to logarithmicfactors, suggesting that our algorithm is optimal.</description><author>Junkai Zhang, Weitong Zhang, Quanquan Gu</author><pubDate>Wed, 14 Feb 2024 17:44:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10165v2</guid></item><item><title>Registration of Longitudinal Spine CTs for Monitoring Lesion Growth</title><link>http://arxiv.org/abs/2402.09341v1</link><description>Accurate and reliable registration of longitudinal spine images is essentialfor assessment of disease progression and surgical outcome. Implementing afully automatic and robust registration is crucial for clinical use, however,it is challenging due to substantial change in shape and appearance due tolesions. In this paper we present a novel method to automatically alignlongitudinal spine CTs and accurately assess lesion progression. Our methodfollows a two-step pipeline where vertebrae are first automatically localized,labeled and 3D surfaces are generated using a deep learning model, thenlongitudinally aligned using a Gaussian mixture model surface registration. Wetested our approach on 37 vertebrae, from 5 patients, with baseline CTs and 3,6, and 12 months follow-ups leading to 111 registrations. Our experiment showedaccurate registration with an average Hausdorff distance of 0.65 mm and averageDice score of 0.92.</description><author>Malika Sanhinova, Nazim Haouchine, Steve D. Pieper, William M. Wells III, Tracy A. Balboni, Alexander Spektor, Mai Anh Huynh, Jeffrey P. Guenette, Bryan Czajkowski, Sarah Caplan, Patrick Doyle, Heejoo Kang, David B. Hackney, Ron N. Alkalay</author><pubDate>Wed, 14 Feb 2024 17:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09341v1</guid></item><item><title>Neural Networks asymptotic behaviours suitable for the resolution of inverse problems</title><link>http://arxiv.org/abs/2402.09338v1</link><description>In this paper, we perform a study on the effectiveness of Neural Network (NN)techniques for deconvolution inverse problems. We consider NN's asymptoticlimits, corresponding to Gaussian Processes (GPs), where parameternon-linearities are lost. Using these resulting GPs, we address thedeconvolution inverse problem in the case of a quantum harmonic oscillatorsimulated through Monte Carlo techniques on a lattice. A scenario with a knownanalytical solution. Our findings indicate that solving the deconvolutioninverse problem with a fully connected NN yields less performing results thanthose obtained using the GPs derived from NN's asymptotic limits. Furthermore,we observe the trained NN's accuracy approaching that of GPs with increasinglayer width. Notably, one of these GPs defies interpretation as a probabilisticmodel, offering a novel perspective compared to established methods in theliterature. Additionally, the NNs, in their asymptotic limit, providecost-effective analytical solutions.</description><author>Luigi Del Debbio, Manuel Naviglio, Francesco Tarantelli</author><pubDate>Wed, 14 Feb 2024 17:42:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09338v1</guid></item><item><title>AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach</title><link>http://arxiv.org/abs/2402.09334v1</link><description>As Large Language Models (LLMs) gain wider adoption in various contexts, itbecomes crucial to ensure they are reasonably safe, consistent, and reliablefor an application at hand. This may require probing or auditing them. ProbingLLMs with varied iterations of a single question could reveal potentialinconsistencies in their knowledge or functionality. However, a tool forperforming such audits with simple workflow and low technical threshold islacking. In this demo, we introduce "AuditLLM," a novel tool designed toevaluate the performance of various LLMs in a methodical way. AuditLLM's corefunctionality lies in its ability to test a given LLM by auditing it usingmultiple probes generated from a single question, thereby identifying anyinconsistencies in the model's understanding or operation. A reasonably robust,reliable, and consistent LLM should output semantically similar responses for aquestion asked differently or by different people. Based on this assumption,AuditLLM produces easily interpretable results regarding the LLM'sconsistencies from a single question that the user enters. A certain level ofinconsistency has been shown to be an indicator of potential bias,hallucinations, and other issues. One could then use the output of AuditLLM tofurther investigate issues with the aforementioned LLM. To facilitatedemonstration and practical uses, AuditLLM offers two key modes: (1) Live modewhich allows instant auditing of LLMs by analyzing responses to real-timequeries; (2) Batch mode which facilitates comprehensive LLM auditing byprocessing multiple queries at once for in-depth analysis. This tool isbeneficial for both researchers and general users, as it enhances ourunderstanding of LLMs' capabilities in generating responses, using astandardized auditing platform.</description><author>Maryam Amirizaniani, Tanya Roosta, Aman Chadha, Chirag Shah</author><pubDate>Wed, 14 Feb 2024 17:31:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09334v1</guid></item><item><title>Automated Process Planning Based on a Semantic Capability Model and SMT</title><link>http://arxiv.org/abs/2312.08801v2</link><description>In research of manufacturing systems and autonomous robots, the termcapability is used for a machine-interpretable specification of a systemfunction. Approaches in this research area develop information models thatcapture all information relevant to interpret the requirements, effects andbehavior of functions. These approaches are intended to overcome theheterogeneity resulting from the various types of processes and from the largenumber of different vendors. However, these models and associated methods donot offer solutions for automated process planning, i.e. finding a sequence ofindividual capabilities required to manufacture a certain product or toaccomplish a mission using autonomous robots. Instead, this is a typical taskfor AI planning approaches, which unfortunately require a high effort to createthe respective planning problem descriptions. In this paper, we present anapproach that combines these two topics: Starting from a semantic capabilitymodel, an AI planning problem is automatically generated. The planning problemis encoded using Satisfiability Modulo Theories and uses an existing solver tofind valid capability sequences including required parameter values. Theapproach also offers possibilities to integrate existing human expertise and toprovide explanations for human operators in order to help understand planningdecisions.</description><author>Aljosha Köcher, Luis Miguel Vieira da Silva, Alexander Fay</author><pubDate>Wed, 14 Feb 2024 17:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08801v2</guid></item><item><title>3D-based RNA function prediction tools in rnaglib</title><link>http://arxiv.org/abs/2402.09330v1</link><description>Understanding the connection between complex structural features of RNA andbiological function is a fundamental challenge in evolutionary studies and inRNA design. However, building datasets of RNA 3D structures and makingappropriate modeling choices remains time-consuming and lacks standardization.In this chapter, we describe the use of rnaglib, to train supervised andunsupervised machine learning-based function prediction models on datasets ofRNA 3D structures.</description><author>Carlos Oliver, Vincent Mallet, Jérôme Waldispühl</author><pubDate>Wed, 14 Feb 2024 17:22:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09330v1</guid></item><item><title>YOLOv8-AM: YOLOv8 with Attention Mechanisms for Pediatric Wrist Fracture Detection</title><link>http://arxiv.org/abs/2402.09329v1</link><description>Wrist trauma and even fractures occur frequently in daily life, particularlyamong children who account for a significant proportion of fracture cases.Before performing surgery, surgeons often request patients to undergo X-rayimaging first and prepare for it based on the analysis of the radiologist. Withthe development of neural networks, You Only Look Once (YOLO) series modelshave been widely used in fracture detection as computer-assisted diagnosis(CAD). In 2023, Ultralytics presented the latest version of the YOLO models,which has been employed for detecting fractures across various parts of thebody. Attention mechanism is one of the hottest methods to improve the modelperformance. This research work proposes YOLOv8-AM, which incorporates theattention mechanism into the original YOLOv8 architecture. Specifically, werespectively employ four attention modules, Convolutional Block AttentionModule (CBAM), Global Attention Mechanism (GAM), Efficient Channel Attention(ECA), and Shuffle Attention (SA), to design the improved models and train themon GRAZPEDWRI-DX dataset. Experimental results demonstrate that the meanAverage Precision at IoU 50 (mAP 50) of the YOLOv8-AM model based on ResBlock +CBAM (ResCBAM) increased from 63.6% to 65.8%, which achieves thestate-of-the-art (SOTA) performance. Conversely, YOLOv8-AM model incorporatingGAM obtains the mAP 50 value of 64.2%, which is not a satisfactory enhancement.Therefore, we combine ResBlock and GAM, introducing ResGAM to design anothernew YOLOv8-AM model, whose mAP 50 value is increased to 65.0%.</description><author>Chun-Tse Chien, Rui-Yang Ju, Kuang-Yi Chou, Chien-Sheng Lin, Jen-Shiun Chiang</author><pubDate>Wed, 14 Feb 2024 17:18:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09329v1</guid></item><item><title>Connecting Algorithmic Fairness to Quality Dimensions in Machine Learning in Official Statistics and Survey Production</title><link>http://arxiv.org/abs/2402.09328v1</link><description>National Statistical Organizations (NSOs) increasingly draw on MachineLearning (ML) to improve the timeliness and cost-effectiveness of theirproducts. When introducing ML solutions, NSOs must ensure that high standardswith respect to robustness, reproducibility, and accuracy are upheld ascodified, e.g., in the Quality Framework for Statistical Algorithms (QF4SA;Yung et al. 2022). At the same time, a growing body of research focuses onfairness as a pre-condition of a safe deployment of ML to prevent disparatesocial impacts in practice. However, fairness has not yet been explicitlydiscussed as a quality aspect in the context of the application of ML at NSOs.We employ Yung et al. (2022)'s QF4SA quality framework and present a mapping ofits quality dimensions to algorithmic fairness. We thereby extend the QF4SAframework in several ways: we argue for fairness as its own quality dimension,we investigate the interaction of fairness with other dimensions, and weexplicitly address data, both on its own and its interaction with appliedmethodology. In parallel with empirical illustrations, we show how our mappingcan contribute to methodology in the domains of official statistics,algorithmic fairness, and trustworthy machine learning.</description><author>Patrick Oliver Schenk, Christoph Kern</author><pubDate>Wed, 14 Feb 2024 17:18:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09328v1</guid></item><item><title>Information Complexity of Stochastic Convex Optimization: Applications to Generalization and Memorization</title><link>http://arxiv.org/abs/2402.09327v1</link><description>In this work, we investigate the interplay between memorization and learningin the context of \emph{stochastic convex optimization} (SCO). We definememorization via the information a learning algorithm reveals about itstraining data points. We then quantify this information using the framework ofconditional mutual information (CMI) proposed by Steinke and Zakynthinou(2020). Our main result is a precise characterization of the tradeoff betweenthe accuracy of a learning algorithm and its CMI, answering an open questionposed by Livni (2023). We show that, in the $L^2$ Lipschitz--bounded settingand under strong convexity, every learner with an excess error $\varepsilon$has CMI bounded below by $\Omega(1/\varepsilon^2)$ and $\Omega(1/\varepsilon)$,respectively. We further demonstrate the essential role of memorization inlearning problems in SCO by designing an adversary capable of accuratelyidentifying a significant fraction of the training samples in specific SCOproblems. Finally, we enumerate several implications of our results, such as alimitation of generalization bounds based on CMI and the incompressibility ofsamples in SCO problems.</description><author>Idan Attias, Gintare Karolina Dziugaite, Mahdi Haghifam, Roi Livni, Daniel M. Roy</author><pubDate>Wed, 14 Feb 2024 17:17:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09327v1</guid></item><item><title>Stability and Multigroup Fairness in Ranking with Uncertain Predictions</title><link>http://arxiv.org/abs/2402.09326v1</link><description>Rankings are ubiquitous across many applications, from search engines tohiring committees. In practice, many rankings are derived from the output ofpredictors. However, when predictors trained for classification tasks haveintrinsic uncertainty, it is not obvious how this uncertainty should berepresented in the derived rankings. Our work considers ranking functions: mapsfrom individual predictions for a classification task to distributions overrankings. We focus on two aspects of ranking functions: stability toperturbations in predictions and fairness towards both individuals andsubgroups. Not only is stability an important requirement for its own sake, but-- as we show -- it composes harmoniously with individual fairness in the senseof Dwork et al. (2012). While deterministic ranking functions cannot be stableaside from trivial scenarios, we show that the recently proposed uncertaintyaware (UA) ranking functions of Singh et al. (2021) are stable. Our main resultis that UA rankings also achieve multigroup fairness through successfulcomposition with multiaccurate or multicalibrated predictors. Our workdemonstrates that UA rankings naturally interpolate between group andindividual level fairness guarantees, while simultaneously satisfying stabilityguarantees important whenever machine-learned predictions are used.</description><author>Siddartha Devic, Aleksandra Korolova, David Kempe, Vatsal Sharan</author><pubDate>Wed, 14 Feb 2024 17:17:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09326v1</guid></item><item><title>PC-NeRF: Parent-Child Neural Radiance Fields Using Sparse LiDAR Frames in Autonomous Driving Environments</title><link>http://arxiv.org/abs/2402.09325v1</link><description>Large-scale 3D scene reconstruction and novel view synthesis are vital forautonomous vehicles, especially utilizing temporally sparse LiDAR frames.However, conventional explicit representations remain a significant bottlenecktowards representing the reconstructed and synthetic scenes at unlimitedresolution. Although the recently developed neural radiance fields (NeRF) haveshown compelling results in implicit representations, the problem oflarge-scale 3D scene reconstruction and novel view synthesis using sparse LiDARframes remains unexplored. To bridge this gap, we propose a 3D scenereconstruction and novel view synthesis framework called parent-child neuralradiance field (PC-NeRF). Based on its two modules, parent NeRF and child NeRF,the framework implements hierarchical spatial partitioning and multi-levelscene representation, including scene, segment, and point levels. Themulti-level scene representation enhances the efficient utilization of sparseLiDAR point cloud data and enables the rapid acquisition of an approximatevolumetric scene representation. With extensive experiments, PC-NeRF is provento achieve high-precision novel LiDAR view synthesis and 3D reconstruction inlarge-scale scenes. Moreover, PC-NeRF can effectively handle situations withsparse LiDAR frames and demonstrate high deployment efficiency with limitedtraining epochs. Our approach implementation and the pre-trained models areavailable at https://github.com/biter0088/pc-nerf.</description><author>Xiuzhong Hu, Guangming Xiong, Zheng Zang, Peng Jia, Yuxuan Han, Junyi Ma</author><pubDate>Wed, 14 Feb 2024 17:16:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09325v1</guid></item><item><title>Optimal transport for automatic alignment of untargeted metabolomic data</title><link>http://arxiv.org/abs/2306.03218v3</link><description>Untargeted metabolomic profiling through liquid chromatography-massspectrometry (LC-MS) measures a vast array of metabolites within biospecimens,advancing drug development, disease diagnosis, and risk prediction. However,the low throughput of LC-MS poses a major challenge for biomarker discovery,annotation, and experimental comparison, necessitating the merging of multipledatasets. Current data pooling methods encounter practical limitations due totheir vulnerability to data variations and hyperparameter dependence. Here weintroduce GromovMatcher, a flexible and user-friendly algorithm thatautomatically combines LC-MS datasets using optimal transport. By capitalizingon feature intensity correlation structures, GromovMatcher delivers superioralignment accuracy and robustness compared to existing approaches. Thisalgorithm scales to thousands of features requiring minimal hyperparametertuning. Applying our method to experimental patient studies of liver andpancreatic cancer, we discover shared metabolic features related to patientalcohol intake, demonstrating how GromovMatcher facilitates the search forbiomarkers associated with lifestyle risk factors linked to several cancertypes.</description><author>Marie Breeur, George Stepaniants, Pekka Keski-Rahkonen, Philippe Rigollet, Vivian Viallon</author><pubDate>Wed, 14 Feb 2024 17:15:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03218v3</guid></item><item><title>AdvST: Revisiting Data Augmentations for Single Domain Generalization</title><link>http://arxiv.org/abs/2312.12720v2</link><description>Single domain generalization (SDG) aims to train a robust model againstunknown target domain shifts using data from a single source domain. Dataaugmentation has been proven an effective approach to SDG. However, the utilityof standard augmentations, such as translate, or invert, has not been fullyexploited in SDG; practically, these augmentations are used as a part of a datapreprocessing procedure. Although it is intuitive to use many suchaugmentations to boost the robustness of a model to out-of-distribution domainshifts, we lack a principled approach to harvest the benefit brought frommultiple these augmentations. Here, we conceptualize standard dataaugmentations with learnable parameters as semantics transformations that canmanipulate certain semantics of a sample, such as the geometry or color of animage. Then, we propose Adversarial learning with Semantics Transformations(AdvST) that augments the source domain data with semantics transformations andlearns a robust model with the augmented data. We theoretically show that AdvSTessentially optimizes a distributionally robust optimization objective definedon a set of semantics distributions induced by the parameters of semanticstransformations. We demonstrate that AdvST can produce samples that expand thecoverage on target domain data. Compared with the state-of-the-art methods,AdvST, despite being a simple method, is surprisingly competitive and achievesthe best average SDG performance on the Digits, PACS, and DomainNet datasets.Our code is available at https://github.com/gtzheng/AdvST.</description><author>Guangtao Zheng, Mengdi Huai, Aidong Zhang</author><pubDate>Wed, 14 Feb 2024 17:15:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12720v2</guid></item><item><title>Transportation Marketplace Rate Forecast Using Signature Transform</title><link>http://arxiv.org/abs/2401.04857v2</link><description>Freight transportation marketplace rates are typically challenging toforecast accurately. In this work, we have developed a novel statisticaltechnique based on signature transforms and have built a predictive andadaptive model to forecast these marketplace rates. Our technique is based ontwo key elements of the signature transform: one being its universalnonlinearity property, which linearizes the feature space and hence translatesthe forecasting problem into linear regression, and the other being thesignature kernel, which allows for comparing computationally efficientlysimilarities between time series data. Combined, it allows for efficientfeature generation and precise identification of seasonality and regimeswitching in the forecasting process. An algorithm based on our technique has been deployed by Amazon truckingoperations, with far superior forecast accuracy and better interpretabilityversus commercially available industry models, even during the COVID-19pandemic and the Ukraine conflict. Furthermore, our technique is able tocapture the influence of business cycles and the heterogeneity of themarketplace, improving prediction accuracy by more than fivefold, with anestimated annualized saving of \$50MM.</description><author>Haotian Gu, Xin Guo, Timothy L. Jacobs, Philip Kaminsky, Xinyu Li</author><pubDate>Wed, 14 Feb 2024 17:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04857v2</guid></item><item><title>ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization</title><link>http://arxiv.org/abs/2402.09320v1</link><description>Large Language Models (LLMs) rely on Human Preference Alignment (HPA) toensure the generation of safe content. Due to the heavy cost associated withfine-tuning, fine-tuning-free methods have emerged, typically modifying LLMdecoding with external auxiliary methods. However, these methods do notessentially enhance the LLM itself. In this paper, we rethink the derivationprocedures of DPO, based on which we conversely build an instant scorer usingthe states of the LLM before and after In-context Learning (ICL). Accordingly,we propose a novel approach called In-Context Direct Preference Optimization(ICDPO). It enables LLMs to borrow the HPA capabilities from superior LLMs withICL, generating well-aligned responses as estimated by the aforementionedinstant scorer, thereby enhancing the final performance. ICDPO can be furtherenhanced with a two-stage retriever and an upgraded scorer, both offeringbenefits. Extensive experiments show its effectiveness, particularly inoutperforming two fine-tuning-free baselines, and it exhibits competitivenesswith SFT + LoRA. We also conduct detailed analyses to offer comprehensiveinsights into ICDPO.</description><author>Feifan Song, Yuxuan Fan, Xin Zhang, Peiyi Wang, Houfeng Wang</author><pubDate>Wed, 14 Feb 2024 17:14:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09320v1</guid></item><item><title>Leveraging Pre-Trained Autoencoders for Interpretable Prototype Learning of Music Audio</title><link>http://arxiv.org/abs/2402.09318v1</link><description>We present PECMAE, an interpretable model for music audio classificationbased on prototype learning. Our model is based on a previous method, APNet,which jointly learns an autoencoder and a prototypical network. Instead, wepropose to decouple both training processes. This enables us to leverageexisting self-supervised autoencoders pre-trained on much larger data(EnCodecMAE), providing representations with better generalization. APNetallows prototypes' reconstruction to waveforms for interpretability relying onthe nearest training data samples. In contrast, we explore using a diffusiondecoder that allows reconstruction without such dependency. We evaluate ourmethod on datasets for music instrument classification (Medley-Solos-DB) andgenre recognition (GTZAN and a larger in-house dataset), the latter being amore challenging task not addressed with prototypical networks before. We findthat the prototype-based models preserve most of the performance achieved withthe autoencoder embeddings, while the sonification of prototypes benefitsunderstanding the behavior of the classifier.</description><author>Pablo Alonso-Jiménez, Leonardo Pepino, Roser Batlle-Roca, Pablo Zinemanas, Dmitry Bogdanov, Xavier Serra, Martín Rocamora</author><pubDate>Wed, 14 Feb 2024 17:13:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09318v1</guid></item><item><title>Memory-Efficient Continual Learning Object Segmentation for Long Video</title><link>http://arxiv.org/abs/2309.15274v2</link><description>Recent state-of-the-art semi-supervised Video Object Segmentation (VOS)methods have shown significant improvements in target object segmentationaccuracy when information from preceding frames is used in segmenting thecurrent frame. In particular, such memory-based approaches can help a model tomore effectively handle appearance changes (representation drift) orocclusions. Ideally, for maximum performance, Online VOS methods would need allor most of the preceding frames (or their extracted information) to be storedin memory and be used for online learning in later frames. Such a solution isnot feasible for long videos, as the required memory size grows without bound,and such methods can fail when memory is limited and a target objectexperiences repeated representation drifts throughout a video. We propose twonovel techniques to reduce the memory requirement of Online VOS methods whileimproving modeling accuracy and generalization on long videos. Motivated by thesuccess of continual learning techniques in preserving previously-learnedknowledge, here we propose Gated-Regularizer Continual Learning (GRCL), whichimproves the performance of any Online VOS subject to limited memory, and aReconstruction-based Memory Selection Continual Learning (RMSCL), whichempowers Online VOS methods to efficiently benefit from stored information inmemory. We also analyze the performance of a hybrid combination of the twoproposed methods. Experimental results show that the proposed methods are ableto improve the performance of Online VOS models by more than 8%, with improvedrobustness on long-video datasets while maintaining comparable performance onshort-video datasets such as DAVIS16, DAVIS17, and YouTube-VOS18.</description><author>Amir Nazemi, Mohammad Javad Shafiee, Zahra Gharaee, Paul Fieguth</author><pubDate>Wed, 14 Feb 2024 17:11:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15274v2</guid></item><item><title>Only My Model On My Data: A Privacy Preserving Approach Protecting one Model and Deceiving Unauthorized Black-Box Models</title><link>http://arxiv.org/abs/2402.09316v1</link><description>Deep neural networks are extensively applied to real-world tasks, such asface recognition and medical image classification, where privacy and dataprotection are critical. Image data, if not protected, can be exploited toinfer personal or contextual information. Existing privacy preservationmethods, like encryption, generate perturbed images that are unrecognizable toeven humans. Adversarial attack approaches prohibit automated inference evenfor authorized stakeholders, limiting practical incentives for commercial andwidespread adaptation. This pioneering study tackles an unexplored practicalprivacy preservation use case by generating human-perceivable images thatmaintain accurate inference by an authorized model while evading otherunauthorized black-box models of similar or dissimilar objectives, andaddresses the previous research gaps. The datasets employed are ImageNet, forimage classification, Celeba-HQ dataset, for identity classification, andAffectNet, for emotion classification. Our results show that the generatedimages can successfully maintain the accuracy of a protected model and degradethe average accuracy of the unauthorized black-box models to 11.97%, 6.63%, and55.51% on ImageNet, Celeba-HQ, and AffectNet datasets, respectively.</description><author>Weiheng Chai, Brian Testa, Huantao Ren, Asif Salekin, Senem Velipasalar</author><pubDate>Wed, 14 Feb 2024 17:11:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09316v1</guid></item><item><title>Few-Shot Object Detection with Sparse Context Transformers</title><link>http://arxiv.org/abs/2402.09315v1</link><description>Few-shot detection is a major task in pattern recognition which seeks tolocalize objects using models trained with few labeled data. One of themainstream few-shot methods is transfer learning which consists in pretraininga detection model in a source domain prior to its fine-tuning in a targetdomain. However, it is challenging for fine-tuned models to effectivelyidentify new classes in the target domain, particularly when the underlyinglabeled training data are scarce. In this paper, we devise a novel sparsecontext transformer (SCT) that effectively leverages object knowledge in thesource domain, and automatically learns a sparse context from only few trainingimages in the target domain. As a result, it combines different relevant cluesin order to enhance the discrimination power of the learned detectors andreduce class confusion. We evaluate the proposed method on two challengingfew-shot object detection benchmarks, and empirical results show that theproposed method obtains competitive performance compared to the relatedstate-of-the-art.</description><author>Jie Mei, Mingyuan Jiu, Hichem Sahbi, Xiaoheng Jiang, Mingliang Xu</author><pubDate>Wed, 14 Feb 2024 17:10:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09315v1</guid></item><item><title>On the Statistical Benefits of Temporal Difference Learning</title><link>http://arxiv.org/abs/2301.13289v3</link><description>Given a dataset on actions and resulting long-term rewards, a directestimation approach fits value functions that minimize prediction error on thetraining data. Temporal difference learning (TD) methods instead fit valuefunctions by minimizing the degree of temporal inconsistency between estimatesmade at successive time-steps. Focusing on finite state Markov chains, weprovide a crisp asymptotic theory of the statistical advantages of thisapproach. First, we show that an intuitive inverse trajectory poolingcoefficient completely characterizes the percent reduction in mean-squarederror of value estimates. Depending on problem structure, the reduction couldbe enormous or nonexistent. Next, we prove that there can be dramaticimprovements in estimates of the difference in value-to-go for two states: TD'serrors are bounded in terms of a novel measure - the problem's trajectorycrossing time - which can be much smaller than the problem's time horizon.</description><author>David Cheikhi, Daniel Russo</author><pubDate>Wed, 14 Feb 2024 17:06:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13289v3</guid></item><item><title>Embracing the black box: Heading towards foundation models for causal discovery from time series data</title><link>http://arxiv.org/abs/2402.09305v1</link><description>Causal discovery from time series data encompasses many existing solutions,including those based on deep learning techniques. However, these methodstypically do not endorse one of the most prevalent paradigms in deep learning:End-to-end learning. To address this gap, we explore what we call CausalPretraining. A methodology that aims to learn a direct mapping frommultivariate time series to the underlying causal graphs in a supervisedmanner. Our empirical findings suggest that causal discovery in a supervisedmanner is possible, assuming that the training and test time series samplesshare most of their dynamics. More importantly, we found evidence that theperformance of Causal Pretraining can increase with data and model size, evenif the additional data do not share the same dynamics. Further, we provideexamples where causal discovery for real-world data with causally pretrainedneural networks is possible within limits. We argue that this hints at thepossibility of a foundation model for causal discovery.</description><author>Gideon Stein, Maha Shadaydeh, Joachim Denzler</author><pubDate>Wed, 14 Feb 2024 16:49:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09305v1</guid></item><item><title>FD-Vision Mamba for Endoscopic Exposure Correction</title><link>http://arxiv.org/abs/2402.06378v2</link><description>In endoscopic imaging, the recorded images are prone to exposureabnormalities, so maintaining high-quality images is important to assisthealthcare professionals in performing decision-making. To overcome this issue,We design a frequency-domain based network, called FD-Vision Mamba (FDVM-Net),which achieves high-quality image exposure correction by reconstructing thefrequency domain of endoscopic images. Specifically, inspired by the StateSpace Sequence Models (SSMs), we develop a C-SSM block that integrates thelocal feature extraction ability of the convolutional layer with the ability ofthe SSM to capture long-range dependencies. A two-path network is built usingC-SSM as the basic function cell, and these two paths deal with the phase andamplitude information of the image, respectively. Finally, a degradedendoscopic image is reconstructed by FDVM-Net to obtain a high-quality clearimage. Extensive experimental results demonstrate that our method achievesstate-of-the-art results in terms of speed and accuracy, and it is noteworthythat our method can enhance endoscopic images of arbitrary resolution. The URLof the code is \url{https://github.com/zzr-idam/FDVM-Net}.</description><author>Zhuoran Zheng, Jun Zhang</author><pubDate>Wed, 14 Feb 2024 16:48:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06378v2</guid></item><item><title>Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence?</title><link>http://arxiv.org/abs/2402.09303v1</link><description>Recent research has seen many behavioral comparisons between humans and deepneural networks (DNNs) in the domain of image classification. Often, comparisonstudies focus on the end-result of the learning process by measuring andcomparing the similarities in the representations of object categories oncethey have been formed. However, the process of how these representationsemerge$\unicode{x2014}$that is, the behavioral changes and intermediate stagesobserved during the acquisition$\unicode{x2014}$is less often directly andempirically compared. Here we report a detailed investigation of how transferable representationsare acquired in human observers and various classic and state-of-the-art DNNs.We develop a constrained supervised learning environment in which we alignlearning-relevant parameters such as starting point, input modality, availableinput data and the feedback provided. Across the whole learning process weevaluate and compare how well learned representations can be generalized topreviously unseen test data. Our findings indicate that in terms of absolute classification performanceDNNs demonstrate a level of data efficiency comparable to$\unicode{x2014}$andsometimes even exceeding that$\unicode{x2014}$of human learners, challengingsome prevailing assumptions in the field. However, comparisons across theentire learning process reveal significant representational differences: whileDNNs' learning is characterized by a pronounced generalisation lag, humansappear to immediately acquire generalizable representations without apreliminary phase of learning training set-specific information that is onlylater transferred to novel data.</description><author>Lukas S. Huber, Fred W. Mast, Felix A. Wichmann</author><pubDate>Wed, 14 Feb 2024 16:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09303v1</guid></item><item><title>Fast and Effective GNN Training with Linearized Random Spanning Trees</title><link>http://arxiv.org/abs/2306.04828v3</link><description>We present a new effective and scalable framework for training GNNs in nodeclassification tasks, based on the effective resistance, a powerful toolsolidly rooted in graph theory. Our approach progressively refines the GNNweights on an extensive sequence of random spanning trees, suitably transformedinto path graphs that retain essential topological and node information of theoriginal graph. The sparse nature of these path graphs substantially lightensthe computational burden of GNN training. This not only enhances scalabilitybut also effectively addresses common issues like over-squashing,over-smoothing, and performance deterioration caused by overfitting in smalltraining set regimes. We carry out an extensive experimental investigation on anumber of real-world graph benchmarks, where we apply our framework to graphconvolutional networks, showing simultaneous improvement of both training speedand test accuracy over a wide pool of representative baselines.</description><author>Francesco Bonchi, Claudio Gentile, Francesco Paolo Nerini, André Panisson, Fabio Vitale</author><pubDate>Wed, 14 Feb 2024 16:45:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04828v3</guid></item><item><title>U-shaped Vision Mamba for Single Image Dehazing</title><link>http://arxiv.org/abs/2402.04139v3</link><description>Currently, Transformer is the most popular architecture for image dehazing,but due to its large computational complexity, its ability to handle long-rangedependency is limited on resource-constrained devices. To tackle thischallenge, we introduce the U-shaped Vision Mamba (UVM-Net), an efficientsingle-image dehazing network. Inspired by the State Space Sequence Models(SSMs), a new deep sequence model known for its power to handle long sequences,we design a Bi-SSM block that integrates the local feature extraction abilityof the convolutional layer with the ability of the SSM to capture long-rangedependencies. Extensive experimental results demonstrate the effectiveness ofour method. Our method provides a more highly efficient idea of long-rangedependency modeling for image dehazing as well as other image restorationtasks. The URL of the code is \url{https://github.com/zzr-idam/UVM-Net}. Ourmethod takes only \textbf{0.009} seconds to infer a $325 \times 325$ resolutionimage (100FPS) without I/O handling time.</description><author>Zhuoran Zheng, Chen Wu</author><pubDate>Wed, 14 Feb 2024 16:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04139v3</guid></item><item><title>Compression-aware Training of Neural Networks using Frank-Wolfe</title><link>http://arxiv.org/abs/2205.11921v2</link><description>Many existing Neural Network pruning approaches rely on either retraining orinducing a strong bias in order to converge to a sparse solution throughouttraining. A third paradigm, 'compression-aware' training, aims to obtainstate-of-the-art dense models that are robust to a wide range of compressionratios using a single dense training run while also avoiding retraining. Wepropose a framework centered around a versatile family of norm constraints andthe Stochastic Frank-Wolfe (SFW) algorithm that encourage convergence towell-performing solutions while inducing robustness towards convolutionalfilter pruning and low-rank matrix decomposition. Our method is able tooutperform existing compression-aware approaches and, in the case of low-rankmatrix decomposition, it also requires significantly less computationalresources than approaches based on nuclear-norm regularization. Our findingsindicate that dynamically adjusting the learning rate of SFW, as suggested byPokutta et al. (2020), is crucial for convergence and robustness of SFW-trainedmodels and we establish a theoretical foundation for that practice.</description><author>Max Zimmer, Christoph Spiegel, Sebastian Pokutta</author><pubDate>Wed, 14 Feb 2024 16:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.11921v2</guid></item><item><title>Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code</title><link>http://arxiv.org/abs/2402.09299v1</link><description>Code auditing ensures that the developed code adheres to standards,regulations, and copyright protection by verifying that it does not containcode from protected sources. The recent advent of Large Language Models (LLMs)as coding assistants in the software development process poses new challengesfor code auditing. The dataset for training these models is mainly collectedfrom publicly available sources. This raises the issue of intellectual propertyinfringement as developers' codes are already included in the dataset.Therefore, auditing code developed using LLMs is challenging, as it isdifficult to reliably assert if an LLM used during development has been trainedon specific copyrighted codes, given that we do not have access to the trainingdatasets of these models. Given the non-disclosure of the training datasets,traditional approaches such as code clone detection are insufficient forasserting copyright infringement. To address this challenge, we propose a newapproach, TraWiC; a model-agnostic and interpretable method based on membershipinference for detecting code inclusion in an LLM's training dataset. We extractsyntactic and semantic identifiers unique to each program to train a classifierfor detecting code inclusion. In our experiments, we observe that TraWiC iscapable of detecting 83.87% of codes that were used to train an LLM. Incomparison, the prevalent clone detection tool NiCad is only capable ofdetecting 47.64%. In addition to its remarkable performance, TraWiC has lowresource overhead in contrast to pair-wise clone detection that is conductedduring the auditing process of tools like CodeWhisperer reference tracker,across thousands of code snippets.</description><author>Vahid Majdinasab, Amin Nikanjam, Foutse Khomh</author><pubDate>Wed, 14 Feb 2024 16:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09299v1</guid></item><item><title>MolTC: Towards Molecular Relational Modeling In Language Models</title><link>http://arxiv.org/abs/2402.03781v4</link><description>Molecular Relational Learning (MRL), aiming to understand interactionsbetween molecular pairs, plays a pivotal role in advancing biochemicalresearch. Recently, the adoption of large language models (LLMs), known fortheir vast knowledge repositories and advanced logical inference capabilities,has emerged as a promising way for efficient and effective MRL. Despite theirpotential, these methods predominantly rely on the textual data, thus not fullyharnessing the wealth of structural information inherent in molecular graphs.Moreover, the absence of a unified framework exacerbates the issue ofinformation underutilization, as it hinders the sharing of interactionmechanism learned across diverse datasets. To address these challenges, thiswork proposes a novel LLM-based multi-modal framework for Molecular inTeractionprediction following Chain-of-Thought (CoT) theory, termed MolTC, whicheffectively integrate graphical information of two molecules in pair. Forachieving a unified MRL, MolTC innovatively develops a dynamicparameter-sharing strategy for cross-dataset information sharing. Moreover, totrain MolTC efficiently, we introduce a Multi-hierarchical CoT concept torefine its training paradigm, and conduct a comprehensive Molecular InteractiveInstructions dataset for the development of biochemical LLMs involving MRL. Ourexperiments, conducted across various datasets involving over 4,000,000molecular pairs, exhibit the superiority of our method over current GNN andLLM-based baselines. Code is available at https://github.com/MangoKiller/MolTC.</description><author>Junfeng Fang, Shuai Zhang, Chang Wu, Zhengyi Yang, Zhiyuan Liu, Sihang Li, Kun Wang, Wenjie Du, Xiang Wang</author><pubDate>Wed, 14 Feb 2024 16:39:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03781v4</guid></item><item><title>General Identifiability and Achievability for Causal Representation Learning</title><link>http://arxiv.org/abs/2310.15450v2</link><description>This paper focuses on causal representation learning (CRL) under a generalnonparametric latent causal model and a general transformation model that mapsthe latent data to the observational data. It establishes identifiability andachievability results using two hard uncoupled interventions per node in thelatent causal graph. Notably, one does not know which pair of interventionenvironments have the same node intervened (hence, uncoupled). Foridentifiability, the paper establishes that perfect recovery of the latentcausal model and variables is guaranteed under uncoupled interventions. Forachievability, an algorithm is designed that uses observational andinterventional data and recovers the latent causal model and variables withprovable guarantees. This algorithm leverages score variations across differentenvironments to estimate the inverse of the transformer and, subsequently, thelatent variables. The analysis, additionally, recovers the identifiabilityresult for two hard coupled interventions, that is when metadata about the pairof environments that have the same node intervened is known. This paper alsoshows that when observational data is available, additional faithfulnessassumptions that are adopted by the existing literature are unnecessary.</description><author>Burak Varıcı, Emre Acartürk, Karthikeyan Shanmugam, Ali Tajer</author><pubDate>Wed, 14 Feb 2024 16:37:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15450v2</guid></item><item><title>Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings</title><link>http://arxiv.org/abs/2402.08543v2</link><description>Despite a large and significant body of recent work focused on estimating theout-of-sample risk of regularized models in the high dimensional regime, atheoretical understanding of this problem for non-differentiable penalties suchas generalized LASSO and nuclear norm is missing. In this paper we resolve thischallenge. We study this problem in the proportional high dimensional regimewhere both the sample size n and number of features p are large, and n/p andthe signal-to-noise ratio (per observation) remain finite. We provide finitesample upper bounds on the expected squared error of leave-one-outcross-validation (LO) in estimating the out-of-sample risk. The theoreticalframework presented here provides a solid foundation for elucidating empiricalfindings that show the accuracy of LO.</description><author>Haolin Zou, Arnab Auddy, Kamiar Rahnama Rad, Arian Maleki</author><pubDate>Wed, 14 Feb 2024 16:28:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08543v2</guid></item><item><title>Investigating Out-of-Distribution Generalization of GNNs: An Architecture Perspective</title><link>http://arxiv.org/abs/2402.08228v2</link><description>Graph neural networks (GNNs) have exhibited remarkable performance under theassumption that test data comes from the same distribution of training data.However, in real-world scenarios, this assumption may not always be valid.Consequently, there is a growing focus on exploring the Out-of-Distribution(OOD) problem in the context of graphs. Most existing efforts have primarilyconcentrated on improving graph OOD generalization from two\textbf{model-agnostic} perspectives: data-driven methods and strategy-basedlearning. However, there has been limited attention dedicated to investigatingthe impact of well-known \textbf{GNN model architectures} on graph OODgeneralization, which is orthogonal to existing research. In this work, weprovide the first comprehensive investigation of OOD generalization on graphsfrom an architecture perspective, by examining the common building blocks ofmodern GNNs. Through extensive experiments, we reveal that both the graphself-attention mechanism and the decoupled architecture contribute positivelyto graph OOD generalization. In contrast, we observe that the linearclassification layer tends to compromise graph OOD generalization capability.Furthermore, we provide in-depth theoretical insights and discussions tounderpin these discoveries. These insights have empowered us to develop a novelGNN backbone model, DGAT, designed to harness the robust properties of bothgraph self-attention mechanism and the decoupled architecture. Extensiveexperimental results demonstrate the effectiveness of our model under graphOOD, exhibiting substantial and consistent enhancements across various trainingstrategies.</description><author>Kai Guo, Hongzhi Wen, Wei Jin, Yaming Guo, Jiliang Tang, Yi Chang</author><pubDate>Wed, 14 Feb 2024 16:26:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08228v2</guid></item><item><title>Metal Oxide-based Gas Sensor Array for the VOCs Analysis in Complex Mixtures using Machine Learning</title><link>http://arxiv.org/abs/2307.06556v2</link><description>Detection of Volatile Organic Compounds (VOCs) from the breath is becoming aviable route for the early detection of diseases non-invasively. This paperpresents a sensor array with three metal oxide electrodes that can use machinelearning methods to identify four distinct VOCs in a mixture. The metal oxidesensor array was subjected to various VOC concentrations, including ethanol,acetone, toluene and chloroform. The dataset obtained from individual gases andtheir mixtures were analyzed using multiple machine learning algorithms, suchas Random Forest (RF), K-Nearest Neighbor (KNN), Decision Tree, LinearRegression, Logistic Regression, Naive Bayes, Linear Discriminant Analysis,Artificial Neural Network, and Support Vector Machine. KNN and RF have shownmore than 99% accuracy in classifying different varying chemicals in the gasmixtures. In regression analysis, KNN has delivered the best results with R2value of more than 0.99 and LOD of 0.012, 0.015, 0.014 and 0.025 PPM forpredicting the concentrations of varying chemicals Acetone, Toluene, Ethanol,and Chloroform, respectively in complex mixtures. Therefore, it is demonstratedthat the array utilizing the provided algorithms can classify and predict theconcentrations of the four gases simultaneously for disease diagnosis andtreatment monitoring.</description><author>Shivam Singh, Sajana S, Poornima, Gajje Sreelekha, Chandranath Adak, Rajendra P. Shukla, Vinayak Kamble</author><pubDate>Wed, 14 Feb 2024 16:25:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06556v2</guid></item><item><title>Learning Interpretable Policies in Hindsight-Observable POMDPs through Partially Supervised Reinforcement Learning</title><link>http://arxiv.org/abs/2402.09290v1</link><description>Deep reinforcement learning has demonstrated remarkable achievements acrossdiverse domains such as video games, robotic control, autonomous driving, anddrug discovery. Common methodologies in partially-observable domains largelylean on end-to-end learning from high-dimensional observations, such as images,without explicitly reasoning about true state. We suggest an alternativedirection, introducing the Partially Supervised Reinforcement Learning (PSRL)framework. At the heart of PSRL is the fusion of both supervised andunsupervised learning. The approach leverages a state estimator to distillsupervised semantic state information from high-dimensional observations whichare often fully observable at training time. This yields more interpretablepolicies that compose state predictions with control. In parallel, it capturesan unsupervised latent representation. These two-the semantic state and thelatent state-are then fused and utilized as inputs to a policy network. Thisjuxtaposition offers practitioners a flexible and dynamic spectrum: fromemphasizing supervised state information to integrating richer, latentinsights. Extensive experimental results indicate that by merging these dualrepresentations, PSRL offers a potent balance, enhancing model interpretabilitywhile preserving, and often significantly outperforming, the performancebenchmarks set by traditional methods in terms of reward and convergence speed.</description><author>Michael Lanier, Ying Xu, Nathan Jacobs, Chongjie Zhang, Yevgeniy Vorobeychik</author><pubDate>Wed, 14 Feb 2024 16:23:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09290v1</guid></item><item><title>EcoVal: An Efficient Data Valuation Framework for Machine Learning</title><link>http://arxiv.org/abs/2402.09288v1</link><description>Quantifying the value of data within a machine learning workflow can play apivotal role in making more strategic decisions in machine learninginitiatives. The existing Shapley value based frameworks for data valuation inmachine learning are computationally expensive as they require considerableamount of repeated training of the model to obtain the Shapley value. In thispaper, we introduce an efficient data valuation framework EcoVal, to estimatethe value of data for machine learning models in a fast and practical manner.Instead of directly working with individual data sample, we determine the valueof a cluster of similar data points. This value is further propagated amongstall the member cluster points. We show that the overall data value can bedetermined by estimating the intrinsic and extrinsic value of each data. Thisis enabled by formulating the performance of a model as a \textit{productionfunction}, a concept which is popularly used to estimate the amount of outputbased on factors like labor and capital in a traditional free economic market.We provide a formal proof of our valuation technique and elucidate theprinciples and mechanisms that enable its accelerated performance. Wedemonstrate the real-world applicability of our method by showcasing itseffectiveness for both in-distribution and out-of-sample data. This workaddresses one of the core challenges of efficient data valuation at scale inmachine learning models.</description><author>Ayush K Tarun, Vikram S Chundawat, Murari Mandal, Hong Ming Tan, Bowei Chen, Mohan Kankanhalli</author><pubDate>Wed, 14 Feb 2024 16:21:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09288v1</guid></item><item><title>Nutrition Facts, Drug Facts, and Model Facts: Putting AI Ethics into Practice in Gun Violence Research</title><link>http://arxiv.org/abs/2402.09286v1</link><description>Objective: Firearm injury research necessitates using data fromoften-exploited vulnerable populations of Black and Brown Americans. In orderto minimize distrust, this study provides a framework for establishing AI trustand transparency with the general population. Methods: We propose a Model Factstemplate that is easily extendable and decomposes accuracy and demographicsinto standardized and minimally complex values. This framework allows generalusers to assess the validity and biases of a model without diving intotechnical model documentation. Examples: We apply the Model Facts template ontwo previously published models, a violence risk identification model and asuicide risk prediction model. We demonstrate the ease of accessing theappropriate information when the data is structured appropriately. Discussion:The Model Facts template is limited in its current form to human based data andbiases. Like nutrition facts, it also will require some educational resourcesfor users to grasp its full utility. Human computer interaction experimentsshould be conducted to ensure that the interaction between user interface andmodel interface is as desired. Conclusion: The Model Facts label is the firstframework dedicated to establishing trust with end users and general populationconsumers. Implementation of Model Facts into firearm injury research willprovide public health practitioners and those impacted by firearm injurygreater faith in the tools the research provides.</description><author>Jessica Zhu, Dr. Michel Cukier, Dr. Joseph Richardson Jr</author><pubDate>Wed, 14 Feb 2024 16:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09286v1</guid></item><item><title>Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey</title><link>http://arxiv.org/abs/2402.09283v1</link><description>Large Language Models (LLMs) are now commonplace in conversationapplications. However, their risks of misuse for generating harmful responseshave raised serious societal concerns and spurred recent research on LLMconversation safety. Therefore, in this survey, we provide a comprehensiveoverview of recent studies, covering three critical aspects of LLM conversationsafety: attacks, defenses, and evaluations. Our goal is to provide a structuredsummary that enhances understanding of LLM conversation safety and encouragesfurther investigation into this important subject. For easy reference, we havecategorized all the studies mentioned in this survey according to our taxonomy,available at: https://github.com/niconi19/LLM-conversation-safety.</description><author>Zhichen Dong, Zhanhui Zhou, Chao Yang, Jing Shao, Yu Qiao</author><pubDate>Wed, 14 Feb 2024 16:14:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09283v1</guid></item><item><title>Counterfactual Generative Models for Time-Varying Treatments</title><link>http://arxiv.org/abs/2305.15742v3</link><description>Estimating the counterfactual outcome of treatment is essential fordecision-making in public health and clinical science, among others. Often,treatments are administered in a sequential, time-varying manner, leading to anexponentially increased number of possible counterfactual outcomes.Furthermore, in modern applications, the outcomes are high-dimensional andconventional average treatment effect estimation fails to capture disparitiesin individuals. To tackle these challenges, we propose a novel conditionalgenerative framework capable of producing counterfactual samples undertime-varying treatment, without the need for explicit density estimation. Ourmethod carefully addresses the distribution mismatch between the observed andcounterfactual distributions via a loss function based on inverse probabilityre-weighting, and supports integration with state-of-the-art conditionalgenerative models such as the guided diffusion and conditional variationalautoencoder. We present a thorough evaluation of our method using bothsynthetic and real-world data. Our results demonstrate that our method iscapable of generating high-quality counterfactual samples and outperforms thestate-of-the-art baselines.</description><author>Shenghao Wu, Wenbin Zhou, Minshuo Chen, Shixiang Zhu</author><pubDate>Wed, 14 Feb 2024 16:12:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15742v3</guid></item><item><title>Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies</title><link>http://arxiv.org/abs/2402.09282v1</link><description>The integration of Large Language Models (LLMs) like GPT-4 into traditionalNatural Language Processing (NLP) tasks has opened new avenues for enhancingmodel performance while reducing the reliance on extensive human annotations.This paper presents a novel approach that leverages the Chain of Thought (CoT)prompting technique to distill knowledge from GPT-4, subsequently applying itto improve the efficiency and effectiveness of a smaller model, BERT, on NamedEntity Recognition (NER) tasks. Our method involves a two-phase trainingprocess: initially employing GPT-4 annotated data for pre-training and thenrefining the model with a combination of distilled and original human-annotateddata. The results demonstrate that our mixed-training strategy significantlyoutperforms models trained solely on human annotations, achieving superiorF1-scores and showcasing a cost-effective solution for resource-limited orclosed-network settings. The study also discusses the challenges encountered,such as LLM output variability and the tendency towards hallucinations,proposing future work directions to enhance prompt design and annotationselection. Our findings indicate a promising synergy between LLM insights andtraditional NLP techniques, paving the way for more accessible and robust NLPapplications.</description><author>Yining Huang</author><pubDate>Wed, 14 Feb 2024 16:10:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09282v1</guid></item><item><title>Synergistic eigenanalysis of covariance and Hessian matrices for enhanced binary classification</title><link>http://arxiv.org/abs/2402.09281v1</link><description>Covariance and Hessian matrices have been analyzed separately in theliterature for classification problems. However, integrating these matrices hasthe potential to enhance their combined power in improving classificationperformance. We present a novel approach that combines the eigenanalysis of acovariance matrix evaluated on a training set with a Hessian matrix evaluatedon a deep learning model to achieve optimal class separability in binaryclassification tasks. Our approach is substantiated by formal proofs thatestablish its capability to maximize between-class mean distance and minimizewithin-class variances. By projecting data into the combined space of the mostrelevant eigendirections from both matrices, we achieve optimal classseparability as per the linear discriminant analysis (LDA) criteria. Empiricalvalidation across neural and health datasets consistently supports ourtheoretical framework and demonstrates that our method outperforms establishedmethods. Our method stands out by addressing both LDA criteria, unlike PCA andthe Hessian method, which predominantly emphasize one criterion each. Thiscomprehensive approach captures intricate patterns and relationships, enhancingclassification performance. Furthermore, through the utilization of both LDAcriteria, our method outperforms LDA itself by leveraging higher-dimensionalfeature spaces, in accordance with Cover's theorem, which favors linearseparability in higher dimensions. Our method also surpasses kernel-basedmethods and manifold learning techniques in performance. Additionally, ourapproach sheds light on complex DNN decision-making, rendering themcomprehensible within a 2D space.</description><author>Agus Hartoyo, Jan Argasiński, Aleksandra Trenk, Kinga Przybylska, Anna Błasiak, Alessandro Crimi</author><pubDate>Wed, 14 Feb 2024 16:10:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09281v1</guid></item><item><title>On the Communication Complexity of Decentralized Bilevel Optimization</title><link>http://arxiv.org/abs/2311.11342v2</link><description>Decentralized bilevel optimization has been actively studied in the past fewyears since it has widespread applications in machine learning. However,existing algorithms suffer from large communication complexity caused by theestimation of stochastic hypergradient, limiting their application toreal-world tasks. To address this issue, we develop a novel decentralizedstochastic bilevel gradient descent algorithm under the heterogeneous setting,which enjoys a small communication cost in each round and a small number ofcommunication rounds. As such, it can achieve a much better communicationcomplexity than existing algorithms without any strong assumptions regardingheterogeneity. To the best of our knowledge, this is the first stochasticalgorithm achieving these theoretical results under the heterogeneous setting.At last, the experimental results confirm the efficacy of our algorithm.</description><author>Yihan Zhang, My T. Thai, Jie Wu, Hongchang Gao</author><pubDate>Wed, 14 Feb 2024 16:08:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11342v2</guid></item><item><title>An All Deep System for Badminton Game Analysis</title><link>http://arxiv.org/abs/2308.12645v2</link><description>The CoachAI Badminton 2023 Track1 initiative aim to automatically detectevents within badminton match videos. Detecting small objects, especially theshuttlecock, is of quite importance and demands high precision within thechallenge. Such detection is crucial for tasks like hit count, hitting time,and hitting location. However, even after revising the well-regardedshuttlecock detecting model, TrackNet, our object detection models still fallshort of the desired accuracy. To address this issue, we've implemented variousdeep learning methods to tackle the problems arising from noisy detectied data,leveraging diverse data types to improve precision. In this report, we detailthe detection model modifications we've made and our approach to the 11 tasks.Notably, our system garnered a score of 0.78 out of 1.0 in the challenge. Wehave released our source code in Githubhttps://github.com/jean50621/Badminton_Challenge</description><author>Po-Yung Chou, Yu-Chun Lo, Bo-Zheng Xie, Cheng-Hung Lin, Yu-Yung Kao</author><pubDate>Wed, 14 Feb 2024 15:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12645v2</guid></item><item><title>Hybrid Machine Learning techniques in the management of harmful algal blooms impact</title><link>http://arxiv.org/abs/2402.09271v1</link><description>Harmful algal blooms (HABs) are episodes of high concentrations of algae thatare potentially toxic for human consumption. Mollusc farming can be affected byHABs because, as filter feeders, they can accumulate high concentrations ofmarine biotoxins in their tissues. To avoid the risk to human consumption,harvesting is prohibited when toxicity is detected. At present, the closure ofproduction areas is based on expert knowledge and the existence of a predictivemodel would help when conditions are complex and sampling is not possible.Although the concentration of toxin in meat is the method most commonly used byexperts in the control of shellfish production areas, it is rarely used as atarget by automatic prediction models. This is largely due to the irregularityof the data due to the established sampling programs. As an alternative, theactivity status of production areas has been proposed as a target variablebased on whether mollusc meat has a toxicity level below or above the legallimit. This new option is the most similar to the actual functioning of thecontrol of shellfish production areas. For this purpose, we have made acomparison between hybrid machine learning models like Neural-Network-AddingBootstrap (BAGNET) and Discriminative Nearest Neighbor Classification (SVM-KNN)when estimating the state of production areas. The study has been carried outin several estuaries with different levels of complexity in the episodes ofalgal blooms to demonstrate the generalization capacity of the models in bloomdetection. As a result, we could observe that, with an average recall value of93.41% and without dropping below 90% in any of the estuaries, BAGNEToutperforms the other models both in terms of results and robustness.</description><author>Andres Molares-Ulloa, Daniel Rivero, Jesus Gil Ruiz, Enrique Fernandez-Blanco, Luis de-la-Fuente-Valentín</author><pubDate>Wed, 14 Feb 2024 15:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09271v1</guid></item><item><title>Fast Window-Based Event Denoising with Spatiotemporal Correlation Enhancement</title><link>http://arxiv.org/abs/2402.09270v1</link><description>Previous deep learning-based event denoising methods mostly suffer from poorinterpretability and difficulty in real-time processing due to their complexarchitecture designs. In this paper, we propose window-based event denoising,which simultaneously deals with a stack of events while existing element-baseddenoising focuses on one event each time. Besides, we give the theoreticalanalysis based on probability distributions in both temporal and spatialdomains to improve interpretability. In temporal domain, we use timestampdeviations between processing events and central event to judge the temporalcorrelation and filter out temporal-irrelevant events. In spatial domain, wechoose maximum a posteriori (MAP) to discriminate real-world event and noise,and use the learned convolutional sparse coding to optimize the objectivefunction. Based on the theoretical analysis, we build Temporal Window (TW)module and Soft Spatial Feature Embedding (SSFE) module to process temporal andspatial information separately, and construct a novel multi-scale window-basedevent denoising network, named MSDNet. The high denoising accuracy and fastrunning speed of our MSDNet enables us to achieve real-time denoising incomplex scenes. Extensive experimental results verify the effectiveness androbustness of our MSDNet. Our algorithm can remove event noise effectively andefficiently and improve the performance of downstream tasks.</description><author>Huachen Fang, Jinjian Wu, Qibin Hou, Weisheng Dong, Guangming Shi</author><pubDate>Wed, 14 Feb 2024 15:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09270v1</guid></item><item><title>Personalized Large Language Models</title><link>http://arxiv.org/abs/2402.09269v1</link><description>Large language models (LLMs) have significantly advanced Natural LanguageProcessing (NLP) tasks in recent years. However, their universal nature poseslimitations in scenarios requiring personalized responses, such asrecommendation systems and chatbots. This paper investigates methods topersonalize LLMs, comparing fine-tuning and zero-shot reasoning approaches onsubjective tasks. Results demonstrate that personalized fine-tuning improvesmodel reasoning compared to non-personalized models. Experiments on datasetsfor emotion recognition and hate speech detection show consistent performancegains with personalized methods across different LLM architectures. Thesefindings underscore the importance of personalization for enhancing LLMcapabilities in subjective text perception tasks.</description><author>Stanisław Woźniak, Bartłomiej Koptyra, Arkadiusz Janz, Przemysław Kazienko, Jan Kocoń</author><pubDate>Wed, 14 Feb 2024 15:55:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09269v1</guid></item><item><title>Transformers, parallel computation, and logarithmic depth</title><link>http://arxiv.org/abs/2402.09268v1</link><description>We show that a constant number of self-attention layers can efficientlysimulate, and be simulated by, a constant number of communication rounds ofMassively Parallel Computation. As a consequence, we show that logarithmicdepth is sufficient for transformers to solve basic computational tasks thatcannot be efficiently solved by several other neural sequence models andsub-quadratic transformer approximations. We thus establish parallelism as akey distinguishing property of transformers.</description><author>Clayton Sanford, Daniel Hsu, Matus Telgarsky</author><pubDate>Wed, 14 Feb 2024 15:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09268v1</guid></item><item><title>Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation</title><link>http://arxiv.org/abs/2402.09267v1</link><description>Despite showing increasingly human-like abilities, large language models(LLMs) often struggle with factual inaccuracies, i.e. "hallucinations", evenwhen they hold relevant knowledge. To address these hallucinations, currentapproaches typically necessitate high-quality human factuality annotations. Inthis work, we explore Self-Alignment for Factuality, where we leverage theself-evaluation capability of an LLM to provide training signals that steer themodel towards factuality. Specifically, we incorporate Self-Eval, aself-evaluation component, to prompt an LLM to validate the factuality of itsown generated responses solely based on its internal knowledge. Additionally,we design Self-Knowledge Tuning (SK-Tuning) to augment the LLM'sself-evaluation ability by improving the model's confidence estimation andcalibration. We then utilize these self-annotated responses to fine-tune themodel via Direct Preference Optimization algorithm. We show that the proposedself-alignment approach substantially enhances factual accuracy over Llamafamily models across three key knowledge-intensive tasks on TruthfulQA andBioGEN.</description><author>Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Lifeng Jin, Linfeng Song, Haitao Mi, Helen Meng</author><pubDate>Wed, 14 Feb 2024 15:52:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09267v1</guid></item><item><title>Machine Learning in management of precautionary closures caused by lipophilic biotoxins</title><link>http://arxiv.org/abs/2402.09266v1</link><description>Mussel farming is one of the most important aquaculture industries. The mainrisk to mussel farming is harmful algal blooms (HABs), which pose a risk tohuman consumption. In Galicia, the Spanish main producer of cultivated mussels,the opening and closing of the production areas is controlled by a monitoringprogram. In addition to the closures resulting from the presence of toxicityexceeding the legal threshold, in the absence of a confirmatory sampling andthe existence of risk factors, precautionary closures may be applied. Thesedecisions are made by experts without the support or formalisation of theexperience on which they are based. Therefore, this work proposes a predictivemodel capable of supporting the application of precautionary closures.Achieving sensitivity, accuracy and kappa index values of 97.34%, 91.83% and0.75 respectively, the kNN algorithm has provided the best results. This allowsthe creation of a system capable of helping in complex situations whereforecast errors are more common.</description><author>Andres Molares-Ulloa, Enrique Fernandez-Blanco, Alejandro Pazos, Daniel Rivero</author><pubDate>Wed, 14 Feb 2024 15:51:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09266v1</guid></item><item><title>Computational Complexity of Preferred Subset Repairs on Data-Graphs</title><link>http://arxiv.org/abs/2402.09265v1</link><description>The problem of repairing inconsistent knowledge bases has a long historywithin the communities of database theory and knowledge representation andreasoning, especially from the perspective of structured data. However, as thedata available in real-world domains becomes more complex and interconnected,the need naturally arises for developing new types of repositories,representation languages, and semantics, to allow for more suitable ways toquery and reason about it. Graph databases provide an effective way torepresent relationships among semi-structured data, and allow processing andquerying these connections efficiently. In this work, we focus on the problemof computing prioritized repairs over graph databases with data values, using anotion of consistency based on Reg-GXPath expressions as integrity constraints.We present several preference criteria based on the standard subset repairsemantics, incorporating weights, multisets, and set-based priority levels. Westudy the most common repairing tasks, showing that it is possible to maintainthe same computational complexity as in the case where no preference criterionis available for exploitation. To complete the picture, we explore thecomplexity of consistent query answering in this setting and obtain tight lowerand upper bounds for all the preference criteria introduced.</description><author>Nina Pardal, Santiago Cifuentes, Edwin Pin, Maria Vanina Martinez, Sergio Abriola</author><pubDate>Wed, 14 Feb 2024 15:51:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09265v1</guid></item><item><title>UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers</title><link>http://arxiv.org/abs/2402.09264v1</link><description>Traditional machine learning techniques are prone to generating inaccuratepredictions when confronted with shifts in the distribution of data between thetraining and testing phases. This vulnerability can lead to severeconsequences, especially in applications such as mobile healthcare. Uncertaintyestimation has the potential to mitigate this issue by assessing thereliability of a model's output. However, existing uncertainty estimationtechniques often require substantial computational resources and memory, makingthem impractical for implementation on microcontrollers (MCUs). This limitationhinders the feasibility of many important on-device wearable event detection(WED) applications, such as heart attack detection. In this paper, we present UR2M, a novel Uncertainty and Resource-aware eventdetection framework for MCUs. Specifically, we (i) develop an uncertainty-awareWED based on evidential theory for accurate event detection and reliableuncertainty estimation; (ii) introduce a cascade ML framework to achieveefficient model inference via early exits, by sharing shallower model layersamong different event models; (iii) optimize the deployment of the model andMCU library for system efficiency. We conducted extensive experiments andcompared UR2M to traditional uncertainty baselines using three wearabledatasets. Our results demonstrate that UR2M achieves up to 864% fasterinference speed, 857% energy-saving for uncertainty estimation, 55% memorysaving on two popular MCUs, and a 22% improvement in uncertainty quantificationperformance. UR2M can be deployed on a wide range of MCUs, significantly expandingreal-time and reliable WED applications.</description><author>Hong Jia, Young D. Kwon, Dong Ma, Nhat Pham, Lorena Qendro, Tam Vu, Cecilia Mascolo</author><pubDate>Wed, 14 Feb 2024 15:51:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09264v1</guid></item><item><title>Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion</title><link>http://arxiv.org/abs/2401.06072v2</link><description>Temporal Knowledge Graph Completion (TKGC) is a complex task involving theprediction of missing event links at future timestamps by leveragingestablished temporal structural knowledge. This paper aims to provide acomprehensive perspective on harnessing the advantages of Large Language Models(LLMs) for reasoning in temporal knowledge graphs, presenting an easilytransferable pipeline. In terms of graph modality, we underscore the LLMs'prowess in discerning the structural information of pivotal nodes within thehistorical chain. As for the generation mode of the LLMs utilized forinference, we conduct an exhaustive exploration into the variances induced by arange of inherent factors in LLMs, with particular attention to the challengesin comprehending reverse logic. We adopt a parameter-efficient fine-tuningstrategy to harmonize the LLMs with the task requirements, facilitating thelearning of the key knowledge highlighted earlier. Comprehensive experimentsare undertaken on several widely recognized datasets, revealing that ourframework exceeds or parallels existing methods across numerous popularmetrics. Additionally, we execute a substantial range of ablation experimentsand draw comparisons with several advanced commercial LLMs, to investigate thecrucial factors influencing LLMs' performance in structured temporal knowledgeinference tasks.</description><author>Ruilin Luo, Tianle Gu, Haoling Li, Junzhe Li, Zicheng Lin, Jiayi Li, Yujiu Yang</author><pubDate>Wed, 14 Feb 2024 15:49:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06072v2</guid></item><item><title>MultiMedEval: A Benchmark and a Toolkit for Evaluating Medical Vision-Language Models</title><link>http://arxiv.org/abs/2402.09262v1</link><description>We introduce MultiMedEval, an open-source toolkit for fair and reproducibleevaluation of large, medical vision-language models (VLM). MultiMedEvalcomprehensively assesses the models' performance on a broad array of sixmulti-modal tasks, conducted over 23 datasets, and spanning over 11 medicaldomains. The chosen tasks and performance metrics are based on their widespreadadoption in the community and their diversity, ensuring a thorough evaluationof the model's overall generalizability. We open-source a Python toolkit(github.com/corentin-ryr/MultiMedEval) with a simple interface and setupprocess, enabling the evaluation of any VLM in just a few lines of code. Ourgoal is to simplify the intricate landscape of VLM evaluation, thus promotingfair and uniform benchmarking of future models.</description><author>Corentin Royer, Bjoern Menze, Anjany Sekuboyina</author><pubDate>Wed, 14 Feb 2024 15:49:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09262v1</guid></item><item><title>SyntaxShap: Syntax-aware Explainability Method for Text Generation</title><link>http://arxiv.org/abs/2402.09259v1</link><description>To harness the power of large language models in safety-critical domains weneed to ensure the explainability of their predictions. However, despite thesignificant attention to model interpretability, there remains an unexploreddomain in explaining sequence-to-sequence tasks using methods tailored fortextual data. This paper introduces SyntaxShap, a local, model-agnosticexplainability method for text generation that takes into consideration thesyntax in the text data. The presented work extends Shapley values to accountfor parsing-based syntactic dependencies. Taking a game theoric approach,SyntaxShap only considers coalitions constraint by the dependency tree. Weadopt a model-based evaluation to compare SyntaxShap and its weighted form tostate-of-the-art explainability methods adapted to text generation tasks, usingdiverse metrics including faithfulness, complexity, coherency, and semanticalignment of the explanations to the model. We show that our syntax-awaremethod produces explanations that help build more faithful, coherent, andinterpretable explanations for predictions by autoregressive models.</description><author>Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady</author><pubDate>Wed, 14 Feb 2024 15:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09259v1</guid></item><item><title>Improving image quality of sparse-view lung tumor CT images with U-Net</title><link>http://arxiv.org/abs/2307.15506v4</link><description>Background: We aimed at improving image quality (IQ) of sparse-view computedtomography (CT) images using a U-Net for lung metastasis detection anddetermining the best tradeoff between number of views, IQ, and diagnosticconfidence. Methods: CT images from 41 subjects aged 62.8 $\pm$ 10.6 years (mean $\pm$standard deviation), 23 men, 34 with lung metastasis, 7 healthy, wereretrospectively selected (2016-2018) and forward projected onto 2,048-viewsinograms. Six corresponding sparse-view CT data subsets at varying levels ofundersampling were reconstructed from sinograms using filtered backprojectionwith 16, 32, 64, 128, 256, and 512 views. A dual-frame U-Net was trained andevaluated for each subsampling level on 8,658 images from 22 diseased subjects.A representative image per scan was selected from 19 subjects (12 diseased, 7healthy) for a single-blinded multireader study. These slices, for all levelsof subsampling, with and without U-Net postprocessing, were presented to threereaders. IQ and diagnostic confidence were ranked using predefined scales.Subjective nodule segmentation was evaluated using sensitivity and Dicesimilarity coefficient (DSC); clustered Wilcoxon signed-rank test was used. Results: The 64-projection sparse-view images resulted in 0.89 sensitivityand 0.81 DSC, while their counterparts, postprocessed with the U-Net, hadimproved metrics (0.94 sensitivity and 0.85 DSC) (p = 0.400). Fewer views ledto insufficient IQ for diagnosis. For increased views, no substantialdiscrepancies were noted between sparse-view and postprocessed images. Conclusions: Projection views can be reduced from 2,048 to 64 whilemaintaining IQ and the confidence of the radiologists on a satisfactory level.</description><author>Annika Ries, Tina Dorosti, Johannes Thalhammer, Daniel Sasse, Andreas Sauter, Felix Meurer, Ashley Benne, Tobias Lasser, Franz Pfeiffer, Florian Schaff, Daniela Pfeiffer</author><pubDate>Wed, 14 Feb 2024 15:42:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15506v4</guid></item><item><title>CM-MaskSD: Cross-Modality Masked Self-Distillation for Referring Image Segmentation</title><link>http://arxiv.org/abs/2305.11481v3</link><description>Referring image segmentation (RIS) is a fundamental vision-language task thatintends to segment a desired object from an image based on a given naturallanguage expression. Due to the essentially distinct data properties betweenimage and text, most of existing methods either introduce complex designstowards fine-grained vision-language alignment or lack required densealignment, resulting in scalability issues or mis-segmentation problems such asover- or under-segmentation. To achieve effective and efficient fine-grainedfeature alignment in the RIS task, we explore the potential of maskedmultimodal modeling coupled with self-distillation and propose a novelcross-modality masked self-distillation framework named CM-MaskSD, in which ourmethod inherits the transferred knowledge of image-text semantic alignment fromCLIP model to realize fine-grained patch-word feature alignment for bettersegmentation accuracy. Moreover, our CM-MaskSD framework can considerably boostmodel performance in a nearly parameter-free manner, since it shares weightsbetween the main segmentation branch and the introduced maskedself-distillation branches, and solely introduces negligible parameters forcoordinating the multimodal features. Comprehensive experiments on threebenchmark datasets (i.e. RefCOCO, RefCOCO+, G-Ref) for the RIS taskconvincingly demonstrate the superiority of our proposed framework overprevious state-of-the-art methods.</description><author>Wenxuan Wang, Jing Liu, Xingjian He, Yisi Zhang, Chen Chen, Jiachen Shen, Yan Zhang, Jiangyun Li</author><pubDate>Wed, 14 Feb 2024 15:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11481v3</guid></item><item><title>Beyond still images: Temporal features and input variance resilience</title><link>http://arxiv.org/abs/2311.00800v2</link><description>Traditionally, vision models have predominantly relied on spatial featuresextracted from static images, deviating from the continuous stream ofspatiotemporal features processed by the brain in natural vision. Whilenumerous video-understanding models have emerged, incorporating videos intoimage-understanding models with spatiotemporal features has been limited.Drawing inspiration from natural vision, which exhibits remarkable resilienceto input changes, our research focuses on the development of a brain-inspiredmodel for vision understanding trained with videos. Our findings demonstratethat models that train on videos instead of still images and include temporalfeatures become more resilient to various alternations on input media.</description><author>Amir Hosein Fadaei, Mohammad-Reza A. Dehaqani</author><pubDate>Wed, 14 Feb 2024 15:41:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00800v2</guid></item><item><title>TDViT: Temporal Dilated Video Transformer for Dense Video Tasks</title><link>http://arxiv.org/abs/2402.09257v1</link><description>Deep video models, for example, 3D CNNs or video transformers, have achievedpromising performance on sparse video tasks, i.e., predicting one result pervideo. However, challenges arise when adapting existing deep video models todense video tasks, i.e., predicting one result per frame. Specifically, thesemodels are expensive for deployment, less effective when handling redundantframes, and difficult to capture long-range temporal correlations. To overcomethese issues, we propose a Temporal Dilated Video Transformer (TDViT) thatconsists of carefully designed temporal dilated transformer blocks (TDTB). TDTBcan efficiently extract spatiotemporal representations and effectivelyalleviate the negative effect of temporal redundancy. Furthermore, by usinghierarchical TDTBs, our approach obtains an exponentially expanded temporalreceptive field and therefore can model long-range dynamics. Extensiveexperiments are conducted on two different dense video benchmarks, i.e.,ImageNet VID for video object detection and YouTube VIS for video instancesegmentation. Excellent experimental results demonstrate the superiorefficiency, effectiveness, and compatibility of our method. The code isavailable at https://github.com/guanxiongsun/vfe.pytorch.</description><author>Guanxiong Sun, Yang Hua, Guosheng Hu, Neil Robertson</author><pubDate>Wed, 14 Feb 2024 15:41:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09257v1</guid></item><item><title>Universal Machine Learning Kohn-Sham Hamiltonian for Materials</title><link>http://arxiv.org/abs/2402.09251v1</link><description>While density functional theory (DFT) serves as a prevalent computationalapproach in electronic structure calculations, its computational demands andscalability limitations persist. Recently, leveraging neural networks toparameterize the Kohn-Sham DFT Hamiltonian has emerged as a promising avenuefor accelerating electronic structure computations. Despite advancements,challenges such as the necessity for computing extensive DFT training data toexplore new systems and the complexity of establishing accurate ML models formulti-elemental materials still exist. Addressing these hurdles, this studyintroduces a universal electronic Hamiltonian model trained on Hamiltonianmatrices obtained from first-principles DFT calculations of nearly all crystalstructures on the Materials Project. We demonstrate its generality inpredicting electronic structures across the whole periodic table, includingcomplex multi-elemental systems. By offering a reliable efficient framework forcomputing electronic properties, this universal Hamiltonian model lays thegroundwork for advancements in diverse fields related to electronic structures.</description><author>Yang Zhong, Jihui Yang, Hongjun Xiang, Xingao Gong</author><pubDate>Wed, 14 Feb 2024 15:38:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09251v1</guid></item></channel></rss>