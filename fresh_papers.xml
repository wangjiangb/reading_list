<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 03 Jan 2025 13:00:13 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>GeoDiffuser: Geometry-Based Image Editing with Diffusion Models</title><link>http://arxiv.org/abs/2404.14403v2</link><description>The success of image generative models has enabled us to build methods thatcan edit images based on text or other user input. However, these methods arebespoke, imprecise, require additional information, or are limited to only 2Dimage edits. We present GeoDiffuser, a zero-shot optimization-based method thatunifies common 2D and 3D image-based object editing capabilities into a singlemethod. Our key insight is to view image editing operations as geometrictransformations. We show that these transformations can be directlyincorporated into the attention layers in diffusion models to implicitlyperform editing operations. Our training-free optimization method uses anobjective function that seeks to preserve object style but generate plausibleimages, for instance with accurate lighting and shadows. It also inpaintsdisoccluded parts of the image where the object was originally located. Given anatural image and user input, we segment the foreground object using SAM andestimate a corresponding transform which is used by our optimization approachfor editing. GeoDiffuser can perform common 2D and 3D edits like objecttranslation, 3D rotation, and removal. We present quantitative results,including a perceptual study, that shows how our approach is better thanexisting methods. Visit https://ivl.cs.brown.edu/research/geodiffuser.html formore information.</description><author>Rahul Sajnani, Jeroen Vanbaar, Jie Min, Kapil Katyal, Srinath Sridhar</author><pubDate>Thu, 02 Jan 2025 18:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14403v2</guid></item><item><title>MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes</title><link>http://arxiv.org/abs/2412.19260v2</link><description>Several studies showed that Large Language Models (LLMs) can answer medicalquestions correctly, even outperforming the average human score in some medicalexams. However, to our knowledge, no study has been conducted to assess theability of language models to validate existing or generated medical text forcorrectness and consistency. In this paper, we introduce MEDEC(https://github.com/abachaa/MEDEC), the first publicly available benchmark formedical error detection and correction in clinical notes, covering five typesof errors (Diagnosis, Management, Treatment, Pharmacotherapy, and CausalOrganism). MEDEC consists of 3,848 clinical texts, including 488 clinical notesfrom three US hospital systems that were not previously seen by any LLM. Thedataset has been used for the MEDIQA-CORR shared task to evaluate seventeenparticipating systems [Ben Abacha et al., 2024]. In this paper, we describe thedata creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,Claude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting andcorrecting medical errors requiring both medical knowledge and reasoningcapabilities. We also conducted a comparative study where two medical doctorsperformed the same task on the MEDEC test set. The results showed that MEDEC isa sufficiently challenging benchmark to assess the ability of models tovalidate existing or generated notes and to correct medical errors. We alsofound that although recent LLMs have a good performance in error detection andcorrection, they are still outperformed by medical doctors in these tasks. Wediscuss the potential factors behind this gap, the insights from ourexperiments, the limitations of current evaluation metrics, and share potentialpointers for future research.</description><author>Asma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, Thomas Lin</author><pubDate>Thu, 02 Jan 2025 18:46:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19260v2</guid></item><item><title>Sparsely Multimodal Data Fusion</title><link>http://arxiv.org/abs/2403.20280v2</link><description>Multimodal data fusion is essential for applications requiring theintegration of diverse data sources, especially in the presence of incompleteor sparsely available modalities. This paper presents a comparative study ofthree multimodal embedding techniques, Modal Channel Attention (MCA), Zorro,and Everything at Once (EAO), to evaluate their performance on sparselymultimodal data. MCA introduces fusion embeddings for all combinations of inputmodalities and uses attention masking to create distinct attention channels,enabling flexible and efficient data fusion. Experiments on two datasets withfour modalities each, CMU-MOSEI and TCGA, demonstrate that MCA outperformsZorro across ranking, recall, regression, and classification tasks andoutperforms EAO across regression and classification tasks. MCA achievessuperior performance by maintaining robust uniformity across unimodal andfusion embeddings. While EAO performs best in ranking metrics due to itsapproach of forming fusion embeddings post-inference, it underperforms indownstream tasks requiring multimodal interactions. These results highlight theimportance of contrasting all modality combinations in constructing embeddingspaces and offers insights into the design of multimodal architectures forreal-world applications with incomplete data.</description><author>Josiah Bjorgaard</author><pubDate>Thu, 02 Jan 2025 18:31:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20280v2</guid></item><item><title>Familiarity-Based Open-Set Recognition Under Adversarial Attacks</title><link>http://arxiv.org/abs/2311.05006v2</link><description>Open-set recognition (OSR), the identification of novel categories, can be acritical component when deploying classification models in real-worldapplications. Recent work has shown that familiarity-based scoring rules suchas the Maximum Softmax Probability (MSP) or the Maximum Logit Score (MLS) arestrong baselines when the closed-set accuracy is high. However, one of thepotential weaknesses of familiarity-based OSR are adversarial attacks. Here, westudy gradient-based adversarial attacks on familiarity scores for both typesof attacks, False Familiarity and False Novelty attacks, and evaluate theireffectiveness in informed and uninformed settings on TinyImageNet. Furthermore,we explore how novel and familiar samples react to adversarial attacks andformulate the adversarial reaction score as an alternative OSR scoring rule,which shows a high correlation with the MLS familiarity score.</description><author>Philip Enevoldsen, Christian Gundersen, Nico Lang, Serge Belongie, Christian Igel</author><pubDate>Thu, 02 Jan 2025 18:10:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05006v2</guid></item><item><title>Accurate RNA 3D structure prediction using a language model-based deep learning approach</title><link>http://arxiv.org/abs/2207.01586v3</link><description>Accurate prediction of RNA three-dimensional (3D) structure remains anunsolved challenge. Determining RNA 3D structures is crucial for understandingtheir functions and informing RNA-targeting drug development and syntheticbiology design. The structural flexibility of RNA, which leads to scarcity ofexperimentally determined data, complicates computational prediction efforts.Here, we present RhoFold+, an RNA language model-based deep learning methodthat accurately predicts 3D structures of single-chain RNAs from sequences. Byintegrating an RNA language model pre-trained on ~23.7 million RNA sequencesand leveraging techniques to address data scarcity, RhoFold+ offers a fullyautomated end-to-end pipeline for RNA 3D structure prediction. Retrospectiveevaluations on RNA-Puzzles and CASP15 natural RNA targets demonstrateRhoFold+'s superiority over existing methods, including human expert groups.Its efficacy and generalizability are further validated through cross-familyand cross-type assessments, as well as time-censored benchmarks. Additionally,RhoFold+ predicts RNA secondary structures and inter-helical angles, providingempirically verifiable features that broaden its applicability to RNA structureand function studies.</description><author>Tao Shen, Zhihang Hu, Siqi Sun, Di Liu, Felix Wong, Jiuming Wang, Jiayang Chen, Yixuan Wang, Liang Hong, Jin Xiao, Liangzhen Zheng, Tejas Krishnamoorthi, Irwin King, Sheng Wang, Peng Yin, James J. Collins, Yu Li</author><pubDate>Thu, 02 Jan 2025 18:03:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.01586v3</guid></item><item><title>Text2Data: Low-Resource Data Generation with Textual Control</title><link>http://arxiv.org/abs/2402.10941v2</link><description>Natural language serves as a common and straightforward signal for humans tointeract seamlessly with machines. Recognizing the importance of thisinterface, the machine learning community is investing considerable effort ingenerating data that is semantically coherent with textual instructions. Whilestrides have been made in text-to-data generation spanning image editing, audiosynthesis, video creation, and beyond, low-resource areas characterized byexpensive annotations or complex data structures, such as molecules, motiondynamics, and time series, often lack textual labels. This deficiency impedessupervised learning, thereby constraining the application of advancedgenerative models for text-to-data tasks. In response to these challenges inthe low-resource scenario, we propose Text2Data, a novel approach that utilizesunlabeled data to understand the underlying data distribution through anunsupervised diffusion model. Subsequently, it undergoes controllablefinetuning via a novel constraint optimization-based learning objective thatensures controllability and effectively counteracts catastrophic forgetting.Comprehensive experiments demonstrate that Text2Data is able to achieveenhanced performance regarding controllability across various modalities,including molecules, motions and time series, when compared to existingbaselines.</description><author>Shiyu Wang, Yihao Feng, Tian Lan, Ning Yu, Yu Bai, Ran Xu, Huan Wang, Caiming Xiong, Silvio Savarese</author><pubDate>Thu, 02 Jan 2025 17:47:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10941v2</guid></item><item><title>Des-q: a quantum algorithm to provably speedup retraining of decision trees</title><link>http://arxiv.org/abs/2309.09976v5</link><description>Decision trees are widely adopted machine learning models due to theirsimplicity and explainability. However, as training data size grows, standardmethods become increasingly slow, scaling polynomially with the number oftraining examples. In this work, we introduce Des-q, a novel quantum algorithmto construct and retrain decision trees for regression and binaryclassification tasks. Assuming the data stream produces small, periodicincrements of new training examples, Des-q significantly reduces the treeretraining time. Des-q achieves a logarithmic complexity in the combined totalnumber of old and new examples, even accounting for the time needed to load thenew samples into quantum-accessible memory. Our approach to grow the tree fromany given node involves performing piecewise linear splits to generate multiplehyperplanes, thus partitioning the input feature space into distinct regions.To determine the suitable anchor points for these splits, we develop anefficient quantum-supervised clustering method, building upon the q-meansalgorithm introduced by Kerenidis et al. We benchmark the simulated version ofDes-q against the state-of-the-art classical methods on multiple data sets andobserve that our algorithm exhibits similar performance to the state-of-the-artdecision trees while significantly speeding up the periodic tree retraining.</description><author>Niraj Kumar, Romina Yalovetzky, Changhao Li, Pierre Minssen, Marco Pistoia</author><pubDate>Thu, 02 Jan 2025 17:40:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09976v5</guid></item><item><title>Task Singular Vectors: Reducing Task Interference in Model Merging</title><link>http://arxiv.org/abs/2412.00081v2</link><description>Task Arithmetic has emerged as a simple yet effective method to merge modelswithout additional training. However, by treating entire networks as flatparameter vectors, it overlooks key structural information and is susceptibleto task interference. In this paper, we study task vectors at the layer level,focusing on task layer matrices and their singular value decomposition. Inparticular, we concentrate on the resulting singular vectors, which we refer toas Task Singular Vectors (TSV). Recognizing that layer task matrices are oftenlow-rank, we propose TSV-Compress (TSV-C), a simple procedure that compressesthem to 10% of their original size while retaining 99% of accuracy. We furtherleverage this low-rank space to define a new measure of task interference basedon the interaction of singular vectors from different tasks. Building on thesefindings, we introduce TSV-Merge (TSV-M), a novel model merging approach thatcombines compression with interference reduction, significantly outperformingexisting methods.</description><author>Antonio Andrea Gargiulo, Donato Crisostomi, Maria Sofia Bucarelli, Simone Scardapane, Fabrizio Silvestri, Emanuele Rodolà</author><pubDate>Thu, 02 Jan 2025 17:33:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.00081v2</guid></item><item><title>In-Trajectory Inverse Reinforcement Learning: Learn Incrementally Before An Ongoing Trajectory Terminates</title><link>http://arxiv.org/abs/2410.15612v3</link><description>Inverse reinforcement learning (IRL) aims to learn a reward function and acorresponding policy that best fit the demonstrated trajectories of an expert.However, current IRL works cannot learn incrementally from an ongoingtrajectory because they have to wait to collect at least one completetrajectory to learn. To bridge the gap, this paper considers the problem oflearning a reward function and a corresponding policy while observing theinitial state-action pair of an ongoing trajectory and keeping updating thelearned reward and policy when new state-action pairs of the ongoing trajectoryare observed. We formulate this problem as an online bi-level optimizationproblem where the upper level dynamically adjusts the learned reward accordingto the newly observed state-action pairs with the help of a meta-regularizationterm, and the lower level learns the corresponding policy. We propose a novelalgorithm to solve this problem and guarantee that the algorithm achievessub-linear local regret $O(\sqrt{T}+\log T+\sqrt{T}\log T)$. If the rewardfunction is linear, we prove that the proposed algorithm achieves sub-linearregret $O(\log T)$. Experiments are used to validate the proposed algorithm.</description><author>Shicheng Liu, Minghui Zhu</author><pubDate>Thu, 02 Jan 2025 17:29:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15612v3</guid></item><item><title>The Role of Handling Attributive Nouns in Improving Chinese-To-English Machine Translation</title><link>http://arxiv.org/abs/2412.14323v2</link><description>Translating between languages with drastically different grammaticalconventions poses challenges, not just for human interpreters but also formachine translation systems. In this work, we specifically target thetranslation challenges posed by attributive nouns in Chinese, which frequentlycause ambiguities in English translation. By manually inserting the omittedparticle X ('DE'). In news article titles from the Penn Chinese DiscourseTreebank, we developed a targeted dataset to fine-tune Hugging Face Chinese toEnglish translation models, specifically improving how this critical functionword is handled. This focused approach not only complements the broaderstrategies suggested by previous studies but also offers a practicalenhancement by specifically addressing a common error type in Chinese-Englishtranslation.</description><author>Lisa Wang, Adam Meyers, John E. Ortega, Rodolfo Zevallos</author><pubDate>Thu, 02 Jan 2025 17:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14323v2</guid></item><item><title>SegKAN: High-Resolution Medical Image Segmentation with Long-Distance Dependencies</title><link>http://arxiv.org/abs/2412.19990v2</link><description>Hepatic vessels in computed tomography scans often suffer from imagefragmentation and noise interference, making it difficult to maintain vesselintegrity and posing significant challenges for vessel segmentation. To addressthis issue, we propose an innovative model: SegKAN. First, we improve theconventional embedding module by adopting a novel convolutional networkstructure for image embedding, which smooths out image noise and preventsissues such as gradient explosion in subsequent stages. Next, we transform thespatial relationships between Patch blocks into temporal relationships to solvethe problem of capturing positional relationships between Patch blocks intraditional Vision Transformer models. We conducted experiments on a Hepaticvessel dataset, and compared to the existing state-of-the-art model, the Dicescore improved by 1.78%. These results demonstrate that the proposed newstructure effectively enhances the segmentation performance of high-resolutionextended objects. Code will be available at https://github.com/goblin327/SegKAN</description><author>Shengbo Tan, Rundong Xue, Shipeng Luo, Zeyu Zhang, Xinran Wang, Lei Zhang, Daji Ergu, Zhang Yi, Yang Zhao, Ying Cai</author><pubDate>Thu, 02 Jan 2025 17:25:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19990v2</guid></item><item><title>From Models to Systems: A Comprehensive Fairness Framework for Compositional Recommender Systems</title><link>http://arxiv.org/abs/2412.04655v2</link><description>Fairness research in machine learning often centers on ensuring equitableperformance of individual models. However, real-world recommendation systemsare built on multiple models and even multiple stages, from candidate retrievalto scoring and serving, which raises challenges for responsible development anddeployment. This system-level view, as highlighted by regulations like the EUAI Act, necessitates moving beyond auditing individual models as independententities. We propose a holistic framework for modeling system-level fairness,focusing on the end-utility delivered to diverse user groups, and considerinteractions between components such as retrieval and scoring models. Weprovide formal insights on the limitations of focusing solely on model-levelfairness and highlight the need for alternative tools that account forheterogeneity in user preferences. To mitigate system-level disparities, weadapt closed-box optimization tools (e.g., BayesOpt) to jointly optimizeutility and equity. We empirically demonstrate the effectiveness of ourproposed framework on synthetic and real datasets, underscoring the need for asystem-level framework.</description><author>Brian Hsu, Cyrus DiCiccio, Natesh Sivasubramoniapillai, Hongseok Namkoong</author><pubDate>Thu, 02 Jan 2025 17:21:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04655v2</guid></item><item><title>Perception-guided Jailbreak against Text-to-Image Models</title><link>http://arxiv.org/abs/2408.10848v3</link><description>In recent years, Text-to-Image (T2I) models have garnered significantattention due to their remarkable advancements. However, security concerns haveemerged due to their potential to generate inappropriate or Not-Safe-For-Work(NSFW) images. In this paper, inspired by the observation that texts withdifferent semantics can lead to similar human perceptions, we propose anLLM-driven perception-guided jailbreak method, termed PGJ. It is a black-boxjailbreak method that requires no specific T2I model (model-free) and generateshighly natural attack prompts. Specifically, we propose identifying a safephrase that is similar in human perception yet inconsistent in text semanticswith the target unsafe word and using it as a substitution. The experimentsconducted on six open-source models and commercial online services withthousands of prompts have verified the effectiveness of PGJ.</description><author>Yihao Huang, Le Liang, Tianlin Li, Xiaojun Jia, Run Wang, Weikai Miao, Geguang Pu, Yang Liu</author><pubDate>Thu, 02 Jan 2025 17:17:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10848v3</guid></item><item><title>Solving Hierarchical Information-Sharing Dec-POMDPs: An Extensive-Form Game Approach</title><link>http://arxiv.org/abs/2402.02954v3</link><description>A recent theory shows that a multi-player decentralized partially observableMarkov decision process can be transformed into an equivalent single-playergame, enabling the application of \citeauthor{bellman}'s principle ofoptimality to solve the single-player game by breaking it down intosingle-stage subgames. However, this approach entangles the decision variablesof all players at each single-stage subgame, resulting in backups with adouble-exponential complexity. This paper demonstrates how to disentangle thesedecision variables while maintaining optimality under hierarchical informationsharing, a prominent management style in our society. To achieve this, we applythe principle of optimality to solve any single-stage subgame by breaking itdown further into smaller subgames, enabling us to make single-player decisionsat a time. Our approach reveals that extensive-form games always exist withsolutions to a single-stage subgame, significantly reducing time complexity.Our experimental results show that the algorithms leveraging these findings canscale up to much larger multi-player games without compromising optimality.</description><author>Johan Peralez, Aurélien Delage, Olivier Buffet, Jilles S. Dibangoye</author><pubDate>Thu, 02 Jan 2025 17:10:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02954v3</guid></item><item><title>SwitchLoRA: Switched Low-Rank Adaptation Can Learn Full-Rank Information</title><link>http://arxiv.org/abs/2406.06564v3</link><description>In the training of large language models, parameter-efficient techniques suchas LoRA optimize memory usage and reduce communication overhead and memoryusage during the fine-tuning phase. However, applying such techniques directlyduring the pre-training phase results in poor performance, primarily becausethe premature implementation of low-rank training significantly reduces modelaccuracy. Existing methods like ReLoRA and GaLore have attempted to addressthis challenge by updating the low-rank subspace. However, they still fallshort of achieving the accuracy of full-rank training. Specifically, ReLoRArestricts the frequency of updates to preserve optimizer states consistency,hindering its ability to closely approximate full-rank training behavior.Meanwhile, GaLore relies on Singular Value Decomposition (SVD) to approximatethe full-rank space, which introduces accuracy loss during the approximationprocess. In this paper, we introduce SwitchLoRA, a parameter-efficient trainingtechnique that frequently and smoothly replaces the trainable parameters ofLoRA adapters with alternative parameters. SwitchLoRA updates the low-ranksubspace incrementally, targeting only a few dimensions at a time to minimizethe impact on optimizer states. This allows a higher update frequency, therebyenhancing accuracy by enabling the updated parameters to more closely mimicfull-rank behavior during the pre-training phase. Our results demonstrate thatSwitchLoRA actually surpasses full-rank training, reducing perplexity from15.23 to 15.01 on the LLaMA 1.3B model, while also cutting communicationoverhead by 54\% and memory usage by 13\%. Furthermore, after full fine-tuningthe SwitchLoRA pre-trained model and the full-rank pre-trained model on theGLUE benchmark, the SwitchLoRA pre-trained model showed an average accuracygain of about 1\% over the full-rank pre-trained model.</description><author>Kaiye Zhou, Shucheng Wang, Jun Xu</author><pubDate>Thu, 02 Jan 2025 17:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06564v3</guid></item><item><title>Variational autoencoders with latent high-dimensional steady geometric flows for dynamics</title><link>http://arxiv.org/abs/2410.10137v4</link><description>We develop Riemannian approaches to variational autoencoders (VAEs) forPDE-type ambient data with regularizing geometric latent dynamics, which werefer to as VAE-DLM, or VAEs with dynamical latent manifolds. We redevelop theVAE framework such that manifold geometries, subject to our geometric flow,embedded in Euclidean space are learned in the intermediary latent spacedeveloped by encoders and decoders. By tailoring the geometric flow in whichthe latent space evolves, we induce latent geometric properties of ourchoosing, which are reflected in empirical performance. We reformulate thetraditional evidence lower bound (ELBO) loss with a considerate choice ofprior. We develop a linear geometric flow with a steady-state regularizingterm. This flow requires only automatic differentiation of one time derivative,and can be solved in moderately high dimensions in a physics-informed approach,allowing more expressive latent representations. We discuss how this flow canbe formulated as a gradient flow, and maintains entropy away from metricsingularity. This, along with an eigenvalue penalization condition, helpsensure the manifold is sufficiently large in measure, nondegenerate, and acanonical geometry, which contribute to a robust representation. Our methodsfocus on the modified multi-layer perceptron architecture with tanh activationsfor the manifold encoder-decoder. We demonstrate, on our datasets of interest,our methods perform at least as well as the traditional VAE, and oftentimesbetter. Our methods can outperform this and a VAE endowed with our proposedarchitecture, frequently reducing out-of-distribution (OOD) error between 15%to 35% on select datasets. We highlight our method on ambient PDEs whosesolutions maintain minimal variation in late times. We provide empiricaljustification towards how we can improve robust learning for external dynamicswith VAEs.</description><author>Andrew Gracyk</author><pubDate>Thu, 02 Jan 2025 17:02:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10137v4</guid></item><item><title>A Closer Look at Deep Learning Methods on Tabular Datasets</title><link>http://arxiv.org/abs/2407.00956v2</link><description>Tabular data is prevalent across diverse domains in machine learning. Whileclassical methods like tree-based models have long been effective, Deep NeuralNetwork (DNN)-based methods have recently demonstrated promising performance.However, the diverse characteristics of methods and the inherent heterogeneityof tabular datasets make understanding and interpreting tabular methods bothchallenging and prone to unstable observations. In this paper, we conductin-depth evaluations and comprehensive analyses of tabular methods, with aparticular focus on DNN-based models, using a benchmark of over 300 tabulardatasets spanning a wide range of task types, sizes, and domains. First, weperform an extensive comparison of 32 state-of-the-art deep and tree-basedmethods, evaluating their average performance across multiple criteria.Although method ranks vary across datasets, we empirically find thattop-performing methods tend to concentrate within a small subset of tabularmodels, regardless of the criteria used. Next, we investigate whether thetraining dynamics of deep tabular models can be predicted based on datasetproperties. This approach not only offers insights into the behavior of deeptabular methods but also identifies a core set of "meta-features" that reflectdataset heterogeneity. The other subset includes datasets where method ranksare consistent with the overall benchmark, acting as a reliable probe forfurther tabular analysis.</description><author>Han-Jia Ye, Si-Yang Liu, Hao-Run Cai, Qi-Le Zhou, De-Chuan Zhan</author><pubDate>Thu, 02 Jan 2025 16:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00956v2</guid></item><item><title>Commutative Evolution Laws in Holographic Cellular Automata: AdS/CFT, Near-Extremal D3-Branes, and a Deep Learning Approach</title><link>http://arxiv.org/abs/2012.06441v8</link><description>According to 't Hooft, restoring Poincar\'e invariance in a holographiccellular automaton (CA) requires two distinct evolution laws that commute. Weexplore how this is realized in the AdS/CFT framework, assuming commutativityas a fundamental principle--much like general covariance once did--for encodingcurvature. In our setup, physical processes in a given spacetime are encoded ina CA; to preserve Poincar\'e symmetry, the spacetime curvature must effectivelyvanish, so we consider a near-extremal black D3-brane solution, in which boththe stretched horizon and the conformal boundary are approximated by Minkowskispace. AdS/CFT implies a spatial evolution law connecting these hypersurfaces.Commutativity means the final state does not depend on the order of timeevolution on each hypersurface and spatial evolution between them, forcing thetime evolution law on the horizon and boundary to coincide. To satisfy allthese conditions, we aim to demonstrate that the spatial evolution lawinevitably encapsulates the curvature of the bulk, including quantum effects.For a computational model, we compactify the hyperplanes to tori, reducing thedegrees of freedom to a finite number; taking these tori to infinite size thenrestores Poincar\'e symmetry. We propose a deep learning algorithm that, givena known time evolution law and commutativity, deduces the corresponding spatialevolution law.</description><author>Hyunju Go</author><pubDate>Thu, 02 Jan 2025 16:40:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.06441v8</guid></item><item><title>BhashaVerse : Translation Ecosystem for Indian Subcontinent Languages</title><link>http://arxiv.org/abs/2412.04351v2</link><description>This paper focuses on developing translation models and related applicationsfor 36 Indian languages, including Assamese, Awadhi, Bengali, Bhojpuri, Braj,Bodo, Dogri, English, Konkani, Gondi, Gujarati, Hindi, Hinglish, Ho, Kannada,Kangri, Kashmiri (Arabic and Devanagari), Khasi, Mizo, Magahi, Maithili,Malayalam, Marathi, Manipuri (Bengali and Meitei), Nepali, Oriya, Punjabi,Sanskrit, Santali, Sinhala, Sindhi (Arabic and Devanagari), Tamil, Tulu,Telugu, and Urdu. Achieving this requires parallel and other types of corporafor all 36 * 36 language pairs, addressing challenges like script variations,phonetic differences, and syntactic diversity. For instance, languages likeKashmiri and Sindhi, which use multiple scripts, demand script normalizationfor alignment, while low-resource languages such as Khasi and Santali requiresynthetic data augmentation to ensure sufficient coverage and quality. To address these challenges, this work proposes strategies for corpuscreation by leveraging existing resources, developing parallel datasets,generating domain-specific corpora, and utilizing synthetic data techniques.Additionally, it evaluates machine translation across various dimensions,including standard and discourse-level translation, domain-specifictranslation, reference-based and reference-free evaluation, error analysis, andautomatic post-editing. By integrating these elements, the study establishes acomprehensive framework to improve machine translation quality and enablebetter cross-lingual communication in India's linguistically diverse ecosystem.</description><author>Vandan Mujadia, Dipti Misra Sharma</author><pubDate>Thu, 02 Jan 2025 16:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04351v2</guid></item><item><title>Prometheus: 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D Scene Generation</title><link>http://arxiv.org/abs/2412.21117v2</link><description>In this work, we introduce Prometheus, a 3D-aware latent diffusion model fortext-to-3D generation at both object and scene levels in seconds. We formulate3D scene generation as multi-view, feed-forward, pixel-aligned 3D Gaussiangeneration within the latent diffusion paradigm. To ensure generalizability, webuild our model upon pre-trained text-to-image generation model with onlyminimal adjustments, and further train it using a large number of images fromboth single-view and multi-view datasets. Furthermore, we introduce an RGB-Dlatent space into 3D Gaussian generation to disentangle appearance and geometryinformation, enabling efficient feed-forward generation of 3D Gaussians withbetter fidelity and geometry. Extensive experimental results demonstrate theeffectiveness of our method in both feed-forward 3D Gaussian reconstruction andtext-to-3D generation. Project page:https://freemty.github.io/project-prometheus/</description><author>Yuanbo Yang, Jiahao Shao, Xinyang Li, Yujun Shen, Andreas Geiger, Yiyi Liao</author><pubDate>Thu, 02 Jan 2025 16:31:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.21117v2</guid></item><item><title>Stable-V2A: Synthesis of Synchronized Sound Effects with Temporal and Semantic Controls</title><link>http://arxiv.org/abs/2412.15023v2</link><description>Sound designers and Foley artists usually sonorize a scene, such as from amovie or video game, by manually annotating and sonorizing each action ofinterest in the video. In our case, the intent is to leave full creativecontrol to sound designers with a tool that allows them to bypass the morerepetitive parts of their work, thus being able to focus on the creativeaspects of sound production. We achieve this presenting Stable-V2A, a two-stagemodel consisting of: an RMS-Mapper that estimates an envelope representative ofthe audio characteristics associated with the input video; and Stable-Foley, adiffusion model based on Stable Audio Open that generates audio semanticallyand temporally aligned with the target video. Temporal alignment is guaranteedby the use of the envelope as a ControlNet input, while semantic alignment isachieved through the use of sound representations chosen by the designer ascross-attention conditioning of the diffusion process. We train and test ourmodel on Greatest Hits, a dataset commonly used to evaluate V2A models. Inaddition, to test our model on a case study of interest, we introduce WalkingThe Maps, a dataset of videos extracted from video games depicting animatedcharacters walking in different locations. Samples and code available on ourdemo page at https://ispamm.github.io/Stable-V2A.</description><author>Riccardo Fosco Gramaccioni, Christian Marinoni, Emilian Postolache, Marco Comunità, Luca Cosmo, Joshua D. Reiss, Danilo Comminiello</author><pubDate>Thu, 02 Jan 2025 16:16:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15023v2</guid></item><item><title>A Survey of Controllable Learning: Methods and Applications in Information Retrieval</title><link>http://arxiv.org/abs/2407.06083v2</link><description>Controllability has become a crucial aspect of trustworthy machine learning,enabling learners to meet predefined targets and adapt dynamically at test timewithout requiring retraining as the targets shift. We provide a formaldefinition of controllable learning (CL), and discuss its applications ininformation retrieval (IR) where information needs are often complex anddynamic. The survey categorizes CL according to what is controllable (e.g.,multiple objectives, user portrait, scenario adaptation), who controls (usersor platforms), how control is implemented (e.g., rule-based method, Paretooptimization, hypernetwork and others), and where to implement control (e.g.,pre-processing, in-processing, post-processing methods). Then, we identifychallenges faced by CL across training, evaluation, task setting, anddeployment in online environments. Additionally, we outline promisingdirections for CL in theoretical analysis, efficient computation, empoweringlarge language models, application scenarios and evaluation frameworks.</description><author>Chenglei Shen, Xiao Zhang, Teng Shi, Changshuo Zhang, Guofu Xie, Jun Xu</author><pubDate>Thu, 02 Jan 2025 16:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06083v2</guid></item><item><title>Degeneracy is OK: Logarithmic Regret for Network Revenue Management with Indiscrete Distributions</title><link>http://arxiv.org/abs/2210.07996v5</link><description>We study the classical Network Revenue Management (NRM) problem withaccept/reject decisions and $T$ IID arrivals. We consider a distributional formwhere each arrival must fall under a finite number of possible categories, eachwith a deterministic resource consumption vector, but a random valuedistributed continuously over an interval. We develop an online algorithm thatachieves $O(\log^2 T)$ regret under this model, with the only (necessary)assumption being that the probability densities are bounded away from 0. Wederive a second result that achieves $O(\log T)$ regret under an additionalassumption of second-order growth. To our knowledge, these are the firstresults achieving logarithmic-level regret in an NRM model with continuousvalues that do not require any kind of "non-degeneracy" assumptions. Ourresults are achieved via new techniques including a new method of boundingmyopic regret, a "semi-fluid" relaxation of the offline allocation, and animproved bound on the "dual convergence".</description><author>Jiashuo Jiang, Will Ma, Jiawei Zhang</author><pubDate>Thu, 02 Jan 2025 16:07:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.07996v5</guid></item><item><title>Navigating the Maze of Explainable AI: A Systematic Approach to Evaluating Methods and Metrics</title><link>http://arxiv.org/abs/2409.16756v3</link><description>Explainable AI (XAI) is a rapidly growing domain with a myriad of proposedmethods as well as metrics aiming to evaluate their efficacy. However, currentstudies are often of limited scope, examining only a handful of XAI methods andignoring underlying design parameters for performance, such as the modelarchitecture or the nature of input data. Moreover, they often rely on one or afew metrics and neglect thorough validation, increasing the risk of selectionbias and ignoring discrepancies among metrics. These shortcomings leavepractitioners confused about which method to choose for their problem. Inresponse, we introduce LATEC, a large-scale benchmark that critically evaluates17 prominent XAI methods using 20 distinct metrics. We systematicallyincorporate vital design parameters like varied architectures and diverse inputmodalities, resulting in 7,560 examined combinations. Through LATEC, weshowcase the high risk of conflicting metrics leading to unreliable rankingsand consequently propose a more robust evaluation scheme. Further, wecomprehensively evaluate various XAI methods to assist practitioners inselecting appropriate methods aligning with their needs. Curiously, theemerging top-performing method, Expected Gradients, is not examined in anyrelevant related study. LATEC reinforces its role in future XAI research bypublicly releasing all 326k saliency maps and 378k metric scores as a(meta-)evaluation dataset. The benchmark is hosted at:https://github.com/IML-DKFZ/latec.</description><author>Lukas Klein, Carsten T. Lüth, Udo Schlegel, Till J. Bungert, Mennatallah El-Assady, Paul F. Jäger</author><pubDate>Thu, 02 Jan 2025 15:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16756v3</guid></item><item><title>Upper Bounds for Learning in Reproducing Kernel Hilbert Spaces for Non IID Samples</title><link>http://arxiv.org/abs/2410.08361v2</link><description>In this paper, we study a Markov chain-based stochastic gradient algorithm ingeneral Hilbert spaces, aiming to approximate the optimal solution of aquadratic loss function. We establish probabilistic upper bounds on itsconvergence. We further extend these results to an online regularized learningalgorithm in reproducing kernel Hilbert spaces, where the samples are drawnalong a Markov chain trajectory hence the samples are of the non i.i.d. type.</description><author>Priyanka Roy, Susanne Saminger-Platz</author><pubDate>Thu, 02 Jan 2025 15:47:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08361v2</guid></item><item><title>Amortized Bayesian Experimental Design for Decision-Making</title><link>http://arxiv.org/abs/2411.02064v2</link><description>Many critical decisions, such as personalized medical diagnoses and productpricing, are made based on insights gained from designing, observing, andanalyzing a series of experiments. This highlights the crucial role ofexperimental design, which goes beyond merely collecting information on systemparameters as in traditional Bayesian experimental design (BED), but also playsa key part in facilitating downstream decision-making. Most recent BED methodsuse an amortized policy network to rapidly design experiments. However, theinformation gathered through these methods is suboptimal for down-the-linedecision-making, as the experiments are not inherently designed with downstreamobjectives in mind. In this paper, we present an amortized decision-aware BEDframework that prioritizes maximizing downstream decision utility. We introducea novel architecture, the Transformer Neural Decision Process (TNDP), capableof instantly proposing the next experimental design, whilst inferring thedownstream decision, thus effectively amortizing both tasks within a unifiedworkflow. We demonstrate the performance of our method across several tasks,showing that it can deliver informative designs and facilitate accuratedecision-making.</description><author>Daolang Huang, Yujia Guo, Luigi Acerbi, Samuel Kaski</author><pubDate>Thu, 02 Jan 2025 15:34:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.02064v2</guid></item><item><title>MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension</title><link>http://arxiv.org/abs/2409.13609v3</link><description>Referring Expression Comprehension (REC), which aims to ground a local visualregion via natural language, is a task that heavily relies on multimodalalignment. Most existing methods utilize powerful pre-trained models totransfer visual/linguistic knowledge by full fine-tuning. However, fullfine-tuning the entire backbone not only breaks the rich prior knowledgeembedded in the pre-training, but also incurs significant computational costs.Motivated by the recent emergence of Parameter-Efficient Transfer Learning(PETL) methods, we aim to solve the REC task in an effective and efficientmanner. Directly applying these PETL methods to the REC task is inappropriate,as they lack the specific-domain abilities for precise local visual perceptionand visual-language alignment. Therefore, we propose a novel framework ofMultimodal Prior-guided Parameter Efficient Tuning, namely MaPPER.Specifically, MaPPER comprises Dynamic Prior Adapters guided by an alignedprior, and Local Convolution Adapters to extract precise local semantics forbetter visual perception. Moreover, the Prior-Guided Text module is proposed tofurther utilize the prior for facilitating the cross-modal alignment.Experimental results on three widely-used benchmarks demonstrate that MaPPERachieves the best accuracy compared to the full fine-tuning and other PETLmethods with only 1.41% tunable backbone parameters. Our code is available athttps://github.com/liuting20/MaPPER.</description><author>Ting Liu, Zunnan Xu, Yue Hu, Liangtao Shi, Zhiqiang Wang, Quanjun Yin</author><pubDate>Thu, 02 Jan 2025 15:26:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.13609v3</guid></item><item><title>Boosting Memory Efficiency in Transfer Learning for High-Resolution Medical Image Classification</title><link>http://arxiv.org/abs/2408.02426v2</link><description>The success of large-scale pre-trained models has established fine-tuning asa standard method for achieving significant improvements in downstream tasks.However, fine-tuning the entire parameter set of a pre-trained model is costly.Parameter-efficient transfer learning (PETL) has recently emerged as acost-effective alternative for adapting pre-trained models to downstream tasks.Despite its advantages, the increasing model size and input resolution presentchallenges for PETL, as the training memory consumption is not reduced aseffectively as the parameter usage. In this paper, we introduce Fine-grainedPrompt Tuning plus (FPT+), a PETL method designed for high-resolution medicalimage classification, which significantly reduces the training memoryconsumption compared to other PETL methods. FPT+ performs transfer learning bytraining a lightweight side network and accessing pre-trained knowledge from alarge pre-trained model (LPM) through fine-grained prompts and fusion modules.Specifically, we freeze the LPM of interest and construct a learnablelightweight side network. The frozen LPM processes high-resolution images toextract fine-grained features, while the side network employs correspondingdown-sampled low-resolution images to minimize the memory usage. To enable theside network to leverage pre-trained knowledge, we propose fine-grained promptsand fusion modules, which collaborate to summarize information through theLPM's intermediate activations. We evaluate FPT+ on eight medical imagedatasets of varying sizes, modalities, and complexities. Experimental resultsdemonstrate that FPT+ outperforms other PETL methods, using only 1.03% of thelearnable parameters and 3.18% of the memory required for fine-tuning an entireViT-B model. Our code is available https://github.com/YijinHuang/FPT.</description><author>Yijin Huang, Pujin Cheng, Roger Tam, Xiaoying Tang</author><pubDate>Thu, 02 Jan 2025 15:25:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02426v2</guid></item><item><title>Derivatives and residual distribution of regularized M-estimators with application to adaptive tuning</title><link>http://arxiv.org/abs/2107.05143v2</link><description>This paper studies M-estimators with gradient-Lipschitz loss functionregularized with convex penalty in linear models with Gaussian design matrixand arbitrary noise distribution. A practical example is the robust M-estimatorconstructed with the Huber loss and the Elastic-Net penalty and the noisedistribution has heavy-tails. Our main contributions are three-fold. (i) Weprovide general formulae for the derivatives of regularized M-estimators$\hat\beta(y,X)$ where differentiation is taken with respect to both $y$ and$X$; this reveals a simple differentiability structure shared by all convexregularized M-estimators. (ii) Using these derivatives, we characterize thedistribution of the residual $r_i = y_i-x_i^\top\hat\beta$ in the intermediatehigh-dimensional regime where dimension and sample size are of the same order.(iii) Motivated by the distribution of the residuals, we propose a noveladaptive criterion to select tuning parameters of regularized M-estimators. Thecriterion approximates the out-of-sample error up to an additive constantindependent of the estimator, so that minimizing the criterion provides a proxyfor minimizing the out-of-sample error. The proposed adaptive criterion doesnot require the knowledge of the noise distribution or of the covariance of thedesign. Simulated data confirms the theoretical findings, regarding both thedistribution of the residuals and the success of the criterion as a proxy ofthe out-of-sample error. Finally our results reveal new relationships betweenthe derivatives of $\hat\beta(y,X)$ and the effective degrees of freedom of theM-estimator, which are of independent interest.</description><author>Pierre C Bellec, Yiwei Shen</author><pubDate>Thu, 02 Jan 2025 15:19:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.05143v2</guid></item><item><title>λ: A Benchmark for Data-Efficiency in Long-Horizon Indoor Mobile Manipulation Robotics</title><link>http://arxiv.org/abs/2412.05313v2</link><description>Efficiently learning and executing long-horizon mobile manipulation (MoMa)tasks is crucial for advancing robotics in household and workplace settings.However, current MoMa models are data-inefficient, underscoring the need forimproved models that require realistic-sized benchmarks to evaluate theirefficiency, which do not exist. To address this, we introduce the LAMBDA({\lambda}) benchmark (Long-horizon Actions for Mobile-manipulationBenchmarking of Directed Activities), which evaluates the data efficiency ofmodels on language-conditioned, long-horizon, multi-room, multi-floor,pick-and-place tasks using a dataset of manageable size, more feasible forcollection. The benchmark includes 571 human-collected demonstrations thatprovide realism and diversity in simulated and real-world settings. Unlikeplanner-generated data, these trajectories offer natural variability andreplay-verifiability, ensuring robust learning and evaluation. We benchmarkseveral models, including learning-based models and a neuro-symbolic modularapproach combining foundation models with task and motion planning.Learning-based models show suboptimal success rates, even when leveragingpretrained weights, underscoring significant data inefficiencies. However, theneuro-symbolic approach performs significantly better while being more dataefficient. Findings highlight the need for more data-efficient learning-basedMoMa approaches. {\lambda} addresses this gap by serving as a key benchmark forevaluating the data efficiency of those future models in handling householdrobotics tasks.</description><author>Ahmed Jaafar, Shreyas Sundara Raman, Yichen Wei, Sofia Juliani, Anneke Wernerfelt, Benedict Quartey, Ifrah Idrees, Jason Xinyu Liu, Stefanie Tellex</author><pubDate>Thu, 02 Jan 2025 15:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05313v2</guid></item><item><title>SAP: Corrective Machine Unlearning with Scaled Activation Projection for Label Noise Robustness</title><link>http://arxiv.org/abs/2403.08618v2</link><description>Label corruption, where training samples are mislabeled due to non-expertannotation or adversarial attacks, significantly degrades model performance.Acquiring large, perfectly labeled datasets is costly, and retraining modelsfrom scratch is computationally expensive. To address this, we introduce ScaledActivation Projection (SAP), a novel SVD (Singular Value Decomposition)-basedcorrective machine unlearning algorithm. SAP mitigates label noise byidentifying a small subset of trusted samples using cross-entropy loss andprojecting model weights onto a clean activation space estimated using SVD onthese trusted samples. This process suppresses the noise introduced inactivations due to the mislabeled samples. In our experiments, we demonstrateSAP's effectiveness on synthetic noise with different settings and real-worldlabel noise. SAP applied to the CIFAR dataset with 25% synthetic corruptionshow upto 6% generalization improvements. Additionally, SAP can improve thegeneralization over noise robust training approaches on CIFAR dataset by ~3.2%on average. Further, we observe generalization improvements of 2.31% for aVision Transformer model trained on naturally corrupted Clothing1M.</description><author>Sangamesh Kodge, Deepak Ravikumar, Gobinda Saha, Kaushik Roy</author><pubDate>Thu, 02 Jan 2025 15:08:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08618v2</guid></item><item><title>OCTAMamba: A State-Space Model Approach for Precision OCTA Vasculature Segmentation</title><link>http://arxiv.org/abs/2409.08000v2</link><description>Optical Coherence Tomography Angiography (OCTA) is a crucial imagingtechnique for visualizing retinal vasculature and diagnosing eye diseases suchas diabetic retinopathy and glaucoma. However, precise segmentation of OCTAvasculature remains challenging due to the multi-scale vessel structures andnoise from poor image quality and eye lesions. In this study, we proposedOCTAMamba, a novel U-shaped network based on the Mamba architecture, designedto segment vasculature in OCTA accurately. OCTAMamba integrates a Quad StreamEfficient Mining Embedding Module for local feature extraction, a Multi-ScaleDilated Asymmetric Convolution Module to capture multi-scale vasculature, and aFocused Feature Recalibration Module to filter noise and highlight targetareas. Our method achieves efficient global modeling and local featureextraction while maintaining linear complexity, making it suitable forlow-computation medical applications. Extensive experiments on the OCTA 3M,OCTA 6M, and ROSSA datasets demonstrated that OCTAMamba outperformsstate-of-the-art methods, providing a new reference for efficient OCTAsegmentation. Code is available at https://github.com/zs1314/OCTAMamba</description><author>Shun Zou, Zhuo Zhang, Guangwei Gao</author><pubDate>Thu, 02 Jan 2025 15:04:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08000v2</guid></item><item><title>Edicho: Consistent Image Editing in the Wild</title><link>http://arxiv.org/abs/2412.21079v2</link><description>As a verified need, consistent editing across in-the-wild images remains atechnical challenge arising from various unmanageable factors, like objectposes, lighting conditions, and photography environments. Edicho steps in witha training-free solution based on diffusion models, featuring a fundamentaldesign principle of using explicit image correspondence to direct editing.Specifically, the key components include an attention manipulation module and acarefully refined classifier-free guidance (CFG) denoising strategy, both ofwhich take into account the pre-estimated correspondence. Such aninference-time algorithm enjoys a plug-and-play nature and is compatible tomost diffusion-based editing methods, such as ControlNet and BrushNet.Extensive results demonstrate the efficacy of Edicho in consistent cross-imageediting under diverse settings. We will release the code to facilitate futurestudies.</description><author>Qingyan Bai, Hao Ouyang, Yinghao Xu, Qiuyu Wang, Ceyuan Yang, Ka Leong Cheng, Yujun Shen, Qifeng Chen</author><pubDate>Thu, 02 Jan 2025 15:00:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.21079v2</guid></item><item><title>Multicollinearity Resolution Based on Machine Learning: A Case Study of Carbon Emissions</title><link>http://arxiv.org/abs/2309.01115v3</link><description>This study presents a general analytical framework using DBSCAN clusteringand penalized regression models to address multifactor problems with structuralcomplexity and multicollinearity issues, such as carbon emission issue. Theframework leverages DBSCAN for unsupervised learning to objectively clusterfeatures. Meanwhile, penalized regression considers model complexity controland high dimensional feature selection to identify dominant influencingfactors. Applying this framework to analyze energy consumption data for 46industries from 2000 to 2019 identified 16 categories in the sample of China.We quantitatively assessed emission characteristics and drivers for each. Theresults demonstrate the framework's analytical approach can identify primaryemission sources by category, providing quantitative references fordecision-making. Overall, this framework can evaluate complex regional issueslike carbon emissions to support policymaking. This research preliminarilyvalidated its application value in identifying opportunities for emissionreduction worldwide.</description><author>Xuanming Zhang, Xiaoxue Wang, Yonghang Chen</author><pubDate>Thu, 02 Jan 2025 14:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01115v3</guid></item><item><title>Athanor: Local Search over Abstract Constraint Specifications</title><link>http://arxiv.org/abs/2410.05937v2</link><description>Local search is a common method for solving combinatorial optimisationproblems. We focus on general-purpose local search solvers that accept as inputa constraint model - a declarative description of a problem consisting of a setof decision variables under a set of constraints. Existing approaches typicallytake as input models written in solver-independent constraint modellinglanguages like MiniZinc. The Athanor solver we describe herein differs in thatit begins from a specification of a problem in the abstract constraintspecification language Essence, which allows problems to be described withoutcommitment to low-level modelling decisions through its support for a rich setof abstract types. The advantage of proceeding from Essence is that thestructure apparent in a concise, abstract specification of a problem can beexploited to generate high quality neighbourhoods automatically, avoiding thedifficult task of identifying that structure in an equivalent constraint model.Based on the twin benefits of neighbourhoods derived from high level types andthe scalability derived by searching directly over those types, our empiricalresults demonstrate strong performance in practice relative to existingsolution methods.</description><author>Saad Attieh, Nguyen Dang, Christopher Jefferson, Ian Miguel, Peter Nightingale</author><pubDate>Thu, 02 Jan 2025 14:41:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05937v2</guid></item><item><title>RiTTA: Modeling Event Relations in Text-to-Audio Generation</title><link>http://arxiv.org/abs/2412.15922v2</link><description>Despite significant advancements in Text-to-Audio (TTA) generation modelsachieving high-fidelity audio with fine-grained context understanding, theystruggle to model the relations between audio events described in the inputtext. However, previous TTA methods have not systematically explored audioevent relation modeling, nor have they proposed frameworks to enhance thiscapability. In this work, we systematically study audio event relation modelingin TTA generation models. We first establish a benchmark for this task by: 1.proposing a comprehensive relation corpus covering all potential relations inreal-world scenarios; 2. introducing a new audio event corpus encompassingcommonly heard audios; and 3. proposing new evaluation metrics to assess audioevent relation modeling from various perspectives. Furthermore, we propose afinetuning framework to enhance existing TTA models ability to model audioevents relation. Code is available at: https://github.com/yuhanghe01/RiTTA</description><author>Yuhang He, Yash Jain, Xubo Liu, Andrew Markham, Vibhav Vineet</author><pubDate>Thu, 02 Jan 2025 14:38:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15922v2</guid></item><item><title>Predictive Model Development to Identify Failed Healing in Patients after Non-Union Fracture Surgery</title><link>http://arxiv.org/abs/2404.11760v3</link><description>Bone non-union is among the most severe complications associated with traumasurgery, occurring in 10-30% of cases after long bone fractures. Treatingnon-unions requires a high level of surgical expertise and often involvesmultiple revision surgeries, sometimes even leading to amputation. Thus, moreaccurate prognosis is crucial for patient well-being. Recent advances inmachine learning (ML) hold promise for developing models to predict non-unionhealing, even when working with smaller datasets, a commonly encounteredchallenge in clinical domains. To demonstrate the effectiveness of ML inidentifying candidates at risk of failed non-union healing, we applied three MLmodels (logistic regression, support vector machine, and XGBoost) to theclinical dataset TRUFFLE, which includes 797 patients with long bone non-union.The models provided prediction results with 70% sensitivity, and thespecificities of 66% (XGBoost), 49% (support vector machine), and 43% (logisticregression). These findings offer valuable clinical insights because theyenable early identification of patients at risk of failed non-union healingafter the initial surgical revision treatment protocol.</description><author>Cedric Donié, Marie K. Reumann, Tony Hartung, Benedikt J. Braun, Tina Histing, Satoshi Endo, Sandra Hirche</author><pubDate>Thu, 02 Jan 2025 14:24:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11760v3</guid></item><item><title>Multi-Agent Quantum Reinforcement Learning using Evolutionary Optimization</title><link>http://arxiv.org/abs/2311.05546v4</link><description>Multi-Agent Reinforcement Learning is becoming increasingly more important intimes of autonomous driving and other smart industrial applications.Simultaneously a promising new approach to Reinforcement Learning arises usingthe inherent properties of quantum mechanics, reducing the trainable parametersof a model significantly. However, gradient-based Multi-Agent QuantumReinforcement Learning methods often have to struggle with barren plateaus,holding them back from matching the performance of classical approaches. Whilegradient free Quantum Reinforcement Learning methods may alleviate some ofthese challenges, they too are not immune to the difficulties posed by barrenplateaus. We build upon an existing approach for gradient free QuantumReinforcement Learning and propose three genetic variations with VariationalQuantum Circuits for Multi-Agent Reinforcement Learning using evolutionaryoptimization. We evaluate our genetic variations in the Coin Game environmentand also compare them to classical approaches. We showed that our VariationalQuantum Circuit approaches perform significantly better compared to a neuralnetwork with a similar amount of trainable parameters. Compared to the largerneural network, our approaches archive similar results using $97.88\%$ lessparameters.</description><author>Michael Kölle, Felix Topp, Thomy Phan, Philipp Altmann, Jonas Nüßlein, Claudia Linnhoff-Popien</author><pubDate>Thu, 02 Jan 2025 14:09:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05546v4</guid></item><item><title>Tensor-Based Foundations of Ordinary Least Squares and Neural Network Regression Models</title><link>http://arxiv.org/abs/2411.12873v3</link><description>This article introduces a novel approach to the mathematical development ofOrdinary Least Squares and Neural Network regression models, diverging fromtraditional methods in current Machine Learning literature. By leveragingTensor Analysis and fundamental matrix computations, the theoreticalfoundations of both models are meticulously detailed and extended to theircomplete algorithmic forms. The study culminates in the presentation of threealgorithms, including a streamlined version of the Backpropagation Algorithmfor Neural Networks, illustrating the benefits of this new mathematicalapproach.</description><author>Roberto Dias Algarte</author><pubDate>Thu, 02 Jan 2025 14:03:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12873v3</guid></item><item><title>Detecting Financial Bots on the Ethereum Blockchain</title><link>http://arxiv.org/abs/2403.19530v2</link><description>The integration of bots in Distributed Ledger Technologies (DLTs) fostersefficiency and automation. However, their use is also associated with predatorytrading and market manipulation, and can pose threats to system integrity. Itis therefore essential to understand the extent of bot deployment in DLTs;despite this, current detection systems are predominantly rule-based and lackflexibility. In this study, we present a novel approach that utilizes machinelearning for the detection of financial bots on the Ethereum platform. First,we systematize existing scientific literature and collect anecdotal evidence toestablish a taxonomy for financial bots, comprising 7 categories and 24subcategories. Next, we create a ground-truth dataset consisting of 133 humanand 137 bot addresses. Third, we employ both unsupervised and supervisedmachine learning algorithms to detect bots deployed on Ethereum. Thehighest-performing clustering algorithm is a Gaussian Mixture Model with anaverage cluster purity of 82.6%, while the highest-performing model for binaryclassification is a Random Forest with an accuracy of 83%. Our machinelearning-based detection mechanism contributes to understanding the Ethereumecosystem dynamics by providing additional insights into the current botlandscape.</description><author>Thomas Niedermayer, Pietro Saggese, Bernhard Haslhofer</author><pubDate>Thu, 02 Jan 2025 13:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19530v2</guid></item><item><title>Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents</title><link>http://arxiv.org/abs/2407.01887v3</link><description>In-context reinforcement learning (ICRL) is a frontier paradigm for solvingreinforcement learning problems in the foundation model era. While ICRLcapabilities have been demonstrated in transformers through task-specifictraining, the potential of Large Language Models (LLMs) out-of-the-box remainslargely unexplored. Recent findings highlight that LLMs often face challengeswhen dealing with numerical contexts, and limited attention has been paid toevaluating their performance through preference feedback generated by theenvironment. This paper is the first to investigate LLMs as in-contextdecision-makers under the problem of Dueling Bandits (DB), a statelesspreference-based reinforcement learning setting that extends the classicMulti-Armed Bandit (MAB) model by querying for preference feedback. We compareGPT-3.5 Turbo, GPT-4, GPT-4 Turbo, Llama 3.1, and o1-Preview against ninewell-established DB algorithms. Our results reveal that our top-performing LLM,GPT-4 Turbo, has the zero-shot relative decision-making ability to achievesurprisingly low weak regret across all the DB environment instances by quicklyincluding the best arm in duels. However, an optimality gap exists between LLMsand classic DB algorithms in terms of strong regret. LLMs struggle to convergeand consistently exploit even when explicitly prompted to do so, and aresensitive to prompt variations. To bridge this gap, we propose an agentic flowframework: LLM with Enhanced Algorithmic Dueling (LEAD), which integratesoff-the-shelf DB algorithms with LLM agents through fine-grained adaptiveinterplay. We show that LEAD has theoretical guarantees inherited from classicDB algorithms on both weak and strong regret. We validate its efficacy androbustness even with noisy and adversarial prompts. The design of our frameworksheds light on how to enhance the trustworthiness of LLMs used for in-contextdecision-making.</description><author>Fanzeng Xia, Hao Liu, Yisong Yue, Tongxin Li</author><pubDate>Thu, 02 Jan 2025 13:49:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01887v3</guid></item><item><title>Hyperparameter Importance Analysis for Multi-Objective AutoML</title><link>http://arxiv.org/abs/2405.07640v3</link><description>Hyperparameter optimization plays a pivotal role in enhancing the predictiveperformance and generalization capabilities of ML models. However, in manyapplications, we do not only care about predictive performance but also aboutadditional objectives such as inference time, memory, or energy consumption. Insuch multi-objective scenarios, determining the importance of hyperparametersposes a significant challenge due to the complex interplay between theconflicting objectives. In this paper, we propose the first method forassessing the importance of hyperparameters in multi-objective hyperparameteroptimization. Our approach leverages surrogate-based hyperparameter importancemeasures, i.e., fANOVA and ablation paths, to provide insights into the impactof hyperparameters on the optimization objectives. Specifically, we compute thea-priori scalarization of the objectives and determine the importance of thehyperparameters for different objective tradeoffs. Through extensive empiricalevaluations on diverse benchmark datasets with three different objective pairs,each combined with accuracy, namely time, demographic parity loss, and energyconsumption, we demonstrate the effectiveness and robustness of our proposedmethod. Our findings not only offer valuable guidance for hyperparameter tuningin multi-objective optimization tasks but also contribute to advancing theunderstanding of hyperparameter importance in complex optimization scenarios.</description><author>Daphne Theodorakopoulos, Frederic Stahl, Marius Lindauer</author><pubDate>Thu, 02 Jan 2025 13:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07640v3</guid></item><item><title>Fine-grained Image-to-LiDAR Contrastive Distillation with Visual Foundation Models</title><link>http://arxiv.org/abs/2405.14271v3</link><description>Contrastive image-to-LiDAR knowledge transfer, commonly used for learning 3Drepresentations with synchronized images and point clouds, often faces aself-conflict dilemma. This issue arises as contrastive losses unintentionallydissociate features of unmatched points and pixels that share semantic labels,compromising the integrity of learned representations. To overcome this, weharness Visual Foundation Models (VFMs), which have revolutionized theacquisition of pixel-level semantics, to enhance 3D representation learning.Specifically, we utilize off-the-shelf VFMs to generate semantic labels forweakly-supervised pixel-to-point contrastive distillation. Additionally, weemploy von Mises-Fisher distributions to structure the feature space, ensuringsemantic embeddings within the same class remain consistent across varyinginputs. Furthermore, we adapt sampling probabilities of points to addressimbalances in spatial distribution and category frequency, promotingcomprehensive and balanced learning. Extensive experiments demonstrate that ourapproach mitigates the challenges posed by traditional methods and consistentlysurpasses existing image-to-LiDAR contrastive distillation methods indownstream tasks. The source code is available athttps://github.com/Eaphan/OLIVINE.</description><author>Yifan Zhang, Junhui Hou</author><pubDate>Thu, 02 Jan 2025 13:30:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14271v3</guid></item><item><title>EraseAnything: Enabling Concept Erasure in Rectified Flow Transformers</title><link>http://arxiv.org/abs/2412.20413v2</link><description>Removing unwanted concepts from large-scale text-to-image (T2I) diffusionmodels while maintaining their overall generative quality remains an openchallenge. This difficulty is especially pronounced in emerging paradigms, suchas Stable Diffusion (SD) v3 and Flux, which incorporate flow matching andtransformer-based architectures. These advancements limit the transferabilityof existing concept-erasure techniques that were originally designed for theprevious T2I paradigm (e.g., SD v1.4). In this work, we introduceEraseAnything, the first method specifically developed to address concepterasure within the latest flow-based T2I framework. We formulate concepterasure as a bi-level optimization problem, employing LoRA-based parametertuning and an attention map regularizer to selectively suppress undesirableactivations. Furthermore, we propose a self-contrastive learning strategy toensure that removing unwanted concepts does not inadvertently harm performanceon unrelated ones. Experimental results demonstrate that EraseAnythingsuccessfully fills the research gap left by earlier methods in this new T2Iparadigm, achieving state-of-the-art performance across a wide range of concepterasure tasks.</description><author>Daiheng Gao, Shilin Lu, Shaw Walters, Wenbo Zhou, Jiaming Chu, Jie Zhang, Bang Zhang, Mengxi Jia, Jian Zhao, Zhaoxin Fan, Weiming Zhang</author><pubDate>Thu, 02 Jan 2025 13:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.20413v2</guid></item><item><title>Real World Federated Learning with a Knowledge Distilled Transformer for Cardiac CT Imaging</title><link>http://arxiv.org/abs/2407.07557v2</link><description>Federated learning is a renowned technique for utilizing decentralized datawhile preserving privacy. However, real-world applications often facechallenges like partially labeled datasets, where only a few locations havecertain expert annotations, leaving large portions of unlabeled data unused.Leveraging these could enhance transformer architectures ability in regimeswith small and diversely annotated sets. We conduct the largest federatedcardiac CT analysis to date (n=8,104) in a real-world setting across eighthospitals. Our two-step semi-supervised strategy distills knowledge fromtask-specific CNNs into a transformer. First, CNNs predict on unlabeled dataper label type and then the transformer learns from these predictions withlabel-specific heads. This improves predictive accuracy and enablessimultaneous learning of all partial labels across the federation, andoutperforms UNet-based models in generalizability on downstream tasks. Code andmodel weights are made openly available for leveraging future cardiac CTanalysis.</description><author>Malte Tölle, Philipp Garthe, Clemens Scherer, Jan Moritz Seliger, Andreas Leha, Nina Krüger, Stefan Simm, Simon Martin, Sebastian Eble, Halvar Kelm, Moritz Bednorz, Florian André, Peter Bannas, Gerhard Diller, Norbert Frey, Stefan Groß, Anja Hennemuth, Lars Kaderali, Alexander Meyer, Eike Nagel, Stefan Orwat, Moritz Seiffert, Tim Friede, Tim Seidler, Sandy Engelhardt</author><pubDate>Thu, 02 Jan 2025 13:22:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07557v2</guid></item><item><title>Realistic Noise Synthesis with Diffusion Models</title><link>http://arxiv.org/abs/2305.14022v4</link><description>Deep denoising models require extensive real-world training data, which ischallenging to acquire. Current noise synthesis techniques struggle toaccurately model complex noise distributions. We propose a novel RealisticNoise Synthesis Diffusor (RNSD) method using diffusion models to address thesechallenges. By encoding camera settings into a time-aware camera-conditionedaffine modulation (TCCAM), RNSD generates more realistic noise distributionsunder various camera conditions. Additionally, RNSD integrates a multi-scalecontent-aware module (MCAM), enabling the generation of structured noise withspatial correlations across multiple frequencies. We also introduce Deep ImagePrior Sampling (DIPS), a learnable sampling sequence based on depth imageprior, which significantly accelerates the sampling process while maintainingthe high quality of synthesized noise. Extensive experiments demonstrate thatour RNSD method significantly outperforms existing techniques in synthesizingrealistic noise under multiple metrics and improving image denoisingperformance.</description><author>Qi Wu, Mingyan Han, Ting Jiang, Chengzhi Jiang, Jinting Luo, Man Jiang, Haoqiang Fan, Shuaicheng Liu</author><pubDate>Thu, 02 Jan 2025 13:13:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14022v4</guid></item><item><title>Security Attacks on LLM-based Code Completion Tools</title><link>http://arxiv.org/abs/2408.11006v4</link><description>The rapid development of large language models (LLMs) has significantlyadvanced code completion capabilities, giving rise to a new generation ofLLM-based Code Completion Tools (LCCTs). Unlike general-purpose LLMs, thesetools possess unique workflows, integrating multiple information sources asinput and prioritizing code suggestions over natural language interaction,which introduces distinct security challenges. Additionally, LCCTs often relyon proprietary code datasets for training, raising concerns about the potentialexposure of sensitive data. This paper exploits these distinct characteristicsof LCCTs to develop targeted attack methodologies on two critical securityrisks: jailbreaking and training data extraction attacks. Our experimentalresults expose significant vulnerabilities within LCCTs, including a 99.4%success rate in jailbreaking attacks on GitHub Copilot and a 46.3% success rateon Amazon Q. Furthermore, We successfully extracted sensitive user data fromGitHub Copilot, including 54 real email addresses and 314 physical addressesassociated with GitHub usernames. Our study also demonstrates that thesecode-based attack methods are effective against general-purpose LLMs, such asthe GPT series, highlighting a broader security misalignment in the handling ofcode by modern LLMs. These findings underscore critical security challengesassociated with LCCTs and suggest essential directions for strengthening theirsecurity frameworks. The example code and attack samples from our research areprovided at https://github.com/Sensente/Security-Attacks-on-LCCTs.</description><author>Wen Cheng, Ke Sun, Xinyu Zhang, Wei Wang</author><pubDate>Thu, 02 Jan 2025 13:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11006v4</guid></item><item><title>Generative Modelling with High-Order Langevin Dynamics</title><link>http://arxiv.org/abs/2404.12814v3</link><description>Diffusion generative modelling (DGM) based on stochastic differentialequations (SDEs) with score matching has achieved unprecedented results in datageneration. In this paper, we propose a novel fast high-quality generativemodelling method based on high-order Langevin dynamics (HOLD) with scorematching. This motive is proved by third-order Langevin dynamics. By augmentingthe previous SDEs, e.g. variance exploding or variance preserving SDEs forsingle-data variable processes, HOLD can simultaneously model position,velocity, and acceleration, thereby improving the quality and speed of the datageneration at the same time. HOLD is composed of one Ornstein-Uhlenbeck processand two Hamiltonians, which reduce the mixing time by two orders of magnitude.Empirical experiments for unconditional image generation on the public data setCIFAR-10 and CelebA-HQ show that the effect is significant in both Frechetinception distance (FID) and negative log-likelihood, and achieves thestate-of-the-art FID of 1.85 on CIFAR-10.</description><author>Ziqiang Shi, Rujie Liu</author><pubDate>Thu, 02 Jan 2025 13:06:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12814v3</guid></item><item><title>IVIM-Morph: Motion-compensated quantitative Intra-voxel Incoherent Motion (IVIM) analysis for functional fetal lung maturity assessment from diffusion-weighted MRI data</title><link>http://arxiv.org/abs/2401.07126v3</link><description>Quantitative analysis of pseudo-diffusion in diffusion-weighted magneticresonance imaging (DWI) data shows potential for assessing fetal lungmaturation and generating valuable imaging biomarkers. Yet, the clinicalutility of DWI data is hindered by unavoidable fetal motion during acquisition.We present IVIM-morph, a self-supervised deep neural network model formotion-corrected quantitative analysis of DWI data using the Intra-voxelIncoherent Motion (IVIM) model. IVIM-morph combines two sub-networks, aregistration sub-network, and an IVIM model fitting sub-network, enablingsimultaneous estimation of IVIM model parameters and motion. To promotephysically plausible image registration, we introduce a biophysically informedloss function that effectively balances registration and model-fitting quality.We validated the efficacy of IVIM-morph by establishing a correlation betweenthe predicted IVIM model parameters of the lung and gestational age (GA) usingfetal DWI data of 39 subjects. IVIM-morph exhibited a notably improvedcorrelation with gestational age (GA) when performing in-vivo quantitativeanalysis of fetal lung DWI data during the canalicular phase. IVIM-morph showspotential in developing valuable biomarkers for non-invasive assessment offetal lung maturity with DWI data. Moreover, its adaptability opens the door topotential applications in other clinical contexts where motion compensation isessential for quantitative DWI analysis. The IVIM-morph code is readilyavailable at: https://github.com/TechnionComputationalMRILab/qDWI-Morph.</description><author>Noga Kertes, Yael Zaffrani-Reznikov, Onur Afacan, Sila Kurugol, Simon K. Warfield, Moti Freiman</author><pubDate>Thu, 02 Jan 2025 12:39:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07126v3</guid></item><item><title>Next Patch Prediction for Autoregressive Visual Generation</title><link>http://arxiv.org/abs/2412.15321v2</link><description>Autoregressive models, built based on the Next Token Prediction (NTP)paradigm, show great potential in developing a unified framework thatintegrates both language and vision tasks. In this work, we rethink the NTP forautoregressive image generation and propose a novel Next Patch Prediction (NPP)paradigm. Our key idea is to group and aggregate image tokens into patch tokenscontaining high information density. With patch tokens as a shorter inputsequence, the autoregressive model is trained to predict the next patch,thereby significantly reducing the computational cost. We further propose amulti-scale coarse-to-fine patch grouping strategy that exploits the naturalhierarchical property of image data. Experiments on a diverse range of models(100M-1.4B parameters) demonstrate that the next patch prediction paradigmcould reduce the training cost to around 0.6 times while improving imagegeneration quality by up to 1.0 FID score on the ImageNet benchmark. Wehighlight that our method retains the original autoregressive modelarchitecture without introducing additional trainable parameters orspecifically designing a custom image tokenizer, thus ensuring flexibility andseamless adaptation to various autoregressive models for visual generation.</description><author>Yatian Pang, Peng Jin, Shuo Yang, Bin Lin, Bin Zhu, Zhenyu Tang, Liuhan Chen, Francis E. H. Tay, Ser-Nam Lim, Harry Yang, Li Yuan</author><pubDate>Thu, 02 Jan 2025 12:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15321v2</guid></item><item><title>Enhancing Preference-based Linear Bandits via Human Response Time</title><link>http://arxiv.org/abs/2409.05798v4</link><description>Interactive preference learning systems infer human preferences by presentingqueries as pairs of options and collecting binary choices. Although binarychoices are simple and widely used, they provide limited information aboutpreference strength. To address this, we leverage human response times, whichare inversely related to preference strength, as an additional signal. Wepropose a computationally efficient method that combines choices and responsetimes to estimate human utility functions, grounded in the EZ diffusion modelfrom psychology. Theoretical and empirical analyses show that for queries withstrong preferences, response times complement choices by providing extrainformation about preference strength, leading to significantly improvedutility estimation. We incorporate this estimator into preference-based linearbandits for fixed-budget best-arm identification. Simulations on threereal-world datasets demonstrate that using response times significantlyaccelerates preference learning compared to choice-only approaches. Additionalmaterials, such as code, slides, and talk video, are available athttps://shenlirobot.github.io/pages/NeurIPS24.html</description><author>Shen Li, Yuyang Zhang, Zhaolin Ren, Claire Liang, Na Li, Julie A. Shah</author><pubDate>Thu, 02 Jan 2025 12:00:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05798v4</guid></item><item><title>Physically Constrained Generative Adversarial Networks for Improving Precipitation Fields from Earth System Models</title><link>http://arxiv.org/abs/2209.07568v2</link><description>Precipitation results from complex processes across many scales, making itsaccurate simulation in Earth system models (ESMs) challenging. Existingpost-processing methods can improve ESM simulations locally, but cannot correcterrors in modelled spatial patterns. Here we propose a framework based onphysically constrained generative adversarial networks (GANs) to improve localdistributions and spatial structure simultaneously. We apply our approach tothe computationally efficient ESM CM2Mc-LPJmL. Our method outperforms existingones in correcting local distributions, and leads to strongly improved spatialpatterns especially regarding the intermittency of daily precipitation.Notably, a double-peaked Intertropical Convergence Zone, a common problem inESMs, is removed. Enforcing a physical constraint to preserve globalprecipitation sums, the GAN can generalize to future climate scenarios unseenduring training. Feature attribution shows that the GAN identifies regionswhere the ESM exhibits strong biases. Our method constitutes a generalframework for correcting ESM variables and enables realistic simulations at afraction of the computational costs.</description><author>Philipp Hess, Markus Drüke, Stefan Petri, Felix M. Strnad, Niklas Boers</author><pubDate>Thu, 02 Jan 2025 11:31:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.07568v2</guid></item><item><title>Fast, Scale-Adaptive, and Uncertainty-Aware Downscaling of Earth System Model Fields with Generative Machine Learning</title><link>http://arxiv.org/abs/2403.02774v2</link><description>Accurate and high-resolution Earth system model (ESM) simulations areessential to assess the ecological and socio-economic impacts of anthropogenicclimate change, but are computationally too expensive to be run at sufficientlyhigh spatial resolution. Recent machine learning approaches have shownpromising results in downscaling ESM simulations, outperformingstate-of-the-art statistical approaches. However, existing methods requirecomputationally costly retraining for each ESM and extrapolate poorly toclimates unseen during training. We address these shortcomings by learning aconsistency model (CM) that efficiently and accurately downscales arbitrary ESMsimulations without retraining in a zero-shot manner. Our approach yieldsprobabilistic downscaled fields at a resolution only limited by theobservational reference data. We show that the CM outperforms state-of-the-artdiffusion models at a fraction of computational cost while maintaining highcontrollability on the downscaling task. Further, our method generalizes toclimate states unseen during training without explicitly formulated physicalconstraints.</description><author>Philipp Hess, Michael Aich, Baoxiang Pan, Niklas Boers</author><pubDate>Thu, 02 Jan 2025 11:30:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02774v2</guid></item><item><title>EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union</title><link>http://arxiv.org/abs/2403.15474v2</link><description>This paper presents Ego-Centric Intersection-over-Union (EC-IoU), addressingthe limitation of the standard IoU measure in characterizing safety-relatedperformance for object detectors in navigating contexts. Concretely, we proposea weighting mechanism to refine IoU, allowing it to assign a higher score to aprediction that covers closer points of a ground-truth object from the egoagent's perspective. The proposed EC-IoU measure can be used in typicalevaluation processes to select object detectors with better safety-relatedperformance for downstream tasks. It can also be integrated into common lossfunctions for model fine-tuning. While geared towards safety, our experimentwith the KITTI dataset demonstrates the performance of a model trained onEC-IoU can be better than that of a variant trained on IoU in terms of meanAverage Precision as well.</description><author>Brian Hsuan-Cheng Liao, Chih-Hong Cheng, Hasan Esen, Alois Knoll</author><pubDate>Thu, 02 Jan 2025 11:28:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15474v2</guid></item><item><title>Spectral Enhancement and Pseudo-Anchor Guidance for Infrared-Visible Person Re-Identification</title><link>http://arxiv.org/abs/2412.19111v2</link><description>The development of deep learning has facilitated the application of personre-identification (ReID) technology in intelligent security. Visible-infraredperson re-identification (VI-ReID) aims to match pedestrians across infraredand visible modality images enabling 24-hour surveillance. Current studiesrelying on unsupervised modality transformations as well as inefficientembedding constraints to bridge the spectral differences between infrared andvisible images, however, limit their potential performance. To tackle thelimitations of the above approaches, this paper introduces a simple yeteffective Spectral Enhancement and Pseudo-anchor Guidance Network, namedSEPG-Net. Specifically, we propose a more homogeneous spectral enhancementscheme based on frequency domain information and greyscale space, which avoidsthe information loss typically caused by inefficient modality transformations.Further, a Pseudo Anchor-guided Bidirectional Aggregation (PABA) loss isintroduced to bridge local modality discrepancies while better preservingdiscriminative identity embeddings. Experimental results on two publicbenchmark datasets demonstrate the superior performance of SEPG-Net againstother state-of-the-art methods. The code is available athttps://github.com/1024AILab/ReID-SEPG.</description><author>Yiyuan Ge, Zhihao Chen, Ziyang Wang, Jiaju Kang, Mingya Zhang</author><pubDate>Thu, 02 Jan 2025 11:22:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19111v2</guid></item><item><title>Baichuan4-Finance Technical Report</title><link>http://arxiv.org/abs/2412.15270v2</link><description>Large language models (LLMs) have demonstrated strong capabilities inlanguage understanding, generation, and reasoning, yet their potential infinance remains underexplored due to the complexity and specialization offinancial knowledge. In this work, we report the development of theBaichuan4-Finance series, including a comprehensive suite of foundationalBaichuan4-Finance-Base and an aligned language model Baichuan4-Finance, whichare built upon Baichuan4-Turbo base model and tailored for finance domain.Firstly, we have dedicated significant effort to building a detailed pipelinefor improving data quality. Moreover, in the continual pre-training phase, wepropose a novel domain self-constraint training strategy, which enablesBaichuan4-Finance-Base to acquire financial knowledge without losing generalcapabilities. After Supervised Fine-tuning and Reinforcement Learning fromHuman Feedback and AI Feedback, the chat model Baichuan4-Finance is able totackle various financial certification questions and real-world scenarioapplications. We evaluate Baichuan4-Finance on many widely used generaldatasets and two holistic financial benchmarks. The evaluation results showthat Baichuan4-Finance-Base surpasses almost all competitive baselines onfinancial tasks by significant margins without sacrificing performance ongeneral LLM benchmarks. At the same time, Baichuan4-Finance demonstrates evenmore impressive performance on financial application scenarios, showcasing itspotential to foster community innovation in the financial LLM field.</description><author>Hanyu Zhang, Boyu Qiu, Yuhao Feng, Shuqi Li, Qian Ma, Xiyuan Zhang, Qiang Ju, Dong Yan, Jian Xie</author><pubDate>Thu, 02 Jan 2025 11:21:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15270v2</guid></item><item><title>FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system</title><link>http://arxiv.org/abs/2410.21349v3</link><description>Recently, large language models (LLMs) have achieved significant progress inautomated code generation. Despite their strong instruction-followingcapabilities, these models frequently struggled to align with user intent incoding scenarios. In particular, they were hampered by datasets that lackeddiversity and failed to address specialized tasks or edge cases. Furthermore,challenges in supervised fine-tuning (SFT) and reinforcement learning fromhuman feedback (RLHF) led to failures in generating precise,human-intent-aligned code. To tackle these challenges and improve the codegeneration performance for automated programming systems, we proposeFeedback-driven Adaptive Long/short-term memory reinforced Coding Optimization(i.e., FALCON). FALCON is structured into two hierarchical levels. From theglobal level, long-term memory improves code quality by retaining and applyinglearned knowledge. At the local level, short-term memory allows for theincorporation of immediate feedback from compilers and AI systems.Additionally, we introduce meta-reinforcement learning with feedback rewards tosolve the global-local bi-level optimization problem and enhance the model'sadaptability across diverse code generation tasks. Extensive experimentsdemonstrate that our technique achieves state-of-the-art performance, leadingother reinforcement learning methods by more than 4.5 percentage points on theMBPP benchmark and 6.1 percentage points on the Humaneval benchmark. Theopen-sourced code is publicly available at https://github.com/titurte/FALCON.</description><author>Zeyuan Li, Yangfan He, Lewei He, Jianhui Wang, Tianyu Shi, Bin Lei, Yuchen Li, Qiuwu Chen</author><pubDate>Thu, 02 Jan 2025 11:16:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21349v3</guid></item><item><title>COMET:Combined Matrix for Elucidating Targets</title><link>http://arxiv.org/abs/2412.02471v2</link><description>Identifying the interaction targets of bioactive compounds is a foundationalelement for deciphering their pharmacological effects. Target predictionalgorithms equip researchers with an effective tool to rapidly scope andexplore potential targets. Here, we introduce the COMET, a multi-technologicalmodular target prediction tool that provides comprehensive predictive insights,including similar active compounds, three-dimensional predicted binding modes,and probability scores, all within an average processing time of less than 10minutes per task. With meticulously curated data, the COMET databaseencompasses 990,944 drug-target interaction pairs and 45,035 binding pockets,enabling predictions for 2,685 targets, which span confirmed and exploratorytherapeutic targets for human diseases. In comparative testing using datasetsfrom ChEMBL and BindingDB, COMET outperformed five other well-known algorithms,offering nearly an 80% probability of accurately identifying at least one truetarget within the top 15 predictions for a given compound. COMET also featuresa user-friendly web server, accessible freely athttps://www.pdbbind-plus.org.cn/comet.</description><author>Haojie Wang, Zhe Zhang, Haotian Gao, Xiangying Zhang, Jingyuan Li, Zhihang Chen, Xinchong Chen, Yifei Qi, Yan Li, Renxiao Wang</author><pubDate>Thu, 02 Jan 2025 11:09:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.02471v2</guid></item><item><title>Dynamic Negative Guidance of Diffusion Models</title><link>http://arxiv.org/abs/2410.14398v2</link><description>Negative Prompting (NP) is widely utilized in diffusion models, particularlyin text-to-image applications, to prevent the generation of undesired features.In this paper, we show that conventional NP is limited by the assumption of aconstant guidance scale, which may lead to highly suboptimal results, or evencomplete failure, due to the non-stationarity and state-dependence of thereverse process. Based on this analysis, we derive a principled techniquecalled Dynamic Negative Guidance, which relies on a near-optimal time and statedependent modulation of the guidance without requiring additional training.Unlike NP, negative guidance requires estimating the posterior classprobability during the denoising process, which is achieved with limitedadditional computational overhead by tracking the discrete Markov Chain duringthe generative process. We evaluate the performance of DNG class-removal onMNIST and CIFAR10, where we show that DNG leads to higher safety, preservationof class balance and image quality when compared with baseline methods.Furthermore, we show that it is possible to use DNG with Stable Diffusion toobtain more accurate and less invasive guidance than NP.</description><author>Felix Koulischer, Johannes Deleu, Gabriel Raya, Thomas Demeester, Luca Ambrogioni</author><pubDate>Thu, 02 Jan 2025 11:06:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14398v2</guid></item><item><title>The Reality of AI and Biorisk</title><link>http://arxiv.org/abs/2412.01946v3</link><description>To accurately and confidently answer the question 'could an AI model orsystem increase biorisk', it is necessary to have both a sound theoreticalthreat model for how AI models or systems could increase biorisk and a robustmethod for testing that threat model. This paper provides an analysis ofexisting available research surrounding two AI and biorisk threat models: 1)access to information and planning via large language models (LLMs), and 2) theuse of AI-enabled biological tools (BTs) in synthesizing novel biologicalartifacts. We find that existing studies around AI-related biorisk are nascent,often speculative in nature, or limited in terms of their methodologicalmaturity and transparency. The available literature suggests that current LLMsand BTs do not pose an immediate risk, and more work is needed to developrigorous approaches to understanding how future models could increase biorisks.We end with recommendations about how empirical work can be expanded to moreprecisely target biorisk and ensure rigor and validity of findings.</description><author>Aidan Peppin, Anka Reuel, Stephen Casper, Elliot Jones, Andrew Strait, Usman Anwar, Anurag Agrawal, Sayash Kapoor, Sanmi Koyejo, Marie Pellat, Rishi Bommasani, Nick Frosst, Sara Hooker</author><pubDate>Thu, 02 Jan 2025 11:04:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01946v3</guid></item><item><title>Summarizing Bayesian Nonparametric Mixture Posterior -- Sliced Optimal Transport Metrics for Gaussian Mixtures</title><link>http://arxiv.org/abs/2411.14674v3</link><description>Existing methods to summarize posterior inference for mixture models focus onidentifying a point estimate of the implied random partition for clustering,with density estimation as a secondary goal (Wade and Ghahramani, 2018; Dahl etal., 2022). We propose a novel approach for summarizing posterior inference innonparametric Bayesian mixture models, prioritizing density estimation of themixing measure (or mixture) as an inference target. One of the key features isthe model-agnostic nature of the approach, which remains valid underarbitrarily complex dependence structures in the underlying sampling model.Using a decision-theoretic framework, our method identifies a point estimate byminimizing posterior expected loss. A loss function is defined as a discrepancybetween mixing measures. Estimating the mixing measure implies inference on themixture density and the random partition. Exploiting the discrete nature of themixing measure, we use a version of sliced Wasserstein distance. We introducetwo specific variants for Gaussian mixtures. The first, mixed slicedWasserstein, applies generalized geodesic projections on the product of theEuclidean space and the manifold of symmetric positive definite matrices. Thesecond, sliced mixture Wasserstein, leverages the linearity of Gaussian mixturemeasures for efficient projection.</description><author>Khai Nguyen, Peter Mueller</author><pubDate>Thu, 02 Jan 2025 11:00:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.14674v3</guid></item><item><title>Trajectory Representation Learning on Road Networks and Grids with Spatio-Temporal Dynamics</title><link>http://arxiv.org/abs/2411.14014v2</link><description>Trajectory representation learning is a fundamental task for applications infields including smart city, and urban planning, as it facilitates theutilization of trajectory data (e.g., vehicle movements) for various downstreamapplications, such as trajectory similarity computation or travel timeestimation. This is achieved by learning low-dimensional representations fromhigh-dimensional and raw trajectory data. However, existing methods fortrajectory representation learning either rely on grid-based or road-basedrepresentations, which are inherently different and thus, could loseinformation contained in the other modality. Moreover, these methods overlookthe dynamic nature of urban traffic, relying on static road network featuresrather than time varying traffic patterns. In this paper, we propose TIGR, anovel model designed to integrate grid and road network modalities whileincorporating spatio-temporal dynamics to learn rich, general-purposerepresentations of trajectories. We evaluate TIGR on two realworld datasets anddemonstrate the effectiveness of combining both modalities by substantiallyoutperforming state-of-the-art methods, i.e., up to 43.22% for trajectorysimilarity, up to 16.65% for travel time estimation, and up to 10.16% fordestination prediction.</description><author>Stefan Schestakov, Simon Gottschalk</author><pubDate>Thu, 02 Jan 2025 10:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.14014v2</guid></item><item><title>Mamba-SEUNet: Mamba UNet for Monaural Speech Enhancement</title><link>http://arxiv.org/abs/2412.16626v2</link><description>In recent speech enhancement (SE) research, transformer and its variants haveemerged as the predominant methodologies. However, the quadratic complexity ofthe self-attention mechanism imposes certain limitations on practicaldeployment. Mamba, as a novel state-space model (SSM), has gained widespreadapplication in natural language processing and computer vision due to itsstrong capabilities in modeling long sequences and relatively low computationalcomplexity. In this work, we introduce Mamba-SEUNet, an innovative architecturethat integrates Mamba with U-Net for SE tasks. By leveraging bidirectionalMamba to model forward and backward dependencies of speech signals at differentresolutions, and incorporating skip connections to capture multi-scaleinformation, our approach achieves state-of-the-art (SOTA) performance.Experimental results on the VCTK+DEMAND dataset indicate that Mamba-SEUNetattains a PESQ score of 3.59, while maintaining low computational complexity.When combined with the Perceptual Contrast Stretching technique, Mamba-SEUNetfurther improves the PESQ score to 3.73.</description><author>Junyu Wang, Zizhen Lin, Tianrui Wang, Meng Ge, Longbiao Wang, Jianwu Dang</author><pubDate>Thu, 02 Jan 2025 10:56:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16626v2</guid></item><item><title>ARNet: Self-Supervised FG-SBIR with Unified Sample Feature Alignment and Multi-Scale Token Recycling</title><link>http://arxiv.org/abs/2406.11551v5</link><description>Fine-Grained Sketch-Based Image Retrieval (FG-SBIR) aims to minimize thedistance between sketches and corresponding images in the embedding space.However, scalability is hindered by the growing complexity of solutions, mainlydue to the abstract nature of fine-grained sketches. In this paper, we proposean effective approach to narrow the gap between the two domains. It mainlyfacilitates unified mutual information sharing both intra- and inter-samples,rather than treating them as a single feature alignment problem betweenmodalities. Specifically, our approach includes: (i) Employing dualweight-sharing networks to optimize alignment within the sketch and imagedomain, which also effectively mitigates model learning saturation issues. (ii)Introducing an objective optimization function based on contrastive loss toenhance the model's ability to align features in both intra- and inter-samples.(iii) Presenting a self-supervised Multi-Scale Token Recycling (MSTR) Modulefeatured by recycling discarded patch tokens in multi-scale features, furtherenhancing representation capability and retrieval performance. Our frameworkachieves excellent results on CNN- and ViT-based backbones. Extensiveexperiments demonstrate its superiority over existing methods. We alsointroduce Cloths-V1, the first professional fashion sketch-image dataset,utilized to validate our method and will be beneficial for other applications.</description><author>Jianan Jiang, Hao Tang, Zhilin Jiang, Weiren Yu, Di Wu</author><pubDate>Thu, 02 Jan 2025 10:51:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11551v5</guid></item><item><title>Improving Graph Neural Network Training Efficiency By Using Top Non-Robust Samples In The Training Set</title><link>http://arxiv.org/abs/2412.14738v4</link><description>Graph Neural Networks (GNNs) are a highly effective neural networkarchitecture for processing graph-structured data. Unlike traditional neuralnetworks that rely solely on the features of the data as input, GNNs leverageboth the graph structure, which represents the relationships between datapoints, and the feature matrix of the data to optimize their featurerepresentation. This unique capability enables GNNs to achieve superiorperformance across various tasks. However, it also makes GNNs more susceptibleto noise from both the graph structure and the data features, which cansignificantly degrade their performance in common tasks such as classificationand prediction. To address this issue, this paper proposes a novel method forconstructing training sets by identifying training samples that areparticularly sensitive to noise for a given model. These samples are then usedto enhance the model's ability to handle noise-prone instances effectively.Experimental results demonstrate that this approach can significantly improvetraining efficiency.</description><author>Yongyu Wang</author><pubDate>Thu, 02 Jan 2025 10:10:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14738v4</guid></item><item><title>Preliminaries to artificial consciousness: a multidimensional heuristic approach</title><link>http://arxiv.org/abs/2403.20177v3</link><description>The pursuit of artificial consciousness requires conceptual clarity tonavigate its theoretical and empirical challenges. This paper introduces acomposite, multilevel, and multidimensional model of consciousness as aheuristic framework to guide research in this field. Consciousness is treatedas a complex phenomenon, with distinct constituents and dimensions that can beoperationalized for study and for evaluating their replication. We argue thatthis model provides a balanced approach to artificial consciousness research byavoiding binary thinking (e.g., conscious vs. non-conscious) and offering astructured basis for testable hypotheses. To illustrate its utility, we focuson "awareness" as a case study, demonstrating how specific dimensions ofconsciousness can be pragmatically analyzed and targeted for potentialartificial instantiation. By breaking down the conceptual intricacies ofconsciousness and aligning them with practical research goals, this paper laysthe groundwork for a robust strategy to advance the scientific and technicalunderstanding of artificial consciousness.</description><author>K. Evers, M. Farisco, R. Chatila, B. D. Earp, I. T. Freire, F. Hamker, E. Nemeth, P. F. M. J. Verschure, M. Khamassi</author><pubDate>Thu, 02 Jan 2025 10:09:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20177v3</guid></item><item><title>The Initial Screening Order Problem</title><link>http://arxiv.org/abs/2307.15398v5</link><description>We investigate the role of the initial screening order (ISO) in candidatescreening. The ISO refers to the order in which the screener searches thecandidate pool when selecting $k$ candidates. Today, it is common for the ISOto be the product of an information access system, such as an online platformor a database query. The ISO has been largely overlooked in the literature,despite its impact on the optimality and fairness of the selected $k$candidates, especially under a human screener. We define two problemformulations describing the search behavior of the screener given an ISO: thebest-$k$, where it selects the top $k$ candidates; and the good-$k$, where itselects the first good-enough $k$ candidates. To study the impact of the ISO,we introduce a human-like screener and compare it to its algorithmiccounterpart, where the human-like screener is conceived to be inconsistent overtime. Our analysis, in particular, shows that the ISO, under a human-likescreener solving for the good-$k$ problem, hinders individual fairness despitemeeting group fairness, and hampers the optimality of the selected $k$candidates. This is due to position bias, where a candidate's evaluation isaffected by its position within the ISO. We report extensive simulatedexperiments exploring the parameters of the best-$k$ and good-$k$ problems forboth screeners. Our simulation framework is flexible enough to account formultiple candidate screening tasks, being an alternative to running real-worldprocedures.</description><author>Jose M. Alvarez, Antonio Mastropietro, Salvatore Ruggieri</author><pubDate>Thu, 02 Jan 2025 10:02:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15398v5</guid></item><item><title>Enhancing Code LLMs with Reinforcement Learning in Code Generation: A Survey</title><link>http://arxiv.org/abs/2412.20367v2</link><description>With the rapid evolution of large language models (LLM), reinforcementlearning (RL) has emerged as a pivotal technique for code generation andoptimization in various domains. This paper presents a systematic survey of theapplication of RL in code optimization and generation, highlighting its role inenhancing compiler optimization, resource allocation, and the development offrameworks and tools. Subsequent sections first delve into the intricateprocesses of compiler optimization, where RL algorithms are leveraged toimprove efficiency and resource utilization. The discussion then progresses tothe function of RL in resource allocation, emphasizing register allocation andsystem optimization. We also explore the burgeoning role of frameworks andtools in code generation, examining how RL can be integrated to bolster theircapabilities. This survey aims to serve as a comprehensive resource forresearchers and practitioners interested in harnessing the power of RL toadvance code generation and optimization techniques.</description><author>Junqiao Wang, Zeng Zhang, Yangfan He, Yuyang Song, Tianyu Shi, Yuchen Li, Hengyuan Xu, Kunyu Wu, Guangwu Qian, Qiuwu Chen, Lewei He</author><pubDate>Thu, 02 Jan 2025 09:43:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.20367v2</guid></item><item><title>Detection and classification of DDoS flooding attacks by machine learning method</title><link>http://arxiv.org/abs/2412.18990v2</link><description>This study focuses on a method for detecting and classifying distributeddenial of service (DDoS) attacks, such as SYN Flooding, ACK Flooding, HTTPFlooding, and UDP Flooding, using neural networks. Machine learning,particularly neural networks, is highly effective in detecting malicioustraffic. A dataset containing normal traffic and various DDoS attacks was usedto train a neural network model with a 24-106-5 architecture. The modelachieved high Accuracy (99.35%), Precision (99.32%), Recall (99.54%), andF-score (0.99) in the classification task. All major attack types werecorrectly identified. The model was also further tested in the lab usingvirtual infrastructures to generate normal and DDoS traffic. The results showedthat the model can accurately classify attacks under near-real-worldconditions, demonstrating 95.05% accuracy and balanced F-score scores for allattack types. This confirms that neural networks are an effective tool fordetecting DDoS attacks in modern information security systems.</description><author>Dmytro Tymoshchuk, Oleh Yasniy, Mykola Mytnyk, Nataliya Zagorodna, Vitaliy Tymoshchuk</author><pubDate>Thu, 02 Jan 2025 09:34:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18990v2</guid></item><item><title>HunyuanVideo: A Systematic Framework For Large Video Generative Models</title><link>http://arxiv.org/abs/2412.03603v3</link><description>Recent advancements in video generation have significantly impacted dailylife for both individuals and industries. However, the leading video generationmodels remain closed-source, resulting in a notable performance gap betweenindustry capabilities and those available to the public. In this report, weintroduce HunyuanVideo, an innovative open-source video foundation model thatdemonstrates performance in video generation comparable to, or even surpassing,that of leading closed-source models. HunyuanVideo encompasses a comprehensiveframework that integrates several key elements, including data curation,advanced architectural design, progressive model scaling and training, and anefficient infrastructure tailored for large-scale model training and inference.As a result, we successfully trained a video generative model with over 13billion parameters, making it the largest among all open-source models. Weconducted extensive experiments and implemented a series of targeted designs toensure high visual quality, motion dynamics, text-video alignment, and advancedfilming techniques. According to evaluations by professionals, HunyuanVideooutperforms previous state-of-the-art models, including Runway Gen-3, Luma 1.6,and three top-performing Chinese video generative models. By releasing the codefor the foundation model and its applications, we aim to bridge the gap betweenclosed-source and open-source communities. This initiative will empowerindividuals within the community to experiment with their ideas, fostering amore dynamic and vibrant video generation ecosystem. The code is publiclyavailable at https://github.com/Tencent/HunyuanVideo.</description><author>Weijie Kong, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jiangfeng Xiong, Xin Li, Bo Wu, Jianwei Zhang, Kathrina Wu, Qin Lin, Junkun Yuan, Yanxin Long, Aladdin Wang, Andong Wang, Changlin Li, Duojun Huang, Fang Yang, Hao Tan, Hongmei Wang, Jacob Song, Jiawang Bai, Jianbing Wu, Jinbao Xue, Joey Wang, Kai Wang, Mengyang Liu, Pengyu Li, Shuai Li, Weiyan Wang, Wenqing Yu, Xinchi Deng, Yang Li, Yi Chen, Yutao Cui, Yuanbo Peng, Zhentao Yu, Zhiyu He, Zhiyong Xu, Zixiang Zhou, Zunnan Xu, Yangyu Tao, Qinglin Lu, Songtao Liu, Daquan Zhou, Hongfa Wang, Yong Yang, Di Wang, Yuhong Liu, Jie Jiang, Caesar Zhong</author><pubDate>Thu, 02 Jan 2025 09:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.03603v3</guid></item><item><title>Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization</title><link>http://arxiv.org/abs/2412.17739v2</link><description>Extending the context length of Language Models (LMs) by improving RotaryPosition Embedding (RoPE) has become a trend. While existing works mainlyaddress RoPE's limitations within attention mechanism, this paper provides ananalysis across nearly all parts of LMs, uncovering their adverse effects onlength generalization for RoPE-based attention. Using Discrete SignalProcessing theory, we show that RoPE enables periodic attention by implicitlyachieving Non-Uniform Discrete Fourier Transform. However, this periodicity isundermined by the spectral damage caused by: 1) linear layers and activationfunctions outside of attention; 2) insufficiently trained frequency componentsbrought by time-domain truncation. Building on our observations, we proposeFourier Position Embedding (FoPE), which enhances attention's frequency-domainproperties to improve both its periodic extension and length generalization.FoPE constructs Fourier Series and zero-outs the destructive frequencycomponents, increasing model robustness against the spectrum damage.Experiments across various model scales show that, within varying contextwindows, FoPE can maintain a more stable perplexity and a more consistentaccuracy in a needle-in-haystack task compared to RoPE and ALiBi. Severalanalyses and ablations bring further support to our method and theoreticalmodeling.</description><author>Ermo Hua, Che Jiang, Xingtai Lv, Kaiyan Zhang, Ning Ding, Youbang Sun, Biqing Qi, Yuchen Fan, Xuekai Zhu, Bowen Zhou</author><pubDate>Thu, 02 Jan 2025 08:58:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17739v2</guid></item><item><title>Text Clustering as Classification with LLMs</title><link>http://arxiv.org/abs/2410.00927v2</link><description>Text clustering remains valuable in real-world applications where manuallabeling is cost-prohibitive. It facilitates efficient organization andanalysis of information by grouping similar texts based on theirrepresentations. However, implementing this approach necessitates fine-tunedembedders for downstream data and sophisticated similarity metrics. To addressthis issue, this study presents a novel framework for text clustering thateffectively leverages the in-context learning capacity of Large Language Models(LLMs). Instead of fine-tuning embedders, we propose to transform the textclustering into a classification task via LLM. First, we prompt LLM to generatepotential labels for a given dataset. Second, after integrating similar labelsgenerated by the LLM, we prompt the LLM to assign the most appropriate label toeach sample in the dataset. Our framework has been experimentally proven toachieve comparable or superior performance to state-of-the-art clusteringmethods that employ embeddings, without requiring complex fine-tuning orclustering algorithms. We make our code available to the public for utilizationat https://github.com/ECNU-Text-Computing/Text-Clustering-via-LLM.</description><author>Chen Huang, Guoxiu He</author><pubDate>Thu, 02 Jan 2025 08:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.00927v2</guid></item><item><title>Function Basis Encoding of Numerical Features in Factorization Machines</title><link>http://arxiv.org/abs/2305.14528v3</link><description>Factorization machine (FM) variants are widely used for large scale real-timecontent recommendation systems, since they offer an excellent balance betweenmodel accuracy and low computational costs for training and inference. Thesesystems are trained on tabular data with both numerical and categoricalcolumns. Incorporating numerical columns poses a challenge, and they aretypically incorporated using a scalar transformation or binning, which can beeither learned or chosen a-priori. In this work, we provide a systematic andtheoretically-justified way to incorporate numerical features into FM variantsby encoding them into a vector of function values for a set of functions ofone's choice. We view factorization machines as approximators of segmentized functions,namely, functions from a field's value to the real numbers, assuming theremaining fields are assigned some given constants, which we refer to as thesegment. From this perspective, we show that our technique yields a model thatlearns segmentized functions of the numerical feature spanned by the set offunctions of one's choice, namely, the spanning coefficients vary betweensegments. Hence, to improve model accuracy we advocate the use of functionsknown to have strong approximation power, and offer the B-Spline basis due toits well-known approximation power, availability in software libraries, andefficiency. Our technique preserves fast training and inference, and requiresonly a small modification of the computational graph of an FM model. Therefore,it is easy to incorporate into an existing system to improve its performance.Finally, we back our claims with a set of experiments, including synthetic,performance evaluation on several data-sets, and an A/B test on a real onlineadvertising system which shows improved performance.</description><author>Alex Shtoff, Elie Abboud, Rotem Stram, Oren Somekh</author><pubDate>Thu, 02 Jan 2025 08:49:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14528v3</guid></item><item><title>Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive Tasks</title><link>http://arxiv.org/abs/2407.09893v3</link><description>Recent advancements in Large Language Models (LLMs) have led to significantbreakthroughs in various natural language processing tasks. However, generatingfactually consistent responses in knowledge-intensive scenarios remains achallenge due to issues such as hallucination, difficulty in acquiringlong-tailed knowledge, and limited memory expansion. This paper introducesSMART, a novel multi-agent framework that leverages external knowledge toenhance the interpretability and factual consistency of LLM-generatedresponses. SMART comprises four specialized agents, each performing a specificsub-trajectory action to navigate complex knowledge-intensive tasks. We proposea multi-agent co-training paradigm, Long-Short Trajectory Learning, whichensures synergistic collaboration among agents while maintaining fine-grainedexecution by each agent. Extensive experiments on five knowledge-intensivetasks demonstrate SMART's superior performance compared to widely adoptedknowledge internalization and knowledge enhancement methods. Our framework canextend beyond knowledge-intensive tasks to more complex scenarios. Our code isavailable at https://github.com/yueshengbin/SMART.</description><author>Shengbin Yue, Siyuan Wang, Wei Chen, Xuanjing Huang, Zhongyu Wei</author><pubDate>Thu, 02 Jan 2025 08:43:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09893v3</guid></item><item><title>A survey of Monte Carlo methods for noisy and costly densities with application to reinforcement learning and ABC</title><link>http://arxiv.org/abs/2108.00490v3</link><description>This survey gives an overview of Monte Carlo methodologies using surrogatemodels, for dealing with densities which are intractable, costly, and/or noisy.This type of problem can be found in numerous real-world scenarios, includingstochastic optimization and reinforcement learning, where each evaluation of adensity function may incur some computationally-expensive or even physical(real-world activity) cost, likely to give different results each time. Thesurrogate model does not incur this cost, but there are important trade-offsand considerations involved in the choice and design of such methodologies. Weclassify the different methodologies into three main classes and describespecific instances of algorithms under a unified notation. A modular schemewhich encompasses the considered methods is also presented. A range ofapplication scenarios is discussed, with special attention to thelikelihood-free setting and reinforcement learning. Several numericalcomparisons are also provided.</description><author>F. Llorente, L. Martino, J. Read, D. Delgado</author><pubDate>Thu, 02 Jan 2025 08:43:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.00490v3</guid></item><item><title>MM-Path: Multi-modal, Multi-granularity Path Representation Learning -- Extended Version</title><link>http://arxiv.org/abs/2411.18428v4</link><description>Developing effective path representations has become increasingly essentialacross various fields within intelligent transportation. Although pre-trainedpath representation learning models have shown improved performance, theypredominantly focus on the topological structures from single modality data,i.e., road networks, overlooking the geometric and contextual featuresassociated with path-related images, e.g., remote sensing images. Similar tohuman understanding, integrating information from multiple modalities canprovide a more comprehensive view, enhancing both representation accuracy andgeneralization. However, variations in information granularity impede thesemantic alignment of road network-based paths (road paths) and image-basedpaths (image paths), while the heterogeneity of multi-modal data posessubstantial challenges for effective fusion and utilization. In this paper, wepropose a novel Multi-modal, Multi-granularity Path Representation LearningFramework (MM-Path), which can learn a generic path representation byintegrating modalities from both road paths and image paths. To enhance thealignment of multi-modal data, we develop a multi-granularity alignmentstrategy that systematically associates nodes, road sub-paths, and road pathswith their corresponding image patches, ensuring the synchronization of bothdetailed local information and broader global contexts. To address theheterogeneity of multi-modal data effectively, we introduce a graph-basedcross-modal residual fusion component designed to comprehensively fuseinformation across different modalities and granularities. Finally, we conductextensive experiments on two large-scale real-world datasets under twodownstream tasks, validating the effectiveness of the proposed MM-Path. Thecode is available at: https://github.com/decisionintelligence/MM-Path.</description><author>Ronghui Xu, Hanyin Cheng, Chenjuan Guo, Hongfan Gao, Jilin Hu, Sean Bin Yang, Bin Yang</author><pubDate>Thu, 02 Jan 2025 07:52:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.18428v4</guid></item><item><title>Token Preference Optimization with Self-Calibrated Visual-Anchored Rewards for Hallucination Mitigation</title><link>http://arxiv.org/abs/2412.14487v2</link><description>Direct Preference Optimization (DPO) has been demonstrated to be highlyeffective in mitigating hallucinations in Large Vision Language Models (LVLMs)by aligning their outputs more closely with human preferences. Despite therecent progress, existing methods suffer from two drawbacks: 1) Lack ofscalable token-level rewards; and 2) Neglect of visual-anchored tokens. To thisend, we propose a novel Token Preference Optimization model withself-calibrated rewards (dubbed as TPO), which adaptively attends tovisual-correlated tokens without fine-grained annotations. Specifically, weintroduce a token-level \emph{visual-anchored} \emph{reward} as the differenceof the logistic distributions of generated tokens conditioned on the raw imageand the corrupted one. In addition, to highlight the informativevisual-anchored tokens, a visual-aware training objective is proposed toenhance more accurate token-level optimization. Extensive experimental resultshave manifested the state-of-the-art performance of the proposed TPO. Forexample, by building on top of LLAVA-1.5-7B, our TPO boosts the performanceabsolute improvement for hallucination benchmarks.</description><author>Jihao Gu, Yingyao Wang, Meng Cao, Pi Bu, Jun Song, Yancheng He, Shilong Li, Bo Zheng</author><pubDate>Thu, 02 Jan 2025 07:39:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14487v2</guid></item><item><title>TOPIC: A Parallel Association Paradigm for Multi-Object Tracking under Complex Motions and Diverse Scenes</title><link>http://arxiv.org/abs/2308.11157v2</link><description>Video data and algorithms have been driving advances in multi-object tracking(MOT). While existing MOT datasets focus on occlusion and appearancesimilarity, complex motion patterns are widespread yet overlooked. To addressthis issue, we introduce a new dataset called BEE24 to highlight complexmotions. Identity association algorithms have long been the focus of MOTresearch. Existing trackers can be categorized into two association paradigms:single-feature paradigm (based on either motion or appearance feature) andserial paradigm (one feature serves as secondary while the other is primary).However, these paradigms are incapable of fully utilizing different features.In this paper, we propose a parallel paradigm and present the Two rOundParallel matchIng meChanism (TOPIC) to implement it. The TOPIC leverages bothmotion and appearance features and can adaptively select the preferable one asthe assignment metric based on motion level. Moreover, we provide anAttention-based Appearance Reconstruction Module (AARM) to reconstructappearance feature embeddings, thus enhancing the representation of appearancefeatures. Comprehensive experiments show that our approach achievesstate-of-the-art performance on four public datasets and BEE24. Moreover, BEE24challenges existing trackers to track multiple similar-appearing small objectswith complex motions over long periods, which is critical in real-worldapplications such as beekeeping and drone swarm surveillance. Notably, ourproposed parallel paradigm surpasses the performance of existing associationparadigms by a large margin, e.g., reducing false negatives by 6% to 81%compared to the single-feature association paradigm. The introduced dataset andassociation paradigm in this work offer a fresh perspective for advancing theMOT field. The source code and dataset are available athttps://github.com/holmescao/TOPICTrack.</description><author>Xiaoyan Cao, Yiyao Zheng, Yao Yao, Huapeng Qin, Xiaoyu Cao, Shihui Guo</author><pubDate>Thu, 02 Jan 2025 07:36:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11157v2</guid></item><item><title>Speech Retrieval-Augmented Generation without Automatic Speech Recognition</title><link>http://arxiv.org/abs/2412.16500v2</link><description>One common approach for question answering over speech data is to firsttranscribe speech using automatic speech recognition (ASR) and then employtext-based retrieval-augmented generation (RAG) on the transcriptions. Whilethis cascaded pipeline has proven effective in many practical settings, ASRerrors can propagate to the retrieval and generation steps. To overcome thislimitation, we introduce SpeechRAG, a novel framework designed foropen-question answering over spoken data. Our proposed approach fine-tunes apre-trained speech encoder into a speech adapter fed into a frozen largelanguage model (LLM)--based retrieval model. By aligning the embedding spacesof text and speech, our speech retriever directly retrieves audio passages fromtext-based queries, leveraging the retrieval capacity of the frozen textretriever. Our retrieval experiments on spoken question answering datasets showthat direct speech retrieval does not degrade over the text-based baseline, andoutperforms the cascaded systems using ASR. For generation, we use a speechlanguage model (SLM) as a generator, conditioned on audio passages rather thantranscripts. Without fine-tuning of the SLM, this approach outperforms cascadedtext-based models when there is high WER in the transcripts.</description><author>Do June Min, Karel Mundnich, Andy Lapastora, Erfan Soltanmohammadi, Srikanth Ronanki, Kyu Han</author><pubDate>Thu, 02 Jan 2025 07:29:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16500v2</guid></item><item><title>ChemDFM-X: Towards Large Multimodal Model for Chemistry</title><link>http://arxiv.org/abs/2409.13194v2</link><description>Rapid developments of AI tools are expected to offer unprecedented assistanceto the research of natural science including chemistry. However, neitherexisting unimodal task-specific specialist models nor emerging general largemultimodal models (LMM) can cover the wide range of chemical data modality andtask categories. To address the real demands of chemists, a cross-modalChemical General Intelligence (CGI) system, which serves as a truly practicaland useful research assistant utilizing the great potential of LMMs, is ingreat need. In this work, we introduce the first Cross-modal DialogueFoundation Model for Chemistry (ChemDFM-X). Diverse multimodal data aregenerated from an initial modality by approximate calculations andtask-specific model predictions. This strategy creates sufficient chemicaltraining corpora, while significantly reducing excessive expense, resulting inan instruction-tuning dataset containing 7.6M data. After instructionfinetuning, ChemDFM-X is evaluated on extensive experiments of differentchemical tasks with various data modalities. The results demonstrate thecapacity of ChemDFM-X for multimodal and inter-modal knowledge comprehension.ChemDFM-X marks a significant milestone toward aligning all modalities inchemistry, a step closer to CGI.</description><author>Zihan Zhao, Bo Chen, Jingpiao Li, Lu Chen, Liyang Wen, Pengyu Wang, Zichen Zhu, Danyang Zhang, Ziping Wan, Yansi Li, Zhongyang Dai, Xin Chen, Kai Yu</author><pubDate>Thu, 02 Jan 2025 07:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.13194v2</guid></item><item><title>Ethical-Lens: Curbing Malicious Usages of Open-Source Text-to-Image Models</title><link>http://arxiv.org/abs/2404.12104v2</link><description>The burgeoning landscape of text-to-image models, exemplified by innovationssuch as Midjourney and DALLE 3, has revolutionized content creation acrossdiverse sectors. However, these advancements bring forth critical ethicalconcerns, particularly with the misuse of open-source models to generatecontent that violates societal norms. Addressing this, we introduceEthical-Lens, a framework designed to facilitate the value-aligned usage oftext-to-image tools without necessitating internal model revision. Ethical-Lensensures value alignment in text-to-image models across toxicity and biasdimensions by refining user commands and rectifying model outputs. Systematicevaluation metrics, combining GPT4-V, HEIM, and FairFace scores, assessalignment capability. Our experiments reveal that Ethical-Lens enhancesalignment capabilities to levels comparable with or superior to commercialmodels like DALLE 3, ensuring user-generated content adheres to ethicalstandards while maintaining image quality. This study indicates the potentialof Ethical-Lens to ensure the sustainable development of open-sourcetext-to-image tools and their beneficial integration into society. Our code isavailable at https://github.com/yuzhu-cai/Ethical-Lens.</description><author>Yuzhu Cai, Sheng Yin, Yuxi Wei, Chenxin Xu, Weibo Mao, Felix Juefei-Xu, Siheng Chen, Yanfeng Wang</author><pubDate>Thu, 02 Jan 2025 07:04:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12104v2</guid></item><item><title>Rethinking Performance Analysis for Configurable Software Systems: A Case Study from a Fitness Landscape Perspective</title><link>http://arxiv.org/abs/2412.16888v2</link><description>Modern software systems are often highly configurable to tailor variedrequirements from diverse stakeholders. Understanding the mapping betweenconfigurations and the desired performance attributes plays a fundamental rolein advancing the controllability and tuning of the underlying system, yet haslong been a dark hole of knowledge due to its black-box nature. While therehave been previous efforts in performance analysis for these systems, theyanalyze the configurations as isolated data points without considering theirinherent spatial relationships. This renders them incapable of interrogatingmany important aspects of the configuration space like local optima. In thiswork, we advocate a novel perspective to rethink performance analysis --modeling the configuration space as a structured ``landscape''. To support thisproposition, we designed \our, an open-source, graph data mining empoweredfitness landscape analysis (FLA) framework. By applying this framework to $86$Mbenchmarked configurations from $32$ running workloads of $3$ real-worldsystems, we arrived at $6$ main findings, which together constitute a holisticpicture of the landscape topography, with thorough discussions about theirimplications on both configuration tuning and performance modeling.</description><author>Mingyu Huang, Peili Mao, Ke Li</author><pubDate>Thu, 02 Jan 2025 06:55:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16888v2</guid></item><item><title>A Competition Winning Deep Reinforcement Learning Agent in microRTS</title><link>http://arxiv.org/abs/2402.08112v2</link><description>Scripted agents have predominantly won the five previous iterations of theIEEE microRTS ($\mu$RTS) competitions hosted at CIG and CoG. Despite DeepReinforcement Learning (DRL) algorithms making significant strides in real-timestrategy (RTS) games, their adoption in this primarily academic competition hasbeen limited due to the considerable training resources required and thecomplexity inherent in creating and debugging such agents. RAISocketAI is thefirst DRL agent to win the IEEE microRTS competition. In a benchmark withoutperformance constraints, RAISocketAI regularly defeated the two priorcompetition winners. This first competition-winning DRL submission can be abenchmark for future microRTS competitions and a starting point for future DRLresearch. Iteratively fine-tuning the base policy and transfer learning tospecific maps were critical to RAISocketAI's winning performance. Thesestrategies can be used to economically train future DRL agents. Further work inImitation Learning using Behavior Cloning and fine-tuning these models with DRLhas proven promising as an efficient way to bootstrap models with demonstrated,competitive behaviors.</description><author>Scott Goodfriend</author><pubDate>Thu, 02 Jan 2025 06:50:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08112v2</guid></item><item><title>Photoacoustic Iterative Optimization Algorithm with Shape Prior Regularization</title><link>http://arxiv.org/abs/2412.00705v4</link><description>Photoacoustic imaging (PAI) suffers from inherent limitations that candegrade the quality of reconstructed results, such as noise, artifacts andincomplete data acquisition caused by sparse sampling or partial arraydetection. In this study, we proposed a new optimization method for bothtwo-dimensional (2D) and three-dimensional (3D) PAI reconstruction results,called the regularized iteration method with shape prior. The shape prior is aprobability matrix derived from the reconstruction results of multiple sets ofrandom partial array signals in a computational imaging system using anyreconstruction algorithm, such as Delay-and-Sum (DAS) and Back-Projection (BP).In the probability matrix, high-probability locations indicate high consistencyamong multiple reconstruction results at those positions, suggesting a highlikelihood of representing the true imaging results. In contrast,low-probability locations indicate higher randomness, leaning more towardsnoise or artifacts. As a shape prior, this probability matrix guides theiteration and regularization of the entire array signal reconstruction resultsusing the original reconstruction algorithm (the same algorithm for processingrandom partial array signals). The method takes advantage of the property thatthe similarity of the object to be imitated is higher than that of noise orartifact in the results reconstructed by multiple sets of random partial arraysignals of the entire imaging system. The probability matrix is taken as aprerequisite for improving the original reconstruction results, and theoptimizer is used to further iterate the imaging results to remove noise andartifacts and improve the imaging fidelity. Especially in the case involvingsparse view which brings more artifacts, the effect is remarkable. Simulationand real experiments have both demonstrated the superiority of this method.</description><author>Yu Zhang, Shuang Li, Yibing Wang, Yu Sun, Wenyi Xiang</author><pubDate>Thu, 02 Jan 2025 05:43:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.00705v4</guid></item><item><title>VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks</title><link>http://arxiv.org/abs/2410.05160v3</link><description>Embedding models have been crucial in enabling various downstream tasks suchas semantic similarity, information retrieval, and clustering. Recently, therehas been a surge of interest in developing universal text embedding models thatcan generalize across tasks (e.g., MTEB). However, progress in learninguniversal multimodal embedding models has been relatively slow despite itsimportance and practicality. In this work, we aim to explore the potential forbuilding universal embeddings capable of handling a wide range of downstreamtasks. Our contributions are twofold: (1) MMEB (Massive Multimodal EmbeddingBenchmark), which covers 4 meta-tasks (i.e. classification, visual questionanswering, multimodal retrieval, and visual grounding) and 36 datasets,including 20 training and 16 evaluation datasets covering both in-distributionand out-of-distribution tasks, and (2) VLM2Vec (Vision-Language Model -&gt;Vector), a contrastive training framework that converts any state-of-the-artvision-language model into an embedding model via training on MMEB. Unlikeprevious models such as CLIP and BLIP, which encodes text or imagesindependently without any task instruction, VLM2Vec can process any combinationof images and text to generate a fixed-dimensional vector based on taskinstructions. We build a series of VLM2Vec models on SoTA VLMs like Phi-3.5-V,LLaVA-1.6 and evaluate them on MMEB's evaluation split. Our results show thatVLM2Vec achieves an absolute average improvement of 10% to 20% over existingmultimodal embedding models on both in-distribution and out-of-distributiondatasets in MMEB. We show that VLMs are secretly strong embedding models.</description><author>Ziyan Jiang, Rui Meng, Xinyi Yang, Semih Yavuz, Yingbo Zhou, Wenhu Chen</author><pubDate>Thu, 02 Jan 2025 05:26:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05160v3</guid></item><item><title>Approximation Rate of the Transformer Architecture for Sequence Modeling</title><link>http://arxiv.org/abs/2305.18475v4</link><description>The Transformer architecture is widely applied in sequence modelingapplications, yet the theoretical understanding of its working principlesremains limited. In this work, we investigate the approximation rate forsingle-layer Transformers with one head. We consider a class of non-linearrelationships and identify a novel notion of complexity measures to establishan explicit Jackson-type approximation rate estimate for the Transformer. Thisrate reveals the structural properties of the Transformer and suggests thetypes of sequential relationships it is best suited for approximating. Inparticular, the results on approximation rates enable us to concretely analyzethe differences between the Transformer and classical sequence modelingmethods, such as recurrent neural networks.</description><author>Haotian Jiang, Qianxiao Li</author><pubDate>Thu, 02 Jan 2025 05:02:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18475v4</guid></item><item><title>FairGP: A Scalable and Fair Graph Transformer Using Graph Partitioning</title><link>http://arxiv.org/abs/2412.10669v2</link><description>Recent studies have highlighted significant fairness issues in GraphTransformer (GT) models, particularly against subgroups defined by sensitivefeatures. Additionally, GTs are computationally intensive and memory-demanding,limiting their application to large-scale graphs. Our experiments demonstratethat graph partitioning can enhance the fairness of GT models while reducingcomputational complexity. To understand this improvement, we conducted atheoretical investigation into the root causes of fairness issues in GT models.We found that the sensitive features of higher-order nodes disproportionatelyinfluence lower-order nodes, resulting in sensitive feature bias. We proposeFairness-aware scalable GT based on Graph Partitioning (FairGP), whichpartitions the graph to minimize the negative impact of higher-order nodes. Byoptimizing attention mechanisms, FairGP mitigates the bias introduced by globalattention, thereby enhancing fairness. Extensive empirical evaluations on sixreal-world datasets validate the superior performance of FairGP in achievingfairness compared to state-of-the-art methods. The codes are available athttps://github.com/LuoRenqiang/FairGP.</description><author>Renqiang Luo, Huafei Huang, Ivan Lee, Chengpei Xu, Jianzhong Qi, Feng Xia</author><pubDate>Thu, 02 Jan 2025 04:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10669v2</guid></item><item><title>Non-Homophilic Graph Pre-Training and Prompt Learning</title><link>http://arxiv.org/abs/2408.12594v5</link><description>Graphs are ubiquitous for modeling complex relationships between objectsacross various fields. Graph neural networks (GNNs) have become a mainstreamtechnique for graph-based applications, but their performance heavily relies onabundant labeled data. To reduce labeling requirement, pre-training and promptlearning has become a popular alternative. However, most existing promptmethods do not differentiate homophilic and heterophilic characteristics ofreal-world graphs. In particular, many real-world graphs are non-homophilic,not strictly or uniformly homophilic with mixing homophilic and heterophilicpatterns, exhibiting varying non-homophilic characteristics across graphs andnodes. In this paper, we propose ProNoG, a novel pre-training and promptlearning framework for such non-homophilic graphs. First, we analyze existinggraph pre-training methods, providing theoretical insights into the choice ofpre-training tasks. Second, recognizing that each node exhibits uniquenon-homophilic characteristics, we propose a conditional network tocharacterize the node-specific patterns in downstream tasks. Finally, wethoroughly evaluate and analyze ProNoG through extensive experiments on tenpublic datasets.</description><author>Xingtong Yu, Jie Zhang, Yuan Fang, Renhe Jiang</author><pubDate>Thu, 02 Jan 2025 04:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12594v5</guid></item><item><title>Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks</title><link>http://arxiv.org/abs/2410.01985v2</link><description>Despite significant advancements, Large Language Models (LLMs) exhibit blindspots that impair their ability to retrieve and process relevant contextualdata effectively. We demonstrate that LLM performance in graph tasks withcomplexities beyond the "needle-in-a-haystack" scenario-where solving theproblem requires cross-referencing and reasoning across multiple subproblemsjointly-is influenced by the proximity of relevant information within thecontext, a phenomenon we term "lost-in-distance". We examine two fundamentalgraph tasks: identifying common connections between two nodes and assessingsimilarity among three nodes, and show that the model's performance in thesetasks significantly depends on the relative positioning of common edges. Weevaluate three publicly available LLMs using various graph encoding techniquesthat represent graph structures for LLM input. We propose a formulation for thelost-in-distance phenomenon and demonstrate that lost-in-distance andlost-in-the middle phenomenas occur independently. Results indicate that modelaccuracy can decline by up to 6x as the distance between node connectionsincreases, independent of graph encoding and model size.</description><author>Hamed Firooz, Maziar Sanjabi, Wenlong Jiang, Xiaoling Zhai</author><pubDate>Thu, 02 Jan 2025 04:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01985v2</guid></item><item><title>World knowledge-enhanced Reasoning Using Instruction-guided Interactor in Autonomous Driving</title><link>http://arxiv.org/abs/2412.06324v3</link><description>The Multi-modal Large Language Models (MLLMs) with extensive world knowledgehave revitalized autonomous driving, particularly in reasoning tasks withinperceivable regions. However, when faced with perception-limited areas (dynamicor static occlusion regions), MLLMs struggle to effectively integrateperception ability with world knowledge for reasoning. These perception-limitedregions can conceal crucial safety information, especially for vulnerable roadusers. In this paper, we propose a framework, which aims to improve autonomousdriving performance under perceptionlimited conditions by enhancing theintegration of perception capabilities and world knowledge. Specifically, wepropose a plug-and-play instruction-guided interaction module that bridgesmodality gaps and significantly reduces the input sequence length, allowing itto adapt effectively to multi-view video inputs. Furthermore, to betterintegrate world knowledge with driving-related tasks, we have collected andrefined a large-scale multi-modal dataset that includes 2 million naturallanguage QA pairs, 1.7 million grounding task data. To evaluate the model'sutilization of world knowledge, we introduce an object-level risk assessmentdataset comprising 200K QA pairs, where the questions necessitate multi-stepreasoning leveraging world knowledge for resolution. Extensive experimentsvalidate the effectiveness of our proposed method.</description><author>Mingliang Zhai, Cheng Li, Zengyuan Guo, Ningrui Yang, Xiameng Qin, Sanyuan Zhao, Junyu Han, Ji Tao, Yuwei Wu, Yunde Jia</author><pubDate>Thu, 02 Jan 2025 04:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06324v3</guid></item><item><title>Advancements in Visual Language Models for Remote Sensing: Datasets, Capabilities, and Enhancement Techniques</title><link>http://arxiv.org/abs/2410.17283v3</link><description>Recently, the remarkable success of ChatGPT has sparked a renewed wave ofinterest in artificial intelligence (AI), and the advancements in visuallanguage models (VLMs) have pushed this enthusiasm to new heights. Differringfrom previous AI approaches that generally formulated different tasks asdiscriminative models, VLMs frame tasks as generative models and align languagewith visual information, enabling the handling of more challenging problems.The remote sensing (RS) field, a highly practical domain, has also embracedthis new trend and introduced several VLM-based RS methods that havedemonstrated promising performance and enormous potential. In this paper, wefirst review the fundamental theories related to VLM, then summarize thedatasets constructed for VLMs in remote sensing and the various tasks theyaddressed. Finally, we categorize the improvement methods into three main partsaccording to the core components of VLMs and provide a detailed introductionand comparison of these methods. A project associated with this review has beencreated at https://github.com/taolijie11111/VLMs-in-RS-review.</description><author>Lijie Tao, Haokui Zhang, Haizhao Jing, Yu Liu, Dawei Yan, Guoting Wei, Xizhe Xue</author><pubDate>Thu, 02 Jan 2025 04:13:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17283v3</guid></item><item><title>Data-Driven Machine Learning Approaches for Predicting In-Hospital Sepsis Mortality</title><link>http://arxiv.org/abs/2408.01612v2</link><description>Sepsis is a severe condition responsible for many deaths in the United Statesand worldwide, making accurate prediction of outcomes crucial for timely andeffective treatment. Previous studies employing machine learning facedlimitations in feature selection and model interpretability, reducing theirclinical applicability. This research aimed to develop an interpretable andaccurate machine learning model to predict in-hospital sepsis mortality,addressing these gaps. Using ICU patient records from the MIMIC-III database,we extracted relevant data through a combination of literature review, clinicalinput refinement, and Random Forest-based feature selection, identifying thetop 35 features. Data preprocessing included cleaning, imputation,standardization, and applying the Synthetic Minority Over-sampling Technique(SMOTE) to address class imbalance, resulting in a dataset of 4,683 patientswith 17,429 admissions. Five models-Random Forest, Gradient Boosting, LogisticRegression, Support Vector Machine, and K-Nearest Neighbor-were developed andevaluated. The Random Forest model demonstrated the best performance, achievingan accuracy of 0.90, AUROC of 0.97, precision of 0.93, recall of 0.91, andF1-score of 0.92. These findings underscore the potential of data-drivenmachine learning approaches to improve critical care, offering clinicians apowerful tool for predicting in-hospital sepsis mortality and enhancing patientoutcomes.</description><author>Arseniy Shumilov, Yueting Zhu, Negin Ashrafi, Armin Abdollahi, Greg Placencia, Kamiar Alaei, Maryam Pishgar</author><pubDate>Thu, 02 Jan 2025 04:06:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01612v2</guid></item><item><title>BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in Large Language Models</title><link>http://arxiv.org/abs/2410.13334v3</link><description>Although large language models (LLMs) demonstrate impressive proficiency invarious tasks, they present potential safety risks, such as `jailbreaks', wheremalicious inputs can coerce LLMs into generating harmful content bypassingsafety alignments. In this paper, we delve into the ethical biases in LLMs andexamine how those biases could be exploited for jailbreaks. Notably, thesebiases result in a jailbreaking success rate in GPT-4o models that differs by20\% between non-binary and cisgender keywords and by 16\% between white andblack keywords, even when the other parts of the prompts are identical. Weintroduce the concept of BiasJailbreak, highlighting the inherent risks posedby these safety-induced biases. BiasJailbreak generates biased keywordsautomatically by asking the target LLM itself, and utilizes the keywords togenerate harmful output. Additionally, we propose an efficient defense methodBiasDefense, which prevents jailbreak attempts by injecting defense promptsprior to generation. BiasDefense stands as an appealing alternative to GuardModels, such as Llama-Guard, that require additional inference cost after textgeneration. Our findings emphasize that ethical biases in LLMs can actuallylead to generating unsafe output, and suggest a method to make the LLMs moresecure and unbiased. To enable further research and improvements, weopen-source our code and artifacts of BiasJailbreak, providing the communitywith tools to better understand and mitigate safety-induced biases in LLMs.</description><author>Isack Lee, Haebin Seong</author><pubDate>Thu, 02 Jan 2025 04:06:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13334v3</guid></item><item><title>Conformalized Interval Arithmetic with Symmetric Calibration</title><link>http://arxiv.org/abs/2408.10939v2</link><description>Uncertainty quantification is essential in decision-making, especially whenjoint distributions of random variables are involved. While conformalprediction provides distribution-free prediction sets with valid coverageguarantees, it traditionally focuses on single predictions. This paperintroduces novel conformal prediction methods for estimating the sum or averageof unknown labels over specific index sets. We develop conformal predictionintervals for single target to the prediction interval for sum of multipletargets. Under permutation invariant assumptions, we prove the validity of ourproposed method. We also apply our algorithms on class average estimation andpath cost prediction tasks, and we show that our method outperforms existingconformalized approaches as well as non-conformal approaches.</description><author>Rui Luo, Zhixin Zhou</author><pubDate>Thu, 02 Jan 2025 04:00:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10939v2</guid></item><item><title>A Survey on Large Language Model Acceleration based on KV Cache Management</title><link>http://arxiv.org/abs/2412.19442v2</link><description>Large Language Models (LLMs) have revolutionized a wide range of domains suchas natural language processing, computer vision, and multi-modal tasks due totheir ability to comprehend context and perform logical reasoning. However, thecomputational and memory demands of LLMs, particularly during inference, posesignificant challenges when scaling them to real-world, long-context, andreal-time applications. Key-Value (KV) cache management has emerged as acritical optimization technique for accelerating LLM inference by reducingredundant computations and improving memory utilization. This survey provides acomprehensive overview of KV cache management strategies for LLM acceleration,categorizing them into token-level, model-level, and system-leveloptimizations. Token-level strategies include KV cache selection, budgetallocation, merging, quantization, and low-rank decomposition, whilemodel-level optimizations focus on architectural innovations and attentionmechanisms to enhance KV reuse. System-level approaches address memorymanagement, scheduling, and hardware-aware designs to improve efficiency acrossdiverse computing environments. Additionally, the survey provides an overviewof both text and multimodal datasets and benchmarks used to evaluate thesestrategies. By presenting detailed taxonomies and comparative analyses, thiswork aims to offer useful insights for researchers and practitioners to supportthe development of efficient and scalable KV cache management techniques,contributing to the practical deployment of LLMs in real-world applications.The curated paper list for KV cache management is in:\href{https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management}{https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management}.</description><author>Haoyang Li, Yiming Li, Anxin Tian, Tianhao Tang, Zhanchao Xu, Xuejia Chen, Nicole Hu, Wei Dong, Qing Li, Lei Chen</author><pubDate>Thu, 02 Jan 2025 03:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19442v2</guid></item><item><title>Reinforcement Learning for Control of Evolutionary and Ecological Processes</title><link>http://arxiv.org/abs/2305.03340v2</link><description>As Evolutionary Dynamics moves from the realm of theory into application,algorithms are needed to move beyond simple models. Yet few such methods existin the literature. Ecological and physiological factors are known to be centralto evolution in realistic contexts, but accounting for them generally rendersproblems intractable to existing methods. We introduce a formulation ofevolutionary games which accounts for ecology and physiology by modeling bothas computations and use this to analyze the problem of directed evolution viamethods from Reinforcement Learning. This combination enables us to developfirst-of-their-kind results on the algorithmic problem of learning to controlan evolving population of cells. We prove a complexity bound oneco-evolutionary control in situations with limited prior knowledge of cellularphysiology or ecology, give the first results on the most general version ofthe mathematical problem of directed evolution, and establish a new linkbetween AI and biology.</description><author>Bryce Allen Bagley, Navin Khoshnan, Claudia K Petritsch</author><pubDate>Thu, 02 Jan 2025 03:38:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03340v2</guid></item><item><title>Conformal Thresholded Intervals for Efficient Regression</title><link>http://arxiv.org/abs/2407.14495v2</link><description>This paper introduces Conformal Thresholded Intervals (CTI), a novelconformal regression method that aims to produce the smallest possibleprediction set with guaranteed coverage. Unlike existing methods that rely onnested conformal frameworks and full conditional distribution estimation, CTIestimates the conditional probability density for a new response to fall intoeach interquantile interval using off-the-shelf multi-output quantileregression. By leveraging the inverse relationship between interval length andprobability density, CTI constructs prediction sets by thresholding theestimated conditional interquantile intervals based on their length. Theoptimal threshold is determined using a calibration set to ensure marginalcoverage, effectively balancing the trade-off between prediction set size andcoverage. CTI's approach is computationally efficient and avoids the complexityof estimating the full conditional distribution. The method is theoreticallygrounded, with provable guarantees for marginal coverage and achieving thesmallest prediction size given by Neyman-Pearson . Extensive experimentalresults demonstrate that CTI achieves superior performance compared tostate-of-the-art conformal regression methods across various datasets,consistently producing smaller prediction sets while maintaining the desiredcoverage level. The proposed method offers a simple yet effective solution forreliable uncertainty quantification in regression tasks, making it anattractive choice for practitioners seeking accurate and efficient conformalprediction.</description><author>Rui Luo, Zhixin Zhou</author><pubDate>Thu, 02 Jan 2025 03:36:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14495v2</guid></item><item><title>A 2-step Framework for Automated Literary Translation Evaluation: Its Promises and Pitfalls</title><link>http://arxiv.org/abs/2412.01340v2</link><description>In this work, we propose and evaluate the feasibility of a two-stage pipelineto evaluate literary machine translation, in a fine-grained manner, fromEnglish to Korean. The results show that our framework provides fine-grained,interpretable metrics suited for literary translation and obtains a highercorrelation with human judgment than traditional machine translation metrics.Nonetheless, it still fails to match inter-human agreement, especially inmetrics like Korean Honorifics. We also observe that LLMs tend to favortranslations generated by other LLMs, and we highlight the necessity ofdeveloping more sophisticated evaluation methods to ensure accurate andculturally sensitive machine translation of literary works.</description><author>Sheikh Shafayat, Dongkeun Yoon, Woori Jang, Jiwoo Choi, Alice Oh, Seohyon Jung</author><pubDate>Thu, 02 Jan 2025 03:29:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01340v2</guid></item><item><title>Causal Deep Learning</title><link>http://arxiv.org/abs/2301.00314v3</link><description>We derive a set of causal deep neural networks whose architectures are aconsequence of tensor (multilinear) factor analysis, a framework thatfacilitates forward and inverse causal inference. Forward causal questions areaddressed with a neural architecture composed of causal capsules and a tensortransformer. Causal capsules compute a set of invariant causal factorrepresentations, whose interactions are governed by a tensor transformation.Inverse causal questions are addressed with a neural network that implementsthe multilinear projection algorithm. The architecture reverses the order ofthe operations of a forward neural network and estimates the causes of effects.As an alternative to aggressive bottleneck dimension reduction or regularizedregression that may camouflage an inherently underdetermined inverse problem,we prescribe modeling different aspects of the mechanism of data formation withpiecewise tensor models whose multilinear projections produce multiplecandidate solutions. Our forward and inverse questions may be addressed withshallow architectures, but for computationally scalable solutions, we derive aset of deep neural networks by taking advantage of block algebra. Aninterleaved kernel hierarchy results in a doubly non-linear tensor factormodels. The causal neural networks that are a consequence of tensor factoranalysis are data agnostic, but are illustrated with facial images. Sequential,parallel and asynchronous parallel computation strategies are described.</description><author>M. Alex O. Vasilescu</author><pubDate>Thu, 02 Jan 2025 03:29:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.00314v3</guid></item><item><title>Detecting subtle cyberattacks on adaptive cruise control vehicles: A machine learning approach</title><link>http://arxiv.org/abs/2310.17091v2</link><description>With the advent of vehicles equipped with advanced driver-assistance systems,such as adaptive cruise control (ACC) and other automated driving features, thepotential for cyberattacks on these automated vehicles (AVs) has emerged. Whileovert attacks that force vehicles to collide may be easily identified, moreinsidious attacks, which only slightly alter driving behavior, can result innetwork-wide increases in congestion, fuel consumption, and even crash riskwithout being easily detected. To address the detection of such attacks, wefirst present a traffic model framework for three types of potentialcyberattacks: malicious manipulation of vehicle control commands, false datainjection attacks on sensor measurements, and denial-of-service (DoS) attacks.We then investigate the impacts of these attacks at both the individual vehicle(micro) and traffic flow (macro) levels. A novel generative adversarial network(GAN)-based anomaly detection model is proposed for real-time identification ofsuch attacks using vehicle trajectory data. We provide numerical evidence {todemonstrate} the efficacy of our machine learning approach in detectingcyberattacks on ACC-equipped vehicles. The proposed method is compared againstsome recently proposed neural network models and observed to have higheraccuracy in identifying anomalous driving behaviors of ACC vehicles.</description><author>Tianyi Li, Mingfeng Shang, Shian Wang, Raphael Stern</author><pubDate>Thu, 02 Jan 2025 03:21:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17091v2</guid></item></channel></rss>