<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 24 Oct 2024 13:00:17 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes</title><link>http://arxiv.org/abs/2410.18084v1</link><description>LiDAR scene generation has been developing rapidly recently. However,existing methods primarily focus on generating static and single-frame scenes,overlooking the inherently dynamic nature of real-world driving environments.In this work, we introduce DynamicCity, a novel 4D LiDAR generation frameworkcapable of generating large-scale, high-quality LiDAR scenes that capture thetemporal evolution of dynamic environments. DynamicCity mainly consists of twokey models. 1) A VAE model for learning HexPlane as the compact 4Drepresentation. Instead of using naive averaging operations, DynamicCityemploys a novel Projection Module to effectively compress 4D LiDAR featuresinto six 2D feature maps for HexPlane construction, which significantlyenhances HexPlane fitting quality (up to 12.56 mIoU gain). Furthermore, weutilize an Expansion &amp; Squeeze Strategy to reconstruct 3D feature volumes inparallel, which improves both network training efficiency and reconstructionaccuracy than naively querying each 3D point (up to 7.05 mIoU gain, 2.06xtraining speedup, and 70.84% memory reduction). 2) A DiT-based diffusion modelfor HexPlane generation. To make HexPlane feasible for DiT generation, a PaddedRollout Operation is proposed to reorganize all six feature planes of theHexPlane as a squared 2D feature map. In particular, various conditions couldbe introduced in the diffusion or sampling process, supporting versatile 4Dgeneration applications, such as trajectory- and command-driven generation,inpainting, and layout-conditioned generation. Extensive experiments on theCarlaSC and Waymo datasets demonstrate that DynamicCity significantlyoutperforms existing state-of-the-art 4D LiDAR generation methods acrossmultiple metrics. The code will be released to facilitate future research.</description><author>Hengwei Bian, Lingdong Kong, Haozhe Xie, Liang Pan, Yu Qiao, Ziwei Liu</author><pubDate>Wed, 23 Oct 2024 17:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18084v1</guid></item><item><title>FIPER: Generalizable Factorized Fields for Joint Image Compression and Super-Resolution</title><link>http://arxiv.org/abs/2410.18083v1</link><description>In this work, we propose a unified representation for Super-Resolution (SR)and Image Compression, termed **Factorized Fields**, motivated by the sharedprinciples between these two tasks. Both SISR and Image Compression requirerecovering and preserving fine image details--whether by enhancing resolutionor reconstructing compressed data. Unlike previous methods that mainly focus onnetwork architecture, our proposed approach utilizes a basis-coefficientdecomposition to explicitly capture multi-scale visual features and structuralcomponents in images, addressing the core challenges of both tasks. We firstderive our SR model, which includes a Coefficient Backbone and Basis SwinTransformer for generalizable Factorized Fields. Then, to further unify thesetwo tasks, we leverage the strong information-recovery capabilities of thetrained SR modules as priors in the compression pipeline, improving bothcompression efficiency and detail reconstruction. Additionally, we introduce amerged-basis compression branch that consolidates shared structures, furtheroptimizing the compression process. Extensive experiments show that our unifiedrepresentation delivers state-of-the-art performance, achieving an averagerelative improvement of 204.4% in PSNR over the baseline in Super-Resolution(SR) and 9.35% BD-rate reduction in Image Compression compared to the previousSOTA.</description><author>Yang-Che Sun, Cheng Yu Yeo, Ernie Chu, Jun-Cheng Chen, Yu-Lun Liu</author><pubDate>Wed, 23 Oct 2024 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18083v1</guid></item><item><title>Prioritized Generative Replay</title><link>http://arxiv.org/abs/2410.18082v1</link><description>Sample-efficient online reinforcement learning often uses replay buffers tostore experience for reuse when updating the value function. However, uniformreplay is inefficient, since certain classes of transitions can be morerelevant to learning. While prioritization of more useful samples is helpful,this strategy can also lead to overfitting, as useful samples are likely to bemore rare. In this work, we instead propose a prioritized, parametric versionof an agent's memory, using generative models to capture online experience.This paradigm enables (1) densification of past experience, with newgenerations that benefit from the generative model's generalization capacityand (2) guidance via a family of "relevance functions" that push thesegenerations towards more useful parts of an agent's acquired history. We showthis recipe can be instantiated using conditional diffusion models and simplerelevance functions such as curiosity- or value-based metrics. Our approachconsistently improves performance and sample efficiency in both state- andpixel-based domains. We expose the mechanisms underlying these gains, showinghow guidance promotes diversity in our generated transitions and reducesoverfitting. We also showcase how our approach can train policies with evenhigher update-to-data ratios than before, opening up avenues to better scaleonline RL agents.</description><author>Renhao Wang, Kevin Frans, Pieter Abbeel, Sergey Levine, Alexei A. Efros</author><pubDate>Wed, 23 Oct 2024 17:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18082v1</guid></item><item><title>FreeVS: Generative View Synthesis on Free Driving Trajectory</title><link>http://arxiv.org/abs/2410.18079v1</link><description>Existing reconstruction-based novel view synthesis methods for driving scenesfocus on synthesizing camera views along the recorded trajectory of the egovehicle. Their image rendering performance will severely degrade on viewpointsfalling out of the recorded trajectory, where camera rays are untrained. Wepropose FreeVS, a novel fully generative approach that can synthesize cameraviews on free new trajectories in real driving scenes. To control thegeneration results to be 3D consistent with the real scenes and accurate inviewpoint pose, we propose the pseudo-image representation of view priors tocontrol the generation process. Viewpoint transformation simulation is appliedon pseudo-images to simulate camera movement in each direction. Once trained,FreeVS can be applied to any validation sequences without reconstructionprocess and synthesis views on novel trajectories. Moreover, we propose two newchallenging benchmarks tailored to driving scenes, which are novel camerasynthesis and novel trajectory synthesis, emphasizing the freedom ofviewpoints. Given that no ground truth images are available on noveltrajectories, we also propose to evaluate the consistency of images synthesizedon novel trajectories with 3D perception models. Experiments on the Waymo OpenDataset show that FreeVS has a strong image synthesis performance on both therecorded trajectories and novel trajectories. Project Page:https://freevs24.github.io/</description><author>Qitai Wang, Lue Fan, Yuqi Wang, Yuntao Chen, Zhaoxiang Zhang</author><pubDate>Wed, 23 Oct 2024 17:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18079v1</guid></item><item><title>ALTA: Compiler-Based Analysis of Transformers</title><link>http://arxiv.org/abs/2410.18077v1</link><description>We propose a new programming language called ALTA and a compiler that can mapALTA programs to Transformer weights. ALTA is inspired by RASP, a languageproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compilerfrom RASP programs to Transformer weights. ALTA complements and extends thisprior work, offering the ability to express loops and to compile programs toUniversal Transformers, among other advantages. ALTA allows us toconstructively show how Transformers can represent length-invariant algorithmsfor computing parity and addition, as well as a solution to the SCAN benchmarkof compositional generalization tasks, without requiring intermediatescratchpad decoding steps. We also propose tools to analyze cases where theexpressibility of an algorithm is established, but end-to-end training on agiven training set fails to induce behavior consistent with the desiredalgorithm. To this end, we explore training from ALTA execution traces as amore fine-grained supervision signal. This enables additional experiments andtheoretical analyses relating the learnability of various algorithms to dataavailability and modeling decisions, such as positional encodings. We make theALTA framework -- language specification, symbolic interpreter, and weightcompiler -- available to the community to enable further applications andinsights.</description><author>Peter Shaw, James Cohan, Jacob Eisenstein, Kenton Lee, Jonathan Berant, Kristina Toutanova</author><pubDate>Wed, 23 Oct 2024 17:58:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18077v1</guid></item><item><title>Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration</title><link>http://arxiv.org/abs/2410.18076v1</link><description>Unsupervised pretraining has been transformative in many supervised domains.However, applying such ideas to reinforcement learning (RL) presents a uniquechallenge in that fine-tuning does not involve mimicking task-specific data,but rather exploring and locating the solution through iterativeself-improvement. In this work, we study how unlabeled prior trajectory datacan be leveraged to learn efficient exploration strategies. While prior datacan be used to pretrain a set of low-level skills, or as additional off-policydata for online RL, it has been unclear how to combine these ideas effectivelyfor online exploration. Our method SUPE (Skills from Unlabeled Prior data forExploration) demonstrates that a careful combination of these ideas compoundstheir benefits. Our method first extracts low-level skills using a variationalautoencoder (VAE), and then pseudo-relabels unlabeled trajectories using anoptimistic reward model, transforming prior data into high-level, task-relevantexamples. Finally, SUPE uses these transformed examples as additionaloff-policy data for online RL to learn a high-level policy that composespretrained low-level skills to explore efficiently. We empirically show thatSUPE reliably outperforms prior strategies, successfully solving a suite oflong-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.</description><author>Max Wilcoxson, Qiyang Li, Kevin Frans, Sergey Levine</author><pubDate>Wed, 23 Oct 2024 17:58:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18076v1</guid></item><item><title>ProFL: Performative Robust Optimal Federated Learning</title><link>http://arxiv.org/abs/2410.18075v1</link><description>Performative prediction (PP) is a framework that captures distribution shiftsthat occur during the training of machine learning models due to theirdeployment. As the trained model is used, its generated data could cause themodel to evolve, leading to deviations from the original data distribution. Theimpact of such model-induced distribution shifts in the federated learning (FL)setup remains unexplored despite being increasingly likely to transpire inreal-life use cases. Although Jin et al. (2024) recently extended PP to FL in astraightforward manner, the resulting model only converges to a performativestable point, which may be far from optimal. The methods in Izzo et al. (2021);Miller et al. (2021) can find a performative optimal point in centralizedsettings, but they require the performative risk to be convex and the trainingdata to be noiseless, assumptions often violated in realistic FL systems. Thispaper overcomes all of these shortcomings and proposes Performative robustoptimal Federated Learning (ProFL), an algorithm that finds performativeoptimal points in FL from noisy and contaminated data. We present theconvergence analysis under the Polyak-Lojasiewicz condition, which applies tonon-convex objectives. Extensive experiments on multiple datasets validate ourproposed algorithms' efficiency.</description><author>Xue Zheng, Tian Xie, Xuwei Tan, Aylin Yener, Xueru Zhang, Ali Payani, Myungjin Lee</author><pubDate>Wed, 23 Oct 2024 17:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18075v1</guid></item><item><title>UnCLe: Unsupervised Continual Learning of Depth Completion</title><link>http://arxiv.org/abs/2410.18074v1</link><description>We propose UnCLe, a standardized benchmark for Unsupervised ContinualLearning of a multimodal depth estimation task: Depth completion aims to infera dense depth map from a pair of synchronized RGB image and sparse depth map.We benchmark depth completion models under the practical scenario ofunsupervised learning over continuous streams of data. Existing methods aretypically trained on a static, or stationary, dataset. However, when adaptingto novel non-stationary distributions, they "catastrophically forget"previously learned information. UnCLe simulates these non-stationarydistributions by adapting depth completion models to sequences of datasetscontaining diverse scenes captured from distinct domains using different visualand range sensors. We adopt representative methods from continual learningparadigms and translate them to enable unsupervised continual learning of depthcompletion. We benchmark these models for indoor and outdoor and investigatethe degree of catastrophic forgetting through standard quantitative metrics.Furthermore, we introduce model inversion quality as an additional measure offorgetting. We find that unsupervised continual learning of depth completion isan open problem, and we invite researchers to leverage UnCLe as a developmentplatform.</description><author>Suchisrit Gangopadhyay, Xien Chen, Michael Chu, Patrick Rim, Hyoungseob Park, Alex Wong</author><pubDate>Wed, 23 Oct 2024 17:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18074v1</guid></item><item><title>WorldSimBench: Towards Video Generation Models as World Simulators</title><link>http://arxiv.org/abs/2410.18072v1</link><description>Recent advancements in predictive models have demonstrated exceptionalcapabilities in predicting the future state of objects and scenes. However, thelack of categorization based on inherent characteristics continues to hinderthe progress of predictive model development. Additionally, existing benchmarksare unable to effectively evaluate higher-capability, highly embodiedpredictive models from an embodied perspective. In this work, we classify thefunctionalities of predictive models into a hierarchy and take the first stepin evaluating World Simulators by proposing a dual evaluation framework calledWorldSimBench. WorldSimBench includes Explicit Perceptual Evaluation andImplicit Manipulative Evaluation, encompassing human preference assessmentsfrom the visual perspective and action-level evaluations in embodied tasks,covering three representative embodied scenarios: Open-Ended EmbodiedEnvironment, Autonomous, Driving, and Robot Manipulation. In the ExplicitPerceptual Evaluation, we introduce the HF-Embodied Dataset, a video assessmentdataset based on fine-grained human feedback, which we use to train a HumanPreference Evaluator that aligns with human perception and explicitly assessesthe visual fidelity of World Simulators. In the Implicit ManipulativeEvaluation, we assess the video-action consistency of World Simulators byevaluating whether the generated situation-aware video can be accuratelytranslated into the correct control signals in dynamic environments. Ourcomprehensive evaluation offers key insights that can drive further innovationin video generation models, positioning World Simulators as a pivotaladvancement toward embodied artificial intelligence.</description><author>Yiran Qin, Zhelun Shi, Jiwen Yu, Xijun Wang, Enshen Zhou, Lijun Li, Zhenfei Yin, Xihui Liu, Lu Sheng, Jing Shao, Lei Bai, Wanli Ouyang, Ruimao Zhang</author><pubDate>Wed, 23 Oct 2024 17:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18072v1</guid></item><item><title>TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts</title><link>http://arxiv.org/abs/2410.18071v1</link><description>Recently, multimodal large language models (MLLMs) have received muchattention for their impressive capabilities. The evaluation of MLLMs isbecoming critical to analyzing attributes of MLLMs and providing valuableinsights. However, current benchmarks overlook the problem of promptsensitivity - minor prompt variations may lead to significant performancefluctuations. Thus, inappropriate prompts may obscure the models' capabilities,underestimating the models' performance. Moreover, different models havedifferent preferences for different prompts, and thus, using the same promptfor all models will cause evaluation bias. This paper analyzes this deficiencyin existing benchmarks and further introduces a new evaluation framework namedTP-Eval, which introduces a prompt customization method to reduce evaluationbiases and tap models' potential. TP-Eval will rewrite the original prompts todifferent customized prompts for different models. In particular, we proposesome well-designed modules for prompt customization tailored to the scenario ofMLLM evaluation. Extensive experiments demonstrate the effectiveness of ourapproach to uncovering models' capabilities, and TP-Eval should benefit thecommunity in developing more comprehensive and convincing MLLM evaluationbenchmarks.</description><author>Yuxuan Xie, Tianhua Li, Wenqi Shao, Kaipeng Zhang</author><pubDate>Wed, 23 Oct 2024 17:54:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18071v1</guid></item><item><title>Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune CNNs and Transformers</title><link>http://arxiv.org/abs/2408.12568v2</link><description>To solve ever more complex problems, Deep Neural Networks are scaled tobillions of parameters, leading to huge computational costs. An effectiveapproach to reduce computational requirements and increase efficiency is toprune unnecessary components of these often over-parameterized networks.Previous work has shown that attribution methods from the field of eXplainableAI serve as effective means to extract and prune the least relevant networkcomponents in a few-shot fashion. We extend the current state by proposing toexplicitly optimize hyperparameters of attribution methods for the task ofpruning, and further include transformer-based networks in our analysis. Ourapproach yields higher model compression rates of large transformer- andconvolutional architectures (VGG, ResNet, ViT) compared to previous works,while still attaining high performance on ImageNet classification tasks. Here,our experiments indicate that transformers have a higher degree ofover-parameterization compared to convolutional neural networks. Code isavailable at https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch.</description><author>Sayed Mohammad Vakilzadeh Hatefi, Maximilian Dreyer, Reduan Achtibat, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin</author><pubDate>Wed, 23 Oct 2024 17:53:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12568v2</guid></item><item><title>Training Free Guided Flow Matching with Optimal Control</title><link>http://arxiv.org/abs/2410.18070v1</link><description>Controlled generation with pre-trained Diffusion and Flow Matching models hasvast applications. One strategy for guiding ODE-based generative models isthrough optimizing a target loss $R(x_1)$ while staying close to the priordistribution. Along this line, some recent work showed the effectiveness ofguiding flow model by differentiating through its ODE sampling process. Despitethe superior performance, the theoretical understanding of this line of methodsis still preliminary, leaving space for algorithm improvement. Moreover,existing methods predominately focus on Euclidean data manifold, and there is acompelling need for guided flow methods on complex geometries such as SO(3),which prevails in high-stake scientific applications like protein design. Wepresent OC-Flow, a general and theoretically grounded training-free frameworkfor guided flow matching using optimal control. Building upon advances inoptimal control theory, we develop effective and practical algorithms forsolving optimal control in guided ODE-based generation and provide a systematictheoretical analysis of the convergence guarantee in both Euclidean and SO(3).We show that existing backprop-through-ODE methods can be interpreted asspecial cases of Euclidean OC-Flow. OC-Flow achieved superior performance inextensive experiments on text-guided image manipulation, conditional moleculegeneration, and all-atom peptide design.</description><author>Luran Wang, Chaoran Cheng, Yizhen Liao, Yanru Qu, Ge Liu</author><pubDate>Wed, 23 Oct 2024 17:53:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18070v1</guid></item><item><title>Correlated Proxies: A New Definition and Improved Mitigation for Reward Hacking</title><link>http://arxiv.org/abs/2403.03185v2</link><description>Because it is difficult to precisely specify complex objectives,reinforcement learning policies are often optimized using flawed proxy rewardsthat seem to capture the true objective. However, optimizing proxy rewardsfrequently leads to reward hacking: the optimized reward function ceases to bea good proxy, and the resulting policy performs poorly with respect to theunspecified true reward. Principled solutions to reward hacking have beenimpeded by the lack of a good definition for the problem. To address this, weintroduce a definition of reward hacking based on the correlation between proxyand true rewards for states and actions seen by a "base policy" that breaksdown under optimization. We show that this definition captures reward hackingbehavior across several realistic settings, including in reinforcement learningfrom human feedback (RLHF). We then show theoretically that regularization tothe base policy can effectively prevent reward hacking. While current RLHFapproaches apply a KL penalty between the action distributions of policies, ourtheory suggests that it is more effective to regularize using the $\chi^2$divergence between the policies' occupancy measures. We intuitively show whythis type of regularization is superior and demonstrate that it bettermitigates reward hacking in practice across four realistic domains, includingRLHF for LLMs. Our code is available at https://github.com/cassidylaidlaw/orpo.</description><author>Cassidy Laidlaw, Shivam Singhal, Anca Dragan</author><pubDate>Wed, 23 Oct 2024 17:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03185v2</guid></item><item><title>Physical Reasoning and Object Planning for Household Embodied Agents</title><link>http://arxiv.org/abs/2311.13577v2</link><description>In this study, we explore the sophisticated domain of task planning forrobust household embodied agents, with a particular emphasis on the intricatetask of selecting substitute objects. We introduce the CommonSense ObjectAffordance Task (COAT), a novel framework designed to analyze reasoningcapabilities in commonsense scenarios. This approach is centered onunderstanding how these agents can effectively identify and utilize alternativeobjects when executing household tasks, thereby offering insights into thecomplexities of practical decision-making in real-world environments. Drawinginspiration from factors affecting human decision-making, we explore how largelanguage models tackle this challenge through four meticulously craftedcommonsense question-and-answer datasets featuring refined rules and humanannotations. Our evaluation of state-of-the-art language models on thesedatasets sheds light on three pivotal considerations: 1) aligning an object'sinherent utility with the task at hand, 2) navigating contextual dependencies(societal norms, safety, appropriateness, and efficiency), and 3) accountingfor the current physical state of the object. To maintain accessibility, weintroduce five abstract variables reflecting an object's physical condition,modulated by human insights, to simulate diverse household scenarios. Ourcontributions include insightful human preference mappings for all threefactors and four extensive QA datasets (2K, 15k, 60k, 70K questions) probingthe intricacies of utility dependencies, contextual dependencies and objectphysical states. The datasets, along with our findings, are accessible at:https://github.com/Ayush8120/COAT. This research not only advances ourunderstanding of physical commonsense reasoning in language models but alsopaves the way for future improvements in household agent intelligence.</description><author>Ayush Agrawal, Raghav Prabhakar, Anirudh Goyal, Dianbo Liu</author><pubDate>Wed, 23 Oct 2024 17:50:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13577v2</guid></item><item><title>Beyond position: how rotary embeddings shape representations and memory in autoregressive transfomers</title><link>http://arxiv.org/abs/2410.18067v1</link><description>Rotary Positional Embeddings (RoPE) enhance positional encoding inTransformer models, yet their full impact on model dynamics remainsunderexplored. This paper studies how RoPE introduces position-dependentrotations, causing phase shifts in token embeddings that influencehigher-frequency components within the model's internal representations.Through spectral analysis, we demonstrate that RoPE's rotation matrices induceoscillatory behaviors in embeddings, affecting information retention acrosslayers and shaping temporal modeling capabilities. We show that activationfunctions in feed-forward networks interact with RoPE-modulated embeddings togenerate harmonics, leading to constructive or destructive interference basedon phase alignment. Our findings reveal that phase alignment amplifiesactivations and sharpens attention, while misalignment weakens activations anddisrupts focus on positional patterns. This study underscores the importance offrequency components as intrinsic elements of model behavior, offering newinsights beyond traditional analyses.</description><author>Valeria Ruscio, Fabrizio Silvestri</author><pubDate>Wed, 23 Oct 2024 17:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18067v1</guid></item><item><title>MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation</title><link>http://arxiv.org/abs/2409.15240v2</link><description>Long-term memory is important for chatbots and dialogue systems (DS) tocreate consistent and human-like conversations, evidenced by numerous developedmemory-augmented DS (MADS). To evaluate the effectiveness of such MADS,existing commonly used evaluation metrics, like retrieval accuracy andperplexity (PPL), mainly focus on query-oriented factualness and languagequality assessment. However, these metrics often lack practical value.Moreover, the evaluation dimensions are insufficient for human-like assessmentin DS. Regarding memory-recalling paradigms, current evaluation schemes onlyconsider passive memory retrieval while ignoring diverse memory recall withrich triggering factors, e.g., emotions and surroundings, which can beessential in emotional support scenarios. To bridge the gap, we construct anovel Memory-Augmented Dialogue Benchmark (MADail-Bench) covering variousmemory-recalling paradigms based on cognitive science and psychology theories.The benchmark assesses two tasks separately: memory retrieval and memoryrecognition with the incorporation of both passive and proactive memory recalldata. We introduce new scoring criteria to the evaluation, including memoryinjection, emotion support (ES) proficiency, and intimacy, to comprehensivelyassess generated responses. Results from cutting-edge embedding models andlarge language models on this benchmark indicate the potential for furtheradvancement. Extensive testing further reveals correlations between memoryinjection, ES proficiency, and intimacy.</description><author>Junqing He, Liang Zhu, Rui Wang, Xi Wang, Reza Haffari, Jiaxing Zhang</author><pubDate>Wed, 23 Oct 2024 17:47:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.15240v2</guid></item><item><title>Does Generative AI speak Nigerian-Pidgin?: Issues about Representativeness and Bias for Multilingualism in LLMs</title><link>http://arxiv.org/abs/2404.19442v2</link><description>Nigeria is a multilingual country with 500+ languages. Naija is aNigerian-Pidgin spoken by approx. 120M speakers in Nigeria and it is a mixedlanguage (e.g., English, Portuguese, Yoruba, Hausa and Igbo). Although it hasmainly been a spoken language until recently, there are now various platformspublishing exclusively in Naija such as Naija Wikipedia. However, it is hard todistinguish by non-native from a larger pidgin languages spoken across WestAfrica known as West African Pidgin English (WAPE) -- which is more simpliedand understandable by wider audience in Ghana, Nigeria, and Cameroon. BBC newsplatform publishes exclusively in WAPE to cater for several countries in WestAfrica. In our paper, we show through statistical analyses and MachineTranslation experiments that these two creole varieties do not represent eachother (i.e., there are linguistic differences in word order and vocabulary) andGenerative AI operates only based on WAPE. In other words, Naija isunder-represented in Generative AI, and it is hard to teach LLMs with fewexamples.</description><author>David Ifeoluwa Adelani, A. Seza Doğruöz, Iyanuoluwa Shode, Anuoluwapo Aremu</author><pubDate>Wed, 23 Oct 2024 17:46:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19442v2</guid></item><item><title>The Double-Edged Sword of Behavioral Responses in Strategic Classification: Theory and User Studies</title><link>http://arxiv.org/abs/2410.18066v1</link><description>When humans are subject to an algorithmic decision system, they canstrategically adjust their behavior accordingly (``game'' the system). While agrowing line of literature on strategic classification has used game-theoreticmodeling to understand and mitigate such gaming, these existing works considerstandard models of fully rational agents. In this paper, we propose a strategicclassification model that considers behavioral biases in human responses toalgorithms. We show how misperceptions of a classifier (specifically, of itsfeature weights) can lead to different types of discrepancies between biasedand rational agents' responses, and identify when behavioral agents over- orunder-invest in different features. We also show that strategic agents withbehavioral biases can benefit or (perhaps, unexpectedly) harm the firm comparedto fully rational strategic agents. We complement our analytical results withuser studies, which support our hypothesis of behavioral biases in humanresponses to the algorithm. Together, our findings highlight the need toaccount for human (cognitive) biases when designing AI systems, and providingexplanations of them, to strategic human in the loop.</description><author>Raman Ebrahimi, Kristen Vaccaro, Parinaz Naghizadeh</author><pubDate>Wed, 23 Oct 2024 17:42:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18066v1</guid></item><item><title>Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning</title><link>http://arxiv.org/abs/2407.15762v2</link><description>Reward-based finetuning is crucial for aligning language policies withintended behaviors (e.g., creativity and safety). A key challenge is to developsteerable language models that trade-off multiple (conflicting) objectives in aflexible and efficient manner. This paper presents Conditional Language Policy(CLP), a general framework for finetuning language models on multipleobjectives. Building on techniques from multi-task training andparameter-efficient finetuning, CLP learn steerable models that effectivelytrade-off conflicting objectives at inference time. Notably, this does notrequire training or maintaining multiple models to achieve different trade-offsbetween the objectives. Through extensive experiments and ablations on twosummarization datasets, we show that CLP learns steerable language models thatoutperform and Pareto-dominate the existing approaches for multi-objectivefinetuning.</description><author>Kaiwen Wang, Rahul Kidambi, Ryan Sullivan, Alekh Agarwal, Christoph Dann, Andrea Michi, Marco Gelmi, Yunxuan Li, Raghav Gupta, Avinava Dubey, Alexandre Ramé, Johan Ferret, Geoffrey Cideron, Le Hou, Hongkun Yu, Amr Ahmed, Aranyak Mehta, Léonard Hussenot, Olivier Bachem, Edouard Leurent</author><pubDate>Wed, 23 Oct 2024 17:42:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.15762v2</guid></item><item><title>SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for Long-Horizon Manipulation</title><link>http://arxiv.org/abs/2410.18065v1</link><description>Robot learning has proven to be a general and effective technique forprogramming manipulators. Imitation learning is able to teach robots solelyfrom human demonstrations but is bottlenecked by the capabilities of thedemonstrations. Reinforcement learning uses exploration to discover betterbehaviors; however, the space of possible improvements can be too large tostart from scratch. And for both techniques, the learning difficulty increasesproportional to the length of the manipulation task. Accounting for this, wepropose SPIRE, a system that first uses Task and Motion Planning (TAMP) todecompose tasks into smaller learning subproblems and second combines imitationand reinforcement learning to maximize their strengths. We develop novelstrategies to train learning agents when deployed in the context of a planningsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robotmanipulation problems. We find that SPIRE outperforms prior approaches thatintegrate imitation learning, reinforcement learning, and planning by 35% to50% in average task performance, is 6 times more data efficient in the numberof human demonstrations needed to train proficient agents, and learns tocomplete tasks nearly twice as efficiently. Viewhttps://sites.google.com/view/spire-corl-2024 for more details.</description><author>Zihan Zhou, Animesh Garg, Dieter Fox, Caelan Garrett, Ajay Mandlekar</author><pubDate>Wed, 23 Oct 2024 17:42:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18065v1</guid></item><item><title>Utilitarian Algorithm Configuration for Infinite Parameter Spaces</title><link>http://arxiv.org/abs/2405.18246v2</link><description>Utilitarian algorithm configuration is a general-purpose technique forautomatically searching the parameter space of a given algorithm to optimizeits performance, as measured by a given utility function, on a given set ofinputs. Recently introduced utilitarian configuration procedures offeroptimality guarantees about the returned parameterization while provablyadapting to the hardness of the underlying problem. However, the applicabilityof these approaches is severely limited by the fact that they only search afinite, relatively small set of parameters. They cannot effectively search theconfiguration space of algorithms with continuous or uncountable parameters. Inthis paper we introduce a new procedure, which we dub COUP (Continuous,Optimistic Utilitarian Procrastination). COUP is designed to search infiniteparameter spaces efficiently to find good configurations quickly. Furthermore,COUP maintains the theoretical benefits of previous utilitarian configurationprocedures when applied to finite parameter spaces but is significantly faster,both provably and experimentally.</description><author>Devon Graham, Kevin Leyton-Brown</author><pubDate>Wed, 23 Oct 2024 17:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18246v2</guid></item><item><title>Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain</title><link>http://arxiv.org/abs/2410.18060v1</link><description>In this paper, we propose a model for building natural language explanationsfor Bayesian Network Reasoning in terms of factor arguments, which areargumentation graphs of flowing evidence, relating the observed evidence to atarget variable we want to learn about. We introduce the notion of factorargument independence to address the outstanding question of defining whenarguments should be presented jointly or separately and present an algorithmthat, starting from the evidence nodes and a target node, produces a list ofall independent factor arguments ordered by their strength. Finally, weimplemented a scheme to build natural language explanations of BayesianReasoning using this approach. Our proposal has been validated in the medicaldomain through a human-driven evaluation study where we compare the BayesianNetwork Reasoning explanations obtained using factor arguments with analternative explanation method. Evaluation results indicate that our proposedexplanation approach is deemed by users as significantly more useful forunderstanding Bayesian Network Reasoning than another existing explanationmethod it is compared to.</description><author>Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin</author><pubDate>Wed, 23 Oct 2024 17:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18060v1</guid></item><item><title>CLEAR: Character Unlearning in Textual and Visual Modalities</title><link>http://arxiv.org/abs/2410.18057v1</link><description>Machine Unlearning (MU) is critical for enhancing privacy and security indeep learning models, particularly in large multimodal language models (MLLMs),by removing specific private or hazardous information. While MU has madesignificant progress in textual and visual modalities, multimodal unlearning(MMU) remains significantly underexplored, partially due to the absence of asuitable open-source benchmark. To address this, we introduce CLEAR, a newbenchmark designed to evaluate MMU methods. CLEAR contains 200 fictitiousindividuals and 3,700 images linked with corresponding question-answer pairs,enabling a thorough evaluation across modalities. We assess 10 MU methods,adapting them for MMU, and highlight new challenges specific to multimodalforgetting. We also demonstrate that simple $\ell_1$ regularization on LoRAweights significantly mitigates catastrophic forgetting, preserving modelperformance on retained data. The dataset is available athttps://huggingface.co/datasets/therem/CLEAR</description><author>Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Y. Rogov, Ivan Oseledets, Elena Tutubalina</author><pubDate>Wed, 23 Oct 2024 17:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18057v1</guid></item><item><title>In-Pixel Foreground and Contrast Enhancement Circuits with Customizable Mapping</title><link>http://arxiv.org/abs/2410.18052v1</link><description>This paper presents an innovative in-pixel contrast enhancement circuit thatperforms image processing directly within the pixel circuit. The circuit can betuned for different modes of operation. In foreground enhancement mode, itsuppresses low-intensity background pixels to nearly zero, isolating theforeground for better object visibility. In contrast enhancement mode, itimproves overall image contrast. The contrast enhancement function iscustomizable both during the design phase and in real-time, allowing thecircuit to adapt to specific applications and varying lighting conditions. Amodel of the designed pixel circuit is developed and applied to a full pixelarray, demonstrating significant improvements in image quality. Simulationsperformed in HSPICE show a nearly 6x increase in Michelson Contrast Ratio (CR)in the foreground enhancement mode. The simulation results indicate itspotential for real-time, adaptive contrast enhancement across various imagingenvironments.</description><author>Md Rahatul Islam Udoy, Md Mazharul Islam, Elijah Johnson, Ahmedullah Aziz</author><pubDate>Wed, 23 Oct 2024 17:26:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18052v1</guid></item><item><title>Safeguard is a Double-edged Sword: Denial-of-service Attack on Large Language Models</title><link>http://arxiv.org/abs/2410.02916v2</link><description>Safety is a paramount concern of large language models (LLMs) in their opendeployment. To this end, safeguard methods aim to enforce the ethical andresponsible use of LLMs through safety alignment or guardrail mechanisms.However, we found that the malicious attackers could exploit false positives ofsafeguards, i.e., fooling the safeguard model to block safe content mistakenly,leading to a new denial-of-service (DoS) attack on LLMs. Specifically, bysoftware or phishing attacks on user client software, attackers insert a short,seemingly innocuous adversarial prompt into to user prompt templates inconfiguration files; thus, this prompt appears in final user requests withoutvisibility in the user interface and is not trivial to identify. By designingan optimization process that utilizes gradient and attention information, ourattack can automatically generate seemingly safe adversarial prompts,approximately only 30 characters long, that universally block over 97\% of userrequests on Llama Guard 3. The attack presents a new dimension of evaluatingLLM safeguards focusing on false positives, fundamentally different from theclassic jailbreak.</description><author>Qingzhao Zhang, Ziyang Xiong, Z. Morley Mao</author><pubDate>Wed, 23 Oct 2024 17:26:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02916v2</guid></item><item><title>Real time anomalies detection on video</title><link>http://arxiv.org/abs/2410.18051v1</link><description>Nowadays, many places use security cameras. Unfortunately, when an incidentoccurs, these technologies are used to show past events. So it can beconsidered as a deterrence tool than a detection tool. In this article, we willpropose a deep learning approach trying to solve this problematic. Thisapproach uses convolutional models (CNN) to extract relevant characteristicslinked to the video images, theses characteristics will form times series to beanalyzed by LSTM / GRU models.</description><author>Fabien Poirier</author><pubDate>Wed, 23 Oct 2024 17:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18051v1</guid></item><item><title>LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering</title><link>http://arxiv.org/abs/2410.18050v1</link><description>Long-Context Question Answering (LCQA), a challenging task, aims to reasonover long-context documents to yield accurate answers to questions. Existinglong-context Large Language Models (LLMs) for LCQA often struggle with the"lost in the middle" issue. Retrieval-Augmented Generation (RAG) mitigates thisissue by providing external factual evidence. However, its chunking strategydisrupts the global long-context information, and its low-quality retrieval inlong contexts hinders LLMs from identifying effective factual details due tosubstantial noise. To this end, we propose LongRAG, a general,dual-perspective, and robust LLM-based RAG system paradigm for LCQA to enhanceRAG's understanding of complex long-context knowledge (i.e., global informationand factual details). We design LongRAG as a plug-and-play paradigm,facilitating adaptation to various domains and LLMs. Extensive experiments onthree multi-hop datasets demonstrate that LongRAG significantly outperformslong-context LLMs (up by 6.94%), advanced RAG (up by 6.16%), and Vanilla RAG(up by 17.25%). Furthermore, we conduct quantitative ablation studies andmulti-dimensional analyses, highlighting the effectiveness of the system'scomponents and fine-tuning strategies. Data and code are available athttps://github.com/QingFei1/LongRAG.</description><author>Qingfei Zhao, Ruobing Wang, Yukuo Cen, Daren Zha, Shicheng Tan, Yuxiao Dong, Jie Tang</author><pubDate>Wed, 23 Oct 2024 17:24:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18050v1</guid></item><item><title>Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases</title><link>http://arxiv.org/abs/2410.18040v1</link><description>Keyphrase selection is a challenging task in natural language processing thathas a wide range of applications. Adapting existing supervised and unsupervisedsolutions for the Russian language faces several limitations due to the richmorphology of Russian and the limited number of training datasets available.Recent studies conducted on English texts show that large language models(LLMs) successfully address the task of generating keyphrases. LLMs allowachieving impressive results without task-specific fine-tuning, using textprompts instead. In this work, we access the performance of prompt-basedmethods for generating keyphrases for Russian scientific abstracts. First, wecompare the performance of zero-shot and few-shot prompt-based methods,fine-tuned models, and unsupervised methods. Then we assess strategies forselecting keyphrase examples in a few-shot setting. We present the outcomes ofhuman evaluation of the generated keyphrases and analyze the strengths andweaknesses of the models through expert assessment. Our results suggest thatprompt-based methods can outperform common baselines even using simple textprompts.</description><author>Anna Glazkova, Dmitry Morozov, Timur Garipov</author><pubDate>Wed, 23 Oct 2024 17:07:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18040v1</guid></item><item><title>POD-Attention: Unlocking Full Prefill-Decode Overlap for Faster LLM Inference</title><link>http://arxiv.org/abs/2410.18038v1</link><description>Each request in LLM inference goes through two phases: compute-bound prefilland memory-bandwidth-bound decode. To improve GPU utilization, recent systemsuse hybrid batching that combines the prefill and decode phases of differentrequests into the same batch. Hybrid batching works well for linear operationsas it amortizes the cost of loading model weights from HBM. However, attentioncomputation in hybrid batches remains inefficient because existing attentionkernels are optimized for either prefill or decode. In this paper, we present POD-Attention -- the first GPU kernel thatefficiently computes attention for hybrid batches. POD-Attention aims tomaximize the utilization of both compute and memory bandwidth by carefullyallocating the GPU's resources such that prefill and decode operations happenconcurrently on the same multiprocessor. We integrate POD-Attention in astate-of-the-art LLM inference scheduler Sarathi-Serve. POD-Attention speeds upattention computation by up to 75% (mean 28%) and increases LLM servingthroughput by up to 22% in offline inference. In online inference,POD-Attention enables lower time-to-first-token (TTFT), time-between-tokens(TBT), and request execution latency versus Sarathi-Serve.</description><author>Aditya K Kamath, Ramya Prabhu, Jayashree Mohan, Simon Peter, Ramachandran Ramjee, Ashish Panwar</author><pubDate>Wed, 23 Oct 2024 17:06:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18038v1</guid></item><item><title>MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning</title><link>http://arxiv.org/abs/2410.18035v1</link><description>Low-rank adaptation (LoRA) and its mixture-of-experts (MOE) variants arehighly effective parameter-efficient fine-tuning (PEFT) methods. However, theyintroduce significant latency in multi-tenant settings due to the LoRA modulesand MOE routers added to multiple linear modules in the Transformer layer. Toaddress this issue, we propose Mixture of Low-Rank Adaptation (MiLoRA), a noveland efficient LoRA variant. MiLoRA differs from previous MOE-style LoRA methodsby considering each LoRA module as an expert and employing a prompt-awarerouting mechanism. This mechanism calculates expert routing results once beforegenerating the first new token and reuses these results for subsequent tokens,reducing latency. Extensive experiments and analysis on commonsense reasoningtasks, math reasoning tasks, and widely used LLM evaluation benchmarksdemonstrate that MiLoRA consistently outperforms strong PEFT baselines withcomparable tunable parameter budgets. Additionally, MiLoRA significantlyreduces latency in multi-tenant settings compared to previous LoRA-basedmethods.</description><author>Jingfan Zhang, Yi Zhao, Dan Chen, Xing Tian, Huanran Zheng, Wei Zhu</author><pubDate>Wed, 23 Oct 2024 17:04:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18035v1</guid></item><item><title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title><link>http://arxiv.org/abs/2410.18032v1</link><description>Graphs are widely used for modeling relational data in real-world scenarios,such as social networks and urban computing. Existing LLM-based graph analysisapproaches either integrate graph neural networks (GNNs) for specific machinelearning tasks, limiting their transferability, or rely solely on LLMs'internal reasoning ability, resulting in suboptimal performance. To addressthese limitations, we take advantage of recent advances in LLM-based agents,which have shown capabilities of utilizing external knowledge or tools forproblem solving. By simulating human problem-solving strategies such as analogyand collaboration, we propose a multi-agent system based on LLMs namedGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents fromthree modules, and the agents with different specialities can collaborate witheach other to address complex problems. Specifically, (1) input-outputnormalization module: the question agent extracts and refines four keyarguments from the original question, facilitating the problem understanding,and the answer agent organizes the results to meet the output requirement; (2)external knowledge retrieval module: we first build a knowledge base consistingof relevant documentation and experience information, and then the search agentretrieves the most relevant entries for each question. (3) problem-solvingmodule: given the retrieved information from search agent, the coding agentuses established algorithms via programming to generate solutions, and in casethe coding agent does not work, the reasoning agent will directly compute theresults without programming. Extensive experiments on six graph analysisbenchmarks demonstrate that GraphTeam achieves state-of-the-art performancewith an average 25.85% improvement over the best baseline in terms of accuracy.The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.</description><author>Xin Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang</author><pubDate>Wed, 23 Oct 2024 17:02:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18032v1</guid></item><item><title>Exploring Large Language Models for Feature Selection: A Data-centric Perspective</title><link>http://arxiv.org/abs/2408.12025v2</link><description>The rapid advancement of Large Language Models (LLMs) has significantlyinfluenced various domains, leveraging their exceptional few-shot and zero-shotlearning capabilities. In this work, we aim to explore and understand theLLMs-based feature selection methods from a data-centric perspective. We beginby categorizing existing feature selection methods with LLMs into two groups:data-driven feature selection which requires numerical values of samples to dostatistical inference and text-based feature selection which utilizes priorknowledge of LLMs to do semantical associations using descriptive context. Weconduct experiments in both classification and regression tasks with LLMs invarious sizes (e.g., GPT-4, ChatGPT and LLaMA-2). Our findings emphasize theeffectiveness and robustness of text-based feature selection methods andshowcase their potentials using a real-world medical application. We alsodiscuss the challenges and future opportunities in employing LLMs for featureselection, offering insights for further research and development in thisemerging field.</description><author>Dawei Li, Zhen Tan, Huan Liu</author><pubDate>Wed, 23 Oct 2024 17:01:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12025v2</guid></item><item><title>Cross-lingual Transfer of Reward Models in Multilingual Alignment</title><link>http://arxiv.org/abs/2410.18027v1</link><description>Reinforcement learning with human feedback (RLHF) is shown to largely benefitfrom precise reward models (RMs). However, recent studies in reward modelingschemes are skewed towards English, limiting the applicability of RLHF inmultilingual alignments. In this work, we investigate the cross-lingualtransfer of RMs trained in diverse languages, primarily from English. Ourexperimental results demonstrate the strong cross-lingual transfer of EnglishRMs, exceeding target language RMs by 3~4% average increase in MultilingualRewardBench. Furthermore, we analyze the cross-lingual transfer of RMs throughthe representation shifts. Finally, we perform multilingual alignment toexemplify how cross-lingual transfer in RM propagates to enhanced multilingualinstruction-following capability, along with extensive analyses onoff-the-shelf RMs. We release the code, model, and data.</description><author>Jiwoo Hong, Noah Lee, Rodrigo Martínez-Castaño, César Rodríguez, James Thorne</author><pubDate>Wed, 23 Oct 2024 17:00:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18027v1</guid></item><item><title>Scalable Ranked Preference Optimization for Text-to-Image Generation</title><link>http://arxiv.org/abs/2410.18013v1</link><description>Direct Preference Optimization (DPO) has emerged as a powerful approach toalign text-to-image (T2I) models with human feedback. Unfortunately, successfulapplication of DPO to T2I models requires a huge amount of resources to collectand label large-scale datasets, e.g., millions of generated paired imagesannotated with human preferences. In addition, these human preference datasetscan get outdated quickly as the rapid improvements of T2I models lead to higherquality images. In this work, we investigate a scalable approach for collectinglarge-scale and fully synthetic datasets for DPO training. Specifically, thepreferences for paired images are generated using a pre-trained rewardfunction, eliminating the need for involving humans in the annotation process,greatly improving the dataset collection efficiency. Moreover, we demonstratethat such datasets allow averaging predictions across multiple models andcollecting ranked preferences as opposed to pairwise preferences. Furthermore,we introduce RankDPO to enhance DPO-based methods using the ranking feedback.Applying RankDPO on SDXL and SD3-Medium models with our synthetically generatedpreference dataset ``Syn-Pic'' improves both prompt-following (on benchmarkslike T2I-Compbench, GenEval, and DPG-Bench) and visual quality (through userstudies). This pipeline presents a practical and scalable solution to developbetter preference datasets to enhance the performance of text-to-image models.</description><author>Shyamgopal Karthik, Huseyin Coskun, Zeynep Akata, Sergey Tulyakov, Jian Ren, Anil Kag</author><pubDate>Wed, 23 Oct 2024 16:42:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18013v1</guid></item><item><title>VILA-U: a Unified Foundation Model Integrating Visual Understanding and Generation</title><link>http://arxiv.org/abs/2409.04429v2</link><description>VILA-U is a Unified foundation model that integrates Video, Image, Languageunderstanding and generation. Traditional visual language models (VLMs) useseparate modules for understanding and generating visual content, which canlead to misalignment and increased complexity. In contrast, VILA-U employs asingle autoregressive next-token prediction framework for both tasks,eliminating the need for additional components like diffusion models. Thisapproach not only simplifies the model but also achieves near state-of-the-artperformance in visual language understanding and generation. The success ofVILA-U is attributed to two main factors: the unified vision tower that alignsdiscrete visual tokens with textual inputs during pretraining, which enhancesvisual perception, and autoregressive image generation can achieve similarquality as diffusion models with high-quality dataset. This allows VILA-U toperform comparably to more complex models using a fully token-basedautoregressive framework.</description><author>Yecheng Wu, Zhuoyang Zhang, Junyu Chen, Haotian Tang, Dacheng Li, Yunhao Fang, Ligeng Zhu, Enze Xie, Hongxu Yin, Li Yi, Song Han, Yao Lu</author><pubDate>Wed, 23 Oct 2024 16:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.04429v2</guid></item><item><title>STAR: SocioTechnical Approach to Red Teaming Language Models</title><link>http://arxiv.org/abs/2406.11757v4</link><description>This research introduces STAR, a sociotechnical framework that improves oncurrent best practices for red teaming safety of large language models. STARmakes two key contributions: it enhances steerability by generatingparameterised instructions for human red teamers, leading to improved coverageof the risk surface. Parameterised instructions also provide more detailedinsights into model failures at no increased cost. Second, STAR improves signalquality by matching demographics to assess harms for specific groups, resultingin more sensitive annotations. STAR further employs a novel step of arbitrationto leverage diverse viewpoints and improve label reliability, treatingdisagreement not as noise but as a valuable contribution to signal quality.</description><author>Laura Weidinger, John Mellor, Bernat Guillen Pegueroles, Nahema Marchal, Ravin Kumar, Kristian Lum, Canfer Akbulut, Mark Diaz, Stevie Bergman, Mikel Rodriguez, Verena Rieser, William Isaac</author><pubDate>Wed, 23 Oct 2024 16:41:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11757v4</guid></item><item><title>JointMotion: Joint Self-Supervision for Joint Motion Prediction</title><link>http://arxiv.org/abs/2403.05489v2</link><description>We present JointMotion, a self-supervised pre-training method for jointmotion prediction in self-driving vehicles. Our method jointly optimizes ascene-level objective connecting motion and environments, and an instance-levelobjective to refine learned representations. Scene-level representations arelearned via non-contrastive similarity learning of past motion sequences andenvironment context. At the instance level, we use masked autoencoding torefine multimodal polyline representations. We complement this with an adaptivepre-training decoder that enables JointMotion to generalize across differentenvironment representations, fusion mechanisms, and dataset characteristics.Notably, our method reduces the joint final displacement error of Wayformer,HPTR, and Scene Transformer models by 3\%, 8\%, and 12\%, respectively; andenables transfer learning between the Waymo Open Motion and the Argoverse 2Motion Forecasting datasets. Code: https://github.com/kit-mrt/future-motion</description><author>Royden Wagner, Omer Sahin Tas, Marvin Klemp, Carlos Fernandez</author><pubDate>Wed, 23 Oct 2024 16:39:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05489v2</guid></item><item><title>Counter-Current Learning: A Biologically Plausible Dual Network Approach for Deep Learning</title><link>http://arxiv.org/abs/2409.19841v2</link><description>Despite its widespread use in neural networks, error backpropagation hasfaced criticism for its lack of biological plausibility, suffering from issuessuch as the backward locking problem and the weight transport problem. Theselimitations have motivated researchers to explore more biologically plausiblelearning algorithms that could potentially shed light on how biological neuralsystems adapt and learn. Inspired by the counter-current exchange mechanismsobserved in biological systems, we propose counter-current learning (CCL), abiologically plausible framework for credit assignment in neural networks. Thisframework employs a feedforward network to process input data and a feedbacknetwork to process targets, with each network enhancing the other throughanti-parallel signal propagation. By leveraging the more informative signalsfrom the bottom layer of the feedback network to guide the updates of the toplayer of the feedforward network and vice versa, CCL enables the simultaneoustransformation of source inputs to target outputs and the dynamic mutualinfluence of these transformations. Experimental results on MNIST,FashionMNIST, CIFAR10, and CIFAR100 datasets using multi-layer perceptrons andconvolutional neural networks demonstrate that CCL achieves comparableperformance to other biologically plausible algorithms while offering a morebiologically realistic learning mechanism. Furthermore, we showcase theapplicability of our approach to an autoencoder task, underscoring itspotential for unsupervised representation learning. Our work presents adirection for biologically inspired and plausible learning algorithms, offeringan alternative mechanism of learning and adaptation in neural networks.</description><author>Chia-Hsiang Kao, Bharath Hariharan</author><pubDate>Wed, 23 Oct 2024 16:27:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.19841v2</guid></item><item><title>Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning</title><link>http://arxiv.org/abs/2409.17270v2</link><description>Large Language Models (LLMs) have revolutionized natural language processing,yet they struggle with inconsistent reasoning, particularly in novel domainsand complex logical sequences. This research introduces Proof of Thought, aframework that enhances the reliability and transparency of LLM outputs. Ourapproach bridges LLM-generated ideas with formal logic verification, employinga custom interpreter to convert LLM outputs into First Order Logic constructsfor theorem prover scrutiny. Central to our method is an intermediaryJSON-based Domain-Specific Language, which by design balances precise logicalstructures with intuitive human concepts. This hybrid representation enablesboth rigorous validation and accessible human comprehension of LLM reasoningprocesses. Key contributions include a robust type system with sort managementfor enhanced logical integrity, explicit representation of rules for cleardistinction between factual and inferential knowledge, and a flexiblearchitecture that allows for easy extension to various domain-specificapplications. We demonstrate Proof of Thought's effectiveness throughbenchmarking on StrategyQA and a novel multimodal reasoning task, showingimproved performance in open-ended scenarios. By providing verifiable andinterpretable results, our technique addresses critical needs for AI systemaccountability and sets a foundation for human-in-the-loop oversight inhigh-stakes domains.</description><author>Debargha Ganguly, Srinivasan Iyengar, Vipin Chaudhary, Shivkumar Kalyanaraman</author><pubDate>Wed, 23 Oct 2024 16:27:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.17270v2</guid></item><item><title>Inferring stability properties of chaotic systems on autoencoders' latent spaces</title><link>http://arxiv.org/abs/2410.18003v1</link><description>The data-driven learning of solutions of partial differential equations canbe based on a divide-and-conquer strategy. First, the high dimensional data iscompressed to a latent space with an autoencoder; and, second, the temporaldynamics are inferred on the latent space with a form of recurrent neuralnetwork. In chaotic systems and turbulence, convolutional autoencoders and echostate networks (CAE-ESN) successfully forecast the dynamics, but little isknown about whether the stability properties can also be inferred. We show thatthe CAE-ESN model infers the invariant stability properties and the geometry ofthe tangent space in the low-dimensional manifold (i.e. the latent space)through Lyapunov exponents and covariant Lyapunov vectors. This work opens upnew opportunities for inferring the stability of high-dimensional chaoticsystems in latent spaces.</description><author>Elise Özalp, Luca Magri</author><pubDate>Wed, 23 Oct 2024 16:25:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18003v1</guid></item><item><title>Telling Stories for Common Sense Zero-Shot Action Recognition</title><link>http://arxiv.org/abs/2309.17327v2</link><description>Video understanding has long suffered from reliance on large labeleddatasets, motivating research into zero-shot learning. Recent progress inlanguage modeling presents opportunities to advance zero-shot video analysis,but constructing an effective semantic space relating action classes remainschallenging. We address this by introducing a novel dataset, Stories, whichcontains rich textual descriptions for diverse action classes extracted fromWikiHow articles. For each class, we extract multi-sentence narrativesdetailing the necessary steps, scenes, objects, and verbs that characterize theaction. This contextual data enables modeling of nuanced relationships betweenactions, paving the way for zero-shot transfer. We also propose an approachthat harnesses Stories to improve feature generation for training zero-shotclassification. Without any target dataset fine-tuning, our method achieves newstate-of-the-art on multiple benchmarks, improving top-1 accuracy by up to6.1%. We believe Stories provides a valuable resource that can catalyzeprogress in zero-shot action recognition. The textual narratives forgeconnections between seen and unseen classes, overcoming the bottleneck oflabeled data that has long impeded advancements in this exciting domain. Thedata can be found here: https://github.com/kini5gowda/Stories .</description><author>Shreyank N Gowda, Laura Sevilla-Lara</author><pubDate>Wed, 23 Oct 2024 16:25:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17327v2</guid></item><item><title>Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation</title><link>http://arxiv.org/abs/2410.18001v1</link><description>Foundation models (FMs) have achieved significant success across varioustasks, leading to research on benchmarks for reasoning abilities. However,there is a lack of studies on FMs performance in exceptional scenarios, whichwe define as out-of-distribution (OOD) reasoning tasks. This paper is the firstto address these cases, developing a novel dataset for evaluation of FMs acrossmultiple modalities, including graphic novels, calligraphy, news articles, andlyrics. It includes tasks for instance classification, character recognition,token prediction, and text generation. The paper also proposes promptengineering techniques like Chain-of-Thought (CoT) and CoT+Few-Shot to enhanceperformance. Validation of FMs using various methods revealed improvements. Thecode repository is accessible at:https://github.com/MLAI-Yonsei/ExceptionalBenchmark</description><author>Suho Kang, Jungyang Park, Joonseo Ha, SoMin Kim, JinHyeong Kim, Subeen Park, Kyungwoo Song</author><pubDate>Wed, 23 Oct 2024 16:24:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18001v1</guid></item><item><title>Generalizable Prompt Tuning for Vision-Language Models</title><link>http://arxiv.org/abs/2410.03189v2</link><description>Prompt tuning for vision-language models such as CLIP involves optimizing thetext prompts used to generate image-text pairs for specific downstream tasks.While hand-crafted or template-based prompts are generally applicable to awider range of unseen classes, they tend to perform poorly in downstream tasks(i.e., seen classes). Learnable soft prompts, on the other hand, often performwell in downstream tasks but lack generalizability. Additionally, priorresearch has predominantly concentrated on the textual modality, with very fewstudies attempting to explore the prompt's generalization potential from thevisual modality. Keeping these limitations in mind, we investigate how toprompt tuning to obtain both a competitive downstream performance andgeneralization. The study shows that by treating soft and hand-crafted promptsas dual views of the textual modality, and maximizing their mutual information,we can better ensemble task-specific and general semantic information.Moreover, to generate more expressive prompts, the study introduces aclass-wise augmentation from the visual modality, resulting in significantrobustness to a wider range of unseen classes. Extensive evaluations on severalbenchmarks report that the proposed approach achieves competitive results interms of both task-specific performance and general abilities.</description><author>Qian Zhang</author><pubDate>Wed, 23 Oct 2024 16:22:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03189v2</guid></item><item><title>AlleNoise: large-scale text classification benchmark dataset with real-world label noise</title><link>http://arxiv.org/abs/2407.10992v2</link><description>Label noise remains a challenge for training robust classification models.Most methods for mitigating label noise have been benchmarked using primarilydatasets with synthetic noise. While the need for datasets with realistic noisedistribution has partially been addressed by web-scraped benchmarks such asWebVision and Clothing1M, those benchmarks are restricted to the computervision domain. With the growing importance of Transformer-based models, it iscrucial to establish text classification benchmarks for learning with noisylabels. In this paper, we present AlleNoise, a new curated text classificationbenchmark dataset with real-world instance-dependent label noise, containingover 500,000 examples across approximately 5,600 classes, complemented with ameaningful, hierarchical taxonomy of categories. The noise distribution comesfrom actual users of a major e-commerce marketplace, so it realisticallyreflects the semantics of human mistakes. In addition to the noisy labels, weprovide human-verified clean labels, which help to get a deeper insight intothe noise distribution, unlike web-scraped datasets typically used in thefield. We demonstrate that a representative selection of established methodsfor learning with noisy labels is inadequate to handle such real-world noise.In addition, we show evidence that these algorithms do not alleviate excessivememorization. As such, with AlleNoise, we set the bar high for the developmentof label noise methods that can handle real-world label noise in textclassification tasks. The code and dataset are available for download athttps://github.com/allegro/AlleNoise.</description><author>Alicja Rączkowska, Aleksandra Osowska-Kurczab, Jacek Szczerbiński, Kalina Jasinska-Kobus, Klaudia Nazarko</author><pubDate>Wed, 23 Oct 2024 16:19:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10992v2</guid></item><item><title>Estimating the Spectral Moments of the Kernel Integral Operator from Finite Sample Matrices</title><link>http://arxiv.org/abs/2410.17998v1</link><description>Analyzing the structure of sampled features from an input data distributionis challenging when constrained by limited measurements in both the number ofinputs and features. Traditional approaches often rely on the eigenvaluespectrum of the sample covariance matrix derived from finite measurementmatrices; however, these spectra are sensitive to the size of the measurementmatrix, leading to biased insights. In this paper, we introduce a novelalgorithm that provides unbiased estimates of the spectral moments of thekernel integral operator in the limit of infinite inputs and features fromfinitely sampled measurement matrices. Our method, based upon dynamicprogramming, is efficient and capable of estimating the moments of the operatorspectrum. We demonstrate the accuracy of our estimator on radial basis function(RBF) kernels, highlighting its consistency with the theoretical spectra.Furthermore, we showcase the practical utility and robustness of our method inunderstanding the geometry of learned representations in neural networks.</description><author>Chanwoo Chun, SueYeon Chung, Daniel D. Lee</author><pubDate>Wed, 23 Oct 2024 16:12:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17998v1</guid></item><item><title>Annotator-Centric Active Learning for Subjective NLP Tasks</title><link>http://arxiv.org/abs/2404.15720v4</link><description>Active Learning (AL) addresses the high costs of collecting human annotationsby strategically annotating the most informative samples. However, forsubjective NLP tasks, incorporating a wide range of perspectives in theannotation process is crucial to capture the variability in human judgments. Weintroduce Annotator-Centric Active Learning (ACAL), which incorporates anannotator selection strategy following data sampling. Our objective istwo-fold: 1) to efficiently approximate the full diversity of human judgments,and 2) to assess model performance using annotator-centric metrics, which valueminority and majority perspectives equally. We experiment with multipleannotator selection strategies across seven subjective NLP tasks, employingboth traditional and novel, human-centered evaluation metrics. Our findingsindicate that ACAL improves data efficiency and excels in annotator-centricperformance evaluations. However, its success depends on the availability of asufficiently large and diverse pool of annotators to sample from.</description><author>Michiel van der Meer, Neele Falk, Pradeep K. Murukannaiah, Enrico Liscio</author><pubDate>Wed, 23 Oct 2024 16:12:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15720v4</guid></item><item><title>Characterization of the multiplicity of solutions for camera pose given two vertically-aligned landmarks and accelerometer</title><link>http://arxiv.org/abs/2410.17997v1</link><description>We consider the problem of recovering the position and orientation of acamera equipped with an accelerometer from sensor images of two labeledlandmarks whose positions in a coordinate system aligned in a known way withgravity are known. This a variant on the much studied P$n$P problem ofrecovering camera position and orientation from $n$ points without anygravitational data. It is proved that in three types of singular cases thereare infinitely many solutions, in another type of case there is one, and in afinal type of case there are two. A precise characterization of each type ofcase. In particular, there is always a unique solution in the practicallyinteresting case where the two landmarks are at the same altitude and thecamera is at a different altitude. This case is studied by numerical simulationand an implementation on a consumer cellphone. It is also proved that if thetwo landmarks are unlabeled, then apart from the same singular cases, there arestill always one or two solutions.</description><author>Alexander R. Pruss</author><pubDate>Wed, 23 Oct 2024 16:12:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17997v1</guid></item><item><title>Robust Variable Selection for High-dimensional Regression with Missing Data and Measurement Errors</title><link>http://arxiv.org/abs/2410.16722v2</link><description>In our paper,we focus on robust variable selection for missing data andmeasurement error.Missing data and measurement errors can lead to confusingdata distribution.We propose an exponential loss function with tuning parameterto apply to Missing and measurement errors data.By adjusting the parameter,theloss functioncan be better and more robust under various different datadistributions.We use inverse probability weighting and additivityerrormodels toaddress missing data and measurement errors.Also,we find that the Atanpunishment method works better.We used Monte Carlo simulations to assess thevalidity of robust variable selection and validated our findings with thebreast cancer dataset</description><author>Zhenhao Zhang</author><pubDate>Wed, 23 Oct 2024 16:10:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16722v2</guid></item><item><title>AI driven health recommender</title><link>http://arxiv.org/abs/2410.17991v1</link><description>As AI emerged as highest valued technology, We used that to create a webapplication that makes a patient work easier .It detects the disease name basedon the symptoms given by the patient and recommends medication for respectivedisease, precautions to take, diet to follow and workouts to do, so the diseasecan be minimized. The web application is made with clean and Realtime data byusing Machine learning as root. We used flask to create a user-friendlyplatform.</description><author>K. Vignesh, B. Pranavi, Ch. Sreenidhi</author><pubDate>Wed, 23 Oct 2024 16:08:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17991v1</guid></item><item><title>Exploring the Adversarial Robustness of CLIP for AI-generated Image Detection</title><link>http://arxiv.org/abs/2407.19553v2</link><description>In recent years, many forensic detectors have been proposed to detectAI-generated images and prevent their use for malicious purposes. Convolutionalneural networks (CNNs) have long been the dominant architecture in this fieldand have been the subject of intense study. However, recently proposedTransformer-based detectors have been shown to match or even outperformCNN-based detectors, especially in terms of generalization. In this paper, westudy the adversarial robustness of AI-generated image detectors, focusing onContrastive Language-Image Pretraining (CLIP)-based methods that rely on VisualTransformer (ViT) backbones and comparing their performance with CNN-basedmethods. We study the robustness to different adversarial attacks under avariety of conditions and analyze both numerical results and frequency-domainpatterns. CLIP-based detectors are found to be vulnerable to white-box attacksjust like CNN-based detectors. However, attacks do not easily transfer betweenCNN-based and CLIP-based methods. This is also confirmed by the differentdistribution of the adversarial noise patterns in the frequency domain.Overall, this analysis provides new insights into the properties of forensicdetectors that can help to develop more effective strategies.</description><author>Vincenzo De Rosa, Fabrizio Guillaro, Giovanni Poggi, Davide Cozzolino, Luisa Verdoliva</author><pubDate>Wed, 23 Oct 2024 16:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19553v2</guid></item><item><title>CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting</title><link>http://arxiv.org/abs/2406.02131v4</link><description>Dataset condensation is a newborn technique that generates a small datasetthat can be used in training deep neural networks to lower training costs. Theobjective of dataset condensation is to ensure that the model trained with thesynthetic dataset can perform comparably to the model trained with fulldatasets. However, existing methods predominantly concentrate on classificationtasks, posing challenges in their adaptation to time series forecasting(TS-forecasting). This challenge arises from disparities in the evaluation ofsynthetic data. In classification, the synthetic data is consideredwell-distilled if the model trained with the full dataset and the model trainedwith the synthetic dataset yield identical labels for the same input,regardless of variations in output logits distribution. Conversely, inTS-forecasting, the effectiveness of synthetic data distillation is determinedby the distance between predictions of the two models. The synthetic data isdeemed well-distilled only when all data points within the predictions aresimilar. Consequently, TS-forecasting has a more rigorous evaluationmethodology compared to classification. To mitigate this gap, we theoreticallyanalyze the optimization objective of dataset condensation for TS-forecastingand propose a new one-line plugin of dataset condensation designated as DatasetCondensation for Time Series Forecasting (CondTSF) based on our analysis.Plugging CondTSF into previous dataset condensation methods facilitates areduction in the distance between the predictions of the model trained with thefull dataset and the model trained with the synthetic dataset, therebyenhancing performance. We conduct extensive experiments on eight commonly usedtime series datasets. CondTSF consistently improves the performance of allprevious dataset condensation methods across all datasets, particularly at lowcondensing ratios.</description><author>Jianrong Ding, Zhanyu Liu, Guanjie Zheng, Haiming Jin, Linghe Kong</author><pubDate>Wed, 23 Oct 2024 16:05:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02131v4</guid></item><item><title>Learning a quantum computer's capability</title><link>http://arxiv.org/abs/2304.10650v2</link><description>Accurately predicting a quantum computer's capability -- which circuits itcan run and how well it can run them -- is a foundational goal of quantumcharacterization and benchmarking. As modern quantum computers becomeincreasingly hard to simulate, we must develop accurate and scalable predictivecapability models to help researchers and stakeholders decide which quantumcomputers to build and use. In this work, we propose a hardware-agnostic methodto efficiently construct scalable predictive models of a quantum computer'scapability for almost any class of circuits, and demonstrate our method usingconvolutional neural networks (CNNs). Our CNN-based approach works byefficiently representing a circuit as a three-dimensional tensor and then usinga CNN to predict its success rate. Our CNN capability models obtainapproximately a $1\%$ average absolute prediction error when modelingprocessors experiencing both Markovian and non-Markovian stochastic Paulierrors. We also apply our CNNs to model the capabilities of cloud-accessquantum computing systems, obtaining moderate prediction accuracy (averageabsolute error around $2-5\%$), and we highlight the challenges to buildingbetter neural network capability models.</description><author>Daniel Hothem, Kevin Young, Tommie Catanach, Timothy Proctor</author><pubDate>Wed, 23 Oct 2024 16:03:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10650v2</guid></item><item><title>A Pipeline for Segmenting and Structuring RGB-D Data for Robotics Applications</title><link>http://arxiv.org/abs/2410.17988v1</link><description>We introduce a novel pipeline for segmenting and structuring color and depth(RGB-D) data. Existing processing pipelines for RGB-D data have focused onextracting geometric information alone. This approach precludes the developmentof more advanced robotic navigation and manipulation algorithms, which benefitfrom a semantic understanding of their environment. Our pipeline can segmentRGB-D data into accurate semantic masks. These masks are then used to fuse rawcaptured point clouds into semantically separated point clouds. We store thisinformation using the Universal Scene Description (USD) file format, a formatsuitable for easy querying by downstream robotics algorithms, human-friendlyvisualization, and robotics simulation.</description><author>Zhiwu Zheng, Lauren Mentzer, Berk Iskender, Michael Price, Colm Prendergast, Audren Cloitre</author><pubDate>Wed, 23 Oct 2024 16:01:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17988v1</guid></item><item><title>Federated Transformer: Multi-Party Vertical Federated Learning on Practical Fuzzily Linked Data</title><link>http://arxiv.org/abs/2410.17986v1</link><description>Federated Learning (FL) is an evolving paradigm that enables multiple partiesto collaboratively train models without sharing raw data. Among its variants,Vertical Federated Learning (VFL) is particularly relevant in real-world,cross-organizational collaborations, where distinct features of a sharedinstance group are contributed by different parties. In these scenarios,parties are often linked using fuzzy identifiers, leading to a common practicetermed as multi-party fuzzy VFL. Existing models generally address eithermulti-party VFL or fuzzy VFL between two parties. Extending these models topractical multi-party fuzzy VFL typically results in significant performancedegradation and increased costs for maintaining privacy. To overcome theselimitations, we introduce the Federated Transformer (FeT), a novel frameworkthat supports multi-party VFL with fuzzy identifiers. FeT innovatively encodesthese identifiers into data representations and employs a transformerarchitecture distributed across different parties, incorporating three newtechniques to enhance performance. Furthermore, we have developed a multi-partyprivacy framework for VFL that integrates differential privacy with securemulti-party computation, effectively protecting local representations whileminimizing associated utility costs. Our experiments demonstrate that the FeTsurpasses the baseline models by up to 46\% in terms of accuracy when scaled to50 parties. Additionally, in two-party fuzzy VFL settings, FeT also showsimproved performance and privacy over cutting-edge VFL models.</description><author>Zhaomin Wu, Junyi Hou, Yiqun Diao, Bingsheng He</author><pubDate>Wed, 23 Oct 2024 16:00:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17986v1</guid></item><item><title>Robust Two-View Geometry Estimation with Implicit Differentiation</title><link>http://arxiv.org/abs/2410.17983v1</link><description>We present a novel two-view geometry estimation framework which is based on adifferentiable robust loss function fitting. We propose to treat the robustfundamental matrix estimation as an implicit layer, which allows us to avoidbackpropagation through time and significantly improves the numericalstability. To take full advantage of the information from the feature matchingstage we incorporate learnable weights that depend on the matching confidences.In this way our solution brings together feature extraction, matching andtwo-view geometry estimation in a unified end-to-end trainable pipeline. Weevaluate our approach on the camera pose estimation task in both outdoor andindoor scenarios. The experiments on several datasets show that the proposedmethod outperforms both classic and learning-based state-of-the-art methods bya large margin. The project webpage is available at:https://github.com/VladPyatov/ihls</description><author>Vladislav Pyatov, Iaroslav Koshelev, Stamatis Lefkimmiatis</author><pubDate>Wed, 23 Oct 2024 15:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17983v1</guid></item><item><title>Stick-breaking Attention</title><link>http://arxiv.org/abs/2410.17980v1</link><description>The self-attention mechanism traditionally relies on the softmax operator,necessitating positional embeddings like RoPE, or position biases to accountfor token order. But current methods using still face length generalisationchallenges. We propose an alternative attention mechanism based on thestick-breaking process: For each token before the current, we determine a breakpoint $\beta_{i,j}$, which represents the proportion of the remaining stick toallocate to the current token. We repeat the process until the stick is fullyallocated, resulting in a sequence of attention weights. This process naturallyincorporates recency bias, which has linguistic motivations for grammar parsing(Shen et. al., 2017). We study the implications of replacing the conventionalsoftmax-based attention mechanism with stick-breaking attention. We thendiscuss implementation of numerically stable stick-breaking attention and adaptFlash Attention to accommodate this mechanism. When used as a drop-inreplacement for current softmax+RoPE attention systems, we find thatstick-breaking attention performs competitively with current methods on lengthgeneralisation and downstream tasks. Stick-breaking also performs well atlength generalisation, allowing a model trained with $2^{11}$ context window toperform well at $2^{14}$ with perplexity improvements.</description><author>Shawn Tan, Yikang Shen, Songlin Yang, Aaron Courville, Rameswar Panda</author><pubDate>Wed, 23 Oct 2024 15:51:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17980v1</guid></item><item><title>Federated Class-Incremental Learning with Hierarchical Generative Prototypes</title><link>http://arxiv.org/abs/2406.02447v3</link><description>Federated Learning (FL) aims at unburdening the training of deep models bydistributing computation across multiple devices (clients) while safeguardingdata privacy. On top of that, Federated Continual Learning (FCL) also accountsfor data distribution evolving over time, mirroring the dynamic nature ofreal-world environments. While previous studies have identified CatastrophicForgetting and Client Drift as primary causes of performance degradation inFCL, we shed light on the importance of Incremental Bias and Federated Bias,which cause models to prioritize classes that are recently introduced orlocally predominant, respectively. Our proposal constrains both biases in thelast layer by efficiently finetuning a pre-trained backbone using learnableprompts, resulting in clients that produce less biased representations and morebiased classifiers. Therefore, instead of solely relying on parameteraggregation, we leverage generative prototypes to effectively balance thepredictions of the global model. Our method significantly improves the currentState Of The Art, providing an average increase of +7.8% in accuracy. Code toreproduce the results is provided in the suppl. material.</description><author>Riccardo Salami, Pietro Buzzega, Matteo Mosconi, Mattia Verasani, Simone Calderara</author><pubDate>Wed, 23 Oct 2024 15:48:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02447v3</guid></item><item><title>Do Large Language Models Truly Grasp Mathematics? An Empirical Exploration</title><link>http://arxiv.org/abs/2410.14979v2</link><description>Despite their proficiency in math tasks, the mechanisms underlying LLMs'mathematical reasoning abilities remain a subject of debate. Recent studiessuggest that chain-of-thought (CoT) prompts can bolster mathematical reasoningby encouraging LLMs to employ human-like logical reasoning (System 2), enablingthem to excel on the Cognitive Reflection Test (CRT). To assess whether LLMsgenuinely possess System 2-like logical reasoning, we introduced targetedmodifications to CRT problems. Our findings reveal that, despite the use of CoTprompts, mainstream LLMs, including the latest o1-preview model, continue toexhibit a significant error rate. Further analysis indicates that theypredominantly rely on System 1-like intuitive reasoning and pattern matchingderived from training data, rather than demonstrating mastery of mathematicalthinking. This discovery challenges the prevailing notion that LLMs possessgenuine logical reasoning abilities and that CoT can enhance them.Consequently, this work may temper overly optimistic projections regardingLLMs' advancement toward artificial general intelligence.</description><author>Wei Xie, Shuoyoucheng Ma, Zhenhua Wang, Enze Wang, Baosheng Wang, Jinshu Su</author><pubDate>Wed, 23 Oct 2024 15:43:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14979v2</guid></item><item><title>metasnf: Meta Clustering with Similarity Network Fusion in R</title><link>http://arxiv.org/abs/2410.17976v1</link><description>metasnf is an R package that enables users to apply meta clustering, a methodfor efficiently searching a broad space of cluster solutions by clustering thesolutions themselves, to clustering workflows based on similarity networkfusion (SNF). SNF is a multi-modal data integration algorithm commonly used forbiomedical subtype discovery. The package also contains functions to assistwith cluster visualization, characterization, and validation. This package canhelp researchers identify SNF-derived cluster solutions that are guided bycontext-specific utility over context-agnostic measures of quality.</description><author>Prashanth S Velayudhan, Xiaoqiao Xu, Prajkta Kallurkar, Ana Patricia Balbon, Maria T Secara, Adam Taback, Denise Sabac, Nicholas Chan, Shihao Ma, Bo Wang, Daniel Felsky, Stephanie H Ameis, Brian Cox, Colin Hawco, Lauren Erdman, Anne L Wheeler</author><pubDate>Wed, 23 Oct 2024 15:39:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17976v1</guid></item><item><title>Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages</title><link>http://arxiv.org/abs/2410.17973v1</link><description>This exploratory study investigates the potential of multilingual AutomaticPost-Editing (APE) systems to enhance the quality of machine translations forlow-resource Indo-Aryan languages. Focusing on two closely related languagepairs, English-Marathi and English-Hindi, we exploit the linguisticsimilarities to develop a robust multilingual APE model. To facilitatecross-linguistic transfer, we generate synthetic Hindi-Marathi andMarathi-Hindi APE triplets. Additionally, we incorporate a Quality Estimation(QE)-APE multi-task learning framework. While the experimental resultsunderline the complementary nature of APE and QE, we also observe that QE-APEmultitask learning facilitates effective domain adaptation. Our experimentsdemonstrate that the multilingual APE models outperform their correspondingEnglish-Hindi and English-Marathi single-pair models by $2.5$ and $2.39$ TERpoints, respectively, with further notable improvements over the multilingualAPE model observed through multi-task learning ($+1.29$ and $+1.44$ TERpoints), data augmentation ($+0.53$ and $+0.45$ TER points) and domainadaptation ($+0.35$ and $+0.45$ TER points). We release the synthetic data,code, and models accrued during this study publicly athttps://github.com/cfiltnlp/Multilingual-APE.</description><author>Sourabh Deoghare, Diptesh Kanojia, Pushpak Bhattacharyya</author><pubDate>Wed, 23 Oct 2024 15:37:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17973v1</guid></item><item><title>Dependency Graph Parsing as Sequence Labeling</title><link>http://arxiv.org/abs/2410.17972v1</link><description>Various linearizations have been proposed to cast syntactic dependencyparsing as sequence labeling. However, these approaches do not support morecomplex graph-based representations, such as semantic dependencies or enhanceduniversal dependencies, as they cannot handle reentrancy or cycles. Byextending them, we define a range of unbounded and bounded linearizations thatcan be used to cast graph parsing as a tagging task, enlarging the toolbox ofproblems that can be solved under this paradigm. Experimental results onsemantic dependency and enhanced UD parsing show that with a good choice ofencoding, sequence-labeling dependency graph parsers combine high efficiencywith accuracies close to the state of the art, in spite of their simplicity.</description><author>Ana Ezquerro, David Vilares, Carlos Gómez-Rodríguez</author><pubDate>Wed, 23 Oct 2024 15:37:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17972v1</guid></item><item><title>Dynamic Spectrum Access for Ambient Backscatter Communication-assisted D2D Systems with Quantum Reinforcement Learning</title><link>http://arxiv.org/abs/2410.17971v1</link><description>Spectrum access is an essential problem in device-to-device (D2D)communications. However, with the recent growth in the number of mobiledevices, the wireless spectrum is becoming scarce, resulting in low spectralefficiency for D2D communications. To address this problem, this paper aims tointegrate the ambient backscatter communication technology into D2D devices toallow them to backscatter ambient RF signals to transmit their data when theshared spectrum is occupied by mobile users. To obtain the optimal spectrumaccess policy, i.e., stay idle or access the shared spectrum and perform activetransmissions or backscattering ambient RF signals for transmissions, tomaximize the average throughput for D2D users, deep reinforcement learning(DRL) can be adopted. However, DRL-based solutions may require long trainingtime due to the curse of dimensionality issue as well as complex deep neuralnetwork architectures. For that, we develop a novel quantum reinforcementlearning (RL) algorithm that can achieve a faster convergence rate with fewertraining parameters compared to DRL thanks to the quantum superposition andquantum entanglement principles. Specifically, instead of using conventionaldeep neural networks, the proposed quantum RL algorithm uses a parametrizedquantum circuit to approximate an optimal policy. Extensive simulations thendemonstrate that the proposed solution not only can significantly improve theaverage throughput of D2D devices when the shared spectrum is busy but also canachieve much better performance in terms of convergence rate and learningcomplexity compared to existing DRL-based methods.</description><author>Nguyen Van Huynh, Bolun Zhang, Dinh-Hieu Tran, Dinh Thai Hoang, Diep N. Nguyen, Gan Zheng, Dusit Niyato, Quoc-Viet Pham</author><pubDate>Wed, 23 Oct 2024 15:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17971v1</guid></item><item><title>Optical Generative Models</title><link>http://arxiv.org/abs/2410.17970v1</link><description>Generative models cover various application areas, including image, video andmusic synthesis, natural language processing, and molecular design, among manyothers. As digital generative models become larger, scalable inference in afast and energy-efficient manner becomes a challenge. Here, we present opticalgenerative models inspired by diffusion models, where a shallow and fastdigital encoder first maps random noise into phase patterns that serve asoptical generative seeds for a desired data distribution; a jointly-trainedfree-space-based reconfigurable decoder all-optically processes thesegenerative seeds to create novel images (never seen before) following thetarget data distribution. Except for the illumination power and the random seedgeneration through a shallow encoder, these optical generative models do notconsume computing power during the synthesis of novel images. We report theoptical generation of monochrome and multi-color novel images of handwrittendigits, fashion products, butterflies, and human faces, following the datadistributions of MNIST, Fashion MNIST, Butterflies-100, and Celeb-A datasets,respectively, achieving an overall performance comparable to digital neuralnetwork-based generative models. To experimentally demonstrate opticalgenerative models, we used visible light to generate, in a snapshot, novelimages of handwritten digits and fashion products. These optical generativemodels might pave the way for energy-efficient, scalable and rapid inferencetasks, further exploiting the potentials of optics and photonics for artificialintelligence-generated content.</description><author>Shiqi Chen, Yuhang Li, Hanlong Chen, Aydogan Ozcan</author><pubDate>Wed, 23 Oct 2024 15:36:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17970v1</guid></item><item><title>On the potential of Optimal Transport in Geospatial Data Science</title><link>http://arxiv.org/abs/2410.11709v2</link><description>Prediction problems in geographic information science and transportation areoften motivated by the possibility to enhance operational efficiency andthereby reduce emissions. Examples range from predicting car sharing demand forrelocation planning to forecasting traffic congestion for navigation purposes.However, conventional accuracy metrics ignore the spatial distribution of theerrors, despite its relevance for operations. Here, we put forward a spatiallyaware evaluation metric and loss function based on Optimal Transport (OT). Ourframework leverages partial OT and can minimize relocation costs in any spatialprediction problem. We showcase the advantages of OT-based evaluation overconventional metrics and further demonstrate the application of an OT lossfunction for improving forecasts of bike sharing demand and charging stationoccupancy. Thus, our framework not only aligns with operational considerations,but also signifies a step forward in refining predictions within geospatialapplications. All code is available at https://github.com/mie-lab/geospatialOT.</description><author>Nina Wiedemann, Théo Uscidda, Martin Raubal</author><pubDate>Wed, 23 Oct 2024 15:35:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11709v2</guid></item><item><title>POMDP-Driven Cognitive Massive MIMO Radar: Joint Target Detection-Tracking In Unknown Disturbances</title><link>http://arxiv.org/abs/2410.17967v1</link><description>The joint detection and tracking of a moving target embedded in an unknowndisturbance represents a key feature that motivates the development of thecognitive radar paradigm. Building upon recent advancements in robust targetdetection with multiple-input multiple-output (MIMO) radars, this work exploresthe application of a Partially Observable Markov Decision Process (POMDP)framework to enhance the tracking and detection tasks in a statisticallyunknown environment. In the POMDP setup, the radar system is considered as anintelligent agent that continuously senses the surrounding environment,optimizing its actions to maximize the probability of detection $(P_D)$ andimprove the target position and velocity estimation, all this while keeping aconstant probability of false alarm $(P_{FA})$. The proposed approach employsan online algorithm that does not require any apriori knowledge of the noisestatistics, and it relies on a much more general observation model than thetraditional range-azimuth-elevation model employed by conventional trackingalgorithms. Simulation results clearly show substantial performance improvementof the POMDP-based algorithm compared to the State-Action-Reward-State-Action(SARSA)-based one that has been recently investigated in the context of massiveMIMO (MMIMO) radar systems.</description><author>Imad Bouhou, Stefano Fortunati, Leila Gharsalli, Alexandre Renaux</author><pubDate>Wed, 23 Oct 2024 15:34:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17967v1</guid></item><item><title>A Wavelet Diffusion GAN for Image Super-Resolution</title><link>http://arxiv.org/abs/2410.17966v1</link><description>In recent years, diffusion models have emerged as a superior alternative togenerative adversarial networks (GANs) for high-fidelity image generation, withwide applications in text-to-image generation, image-to-image translation, andsuper-resolution. However, their real-time feasibility is hindered by slowtraining and inference speeds. This study addresses this challenge by proposinga wavelet-based conditional Diffusion GAN scheme for Single-ImageSuper-Resolution (SISR). Our approach utilizes the diffusion GAN paradigm toreduce the timesteps required by the reverse diffusion process and the DiscreteWavelet Transform (DWT) to achieve dimensionality reduction, decreasingtraining and inference times significantly. The results of an experimentalvalidation on the CelebA-HQ dataset confirm the effectiveness of our proposedscheme. Our approach outperforms other state-of-the-art methodologiessuccessfully ensuring high-fidelity output while overcoming inherent drawbacksassociated with diffusion models in time-sensitive applications.</description><author>Lorenzo Aloisi, Luigi Sigillo, Aurelio Uncini, Danilo Comminiello</author><pubDate>Wed, 23 Oct 2024 15:34:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17966v1</guid></item><item><title>Leveraging Hallucinations to Reduce Manual Prompt Dependency in Promptable Segmentation</title><link>http://arxiv.org/abs/2408.15205v2</link><description>Promptable segmentation typically requires instance-specific manual promptsto guide the segmentation of each desired object. To minimize such a need,task-generic promptable segmentation has been introduced, which employs asingle task-generic prompt to segment various images of different objects inthe same task. Current methods use Multimodal Large Language Models (MLLMs) toreason detailed instance-specific prompts from a task-generic prompt forimproving segmentation accuracy. The effectiveness of this segmentation heavilydepends on the precision of these derived prompts. However, MLLMs often sufferhallucinations during reasoning, resulting in inaccurate prompting. Whileexisting methods focus on eliminating hallucinations to improve a model, weargue that MLLM hallucinations can reveal valuable contextual insights whenleveraged correctly, as they represent pre-trained large-scale knowledge beyondindividual images. In this paper, we utilize hallucinations to minetask-related information from images and verify its accuracy for enhancingprecision of the generated prompts. Specifically, we introduce an iterativePrompt-Mask Cycle generation framework (ProMaC) with a prompt generator and amask generator.The prompt generator uses a multi-scale chain of thoughtprompting, initially exploring hallucinations for extracting extendedcontextual knowledge on a test image.These hallucinations are then reduced toformulate precise instance-specific prompts, directing the mask generator toproduce masks that are consistent with task semantics by mask semanticalignment. The generated masks iteratively induce the prompt generator to focusmore on task-relevant image areas and reduce irrelevant hallucinations,resulting jointly in better prompts and masks. Experiments on 5 benchmarksdemonstrate the effectiveness of ProMaC. Code given inhttps://lwpyh.github.io/ProMaC/.</description><author>Jian Hu, Jiayi Lin, Junchi Yan, Shaogang Gong</author><pubDate>Wed, 23 Oct 2024 15:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15205v2</guid></item><item><title>Quantum Architecture Search with Unsupervised Representation Learning</title><link>http://arxiv.org/abs/2401.11576v3</link><description>Unsupervised representation learning presents new opportunities for advancingQuantum Architecture Search (QAS) on Noisy Intermediate-Scale Quantum (NISQ)devices. QAS is designed to optimize quantum circuits for Variational QuantumAlgorithms (VQAs). Most QAS algorithms tightly couple the search space andsearch algorithm, typically requiring the evaluation of numerous quantumcircuits, resulting in high computational costs and limiting scalability tolarger quantum circuits. Predictor-based QAS algorithms mitigate this issue byestimating circuit performance based on structure or embedding. However, thesemethods often demand time-intensive labeling to optimize gate parameters acrossmany circuits, which is crucial for training accurate predictors. Inspired bythe classical neural architecture search algorithm Arch2vec, we investigate thepotential of unsupervised representation learning for QAS without relying onpredictors. Our framework decouples unsupervised architecture representationlearning from the search process, enabling the learned representations to beapplied across various downstream tasks. Additionally, it integrates animproved quantum circuit graph encoding scheme, addressing the limitations ofexisting representations and enhancing search efficiency. This predictor-freeapproach removes the need for large labeled datasets. During the search, weemploy REINFORCE and Bayesian Optimization to explore the latent representationspace and compare their performance against baseline methods. Our resultsdemonstrate that the framework efficiently identifies high-performing quantumcircuits with fewer search iterations.</description><author>Yize Sun, Zixin Wu, Yunpu Ma, Volker Tresp</author><pubDate>Wed, 23 Oct 2024 15:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11576v3</guid></item><item><title>A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024</title><link>http://arxiv.org/abs/2410.17963v1</link><description>The eRisk laboratory aims to address issues related to early risk detectionon the Web. In this year's edition, three tasks were proposed, where Task 2 wasabout early detection of signs of anorexia. Early risk detection is a problemwhere precision and speed are two crucial objectives. Our research group solvedTask 2 by defining a CPI+DMC approach, addressing both objectivesindependently, and a time-aware approach, where precision and speed areconsidered a combined single-objective. We implemented the last approach byexplicitly integrating time during the learning process, considering theERDE{\theta} metric as the training objective. It also allowed us toincorporate temporal metrics to validate and select the optimal models. Weachieved outstanding results for the ERDE50 metric and ranking-based metrics,demonstrating consistency in solving ERD problems.</description><author>Horacio Thompson, Marcelo Errecalde</author><pubDate>Wed, 23 Oct 2024 15:30:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17963v1</guid></item><item><title>Closed-form merging of parameter-efficient modules for Federated Continual Learning</title><link>http://arxiv.org/abs/2410.17961v1</link><description>Model merging has emerged as a crucial technique in Deep Learning, enablingthe integration of multiple models into a unified system while preservingperformance and scalability. In this respect, the compositional properties oflow-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simpleaveraging LoRA modules yields a single model that mostly integrates thecapabilities of all individual modules. Building on LoRA, we take a stepfurther by imposing that the merged model matches the responses of all learnedmodules. Solving this objective in closed form yields an indeterminate systemwith A and B as unknown variables, indicating the existence of infinitely manyclosed-form solutions. To address this challenge, we introduce LoRM, analternating optimization strategy that trains one LoRA matrix at a time. Thisallows solving for each unknown variable individually, thus finding a uniquesolution. We apply our proposed methodology to Federated Class-IncrementalLearning (FCIL), ensuring alignment of model responses both between clients andacross tasks. Our method demonstrates state-of-the-art performance across arange of FCIL scenarios.</description><author>Riccardo Salami, Pietro Buzzega, Matteo Mosconi, Jacopo Bonato, Luigi Sabetta, Simone Calderara</author><pubDate>Wed, 23 Oct 2024 15:30:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17961v1</guid></item><item><title>MOTIVE: A Drug-Target Interaction Graph For Inductive Link Prediction</title><link>http://arxiv.org/abs/2406.08649v2</link><description>Drug-target interaction (DTI) prediction is crucial for identifying newtherapeutics and detecting mechanisms of action. While structure-based methodsaccurately model physical interactions between a drug and its protein target,cell-based assays such as Cell Painting can better capture complex DTIinteractions. This paper introduces MOTIVE, a Morphological cOmpound TargetInteraction Graph dataset comprising Cell Painting features for 11,000 genesand 3,600 compounds, along with their relationships extracted from sevenpublicly available databases. We provide random, cold-source (new drugs), andcold-target (new genes) data splits to enable rigorous evaluation underrealistic use cases. Our benchmark results show that graph neural networks thatuse Cell Painting features consistently outperform those that learn from graphstructure alone, feature-based models, and topological heuristics. MOTIVEaccelerates both graph ML research and drug discovery by promoting thedevelopment of more reliable DTI prediction models. MOTIVE resources areavailable at https://github.com/carpenter-singh-lab/motive.</description><author>John Arevalo, Ellen Su, Anne E Carpenter, Shantanu Singh</author><pubDate>Wed, 23 Oct 2024 15:29:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08649v2</guid></item><item><title>Bounded KRnet and its applications to density estimation and approximation</title><link>http://arxiv.org/abs/2305.09063v3</link><description>In this paper, we develop an invertible mapping, called B-KRnet, on a boundeddomain and apply it to density estimation/approximation for data or thesolutions of PDEs such as the Fokker-Planck equation and the Keller-Segelequation. Similar to KRnet, the structure of B-KRnet adapts thepseudo-triangular structure into a normalizing flow model. The main differencebetween B-KRnet and KRnet is that B-KRnet is defined on a hypercube while KRnetis defined on the whole space, in other words, a new mechanism is introduced inB-KRnet to maintain the exact invertibility. Using B-KRnet as a transport map,we obtain an explicit probability density function (PDF) model that correspondsto the pushforward of a prior (uniform) distribution on the hypercube. It canbe directly applied to density estimation when only data are available. Bycoupling KRnet and B-KRnet, we define a deep generative model on ahigh-dimensional domain where some dimensions are bounded and other dimensionsare unbounded. A typical case is the solution of the stationary kineticFokker-Planck equation, which is a PDF of position and momentum. Based onB-KRnet, we develop an adaptive learning approach to approximate partialdifferential equations whose solutions are PDFs or can be treated as PDFs. Avariety of numerical experiments is presented to demonstrate the effectivenessof B-KRnet.</description><author>Li Zeng, Xiaoliang Wan, Tao Zhou</author><pubDate>Wed, 23 Oct 2024 15:28:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09063v3</guid></item><item><title>Zeitenwenden: Detecting changes in the German political discourse</title><link>http://arxiv.org/abs/2410.17960v1</link><description>From a monarchy to a democracy, to a dictatorship and back to a democracy --the German political landscape has been constantly changing ever since thefirst German national state was formed in 1871. After World War II, the FederalRepublic of Germany was formed in 1949. Since then every plenary session of theGerman Bundestag was logged and even has been digitized over the course of thelast few years. We analyze these texts using a time series variant of the topicmodel LDA to investigate which events had a lasting effect on the politicaldiscourse and how the political topics changed over time. This allows us todetect changes in word frequency (and thus key discussion points) in politicaldiscourse.</description><author>Kai-Robin Lange, Jonas Rieger, Niklas Benner, Carsten Jentsch</author><pubDate>Wed, 23 Oct 2024 15:28:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17960v1</guid></item><item><title>StockGPT: A GenAI Model for Stock Prediction and Trading</title><link>http://arxiv.org/abs/2404.05101v3</link><description>This paper introduces StockGPT, an autoregressive ``number'' model trainedand tested on 70 million daily U.S.\ stock returns over nearly 100 years.Treating each return series as a sequence of tokens, StockGPT automaticallylearns the hidden patterns predictive of future returns via its attentionmechanism. On a held-out test sample from 2001 to 2023, daily and monthlyrebalanced long-short portfolios formed from StockGPT predictions yield strongperformance. The StockGPT-based portfolios span momentum and long-/short-termreversals, eliminating the need for manually crafted price-based strategies,and yield highly significant alphas against leading stock market factors,suggesting a novel AI pricing effect. This highlights the immense promise ofgenerative AI in surpassing human in making complex financial investmentdecisions.</description><author>Dat Mai</author><pubDate>Wed, 23 Oct 2024 15:28:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05101v3</guid></item><item><title>Linear Adversarial Concept Erasure</title><link>http://arxiv.org/abs/2201.12091v5</link><description>Modern neural models trained on textual data rely on pre-trainedrepresentations that emerge without direct supervision. As theserepresentations are increasingly being used in real-world applications, theinability to \emph{control} their content becomes an increasingly importantproblem. We formulate the problem of identifying and erasing a linear subspacethat corresponds to a given concept, in order to prevent linear predictors fromrecovering the concept. We model this problem as a constrained, linear maximingame, and show that existing solutions are generally not optimal for this task.We derive a closed-form solution for certain objectives, and propose a convexrelaxation, \method, that works well for others. When evaluated in the contextof binary gender removal, the method recovers a low-dimensional subspace whoseremoval mitigates bias by intrinsic and extrinsic evaluation. We show that themethod is highly expressive, effectively mitigating bias in deep nonlinearclassifiers while maintaining tractability and interpretability.</description><author>Shauli Ravfogel, Michael Twiton, Yoav Goldberg, Ryan Cotterell</author><pubDate>Wed, 23 Oct 2024 15:28:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.12091v5</guid></item><item><title>Medical Imaging Complexity and its Effects on GAN Performance</title><link>http://arxiv.org/abs/2410.17959v1</link><description>The proliferation of machine learning models in diverse clinical applicationshas led to a growing need for high-fidelity, medical image training data. Suchdata is often scarce due to cost constraints and privacy concerns. Alleviatingthis burden, medical image synthesis via generative adversarial networks (GANs)emerged as a powerful method for synthetically generating photo-realisticimages based on existing sets of real medical images. However, the exact imageset size required to efficiently train such a GAN is unclear. In this work, weexperimentally establish benchmarks that measure the relationship between asample dataset size and the fidelity of the generated images, given thedataset's distribution of image complexities. We analyze statistical metricsbased on delentropy, an image complexity measure rooted in Shannon's entropy ininformation theory. For our pipeline, we conduct experiments with twostate-of-the-art GANs, StyleGAN 3 and SPADE-GAN, trained on multiple medicalimaging datasets with variable sample sizes. Across both GANs, generalperformance improved with increasing training set size but suffered withincreasing complexity.</description><author>William Cagas, Chan Ko, Blake Hsiao, Shryuk Grandhi, Rishi Bhattacharya, Kevin Zhu, Michael Lam</author><pubDate>Wed, 23 Oct 2024 15:28:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17959v1</guid></item><item><title>MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers</title><link>http://arxiv.org/abs/2410.17957v1</link><description>In this paper, we propose MCUBERT to enable language models like BERT on tinymicrocontroller units (MCUs) through network and scheduling co-optimization. Weobserve the embedding table contributes to the major storage bottleneck fortiny BERT models. Hence, at the network level, we propose an MCU-awaretwo-stage neural architecture search algorithm based on clustered low-rankapproximation for embedding compression. To reduce the inference memoryrequirements, we further propose a novel fine-grained MCU-friendly schedulingstrategy. Through careful computation tiling and re-ordering as well as kerneldesign, we drastically increase the input sequence lengths supported on MCUswithout any latency or accuracy penalty. MCUBERT reduces the parameter size ofBERT-tiny and BERT-mini by 5.7$\times$ and 3.0$\times$ and the execution memoryby 3.5$\times$ and 4.3$\times$, respectively. MCUBERT also achieves 1.5$\times$latency reduction. For the first time, MCUBERT enables lightweight BERT modelson commodity MCUs and processing more than 512 tokens with less than 256KB ofmemory.</description><author>Zebin Yang, Renze Chen, Taiqiang Wu, Ngai Wong, Yun Liang, Runsheng Wang, Ru Huang, Meng Li</author><pubDate>Wed, 23 Oct 2024 15:27:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17957v1</guid></item><item><title>ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference</title><link>http://arxiv.org/abs/2410.17954v1</link><description>Sparse Mixture of Experts (MoE) models, while outperforming dense LargeLanguage Models (LLMs) in terms of performance, face significant deploymentchallenges during inference due to their high memory demands. Existingoffloading techniques, which involve swapping activated and idle expertsbetween the GPU and CPU, often suffer from rigid expert caching mechanisms.These mechanisms fail to adapt to dynamic routing, leading to inefficient cacheutilization, or incur prohibitive costs for prediction training. To tacklethese inference-specific challenges, we introduce ExpertFlow, a comprehensivesystem specifically designed to enhance inference efficiency by accommodatingflexible routing and enabling efficient expert scheduling between CPU and GPU.This reduces overhead and boosts system performance. Central to our approach isa predictive routing path-based offloading mechanism that utilizes alightweight predictor to accurately forecast routing paths before computationbegins. This proactive strategy allows for real-time error correction in expertcaching, significantly increasing cache hit ratios and reducing the frequencyof expert transfers, thereby minimizing I/O overhead. Additionally, weimplement a dynamic token scheduling strategy that optimizes MoE inference byrearranging input tokens across different batches. This method not only reducesthe number of activated experts per batch but also improves computationalefficiency. Our extensive experiments demonstrate that ExpertFlow achieves upto 93.72\% GPU memory savings and enhances inference speed by 2 to 10 timescompared to baseline methods, highlighting its effectiveness and utility as arobust solution for resource-constrained inference scenarios.</description><author>Xin He, Shunkang Zhang, Yuxin Wang, Haiyan Yin, Zihao Zeng, Shaohuai Shi, Zhenheng Tang, Xiaowen Chu, Ivor Tsang, Ong Yew Soon</author><pubDate>Wed, 23 Oct 2024 15:24:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17954v1</guid></item><item><title>SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains</title><link>http://arxiv.org/abs/2410.17952v1</link><description>Retrieval-augmented generation (RAG) enhances the question-answering (QA)abilities of large language models (LLMs) by integrating external knowledge.However, adapting general-purpose RAG systems to specialized fields such asscience and medicine poses unique challenges due to distribution shifts andlimited access to domain-specific data. To tackle this, we propose SimRAG, aself-training approach that equips the LLM with joint capabilities of questionanswering and question generation for domain adaptation. Our method firstfine-tunes the LLM on instruction-following, question-answering, andsearch-related data. Then, it prompts the same LLM to generate diversedomain-relevant questions from unlabeled corpora, with an additional filteringstrategy to retain high-quality synthetic examples. By leveraging thesesynthetic examples, the LLM can improve their performance on domain-specificRAG tasks. Experiments on 11 datasets, spanning two backbone sizes and threedomains, demonstrate that SimRAG outperforms baselines by 1.2\%--8.6\%.</description><author>Ran Xu, Hui Liu, Sreyashi Nag, Zhenwei Dai, Yaochen Xie, Xianfeng Tang, Chen Luo, Yang Li, Joyce C. Ho, Carl Yang, Qi He</author><pubDate>Wed, 23 Oct 2024 15:24:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17952v1</guid></item><item><title>Benchmarking Floworks against OpenAI &amp; Anthropic: A Novel Framework for Enhanced LLM Function Calling</title><link>http://arxiv.org/abs/2410.17950v1</link><description>Large Language Models (LLMs) have shown remarkable capabilities in variousdomains, yet their economic impact has been limited by challenges in tool useand function calling. This paper introduces ThorV2, a novel architecture thatsignificantly enhances LLMs' function calling abilities. We develop acomprehensive benchmark focused on HubSpot CRM operations to evaluate ThorV2against leading models from OpenAI and Anthropic. Our results demonstrate thatThorV2 outperforms existing models in accuracy, reliability, latency, and costefficiency for both single and multi-API calling tasks. We also show thatThorV2 is far more reliable and scales better to multistep tasks compared totraditional models. Our work offers the tantalizing possibility of moreaccurate function-calling compared to today's best-performing models usingsignificantly smaller LLMs. These advancements have significant implicationsfor the development of more capable AI assistants and the broader applicationof LLMs in real-world scenarios.</description><author>Nirav Bhan, Shival Gupta, Sai Manaswini, Ritik Baba, Narun Yadav, Hillori Desai, Yash Choudhary, Aman Pawar, Sarthak Shrivastava, Sudipta Biswas</author><pubDate>Wed, 23 Oct 2024 15:23:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17950v1</guid></item><item><title>Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding</title><link>http://arxiv.org/abs/2406.12295v2</link><description>Large Language Models (LLMs) exhibit impressive capabilities across variousapplications but encounter substantial challenges such as high inferencelatency, considerable training costs, and the generation of hallucinations.Collaborative decoding between large and small language models (SLMs) presentsa promising strategy to mitigate these issues through methods includingspeculative decoding, contrastive decoding, and emulator or proxy fine-tuning.However, the specifics of such collaborations, particularly from a unifiedperspective, remain largely unexplored. Inspired by dual-process cognitivetheory, we propose a unified framework in this paper, termed Fast and SlowGenerating (FS-GEN). Within this framework, LLMs (sometimes along with SLMs)are categorized as System 2 (slow and deliberate), while independent SLMs aredesignated as System 1 (fast and intuitive). We provide a comprehensiveanalysis of these collaborative methodologies, elucidating their commonproperties and shedding light on the differential knowledge capabilities ofSystem 2 versus System 1 through the FS-GEN framework. Our findings indicatethat only a small proportion of collaborative interactions (approximately lessthan 20\% in most instances) are necessary across various methods. Theseinteractions between System 1 and System 2 conform to a scaling law related tothe parameter ratios, enabling predictable collaboration. Furthermore, weexplore the specific conditions under which collaboration proves mosteffective, particularly from an uncertainty perspective, offering novelinsights that may guide future optimization efforts. Our research underscoresthat the fundamental distinction between System 1 and System 2 lies in theuncertainty of next token predictions, where interventions by System 2 arecrucial to support System 1. Code for Reproduction:https://github.com/TsinghuaC3I/FS-GEN</description><author>Kaiyan Zhang, Jianyu Wang, Ning Ding, Biqing Qi, Ermo Hua, Xingtai Lv, Bowen Zhou</author><pubDate>Wed, 23 Oct 2024 15:23:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12295v2</guid></item><item><title>Generalized Resubstitution for Regression Error Estimation</title><link>http://arxiv.org/abs/2410.17948v1</link><description>We propose generalized resubstitution error estimators for regression, abroad family of estimators, each corresponding to a choice of empiricalprobability measures and loss function. The usual sum of squares criterion is aspecial case corresponding to the standard empirical probability measure andthe quadratic loss. Other choices of empirical probability measure lead to moregeneral estimators with superior bias and variance properties. We prove thatthese error estimators are consistent under broad assumptions. In addition,procedures for choosing the empirical measure based on the method of momentsand maximum pseudo-likelihood are proposed and investigated. Detailedexperimental results using polynomial regression demonstrate empirically thesuperior finite-sample bias and variance properties of the proposed estimators.The R code for the experiments is provided.</description><author>Diego Marcondes, Ulisses Braga-Neto</author><pubDate>Wed, 23 Oct 2024 15:22:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17948v1</guid></item><item><title>LocoMotion: Learning Motion-Focused Video-Language Representations</title><link>http://arxiv.org/abs/2410.12018v2</link><description>This paper strives for motion-focused video-language representations.Existing methods to learn video-language representations use spatial-focuseddata, where identifying the objects and scene is often enough to distinguishthe relevant caption. We instead propose LocoMotion to learn frommotion-focused captions that describe the movement and temporal progression oflocal object motions. We achieve this by adding synthetic motions to videos andusing the parameters of these motions to generate corresponding captions.Furthermore, we propose verb-variation paraphrasing to increase the captionvariety and learn the link between primitive motions and high-level verbs. Withthis, we are able to learn a motion-focused video-language representation.Experiments demonstrate our approach is effective for a variety of downstreamtasks, particularly when limited data is available for fine-tuning. Code isavailable: https://hazeldoughty.github.io/Papers/LocoMotion/</description><author>Hazel Doughty, Fida Mohammad Thoker, Cees G. M. Snoek</author><pubDate>Wed, 23 Oct 2024 15:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12018v2</guid></item><item><title>Theoretically Grounded Pruning of Large Ground Sets for Constrained, Discrete Optimization</title><link>http://arxiv.org/abs/2410.17945v1</link><description>Modern instances of combinatorial optimization problems often exhibitbillion-scale ground sets, which have many uninformative or redundant elements.In this work, we develop light-weight pruning algorithms to quickly discardelements that are unlikely to be part of an optimal solution. Under mildassumptions on the instance, we prove theoretical guarantees on the fraction ofthe optimal value retained and the size of the resulting pruned ground set.Through extensive experiments on real-world datasets for various applications,we demonstrate that our algorithm, QuickPrune, efficiently prunes over 90% ofthe ground set and outperforms state-of-the-art classical and machine learningheuristics for pruning.</description><author>Ankur Nath, Alan Kuhnle</author><pubDate>Wed, 23 Oct 2024 15:18:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17945v1</guid></item><item><title>Optimizing Travel Itineraries with AI Algorithms in a Microservices Architecture: Balancing Cost, Time, Preferences, and Sustainability</title><link>http://arxiv.org/abs/2410.17943v1</link><description>The objective of this research is how an implementation of AI algorithms inthe microservices architecture enhances travel itineraries by cost, time, userpreferences, and environmental sustainability. It uses machine learning modelsfor both cost forecasting and personalization, genetic algorithm foroptimization of the itinerary, and heuristics for sustainability checking.Primary evaluated parameters consist of latency, ability to satisfy userpreferences, cost and environmental concern. The experimental resultsdemonstrate an average of 4.5 seconds of response time on 1000 concurrent usersand 92% of user preferences accuracy. The cost efficiency is proved, with 95%of provided trips being within the limits of the budget declared by the user.The system also implements some measures to alleviate negative externalitiesrelated to travel and 60% of offered travel plans had green optionsincorporated, resulting in the average 15% lower carbon emissions than thetraditional travel plans offered. The genetic algorithm with time complexityO(g.p.f) provides the optimal solution in 100 generations. Every iterationimproves the quality of the solution by 5%, thus enabling its effective use inoptimization problems where time is measured in seconds. Finally, the system isdesigned to be fault-tolerant with functional 99.9% availability which allowsthe provision of services even when requirements are exceeded. Traveloptimization platform is turned dynamic and efficient by this microservicesbased architecture which provides enhanced scaling, allows asynchronouscommunication and real time changes. Because of the incorporation of Ai, costcontrol and eco-friendliness approaches, the system addresses the differentuser needs in the present days travel business.</description><author>Biman Barua, M. Shamim Kaiser</author><pubDate>Wed, 23 Oct 2024 15:15:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17943v1</guid></item><item><title>Spiking Graph Neural Network on Riemannian Manifolds</title><link>http://arxiv.org/abs/2410.17941v1</link><description>Graph neural networks (GNNs) have become the dominant solution for learningon graphs, the typical non-Euclidean structures. Conventional GNNs, constructedwith the Artificial Neuron Network (ANN), have achieved impressive performanceat the cost of high computation and energy consumption. In parallel, spikingGNNs with brain-like spiking neurons are drawing increasing research attentionowing to the energy efficiency. So far, existing spiking GNNs consider graphsin Euclidean space, ignoring the structural geometry, and suffer from the highlatency issue due to Back-Propagation-Through-Time (BPTT) with the surrogategradient. In light of the aforementioned issues, we are devoted to exploringspiking GNN on Riemannian manifolds, and present a Manifold-valued Spiking GNN(MSG). In particular, we design a new spiking neuron on geodesically completemanifolds with the diffeomorphism, so that BPTT regarding the spikes isreplaced by the proposed differentiation via manifold. Theoretically, we showthat MSG approximates a solver of the manifold ordinary differential equation.Extensive experiments on common graphs show the proposed MSG achieves superiorperformance to previous spiking GNNs and energy efficiency to conventionalGNNs.</description><author>Li Sun, Zhenhao Huang, Qiqi Wan, Hao Peng, Philip S. Yu</author><pubDate>Wed, 23 Oct 2024 15:09:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17941v1</guid></item><item><title>Accessible, At-Home Detection of Parkinson's Disease via Multi-task Video Analysis</title><link>http://arxiv.org/abs/2406.14856v2</link><description>Limited accessibility to neurological care leads to underdiagnosedParkinson's Disease (PD), preventing early intervention. Existing AI-based PDdetection methods primarily focus on unimodal analysis of motor or speechtasks, overlooking the multifaceted nature of the disease. To address this, weintroduce a large-scale, multi-task video dataset consisting of 1102 sessions(each containing videos of finger tapping, facial expression, and speech taskscaptured via webcam) from 845 participants (272 with PD). We propose a novelUncertainty-calibrated Fusion Network (UFNet) that leverages this multimodaldata to enhance diagnostic accuracy. UFNet employs independent task-specificnetworks, trained with Monte Carlo Dropout for uncertainty quantification,followed by self-attended fusion of features, with attention weightsdynamically adjusted based on task-specific uncertainties. To ensurepatient-centered evaluation, the participants were randomly split into threesets: 60% for training, 20% for model selection, and 20% for final performanceevaluation. UFNet significantly outperformed single-task models in terms ofaccuracy, area under the ROC curve (AUROC), and sensitivity while maintainingnon-inferior specificity. Withholding uncertain predictions further boosted theperformance, achieving 88.0+-0.3%$ accuracy, 93.0+-0.2% AUROC, 79.3+-0.9%sensitivity, and 92.6+-0.3% specificity, at the expense of not being able topredict for 2.3+-0.3% data (+- denotes 95% confidence interval). Furtheranalysis suggests that the trained model does not exhibit any detectable biasacross sex and ethnic subgroups and is most effective for individuals agedbetween 50 and 80. Requiring only a webcam and microphone, our approachfacilitates accessible home-based PD screening, especially in regions withlimited healthcare resources.</description><author>Md Saiful Islam, Tariq Adnan, Jan Freyberg, Sangwu Lee, Abdelrahman Abdelkader, Meghan Pawlik, Cathe Schwartz, Karen Jaffe, Ruth B. Schneider, E Ray Dorsey, Ehsan Hoque</author><pubDate>Wed, 23 Oct 2024 15:08:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14856v2</guid></item><item><title>Reconfidencing LLMs from the Grouping Loss Perspective</title><link>http://arxiv.org/abs/2402.04957v3</link><description>Large Language Models (LLMs), including ChatGPT and LLaMA, are susceptible togenerating hallucinated answers in a confident tone. While efforts to elicitand calibrate confidence scores have proven useful, recent findings show thatcontrolling uncertainty must go beyond calibration: predicted scores maydeviate significantly from the actual posterior probabilities due to the impactof grouping loss. In this work, we construct a new evaluation dataset derivedfrom a knowledge base to assess confidence scores given to answers of Mistraland LLaMA. Experiments show that they tend to be overconfident. Further, weshow that they are more overconfident on some answers than others, \emph{eg}depending on the nationality of the person in the query. Inuncertainty-quantification theory, this is grouping loss. To address this, wepropose a solution to reconfidence LLMs, canceling not only calibration butalso grouping loss. The LLMs, after the reconfidencing process, indicateimproved confidence alignment with the accuracy of their responses.</description><author>Lihu Chen, Alexandre Perez-Lebel, Fabian M. Suchanek, Gaël Varoquaux</author><pubDate>Wed, 23 Oct 2024 15:08:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04957v3</guid></item><item><title>TravelPlanner: A Benchmark for Real-World Planning with Language Agents</title><link>http://arxiv.org/abs/2402.01622v4</link><description>Planning has been part of the core pursuit for artificial intelligence sinceits conception, but earlier AI agents mostly focused on constrained settingsbecause many of the cognitive substrates necessary for human-level planninghave been lacking. Recently, language agents powered by large language models(LLMs) have shown interesting capabilities such as tool use and reasoning. Arethese language agents capable of planning in more complex settings that are outof the reach of prior AI agents? To advance this investigation, we proposeTravelPlanner, a new planning benchmark that focuses on travel planning, acommon real-world planning scenario. It provides a rich sandbox environment,various tools for accessing nearly four million data records, and 1,225meticulously curated planning intents and reference plans. Comprehensiveevaluations show that the current language agents are not yet capable ofhandling such complex planning tasks-even GPT-4 only achieves a success rate of0.6%. Language agents struggle to stay on task, use the right tools to collectinformation, or keep track of multiple constraints. However, we note that themere possibility for language agents to tackle such a complex problem is initself non-trivial progress. TravelPlanner provides a challenging yetmeaningful testbed for future language agents.</description><author>Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, Yu Su</author><pubDate>Wed, 23 Oct 2024 15:02:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01622v4</guid></item><item><title>Certifiably Robust Policies for Uncertain Parametric Environments</title><link>http://arxiv.org/abs/2408.03093v2</link><description>We present a data-driven approach for producing policies that are provablyrobust across unknown stochastic environments. Existing approaches can learnmodels of a single environment as an interval Markov decision processes (IMDP)and produce a robust policy with a probably approximately correct (PAC)guarantee on its performance. However these are unable to reason about theimpact of environmental parameters underlying the uncertainty. We propose aframework based on parametric Markov decision processes (MDPs) with unknowndistributions over parameters. We learn and analyse IMDPs for a set of unknownsample environments induced by parameters. The key challenge is then to producemeaningful performance guarantees that combine the two layers of uncertainty:(1) multiple environments induced by parameters with an unknown distribution;(2) unknown induced environments which are approximated by IMDPs. We present anovel approach based on scenario optimisation that yields a single PACguarantee quantifying the risk level for which a specified performance levelcan be assured in unseen environments, plus a means to trade-off risk andperformance. We implement and evaluate our framework using multiple robustpolicy generation methods on a range of benchmarks. We show that our approachproduces tight bounds on a policy's performance with high confidence.</description><author>Yannik Schnitzer, Alessandro Abate, David Parker</author><pubDate>Wed, 23 Oct 2024 15:01:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03093v2</guid></item><item><title>Semi-Implicit Functional Gradient Flow</title><link>http://arxiv.org/abs/2410.17935v1</link><description>Particle-based variational inference methods (ParVIs) use non-parametricvariational families represented by particles to approximate the targetdistribution according to the kernelized Wasserstein gradient flow for theKullback-Leibler (KL) divergence. Recent works introduce functional gradientflows to substitute the kernel for better flexibility. However, thedeterministic updating mechanism may suffer from limited exploration andrequire expensive repetitive runs for new samples. In this paper, we proposeSemi-Implicit Functional Gradient flow (SIFG), a functional gradient ParVImethod that uses perturbed particles as the approximation family. Thecorresponding functional gradient flow, which can be estimated via denoisingscore matching, exhibits strong theoretical convergence guarantee. We alsopresent an adaptive version of our method to automatically choose the suitablenoise magnitude. Extensive experiments demonstrate the effectiveness andefficiency of the proposed framework on both simulated and real data problems.</description><author>Shiyue Zhang, Ziheng Cheng, Cheng Zhang</author><pubDate>Wed, 23 Oct 2024 15:00:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17935v1</guid></item><item><title>Retrieving snow depth distribution by downscaling ERA5 Reanalysis with ICESat-2 laser altimetry</title><link>http://arxiv.org/abs/2410.17934v1</link><description>Estimating the variability of seasonal snow cover, in particular snow depthin remote areas, poses significant challenges due to limited spatial andtemporal data availability. This study uses snow depth measurements from theICESat-2 satellite laser altimeter, which are sparse in both space and time,and incorporates them with climate reanalysis data into adownscaling-calibration scheme to produce monthly gridded snow depth maps atmicroscale (10 m). Snow surface elevation measurements from ICESat-2 alongprofiles are compared to a digital elevation model to determine snow depth ateach point. To efficiently turn sparse measurements into snow depth maps, aregression model is fitted to establish a relationship between the retrievedsnow depth and the corresponding ERA5 Land snow depth. This relationship,referred to as subgrid variability, is then applied to downscale the monthlyERA5 Land snow depth data. The method can provide timeseries of monthly snowdepth maps for the entire ERA5 time range (since 1950). The validation ofdownscaled snow depth data was performed at an intermediate scale (100 m x 500m) using datasets from airborne laser scanning (ALS) in the Hardangerviddaregion of southern Norway. Results show that snow depth prediction achieved R2values ranging from 0.74 to 0.88 (post-calibration). The method relies onglobally available data and is applicable to other snow regions above thetreeline. Though requiring area-specific calibration, our approach has thepotential to provide snow depth maps in areas where no such data exist and canbe used to extrapolate existing snow surveys in time and over larger areas.With this, it can offer valuable input data for hydrological, ecological orpermafrost modeling tasks.</description><author>Zhihao Liu, Simon Filhol, Désirée Treichler</author><pubDate>Wed, 23 Oct 2024 14:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17934v1</guid></item><item><title>Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning</title><link>http://arxiv.org/abs/2410.17933v1</link><description>One of the biggest challenges of building artificial intelligence (AI) modelin healthcare area is the data sharing. Since healthcare data is private,sensitive, and heterogeneous, collecting sufficient data for modelling isexhausted, costly, and sometimes impossible. In this paper, we propose aframework for global healthcare modelling using datasets from multi-continents(Europe, North America and Asia) while without sharing the local datasets, andchoose glucose management as a study model to verify its effectiveness.Technically, blockchain-enabled federated learning is implemented with adaptionto make it meet with the privacy and safety requirements of healthcare data,meanwhile rewards honest participation and penalize malicious activities usingits on-chain incentive mechanism. Experimental results show that the proposedframework is effective, efficient, and privacy preserved. Its predictionaccuracy is much better than the models trained from limited personal data andis similar to, and even slightly better than, the results from a centralizeddataset. This work paves the way for international collaborations on healthcareprojects, where additional data is crucial for reducing bias and providingbenefits to humanity.</description><author>Rui Sun, Zhipeng Wang, Hengrui Zhang, Ming Jiang, Yizhe Wen, Jiqun Zhang, Jiahao Sun, Shuoying Zhang, Erwu Liu, Kezhi Li</author><pubDate>Wed, 23 Oct 2024 14:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17933v1</guid></item><item><title>VR-Splatting: Foveated Radiance Field Rendering via 3D Gaussian Splatting and Neural Points</title><link>http://arxiv.org/abs/2410.17932v1</link><description>Recent advances in novel view synthesis (NVS), particularly neural radiancefields (NeRF) and Gaussian splatting (3DGS), have demonstrated impressiveresults in photorealistic scene rendering. These techniques hold greatpotential for applications in virtual tourism and teleportation, whereimmersive realism is crucial. However, the high-performance demands of virtualreality (VR) systems present challenges in directly utilizing even suchfast-to-render scene representations like 3DGS due to latency and computationalconstraints. In this paper, we propose foveated rendering as a promising solution to theseobstacles. We analyze state-of-the-art NVS methods with respect to theirrendering performance and compatibility with the human visual system. Ourapproach introduces a novel foveated rendering approach for Virtual Reality,that leverages the sharp, detailed output of neural point rendering for thefoveal region, fused with a smooth rendering of 3DGS for the peripheral vision. Our evaluation confirms that perceived sharpness and detail-richness areincreased by our approach compared to a standard VR-ready 3DGS configuration.Our system meets the necessary performance requirements for real-time VRinteractions, ultimately enhancing the user's immersive experience. Project page: https://lfranke.github.io/vr_splatting</description><author>Linus Franke, Laura Fink, Marc Stamminger</author><pubDate>Wed, 23 Oct 2024 14:54:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17932v1</guid></item><item><title>SCA: Highly Efficient Semantic-Consistent Unrestricted Adversarial Attack</title><link>http://arxiv.org/abs/2410.02240v4</link><description>Deep neural network based systems deployed in sensitive environments arevulnerable to adversarial attacks. Unrestricted adversarial attacks typicallymanipulate the semantic content of an image (e.g., color or texture) to createadversarial examples that are both effective and photorealistic. Recent workshave utilized the diffusion inversion process to map images into a latentspace, where high-level semantics are manipulated by introducing perturbations.However, they often results in substantial semantic distortions in the denoisedoutput and suffers from low efficiency. In this study, we propose a novelframework called Semantic-Consistent Unrestricted Adversarial Attacks (SCA),which employs an inversion method to extract edit-friendly noise maps andutilizes Multimodal Large Language Model (MLLM) to provide semantic guidancethroughout the process. Under the condition of rich semantic informationprovided by MLLM, we perform the DDPM denoising process of each step using aseries of edit-friendly noise maps, and leverage DPM Solver++ to acceleratethis process, enabling efficient sampling with semantic consistency. Comparedto existing methods, our framework enables the efficient generation ofadversarial examples that exhibit minimal discernible semantic changes.Consequently, we for the first time introduce Semantic-Consistent AdversarialExamples (SCAE). Extensive experiments and visualizations have demonstrated thehigh efficiency of SCA, particularly in being on average 12 times faster thanthe state-of-the-art attacks. Our research can further draw attention to thesecurity of multimedia information.</description><author>Zihao Pan, Weibin Wu, Yuhang Cao, Zibin Zheng</author><pubDate>Wed, 23 Oct 2024 14:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02240v4</guid></item><item><title>On provable privacy vulnerabilities of graph representations</title><link>http://arxiv.org/abs/2402.04033v3</link><description>Graph representation learning (GRL) is critical for extracting insights fromcomplex network structures, but it also raises security concerns due topotential privacy vulnerabilities in these representations. This paperinvestigates the structural vulnerabilities in graph neural models wheresensitive topological information can be inferred through edge reconstructionattacks. Our research primarily addresses the theoretical underpinnings ofsimilarity-based edge reconstruction attacks (SERA), furnishing anon-asymptotic analysis of their reconstruction capacities. Moreover, wepresent empirical corroboration indicating that such attacks can perfectlyreconstruct sparse graphs as graph size increases. Conversely, we establishthat sparsity is a critical factor for SERA's effectiveness, as demonstratedthrough analysis and experiments on (dense) stochastic block models. Finally,we explore the resilience of private graph representations produced via noisyaggregation (NAG) mechanism against SERA. Through theoretical analysis andempirical assessments, we affirm the mitigation of SERA using NAG . Inparallel, we also empirically delineate instances wherein SERA demonstratesboth efficacy and deficiency in its capacity to function as an instrument forelucidating the trade-off between privacy and utility.</description><author>Ruofan Wu, Guanhua Fang, Qiying Pan, Mingyang Zhang, Tengfei Liu, Weiqiang Wang</author><pubDate>Wed, 23 Oct 2024 14:50:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04033v3</guid></item><item><title>Adaptive Variance Reduction for Stochastic Optimization under Weaker Assumptions</title><link>http://arxiv.org/abs/2406.01959v2</link><description>This paper explores adaptive variance reduction methods for stochasticoptimization based on the STORM technique. Existing adaptive extensions ofSTORM rely on strong assumptions like bounded gradients and bounded functionvalues, or suffer an additional $\mathcal{O}(\log T)$ term in the convergencerate. To address these limitations, we introduce a novel adaptive STORM methodthat achieves an optimal convergence rate of $\mathcal{O}(T^{-1/3})$ fornon-convex functions with our newly designed learning rate strategy. Comparedwith existing approaches, our method requires weaker assumptions and attainsthe optimal convergence rate without the additional $\mathcal{O}(\log T)$ term.We also extend the proposed technique to stochastic compositional optimization,obtaining the same optimal rate of $\mathcal{O}(T^{-1/3})$. Furthermore, weinvestigate the non-convex finite-sum problem and develop another innovativeadaptive variance reduction method that achieves an optimal convergence rate of$\mathcal{O}(n^{1/4} T^{-1/2} )$, where $n$ represents the number of componentfunctions. Numerical experiments across various tasks validate theeffectiveness of our method.</description><author>Wei Jiang, Sifan Yang, Yibo Wang, Lijun Zhang</author><pubDate>Wed, 23 Oct 2024 14:49:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01959v2</guid></item><item><title>PnLCalib: Sports Field Registration via Points and Lines Optimization</title><link>http://arxiv.org/abs/2404.08401v3</link><description>Camera calibration in broadcast sports videos presents numerous challengesfor accurate sports field registration due to multiple camera angles, varyingcamera parameters, and frequent occlusions of the field. Traditionalsearch-based methods depend on initial camera pose estimates, which canstruggle in non-standard positions and dynamic environments. In response, wepropose an optimization-based calibration pipeline that leverages a 3D soccerfield model and a predefined set of keypoints to overcome these limitations.Our method also introduces a novel refinement module that improves initialcalibration by using detected field lines in a non-linear optimization process.This approach outperforms existing techniques in both multi-view andsingle-view 3D camera calibration tasks, while maintaining competitiveperformance in homography estimation. Extensive experimentation on real-worldsoccer datasets, including SoccerNet-Calibration, WorldCup 2014, andTS-WorldCup, highlights the robustness and accuracy of our method acrossdiverse broadcast scenarios. Our approach offers significant improvements incamera calibration precision and reliability.</description><author>Marc Gutiérrez-Pérez, Antonio Agudo</author><pubDate>Wed, 23 Oct 2024 14:48:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08401v3</guid></item><item><title>Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications</title><link>http://arxiv.org/abs/2311.05876v3</link><description>Large language models (LLMs) exhibit superior performance on various naturallanguage tasks, but they are susceptible to issues stemming from outdated dataand domain-specific limitations. In order to address these challenges,researchers have pursued two primary strategies, knowledge editing andretrieval augmentation, to enhance LLMs by incorporating external informationfrom different aspects. Nevertheless, there is still a notable absence of acomprehensive survey. In this paper, we propose a review to discuss the trendsin integration of knowledge and large language models, including taxonomy ofmethods, benchmarks, and applications. In addition, we conduct an in-depthanalysis of different methods and point out potential research directions inthe future. We hope this survey offers the community quick access and acomprehensive overview of this research area, with the intention of inspiringfuture research endeavors.</description><author>Zhangyin Feng, Weitao Ma, Weijiang Yu, Lei Huang, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, Ting liu</author><pubDate>Wed, 23 Oct 2024 14:48:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05876v3</guid></item><item><title>Posterior Sampling-based Online Learning for Episodic POMDPs</title><link>http://arxiv.org/abs/2310.10107v4</link><description>Learning in POMDPs is known to be significantly harder than in MDPs. In thispaper, we consider the online learning problem for episodic POMDPs with unknowntransition and observation models. We propose a Posterior Sampling-basedreinforcement learning algorithm for POMDPs (PS4POMDPs), which is much simplerand more implementable compared to state-of-the-art optimism-based onlinelearning algorithms for POMDPs. We show that the Bayesian regret of theproposed algorithm scales as the square root of the number of episodes and ispolynomial in the other parameters. In a general setting, the regret scalesexponentially in the horizon length $H$, and we show that this is inevitable byproviding a lower bound. However, when the POMDP is undercomplete and weaklyrevealing (a common assumption in the recent literature), we establish apolynomial Bayesian regret bound. We finally propose a posterior samplingalgorithm for multi-agent POMDPs, and show it too has sublinear regret.</description><author>Dengwang Tang, Dongze Ye, Rahul Jain, Ashutosh Nayyar, Pierluigi Nuzzo</author><pubDate>Wed, 23 Oct 2024 14:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10107v4</guid></item></channel></rss>