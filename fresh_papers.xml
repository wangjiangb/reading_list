<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 09 Jan 2024 06:00:08 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Dr$^2$Net: Dynamic Reversible Dual-Residual Networks for Memory-Efficient Finetuning</title><link>http://arxiv.org/abs/2401.04105v1</link><description>Large pretrained models are increasingly crucial in modern computer visiontasks. These models are typically used in downstream tasks by end-to-endfinetuning, which is highly memory-intensive for tasks with high-resolutiondata, e.g., video understanding, small object detection, and point cloudanalysis. In this paper, we propose Dynamic Reversible Dual-Residual Networks,or Dr$^2$Net, a novel family of network architectures that acts as a surrogatenetwork to finetune a pretrained model with substantially reduced memoryconsumption. Dr$^2$Net contains two types of residual connections, onemaintaining the residual structure in the pretrained models, and the othermaking the network reversible. Due to its reversibility, intermediateactivations, which can be reconstructed from output, are cleared from memoryduring training. We use two coefficients on either type of residual connectionsrespectively, and introduce a dynamic training strategy that seamlesslytransitions the pretrained model to a reversible network with much highernumerical precision. We evaluate Dr$^2$Net on various pretrained models andvarious tasks, and show that it can reach comparable performance toconventional finetuning but with significantly less memory usage.</description><author>Chen Zhao, Shuming Liu, Karttikeya Mangalam, Guocheng Qian, Fatimah Zohra, Abdulmohsen Alghannam, Jitendra Malik, Bernard Ghanem</author><pubDate>Mon, 08 Jan 2024 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04105v1</guid></item><item><title>AGG: Amortized Generative 3D Gaussians for Single Image to 3D</title><link>http://arxiv.org/abs/2401.04099v1</link><description>Given the growing need for automatic 3D content creation pipelines, various3D representations have been studied to generate 3D objects from a singleimage. Due to its superior rendering efficiency, 3D Gaussian splatting-basedmodels have recently excelled in both 3D reconstruction and generation. 3DGaussian splatting approaches for image to 3D generation are oftenoptimization-based, requiring many computationally expensive score-distillationsteps. To overcome these challenges, we introduce an Amortized Generative 3DGaussian framework (AGG) that instantly produces 3D Gaussians from a singleimage, eliminating the need for per-instance optimization. Utilizing anintermediate hybrid representation, AGG decomposes the generation of 3DGaussian locations and other appearance attributes for joint optimization.Moreover, we propose a cascaded pipeline that first generates a coarserepresentation of the 3D data and later upsamples it with a 3D Gaussiansuper-resolution module. Our method is evaluated against existingoptimization-based 3D Gaussian frameworks and sampling-based pipelinesutilizing other 3D representations, where AGG showcases competitive generationabilities both qualitatively and quantitatively while being several orders ofmagnitude faster. Project page: https://ir1d.github.io/AGG/</description><author>Dejia Xu, Ye Yuan, Morteza Mardani, Sifei Liu, Jiaming Song, Zhangyang Wang, Arash Vahdat</author><pubDate>Mon, 08 Jan 2024 18:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04099v1</guid></item><item><title>GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation</title><link>http://arxiv.org/abs/2401.04092v1</link><description>Despite recent advances in text-to-3D generative methods, there is a notableabsence of reliable evaluation metrics. Existing metrics usually focus on asingle criterion each, such as how well the asset aligned with the input text.These metrics lack the flexibility to generalize to different evaluationcriteria and might not align well with human preferences. Conducting userpreference studies is an alternative that offers both adaptability andhuman-aligned results. User studies, however, can be very expensive to scale.This paper presents an automatic, versatile, and human-aligned evaluationmetric for text-to-3D generative models. To this end, we first develop a promptgenerator using GPT-4V to generate evaluating prompts, which serve as input tocompare text-to-3D models. We further design a method instructing GPT-4V tocompare two 3D assets according to user-defined criteria. Finally, we use thesepairwise comparison results to assign these models Elo ratings. Experimentalresults suggest our metric strongly align with human preference acrossdifferent evaluation criteria.</description><author>Tong Wu, Guandao Yang, Zhibing Li, Kai Zhang, Ziwei Liu, Leonidas Guibas, Dahua Lin, Gordon Wetzstein</author><pubDate>Mon, 08 Jan 2024 18:52:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04092v1</guid></item><item><title>Mixtral of Experts</title><link>http://arxiv.org/abs/2401.04088v1</link><description>We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model.Mixtral has the same architecture as Mistral 7B, with the difference that eachlayer is composed of 8 feedforward blocks (i.e. experts). For every token, ateach layer, a router network selects two experts to process the current stateand combine their outputs. Even though each token only sees two experts, theselected experts can be different at each timestep. As a result, each token hasaccess to 47B parameters, but only uses 13B active parameters during inference.Mixtral was trained with a context size of 32k tokens and it outperforms ormatches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular,Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, andmultilingual benchmarks. We also provide a model fine-tuned to followinstructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5 Turbo,Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Boththe base and instruct models are released under the Apache 2.0 license.</description><author>Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed</author><pubDate>Mon, 08 Jan 2024 18:47:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04088v1</guid></item><item><title>Point-of-Care Real-Time Signal Quality for Fetal Doppler Ultrasound Using a Deep Learning Approach</title><link>http://arxiv.org/abs/2312.09433v2</link><description>In this study, we present a deep learning framework designed to integratewith our previously developed system that facilitates large-scale 1D fetalDoppler data collection, aiming to enhance data quality. This system, tailoredfor traditional Indigenous midwives in low-resource communities, leverages acost-effective Android phone to improve the quality of recorded signals. Wehave shown that the Doppler data can be used to identify fetal growthrestriction, hypertension, and other concerning issues during pregnancy.However, the quality of the signal is dependent on many factors, includingradio frequency interference, position of the fetus, maternal body habitus, andusage of the Doppler by the birth attendants. In order to provide instantfeedback to allow correction of the data at source, a signal quality metric isrequired that can run in real-time on the mobile phone. In this study, 191 DUS signals with durations mainly in the range between 5to 10 minutes were evaluated for quality and classified into five categories:Good, Poor, (Radiofrequency) Interference, Talking, and Silent, at a resolutionof 3.75 seconds. A deep neural network was trained on each 3.75-second segmentfrom these recordings and validated using five-fold cross-validation. An average micro F1 = 97.4\% and macro F1 = 94.2\% were achieved, with F1 =99.2\% for `Good' quality data. These results indicate that the algorithm,which will now be implemented in the midwives' app, should allow a significantincrease in the quality of data at the time of capture.</description><author>Mohsen Motie-Shirazi, Reza Sameni, Peter Rohloff, Nasim Katebi, Gari D. Clifford</author><pubDate>Mon, 08 Jan 2024 18:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09433v2</guid></item><item><title>A Priori Determination of the Pretest Probability</title><link>http://arxiv.org/abs/2401.04086v1</link><description>In this manuscript, we present various proposed methods estimate theprevalence of disease, a critical prerequisite for the adequate interpretationof screening tests. To address the limitations of these approaches, whichrevolve primarily around their a posteriori nature, we introduce a novel methodto estimate the pretest probability of disease, a priori, utilizing the Logitfunction from the logistic regression model. This approach is a modification ofMcGee's heuristic, originally designed for estimating the posttest probabilityof disease. In a patient presenting with $n_\theta$ signs or symptoms, theminimal bound of the pretest probability, $\phi$, can be approximated by: $\phi \approx\frac{1}{5}{ln\left[\displaystyle\prod_{\theta=1}^{i}\kappa_\theta\right]}$ where $ln$ is the natural logarithm, and $\kappa_\theta$ is the likelihoodratio associated with the sign or symptom in question.</description><author>Jacques Balayla</author><pubDate>Mon, 08 Jan 2024 18:44:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04086v1</guid></item><item><title>Improved motif-scaffolding with SE(3) flow matching</title><link>http://arxiv.org/abs/2401.04082v1</link><description>Protein design often begins with knowledge of a desired function from a motifwhich motif-scaffolding aims to construct a functional protein around.Recently, generative models have achieved breakthrough success in designingscaffolds for a diverse range of motifs. However, the generated scaffolds tendto lack structural diversity, which can hinder success in wet-lab validation.In this work, we extend FrameFlow, an SE(3) flow matching model for proteinbackbone generation, to perform motif-scaffolding with two complementaryapproaches. The first is motif amortization, in which FrameFlow is trained withthe motif as input using a data augmentation strategy. The second is motifguidance, which performs scaffolding using an estimate of the conditional scorefrom FrameFlow, and requires no additional training. Both approaches achieve anequivalent or higher success rate than previous state-of-the-art methods, with2.5 times more structurally diverse scaffolds. Code: https://github.com/microsoft/frame-flow.</description><author>Jason Yim, Andrew Campbell, Emile Mathieu, Andrew Y. K. Foong, Michael Gastegger, José Jiménez-Luna, Sarah Lewis, Victor Garcia Satorras, Bastiaan S. Veeling, Frank Noé, Regina Barzilay, Tommi S. Jaakkola</author><pubDate>Mon, 08 Jan 2024 18:38:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04082v1</guid></item><item><title>MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts</title><link>http://arxiv.org/abs/2401.04081v1</link><description>State Space Models (SSMs) have become serious contenders in the field ofsequential modeling, challenging the dominance of Transformers. At the sametime, Mixture of Experts (MoE) has significantly improved Transformer-basedLLMs, including recent state-of-the-art open-source models. We propose that tounlock the potential of SSMs for scaling, they should be combined with MoE. Weshowcase this on Mamba, a recent SSM-based model that achieves remarkable,Transformer-like performance. Our model, MoE-Mamba, outperforms both Mamba andTransformer-MoE. In particular, MoE-Mamba reaches the same performance as Mambain 2.2x less training steps while preserving the inference performance gains ofMamba against the Transformer.</description><author>Maciej Pióro, Kamil Ciebiera, Krystian Król, Jan Ludziejewski, Sebastian Jaszczur</author><pubDate>Mon, 08 Jan 2024 18:35:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04081v1</guid></item><item><title>RudolfV: A Foundation Model by Pathologists for Pathologists</title><link>http://arxiv.org/abs/2401.04079v1</link><description>Histopathology plays a central role in clinical medicine and biomedicalresearch. While artificial intelligence shows promising results on manypathological tasks, generalization and dealing with rare diseases, wheretraining data is scarce, remains a challenge. Distilling knowledge fromunlabeled data into a foundation model before learning from, potentiallylimited, labeled data provides a viable path to address these challenges. Inthis work, we extend the state of the art of foundation models for digitalpathology whole slide images by semi-automated data curation and incorporatingpathologist domain knowledge. Specifically, we combine computational andpathologist domain knowledge (1) to curate a diverse dataset of 103k slidescorresponding to 750 million image patches covering data from differentfixation, staining, and scanning protocols as well as data from differentindications and labs across the EU and US, (2) for grouping semanticallysimilar slides and tissue patches, and (3) to augment the input images duringtraining. We evaluate the resulting model on a set of public and internalbenchmarks and show that although our foundation model is trained with an orderof magnitude less slides, it performs on par or better than competing models.We expect that scaling our approach to more data and larger models will furtherincrease its performance and capacity to deal with increasingly complex realworld tasks in diagnostics and biomedical research.</description><author>Jonas Dippel, Barbara Feulner, Tobias Winterhoff, Simon Schallenberg, Gabriel Dernbach, Andreas Kunft, Stephan Tietz, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen, Maximilian Alber</author><pubDate>Mon, 08 Jan 2024 18:31:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04079v1</guid></item><item><title>Fun with Flags: Robust Principal Directions via Flag Manifolds</title><link>http://arxiv.org/abs/2401.04071v1</link><description>Principal component analysis (PCA), along with its extensions to manifoldsand outlier contaminated data, have been indispensable in computer vision andmachine learning. In this work, we present a unifying formalism for PCA and itsvariants, and introduce a framework based on the flags of linear subspaces, \iea hierarchy of nested linear subspaces of increasing dimension, which not onlyallows for a common implementation but also yields novel variants, not exploredpreviously. We begin by generalizing traditional PCA methods that eithermaximize variance or minimize reconstruction error. We expand theseinterpretations to develop a wide array of new dimensionality reductionalgorithms by accounting for outliers and the data manifold. To devise a commoncomputational approach, we recast robust and dual forms of PCA as optimizationproblems on flag manifolds. We then integrate tangent space approximations ofprincipal geodesic analysis (tangent-PCA) into this flag-based framework,creating novel robust and dual geodesic PCA variations. The remarkableflexibility offered by the 'flagification' introduced here enables even morealgorithmic variants identified by specific flag types. Last but not least, wepropose an effective convergent solver for these flag-formulations employingthe Stiefel manifold. Our empirical results on both real-world and syntheticscenarios, demonstrate the superiority of our novel algorithms, especially interms of robustness to outliers on manifolds.</description><author>Nathan Mankovich, Gustau Camps-Valls, Tolga Birdal</author><pubDate>Mon, 08 Jan 2024 18:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04071v1</guid></item><item><title>Vulnerabilities Unveiled: Adversarially Attacking a Multimodal Vision Language Model for Pathology Imaging</title><link>http://arxiv.org/abs/2401.02565v2</link><description>In the dynamic landscape of medical artificial intelligence, this studyexplores the vulnerabilities of the Pathology Language-Image Pretraining (PLIP)model, a Vision Language Foundation model, under targeted adversarialconditions. Leveraging the Kather Colon dataset with 7,180 H&amp;E images acrossnine tissue types, our investigation employs Projected Gradient Descent (PGD)adversarial attacks to intentionally induce misclassifications. The outcomesreveal a 100% success rate in manipulating PLIP's predictions, underscoring itssusceptibility to adversarial perturbations. The qualitative analysis ofadversarial examples delves into the interpretability challenges, sheddinglight on nuanced changes in predictions induced by adversarial manipulations.These findings contribute crucial insights into the interpretability, domainadaptation, and trustworthiness of Vision Language Models in medical imaging.The study emphasizes the pressing need for robust defenses to ensure thereliability of AI models.</description><author>Jai Prakash Veerla, Poojitha Thota, Partha Sai Guttikonda, Shirin Nilizadeh, Jacob M. Luber</author><pubDate>Mon, 08 Jan 2024 18:15:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02565v2</guid></item><item><title>Convex SGD: Generalization Without Early Stopping</title><link>http://arxiv.org/abs/2401.04067v1</link><description>We consider the generalization error associated with stochastic gradientdescent on a smooth convex function over a compact set. We show the first boundon the generalization error that vanishes when the number of iterations $T$ andthe dataset size $n$ go to zero at arbitrary rates; our bound scales as$\tilde{O}(1/\sqrt{T} + 1/\sqrt{n})$ with step-size $\alpha_t = 1/\sqrt{t}$. Inparticular, strong convexity is not needed for stochastic gradient descent togeneralize well.</description><author>Julien Hendrickx, Alex Olshevsky</author><pubDate>Mon, 08 Jan 2024 18:10:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04067v1</guid></item><item><title>Variance Reduction in Ratio Metrics for Efficient Online Experiments</title><link>http://arxiv.org/abs/2401.04062v1</link><description>Online controlled experiments, such as A/B-tests, are commonly used by moderntech companies to enable continuous system improvements. Despite theirparamount importance, A/B-tests are expensive: by their very definition, apercentage of traffic is assigned an inferior system variant. To ensurestatistical significance on top-level metrics, online experiments typically runfor several weeks. Even then, a considerable amount of experiments will lead toinconclusive results (i.e. false negatives, or type-II error). The main culpritfor this inefficiency is the variance of the online metrics. Variance reductiontechniques have been proposed in the literature, but their direct applicabilityto commonly used ratio metrics (e.g. click-through rate or user retention) islimited. In this work, we successfully apply variance reduction techniques to ratiometrics on a large-scale short-video platform: ShareChat. Our empirical resultsshow that we can either improve A/B-test confidence in 77% of cases, or canretain the same level of confidence with 30% fewer data points. Importantly, weshow that the common approach of including as many covariates as possible inregression is counter-productive, highlighting that control variates based onGradient-Boosted Decision Tree predictors are most effective. We discuss thepracticalities of implementing these methods at scale and showcase the costreduction they beget.</description><author>Shubham Baweja, Neeti Pokharna, Aleksei Ustimenko, Olivier Jeunen</author><pubDate>Mon, 08 Jan 2024 18:01:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04062v1</guid></item><item><title>Toward A Reinforcement-Learning-Based System for Adjusting Medication to Minimize Speech Disfluency</title><link>http://arxiv.org/abs/2312.11509v2</link><description>We propose a Reinforcement-Learning-based system that would automaticallyprescribe a hypothetical patient medication that may help the patient withtheir mental-health-related speech disfluency, and adjust the medication andthe dosages in response to zero-cost frequent measurement of the fluency of thepatient. We demonstrate the components of the system: a module that detects andevaluates speech disfluency on a large dataset we built, and a ReinforcementLearning algorithm that automatically finds good combinations of medications.To support the two modules, we collect data on the effect of psychiatricmedications for speech disfluency from the literature, and build a plausiblepatient simulation system. We demonstrate that the Reinforcement Learningsystem is, under some circumstances, able to converge to a good medicationregime. We collect and label a dataset of people with possible speechdisfluency and demonstrate our methods using that dataset. Our work is a proofof concept: we show that there is promise in the idea of using automatic datacollection to address disfluency.</description><author>Pavlos Constas, Vikram Rawal, Matthew Honorio Oliveira, Andreas Constas, Aditya Khan, Kaison Cheung, Najma Sultani, Carrie Chen, Micol Altomare, Michael Akzam, Jiacheng Chen, Vhea He, Lauren Altomare, Heraa Murqi, Asad Khan, Nimit Amikumar Bhanshali, Youssef Rachad, Michael Guerzhoy</author><pubDate>Mon, 08 Jan 2024 17:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11509v2</guid></item><item><title>Unveiling Bias in Fairness Evaluations of Large Language Models: A Critical Literature Review of Music and Movie Recommendation Systems</title><link>http://arxiv.org/abs/2401.04057v1</link><description>The rise of generative artificial intelligence, particularly Large LanguageModels (LLMs), has intensified the imperative to scrutinize fairness alongsideaccuracy. Recent studies have begun to investigate fairness evaluations forLLMs within domains such as recommendations. Given that personalization is anintrinsic aspect of recommendation systems, its incorporation into fairnessassessments is paramount. Yet, the degree to which current fairness evaluationframeworks account for personalization remains unclear. Our comprehensiveliterature review aims to fill this gap by examining how existing frameworkshandle fairness evaluations of LLMs, with a focus on the integration ofpersonalization factors. Despite an exhaustive collection and analysis ofrelevant works, we discovered that most evaluations overlook personalization, acritical facet of recommendation systems, thereby inadvertently perpetuatingunfair practices. Our findings shed light on this oversight and underscore theurgent need for more nuanced fairness evaluations that acknowledgepersonalization. Such improvements are vital for fostering equitabledevelopment within the AI community.</description><author>Chandan Kumar Sah, Dr. Lian Xiaoli, Muhammad Mirajul Islam</author><pubDate>Mon, 08 Jan 2024 17:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04057v1</guid></item><item><title>A Minimaximalist Approach to Reinforcement Learning from Human Feedback</title><link>http://arxiv.org/abs/2401.04056v1</link><description>We present Self-Play Preference Optimization (SPO), an algorithm forreinforcement learning from human feedback. Our approach is minimalist in thatit does not require training a reward model nor unstable adversarial trainingand is therefore rather simple to implement. Our approach is maximalist in thatit provably handles non-Markovian, intransitive, and stochastic preferenceswhile being robust to the compounding errors that plague offline approaches tosequential prediction. To achieve the preceding qualities, we build upon theconcept of a Minimax Winner (MW), a notion of preference aggregation from thesocial choice theory literature that frames learning from preferences as azero-sum game between two policies. By leveraging the symmetry of this game, weprove that rather than using the traditional technique of dueling two policiesto compute the MW, we can simply have a single agent play against itself whilemaintaining strong convergence guarantees. Practically, this corresponds tosampling multiple trajectories from a policy, asking a rater or preferencemodel to compare them, and then using the proportion of wins as the reward fora particular trajectory. We demonstrate that on a suite of continuous controltasks, we are able to learn significantly more efficiently than reward-modelbased approaches while maintaining robustness to the intransitive andstochastic preferences that frequently occur in practice when aggregating humanjudgments.</description><author>Gokul Swamy, Christoph Dann, Rahul Kidambi, Zhiwei Steven Wu, Alekh Agarwal</author><pubDate>Mon, 08 Jan 2024 17:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04056v1</guid></item><item><title>Federated Multi-Objective Learning</title><link>http://arxiv.org/abs/2310.09866v3</link><description>In recent years, multi-objective optimization (MOO) emerges as a foundationalproblem underpinning many multi-agent multi-task learning applications.However, existing algorithms in MOO literature remain limited to centralizedlearning settings, which do not satisfy the distributed nature and data privacyneeds of such multi-agent multi-task learning applications. This motivates usto propose a new federated multi-objective learning (FMOL) framework withmultiple clients distributively and collaboratively solving an MOO problemwhile keeping their training data private. Notably, our FMOL framework allows adifferent set of objective functions across different clients to support a widerange of applications, which advances and generalizes the MOO formulation tothe federated learning paradigm for the first time. For this FMOL framework, wepropose two new federated multi-objective optimization (FMOO) algorithms calledfederated multi-gradient descent averaging (FMGDA) and federated stochasticmulti-gradient descent averaging (FSMGDA). Both algorithms allow local updatesto significantly reduce communication costs, while achieving the {\em same}convergence rates as those of their algorithmic counterparts in thesingle-objective federated learning. Our extensive experiments also corroboratethe efficacy of our proposed FMOO algorithms.</description><author>Haibo Yang, Zhuqing Liu, Jia Liu, Chaosheng Dong, Michinari Momma</author><pubDate>Mon, 08 Jan 2024 17:47:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09866v3</guid></item><item><title>Empirical Analysis of Efficient Fine-Tuning Methods for Large Pre-Trained Language Models</title><link>http://arxiv.org/abs/2401.04051v1</link><description>Fine-tuning large pre-trained language models for downstream tasks remains acritical challenge in natural language processing. This paper presents anempirical analysis comparing two efficient fine-tuning methods - BitFit andadapter modules - to standard full model fine-tuning. Experiments conducted onGLUE benchmark datasets (MRPC, COLA, STS-B) reveal several key insights. TheBitFit approach, which trains only bias terms and task heads, matches fullfine-tuning performance across varying amounts of training data and timeconstraints. It demonstrates remarkable stability even with only 30\% of data,outperforming full fine-tuning at intermediate data levels. Adapter modulesexhibit high variability, with inconsistent gains over default models. Thefindings indicate BitFit offers an attractive balance between performance andparameter efficiency. Our work provides valuable perspectives on model tuning,emphasizing robustness and highlighting BitFit as a promising alternative forresource-constrained or streaming task settings. The analysis offers actionableguidelines for efficient adaptation of large pre-trained models, whileillustrating open challenges in stabilizing techniques like adapter modules.</description><author>Nigel Doering, Cyril Gorlla, Trevor Tuttle, Adhvaith Vijay</author><pubDate>Mon, 08 Jan 2024 17:44:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04051v1</guid></item><item><title>Pre-trained Recommender Systems: A Causal Debiasing Perspective</title><link>http://arxiv.org/abs/2310.19251v4</link><description>Recent studies on pre-trained vision/language models have demonstrated thepractical benefit of a new, promising solution-building paradigm in AI wheremodels can be pre-trained on broad data describing a generic task space andthen adapted successfully to solve a wide range of downstream tasks, even whentraining data is severely limited (e.g., in zero- or few-shot learningscenarios). Inspired by such progress, we investigate in this paper thepossibilities and challenges of adapting such a paradigm to the context ofrecommender systems, which is less investigated from the perspective ofpre-trained model. In particular, we propose to develop a generic recommenderthat captures universal interaction patterns by training on generic user-iteminteraction data extracted from different domains, which can then be fastadapted to improve few-shot learning performance in unseen new domains (withlimited data). However, unlike vision/language data which share strong conformity in thesemantic space, universal patterns underlying recommendation data collectedacross different domains (e.g., different countries or different E-commerceplatforms) are often occluded by both in-domain and cross-domain biasesimplicitly imposed by the cultural differences in their user and item bases, aswell as their uses of different e-commerce platforms. As shown in ourexperiments, such heterogeneous biases in the data tend to hinder theeffectiveness of the pre-trained model. To address this challenge, we furtherintroduce and formalize a causal debiasing perspective, which is substantiatedvia a hierarchical Bayesian deep learning model, named PreRec. Our empiricalstudies on real-world data show that the proposed model could significantlyimprove the recommendation performance in zero- and few-shot learning settingsunder both cross-market and cross-platform scenarios.</description><author>Ziqian Lin, Hao Ding, Nghia Trong Hoang, Branislav Kveton, Anoop Deoras, Hao Wang</author><pubDate>Mon, 08 Jan 2024 17:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19251v4</guid></item><item><title>FFSplit: Split Feed-Forward Network For Optimizing Accuracy-Efficiency Trade-off in Language Model Inference</title><link>http://arxiv.org/abs/2401.04044v1</link><description>The large number of parameters in Pretrained Language Models enhance theirperformance, but also make them resource-intensive, making it challenging todeploy them on commodity hardware like a single GPU. Due to the memory andpower limitations of these devices, model compression techniques are often usedto decrease both the model's size and its inference latency. This usuallyresults in a trade-off between model accuracy and efficiency. Therefore,optimizing this balance is essential for effectively deploying LLMs oncommodity hardware. A significant portion of the efficiency challenge is theFeed-forward network (FFN) component, which accounts for roughly $\frac{2}{3}$total parameters and inference latency. In this paper, we first observe thatonly a few neurons of FFN module have large output norm for any input tokens,a.k.a. heavy hitters, while the others are sparsely triggered by differenttokens. Based on this observation, we explicitly split the FFN into two partsaccording to the heavy hitters. We improve the efficiency-accuracy trade-off ofexisting compression methods by allocating more resource to FFN parts withheavy hitters. In practice, our method can reduce model size by 43.1\% andbring $1.25\sim1.56\times$ wall clock time speedup on different hardware withnegligible accuracy drop.</description><author>Zirui Liu, Qingquan Song, Qiang Charles Xiao, Sathiya Keerthi Selvaraj, Rahul Mazumder, Aman Gupta, Xia Hu</author><pubDate>Mon, 08 Jan 2024 17:29:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04044v1</guid></item><item><title>IDoFew: Intermediate Training Using Dual-Clustering in Language Models for Few Labels Text Classification</title><link>http://arxiv.org/abs/2401.04025v1</link><description>Language models such as Bidirectional Encoder Representations fromTransformers (BERT) have been very effective in various Natural LanguageProcessing (NLP) and text mining tasks including text classification. However,some tasks still pose challenges for these models, including textclassification with limited labels. This can result in a cold-start problem.Although some approaches have attempted to address this problem throughsingle-stage clustering as an intermediate training step coupled with apre-trained language model, which generates pseudo-labels to improveclassification, these methods are often error-prone due to the limitations ofthe clustering algorithms. To overcome this, we have developed a noveltwo-stage intermediate clustering with subsequent fine-tuning that models thepseudo-labels reliably, resulting in reduced prediction errors. The key noveltyin our model, IDoFew, is that the two-stage clustering coupled with twodifferent clustering algorithms helps exploit the advantages of thecomplementary algorithms that reduce the errors in generating reliablepseudo-labels for fine-tuning. Our approach has shown significant improvementscompared to strong comparative models.</description><author>Abdullah Alsuhaibani, Hamad Zogan, Imran Razzak, Shoaib Jameel, Guandong Xu</author><pubDate>Mon, 08 Jan 2024 17:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04025v1</guid></item><item><title>Non-flat ABA is an Instance of Bipolar Argumentation</title><link>http://arxiv.org/abs/2305.12453v2</link><description>Assumption-based Argumentation (ABA) is a well-known structured argumentationformalism, whereby arguments and attacks between them are drawn from rules,defeasible assumptions and their contraries. A common restriction imposed onABA frameworks (ABAFs) is that they are flat, i.e., each of the defeasibleassumptions can only be assumed, but not derived. While it is known that flatABAFs can be translated into abstract argumentation frameworks (AFs) asproposed by Dung, no translation exists from general, possibly non-flat ABAFsinto any kind of abstract argumentation formalism. In this paper, we close thisgap and show that bipolar AFs (BAFs) can instantiate general ABAFs. To this endwe develop suitable, novel BAF semantics which borrow from the notion ofdeductive support. We investigate basic properties of our BAFs, includingcomputational complexity, and prove the desired relation to ABAFs under severalsemantics. Finally, in order to support computation and explainability, wepropose the notion of dispute trees for our BAF semantics.</description><author>Markus Ulbricht, Nico Potyka, Anna Rapberger, Francesca Toni</author><pubDate>Mon, 08 Jan 2024 17:06:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12453v2</guid></item><item><title>Highly Efficient Real-Time Streaming and Fully On-Device Speaker Diarization with Multi-Stage Clustering</title><link>http://arxiv.org/abs/2210.13690v4</link><description>While recent research advances in speaker diarization mostly focus onimproving the quality of diarization results, there is also an increasinginterest in improving the efficiency of diarization systems. In this paper, wedemonstrate that a multi-stage clustering strategy that uses differentclustering algorithms for input of different lengths can address multi-facetedchallenges of on-device speaker diarization applications. Specifically, afallback clusterer is used to handle short-form inputs; a main clusterer isused to handle medium-length inputs; and a pre-clusterer is used to compresslong-form inputs before they are processed by the main clusterer. Both the mainclusterer and the pre-clusterer can be configured with an upper bound of thecomputational complexity to adapt to devices with different resourceconstraints. This multi-stage clustering strategy is critical for streamingon-device speaker diarization systems, where the budgets of CPU, memory andbattery are tight.</description><author>Quan Wang, Yiling Huang, Han Lu, Guanlong Zhao, Ignacio Lopez Moreno</author><pubDate>Mon, 08 Jan 2024 17:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.13690v4</guid></item><item><title>TPC-ViT: Token Propagation Controller for Efficient Vision Transformer</title><link>http://arxiv.org/abs/2401.01470v2</link><description>Vision transformers (ViTs) have achieved promising results on a variety ofComputer Vision tasks, however their quadratic complexity in the number ofinput tokens has limited their application specially in resource-constrainedsettings. Previous approaches that employ gradual token reduction to addressthis challenge assume that token redundancy in one layer implies redundancy inall the following layers. We empirically demonstrate that this assumption isoften not correct, i.e., tokens that are redundant in one layer can be usefulin later layers. We employ this key insight to propose a novel tokenpropagation controller (TPC) that incorporates two differenttoken-distributions, i.e., pause probability and restart probability to controlthe reduction and reuse of tokens respectively, which results in more efficienttoken utilization. To improve the estimates of token distributions, we proposea smoothing mechanism that acts as a regularizer and helps remove noisyoutliers. Furthermore, to improve the training-stability of our proposed TPC,we introduce a model stabilizer that is able to implicitly encode local imagestructures and minimize accuracy fluctuations during model training. We presentextensive experimental results on the ImageNet-1K dataset using DeiT, LV-ViTand Swin models to demonstrate the effectiveness of our proposed method. Forexample, compared to baseline models, our proposed method improves theinference speed of the DeiT-S by 250% while increasing the classificationaccuracy by 1.0%.</description><author>Wentao Zhu</author><pubDate>Mon, 08 Jan 2024 17:03:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01470v2</guid></item><item><title>Efficient Multiscale Multimodal Bottleneck Transformer for Audio-Video Classification</title><link>http://arxiv.org/abs/2401.04023v1</link><description>In recent years, researchers combine both audio and video signals to dealwith challenges where actions are not well represented or captured by visualcues. However, how to effectively leverage the two modalities is still underdevelopment. In this work, we develop a multiscale multimodal Transformer (MMT)that leverages hierarchical representation learning. Particularly, MMT iscomposed of a novel multiscale audio Transformer (MAT) and a multiscale videoTransformer [43]. To learn a discriminative cross-modality fusion, we furtherdesign multimodal supervised contrastive objectives called audio-videocontrastive loss (AVC) and intra-modal contrastive loss (IMC) that robustlyalign the two modalities. MMT surpasses previous state-of-the-art approaches by7.3% and 2.1% on Kinetics-Sounds and VGGSound in terms of the top-1 accuracywithout external training data. Moreover, the proposed MAT significantlyoutperforms AST [28] by 22.2%, 4.4% and 4.7% on three public benchmarkdatasets, and is about 3% more efficient based on the number of FLOPs and 9.8%more efficient based on GPU memory usage.</description><author>Wentao Zhu</author><pubDate>Mon, 08 Jan 2024 17:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04023v1</guid></item><item><title>Learning solutions to some toy constrained optimization problems in infinite dimensional Hilbert spaces</title><link>http://arxiv.org/abs/2401.01306v2</link><description>In this work we present deep learning implementations of two populartheoretical constrained optimization algorithms in infinite dimensional Hilbertspaces, namely, the penalty and the augmented Lagrangian methods. We test thesealgorithms on some toy problems originating in either calculus of variations orphysics. We demonstrate that both methods are able to produce decentapproximations for the test problems and are comparable in terms of differenterrors produced. Leveraging the common occurrence of the Lagrange multiplierupdate rule being computationally less expensive than solving subproblems inthe penalty method, we achieve significant speedups in cases when the output ofthe constraint function is itself a function.</description><author>Pinak Mandal</author><pubDate>Mon, 08 Jan 2024 16:57:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01306v2</guid></item><item><title>Weak Correlations as the Underlying Principle for Linearization of Gradient-Based Learning Systems</title><link>http://arxiv.org/abs/2401.04013v1</link><description>Deep learning models, such as wide neural networks, can be conceptualized asnonlinear dynamical physical systems characterized by a multitude ofinteracting degrees of freedom. Such systems in the infinite limit, tend toexhibit simplified dynamics. This paper delves into gradient descent-basedlearning algorithms, that display a linear structure in their parameterdynamics, reminiscent of the neural tangent kernel. We establish this apparentlinearity arises due to weak correlations between the first and higher-orderderivatives of the hypothesis function, concerning the parameters, taken aroundtheir initial values. This insight suggests that these weak correlations couldbe the underlying reason for the observed linearization in such systems. As acase in point, we showcase this weak correlations structure within neuralnetworks in the large width limit. Exploiting the relationship betweenlinearity and weak correlations, we derive a bound on deviations from linearityobserved during the training trajectory of stochastic gradient descent. Tofacilitate our proof, we introduce a novel method to characterise theasymptotic behavior of random tensors.</description><author>Ori Shem-Ur, Yaron Oz</author><pubDate>Mon, 08 Jan 2024 16:44:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04013v1</guid></item><item><title>Generative adversarial wavelet neural operator: Application to fault detection and isolation of multivariate time series data</title><link>http://arxiv.org/abs/2401.04004v1</link><description>Fault detection and isolation in complex systems are critical to ensurereliable and efficient operation. However, traditional fault detection methodsoften struggle with issues such as nonlinearity and multivariatecharacteristics of the time series variables. This article proposes agenerative adversarial wavelet neural operator (GAWNO) as a novel unsuperviseddeep learning approach for fault detection and isolation of multivariate timeseries processes.The GAWNO combines the strengths of wavelet neural operatorsand generative adversarial networks (GANs) to effectively capture both thetemporal distributions and the spatial dependencies among different variablesof an underlying system. The approach of fault detection and isolation usingGAWNO consists of two main stages. In the first stage, the GAWNO is trained ona dataset of normal operating conditions to learn the underlying datadistribution. In the second stage, a reconstruction error-based thresholdapproach using the trained GAWNO is employed to detect and isolate faults basedon the discrepancy values. We validate the proposed approach using theTennessee Eastman Process (TEP) dataset and Avedore wastewater treatment plant(WWTP) and N2O emissions named as WWTPN2O datasets. Overall, we showcase thatthe idea of harnessing the power of wavelet analysis, neural operators, andgenerative models in a single framework to detect and isolate faults has shownpromising results compared to various well-established baselines in theliterature.</description><author>Jyoti Rani, Tapas Tripura, Hariprasad Kodamana, Souvik Chakraborty</author><pubDate>Mon, 08 Jan 2024 16:36:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04004v1</guid></item><item><title>Simultaneous Task Allocation and Planning for Multi-Robots under Hierarchical Temporal Logic Specifications</title><link>http://arxiv.org/abs/2401.04003v1</link><description>Past research into robotic planning with temporal logic specifications,notably Linear Temporal Logic (LTL), was largely based on singular formulas forindividual or groups of robots. But with increasing task complexity, LTLformulas unavoidably grow lengthy, complicating interpretation andspecification generation, and straining the computational capacities of theplanners. In order to maximize the potential of LTL specifications, wecapitalized on the intrinsic structure of tasks and introduced a hierarchicalstructure to LTL specifications, and designed an algorithm to ascertain whetherthey are satisfied given an input sequence. Second, we employ a search-basedapproach to synthesize plans for a multi-robot system, accomplishingsimultaneous task allocation and planning. The search space is approximated byloosely interconnected sub-spaces, with each sub-space corresponding to one LTLspecification. The search is predominantly confined to a single sub-space,transitioning to another sub-space under certain conditions, determined by thedecomposition of automatons. Moreover, multiple heuristics are formulated toexpedite the search significantly. A theoretical analysis concerningcompleteness and optimality is conducted under mild assumptions. When comparedwith existing methods on service tasks, our method outperforms in terms ofexecution times with comparable solution quality. Finally, scalability isevaluated by testing a group of 30 robots and achieving reasonable runtimes.</description><author>Xusheng Luo, Changliu Liu</author><pubDate>Mon, 08 Jan 2024 16:35:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04003v1</guid></item><item><title>Polynomial Precision Dependence Solutions to Alignment Research Center Matrix Completion Problems</title><link>http://arxiv.org/abs/2401.03999v1</link><description>We present solutions to the matrix completion problems proposed by theAlignment Research Center that have a polynomial dependence on the precision$\varepsilon$. The motivation for these problems is to enable efficientcomputation of heuristic estimators to formally evaluate and reason aboutdifferent quantities of deep neural networks in the interest of AI alignment.Our solutions involve reframing the matrix completion problems as asemidefinite program (SDP) and using recent advances in spectral bundle methodsfor fast, efficient, and scalable SDP solving.</description><author>Rico Angell</author><pubDate>Mon, 08 Jan 2024 16:25:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03999v1</guid></item><item><title>A Comprehensive Study of Knowledge Editing for Large Language Models</title><link>http://arxiv.org/abs/2401.01286v2</link><description>Large Language Models (LLMs) have shown extraordinary capabilities inunderstanding and generating text that closely mirrors human communication.However, a primary limitation lies in the significant computational demandsduring training, arising from their extensive parameterization. This challengeis further intensified by the dynamic nature of the world, necessitatingfrequent updates to LLMs to correct outdated information or integrate newknowledge, thereby ensuring their continued relevance. Note that manyapplications demand continual model adjustments post-training to addressdeficiencies or undesirable behaviors. There is an increasing interest inefficient, lightweight methods for on-the-fly model modifications. To this end,recent years have seen a burgeoning in the techniques of knowledge editing forLLMs, which aim to efficiently modify LLMs' behaviors within specific domainswhile preserving overall performance across various inputs. In this paper, wefirst define the knowledge editing problem and then provide a comprehensivereview of cutting-edge approaches. Drawing inspiration from educational andcognitive research theories, we propose a unified categorization criterion thatclassifies knowledge editing methods into three groups: resorting to externalknowledge, merging knowledge into the model, and editing intrinsic knowledge.Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensiveempirical evaluation of representative knowledge editing approaches.Additionally, we provide an in-depth analysis of knowledge location, which canprovide a deeper understanding of the knowledge structures inherent withinLLMs. Finally, we discuss several potential applications of knowledge editing,outlining its broad and impactful implications.</description><author>Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, Siyuan Cheng, Ziwen Xu, Xin Xu, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, Huajun Chen</author><pubDate>Mon, 08 Jan 2024 16:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01286v2</guid></item><item><title>Standardized CycleGAN training for unsupervised stain adaptation in invasive carcinoma classification for breast histopathology</title><link>http://arxiv.org/abs/2301.13128v2</link><description>Generalization is one of the main challenges of computational pathology.Slide preparation heterogeneity and the diversity of scanners lead to poormodel performance when used on data from medical centers not seen duringtraining. In order to achieve stain invariance in breast invasive carcinomapatch classification, we implement a stain translation strategy using cycleGANsfor unsupervised image-to-image translation. We compare three cycleGAN-basedapproaches to a baseline classification model obtained without any staininvariance strategy. Two of the proposed approaches use cycleGAN's translationsat inference or training in order to build stain-specific classificationmodels. The last method uses them for stain data augmentation during training.This constrains the classification model to learn stain-invariant features.Baseline metrics are set by training and testing the baseline classificationmodel on a reference stain. We assessed performances using three medicalcenters with H&amp;E and H&amp;E&amp;S staining. Every approach tested in this studyimproves baseline metrics without needing labels on target stains. The stainaugmentation-based approach produced the best results on every stain. Eachmethod's pros and cons are studied and discussed in this paper. However,training highly performing cycleGANs models in itself represents a challenge.In this work, we introduce a systematical method for optimizing cycleGANtraining by setting a novel stopping criterion. This method has the benefit ofnot requiring any visual inspection of cycleGAN results and proves superiorityto methods using a predefined number of training epochs. In addition, we alsostudy the minimal amount of data required for cycleGAN training.</description><author>Nicolas Nerrienet, Rémy Peyret, Marie Sockeel, Stéphane Sockeel</author><pubDate>Mon, 08 Jan 2024 16:24:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13128v2</guid></item><item><title>If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents</title><link>http://arxiv.org/abs/2401.00812v2</link><description>The prominent large language models (LLMs) of today differ from past languagemodels not only in size, but also in the fact that they are trained on acombination of natural language and formal language (code). As a medium betweenhumans and computers, code translates high-level goals into executable steps,featuring standard syntax, logical consistency, abstraction, and modularity. Inthis survey, we present an overview of the various benefits of integrating codeinto LLMs' training data. Specifically, beyond enhancing LLMs in codegeneration, we observe that these unique properties of code help (i) unlock thereasoning ability of LLMs, enabling their applications to a range of morecomplex natural language tasks; (ii) steer LLMs to produce structured andprecise intermediate steps, which can then be connected to external executionends through function calls; and (iii) take advantage of code compilation andexecution environment, which also provides diverse feedback for modelimprovement. In addition, we trace how these profound capabilities of LLMs,brought by code, have led to their emergence as intelligent agents (IAs) insituations where the ability to understand instructions, decompose goals, planand execute actions, and refine from feedback are crucial to their success ondownstream tasks. Finally, we present several key challenges and futuredirections of empowering LLMs with code.</description><author>Ke Yang, Jiateng Liu, John Wu, Chaoqi Yang, Yi R. Fung, Sha Li, Zixuan Huang, Xu Cao, Xingyao Wang, Yiquan Wang, Heng Ji, Chengxiang Zhai</author><pubDate>Mon, 08 Jan 2024 16:22:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00812v2</guid></item><item><title>A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models</title><link>http://arxiv.org/abs/2401.01313v3</link><description>As Large Language Models (LLMs) continue to advance in their ability to writehuman-like text, a key challenge remains around their tendency to hallucinategenerating content that appears factual but is ungrounded. This issue ofhallucination is arguably the biggest hindrance to safely deploying thesepowerful LLMs into real-world production systems that impact people's lives.The journey toward widespread adoption of LLMs in practical settings heavilyrelies on addressing and mitigating hallucinations. Unlike traditional AIsystems focused on limited tasks, LLMs have been exposed to vast amounts ofonline text data during training. While this allows them to display impressivelanguage fluency, it also means they are capable of extrapolating informationfrom the biases in training data, misinterpreting ambiguous prompts, ormodifying the information to align superficially with the input. This becomeshugely alarming when we rely on language generation capabilities for sensitiveapplications, such as summarizing medical records, financial analysis reports,etc. This paper presents a comprehensive survey of over 32 techniques developedto mitigate hallucination in LLMs. Notable among these are Retrieval AugmentedGeneration (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023),CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, weintroduce a detailed taxonomy categorizing these methods based on variousparameters, such as dataset utilization, common tasks, feedback mechanisms, andretriever types. This classification helps distinguish the diverse approachesspecifically designed to tackle hallucination issues in LLMs. Additionally, weanalyze the challenges and limitations inherent in these techniques, providinga solid foundation for future research in addressing hallucinations and relatedphenomena within the realm of LLMs.</description><author>S. M Towhidul Islam Tonmoy, S M Mehedi Zaman, Vinija Jain, Anku Rani, Vipula Rawte, Aman Chadha, Amitava Das</author><pubDate>Mon, 08 Jan 2024 16:19:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01313v3</guid></item><item><title>Behavioural Cloning in VizDoom</title><link>http://arxiv.org/abs/2401.03993v1</link><description>This paper describes methods for training autonomous agents to play the game"Doom 2" through Imitation Learning (IL) using only pixel data as input. Wealso explore how Reinforcement Learning (RL) compares to IL for humanness bycomparing camera movement and trajectory data. Through behavioural cloning, weexamine the ability of individual models to learn varying behavioural traits.We attempt to mimic the behaviour of real players with different play styles,and find we can train agents that behave aggressively, passively, or simplymore human-like than traditional AIs. We propose these methods of introducingmore depth and human-like behaviour to agents in video games. The trained ILagents perform on par with the average players in our dataset, whilstoutperforming the worst players. While performance was not as strong as commonRL approaches, it provides much stronger human-like behavioural traits to theagent.</description><author>Ryan Spick, Timothy Bradley, Ayush Raina, Pierluigi Vito Amadori, Guy Moss</author><pubDate>Mon, 08 Jan 2024 16:15:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03993v1</guid></item><item><title>Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark</title><link>http://arxiv.org/abs/2401.03991v1</link><description>Artificial intelligence (AI) has made remarkable progress across variousdomains, with large language models like ChatGPT gaining substantial attentionfor their human-like text-generation capabilities. Despite these achievements,spatial reasoning remains a significant challenge for these models. Benchmarkslike StepGame evaluate AI spatial reasoning, where ChatGPT has shownunsatisfactory performance. However, the presence of template errors in thebenchmark has an impact on the evaluation results. Thus there is potential forChatGPT to perform better if these template errors are addressed, leading tomore accurate assessments of its spatial reasoning capabilities. In this study,we refine the StepGame benchmark, providing a more accurate dataset for modelevaluation. We analyze GPT's spatial reasoning performance on the rectifiedbenchmark, identifying proficiency in mapping natural language text to spatialrelations but limitations in multi-hop reasoning. We provide a flawlesssolution to the benchmark by combining template-to-relation mapping withlogic-based reasoning. This combination demonstrates proficiency in performingqualitative reasoning on StepGame without encountering any errors. We thenaddress the limitations of GPT models in spatial reasoning. We deployChain-of-thought and Tree-of-thoughts prompting strategies, offering insightsinto GPT's ``cognitive process", and achieving remarkable improvements inaccuracy. Our investigation not only sheds light on model deficiencies but alsoproposes enhancements, contributing to the advancement of AI with more robustspatial reasoning capabilities.</description><author>Fangjun Li, David C. Hogg, Anthony G. Cohn</author><pubDate>Mon, 08 Jan 2024 16:13:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03991v1</guid></item><item><title>MS-DETR: Efficient DETR Training with Mixed Supervision</title><link>http://arxiv.org/abs/2401.03989v1</link><description>DETR accomplishes end-to-end object detection through iteratively generatingmultiple object candidates based on image features and promoting one candidatefor each ground-truth object. The traditional training procedure usingone-to-one supervision in the original DETR lacks direct supervision for theobject detection candidates. We aim at improving the DETR training efficiency by explicitly supervisingthe candidate generation procedure through mixing one-to-one supervision andone-to-many supervision. Our approach, namely MS-DETR, is simple, and placesone-to-many supervision to the object queries of the primary decoder that isused for inference. In comparison to existing DETR variants with one-to-manysupervision, such as Group DETR and Hybrid DETR, our approach does not needadditional decoder branches or object queries. The object queries of theprimary decoder in our approach directly benefit from one-to-many supervisionand thus are superior in object candidate prediction. Experimental results showthat our approach outperforms related DETR variants, such as DN-DETR, HybridDETR, and Group DETR, and the combination with related DETR variants furtherimproves the performance.</description><author>Chuyang Zhao, Yifan Sun, Wenhao Wang, Qiang Chen, Errui Ding, Yi Yang, Jingdong Wang</author><pubDate>Mon, 08 Jan 2024 16:08:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03989v1</guid></item><item><title>A Primer on Temporal Graph Learning</title><link>http://arxiv.org/abs/2401.03988v1</link><description>This document aims to familiarize readers with temporal graph learning (TGL)through a concept-first approach. We have systematically presented vitalconcepts essential for understanding the workings of a TGL framework. Inaddition to qualitative explanations, we have incorporated mathematicalformulations where applicable, enhancing the clarity of the text. Since TGLinvolves temporal and spatial learning, we introduce relevant learningarchitectures ranging from recurrent and convolutional neural networks totransformers and graph neural networks. We also discuss classical time seriesforecasting methods to inspire interpretable learning solutions for TGL.</description><author>Aniq Ur Rahman, Justin P. Coon</author><pubDate>Mon, 08 Jan 2024 16:08:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03988v1</guid></item><item><title>TSPP: A Unified Benchmarking Tool for Time-series Forecasting</title><link>http://arxiv.org/abs/2312.17100v2</link><description>While machine learning has witnessed significant advancements, the emphasishas largely been on data acquisition and model creation. However, achieving acomprehensive assessment of machine learning solutions in real-world settingsnecessitates standardization throughout the entire pipeline. This need isparticularly acute in time series forecasting, where diverse settings impedemeaningful comparisons between various methods. To bridge this gap, we proposea unified benchmarking framework that exposes the crucial modelling and machinelearning decisions involved in developing time series forecasting models. Thisframework fosters seamless integration of models and datasets, aiding bothpractitioners and researchers in their development efforts. We benchmarkrecently proposed models within this framework, demonstrating that carefullyimplemented deep learning models with minimal effort can rivalgradient-boosting decision trees requiring extensive feature engineering andexpert knowledge.</description><author>Jan Bączek, Dmytro Zhylko, Gilberto Titericz, Sajad Darabi, Jean-Francois Puget, Izzy Putterman, Dawid Majchrowski, Anmol Gupta, Kyle Kranen, Pawel Morkisz</author><pubDate>Mon, 08 Jan 2024 16:04:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17100v2</guid></item><item><title>The Impact of Adversarial Node Placement in Decentralized Federated Learning Networks</title><link>http://arxiv.org/abs/2311.07946v2</link><description>As Federated Learning (FL) grows in popularity, new decentralized frameworksare becoming widespread. These frameworks leverage the benefits ofdecentralized environments to enable fast and energy-efficient inter-devicecommunication. However, this growing popularity also intensifies the need forrobust security measures. While existing research has explored various aspectsof FL security, the role of adversarial node placement in decentralizednetworks remains largely unexplored. This paper addresses this gap by analyzingthe performance of decentralized FL for various adversarial placementstrategies when adversaries can jointly coordinate their placement within anetwork. We establish two baseline strategies for placing adversarial node:random placement and network centrality-based placement. Building on thisfoundation, we propose a novel attack algorithm that prioritizes adversarialspread over adversarial centrality by maximizing the average network distancebetween adversaries. We show that the new attack algorithm significantlyimpacts key performance metrics such as testing accuracy, outperforming thebaseline frameworks by between 9% and 66.5% for the considered setups. Ourfindings provide valuable insights into the vulnerabilities of decentralized FLsystems, setting the stage for future research aimed at developing more secureand robust decentralized FL frameworks.</description><author>Adam Piaseczny, Eric Ruzomberka, Rohit Parasnis, Christopher G. Brinton</author><pubDate>Mon, 08 Jan 2024 15:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07946v2</guid></item><item><title>Conditional expectation using compactification operators</title><link>http://arxiv.org/abs/2306.10592v4</link><description>The separate tasks of denoising, least squares expectation, and manifoldlearning can often be posed in a common setting of finding the conditionalexpectations arising from a product of two random variables. This paper focuseson this more general problem and describes an operator theoretic approach toestimating the conditional expectation. Kernel integral operators are used as acompactification tool, to set up the estimation problem as a linear inverseproblem in a reproducing kernel Hilbert space. This equation is shown to havesolutions that allow numerical approximation, thus guaranteeing the convergenceof data-driven implementations. The overall technique is easy to implement, andtheir successful application to some real-world problems are also shown.</description><author>Suddhasattwa Das</author><pubDate>Mon, 08 Jan 2024 15:49:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10592v4</guid></item><item><title>scDiffusion: conditional generation of high-quality single-cell data using diffusion model</title><link>http://arxiv.org/abs/2401.03968v1</link><description>Single-cell RNA sequencing (scRNA-seq) data are important for studying thebiology of development or diseases at single-cell level. To better understandthe properties of the data, to build controlled benchmark data for testingdownstream methods, and to augment data when collecting sufficient real data ischallenging, generative models have been proposed to computationally generatesynthetic scRNA-seq data. However, the data generated with current models arenot very realistic yet, especially when we need to generate data withcontrolled conditions. In the meantime, the Diffusion models have shown theirpower in generating data in computer vision at high fidelity, providing a newopportunity for scRNA-seq generation. In this study, we developed scDiffusion, a diffusion-based model to generatehigh-quality scRNA-seq data with controlled conditions. We designed multipleclassifiers to guide the diffusion process simultaneously, enabling scDiffusionto generate data under multiple condition combinations. We also proposed a newcontrol strategy called Gradient Interpolation. This strategy allows the modelto generate continuous trajectories of cell development from a given cellstate. Experiments showed that scDiffusion can generate single-cell gene expressiondata closely resembling real scRNA-seq data, surpassing state-of-the-art modelsin multiple metrics. Also, scDiffusion can conditionally produce data onspecific cell types including rare cell types. Furthermore, we could use themultiple-condition generation of scDiffusion to generate cell type that was outof the training data. Leveraging the Gradient Interpolation strategy, wegenerated a continuous developmental trajectory of mouse embryonic cells. Theseexperiments demonstrate that scDiffusion is a powerful tool for augmenting thereal scRNA-seq data and can provide insights into cell fate research.</description><author>Erpai Luo, Minsheng Hao, Lei Wei, Xuegong Zhang</author><pubDate>Mon, 08 Jan 2024 15:44:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03968v1</guid></item><item><title>Differential Equations for Continuous-Time Deep Learning</title><link>http://arxiv.org/abs/2401.03965v1</link><description>This short, self-contained article seeks to introduce and surveycontinuous-time deep learning approaches that are based on neural ordinarydifferential equations (neural ODEs). It primarily targets readers familiarwith ordinary and partial differential equations and their analysis who arecurious to see their role in machine learning. Using three examples frommachine learning and applied mathematics, we will see how neural ODEs canprovide new insights into deep learning and a foundation for more efficientalgorithms.</description><author>Lars Ruthotto</author><pubDate>Mon, 08 Jan 2024 15:40:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03965v1</guid></item><item><title>PPBFL: A Privacy Protected Blockchain-based Federated Learning Model</title><link>http://arxiv.org/abs/2401.01204v2</link><description>With the rapid development of machine learning and a growing concern for dataprivacy, federated learning has become a focal point of attention. However,attacks on model parameters and a lack of incentive mechanisms hinder theeffectiveness of federated learning. Therefore, we propose A Privacy ProtectedBlockchain-based Federated Learning Model (PPBFL) to enhance the security offederated learning and encourage active participation of nodes in modeltraining. Blockchain technology ensures the integrity of model parametersstored in the InterPlanetary File System (IPFS), providing protection againsttampering. Within the blockchain, we introduce a Proof of Training Work (PoTW)consensus algorithm tailored for federated learning, aiming to incentivetraining nodes. This algorithm rewards nodes with greater computational power,promoting increased participation and effort in the federated learning process.A novel adaptive differential privacy algorithm is simultaneously applied tolocal and global models. This safeguards the privacy of local data at trainingclients, preventing malicious nodes from launching inference attacks.Additionally, it enhances the security of the global model, preventingpotential security degradation resulting from the combination of numerous localmodels. The possibility of security degradation is derived from the compositiontheorem. By introducing reverse noise in the global model, a zero-bias estimateof differential privacy noise between local and global models is achieved.Furthermore, we propose a new mix transactions mechanism utilizing ringsignature technology to better protect the identity privacy of local trainingclients. Security analysis and experimental results demonstrate that PPBFL,compared to baseline methods, not only exhibits superior model performance butalso achieves higher security.</description><author>Yang Li, Chunhe Xia, Wanshuang Lin, Tianbo Wang</author><pubDate>Mon, 08 Jan 2024 15:38:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01204v2</guid></item><item><title>Entry Dependent Expert Selection in Distributed Gaussian Processes Using Multilabel Classification</title><link>http://arxiv.org/abs/2211.09940v2</link><description>By distributing the training process, local approximation reduces the cost ofthe standard Gaussian Process. An ensemble technique combines local predictionsfrom Gaussian experts trained on different partitions of the data. Ensemblemethods aggregate models' predictions by assuming a perfect diversity of localpredictors. Although it keeps the aggregation tractable, this assumption isoften violated in practice. Even though ensemble methods provide consistentresults by assuming dependencies between experts, they have a highcomputational cost, which is cubic in the number of experts involved. Byimplementing an expert selection strategy, the final aggregation step usesfewer experts and is more efficient. However, a selection approach that assignsa fixed set of experts to each new data point cannot encode the specificproperties of each unique data point. This paper proposes a flexible expertselection approach based on the characteristics of entry data points. To thisend, we investigate the selection task as a multi-label classification problemwhere the experts define labels, and each entry point is assigned to someexperts. The proposed solution's prediction quality, efficiency, and asymptoticproperties are discussed in detail. We demonstrate the efficacy of our methodthrough extensive numerical experiments using synthetic and real-world datasets.</description><author>Hamed Jalali, Gjergji Kasneci</author><pubDate>Mon, 08 Jan 2024 15:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.09940v2</guid></item><item><title>Distributed Quantum Neural Networks via Partitioned Features Encoding</title><link>http://arxiv.org/abs/2312.13650v2</link><description>Quantum neural networks are expected to be a promising application innear-term quantum computing, but face challenges such as vanishing gradientsduring optimization and limited expressibility by a limited number of qubitsand shallow circuits. To mitigate these challenges, an approach usingdistributed quantum neural networks has been proposed to make a prediction byapproximating outputs of a large circuit using multiple small circuits.However, the approximation of a large circuit requires an exponential number ofsmall circuit evaluations. Here, we instead propose to distribute partitionedfeatures over multiple small quantum neural networks and use the ensemble oftheir expectation values to generate predictions. To verify our distributedapproach, we demonstrate ten class classification of the Semeion and MNISThandwritten digit datasets. The results of the Semeion dataset imply that whileour distributed approach may outperform a single quantum neural network inclassification performance, excessive partitioning reduces performance.Nevertheless, for the MNIST dataset, we succeeded in ten class classificationwith exceeding 96\% accuracy. Our proposed method not only achieved highlyaccurate predictions for a large dataset but also reduced the hardwarerequirements for each quantum neural network compared to a large single quantumneural network. Our results highlight distributed quantum neural networks as apromising direction for practical quantum machine learning algorithmscompatible with near-term quantum devices. We hope that our approach is usefulfor exploring quantum machine learning applications.</description><author>Yoshiaki Kawase</author><pubDate>Mon, 08 Jan 2024 15:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13650v2</guid></item><item><title>Comparing Data-Driven and Mechanistic Models for Predicting Phenology in Deciduous Broadleaf Forests</title><link>http://arxiv.org/abs/2401.03960v1</link><description>Understanding the future climate is crucial for informed policy decisions onclimate change prevention and mitigation. Earth system models play an importantrole in predicting future climate, requiring accurate representation of complexsub-processes that span multiple time scales and spatial scales. One suchprocess that links seasonal and interannual climate variability to cyclicalbiological events is tree phenology in deciduous broadleaf forests.Phenological dates, such as the start and end of the growing season, arecritical for understanding the exchange of carbon and water between thebiosphere and the atmosphere. Mechanistic prediction of these dates ischallenging. Hybrid modelling, which integrates data-driven approaches intocomplex models, offers a solution. In this work, as a first step towards thisgoal, train a deep neural network to predict a phenological index frommeteorological time series. We find that this approach outperforms traditionalprocess-based models. This highlights the potential of data-driven methods toimprove climate predictions. We also analyze which variables and aspects of thetime series influence the predicted onset of the season, in order to gain abetter understanding of the advantages and limitations of our model.</description><author>Christian Reimers, David Hafezi Rachti, Guahua Liu, Alexander J. Winkler</author><pubDate>Mon, 08 Jan 2024 15:29:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03960v1</guid></item><item><title>TTMs: Fast Multi-level Tiny Time Mixers for Improved Zero-shot and Few-shot Forecasting of Multivariate Time Series</title><link>http://arxiv.org/abs/2401.03955v1</link><description>Large Pretrained models for Zero/Few-shot learning excel in language andvision domains but encounter challenges in multivariate time series (TS) due tothe diverse nature and scarcity of publicly available pretraining data.Consequently, there has been a recent surge in utilizing pretrained largelanguage models (LLMs) with various adaptations for time series forecasting.These approaches employ cross-domain transfer learning, yielding highlyimpressive results. However, these models are typically very large ($\sim$billion parameters), exhibit slow execution, and do not consider cross-channelcorrelations. To address this, we present Multi-level Tiny Time Mixers (TTM), asignificantly smaller model based on the lightweight TSMixer architecture. TTMmarks the first success in developing tiny pretrained models ($\le$1 millionparameters), exclusively trained on public TS data with effective transferlearning capabilities. To tackle the complexity of pretraining on multipledatasets with varied temporal resolutions, we introduce several novelenhancements such as adaptive patching, dataset augmentation via downsampling,and resolution prefix tuning. Moreover, we employ a multi-level modelingstrategy to effectively model channel correlations and incorporate exogenoussignals during finetuning, a crucial capability lacking in existing benchmarks.TTM excels in few/zero-shot forecasting, demonstrating significant accuracygains (12-38%) over existing benchmarks. Further, it achieves a remarkable14-106X reduction in model parameters, enabling 54-65X fastertraining/inference as compared to the LLM-TS benchmarks. In fact, TTM'szero-shot results often surpass the few-shot results in many benchmarks,highlighting the efficacy of our approach. Code and Pretrained Models will beopen-sourced.</description><author>Vijay Ekambaram, Arindam Jati, Nam H. Nguyen, Pankaj Dayama, Chandra Reddy, Wesley M. Gifford, Jayant Kalagnanam</author><pubDate>Mon, 08 Jan 2024 15:21:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03955v1</guid></item><item><title>The Deep Latent Position Topic Model for Clustering and Representation of Networks with Textual Edges</title><link>http://arxiv.org/abs/2304.08242v2</link><description>Numerical interactions leading to users sharing textual content published byothers are naturally represented by a network where the individuals areassociated with the nodes and the exchanged texts with the edges. To understandthose heterogeneous and complex data structures, clustering nodes intohomogeneous groups as well as rendering a comprehensible visualisation of thedata is mandatory. To address both issues, we introduce Deep-LPTM, amodel-based clustering strategy relying on a variational graph auto-encoderapproach as well as a probabilistic model to characterise the topics ofdiscussion. Deep-LPTM allows to build a joint representation of the nodes andof the edges in two embeddings spaces. The parameters are inferred using avariational inference algorithm. We also introduce IC2L, a model selectioncriterion specifically designed to choose models with relevant clustering andvisualisation properties. An extensive benchmark study on synthetic data isprovided. In particular, we find that Deep-LPTM better recovers the partitionsof the nodes than the state-of-the art ETSBM and STBM. Eventually, the emailsof the Enron company are analysed and visualisations of the results arepresented, with meaningful highlights of the graph structure.</description><author>Rémi Boutin, Pierre Latouche, Charles Bouveyron</author><pubDate>Mon, 08 Jan 2024 15:14:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08242v2</guid></item><item><title>Guiding drones by information gain</title><link>http://arxiv.org/abs/2401.03947v1</link><description>The accurate estimation of locations and emission rates of gas sources iscrucial across various domains, including environmental monitoring andgreenhouse gas emission analysis. This study investigates two drone samplingstrategies for inferring source term parameters of gas plumes from atmosphericmeasurements. Both strategies are guided by the goal of maximizing informationgain attained from observations at sequential locations. Our research comparesthe myopic approach of infotaxis to a far-sighted navigation strategy trainedthrough deep reinforcement learning. We demonstrate the superior performance ofdeep reinforcement learning over infotaxis in environments with non-isotropicgas plumes.</description><author>Alouette van Hove, Kristoffer Aalstad, Norbert Pirk</author><pubDate>Mon, 08 Jan 2024 15:13:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03947v1</guid></item><item><title>TextMachina: Seamless Generation of Machine-Generated Text Datasets</title><link>http://arxiv.org/abs/2401.03946v1</link><description>Recent advancements in Large Language Models (LLMs) have led to high-qualityMachine-Generated Text (MGT), giving rise to countless new use cases andapplications. However, easy access to LLMs is posing new challenges due tomisuse. To address malicious usage, researchers have released datasets toeffectively train models on MGT-related tasks. Similar strategies are used tocompile these datasets, but no tool currently unifies them. In this scenario,we introduce TextMachina, a modular and extensible Python framework, designedto aid in the creation of high-quality, unbiased datasets to build robustmodels for MGT-related tasks such as detection, attribution, or boundarydetection. It provides a user-friendly pipeline that abstracts away theinherent intricacies of building MGT datasets, such as LLM integrations, prompttemplating, and bias mitigation. The quality of the datasets generated byTextMachina has been assessed in previous works, including shared tasks wheremore than one hundred teams trained robust MGT detectors.</description><author>Areg Mikael Sarvazyan, José Ángel González, Marc Franco-Salvador</author><pubDate>Mon, 08 Jan 2024 15:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03946v1</guid></item><item><title>SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems</title><link>http://arxiv.org/abs/2401.03945v1</link><description>Human communication is a complex and diverse process that not only involvesmultiple factors such as language, commonsense, and cultural backgrounds butalso requires the participation of multimodal information, such as speech.Large Language Model (LLM)-based multi-agent systems have demonstratedpromising performance in simulating human society. Can we leverage LLM-basedmulti-agent systems to simulate human communication? However, current LLM-basedmulti-agent systems mainly rely on text as the primary medium. In this paper,we propose SpeechAgents, a multi-modal LLM based multi-agent system designedfor simulating human communication. SpeechAgents utilizes multi-modal LLM asthe control center for individual agent and employes multi-modal signals as themedium for exchanged messages among agents. Additionally, we proposeMulti-Agent Tuning to enhance the multi-agent capabilities of LLM withoutcompromising general abilities. To strengthen and evaluate the effectiveness ofhuman communication simulation, we build the Human-Communication SimulationBenchmark. Experimental results demonstrate that SpeechAgents can simulatehuman communication dialogues with consistent content, authentic rhythm, andrich emotions and demonstrate excellent scalability even with up to 25 agents,which can apply to tasks such as drama creation and audio novels generation.Code and models will be open-sourced at https://github.com/0nutation/SpeechAgents</description><author>Dong Zhang, Zhaowei Li, Pengyu Wang, Xin Zhang, Yaqian Zhou, Xipeng Qiu</author><pubDate>Mon, 08 Jan 2024 15:01:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03945v1</guid></item><item><title>ARFA: An Asymmetric Receptive Field Autoencoder Model for Spatiotemporal Prediction</title><link>http://arxiv.org/abs/2309.00314v2</link><description>Spatiotemporal prediction aims to generate future sequences by paradigmslearned from historical contexts. It is essential in numerous domains, such astraffic flow prediction and weather forecasting. Recently, research in thisfield has been predominantly driven by deep neural networks based onautoencoder architectures. However, existing methods commonly adopt autoencoderarchitectures with identical receptive field sizes. To address this issue, wepropose an Asymmetric Receptive Field Autoencoder (ARFA) model, whichintroduces corresponding sizes of receptive field modules tailored to thedistinct functionalities of the encoder and decoder. In the encoder, we presenta large kernel module for global spatiotemporal feature extraction. In thedecoder, we develop a small kernel module for local spatiotemporal informationreconstruction. Experimental results demonstrate that ARFA consistentlyachieves state-of-the-art performance on popular datasets. Additionally, weconstruct the RainBench, a large-scale radar echo dataset for precipitationprediction, to address the scarcity of meteorological data in the domain.</description><author>Wenxuan Zhang, Xuechao Zou, Li Wu, Xiaoying Wang, Jianqiang Huang, Junliang Xing</author><pubDate>Mon, 08 Jan 2024 14:57:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00314v2</guid></item><item><title>Multi-scale attention-based instance segmentation for measuring crystals with large size variation</title><link>http://arxiv.org/abs/2401.03939v1</link><description>Quantitative measurement of crystals in high-resolution images allows forimportant insights into underlying material characteristics. Deep learning hasshown great progress in vision-based automatic crystal size measurement, butcurrent instance segmentation methods reach their limits with images that havelarge variation in crystal size or hard to detect crystal boundaries. Evensmall image segmentation errors, such as incorrectly fused or separatedsegments, can significantly lower the accuracy of the measured results. Insteadof improving the existing pixel-wise boundary segmentation methods, we proposeto use an instance-based segmentation method, which gives more robustsegmentation results to improve measurement accuracy. Our novel method enhancesflow maps with a size-aware multi-scale attention module. The attention moduleadaptively fuses information from multiple scales and focuses on the mostrelevant scale for each segmented image area. We demonstrate that our proposedattention fusion strategy outperforms state-of-the-art instance and boundarysegmentation methods, as well as simple average fusion of multi-scalepredictions. We evaluate our method on a refractory raw material dataset ofhigh-resolution images with large variation in crystal size and show that ourmodel can be used to calculate the crystal size more accurately than existingmethods.</description><author>Theresa Neubauer, Astrid Berg, Maria Wimmer, Dimitrios Lenis, David Major, Philip Matthias Winter, Gaia Romana De Paolis, Johannes Novotny, Daniel Lüftner, Katja Reinharter, Katja Bühler</author><pubDate>Mon, 08 Jan 2024 14:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03939v1</guid></item><item><title>Exploratory Evaluation of Speech Content Masking</title><link>http://arxiv.org/abs/2401.03936v1</link><description>Most recent speech privacy efforts have focused on anonymizing acousticspeaker attributes but there has not been as much research into protectinginformation from speech content. We introduce a toy problem that explores anemerging type of privacy called "content masking" which conceals selected wordsand phrases in speech. In our efforts to define this problem space, we evaluatean introductory baseline masking technique based on modifying sequences ofdiscrete phone representations (phone codes) produced from a pre-trainedvector-quantized variational autoencoder (VQ-VAE) and re-synthesized usingWaveRNN. We investigate three different masking locations and three types ofmasking strategies: noise substitution, word deletion, and phone sequencereversal. Our work attempts to characterize how masking affects two downstreamtasks: automatic speech recognition (ASR) and automatic speaker verification(ASV). We observe how the different masks types and locations impact thesedownstream tasks and discuss how these issues may influence privacy goals.</description><author>Jennifer Williams, Karla Pizzi, Paul-Gauthier Noe, Sneha Das</author><pubDate>Mon, 08 Jan 2024 14:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03936v1</guid></item><item><title>Language-free Compositional Action Generation via Decoupling Refinement</title><link>http://arxiv.org/abs/2307.03538v3</link><description>Composing simple elements into complex concepts is crucial yet challenging,especially for 3D action generation. Existing methods largely rely on extensiveneural language annotations to discern composable latent semantics, a processthat is often costly and labor-intensive. In this study, we introduce a novelframework to generate compositional actions without reliance on languageauxiliaries. Our approach consists of three main components: Action Coupling,Conditional Action Generation, and Decoupling Refinement. Action Couplingutilizes an energy model to extract the attention masks of each sub-action,subsequently integrating two actions using these attentions to generatepseudo-training examples. Then, we employ a conditional generative model, CVAE,to learn a latent space, facilitating the diverse generation. Finally, wepropose Decoupling Refinement, which leverages a self-supervised pre-trainedmodel MAE to ensure semantic consistency between the sub-actions andcompositional actions. This refinement process involves rendering generated 3Dactions into 2D space, decoupling these images into two sub-segments, using theMAE model to restore the complete image from sub-segments, and constraining therecovered images to match images rendered from raw sub-actions. Due to the lackof existing datasets containing both sub-actions and compositional actions, wecreated two new datasets, named HumanAct-C and UESTC-C, and present acorresponding evaluation metric. Both qualitative and quantitative assessmentsare conducted to show our efficacy.</description><author>Xiao Liu, Guangyi Chen, Yansong Tang, Guangrun Wang, Xiao-Ping Zhang, Ser-Nam Lim</author><pubDate>Mon, 08 Jan 2024 14:54:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03538v3</guid></item><item><title>Online Sensitivity Optimization in Differentially Private Learning</title><link>http://arxiv.org/abs/2310.00829v2</link><description>Training differentially private machine learning models requires constrainingan individual's contribution to the optimization process. This is achieved byclipping the $2$-norm of their gradient at a predetermined threshold prior toaveraging and batch sanitization. This selection adversely influencesoptimization in two opposing ways: it either exacerbates the bias due toexcessive clipping at lower values, or augments sanitization noise at highervalues. The choice significantly hinges on factors such as the dataset, modelarchitecture, and even varies within the same optimization, demandingmeticulous tuning usually accomplished through a grid search. In order tocircumvent the privacy expenses incurred in hyperparameter tuning, we present anovel approach to dynamically optimize the clipping threshold. We treat thisthreshold as an additional learnable parameter, establishing a cleanrelationship between the threshold and the cost function. This allows us tooptimize the former with gradient descent, with minimal repercussions on theoverall privacy analysis. Our method is thoroughly assessed against alternativefixed and adaptive strategies across diverse datasets, tasks, model dimensions,and privacy levels. Our results indicate that it performs comparably or betterin the evaluated scenarios, given the same privacy requirements.</description><author>Filippo Galli, Catuscia Palamidessi, Tommaso Cucinotta</author><pubDate>Mon, 08 Jan 2024 14:51:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00829v2</guid></item><item><title>LEFormer: A Hybrid CNN-Transformer Architecture for Accurate Lake Extraction from Remote Sensing Imagery</title><link>http://arxiv.org/abs/2308.04397v2</link><description>Lake extraction from remote sensing images is challenging due to the complexlake shapes and inherent data noises. Existing methods suffer from blurredsegmentation boundaries and poor foreground modeling. This paper proposes ahybrid CNN-Transformer architecture, called LEFormer, for accurate lakeextraction. LEFormer contains three main modules: CNN encoder, Transformerencoder, and cross-encoder fusion. The CNN encoder effectively recovers localspatial information and improves fine-scale details. Simultaneously, theTransformer encoder captures long-range dependencies between sequences of anylength, allowing them to obtain global features and context information. Thecross-encoder fusion module integrates the local and global features to improvemask prediction. Experimental results show that LEFormer consistently achievesstate-of-the-art performance and efficiency on the Surface Water and theQinghai-Tibet Plateau Lake datasets. Specifically, LEFormer achieves 90.86% and97.42% mIoU on two datasets with a parameter count of 3.61M, respectively,while being 20 minor than the previous best lake extraction method. The sourcecode is available at https://github.com/BastianChen/LEFormer.</description><author>Ben Chen, Xuechao Zou, Yu Zhang, Jiayu Li, Kai Li, Junliang Xing, Pin Tao</author><pubDate>Mon, 08 Jan 2024 14:50:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04397v2</guid></item><item><title>Using reinforcement learning to improve drone-based inference of greenhouse gas fluxes</title><link>http://arxiv.org/abs/2401.03932v1</link><description>Accurate mapping of greenhouse gas fluxes at the Earth's surface is essentialfor the validation and calibration of climate models. In this study, we presenta framework for surface flux estimation with drones. Our approach uses dataassimilation (DA) to infer fluxes from drone-based observations, andreinforcement learning (RL) to optimize the drone's sampling strategy. Herein,we demonstrate that a RL-trained drone can quantify a CO2 hotspot moreaccurately than a drone sampling along a predefined flight path that traversesthe emission plume. We find that information-based reward functions can matchthe performance of an error-based reward function that quantifies thedifference between the estimated surface flux and the true value. Rewardfunctions based on information gain and information entropy can motivateactions that increase the drone's confidence in its updated belief, withoutrequiring knowledge of the true surface flux. These findings provide valuableinsights for further development of the framework for the mapping of morecomplex surface flux fields.</description><author>Alouette van Hove, Kristoffer Aalstad, Norbert Pirk</author><pubDate>Mon, 08 Jan 2024 14:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03932v1</guid></item><item><title>Rastro-DM: data mining with a trail</title><link>http://arxiv.org/abs/2401.03925v1</link><description>This paper proposes a methodology for documenting data mining (DM) projects,Rastro-DM (Trail Data Mining), with a focus not on the model that is generated,but on the processes behind its construction, in order to leave a trail (Rastroin Portuguese) of planned actions, training completed, results obtained, andlessons learned. The proposed practices are complementary to structuringmethodologies of DM, such as CRISP-DM, which establish a methodological andparadigmatic framework for the DM process. The application of best practicesand their benefits is illustrated in a project called 'Cladop' that was createdfor the classification of PDF documents associated with the investigativeprocess of damages to the Brazilian Federal Public Treasury. Building theRastro-DM kit in the context of a project is a small step that can lead to aninstitutional leap to be achieved by sharing and using the trail across theenterprise.</description><author>Marcus Vinicius Borela de Castro, Remis Balaniuk</author><pubDate>Mon, 08 Jan 2024 14:39:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03925v1</guid></item><item><title>Stepwise functional refoundation of relational concept analysis</title><link>http://arxiv.org/abs/2310.06441v2</link><description>Relational concept analysis (RCA) is an extension of formal concept analysisallowing to deal with several related contexts simultaneously. It has beendesigned for learning description logic theories from data and used withinvarious applications. A puzzling observation about RCA is that it returns asingle family of concept lattices although, when the data feature circulardependencies, other solutions may be considered acceptable. The semantics ofRCA, provided in an operational way, does not shed light on this issue. In thisreport, we define these acceptable solutions as those families of conceptlattices which belong to the space determined by the initial contexts(well-formed), cannot scale new attributes (saturated), and refer only toconcepts of the family (self-supported). We adopt a functional view on the RCAprocess by defining the space of well-formed solutions and two functions onthat space: one expansive and the other contractive. We show that theacceptable solutions are the common fixed points of both functions. This isachieved step-by-step by starting from a minimal version of RCA that considersonly one single context defined on a space of contexts and a space of lattices.These spaces are then joined into a single space of context-lattice pairs,which is further extended to a space of indexed families of context-latticepairs representing the objects manippulated by RCA. We show that RCA returnsthe least element of the set of acceptable solutions. In addition, it ispossible to build dually an operation that generates its greatest element. Theset of acceptable solutions is a complete sublattice of the interval betweenthese two elements. Its structure and how the defined functions traverse it arestudied in detail.</description><author>Jérôme Euzenat</author><pubDate>Mon, 08 Jan 2024 14:36:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06441v2</guid></item><item><title>A non-asymptotic distributional theory of approximate message passing for sparse and robust regression</title><link>http://arxiv.org/abs/2401.03923v1</link><description>Characterizing the distribution of high-dimensional statistical estimators isa challenging task, due to the breakdown of classical asymptotic theory in highdimension. This paper makes progress towards this by developing non-asymptoticdistributional characterizations for approximate message passing (AMP) -- afamily of iterative algorithms that prove effective as both fast estimators andpowerful theoretical machinery -- for both sparse and robust regression. PriorAMP theory, which focused on high-dimensional asymptotics for the most part,failed to describe the behavior of AMP when the number of iterations exceeds$o\big({\log n}/{\log \log n}\big)$ (with $n$ the sample size). We establishthe first finite-sample non-asymptotic distributional theory of AMP for bothsparse and robust regression that accommodates a polynomial number ofiterations. Our results derive approximate accuracy of Gaussian approximationof the AMP iterates, which improves upon all prior results and implies enhanceddistributional characterizations for both optimally tuned Lasso and robustM-estimator.</description><author>Gen Li, Yuting Wei</author><pubDate>Mon, 08 Jan 2024 14:34:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03923v1</guid></item><item><title>Structure-focused Neurodegeneration Convolutional Neural Network for Modeling and Classification of Alzheimer's Disease</title><link>http://arxiv.org/abs/2401.03922v1</link><description>Alzheimer's disease (AD), the predominant form of dementia, poses a growingglobal challenge and underscores the urgency of accurate and early diagnosis.The clinical technique radiologists adopt for distinguishing between mildcognitive impairment (MCI) and AD using Machine Resonance Imaging (MRI)encounter hurdles because they are not consistent and reliable. Machinelearning has been shown to offer promise for early AD diagnosis. However,existing models focused on focal fine-grain features without considerations tofocal structural features that give off information on neurodegeneration of thebrain cerebral cortex. Therefore, this paper proposes a machine learning (ML)framework that integrates Gamma correction, an image enhancement technique, andincludes a structure-focused neurodegeneration convolutional neural network(CNN) architecture called SNeurodCNN for discriminating between AD and MCI. TheML framework leverages the mid-sagittal and para-sagittal brain imageviewpoints of the structure-focused Alzheimer's Disease Neuroimaging Initiative(ADNI) dataset. Through experiments, our proposed machine learning frameworkshows exceptional performance. The parasagittal viewpoint set achieves 97.8%accuracy, with 97.0% specificity and 98.5% sensitivity. The midsagittalviewpoint is shown to present deeper insights into the structural brain changesgiven the increase in accuracy, specificity, and sensitivity, which are 98.1%97.2%, and 99.0%, respectively. Using GradCAM technique, we show that ourproposed model is capable of capturing the structural dynamics of MCI and ADwhich exist about the frontal lobe, occipital lobe, cerebellum, and parietallobe. Therefore, our model itself as a potential brain structural changeDigi-Biomarker for early diagnosis of AD.</description><author>Simisola Odimayo, Chollette C. Olisah, Khadija Mohammed</author><pubDate>Mon, 08 Jan 2024 14:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03922v1</guid></item><item><title>Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review</title><link>http://arxiv.org/abs/2308.04306v4</link><description>Metaphor as an advanced cognitive modality works by extracting familiarconcepts in the target domain in order to understand vague and abstractconcepts in the source domain. This helps humans to quickly understand andmaster new domains and thus adapt to changing environments. With the continuousdevelopment of metaphor research in the natural language community, manystudies using knowledge-assisted models to detect textual metaphors haveemerged in recent years. Compared to not using knowledge, systems thatintroduce various kinds of knowledge achieve greater performance gains andreach SOTA in a recent study. Based on this, the goal of this paper is toprovide a comprehensive review of research advances in the application of deeplearning for knowledge injection in metaphor detection tasks. We will firstsystematically summarize and generalize the mainstream knowledge and knowledgeinjection principles. Then, the datasets, evaluation metrics, and benchmarkmodels used in metaphor detection tasks are examined. Finally, we explore thecurrent issues facing knowledge injection methods and provide an outlook onfuture research directions.</description><author>Cheng Yang, Zheng Li, Zhiyue Liu, Qingbao Huang</author><pubDate>Mon, 08 Jan 2024 14:32:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04306v4</guid></item><item><title>Preference as Reward, Maximum Preference Optimization with Importance Sampling</title><link>http://arxiv.org/abs/2312.16430v4</link><description>Preference learning is a key technology for aligning language models withhuman values. Reinforcement Learning from Human Feedback (RLHF) is a modelbased algorithm to optimize preference learning, which first fitting a rewardmodel for preference score, and then optimizing generating policy withon-policy PPO algorithm to maximize the reward. The processing of RLHF iscomplex, time-consuming and unstable. Direct Preference Optimization (DPO)algorithm using off-policy algorithm to direct optimize generating policy andeliminating the need for reward model, which is data efficient and stable. DPOuse Bradley-Terry model and log-loss which leads to over-fitting to thepreference data at the expense of ignoring KL-regularization term whenpreference is deterministic. IPO uses a root-finding MSE loss to solve theignoring KL-regularization problem. In this paper, we'll figure out, althoughIPO fix the problem when preference is deterministic, but both DPO and IPOfails the KL-regularization term because the support of preference distributionnot equal to reference distribution. Then, we design a simple and intuitiveoff-policy preference optimization algorithm from an importance sampling view,which we call Maximum Preference Optimization (MPO), and add off-policyKL-regularization terms which makes KL-regularization truly effective. Theobjective of MPO bears resemblance to RLHF's objective, and likes IPO, MPO isoff-policy. So, MPO attains the best of both worlds. To simplify the learningprocess and save memory usage, MPO eliminates the needs for both reward modeland reference policy.</description><author>Zaifan Jiang, Xing Huang, Chao Wei</author><pubDate>Mon, 08 Jan 2024 14:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16430v4</guid></item><item><title>Design a Metric Robust to Complicated High Dimensional Noise for Efficient Manifold Denoising</title><link>http://arxiv.org/abs/2401.03921v1</link><description>In this manuscript, we propose an efficient manifold denoiser based onlandmark diffusion and optimal shrinkage under the complicated high dimensionalnoise and compact manifold setup. It is flexible to handle several setups,including the high ambient space dimension with a manifold embedding thatoccupies a subspace of high or low dimensions, and the noise could be coloredand dependent. A systematic comparison with other existing algorithms on bothsimulated and real datasets is provided. This manuscript is mainly algorithmicand we report several existing tools and numerical results. Theoreticalguarantees and more comparisons will be reported in the official paper of thismanuscript.</description><author>Hau-Tieng Wu</author><pubDate>Mon, 08 Jan 2024 14:30:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03921v1</guid></item><item><title>Breaking the Silence: the Threats of Using LLMs in Software Engineering</title><link>http://arxiv.org/abs/2312.08055v2</link><description>Large Language Models (LLMs) have gained considerable traction within theSoftware Engineering (SE) community, impacting various SE tasks from codecompletion to test generation, from program repair to code summarization.Despite their promise, researchers must still be careful as numerous intricatefactors can influence the outcomes of experiments involving LLMs. This paperinitiates an open discussion on potential threats to the validity of LLM-basedresearch including issues such as closed-source models, possible data leakagebetween LLM training data and research evaluation, and the reproducibility ofLLM-based findings. In response, this paper proposes a set of guidelinestailored for SE researchers and Language Model (LM) providers to mitigate theseconcerns. The implications of the guidelines are illustrated using existinggood practices followed by LLM providers and a practical example for SEresearchers in the context of test case generation.</description><author>June Sallou, Thomas Durieux, Annibale Panichella</author><pubDate>Mon, 08 Jan 2024 14:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08055v2</guid></item><item><title>D3PRefiner: A Diffusion-based Denoise Method for 3D Human Pose Refinement</title><link>http://arxiv.org/abs/2401.03914v1</link><description>Three-dimensional (3D) human pose estimation using a monocular camera hasgained increasing attention due to its ease of implementation and the abundanceof data available from daily life. However, owing to the inherent depthambiguity in images, the accuracy of existing monocular camera-based 3D poseestimation methods remains unsatisfactory, and the estimated 3D poses usuallyinclude much noise. By observing the histogram of this noise, we find eachdimension of the noise follows a certain distribution, which indicates thepossibility for a neural network to learn the mapping between noisy poses andground truth poses. In this work, in order to obtain more accurate 3D poses, aDiffusion-based 3D Pose Refiner (D3PRefiner) is proposed to refine the outputof any existing 3D pose estimator. We first introduce a conditionalmultivariate Gaussian distribution to model the distribution of noisy 3D poses,using paired 2D poses and noisy 3D poses as conditions to achieve greateraccuracy. Additionally, we leverage the architecture of current diffusionmodels to convert the distribution of noisy 3D poses into ground truth 3Dposes. To evaluate the effectiveness of the proposed method, twostate-of-the-art sequence-to-sequence 3D pose estimators are used as basic 3Dpose estimation models, and the proposed method is evaluated on different typesof 2D poses and different lengths of the input sequence. Experimental resultsdemonstrate the proposed architecture can significantly improve the performanceof current sequence-to-sequence 3D pose estimators, with a reduction of atleast 10.3% in the mean per joint position error (MPJPE) and at least 11.0% inthe Procrustes MPJPE (P-MPJPE).</description><author>Danqi Yan, Qing Gao, Yuepeng Qian, Xinxing Chen, Chenglong Fu, Yuquan Leng</author><pubDate>Mon, 08 Jan 2024 14:21:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03914v1</guid></item><item><title>Comparative Experimentation of Accuracy Metrics in Automated Medical Reporting: The Case of Otitis Consultations</title><link>http://arxiv.org/abs/2311.13273v2</link><description>Generative Artificial Intelligence (AI) can be used to automatically generatemedical reports based on transcripts of medical consultations. The aim is toreduce the administrative burden that healthcare professionals face. Theaccuracy of the generated reports needs to be established to ensure theircorrectness and usefulness. There are several metrics for measuring theaccuracy of AI generated reports, but little work has been done towards theapplication of these metrics in medical reporting. A comparativeexperimentation of 10 accuracy metrics has been performed on AI generatedmedical reports against their corresponding General Practitioner's (GP) medicalreports concerning Otitis consultations. The number of missing, incorrect, andadditional statements of the generated reports have been correlated with themetric scores. In addition, we introduce and define a Composite Accuracy Scorewhich produces a single score for comparing the metrics within the field ofautomated medical reporting. Findings show that based on the correlation studyand the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metricsare the preferred metrics, which is not in line with previous work. Thesefindings help determine the accuracy of an AI generated medical report, whichaids the development of systems that generate medical reports for GPs to reducethe administrative burden.</description><author>Wouter Faber, Renske Eline Bootsma, Tom Huibers, Sandra van Dulmen, Sjaak Brinkkemper</author><pubDate>Mon, 08 Jan 2024 14:19:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13273v2</guid></item><item><title>Attention-Guided Erasing: A Novel Augmentation Method for Enhancing Downstream Breast Density Classification</title><link>http://arxiv.org/abs/2401.03912v1</link><description>The assessment of breast density is crucial in the context of breast cancerscreening, especially in populations with a higher percentage of dense breasttissues. This study introduces a novel data augmentation technique termedAttention-Guided Erasing (AGE), devised to enhance the downstreamclassification of four distinct breast density categories in mammographyfollowing the BI-RADS recommendation in the Vietnamese cohort. The proposedmethod integrates supplementary information during transfer learning, utilizingvisual attention maps derived from a vision transformer backbone trained usingthe self-supervised DINO method. These maps are utilized to erase backgroundregions in the mammogram images, unveiling only the potential areas of densebreast tissues to the network. Through the incorporation of AGE during transferlearning with varying random probabilities, we consistently surpassclassification performance compared to scenarios without AGE and thetraditional random erasing transformation. We validate our methodology usingthe publicly available VinDr-Mammo dataset. Specifically, we attain a meanF1-score of 0.5910, outperforming values of 0.5594 and 0.5691 corresponding toscenarios without AGE and with random erasing (RE), respectively. Thissuperiority is further substantiated by t-tests, revealing a p-value ofp&lt;0.0001, underscoring the statistical significance of our approach.</description><author>Adarsh Bhandary Panambur, Hui Yu, Sheethal Bhat, Prathmesh Madhu, Siming Bayer, Andreas Maier</author><pubDate>Mon, 08 Jan 2024 14:16:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03912v1</guid></item><item><title>A Philosophical Introduction to Language Models -- Part I: Continuity With Classic Debates</title><link>http://arxiv.org/abs/2401.03910v1</link><description>Large language models like GPT-4 have achieved remarkable proficiency in abroad spectrum of language-based tasks, some of which are traditionallyassociated with hallmarks of human intelligence. This has prompted ongoingdisagreements about the extent to which we can meaningfully ascribe any kind oflinguistic or cognitive competence to language models. Such questions have deepphilosophical roots, echoing longstanding debates about the status ofartificial neural networks as cognitive models. This article -- the first partof two companion papers -- serves both as a primer on language models forphilosophers, and as an opinionated survey of their significance in relation toclassic debates in the philosophy cognitive science, artificial intelligence,and linguistics. We cover topics such as compositionality, languageacquisition, semantic competence, grounding, world models, and the transmissionof cultural knowledge. We argue that the success of language models challengesseveral long-held assumptions about artificial neural networks. However, wealso highlight the need for further empirical investigation to betterunderstand their internal mechanisms. This sets the stage for the companionpaper (Part II), which turns to novel empirical methods for probing the innerworkings of language models, and new philosophical questions prompted by theirlatest developments.</description><author>Raphaël Millière, Cameron Buckner</author><pubDate>Mon, 08 Jan 2024 14:12:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03910v1</guid></item><item><title>RoboFusion: Towards Robust Multi-Modal 3D obiect Detection via SAM</title><link>http://arxiv.org/abs/2401.03907v1</link><description>Multi-modal 3D object detectors are dedicated to exploring secure andreliable perception systems for autonomous driving (AD). However, whileachieving state-of-the-art (SOTA) performance on clean benchmark datasets, theytend to overlook the complexity and harsh conditions of real-worldenvironments. Meanwhile, with the emergence of visual foundation models (VFMs),opportunities and challenges are presented for improving the robustness andgeneralization of multi-modal 3D object detection in autonomous driving.Therefore, we propose RoboFusion, a robust framework that leverages VFMs likeSAM to tackle out-of-distribution (OOD) noise scenarios. We first adapt theoriginal SAM for autonomous driving scenarios named SAM-AD. To align SAM orSAM-AD with multi-modal methods, we then introduce AD-FPN for upsampling theimage features extracted by SAM. We employ wavelet decomposition to denoise thedepth-guided images for further noise reduction and weather interference.Lastly, we employ self-attention mechanisms to adaptively reweight the fusedfeatures, enhancing informative features while suppressing excess noise. Insummary, our RoboFusion gradually reduces noise by leveraging thegeneralization and robustness of VFMs, thereby enhancing the resilience ofmulti-modal 3D object detection. Consequently, our RoboFusion achievesstate-of-the-art performance in noisy scenarios, as demonstrated by the KITTI-Cand nuScenes-C benchmarks.</description><author>Ziying Song, Guoxing Zhang, Lin Liu, Lei Yang, Shaoqing Xu, Caiyan Jia, Feiyang Jia, Li Wang</author><pubDate>Mon, 08 Jan 2024 14:10:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03907v1</guid></item><item><title>WEBDial, a Multi-domain, Multitask Statistical Dialogue Framework with RDF</title><link>http://arxiv.org/abs/2401.03905v1</link><description>Typically available dialogue frameworks have adopted a semanticrepresentation based on dialogue-acts and slot-value pairs. Despite itssimplicity, this representation has disadvantages such as the lack ofexpressivity, scalability and explainability. We present WEBDial: a dialogueframework that relies on a graph formalism by using RDF triples instead ofslot-value pairs. We describe its overall architecture and the graph-basedsemantic representation. We show its applicability from simple to complexapplications, by varying the complexity of domains and tasks: from singledomain and tasks to multiple domains and complex tasks.</description><author>Morgan Veyret, Jean-Baptiste Duchene, Kekeli Afonouvi, Quentin Brabant, Gwenole Lecorve, Lina M. Rojas-Barahona</author><pubDate>Mon, 08 Jan 2024 14:08:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03905v1</guid></item><item><title>STAIR: Spatial-Temporal Reasoning with Auditable Intermediate Results for Video Question Answering</title><link>http://arxiv.org/abs/2401.03901v1</link><description>Recently we have witnessed the rapid development of video question answeringmodels. However, most models can only handle simple videos in terms of temporalreasoning, and their performance tends to drop when answeringtemporal-reasoning questions on long and informative videos. To tackle thisproblem we propose STAIR, a Spatial-Temporal Reasoning model with AuditableIntermediate Results for video question answering. STAIR is a neural modulenetwork, which contains a program generator to decompose a given question intoa hierarchical combination of several sub-tasks, and a set of lightweightneural modules to complete each of these sub-tasks. Though neural modulenetworks are already widely studied on image-text tasks, applying them tovideos is a non-trivial task, as reasoning on videos requires differentabilities. In this paper, we define a set of basic video-text sub-tasks forvideo question answering and design a set of lightweight modules to completethem. Different from most prior works, modules of STAIR return intermediateoutputs specific to their intentions instead of always returning attentionmaps, which makes it easier to interpret and collaborate with pre-trainedmodels. We also introduce intermediate supervision to make these intermediateoutputs more accurate. We conduct extensive experiments on several videoquestion answering datasets under various settings to show STAIR's performance,explainability, compatibility with pre-trained models, and applicability whenprogram annotations are not available. Code:https://github.com/yellow-binary-tree/STAIR</description><author>Yueqian Wang, Yuxuan Wang, Kai Chen, Dongyan Zhao</author><pubDate>Mon, 08 Jan 2024 14:01:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03901v1</guid></item><item><title>A Tensor Network Implementation of Multi Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2401.03896v1</link><description>Recently it has been shown that tensor networks (TNs) have the ability torepresent the expected return of a single-agent finite Markov decision process(FMDP). The TN represents a distribution model, where all possible trajectoriesare considered. When extending these ideas to a multi-agent setting,distribution models suffer from the curse of dimensionality: the exponentialrelation between the number of possible trajectories and the number of agents.The key advantage of using TNs in this setting is that there exists a largenumber of established optimisation and decomposition techniques that arespecific to TNs, that one can apply to ensure the most efficient representationis found. In this report, these methods are used to form a TN that representsthe expected return of a multi-agent reinforcement learning (MARL) task. Thismodel is then applied to a 2 agent random walker example, where it was shownthat the policy is correctly optimised using a DMRG technique. Finally, Idemonstrate the use of an exact decomposition technique, reducing the number ofelements in the tensors by 97.5%, without experiencing any loss of information.</description><author>Sunny Howard</author><pubDate>Mon, 08 Jan 2024 13:50:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03896v1</guid></item><item><title>Finite-Time Decoupled Convergence in Nonlinear Two-Time-Scale Stochastic Approximation</title><link>http://arxiv.org/abs/2401.03893v1</link><description>In two-time-scale stochastic approximation (SA), two iterates are updated atvarying speeds using different step sizes, with each update influencing theother. Previous studies in linear two-time-scale SA have found that theconvergence rates of the mean-square errors for these updates are dependentsolely on their respective step sizes, leading to what is referred to asdecoupled convergence. However, the possibility of achieving this decoupledconvergence in nonlinear SA remains less understood. Our research explores thepotential for finite-time decoupled convergence in nonlinear two-time-scale SA.We find that under a weaker Lipschitz condition, traditional analyses areinsufficient for achieving decoupled convergence. This finding is furthernumerically supported by a counterexample. But by introducing an additionalcondition of nested local linearity, we show that decoupled convergence isstill feasible, contingent on the appropriate choice of step sizes associatedwith smoothness parameters. Our analysis depends on a refined characterizationof the matrix cross term between the two iterates and utilizes fourth-ordermoments to control higher-order approximation errors induced by the locallinearity assumption.</description><author>Yuze Han, Xiang Li, Zhihua Zhang</author><pubDate>Mon, 08 Jan 2024 13:44:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03893v1</guid></item><item><title>Sampling in Unit Time with Kernel Fisher-Rao Flow</title><link>http://arxiv.org/abs/2401.03892v1</link><description>We introduce a new mean-field ODE and corresponding interacting particlesystems for sampling from an unnormalized target density or Bayesian posterior.The interacting particle systems are gradient-free, available in closed form,and only require the ability to sample from the reference density and computethe (unnormalized) target-to-reference density ratio. The mean-field ODE isobtained by solving a Poisson equation for a velocity field that transportssamples along the geometric mixture of the two densities, which is the path ofa particular Fisher-Rao gradient flow. We employ a reproducing kernel Hilbertspace ansatz for the velocity field, which makes the Poisson equation tractableand enables us to discretize the resulting mean-field ODE over finite samples,as a simple interacting particle system. The mean-field ODE can be additionallybe derived from a discrete-time perspective as the limit of successivelinearizations of the Monge-Amp\`ere equations within a framework known assample-driven optimal transport. We demonstrate empirically that ourinteracting particle systems can produce high-quality samples fromdistributions with varying characteristics.</description><author>Aimee Maurais, Youssef Marzouk</author><pubDate>Mon, 08 Jan 2024 13:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03892v1</guid></item><item><title>A Survey on 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2401.03890v1</link><description>3D Gaussian splatting (3D GS) has recently emerged as a transformativetechnique in the explicit radiance field and computer graphics landscape. Thisinnovative approach, characterized by the utilization of millions of 3DGaussians, represents a significant departure from the neural radiance field(NeRF) methodologies, which predominantly use implicit, coordinate-based modelsto map spatial coordinates to pixel values. 3D GS, with its explicit scenerepresentations and differentiable rendering algorithms, not only promisesreal-time rendering capabilities but also introduces unprecedented levels ofcontrol and editability. This positions 3D GS as a potential game-changer forthe next generation of 3D reconstruction and representation. In the presentpaper, we provide the first systematic overview of the recent developments andcritical contributions in the domain of 3D GS. We begin with a detailedexploration of the underlying principles and the driving forces behind theadvent of 3D GS, setting the stage for understanding its significance. A focalpoint of our discussion is the practical applicability of 3D GS. Byfacilitating real-time performance, 3D GS opens up a plethora of applications,ranging from virtual reality to interactive media and beyond. This iscomplemented by a comparative analysis of leading 3D GS models, evaluatedacross various benchmark tasks to highlight their performance and practicalutility. The survey concludes by identifying current challenges and suggestingpotential avenues for future research in this domain. Through this survey, weaim to provide a valuable resource for both newcomers and seasoned researchers,fostering further exploration and advancement in applicable and explicitradiance field representation.</description><author>Guikun Chen, Wenguan Wang</author><pubDate>Mon, 08 Jan 2024 13:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03890v1</guid></item><item><title>Ranking-based Adaptive Query Generation for DETRs in Crowded Pedestrian Detection</title><link>http://arxiv.org/abs/2310.15725v2</link><description>DEtection TRansformer (DETR) and its variants (DETRs) have been successfullyapplied to crowded pedestrian detection, which achieved promising performance.However, we find that, in different degrees of crowded scenes, the number ofDETRs' queries must be adjusted manually, otherwise, the performance woulddegrade to varying degrees. In this paper, we first analyze the two currentquery generation methods and summarize four guidelines for designing theadaptive query generation method. Then, we propose Rank-based Adaptive QueryGeneration (RAQG) to alleviate the problem. Specifically, we design a rankprediction head that can predict the rank of the lowest confidence positivetraining sample produced by the encoder. Based on the predicted rank, we designan adaptive selection method that can adaptively select coarse detectionresults produced by the encoder to generate queries. Moreover, to train therank prediction head better, we propose Soft Gradient L1 Loss. The gradient ofSoft Gradient L1 Loss is continuous, which can describe the relationshipbetween the loss value and the updated value of model parameters granularly.Our method is simple and effective, which can be plugged into any DETRs to makeit query-adaptive in theory. The experimental results on Crowdhuman dataset andCitypersons dataset show that our method can adaptively generate queries forDETRs and achieve competitive results. Especially, our method achievesstate-of-the-art 39.4% MR on Crowdhuman dataset.</description><author>Feng Gao, Jiaxu Leng, Ji Gan, Xinbo Gao</author><pubDate>Mon, 08 Jan 2024 13:36:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15725v2</guid></item><item><title>Unlocking Pre-trained Image Backbones for Semantic Image Synthesis</title><link>http://arxiv.org/abs/2312.13314v2</link><description>Semantic image synthesis, i.e., generating images from user-provided semanticlabel maps, is an important conditional image generation task as it allows tocontrol both the content as well as the spatial layout of generated images.Although diffusion models have pushed the state of the art in generative imagemodeling, the iterative nature of their inference process makes themcomputationally demanding. Other approaches such as GANs are more efficient asthey only need a single feed-forward pass for generation, but the image qualitytends to suffer on large and diverse datasets. In this work, we propose a newclass of GAN discriminators for semantic image synthesis that generates highlyrealistic images by exploiting feature backbone networks pre-trained for taskssuch as image classification. We also introduce a new generator architecturewith better context modeling and using cross-attention to inject noise intolatent variables, leading to more diverse generated images. Our model, which wedub DP-SIMS, achieves state-of-the-art results in terms of image quality andconsistency with the input label maps on ADE-20K, COCO-Stuff, and Cityscapes,surpassing recent diffusion models while requiring two orders of magnitude lesscompute for inference.</description><author>Tariq Berrada, Jakob Verbeek, Camille Couprie, Karteek Alahari</author><pubDate>Mon, 08 Jan 2024 13:30:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13314v2</guid></item><item><title>DamWorld: Progressive Reasoning with World Models for Robotic Manipulation</title><link>http://arxiv.org/abs/2306.11335v3</link><description>The research on embodied AI has greatly promoted the development of robotmanipulation. However, it still faces significant challenges in various aspectssuch as benchmark construction, multi-modal perception and decision-making, andphysical execution. Previous robot manipulation simulators were primarilydesigned to enrich manipulation types and types of objects while neglecting thebalance between physical manipulation and language instruction complexity inmulti-modal environments. This paper proposes a new robot manipulationsimulator and builds a comprehensive and systematic robot manipulationbenchmark with progressive reasoning tasks called SeaWave (i.e., a progressivereasoning benchmark). It provides a standard test platform for embedded AIagents in a multi-modal environment, which can evaluate and execute four levelsof human natural language instructions at the same time. Previous world model-based robot manipulation work lacked research on theperception and decision-making of complex instructions in multi-modalenvironments. To this end, we propose a new world model tailored forcross-modal robot manipulation called DamWorld. Specifically, DamWorld takesthe current visual scene and predicted execution actions based on naturallanguage instructions as input, and uses the next action frame to supervise theoutput of the world model to force the model to learn robot manipulationconsistent with world knowledge. Compared with the renowned baselines (e.g.,RT-1), our DamWorld improves the manipulation success rate by 5.6% on averageon four levels of progressive reasoning tasks. It is worth noting that on themost challenging level 4 manipulation task, DamWorld still improved by 9.0%compared to prior works.</description><author>Pengzhen Ren, Kaidong Zhang, Hetao Zheng, Zixuan Li, Yuhang Wen, Fengda Zhu, Mas Ma, Xiaodan Liang</author><pubDate>Mon, 08 Jan 2024 13:29:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11335v3</guid></item><item><title>Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric</title><link>http://arxiv.org/abs/2211.11010v2</link><description>Combining the Color and Event cameras (also called Dynamic Vision Sensors,DVS) for robust object tracking is a newly emerging research topic in recentyears. Existing color-event tracking framework usually contains multiplescattered modules which may lead to low efficiency and high computationalcomplexity, including feature extraction, fusion, matching, interactivelearning, etc. In this paper, we propose a single-stage backbone network forColor-Event Unified Tracking (CEUTrack), which achieves the above functionssimultaneously. Given the event points and RGB frames, we first transform thepoints into voxels and crop the template and search regions for bothmodalities, respectively. Then, these regions are projected into tokens andparallelly fed into the unified Transformer backbone network. The outputfeatures will be fed into a tracking head for target object localization. Ourproposed CEUTrack is simple, effective, and efficient, which achieves over 75FPS and new SOTA performance. To better validate the effectiveness of our modeland address the data deficiency of this task, we also propose a generic andlarge-scale benchmark dataset for color-event tracking, termed COESOT, whichcontains 90 categories and 1354 video sequences. Additionally, a new evaluationmetric named BOC is proposed in our evaluation toolkit to evaluate theprominence with respect to the baseline methods. We hope the newly proposedmethod, dataset, and evaluation metric provide a better platform forcolor-event-based tracking. The dataset, toolkit, and source code will bereleased on: \url{https://github.com/Event-AHU/COESOT}.</description><author>Chuanming Tang, Xiao Wang, Ju Huang, Bo Jiang, Lin Zhu, Jianlin Zhang, Yaowei Wang, Yonghong Tian</author><pubDate>Mon, 08 Jan 2024 13:27:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11010v2</guid></item><item><title>Exploring Format Consistency for Instruction Tuning</title><link>http://arxiv.org/abs/2307.15504v2</link><description>Instruction tuning has emerged as a promising approach to enhancing largelanguage models in following human instructions. It is shown that increasingthe diversity and number of instructions in the training data can consistentlyenhance generalization performance, which facilitates a recent endeavor tocollect various instructions and integrate existing instruction tuning datasetsinto larger collections. However, different users have their unique ways ofexpressing instructions, and there often exist variations across differentdatasets in the instruction styles and formats, i.e., format inconsistency. Inthis work, we propose a framework named Unified Instruction Tuning (UIT), whichcalls OpenAI APIs for automatic format transfer among different instructiontuning datasets such as PromptSource, FLAN and CrossFit. With the framework, we(1) demonstrate the necessity of maintaining format consistency in instructiontuning; (2) improve the generalization performance on unseen instructions onT5-LM-xl; (3) provide a novel perplexity-based denoising method to reduce thenoise of automatic format transfer to make the UIT framework more practical anda smaller offline model based on GPT-J that achieves comparable format transfercapability to OpenAI APIs to reduce costs in practice. Further analysisregarding variations of targeted formats and other effects is intended.</description><author>Shihao Liang, Runchu Tian, Kunlun Zhu, Yujia Qin, Huadong Wang, Xin Cong, Zhiyuan Liu, Xiaojiang Liu, Maosong Sun</author><pubDate>Mon, 08 Jan 2024 13:26:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15504v2</guid></item><item><title>Metaheuristics for (Variable-Size) Mixed Optimization Problems: A Unified Taxonomy and Survey</title><link>http://arxiv.org/abs/2401.03880v1</link><description>Many real world optimization problems are formulated as mixed-variableoptimization problems (MVOPs) which involve both continuous and discretevariables. MVOPs including dimensional variables are characterized by avariable-size search space. Depending on the values of dimensional variables,the number and type of the variables of the problem can vary dynamically. MVOPsand variable-size MVOPs (VMVOPs) are difficult to solve and raise a number ofscientific challenges in the design of metaheuristics. Standard metaheuristicshave been first designed to address continuous or discrete optimizationproblems, and are not able to tackle (V)MVOPs in an efficient way. Thedevelopment of metaheuristics for solving such problems has attracted theattention of many researchers and is increasingly popular. However, to ourknowledge there is no well established taxonomy and comprehensive survey forhandling this important family of optimization problems. This paper presents a unified taxonomy for metaheuristic solutions forsolving (V)MVOPs in an attempt to provide a common terminology andclassification mechanisms. It provides a general mathematical formulation andconcepts of (V)MVOPs, and identifies the various solving methodologies than canbe applied in metaheuristics. The advantages, the weaknesses and thelimitations of the presented methodologies are discussed. The proposed taxonomyalso allows to identify some open research issues which needs further in-depthinvestigations.</description><author>Prof. El-Ghazali Talbi</author><pubDate>Mon, 08 Jan 2024 13:24:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03880v1</guid></item><item><title>QCM-SGM+: Improved Quantized Compressed Sensing With Score-Based Generative Models</title><link>http://arxiv.org/abs/2302.00919v4</link><description>In practical compressed sensing (CS), the obtained measurements typicallynecessitate quantization to a limited number of bits prior to transmission orstorage. This nonlinear quantization process poses significant recoverychallenges, particularly with extreme coarse quantization such as 1-bit.Recently, an efficient algorithm called QCS-SGM was proposed for quantized CS(QCS) which utilizes score-based generative models (SGM) as an implicit prior.Due to the adeptness of SGM in capturing the intricate structures of naturalsignals, QCS-SGM substantially outperforms previous QCS methods. However,QCS-SGM is constrained to (approximately) row-orthogonal sensing matrices asthe computation of the likelihood score becomes intractable otherwise. Toaddress this limitation, we introduce an advanced variant of QCS-SGM, termedQCS-SGM+, capable of handling general matrices effectively. The key idea is aBayesian inference perspective on the likelihood score computation, whereinexpectation propagation is employed for its approximate computation. Extensiveexperiments are conducted, demonstrating the substantial superiority ofQCS-SGM+ over QCS-SGM for general sensing matrices beyond mererow-orthogonality.</description><author>Xiangming Meng, Yoshiyuki Kabashima</author><pubDate>Mon, 08 Jan 2024 13:19:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00919v4</guid></item><item><title>Synthetic Data Generation in Low-Resource Settings via Fine-Tuning of Large Language Models</title><link>http://arxiv.org/abs/2310.01119v2</link><description>The in-context learning ability of large language models (LLMs) enables themto generalize to novel downstream tasks with relatively few labeled examples.However, they require enormous computational resources to be deployed.Alternatively, smaller models can solve specific tasks if fine-tuned withenough labeled examples. These examples, however, are expensive to obtain. Inpursuit of the best of both worlds, we study synthetic data generation offine-tuning training data via fine-tuned teacher LLMs to improve the downstreamperformance of much smaller models. In four text classification and two textgeneration tasks, we find that both data generation and annotation dramaticallyimprove the respective downstream model's performance, occasionallynecessitating only a minor fraction of the original training dataset.</description><author>Jean Kaddour, Qi Liu</author><pubDate>Mon, 08 Jan 2024 13:09:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01119v2</guid></item><item><title>A New Dataset and a Distractor-Aware Architecture for Transparent Object Tracking</title><link>http://arxiv.org/abs/2401.03872v1</link><description>Performance of modern trackers degrades substantially on transparent objectscompared to opaque objects. This is largely due to two distinct reasons.Transparent objects are unique in that their appearance is directly affected bythe background. Furthermore, transparent object scenes often contain manyvisually similar objects (distractors), which often lead to tracking failure.However, development of modern tracking architectures requires large trainingsets, which do not exist in transparent object tracking. We present twocontributions addressing the aforementioned issues. We propose the firsttransparent object tracking training dataset Trans2k that consists of over 2ksequences with 104,343 images overall, annotated by bounding boxes andsegmentation masks. Standard trackers trained on this dataset consistentlyimprove by up to 16%. Our second contribution is a new distractor-awaretransparent object tracker (DiTra) that treats localization accuracy and targetidentification as separate tasks and implements them by a novel architecture.DiTra sets a new state-of-the-art in transparent object tracking andgeneralizes well to opaque objects.</description><author>Alan Lukezic, Ziga Trojer, Jiri Matas, Matej Kristan</author><pubDate>Mon, 08 Jan 2024 13:04:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03872v1</guid></item><item><title>TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild</title><link>http://arxiv.org/abs/2309.08637v4</link><description>Large language models with instruction-following abilities haverevolutionized the field of artificial intelligence. These models showexceptional generalizability to tackle various real-world tasks through theirnatural language interfaces. However, their performance heavily relies onhigh-quality exemplar data, which is often difficult to obtain. This challengeis further exacerbated when it comes to multimodal instruction following. Weintroduce TextBind, an almost annotation-free framework for empowering largerlanguage models with the multi-turn interleaved multimodalinstruction-following capabilities. Our approach requires only image-captionpairs and generates multi-turn multimodal instruction-response conversationsfrom a language model. To accommodate interleaved image-text inputs andoutputs, we devise MIM, a language model-centric architecture that seamlesslyintegrates image encoder and decoder models. We release our dataset, model, anddemo to foster future research in the area of multimodal instruction following.</description><author>Huayang Li, Siheng Li, Deng Cai, Longyue Wang, Lemao Liu, Taro Watanabe, Yujiu Yang, Shuming Shi</author><pubDate>Mon, 08 Jan 2024 13:02:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08637v4</guid></item><item><title>Gramformer: Learning Crowd Counting via Graph-Modulated Transformer</title><link>http://arxiv.org/abs/2401.03870v1</link><description>Transformer has been popular in recent crowd counting work since it breaksthe limited receptive field of traditional CNNs. However, since crowd imagesalways contain a large number of similar patches, the self-attention mechanismin Transformer tends to find a homogenized solution where the attention maps ofalmost all patches are identical. In this paper, we address this problem byproposing Gramformer: a graph-modulated transformer to enhance the network byadjusting the attention and input node features respectively on the basis oftwo different types of graphs. Firstly, an attention graph is proposed todiverse attention maps to attend to complementary information. The graph isbuilding upon the dissimilarities between patches, modulating the attention inan anti-similarity fashion. Secondly, a feature-based centrality encoding isproposed to discover the centrality positions or importance of nodes. We encodethem with a proposed centrality indices scheme to modulate the node featuresand similarity relationships. Extensive experiments on four challenging crowdcounting datasets have validated the competitiveness of the proposed method.Code is available at {https://github.com/LoraLinH/Gramformer}.</description><author>Hui Lin, Zhiheng Ma, Xiaopeng Hong, Qinnan Shangguan, Deyu Meng</author><pubDate>Mon, 08 Jan 2024 13:01:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03870v1</guid></item><item><title>FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGA</title><link>http://arxiv.org/abs/2401.03868v1</link><description>Transformer-based Large Language Models (LLMs) have made a significant impacton various domains. However, LLMs' efficiency suffers from both heavycomputation and memory overheads. Compression techniques like sparsificationand quantization are commonly used to mitigate the gap between LLM'scomputation/memory overheads and hardware capacity. However, existing GPU andtransformer-based accelerators cannot efficiently process compressed LLMs, dueto the following unresolved challenges: low computational efficiency,underutilized memory bandwidth, and large compilation overheads. This paper proposes FlightLLM, enabling efficient LLMs inference with acomplete mapping flow on FPGAs. In FlightLLM, we highlight an innovativesolution that the computation and memory overhead of LLMs can be solved byutilizing FPGA-specific resources (e.g., DSP48 and heterogeneous memoryhierarchy). We propose a configurable sparse DSP chain to support differentsparsity patterns with high computation efficiency. Second, we propose analways-on-chip decode scheme to boost memory bandwidth with mixed-precisionsupport. Finally, to make FlightLLM available for real-world LLMs, we propose alength adaptive compilation method to reduce the compilation overhead.Implemented on the Xilinx Alveo U280 FPGA, FlightLLM achieves 6.0$\times$higher energy efficiency and 1.8$\times$ better cost efficiency againstcommercial GPUs (e.g., NVIDIA V100S) on modern LLMs (e.g., LLaMA2-7B) usingvLLM and SmoothQuant under the batch size of one. FlightLLM beats NVIDIA A100GPU with 1.2$\times$ higher throughput using the latest Versal VHK158 FPGA.</description><author>Shulin Zeng, Jun Liu, Guohao Dai, Xinhao Yang, Tianyu Fu, Hongyi Wang, Wenheng Ma, Hanbo Sun, Shiyao Li, Zixiao Huang, Yadong Dai, Jintao Li, Zehao Wang, Ruoyu Zhang, Kairui Wen, Xuefei Ning, Yu Wang</author><pubDate>Mon, 08 Jan 2024 13:00:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03868v1</guid></item><item><title>Convoifilter: A case study of doing cocktail party speech recognition</title><link>http://arxiv.org/abs/2308.11380v2</link><description>This paper presents an end-to-end model designed to improve automatic speechrecognition (ASR) for a particular speaker in a crowded, noisy environment. Themodel utilizes a single-channel speech enhancement module that isolates thespeaker's voice from background noise (ConVoiFilter) and an ASR module. Themodel can decrease ASR's word error rate (WER) from 80% to 26.4% through thisapproach. Typically, these two components are adjusted independently due tovariations in data requirements. However, speech enhancement can createanomalies that decrease ASR efficiency. By implementing a joint fine-tuningstrategy, the model can reduce the WER from 26.4% in separate tuning to 14.5%in joint tuning. We openly share our pre-trained model to foster furtherresearch hf.co/nguyenvulebinh/voice-filter.</description><author>Thai-Binh Nguyen, Alexander Waibel</author><pubDate>Mon, 08 Jan 2024 12:54:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11380v2</guid></item><item><title>A Contrastive Learning Scheme with Transformer Innate Patches</title><link>http://arxiv.org/abs/2303.14806v2</link><description>This paper presents Contrastive Transformer, a contrastive learning schemeusing the Transformer innate patches. Contrastive Transformer enables existingcontrastive learning techniques, often used for image classification, tobenefit dense downstream prediction tasks such as semantic segmentation. Thescheme performs supervised patch-level contrastive learning, selecting thepatches based on the ground truth mask, subsequently used for hard-negative andhard-positive sampling. The scheme applies to all vision-transformerarchitectures, is easy to implement, and introduces minimal additional memoryfootprint. Additionally, the scheme removes the need for huge batch sizes, aseach patch is treated as an image. We apply and test Contrastive Transformer for the case of aerial imagesegmentation, known for low-resolution data, large class imbalance, and similarsemantic classes. We perform extensive experiments to show the efficacy of theContrastive Transformer scheme on the ISPRS Potsdam aerial image segmentationdataset. Additionally, we show the generalizability of our scheme by applyingit to multiple inherently different Transformer architectures. Ultimately, theresults show a consistent increase in mean IoU across all classes.</description><author>Sander Riisøen Jyhne, Per-Arne Andersen, Morten Goodwin</author><pubDate>Mon, 08 Jan 2024 12:54:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14806v2</guid></item><item><title>Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks</title><link>http://arxiv.org/abs/2401.02731v2</link><description>Large Language Models (LLMs) have demonstrated considerable proficiency ingeneral natural language processing (NLP) tasks. Instruction tuning, asuccessful paradigm, enhances the ability of LLMs to follow natural languageinstructions and exhibit robust generalization across a wide range of tasks.However, these models often encounter performance limitations across multipletasks due to constrained model capacity. Expanding this capacity during theinstruction tuning phase poses significant challenges. To address this issue,we introduce a novel approach, Parameter-Efficient Sparsity Crafting (PESC),which transitions dense models to sparse models using a Mixture of Experts(MoE) architecture. PESC integrates adapters into the MoE layers of sparsemodels, differentiating experts without altering the individual weights withinthese layers. This method significantly reduces computational costs and GPUmemory requirements, facilitating model capacity expansion through a minimalincrease in parameters via the inserted adapters. Our empirical evaluationdemonstrates the effectiveness of the PESC method. Using PESC duringinstruction tuning, our sparse models, dubbed Camelidae outperform all otheropensource sparse models and exhibit superior general capabilities compared toGPT3.5.</description><author>Haoyuan Wu, Haisheng Zheng, Bei Yu</author><pubDate>Mon, 08 Jan 2024 12:51:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02731v2</guid></item><item><title>End-to-End Crystal Structure Prediction from Powder X-Ray Diffraction</title><link>http://arxiv.org/abs/2401.03862v1</link><description>Powder X-ray diffraction (PXRD) is a crucial means for crystal structuredetermination. Such determination often involves external database matching tofind a structural analogue and Rietveld refinement to obtain finer structure.However, databases may be incomplete and Rietveld refinement often requiresintensive trial-and-error efforts from trained experimentalists, which remainsineffective in practice. To settle these issues, we propose XtalNet, the firstend-to-end deep learning-based framework capable of ab initio generation ofcrystal structures that accurately match given PXRD patterns. The model employscontrastive learning and Diffusion-based conditional generation to enable thesimultaneous execution of two tasks: crystal structure retrieval based on PXRDpatterns and conditional structure generations. To validate the effectivenessof XtalNet, we curate a much more challenging and practical dataset hMOF-100,XtalNet performs well on this dataset, reaching 96.3\% top-10 hit ratio on thedatabase retrieval task and 95.0\% top-10 match rate on the ranked structuregeneration task.</description><author>Qingsi Lai, Lin Yao, Zhifeng Gao, Siyuan Liu, Hongshuai Wang, Shuqi Lu, Di He, Liwei Wang, Cheng Wang, Guolin Ke</author><pubDate>Mon, 08 Jan 2024 12:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03862v1</guid></item><item><title>Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting</title><link>http://arxiv.org/abs/2312.11945v2</link><description>Recent approaches in Incomplete Utterance Rewriting (IUR) fail to capture thesource of important words, which is crucial to edit the incomplete utterance,and introduce words from irrelevant utterances. We propose a novel andeffective multi-task information interaction framework including contextselection, edit matrix construction, and relevance merging to capture themulti-granularity of semantic information. Benefiting from fetching therelevant utterance and figuring out the important words, our approachoutperforms existing state-of-the-art models on two benchmark datasetsRestoration-200K and CANAND in this field. Code will be provided on\url{https://github.com/yanmenxue/QR}.</description><author>Haowei Du, Dinghao Zhang, Chen Li, Yang Li, Dongyan Zhao</author><pubDate>Mon, 08 Jan 2024 12:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11945v2</guid></item><item><title>General time-reversal equivariant neural network potential for magnetic materials</title><link>http://arxiv.org/abs/2211.11403v3</link><description>This study introduces time-reversal E(3)-equivariant neural network andSpinGNN++ framework for constructing a comprehensive interatomic potential formagnetic systems, encompassing spin-orbit coupling and noncollinear magneticmoments. SpinGNN++ integrates multitask spin equivariant neural network withexplicit spin-lattice terms, including Heisenberg, Dzyaloshinskii-Moriya,Kitaev, single-ion anisotropy, and biquadratic interactions, and employstime-reversal equivariant neural network to learn high-order spin-latticeinteractions using time-reversal E(3)-equivariant convolutions. To validateSpinGNN++, a complex magnetic model dataset is introduced as a benchmark andemployed to demonstrate its capabilities. SpinGNN++ provides accuratedescriptions of the complex spin-lattice coupling in monolayer CrI$_3$ andCrTe$_2$, achieving sub-meV errors. Importantly, it facilitates large-scaleparallel spin-lattice dynamics, thereby enabling the exploration of associatedproperties, including the magnetic ground state and phase transition.Remarkably, SpinGNN++ identifies a new ferrimagnetic state as the groundmagnetic state for monolayer CrTe2, thereby enriching its phase diagram andproviding deeper insights into the distinct magnetic signals observed invarious experiments.</description><author>Hongyu Yu, Boyu Liu, Yang Zhong, Liangliang Hong, Junyi Ji, Changsong Xu, Xingao Gong, Hongjun Xiang</author><pubDate>Mon, 08 Jan 2024 12:45:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11403v3</guid></item><item><title>Inverse Reinforcement Learning with Sub-optimal Experts</title><link>http://arxiv.org/abs/2401.03857v1</link><description>Inverse Reinforcement Learning (IRL) techniques deal with the problem ofdeducing a reward function that explains the behavior of an expert agent who isassumed to act optimally in an underlying unknown task. In several problems ofinterest, however, it is possible to observe the behavior of multiple expertswith different degree of optimality (e.g., racing drivers whose skills rangesfrom amateurs to professionals). For this reason, in this work, we extend theIRL formulation to problems where, in addition to demonstrations from theoptimal agent, we can observe the behavior of multiple sub-optimal experts.Given this problem, we first study the theoretical properties of the class ofreward functions that are compatible with a given set of experts, i.e., thefeasible reward set. Our results show that the presence of multiple sub-optimalexperts can significantly shrink the set of compatible rewards. Furthermore, westudy the statistical complexity of estimating the feasible reward set with agenerative model. To this end, we analyze a uniform sampling algorithm thatresults in being minimax optimal whenever the sub-optimal experts' performancelevel is sufficiently close to the one of the optimal agent.</description><author>Riccardo Poiani, Gabriele Curti, Alberto Maria Metelli, Marcello Restelli</author><pubDate>Mon, 08 Jan 2024 12:39:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03857v1</guid></item><item><title>The Compute Divide in Machine Learning: A Threat to Academic Contribution and Scrutiny?</title><link>http://arxiv.org/abs/2401.02452v2</link><description>There are pronounced differences in the extent to which industrial andacademic AI labs use computing resources. We provide a data-driven survey ofthe role of the compute divide in shaping machine learning research. We showthat a compute divide has coincided with a reduced representation ofacademic-only research teams in compute intensive research topics, especiallyfoundation models. We argue that, academia will likely play a smaller role inadvancing the associated techniques, providing critical evaluation andscrutiny, and in the diffusion of such models. Concurrent with this change inresearch focus, there is a noticeable shift in academic research towardsembracing open source, pre-trained models developed within the industry. Toaddress the challenges arising from this trend, especially reduced scrutiny ofinfluential models, we recommend approaches aimed at thoughtfully expandingacademic insights. Nationally-sponsored computing infrastructure coupled withopen science initiatives could judiciously boost academic compute access,prioritizing research on interpretability, safety and security. Structuredaccess programs and third-party auditing may also allow measured externalevaluation of industry systems.</description><author>Tamay Besiroglu, Sage Andrus Bergerson, Amelia Michael, Lennart Heim, Xueyun Luo, Neil Thompson</author><pubDate>Mon, 08 Jan 2024 12:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02452v2</guid></item><item><title>Boldly Going Where No Benchmark Has Gone Before: Exposing Bias and Shortcomings in Code Generation Evaluation</title><link>http://arxiv.org/abs/2401.03855v1</link><description>Motivated by the increasing popularity of code generation from humandescriptions using large language models (LLMs), several benchmarks have beenproposed to assess the capabilities of existing and emerging models. This studypresents a large-scale human evaluation of HumanEval and MBPP, two widely usedbenchmarks for Python code generation, focusing on their diversity anddifficulty. Our findings reveal a significant bias towards a limited number ofprogramming concepts, with negligible or no representation of most concepts.Additionally, we identify a concerningly high proportion of easy programmingquestions, potentially leading to an overestimation of model performance oncode generation tasks.</description><author>Ankit Yadav, Mayank Singh</author><pubDate>Mon, 08 Jan 2024 12:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03855v1</guid></item><item><title>TIER: Text and Image Encoder-based Regression for AIGC Image Quality Assessment</title><link>http://arxiv.org/abs/2401.03854v1</link><description>Recently, AIGC image quality assessment (AIGCIQA), which aims to assess thequality of AI-generated images from a human perception perspective, has emergedas a new topic in computer vision. Unlike common image quality assessment taskswhere images are derived from original ones distorted by noise, blur, andcompression, in AIGCIQA tasks, images are typically generated by generativemodels using text prompts. Considerable efforts have been made in the pastyears to advance AIGCIQA. However, most existing AIGCIQA methods regresspredicted scores directly from individual generated images, overlooking theinformation contained in the text prompts of these images. This oversightpartially limits the performance of these AIGCIQA methods. To address thisissue, we propose a text and image encoder-based regression (TIER) framework.Specifically, we process the generated images and their corresponding textprompts as inputs, utilizing a text encoder and an image encoder to extractfeatures from these text prompts and generated images, respectively. Todemonstrate the effectiveness of our proposed TIER method, we conduct extensiveexperiments on several mainstream AIGCIQA databases, including AGIQA-1K,AGIQA-3K, and AIGCIQA2023. The experimental results indicate that our proposedTIER method generally demonstrates superior performance compared to baseline inmost cases.</description><author>Jiquan Yuan, Xinyan Cao, Jinming Che, Qinyuan Wang, Sen Liang, Wei Ren, Jinlong Lin, Xixin Cao</author><pubDate>Mon, 08 Jan 2024 12:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03854v1</guid></item></channel></rss>