<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 20 Oct 2024 13:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens</title><link>http://arxiv.org/abs/2410.13863v1</link><description>Scaling up autoregressive models in vision has not proven as beneficial as inlarge language models. In this work, we investigate this scaling problem in thecontext of text-to-image generation, focusing on two critical factors: whethermodels use discrete or continuous tokens, and whether tokens are generated in arandom or fixed raster order using BERT- or GPT-like transformer architectures.Our empirical results show that, while all models scale effectively in terms ofvalidation loss, their evaluation performance -- measured by FID, GenEvalscore, and visual quality -- follows different trends. Models based oncontinuous tokens achieve significantly better visual quality than those usingdiscrete tokens. Furthermore, the generation order and attention mechanismssignificantly affect the GenEval score: random-order models achieve notablybetter GenEval scores compared to raster-order models. Inspired by thesefindings, we train Fluid, a random-order autoregressive model on continuoustokens. Fluid 10.5B model achieves a new state-of-the-art zero-shot FID of 6.16on MS-COCO 30K, and 0.69 overall score on the GenEval benchmark. We hope ourfindings and results will encourage future efforts to further bridge thescaling gap between vision and language models.</description><author>Lijie Fan, Tianhong Li, Siyang Qin, Yuanzhen Li, Chen Sun, Michael Rubinstein, Deqing Sun, Kaiming He, Yonglong Tian</author><pubDate>Thu, 17 Oct 2024 17:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13863v1</guid></item><item><title>UniDrive: Towards Universal Driving Perception Across Camera Configurations</title><link>http://arxiv.org/abs/2410.13864v1</link><description>Vision-centric autonomous driving has demonstrated excellent performance witheconomical sensors. As the fundamental step, 3D perception aims to infer 3Dinformation from 2D images based on 3D-2D projection. This makes drivingperception models susceptible to sensor configuration (e.g., camera intrinsicsand extrinsics) variations. However, generalizing across camera configurationsis important for deploying autonomous driving models on different car models.In this paper, we present UniDrive, a novel framework for vision-centricautonomous driving to achieve universal perception across cameraconfigurations. We deploy a set of unified virtual cameras and propose aground-aware projection method to effectively transform the original imagesinto these unified virtual views. We further propose a virtual configurationoptimization method by minimizing the expected projection error betweenoriginal cameras and virtual cameras. The proposed virtual camera projectioncan be applied to existing 3D perception methods as a plug-and-play module tomitigate the challenges posed by camera parameter variability, resulting inmore adaptable and reliable driving perception models. To evaluate theeffectiveness of our framework, we collect a dataset on Carla by driving thesame routes while only modifying the camera configurations. Experimentalresults demonstrate that our method trained on one specific cameraconfiguration can generalize to varying configurations with minor performancedegradation.</description><author>Ye Li, Wenzhao Zheng, Xiaonan Huang, Kurt Keutzer</author><pubDate>Thu, 17 Oct 2024 17:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13864v1</guid></item><item><title>DepthSplat: Connecting Gaussian Splatting and Depth</title><link>http://arxiv.org/abs/2410.13862v1</link><description>Gaussian splatting and single/multi-view depth estimation are typicallystudied in isolation. In this paper, we present DepthSplat to connect Gaussiansplatting and depth estimation and study their interactions. More specifically,we first contribute a robust multi-view depth model by leveraging pre-trainedmonocular depth features, leading to high-quality feed-forward 3D Gaussiansplatting reconstructions. We also show that Gaussian splatting can serve as anunsupervised pre-training objective for learning powerful depth models fromlarge-scale unlabelled datasets. We validate the synergy between Gaussiansplatting and depth estimation through extensive ablation and cross-tasktransfer experiments. Our DepthSplat achieves state-of-the-art performance onScanNet, RealEstate10K and DL3DV datasets in terms of both depth estimation andnovel view synthesis, demonstrating the mutual benefits of connecting bothtasks. Our code, models, and video results are available athttps://haofeixu.github.io/depthsplat/.</description><author>Haofei Xu, Songyou Peng, Fangjinhua Wang, Hermann Blum, Daniel Barath, Andreas Geiger, Marc Pollefeys</author><pubDate>Thu, 17 Oct 2024 17:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13862v1</guid></item><item><title>PUMA: Empowering Unified MLLM with Multi-granular Visual Generation</title><link>http://arxiv.org/abs/2410.13861v1</link><description>Recent advancements in multimodal foundation models have yielded significantprogress in vision-language understanding. Initial attempts have also exploredthe potential of multimodal large language models (MLLMs) for visual contentgeneration. However, existing works have insufficiently addressed the varyinggranularity demands of different image generation tasks within a unified MLLMparadigm - from the diversity required in text-to-image generation to theprecise controllability needed in image manipulation. In this work, we proposePUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMAunifies multi-granular visual features as both inputs and outputs of MLLMs,elegantly addressing the different granularity requirements of various imagegeneration tasks within a unified MLLM framework. Following multimodalpretraining and task-specific instruction tuning, PUMA demonstrates proficiencyin a wide range of multimodal tasks. This work represents a significant steptowards a truly unified MLLM capable of adapting to the granularity demands ofvarious visual tasks. The code and model will be released inhttps://github.com/rongyaofang/PUMA.</description><author>Rongyao Fang, Chengqi Duan, Kun Wang, Hao Li, Hao Tian, Xingyu Zeng, Rui Zhao, Jifeng Dai, Hongsheng Li, Xihui Liu</author><pubDate>Thu, 17 Oct 2024 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13861v1</guid></item><item><title>VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding</title><link>http://arxiv.org/abs/2410.13860v1</link><description>3D visual grounding is crucial for robots, requiring integration of naturallanguage and 3D scene understanding. Traditional methods depending onsupervised learning with 3D point clouds are limited by scarce datasets.Recently zero-shot methods leveraging LLMs have been proposed to address thedata issue. While effective, these methods only use object-centric information,limiting their ability to handle complex queries. In this work, we presentVLM-Grounder, a novel framework using vision-language models (VLMs) forzero-shot 3D visual grounding based solely on 2D images. VLM-Grounderdynamically stitches image sequences, employs a grounding and feedback schemeto find the target object, and uses a multi-view ensemble projection toaccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3Ddatasets show VLM-Grounder outperforms previous zero-shot methods, achieving51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3Dgeometry or object priors. Codes are available athttps://github.com/OpenRobotLab/VLM-Grounder .</description><author>Runsen Xu, Zhiwei Huang, Tai Wang, Yilun Chen, Jiangmiao Pang, Dahua Lin</author><pubDate>Thu, 17 Oct 2024 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13860v1</guid></item><item><title>$Î³-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2410.13859v1</link><description>Despite the significant progress in multimodal large language models (MLLMs),their high computational cost remains a barrier to real-world deployment.Inspired by the mixture of depths (MoDs) in natural language processing, we aimto address this limitation from the perspective of ``activated tokens''. Ourkey insight is that if most tokens are redundant for the layer computation,then can be skipped directly via the MoD layer. However, directly convertingthe dense layers of MLLMs to MoD layers leads to substantial performancedegradation. To address this issue, we propose an innovative MoD adaptationstrategy for existing MLLMs called $\gamma$-MoD. In $\gamma$-MoD, a novelmetric is proposed to guide the deployment of MoDs in the MLLM, namely rank ofattention maps (ARank). Through ARank, we can effectively identify which layeris redundant and should be replaced with the MoD layer. Based on ARank, wefurther propose two novel designs to maximize the computational sparsity ofMLLM while maintaining its performance, namely shared vision-language routerand masked routing learning. With these designs, more than 90% dense layers ofthe MLLM can be effectively converted to the MoD ones. To validate our method,we apply it to three popular MLLMs, and conduct extensive experiments on 9benchmark datasets. Experimental results not only validate the significantefficiency benefit of $\gamma$-MoD to existing MLLMs but also confirm itsgeneralization ability on various MLLMs. For example, with a minor performancedrop, i.e., -1.5%, $\gamma$-MoD can reduce the training and inference time ofLLaVA-HR by 31.0% and 53.2%, respectively.</description><author>Yaxin Luo, Gen Luo, Jiayi Ji, Yiyi Zhou, Xiaoshuai Sun, Zhiqiang Shen, Rongrong Ji</author><pubDate>Thu, 17 Oct 2024 17:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13859v1</guid></item><item><title>How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs</title><link>http://arxiv.org/abs/2410.13857v1</link><description>Despite the remarkable success of Transformer-based Large Language Models(LLMs) across various domains, understanding and enhancing their mathematicalcapabilities remains a significant challenge. In this paper, we conduct arigorous theoretical analysis of LLMs' mathematical abilities, with a specificfocus on their arithmetic performances. We identify numerical precision as akey factor that influences their effectiveness in mathematical tasks. Ourresults show that Transformers operating with low numerical precision fail toaddress arithmetic tasks, such as iterated addition and integer multiplication,unless the model size grows super-polynomially with respect to the inputlength. In contrast, Transformers with standard numerical precision canefficiently handle these tasks with significantly smaller model sizes. Wefurther support our theoretical findings through empirical experiments thatexplore the impact of varying numerical precision on arithmetic tasks,providing valuable insights for improving the mathematical reasoningcapabilities of LLMs.</description><author>Guhao Feng, Kai Yang, Yuntian Gu, Xinyue Ai, Shengjie Luo, Jiacheng Sun, Di He, Zhenguo Li, Liwei Wang</author><pubDate>Thu, 17 Oct 2024 17:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13857v1</guid></item><item><title>Diffusing States and Matching Scores: A New Framework for Imitation Learning</title><link>http://arxiv.org/abs/2410.13855v1</link><description>Adversarial Imitation Learning is traditionally framed as a two-playerzero-sum game between a learner and an adversarially chosen cost function, andcan therefore be thought of as the sequential generalization of a GenerativeAdversarial Network (GAN). A prominent example of this framework is GenerativeAdversarial Imitation Learning (GAIL). However, in recent years, diffusionmodels have emerged as a non-adversarial alternative to GANs that merelyrequire training a score function via regression, yet produce generations of ahigher quality. In response, we investigate how to lift insights from diffusionmodeling to the sequential setting. We propose diffusing states and performingscore-matching along diffused states to measure the discrepancy between theexpert's and learner's states. Thus, our approach only requires training scorefunctions to predict noises via standard regression, making it significantlyeasier and more stable to train than adversarial methods. Theoretically, weprove first- and second-order instance-dependent bounds with linear scaling inthe horizon, proving that our approach avoids the compounding errors thatstymie offline approaches to imitation learning. Empirically, we show ourapproach outperforms GAN-style imitation learning baselines across variouscontinuous control problems, including complex tasks like controlling humanoidsto walk, sit, and crawl.</description><author>Runzhe Wu, Yiding Chen, Gokul Swamy, KiantÃ© Brantley, Wen Sun</author><pubDate>Thu, 17 Oct 2024 17:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13855v1</guid></item><item><title>Can MLLMs Understand the Deep Implication Behind Chinese Images?</title><link>http://arxiv.org/abs/2410.13854v1</link><description>As the capabilities of Multimodal Large Language Models (MLLMs) continue toimprove, the need for higher-order capability evaluation of MLLMs isincreasing. However, there is a lack of work evaluating MLLM for higher-orderperception and understanding of Chinese visual content. To fill the gap, weintroduce the **C**hinese **I**mage **I**mplication understanding**Bench**mark, **CII-Bench**, which aims to assess the higher-order perceptionand understanding capabilities of MLLMs for Chinese images. CII-Bench standsout in several ways compared to existing benchmarks. Firstly, to ensure theauthenticity of the Chinese context, images in CII-Bench are sourced from theChinese Internet and manually reviewed, with corresponding answers alsomanually crafted. Additionally, CII-Bench incorporates images that representChinese traditional culture, such as famous Chinese traditional paintings,which can deeply reflect the model's understanding of Chinese traditionalculture. Through extensive experiments on CII-Bench across multiple MLLMs, wehave made significant findings. Initially, a substantial gap is observedbetween the performance of MLLMs and humans on CII-Bench. The highest accuracyof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at animpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditionalculture images, suggesting limitations in their ability to understandhigh-level semantics and lack a deep knowledge base of Chinese traditionalculture. Finally, it is observed that most models exhibit enhanced accuracywhen image emotion hints are incorporated into the prompts. We believe thatCII-Bench will enable MLLMs to gain a better understanding of Chinese semanticsand Chinese-specific images, advancing the journey towards expert artificialgeneral intelligence (AGI). Our project is publicly available athttps://cii-bench.github.io/.</description><author>Chenhao Zhang, Xi Feng, Yuelin Bai, Xinrun Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge Zhang, Shiwen Ni</author><pubDate>Thu, 17 Oct 2024 17:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13854v1</guid></item><item><title>AutoAL: Automated Active Learning with Differentiable Query Strategy Search</title><link>http://arxiv.org/abs/2410.13853v1</link><description>As deep learning continues to evolve, the need for data efficiency becomesincreasingly important. Considering labeling large datasets is bothtime-consuming and expensive, active learning (AL) provides a promisingsolution to this challenge by iteratively selecting the most informativesubsets of examples to train deep neural networks, thereby reducing thelabeling cost. However, the effectiveness of different AL algorithms can varysignificantly across data scenarios, and determining which AL algorithm bestfits a given task remains a challenging problem. This work presents the firstdifferentiable AL strategy search method, named AutoAL, which is designed ontop of existing AL sampling strategies. AutoAL consists of two neural nets,named SearchNet and FitNet, which are optimized concurrently under adifferentiable bi-level optimization framework. For any given task, SearchNetand FitNet are iteratively co-optimized using the labeled data, learning howwell a set of candidate AL algorithms perform on that task. With the optimal ALstrategies identified, SearchNet selects a small subset from the unlabeled poolfor querying their annotations, enabling efficient training of the task model.Experimental results demonstrate that AutoAL consistently achieves superioraccuracy compared to all candidate AL algorithms and other selective ALapproaches, showcasing its potential for adapting and integrating multipleexisting AL methods across diverse tasks and domains. Code will be availableat: https://github.com/haizailache999/AutoAL.</description><author>Yifeng Wang, Xueying Zhan, Siyu Huang</author><pubDate>Thu, 17 Oct 2024 17:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13853v1</guid></item><item><title>Retrospective Learning from Interactions</title><link>http://arxiv.org/abs/2410.13852v1</link><description>Multi-turn interactions between large language models (LLMs) and usersnaturally include implicit feedback signals. If an LLM responds in anunexpected way to an instruction, the user is likely to signal it by rephrasingthe request, expressing frustration, or pivoting to an alternative task. Suchsignals are task-independent and occupy a relatively constrained subspace oflanguage, allowing the LLM to identify them even if it fails on the actualtask. This creates an avenue for continually learning from interactions withoutadditional annotations. We introduce ReSpect, a method to learn from suchsignals in past interactions via retrospection. We deploy ReSpect in a newmultimodal interaction scenario, where humans instruct an LLM to solve anabstract reasoning task with a combinatorial solution space. Through thousandsof interactions with humans, we show how ReSpect gradually improves taskcompletion rate from 31% to 82%, all without any external annotation.</description><author>Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi</author><pubDate>Thu, 17 Oct 2024 17:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13852v1</guid></item><item><title>Differentiable Robot Rendering</title><link>http://arxiv.org/abs/2410.13851v1</link><description>Vision foundation models trained on massive amounts of visual data have shownunprecedented reasoning and planning skills in open-world settings. A keychallenge in applying them to robotic tasks is the modality gap between visualdata and action data. We introduce differentiable robot rendering, a methodallowing the visual appearance of a robot body to be directly differentiablewith respect to its control parameters. Our model integrates a kinematics-awaredeformable model and Gaussians Splatting and is compatible with any robot formfactors and degrees of freedom. We demonstrate its capability and usage inapplications including reconstruction of robot poses from images andcontrolling robots through vision language models. Quantitative and qualitativeresults show that our differentiable rendering model provides effectivegradients for robotic control directly from pixels, setting the foundation forthe future applications of vision foundation models in robotics.</description><author>Ruoshi Liu, Alper Canberk, Shuran Song, Carl Vondrick</author><pubDate>Thu, 17 Oct 2024 17:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13851v1</guid></item><item><title>Influence Functions for Scalable Data Attribution in Diffusion Models</title><link>http://arxiv.org/abs/2410.13850v1</link><description>Diffusion models have led to significant advancements in generativemodelling. Yet their widespread adoption poses challenges regarding dataattribution and interpretability. In this paper, we aim to help address suchchallenges in diffusion models by developing an \textit{influence functions}framework. Influence function-based data attribution methods approximate how amodel's output would have changed if some training data were removed. Insupervised learning, this is usually used for predicting how the loss on aparticular example would change. For diffusion models, we focus on predictingthe change in the probability of generating a particular example via severalproxy measurements. We show how to formulate influence functions for suchquantities and how previously proposed methods can be interpreted as particulardesign choices in our framework. To ensure scalability of the Hessiancomputations in influence functions, we systematically develop K-FACapproximations based on generalised Gauss-Newton matrices specifically tailoredto diffusion models. We recast previously proposed methods as specific designchoices in our framework and show that our recommended method outperformsprevious data attribution approaches on common evaluations, such as the LinearData-modelling Score (LDS) or retraining without top influences, without theneed for method-specific hyperparameter tuning.</description><author>Bruno Mlodozeniec, Runa Eschenhagen, Juhan Bae, Alexander Immer, David Krueger, Richard Turner</author><pubDate>Thu, 17 Oct 2024 17:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13850v1</guid></item><item><title>From Gradient Clipping to Normalization for Heavy Tailed SGD</title><link>http://arxiv.org/abs/2410.13849v1</link><description>Recent empirical evidence indicates that many machine learning applicationsinvolve heavy-tailed gradient noise, which challenges the standard assumptionsof bounded variance in stochastic optimization. Gradient clipping has emergedas a popular tool to handle this heavy-tailed noise, as it achieves goodperformance in this setting both theoretically and practically. However, ourcurrent theoretical understanding of non-convex gradient clipping has threemain shortcomings. First, the theory hinges on large, increasing clippingthresholds, which are in stark contrast to the small constant clippingthresholds employed in practice. Second, clipping thresholds require knowledgeof problem-dependent parameters to guarantee convergence. Lastly, even withthis knowledge, current sampling complexity upper bounds for the method aresub-optimal in nearly all parameters. To address these issues, we studyconvergence of Normalized SGD (NSGD). First, we establish a parameter-freesample complexity for NSGD of$\mathcal{O}\left(\varepsilon^{-\frac{2p}{p-1}}\right)$ to find an$\varepsilon$-stationary point. Furthermore, we prove tightness of this result,by providing a matching algorithm-specific lower bound. In the setting whereall problem parameters are known, we show this complexity is improved to$\mathcal{O}\left(\varepsilon^{-\frac{3p-2}{p-1}}\right)$, matching thepreviously known lower bound for all first-order methods in all problemdependent parameters. Finally, we establish high-probability convergence ofNSGD with a mild logarithmic dependence on the failure probability. Our workcomplements the studies of gradient clipping under heavy tailed noise improvingthe sample complexities of existing algorithms and offering an alternativemechanism to achieve high probability convergence.</description><author>Florian HÃ¼bler, Ilyas Fatkhullin, Niao He</author><pubDate>Thu, 17 Oct 2024 17:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13849v1</guid></item><item><title>Towards Multilingual LLM Evaluation for European Languages</title><link>http://arxiv.org/abs/2410.08928v2</link><description>The rise of Large Language Models (LLMs) has revolutionized natural languageprocessing across numerous languages and tasks. However, evaluating LLMperformance in a consistent and meaningful way across multiple Europeanlanguages remains challenging, especially due to the scarcity oflanguage-parallel multilingual benchmarks. We introduce a multilingualevaluation approach tailored for European languages. We employ translatedversions of five widely-used benchmarks to assess the capabilities of 40 LLMsacross 21 European languages. Our contributions include examining theeffectiveness of translated benchmarks, assessing the impact of differenttranslation services, and offering a multilingual evaluation framework for LLMsthat includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC,EU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publiclyavailable to encourage further research in multilingual LLM evaluation.</description><author>Klaudia Thellmann, Bernhard Stadler, Michael Fromm, Jasper Schulze Buschhoff, Alex Jude, Fabio Barth, Johannes Leveling, Nicolas Flores-Herr, Joachim KÃ¶hler, RenÃ© JÃ¤kel, Mehdi Ali</author><pubDate>Thu, 17 Oct 2024 17:58:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08928v2</guid></item><item><title>Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</title><link>http://arxiv.org/abs/2410.13848v1</link><description>In this paper, we introduce Janus, an autoregressive framework that unifiesmultimodal understanding and generation. Prior research often relies on asingle visual encoder for both tasks, such as Chameleon. However, due to thediffering levels of information granularity required by multimodalunderstanding and generation, this approach can lead to suboptimal performance,particularly in multimodal understanding. To address this issue, we decouplevisual encoding into separate pathways, while still leveraging a single,unified transformer architecture for processing. The decoupling not onlyalleviates the conflict between the visual encoder's roles in understanding andgeneration, but also enhances the framework's flexibility. For instance, boththe multimodal understanding and generation components can independently selecttheir most suitable encoding methods. Experiments show that Janus surpassesprevious unified model and matches or exceeds the performance of task-specificmodels. The simplicity, high flexibility, and effectiveness of Janus make it astrong candidate for next-generation unified multimodal models.</description><author>Chengyue Wu, Xiaokang Chen, Zhiyu Wu, Yiyang Ma, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan, Ping Luo</author><pubDate>Thu, 17 Oct 2024 17:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13848v1</guid></item><item><title>SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction</title><link>http://arxiv.org/abs/2410.13846v1</link><description>Recent advancements in large language models (LLMs) have extended theircapabilities to handle long contexts. However, increasing the number of modellayers and the length of input sequences significantly escalates the memoryrequired to store key-value (KV) cache, posing challenges for efficientinference. To mitigate this issue, we present SimLayerKV, a simple yeteffective method that reduces inter-layer KV cache redundancies by selectivelydropping cache in identified lazy layers. Our approach is based on theobservation that certain layers in long-context LLMs exhibit "lazy" behavior,contributing less to modeling long-range dependencies compared to non-lazylayers. By analyzing attention weight patterns, we find that the behavior ofthese lazy layers is consistent across tokens during generation for a giveninput. This insight motivates our SimLayerKV, which identifies lazy layers andreduces their KV cache accordingly. SimLayerKV is training-free, generalizable,and can be implemented with only seven lines of code. We conduct extensiveexperiments on three representative LLMs, e.g., LLaMA2-7B, LLaMA3-8B, andMistral-7B across 16 tasks from the LongBench benchmark. The resultsdemonstrate that SimLayerKV achieves a KV cache compression ratio of 5$\times$with only a 1.2% performance drop when combined with 4-bit quantization. Ourcode is available at https://github.com/sail-sg/SimLayerKV.</description><author>Xuan Zhang, Cunxiao Du, Chao Du, Tianyu Pang, Wei Gao, Min Lin</author><pubDate>Thu, 17 Oct 2024 17:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13846v1</guid></item><item><title>D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution Refinement</title><link>http://arxiv.org/abs/2410.13842v1</link><description>We introduce D-FINE, a powerful real-time object detector that achievesoutstanding localization precision by redefining the bounding box regressiontask in DETR models. D-FINE comprises two key components: Fine-grainedDistribution Refinement (FDR) and Global Optimal Localization Self-Distillation(GO-LSD). FDR transforms the regression process from predicting fixedcoordinates to iteratively refining probability distributions, providing afine-grained intermediate representation that significantly enhanceslocalization accuracy. GO-LSD is a bidirectional optimization strategy thattransfers localization knowledge from refined distributions to shallower layersthrough self-distillation, while also simplifying the residual prediction tasksfor deeper layers. Additionally, D-FINE incorporates lightweight optimizationsin computationally intensive modules and operations, achieving a better balancebetween speed and accuracy. Specifically, D-FINE-L / X achieves 54.0% / 55.8%AP on the COCO dataset at 124 / 78 FPS on an NVIDIA T4 GPU. When pretrained onObjects365, D-FINE-L / X attains 57.1% / 59.3% AP, surpassing all existingreal-time detectors. Furthermore, our method significantly enhances theperformance of a wide range of DETR models by up to 5.3% AP with negligibleextra parameters and training costs. Our code and pretrained models:https://github.com/Peterande/D-FINE.</description><author>Yansong Peng, Hebei Li, Peixi Wu, Yueyi Zhang, Xiaoyan Sun, Feng Wu</author><pubDate>Thu, 17 Oct 2024 17:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13842v1</guid></item><item><title>A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models</title><link>http://arxiv.org/abs/2410.13841v1</link><description>Post-training has emerged as a crucial paradigm for adapting large-scalepre-trained models to various tasks, whose effects are fully reflected by deltaparameters (i.e., the disparity between post-trained and pre-trainedparameters). While numerous studies have explored delta parameter propertiesvia operations like pruning, quantization, low-rank approximation, andextrapolation, a unified framework for systematically examining thesecharacteristics has been lacking. In this paper, we propose a novel perspectivebased on Riemann sum approximation of the loss function to elucidate deltaparameter editing operations. Our analysis categorizes existing methods intothree classes based on their post-editing performance: competitive, decreased,and improved, explaining how they are expressed by the Riemann sumapproximation term and how they alter the model performance. Extensiveexperiments on both visual and language models, including ViT, LLaMA 3, Qwen 2,and Mistral, corroborate our theoretical findings. Furthermore, we introduceextensions to existing techniques like DARE and BitDelta, highlighting theirlimitations in leveraging the properties of delta parameters and reorganizingthem into general expressions to enhance the applicability and effectiveness ofdelta parameter editing in post-trained models.</description><author>Qiaoyu Tang, Le Yu, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Le Sun</author><pubDate>Thu, 17 Oct 2024 17:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13841v1</guid></item><item><title>Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding</title><link>http://arxiv.org/abs/2410.13839v1</link><description>The goal of this paper is to accelerate codec-based speech synthesis systemswith minimum sacrifice to speech quality. We propose an enhanced inferencemethod that allows for flexible trade-offs between speed and quality duringinference without requiring additional training. Our core idea is to predictmultiple tokens per inference step of the AR module using multiple predictionheads, resulting in a linear reduction in synthesis time as the number of headsincreases. Furthermore, we introduce a novel speculative decoding techniquethat utilises a Viterbi-based algorithm to select the optimal sequence ofgenerated tokens at each decoding step. In our experiments, we demonstrate thatthe time required to predict each token is reduced by a factor of 4 to 5compared to baseline models, with minimal quality trade-off or even improvementin terms of speech intelligibility. Audio samples are available at:multpletokensprediction.github.io/multipletokensprediction.github.io/.</description><author>Tan Dat Nguyen, Ji-Hoon Kim, Jeongsoo Choi, Shukjae Choi, Jinseok Park, Younglo Lee, Joon Son Chung</author><pubDate>Thu, 17 Oct 2024 17:55:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13839v1</guid></item><item><title>ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization</title><link>http://arxiv.org/abs/2410.13837v1</link><description>Reward shaping is a critical component in reinforcement learning (RL),particularly for complex tasks where sparse rewards can hinder learning. Whileshaping rewards have been introduced to provide additional guidance, selectingeffective shaping functions remains challenging and computationally expensive.This paper introduces Online Reward Selection and Policy Optimization (ORSO), anovel approach that frames shaping reward selection as an online modelselection problem. ORSO employs principled exploration strategies toautomatically identify promising shaping reward functions without humanintervention, balancing exploration and exploitation with provable regretguarantees. We demonstrate ORSO's effectiveness across various continuouscontrol tasks using the Isaac Gym simulator. Compared to traditional methodsthat fully evaluate each shaping reward function, ORSO significantly improvessample efficiency, reduces computational time, and consistently identifieshigh-quality reward functions that produce policies comparable to thosegenerated by domain experts through hand-engineered rewards.</description><author>Chen Bo Calvin Zhang, Zhang-Wei Hong, Aldo Pacchiano, Pulkit Agrawal</author><pubDate>Thu, 17 Oct 2024 17:55:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13837v1</guid></item><item><title>Active-Dormant Attention Heads: Mechanistically Demystifying Extreme-Token Phenomena in LLMs</title><link>http://arxiv.org/abs/2410.13835v1</link><description>Practitioners have consistently observed three puzzling phenomena intransformer-based large language models (LLMs): attention sinks, value-statedrains, and residual-state peaks, collectively referred to as extreme-tokenphenomena. These phenomena are characterized by certain so-called "sink tokens"receiving disproportionately high attention weights, exhibiting significantlysmaller value states, and having much larger residual-state norms than those ofother tokens. These extreme tokens give rise to various challenges in LLMinference, quantization, and interpretability. We elucidate the mechanisms behind extreme-token phenomena. First, we showthat these phenomena arise in very simple architectures -- transformers withone to three layers -- trained on a toy model, the Bigram-Backcopy (BB) task.In this setting, we identify an active-dormant mechanism, where attention headsbecome sinks for specific input domains while remaining non-sinks for others.Our theoretical analysis of the training dynamics reveals that these phenomenaare driven by a mutual reinforcement mechanism. Building on these insights, wepropose strategies to mitigate extreme-token phenomena during pretraining,including replacing softmax with ReLU and Adam with SGD. Next, we extend ouranalysis to pretrained LLMs, including Llama and OLMo, showing that manyattention heads exhibit a similar active-dormant mechanism as in the BB task,and that the mutual reinforcement mechanism also governs the emergence ofextreme-token phenomena during LLM pretraining. Our results reveal that many ofthe static and dynamic properties of extreme-token phenomena predicted by theBB task align with observations in pretrained LLMs.</description><author>Tianyu Guo, Druv Pai, Yu Bai, Jiantao Jiao, Michael I. Jordan, Song Mei</author><pubDate>Thu, 17 Oct 2024 17:54:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13835v1</guid></item><item><title>VidPanos: Generative Panoramic Videos from Casual Panning Videos</title><link>http://arxiv.org/abs/2410.13832v1</link><description>Panoramic image stitching provides a unified, wide-angle view of a scene thatextends beyond the camera's field of view. Stitching frames of a panning videointo a panoramic photograph is a well-understood problem for stationary scenes,but when objects are moving, a still panorama cannot capture the scene. Wepresent a method for synthesizing a panoramic video from a casually-capturedpanning video, as if the original video were captured with a wide-angle camera.We pose panorama synthesis as a space-time outpainting problem, where we aim tocreate a full panoramic video of the same length as the input video. Consistentcompletion of the space-time volume requires a powerful, realistic prior overvideo content and motion, for which we adapt generative video models. Existinggenerative models do not, however, immediately extend to panorama completion,as we show. We instead apply video generation as a component of our panoramasynthesis system, and demonstrate how to exploit the strengths of the modelswhile minimizing their limitations. Our system can create video panoramas for arange of in-the-wild scenes including people, vehicles, and flowing water, aswell as stationary background features.</description><author>Jingwei Ma, Erika Lu, Roni Paiss, Shiran Zada, Aleksander Holynski, Tali Dekel, Brian Curless, Michael Rubinstein, Forrester Cole</author><pubDate>Thu, 17 Oct 2024 17:53:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13832v1</guid></item><item><title>The Disparate Benefits of Deep Ensembles</title><link>http://arxiv.org/abs/2410.13831v1</link><description>Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as asimple way to boost predictive performance. However, their impact onalgorithmic fairness is not well understood yet. Algorithmic fairnessinvestigates how a model's performance varies across different groups,typically defined by protected attributes such as age, gender, or race. In thiswork, we investigate the interplay between the performance gains from DeepEnsembles and fairness. Our analysis reveals that they unevenly favor differentgroups in what we refer to as a disparate benefits effect. We empiricallyinvestigate this effect with Deep Ensembles applied to popular facial analysisand medical imaging datasets, where protected group attributes are given andfind that it occurs for multiple established group fairness metrics, includingstatistical parity and equal opportunity. Furthermore, we identify theper-group difference in predictive diversity of ensemble members as thepotential cause of the disparate benefits effect. Finally, we evaluatedifferent approaches to reduce unfairness due to the disparate benefits effect.Our findings show that post-processing is an effective method to mitigate thisunfairness while preserving the improved performance of Deep Ensembles.</description><author>Kajetan Schweighofer, Adrian Arnaiz-Rodriguez, Sepp Hochreiter, Nuria Oliver</author><pubDate>Thu, 17 Oct 2024 17:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13831v1</guid></item><item><title>DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control</title><link>http://arxiv.org/abs/2410.13830v1</link><description>Recent advances in customized video generation have enabled users to createvideos tailored to both specific subjects and motion trajectories. However,existing methods often require complicated test-time fine-tuning and strugglewith balancing subject learning and motion control, limiting their real-worldapplications. In this paper, we present DreamVideo-2, a zero-shot videocustomization framework capable of generating videos with a specific subjectand motion trajectory, guided by a single image and a bounding box sequence,respectively, and without the need for test-time fine-tuning. Specifically, weintroduce reference attention, which leverages the model's inherentcapabilities for subject learning, and devise a mask-guided motion module toachieve precise motion control by fully utilizing the robust motion signal ofbox masks derived from bounding boxes. While these two components achieve theirintended functions, we empirically observe that motion control tends todominate over subject learning. To address this, we propose two key designs: 1)the masked reference attention, which integrates a blended latent mask modelingscheme into reference attention to enhance subject representations at thedesired positions, and 2) a reweighted diffusion loss, which differentiates thecontributions of regions inside and outside the bounding boxes to ensure abalance between subject and motion control. Extensive experimental results on anewly curated dataset demonstrate that DreamVideo-2 outperformsstate-of-the-art methods in both subject customization and motion control. Thedataset, code, and models will be made publicly available.</description><author>Yujie Wei, Shiwei Zhang, Hangjie Yuan, Xiang Wang, Haonan Qiu, Rui Zhao, Yutong Feng, Feng Liu, Zhizhong Huang, Jiaxin Ye, Yingya Zhang, Hongming Shan</author><pubDate>Thu, 17 Oct 2024 17:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13830v1</guid></item><item><title>A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement</title><link>http://arxiv.org/abs/2410.13828v1</link><description>Reinforcement Learning from Human Feedback (RLHF) has become the predominantapproach for language model (LM) alignment. At its core, RLHF uses amargin-based loss for preference optimization, specifying ideal LM behavioronly by the difference between preferred and dispreferred responses. In thispaper, we identify a common pitfall of margin-based methods -- theunder-specification of ideal LM behavior on preferred and dispreferredresponses individually, which leads to two unintended consequences as themargin increases: (1) The probability of dispreferred (e.g., unsafe) responsesmay increase, resulting in potential safety alignment failures. (2) Theprobability of preferred responses may decrease, even when those responses areideal. We demystify the reasons behind these problematic behaviors:margin-based losses couple the change in the preferred probability to thegradient of the dispreferred one, and vice versa, often preventing thepreferred probability from increasing while the dispreferred one decreases, andthus causing a synchronized increase or decrease in both probabilities. We termthis effect, inherent in margin-based objectives, gradient entanglement.Formally, we derive conditions for general margin-based alignment objectivesunder which gradient entanglement becomes concerning: the inner product of thegradients of preferred and dispreferred log-probabilities is large relative tothe individual gradient norms. We theoretically investigate why such innerproducts can be large when aligning language models and empirically validateour findings. Empirical implications of our framework extend to explainingimportant differences in the training dynamics of various preferenceoptimization algorithms, and suggesting potential algorithm designs to mitigatethe under-specification issue of margin-based methods and thereby improvinglanguage model alignment.</description><author>Hui Yuan, Yifan Zeng, Yue Wu, Huazheng Wang, Mengdi Wang, Liu Leqi</author><pubDate>Thu, 17 Oct 2024 17:52:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13828v1</guid></item><item><title>Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models</title><link>http://arxiv.org/abs/2410.13826v1</link><description>With models getting stronger, evaluations have grown more complex, testingmultiple skills in one benchmark and even in the same instance at once.However, skill-wise performance is obscured when inspecting aggregate accuracy,under-utilizing the rich signal modern benchmarks contain. We propose anautomatic approach to recover the underlying skills relevant for any evaluationinstance, by way of inspecting model-generated rationales. After validating therelevance of rationale-parsed skills and inferring skills for $46$k instancesover $12$ benchmarks, we observe many skills to be common across benchmarks,resulting in the curation of hundreds of skill-slices (i.e. sets of instancestesting a common skill). Inspecting accuracy over these slices yields novelinsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,on average, Gemini 1.5 Pro is $18\%$ more accurate in "computing molar mass",but $19\%$ less accurate in "applying constitutional law", despite the overallaccuracies of the three models differing by a mere $0.4\%$. Furthermore, wedemonstrate the practical utility of our approach by showing that insightsderived from skill slice analysis can generalize to held-out instances: whenrouting each instance to the model strongest on the relevant skills, we see a$3\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices andframework open a new avenue in model evaluation, leveraging skill-specificanalyses to unlock a more granular and actionable understanding of modelcapabilities.</description><author>Mazda Moayeri, Vidhisha Balachandran, Varun Chandrasekaran, Safoora Yousefi, Thomas Fel, Soheil Feizi, Besmira Nushi, Neel Joshi, Vibhav Vineet</author><pubDate>Thu, 17 Oct 2024 17:51:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13826v1</guid></item><item><title>Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach</title><link>http://arxiv.org/abs/2407.16833v2</link><description>Retrieval Augmented Generation (RAG) has been a powerful tool for LargeLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,recent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities tounderstand long contexts directly. We conduct a comprehensive comparisonbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths ofboth. We benchmark RAG and LC across various public datasets using three latestLLMs. Results reveal that when resourced sufficiently, LC consistentlyoutperforms RAG in terms of average performance. However, RAG's significantlylower cost remains a distinct advantage. Based on this observation, we proposeSelf-Route, a simple yet effective method that routes queries to RAG or LCbased on model self-reflection. Self-Route significantly reduces thecomputation cost while maintaining a comparable performance to LC. Our findingsprovide a guideline for long-context applications of LLMs using RAG and LC.</description><author>Zhuowan Li, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky</author><pubDate>Thu, 17 Oct 2024 17:51:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16833v2</guid></item><item><title>AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents</title><link>http://arxiv.org/abs/2410.13825v1</link><description>Autonomy via agents using large language models (LLMs) for personalized,standardized tasks boosts human efficiency. Automating web tasks (like bookinghotels within a budget) is increasingly sought after. Fulfilling practicalneeds, the web agent also serves as an important proof-of-concept example forvarious agent grounding scenarios, with its success promising advancements inmany future applications. Prior research often handcrafts web agent strategies(e.g., prompting templates, multi-agent systems, search methods, etc.) and thecorresponding in-context examples, which may not generalize well across allreal-world scenarios. On the other hand, there has been limited study on themisalignment between a web agent's observation/action representation and thepre-training data of the LLM it's based on. This discrepancy is especiallynotable when LLMs are primarily trained for language completion rather thantasks involving embodied navigation actions and symbolic web elements. Ourstudy enhances an LLM-based web agent by simply refining its observation andaction space to better align with the LLM's capabilities. This approach enablesour base agent to significantly outperform previous methods on a wide varietyof web tasks. Specifically, on WebArena, a benchmark featuring general-purposeweb interaction tasks, our agent AgentOccam surpasses the previousstate-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolutepoints respectively, and boosts the success rate by 26.6 points (+161%) oversimilar plain web agents with its observation and action space alignment. Weachieve this without using in-context examples, new agent roles, onlinefeedback or search strategies. AgentOccam's simple design highlights LLMs'impressive zero-shot performance on web tasks, and underlines the critical roleof carefully tuning observation and action spaces for LLM-based agents.</description><author>Ke Yang, Yao Liu, Sapana Chaudhary, Rasool Fakoor, Pratik Chaudhari, George Karypis, Huzefa Rangwala</author><pubDate>Thu, 17 Oct 2024 17:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13825v1</guid></item><item><title>Harnessing Webpage UIs for Text-Rich Visual Understanding</title><link>http://arxiv.org/abs/2410.13824v1</link><description>Text-rich visual understanding-the ability to process environments wheredense textual content is integrated with visuals-is crucial for multimodallarge language models (MLLMs) to interact effectively with structuredenvironments. To enhance this capability, we propose synthesizing generalmultimodal instructions from webpage UIs using text-based large language models(LLMs). Despite lacking direct visual input, text-based LLMs are able toprocess structured text representations from webpage accessibility trees. Theseinstructions are then paired with UI screenshots to train multimodal models. Weintroduce MultiUI, a dataset containing 7.3 million samples from 1 millionwebsites, covering diverse multimodal tasks and UI layouts. Models trained onMultiUI not only excel in web UI tasks-achieving up to a 48\% improvement onVisualWebBench and a 19.1\% boost in action accuracy on a web agent datasetMind2Web-but also generalize surprisingly well to non-web UI tasks and even tonon-UI domains, such as document understanding, OCR, and chart interpretation.These results highlight the broad applicability of web UI data for advancingtext-rich visual understanding across various scenarios.</description><author>Junpeng Liu, Tianyue Ou, Yifan Song, Yuxiao Qu, Wai Lam, Chenyan Xiong, Wenhu Chen, Graham Neubig, Xiang Yue</author><pubDate>Thu, 17 Oct 2024 17:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13824v1</guid></item><item><title>Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning</title><link>http://arxiv.org/abs/2410.13823v1</link><description>Deep generative models have significantly advanced medical imaging analysisby enhancing dataset size and quality. Beyond mere data augmentation, ourresearch in this paper highlights an additional, significant capacity of deepgenerative models: their ability to reveal and demonstrate patterns in medicalimages. We employ a generative structure with hybrid conditions, combiningclinical data and segmentation masks to guide the image synthesis process.Furthermore, we innovatively transformed the tabular clinical data into textualdescriptions. This approach simplifies the handling of missing values and alsoenables us to leverage large pre-trained vision-language models thatinvestigate the relations between independent clinical entries and comprehendgeneral terms, such as gender and smoking status. Our approach differs from andpresents a more challenging task than traditional medical report-guidedsynthesis due to the less visual correlation of our clinical information withthe images. To overcome this, we introduce a text-visual embedding mechanismthat strengthens the conditions, ensuring the network effectively utilizes theprovided information. Our pipeline is generalizable to both GAN-based anddiffusion models. Experiments on chest CT, particularly focusing on the smokingstatus, demonstrated a consistent intensity shift in the lungs which is inagreement with clinical observations, indicating the effectiveness of ourmethod in capturing and visualizing the impact of specific attributes onmedical image patterns. Our methods offer a new avenue for the early detectionand precise visualization of complex clinical conditions with deep generativemodels. All codes are https://github.com/junzhin/DGM-VLC.</description><author>Xiaodan Xing, Junzhi Ning, Yang Nan, Guang Yang</author><pubDate>Thu, 17 Oct 2024 17:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13823v1</guid></item><item><title>Generalization-baed similarity</title><link>http://arxiv.org/abs/2302.10096v7</link><description>Detecting and exploiting similarities between seemingly distant objects iswithout doubt an important human ability. This paper develops \textit{from theground up} an abstract algebraic and qualitative notion of similarity based onthe observation that sets of generalizations encode important properties ofelements. We show that similarity defined in this way has appealingmathematical properties. As we construct our notion of similarity from firstprinciples using only elementary concepts of universal algebra, to convince thereader of its plausibility, we show that it can model fundamental relationsoccurring in mathematics and be naturally embedded into first-order logic viamodel-theoretic types.</description><author>Christian AntiÄ</author><pubDate>Thu, 17 Oct 2024 17:48:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10096v7</guid></item><item><title>Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks</title><link>http://arxiv.org/abs/2410.13822v1</link><description>The diagnosis of diabetic retinopathy, which relies on fundus images, faceschallenges in achieving transparency and interpretability when using a globalclassification approach. However, segmentation-based databases aresignificantly more expensive to acquire and combining them is oftenproblematic. This paper introduces a novel method, termed adversarial styleconversion, to address the lack of standardization in annotation styles acrossdiverse databases. By training a single architecture on combined databases, themodel spontaneously modifies its segmentation style depending on the input,demonstrating the ability to convert among different labeling styles. Theproposed methodology adds a linear probe to detect dataset origin based onencoder features and employs adversarial attacks to condition the model'ssegmentation style. Results indicate significant qualitative and quantitativethrough dataset combination, offering avenues for improved modelgeneralization, uncertainty estimation and continuous interpolation betweenannotation styles. Our approach enables training a segmentation model withdiverse databases while controlling and leveraging annotation styles forimproved retinopathy diagnosis.</description><author>ClÃ©ment Playout, Renaud Duval, Marie Carole Boucher, Farida Cheriet</author><pubDate>Thu, 17 Oct 2024 17:48:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13822v1</guid></item><item><title>Artificial Kuramoto Oscillatory Neurons</title><link>http://arxiv.org/abs/2410.13821v1</link><description>It has long been known in both neuroscience and AI that ``binding'' betweenneurons leads to a form of competitive learning where representations arecompressed in order to represent more abstract concepts in deeper layers of thenetwork. More recently, it was also hypothesized that dynamic (spatiotemporal)representations play an important role in both neuroscience and AI. Building onthese ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as adynamical alternative to threshold units, which can be combined with arbitraryconnectivity designs such as fully connected, convolutional, or attentivemechanisms. Our generalized Kuramoto updates bind neurons together throughtheir synchronization dynamics. We show that this idea provides performanceimprovements across a wide spectrum of tasks such as unsupervised objectdiscovery, adversarial robustness, calibrated uncertainty quantification, andreasoning. We believe that these empirical results show the importance ofrethinking our assumptions at the most basic neuronal level of neuralrepresentation, and in particular show the importance of dynamicalrepresentations.</description><author>Takeru Miyato, Sindy LÃ¶we, Andreas Geiger, Max Welling</author><pubDate>Thu, 17 Oct 2024 17:47:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13821v1</guid></item><item><title>Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation</title><link>http://arxiv.org/abs/2410.13817v1</link><description>Reinforcement learning (RL) often necessitates a meticulous Markov DecisionProcess (MDP) design tailored to each task. This work aims to address thischallenge by proposing a systematic approach to behavior synthesis and controlfor multi-contact loco-manipulation tasks, such as navigating spring-loadeddoors and manipulating heavy dishwashers. We define a task-independent MDP totrain RL policies using only a single demonstration per task generated from amodel-based trajectory optimizer. Our approach incorporates an adaptive phasedynamics formulation to robustly track the demonstrations while accommodatingdynamic uncertainties and external disturbances. We compare our method againstprior motion imitation RL works and show that the learned policies achievehigher success rates across all considered tasks. These policies learn recoverymaneuvers that are not present in the demonstration, such as re-graspingobjects during execution or dealing with slippages. Finally, we successfullytransfer the policies to a real robot, demonstrating the practical viability ofour approach.</description><author>Jean-Pierre Sleiman, Mayank Mittal, Marco Hutter</author><pubDate>Thu, 17 Oct 2024 17:46:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13817v1</guid></item><item><title>Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance</title><link>http://arxiv.org/abs/2410.13816v1</link><description>Large, general-purpose robotic policies trained on diverse demonstrationdatasets have been shown to be remarkably effective both for controlling avariety of robots in a range of different scenes, and for acquiring broadrepertoires of manipulation skills. However, the data that such policies aretrained on is generally of mixed quality -- not only are human-collecteddemonstrations unlikely to perform the task perfectly, but the larger thedataset is, the harder it is to curate only the highest quality examples. Italso remains unclear how optimal data from one embodiment is for training onanother embodiment. In this paper, we present a general and broadly applicableapproach that enhances the performance of such generalist robot policies atdeployment time by re-ranking their actions according to a value functionlearned via offline RL. This approach, which we call Value-Guided PolicySteering (V-GPS), is compatible with a wide range of different generalistpolicies, without needing to fine-tune or even access the weights of thepolicy. We show that the same value function can improve the performance offive different state-of-the-art policies with different architectures, eventhough they were trained on distinct datasets, attaining consistent performanceimprovement on multiple robotic platforms across a total of 12 tasks. Code andvideos can be found at: https://nakamotoo.github.io/V-GPS</description><author>Mitsuhiko Nakamoto, Oier Mees, Aviral Kumar, Sergey Levine</author><pubDate>Thu, 17 Oct 2024 17:46:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13816v1</guid></item><item><title>Many-Shot In-Context Learning</title><link>http://arxiv.org/abs/2404.11018v3</link><description>Large language models (LLMs) excel at few-shot in-context learning (ICL) --learning from a few examples provided in context at inference, without anyweight updates. Newly expanded context windows allow us to investigate ICL withhundreds or thousands of examples -- the many-shot regime. Going from few-shotto many-shot, we observe significant performance gains across a wide variety ofgenerative and discriminative tasks. While promising, many-shot ICL can bebottlenecked by the available amount of human-generated examples. To mitigatethis limitation, we explore two new settings: Reinforced and Unsupervised ICL.Reinforced ICL uses model-generated chain-of-thought rationales in place ofhuman examples. Unsupervised ICL removes rationales from the prompt altogether,and prompts the model only with domain-specific questions. We find that bothReinforced and Unsupervised ICL can be quite effective in the many-shot regime,particularly on complex reasoning tasks. Finally, we demonstrate that, unlikefew-shot learning, many-shot learning is effective at overriding pretrainingbiases, can learn high-dimensional functions with numerical inputs, andperforms comparably to fine-tuning. We also find that inference cost increaseslinearly in the many-shot regime, and frontier LLMs benefit from many-shot ICLto varying degrees. Our analysis also reveals the limitations of next-tokenprediction loss as an indicator of downstream ICL performance.</description><author>Rishabh Agarwal, Avi Singh, Lei M. Zhang, Bernd Bohnet, Luis Rosias, Stephanie Chan, Biao Zhang, Ankesh Anand, Zaheer Abbas, Azade Nova, John D. Co-Reyes, Eric Chu, Feryal Behbahani, Aleksandra Faust, Hugo Larochelle</author><pubDate>Thu, 17 Oct 2024 17:45:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11018v3</guid></item><item><title>Private Counterfactual Retrieval</title><link>http://arxiv.org/abs/2410.13812v1</link><description>Transparency and explainability are two extremely important aspects to beconsidered when employing black-box machine learning models in high-stakeapplications. Providing counterfactual explanations is one way of catering thisrequirement. However, this also poses a threat to the privacy of both theinstitution that is providing the explanation as well as the user who isrequesting it. In this work, we propose multiple schemes inspired by privateinformation retrieval (PIR) techniques which ensure the \emph{user's privacy}when retrieving counterfactual explanations. We present a scheme whichretrieves the \emph{exact} nearest neighbor counterfactual explanation from adatabase of accepted points while achieving perfect (information-theoretic)privacy for the user. While the scheme achieves perfect privacy for the user,some leakage on the database is inevitable which we quantify using a mutualinformation based metric. Furthermore, we propose strategies to reduce thisleakage to achieve an advanced degree of database privacy. We extend theseschemes to incorporate user's preference on transforming their attributes, sothat a more actionable explanation can be received. Since our schemes rely onfinite field arithmetic, we empirically validate our schemes on real datasetsto understand the trade-off between the accuracy and the finite field sizes.</description><author>Mohamed Nomeir, Pasan Dissanayake, Shreya Meel, Sanghamitra Dutta, Sennur Ulukus</author><pubDate>Thu, 17 Oct 2024 17:45:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13812v1</guid></item><item><title>De-mark: Watermark Removal in Large Language Models</title><link>http://arxiv.org/abs/2410.13808v1</link><description>Watermarking techniques offer a promising way to identify machine-generatedcontent via embedding covert information into the contents generated fromlanguage models (LMs). However, the robustness of the watermarking schemes hasnot been well explored. In this paper, we present De-mark, an advancedframework designed to remove n-gram-based watermarks effectively. Our methodutilizes a novel querying strategy, termed random selection probing, which aidsin assessing the strength of the watermark and identifying the red-green listwithin the n-gram watermark. Experiments on popular LMs, such as Llama3 andChatGPT, demonstrate the efficiency and effectiveness of De-mark in watermarkremoval and exploitation tasks.</description><author>Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang</author><pubDate>Thu, 17 Oct 2024 17:42:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13808v1</guid></item><item><title>ConsisSR: Delving Deep into Consistency in Diffusion-based Image Super-Resolution</title><link>http://arxiv.org/abs/2410.13807v1</link><description>Real-world image super-resolution (Real-ISR) aims at restoring high-quality(HQ) images from low-quality (LQ) inputs corrupted by unknown and complexdegradations. In particular, pretrained text-to-image (T2I) diffusion modelsprovide strong generative priors to reconstruct credible and intricate details.However, T2I generation focuses on semantic consistency while Real-ISRemphasizes pixel-level reconstruction, which hinders existing methods fromfully exploiting diffusion priors. To address this challenge, we introduceConsisSR to handle both semantic and pixel-level consistency. Specifically,compared to coarse-grained text prompts, we exploit the more powerful CLIPimage embedding and effectively leverage both modalities through our HybridPrompt Adapter (HPA) for semantic guidance. Secondly, we introduce Time-awareLatent Augmentation (TALA) to mitigate the inherent gap between T2I generationand Real-ISR consistency requirements. By randomly mixing LQ and HQ latentinputs, our model not only handle timestep-specific diffusion noise but alsorefine the accumulated latent representations. Last but not least, ourGAN-Embedding strategy employs the pretrained Real-ESRGAN model to refine thediffusion start point. This accelerates the inference process to 10 steps whilepreserving sampling quality, in a training-free manner.Our method demonstratesstate-of-the-art performance among both full-scale and accelerated models. Thecode will be made publicly available.</description><author>Junhao Gu, Peng-Tao Jiang, Hao Zhang, Mi Zhou, Jinwei Chen, Wenming Yang, Bo Li</author><pubDate>Thu, 17 Oct 2024 17:41:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13807v1</guid></item><item><title>A Watermark for Order-Agnostic Language Models</title><link>http://arxiv.org/abs/2410.13805v1</link><description>Statistical watermarking techniques are well-established for sequentiallydecoded language models (LMs). However, these techniques cannot be directlyapplied to order-agnostic LMs, as the tokens in order-agnostic LMs are notgenerated sequentially. In this work, we introduce Pattern-mark, apattern-based watermarking framework specifically designed for order-agnosticLMs. We develop a Markov-chain-based watermark generator that produceswatermark key sequences with high-frequency key patterns. Correspondingly, wepropose a statistical pattern-based detection algorithm that recovers the keysequence during detection and conducts statistical tests based on the count ofhigh-frequency patterns. Our extensive evaluations on order-agnostic LMs, suchas ProteinMPNN and CMLM, demonstrate Pattern-mark's enhanced detectionefficiency, generation quality, and robustness, positioning it as a superiorwatermarking technique for order-agnostic LMs.</description><author>Ruibo Chen, Yihan Wu, Yanshuo Chen, Chenxi Liu, Junfeng Guo, Heng Huang</author><pubDate>Thu, 17 Oct 2024 17:41:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13805v1</guid></item><item><title>BenTo: Benchmark Task Reduction with In-Context Transferability</title><link>http://arxiv.org/abs/2410.13804v1</link><description>Evaluating large language models (LLMs) is costly: it requires the generationand examination of LLM outputs on a large-scale benchmark of various tasks.This paper investigates how to efficiently reduce the tasks used to benchmarkLLMs without affecting the evaluation quality. Our study reveals that tasktransferability and relevance provide critical information to identify the mostrepresentative subset of tasks via optimizing a facility location function. Wepropose a practically efficient metric for estimating the transferabilitybetween two tasks via in-context learning (ICL). By analyzing the pairwisetransferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU orFLAN) to 5% while inducing only a &lt;4% difference to the evaluation on theoriginal benchmark. Compared to prior works, our method is training-free,gradient-free, and highly efficient requiring ICL only.</description><author>Hongyu Zhao, Ming Li, Lichao Sun, Tianyi Zhou</author><pubDate>Thu, 17 Oct 2024 17:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13804v1</guid></item><item><title>A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities</title><link>http://arxiv.org/abs/2410.13803v1</link><description>The ability to reason with and integrate different sensory inputs is thefoundation underpinning human intelligence and it is the reason for the growinginterest in modelling multi-modal information within Knowledge Graphs.Multi-Modal Knowledge Graphs extend traditional Knowledge Graphs by associatingan entity with its possible modal representations, including text, images,audio, and videos, all of which are used to convey the semantics of the entity.Despite the increasing attention that Multi-Modal Knowledge Graphs havereceived, there is a lack of consensus about the definitions and modelling ofmodalities, whose definition is often determined by application domains. Inthis paper, we propose a novel ontology design pattern that captures theseparation of concerns between an entity (and the information it conveys),whose semantics can have different manifestations across different media, andits realisation in terms of a physical information entity. By introducing thisabstract model, we aim to facilitate the harmonisation and integration ofdifferent existing multi-modal ontologies which is crucial for many intelligentapplications across different domains spanning from medicine to digitalhumanities.</description><author>Gianluca Apriceno, Valentina Tamma, Tania Bailoni, Jacopo de Berardinis, Mauro Dragoni</author><pubDate>Thu, 17 Oct 2024 17:41:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13803v1</guid></item><item><title>Data-Driven Estimation of Heterogeneous Treatment Effects</title><link>http://arxiv.org/abs/2301.06615v2</link><description>Estimating how a treatment affects different individuals, known asheterogeneous treatment effect estimation, is an important problem in empiricalsciences. In the last few years, there has been a considerable interest inadapting machine learning algorithms to the problem of estimating heterogeneouseffects from observational and experimental data. However, these algorithmsoften make strong assumptions about the observed features in the data andignore the structure of the underlying causal model, which can lead to biasedestimation. At the same time, the underlying causal mechanism is rarely knownin real-world datasets, making it hard to take it into consideration. In thiswork, we provide a survey of state-of-the-art data-driven methods forheterogeneous treatment effect estimation using machine learning, broadlycategorizing them as methods that focus on counterfactual prediction andmethods that directly estimate the causal effect. We also provide an overviewof a third category of methods which rely on structural causal models and learnthe model structure from data. Our empirical evaluation under variousunderlying structural model mechanisms shows the advantages and deficiencies ofexisting estimators and of the metrics for measuring their performance.</description><author>Christopher Tran, Keith Burghardt, Kristina Lerman, Elena Zheleva</author><pubDate>Thu, 17 Oct 2024 17:40:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06615v2</guid></item><item><title>Adversarial Testing as a Tool for Interpretability: Length-based Overfitting of Elementary Functions in Transformers</title><link>http://arxiv.org/abs/2410.13802v1</link><description>The Transformer model has a tendency to overfit various aspects of thetraining data, such as the overall sequence length. We study elementary stringedit functions using a defined set of error indicators to interpret thebehaviour of the sequence-to-sequence Transformer. We show that generalizationto shorter sequences is often possible, but confirm that longer sequences arehighly problematic, although partially correct answers are often obtained.Additionally, we find that other structural characteristics of the sequences,such as subsegment length, may be equally important. We hypothesize that themodels learn algorithmic aspects of the tasks simultaneously with structuralaspects but adhering to the structural aspects is unfortunately often preferredby Transformer when they come into conflict.</description><author>Patrik Zavoral, DuÅ¡an VariÅ¡, OndÅej Bojar</author><pubDate>Thu, 17 Oct 2024 17:39:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13802v1</guid></item><item><title>Machine-Learning Analysis of Radiative Decays to Dark Matter at the LHC</title><link>http://arxiv.org/abs/2410.13799v1</link><description>The search for weakly interacting matter particles (WIMPs) is one of the mainobjectives of the High Luminosity Large Hadron Collider (HL-LHC). In this workwe use Machine Learning (ML) techniques to explore WIMP radiative decays into aDark Matter (DM) candidate in a supersymmetric framework. The minimalsupersymmetric WIMP sector includes the lightest neutralino that can providethe observed DM relic density through its co-annihilation with the secondlightest neutralino and lightest chargino. Moreover, the direct DM detectioncross section rates fulfill current experimental bounds and provide discoverytargets for the same region of model parameters in which the radiative decay ofthe second lightest neutralino into a photon and the lightest neutralino isenhanced. This strongly motivates the search for radiatively decayingneutralinos which, however, suffers from strong backgrounds. We investigate theLHC reach in the search for these radiatively decaying particles by means ofcut-based and ML methods and estimate its discovery potential in thiswell-motivated, new physics scenario.</description><author>Ernesto Arganda, Marcela Carena, MartÃ­n de los Rios, Andres D. Perez, Duncan Rocha, Rosa M. SandÃ¡ Seoane, Carlos E. M. Wagner</author><pubDate>Thu, 17 Oct 2024 17:38:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13799v1</guid></item><item><title>Discrete distributions are learnable from metastable samples</title><link>http://arxiv.org/abs/2410.13800v1</link><description>Markov chain samplers designed to sample from multi-variable distributionsoften undesirably get stuck in specific regions of their state space. Thiscauses such samplers to approximately sample from a metastable distributionwhich is usually quite different from the desired, stationary distribution ofthe chain. We show that single-variable conditionals of metastabledistributions of reversible Markov chain samplers that satisfy a strongmetastability condition are on average very close to those of the truedistribution. This holds even when the metastable distribution is far away fromthe true model in terms of global metrics like Kullback-Leibler divergence ortotal variation distance. This property allows us to learn the true model usinga conditional likelihood based estimator, even when the samples come from ametastable distribution concentrated in a small region of the state space.Explicit examples of such metastable states can be constructed from regionsthat effectively bottleneck the probability flow and cause poor mixing of theMarkov chain. For specific cases of binary pairwise undirected graphicalmodels, we extend our results to further rigorously show that data coming frommetastable states can be used to learn the parameters of the energy functionand recover the structure of the model.</description><author>Abhijith Jayakumar, Andrey Y. Lokhov, Sidhant Misra, Marc Vuffray</author><pubDate>Thu, 17 Oct 2024 17:38:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13800v1</guid></item><item><title>Learning Graph Quantized Tokenizers for Transformers</title><link>http://arxiv.org/abs/2410.13798v1</link><description>Transformers serve as the backbone architectures of Foundational Models,where a domain-specific tokenizer helps them adapt to various domains. GraphTransformers (GTs) have recently emerged as a leading model in geometric deeplearning, outperforming Graph Neural Networks (GNNs) in various graph learningtasks. However, the development of tokenizers for graphs has lagged behindother modalities, with existing approaches relying on heuristics or GNNsco-trained with Transformers. To address this, we introduce GQT (\textbf{G}raph\textbf{Q}uantized \textbf{T}okenizer), which decouples tokenizer training fromTransformer training by leveraging multi-task graph self-supervised learning,yielding robust and generalizable graph tokens. Furthermore, the GQT utilizesResidual Vector Quantization (RVQ) to learn hierarchical discrete tokens,resulting in significantly reduced memory requirements and improvedgeneralization capabilities. By combining the GQT with token modulation, aTransformer encoder achieves state-of-the-art performance on 16 out of 18benchmarks, including large-scale homophilic and heterophilic datasets. Thecode is available at: https://github.com/limei0307/graph-tokenizer</description><author>Limei Wang, Kaveh Hassani, Si Zhang, Dongqi Fu, Baichuan Yuan, Weilin Cong, Zhigang Hua, Hao Wu, Ning Yao, Bo Long</author><pubDate>Thu, 17 Oct 2024 17:38:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13798v1</guid></item><item><title>Dynamic Topic Language Model on Heterogeneous Children's Mental Health Clinical Notes</title><link>http://arxiv.org/abs/2312.14180v2</link><description>Mental health diseases affect children's lives and well-beings which havereceived increased attention since the COVID-19 pandemic. Analyzing psychiatricclinical notes with topic models is critical to evaluating children's mentalstatus over time. However, few topic models are built for longitudinalsettings, and most existing approaches fail to capture temporal trajectoriesfor each document. To address these challenges, we develop a dynamic topicmodel with consistent topics and individualized temporal dependencies on theevolving document metadata. Our model preserves the semantic meaning ofdiscovered topics over time and incorporates heterogeneity among documents. Inparticular, when documents can be categorized, we propose a classifier-freeapproach to maximize topic heterogeneity across different document groups. Wealso present an efficient variational optimization procedure adapted for themultistage longitudinal setting. In this case study, we apply our method to thepsychiatric clinical notes from a large tertiary pediatric hospital in SouthernCalifornia and achieve a 38% increase in the overall coherence of extractedtopics. Our real data analysis reveals that children tend to express morenegative emotions during state shutdowns and more positive when schools reopen.Furthermore, it suggests that sexual and gender minority (SGM) children displaymore pronounced reactions to major COVID-19 events and a greater sensitivity tovaccine-related news than non-SGM children. This study examines children'smental health progression during the pandemic and offers clinicians valuableinsights to recognize disparities in children's mental health related to theirsexual and gender identities.</description><author>Hanwen Ye, Tatiana Moreno, Adrianne Alpern, Louis Ehwerhemuepha, Annie Qu</author><pubDate>Thu, 17 Oct 2024 17:38:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14180v2</guid></item><item><title>Arbitrarily-Conditioned Multi-Functional Diffusion for Multi-Physics Emulation</title><link>http://arxiv.org/abs/2410.13794v1</link><description>Modern physics simulation often involves multiple functions of interests, andtraditional numerical approaches are known to be complex and computationallycostly. While machine learning-based surrogate models can offer significantcost reductions, most focus on a single task, such as forward prediction, andtypically lack uncertainty quantification -- an essential component in manyapplications. To overcome these limitations, we propose Arbitrarily-ConditionedMulti-Functional Diffusion (ACMFD), a versatile probabilistic surrogate modelfor multi-physics emulation. ACMFD can perform a wide range of tasks within asingle framework, including forward prediction, various inverse problems, andsimulating data for entire systems or subsets of quantities conditioned onothers. Specifically, we extend the standard Denoising Diffusion ProbabilisticModel (DDPM) for multi-functional generation by modeling noise as Gaussianprocesses (GP). We then introduce an innovative denoising loss. The traininginvolves randomly sampling the conditioned part and fitting the correspondingpredicted noise to zero, enabling ACMFD to flexibly generate function valuesconditioned on any other functions or quantities. To enable efficient trainingand sampling, and to flexibly handle irregularly sampled data, we use GPs tointerpolate function samples onto a grid, inducing a Kronecker productstructure for efficient computation. We demonstrate the advantages of ACMFDacross several fundamental multi-physics systems.</description><author>Da Long, Zhitong Xu, Guang Yang, Akil Narayan, Shandian Zhe</author><pubDate>Thu, 17 Oct 2024 17:34:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13794v1</guid></item><item><title>Analyzing Deep Transformer Models for Time Series Forecasting via Manifold Learning</title><link>http://arxiv.org/abs/2410.13792v1</link><description>Transformer models have consistently achieved remarkable results in variousdomains such as natural language processing and computer vision. However,despite ongoing research efforts to better understand these models, the fieldstill lacks a comprehensive understanding. This is particularly true for deeptime series forecasting methods, where analysis and understanding work isrelatively limited. Time series data, unlike image and text information, can bemore challenging to interpret and analyze. To address this, we approach theproblem from a manifold learning perspective, assuming that the latentrepresentations of time series forecasting models lie next to a low-dimensionalmanifold. In our study, we focus on analyzing the geometric features of theselatent data manifolds, including intrinsic dimension and principal curvatures.Our findings reveal that deep transformer models exhibit similar geometricbehavior across layers, and these geometric features are correlated with modelperformance. Additionally, we observe that untrained models initially havedifferent structures, but they rapidly converge during training. By leveragingour geometric analysis and differentiable tools, we can potentially design newand improved deep forecasting neural networks. This approach complementsexisting analysis studies and contributes to a better understanding oftransformer models in the context of time series forecasting. Code is releasedat https://github.com/azencot-group/GATLM.</description><author>Ilya Kaufman, Omri Azencot</author><pubDate>Thu, 17 Oct 2024 17:32:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13792v1</guid></item><item><title>MotionBank: A Large-scale Video Motion Benchmark with Disentangled Rule-based Annotations</title><link>http://arxiv.org/abs/2410.13790v1</link><description>In this paper, we tackle the problem of how to build and benchmark a largemotion model (LMM). The ultimate goal of LMM is to serve as a foundation modelfor versatile motion-related tasks, e.g., human motion generation, withinterpretability and generalizability. Though advanced, recent LMM-relatedworks are still limited by small-scale motion data and costly textdescriptions. Besides, previous motion benchmarks primarily focus on pure bodymovements, neglecting the ubiquitous motions in context, i.e., humansinteracting with humans, objects, and scenes. To address these limitations, weconsolidate large-scale video action datasets as knowledge banks to buildMotionBank, which comprises 13 video action datasets, 1.24M motion sequences,and 132.9M frames of natural and diverse human motions. Different fromlaboratory-captured motions, in-the-wild human-centric videos contain abundantmotions in context. To facilitate better motion text alignment, we alsometiculously devise a motion caption generation algorithm to automaticallyproduce rule-based, unbiased, and disentangled text descriptions via thekinematic characteristics for each motion. Extensive experiments show that ourMotionBank is beneficial for general motion-related tasks of human motiongeneration, motion in-context generation, and motion understanding. Videomotions together with the rule-based text annotations could serve as anefficient alternative for larger LMMs. Our dataset, codes, and benchmark willbe publicly available at https://github.com/liangxuy/MotionBank.</description><author>Liang Xu, Shaoyang Hua, Zili Lin, Yifan Liu, Feipeng Ma, Yichao Yan, Xin Jin, Xiaokang Yang, Wenjun Zeng</author><pubDate>Thu, 17 Oct 2024 17:31:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13790v1</guid></item><item><title>The Impact of Visual Information in Chinese Characters: Evaluating Large Models' Ability to Recognize and Utilize Radicals</title><link>http://arxiv.org/abs/2410.09013v2</link><description>The glyphic writing system of Chinese incorporates information-rich visualfeatures in each character, such as radicals that provide hints about meaningor pronunciation. However, there has been no investigation into whethercontemporary Large Language Models (LLMs) and Vision-Language Models (VLMs) canharness these sub-character features in Chinese through prompting. In thisstudy, we establish a benchmark to evaluate LLMs' and VLMs' understanding ofvisual elements in Chinese characters, including radicals, compositionstructures, strokes, and stroke counts. Our results reveal that modelssurprisingly exhibit some, but still limited, knowledge of the visualinformation, regardless of whether images of characters are provided. To incitemodels' ability to use radicals, we further experiment with incorporatingradicals into the prompts for Chinese language processing (CLP) tasks. Weobserve consistent improvement in Part-Of-Speech tagging when providingadditional information about radicals, suggesting the potential to enhance CLPby integrating sub-character information.</description><author>Xiaofeng Wu, Karl Stratos, Wei Xu</author><pubDate>Thu, 17 Oct 2024 17:30:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09013v2</guid></item><item><title>Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions</title><link>http://arxiv.org/abs/2410.13788v1</link><description>Large language models (LLMs) must often respond to highly ambiguous userrequests. In such cases, the LLM's best response may be to ask a clarifyingquestion to elicit more information. We observe existing LLMs often respond bypresupposing a single interpretation of such ambiguous requests, frustratingusers who intended a different interpretation. We speculate this is caused bycurrent preference data labeling practice, where LLM responses are evaluatedonly on their prior contexts. To address this, we propose to assign preferencelabels by simulating their expected outcomes in the future turns. This allowsLLMs to learn to ask clarifying questions when it can generate responses thatare tailored to each user interpretation in future turns. In experiments onopen-domain QA, we compare systems that trained using our proposed preferencelabeling methods against standard methods, which assign preferences based ononly prior context. We evaluate systems based on their ability to askclarifying questions that can recover each user's interpretation and expectedanswer, and find that our training with our proposed method trains LLMs to askclarifying questions with a 5% improvement in F1 measured against the answerset from different interpretations of each query</description><author>Michael J. Q. Zhang, W. Bradley Knox, Eunsol Choi</author><pubDate>Thu, 17 Oct 2024 17:29:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13788v1</guid></item><item><title>Achieving Exponential Asymptotic Optimality in Average-Reward Restless Bandits without Global Attractor Assumption</title><link>http://arxiv.org/abs/2405.17882v2</link><description>We consider the infinite-horizon average-reward restless bandit problem. Wepropose a novel \emph{two-set policy} that maintains two dynamic subsets ofarms: one subset of arms has a nearly optimal state distribution and takesactions according to an Optimal Local Control routine; the other subset of armsis driven towards the optimal state distribution and gradually merged into thefirst subset. We show that our two-set policy is asymptotically optimal with an$O(\exp(-C N))$ optimality gap for an $N$-armed problem, under the mildassumptions of aperiodic-unichain, non-degeneracy, and local stability. Ourpolicy is the first to achieve \emph{exponential asymptotic optimality} underthe above set of easy-to-verify assumptions, whereas prior work either requiresa strong \emph{global attractor} assumption or only achieves an $O(1/\sqrt{N})$optimality gap. We further discuss obstacles in weakening the assumptions bydemonstrating examples where exponential asymptotic optimality is notachievable when any of the three assumptions is violated. Notably, we prove alower bound for a large class of locally unstable restless bandits, showingthat local stability is particularly fundamental for exponential asymptoticoptimality. Finally, we use simulations to demonstrate that the two-set policyoutperforms previous policies on certain RB problems and performs competitivelyoverall.</description><author>Yige Hong, Qiaomin Xie, Yudong Chen, Weina Wang</author><pubDate>Thu, 17 Oct 2024 17:28:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17882v2</guid></item><item><title>Looking Inward: Language Models Can Learn About Themselves by Introspection</title><link>http://arxiv.org/abs/2410.13787v1</link><description>Humans acquire knowledge by observing the external world, but also byintrospection. Introspection gives a person privileged access to their currentstate of mind (e.g., thoughts and feelings) that is not accessible to externalobservers. Can LLMs introspect? We define introspection as acquiring knowledgethat is not contained in or derived from training data but instead originatesfrom internal states. Such a capability could enhance model interpretability.Instead of painstakingly analyzing a model's internal workings, we could simplyask the model about its beliefs, world models, and goals. More speculatively,an introspective model might self-report on whether it possesses certaininternal states such as subjective feelings or desires and this could inform usabout the moral status of these states. Such self-reports would not be entirelydictated by the model's training data. We study introspection by finetuning LLMs to predict properties of their ownbehavior in hypothetical scenarios. For example, "Given the input P, would youroutput favor the short- or long-term option?" If a model M1 can introspect, itshould outperform a different model M2 in predicting M1's behavior even if M2is trained on M1's ground-truth behavior. The idea is that M1 has privilegedaccess to its own behavioral tendencies, and this enables it to predict itselfbetter than M2 (even if M2 is generally stronger). In experiments with GPT-4, GPT-4o, and Llama-3 models (each finetuned topredict itself), we find that the model M1 outperforms M2 in predicting itself,providing evidence for introspection. Notably, M1 continues to predict itsbehavior accurately even after we intentionally modify its ground-truthbehavior. However, while we successfully elicit introspection on simple tasks,we are unsuccessful on more complex tasks or those requiringout-of-distribution generalization.</description><author>Felix J Binder, James Chua, Tomek Korbak, Henry Sleight, John Hughes, Robert Long, Ethan Perez, Miles Turpin, Owain Evans</author><pubDate>Thu, 17 Oct 2024 17:24:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13787v1</guid></item><item><title>Emphasizing Semantic Consistency of Salient Posture for Speech-Driven Gesture Generation</title><link>http://arxiv.org/abs/2410.13786v1</link><description>Speech-driven gesture generation aims at synthesizing a gesture sequencesynchronized with the input speech signal. Previous methods leverage neuralnetworks to directly map a compact audio representation to the gesturesequence, ignoring the semantic association of different modalities and failingto deal with salient gestures. In this paper, we propose a novel speech-drivengesture generation method by emphasizing the semantic consistency of salientposture. Specifically, we first learn a joint manifold space for the individualrepresentation of audio and body pose to exploit the inherent semanticassociation between two modalities, and propose to enforce semantic consistencyvia a consistency loss. Furthermore, we emphasize the semantic consistency ofsalient postures by introducing a weakly-supervised detector to identifysalient postures, and reweighting the consistency loss to focus more onlearning the correspondence between salient postures and the high-levelsemantics of speech content. In addition, we propose to extract audio featuresdedicated to facial expression and body gesture separately, and design separatebranches for face and body gesture synthesis. Extensive experimental resultsdemonstrate the superiority of our method over the state-of-the-art approaches.</description><author>Fengqi Liu, Hexiang Wang, Jingyu Gong, Ran Yi, Qianyu Zhou, Xuequan Lu, Jiangbo Lu, Lizhuang Ma</author><pubDate>Thu, 17 Oct 2024 17:22:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13786v1</guid></item><item><title>PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment</title><link>http://arxiv.org/abs/2410.13785v1</link><description>Alignment of large language models (LLMs) involves training models onpreference-contrastive output pairs to adjust their responses according tohuman preferences. To obtain such contrastive pairs, traditional methods likeRLHF and RLAIF rely on limited contrasting patterns, such as varying modelvariants or decoding temperatures. This singularity leads to two issues: (1)alignment is not comprehensive; and thereby (2) models are susceptible tojailbreaking attacks. To address these issues, we investigate how to constructmore comprehensive and diversified contrasting patterns to enhance preferencedata (RQ1) and verify the impact of the diversification of contrasting patternson model alignment (RQ2). For RQ1, we propose PopAlign, a framework thatintegrates diversified contrasting patterns across the prompt, model, andpipeline levels, introducing six contrasting strategies that do not requireadditional feedback labeling procedures. Regarding RQ2, we conduct thoroughexperiments demonstrating that PopAlign significantly outperforms existingmethods, leading to more comprehensive alignment.</description><author>Zekun Moore Wang, Shawn Wang, Kang Zhu, Jiaheng Liu, Ke Xu, Jie Fu, Wangchunshu Zhou, Wenhao Huang</author><pubDate>Thu, 17 Oct 2024 17:22:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13785v1</guid></item><item><title>Quantity vs. Quality of Monolingual Source Data in Automatic Text Translation: Can It Be Too Little If It Is Too Good?</title><link>http://arxiv.org/abs/2410.13783v1</link><description>Monolingual data, being readily available in large quantities, has been usedto upscale the scarcely available parallel data to train better models forautomatic translation. Self-learning, where a model is made to learn from itsoutput, is one approach to exploit such data. However, it has been shown thattoo much of this data can be detrimental to the performance of the model if theavailable parallel data is comparatively extremely low. In this study, weinvestigate whether the monolingual data can also be too little and if thisreduction, based on quality, has any effect on the performance of thetranslation model. Experiments have shown that on English-German low-resourceNMT, it is often better to select only the most useful additional data, basedon quality or closeness to the domain of the test data, than utilizing all ofthe available data.</description><author>Idris Abdulmumin, Bashir Shehu Galadanci, Garba Aliyu, Shamsuddeen Hassan Muhammad</author><pubDate>Thu, 17 Oct 2024 17:20:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13783v1</guid></item><item><title>DPLM-2: A Multimodal Diffusion Protein Language Model</title><link>http://arxiv.org/abs/2410.13782v1</link><description>Proteins are essential macromolecules defined by their amino acid sequences,which determine their three-dimensional structures and, consequently, theirfunctions in all living organisms. Therefore, generative protein modelingnecessitates a multimodal approach to simultaneously model, understand, andgenerate both sequences and structures. However, existing methods typically useseparate models for each modality, limiting their ability to capture theintricate relationships between sequence and structure. This results insuboptimal performance in tasks that requires joint understanding andgeneration of both modalities. In this paper, we introduce DPLM-2, a multimodalprotein foundation model that extends discrete diffusion protein language model(DPLM) to accommodate both sequences and structures. To enable structurallearning with the language model, 3D coordinates are converted to discretetokens using a lookup-free quantization-based tokenizer. By training on bothexperimental and high-quality synthetic structures, DPLM-2 learns the jointdistribution of sequence and structure, as well as their marginals andconditionals. We also implement an efficient warm-up strategy to exploit theconnection between large-scale evolutionary data and structural inductivebiases from pre-trained sequence-based protein language models. Empiricalevaluation shows that DPLM-2 can simultaneously generate highly compatibleamino acid sequences and their corresponding 3D structures eliminating the needfor a two-stage generation approach. Moreover, DPLM-2 demonstrates competitiveperformance in various conditional generation tasks, including folding, inversefolding, and scaffolding with multimodal motif inputs, as well as providingstructure-aware representations for predictive tasks.</description><author>Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, Quanquan Gu</author><pubDate>Thu, 17 Oct 2024 17:20:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13782v1</guid></item><item><title>Optimal Quantization for Matrix Multiplication</title><link>http://arxiv.org/abs/2410.13780v1</link><description>Recent work in machine learning community proposed multiple methods forperforming lossy compression (quantization) of large matrices. Thisquantization is important for accelerating matrix multiplication (maincomponent of large language models), which is often bottlenecked by the speedof loading these matrices from memory. Unlike classical vector quantization andrate-distortion theory, the goal of these new compression algorithms is to beable to approximate not the matrices themselves, but their matrix product.Specifically, given a pair of real matrices $A,B$ an encoder (compressor) isapplied to each of them independently producing descriptions with $R$ bits perentry. These representations subsequently are used by the decoder to estimatematrix product $A^\top B$. In this work, we provide a non-asymptotic lowerbound on the mean squared error of this approximation (as a function of rate$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,we construct a universal quantizer based on nested lattices with an explicitguarantee of approximation error for any (non-random) pair of matrices $A$, $B$in terms of only Frobenius norms $\|A\|_F, \|B\|_F$ and $\|A^\top B\|_F$. Foriid Gaussian matrices our quantizer achieves the lower bound and is, thus,asymptotically optimal. A practical low-complexity version of our quantizerachieves performance quite close to optimal. In information-theoretic terms wederive rate-distortion function for matrix multiplication of iid Gaussianmatrices.</description><author>Or Ordentlich, Yury Polyanskiy</author><pubDate>Thu, 17 Oct 2024 17:19:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13780v1</guid></item><item><title>Superlatives in Context: Modeling the Implicit Semantics of Superlatives</title><link>http://arxiv.org/abs/2405.20967v2</link><description>Superlatives are used to single out elements with a maximal/minimal property.Semantically, superlatives perform a set comparison: something (or some things)has the min/max property out of a set. As such, superlatives provide an idealphenomenon for studying implicit phenomena and discourse restrictions. Whilethis comparison set is often not explicitly defined, its (implicit)restrictions can be inferred from the discourse context the expression appearsin. In this work we provide an extensive computational study on the semanticsof superlatives. We propose a unified account of superlative semantics whichallows us to derive a broad-coverage annotation schema. Using this unifiedschema we annotated a multi-domain dataset of superlatives and their semanticinterpretations. We specifically focus on interpreting implicit or ambiguoussuperlative expressions, by analyzing how the discourse context restricts theset of interpretations. In a set of experiments we then analyze how well modelsperform at variations of predicting superlative semantics, with and withoutcontext. We show that the fine-grained semantics of superlatives in context canbe challenging for contemporary models, including GPT-4.</description><author>Valentina Pyatkin, Bonnie Webber, Ido Dagan, Reut Tsarfaty</author><pubDate>Thu, 17 Oct 2024 17:19:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20967v2</guid></item><item><title>The Mystery of the Pathological Path-star Task for Language Models</title><link>http://arxiv.org/abs/2410.13779v1</link><description>The recently introduced path-star task is a minimal task designed toexemplify limitations to the abilities of language models (Bachmann andNagarajan, 2024). It involves a path-star graph where multiple arms radiatefrom a single starting node and each node is unique. Given the start node and aspecified target node that ends an arm, the task is to generate the armcontaining that target node. This is straightforward for a human butsurprisingly difficult for language models, which did not outperform the randombaseline. The authors hypothesized this is due to a deficiency inteacher-forcing and the next-token prediction paradigm. We demonstrate the task is learnable using teacher-forcing in alternativesettings and that the issue is partially due to representation. We introduce aregularization method using structured samples of the same graph but withdiffering target nodes, improving results across a variety of model types. Weprovide RASP proofs showing the task is theoretically solvable. Finally, wefind settings where an encoder-only model can consistently solve the task.</description><author>Arvid Frydenlund</author><pubDate>Thu, 17 Oct 2024 17:18:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13779v1</guid></item><item><title>Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree</title><link>http://arxiv.org/abs/2410.13778v1</link><description>We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),a non-parametric change-detection algorithm that combines the Kernel-QuantTree(KQT) histogram and the EWMA statistic to monitor multivariate data streamsonline. The resulting monitoring scheme is very flexible, since histograms canbe used to model any stationary distribution, and practical, since thedistribution of test statistics does not depend on the distribution ofdatastream in stationary conditions (non-parametric monitoring). KQT-EWMAenables controlling false alarms by operating at a pre-determined Average RunLength ($ARL_0$), which measures the expected number of stationary samples tobe monitored before triggering a false alarm. The latter peculiarity is incontrast with most non-parametric change-detection tests, which rarely cancontrol the $ARL_0$ a priori. Our experiments on synthetic and real-worlddatasets demonstrate that KQT-EWMA can control $ARL_0$ while achievingdetection delays comparable to or lower than state-of-the-art methods designedto work in the same conditions.</description><author>Michelangelo Olmo Nogara Notarianni, Filippo Leveni, Diego Stucchi, Luca Frittoli, Giacomo Boracchi</author><pubDate>Thu, 17 Oct 2024 17:17:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13778v1</guid></item><item><title>Representing Model Weights with Language using Tree Experts</title><link>http://arxiv.org/abs/2410.13569v1</link><description>The increasing availability of public models begs the question: can we trainneural networks that use other networks as input? This paper learns torepresent models within a joint space that embeds both model weights andlanguage. However, machine learning on model weights is challenging as modelweights often exhibit significant variation unrelated to the models' semanticproperties (nuisance variation). We identify a key property of real-worldmodels: most public models belong to a small set of Model Trees, where allmodels within a tree are fine-tuned from a common ancestor (e.g., a foundationmodel). Importantly, we find that within each tree there is less nuisancevariation between models. For example, while classifying models according totheir training dataset generally requires complex architectures, in our case,even a linear classifier trained on a single layer is often effective. Whileeffective, linear layers are computationally expensive as model weights arevery high dimensional. To address this, we introduce Probing Experts (ProbeX),a theoretically motivated, lightweight probing method. Notably, ProbeX is thefirst probing method designed to learn from the weights of just a single modellayer. We also construct and release a dataset that simulates the structure ofpublic model repositories. Our results show that ProbeX can effectively map theweights of large models into a shared weight-language embedding space.Furthermore, we demonstrate the impressive generalization of our method,achieving zero-shot model classification and retrieval.</description><author>Eliahu Horwitz, Bar Cavia, Jonathan Kahana, Yedid Hoshen</author><pubDate>Thu, 17 Oct 2024 17:17:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13569v1</guid></item><item><title>Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors</title><link>http://arxiv.org/abs/2410.13776v1</link><description>In-context Learning (ICL) has become the primary method for performingnatural language tasks with Large Language Models (LLMs). The knowledgeacquired during pre-training is crucial for this few-shot capability, providingthe model with task priors. However, recent studies have shown that ICLpredominantly relies on retrieving task priors rather than "learning" toperform tasks. This limitation is particularly evident in complex subjectivedomains such as emotion and morality, where priors significantly influenceposterior predictions. In this work, we examine whether this is the result ofthe aggregation used in corresponding datasets, where trying to combinelow-agreement, disparate annotations might lead to annotation artifacts thatcreate detrimental noise in the prompt. Moreover, we evaluate the posteriorbias towards certain annotators by grounding our study in appropriate,quantitative measures of LLM priors. Our results indicate that aggregation is aconfounding factor in the modeling of subjective tasks, and advocate focusingon modeling individuals instead. However, aggregation does not explain theentire gap between ICL and the state of the art, meaning other factors in suchtasks also account for the observed phenomena. Finally, by rigorously studyingannotator-level labels, we find that it is possible for minority annotators toboth better align with LLMs and have their perspectives further amplified.</description><author>Georgios Chochlakis, Alexandros Potamianos, Kristina Lerman, Shrikanth Narayanan</author><pubDate>Thu, 17 Oct 2024 17:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13776v1</guid></item><item><title>Enhancing Retail Sales Forecasting with Optimized Machine Learning Models</title><link>http://arxiv.org/abs/2410.13773v1</link><description>In retail sales forecasting, accurately predicting future sales is crucialfor inventory management and strategic planning. Traditional methods like LRoften fall short due to the complexity of sales data, which includesseasonality and numerous product families. Recent advancements in machinelearning (ML) provide more robust alternatives. This research benefits from thepower of ML, particularly Random Forest (RF), Gradient Boosting (GB), SupportVector Regression (SVR), and XGBoost, to improve prediction accuracy. Despiteadvancements, a significant gap exists in handling complex datasets with highseasonality and multiple product families. The proposed solution involvesimplementing and optimizing a RF model, leveraging hyperparameter tuningthrough randomized search cross-validation. This approach addresses thecomplexities of the dataset, capturing intricate patterns that traditionalmethods miss. The optimized RF model achieved an R-squared value of 0.945,substantially higher than the initial RF model and traditional LR, which had anR-squared of 0.531. The model reduced the root mean squared logarithmic error(RMSLE) to 1.172, demonstrating its superior predictive capability. Theoptimized RF model did better than cutting-edge models like Gradient Boosting(R-squared: 0.942), SVR (R-squared: 0.940), and XGBoost (R-squared: 0.939),with more minor mean squared error (MSE) and mean absolute error (MAE) numbers.The results demonstrate that the optimized RF model excels in forecastingretail sales, handling the datasets complexity with higher accuracy andreliability. This research highlights the importance of advanced ML techniquesin predictive analytics, offering a significant improvement over traditionalmethods and other contemporary models.</description><author>Priyam Ganguly, Isha Mukherjee</author><pubDate>Thu, 17 Oct 2024 17:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13773v1</guid></item><item><title>Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?</title><link>http://arxiv.org/abs/2410.13772v1</link><description>We study the problem of Non-Stationary Reinforcement Learning (NS-RL) withoutprior knowledge about the system's non-stationarity. A state-of-the-art,black-box algorithm, known as MASTER, is considered, with a focus onidentifying the conditions under which it can achieve its stated goals.Specifically, we prove that MASTER's non-stationarity detection mechanism isnot triggered for practical choices of horizon, leading to performance akin toa random restarting algorithm. Moreover, we show that the regret bound forMASTER, while being order optimal, stays above the worst-case linear regretuntil unreasonably large values of the horizon. To validate these observations,MASTER is tested for the special case of piecewise stationary multi-armedbandits, along with methods that employ random restarting, and others that usequickest change detection to restart. A simple, order optimal random restartingalgorithm, that has prior knowledge of the non-stationarity is proposed as abaseline. The behavior of the MASTER algorithm is validated in simulations, andit is shown that methods employing quickest change detection are more robustand consistently outperform MASTER and other random restarting approaches.</description><author>Argyrios Gerogiannis, Yu-Han Huang, Venugopal V. Veeravalli</author><pubDate>Thu, 17 Oct 2024 17:09:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13772v1</guid></item><item><title>Probing the Latent Hierarchical Structure of Data via Diffusion Models</title><link>http://arxiv.org/abs/2410.13770v1</link><description>High-dimensional data must be highly structured to be learnable. Although thecompositional and hierarchical nature of data is often put forward to explainlearnability, quantitative measurements establishing these properties arescarce. Likewise, accessing the latent variables underlying such a datastructure remains a challenge. In this work, we show that forward-backwardexperiments in diffusion-based models, where data is noised and then denoisedto generate new samples, are a promising tool to probe the latent structure ofdata. We predict in simple hierarchical models that, in this process, changesin data occur by correlated chunks, with a length scale that diverges at anoise level where a phase transition is known to take place. Remarkably, weconfirm this prediction in both text and image datasets using state-of-the-artdiffusion models. Our results show how latent variable changes manifest in thedata and establish how to measure these effects in real data using diffusionmodels.</description><author>Antonio Sclocchi, Alessandro Favero, Noam Itzhak Levi, Matthieu Wyart</author><pubDate>Thu, 17 Oct 2024 17:08:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13770v1</guid></item><item><title>Transformer Guided Coevolution: Improved Team Formation in Multiagent Adversarial Games</title><link>http://arxiv.org/abs/2410.13769v1</link><description>We consider the problem of team formation within multiagent adversarialgames. We propose BERTeam, a novel algorithm that uses a transformer-based deepneural network with Masked Language Model training to select the best team ofplayers from a trained population. We integrate this with coevolutionary deepreinforcement learning, which trains a diverse set of individual players tochoose teams from. We test our algorithm in the multiagent adversarial gameMarine Capture-The-Flag, and we find that BERTeam learns non-trivial teamcompositions that perform well against unseen opponents. For this game, we findthat BERTeam outperforms MCAA, an algorithm that similarly optimizes teamformation.</description><author>Pranav Rajbhandari, Prithviraj Dasgupta, Donald Sofge</author><pubDate>Thu, 17 Oct 2024 17:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13769v1</guid></item><item><title>Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems</title><link>http://arxiv.org/abs/2410.13768v1</link><description>A multi-agent AI model is used to automate the discovery of new metallicalloys, integrating multimodal data and external knowledge including insightsfrom physics via atomistic simulations. Our multi-agent system features threekey components: (a) a suite of LLMs responsible for tasks such as reasoning andplanning, (b) a group of AI agents with distinct roles and expertise thatdynamically collaborate, and (c) a newly developed graph neural network (GNN)model for rapid retrieval of key physical properties. A set of LLM-driven AIagents collaborate to automate the exploration of the vast design space ofMPEAs, guided by predictions from the GNN. We focus on the NbMoTa family ofbody-centered cubic (bcc) alloys, modeled using an ML-based interatomicpotential, and target two key properties: the Peierls barrier and solute/screwdislocation interaction energy. Our GNN model accurately predicts theseatomic-scale properties, providing a faster alternative to costly brute-forcecalculations and reducing the computational burden on multi-agent systems forphysics retrieval. This AI system revolutionizes materials discovery byreducing reliance on human expertise and overcoming the limitations of directall-atom simulations. By synergizing the predictive power of GNNs with thedynamic collaboration of LLM-based agents, the system autonomously navigatesvast alloy design spaces, identifying trends in atomic-scale materialproperties and predicting macro-scale mechanical strength, as demonstrated byseveral computational experiments. This approach accelerates the discovery ofadvanced alloys and holds promise for broader applications in other complexsystems, marking a significant step forward in automated materials design.</description><author>Alireza Ghafarollahi, Markus J. Buehler</author><pubDate>Thu, 17 Oct 2024 17:06:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13768v1</guid></item><item><title>Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval</title><link>http://arxiv.org/abs/2410.13765v1</link><description>Large language models (LLMs) have been used to generate query expansionsaugmenting original queries for improving information search. Recent studiesalso explore providing LLMs with initial retrieval results to generate queryexpansions more grounded to document corpus. However, these methods mostlyfocus on enhancing textual similarities between search queries and targetdocuments, overlooking document relations. For queries like "Find me a highlyrated camera for wildlife photography compatible with my Nikon F-Mount lenses",existing methods may generate expansions that are semantically similar butstructurally unrelated to user intents. To handle such semi-structured querieswith both textual and relational requirements, in this paper we propose aknowledge-aware query expansion framework, augmenting LLMs with structureddocument relations from knowledge graph (KG). To further address the limitationof entity-based scoring in existing KG-based methods, we leverage documenttexts as rich KG node representations and use document-based relation filteringfor our Knowledge-Aware Retrieval (KAR). Extensive experiments on threedatasets of diverse domains show the advantages of our method compared againststate-of-the-art baselines on textual and relational semi-structured retrieval.</description><author>Yu Xia, Junda Wu, Sungchul Kim, Tong Yu, Ryan A. Rossi, Haoliang Wang, Julian McAuley</author><pubDate>Thu, 17 Oct 2024 17:03:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13765v1</guid></item><item><title>Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks</title><link>http://arxiv.org/abs/2409.06173v3</link><description>In-Context Learning (ICL) in Large Language Models (LLM) has emerged as thedominant technique for performing natural language tasks, as it does notrequire updating the model parameters with gradient-based methods. ICL promisesto "adapt" the LLM to perform the present task at a competitive orstate-of-the-art level at a fraction of the computational cost. ICL can beaugmented by incorporating the reasoning process to arrive at the final labelexplicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.However, recent work has found that ICL relies mostly on the retrieval of taskpriors and less so on "learning" to perform tasks, especially for complexsubjective domains like emotion and morality, where priors ossify posteriorpredictions. In this work, we examine whether "enabling" reasoning also createsthe same behavior in LLMs, wherein the format of CoT retrieves reasoning priorsthat remain relatively unchanged despite the evidence in the prompt. We findthat, surprisingly, CoT indeed suffers from the same posterior collapse as ICLfor larger language models. Code is avalaible athttps://github.com/gchochla/cot-priors.</description><author>Georgios Chochlakis, Niyantha Maruthu Pandiyan, Kristina Lerman, Shrikanth Narayanan</author><pubDate>Thu, 17 Oct 2024 17:02:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06173v3</guid></item><item><title>Guided Multi-objective Generative AI to Enhance Structure-based Drug Design</title><link>http://arxiv.org/abs/2405.11785v2</link><description>Generative AI has the potential to revolutionize drug discovery. Yet, despiterecent advances in deep learning, existing models cannot generate moleculesthat satisfy all desired physicochemical properties. Herein, we describeIDOLpro, a generative chemistry AI combining diffusion with multi-objectiveoptimization for structure-based drug design. Differentiable scoring functionsguide the latent variables of the diffusion model to explore uncharted chemicalspace and generate novel ligands in silico, optimizing a plurality of targetphysicochemical properties. We demonstrate our platform's effectiveness bygenerating ligands with optimized binding affinity and synthetic accessibilityon two benchmark sets. IDOLpro produces ligands with binding affinities over10%-20% better than the next best state-of-the-art method on each test set,producing more drug-like molecules with generally better syntheticaccessibility scores than other methods. We do a head-to-head comparison ofIDOLpro against a classic virtual screen of a large database of drug-likemolecules. We show that IDOLpro can generate molecules for a range of importantdisease-related targets with better binding affinity and syntheticaccessibility than any molecule found in the virtual screen while being over100x faster and less expensive to run. On a test set of experimental complexes,IDOLpro is the first to produce molecules with better binding affinities thanexperimentally observed ligands. IDOLpro can accommodate other scoringfunctions (e.g. ADME-Tox) to accelerate hit-finding, hit-to-lead, and leadoptimization for drug discovery.</description><author>Amit Kadan, Kevin Ryczko, Erika Lloyd, Adrian Roitberg, Takeshi Yamazaki</author><pubDate>Thu, 17 Oct 2024 17:00:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11785v2</guid></item><item><title>Stage-Aware Learning for Dynamic Treatments</title><link>http://arxiv.org/abs/2310.19300v2</link><description>Recent advances in dynamic treatment regimes (DTRs) facilitate the search foroptimal treatments, which are tailored to individuals' specific needs and ableto maximize their expected clinical benefits. However, existing algorithmsrelying on consistent trajectories, such as inverse probability weightingestimators (IPWEs), could suffer from insufficient sample size under optimaltreatments and a growing number of decision-making stages, particularly in thecontext of chronic diseases. To address these challenges, we propose a novelindividualized learning method which estimates the DTR with a focus onprioritizing alignment between the observed treatment trajectory and the oneobtained by the optimal regime across decision stages. By relaxing therestriction that the observed trajectory must be fully aligned with the optimaltreatments, our approach substantially improves the sample efficiency andstability of IPWE-based methods. In particular, the proposed learning schemebuilds a more general framework which includes the popular outcome weightedlearning framework as a special case of ours. Moreover, we introduce the notionof stage importance scores along with an attention mechanism to explicitlyaccount for heterogeneity among decision stages. We establish the theoreticalproperties of the proposed approach, including the Fisher consistency andfinite-sample performance bound. Empirically, we evaluate the proposed methodin extensive simulated environments and a real case study for the COVID-19pandemic.</description><author>Hanwen Ye, Wenzhuo Zhou, Ruoqing Zhu, Annie Qu</author><pubDate>Thu, 17 Oct 2024 16:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19300v2</guid></item><item><title>Natural Language Processing Methods for the Study of Protein-Ligand Interactions</title><link>http://arxiv.org/abs/2409.13057v2</link><description>Recent advances in Natural Language Processing (NLP) have ignited interest indeveloping effective methods for predicting protein-ligand interactions (PLIs)given their relevance to drug discovery and protein engineering efforts and theever-growing volume of biochemical sequence and structural data available. Theparallels between human languages and the "languages" used to representproteins and ligands have enabled the use of NLP machine learning approaches toadvance PLI studies. In this review, we explain where and how such approacheshave been applied in the recent literature and discuss useful mechanisms suchas long short-term memory, transformers, and attention. We conclude with adiscussion of the current limitations of NLP methods for the study of PLIs aswell as key challenges that need to be addressed in future work.</description><author>James Michels, Ramya Bandarupalli, Amin Ahangar Akbari, Thai Le, Hong Xiao, Jing Li, Erik F. Y. Hom</author><pubDate>Thu, 17 Oct 2024 16:56:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.13057v2</guid></item><item><title>Virtual Sensing for Real-Time Degradation Monitoring of Nuclear Systems: Leveraging DeepONet for Enhanced Sensing Coverage for Digital Twin-Enabling Technology</title><link>http://arxiv.org/abs/2410.13762v1</link><description>Effective real-time monitoring technique is crucial for detecting materialdegradation and maintaining the structural integrity of nuclear systems toensure both safety and operational efficiency. Traditional physical sensorsystems face limitations such as installation challenges, high costs, anddifficulties in measuring critical parameters in hard-to-reach or harshenvironments, often resulting in incomplete data coverage. Machinelearning-driven virtual sensors offer a promising solution by enhancingphysical sensor capabilities to monitor critical degradation indicators likepressure, velocity, and turbulence. However, conventional machine learningmodels struggle with real-time monitoring due to the high-dimensional nature ofreactor data and the need for frequent retraining. This paper explores the useof Deep Operator Networks (DeepONet) within a digital twin (DT) framework topredict key thermal-hydraulic parameters in the hot leg of an AP-1000Pressurized Water Reactor (PWR). In this study, DeepONet is trained withdifferent operational conditions, which relaxes the requirement of continuousretraining, making it suitable for online and real-time prediction componentsfor DT. Our results show that DeepONet achieves accurate predictions with lowmean squared error and relative L2 error and can make predictions on unknowndata 160,000 times faster than traditional finite element (FE) simulations.This speed and accuracy make DeepONet a powerful tool for tracking conditionsthat contribute to material degradation in real-time, enhancing reactor safetyand longevity.</description><author>Raisa Bentay Hossain, Farid Ahmed, Kazuma Kobayashi, Seid Koric, Diab Abueidda, Syed Bahauddin Alam</author><pubDate>Thu, 17 Oct 2024 16:56:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13762v1</guid></item><item><title>GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning</title><link>http://arxiv.org/abs/2410.13761v1</link><description>Training high-quality deep models necessitates vast amounts of data,resulting in overwhelming computational and memory demands. Recently, datapruning, distillation, and coreset selection have been developed to streamlinedata volume by retaining, synthesizing, or selecting a small yet informativesubset from the full set. Among these methods, data pruning incurs the leastadditional training cost and offers the most practical acceleration benefits.However, it is the most vulnerable, often suffering significant performancedegradation with imbalanced or biased data schema, thus raising concerns aboutits accuracy and reliability in on-device deployment. Therefore, there is alooming need for a new data pruning paradigm that maintains the efficiency ofprevious practices while ensuring balance and robustness. Unlike the fields ofcomputer vision and natural language processing, where mature solutions havebeen developed to address these issues, graph neural networks (GNNs) continueto struggle with increasingly large-scale, imbalanced, and noisy datasets,lacking a unified dataset pruning solution. To achieve this, we introduce anovel dynamic soft-pruning method, GDeR, designed to update the training``basket'' during the process using trainable prototypes. GDeR first constructsa well-modeled graph embedding hypersphere and then samples\textit{representative, balanced, and unbiased subsets} from this embeddingspace, which achieves the goal we called Graph Training Debugging. Extensiveexperiments on five datasets across three GNN backbones, demonstrate that GDeR(I) achieves or surpasses the performance of the full dataset with 30%~50%fewer training samples, (II) attains up to a 2.81x lossless training speedup,and (III) outperforms state-of-the-art pruning methods in imbalanced trainingand noisy training scenarios by 0.3%~4.3% and 3.6%~7.8%, respectively.</description><author>Guibin Zhang, Haonan Dong, Yuchen Zhang, Zhixun Li, Dingshuo Chen, Kai Wang, Tianlong Chen, Yuxuan Liang, Dawei Cheng, Kun Wang</author><pubDate>Thu, 17 Oct 2024 16:56:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13761v1</guid></item><item><title>Eyelid Fold Consistency in Facial Modeling</title><link>http://arxiv.org/abs/2410.13760v1</link><description>Eyelid shape is integral to identity and likeness in human facial modeling.Human eyelids are diverse in appearance with varied skin fold and epicanthalfold morphology between individuals. Existing parametric face models expresseyelid shape variation to an extent, but do not preserve sufficient likenessacross a diverse range of individuals. We propose a new definition of eyelidfold consistency and implement geometric processing techniques to model diverseeyelid shapes in a unified topology. Using this method we reprocess data usedto train a parametric face model and demonstrate significant improvements inface-related machine learning tasks.</description><author>Lohit Petikam, Charlie Hewitt, Fatemeh Saleh, Tadas BaltruÅ¡aitis</author><pubDate>Thu, 17 Oct 2024 16:55:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13760v1</guid></item><item><title>LifeGPT: Topology-Agnostic Generative Pretrained Transformer Model for Cellular Automata</title><link>http://arxiv.org/abs/2409.12182v2</link><description>Conway's Game of Life (Life), a well known algorithm within the broader classof cellular automata (CA), exhibits complex emergent dynamics, with extremesensitivity to initial conditions. Modeling and predicting such intricatebehavior without explicit knowledge of the system's underlying topologypresents a significant challenge, motivating the development of algorithms thatcan generalize across various grid configurations and boundary conditions. Wedevelop a decoder-only generative pretrained transformer (GPT) model to solvethis problem, showing that our model can simulate Life on a toroidal grid withno prior knowledge on the size of the grid, or its periodic boundary conditions(LifeGPT). LifeGPT is topology-agnostic with respect to its training data andour results show that a GPT model is capable of capturing the deterministicrules of a Turing-complete system with near-perfect accuracy, givensufficiently diverse training data. We also introduce the idea of an`autoregressive autoregressor' to recursively implement Life using LifeGPT. Ourresults pave the path towards true universal computation within a largelanguage model framework, synthesizing of mathematical analysis with naturallanguage processing, and probing AI systems for situational awareness about theevolution of such algorithms without ever having to compute them. Similar GPTscould potentially solve inverse problems in multicellular self-assembly byextracting CA-compatible rulesets from real-world biological systems to createnew predictive models, which would have significant consequences for the fieldsof bioinspired materials, tissue engineering, and architected materials design.</description><author>Jaime A. Berkovich, Markus J. Buehler</author><pubDate>Thu, 17 Oct 2024 16:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.12182v2</guid></item><item><title>MobA: A Two-Level Agent System for Efficient Mobile Task Automation</title><link>http://arxiv.org/abs/2410.13757v1</link><description>Current mobile assistants are limited by dependence on system APIs orstruggle with complex user instructions and diverse interfaces due torestricted comprehension and decision-making abilities. To address thesechallenges, we propose MobA, a novel Mobile phone Agent powered by multimodallarge language models that enhances comprehension and planning capabilitiesthrough a sophisticated two-level agent architecture. The high-level GlobalAgent (GA) is responsible for understanding user commands, tracking historymemories, and planning tasks. The low-level Local Agent (LA) predicts detailedactions in the form of function calls, guided by sub-tasks and memory from theGA. Integrating a Reflection Module allows for efficient task completion andenables the system to handle previously unseen complex tasks. MobA demonstratessignificant improvements in task execution efficiency and completion rate inreal-life evaluations, underscoring the potential of MLLM-empowered mobileassistants.</description><author>Zichen Zhu, Hao Tang, Yansi Li, Kunyao Lan, Yixuan Jiang, Hao Zhou, Yixiao Wang, Situo Zhang, Liangtai Sun, Lu Chen, Kai Yu</author><pubDate>Thu, 17 Oct 2024 16:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13757v1</guid></item><item><title>CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building</title><link>http://arxiv.org/abs/2410.13756v1</link><description>Intelligent and reliable task planning is a core capability for generalizedrobotics, requiring a descriptive domain representation that sufficientlymodels all object and state information for the scene. We present CLIMB, acontinual learning framework for robot task planning that leverages foundationmodels and execution feedback to guide domain model construction. CLIMB canbuild a model from a natural language description, learn non-obvious predicateswhile solving tasks, and store that information for future problems. Wedemonstrate the ability of CLIMB to improve performance in common planningenvironments compared to baseline methods. We also develop the BlocksWorld++domain, a simulated environment with an easily usable real counterpart,together with a curriculum of tasks with progressing difficulty for evaluatingcontinual learning. Additional details and demonstrations for this system canbe found at https://plan-with-climb.github.io/ .</description><author>Walker Byrnes, Miroslav Bogdanovic, Avi Balakirsky, Stephen Balakirsky, Animesh Garg</author><pubDate>Thu, 17 Oct 2024 16:53:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13756v1</guid></item><item><title>Can Large Language Models Generate High-quality Patent Claims?</title><link>http://arxiv.org/abs/2406.19465v2</link><description>Large language models (LLMs) have shown exceptional performance acrossvarious text generation tasks but remain under-explored in the patent domain,which offers highly structured and precise language. This paper constructs adataset to investigate the performance of current LLMs in patent claimgeneration. Our results demonstrate that generating claims based on patentdescriptions outperforms previous research relying on abstracts. Interestingly,current patent-specific LLMs perform much worse than state-of-the-art generalLLMs, highlighting the necessity for future research on in-domain LLMs. We alsofind that LLMs can produce high-quality first independent claims, but theirperformances markedly decrease for subsequent dependent claims. Moreover,fine-tuning can enhance the completeness of inventions' features, conceptualclarity, and feature linkage. Among the tested LLMs, GPT-4 demonstrates thebest performance in comprehensive human evaluations by patent experts, withbetter feature coverage, conceptual clarity, and technical coherence. Despitethese capabilities, comprehensive revision and modification are still necessaryto pass rigorous patent scrutiny and ensure legal robustness.</description><author>Lekang Jiang, Caiqi Zhang, Pascal A Scherz, Stephan Goetz</author><pubDate>Thu, 17 Oct 2024 16:53:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19465v2</guid></item><item><title>MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures</title><link>http://arxiv.org/abs/2410.13754v1</link><description>Perceiving and generating diverse modalities are crucial for AI models toeffectively learn from and engage with real-world signals, necessitatingreliable evaluations for their development. We identify two major issues incurrent evaluations: (1) inconsistent standards, shaped by differentcommunities with varying protocols and maturity levels; and (2) significantquery, grading, and generalization biases. To address these, we introduceMixEval-X, the first any-to-any real-world benchmark designed to optimize andstandardize evaluations across input and output modalities. We proposemulti-modal benchmark mixture and adaptation-rectification pipelines toreconstruct real-world task distributions, ensuring evaluations generalizeeffectively to real-world use cases. Extensive meta-evaluations show ourapproach effectively aligns benchmark samples with real-world taskdistributions and the model rankings correlate strongly with that ofcrowd-sourced real-world evaluations (up to 0.98). We provide comprehensiveleaderboards to rerank existing models and organizations and offer insights toenhance understanding of multi-modal evaluations and inform future research.</description><author>Jinjie Ni, Yifan Song, Deepanway Ghosal, Bo Li, David Junhao Zhang, Xiang Yue, Fuzhao Xue, Zian Zheng, Kaichen Zhang, Mahir Shah, Kabir Jain, Yang You, Michael Shieh</author><pubDate>Thu, 17 Oct 2024 16:52:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13754v1</guid></item><item><title>Privacy-Preserving Decentralized AI with Confidential Computing</title><link>http://arxiv.org/abs/2410.13752v1</link><description>This paper addresses privacy protection in decentralized ArtificialIntelligence (AI) using Confidential Computing (CC) within the Atoma Network, adecentralized AI platform designed for the Web3 domain. Decentralized AIdistributes AI services among multiple entities without centralized oversight,fostering transparency and robustness. However, this structure introducessignificant privacy challenges, as sensitive assets such as proprietary modelsand personal data may be exposed to untrusted participants. Cryptography-basedprivacy protection techniques such as zero-knowledge machine learning (zkML)suffers prohibitive computational overhead. To address the limitation, wepropose leveraging Confidential Computing (CC). Confidential Computingleverages hardware-based Trusted Execution Environments (TEEs) to provideisolation for processing sensitive data, ensuring that both model parametersand user data remain secure, even in decentralized, potentially untrustedenvironments. While TEEs face a few limitations, we believe they can bridge theprivacy gap in decentralized AI. We explore how we can integrate TEEs intoAtoma's decentralized framework.</description><author>Dayeol Lee, Jorge Antonio, Hisham Khan</author><pubDate>Thu, 17 Oct 2024 16:50:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13752v1</guid></item><item><title>Supervised Kernel Thinning</title><link>http://arxiv.org/abs/2410.13749v1</link><description>The kernel thinning algorithm of Dwivedi &amp; Mackey (2024) provides abetter-than-i.i.d. compression of a generic set of points. By generatinghigh-fidelity coresets of size significantly smaller than the input points, KTis known to speed up unsupervised tasks like Monte Carlo integration,uncertainty quantification, and non-parametric hypothesis testing, with minimalloss in statistical accuracy. In this work, we generalize the KT algorithm tospeed up supervised learning problems involving kernel methods. Specifically,we combine two classical algorithms--Nadaraya-Watson (NW) regression or kernelsmoothing, and kernel ridge regression (KRR)--with KT to provide a quadraticspeed-up in both training and inference times. We show how distributioncompression with KT in each setting reduces to constructing an appropriatekernel, and introduce the Kernel-Thinned NW and Kernel-Thinned KRR estimators.We prove that KT-based regression estimators enjoy significantly superiorcomputational efficiency over the full-data estimators and improved statisticalefficiency over i.i.d. subsampling of the training data. En route, we alsoprovide a novel multiplicative error guarantee for compressing with KT. Wevalidate our design choices with both simulations and real data experiments.</description><author>Albert Gong, Kyuseong Choi, Raaz Dwivedi</author><pubDate>Thu, 17 Oct 2024 16:48:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13749v1</guid></item><item><title>Corrective Machine Unlearning</title><link>http://arxiv.org/abs/2402.14015v2</link><description>Machine Learning models increasingly face data integrity challenges due tothe use of large-scale training datasets drawn from the Internet. We study whatmodel developers can do if they detect that some data was manipulated orincorrect. Such manipulated data can cause adverse effects includingvulnerability to backdoored samples, systemic biases, and reduced accuracy oncertain input domains. Realistically, all manipulated training samples cannotbe identified, and only a small, representative subset of the affected data canbe flagged. We formalize Corrective Machine Unlearning as the problem of mitigating theimpact of data affected by unknown manipulations on a trained model, onlyhaving identified a subset of the corrupted data. We demonstrate that theproblem of corrective unlearning has significantly different requirements fromtraditional privacy-oriented unlearning. We find most existing unlearningmethods, including retraining-from-scratch without the deletion set, requiremost of the manipulated data to be identified for effective correctiveunlearning. However, one approach, Selective Synaptic Dampening, achieveslimited success, unlearning adverse effects with just a small portion of themanipulated samples in our setting, which shows encouraging signs for futureprogress. We hope our work spurs research towards developing better methods forcorrective unlearning and offers practitioners a new strategy to handle dataintegrity challenges arising from web-scale training. Code is available athttps://github.com/drimpossible/corrective-unlearning-bench.</description><author>Shashwat Goel, Ameya Prabhu, Philip Torr, Ponnurangam Kumaraguru, Amartya Sanyal</author><pubDate>Thu, 17 Oct 2024 16:47:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14015v2</guid></item><item><title>GPTreeO: An R package for continual regression with dividing local Gaussian processes</title><link>http://arxiv.org/abs/2410.01024v2</link><description>We introduce GPTreeO, a flexible R package for scalable Gaussian process (GP)regression, particularly tailored to continual learning problems. GPTreeObuilds upon the Dividing Local Gaussian Processes (DLGP) algorithm, in which abinary tree of local GP regressors is dynamically constructed using a continualstream of input data. In GPTreeO we extend the original DLGP algorithm byallowing continual optimisation of the GP hyperparameters, incorporatinguncertainty calibration, and introducing new strategies for how the localpartitions are created. Moreover, the modular code structure allows users tointerface their favourite GP library to perform the local GP regression inGPTreeO. The flexibility of GPTreeO gives the user fine-grained control of thebalance between computational speed, accuracy, stability and smoothness. Weconduct a sensitivity analysis to show how GPTreeO's configurable featuresimpact the regression performance in a continual learning setting.</description><author>Timo Braun, Anders Kvellestad, Riccardo De Bin</author><pubDate>Thu, 17 Oct 2024 16:45:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01024v2</guid></item><item><title>Theory on Score-Mismatched Diffusion Models and Zero-Shot Conditional Samplers</title><link>http://arxiv.org/abs/2410.13746v1</link><description>The denoising diffusion model has recently emerged as a powerful generativetechnique, capable of transforming noise into meaningful data. Whiletheoretical convergence guarantees for diffusion models are well establishedwhen the target distribution aligns with the training distribution, practicalscenarios often present mismatches. One common case is in zero-shot conditionaldiffusion sampling, where the target conditional distribution is different fromthe (unconditional) training distribution. These score-mismatched diffusionmodels remain largely unexplored from a theoretical perspective. In this paper,we present the first performance guarantee with explicit dimensionaldependencies for general score-mismatched diffusion samplers, focusing ontarget distributions with finite second moments. We show that score mismatchesresult in an asymptotic distributional bias between the target and samplingdistributions, proportional to the accumulated mismatch between the target andtraining distributions. This result can be directly applied to zero-shotconditional samplers for any conditional model, irrespective of measurementnoise. Interestingly, the derived convergence upper bound offers usefulguidance for designing a novel bias-optimal zero-shot sampler in linearconditional models that minimizes the asymptotic bias. For such bias-optimalsamplers, we further establish convergence guarantees with explicitdependencies on dimension and conditioning, applied to several interestingtarget distributions, including those with bounded support and Gaussianmixtures. Our findings are supported by numerical studies.</description><author>Yuchen Liang, Peizhong Ju, Yingbin Liang, Ness Shroff</author><pubDate>Thu, 17 Oct 2024 16:42:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13746v1</guid></item><item><title>Single-Timescale Multi-Sequence Stochastic Approximation Without Fixed Point Smoothness: Theories and Applications</title><link>http://arxiv.org/abs/2410.13743v1</link><description>Stochastic approximation (SA) that involves multiple coupled sequences, knownas multiple-sequence SA (MSSA), finds diverse applications in the fields ofsignal processing and machine learning. However, existing theoreticalunderstandings {of} MSSA are limited: the multi-timescale analysis implies aslow convergence rate, whereas the single-timescale analysis relies on astringent fixed point smoothness assumption. This paper establishes tightersingle-timescale analysis for MSSA, without assuming smoothness of the fixedpoints. Our theoretical findings reveal that, when all involved operators arestrongly monotone, MSSA converges at a rate of $\tilde{\mathcal{O}}(K^{-1})$,where $K$ denotes the total number of iterations. In addition, when allinvolved operators are strongly monotone except for the main one, MSSAconverges at a rate of $\mathcal{O}(K^{-\frac{1}{2}})$. These theoreticalfindings align with those established for single-sequence SA. Applying thesetheoretical findings to bilevel optimization and communication-efficientdistributed learning offers relaxed assumptions and/or simpler algorithms withperformance guarantees, as validated by numerical experiments.</description><author>Yue Huang, Zhaoxian Wu, Shiqian Ma, Qing Ling</author><pubDate>Thu, 17 Oct 2024 16:39:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13743v1</guid></item><item><title>Improved Convergence Rate for Diffusion Probabilistic Models</title><link>http://arxiv.org/abs/2410.13738v1</link><description>Score-based diffusion models have achieved remarkable empirical performancein the field of machine learning and artificial intelligence for their abilityto generate high-quality new data instances from complex distributions.Improving our understanding of diffusion models, including mainly convergenceanalysis for such models, has attracted a lot of interests. Despite a lot oftheoretical attempts, there still exists significant gap between theory andpractice. Towards to close this gap, we establish an iteration complexity atthe order of $d^{1/3}\varepsilon^{-2/3}$, which is better than$d^{5/12}\varepsilon^{-1}$, the best known complexity achieved before our work.This convergence analysis is based on a randomized midpoint method, which isfirst proposed for log-concave sampling (Shen and Lee, 2019), and then extendedto diffusion models by Gupta et al. (2024). Our theory accommodates$\varepsilon$-accurate score estimates, and does not require log-concavity onthe target distribution. Moreover, the algorithm can also be parallelized torun in only $O(\log^2(d/\varepsilon))$ parallel rounds in a similar way toprior works.</description><author>Gen Li, Yuchen Jiao</author><pubDate>Thu, 17 Oct 2024 16:37:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13738v1</guid></item><item><title>Optimizing Probabilistic Conformal Prediction with Vectorized Non-Conformity Scores</title><link>http://arxiv.org/abs/2410.13735v1</link><description>Generative models have shown significant promise in critical domains such asmedical diagnosis, autonomous driving, and climate science, where reliabledecision-making hinges on accurate uncertainty quantification. Whileprobabilistic conformal prediction (PCP) offers a powerful framework for thispurpose, its coverage efficiency -- the size of the uncertainty set -- islimited when dealing with complex underlying distributions and a finite numberof generated samples. In this paper, we propose a novel PCP framework thatenhances efficiency by first vectorizing the non-conformity scores with rankedsamples and then optimizing the shape of the prediction set by varying thequantiles for samples at the same rank. Our method delivers valid coveragewhile producing discontinuous and more efficient prediction sets, making itparticularly suited for high-stakes applications. We demonstrate theeffectiveness of our approach through experiments on both synthetic andreal-world datasets.</description><author>Minxing Zheng, Shixiang Zhu</author><pubDate>Thu, 17 Oct 2024 16:37:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13735v1</guid></item><item><title>Improving Multi-modal Large Language Model through Boosting Vision Capabilities</title><link>http://arxiv.org/abs/2410.13733v1</link><description>We focus on improving the visual understanding capability for boosting thevision-language models. We propose \textbf{Arcana}, a multiModal languagemodel, which introduces two crucial techniques. First, we present MultimodalLoRA (MM-LoRA), a module designed to enhance the decoder. Unlike traditionallanguage-driven decoders, MM-LoRA consists of two parallel LoRAs -- one forvision and one for language -- each with its own parameters. This disentangledparameters design allows for more specialized learning in each modality andbetter integration of multimodal information. Second, we introduce the QueryLadder adapter (QLadder) to improve the visual encoder. QLadder employs alearnable ``\textit{ladder}'' structure to deeply aggregates the intermediaterepresentations from the frozen pretrained visual encoder (e.g., CLIP imageencoder). This enables the model to learn new and informative visual features,as well as remaining the powerful capabilities of the pretrained visualencoder. These techniques collectively enhance Arcana's visual perceptionpower, enabling it to leverage improved visual information for more accurateand contextually relevant outputs across various multimodal scenarios.Extensive experiments and ablation studies demonstrate the effectiveness andgeneralization capability of our Arcana. The code and re-annotated data areavailable at \url{https://arcana-project-page.github.io}.</description><author>Yanpeng Sun, Huaxin Zhang, Qiang Chen, Xinyu Zhang, Nong Sang, Gang Zhang, Jingdong Wang, Zechao Li</author><pubDate>Thu, 17 Oct 2024 16:36:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13733v1</guid></item><item><title>Reducing the Transformer Architecture to a Minimum</title><link>http://arxiv.org/abs/2410.13732v1</link><description>Transformers are a widespread and successful model architecture, particularlyin Natural Language Processing (NLP) and Computer Vision (CV). The essentialinnovation of this architecture is the Attention Mechanism, which solves theproblem of extracting relevant context information from long sequences in NLPand realistic scenes in CV. A classical neural network component, a Multi-LayerPerceptron (MLP), complements the attention mechanism. Its necessity isfrequently justified by its capability of modeling nonlinear relationships.However, the attention mechanism itself is nonlinear through its internal useof similarity measures. A possible hypothesis is that this nonlinearity issufficient for modeling typical application problems. As the MLPs usuallycontain the most trainable parameters of the whole model, their omission wouldsubstantially reduce the parameter set size. Further components can also bereorganized to reduce the number of parameters. Under some conditions, queryand key matrices can be collapsed into a single matrix of the same size. Thesame is true about value and projection matrices, which can also be omittedwithout eliminating the substance of the attention mechanism. Initially, thesimilarity measure was defined asymmetrically, with peculiar properties such asthat a token is possibly dissimilar to itself. A possible symmetric definitionrequires only half of the parameters. We have laid the groundwork by testingwidespread CV benchmarks: MNIST and CIFAR-10. The tests have shown thatsimplified transformer architectures (a) without MLP, (b) with collapsedmatrices, and (c) symmetric similarity matrices exhibit similar performance asthe original architecture, saving up to 90% of parameters without hurting theclassification performance.</description><author>Bernhard Bermeitinger, Tomas Hrycej, Massimo Pavone, Julianus Kath, Siegfried Handschuh</author><pubDate>Thu, 17 Oct 2024 16:36:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13732v1</guid></item><item><title>LLM-Human Pipeline for Cultural Context Grounding of Conversations</title><link>http://arxiv.org/abs/2410.13727v1</link><description>Conversations often adhere to well-understood social norms that vary acrosscultures. For example, while "addressing parents by name" is commonplace in theWest, it is rare in most Asian cultures. Adherence or violation of such normsoften dictates the tenor of conversations. Humans are able to navigate socialsituations requiring cultural awareness quite adeptly. However, it is a hardtask for NLP models. In this paper, we tackle this problem by introducing a "Cultural ContextSchema" for conversations. It comprises (1) conversational information such asemotions, dialogue acts, etc., and (2) cultural information such as socialnorms, violations, etc. We generate ~110k social norm and violationdescriptions for ~23k conversations from Chinese culture using LLMs. We refinethem using automated verification strategies which are evaluated againstculturally aware human judgements. We organize these descriptions intomeaningful structures we call "Norm Concepts", using an interactivehuman-in-loop framework. We ground the norm concepts and the descriptions inconversations using symbolic annotation. Finally, we use the obtained datasetfor downstream tasks such as emotion, sentiment, and dialogue act detection. Weshow that it significantly improves the empirical performance.</description><author>Rajkumar Pujari, Dan Goldwasser</author><pubDate>Thu, 17 Oct 2024 16:33:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13727v1</guid></item><item><title>Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas</title><link>http://arxiv.org/abs/2406.14462v2</link><description>Large language models (LLMs) are increasingly being used in human-centeredsocial scientific tasks, such as data annotation, synthetic data creation, andengaging in dialog. However, these tasks are highly subjective and dependent onhuman factors, such as one's environment, attitudes, beliefs, and livedexperiences. Thus, it may be the case that employing LLMs (which do not havesuch human factors) in these tasks results in a lack of variation in data,failing to reflect the diversity of human experiences. In this paper, weexamine the role of prompting LLMs with human-like personas and asking themodels to answer as if they were a specific human. This is done explicitly,with exact demographics, political beliefs, and lived experiences, orimplicitly via names prevalent in specific populations. The LLM personas arethen evaluated via (1) subjective annotation task (e.g., detecting toxicity)and (2) a belief generation task, where both tasks are known to vary acrosshuman factors. We examine the impact of explicit vs. implicit personas andinvestigate which human factors LLMs recognize and respond to. Results showthat explicit LLM personas show mixed results when reproducing known humanbiases, but generally fail to demonstrate implicit biases. We conclude thatLLMs may capture the statistical patterns of how people speak, but aregenerally unable to model the complex interactions and subtleties of humanperceptions, potentially limiting their effectiveness in social scienceapplications.</description><author>Salvatore Giorgi, Tingting Liu, Ankit Aich, Kelsey Isman, Garrick Sherman, Zachary Fried, JoÃ£o Sedoc, Lyle H. Ungar, Brenda Curtis</author><pubDate>Thu, 17 Oct 2024 16:32:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14462v2</guid></item><item><title>DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation</title><link>http://arxiv.org/abs/2410.13726v1</link><description>Talking head generation intends to produce vivid and realistic talking headvideos from a single portrait and speech audio clip. Although significantprogress has been made in diffusion-based talking head generation, almost allmethods rely on autoregressive strategies, which suffer from limited contextutilization beyond the current generation step, error accumulation, and slowergeneration speed. To address these challenges, we present DAWN (Dynamic frameAvatar With Non-autoregressive diffusion), a framework that enables all-at-oncegeneration of dynamic-length video sequences. Specifically, it consists of twomain components: (1) audio-driven holistic facial dynamics generation in thelatent motion space, and (2) audio-driven head pose and blink generation.Extensive experiments demonstrate that our method generates authentic and vividvideos with precise lip motions, and natural pose/blink movements.Additionally, with a high generation speed, DAWN possesses strong extrapolationcapabilities, ensuring the stable production of high-quality long videos. Theseresults highlight the considerable promise and potential impact of DAWN in thefield of talking head video generation. Furthermore, we hope that DAWN sparksfurther exploration of non-autoregressive approaches in diffusion models. Ourcode will be publicly at https://github.com/Hanbo-Cheng/DAWN-pytorch.</description><author>Hanbo Cheng, Limin Lin, Chenyu Liu, Pengcheng Xia, Pengfei Hu, Jiefeng Ma, Jun Du, Jia Pan</author><pubDate>Thu, 17 Oct 2024 16:32:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13726v1</guid></item><item><title>Persistent Pre-Training Poisoning of LLMs</title><link>http://arxiv.org/abs/2410.13722v1</link><description>Large language models are pre-trained on uncurated text datasets consistingof trillions of tokens scraped from the Web. Prior work has shown that: (1)web-scraped pre-training datasets can be practically poisoned by maliciousactors; and (2) adversaries can compromise language models after poisoningfine-tuning datasets. Our work evaluates for the first time whether languagemodels can also be compromised during pre-training, with a focus on thepersistence of pre-training attacks after models are fine-tuned as helpful andharmless chatbots (i.e., after SFT and DPO). We pre-train a series of LLMs fromscratch to measure the impact of a potential poisoning adversary under fourdifferent attack objectives (denial-of-service, belief manipulation,jailbreaking, and prompt stealing), and across a wide range of model sizes(from 600M to 7B). Our main result is that poisoning only 0.1% of a model'spre-training dataset is sufficient for three out of four attacks to measurablypersist through post-training. Moreover, simple attacks like denial-of-servicepersist through post-training with a poisoning rate of only 0.001%.</description><author>Yiming Zhang, Javier Rando, Ivan Evtimov, Jianfeng Chi, Eric Michael Smith, Nicholas Carlini, Florian TramÃ¨r, Daphne Ippolito</author><pubDate>Thu, 17 Oct 2024 16:27:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13722v1</guid></item><item><title>Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling</title><link>http://arxiv.org/abs/2403.08854v2</link><description>Many machine learning applications involve learning a latent representationof data, which is often high-dimensional and difficult to directly interpret.In this work, we propose "Moment Pooling", a natural extension of Deep Setsnetworks which drastically decrease latent space dimensionality of thesenetworks while maintaining or even improving performance. Moment Poolinggeneralizes the summation in Deep Sets to arbitrary multivariate moments, whichenables the model to achieve a much higher effective latent dimensionality fora fixed latent dimension. We demonstrate Moment Pooling on the collider physicstask of quark/gluon jet classification by extending Energy Flow Networks (EFNs)to Moment EFNs. We find that Moment EFNs with latent dimensions as small as 1perform similarly to ordinary EFNs with higher latent dimension. This smalllatent dimension allows for the internal representation to be directlyvisualized and interpreted, which in turn enables the learned internal jetrepresentation to be extracted in closed form.</description><author>Rikab Gambhir, Athis Osathapan, Jesse Thaler</author><pubDate>Thu, 17 Oct 2024 16:23:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08854v2</guid></item><item><title>Machine-learning prediction of tipping with applications to the Atlantic Meridional Overturning Circulation</title><link>http://arxiv.org/abs/2402.14877v2</link><description>Anticipating a tipping point, a transition from one stable steady state toanother, is a problem of broad relevance due to the ubiquity of the phenomenonin diverse fields. The steady-state nature of the dynamics about a tippingpoint makes its prediction significantly more challenging than predicting othertypes of critical transitions from oscillatory or chaotic dynamics. Exploitingthe benefits of noise, we develop a general data-driven and machine-learningapproach to predicting potential future tipping in nonautonomous dynamicalsystems and validate the framework using examples from different fields. As anapplication, we address the problem of predicting the potential collapse of theAtlantic Meridional Overturning Circulation (AMOC), possibly driven byclimate-induced changes in the freshwater input to the North Atlantic. Ourpredictions based on synthetic and currently available empirical data place apotential collapse window spanning from 2040 to 2065, in consistency with theresults in the current literature.</description><author>Shirin Panahi, Ling-Wei Kong, Mohammadamin Moradi, Zheng-Meng Zhai, Bryan Glaz, Mulugeta Haile, Ying-Cheng Lai</author><pubDate>Thu, 17 Oct 2024 16:22:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14877v2</guid></item></channel></rss>