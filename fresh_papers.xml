<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 09 Jan 2025 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LargeAD: Large-Scale Cross-Sensor Data Pretraining for Autonomous Driving</title><link>http://arxiv.org/abs/2501.04005v1</link><description>Recent advancements in vision foundation models (VFMs) have revolutionizedvisual perception in 2D, yet their potential for 3D scene understanding,particularly in autonomous driving applications, remains underexplored. In thispaper, we introduce LargeAD, a versatile and scalable framework designed forlarge-scale 3D pretraining across diverse real-world driving datasets. Ourframework leverages VFMs to extract semantically rich superpixels from 2Dimages, which are aligned with LiDAR point clouds to generate high-qualitycontrastive samples. This alignment facilitates cross-modal representationlearning, enhancing the semantic consistency between 2D and 3D data. Weintroduce several key innovations: i) VFM-driven superpixel generation fordetailed semantic representation, ii) a VFM-assisted contrastive learningstrategy to align multimodal features, iii) superpoint temporal consistency tomaintain stable representations across time, and iv) multi-source datapretraining to generalize across various LiDAR configurations. Our approachdelivers significant performance improvements over state-of-the-art methods inboth linear probing and fine-tuning tasks for both LiDAR-based segmentation andobject detection. Extensive experiments on eleven large-scale multi-modaldatasets highlight our superior performance, demonstrating the adaptability,efficiency, and robustness in real-world autonomous driving scenarios.</description><author>Lingdong Kong, Xiang Xu, Youquan Liu, Jun Cen, Runnan Chen, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu</author><pubDate>Tue, 07 Jan 2025 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04005v1</guid></item><item><title>LiMoE: Mixture of LiDAR Representation Learners from Automotive Scenes</title><link>http://arxiv.org/abs/2501.04004v1</link><description>LiDAR data pretraining offers a promising approach to leveraging large-scale,readily available datasets for enhanced data utilization. However, existingmethods predominantly focus on sparse voxel representation, overlooking thecomplementary attributes provided by other LiDAR representations. In this work,we propose LiMoE, a framework that integrates the Mixture of Experts (MoE)paradigm into LiDAR data representation learning to synergistically combinemultiple representations, such as range images, sparse voxels, and raw points.Our approach consists of three stages: i) Image-to-LiDAR Pretraining, whichtransfers prior knowledge from images to point clouds across differentrepresentations; ii) Contrastive Mixture Learning (CML), which uses MoE toadaptively activate relevant attributes from each representation and distillsthese mixed features into a unified 3D network; iii) Semantic MixtureSupervision (SMS), which combines semantic logits from multiple representationsto boost downstream segmentation performance. Extensive experiments across 11large-scale LiDAR datasets demonstrate our effectiveness and superiority. Thecode and model checkpoints have been made publicly accessible.</description><author>Xiang Xu, Lingdong Kong, Hui Shuai, Liang Pan, Ziwei Liu, Qingshan Liu</author><pubDate>Tue, 07 Jan 2025 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04004v1</guid></item><item><title>Are VLMs Ready for Autonomous Driving? An Empirical Study from the Reliability, Data, and Metric Perspectives</title><link>http://arxiv.org/abs/2501.04003v1</link><description>Recent advancements in Vision-Language Models (VLMs) have sparked interest intheir use for autonomous driving, particularly in generating interpretabledriving decisions through natural language. However, the assumption that VLMsinherently provide visually grounded, reliable, and interpretable explanationsfor driving remains largely unexamined. To address this gap, we introduceDriveBench, a benchmark dataset designed to evaluate VLM reliability across 17settings (clean, corrupted, and text-only inputs), encompassing 19,200 frames,20,498 question-answer pairs, three question types, four mainstream drivingtasks, and a total of 12 popular VLMs. Our findings reveal that VLMs oftengenerate plausible responses derived from general knowledge or textual cuesrather than true visual grounding, especially under degraded or missing visualinputs. This behavior, concealed by dataset imbalances and insufficientevaluation metrics, poses significant risks in safety-critical scenarios likeautonomous driving. We further observe that VLMs struggle with multi-modalreasoning and display heightened sensitivity to input corruptions, leading toinconsistencies in performance. To address these challenges, we propose refinedevaluation metrics that prioritize robust visual grounding and multi-modalunderstanding. Additionally, we highlight the potential of leveraging VLMs'awareness of corruptions to enhance their reliability, offering a roadmap fordeveloping more trustworthy and interpretable decision-making systems inreal-world autonomous driving contexts. The benchmark toolkit is publiclyaccessible.</description><author>Shaoyuan Xie, Lingdong Kong, Yuhao Dong, Chonghao Sima, Wenwei Zhang, Qi Alfred Chen, Ziwei Liu, Liang Pan</author><pubDate>Tue, 07 Jan 2025 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04003v1</guid></item><item><title>Extraction Of Cumulative Blobs From Dynamic Gestures</title><link>http://arxiv.org/abs/2501.04002v1</link><description>Gesture recognition is a perceptual user interface, which is based on CVtechnology that allows the computer to interpret human motions as commands,allowing users to communicate with a computer without the use of hands, thusmaking the mouse and keyboard superfluous. Gesture recognition's main weaknessis a light condition because gesture control is based on computer vision, whichheavily relies on cameras. These cameras are used to interpret gestures in 2Dand 3D, so the extracted information can vary depending on the source of light.The limitation of the system cannot work in a dark environment. A simple nightvision camera can be used as our camera for motion capture as they also blastout infrared light which is not visible to humans but can be clearly seen witha camera that has no infrared filter this majorly overcomes the limitation ofsystems which cannot work in a dark environment. So, the video stream from thecamera is fed into a Raspberry Pi which has a Python program running OpenCVmodule which is used for detecting, isolating and tracking the path of dynamicgesture, then we use an algorithm of machine learning to recognize the patterndrawn and accordingly control the GPIOs of the raspberry pi to perform someactivities.</description><author>Rishabh Naulakha, Shubham Gaur, Dhairya Lodha, Mehek Tulsyan, Utsav Kotecha</author><pubDate>Tue, 07 Jan 2025 18:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04002v1</guid></item><item><title>Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos</title><link>http://arxiv.org/abs/2501.04001v1</link><description>This work presents Sa2VA, the first unified model for dense groundedunderstanding of both images and videos. Unlike existing multi-modal largelanguage models, which are often limited to specific modalities and tasks,Sa2VA supports a wide range of image and video tasks, including referringsegmentation and conversation, with minimal one-shot instruction tuning. Sa2VAcombines SAM-2, a foundation video segmentation model, with LLaVA, an advancedvision-language model, and unifies text, image, and video into a shared LLMtoken space. Using the LLM, Sa2VA generates instruction tokens that guide SAM-2in producing precise masks, enabling a grounded, multi-modal understanding ofboth static and dynamic visual content. Additionally, we introduce Ref-SAV, anauto-labeled dataset containing over 72k object expressions in complex videoscenes, designed to boost model performance. We also manually validate 2k videoobjects in the Ref-SAV datasets to benchmark referring video objectsegmentation in complex environments. Experiments show that Sa2VA achievesstate-of-the-art across multiple tasks, particularly in referring video objectsegmentation, highlighting its potential for complex real-world applications.</description><author>Haobo Yuan, Xiangtai Li, Tao Zhang, Zilong Huang, Shilin Xu, Shunping Ji, Yunhai Tong, Lu Qi, Jiashi Feng, Ming-Hsuan Yang</author><pubDate>Tue, 07 Jan 2025 18:58:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04001v1</guid></item><item><title>Î»: A Benchmark for Data-Efficiency in Long-Horizon Indoor Mobile Manipulation Robotics</title><link>http://arxiv.org/abs/2412.05313v3</link><description>Efficiently learning and executing long-horizon mobile manipulation (MoMa)tasks is crucial for advancing robotics in household and workplace settings.However, current MoMa models are data-inefficient, underscoring the need forimproved models that require realistic-sized benchmarks to evaluate theirefficiency, which do not exist. To address this, we introduce the LAMBDA({\lambda}) benchmark (Long-horizon Actions for Mobile-manipulationBenchmarking of Directed Activities), which evaluates the data efficiency ofmodels on language-conditioned, long-horizon, multi-room, multi-floor,pick-and-place tasks using a dataset of manageable size, more feasible forcollection. The benchmark includes 571 human-collected demonstrations thatprovide realism and diversity in simulated and real-world settings. Unlikeplanner-generated data, these trajectories offer natural variability andreplay-verifiability, ensuring robust learning and evaluation. We benchmarkseveral models, including learning-based models and a neuro-symbolic modularapproach combining foundation models with task and motion planning.Learning-based models show suboptimal success rates, even when leveragingpretrained weights, underscoring significant data inefficiencies. However, theneuro-symbolic approach performs significantly better while being more dataefficient. Findings highlight the need for more data-efficient learning-basedMoMa approaches. {\lambda} addresses this gap by serving as a key benchmark forevaluating the data efficiency of those future models in handling householdrobotics tasks.</description><author>Ahmed Jaafar, Shreyas Sundara Raman, Yichen Wei, Sudarshan Harithas, Sofia Juliani, Anneke Wernerfelt, Benedict Quartey, Ifrah Idrees, Jason Xinyu Liu, Stefanie Tellex</author><pubDate>Tue, 07 Jan 2025 18:57:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05313v3</guid></item><item><title>A Survey on Federated Learning in Human Sensing</title><link>http://arxiv.org/abs/2501.04000v1</link><description>Human Sensing, a field that leverages technology to monitor human activities,psycho-physiological states, and interactions with the environment, enhancesour understanding of human behavior and drives the development of advancedservices that improve overall quality of life. However, its reliance ondetailed and often privacy-sensitive data as the basis for its machine learning(ML) models raises significant legal and ethical concerns. The recentlyproposed ML approach of Federated Learning (FL) promises to alleviate many ofthese concerns, as it is able to create accurate ML models without sending rawuser data to a central server. While FL has demonstrated its usefulness acrossa variety of areas, such as text prediction and cyber security, its benefits inHuman Sensing are under-explored, given the particular challenges in thisdomain. This survey conducts a comprehensive analysis of the currentstate-of-the-art studies on FL in Human Sensing, and proposes a taxonomy and aneight-dimensional assessment for FL approaches. Through the eight-dimensionalassessment, we then evaluate whether the surveyed studies consider a specificFL-in-Human-Sensing challenge or not. Finally, based on the overall analysis,we discuss open challenges and highlight five research aspects related to FL inHuman Sensing that require urgent research attention. Our work provides acomprehensive corpus of FL studies and aims to assist FL practitioners indeveloping and evaluating solutions that effectively address the real-worldcomplexities of Human Sensing.</description><author>Mohan Li, Martin Gjoreski, Pietro Barbiero, GaÅ¡per SlapniÄar, Mitja LuÅ¡trek, Nicholas D. Lane, Marc Langheinrich</author><pubDate>Tue, 07 Jan 2025 18:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04000v1</guid></item><item><title>WAPTS: A Weighted Allocation Probability Adjusted Thompson Sampling Algorithm for High-Dimensional and Sparse Experiment Settings</title><link>http://arxiv.org/abs/2501.03999v1</link><description>Aiming for more effective experiment design, such as in video contentadvertising where different content options compete for user engagement, thesescenarios can be modeled as multi-arm bandit problems. In cases where limitedinteractions are available due to external factors, such as the cost ofconducting experiments, recommenders often face constraints due to the smallnumber of user interactions. In addition, there is a trade-off betweenselecting the best treatment and the ability to personalize and contextualizebased on individual factors. A popular solution to this dilemma is theContextual Bandit framework. It aims to maximize outcomes while incorporatingpersonalization (contextual) factors, customizing treatments such as a user'sprofile to individual preferences. Despite their advantages, Contextual Banditalgorithms face challenges like measurement bias and the 'curse ofdimensionality.' These issues complicate the management of numerousinterventions and often lead to data sparsity through participant segmentation.To address these problems, we introduce the Weighted Allocation ProbabilityAdjusted Thompson Sampling (WAPTS) algorithm. WAPTS builds on the contextualThompson Sampling method by using a dynamic weighting parameter. This improvesthe allocation process for interventions and enables rapid optimization indata-sparse environments. We demonstrate the performance of our approach ondifferent numbers of arms and effect sizes.</description><author>Haochen Song, Ilya Musabirov, Ananya Bhattacharjee, Audrey Durand, Meredith Franklin, Anna Rafferty, Joseph Jay Williams</author><pubDate>Tue, 07 Jan 2025 18:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03999v1</guid></item><item><title>RAG-Check: Evaluating Multimodal Retrieval Augmented Generation Performance</title><link>http://arxiv.org/abs/2501.03995v1</link><description>Retrieval-augmented generation (RAG) improves large language models (LLMs) byusing external knowledge to guide response generation, reducing hallucinations.However, RAG, particularly multi-modal RAG, can introduce new hallucinationsources: (i) the retrieval process may select irrelevant pieces (e.g.,documents, images) as raw context from the database, and (ii) retrieved imagesare processed into text-based context via vision-language models (VLMs) ordirectly used by multi-modal language models (MLLMs) like GPT-4o, which mayhallucinate. To address this, we propose a novel framework to evaluate thereliability of multi-modal RAG using two performance measures: (i) therelevancy score (RS), assessing the relevance of retrieved entries to thequery, and (ii) the correctness score (CS), evaluating the accuracy of thegenerated response. We train RS and CS models using a ChatGPT-derived databaseand human evaluator samples. Results show that both models achieve ~88%accuracy on test data. Additionally, we construct a 5000-sample human-annotateddatabase evaluating the relevancy of retrieved pieces and the correctness ofresponse statements. Our RS model aligns with human preferences 20% more oftenthan CLIP in retrieval, and our CS model matches human preferences ~91% of thetime. Finally, we assess various RAG systems' selection and generationperformances using RS and CS.</description><author>Matin Mortaheb, Mohammad A. Amir Khojastepour, Srimat T. Chakradhar, Sennur Ulukus</author><pubDate>Tue, 07 Jan 2025 18:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03995v1</guid></item><item><title>Synthetic Data for Portfolios: A Throw of the Dice Will Never Abolish Chance</title><link>http://arxiv.org/abs/2501.03993v1</link><description>Simulation methods have always been instrumental in finance, and data-drivenmethods with minimal model specification, commonly referred to as generativemodels, have attracted increasing attention, especially after the success ofdeep learning in a broad range of fields. However, the adoption of these modelsin financial applications has not kept pace with the growing interest, probablydue to the unique complexities and challenges of financial markets. This paperaims to contribute to a deeper understanding of the limitations of generativemodels, particularly in portfolio and risk management. To this end, we begin bypresenting theoretical results on the importance of initial sample size, andpoint out the potential pitfalls of generating far more data than originallyavailable. We then highlight the inseparable nature of model development andthe desired use case by touching on a paradox: generic generative modelsinherently care less about what is important for constructing portfolios (inparticular the long-short ones). Based on these findings, we propose a pipelinefor the generation of multivariate returns that meets conventional evaluationstandards on a large universe of US equities while being compliant withstylized facts observed in asset returns and turning around the pitfalls wepreviously identified. Moreover, we insist on the need for more delicateevaluation methods, and suggest, through an example of mean-reversionstrategies, a method designed to identify poor models for a given applicationbased on regurgitative training, i.e. retraining the model using the data ithas itself generated, which is commonly referred to in statistics asidentifiability.</description><author>Adil Rengim Cetingoz, Charles-Albert Lehalle</author><pubDate>Tue, 07 Jan 2025 18:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03993v1</guid></item><item><title>NeuralSVG: An Implicit Representation for Text-to-Vector Generation</title><link>http://arxiv.org/abs/2501.03992v1</link><description>Vector graphics are essential in design, providing artists with a versatilemedium for creating resolution-independent and highly editable visual content.Recent advancements in vision-language and diffusion models have fueledinterest in text-to-vector graphics generation. However, existing approachesoften suffer from over-parameterized outputs or treat the layered structure - acore feature of vector graphics - as a secondary goal, diminishing theirpractical use. Recognizing the importance of layered SVG representations, wepropose NeuralSVG, an implicit neural representation for generating vectorgraphics from text prompts. Inspired by Neural Radiance Fields (NeRFs),NeuralSVG encodes the entire scene into the weights of a small MLP network,optimized using Score Distillation Sampling (SDS). To encourage a layeredstructure in the generated SVG, we introduce a dropout-based regularizationtechnique that strengthens the standalone meaning of each shape. Weadditionally demonstrate that utilizing a neural representation provides anadded benefit of inference-time control, enabling users to dynamically adaptthe generated SVG based on user-provided inputs, all with a single learnedrepresentation. Through extensive qualitative and quantitative evaluations, wedemonstrate that NeuralSVG outperforms existing methods in generatingstructured and flexible SVG.</description><author>Sagi Polaczek, Yuval Alaluf, Elad Richardson, Yael Vinker, Daniel Cohen-Or</author><pubDate>Tue, 07 Jan 2025 18:50:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03992v1</guid></item><item><title>ImageFlowNet: Forecasting Multiscale Image-Level Trajectories of Disease Progression with Irregularly-Sampled Longitudinal Medical Images</title><link>http://arxiv.org/abs/2406.14794v5</link><description>Advances in medical imaging technologies have enabled the collection oflongitudinal images, which involve repeated scanning of the same patients overtime, to monitor disease progression. However, predictive modeling of such dataremains challenging due to high dimensionality, irregular sampling, and datasparsity. To address these issues, we propose ImageFlowNet, a novel modeldesigned to forecast disease trajectories from initial images while preservingspatial details. ImageFlowNet first learns multiscale joint representationspaces across patients and time points, then optimizes deterministic orstochastic flow fields within these spaces using a position-parameterizedneural ODE/SDE framework. The model leverages a UNet architecture to createrobust multiscale representations and mitigates data scarcity by combiningknowledge from all patients. We provide theoretical insights that support ourformulation of ODEs, and motivate our regularizations involving high-levelvisual features, latent space organization, and trajectory smoothness. Wevalidate ImageFlowNet on three longitudinal medical image datasets depictingprogression in geographic atrophy, multiple sclerosis, and glioblastoma,demonstrating its ability to effectively forecast disease progression andoutperform existing methods. Our contributions include the development ofImageFlowNet, its theoretical underpinnings, and empirical validation onreal-world datasets. The official implementation is available athttps://github.com/KrishnaswamyLab/ImageFlowNet.</description><author>Chen Liu, Ke Xu, Liangbo L. Shen, Guillaume Huguet, Zilong Wang, Alexander Tong, Danilo Bzdok, Jay Stewart, Jay C. Wang, Lucian V. Del Priore, Smita Krishnaswamy</author><pubDate>Tue, 07 Jan 2025 18:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14794v5</guid></item><item><title>Influences on LLM Calibration: A Study of Response Agreement, Loss Functions, and Prompt Styles</title><link>http://arxiv.org/abs/2501.03991v1</link><description>Calibration, the alignment between model confidence and prediction accuracy,is critical for the reliable deployment of large language models (LLMs).Existing works neglect to measure the generalization of their methods to otherprompt styles and different sizes of LLMs. To address this, we define acontrolled experimental setting covering 12 LLMs and four prompt styles. Weadditionally investigate if incorporating the response agreement of multipleLLMs and an appropriate loss function can improve calibration performance.Concretely, we build Calib-n, a novel framework that trains an auxiliary modelfor confidence estimation that aggregates responses from multiple LLMs tocapture inter-model agreement. To optimize calibration, we integrate focal andAUC surrogate losses alongside binary cross-entropy. Experiments across fourdatasets demonstrate that both response agreement and focal loss improvecalibration from baselines. We find that few-shot prompts are the mosteffective for auxiliary model-based methods, and auxiliary models demonstraterobust calibration performance across accuracy variations, outperforming LLMs'internal probabilities and verbalized confidences. These insights deepen theunderstanding of influence factors in LLM calibration, supporting theirreliable deployment in diverse applications.</description><author>Yuxi Xia, Pedro Henrique Luz de Araujo, Klim Zaporojets, Benjamin Roth</author><pubDate>Tue, 07 Jan 2025 18:48:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03991v1</guid></item><item><title>Semantically Cohesive Word Grouping in Indian Languages</title><link>http://arxiv.org/abs/2501.03988v1</link><description>Indian languages are inflectional and agglutinative and typically followclause-free word order. The structure of sentences across most major Indianlanguages are similar when their dependency parse trees are considered. Whilesome differences in the parsing structure occur due to peculiarities of alanguage or its preferred natural way of conveying meaning, several apparentdifferences are simply due to the granularity of representation of the smallestsemantic unit of processing in a sentence. The semantic unit is typically aword, typographically separated by whitespaces. A single whitespace-separatedword in one language may correspond to a group of words in another. Hence,grouping of words based on semantics helps unify the parsing structure ofparallel sentences across languages and, in the process, morphology. In thiswork, we propose word grouping as a major preprocessing step for anycomputational or linguistic processing of sentences for Indian languages. AmongIndian languages, since Hindi is one of the least agglutinative, we expect itto benefit the most from word-grouping. Hence, in this paper, we focus on Hindito study the effects of grouping. We perform quantitative assessment of ourproposal with an intrinsic method that perturbs sentences by shuffling words aswell as an extrinsic evaluation that verifies the importance of word groupingfor the task of Machine Translation (MT) using decomposed prompting. We alsoqualitatively analyze certain aspects of the syntactic structure of sentences.Our experiments and analyses show that the proposed grouping technique bringsuniformity in the syntactic structures, as well as aids underlying NLP tasks.</description><author>N J Karthika, Adyasha Patra, Nagasai Saketh Naidu, Arnab Bhattacharya, Ganesh Ramakrishnan, Chaitali Dangarikar</author><pubDate>Tue, 07 Jan 2025 18:46:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03988v1</guid></item><item><title>Multimodal Machine Learning Can Predict Videoconference Fluidity and Enjoyment</title><link>http://arxiv.org/abs/2501.03190v2</link><description>Videoconferencing is now a frequent mode of communication in bothprofessional and informal settings, yet it often lacks the fluidity andenjoyment of in-person conversation. This study leverages multimodal machinelearning to predict moments of negative experience in videoconferencing. Wesampled thousands of short clips from the RoomReader corpus, extracting audioembeddings, facial actions, and body motion features to train models foridentifying low conversational fluidity, low enjoyment, and classifyingconversational events (backchanneling, interruption, or gap). Our best modelsachieved an ROC-AUC of up to 0.87 on hold-out videoconference sessions, withdomain-general audio features proving most critical. This work demonstratesthat multimodal audio-video signals can effectively predict high-levelsubjective conversational outcomes. In addition, this is a contribution toresearch on videoconferencing user experience by showing that multimodalmachine learning can be used to identify rare moments of negative userexperience for further study or mitigation.</description><author>Andrew Chang, Viswadruth Akkaraju, Ray McFadden Cogliano, David Poeppel, Dustin Freeman</author><pubDate>Tue, 07 Jan 2025 18:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03190v2</guid></item><item><title>Multi-Scenario Reasoning: Unlocking Cognitive Autonomy in Humanoid Robots for Multimodal Understanding</title><link>http://arxiv.org/abs/2412.20429v3</link><description>To improve the cognitive autonomy of humanoid robots, this research proposesa multi-scenario reasoning architecture to solve the technical shortcomings ofmulti-modal understanding in this field. It draws on simulation basedexperimental design that adopts multi-modal synthesis (visual, auditory,tactile) and builds a simulator "Maha" to perform the experiment. The findingsdemonstrate the feasibility of this architecture in multimodal data. Itprovides reference experience for the exploration of cross-modal interactionstrategies for humanoid robots in dynamic environments. In addition,multi-scenario reasoning simulates the high-level reasoning mechanism of thehuman brain to humanoid robots at the cognitive level. This new conceptpromotes cross-scenario practical task transfer and semantic-driven actionplanning. It heralds the future development of self-learning and autonomousbehavior of humanoid robots in changing scenarios.</description><author>Libo Wang</author><pubDate>Tue, 07 Jan 2025 18:24:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.20429v3</guid></item><item><title>Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control</title><link>http://arxiv.org/abs/2409.08861v5</link><description>Dynamical generative models that produce samples through an iterativeprocess, such as Flow Matching and denoising diffusion models, have seenwidespread use, but there have not been many theoretically-sound methods forimproving these models with reward fine-tuning. In this work, we cast rewardfine-tuning as stochastic optimal control (SOC). Critically, we prove that avery specific memoryless noise schedule must be enforced during fine-tuning, inorder to account for the dependency between the noise variable and thegenerated samples. We also propose a new algorithm named Adjoint Matching whichoutperforms existing SOC algorithms, by casting SOC problems as a regressionproblem. We find that our approach significantly improves over existing methodsfor reward fine-tuning, achieving better consistency, realism, andgeneralization to unseen human preference reward models, while retaining samplediversity.</description><author>Carles Domingo-Enrich, Michal Drozdzal, Brian Karrer, Ricky T. Q. Chen</author><pubDate>Tue, 07 Jan 2025 18:12:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08861v5</guid></item><item><title>VLM-driven Behavior Tree for Context-aware Task Planning</title><link>http://arxiv.org/abs/2501.03968v1</link><description>The use of Large Language Models (LLMs) for generating Behavior Trees (BTs)has recently gained attention in the robotics community, yet remains in itsearly stages of development. In this paper, we propose a novel framework thatleverages Vision-Language Models (VLMs) to interactively generate and edit BTsthat address visual conditions, enabling context-aware robot operations invisually complex environments. A key feature of our approach lies in theconditional control through self-prompted visual conditions. Specifically, theVLM generates BTs with visual condition nodes, where conditions are expressedas free-form text. Another VLM process integrates the text into its prompt andevaluates the conditions against real-world images during robot execution. Wevalidated our framework in a real-world cafe scenario, demonstrating both itsfeasibility and limitations.</description><author>Naoki Wake, Atsushi Kanehira, Jun Takamatsu, Kazuhiro Sasabuchi, Katsushi Ikeuchi</author><pubDate>Tue, 07 Jan 2025 18:06:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03968v1</guid></item><item><title>Temporal Feature Weaving for Neonatal Echocardiographic Viewpoint Video Classification</title><link>http://arxiv.org/abs/2501.03967v1</link><description>Automated viewpoint classification in echocardiograms can helpunder-resourced clinics and hospitals in providing faster diagnosis andscreening when expert technicians may not be available. We propose a novelapproach towards echocardiographic viewpoint classification. We show thattreating viewpoint classification as video classification rather than imageclassification yields advantage. We propose a CNN-GRU architecture with a noveltemporal feature weaving method, which leverages both spatial and temporalinformation to yield a 4.33\% increase in accuracy over baseline imageclassification while using only four consecutive frames. The proposed approachincurs minimal computational overhead. Additionally, we publish the NeonatalEchocardiogram Dataset (NED), a professionally-annotated dataset providingsixteen viewpoints and associated echocardipgraphy videos to encourage futurework and development in this field. Code available at:https://github.com/satchelfrench/NED</description><author>Satchel French, Faith Zhu, Amish Jain, Naimul Khan</author><pubDate>Tue, 07 Jan 2025 18:05:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03967v1</guid></item><item><title>Unity by Diversity: Improved Representation Learning in Multimodal VAEs</title><link>http://arxiv.org/abs/2403.05300v5</link><description>Variational Autoencoders for multimodal data hold promise for many tasks indata analysis, such as representation learning, conditional generation, andimputation. Current architectures either share the encoder output, decoderinput, or both across modalities to learn a shared representation. Sucharchitectures impose hard constraints on the model. In this work, we show thata better latent representation can be obtained by replacing these hardconstraints with a soft constraint. We propose a new mixture-of-experts prior,softly guiding each modality's latent representation towards a shared aggregateposterior. This approach results in a superior latent representation and allowseach encoding to preserve information better from its uncompressed originalfeatures. In extensive experiments on multiple benchmark datasets and twochallenging real-world datasets, we show improved learned latentrepresentations and imputation of missing data modalities compared to existingmethods.</description><author>Thomas M. Sutter, Yang Meng, Andrea Agostini, DaphnÃ© Chopard, Norbert Fortin, Julia E. Vogt, Babak Shahbaba, Stephan Mandt</author><pubDate>Tue, 07 Jan 2025 17:42:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05300v5</guid></item><item><title>Vision Language Models as Values Detectors</title><link>http://arxiv.org/abs/2501.03957v1</link><description>Large Language Models integrating textual and visual inputs have introducednew possibilities for interpreting complex data. Despite their remarkableability to generate coherent and contextually relevant text based on visualstimuli, the alignment of these models with human perception in identifyingrelevant elements in images requires further exploration. This paperinvestigates the alignment between state-of-the-art LLMs and human annotatorsin detecting elements of relevance within home environment scenarios. Wecreated a set of twelve images depicting various domestic scenarios andenlisted fourteen annotators to identify the key element in each image. We thencompared these human responses with outputs from five different LLMs, includingGPT-4o and four LLaVA variants. Our findings reveal a varied degree ofalignment, with LLaVA 34B showing the highest performance but still scoringlow. However, an analysis of the results highlights the models' potential todetect value-laden elements in images, suggesting that with improved trainingand refined prompts, LLMs could enhance applications in social robotics,assistive technologies, and human-computer interaction by providing deeperinsights and more contextually relevant responses.</description><author>Giulio Antonio Abbo, Tony Belpaeme</author><pubDate>Tue, 07 Jan 2025 17:37:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03957v1</guid></item><item><title>Constrained Sampling with Primal-Dual Langevin Monte Carlo</title><link>http://arxiv.org/abs/2411.00568v2</link><description>This work considers the problem of sampling from a probability distributionknown up to a normalization constant while satisfying a set of statisticalconstraints specified by the expected values of general nonlinear functions.This problem finds applications in, e.g., Bayesian inference, where it canconstrain moments to evaluate counterfactual scenarios or enforce desideratasuch as prediction fairness. Methods developed to handle support constraints,such as those based on mirror maps, barriers, and penalties, are not suited forthis task. This work therefore relies on gradient descent-ascent dynamics inWasserstein space to put forward a discrete-time primal-dual Langevin MonteCarlo algorithm (PD-LMC) that simultaneously constrains the target distributionand samples from it. We analyze the convergence of PD-LMC under standardassumptions on the target distribution and constraints, namely (strong)convexity and log-Sobolev inequalities. To do so, we bring classicaloptimization arguments for saddle-point algorithms to the geometry ofWasserstein space. We illustrate the relevance and effectiveness of PD-LMC inseveral applications.</description><author>Luiz F. O. Chamon, Mohammad Reza Karimi, Anna Korba</author><pubDate>Tue, 07 Jan 2025 17:36:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.00568v2</guid></item><item><title>Stochastic Neural Network Symmetrisation in Markov Categories</title><link>http://arxiv.org/abs/2406.11814v4</link><description>We consider the problem of symmetrising a neural network along a grouphomomorphism: given a homomorphism $\varphi : H \to G$, we would like aprocedure that converts $H$-equivariant neural networks to $G$-equivariantones. We formulate this in terms of Markov categories, which allows us toconsider neural networks whose outputs may be stochastic, but withmeasure-theoretic details abstracted away. We obtain a flexible andcompositional framework for symmetrisation that relies on minimal assumptionsabout the structure of the group and the underlying neural networkarchitecture. Our approach recovers existing canonicalisation and averagingtechniques for symmetrising deterministic models, and extends to provide anovel methodology for symmetrising stochastic models also. Beyond this, ourfindings also demonstrate the utility of Markov categories for addressingcomplex problems in machine learning in a conceptually clear yet mathematicallyprecise way.</description><author>Rob Cornish</author><pubDate>Tue, 07 Jan 2025 17:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11814v4</guid></item><item><title>Clinical Insights: A Comprehensive Review of Language Models in Medicine</title><link>http://arxiv.org/abs/2408.11735v3</link><description>This paper explores the advancements and applications of language models inhealthcare, focusing on their clinical use cases. It examines the evolutionfrom early encoder-based systems requiring extensive fine-tuning tostate-of-the-art large language and multimodal models capable of integratingtext and visual data through in-context learning. The analysis emphasizeslocally deployable models, which enhance data privacy and operational autonomy,and their applications in tasks such as text generation, classification,information extraction, and conversational systems. The paper also highlights astructured organization of tasks and a tiered ethical approach, providing avaluable resource for researchers and practitioners, while discussing keychallenges related to ethics, evaluation, and implementation.</description><author>Nikita Neveditsin, Pawan Lingras, Vijay Mago</author><pubDate>Tue, 07 Jan 2025 17:34:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11735v3</guid></item><item><title>Follow The Approximate Sparse Leader for No-Regret Online Sparse Linear Approximation</title><link>http://arxiv.org/abs/2501.00799v2</link><description>We consider the problem of \textit{online sparse linear approximation}, whereone predicts the best sparse approximation of a sequence of measurements interms of linear combination of columns of a given measurement matrix. Suchonline prediction problems are ubiquitous, ranging from medical trials to webcaching to resource allocation. The inherent difficulty of offline recoveryalso makes the online problem challenging. In this letter, we proposeFollow-The-Approximate-Sparse-Leader, an efficient online meta-policy toaddress this online problem. Through a detailed theoretical analysis, we provethat under certain assumptions on the measurement sequence, the proposed policyenjoys a data-dependent sublinear upper bound on the static regret, which canrange from logarithmic to square-root. Numerical simulations are performed tocorroborate the theoretical findings and demonstrate the efficacy of theproposed online policy.</description><author>Samrat Mukhopadhyay, Debasmita Mukherjee</author><pubDate>Tue, 07 Jan 2025 17:32:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00799v2</guid></item><item><title>AtMan: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation</title><link>http://arxiv.org/abs/2301.08110v6</link><description>Generative transformer models have become increasingly complex, with largenumbers of parameters and the ability to process multiple input modalities.Current methods for explaining their predictions are resource-intensive. Mostcrucially, they require prohibitively large amounts of extra memory, since theyrely on backpropagation which allocates almost twice as much GPU memory as theforward pass. This makes it difficult, if not impossible, to use them inproduction. We present AtMan that provides explanations of generativetransformer models at almost no extra cost. Specifically, AtMan is amodality-agnostic perturbation method that manipulates the attention mechanismsof transformers to produce relevance maps for the input with respect to theoutput prediction. Instead of using backpropagation, AtMan applies aparallelizable token-based search method based on cosine similarityneighborhood in the embedding space. Our exhaustive experiments on text andimage-text benchmarks demonstrate that AtMan outperforms currentstate-of-the-art gradient-based methods on several metrics while beingcomputationally efficient. As such, AtMan is suitable for use in large modelinference deployments.</description><author>BjÃ¶rn Deiseroth, Mayukh Deb, Samuel Weinbach, Manuel Brack, Patrick Schramowski, Kristian Kersting</author><pubDate>Tue, 07 Jan 2025 17:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08110v6</guid></item><item><title>Localizing AI: Evaluating Open-Weight Language Models for Languages of Baltic States</title><link>http://arxiv.org/abs/2501.03952v1</link><description>Although large language models (LLMs) have transformed our expectations ofmodern language technologies, concerns over data privacy often restrict the useof commercially available LLMs hosted outside of EU jurisdictions. This limitstheir application in governmental, defence, and other data-sensitive sectors.In this work, we evaluate the extent to which locally deployable open-weightLLMs support lesser-spoken languages such as Lithuanian, Latvian, and Estonian.We examine various size and precision variants of the top-performingmultilingual open-weight models, Llama~3, Gemma~2, Phi, and NeMo, on machinetranslation, multiple-choice question answering, and free-form text generation.The results indicate that while certain models like Gemma~2 perform close tothe top commercially available models, many LLMs struggle with these languages.Most surprisingly, however, we find that these models, while showing close tostate-of-the-art translation performance, are still prone to lexicalhallucinations with errors in at least 1 in 20 words for all open-weightmultilingual LLMs.</description><author>Jurgita KapoÄiÅ«tÄ-DzikienÄ, Toms Bergmanis, MÄrcis Pinnis</author><pubDate>Tue, 07 Jan 2025 17:24:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03952v1</guid></item><item><title>Probability-density-aware Semi-supervised Learning</title><link>http://arxiv.org/abs/2412.17547v2</link><description>Semi-supervised learning (SSL) assumes that neighbor points lie in the samecategory (neighbor assumption), and points in different clusters belong tovarious categories (cluster assumption). Existing methods usually rely onsimilarity measures to retrieve the similar neighbor points, ignoring clusterassumption, which may not utilize unlabeled information sufficiently andeffectively. This paper first provides a systematical investigation into thesignificant role of probability density in SSL and lays a solid theoreticalfoundation for cluster assumption. To this end, we introduce aProbability-Density-Aware Measure (PM) to discern the similarity betweenneighbor points. To further improve Label Propagation, we also design aProbability-Density-Aware Measure Label Propagation (PMLP) algorithm to fullyconsider the cluster assumption in label propagation. Last but not least, weprove that traditional pseudo-labeling could be viewed as a particular case ofPMLP, which provides a comprehensive theoretical understanding of PMLP'ssuperior performance. Extensive experiments demonstrate that PMLP achievesoutstanding performance compared with other recent methods.</description><author>Shuyang Liu, Ruiqiu Zheng, Yunhang Shen, Ke Li, Xing Sun, Zhou Yu, Shaohui Lin</author><pubDate>Tue, 07 Jan 2025 17:23:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17547v2</guid></item><item><title>A GPU Implementation of Multi-Guiding Spark Fireworks Algorithm for Efficient Black-Box Neural Network Optimization</title><link>http://arxiv.org/abs/2501.03944v1</link><description>Swarm intelligence optimization algorithms have gained significant attentiondue to their ability to solve complex optimization problems. However, theefficiency of optimization in large-scale problems limits the use of relatedmethods. This paper presents a GPU-accelerated version of the Multi-GuidingSpark Fireworks Algorithm (MGFWA), which significantly improves thecomputational efficiency compared to its traditional CPU-based counterpart. Webenchmark the GPU-MGFWA on several neural network black-box optimizationproblems and demonstrate its superior performance in terms of both speed andsolution quality. By leveraging the parallel processing power of modern GPUs,the proposed GPU-MGFWA results in faster convergence and reduced computationtime for large-scale optimization tasks. The proposed implementation offers apromising approach to accelerate swarm intelligence algorithms, making themmore suitable for real-time applications and large-scale industrial problems.Source code is released at https://github.com/mxxxr/MGFWA.</description><author>Xiangrui Meng, Ying Tan</author><pubDate>Tue, 07 Jan 2025 17:09:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03944v1</guid></item><item><title>Statistical Error Bounds for GANs with Nonlinear Objective Functionals</title><link>http://arxiv.org/abs/2406.16834v2</link><description>Generative adversarial networks (GANs) are unsupervised learning methods fortraining a generator distribution to produce samples that approximate thosedrawn from a target distribution. Many such methods can be formulated asminimization of a metric or divergence between probability distributions.Recent works have derived statistical error bounds for GANs that are based onintegral probability metrics (IPMs), e.g., WGAN which is based on the1-Wasserstein metric. In general, IPMs are defined by optimizing a linearfunctional (difference of expectations) over a space of discriminators. A muchlarger class of GANs, which we here call $(f,\Gamma)$-GANs, can be constructedusing $f$-divergences (e.g., Jensen-Shannon, KL, or $\alpha$-divergences)together with a regularizing discriminator space $\Gamma$ (e.g., $1$-Lipschitzfunctions). These GANs have nonlinear objective functions, depending on thechoice of $f$, and have been shown to exhibit improved performance in a numberof applications. In this work we derive statistical error bounds for$(f,\Gamma)$-GANs for general classes of $f$ and $\Gamma$ in the form offinite-sample concentration inequalities. These results prove the statisticalconsistency of $(f,\Gamma)$-GANs and reduce to the known results for IPM-GANsin the appropriate limit. Finally, our results also give new insight into theperformance of GANs for distributions with unbounded support.</description><author>Jeremiah Birrell</author><pubDate>Tue, 07 Jan 2025 17:05:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16834v2</guid></item><item><title>Synthetic Data Privacy Metrics</title><link>http://arxiv.org/abs/2501.03941v1</link><description>Recent advancements in generative AI have made it possible to createsynthetic datasets that can be as accurate as real-world data for training AImodels, powering statistical insights, and fostering collaboration withsensitive datasets while offering strong privacy guarantees. Effectivelymeasuring the empirical privacy of synthetic data is an important step in theprocess. However, while there is a multitude of new privacy metrics beingpublished every day, there currently is no standardization. In this paper, wereview the pros and cons of popular metrics that include simulations ofadversarial attacks. We also review current best practices for amendinggenerative models to enhance the privacy of the data they create (e.g.differential privacy).</description><author>Amy Steier, Lipika Ramaswamy, Andre Manoel, Alexa Haushalter</author><pubDate>Tue, 07 Jan 2025 17:02:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03941v1</guid></item><item><title>Not all tokens are created equal: Perplexity Attention Weighted Networks for AI generated text detection</title><link>http://arxiv.org/abs/2501.03940v1</link><description>The rapid advancement in large language models (LLMs) has significantlyenhanced their ability to generate coherent and contextually relevant text,raising concerns about the misuse of AI-generated content and making itcritical to detect it. However, the task remains challenging, particularly inunseen domains or with unfamiliar LLMs. Leveraging LLM next-token distributionoutputs offers a theoretically appealing approach for detection, as theyencapsulate insights from the models' extensive pre-training on diversecorpora. Despite its promise, zero-shot methods that attempt to operationalizethese outputs have met with limited success. We hypothesize that one of theproblems is that they use the mean to aggregate next-token distribution metricsacross tokens, when some tokens are naturally easier or harder to predict andshould be weighted differently. Based on this idea, we propose the PerplexityAttention Weighted Network (PAWN), which uses the last hidden states of the LLMand positions to weight the sum of a series of features based on metrics fromthe next-token distribution across the sequence length. Although not zero-shot,our method allows us to cache the last hidden states and next-tokendistribution metrics on disk, greatly reducing the training resourcerequirements. PAWN shows competitive and even better performancein-distribution than the strongest baselines (fine-tuned LMs) with a fractionof their trainable parameters. Our model also generalizes better to unseendomains and source models, with smaller variability in the decision boundaryacross distribution shifts. It is also more robust to adversarial attacks, andif the backbone has multilingual capabilities, it presents decentgeneralization to languages not seen during supervised training, with LLaMA3-1Breaching a mean macro-averaged F1 score of 81.46% in cross-validation with ninelanguages.</description><author>Pablo Miralles-GonzÃ¡lez, Javier Huertas-Tato, Alejandro MartÃ­n, David Camacho</author><pubDate>Tue, 07 Jan 2025 17:00:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03940v1</guid></item><item><title>Vim-F: Visual State Space Model Benefiting from Learning in the Frequency Domain</title><link>http://arxiv.org/abs/2405.18679v2</link><description>In recent years, State Space Models (SSMs) with efficient hardware-awaredesigns, known as the Mamba deep learning models, have made significantprogress in modeling long sequences such as language understanding. Therefore,building efficient and general-purpose visual backbones based on SSMs is apromising direction. Compared to traditional convolutional neural networks(CNNs) and Vision Transformers (ViTs), the performance of Vision Mamba (ViM)methods is not yet fully competitive. To enable SSMs to process image data,ViMs typically flatten 2D images into 1D sequences, inevitably ignoring some 2Dlocal dependencies, thereby weakening the model's ability to interpret spatialrelationships from a global perspective. We use Fast Fourier Transform (FFT) toobtain the spectrum of the feature map and add it to the original feature map,enabling ViM to model a unified visual representation in both frequency andspatial domains. The introduction of frequency domain information enables ViMto have a global receptive field during scanning. We propose a novel modelcalled Vim-F, which employs pure Mamba encoders and scans in both the frequencyand spatial domains. Moreover, we question the necessity of position embeddingin ViM and remove it accordingly in Vim-F, which helps to fully utilize theefficient long-sequence modeling capability of ViM. Finally, we redesign apatch embedding for Vim-F, leveraging a convolutional stem to capture morelocal correlations, further improving the performance of Vim-F. Code isavailable at: \url{https://github.com/yws-wxs/Vim-F}.</description><author>Juntao Zhang, Shaogeng Liu, Kun Bian, You Zhou, Pei Zhang, Wenbo An, Jun Zhou, Kun Shao</author><pubDate>Tue, 07 Jan 2025 17:00:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18679v2</guid></item><item><title>Visual question answering: from early developments to recent advances -- a survey</title><link>http://arxiv.org/abs/2501.03939v1</link><description>Visual Question Answering (VQA) is an evolving research field aimed atenabling machines to answer questions about visual content by integrating imageand language processing techniques such as feature extraction, objectdetection, text embedding, natural language understanding, and languagegeneration. With the growth of multimodal data research, VQA has gainedsignificant attention due to its broad applications, including interactiveeducational tools, medical image diagnosis, customer service, entertainment,and social media captioning. Additionally, VQA plays a vital role in assistingvisually impaired individuals by generating descriptive content from images.This survey introduces a taxonomy of VQA architectures, categorizing them basedon design choices and key components to facilitate comparative analysis andevaluation. We review major VQA approaches, focusing on deep learning-basedmethods, and explore the emerging field of Large Visual Language Models (LVLMs)that have demonstrated success in multimodal tasks like VQA. The paper furtherexamines available datasets and evaluation metrics essential for measuring VQAsystem performance, followed by an exploration of real-world VQA applications.Finally, we highlight ongoing challenges and future directions in VQA research,presenting open questions and potential areas for further development. Thissurvey serves as a comprehensive resource for researchers and practitionersinterested in the latest advancements and future</description><author>Ngoc Dung Huynh, Mohamed Reda Bouadjenek, Sunil Aryal, Imran Razzak, Hakim Hacid</author><pubDate>Tue, 07 Jan 2025 17:00:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03939v1</guid></item><item><title>Scaling Efficient LLMs</title><link>http://arxiv.org/abs/2402.14746v3</link><description>Trained LLMs are typically sparse in that most of the parameters are zero,raising questions on efficiency. In response, we inquire into efficient LLMs,i.e. those with the fewest parameters that achieve the desired accuracy on atraining corpus. Specifically, we compare theoretical and empirical estimatesfor training loss to obtain upper and lower bounds on the number of uniquesequences in a natural training corpus as a function of its size. Our resultimplies (1) to double the number of skills represented in a training corpus,the corpus must scale more than four fold (2) for efficient LLMs, the number ofparameters N and the size D of a natural training corpus scale as $N \proptoD^{0.44}$; (3) if the number of parameters of an LLM is smaller than the numberof unique sequences in the training corpus, scaling up can uncover emergentskills.</description><author>B. N. Kausik</author><pubDate>Tue, 07 Jan 2025 16:58:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14746v3</guid></item><item><title>A precise asymptotic analysis of learning diffusion models: theory and insights</title><link>http://arxiv.org/abs/2501.03937v1</link><description>In this manuscript, we consider the problem of learning a flow ordiffusion-based generative model parametrized by a two-layer auto-encoder,trained with online stochastic gradient descent, on a high-dimensional targetdensity with an underlying low-dimensional manifold structure. We derive atight asymptotic characterization of low-dimensional projections of thedistribution of samples generated by the learned model, ascertaining inparticular its dependence on the number of training samples. Building on thisanalysis, we discuss how mode collapse can arise, and lead to model collapsewhen the generative model is re-trained on generated synthetic data.</description><author>Hugo Cui, Cengiz Pehlevan, Yue M. Lu</author><pubDate>Tue, 07 Jan 2025 16:56:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03937v1</guid></item><item><title>PPTAgent: Generating and Evaluating Presentations Beyond Text-to-Slides</title><link>http://arxiv.org/abs/2501.03936v1</link><description>Automatically generating presentations from documents is a challenging taskthat requires balancing content quality, visual design, and structuralcoherence. Existing methods primarily focus on improving and evaluating thecontent quality in isolation, often overlooking visual design and structuralcoherence, which limits their practical applicability. To address theselimitations, we propose PPTAgent, which comprehensively improves presentationgeneration through a two-stage, edit-based approach inspired by humanworkflows. PPTAgent first analyzes reference presentations to understand theirstructural patterns and content schemas, then drafts outlines and generatesslides through code actions to ensure consistency and alignment. Tocomprehensively evaluate the quality of generated presentations, we furtherintroduce PPTEval, an evaluation framework that assesses presentations acrossthree dimensions: Content, Design, and Coherence. Experiments show thatPPTAgent significantly outperforms traditional automatic presentationgeneration methods across all three dimensions. The code and data are availableat https://github.com/icip-cas/PPTAgent.</description><author>Hao Zheng, Xinyan Guan, Hao Kong, Jia Zheng, Hongyu Lin, Yaojie Lu, Ben He, Xianpei Han, Le Sun</author><pubDate>Tue, 07 Jan 2025 16:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03936v1</guid></item><item><title>Gaussian Building Mesh (GBM): Extract a Building's 3D Mesh with Google Earth and Gaussian Splatting</title><link>http://arxiv.org/abs/2501.00625v2</link><description>Recently released open-source pre-trained foundational image segmentation andobject detection models (SAM2+GroundingDINO) allow for geometrically consistentsegmentation of objects of interest in multi-view 2D images. Users can usetext-based or click-based prompts to segment objects of interest withoutrequiring labeled training datasets. Gaussian Splatting allows for the learningof the 3D representation of a scene's geometry and radiance based on 2D images.Combining Google Earth Studio, SAM2+GroundingDINO, 2D Gaussian Splatting, andour improvements in mask refinement based on morphological operations andcontour simplification, we created a pipeline to extract the 3D mesh of anybuilding based on its name, address, or geographic coordinates.</description><author>Kyle Gao, Liangzhi Li, Hongjie He, Dening Lu, Linlin Xu, Jonathan Li</author><pubDate>Tue, 07 Jan 2025 16:49:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00625v2</guid></item><item><title>CoStruction: Conjoint radiance field optimization for urban scene reconStruction with limited image overlap</title><link>http://arxiv.org/abs/2501.03932v1</link><description>Reconstructing the surrounding surface geometry from recorded drivingsequences poses a significant challenge due to the limited image overlap andcomplex topology of urban environments. SoTA neural implicit surfacereconstruction methods often struggle in such setting, either failing due tosmall vision overlap or exhibiting suboptimal performance in accuratelyreconstructing both the surface and fine structures. To address theselimitations, we introduce CoStruction, a novel hybrid implicit surfacereconstruction method tailored for large driving sequences with limited cameraoverlap. CoStruction leverages cross-representation uncertainty estimation tofilter out ambiguous geometry caused by limited observations. Our methodperforms joint optimization of both radiance fields in addition to guidedsampling achieving accurate reconstruction of large areas along with finestructures in complex urban scenarios. Extensive evaluation on major drivingdatasets demonstrates the superiority of our approach in reconstructing largedriving sequences with limited image overlap, outperforming concurrent SoTAmethods.</description><author>Fusang Wang, Hala Djeghim, Nathan Piasco, Moussab Bennehar, Luis RoldÃ£o, Dzmitry Tsishkou</author><pubDate>Tue, 07 Jan 2025 16:48:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03932v1</guid></item><item><title>Information Extraction from Clinical Notes: Are We Ready to Switch to Large Language Models?</title><link>http://arxiv.org/abs/2411.10020v4</link><description>Backgrounds: Information extraction (IE) is critical in clinical naturallanguage processing (NLP). While large language models (LLMs) excel ongenerative tasks, their performance on extractive tasks remains debated.Methods: We investigated Named Entity Recognition (NER) and Relation Extraction(RE) using 1,588 clinical notes from four sources (UT Physicians, MTSamples,MIMIC-III, and i2b2). We developed an annotated corpus covering 4 clinicalentities and 16 modifiers, and compared instruction-tuned LLaMA-2 and LLaMA-3against BERT in terms of performance, generalizability, computationalresources, and throughput to BERT. Results: LLaMA models outperformed BERTacross datasets. With sufficient training data, LLaMA showed modestimprovements (1% on NER, 1.5-3.7% on RE); improvements were larger with limitedtraining data. On unseen i2b2 data, LLaMA-3-70B outperformed BERT by 7% (F1) onNER and 4% on RE. However, LLaMA models required more computing resources andran up to 28 times slower. We implemented "Kiwi," a clinical IE packagefeaturing both models, available at https://kiwi.clinicalnlp.org/. Conclusion:This study is among the first to develop and evaluate a comprehensive clinicalIE system using open-source LLMs. Results indicate that LLaMA models outperformBERT for clinical NER and RE but with higher computational costs and lowerthroughputs. These findings highlight that choosing between LLMs andtraditional deep learning methods for clinical IE applications should remaintask-specific, taking into account both performance metrics and practicalconsiderations such as available computing resources and the intended use casescenarios.</description><author>Yan Hu, Xu Zuo, Yujia Zhou, Xueqing Peng, Jimin Huang, Vipina K. Keloth, Vincent J. Zhang, Ruey-Ling Weng, Qingyu Chen, Xiaoqian Jiang, Kirk E. Roberts, Hua Xu</author><pubDate>Tue, 07 Jan 2025 16:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10020v4</guid></item><item><title>Magic Mirror: ID-Preserved Video Generation in Video Diffusion Transformers</title><link>http://arxiv.org/abs/2501.03931v1</link><description>We present Magic Mirror, a framework for generating identity-preserved videoswith cinematic-level quality and dynamic motion. While recent advances in videodiffusion models have shown impressive capabilities in text-to-videogeneration, maintaining consistent identity while producing natural motionremains challenging. Previous methods either require person-specificfine-tuning or struggle to balance identity preservation with motion diversity.Built upon Video Diffusion Transformers, our method introduces three keycomponents: (1) a dual-branch facial feature extractor that captures bothidentity and structural features, (2) a lightweight cross-modal adapter withConditioned Adaptive Normalization for efficient identity integration, and (3)a two-stage training strategy combining synthetic identity pairs with videodata. Extensive experiments demonstrate that Magic Mirror effectively balancesidentity consistency with natural motion, outperforming existing methods acrossmultiple metrics while requiring minimal parameters added. The code and modelwill be made publicly available at:https://github.com/dvlab-research/MagicMirror/</description><author>Yuechen Zhang, Yaoyang Liu, Bin Xia, Bohao Peng, Zexin Yan, Eric Lo, Jiaya Jia</author><pubDate>Tue, 07 Jan 2025 16:48:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03931v1</guid></item><item><title>From Newswire to Nexus: Using text-based actor embeddings and transformer networks to forecast conflict dynamics</title><link>http://arxiv.org/abs/2501.03928v1</link><description>This study advances the field of conflict forecasting by using text-basedactor embeddings with transformer models to predict dynamic changes in violentconflict patterns at the actor level. More specifically, we combine newswiretexts with structured conflict event data and leverage recent advances inNatural Language Processing (NLP) techniques to forecast escalations andde-escalations among conflicting actors, such as governments, militias,separatist movements, and terrorists. This new approach accurately and promptlycaptures the inherently volatile patterns of violent conflicts, which existingmethods have not been able to achieve. To create this framework, we began bycurating and annotating a vast international newswire corpus, leveraginghand-labeled event data from the Uppsala Conflict Data Program. By using thishybrid dataset, our models can incorporate the textual context of news sourcesalong with the precision and detail of structured event data. This combinationenables us to make both dynamic and granular predictions about conflictdevelopments. We validate our approach through rigorous back-testing againsthistorical events, demonstrating superior out-of-sample predictive power. Wefind that our approach is quite effective in identifying and predicting phasesof conflict escalation and de-escalation, surpassing the capabilities oftraditional models. By focusing on actor interactions, our explicit goal is toprovide actionable insights to policymakers, humanitarian organizations, andpeacekeeping operations in order to enable targeted and effective interventionstrategies.</description><author>Mihai Croicu, Simon Polichinel von der Maase</author><pubDate>Tue, 07 Jan 2025 16:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03928v1</guid></item><item><title>Explainable AI model reveals disease-related mechanisms in single-cell RNA-seq data</title><link>http://arxiv.org/abs/2501.03923v1</link><description>Neurodegenerative diseases (NDDs) are complex and lack effective treatmentdue to their poorly understood mechanism. The increasingly used data analysisfrom Single nucleus RNA Sequencing (snRNA-seq) allows to explore transcriptomicevents at a single cell level, yet face challenges in interpreting themechanisms underlying a disease. On the other hand, Neural Network (NN) modelscan handle complex data to offer insights but can be seen as black boxes withpoor interpretability. In this context, explainable AI (XAI) emerges as asolution that could help to understand disease-associated mechanisms whencombined with efficient NN models. However, limited research explores XAI insingle-cell data. In this work, we implement a method for identifyingdisease-related genes and the mechanistic explanation of disease progressionbased on NN model combined with SHAP. We analyze available Huntington's disease(HD) data to identify both HD-altered genes and mechanisms by adding Gene SetEnrichment Analysis (GSEA) comparing two methods, differential gene expressionanalysis (DGE) and NN combined with SHAP approach. Our results show that DGEand SHAP approaches offer both common and differential sets of altered genesand pathways, reinforcing the usefulness of XAI methods for a broaderperspective of disease.</description><author>Mohammad Usman, Olga Varea, Petia Radeva, Josep Canals, Jordi Abante, Daniel Ortiz</author><pubDate>Tue, 07 Jan 2025 16:35:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03923v1</guid></item><item><title>Cosmological Parameter Estimation with Sequential Linear Simulation-based Inference</title><link>http://arxiv.org/abs/2501.03921v1</link><description>We develop the framework of Linear Simulation-based Inference (LSBI), anapplication of simulation-based inference where the likelihood is approximatedby a Gaussian linear function of its parameters. We obtain analyticalexpressions for the posterior distributions of hyper-parameters of the linearlikelihood in terms of samples drawn from a simulator, for both uniform andconjugate priors. This method is applied sequentially to several toy-models andtested on emulated datasets for the Cosmic Microwave Background temperaturepower spectrum. We find that convergence is achieved after four or five roundsof $\mathcal{O}(10^4)$ simulations, which is competitive with state-of-the-artneural density estimation methods. Therefore, we demonstrate that it ispossible to obtain significant information gain and generate posteriors thatagree with the underlying parameters while maintaining explainability andintellectual oversight.</description><author>Nicolas Mediato-Diaz, Will Handley</author><pubDate>Tue, 07 Jan 2025 16:34:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03921v1</guid></item><item><title>Exploring Federated Unlearning: Analysis, Comparison, and Insights</title><link>http://arxiv.org/abs/2310.19218v4</link><description>The increasing demand for privacy-preserving machine learning has spurredinterest in federated unlearning, which enables the selective removal of datafrom models trained in federated systems. However, developing federatedunlearning methods presents challenges, particularly in balancing three oftenconflicting objectives: privacy, accuracy, and efficiency. This paper providesa comprehensive analysis of existing federated unlearning approaches, examiningtheir algorithmic efficiency, impact on model accuracy, and effectiveness inpreserving privacy. We discuss key trade-offs among these dimensions andhighlight their implications for practical applications across various domains.Additionally, we propose the OpenFederatedUnlearning framework, a unifiedbenchmark for evaluating federated unlearning methods, incorporating classicbaselines and diverse performance metrics. Our findings aim to guidepractitioners in navigating the complex interplay of these objectives, offeringinsights to achieve effective and efficient federated unlearning. Finally, weoutline directions for future research to further advance the state offederated unlearning techniques.</description><author>Yang Zhao, Jiaxi Yang, Yiling Tao, Lixu Wang, Xiaoxiao Li, Dusit Niyato, H. Vincent Poor</author><pubDate>Tue, 07 Jan 2025 16:31:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19218v4</guid></item><item><title>Dolphin: Closed-loop Open-ended Auto-research through Thinking, Practice, and Feedback</title><link>http://arxiv.org/abs/2501.03916v1</link><description>The scientific research paradigm is undergoing a profound transformationowing to the development of Artificial Intelligence (AI). Recent worksdemonstrate that various AI-assisted research methods can largely improveresearch efficiency by improving data analysis, accelerating computation, andfostering novel idea generation. To further move towards the ultimate goal(i.e., automatic scientific research), in this paper, we propose Dolphin, thefirst closed-loop open-ended auto-research framework to further build theentire process of human scientific research. Dolphin can generate researchideas, perform experiments, and get feedback from experimental results togenerate higher-quality ideas. More specifically, Dolphin first generates novelideas based on relevant papers which are ranked by the topic and taskattributes. Then, the codes are automatically generated and debugged with theexception-traceback-guided local code structure. Finally, Dolphin automaticallyanalyzes the results of each idea and feeds the results back to the next roundof idea generation. Experiments are conducted on the benchmark datasets ofdifferent topics and results show that Dolphin can generate novel ideascontinuously and complete the experiment in a loop. We highlight that Dolphincan automatically propose methods that are comparable to the state-of-the-artin some tasks such as 2D image classification and 3D point classification.</description><author>Jiakang Yuan, Xiangchao Yan, Botian Shi, Tao Chen, Wanli Ouyang, Bo Zhang, Lei Bai, Yu Qiao, Bowen Zhou</author><pubDate>Tue, 07 Jan 2025 16:31:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03916v1</guid></item><item><title>HYB-VITON: A Hybrid Approach to Virtual Try-On Combining Explicit and Implicit Warping</title><link>http://arxiv.org/abs/2501.03910v1</link><description>Virtual try-on systems have significant potential in e-commerce, allowingcustomers to visualize garments on themselves. Existing image-based methodsfall into two categories: those that directly warp garment-images ontoperson-images (explicit warping), and those using cross-attention toreconstruct given garments (implicit warping). Explicit warping preservesgarment details but often produces unrealistic output, while implicit warpingachieves natural reconstruction but struggles with fine details. We proposeHYB-VITON, a novel approach that combines the advantages of each method andincludes both a preprocessing pipeline for warped garments and a novel trainingoption. These components allow us to utilize beneficial regions of explicitlywarped garments while leveraging the natural reconstruction of implicitwarping. A series of experiments demonstrates that HYB-VITON preserves garmentdetails more faithfully than recent diffusion-based methods, while producingmore realistic results than a state-of-the-art explicit warping method.</description><author>Kosuke Takemoto, Takafumi Koshinaka</author><pubDate>Tue, 07 Jan 2025 16:24:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03910v1</guid></item><item><title>T-FREE: Subword Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings</title><link>http://arxiv.org/abs/2406.19223v2</link><description>Tokenizers are crucial for encoding information in Large Language Models, buttheir development has recently stagnated, and they contain inherent weaknesses.Major limitations include computational overhead, ineffective vocabulary use,and unnecessarily large embedding and head layers. Additionally, theirperformance is biased towards a reference corpus, leading to reducedeffectiveness for underrepresented languages. To remedy these issues, we propose T-FREE, which directly embeds wordsthrough sparse activation patterns over character triplets, and does notrequire a reference corpus. T-FREE inherently exploits morphologicalsimilarities and allows for strong compression of embedding layers. In ourexhaustive experimental evaluation, we achieve competitive downstreamperformance with a parameter reduction of more than 85% on these layers.Further, T-FREE shows significant improvements in cross-lingual transferlearning.</description><author>BjÃ¶rn Deiseroth, Manuel Brack, Patrick Schramowski, Kristian Kersting, Samuel Weinbach</author><pubDate>Tue, 07 Jan 2025 16:20:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19223v2</guid></item><item><title>mFabric: An Efficient and Scalable Fabric for Mixture-of-Experts Training</title><link>http://arxiv.org/abs/2501.03905v1</link><description>Mixture-of-Expert (MoE) models outperform conventional models by selectivelyactivating different subnets, named \emph{experts}, on a per-token basis. Thisgated computation generates dynamic communications that cannot be determinedbeforehand, challenging the existing GPU interconnects that remain\emph{static} during the distributed training process. In this paper, weadvocate for a first-of-its-kind system, called mFabric, that unlocks topologyreconfiguration \emph{during} distributed MoE training. Towards this vision, wefirst perform a production measurement study and show that the MoE dynamiccommunication pattern has \emph{strong locality}, alleviating the requirementof global reconfiguration. Based on this, we design and implement a\emph{regionally reconfigurable high-bandwidth domain} on top of existingelectrical interconnects using optical circuit switching (OCS), achievingscalability while maintaining rapid adaptability. We have built a fullyfunctional mFabric prototype with commodity hardware and a customizedcollective communication runtime that trains state-of-the-art MoE models with\emph{in-training} topology reconfiguration across 32 A100 GPUs. Large-scalepacket-level simulations show that mFabric delivers comparable performance asthe non-blocking fat-tree fabric while boosting the training cost efficiency(e.g., performance per dollar) of four representative MoE models by1.2$\times$--1.5$\times$ and 1.9$\times$--2.3$\times$ at 100 Gbps and 400 Gbpslink bandwidths, respectively.</description><author>Xudong Liao, Yijun Sun, Han Tian, Xinchen Wan, Yilun Jin, Zilong Wang, Zhenghang Ren, Xinyang Huang, Wenxue Li, Kin Fai Tse, Zhizhen Zhong, Guyue Liu, Ying Zhang, Xiaofeng Ye, Yiming Zhang, Kai Chen</author><pubDate>Tue, 07 Jan 2025 16:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03905v1</guid></item><item><title>Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study</title><link>http://arxiv.org/abs/2501.03904v1</link><description>The integration of large language models (LLMs) into public transit systemspresents a transformative opportunity to enhance urban mobility. This studyexplores the potential of LLMs to revolutionize public transportationmanagement within the context of San Antonio's transit system. Leveraging thecapabilities of LLMs in natural language processing and data analysis, weinvestigate their capabilities to optimize route planning, reduce wait times,and provide personalized travel assistance. By utilizing the General TransitFeed Specification (GTFS) and other relevant data, this research aims todemonstrate how LLMs can potentially improve resource allocation, elevatepassenger satisfaction, and inform data-driven decision-making in transitoperations. A comparative analysis of different ChatGPT models was conducted toassess their ability to understand transportation information, retrieverelevant data, and provide comprehensive responses. Findings from this studysuggest that while LLMs hold immense promise for public transit, carefulengineering and fine-tuning are essential to realizing their full potential.San Antonio serves as a case study to inform the development of LLM-poweredtransit systems in other urban environments.</description><author>Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi</author><pubDate>Tue, 07 Jan 2025 16:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03904v1</guid></item><item><title>LMS-AutoTSF: Learnable Multi-Scale Decomposition and Integrated Autocorrelation for Time Series Forecasting</title><link>http://arxiv.org/abs/2412.06866v3</link><description>Time series forecasting is an important challenge with significantapplications in areas such as weather prediction, stock market analysis,scientific simulations and industrial process analysis. In this work, weintroduce LMS-AutoTSF, a novel time series forecasting architecture thatincorporates autocorrelation while leveraging dual encoders operating atmultiple scales. Unlike models that rely on predefined trend and seasonalcomponents, LMS-AutoTSF employs two separate encoders per scale: one focusingon low-pass filtering to capture trends and the other utilizing high-passfiltering to model seasonal variations. These filters are learnable, allowingthe model to dynamically adapt and isolate trend and seasonal componentsdirectly in the frequency domain. A key innovation in our approach is theintegration of autocorrelation, achieved by computing lagged differences intime steps, which enables the model to capture dependencies across time moreeffectively. Each encoder processes the input through fully connected layers tohandle temporal and channel interactions. By combining frequency-domainfiltering, autocorrelation-based temporal modeling, and channel-wisetransformations, LMS-AutoTSF not only accurately captures long-termdependencies and fine-grained patterns but also operates more efficientlycompared to other state-of-the-art methods. Its lightweight design ensuresfaster processing while maintaining high precision in forecasting acrossdiverse time horizons. The source code is publicly available at\url{http://github.com/mribrahim/LMS-TSF}</description><author>Ibrahim Delibasoglu, Sanjay Chakraborty, Fredrik Heintz</author><pubDate>Tue, 07 Jan 2025 16:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06866v3</guid></item><item><title>Two-Layer Retrieval-Augmented Generation Framework for Low-Resource Medical Question Answering Using Reddit Data: Proof-of-Concept Study</title><link>http://arxiv.org/abs/2405.19519v2</link><description>The increasing use of social media to share lived and living experiences ofsubstance use presents a unique opportunity to obtain information on sideeffects, use patterns, and opinions on novel psychoactive substances. However,due to the large volume of data, obtaining useful insights through naturallanguage processing technologies such as large language models is challenging.This paper aims to develop a retrieval-augmented generation (RAG) architecturefor medical question answering pertaining to clinicians' queries on emergingissues associated with health-related topics, using user-generated medicalinformation on social media. We proposed a two-layer RAG framework forquery-focused answer generation and evaluated a proof of concept for theframework in the context of query-focused summary generation from social mediaforums, focusing on emerging drug-related information. Our modular frameworkgenerates individual summaries followed by an aggregated summary to answermedical queries from large amounts of user-generated social media data in anefficient manner. We compared the performance of a quantized large languagemodel (Nous-Hermes-2-7B-DPO), deployable in low-resource settings, with GPT-4.For this proof-of-concept study, we used user-generated data from Reddit toanswer clinicians' questions on the use of xylazine and ketamine. Our frameworkachieves comparable median scores in terms of relevance, length, hallucination,coverage, and coherence when evaluated using GPT-4 and Nous-Hermes-2-7B-DPO,evaluated for 20 queries with 76 samples. There was no statisticallysignificant difference between the two for coverage, coherence, relevance,length, and hallucination. A statistically significant difference was noted forthe Coleman-Liau Index. Our RAG framework can effectively answer medicalquestions about targeted topics and can be deployed in resource-constrainedsettings.</description><author>Sudeshna Das, Yao Ge, Yuting Guo, Swati Rajwal, JaMor Hairston, Jeanne Powell, Drew Walker, Snigdha Peddireddy, Sahithi Lakamana, Selen Bozkurt, Matthew Reyna, Reza Sameni, Yunyu Xiao, Sangmi Kim, Rasheeta Chandler, Natalie Hernandez, Danielle Mowery, Rachel Wightman, Jennifer Love, Anthony Spadaro, Jeanmarie Perrone, Abeed Sarker</author><pubDate>Tue, 07 Jan 2025 16:13:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19519v2</guid></item><item><title>Koopman Learning with Episodic Memory</title><link>http://arxiv.org/abs/2311.12615v3</link><description>Koopman operator theory has found significant success in learning models ofcomplex, real-world dynamical systems, enabling prediction and control. Thegreater interpretability and lower computational costs of these models,compared to traditional machine learning methodologies, make Koopman learningan especially appealing approach. Despite this, little work has been performedon endowing Koopman learning with the ability to leverage its own failures. Toaddress this, we equip Koopman methods -- developed for predictingnon-autonomous time-series -- with an episodic memory mechanism, enablingglobal recall of (or attention to) periods in time where similar dynamicspreviously occurred. We find that a basic implementation of Koopman learningwith episodic memory leads to significant improvements in prediction onsynthetic and real-world data. Our framework has considerable potential forexpansion, allowing for future advances, and opens exciting new directions forKoopman learning.</description><author>William T. Redman, Dean Huang, Maria Fonoberova, Igor MeziÄ</author><pubDate>Tue, 07 Jan 2025 16:11:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12615v3</guid></item><item><title>Explainable Reinforcement Learning via Temporal Policy Decomposition</title><link>http://arxiv.org/abs/2501.03902v1</link><description>We investigate the explainability of Reinforcement Learning (RL) policiesfrom a temporal perspective, focusing on the sequence of future outcomesassociated with individual actions. In RL, value functions compress informationabout rewards collected across multiple trajectories and over an infinitehorizon, allowing a compact form of knowledge representation. However, thiscompression obscures the temporal details inherent in sequentialdecision-making, presenting a key challenge for interpretability. We presentTemporal Policy Decomposition (TPD), a novel explainability approach thatexplains individual RL actions in terms of their Expected Future Outcome (EFO).These explanations decompose generalized value functions into a sequence ofEFOs, one for each time step up to a prediction horizon of interest, revealinginsights into when specific outcomes are expected to occur. We leveragefixed-horizon temporal difference learning to devise an off-policy method forlearning EFOs for both optimal and suboptimal actions, enabling contrastiveexplanations consisting of EFOs for different state-action pairs. Ourexperiments demonstrate that TPD generates accurate explanations that (i)clarify the policy's future strategy and anticipated trajectory for a givenaction and (ii) improve understanding of the reward composition, facilitatingfine-tuning of the reward function to align with human expectations.</description><author>Franco Ruggeri, Alessio Russo, Rafia Inam, Karl Henrik Johansson</author><pubDate>Tue, 07 Jan 2025 16:10:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03902v1</guid></item><item><title>Learning Lipschitz Operators with respect to Gaussian Measures with Near-Optimal Sample Complexity</title><link>http://arxiv.org/abs/2410.23440v2</link><description>Operator learning, the approximation of mappings between infinite-dimensionalfunction spaces using ideas from machine learning, has gained increasingresearch attention in recent years. Approximate operators, learned from data,hold promise to serve as efficient surrogate models for problems incomputational science and engineering, complementing traditional numericalmethods. However, despite their empirical success, our understanding of theunderpinning mathematical theory is in large part still incomplete. In thispaper, we study the approximation of Lipschitz operators in expectation withrespect to Gaussian measures. We prove higher Gaussian Sobolev regularity ofLipschitz operators and establish lower and upper bounds on the Hermitepolynomial approximation error. We further consider the reconstruction ofLipschitz operators from $m$ arbitrary (adaptive) linear samples. A key findingis the tight characterization of the smallest achievable error for all possible(adaptive) sampling and reconstruction maps in terms of $m$. It is shown thatHermite polynomial approximation is an optimal recovery strategy, but we havethe following curse of sample complexity: No method to approximate Lipschitzoperators based on $m$ samples can achieve algebraic convergence rates in $m$.On the positive side, we prove that a sufficiently fast spectral decay of thecovariance operator of the Gaussian measure guarantees convergence rates whichare arbitrarily close to any algebraic rate in the large data limit $m \to\infty$. A main focus of this work is on the recovery of Lipschitz operatorsfrom finitely many point samples. We use Christoffel sampling and weightedleast-squares approximation to propose an algorithm which provably achievesnear-optimal sample complexity in high probability.</description><author>Ben Adcock, Michael Griebel, Gregor Maier</author><pubDate>Tue, 07 Jan 2025 16:07:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23440v2</guid></item><item><title>Finer: Investigating and Enhancing Fine-Grained Visual Concept Recognition in Large Vision Language Models</title><link>http://arxiv.org/abs/2402.16315v4</link><description>Recent advances in instruction-tuned Large Vision-Language Models (LVLMs)have imbued the models with the ability to generate high-level, image-groundedexplanations with ease. While such capability is largely attributed to the richworld knowledge contained within the Large Language Models (LLMs), our workreveals their shortcomings in fine-grained visual categorization (FGVC) acrosssix different benchmark settings. Most recent state-of-the-art LVLMs likeLLaVa-1.5, InstructBLIP and GPT-4V not only severely deteriorate in terms ofclassification performance, e.g., average drop of 65.58 in EM for Stanford Dogsfor LLaVA-1.5, but also struggle to generate an accurate explanation withdetailed attributes based on the concept that appears within an input imagedespite their capability to generate holistic image-level descriptions.In-depth analyses show that instruction-tuned LVLMs exhibit modality gap,showing discrepancy when given textual and visual inputs that correspond to thesame concept, preventing the image modality from leveraging the rich parametricknowledge within the LLMs. In an effort to further the community's endeavor inthis direction, we propose a multiple granularity attribute-centric evaluationbenchmark, Finer, which aims to establish a ground to evaluate LVLMs'fine-grained visual comprehension ability and provide significantly improvedexplainability.</description><author>Jeonghwan Kim, Heng Ji</author><pubDate>Tue, 07 Jan 2025 16:05:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16315v4</guid></item><item><title>LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token</title><link>http://arxiv.org/abs/2501.03895v1</link><description>The advent of real-time large multimodal models (LMMs) like GPT-4o hassparked considerable interest in efficient LMMs. LMM frameworks typicallyencode visual inputs into vision tokens (continuous representations) andintegrate them and textual instructions into the context of large languagemodels (LLMs), where large-scale parameters and numerous context tokens(predominantly vision tokens) result in substantial computational overhead.Previous efforts towards efficient LMMs always focus on replacing the LLMbackbone with smaller models, while neglecting the crucial issue of tokenquantity. In this paper, we introduce LLaVA-Mini, an efficient LMM with minimalvision tokens. To achieve a high compression ratio of vision tokens whilepreserving visual information, we first analyze how LMMs understand visiontokens and find that most vision tokens only play a crucial role in the earlylayers of LLM backbone, where they mainly fuse visual information into texttokens. Building on this finding, LLaVA-Mini introduces modality pre-fusion tofuse visual information into text tokens in advance, thereby facilitating theextreme compression of vision tokens fed to LLM backbone into one token.LLaVA-Mini is a unified large multimodal model that can support theunderstanding of images, high-resolution images, and videos in an efficientmanner. Experiments across 11 image-based and 7 video-based benchmarksdemonstrate that LLaVA-Mini outperforms LLaVA-v1.5 with just 1 vision tokeninstead of 576. Efficiency analyses reveal that LLaVA-Mini can reduce FLOPs by77%, deliver low-latency responses within 40 milliseconds, and process over10,000 frames of video on the GPU hardware with 24GB of memory.</description><author>Shaolei Zhang, Qingkai Fang, Zhe Yang, Yang Feng</author><pubDate>Tue, 07 Jan 2025 16:03:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03895v1</guid></item><item><title>From Glucose Patterns to Health Outcomes: A Generalizable Foundation Model for Continuous Glucose Monitor Data Analysis</title><link>http://arxiv.org/abs/2408.11876v2</link><description>Recent advances in SSL enabled novel medical AI models, known as foundationmodels, offer great potential for better characterizing health from diversebiomedical data. CGM provides rich, temporal data on glycemic patterns, but itsfull potential for predicting broader health outcomes remains underutilized.Here, we present GluFormer, a generative foundation model for CGM data thatlearns nuanced glycemic patterns and translates them into predictiverepresentations of metabolic health. Trained on over 10 million CGMmeasurements from 10,812 adults, primarily without diabetes, GluFormer usesautoregressive token prediction to capture longitudinal glucose dynamics. Weshow that GluFormer generalizes to 19 external cohorts (n=6,044) spanningdifferent ethnicities and ages, 5 countries, 8 CGM devices, and diversepathophysiological states. GluFormers representations exceed the performance ofcurrent CGM metrics, such as the Glucose Management Indicator (GMI), forforecasting clinical measures. In a longitudinal study of 580 adults with CGMdata and 12-year follow-up, GluFormer identifies individuals at elevated riskof developing diabetes more effectively than blood HbA1C%, capturing 66% of allnew-onset diabetes diagnoses in the top quartile versus 7% in the bottomquartile. Similarly, 69% of cardiovascular-death events occurred in the topquartile with none in the bottom quartile, demonstrating powerful riskstratification beyond traditional glycemic metrics. We also show that CGMrepresentations from pre-intervention periods in Randomized Clinical Trialsoutperform other methods in predicting primary and secondary outcomes. Whenintegrating dietary data into GluFormer, we show that the multi-modal versionof the model can accurately generate CGM data based on dietary intake data,simulate outcomes of dietary interventions, and predict individual responses tospecific foods.</description><author>Guy Lutsker, Gal Sapir, Smadar Shilo, Jordi Merino, Anastasia Godneva, Jerry R Greenfield, Dorit Samocha-Bonet, Raja Dhir, Francisco Gude, Shie Mannor, Eli Meirom, Gal Chechik, Hagai Rossman, Eran Segal</author><pubDate>Tue, 07 Jan 2025 16:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11876v2</guid></item><item><title>Abstracted Shapes as Tokens -- A Generalizable and Interpretable Model for Time-series Classification</title><link>http://arxiv.org/abs/2411.01006v3</link><description>In time-series analysis, many recent works seek to provide a unified view andrepresentation for time-series across multiple domains, leading to thedevelopment of foundation models for time-series data. Despite diverse modelingtechniques, existing models are black boxes and fail to provide insights andexplanations about their representations. In this paper, we present VQShape, apre-trained, generalizable, and interpretable model for time-seriesrepresentation learning and classification. By introducing a novelrepresentation for time-series data, we forge a connection between the latentspace of VQShape and shape-level features. Using vector quantization, we showthat time-series from different domains can be described using a unified set oflow-dimensional codes, where each code can be represented as an abstractedshape in the time domain. On classification tasks, we show that therepresentations of VQShape can be utilized to build interpretable classifiers,achieving comparable performance to specialist models. Additionally, inzero-shot learning, VQShape and its codebook can generalize to previouslyunseen datasets and domains that are not included in the pre-training process.The code and pre-trained weights are available athttps://github.com/YunshiWen/VQShape.</description><author>Yunshi Wen, Tengfei Ma, Tsui-Wei Weng, Lam M. Nguyen, Anak Agung Julius</author><pubDate>Tue, 07 Jan 2025 16:00:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01006v3</guid></item><item><title>Superpixel Boundary Correction for Weakly-Supervised Semantic Segmentation on Histopathology Images</title><link>http://arxiv.org/abs/2501.03891v1</link><description>With the rapid advancement of deep learning, computational pathology has madesignificant progress in cancer diagnosis and subtyping. Tissue segmentation isa core challenge, essential for prognosis and treatment decisions. Weaklysupervised semantic segmentation (WSSS) reduces the annotation requirement byusing image-level labels instead of pixel-level ones. However, Class ActivationMap (CAM)-based methods still suffer from low spatial resolution and unclearboundaries. To address these issues, we propose a multi-level superpixelcorrection algorithm that refines CAM boundaries using superpixel clusteringand floodfill. Experimental results show that our method achieves greatperformance on breast cancer segmentation dataset with mIoU of 71.08%,significantly improving tumor microenvironment boundary delineation.</description><author>Hongyi Wu, Hong Zhang</author><pubDate>Tue, 07 Jan 2025 15:54:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03891v1</guid></item><item><title>Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and Editable Policies</title><link>http://arxiv.org/abs/2501.03888v1</link><description>Although deep reinforcement learning has been shown to be effective, themodel's black-box nature presents barriers to direct policy interpretation. Toaddress this problem, we propose a neuro-symbolic approach called neural DNF-MTfor end-to-end policy learning. The differentiable nature of the neural DNF-MTmodel enables the use of deep actor-critic algorithms for training. At the sametime, its architecture is designed so that trained models can be directlytranslated into interpretable policies expressed as standard (bivalent orprobabilistic) logic programs. Moreover, additional layers can be included toextract abstract features from complex observations, acting as a form ofpredicate invention. The logic representations are highly interpretable, and weshow how the bivalent representations of deterministic policies can be editedand incorporated back into a neural model, facilitating manual intervention andadaptation of learned policies. We evaluate our approach on a range of tasksrequiring learning deterministic or stochastic behaviours from various forms ofobservations. Our empirical results show that our neural DNF-MT model performsat the level of competing black-box methods whilst providing interpretablepolicies.</description><author>Kexin Gu Baugh, Luke Dickens, Alessandra Russo</author><pubDate>Tue, 07 Jan 2025 15:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03888v1</guid></item><item><title>Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2410.11463v2</link><description>The development of the DRL model for malware attribution involved extensiveresearch, iterative coding, and numerous adjustments based on the insightsgathered from predecessor models and contemporary research papers. Thispreparatory work was essential to establish a robust foundation for the model,ensuring it could adapt and respond effectively to the dynamic nature ofmalware threats. Initially, the model struggled with low accuracy levels, butthrough persistent adjustments to its architecture and learning algorithms,accuracy improved dramatically from about 7 percent to over 73 percent in earlyiterations. By the end of the training, the model consistently reached accuracylevels near 98 percent, demonstrating its strong capability to accuratelyrecognise and attribute malware activities. This upward trajectory in trainingaccuracy is graphically represented in the Figure, which vividly illustratesthe model maturation and increasing proficiency over time.</description><author>Animesh Singh Basnet, Mohamed Chahine Ghanem, Dipo Dunsin, Wiktor Sowinski-Mydlarz</author><pubDate>Tue, 07 Jan 2025 15:48:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11463v2</guid></item><item><title>AlphaPO -- Reward shape matters for LLM alignment</title><link>http://arxiv.org/abs/2501.03884v1</link><description>Reinforcement Learning with Human Feedback (RLHF) and its variants have madehuge strides toward the effective alignment of large language models (LLMs) tofollow instructions and reflect human values. More recently, Direct AlignmentAlgorithms (DAAs) have emerged in which the reward modeling stage of RLHF isskipped by characterizing the reward directly as a function of the policy beinglearned. Examples include Direct Preference Optimization (DPO) and SimplePreference Optimization (SimPO). These methods often suffer from likelihooddisplacement, a phenomenon by which the probabilities of preferred responsesare often reduced undesirably. In this paper, we argue that, for DAAs the reward (function) shape matters.We introduce AlphaPO, a new DAA method that leverages an $\alpha$-parameter tohelp change the shape of the reward function beyond the standard log reward.AlphaPO helps maintain fine-grained control over likelihood displacement andover-optimization. Compared to SimPO, one of the best performing DAAs, AlphaPOleads to about 7\% to 10\% relative improvement in alignment performance forthe instruct versions of Mistral-7B and Llama3-8B. The analysis and resultspresented highlight the importance of the reward shape, and how one cansystematically change it to affect training dynamics, as well as improvealignment performance.</description><author>Aman Gupta, Shao Tang, Qingquan Song, Sirou Zhu, Jiwoo Hong, Ankan Saha, Viral Gupta, Noah Lee, Eunki Kim, Jason Zhu, Natesh Pillai, S. Sathiya Keerthi</author><pubDate>Tue, 07 Jan 2025 15:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03884v1</guid></item><item><title>Deep Learning-based Accelerated MR Cholangiopancreatography without Fully-sampled Data</title><link>http://arxiv.org/abs/2405.03732v3</link><description>The purpose of this study was to accelerate MR cholangiopancreatography(MRCP) acquisitions using deep learning-based (DL) reconstruction at 3T and0.55T. A total of 35 healthy volunteers underwent conventional two-foldaccelerated MRCP scans at field strengths of 3T and 0.55T. We trained DLreconstructions using two different training strategies, supervised (SV) andself-supervised (SSV), with retrospectively six-fold undersampled data obtainedat 3T. We then evaluated the DL reconstructions against standard techniques,parallel imaging (PI) and compressed sensing (CS), focusing on peaksignal-to-noise ratio (PSNR) and structural similarity (SSIM) as metrics. Wealso tested DL reconstructions with prospectively accelerated acquisitions andevaluated their robustness when changing fields strengths from 3T to 0.55T. DLreconstructions demonstrated a reduction in average acquisition time from599/542 to 255/180 seconds for MRCP at 3T/0.55T. In both retrospective andprospective undersampling, PSNR and SSIM of DL reconstructions were higher thanthose of PI and CS. At the same time, DL reconstructions preserved the imagequality of undersampled data, including sharpness and the visibility ofhepatobiliary ducts. In addition, both DL approaches produced high-qualityreconstructions at 0.55T. In summary, DL reconstructions trained for highlyaccelerated MRCP enabled a reduction in acquisition time by a factor of 2.4/3.0at 3T/0.55T while maintaining the image quality of conventional acquisitions.</description><author>Jinho Kim, Marcel Dominik Nickel, Florian Knoll</author><pubDate>Tue, 07 Jan 2025 15:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03732v3</guid></item><item><title>SELMA3D challenge: Self-supervised learning for 3D light-sheet microscopy image segmentation</title><link>http://arxiv.org/abs/2501.03880v1</link><description>Recent innovations in light sheet microscopy, paired with developments intissue clearing techniques, enable the 3D imaging of large mammalian tissueswith cellular resolution. Combined with the progress in large-scale dataanalysis, driven by deep learning, these innovations empower researchers torapidly investigate the morphological and functional properties of diversebiological samples. Segmentation, a crucial preliminary step in the analysisprocess, can be automated using domain-specific deep learning models withexpert-level performance. However, these models exhibit high sensitivity todomain shifts, leading to a significant drop in accuracy when applied to dataoutside their training distribution. To address this limitation, and inspiredby the recent success of self-supervised learning in training generalizablemodels, we organized the SELMA3D Challenge during the MICCAI 2024 conference.SELMA3D provides a vast collection of light-sheet images from cleared mice andhuman brains, comprising 35 large 3D images-each with over 1000^3 voxels-and315 annotated small patches for finetuning, preliminary testing and finaltesting. The dataset encompasses diverse biological structures, includingvessel-like and spot-like structures. Five teams participated in all phases ofthe challenge, and their proposed methods are reviewed in this paper.Quantitative and qualitative results from most participating teams demonstratethat self-supervised learning on large datasets improves segmentation modelperformance and generalization. We will continue to support and extend SELMA3Das an inaugural MICCAI challenge focused on self-supervised learning for 3Dmicroscopy image segmentation.</description><author>Ying Chen, Rami Al-Maskari, Izabela Horvath, Mayar Ali, Luciano HÃ¶her, Kaiyuan Yang, Zengming Lin, Zhiwei Zhai, Mengzhe Shen, Dejin Xun, Yi Wang, Tony Xu, Maged Goubran, Yunheng Wu, Ali Erturk, Johannes C. Paetzold</author><pubDate>Tue, 07 Jan 2025 15:43:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03880v1</guid></item><item><title>CL3DOR: Contrastive Learning for 3D Large Multimodal Models via Odds Ratio on High-Resolution Point Clouds</title><link>http://arxiv.org/abs/2501.03879v1</link><description>Recent research has demonstrated that Large Language Models (LLMs) are notlimited to text-only tasks but can also function as multimodal models acrossvarious modalities, including audio, images, and videos. In particular,research on 3D Large Multimodal Models (3D LMMs) is making notable strides,driven by the potential of processing higher-dimensional data like pointclouds. However, upon closer examination, we find that the visual and textualcontent within each sample of existing training datasets lacks both highinformational granularity and clarity, which serve as a bottleneck for precisecross-modal understanding. To address these issues, we propose CL3DOR,Contrastive Learning for 3D large multimodal models via Odds ratio onhigh-Resolution point clouds, designed to ensure greater specificity andclarity in both visual and textual content. Specifically, we increase thedensity of point clouds per object and construct informative hard negativeresponses in the training dataset to penalize unwanted responses. To leveragehard negative responses, we incorporate the odds ratio as an auxiliary term forcontrastive learning into the conventional language modeling loss. CL3DORachieves state-of-the-art performance in 3D scene understanding and reasoningbenchmarks. Additionally, we demonstrate the effectiveness of CL3DOR's keycomponents through extensive experiments.</description><author>Keonwoo Kim, Yeongjae Cho, Taebaek Hwang, Minsoo Jo, Sangdo Han</author><pubDate>Tue, 07 Jan 2025 15:42:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03879v1</guid></item><item><title>Stochastically Constrained Best Arm Identification with Thompson Sampling</title><link>http://arxiv.org/abs/2501.03877v1</link><description>We consider the problem of the best arm identification in the presence ofstochastic constraints, where there is a finite number of arms associated withmultiple performance measures. The goal is to identify the arm that optimizesthe objective measure subject to constraints on the remaining measures. We willexplore the popular idea of Thompson sampling (TS) as a means to solve it. Tothe best of our knowledge, it is the first attempt to extend TS to thisproblem. We will design a TS-based sampling algorithm, establish its asymptoticoptimality in the rate of posterior convergence, and demonstrate its superiorperformance using numerical examples.</description><author>Le Yang, Siyang Gao, Cheng Li, Yi Wang</author><pubDate>Tue, 07 Jan 2025 15:40:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03877v1</guid></item><item><title>ZDySS -- Zero-Shot Dynamic Scene Stylization using Gaussian Splatting</title><link>http://arxiv.org/abs/2501.03875v1</link><description>Stylizing a dynamic scene based on an exemplar image is critical for variousreal-world applications, including gaming, filmmaking, and augmented andvirtual reality. However, achieving consistent stylization across both spatialand temporal dimensions remains a significant challenge. Most existing methodsare designed for static scenes and often require an optimization process foreach style image, limiting their adaptability. We introduce ZDySS, a zero-shotstylization framework for dynamic scenes, allowing our model to generalize topreviously unseen style images at inference. Our approach employs Gaussiansplatting for scene representation, linking each Gaussian to a learned featurevector that renders a feature map for any given view and timestamp. By applyingstyle transfer on the learned feature vectors instead of the rendered featuremap, we enhance spatio-temporal consistency across frames. Our methoddemonstrates superior performance and coherence over state-of-the-art baselinesin tests on real-world dynamic scenes, making it a robust solution forpractical applications.</description><author>Abhishek Saroha, Florian Hofherr, Mariia Gladkova, Cecilia Curreli, Or Litany, Daniel Cremers</author><pubDate>Tue, 07 Jan 2025 15:39:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03875v1</guid></item><item><title>Neuromorphic Optical Tracking and Imaging of Randomly Moving Targets through Strongly Scattering Media</title><link>http://arxiv.org/abs/2501.03874v1</link><description>Tracking and acquiring simultaneous optical images of randomly moving targetsobscured by scattering media remains a challenging problem of importance tomany applications that require precise object localization and identification.In this work we develop an end-to-end neuromorphic optical engineering andcomputational approach to demonstrate how to track and image normally invisibleobjects by combining an event detecting camera with a multistage neuromorphicdeep learning strategy. Photons emerging from dense scattering media aredetected by the event camera and converted to pixel-wise asynchronized spiketrains - a first step in isolating object-specific information from thedominant uninformative background. Spiking data is fed into a deep spikingneural network (SNN) engine where object tracking and image reconstruction areperformed by two separate yet interconnected modules running in parallel indiscrete time steps over the event duration. Through benchtop experiments wedemonstrate tracking and imaging randomly moving objects in dense turbid mediaas well as image reconstruction of spatially stationary but optically dynamicobjects. Standardized character sets serve as representative proxies forgeometrically complex objects, underscoring the method's generality. Theresults highlight the advantages of a fully neuromorphic approach in meeting amajor imaging technology with high computational efficiency and low powerconsumption.</description><author>Ning Zhang, Timothy Shea, Arto Nurmikko</author><pubDate>Tue, 07 Jan 2025 15:38:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03874v1</guid></item><item><title>Apollo: Band-sequence Modeling for High-Quality Audio Restoration</title><link>http://arxiv.org/abs/2409.08514v2</link><description>Audio restoration has become increasingly significant in modern society, notonly due to the demand for high-quality auditory experiences enabled byadvanced playback devices, but also because the growing capabilities ofgenerative audio models necessitate high-fidelity audio. Typically, audiorestoration is defined as a task of predicting undistorted audio from damagedinput, often trained using a GAN framework to balance perception anddistortion. Since audio degradation is primarily concentrated in mid- andhigh-frequency ranges, especially due to codecs, a key challenge lies indesigning a generator capable of preserving low-frequency information whileaccurately reconstructing high-quality mid- and high-frequency content.Inspired by recent advancements in high-sample-rate music separation, speechenhancement, and audio codec models, we propose Apollo, a generative modeldesigned for high-sample-rate audio restoration. Apollo employs an explicitfrequency band split module to model the relationships between differentfrequency bands, allowing for more coherent and higher-quality restored audio.Evaluated on the MUSDB18-HQ and MoisesDB datasets, Apollo consistentlyoutperforms existing SR-GAN models across various bit rates and music genres,particularly excelling in complex scenarios involving mixtures of multipleinstruments and vocals. Apollo significantly improves music restoration qualitywhile maintaining computational efficiency. The source code for Apollo ispublicly available at https://github.com/JusperLee/Apollo.</description><author>Kai Li, Yi Luo</author><pubDate>Tue, 07 Jan 2025 15:37:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08514v2</guid></item><item><title>LLaVA Steering: Visual Instruction Tuning with 500x Fewer Parameters through Modality Linear Representation-Steering</title><link>http://arxiv.org/abs/2412.12359v2</link><description>Multimodal Large Language Models (MLLMs) have significantly advanced visualtasks by integrating visual representations into large language models (LLMs).The textual modality, inherited from LLMs, equips MLLMs with abilities likeinstruction following and in-context learning. In contrast, the visual modalityenhances performance in downstream tasks by leveraging rich semantic content,spatial information, and grounding capabilities. These intrinsic modalitieswork synergistically across various visual tasks. Our research initiallyreveals a persistent imbalance between these modalities, with text oftendominating output generation during visual instruction tuning. This imbalanceoccurs when using both full fine-tuning and parameter-efficient fine-tuning(PEFT) methods. We then found that re-balancing these modalities cansignificantly reduce the number of trainable parameters required, inspiring adirection for further optimizing visual instruction tuning. We introduceModality Linear Representation-Steering (MoReS) to achieve the goal. MoReSeffectively re-balances the intrinsic modalities throughout the model, wherethe key idea is to steer visual representations through linear transformationsin the visual subspace across each model layer. To validate our solution, wecomposed LLaVA Steering, a suite of models integrated with the proposed MoReSmethod. Evaluation results show that the composed LLaVA Steering modelsrequire, on average, 500 times fewer trainable parameters than LoRA needs whilestill achieving comparable performance across three visual benchmarks and eightvisual question-answering tasks. Last, we present the LLaVA Steering Factory,an in-house developed platform that enables researchers to quickly customizevarious MLLMs with component-based architecture for seamlessly integratingstate-of-the-art models, and evaluate their intrinsic modality imbalance.</description><author>Jinhe Bi, Yujun Wang, Haokun Chen, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma</author><pubDate>Tue, 07 Jan 2025 15:36:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.12359v2</guid></item><item><title>Add Noise, Tasks, or Layers? MaiNLP at the VarDial 2025 Shared Task on Norwegian Dialectal Slot and Intent Detection</title><link>http://arxiv.org/abs/2501.03870v1</link><description>Slot and intent detection (SID) is a classic natural language understandingtask. Despite this, research has only more recently begun focusing on SID fordialectal and colloquial varieties. Many approaches for low-resource scenarioshave not yet been applied to dialectal SID data, or compared to each other onthe same datasets. We participate in the VarDial 2025 shared task on slot andintent detection in Norwegian varieties, and compare multiple set-ups: varyingthe training data (English, Norwegian, or dialectal Norwegian), injectingcharacter-level noise, training on auxiliary tasks, and applying LayerSwapping, a technique in which layers of models fine-tuned on differentdatasets are assembled into a model. We find noise injection to be beneficialwhile the effects of auxiliary tasks are mixed. Though some experimentation wasrequired to successfully assemble a model from layers, it worked surprisinglywell; a combination of models trained on English and small amounts of dialectaldata produced the most robust slot predictions. Our best models achieve 97.6%intent accuracy and 85.6% slot F1 in the shared task.</description><author>Verena Blaschke, Felicia KÃ¶rner, Barbara Plank</author><pubDate>Tue, 07 Jan 2025 15:36:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03870v1</guid></item><item><title>The Faetar Benchmark: Speech Recognition in a Very Under-Resourced Language</title><link>http://arxiv.org/abs/2409.08103v3</link><description>We introduce the Faetar Automatic Speech Recognition Benchmark, a benchmarkcorpus designed to push the limits of current approaches to low-resource speechrecognition. Faetar, a Franco-Proven\c{c}al variety spoken primarily in Italy,has no standard orthography, has virtually no existing textual or speechresources other than what is included in the benchmark, and is quite differentfrom other forms of Franco-Proven\c{c}al. The corpus comes from fieldrecordings, most of which are noisy, for which only 5 hrs have matchingtranscriptions, and for which forced alignment is of variable quality. Thecorpus contains an additional 20 hrs of unlabelled speech. We report baselineresults from state-of-the-art multilingual speech foundation models with a bestphone error rate of 30.4%, using a pipeline that continues pre-training on thefoundation model using the unlabelled set.</description><author>Michael Ong, Sean Robertson, Leo Peckham, Alba Jorquera Jimenez de Aberasturi, Paula Arkhangorodsky, Robin Huo, Aman Sakhardande, Mark Hallap, Naomi Nagy, Ewan Dunbar</author><pubDate>Tue, 07 Jan 2025 15:32:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08103v3</guid></item><item><title>Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis</title><link>http://arxiv.org/abs/2412.14841v2</link><description>Large Language Models (LLMs) are one of the most promising developments inthe field of artificial intelligence, and the software engineering communityhas readily noticed their potential role in the software developmentlife-cycle. Developers routinely ask LLMs to generate code snippets, increasingproductivity but also potentially introducing ownership, privacy, correctness,and security issues. Previous work highlighted how code generated by mainstreamcommercial LLMs is often not safe, containing vulnerabilities, bugs, and codesmells. In this paper, we present a framework that leverages testing and staticanalysis to assess the quality, and guide the self-improvement, of codegenerated by general-purpose, open-source LLMs. First, we ask LLMs to generate C code to solve a number of programming tasks.Then we employ ground-truth tests to assess the (in)correctness of thegenerated code, and a static analysis tool to detect potential safetyvulnerabilities. Next, we assess the models ability to evaluate the generatedcode, by asking them to detect errors and vulnerabilities. Finally, we test themodels ability to fix the generated code, providing the reports produced duringthe static analysis and incorrectness evaluation phases as feedback. Our results show that models often produce incorrect code, and that thegenerated code can include safety issues. Moreover, they perform very poorly atdetecting either issue. On the positive side, we observe a substantial abilityto fix flawed code when provided with information about failed tests orpotential vulnerabilities, indicating a promising avenue for improving thesafety of LLM-based code generation tools.</description><author>Greta Dolcetti, Vincenzo Arceri, Eleonora Iotti, Sergio Maffeis, Agostino Cortesi, Enea Zaffanella</author><pubDate>Tue, 07 Jan 2025 15:30:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14841v2</guid></item><item><title>Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use</title><link>http://arxiv.org/abs/2410.19155v3</link><description>Adverse Drug Reactions (ADRs) from psychiatric medications are the leadingcause of hospitalizations among mental health patients. With healthcare systemsand online communities facing limitations in resolving ADR-related issues,Large Language Models (LLMs) have the potential to fill this gap. Despite theincreasing capabilities of LLMs, past research has not explored theircapabilities in detecting ADRs related to psychiatric medications or inproviding effective harm reduction strategies. To address this, we introducethe Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment(ADRA) framework to systematically evaluate LLM performance in detecting ADRexpressions and delivering expert-aligned mitigation strategies. Our analysesshow that LLMs struggle with understanding the nuances of ADRs anddifferentiating between types of ADRs. While LLMs align with experts in termsof expressed emotions and tone of the text, their responses are more complex,harder to read, and only 70.86% aligned with expert strategies. Furthermore,they provide less actionable advice by a margin of 12.32% on average. Our workprovides a comprehensive benchmark and evaluation framework for assessing LLMsin strategy-driven tasks within high-risk domains.</description><author>Mohit Chandra, Siddharth Sriraman, Gaurav Verma, Harneet Singh Khanuja, Jose Suarez Campayo, Zihang Li, Michael L. Birnbaum, Munmun De Choudhury</author><pubDate>Tue, 07 Jan 2025 15:30:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19155v3</guid></item><item><title>Influence Functions for Scalable Data Attribution in Diffusion Models</title><link>http://arxiv.org/abs/2410.13850v3</link><description>Diffusion models have led to significant advancements in generativemodelling. Yet their widespread adoption poses challenges regarding dataattribution and interpretability. In this paper, we aim to help address suchchallenges in diffusion models by developing an influence functions framework.Influence function-based data attribution methods approximate how a model'soutput would have changed if some training data were removed. In supervisedlearning, this is usually used for predicting how the loss on a particularexample would change. For diffusion models, we focus on predicting the changein the probability of generating a particular example via several proxymeasurements. We show how to formulate influence functions for such quantitiesand how previously proposed methods can be interpreted as particular designchoices in our framework. To ensure scalability of the Hessian computations ininfluence functions, we systematically develop K-FAC approximations based ongeneralised Gauss-Newton matrices specifically tailored to diffusion models. Werecast previously proposed methods as specific design choices in our frameworkand show that our recommended method outperforms previous data attributionapproaches on common evaluations, such as the Linear Data-modelling Score (LDS)or retraining without top influences, without the need for method-specifichyperparameter tuning.</description><author>Bruno Mlodozeniec, Runa Eschenhagen, Juhan Bae, Alexander Immer, David Krueger, Richard Turner</author><pubDate>Tue, 07 Jan 2025 15:28:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13850v3</guid></item><item><title>Highway Graph to Accelerate Reinforcement Learning</title><link>http://arxiv.org/abs/2405.11727v2</link><description>Reinforcement Learning (RL) algorithms often struggle with low trainingefficiency. A common approach to address this challenge is integratingmodel-based planning algorithms, such as Monte Carlo Tree Search (MCTS) orValue Iteration (VI), into the environmental model. However, VI requiresiterating over a large tensor which updates the value of the preceding statebased on the succeeding state through value propagation, resulting incomputationally intensive operations. To enhance the RL training efficiency, wepropose improving the efficiency of the value learning process. Indeterministic environments with discrete state and action spaces, we observethat on the sampled empirical state-transition graph, a non-branching sequenceof transitions-termed a highway-can take the agent to another state withoutdeviation through intermediate states. On these non-branching highways, thevalue-updating process can be streamlined into a single-step operation,eliminating the need for step-by-step updates. Building on this observation, weintroduce the highway graph to model state transitions. The highway graphcompresses the transition model into a compact representation, where edges canencapsulate multiple state transitions, enabling value propagation acrossmultiple time steps in a single iteration. By integrating the highway graphinto RL, the training process is significantly accelerated, particularly in theearly stages of training. Experiments across four categories of environmentsdemonstrate that our method learns significantly faster than established andstate-of-the-art RL algorithms (often by a factor of 10 to 150) whilemaintaining equal or superior expected returns. Furthermore, a deep neuralnetwork-based agent trained using the highway graph exhibits improvedgeneralization capabilities and reduced storage costs. Code is publiclyavailable at https://github.com/coodest/highwayRL.</description><author>Zidu Yin, Zhen Zhang, Dong Gong, Stefano V. Albrecht, Javen Q. Shi</author><pubDate>Tue, 07 Jan 2025 15:26:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11727v2</guid></item><item><title>Truthful mechanisms for linear bandit games with private contexts</title><link>http://arxiv.org/abs/2501.03865v1</link><description>The contextual bandit problem, where agents arrive sequentially with personalcontexts and the system adapts its arm allocation decisions accordingly, hasrecently garnered increasing attention for enabling more personalized outcomes.However, in many healthcare and recommendation applications, agents haveprivate profiles and may misreport their contexts to gain from the system. Forexample, in adaptive clinical trials, where hospitals sequentially recruitvolunteers to test multiple new treatments and adjust plans based onvolunteers' reported profiles such as symptoms and interim data, participantsmay misreport severe side effects like allergy and nausea to avoid perceivedsuboptimal treatments. We are the first to study this issue of private contextmisreporting in a stochastic contextual bandit game between the system andnon-repeated agents. We show that traditional low-regret algorithms, such asUCB family algorithms and Thompson sampling, fail to ensure truthful reportingand can result in linear regret in the worst case, while traditional truthfulalgorithms like explore-then-commit (ETC) and $\epsilon$-greedy algorithm incursublinear but high regret. We propose a mechanism that uses a linear program toensure truthfulness while minimizing deviation from Thompson sampling, yieldingan $O(\ln T)$ frequentist regret. Our numerical experiments further demonstratestrong performance in multiple contexts and across other distribution families.</description><author>Yiting Hu, Lingjie Duan</author><pubDate>Tue, 07 Jan 2025 15:24:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03865v1</guid></item><item><title>Improving Dialectal Slot and Intent Detection with Auxiliary Tasks: A Multi-Dialectal Bavarian Case Study</title><link>http://arxiv.org/abs/2501.03863v1</link><description>Reliable slot and intent detection (SID) is crucial in natural languageunderstanding for applications like digital assistants. Encoder-onlytransformer models fine-tuned on high-resource languages generally perform wellon SID. However, they struggle with dialectal data, where no standardized formexists and training data is scarce and costly to produce. We explore zero-shottransfer learning for SID, focusing on multiple Bavarian dialects, for which werelease a new dataset for the Munich dialect. We evaluate models trained onauxiliary tasks in Bavarian, and compare joint multi-task learning withintermediate-task training. We also compare three types of auxiliary tasks:token-level syntactic tasks, named entity recognition (NER), and languagemodelling. We find that the included auxiliary tasks have a more positiveeffect on slot filling than intent classification (with NER having the mostpositive effect), and that intermediate-task training yields more consistentperformance gains. Our best-performing approach improves intent classificationperformance on Bavarian dialects by 5.1 and slot filling F1 by 8.4 percentagepoints.</description><author>Xaver Maria KrÃ¼ckl, Verena Blaschke, Barbara Plank</author><pubDate>Tue, 07 Jan 2025 15:21:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03863v1</guid></item><item><title>Symmetry and Generalisation in Machine Learning</title><link>http://arxiv.org/abs/2501.03858v1</link><description>This work is about understanding the impact of invariance and equivariance ongeneralisation in supervised learning. We use the perspective afforded by anaveraging operator to show that for any predictor that is not equivariant,there is an equivariant predictor with strictly lower test risk on allregression problems where the equivariance is correctly specified. Thisconstitutes a rigorous proof that symmetry, in the form of invariance orequivariance, is a useful inductive bias. We apply these ideas to equivariance and invariance in random design leastsquares and kernel ridge regression respectively. This allows us to specify thereduction in expected test risk in more concrete settings and express it interms of properties of the group, the model and the data. Along the way, we give examples and additional results to demonstrate theutility of the averaging operator approach in analysing equivariant predictors.In addition, we adopt an alternative perspective and formalise the commonintuition that learning with invariant models reduces to a problem in terms oforbit representatives. The formalism extends naturally to a similar intuitionfor equivariant models. We conclude by connecting the two perspectives andgiving some ideas for future work.</description><author>Hayder Elesedy</author><pubDate>Tue, 07 Jan 2025 15:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03858v1</guid></item><item><title>Progressive Document-level Text Simplification via Large Language Models</title><link>http://arxiv.org/abs/2501.03857v1</link><description>Research on text simplification has primarily focused on lexical andsentence-level changes. Long document-level simplification (DS) is stillrelatively unexplored. Large Language Models (LLMs), like ChatGPT, haveexcelled in many natural language processing tasks. However, their performanceon DS tasks is unsatisfactory, as they often treat DS as merely documentsummarization. For the DS task, the generated long sequences not only mustmaintain consistency with the original document throughout, but completemoderate simplification operations encompassing discourses, sentences, andword-level simplifications. Human editors employ a hierarchical complexitysimplification strategy to simplify documents. This study delves intosimulating this strategy through the utilization of a multi-stage collaborationusing LLMs. We propose a progressive simplification method (ProgDS) byhierarchically decomposing the task, including the discourse-level,topic-level, and lexical-level simplification. Experimental results demonstratethat ProgDS significantly outperforms existing smaller models or directprompting with LLMs, advancing the state-of-the-art in the documentsimplification task.</description><author>Dengzhao Fang, Jipeng Qiang, Yi Zhu, Yunhao Yuan, Wei Li, Yan Liu</author><pubDate>Tue, 07 Jan 2025 15:14:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03857v1</guid></item><item><title>BabyLMs for isiXhosa: Data-Efficient Language Modelling in a Low-Resource Context</title><link>http://arxiv.org/abs/2501.03855v1</link><description>The BabyLM challenge called on participants to develop sample-efficientlanguage models. Submissions were pretrained on a fixed English corpus, limitedto the amount of words children are exposed to in development (&lt;100m). Thechallenge produced new architectures for data-efficient language modelling,which outperformed models trained on trillions of words. This is promising forlow-resource languages, where available corpora are limited to much less than100m words. In this paper, we explore the potential of BabyLMs for low-resourcelanguages, using the isiXhosa language as a case study. We pretrain two BabyLMarchitectures, ELC-BERT and MLSM, on an isiXhosa corpus. They outperform avanilla pretrained model on POS tagging and NER, achieving notable gains (+3.2F1) for the latter. In some instances, the BabyLMs even outperform XLM-R. Ourfindings show that data-efficient models are viable for low-resource languages,but highlight the continued importance, and lack of, high-quality pretrainingdata. Finally, we visually analyse how BabyLM architectures encode isiXhosa.</description><author>Alexis Matzopoulos, Charl Hendriks, Hishaam Mahomed, Francois Meyer</author><pubDate>Tue, 07 Jan 2025 15:13:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03855v1</guid></item><item><title>Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders</title><link>http://arxiv.org/abs/2501.03038v2</link><description>Automatic Music Transcription (AMT), aiming to get musical notes from rawaudio, typically uses frame-level systems with piano-roll outputs or languagemodel (LM)-based systems with note-level predictions. However, frame-levelsystems require manual thresholding, while the LM-based systems struggle withlong sequences. In this paper, we propose a hybrid method combining pre-trainedroll-based encoders with an LM decoder to leverage the strengths of bothmethods. Besides, our approach employs a hierarchical prediction strategy,first predicting onset and pitch, then velocity, and finally offset. Thehierarchical prediction strategy reduces computational costs by breaking downlong sequences into different hierarchies. Evaluated on two benchmarkroll-based encoders, our method outperforms traditional piano-roll outputs 0.01and 0.022 in onset-offset-velocity F1 score, demonstrating its potential as aperformance-enhancing plug-in for arbitrary roll-based music transcriptionencoder.</description><author>Dichucheng Li, Yongyi Zang, Qiuqiang Kong</author><pubDate>Tue, 07 Jan 2025 15:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03038v2</guid></item><item><title>Leveraging time and parameters for nonlinear model reduction methods</title><link>http://arxiv.org/abs/2501.03853v1</link><description>In this paper, we consider model order reduction (MOR) methods for problemswith slowly decaying Kolmogorov $n$-widths as, e.g., certain wave-like ortransport-dominated problems. To overcome this Kolmogorov barrier within MOR,nonlinear projections are used, which are often realized numerically usingautoencoders. These autoencoders generally consist of a nonlinear encoder and anonlinear decoder and involve costly training of the hyperparameters to obtaina good approximation quality of the reduced system. To facilitate the trainingprocess, we show that extending the to-be-reduced system and its correspondingtraining data makes it possible to replace the nonlinear encoder with a linearencoder without sacrificing accuracy, thus roughly halving the number ofhyperparameters to be trained.</description><author>Silke Glas, Benjamin Unger</author><pubDate>Tue, 07 Jan 2025 15:10:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03853v1</guid></item><item><title>Semise: Semi-supervised learning for severity representation in medical image</title><link>http://arxiv.org/abs/2501.03848v1</link><description>This paper introduces SEMISE, a novel method for representation learning inmedical imaging that combines self-supervised and supervised learning. Byleveraging both labeled and augmented data, SEMISE addresses the challenge ofdata scarcity and enhances the encoder's ability to extract meaningfulfeatures. This integrated approach leads to more informative representations,improving performance on downstream tasks. As result, our approach achieved a12% improvement in classification and a 3% improvement in segmentation,outperforming existing methods. These results demonstrate the potential ofSIMESE to advance medical image analysis and offer more accurate solutions forhealthcare applications, particularly in contexts where labeled data islimited.</description><author>Dung T. Tran, Hung Vu, Anh Tran, Hieu Pham, Hong Nguyen, Phong Nguyen</author><pubDate>Tue, 07 Jan 2025 15:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03848v1</guid></item><item><title>Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control</title><link>http://arxiv.org/abs/2501.03847v1</link><description>Diffusion models have demonstrated impressive performance in generatinghigh-quality videos from text prompts or images. However, precise control overthe video generation process, such as camera manipulation or content editing,remains a significant challenge. Existing methods for controlled videogeneration are typically limited to a single control type, lacking theflexibility to handle diverse control demands. In this paper, we introduceDiffusion as Shader (DaS), a novel approach that supports multiple videocontrol tasks within a unified architecture. Our key insight is that achievingversatile video control necessitates leveraging 3D control signals, as videosare fundamentally 2D renderings of dynamic 3D content. Unlike prior methodslimited to 2D control signals, DaS leverages 3D tracking videos as controlinputs, making the video diffusion process inherently 3D-aware. This innovationallows DaS to achieve a wide range of video controls by simply manipulating the3D tracking videos. A further advantage of using 3D tracking videos is theirability to effectively link frames, significantly enhancing the temporalconsistency of the generated videos. With just 3 days of fine-tuning on 8 H800GPUs using less than 10k videos, DaS demonstrates strong control capabilitiesacross diverse tasks, including mesh-to-video generation, camera control,motion transfer, and object manipulation.</description><author>Zekai Gu, Rui Yan, Jiahao Lu, Peng Li, Zhiyang Dou, Chenyang Si, Zhen Dong, Qifeng Liu, Cheng Lin, Ziwei Liu, Wenping Wang, Yuan Liu</author><pubDate>Tue, 07 Jan 2025 15:01:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03847v1</guid></item><item><title>GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning</title><link>http://arxiv.org/abs/2409.16670v2</link><description>Graph Neural Networks (GNNs) have demonstrated remarkable proficiency inhandling a range of graph analytical tasks across various domains, such ase-commerce and social networks. Despite their versatility, GNNs facesignificant challenges in transferability, limiting their utility in real-worldapplications. Existing research in GNN transfer learning overlooksdiscrepancies in distribution among various graph datasets, facing challengeswhen transferring across different distributions. How to effectively adopt awell-trained GNN to new graphs with varying feature and structuraldistributions remains an under-explored problem. Taking inspiration from thesuccess of Low-Rank Adaptation (LoRA) in adapting large language models tovarious domains, we propose GraphLoRA, an effective and parameter-efficientmethod for transferring well-trained GNNs to diverse graph domains.Specifically, we first propose a Structure-aware Maximum Mean Discrepancy(SMMD) to align divergent node feature distributions across source and targetgraphs. Moreover, we introduce low-rank adaptation by injecting a smalltrainable GNN alongside the pre-trained one, effectively bridging structuraldistribution gaps while mitigating the catastrophic forgetting. Additionally, astructure-aware regularization objective is proposed to enhance theadaptability of the pre-trained GNN to target graph with scarce supervisionlabels. Extensive experiments on eight real-world datasets demonstrate theeffectiveness of GraphLoRA against fourteen baselines by tuning only 20% ofparameters, even across disparate graph domains. The code is available athttps://github.com/AllminerLab/GraphLoRA.</description><author>Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu</author><pubDate>Tue, 07 Jan 2025 15:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16670v2</guid></item><item><title>Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training</title><link>http://arxiv.org/abs/2410.15460v3</link><description>As large language models (LLMs) are increasingly deployed across variousindustries, concerns regarding their reliability, particularly due tohallucinations - outputs that are factually inaccurate or irrelevant to userinput - have grown. Our research investigates the relationship between thetraining process and the emergence of hallucinations to address a key gap inexisting research that focuses primarily on post hoc detection and mitigationstrategies. Using models from the Pythia suite (70M - 12B parameters) andseveral hallucination detection metrics, we analyze hallucination trendsthroughout training and explore LLM internal dynamics. We introduce SensitivityDropout (SenD), a novel training protocol designed to mitigate hallucinationsby reducing variance during training. SenD achieves this by deterministicallydropping embedding indices with significant variability, referred to asSensitive Embedding Indices. In addition, we develop an unsupervisedhallucination detection metric, Efficient EigenScore (EES), which approximatesthe traditional EigenScore at 2x speed. This efficient metric is integratedinto our protocol, allowing SenD to be both computationally scalable andeffective at reducing hallucinations. Our empirical evaluation demonstratesthat our approach improves LLM reliability at test time by up to 40% comparedto normal training while also providing an efficient method to improve factualaccuracy when adapting LLMs to Wikipedia, Medical, and LegalBench domains.</description><author>Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi</author><pubDate>Tue, 07 Jan 2025 14:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15460v3</guid></item><item><title>BERTopic for Topic Modeling of Hindi Short Texts: A Comparative Study</title><link>http://arxiv.org/abs/2501.03843v1</link><description>As short text data in native languages like Hindi increasingly appear inmodern media, robust methods for topic modeling on such data have gainedimportance. This study investigates the performance of BERTopic in modelingHindi short texts, an area that has been under-explored in existing research.Using contextual embeddings, BERTopic can capture semantic relationships indata, making it potentially more effective than traditional models, especiallyfor short and diverse texts. We evaluate BERTopic using 6 different documentembedding models and compare its performance against 8 established topicmodeling techniques, such as Latent Dirichlet Allocation (LDA), Non-negativeMatrix Factorization (NMF), Latent Semantic Indexing (LSI), AdditiveRegularization of Topic Models (ARTM), Probabilistic Latent Semantic Analysis(PLSA), Embedded Topic Model (ETM), Combined Topic Model (CTM), and Top2Vec.The models are assessed using coherence scores across a range of topic counts.Our results reveal that BERTopic consistently outperforms other models incapturing coherent topics from short Hindi texts.</description><author>Atharva Mutsaddi, Anvi Jamkhande, Aryan Thakre, Yashodhara Haribhakta</author><pubDate>Tue, 07 Jan 2025 14:53:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03843v1</guid></item><item><title>Predicting risk of cardiovascular disease using retinal OCT imaging</title><link>http://arxiv.org/abs/2403.18873v2</link><description>Cardiovascular diseases (CVD) are the leading cause of death globally.Non-invasive, cost-effective imaging techniques play a crucial role in earlydetection and prevention of CVD. Optical coherence tomography (OCT) has gainedrecognition as a potential tool for early CVD risk prediction, though its useremains underexplored. In this study, we investigated the potential of OCT asan additional imaging technique to predict future CVD events. We analysedretinal OCT data from the UK Biobank. The dataset included 612 patients whosuffered a myocardial infarction (MI) or stroke within five years of imagingand 2,234 controls without CVD (total: 2,846 participants). A self-superviseddeep learning approach based on Variational Autoencoders (VAE) was used toextract low-dimensional latent representations from high-dimensional 3D OCTimages, capturing distinct features of retinal layers. These latent features,along with clinical data, were used to train a Random Forest (RF) classifier todifferentiate between patients at risk of future CVD events (MI or stroke) andhealthy controls. Our model achieved an AUC of 0.75, sensitivity of 0.70,specificity of 0.70, and accuracy of 0.70, outperforming the QRISK3 score (thethird version of the QRISK cardiovascular disease risk prediction algorithm;AUC = 0.60, sensitivity = 0.60, specificity = 0.55, accuracy = 0.55). Thechoroidal layer in OCT images was identified as a key predictor of future CVDevents, revealed through a novel model explainability approach. This studydemonstrates that retinal OCT imaging is a cost-effective, non-invasivealternative for predicting CVD risk, offering potential for widespreadapplication in optometry practices and hospitals.</description><author>Cynthia Maldonado-Garcia, Rodrigo Bonazzola, Enzo Ferrante, Thomas H Julian, Panagiotis I Sergouniotis, Nishant Ravikumara, Alejandro F Frangi</author><pubDate>Tue, 07 Jan 2025 14:52:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18873v2</guid></item><item><title>Machine learning applications in archaeological practices: a review</title><link>http://arxiv.org/abs/2501.03840v1</link><description>Artificial intelligence and machine learning applications in archaeology haveincreased significantly in recent years, and these now span all subfields,geographical regions, and time periods. The prevalence and success of theseapplications have remained largely unexamined, as recent reviews on the use ofmachine learning in archaeology have only focused only on specific subfields ofarchaeology. Our review examined an exhaustive corpus of 135 articles publishedbetween 1997 and 2022. We observed a significant increase in the number ofrelevant publications from 2019 onwards. Automatic structure detection andartefact classification were the most represented tasks in the articlesreviewed, followed by taphonomy, and archaeological predictive modelling. Fromthe review, clustering and unsupervised methods were underrepresented comparedto supervised models. Artificial neural networks and ensemble learning accountfor two thirds of the total number of models used. However, if machine learningis gaining in popularity it remains subject to misunderstanding. We observed,in some cases, poorly defined requirements and caveats of the machine learningmethods used. Furthermore, the goals and the needs of machine learningapplications for archaeological purposes are in some cases unclear or poorlyexpressed. To address this, we proposed a workflow guide for archaeologists todevelop coherent and consistent methodologies adapted to their researchquestions, project scale and data. As in many other areas, machine learning israpidly becoming an important tool in archaeological research and practice,useful for the analyses of large and multivariate data, although not withoutlimitations. This review highlights the importance of well-defined andwell-reported structured methodologies and collaborative practices to maximisethe potential of applications of machine learning methods in archaeology.</description><author>Mathias Bellat, Jordy D. Orellana Figueroa, Jonathan S. Reeves, Ruhollah Taghizadeh-Mehrjardi, Claudio Tennie, Thomas Scholten</author><pubDate>Tue, 07 Jan 2025 14:50:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03840v1</guid></item><item><title>Improving Speech Emotion Recognition in Under-Resourced Languages via Speech-to-Speech Translation with Bootstrapping Data Selection</title><link>http://arxiv.org/abs/2409.10985v2</link><description>Speech Emotion Recognition (SER) is a crucial component in developinggeneral-purpose AI agents capable of natural human-computer interaction.However, building robust multilingual SER systems remains challenging due tothe scarcity of labeled data in languages other than English and Chinese. Inthis paper, we propose an approach to enhance SER performance in low SERresource languages by leveraging data from high-resource languages.Specifically, we employ expressive Speech-to-Speech translation (S2ST) combinedwith a novel bootstrapping data selection pipeline to generate labeled data inthe target language. Extensive experiments demonstrate that our method is botheffective and generalizable across different upstream models and languages. Ourresults suggest that this approach can facilitate the development of morescalable and robust multilingual SER systems.</description><author>Hsi-Che Lin, Yi-Cheng Lin, Huang-Cheng Chou, Hung-yi Lee</author><pubDate>Tue, 07 Jan 2025 14:49:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10985v2</guid></item><item><title>MedFocusCLIP : Improving few shot classification in medical datasets using pixel wise attention</title><link>http://arxiv.org/abs/2501.03839v1</link><description>With the popularity of foundational models, parameter efficient fine tuninghas become the defacto approach to leverage pretrained models to performdownstream tasks. Taking inspiration from recent advances in large languagemodels, Visual Prompt Tuning, and similar techniques, learn an additionalprompt to efficiently finetune a pretrained vision foundational model. However,we observe that such prompting is insufficient for fine-grained visualclassification tasks such as medical image classification, where there is largeinter-class variance, and small intra-class variance. Hence, in this paper wepropose to leverage advanced segmentation capabilities of Segment AnythingModel 2 (SAM2) as a visual prompting cue to help visual encoder in the CLIP(Contrastive Language-Image Pretraining) by guiding the attention in CLIPvisual encoder to relevant regions in the image. This helps the model to focuson highly discriminative regions, without getting distracted from visuallysimilar background features, an essential requirement in a fewshot, finegrainedclassification setting. We evaluate our method on diverse medical datasetsincluding X-rays, CT scans, and MRI images, and report an accuracy of (71%,81%, 86%, 58%) from the proposed approach on (COVID, lung-disease, brain-tumor,breast-cancer) datasets against (66%, 70%, 68%, 29%) from a pretrained CLIPmodel after fewshot training. The proposed approach also allows to obtaininterpretable explanation for the classification performance through thelocalization obtained using segmentation.</description><author>Aadya Arora, Vinay Namboodiri</author><pubDate>Tue, 07 Jan 2025 14:49:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03839v1</guid></item><item><title>LM-Net: A Light-weight and Multi-scale Network for Medical Image Segmentation</title><link>http://arxiv.org/abs/2501.03838v1</link><description>Current medical image segmentation approaches have limitations in deeplyexploring multi-scale information and effectively combining local detailtextures with global contextual semantic information. This results inover-segmentation, under-segmentation, and blurred segmentation boundaries. Totackle these challenges, we explore multi-scale feature representations fromdifferent perspectives, proposing a novel, lightweight, and multi-scalearchitecture (LM-Net) that integrates advantages of both Convolutional NeuralNetworks (CNNs) and Vision Transformers (ViTs) to enhance segmentationaccuracy. LM-Net employs a lightweight multi-branch module to capturemulti-scale features at the same level. Furthermore, we introduce two modulesto concurrently capture local detail textures and global semantics withmulti-scale features at different levels: the Local Feature Transformer (LFT)and Global Feature Transformer (GFT). The LFT integrates local windowself-attention to capture local detail textures, while the GFT leverages globalself-attention to capture global contextual semantics. By combining thesemodules, our model achieves complementarity between local and globalrepresentations, alleviating the problem of blurred segmentation boundaries inmedical image segmentation. To evaluate the feasibility of LM-Net, extensiveexperiments have been conducted on three publicly available datasets withdifferent modalities. Our proposed model achieves state-of-the-art results,surpassing previous methods, while only requiring 4.66G FLOPs and 5.4Mparameters. These state-of-the-art results on three datasets with differentmodalities demonstrate the effectiveness and adaptability of our proposedLM-Net for various medical image segmentation tasks.</description><author>Zhenkun Lu, Chaoyin She, Wei Wang, Qinghua Huang</author><pubDate>Tue, 07 Jan 2025 14:47:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03838v1</guid></item><item><title>SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis</title><link>http://arxiv.org/abs/2501.03836v1</link><description>Brain tumors can result in neurological dysfunction, alterations in cognitiveand psychological states, increased intracranial pressure, and the occurrenceof seizures, thereby presenting a substantial risk to human life and health.The You Only Look Once(YOLO) series models have demonstrated superior accuracyin object detection for medical imaging. In this paper, we develop a novelSCC-YOLO architecture by integrating the SCConv attention mechanism intoYOLOv9. The SCConv module reconstructs an efficient convolutional module byreducing spatial and channel redundancy among features, thereby enhancing thelearning of image features. We investigate the impact of intergrating differentattention mechanisms with the YOLOv9 model on brain tumor image detection usingboth the Br35H dataset and our self-made dataset(Brain_Tumor_Dataset).Experimental results show that on the Br35H dataset, SCC-YOLO achieved a 0.3%improvement in mAp50 compared to YOLOv9, while on our self-made dataset,SCC-YOLO exhibited a 0.5% improvement over YOLOv9. SCC-YOLO has reachedstate-of-the-art performance in brain tumor detection. Source code is availableat : https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master</description><author>Runci Bai</author><pubDate>Tue, 07 Jan 2025 14:45:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03836v1</guid></item><item><title>TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification</title><link>http://arxiv.org/abs/2501.03835v1</link><description>Product Attribute Value Identification (PAVI) involves identifying attributevalues from product profiles, a key task for improving product search,recommendations, and business analytics on e-commerce platforms. However,existing PAVI methods face critical challenges, such as inferring implicitvalues, handling out-of-distribution (OOD) values, and producing normalizedoutputs. To address these limitations, we introduce Taxonomy-Aware ContrastiveLearning Retrieval (TACLR), the first retrieval-based method for PAVI. TACLRformulates PAVI as an information retrieval task by encoding product profilesand candidate values into embeddings and retrieving values based on theirsimilarity to the item embedding. It leverages contrastive training withtaxonomy-aware hard negative sampling and employs adaptive inference withdynamic thresholds. TACLR offers three key advantages: (1) it effectivelyhandles implicit and OOD values while producing normalized outputs; (2) itscales to thousands of categories, tens of thousands of attributes, andmillions of values; and (3) it supports efficient inference for high-loadindustrial scenarios. Extensive experiments on proprietary and public datasetsvalidate the effectiveness and efficiency of TACLR. Moreover, it has beensuccessfully deployed in a real-world e-commerce platform, processing millionsof product listings daily while supporting dynamic, large-scale attributetaxonomies.</description><author>Yindu Su, Huike Zou, Lin Sun, Ting Zhang, Haiyang Yang, Liyu Chen, David Lo, Qingheng Zhang, Shuguang Han, Jufeng Chen</author><pubDate>Tue, 07 Jan 2025 14:45:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03835v1</guid></item><item><title>On Local Overfitting and Forgetting in Deep Neural Networks</title><link>http://arxiv.org/abs/2412.12968v2</link><description>The infrequent occurrence of overfitting in deep neural networks isperplexing: contrary to theoretical expectations, increasing model size oftenenhances performance in practice. But what if overfitting does occur, thoughrestricted to specific sub-regions of the data space? In this work, we proposea novel score that captures the forgetting rate of deep models on validationdata. We posit that this score quantifies local overfitting: a decline inperformance confined to certain regions of the data space. We then showempirically that local overfitting occurs regardless of the presence oftraditional overfitting. Using the framework of deep over-parametrized linearmodels, we offer a certain theoretical characterization of forgotten knowledge,and show that it correlates with knowledge forgotten by real deep models.Finally, we devise a new ensemble method that aims to recover forgottenknowledge, relying solely on the training history of a single network. Whencombined with self-distillation, this method enhances the performance of anytrained model without adding inference costs. Extensive empirical evaluationsdemonstrate the efficacy of our method across multiple datasets, contemporaryneural network architectures, and training protocols.</description><author>Uri Stern, Tomer Yaacoby, Daphna Weinshall</author><pubDate>Tue, 07 Jan 2025 14:45:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.12968v2</guid></item><item><title>Three-dimensional attention Transformer for state evaluation in real-time strategy games</title><link>http://arxiv.org/abs/2501.03832v1</link><description>Situation assessment in Real-Time Strategy (RTS) games is crucial forunderstanding decision-making in complex adversarial environments. However,existing methods remain limited in processing multi-dimensional featureinformation and temporal dependencies. Here we propose a tri-dimensionalSpace-Time-Feature Transformer (TSTF Transformer) architecture, whichefficiently models battlefield situations through three independent butcascaded modules: spatial attention, temporal attention, and feature attention.On a dataset comprising 3,150 adversarial experiments, the 8-layer TSTFTransformer demonstrates superior performance: achieving 58.7% accuracy in theearly game (~4% progress), significantly outperforming the conventionalTimesformer's 41.8%; reaching 97.6% accuracy in the mid-game (~40% progress)while maintaining low performance variation (standard deviation 0.114).Meanwhile, this architecture requires fewer parameters (4.75M) compared to thebaseline model (5.54M). Our study not only provides new insights into situationassessment in RTS games but also presents an innovative paradigm forTransformer-based multi-dimensional temporal modeling.</description><author>Yanqing Ye, Weilong Yang, Kai Qiu, Jie Zhang</author><pubDate>Tue, 07 Jan 2025 14:42:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03832v1</guid></item><item><title>MeshConv3D: Efficient convolution and pooling operators for triangular 3D meshes</title><link>http://arxiv.org/abs/2501.03830v1</link><description>Convolutional neural networks (CNNs) have been pivotal in various 2D imageanalysis tasks, including computer vision, image indexing and retrieval orsemantic classification. Extending CNNs to 3D data such as point clouds and 3Dmeshes raises significant challenges since the very basic convolution andpooling operators need to be completely re-visited and re-defined in anappropriate manner to tackle irregular connectivity issues. In this paper, weintroduce MeshConv3D, a 3D mesh-dedicated methodology integrating specializedconvolution and face collapse-based pooling operators. MeshConv3D operatesdirectly on meshes of arbitrary topology, without any need of priorre-meshing/conversion techniques. In order to validate our approach, we haveconsidered a semantic classification task. The experimental results obtained onthree distinct benchmark datasets show that the proposed approach makes itpossible to achieve equivalent or superior classification results, whileminimizing the related memory footprint and computational load.</description><author>Germain Bregeon, Marius Preda, Radu Ispas, Titus Zaharia</author><pubDate>Tue, 07 Jan 2025 14:41:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03830v1</guid></item><item><title>Gaze-guided Hand-Object Interaction Synthesis: Dataset and Method</title><link>http://arxiv.org/abs/2403.16169v5</link><description>Gaze plays a crucial role in revealing human attention and intention,particularly in hand-object interaction scenarios, where it guides andsynchronizes complex tasks that require precise coordination between the brain,hand, and object. Motivated by this, we introduce a novel task: Gaze-GuidedHand-Object Interaction Synthesis, with potential applications in augmentedreality, virtual reality, and assistive technologies. To support this task, wepresent GazeHOI, the first dataset to capture simultaneous 3D modeling of gaze,hand, and object interactions. This task poses significant challenges due tothe inherent sparsity and noise in gaze data, as well as the need for highconsistency and physical plausibility in generating hand and object motions. Totackle these issues, we propose a stacked gaze-guided hand-object interactiondiffusion model, named GHO-Diffusion. The stacked design effectively reducesthe complexity of motion generation. We also introduce HOI-Manifold Guidanceduring the sampling stage of GHO-Diffusion, enabling fine-grained control overgenerated motions while maintaining the data manifold. Additionally, we proposea spatial-temporal gaze feature encoding for the diffusion condition and selectdiffusion results based on consistency scores between gaze-contact maps andgaze-interaction trajectories. Extensive experiments highlight theeffectiveness of our method and the unique contributions of our dataset. Moredetails in https://takiee.github.io/gaze-hoi/.</description><author>Jie Tian, Ran Ji, Lingxiao Yang, Suting Ni, Yuexin Ma, Lan Xu, Jingyi Yu, Ye Shi, Jingya Wang</author><pubDate>Tue, 07 Jan 2025 14:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16169v5</guid></item></channel></rss>