<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 04 Sep 2024 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Bridging Episodes and Semantics: A Novel Framework for Long-Form Video Understanding</title><link>http://arxiv.org/abs/2408.17443v1</link><description>While existing research often treats long-form videos as extended shortvideos, we propose a novel approach that more accurately reflects humancognition. This paper introduces BREASE: BRidging Episodes And SEmantics forLong-Form Video Understanding, a model that simulates episodic memoryaccumulation to capture action sequences and reinforces them with semanticknowledge dispersed throughout the video. Our work makes two key contributions:First, we develop an Episodic COmpressor (ECO) that efficiently aggregatescrucial representations from micro to semi-macro levels. Second, we propose aSemantics reTRiever (SeTR) that enhances these aggregated representations withsemantic information by focusing on the broader context, dramatically reducingfeature dimensionality while preserving relevant macro-level information.Extensive experiments demonstrate that BREASE achieves state-of-the-artperformance across multiple long video understanding benchmarks in bothzero-shot and fully-supervised settings. The project page and code are at:https://joslefaure.github.io/assets/html/hermes.html.</description><author>Gueter Josmy Faure, Jia-Fong Yeh, Min-Hung Chen, Hung-Ting Su, Winston H. Hsu, Shang-Hong Lai</author><pubDate>Fri, 30 Aug 2024 17:52:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17443v1</guid></item><item><title>SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists</title><link>http://arxiv.org/abs/2408.17437v1</link><description>Traditional benchmarking in NLP typically involves using static held-out testsets. However, this approach often results in an overestimation of performanceand lacks the ability to offer comprehensive, interpretable, and dynamicassessments of NLP models. Recently, works like DynaBench (Kiela et al., 2021)and CheckList (Ribeiro et al., 2020) have addressed these limitations throughbehavioral testing of NLP models with test types generated by a multistephuman-annotated pipeline. Unfortunately, manually creating a variety of testtypes requires much human labor, often at prohibitive cost. In this work, wepropose SYNTHEVAL, a hybrid behavioral testing framework that leverages largelanguage models (LLMs) to generate a wide range of test types for acomprehensive evaluation of NLP models. SYNTHEVAL first generates sentences viaLLMs using controlled generation, and then identifies challenging examples bycomparing the predictions made by LLMs with task-specific NLP models. In thelast stage, human experts investigate the challenging examples, manually designtemplates, and identify the types of failures the taskspecific modelsconsistently exhibit. We apply SYNTHEVAL to two classification tasks, sentimentanalysis and toxic language detection, and show that our framework is effectivein identifying weaknesses of strong models on these tasks. We share our code inhttps://github.com/Loreley99/SynthEval_CheckList.</description><author>Raoyuan Zhao, Abdullatif Köksal, Yihong Liu, Leonie Weissweiler, Anna Korhonen, Hinrich Schütze</author><pubDate>Fri, 30 Aug 2024 17:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17437v1</guid></item><item><title>Frankenstein: Generating Semantic-Compositional 3D Scenes in One Tri-Plane</title><link>http://arxiv.org/abs/2403.16210v2</link><description>We present Frankenstein, a diffusion-based framework that can generatesemantic-compositional 3D scenes in a single pass. Unlike existing methods thatoutput a single, unified 3D shape, Frankenstein simultaneously generatesmultiple separated shapes, each corresponding to a semantically meaningfulpart. The 3D scene information is encoded in one single tri-plane tensor, fromwhich multiple Singed Distance Function (SDF) fields can be decoded torepresent the compositional shapes. During training, an auto-encoder compressestri-planes into a latent space, and then the denoising diffusion process isemployed to approximate the distribution of the compositional scenes.Frankenstein demonstrates promising results in generating room interiors aswell as human avatars with automatically separated parts. The generated scenesfacilitate many downstream applications, such as part-wise re-texturing, objectrearrangement in the room or avatar cloth re-targeting. Our project page isavailable at: https://wolfball.github.io/frankenstein/.</description><author>Han Yan, Yang Li, Zhennan Wu, Shenzhou Chen, Weixuan Sun, Taizhang Shang, Weizhe Liu, Tian Chen, Xiaqiang Dai, Chao Ma, Hongdong Li, Pan Ji</author><pubDate>Fri, 30 Aug 2024 17:39:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16210v2</guid></item><item><title>Quantum Distance Approximation for Persistence Diagrams</title><link>http://arxiv.org/abs/2402.17295v2</link><description>Topological Data Analysis methods can be useful for classification andclustering tasks in many different fields as they can provide two dimensionalpersistence diagrams that summarize important information about the shape ofpotentially complex and high dimensional data sets. The space of persistencediagrams can be endowed with various metrics such as the Wasserstein distancewhich admit a statistical structure and allow to use these summaries formachine learning algorithms. However, computing the distance between twopersistence diagrams involves finding an optimal way to match the points of thetwo diagrams and may not always be an easy task for classical computers. Inthis work we explore the potential of quantum computers to estimate thedistance between persistence diagrams, in particular we propose variationalquantum algorithms for the Wasserstein distance as well as the $d^{c}_{p}$distance. Our implementation is a weighted version of the Quantum ApproximateOptimization Algorithm that relies on control clauses to encode the constraintsof the optimization problem.</description><author>Bernardo Ameneyro, Rebekah Herrman, George Siopsis, Vasileios Maroulas</author><pubDate>Fri, 30 Aug 2024 17:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17295v2</guid></item><item><title>DARES: Depth Anything in Robotic Endoscopic Surgery with Self-supervised Vector-LoRA of the Foundation Model</title><link>http://arxiv.org/abs/2408.17433v1</link><description>Robotic-assisted surgery (RAS) relies on accurate depth estimation for 3Dreconstruction and visualization. While foundation models like Depth AnythingModels (DAM) show promise, directly applying them to surgery often yieldssuboptimal results. Fully fine-tuning on limited surgical data can causeoverfitting and catastrophic forgetting, compromising model robustness andgeneralization. Although Low-Rank Adaptation (LoRA) addresses some adaptationissues, its uniform parameter distribution neglects the inherent featurehierarchy, where earlier layers, learning more general features, require moreparameters than later ones. To tackle this issue, we introduce Depth Anythingin Robotic Endoscopic Surgery (DARES), a novel approach that employs a newadaptation technique, Vector Low-Rank Adaptation (Vector-LoRA) on the DAM V2 toperform self-supervised monocular depth estimation in RAS scenes. To enhancelearning efficiency, we introduce Vector-LoRA by integrating more parameters inearlier layers and gradually decreasing parameters in later layers. We alsodesign a reprojection loss based on the multi-scale SSIM error to enhance depthperception by better tailoring the foundation model to the specificrequirements of the surgical environment. The proposed method is validated onthe SCARED dataset and demonstrates superior performance over recentstate-of-the-art self-supervised monocular depth estimation techniques,achieving an improvement of 13.3% in the absolute relative error metric. Thecode and pre-trained weights are available athttps://github.com/mobarakol/DARES.</description><author>Mona Sheikh Zeinoddin, Chiara Lena, Jiongqi Qu, Luca Carlini, Mattia Magro, Seunghoi Kim, Elena De Momi, Sophia Bano, Matthew Grech-Sollars, Evangelos Mazomenos, Daniel C. Alexander, Danail Stoyanov, Matthew J. Clarkson, Mobarakol Islam</author><pubDate>Fri, 30 Aug 2024 17:35:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17433v1</guid></item><item><title>SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection</title><link>http://arxiv.org/abs/2408.17432v1</link><description>Synthesizing the voices of unseen speakers is a persisting challenge inmulti-speaker text-to-speech (TTS). Most multi-speaker TTS models rely onmodeling speaker characteristics through speaker conditioning during training.Modeling unseen speaker attributes through this approach has necessitated anincrease in model complexity, which makes it challenging to reproduce resultsand improve upon them. We design a simple alternative to this. We proposeSelectTTS, a novel method to select the appropriate frames from the targetspeaker and decode using frame-level self-supervised learning (SSL) features.We show that this approach can effectively capture speaker characteristics forunseen speakers, and achieves comparable results to other multi-speaker TTSframeworks in both objective and subjective metrics. With SelectTTS, we showthat frame selection from the target speaker's speech is a direct way toachieve generalization in unseen speakers with low model complexity. We achievebetter speaker similarity performance than SOTA baselines XTTS-v2 and VALL-Ewith over an 8x reduction in model parameters and a 270x reduction in trainingdata</description><author>Ismail Rasim Ulgen, Shreeram Suresh Chandra, Junchen Lu, Berrak Sisman</author><pubDate>Fri, 30 Aug 2024 17:34:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17432v1</guid></item><item><title>Advancing Multi-talker ASR Performance with Large Language Models</title><link>http://arxiv.org/abs/2408.17431v1</link><description>Recognizing overlapping speech from multiple speakers in conversationalscenarios is one of the most challenging problem for automatic speechrecognition (ASR). Serialized output training (SOT) is a classic method toaddress multi-talker ASR, with the idea of concatenating transcriptions frommultiple speakers according to the emission times of their speech for training.However, SOT-style transcriptions, derived from concatenating multiple relatedutterances in a conversation, depend significantly on modeling long contexts.Therefore, compared to traditional methods that primarily emphasize encoderperformance in attention-based encoder-decoder (AED) architectures, a novelapproach utilizing large language models (LLMs) that leverages the capabilitiesof pre-trained decoders may be better suited for such complex and challengingscenarios. In this paper, we propose an LLM-based SOT approach for multi-talkerASR, leveraging pre-trained speech encoder and LLM, fine-tuning them onmulti-talker dataset using appropriate strategies. Experimental resultsdemonstrate that our approach surpasses traditional AED-based methods on thesimulated dataset LibriMix and achieves state-of-the-art performance on theevaluation set of the real-world dataset AMI, outperforming the AED modeltrained with 1000 times more supervised data in previous works.</description><author>Mohan Shi, Zengrui Jin, Yaoxun Xu, Yong Xu, Shi-Xiong Zhang, Kun Wei, Yiwen Shao, Chunlei Zhang, Dong Yu</author><pubDate>Fri, 30 Aug 2024 17:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17431v1</guid></item><item><title>CLOCR-C: Context Leveraging OCR Correction with Pre-trained Language Models</title><link>http://arxiv.org/abs/2408.17428v1</link><description>The digitisation of historical print media archives is crucial for increasingaccessibility to contemporary records. However, the process of OpticalCharacter Recognition (OCR) used to convert physical records to digital text isprone to errors, particularly in the case of newspapers and periodicals due totheir complex layouts. This paper introduces Context Leveraging OCR Correction(CLOCR-C), which utilises the infilling and context-adaptive abilities oftransformer-based language models (LMs) to improve OCR quality. The study aimsto determine if LMs can perform post-OCR correction, improve downstream NLPtasks, and the value of providing the socio-cultural context as part of thecorrection process. Experiments were conducted using seven LMs on threedatasets: the 19th Century Serials Edition (NCSE) and two datasets from theOverproof collection. The results demonstrate that some LMs can significantlyreduce error rates, with the top-performing model achieving over a 60%reduction in character error rate on the NCSE dataset. The OCR improvementsextend to downstream tasks, such as Named Entity Recognition, with increasedCosine Named Entity Similarity. Furthermore, the study shows that providingsocio-cultural context in the prompts improves performance, while misleadingprompts lower performance. In addition to the findings, this study releases adataset of 91 transcribed articles from the NCSE, containing a total of 40thousand words, to support further research in this area. The findings suggestthat CLOCR-C is a promising approach for enhancing the quality of existingdigital archives by leveraging the socio-cultural information embedded in theLMs and the text requiring correction.</description><author>Jonathan Bourne</author><pubDate>Fri, 30 Aug 2024 17:26:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17428v1</guid></item><item><title>A Survey on Knowledge Editing of Neural Networks</title><link>http://arxiv.org/abs/2310.19704v3</link><description>Deep neural networks are becoming increasingly pervasive in academia andindustry, matching and surpassing human performance on a wide variety of fieldsand related tasks. However, just as humans, even the largest artificial neuralnetworks make mistakes, and once-correct predictions can become invalid as theworld progresses in time. Augmenting datasets with samples that account formistakes or up-to-date information has become a common workaround in practicalapplications. However, the well-known phenomenon of catastrophic forgettingposes a challenge in achieving precise changes in the implicitly memorizedknowledge of neural network parameters, often requiring a full modelre-training to achieve desired behaviors. That is expensive, unreliable, andincompatible with the current trend of large self-supervised pre-training,making it necessary to find more efficient and effective methods for adaptingneural network models to changing data. To address this need, knowledge editingis emerging as a novel area of research that aims to enable reliable,data-efficient, and fast changes to a pre-trained target model, withoutaffecting model behaviors on previously learned tasks. In this survey, weprovide a brief review of this recent artificial intelligence field ofresearch. We first introduce the problem of editing neural networks, formalizeit in a common framework and differentiate it from more notorious branches ofresearch such as continuous learning. Next, we provide a review of the mostrelevant knowledge editing approaches and datasets proposed so far, groupingworks under four different families: regularization techniques, meta-learning,direct model editing, and architectural strategies. Finally, we outline someintersections with other fields of research and potential directions for futureworks.</description><author>Vittorio Mazzia, Alessandro Pedrani, Andrea Caciolai, Kay Rottmann, Davide Bernardi</author><pubDate>Fri, 30 Aug 2024 17:22:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19704v3</guid></item><item><title>CinePreGen: Camera Controllable Video Previsualization via Engine-powered Diffusion</title><link>http://arxiv.org/abs/2408.17424v1</link><description>With advancements in video generative AI models (e.g., SORA), creators areincreasingly using these techniques to enhance video previsualization. However,they face challenges with incomplete and mismatched AI workflows. Existingmethods mainly rely on text descriptions and struggle with camera placement, akey component of previsualization. To address these issues, we introduceCinePreGen, a visual previsualization system enhanced with engine-powereddiffusion. It features a novel camera and storyboard interface that offersdynamic control, from global to local camera adjustments. This is combined witha user-friendly AI rendering workflow, which aims to achieve consistent resultsthrough multi-masked IP-Adapter and engine simulation guidelines. In ourcomprehensive evaluation study, we demonstrate that our system reducesdevelopment viscosity (i.e., the complexity and challenges in the developmentprocess), meets users' needs for extensive control and iteration in the designprocess, and outperforms other AI video production workflows in cinematiccamera movement, as shown by our experiments and a within-subjects user study.With its intuitive camera controls and realistic rendering of camera motion,CinePreGen shows great potential for improving video production for bothindividual creators and industry professionals.</description><author>Yiran Chen, Anyi Rao, Xuekun Jiang, Shishi Xiao, Ruiqing Ma, Zeyu Wang, Hui Xiong, Bo Dai</author><pubDate>Fri, 30 Aug 2024 17:16:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17424v1</guid></item><item><title>Open-vocabulary Temporal Action Localization using VLMs</title><link>http://arxiv.org/abs/2408.17422v1</link><description>Video action localization aims to find timings of a specific action from along video. Although existing learning-based approaches have been successful,those require annotating videos that come with a considerable labor cost. Thispaper proposes a learning-free, open-vocabulary approach based on emergingvision-language models (VLM). The challenge stems from the fact that VLMs areneither designed to process long videos nor tailored for finding actions. Weovercome these problems by extending an iterative visual prompting technique.Specifically, we sample video frames into a concatenated image with frame indexlabels, making a VLM guess a frame that is considered to be closest to thestart/end of the action. Iterating this process by narrowing a sampling timewindow results in finding a specific frame of start and end of an action. Wedemonstrate that this sampling technique yields reasonable results,illustrating a practical extension of VLMs for understanding videos.</description><author>Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi</author><pubDate>Fri, 30 Aug 2024 17:12:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17422v1</guid></item><item><title>Generative AI Enables Medical Image Segmentation in Ultra Low-Data Regimes</title><link>http://arxiv.org/abs/2408.17421v1</link><description>Semantic segmentation of medical images is pivotal in applications likedisease diagnosis and treatment planning. While deep learning has excelled inautomating this task, a major hurdle is the need for numerous annotatedsegmentation masks, which are resource-intensive to produce due to the requiredexpertise and time. This scenario often leads to ultra low-data regimes, whereannotated images are extremely limited, posing significant challenges for thegeneralization of conventional deep learning methods on test images. To addressthis, we introduce a generative deep learning framework, which uniquelygenerates high-quality paired segmentation masks and medical images, serving asauxiliary data for training robust models in data-scarce environments. Unliketraditional generative models that treat data generation and segmentation modeltraining as separate processes, our method employs multi-level optimization forend-to-end data generation. This approach allows segmentation performance todirectly influence the data generation process, ensuring that the generateddata is specifically tailored to enhance the performance of the segmentationmodel. Our method demonstrated strong generalization performance across 9diverse medical image segmentation tasks and on 16 datasets, in ultra-low dataregimes, spanning various diseases, organs, and imaging modalities. Whenapplied to various segmentation models, it achieved performance improvements of10-20\% (absolute), in both same-domain and out-of-domain scenarios. Notably,it requires 8 to 20 times less training data than existing methods to achievecomparable results. This advancement significantly improves the feasibility andcost-effectiveness of applying deep learning in medical imaging, particularlyin scenarios with limited data availability.</description><author>Li Zhang, Basu Jindal, Ahmed Alaa, Robert Weinreb, David Wilson, Eran Segal, James Zou, Pengtao Xie</author><pubDate>Fri, 30 Aug 2024 17:11:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17421v1</guid></item><item><title>Evaluating Named Entity Recognition: A comparative analysis of mono- and multilingual transformer models on a novel Brazilian corporate earnings call transcripts dataset</title><link>http://arxiv.org/abs/2403.12212v2</link><description>Since 2018, when the Transformer architecture was introduced, NaturalLanguage Processing has gained significant momentum with pre-trainedTransformer-based models that can be fine-tuned for various tasks. Most modelsare pre-trained on large English corpora, making them less applicable to otherlanguages, such as Brazilian Portuguese. In our research, we identified twomodels pre-trained in Brazilian Portuguese (BERTimbau and PTT5) and twomultilingual models (mBERT and mT5). BERTimbau and mBERT use only the Encodermodule, while PTT5 and mT5 use both the Encoder and Decoder. Our study aimed toevaluate their performance on a financial Named Entity Recognition (NER) taskand determine the computational requirements for fine-tuning and inference. Tothis end, we developed the Brazilian Financial NER (BraFiNER) dataset,comprising sentences from Brazilian banks' earnings calls transcripts annotatedusing a weakly supervised approach. Additionally, we introduced a novelapproach that reframes the token classification task as a text generationproblem. After fine-tuning the models, we evaluated them using performance anderror metrics. Our findings reveal that BERT-based models consistentlyoutperform T5-based models. While the multilingual models exhibit comparablemacro F1-scores, BERTimbau demonstrates superior performance over PTT5. Interms of error metrics, BERTimbau outperforms the other models. We alsoobserved that PTT5 and mT5 generated sentences with changes in monetary andpercentage values, highlighting the importance of accuracy and consistency inthe financial domain. Our findings provide insights into the differingperformance of BERT- and T5-based models for the NER task.</description><author>Ramon Abilio, Guilherme Palermo Coelho, Ana Estela Antunes da Silva</author><pubDate>Fri, 30 Aug 2024 17:02:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12212v2</guid></item><item><title>Can We Remove the Square-Root in Adaptive Gradient Methods? A Second-Order Perspective</title><link>http://arxiv.org/abs/2402.03496v9</link><description>Adaptive gradient optimizers like Adam(W) are the default training algorithmsfor many deep learning architectures, such as transformers. Their diagonalpreconditioner is based on the gradient outer product which is incorporatedinto the parameter update via a square root. While these methods are oftenmotivated as approximate second-order methods, the square root represents afundamental difference. In this work, we investigate how the behavior ofadaptive methods changes when we remove the root, i.e., strengthen theirsecond-order motivation. Surprisingly, we find that such square-root-freeadaptive methods close the generalization gap to SGD on convolutionalarchitectures, while maintaining their root-based counterpart's performance ontransformers. The second-order perspective also has practical benefits fordeveloping non-diagonal methods that can incorporate arbitrary curvatureapproximations through the concept of preconditioner invariance. In contrast toroot-based methods like Shampoo, root-free counterparts work well and fast withhalf-precision since they do not require numerically unstable matrix rootdecompositions and inversions. Overall, our findings provide new insights intothe development of adaptive methods and raise important questions regarding theoverlooked role of adaptivity in their success. (experiment code:https://github.com/yorkerlin/remove-the-square-root optimizer code:https://github.com/f-dangel/sirfshampoo)</description><author>Wu Lin, Felix Dangel, Runa Eschenhagen, Juhan Bae, Richard E. Turner, Alireza Makhzani</author><pubDate>Fri, 30 Aug 2024 16:45:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03496v9</guid></item><item><title>Getting Inspiration for Feature Elicitation: App Store- vs. LLM-based Approach</title><link>http://arxiv.org/abs/2408.17404v1</link><description>Over the past decade, app store (AppStore)-inspired requirements elicitationhas proven to be highly beneficial. Developers often explore competitors' appsto gather inspiration for new features. With the advance of Generative AI,recent studies have demonstrated the potential of large language model(LLM)-inspired requirements elicitation. LLMs can assist in this process byproviding inspiration for new feature ideas. While both approaches are gainingpopularity in practice, there is a lack of insight into their differences. Wereport on a comparative study between AppStore- and LLM-based approaches forrefining features into sub-features. By manually analyzing 1,200 sub-featuresrecommended from both approaches, we identified their benefits, challenges, andkey differences. While both approaches recommend highly relevant sub-featureswith clear descriptions, LLMs seem more powerful particularly concerning novelunseen app scopes. Moreover, some recommended features are imaginary withunclear feasibility, which suggests the importance of a human-analyst in theelicitation loop.</description><author>Jialiang Wei, Anne-Lise Courbis, Thomas Lambolais, Binbin Xu, Pierre Louis Bernard, Gérard Dray, Walid Maalej</author><pubDate>Fri, 30 Aug 2024 16:42:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17404v1</guid></item><item><title>Exploring Group and Symmetry Principles in Large Language Models</title><link>http://arxiv.org/abs/2402.06120v2</link><description>Large Language Models (LLMs) have demonstrated impressive performance acrossa wide range of applications; however, assessing their reasoning capabilitiesremains a significant challenge. In this paper, we introduce a frameworkgrounded in group and symmetry principles, which have played a crucial role infields such as physics and mathematics, and offer another way to evaluate theircapabilities. While the proposed framework is general, to showcase the benefitsof employing these properties, we focus on arithmetic reasoning and investigatethe performance of these models on four group properties: closure, identity,inverse, and associativity. Our findings reveal that LLMs studied in this workstruggle to preserve group properties across different test regimes. In theclosure test, we observe biases towards specific outputs and an abruptdegradation in their performance from 100% to 0% after a specific sequencelength. They also perform poorly in the identity test, which represents addingirrelevant information in the context, and show sensitivity when subjected toinverse test, which examines the robustness of the model with respect tonegation. In addition, we demonstrate that breaking down problems into smallersteps helps LLMs in the associativity test that we have conducted. To supportthese tests we have developed a synthetic dataset which will be released.</description><author>Shima Imani, Hamid Palangi</author><pubDate>Fri, 30 Aug 2024 16:42:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06120v2</guid></item><item><title>Hoaxpedia: A Unified Wikipedia Hoax Articles Dataset</title><link>http://arxiv.org/abs/2405.02175v3</link><description>Hoaxes are a recognised form of disinformation created deliberately, withpotential serious implications in the credibility of reference knowledgeresources such as Wikipedia. What makes detecting Wikipedia hoaxes hard is thatthey often are written according to the official style guidelines. In thiswork, we first provide a systematic analysis of similarities and discrepanciesbetween legitimate and hoax Wikipedia articles, and introduce Hoaxpedia, acollection of 311 hoax articles (from existing literature and officialWikipedia lists), together with semantically similar legitimate articles, whichtogether form a binary text classification dataset aimed at fostering researchin automated hoax detection. In this paper, We report results after analyzingseveral language models, hoax-to-legit ratios, and the amount of textclassifiers are exposed to (full article vs the article's definition alone).Our results suggest that detecting deceitful content in Wikipedia based oncontent alone is hard but feasible, and complement our analysis with a study onthe differences in distributions in edit histories, and find that looking atthis feature yields better classification results than context.</description><author>Hsuvas Borkakoty, Luis Espinosa-Anke</author><pubDate>Fri, 30 Aug 2024 16:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02175v3</guid></item><item><title>Exploring the Effect of Explanation Content and Format on User Comprehension and Trust</title><link>http://arxiv.org/abs/2408.17401v1</link><description>In recent years, various methods have been introduced for explaining theoutputs of "black-box" AI models. However, it is not well understood whetherusers actually comprehend and trust these explanations. In this paper, we focuson explanations for a regression tool for assessing cancer risk and examine theeffect of the explanations' content and format on the user-centric metrics ofcomprehension and trust. Regarding content, we experiment with two explanationmethods: the popular SHAP, based on game-theoretic notions and thus potentiallycomplex for everyday users to comprehend, and occlusion-1, based on featureocclusion which may be more comprehensible. Regarding format, we present SHAPexplanations as charts (SC), as is conventional, and occlusion-1 explanationsas charts (OC) as well as text (OT), to which their simpler nature also lendsitself. The experiments amount to user studies questioning participants, withtwo different levels of expertise (the general population and those with somemedical training), on their subjective and objective comprehension of and trustin explanations for the outputs of the regression tool. In both studies wefound a clear preference in terms of subjective comprehension and trust forocclusion-1 over SHAP explanations in general, when comparing based on content.However, direct comparisons of explanations when controlling for format onlyrevealed evidence for OT over SC explanations in most cases, suggesting thatthe dominance of occlusion-1 over SHAP explanations may be driven by apreference for text over charts as explanations. Finally, we found no evidenceof a difference between the explanation types in terms of objectivecomprehension. Thus overall, the choice of the content and format ofexplanations needs careful attention, since in some contexts format, ratherthan content, may play the critical role in improving user experience.</description><author>Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni</author><pubDate>Fri, 30 Aug 2024 16:36:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17401v1</guid></item><item><title>How Knowledge Distillation Mitigates the Synthetic Gap in Fair Face Recognition</title><link>http://arxiv.org/abs/2408.17399v1</link><description>Leveraging the capabilities of Knowledge Distillation (KD) strategies, wedevise a strategy to fight the recent retraction of face recognition datasets.Given a pretrained Teacher model trained on a real dataset, we show thatcarefully utilising synthetic datasets, or a mix between real and syntheticdatasets to distil knowledge from this teacher to smaller students can yieldsurprising results. In this sense, we trained 33 different models with andwithout KD, on different datasets, with different architectures and losses. Andour findings are consistent, using KD leads to performance gains across allethnicities and decreased bias. In addition, it helps to mitigate theperformance gap between real and synthetic datasets. This approach addressesthe limitations of synthetic data training, improving both the accuracy andfairness of face recognition models.</description><author>Pedro C. Neto, Ivona Colakovic, Sašo Karakatič, Ana F. Sequeira</author><pubDate>Fri, 30 Aug 2024 16:35:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17399v1</guid></item><item><title>DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model Transformer for Multimodal Aspect-based Sentiment Analysis</title><link>http://arxiv.org/abs/2408.15379v2</link><description>Multimodal aspect-based sentiment analysis (MABSA) enhances sentimentdetection by combining text with other data types like images. However, despitesetting significant benchmarks, attention mechanisms exhibit limitations inefficiently modelling long-range dependencies between aspect and opiniontargets within the text. They also face challenges in capturing global-contextdependencies for visual representations. To this end, we proposeKolmogorov-Arnold Networks (KANs) and Selective State Space model (Mamba)transformer (DualKanbaFormer), a novel architecture to address the aboveissues. We leverage the power of Mamba to capture global context dependencies,Multi-head Attention (MHA) to capture local context dependencies, and KANs tocapture non-linear modelling patterns for both textual representations (textualKanbaFormer) and visual representations (visual KanbaFormer). Furthermore, wefuse the textual KanbaFormer and visual KanbaFomer with a gated fusion layer tocapture the inter-modality dynamics. According to extensive experimentalresults, our model outperforms some state-of-the-art (SOTA) studies on twopublic datasets.</description><author>Adamu Lawan, Juhua Pu, Haruna Yunusa, Muhammad Lawan, Aliyu Umar, Adamu Sani Yahya</author><pubDate>Fri, 30 Aug 2024 16:30:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15379v2</guid></item><item><title>Fairness-Aware Estimation of Graphical Models</title><link>http://arxiv.org/abs/2408.17396v1</link><description>This paper examines the issue of fairness in the estimation of graphicalmodels (GMs), particularly Gaussian, Covariance, and Ising models. These modelsplay a vital role in understanding complex relationships in high-dimensionaldata. However, standard GMs can result in biased outcomes, especially when theunderlying data involves sensitive characteristics or protected groups. Toaddress this, we introduce a comprehensive framework designed to reduce bias inthe estimation of GMs related to protected attributes. Our approach involvesthe integration of the pairwise graph disparity error and a tailored lossfunction into a nonsmooth multi-objective optimization problem, striving toachieve fairness across different sensitive groups while maintaining theeffectiveness of the GMs. Experimental evaluations on synthetic and real-worlddatasets demonstrate that our framework effectively mitigates bias withoutundermining GMs' performance.</description><author>Zhuoping Zhou, Davoud Ataee Tarzanagh, Bojian Hou, Qi Long, Li Shen</author><pubDate>Fri, 30 Aug 2024 16:30:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17396v1</guid></item><item><title>Continual learning with the neural tangent ensemble</title><link>http://arxiv.org/abs/2408.17394v1</link><description>A natural strategy for continual learning is to weigh a Bayesian ensemble offixed functions. This suggests that if a (single) neural network could beinterpreted as an ensemble, one could design effective algorithms that learnwithout forgetting. To realize this possibility, we observe that a neuralnetwork classifier with N parameters can be interpreted as a weighted ensembleof N classifiers, and that in the lazy regime limit these classifiers are fixedthroughout learning. We term these classifiers the neural tangent experts andshow they output valid probability distributions over the labels. We thenderive the likelihood and posterior probability of each expert given past data.Surprisingly, we learn that the posterior updates for these experts areequivalent to a scaled and projected form of stochastic gradient descent (SGD)over the network weights. Away from the lazy regime, networks can be seen asensembles of adaptive experts which improve over time. These results offer anew interpretation of neural networks as Bayesian ensembles of experts,providing a principled framework for understanding and mitigating catastrophicforgetting in continual learning settings.</description><author>Ari S. Benjamin, Christian Pehle, Kyle Daruwalla</author><pubDate>Fri, 30 Aug 2024 16:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17394v1</guid></item><item><title>Bayesian Optimization for Non-Convex Two-Stage Stochastic Optimization Problems</title><link>http://arxiv.org/abs/2408.17387v1</link><description>Bayesian optimization is a sample-efficient method for solving expensive,black-box optimization problems. Stochastic programming concerns optimizationunder uncertainty where, typically, average performance is the quantity ofinterest. In the first stage of a two-stage problem, here-and-now decisionsmust be made in the face of this uncertainty, while in the second stage,wait-and-see decisions are made after the uncertainty has been resolved. Manymethods in stochastic programming assume that the objective is cheap toevaluate and linear or convex. In this work, we apply Bayesian optimization tosolve non-convex, two-stage stochastic programs which are expensive toevaluate. We formulate a knowledge-gradient-based acquisition function tojointly optimize the first- and second-stage variables, establish a guaranteeof asymptotic consistency and provide a computationally efficientapproximation. We demonstrate comparable empirical results to an alternative weformulate which alternates its focus between the two variable types, andsuperior empirical results over the standard, naive, two-step benchmark. Weshow that differences in the dimension and length scales between the variabletypes can lead to inefficiencies of the two-step algorithm, while the joint andalternating acquisition functions perform well in all problems tested.Experiments are conducted on both synthetic and real-world examples.</description><author>Jack M. Buckingham, Ivo Couckuyt, Juergen Branke</author><pubDate>Fri, 30 Aug 2024 16:26:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17387v1</guid></item><item><title>LASSO-MOGAT: A Multi-Omics Graph Attention Framework for Cancer Classification</title><link>http://arxiv.org/abs/2408.17384v1</link><description>The application of machine learning methods to analyze changes in geneexpression patterns has recently emerged as a powerful approach in cancerresearch, enhancing our understanding of the molecular mechanisms underpinningcancer development and progression. Combining gene expression data with othertypes of omics data has been reported by numerous works to improve cancerclassification outcomes. Despite these advances, effectively integratinghigh-dimensional multi-omics data and capturing the complex relationshipsacross different biological layers remains challenging. This paper introducesLASSO-MOGAT (LASSO-Multi-Omics Gated ATtention), a novel graph-based deeplearning framework that integrates messenger RNA, microRNA, and DNA methylationdata to classify 31 cancer types. Utilizing differential expression analysiswith LIMMA and LASSO regression for feature selection, and leveraging GraphAttention Networks (GATs) to incorporate protein-protein interaction (PPI)networks, LASSO-MOGAT effectively captures intricate relationships withinmulti-omics data. Experimental validation using five-fold cross-validationdemonstrates the method's precision, reliability, and capacity for providingcomprehensive insights into cancer molecular mechanisms. The computation ofattention coefficients for the edges in the graph by the proposedgraph-attention architecture based on protein-protein interactions provedbeneficial for identifying synergies in multi-omics data for cancerclassification.</description><author>Fadi Alharbi, Aleksandar Vakanski, Murtada K. Elbashir, Mohanad Mohammed</author><pubDate>Fri, 30 Aug 2024 16:26:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17384v1</guid></item><item><title>MoRe Fine-Tuning with 10x Fewer Parameters</title><link>http://arxiv.org/abs/2408.17383v1</link><description>Parameter-efficient fine-tuning (PEFT) techniques have unlocked the potentialto cheaply and easily specialize large pretrained models. However, the mostprominent approaches, like low-rank adapters (LoRA), depend on heuristics orrules-of-thumb for their architectural choices -- potentially limiting theirperformance for new models and architectures. This limitation suggests thattechniques from neural architecture search could be used to obtain optimaladapter architectures, but these are often expensive and difficult toimplement. We address this challenge with Monarch Rectangular Fine-tuning(MoRe), a simple framework to search over adapter architectures that relies onthe Monarch matrix class. Theoretically, we show that MoRe is more expressivethan LoRA. Empirically, our approach is more parameter-efficient and performantthan state-of-the-art PEFTs on a range of tasks and models, with as few as 5\%of LoRA's parameters.</description><author>Wenxuan Tan, Nicholas Roberts, Tzu-Heng Huang, Jitian Zhao, John Cooper, Samuel Guo, Chengyu Duan, Frederic Sala</author><pubDate>Fri, 30 Aug 2024 16:24:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17383v1</guid></item><item><title>Question-Based Retrieval using Atomic Units for Enterprise RAG</title><link>http://arxiv.org/abs/2405.12363v2</link><description>Enterprise retrieval augmented generation (RAG) offers a highly flexibleframework for combining powerful large language models (LLMs) with internal,possibly temporally changing, documents. In RAG, documents are first chunked.Relevant chunks are then retrieved for a user query, which are passed ascontext to a synthesizer LLM to generate the query response. However, theretrieval step can limit performance, as incorrect chunks can lead thesynthesizer LLM to generate a false response. This work applies a zero-shotadaptation of standard dense retrieval steps for more accurate chunk recall.Specifically, a chunk is first decomposed into atomic statements. A set ofsynthetic questions are then generated on these atoms (with the chunk as thecontext). Dense retrieval involves finding the closest set of syntheticquestions, and associated chunks, to the user query. It is found that retrievalwith the atoms leads to higher recall than retrieval with chunks. Furtherperformance gain is observed with retrieval using the synthetic questionsgenerated over the atoms. Higher recall at the retrieval step enables higherperformance of the enterprise LLM using the RAG pipeline.</description><author>Vatsal Raina, Mark Gales</author><pubDate>Fri, 30 Aug 2024 16:23:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12363v2</guid></item><item><title>Traffic expertise meets residual RL: Knowledge-informed model-based residual reinforcement learning for CAV trajectory control</title><link>http://arxiv.org/abs/2408.17380v1</link><description>Model-based reinforcement learning (RL) is anticipated to exhibit highersample efficiency compared to model-free RL by utilizing a virtual environmentmodel. However, it is challenging to obtain sufficiently accuraterepresentations of the environmental dynamics due to uncertainties in complexsystems and environments. An inaccurate environment model may degrade thesample efficiency and performance of model-based RL. Furthermore, whilemodel-based RL can improve sample efficiency, it often still requiressubstantial training time to learn from scratch, potentially limiting itsadvantages over model-free approaches. To address these challenges, this paperintroduces a knowledge-informed model-based residual reinforcement learningframework aimed at enhancing learning efficiency by infusing established expertknowledge into the learning process and avoiding the issue of beginning fromzero. Our approach integrates traffic expert knowledge into a virtualenvironment model, employing the Intelligent Driver Model (IDM) for basicdynamics and neural networks for residual dynamics, thus ensuring adaptabilityto complex scenarios. We propose a novel strategy that combines traditionalcontrol methods with residual RL, facilitating efficient learning and policyoptimization without the need to learn from scratch. The proposed approach isapplied to CAV trajectory control tasks for the dissipation of stop-and-gowaves in mixed traffic flow. Experimental results demonstrate that our proposedapproach enables the CAV agent to achieve superior performance in trajectorycontrol compared to the baseline agents in terms of sample efficiency, trafficflow smoothness and traffic mobility. The source code and supplementarymaterials are available at https://github.com/zihaosheng/traffic-expertise-RL/.</description><author>Zihao Sheng, Zilin Huang, Sikai Chen</author><pubDate>Fri, 30 Aug 2024 16:16:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17380v1</guid></item><item><title>EMPOWER: Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution</title><link>http://arxiv.org/abs/2408.17379v1</link><description>Task planning for robots in real-life settings presents significantchallenges. These challenges stem from three primary issues: the difficulty inidentifying grounded sequences of steps to achieve a goal; the lack of astandardized mapping between high-level actions and low-level commands; and thechallenge of maintaining low computational overhead given the limited resourcesof robotic hardware. We introduce EMPOWER, a framework designed foropen-vocabulary online grounding and planning for embodied agents aimed ataddressing these issues. By leveraging efficient pre-trained foundation modelsand a multi-role mechanism, EMPOWER demonstrates notable improvements ingrounded planning and execution. Quantitative results highlight theeffectiveness of our approach, achieving an average success rate of 0.73 acrosssix different real-life scenarios using a TIAGo robot.</description><author>Francesco Argenziano, Michele Brienza, Vincenzo Suriani, Daniele Nardi, Domenico D. Bloisi</author><pubDate>Fri, 30 Aug 2024 16:15:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17379v1</guid></item><item><title>RT-GS2: Real-Time Generalizable Semantic Segmentation for 3D Gaussian Representations of Radiance Fields</title><link>http://arxiv.org/abs/2405.18033v2</link><description>Gaussian Splatting has revolutionized the world of novel view synthesis byachieving high rendering performance in real-time. Recently, studies havefocused on enriching these 3D representations with semantic information fordownstream tasks. In this paper, we introduce RT-GS2, the first generalizablesemantic segmentation method employing Gaussian Splatting. While existingGaussian Splatting-based approaches rely on scene-specific training, RT-GS2demonstrates the ability to generalize to unseen scenes. Our method adopts anew approach by first extracting view-independent 3D Gaussian features in aself-supervised manner, followed by a novel View-Dependent / View-Independent(VDVI) feature fusion to enhance semantic consistency over different views.Extensive experimentation on three different datasets showcases RT-GS2'ssuperiority over the state-of-the-art methods in semantic segmentation quality,exemplified by a 8.01% increase in mIoU on the Replica dataset. Moreover, ourmethod achieves real-time performance of 27.03 FPS, marking an astonishing 901times speedup compared to existing approaches. This work represents asignificant advancement in the field by introducing, to the best of ourknowledge, the first real-time generalizable semantic segmentation method for3D Gaussian representations of radiance fields.</description><author>Mihnea-Bogdan Jurca, Remco Royen, Ion Giosan, Adrian Munteanu</author><pubDate>Fri, 30 Aug 2024 16:14:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18033v2</guid></item><item><title>NDP: Next Distribution Prediction as a More Broad Target</title><link>http://arxiv.org/abs/2408.17377v1</link><description>Large language models (LLMs) trained on next-token prediction (NTP) paradigmhave demonstrated powerful capabilities. However, the existing NTP paradigmcontains several limitations, particularly related to planned taskcomplications and error propagation during inference. In our work, we extendthe critique of NTP, highlighting its limitation also due to training with anarrow objective: the prediction of a sub-optimal one-hot distribution. Tosupport this critique, we conducted a pre-experiment treating the outputdistribution from powerful LLMs as efficient world data compression. Byevaluating the similarity between the $n$-gram distribution and the one-hotdistribution with LLMs, we observed that the $n$-gram distributions align moreclosely with the output distribution of LLMs. Based on this insight, weintroduce Next Distribution Prediction (NDP), which uses $n$-gram distributionsto replace the one-hot targets, enhancing learning without extra onlinetraining time. We conducted experiments across translation, general task,language transfer, and medical domain adaptation. Compared to NTP, NDP canachieve up to +2.97 COMET improvement in translation tasks, +0.61 averageimprovement in general tasks, and incredible +10.75 average improvement in themedical domain. This demonstrates the concrete benefits of addressing thetarget narrowing problem, pointing to a new direction for future work onimproving NTP.</description><author>Junhao Ruan, Abudukeyumu Abudula, Xinyu Liu, Bei Li, Yinqiao Li, Chenglong Wang, Yuchun Fan, Yuan Ge, Tong Xiao, Jingbo Zhu</author><pubDate>Fri, 30 Aug 2024 16:13:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17377v1</guid></item><item><title>Exploring the Impact of Environmental Pollutants on Multiple Sclerosis Progression</title><link>http://arxiv.org/abs/2408.17376v1</link><description>Multiple Sclerosis (MS) is a chronic autoimmune and inflammatory neurologicaldisorder characterised by episodes of symptom exacerbation, known as relapses.In this study, we investigate the role of environmental factors in relapseoccurrence among MS patients, using data from the H2020 BRAINTEASER project. Weemployed predictive models, including Random Forest (RF) and LogisticRegression (LR), with varying sets of input features to predict the occurrenceof relapses based on clinical and pollutant data collected over a week. The RFyielded the best result, with an AUC-ROC score of 0.713. Environmentalvariables, such as precipitation, NO2, PM2.5, humidity, and temperature, werefound to be relevant to the prediction.</description><author>Elena Marinello, Erica Tavazzi, Enrico Longato, Pietro Bosoni, Arianna Dagliati, Mahin Vazifehdan, Riccardo Bellazzi, Isotta Trescato, Alessandro Guazzo, Martina Vettoretti, Eleonora Tavazzi, Lara Ahmad, Roberto Bergamaschi, Paola Cavalla, Umberto Manera, Adriano Chio, Barbara Di Camillo</author><pubDate>Fri, 30 Aug 2024 16:12:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17376v1</guid></item><item><title>Recursive Estimation of Conditional Kernel Mean Embeddings</title><link>http://arxiv.org/abs/2302.05955v2</link><description>Kernel mean embeddings, a widely used technique in machine learning, mapprobability distributions to elements of a reproducing kernel Hilbert space(RKHS). For supervised learning problems, where input-output pairs areobserved, the conditional distribution of outputs given the inputs is a keyobject. The input dependent conditional distribution of an output can beencoded with an RKHS valued function, the conditional kernel mean map. In thispaper we present a new recursive algorithm to estimate the conditional kernelmean map in a Hilbert space valued $L_2$ space, that is in a Bochner space. Weprove the weak and strong $L_2$ consistency of our recursive estimator undermild conditions. The idea is to generalize Stone's theorem for Hilbert spacevalued regression in a locally compact Polish space. We present new insightsabout conditional kernel mean embeddings and give strong asymptotic boundsregarding the convergence of the proposed recursive method. Finally, theresults are demonstrated on three application domains: for inputs coming fromEuclidean spaces, Riemannian manifolds and locally compact subsets of functionspaces.</description><author>Ambrus Tamás, Balázs Csanád Csáji</author><pubDate>Fri, 30 Aug 2024 16:04:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.05955v2</guid></item><item><title>Complexity of High-Dimensional Identity Testing with Coordinate Conditional Sampling</title><link>http://arxiv.org/abs/2207.09102v3</link><description>We study the identity testing problem for high-dimensional distributions.Given as input an explicit distribution $\mu$, an $\varepsilon&gt;0$, and accessto sampling oracle(s) for a hidden distribution $\pi$, the goal in identitytesting is to distinguish whether the two distributions $\mu$ and $\pi$ areidentical or are at least $\varepsilon$-far apart. When there is only access tofull samples from the hidden distribution $\pi$, it is known that exponentiallymany samples (in the dimension) may be needed for identity testing, and henceprevious works have studied identity testing with additional access to various"conditional" sampling oracles. We consider a significantly weaker conditionalsampling oracle, which we call the $\mathsf{Coordinate\ Oracle}$, and provide acomputational and statistical characterization of the identity testing problemin this new model. We prove that if an analytic property known as approximate tensorization ofentropy holds for an $n$-dimensional visible distribution $\mu$, then there isan efficient identity testing algorithm for any hidden distribution $\pi$ using$\tilde{O}(n/\varepsilon)$ queries to the $\mathsf{Coordinate\ Oracle}$.Approximate tensorization of entropy is a pertinent condition as recent workshave established it for a large class of high-dimensional distributions. Wealso prove a computational phase transition: for a well-studied class of$n$-dimensional distributions, specifically sparse antiferromagnetic Isingmodels over $\{+1,-1\}^n$, we show that in the regime where approximatetensorization of entropy fails, there is no efficient identity testingalgorithm unless $\mathsf{RP}=\mathsf{NP}$. We complement our results with amatching $\Omega(n/\varepsilon)$ statistical lower bound for the samplecomplexity of identity testing in the $\mathsf{Coordinate\ Oracle}$ model.</description><author>Antonio Blanca, Zongchen Chen, Daniel Štefankovič, Eric Vigoda</author><pubDate>Fri, 30 Aug 2024 16:03:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.09102v3</guid></item><item><title>Beyond One-Size-Fits-All: Multi-Domain, Multi-Task Framework for Embedding Model Selection</title><link>http://arxiv.org/abs/2404.00458v2</link><description>This position paper proposes a systematic approach towards developing aframework to help select the most effective embedding models for naturallanguage processing (NLP) tasks, addressing the challenge posed by theproliferation of both proprietary and open-source encoder models.</description><author>Vivek Khetan</author><pubDate>Fri, 30 Aug 2024 15:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00458v2</guid></item><item><title>Scale-Adaptive Balancing of Exploration and Exploitation in Classical Planning</title><link>http://arxiv.org/abs/2305.09840v3</link><description>Balancing exploration and exploitation has been an important problem in bothgame tree search and automated planning. However, while the problem has beenextensively analyzed within the Multi-Armed Bandit (MAB) literature, theplanning community has had limited success when attempting to apply thoseresults. We show that a more detailed theoretical understanding of MABliterature helps improve existing planning algorithms that are based on MonteCarlo Tree Search (MCTS) / Trial Based Heuristic Tree Search (THTS). Inparticular, THTS uses UCB1 MAB algorithms in an ad hoc manner, as UCB1'stheoretical requirement of fixed bounded support reward distributions is notsatisfied within heuristic search for classical planning. The core issue liesin UCB1's lack of adaptations to the different scales of the rewards. Wepropose GreedyUCT-Normal, a MCTS/THTS algorithm with UCB1-Normal bandit foragile classical planning, which handles distributions with different scales bytaking the reward variance into consideration, and resulted in an improvedalgorithmic performance (more plans found with less node expansions) thatoutperforms Greedy Best First Search and existing MCTS/THTS-based algorithms(GreedyUCT,GreedyUCT*).</description><author>Stephen Wissow, Masataro Asai</author><pubDate>Fri, 30 Aug 2024 15:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09840v3</guid></item><item><title>Leveraging Graph Neural Networks to Forecast Electricity Consumption</title><link>http://arxiv.org/abs/2408.17366v1</link><description>Accurate electricity demand forecasting is essential for several reasons,especially as the integration of renewable energy sources and the transition toa decentralized network paradigm introduce greater complexity and uncertainty.The proposed methodology leverages graph-based representations to effectivelycapture the spatial distribution and relational intricacies inherent in thisdecentralized network structure. This research work offers a novel approachthat extends beyond the conventional Generalized Additive Model framework byconsidering models like Graph Convolutional Networks or Graph SAGE. Thesegraph-based models enable the incorporation of various levels ofinterconnectedness and information sharing among nodes, where each nodecorresponds to the combined load (i.e. consumption) of a subset of consumers(e.g. the regions of a country). More specifically, we introduce a range ofmethods for inferring graphs tailored to consumption forecasting, along with aframework for evaluating the developed models in terms of both performance andexplainability. We conduct experiments on electricity forecasting, in both asynthetic and a real framework considering the French mainland regions, and theperformance and merits of our approach are discussed.</description><author>Eloi Campagne, Yvenn Amara-Ouali, Yannig Goude, Argyris Kalogeratos</author><pubDate>Fri, 30 Aug 2024 15:54:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17366v1</guid></item><item><title>Look, Learn and Leverage (L$^3$): Mitigating Visual-Domain Shift and Discovering Intrinsic Relations via Symbolic Alignment</title><link>http://arxiv.org/abs/2408.17363v1</link><description>Modern deep learning models have demonstrated outstanding performance ondiscovering the underlying mechanisms when both visual appearance and intrinsicrelations (e.g., causal structure) data are sufficient, such as DisentangledRepresentation Learning (DRL), Causal Representation Learning (CRL) and VisualQuestion Answering (VQA) methods. However, generalization ability of thesemodels is challenged when the visual domain shifts and the relations data isabsent during finetuning. To address this challenge, we propose a novellearning framework, Look, Learn and Leverage (L$^3$), which decomposes thelearning process into three distinct phases and systematically utilize theclass-agnostic segmentation masks as the common symbolic space to align visualdomains. Thus, a relations discovery model can be trained on the source domain,and when the visual domain shifts and the intrinsic relations are absent, thepretrained relations discovery model can be directly reused and maintain asatisfactory performance. Extensive performance evaluations are conducted onthree different tasks: DRL, CRL and VQA, and show outstanding results on allthree tasks, which reveals the advantages of L$^3$.</description><author>Hanchen Xie, Jiageng Zhu, Mahyar Khayatkhoei, Jiazhi Li, Wael AbdAlmageed</author><pubDate>Fri, 30 Aug 2024 15:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17363v1</guid></item><item><title>Assessing Generative Language Models in Classification Tasks: Performance and Self-Evaluation Capabilities in the Environmental and Climate Change Domain</title><link>http://arxiv.org/abs/2408.17362v1</link><description>This paper examines the performance of two Large Language Models (LLMs),GPT3.5 and Llama2 and one Small Language Model (SLM) Gemma, across threedifferent classification tasks within the climate change (CC) and environmentaldomain. Employing BERT-based models as a baseline, we compare their efficacyagainst these transformer-based models. Additionally, we assess the models'self-evaluation capabilities by analyzing the calibration of verbalizedconfidence scores in these text classification tasks. Our findings reveal thatwhile BERT-based models generally outperform both the LLMs and SLM, theperformance of the large generative models is still noteworthy. Furthermore,our calibration analysis reveals that although Gemma is well-calibrated ininitial tasks, it thereafter produces inconsistent results; Llama is reasonablycalibrated, and GPT consistently exhibits strong calibration. Through thisresearch, we aim to contribute to the ongoing discussion on the utility andeffectiveness of generative LMs in addressing some of the planet's most urgentissues, highlighting their strengths and limitations in the context of ecologyand CC.</description><author>Francesca Grasso, Stefano Locci</author><pubDate>Fri, 30 Aug 2024 15:52:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17362v1</guid></item><item><title>Evolving Virtual World with Delta-Engine</title><link>http://arxiv.org/abs/2408.05842v3</link><description>In this paper, we focus on the \emph{virtual world}, a cyberspace wherepeople can live in. An ideal virtual world shares great similarity with ourreal world. One of the crucial aspects is its evolving nature, reflected byindividuals' capability to grow and thereby influence the objective world. Suchdynamics is unpredictable and beyond the reach of existing systems. For this,we propose a special engine called \textbf{\emph{Delta-Engine}} to drive thisvirtual world. $\Delta$ associates the world's evolution to the engine'sscalability. It consists of a base engine and a neural proxy. The base engineprograms the prototype of the virtual world; given a trigger, the neural proxygenerates new snippets on the base engine through \emph{incrementalprediction}. This paper presents a full-stack introduction to the delta-engine.The key feature of the delta-engine is its scalability to unknown elementswithin the world, Technically, it derives from the prefect co-work of theneural proxy and the base engine, and the alignment with high-quality data. Weintroduce an engine-oriented fine-tuning method that embeds the base engineinto the proxy. We then discuss the human-LLM collaborative design to producenovel and interesting data efficiently. Eventually, we propose three evaluationprinciples to comprehensively assess the performance of a delta engine: naiveevaluation, incremental evaluation, and adversarial evaluation.</description><author>Hongqiu Wu, Zekai Xu, Tianyang Xu, Shize Wei, Yan Wang, Jiale Hong, Weiqi Wu, Hai Zhao, Min Zhang, Zhezhi He</author><pubDate>Fri, 30 Aug 2024 15:51:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05842v3</guid></item><item><title>Hold Me Tight: Stable Encoder-Decoder Design for Speech Enhancement</title><link>http://arxiv.org/abs/2408.17358v1</link><description>Convolutional layers with 1-D filters are often used as frontend to encodeaudio signals. Unlike fixed time-frequency representations, they can adapt tothe local characteristics of input data. However, 1-D filters on raw audio arehard to train and often suffer from instabilities. In this paper, we addressthese problems with hybrid solutions, i.e., combining theory-driven anddata-driven approaches. First, we preprocess the audio signals via a auditoryfilterbank, guaranteeing good frequency localization for the learned encoder.Second, we use results from frame theory to define an unsupervised learningobjective that encourages energy conservation and perfect reconstruction.Third, we adapt mixed compressed spectral norms as learning objectives to theencoder coefficients. Using these solutions in a low-complexityencoder-mask-decoder model significantly improves the perceptual evaluation ofspeech quality (PESQ) in speech enhancement.</description><author>Daniel Haider, Felix Perfler, Vincent Lostanlen, Martin Ehler, Peter Balazs</author><pubDate>Fri, 30 Aug 2024 15:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17358v1</guid></item><item><title>Learning Dynamic Bayesian Networks from Data: Foundations, First Principles and Numerical Comparisons</title><link>http://arxiv.org/abs/2406.17585v2</link><description>In this paper, we present a guide to the foundations of learning DynamicBayesian Networks (DBNs) from data in the form of multiple samples oftrajectories for some length of time. We present the formalism for a generic aswell as a set of common types of DBNs for particular variable distributions. Wepresent the analytical form of the models, with a comprehensive discussion onthe interdependence between structure and weights in a DBN model and theirimplications for learning. Next, we give a broad overview of learning methodsand describe and categorize them based on the most important statisticalfeatures, and how they treat the interplay between learning structure andweights. We give the analytical form of the likelihood and Bayesian scorefunctions, emphasizing the distinction from the static case. We discussfunctions used in optimization to enforce structural requirements. We brieflydiscuss more complex extensions and representations. Finally we present a setof comparisons in different settings for various distinct but representativealgorithms across the variants.</description><author>Vyacheslav Kungurtsev, Fadwa Idlahcen, Petr Rysavy, Pavel Rytir, Ales Wodecki</author><pubDate>Fri, 30 Aug 2024 15:45:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17585v2</guid></item><item><title>C-RADAR: A Centralized Deep Learning System for Intrusion Detection in Software Defined Networks</title><link>http://arxiv.org/abs/2408.17356v1</link><description>The popularity of Software Defined Networks (SDNs) has grown in recent years,mainly because of their ability to simplify network management and improvenetwork flexibility. However, this also makes them vulnerable to various typesof cyber attacks. SDNs work on a centralized control plane which makes themmore prone to network attacks. Research has demonstrated that deep learning(DL) methods can be successful in identifying intrusions in conventionalnetworks, but their application in SDNs is still an open research area. In thisresearch, we propose the use of DL techniques for intrusion detection in SDNs.We measure the effectiveness of our method by experimentation on a dataset ofnetwork traffic and comparing it to existing techniques. Our results show thatthe DL-based approach outperforms traditional methods in terms of detectionaccuracy and computational efficiency. The deep learning architecture that hasbeen used in this research is a Long Short Term Memory Network andSelf-Attention based architecture i.e. LSTM-Attn which achieves an Fl-score of0.9721. Furthermore, this technique can be trained to detect new attackpatterns and improve the overall security of SDNs.</description><author>Osama Mustafa, Khizer Ali, Talha Naqash</author><pubDate>Fri, 30 Aug 2024 15:39:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17356v1</guid></item><item><title>Bidirectional Decoding: Improving Action Chunking via Closed-Loop Resampling</title><link>http://arxiv.org/abs/2408.17355v1</link><description>Predicting and executing a sequence of actions without intermediatereplanning, known as action chunking, is increasingly used in robot learningfrom human demonstrations. However, its effects on learned policies remainpuzzling: some studies highlight its importance for achieving strongperformance, while others observe detrimental effects. In this paper, we firstdissect the role of action chunking by analyzing the divergence between thelearner and the demonstrator. We find that longer action chunks enable a policyto better capture temporal dependencies by taking into account more past statesand actions within the chunk. However, this advantage comes at the cost ofexacerbating errors in stochastic environments due to fewer observations ofrecent states. To address this, we propose Bidirectional Decoding (BID), atest-time inference algorithm that bridges action chunking with closed-loopoperations. BID samples multiple predictions at each time step and searches forthe optimal one based on two criteria: (i) backward coherence, which favorssamples aligned with previous decisions, (ii) forward contrast, which favorssamples close to outputs of a stronger policy and distant from those of aweaker policy. By coupling decisions within and across action chunks, BIDenhances temporal consistency over extended sequences while enabling adaptivereplanning in stochastic environments. Experimental results show that BIDsubstantially outperforms conventional closed-loop operations of twostate-of-the-art generative policies across seven simulation benchmarks and tworeal-world tasks.</description><author>Yuejiang Liu, Jubayer Ibn Hamid, Annie Xie, Yoonho Lee, Maximilian Du, Chelsea Finn</author><pubDate>Fri, 30 Aug 2024 15:39:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17355v1</guid></item><item><title>Forget to Flourish: Leveraging Machine-Unlearning on Pretrained Language Models for Privacy Leakage</title><link>http://arxiv.org/abs/2408.17354v1</link><description>Fine-tuning large language models on private data for downstream applicationsposes significant privacy risks in potentially exposing sensitive information.Several popular community platforms now offer convenient distribution of alarge variety of pre-trained models, allowing anyone to publish withoutrigorous verification. This scenario creates a privacy threat, as pre-trainedmodels can be intentionally crafted to compromise the privacy of fine-tuningdatasets. In this study, we introduce a novel poisoning technique that usesmodel-unlearning as an attack tool. This approach manipulates a pre-trainedlanguage model to increase the leakage of private data during the fine-tuningprocess. Our method enhances both membership inference and data extractionattacks while preserving model utility. Experimental results across differentmodels, datasets, and fine-tuning setups demonstrate that our attackssignificantly surpass baseline performance. This work serves as a cautionarynote for users who download pre-trained models from unverified sources,highlighting the potential risks involved.</description><author>Md Rafi Ur Rashid, Jing Liu, Toshiaki Koike-Akino, Shagufta Mehnaz, Ye Wang</author><pubDate>Fri, 30 Aug 2024 15:35:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17354v1</guid></item><item><title>AASIST3: KAN-Enhanced AASIST Speech Deepfake Detection using SSL Features and Additional Regularization for the ASVspoof 2024 Challenge</title><link>http://arxiv.org/abs/2408.17352v1</link><description>Automatic Speaker Verification (ASV) systems, which identify speakers basedon their voice characteristics, have numerous applications, such as userauthentication in financial transactions, exclusive access control in smartdevices, and forensic fraud detection. However, the advancement of deeplearning algorithms has enabled the generation of synthetic audio throughText-to-Speech (TTS) and Voice Conversion (VC) systems, exposing ASV systems topotential vulnerabilities. To counteract this, we propose a novel architecturenamed AASIST3. By enhancing the existing AASIST framework withKolmogorov-Arnold networks, additional layers, encoders, and pre-emphasistechniques, AASIST3 achieves a more than twofold improvement in performance. Itdemonstrates minDCF results of 0.5357 in the closed condition and 0.1414 in theopen condition, significantly enhancing the detection of synthetic voices andimproving ASV security.</description><author>Kirill Borodin, Vasiliy Kudryavtsev, Dmitrii Korzh, Alexey Efimenko, Grach Mkrtchian, Mikhail Gorodnichev, Oleg Y. Rogov</author><pubDate>Fri, 30 Aug 2024 15:30:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17352v1</guid></item><item><title>A Permuted Autoregressive Approach to Word-Level Recognition for Urdu Digital Text</title><link>http://arxiv.org/abs/2408.15119v3</link><description>This research paper introduces a novel word-level Optical CharacterRecognition (OCR) model specifically designed for digital Urdu text, leveragingtransformer-based architectures and attention mechanisms to address thedistinct challenges of Urdu script recognition, including its diverse textstyles, fonts, and variations. The model employs a permuted autoregressivesequence (PARSeq) architecture, which enhances its performance by enablingcontext-aware inference and iterative refinement through the training ofmultiple token permutations. This method allows the model to adeptly managecharacter reordering and overlapping characters, commonly encountered in Urduscript. Trained on a dataset comprising approximately 160,000 Urdu text images,the model demonstrates a high level of accuracy in capturing the intricacies ofUrdu script, achieving a CER of 0.178. Despite ongoing challenges in handlingcertain text variations, the model exhibits superior accuracy and effectivenessin practical applications. Future work will focus on refining the model throughadvanced data augmentation techniques and the integration of context-awarelanguage models to further enhance its performance and robustness in Urdu textrecognition.</description><author>Ahmed Mustafa, Muhammad Tahir Rafique, Muhammad Ijlal Baig, Hasan Sajid, Muhammad Jawad Khan, Karam Dad Kallu</author><pubDate>Fri, 30 Aug 2024 15:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15119v3</guid></item><item><title>LSMS: Language-guided Scale-aware MedSegmentor for Medical Image Referring Segmentation</title><link>http://arxiv.org/abs/2408.17347v1</link><description>Conventional medical image segmentation methods have been found inadequate infacilitating physicians with the identification of specific lesions fordiagnosis and treatment. Given the utility of text as an instructional format,we introduce a novel task termed Medical Image Referring Segmentation (MIRS),which requires segmenting specified lesions in images based on the givenlanguage expressions. Due to the varying object scales in medical images, MIRSdemands robust vision-language modeling and comprehensive multi-scaleinteraction for precise localization and segmentation under linguisticguidance. However, existing medical image segmentation methods fall short inmeeting these demands, resulting in insufficient segmentation accuracy. Inresponse, we propose an approach named Language-guided Scale-aware MedSegmentor(LSMS), incorporating two appealing designs: (1)~a Scale-aware Vision-LanguageAttention module that leverages diverse convolutional kernels to acquire richvisual knowledge and interact closely with linguistic features, therebyenhancing lesion localization capability; (2)~a Full-Scale Decoder thatglobally models multi-modal features across various scales, capturingcomplementary information between scales to accurately outline lesionboundaries. Addressing the lack of suitable datasets for MIRS, we constructed avision-language medical dataset called Reference Hepatic Lesion Segmentation(RefHL-Seg). This dataset comprises 2,283 abdominal CT slices from 231 cases,with corresponding textual annotations and segmentation masks for various liverlesions in images. We validated the performance of LSMS for MIRS andconventional medical image segmentation tasks across various datasets. Our LSMSconsistently outperforms on all datasets with lower computational costs. Thecode and datasets will be released.</description><author>Shuyi Ouyang, Jinyang Zhang, Xiangye Lin, Xilai Wang, Qingqing Chen, Yen-Wei Chen, Lanfen Lin</author><pubDate>Fri, 30 Aug 2024 15:22:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17347v1</guid></item><item><title>LightFF: Lightweight Inference for Forward-Forward Algorithm</title><link>http://arxiv.org/abs/2404.05241v6</link><description>The human brain performs tasks with an outstanding energy efficiency, i.e.,with approximately 20 Watts. The state-of-the-art Artificial/Deep NeuralNetworks (ANN/DNN), on the other hand, have recently been shown to consumemassive amounts of energy. The training of these ANNs/DNNs is done almostexclusively based on the back-propagation algorithm, which is known to bebiologically implausible. This has led to a new generation of forward-onlytechniques, including the Forward-Forward algorithm. In this paper, we proposea lightweight inference scheme specifically designed for DNNs trained using theForward-Forward algorithm. We have evaluated our proposed lightweight inferencescheme in the case of the MNIST and CIFAR datasets, as well as two real-worldapplications, namely, epileptic seizure detection and cardiac arrhythmiaclassification using wearable technologies, where complexity overheads/energyconsumption is a major constraint, and demonstrate its relevance. Our code isavailable at https://github.com/AminAminifar/LightFF.</description><author>Amin Aminifar, Baichuan Huang, Azra Abtahi, Amir Aminifar</author><pubDate>Fri, 30 Aug 2024 15:17:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05241v6</guid></item><item><title>rerankers: A Lightweight Python Library to Unify Ranking Methods</title><link>http://arxiv.org/abs/2408.17344v1</link><description>This paper presents rerankers, a Python library which provides an easy-to-useinterface to the most commonly used re-ranking approaches. Re-ranking is anintegral component of many retrieval pipelines; however, there exist numerousapproaches to it, relying on different implementation methods.\texttt{rerankers} unifies these methods into a single user-friendly interface,allowing practitioners and researchers alike to explore different methods whileonly changing a single line of Python code. Moreover ,rerankers ensures thatits implementations are done with the fewest dependencies possible, and re-usesthe original implementation whenever possible, guaranteeing that our simplifiedinterface results in no performance degradation compared to more complex ones.The full source code and list of supported models are updated regularly andavailable at https://github.com/answerdotai/rerankers.</description><author>Benjamin Clavié</author><pubDate>Fri, 30 Aug 2024 15:16:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17344v1</guid></item><item><title>DeformGS: Scene Flow in Highly Deformable Scenes for Deformable Object Manipulation</title><link>http://arxiv.org/abs/2312.00583v2</link><description>Teaching robots to fold, drape, or reposition deformable objects such ascloth will unlock a variety of automation applications. While remarkableprogress has been made for rigid object manipulation, manipulating deformableobjects poses unique challenges, including frequent occlusions,infinite-dimensional state spaces and complex dynamics. Just as object poseestimation and tracking have aided robots for rigid manipulation, dense 3Dtracking (scene flow) of highly deformable objects will enable new applicationsin robotics while aiding existing approaches, such as imitation learning orcreating digital twins with real2sim transfer. We propose DeformGS, an approachto recover scene flow in highly deformable scenes, using simultaneous videocaptures of a dynamic scene from multiple cameras. DeformGS builds on recentadvances in Gaussian splatting, a method that learns the properties of a largenumber of Gaussians for state-of-the-art and fast novel-view synthesis.DeformGS learns a deformation function to project a set of Gaussians withcanonical properties into world space. The deformation function uses aneural-voxel encoding and a multilayer perceptron (MLP) to infer Gaussianposition, rotation, and a shadow scalar. We enforce physics-inspiredregularization terms based on conservation of momentum and isometry, whichleads to trajectories with smaller trajectory errors. We also leverage existingfoundation models SAM and XMEM to produce noisy masks, and learn a per-Gaussianmask for better physics-inspired regularization. DeformGS achieves high-quality3D tracking on highly deformable scenes with shadows and occlusions. Inexperiments, DeformGS improves 3D tracking by an average of 55.8% compared tothe state-of-the-art. With sufficient texture, DeformGS achieves a mediantracking error of 3.3 mm on a cloth of 1.5 x 1.5 m in area. Website:https://deformgs.github.io</description><author>Bardienus P. Duisterhof, Zhao Mandi, Yunchao Yao, Jia-Wei Liu, Jenny Seidenschwarz, Mike Zheng Shou, Deva Ramanan, Shuran Song, Stan Birchfield, Bowen Wen, Jeffrey Ichnowski</author><pubDate>Fri, 30 Aug 2024 15:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00583v2</guid></item><item><title>OpticalRS-4M: Scaling Efficient Masked Autoencoder Learning on Large Remote Sensing Dataset</title><link>http://arxiv.org/abs/2406.11933v3</link><description>Masked Image Modeling (MIM) has become an essential method for buildingfoundational visual models in remote sensing (RS). However, the limitations insize and diversity of existing RS datasets restrict the ability of MIM methodsto learn generalizable representations. Additionally, conventional MIMtechniques, which require reconstructing all tokens, introduce unnecessarycomputational overhead. To address these issues, we present a new pre-trainingpipeline for RS models, featuring the creation of a large-scale RS dataset andan efficient MIM approach. We curated a high-quality dataset named OpticalRS-4Mby collecting publicly available RS datasets and processing them throughexclusion, slicing, and deduplication. OpticalRS-4M comprises 4 million opticalimages covering various RS tasks, such as object detection and pixelsegmentation. To enhance efficiency, we propose SelectiveMAE, a pre-trainingmethod that dynamically encodes and reconstructs semantically rich patchtokens, thereby reducing the inefficiencies of traditional MIM models caused byredundant background pixels in RS images. Extensive experiments demonstratethat OpticalRS-4M significantly improves classification, detection, andsegmentation performance, while SelectiveMAE increases training efficiency over2 times. This highlights the effectiveness and scalability of our pipeline indeveloping RS foundational models.</description><author>Fengxiang Wang, Hongzhen Wang, Di Wang, Zonghao Guo, Zhenyu Zhong, Long Lan, Jing Zhang, Zhiyuan Liu, Maosong Sun</author><pubDate>Fri, 30 Aug 2024 15:08:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11933v3</guid></item><item><title>Enhancing Underwater Imaging with 4-D Light Fields: Dataset and Method</title><link>http://arxiv.org/abs/2408.17339v1</link><description>In this paper, we delve into the realm of 4-D light fields (LFs) to enhanceunderwater imaging plagued by light absorption, scattering, and otherchallenges. Contrasting with conventional 2-D RGB imaging, 4-D LF imagingexcels in capturing scenes from multiple perspectives, thereby indirectlyembedding geometric information. This intrinsic property is anticipated toeffectively address the challenges associated with underwater imaging. Byleveraging both explicit and implicit depth cues present in 4-D LF images, wepropose a progressive, mutually reinforcing framework for underwater 4-D LFimage enhancement and depth estimation. Specifically, our framework explicitlyutilizes estimated depth information alongside implicit depth-related dynamicconvolutional kernels to modulate output features. The entire frameworkdecomposes this complex task, iteratively optimizing the enhanced image anddepth information to progressively achieve optimal enhancement results. Moreimportantly, we construct the first 4-D LF-based underwater image dataset forquantitative evaluation and supervised training of learning-based methods,comprising 75 underwater scenes and 3675 high-resolution 2K pairs. To craftvibrant and varied underwater scenes, we build underwater environments withvarious objects and adopt several types of degradation. Through extensiveexperimentation, we showcase the potential and superiority of 4-D LF-basedunderwater imaging vis-a-vis traditional 2-D RGB-based approaches. Moreover,our method effectively corrects color bias and achieves state-of-the-artperformance. The dataset and code will be publicly available athttps://github.com/linlos1234/LFUIE.</description><author>Yuji Lin, Xianqiang Lyu, Junhui Hou, Qian Zhao, Deyu Meng</author><pubDate>Fri, 30 Aug 2024 15:06:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17339v1</guid></item><item><title>Docling Technical Report</title><link>http://arxiv.org/abs/2408.09869v3</link><description>This technical report introduces Docling, an easy to use, self-contained,MIT-licensed open-source package for PDF document conversion. It is powered bystate-of-the-art specialized AI models for layout analysis (DocLayNet) andtable structure recognition (TableFormer), and runs efficiently on commodityhardware in a small resource budget. The code interface allows for easyextensibility and addition of new features and models.</description><author>Christoph Auer, Maksym Lysak, Ahmed Nassar, Michele Dolfi, Nikolaos Livathinos, Panos Vagenas, Cesar Berrospi Ramis, Matteo Omenetti, Fabian Lindlbauer, Kasper Dinkla, Lokesh Mishra, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar</author><pubDate>Fri, 30 Aug 2024 15:05:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09869v3</guid></item><item><title>Evaluating Reliability in Medical DNNs: A Critical Analysis of Feature and Confidence-Based OOD Detection</title><link>http://arxiv.org/abs/2408.17337v1</link><description>Reliable use of deep neural networks (DNNs) for medical image analysisrequires methods to identify inputs that differ significantly from the trainingdata, called out-of-distribution (OOD), to prevent erroneous predictions. OODdetection methods can be categorised as either confidence-based (using themodel's output layer for OOD detection) or feature-based (not using the outputlayer). We created two new OOD benchmarks by dividing the D7P (dermatology) andBreastMNIST (ultrasound) datasets into subsets which either contain or don'tcontain an artefact (rulers or annotations respectively). Models were trainedwith artefact-free images, and images with the artefacts were used as OOD testsets. For each OOD image, we created a counterfactual by manually removing theartefact via image processing, to assess the artefact's impact on the model'spredictions. We show that OOD artefacts can boost a model's softmax confidencein its predictions, due to correlations in training data among other factors.This contradicts the common assumption that OOD artefacts should lead to moreuncertain outputs, an assumption on which most confidence-based methods rely.We use this to explain why feature-based methods (e.g. Mahalanobis score)typically have greater OOD detection performance than confidence-based methods(e.g. MCP). However, we also show that feature-based methods typically performworse at distinguishing between inputs that lead to correct and incorrectpredictions (for both OOD and ID data). Following from these insights, we arguethat a combination of feature-based and confidence-based methods should be usedwithin DNN pipelines to mitigate their respective weaknesses. These project'scode and OOD benchmarks are available at:https://github.com/HarryAnthony/Evaluating_OOD_detection.</description><author>Harry Anthony, Konstantinos Kamnitsas</author><pubDate>Fri, 30 Aug 2024 15:02:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17337v1</guid></item><item><title>An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought</title><link>http://arxiv.org/abs/2407.15569v2</link><description>Since the launch of ChatGPT at the end of 2022, generative dialogue modelsrepresented by ChatGPT have quickly become essential tools in daily life. Asuser expectations increase, enhancing the capability of generative dialoguemodels to solve complex problems has become a focal point of current research.This paper delves into the effectiveness of the RAFT (Retrieval AugmentedFine-Tuning) method in improving the performance of Generative dialogue models.RAFT combines chain-of-thought with model supervised fine-tuning (SFT) andretrieval augmented generation (RAG), which significantly enhanced the model'sinformation extraction and logical reasoning abilities. We evaluated the RAFTmethod across multiple datasets and analysed its performance in variousreasoning tasks, including long-form QA and short-form QA tasks, tasks in bothChinese and English, and supportive and comparison reasoning tasks. Notably, itaddresses the gaps in previous research regarding long-form QA tasks andChinese datasets. Moreover, we also evaluate the benefit of thechain-of-thought (CoT) in the RAFT method. This work offers valuable insightsfor studies focused on enhancing the performance of generative dialogue models.</description><author>Yuetong Zhao, Hongyu Cao, Xianyu Zhao, Zhijian Ou</author><pubDate>Fri, 30 Aug 2024 14:52:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.15569v2</guid></item><item><title>Learning the irreversible progression trajectory of Alzheimer's disease</title><link>http://arxiv.org/abs/2403.06087v2</link><description>Alzheimer's disease (AD) is a progressive and irreversible brain disorderthat unfolds over the course of 30 years. Therefore, it is critical to capturethe disease progression in an early stage such that intervention can be appliedbefore the onset of symptoms. Machine learning (ML) models have been showneffective in predicting the onset of AD. Yet for subjects with follow-upvisits, existing techniques for AD classification only aim for accurate groupassignment, where the monotonically increasing risk across follow-up visits isusually ignored. Resulted fluctuating risk scores across visits violate theirreversibility of AD, hampering the trustworthiness of models and alsoproviding little value to understanding the disease progression. To addressthis issue, we propose a novel regularization approach to predict ADlongitudinally. Our technique aims to maintain the expected monotonicity ofincreasing disease risk during progression while preserving expressiveness.Specifically, we introduce a monotonicity constraint that encourages the modelto predict disease risk in a consistent and ordered manner across follow-upvisits. We evaluate our method using the longitudinal structural MRI andamyloid-PET imaging data from the Alzheimer's Disease Neuroimaging Initiative(ADNI). Our model outperforms existing techniques in capturing theprogressiveness of disease risk, and at the same time preserves predictionaccuracy.</description><author>Yipei Wang, Bing He, Shannon Risacher, Andrew Saykin, Jingwen Yan, Xiaoqian Wang</author><pubDate>Fri, 30 Aug 2024 14:46:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.06087v2</guid></item><item><title>Language models align with human judgments on key grammatical constructions</title><link>http://arxiv.org/abs/2402.01676v2</link><description>Do large language models (LLMs) make human-like linguistic generalizations?Dentella et al. (2023) ("DGL") prompt several LLMs ("Is the following sentencegrammatically correct in English?") to elicit grammaticality judgments of 80English sentences, concluding that LLMs demonstrate a "yes-response bias" and a"failure to distinguish grammatical from ungrammatical sentences". Were-evaluate LLM performance using well-established practices and find thatDGL's data in fact provide evidence for just how well LLMs capture humanbehaviors. Models not only achieve high accuracy overall, but also capturefine-grained variation in human linguistic judgments.</description><author>Jennifer Hu, Kyle Mahowald, Gary Lupyan, Anna Ivanova, Roger Levy</author><pubDate>Fri, 30 Aug 2024 14:43:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01676v2</guid></item><item><title>Estimation of Cardiac and Non-cardiac Diagnosis from Electrocardiogram Features</title><link>http://arxiv.org/abs/2408.17329v1</link><description>Introduction: Ensuring timely and accurate diagnosis of medical conditions isparamount for effective patient care. Electrocardiogram (ECG) signals arefundamental for evaluating a patient's cardiac health and are readilyavailable. Despite this, little attention has been given to the remarkablepotential of ECG data in detecting non-cardiac conditions. Methods: In our study, we used publicly available datasets (MIMIC-IV-ECG-ICDand ECG-VIEW II) to investigate the feasibility of inferring general diagnosticconditions from ECG features. To this end, we trained a tree-based model(XGBoost) based on ECG features and basic demographic features to estimate awide range of diagnoses, encompassing both cardiac and non-cardiac conditions. Results: Our results demonstrate the reliability of estimating 23 cardiac aswell as 21 non-cardiac conditions above 0.7 AUROC in a statisticallysignificant manner across a wide range of physiological categories. Ourfindings underscore the predictive potential of ECG data in identifyingwell-known cardiac conditions. However, even more striking, this researchrepresents a pioneering effort in systematically expanding the scope ofECG-based diagnosis to conditions not traditionally associated with the cardiacsystem.</description><author>Juan Miguel Lopez Alcaraz, Nils Strodthoff</author><pubDate>Fri, 30 Aug 2024 14:42:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17329v1</guid></item><item><title>Temporal Ensemble Logic</title><link>http://arxiv.org/abs/2408.14443v2</link><description>We introduce Temporal Ensemble Logic (TEL), a monadic, first-order modallogic for linear-time temporal reasoning. TEL includes primitive temporalconstructs such as ``always up to $t$ time later'' ($\Box_t$), ``sometimesbefore $t$ time in the future'' ($\Diamond_t$), and ``$t$-time later''$\varphi_t$. TEL has been motivated from the requirement for rigor andreproducibility for cohort specification and discovery in clinical andpopulation health research, to fill a gap in formalizing temporal reasoning inbiomedicine. Existing logical frameworks such as linear temporal logic are toorestrictive to express temporal and sequential properties in biomedicine, ortoo permissive in semantic constructs, such as in Halpern-Shoham logic, toserve this purpose. In this paper, we first introduce TEL in a general set up,with discrete and dense time as special cases. We then focus on the theoreticaldevelopment of discrete TEL on the temporal domain of positive integers$\mathbb{N}^+$, denoted as ${\rm TEL}_{\mathbb{N}^+}$. ${\rmTEL}_{\mathbb{N}^+}$ is strictly more expressive than the standard monadicsecond order logic, characterized by B\"{u}chi automata. We present its formalsemantics, a proof system, and provide a proof for the undecidability of thesatisfiability of ${\rm TEL}_{\mathbb{N}^+}$. We also include initial resultson expressiveness and decidability fragments for ${\rm TEL}_{\mathbb{N}^+}$,followed by application outlook and discussions.</description><author>Guo-Qiang Zhang</author><pubDate>Fri, 30 Aug 2024 14:41:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14443v2</guid></item><item><title>Parameters Inference for Nonlinear Wave Equations with Markovian Switching</title><link>http://arxiv.org/abs/2408.05990v2</link><description>Traditional partial differential equations with constant coefficients oftenstruggle to capture abrupt changes in real-world phenomena, leading to thedevelopment of variable coefficient PDEs and Markovian switching models.Recently, research has introduced the concept of PDEs with Markov switchingmodels, established their well-posedness and presented numerical methods.However, there has been limited discussion on parameter estimation for the jumpcoefficients in these models. This paper addresses this gap by focusing onparameter inference for the wave equation with Markovian switching. We proposea Bayesian statistical framework using discrete sparse Bayesian learning toestablish its convergence and a uniform error bound. Our method requires fewerassumptions and enables independent parameter inference for each segment byallowing different underlying structures for the parameter estimation problemwithin each segmented time interval. The effectiveness of our approach isdemonstrated through three numerical cases, which involve noisy spatiotemporaldata from different wave equations with Markovian switching. The results showstrong performance in parameter estimation for variable coefficient PDEs.</description><author>Yi Zhang, Zhikun Zhang, Xiangjun Wang</author><pubDate>Fri, 30 Aug 2024 14:39:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05990v2</guid></item><item><title>Effectiveness of probabilistic contact tracing in epidemic containment: the role of super-spreaders and transmission path reconstruction</title><link>http://arxiv.org/abs/2312.00910v2</link><description>The recent COVID-19 pandemic underscores the significance of early-stagenon-pharmacological intervention strategies. The widespread use of masks andthe systematic implementation of contact tracing strategies provide apotentially equally effective and socially less impactful alternative to moreconventional approaches, such as large-scale mobility restrictions. However,manual contact tracing faces strong limitations in accessing the network ofcontacts, and the scalability of currently implemented protocols forsmartphone-based digital contact tracing becomes impractical during the rapidexpansion phases of the outbreaks, due to the surge in exposure notificationsand associated tests. A substantial improvement in digital contact tracing canbe obtained through the integration of probabilistic techniques for riskassessment that can more effectively guide the allocation of new diagnostictests. In this study, we first quantitatively analyze the diagnostic and socialcosts associated with these containment measures based on contact tracing,employing three state-of-the-art models of SARS-CoV-2 spreading. Our resultssuggest that probabilistic techniques allow for more effective mitigation at alower cost. Secondly, our findings reveal a remarkable efficacy ofprobabilistic contact-tracing techniques in performing backward and multi-steptracing and capturing super-spreading events.</description><author>A. P. Muntoni, F. Mazza, A. Braunstein, G. Catania, L. Dall'Asta</author><pubDate>Fri, 30 Aug 2024 14:37:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00910v2</guid></item><item><title>Impact of ChatGPT on the writing style of condensed matter physicists</title><link>http://arxiv.org/abs/2408.17325v1</link><description>We apply a state-of-the-art difference-in-differences approach to estimatethe impact of ChatGPT's release on the writing style of condensed matter paperson arXiv. Our analysis reveals a statistically significant improvement in theEnglish quality of abstracts written by non-native English speakers.Importantly, this improvement remains robust even after accounting for otherpotential factors, confirming that it can be attributed to the release ofChatGPT. This indicates widespread adoption of the tool. Following the releaseof ChatGPT, there is a significant increase in the use of unique words, whilethe frequency of rare words decreases. Across language families, the changes inwriting style are significant for authors from the Latin and Ural-Altaicgroups, but not for those from the Germanic or other Indo-European groups.</description><author>Shaojun Xu, Xiaohui Ye, Mengqi Zhang, Pei Wang</author><pubDate>Fri, 30 Aug 2024 14:37:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17325v1</guid></item><item><title>Foundational Models for Pathology and Endoscopy Images: Application for Gastric Inflammation</title><link>http://arxiv.org/abs/2406.18249v2</link><description>The integration of artificial intelligence (AI) in medical diagnosticsrepresents a significant advancement in managing upper gastrointestinal (GI)cancer, a major cause of global cancer mortality. Specifically for gastriccancer (GC), chronic inflammation causes changes in the mucosa such as atrophy,intestinal metaplasia (IM), dysplasia and ultimately cancer. Early detectionthrough endoscopic regular surveillance is essential for better outcomes.Foundation models (FM), which are machine or deep learning models trained ondiverse data and applicable to broad use cases, offer a promising solution toenhance the accuracy of endoscopy and its subsequent pathology image analysis.This review explores the recent advancements, applications, and challengesassociated with FM in endoscopy and pathology imaging. We started byelucidating the core principles and architectures underlying these models,including their training methodologies and the pivotal role of large-scale datain developing their predictive capabilities. Moreover, this work discussesemerging trends and future research directions, emphasizing the integration ofmultimodal data, the development of more robust and equitable models, and thepotential for real-time diagnostic support. This review aims to provide aroadmap for researchers and practitioners in navigating the complexities ofincorporating FM into clinical practice for prevention/management of GC cases,thereby improving patient outcomes.</description><author>Hamideh Kerdegari, Kyle Higgins, Dennis Veselkov, Ivan Laponogov, Inese Polaka, Miguel Coimbra, Junior Andrea Pescino, Marcis Leja, Mario Dinis-Ribeiro, Tania Fleitas Kanonnikoff, Kirill Veselkov</author><pubDate>Fri, 30 Aug 2024 14:36:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18249v2</guid></item><item><title>Modularity in Transformers: Investigating Neuron Separability &amp; Specialization</title><link>http://arxiv.org/abs/2408.17324v1</link><description>Transformer models are increasingly prevalent in various applications, yetour understanding of their internal workings remains limited. This paperinvestigates the modularity and task specialization of neurons withintransformer architectures, focusing on both vision (ViT) and language (Mistral7B) models. Using a combination of selective pruning and MoEfication clusteringtechniques, we analyze the overlap and specialization of neurons acrossdifferent tasks and data subsets. Our findings reveal evidence of task-specificneuron clusters, with varying degrees of overlap between related tasks. Weobserve that neuron importance patterns persist to some extent even in randomlyinitialized models, suggesting an inherent structure that training refines.Additionally, we find that neuron clusters identified through MoEficationcorrespond more strongly to task-specific neurons in earlier and later layersof the models. This work contributes to a more nuanced understanding oftransformer internals and offers insights into potential avenues for improvingmodel interpretability and efficiency.</description><author>Nicholas Pochinkov, Thomas Jones, Mohammed Rashidur Rahman</author><pubDate>Fri, 30 Aug 2024 14:35:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17324v1</guid></item><item><title>Investigating Neuron Ablation in Attention Heads: The Case for Peak Activation Centering</title><link>http://arxiv.org/abs/2408.17322v1</link><description>The use of transformer-based models is growing rapidly throughout society.With this growth, it is important to understand how they work, and inparticular, how the attention mechanisms represent concepts. Though there aremany interpretability methods, many look at models through their neuronalactivations, which are poorly understood. We describe different lenses throughwhich to view neuron activations, and investigate the effectiveness in languagemodels and vision transformers through various methods of neural ablation: zeroablation, mean ablation, activation resampling, and a novel approach we term'peak ablation'. Through experimental analysis, we find that in differentregimes and models, each method can offer the lowest degradation of modelperformance compared to other methods, with resampling usually causing the mostsignificant performance deterioration. We make our code available athttps://github.com/nickypro/investigating-ablation.</description><author>Nicholas Pochinkov, Ben Pasero, Skylar Shibayama</author><pubDate>Fri, 30 Aug 2024 14:32:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17322v1</guid></item><item><title>A Newton-CG based barrier-augmented Lagrangian method for general nonconvex conic optimization</title><link>http://arxiv.org/abs/2301.04204v2</link><description>In this paper we consider finding an approximate second-order stationarypoint (SOSP) of general nonconvex conic optimization that minimizes a twicedifferentiable function subject to nonlinear equality constraints and also aconvex conic constraint. In particular, we propose a Newton-conjugate gradient(Newton-CG) based barrier-augmented Lagrangian method for finding anapproximate SOSP of this problem. Under some mild assumptions, we show that ourmethod enjoys a total inner iteration complexity of $\widetilde{\calO}(\epsilon^{-11/2})$ and an operation complexity of $\widetilde{\calO}(\epsilon^{-11/2}\min\{n,\epsilon^{-5/4}\})$ for finding an$(\epsilon,\sqrt{\epsilon})$-SOSP of general nonconvex conic optimization withhigh probability. Moreover, under a constraint qualification, these complexitybounds are improved to $\widetilde{\cal O}(\epsilon^{-7/2})$ and$\widetilde{\cal O}(\epsilon^{-7/2}\min\{n,\epsilon^{-3/4}\})$, respectively.To the best of our knowledge, this is the first study on the complexity offinding an approximate SOSP of general nonconvex conic optimization.Preliminary numerical results are presented to demonstrate superiority of theproposed method over first-order methods in terms of solution quality.</description><author>Chuan He, Heng Huang, Zhaosong Lu</author><pubDate>Fri, 30 Aug 2024 14:30:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.04204v2</guid></item><item><title>Invariant Causal Prediction with Local Models</title><link>http://arxiv.org/abs/2401.05218v2</link><description>We consider the task of identifying the causal parents of a target variableamong a set of candidates from observational data. Our main assumption is thatthe candidate variables are observed in different environments which may, undercertain assumptions, be regarded as interventions on the observed system. Weassume a linear relationship between target and candidates, which can bedifferent in each environment with the only restriction that the causalstructure is invariant across environments. Within our proposed setting weprovide sufficient conditions for identifiability of the causal parents andintroduce a practical method called L-ICP ($\textbf{L}$ocalized$\textbf{I}$nvariant $\textbf{Ca}$usal $\textbf{P}$rediction), which is basedon a hypothesis test for parent identification using a ratio of minimum andmaximum statistics. We then show in a simplified setting that the statisticalpower of L-ICP converges exponentially fast in the sample size, and finally weanalyze the behavior of L-ICP experimentally in more general settings.</description><author>Alexander Mey, Rui Manuel Castro</author><pubDate>Fri, 30 Aug 2024 14:27:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05218v2</guid></item><item><title>Spiking Wavelet Transformer</title><link>http://arxiv.org/abs/2403.11138v4</link><description>Spiking neural networks (SNNs) offer an energy-efficient alternative toconventional deep learning by emulating the event-driven processing manner ofthe brain. Incorporating Transformers with SNNs has shown promise for accuracy.However, they struggle to learn high-frequency patterns, such as moving edgesand pixel-level brightness changes, because they rely on the globalself-attention mechanism. Learning these high-frequency representations ischallenging but essential for SNN-based event-driven vision. To address thisissue, we propose the Spiking Wavelet Transformer (SWformer), an attention-freearchitecture that effectively learns comprehensive spatial-frequency featuresin a spike-driven manner by leveraging the sparse wavelet transform. Thecritical component is a Frequency-Aware Token Mixer (FATM) with three branches:1) spiking wavelet learner for spatial-frequency domain learning, 2)convolution-based learner for spatial feature extraction, and 3) spikingpointwise convolution for cross-channel information aggregation - with negativespike dynamics incorporated in 1) to enhance frequency representation. The FATMenables the SWformer to outperform vanilla Spiking Transformers in capturinghigh-frequency visual components, as evidenced by our empirical results.Experiments on both static and neuromorphic datasets demonstrate SWformer'seffectiveness in capturing spatial-frequency patterns in a multiplication-freeand event-driven fashion, outperforming state-of-the-art SNNs. SWformerachieves a 22.03% reduction in parameter count, and a 2.52% performanceimprovement on the ImageNet dataset compared to vanilla Spiking Transformers.The code is available at: https://github.com/bic-L/Spiking-Wavelet-Transformer.</description><author>Yuetong Fang, Ziqing Wang, Lingfeng Zhang, Jiahang Cao, Honglei Chen, Renjing Xu</author><pubDate>Fri, 30 Aug 2024 14:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11138v4</guid></item><item><title>Bridging Domain Knowledge and Process Discovery Using Large Language Models</title><link>http://arxiv.org/abs/2408.17316v1</link><description>Discovering good process models is essential for different process analysistasks such as conformance checking and process improvements. Automated processdiscovery methods often overlook valuable domain knowledge. This knowledge,including insights from domain experts and detailed process documentation,remains largely untapped during process discovery. This paper leverages LargeLanguage Models (LLMs) to integrate such knowledge directly into processdiscovery. We use rules derived from LLMs to guide model construction, ensuringalignment with both domain knowledge and actual process executions. Byintegrating LLMs, we create a bridge between process knowledge expressed innatural language and the discovery of robust process models, advancing processdiscovery methodologies significantly. To showcase the usability of ourframework, we conducted a case study with the UWV employee insurance agency,demonstrating its practical benefits and effectiveness.</description><author>Ali Norouzifar, Humam Kourani, Marcus Dees, Wil van der Aalst</author><pubDate>Fri, 30 Aug 2024 14:23:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17316v1</guid></item><item><title>Fair Best Arm Identification with Fixed Confidence</title><link>http://arxiv.org/abs/2408.17313v1</link><description>In this work, we present a novel framework for Best Arm Identification (BAI)under fairness constraints, a setting that we refer to as \textit{F-BAI} (fairBAI). Unlike traditional BAI, which solely focuses on identifying the optimalarm with minimal sample complexity, F-BAI also includes a set of fairnessconstraints. These constraints impose a lower limit on the selection rate ofeach arm and can be either model-agnostic or model-dependent. For this setting,we establish an instance-specific sample complexity lower bound and analyze the\textit{price of fairness}, quantifying how fairness impacts sample complexity.Based on the sample complexity lower bound, we propose F-TaS, an algorithmprovably matching the sample complexity lower bound, while ensuring that thefairness constraints are satisfied. Numerical results, conducted using both asynthetic model and a practical wireless scheduling application, show theefficiency of F-TaS in minimizing the sample complexity while achieving lowfairness violations.</description><author>Alessio Russo, Filippo Vannella</author><pubDate>Fri, 30 Aug 2024 14:18:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17313v1</guid></item><item><title>Structuring a Training Strategy to Robustify Perception Models with Realistic Image Augmentations</title><link>http://arxiv.org/abs/2408.17311v1</link><description>Advancing Machine Learning (ML)-based perception models for autonomoussystems necessitates addressing weak spots within the models, particularly inchallenging Operational Design Domains (ODDs). These are environmentaloperating conditions of an autonomous vehicle which can contain difficultconditions, e.g., lens flare at night or objects reflected in a wet street.This report introduces a novel methodology for training with augmentations toenhance model robustness and performance in such conditions. The proposedapproach leverages customized physics-based augmentation functions, to generaterealistic training data that simulates diverse ODD scenarios. We present a comprehensive framework that includes identifying weak spots inML models, selecting suitable augmentations, and devising effective trainingstrategies. The methodology integrates hyperparameter optimization and latentspace optimization to fine-tune augmentation parameters, ensuring theymaximally improve the ML models' performance. Experimental results demonstrateimprovements in model performance, as measured by commonly used metrics such asmean Average Precision (mAP) and mean Intersection over Union (mIoU) onopen-source object detection and semantic segmentation models and datasets. Our findings emphasize that optimal training strategies are model- anddata-specific and highlight the benefits of integrating augmentations into thetraining pipeline. By incorporating augmentations, we observe enhancedrobustness of ML-based perception models, making them more resilient to edgecases encountered in real-world ODDs. This work underlines the importance ofcustomized augmentations and offers an effective solution for improving thesafety and reliability of autonomous driving functions.</description><author>Ahmed Hammam, Bharathwaj Krishnaswami Sreedhar, Nura Kawa, Tim Patzelt, Oliver De Candido</author><pubDate>Fri, 30 Aug 2024 14:15:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17311v1</guid></item><item><title>On the Curse of Memory in Recurrent Neural Networks: Approximation and Optimization Analysis</title><link>http://arxiv.org/abs/2009.07799v3</link><description>We study the approximation properties and optimization dynamics of recurrentneural networks (RNNs) when applied to learn input-output relationships intemporal data. We consider the simple but representative setting of usingcontinuous-time linear RNNs to learn from data generated by linearrelationships. Mathematically, the latter can be understood as a sequence oflinear functionals. We prove a universal approximation theorem of such linearfunctionals, and characterize the approximation rate and its relation withmemory. Moreover, we perform a fine-grained dynamical analysis of traininglinear RNNs, which further reveal the intricate interactions between memory andlearning. A unifying theme uncovered is the non-trivial effect of memory, anotion that can be made precise in our framework, on approximation andoptimization: when there is long term memory in the target, it takes a largenumber of neurons to approximate it. Moreover, the training process will sufferfrom slow downs. In particular, both of these effects become exponentially morepronounced with memory - a phenomenon we call the "curse of memory". Theseanalyses represent a basic step towards a concrete mathematical understandingof new phenomenon that may arise in learning temporal relationships usingrecurrent architectures.</description><author>Zhong Li, Jiequn Han, Weinan E, Qianxiao Li</author><pubDate>Fri, 30 Aug 2024 14:12:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2009.07799v3</guid></item><item><title>Towards Tailored Recovery of Lexical Diversity in Literary Machine Translation</title><link>http://arxiv.org/abs/2408.17308v1</link><description>Machine translations are found to be lexically poorer than humantranslations. The loss of lexical diversity through MT poses an issue in theautomatic translation of literature, where it matters not only what is written,but also how it is written. Current methods for increasing lexical diversity inMT are rigid. Yet, as we demonstrate, the degree of lexical diversity can varyconsiderably across different novels. Thus, rather than aiming for the rigidincrease of lexical diversity, we reframe the task as recovering what is lostin the machine translation process. We propose a novel approach that consistsof reranking translation candidates with a classifier that distinguishesbetween original and translated text. We evaluate our approach on 31English-to-Dutch book translations, and find that, for certain books, ourapproach retrieves lexical diversity scores that are close to humantranslation.</description><author>Esther Ploeger, Huiyuan Lai, Rik van Noord, Antonio Toral</author><pubDate>Fri, 30 Aug 2024 14:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17308v1</guid></item><item><title>Hybridizing Base-Line 2D-CNN Model with Cat Swarm Optimization for Enhanced Advanced Persistent Threat Detection</title><link>http://arxiv.org/abs/2408.17307v1</link><description>In the realm of cyber-security, detecting Advanced Persistent Threats (APTs)remains a formidable challenge due to their stealthy and sophisticated nature.This research paper presents an innovative approach that leveragesConvolutional Neural Networks (CNNs) with a 2D baseline model, enhanced by thecutting-edge Cat Swarm Optimization (CSO) algorithm, to significantly improveAPT detection accuracy. By seamlessly integrating the 2D-CNN baseline modelwith CSO, we unlock the potential for unprecedented accuracy and efficiency inAPT detection. The results unveil an impressive accuracy score of $98.4\%$,marking a significant enhancement in APT detection across various attackstages, illuminating a path forward in combating these relentless andsophisticated threats.</description><author>Ali M. Bakhiet, Salah A. Aly</author><pubDate>Fri, 30 Aug 2024 14:11:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17307v1</guid></item><item><title>Wasserstein multivariate auto-regressive models for modeling distributional time series</title><link>http://arxiv.org/abs/2207.05442v3</link><description>This paper is focused on the statistical analysis of data consisting of acollection of multiple series of probability measures that are indexed bydistinct time instants and supported over a bounded interval of the real line.By modeling these time-dependent probability measures as random objects in theWasserstein space, we propose a new auto-regressive model for the statisticalanalysis of multivariate distributional time series. Using the theory ofiterated random function systems, results on the existence, uniqueness andstationarity of the solution of such a model are provided. We also propose aconsistent estimator for the auto-regressive coefficients of this model. Due tothe simplex constraints that we impose on the model coefficients, the proposedestimator that is learned under these constraints, naturally has a sparsestructure. The sparsity allows the application of the proposed model inlearning a graph of temporal dependency from multivariate distributional timeseries. We explore the numerical performances of our estimation procedure usingsimulated data. To shed some light on the benefits of our approach for realdata analysis, we also apply this methodology to a data set made ofobservations from age distribution in different countries.</description><author>Yiye Jiang, Jérémie Bigot</author><pubDate>Fri, 30 Aug 2024 14:11:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.05442v3</guid></item><item><title>DreamPhysics: Learning Physical Properties of Dynamic 3D Gaussians with Video Diffusion Priors</title><link>http://arxiv.org/abs/2406.01476v2</link><description>Dynamic 3D interaction has been attracting a lot of attention recently.However, creating such 4D content remains challenging. One solution is toanimate 3D scenes with physics-based simulation, which requires manuallyassigning precise physical properties to the object or the simulated resultswould become unnatural. Another solution is to learn the deformation of 3Dobjects with the distillation of video generative models, which, however, tendsto produce 3D videos with small and discontinuous motions due to theinappropriate extraction and application of physical prior. In this work,combining the strengths and complementing shortcomings of the above twosolutions, we propose to learn the physical properties of a material field withvideo diffusion priors, and then utilize a physics-based Material-Point-Method(MPM) simulator to generate 4D content with realistic motions. In particular,we propose motion distillation sampling to emphasize video motion informationduring distillation. Moreover, to facilitate the optimization, we furtherpropose a KAN-based material field with frame boosting. Experimental resultsdemonstrate that our method enjoys more realistic motion thanstate-of-the-arts. Codes are released at:https://github.com/tyhuang0428/DreamPhysics.</description><author>Tianyu Huang, Haoze Zhang, Yihan Zeng, Zhilu Zhang, Hui Li, Wangmeng Zuo, Rynson W. H. Lau</author><pubDate>Fri, 30 Aug 2024 14:09:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01476v2</guid></item><item><title>Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with Robotic and Human Co-Workers</title><link>http://arxiv.org/abs/2212.11498v3</link><description>We consider a warehouse in which dozens of mobile robots and human pickerswork together to collect and deliver items within the warehouse. Thefundamental problem we tackle, called the order-picking problem, is how theseworker agents must coordinate their movement and actions in the warehouse tomaximise performance in this task. Established industry methods using heuristicapproaches require large engineering efforts to optimise for innately variablewarehouse configurations. In contrast, multi-agent reinforcement learning(MARL) can be flexibly applied to diverse warehouse configurations (e.g. size,layout, number/types of workers, item replenishment frequency), and differenttypes of order-picking paradigms (e.g. Goods-to-Person and Person-to-Goods), asthe agents can learn how to cooperate optimally through experience. We develophierarchical MARL algorithms in which a manager agent assigns goals to workeragents, and the policies of the manager and workers are co-trained towardmaximising a global objective (e.g. pick rate). Our hierarchical algorithmsachieve significant gains in sample efficiency over baseline MARL algorithmsand overall pick rates over multiple established industry heuristics in adiverse set of warehouse configurations and different order-picking paradigms.</description><author>Aleksandar Krnjaic, Raul D. Steleac, Jonathan D. Thomas, Georgios Papoudakis, Lukas Schäfer, Andrew Wing Keung To, Kuan-Ho Lao, Murat Cubuktepe, Matthew Haley, Peter Börsting, Stefano V. Albrecht</author><pubDate>Fri, 30 Aug 2024 14:07:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.11498v3</guid></item><item><title>A Deep-Learning Technique to Locate Cryptographic Operations in Side-Channel Traces</title><link>http://arxiv.org/abs/2402.19037v2</link><description>Side-channel attacks allow extracting secret information from the executionof cryptographic primitives by correlating the partially known computed dataand the measured side-channel signal. However, to set up a successfulside-channel attack, the attacker has to perform i) the challenging task oflocating the time instant in which the target cryptographic primitive isexecuted inside a side-channel trace and then ii)the time-alignment of themeasured data on that time instant. This paper presents a novel deep-learningtechnique to locate the time instant in which the target computed cryptographicoperations are executed in the side-channel trace. In contrast tostate-of-the-art solutions, the proposed methodology works even in the presenceof trace deformations obtained through random delay insertion techniques. Wevalidated our proposal through a successful attack against a variety ofunprotected and protected cryptographic primitives that have been executed onan FPGA-implemented system-on-chip featuring a RISC-V CPU.</description><author>Giuseppe Chiari, Davide Galli, Francesco Lattari, Matteo Matteucci, Davide Zoni</author><pubDate>Fri, 30 Aug 2024 13:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19037v2</guid></item><item><title>L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection</title><link>http://arxiv.org/abs/2408.03677v3</link><description>LiDAR-based vision systems are integral for 3D object detection, which iscrucial for autonomous navigation. However, they suffer from performancedegradation in adverse weather conditions due to the quality deterioration ofLiDAR point clouds. Fusing LiDAR with the weather-robust 4D radar sensor isexpected to solve this problem. However, the fusion of LiDAR and 4D radar ischallenging because they differ significantly in terms of data quality and thedegree of degradation in adverse weather. To address these issues, we introduceL4DR, a weather-robust 3D object detection method that effectively achievesLiDAR and 4D Radar fusion. Our L4DR includes Multi-Modal Encoding (MME) andForeground-Aware Denoising (FAD) technique to reconcile sensor gaps, which isthe first exploration of the complementarity of early fusion between LiDAR and4D radar. Additionally, we design an Inter-Modal and Intra-Modal ({IM}2 )parallel feature extraction backbone coupled with a Multi-Scale Gated Fusion(MSGF) module to counteract the varying degrees of sensor degradation underadverse weather conditions. Experimental evaluation on a VoD dataset withsimulated fog proves that L4DR is more adaptable to changing weatherconditions. It delivers a significant performance increase under different foglevels, improving the 3D mAP by up to 20.0% over the traditional LiDAR-onlyapproach. Moreover, the results on the K-Radar dataset validate the consistentperformance improvement of L4DR in real-world adverse weather conditions.</description><author>Xun Huang, Ziyu Xu, Hai Wu, Jinlong Wang, Qiming Xia, Yan Xia, Jonathan Li, Kyle Gao, Chenglu Wen, Cheng Wang</author><pubDate>Fri, 30 Aug 2024 13:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03677v3</guid></item><item><title>Accelerating the discovery of steady-states of planetary interior dynamics with machine learning</title><link>http://arxiv.org/abs/2408.17298v1</link><description>Simulating mantle convection often requires reaching a computationallyexpensive steady-state, crucial for deriving scaling laws for thermal anddynamical flow properties and benchmarking numerical solutions. The strongtemperature dependence of the rheology of mantle rocks causes viscosityvariations of several orders of magnitude, leading to a slow-evolving stagnantlid where heat conduction dominates, overlying a rapidly-evolving and stronglyconvecting region. Time-stepping methods, while effective for fluids withconstant viscosity, are hindered by the Courant criterion, which restricts thetime step based on the system's maximum velocity and grid size. Consequently,achieving steady-state requires a large number of time steps due to thedisparate time scales governing the stagnant and convecting regions. We present a concept for accelerating mantle convection simulations usingmachine learning. We generate a dataset of 128 two-dimensional simulations withmixed basal and internal heating, and pressure- and temperature-dependentviscosity. We train a feedforward neural network on 97 simulations to predictsteady-state temperature profiles. These can then be used to initializenumerical time stepping methods for different simulation parameters. Comparedto typical initializations, the number of time steps required to reachsteady-state is reduced by a median factor of 3.75. The benefit of this methodlies in requiring very few simulations to train on, providing a solution withno prediction error as we initialize a numerical method, and posing minimalcomputational overhead at inference time. We demonstrate the effectiveness ofour approach and discuss the potential implications for accelerated simulationsfor advancing mantle convection research.</description><author>Siddhant Agarwal, Nicola Tosi, Christian Hüttig, David S. Greenberg, Ali Can Bekar</author><pubDate>Fri, 30 Aug 2024 13:55:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17298v1</guid></item><item><title>Minor DPO reject penalty to increase training robustness</title><link>http://arxiv.org/abs/2408.09834v3</link><description>Learning from human preference is a paradigm used in large-scale languagemodel (LLM) fine-tuning step to better align pretrained LLM to human preferencefor downstream task. In the past it uses reinforcement learning from humanfeedback (RLHF) algorithm to optimize the LLM policy to align with thesepreferences and not to draft too far from the original model. Recently, DirectPreference Optimization (DPO) has been proposed to solve the alignment problemwith a simplified RL-free method. Using preference pairs of chosen and rejectdata, DPO models the relative log probability as implicit reward function andoptimize LLM policy using a simple binary cross entropy objective directly. DPOis quite straight forward and easy to be understood. It perform efficiently andwell in most cases. In this article, we analyze the working mechanism of$\beta$ in DPO, disclose its syntax difference between RL algorithm and DPO,and understand the potential shortage brought by the DPO simplification. Withthese insights, we propose MinorDPO, which is better aligned to the original RLalgorithm, and increase the stability of preference optimization process.</description><author>Shiming Xie, Hong Chen, Fred Yu, Zeye Sun, Xiuyu Wu, Yingfan Hu</author><pubDate>Fri, 30 Aug 2024 13:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09834v3</guid></item><item><title>BOP-D: Revisiting 6D Pose Estimation Benchmark for Better Evaluation under Visual Ambiguities</title><link>http://arxiv.org/abs/2408.17297v1</link><description>Currently, 6D pose estimation methods are benchmarked on datasets thatconsider, for their ground truth annotations, visual ambiguities as onlyrelated to global object symmetries. However, as previously observed [26],visual ambiguities can also happen depending on the viewpoint or the presenceof occluding objects, when disambiguating parts become hidden. The visualambiguities are therefore actually different across images. We thus firstpropose an automatic method to re-annotate those datasets with a 6D posedistribution specific to each image, taking into account the visibility of theobject surface in the image to correctly determine the visual ambiguities.Given this improved ground truth, we re-evaluate the state-of-the-art methodsand show this greatly modify the ranking of these methods. Our annotations alsoallow us to benchmark recent methods able to estimate a pose distribution onreal images for the first time. We will make our annotations for the T-LESSdataset and our code publicly available.</description><author>Boris Meden, Asma Brazi, Steve Bourgeois, Fabrice Mayran de Chamisso, Vincent Lepetit</author><pubDate>Fri, 30 Aug 2024 13:52:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17297v1</guid></item><item><title>GeoMeter: Probing Depth and Height Perception of Large Visual-Language Models</title><link>http://arxiv.org/abs/2408.11748v3</link><description>Geometric understanding is crucial for navigating and interacting with ourenvironment. While large Vision Language Models (VLMs) demonstrate impressivecapabilities, deploying them in real-world scenarios necessitates a comparablegeometric understanding in visual perception. In this work, we focus on thegeometric comprehension of these models; specifically targeting the depths andheights of objects within a scene. Our observations reveal that, although VLMsexcel in basic geometric properties perception such as shape and size, theyencounter significant challenges in reasoning about the depth and height ofobjects. To address this, we introduce GeoMeter, a suite of benchmark datasetsencompassing Synthetic 2D, Synthetic 3D, and Real-World scenarios to rigorouslyevaluate these aspects. We benchmark 17 state-of-the-art VLMs using thesedatasets and find that they consistently struggle with both depth and heightperception. Our key insights include detailed analyses of the shortcomings indepth and height reasoning capabilities of VLMs and the inherent bias presentin these models. This study aims to pave the way for the development of VLMswith enhanced geometric understanding, crucial for real-world applications.</description><author>Shehreen Azad, Yash Jain, Rishit Garg, Yogesh S Rawat, Vibhav Vineet</author><pubDate>Fri, 30 Aug 2024 13:52:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11748v3</guid></item><item><title>Revisiting 360 Depth Estimation with PanoGabor: A New Fusion Perspective</title><link>http://arxiv.org/abs/2408.16227v2</link><description>Depth estimation from a monocular 360 image is important to the perception ofthe entire 3D environment. However, the inherent distortion and large field ofview (FoV) in 360 images pose great challenges for this task. To this end,existing mainstream solutions typically introduce additional perspective-based360 representations (\textit{e.g.}, Cubemap) to achieve effective featureextraction. Nevertheless, regardless of the introduced representations, theyeventually need to be unified into the equirectangular projection (ERP) formatfor the subsequent depth estimation, which inevitably reintroduces thetroublesome distortions. In this work, we propose an oriented distortion-awareGabor Fusion framework (PGFuse) to address the above challenges. First, weintroduce Gabor filters that analyze texture in the frequency domain, therebyextending the receptive fields and enhancing depth cues. To address thereintroduced distortions, we design a linear latitude-aware distortionrepresentation method to generate customized, distortion-aware Gabor filters(PanoGabor filters). Furthermore, we design a channel-wise and spatial-wiseunidirectional fusion module (CS-UFM) that integrates the proposed PanoGaborfilters to unify other representations into the ERP format, deliveringeffective and distortion-free features. Considering the orientation sensitivityof the Gabor transform, we introduce a spherical gradient constraint tostabilize this sensitivity. Experimental results on three popular indoor 360benchmarks demonstrate the superiority of the proposed PGFuse to existingstate-of-the-art solutions. Code can be available upon acceptance.</description><author>Zhijie Shen, Chunyu Lin, Lang Nie, Kang Liao</author><pubDate>Fri, 30 Aug 2024 13:48:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16227v2</guid></item><item><title>Novel Methods for Analyzing Cellular Interactions in Deep Learning-Based Image Cytometry: Spatial Interaction Potential and Co-Localization Index</title><link>http://arxiv.org/abs/2408.16008v2</link><description>The study presents a novel approach for quantifying cellular interactions indigital pathology using deep learning-based image cytometry. Traditionalmethods struggle with the diversity and heterogeneity of cells within tissues.To address this, we introduce the Spatial Interaction Potential (SIP) and theCo-Localization Index (CLI), leveraging deep learning classificationprobabilities. SIP assesses the potential for cell-to-cell interactions,similar to an electric field, while CLI incorporates distances between cells,accounting for dynamic cell movements. Our approach enhances traditionalmethods, providing a more sophisticated analysis of cellular interactions. Wevalidate SIP and CLI through simulations and apply them to colorectal cancerspecimens, demonstrating strong correlations with actual biological data. Thisinnovative method offers significant improvements in understanding cellularinteractions and has potential applications in various fields of digitalpathology.</description><author>Toru Nagasaka, Kimihiro Yamashita, Mitsugu Fujita</author><pubDate>Fri, 30 Aug 2024 13:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16008v2</guid></item><item><title>Diversifying the Mixture-of-Experts Representation for Language Models with Orthogonal Optimizer</title><link>http://arxiv.org/abs/2310.09762v2</link><description>The Mixture of Experts (MoE) has emerged as a highly successful technique indeep learning, based on the principle of divide-and-conquer to maximize modelcapacity without significant additional computational cost. Even in the era oflarge-scale language models (LLMs), MoE continues to play a crucial role, assome researchers have indicated that GPT-4 adopts the MoE structure to ensurediverse inference results. However, MoE is susceptible to performancedegeneracy, particularly evident in the issues of imbalance and homogeneousrepresentation among experts. While previous studies have extensively addressedthe problem of imbalance, the challenge of homogeneous representation remainsunresolved. In this study, we shed light on the homogeneous representationproblem, wherein experts in the MoE fail to specialize and lack diversity,leading to frustratingly high similarities in their representations (up to 99\%in a well-performed MoE model). This problem restricts the expressive power ofthe MoE and, we argue, contradicts its original intention. To tackle thisissue, we propose a straightforward yet highly effective solution: OMoE, anorthogonal expert optimizer. Additionally, we introduce an alternating trainingstrategy that encourages each expert to update in a direction orthogonal to thesubspace spanned by other experts. Our algorithm facilitates MoE training intwo key ways: firstly, it explicitly enhances representation diversity, andsecondly, it implicitly fosters interaction between experts during orthogonalweights computation. Through extensive experiments, we demonstrate that ourproposed optimization algorithm significantly improves the performance offine-tuning the MoE model on the GLUE benchmark, SuperGLUE benchmark,question-answering task, and name entity recognition tasks.</description><author>Boan Liu, Liang Ding, Li Shen, Keqin Peng, Yu Cao, Dazhao Cheng, Dacheng Tao</author><pubDate>Fri, 30 Aug 2024 13:39:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09762v2</guid></item><item><title>High Probability Complexity Bounds for Non-Smooth Stochastic Optimization with Heavy-Tailed Noise</title><link>http://arxiv.org/abs/2106.05958v3</link><description>Stochastic first-order methods are standard for training large-scale machinelearning models. Random behavior may cause a particular run of an algorithm toresult in a highly suboptimal objective value, whereas theoretical guaranteesare usually proved for the expectation of the objective value. Thus, it isessential to theoretically guarantee that algorithms provide small objectiveresidual with high probability. Existing methods for non-smooth stochasticconvex optimization have complexity bounds with the dependence on theconfidence level that is either negative-power or logarithmic but under anadditional assumption of sub-Gaussian (light-tailed) noise distribution thatmay not hold in practice. In our paper, we resolve this issue and derive thefirst high-probability convergence results with logarithmic dependence on theconfidence level for non-smooth convex stochastic optimization problems withnon-sub-Gaussian (heavy-tailed) noise. To derive our results, we propose novelstepsize rules for two stochastic methods with gradient clipping. Moreover, ouranalysis works for generalized smooth objectives with H\"older-continuousgradients, and for both methods, we provide an extension for strongly convexproblems. Finally, our results imply that the first (accelerated) method weconsider also has optimal iteration and oracle complexity in all the regimes,and the second one is optimal in the non-smooth setting.</description><author>Eduard Gorbunov, Marina Danilova, Innokentiy Shibaev, Pavel Dvurechensky, Alexander Gasnikov</author><pubDate>Fri, 30 Aug 2024 13:35:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.05958v3</guid></item><item><title>Stationary Policies are Optimal in Risk-averse Total-reward MDPs with EVaR</title><link>http://arxiv.org/abs/2408.17286v1</link><description>Optimizing risk-averse objectives in discounted MDPs is challenging becausemost models do not admit direct dynamic programming equations and requirecomplex history-dependent policies. In this paper, we show that the risk-averse{\em total reward criterion}, under the Entropic Risk Measure (ERM) andEntropic Value at Risk (EVaR) risk measures, can be optimized by a stationarypolicy, making it simple to analyze, interpret, and deploy. We proposeexponential value iteration, policy iteration, and linear programming tocompute optimal policies. In comparison with prior work, our results onlyrequire the relatively mild condition of transient MDPs and allow for {\emboth} positive and negative rewards. Our results indicate that the total rewardcriterion may be preferable to the discounted criterion in a broad range ofrisk-averse reinforcement learning domains.</description><author>Xihong Su, Marek Petrik, Julien Grand-Clément</author><pubDate>Fri, 30 Aug 2024 13:33:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17286v1</guid></item><item><title>Image-Perfect Imperfections: Safety, Bias, and Authenticity in the Shadow of Text-To-Image Model Evolution</title><link>http://arxiv.org/abs/2408.17285v1</link><description>Text-to-image models, such as Stable Diffusion (SD), undergo iterativeupdates to improve image quality and address concerns such as safety.Improvements in image quality are straightforward to assess. However, how modelupdates resolve existing concerns and whether they raise new questions remainunexplored. This study takes an initial step in investigating the evolution oftext-to-image models from the perspectives of safety, bias, and authenticity.Our findings, centered on Stable Diffusion, indicate that model updates paint amixed picture. While updates progressively reduce the generation of unsafeimages, the bias issue, particularly in gender, intensifies. We also find thatnegative stereotypes either persist within the same Non-White race group orshift towards other Non-White race groups through SD updates, yet with minimalassociation of these traits with the White race group. Additionally, ourevaluation reveals a new concern stemming from SD updates: State-of-the-artfake image detectors, initially trained for earlier SD versions, struggle toidentify fake images generated by updated versions. We show that fine-tuningthese detectors on fake images generated by updated versions achieves at least96.6\% accuracy across various SD versions, addressing this issue. Our insightshighlight the importance of continued efforts to mitigate biases andvulnerabilities in evolving text-to-image models.</description><author>Yixin Wu, Yun Shen, Michael Backes, Yang Zhang</author><pubDate>Fri, 30 Aug 2024 13:33:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17285v1</guid></item><item><title>DCUDF2: Improving Efficiency and Accuracy in Extracting Zero Level Sets from Unsigned Distance Fields</title><link>http://arxiv.org/abs/2408.17284v1</link><description>Unsigned distance fields (UDFs) allow for the representation of models withcomplex topologies, but extracting accurate zero level sets from these fieldsposes significant challenges, particularly in preserving topological accuracyand capturing fine geometric details. To overcome these issues, we introduceDCUDF2, an enhancement over DCUDF--the current state-of-the-art method--forextracting zero level sets from UDFs. Our approach utilizes an accuracy-awareloss function, enhanced with self-adaptive weights, to improve geometricquality significantly. We also propose a topology correction strategy thatreduces the dependence on hyper-parameter, increasing the robustness of ourmethod. Furthermore, we develop new operations leveraging self-adaptive weightsto boost runtime efficiency. Extensive experiments on surface extraction acrossdiverse datasets demonstrate that DCUDF2 outperforms DCUDF and existing methodsin both geometric fidelity and topological accuracy. We will make the sourcecode publicly available.</description><author>Xuhui Chen, Fugang Yu, Fei Hou, Wencheng Wang, Zhebin Zhang, Ying He</author><pubDate>Fri, 30 Aug 2024 13:31:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17284v1</guid></item><item><title>Flexible and Effective Mixing of Large Language Models into a Mixture of Domain Experts</title><link>http://arxiv.org/abs/2408.17280v1</link><description>We present a toolkit for creating low-cost Mixture-of-Domain-Experts (MOE)from trained models. The toolkit can be used for creating a mixture from modelsor from adapters. We perform extensive tests and offer guidance on defining thearchitecture of the resulting MOE using the toolkit. A public repository isavailable.</description><author>Rhui Dih Lee, Laura Wynter, Raghu Kiran Ganti</author><pubDate>Fri, 30 Aug 2024 13:28:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17280v1</guid></item><item><title>Object-Centric Diffusion for Efficient Video Editing</title><link>http://arxiv.org/abs/2401.05735v3</link><description>Diffusion-based video editing have reached impressive quality and cantransform either the global style, local structure, and attributes of givenvideo inputs, following textual edit prompts. However, such solutions typicallyincur heavy memory and computational costs to generate temporally-coherentframes, either in the form of diffusion inversion and/or cross-frame attention.In this paper, we conduct an analysis of such inefficiencies, and suggestsimple yet effective modifications that allow significant speed-ups whilstmaintaining quality. Moreover, we introduce Object-Centric Diffusion, to fixgeneration artifacts and further reduce latency by allocating more computationstowards foreground edited regions, arguably more important for perceptualquality. We achieve this by two novel proposals: i) Object-Centric Sampling,decoupling the diffusion steps spent on salient or background regions andspending most on the former, and ii) Object-Centric Token Merging, whichreduces cost of cross-frame attention by fusing redundant tokens in unimportantbackground regions. Both techniques are readily applicable to a given videoediting model without retraining, and can drastically reduce its memory andcomputational cost. We evaluate our proposals on inversion-based andcontrol-signal-based editing pipelines, and show a latency reduction up to 10xfor a comparable synthesis quality. Project page:qualcomm-ai-research.github.io/object-centric-diffusion.</description><author>Kumara Kahatapitiya, Adil Karjauv, Davide Abati, Fatih Porikli, Yuki M. Asano, Amirhossein Habibian</author><pubDate>Fri, 30 Aug 2024 13:28:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05735v3</guid></item><item><title>CaFNet: A Confidence-Driven Framework for Radar Camera Depth Estimation</title><link>http://arxiv.org/abs/2407.00697v3</link><description>Depth estimation is critical in autonomous driving for interpreting 3D scenesaccurately. Recently, radar-camera depth estimation has become of sufficientinterest due to the robustness and low-cost properties of radar. Thus, thispaper introduces a two-stage, end-to-end trainable Confidence-aware Fusion Net(CaFNet) for dense depth estimation, combining RGB imagery with sparse andnoisy radar point cloud data. The first stage addresses radar-specificchallenges, such as ambiguous elevation and noisy measurements, by predicting aradar confidence map and a preliminary coarse depth map. A novel approach ispresented for generating the ground truth for the confidence map, whichinvolves associating each radar point with its corresponding object to identifypotential projection surfaces. These maps, together with the initial radarinput, are processed by a second encoder. For the final depth estimation, weinnovate a confidence-aware gated fusion mechanism to integrate radar and imagefeatures effectively, thereby enhancing the reliability of the depth map byfiltering out radar noise. Our methodology, evaluated on the nuScenes dataset,demonstrates superior performance, improving upon the current leading model by3.2% in Mean Absolute Error (MAE) and 2.7% in Root Mean Square Error (RMSE).Code: https://github.com/harborsarah/CaFNet</description><author>Huawei Sun, Hao Feng, Julius Ott, Lorenzo Servadei, Robert Wille</author><pubDate>Fri, 30 Aug 2024 13:25:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00697v3</guid></item><item><title>Minimax and Communication-Efficient Distributed Best Subset Selection with Oracle Property</title><link>http://arxiv.org/abs/2408.17276v1</link><description>The explosion of large-scale data in fields such as finance, e-commerce, andsocial media has outstripped the processing capabilities of single-machinesystems, driving the need for distributed statistical inference methods.Traditional approaches to distributed inference often struggle with achievingtrue sparsity in high-dimensional datasets and involve high computationalcosts. We propose a novel, two-stage, distributed best subset selectionalgorithm to address these issues. Our approach starts by efficientlyestimating the active set while adhering to the $\ell_0$ norm-constrainedsurrogate likelihood function, effectively reducing dimensionality andisolating key variables. A refined estimation within the active set follows,ensuring sparse estimates and matching the minimax $\ell_2$ error bound. Weintroduce a new splicing technique for adaptive parameter selection to tacklesubproblems under $\ell_0$ constraints and a Generalized Information Criterion(GIC). Our theoretical and numerical studies show that the proposed algorithmcorrectly finds the true sparsity pattern, has the oracle property, and greatlylowers communication costs. This is a big step forward in distributed sparseestimation.</description><author>Jingguo Lan, Hongmei Lin, Xueqin Wang</author><pubDate>Fri, 30 Aug 2024 13:22:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17276v1</guid></item><item><title>The Transferability of Downsampling Sparse Graph Convolutional Networks</title><link>http://arxiv.org/abs/2408.17274v1</link><description>In this paper, we propose a large-scale sparse graph downsampling methodbased on a sparse random graph model, which allows for the adjustment ofdifferent sparsity levels. We combine sparsity and topological similarity: thesparse graph model reduces the node connection probability as the graph sizeincreases, while the downsampling method preserves a specific topologicalconnection pattern during this change. Based on the downsampling method, wederive a theoretical transferability bound about downsampling sparse graphconvolutional networks (GCNs), that higher sampling rates, greater averagedegree expectations, and smaller initial graph sizes lead to betterdownsampling transferability performance.</description><author>Qinji Shu, Hang Sheng, Hui Feng, Bo Hu</author><pubDate>Fri, 30 Aug 2024 13:19:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17274v1</guid></item><item><title>Equation identification for fluid flows via physics-informed neural networks</title><link>http://arxiv.org/abs/2408.17271v1</link><description>Scientific machine learning (SciML) methods such as physics-informed neuralnetworks (PINNs) are used to estimate parameters of interest from governingequations and small quantities of data. However, there has been little work inassessing how well PINNs perform for inverse problems across wide ranges ofgoverning equations across the mathematical sciences. We present a new andchallenging benchmark problem for inverse PINNs based on a parametric sweep ofthe 2D Burgers' equation with rotational flow. We show that a novel strategythat alternates between first- and second-order optimization proves superior totypical first-order strategies for estimating parameters. In addition, wepropose a novel data-driven method to characterize PINN effectiveness in theinverse setting. PINNs' physics-informed regularization enables them toleverage small quantities of data more efficiently than the data-drivenbaseline. However, both PINNs and the baseline can fail to recover parametersfor highly inviscid flows, motivating the need for further development of PINNmethods.</description><author>Alexander New, Marisel Villafañe-Delgado, Charles Shugert</author><pubDate>Fri, 30 Aug 2024 13:17:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17271v1</guid></item><item><title>UrBench: A Comprehensive Benchmark for Evaluating Large Multimodal Models in Multi-View Urban Scenarios</title><link>http://arxiv.org/abs/2408.17267v1</link><description>Recent evaluations of Large Multimodal Models (LMMs) have explored theircapabilities in various domains, with only few benchmarks specifically focusingon urban environments. Moreover, existing urban benchmarks have been limited toevaluating LMMs with basic region-level urban tasks under singular views,leading to incomplete evaluations of LMMs' abilities in urban environments. Toaddress these issues, we present UrBench, a comprehensive benchmark designedfor evaluating LMMs in complex multi-view urban scenarios. UrBench contains11.6K meticulously curated questions at both region-level and role-level thatcover 4 task dimensions: Geo-Localization, Scene Reasoning, SceneUnderstanding, and Object Understanding, totaling 14 task types. Inconstructing UrBench, we utilize data from existing datasets and additionallycollect data from 11 cities, creating new annotations using a cross-viewdetection-matching method. With these images and annotations, we then integrateLMM-based, rule-based, and human-based methods to construct large-scalehigh-quality questions. Our evaluations on 21 LMMs show that current LMMsstruggle in the urban environments in several aspects. Even the best performingGPT-4o lags behind humans in most tasks, ranging from simple tasks such ascounting to complex tasks such as orientation, localization and objectattribute recognition, with an average performance gap of 17.4%. Our benchmarkalso reveals that LMMs exhibit inconsistent behaviors with different urbanviews, especially with respect to understanding cross-view relations. UrBenchdatasets and benchmark results will be publicly available athttps://opendatalab.github.io/UrBench/.</description><author>Baichuan Zhou, Haote Yang, Dairong Chen, Junyan Ye, Tianyi Bai, Jinhua Yu, Songyang Zhang, Dahua Lin, Conghui He, Weijia Li</author><pubDate>Fri, 30 Aug 2024 13:13:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17267v1</guid></item><item><title>Addressing the challenges of loop detection in agricultural environments</title><link>http://arxiv.org/abs/2408.15761v2</link><description>While visual SLAM systems are well studied and achieve impressive results inindoor and urban settings, natural, outdoor and open-field environments aremuch less explored and still present relevant research challenges. Visualnavigation and local mapping have shown a relatively good performance inopen-field environments. However, globally consistent mapping and long-termlocalization still depend on the robustness of loop detection and closure, forwhich the literature is scarce. In this work we propose a novel method to pavethe way towards robust loop detection in open fields, particularly inagricultural settings, based on local feature search and stereo geometricrefinement, with a final stage of relative pose estimation. Our methodconsistently achieves good loop detections, with a median error of 15cm. We aimto characterize open fields as a novel environment for loop detection,understanding the limitations and problems that arise when dealing with them.</description><author>Nicolás Soncini, Javier Civera, Taihú Pire</author><pubDate>Fri, 30 Aug 2024 13:13:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15761v2</guid></item><item><title>Fast Fishing: Approximating BAIT for Efficient and Scalable Deep Active Image Classification</title><link>http://arxiv.org/abs/2404.08981v2</link><description>Deep active learning (AL) seeks to minimize the annotation costs for trainingdeep neural networks. BAIT, a recently proposed AL strategy based on the FisherInformation, has demonstrated impressive performance across various datasets.However, BAIT's high computational and memory requirements hinder itsapplicability on large-scale classification tasks, resulting in currentresearch neglecting BAIT in their evaluation. This paper introduces two methodsto enhance BAIT's computational efficiency and scalability. Notably, wesignificantly reduce its time complexity by approximating the FisherInformation. In particular, we adapt the original formulation by i) taking theexpectation over the most probable classes, and ii) constructing a binaryclassification task, leading to an alternative likelihood for gradientcomputations. Consequently, this allows the efficient use of BAIT onlarge-scale datasets, including ImageNet. Our unified and comprehensiveevaluation across a variety of datasets demonstrates that our approximationsachieve strong performance with considerably reduced time complexity.Furthermore, we provide an extensive open-source toolbox that implements recentstate-of-the-art AL strategies, available athttps://github.com/dhuseljic/dal-toolbox.</description><author>Denis Huseljic, Paul Hahn, Marek Herde, Lukas Rauch, Bernhard Sick</author><pubDate>Fri, 30 Aug 2024 13:06:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08981v2</guid></item><item><title>Joint Estimation and Prediction of City-wide Delivery Demand: A Large Language Model Empowered Graph-based Learning Approach</title><link>http://arxiv.org/abs/2408.17258v1</link><description>The proliferation of e-commerce and urbanization has significantlyintensified delivery operations in urban areas, boosting the volume andcomplexity of delivery demand. Data-driven predictive methods, especially thoseutilizing machine learning techniques, have emerged to handle thesecomplexities in urban delivery demand management problems. One particularlypressing problem that has not yet been sufficiently studied is the jointestimation and prediction of city-wide delivery demand. To this end, weformulate this problem as a graph-based spatiotemporal learning task. First, amessage-passing neural network model is formalized to capture the interactionbetween demand patterns of associated regions. Second, by exploiting recentadvances in large language models, we extract general geospatial knowledgeencodings from the unstructured locational data and integrate them into thedemand predictor. Last, to encourage the cross-city transferability of themodel, an inductive training scheme is developed in an end-to-end routine.Extensive empirical results on two real-world delivery datasets, includingeight cities in China and the US, demonstrate that our model significantlyoutperforms state-of-the-art baselines in these challenging tasks.</description><author>Tong Nie, Junlin He, Yuewen Mei, Guoyang Qin, Guilong Li, Jian Sun, Wei Ma</author><pubDate>Fri, 30 Aug 2024 12:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17258v1</guid></item></channel></rss>