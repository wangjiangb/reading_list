<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 30 Jan 2024 06:00:36 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Computer Vision for Primate Behavior Analysis in the Wild</title><link>http://arxiv.org/abs/2401.16424v1</link><description>Advances in computer vision as well as increasingly widespread video-basedbehavioral monitoring have great potential for transforming how we study animalcognition and behavior. However, there is still a fairly large gap between theexciting prospects and what can actually be achieved in practice today,especially in videos from the wild. With this perspective paper, we want tocontribute towards closing this gap, by guiding behavioral scientists in whatcan be expected from current methods and steering computer vision researcherstowards problems that are relevant to advance research in animal behavior. Westart with a survey of the state-of-the-art methods for computer visionproblems that are directly relevant to the video-based study of animalbehavior, including object detection, multi-individual tracking, (inter)actionrecognition and individual identification. We then review methods foreffort-efficient learning, which is one of the biggest challenges from apractical perspective. Finally, we close with an outlook into the future of theemerging field of computer vision for animal behavior, where we argue that thefield should move fast beyond the common frame-by-frame processing and treatvideo as a first-class citizen.</description><author>Richard Vogg, Timo Lüddecke, Jonathan Henrich, Sharmita Dey, Matthias Nuske, Valentin Hassler, Derek Murphy, Julia Fischer, Julia Ostner, Oliver Schülke, Peter M. Kappeler, Claudia Fichtel, Alexander Gail, Stefan Treue, Hansjörg Scherberger, Florentin Wörgötter, Alexander S. Ecker</author><pubDate>Mon, 29 Jan 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16424v1</guid></item><item><title>Synchformer: Efficient Synchronization from Sparse Cues</title><link>http://arxiv.org/abs/2401.16423v1</link><description>Our objective is audio-visual synchronization with a focus on 'in-the-wild'videos, such as those on YouTube, where synchronization cues can be sparse. Ourcontributions include a novel audio-visual synchronization model, and trainingthat decouples feature extraction from synchronization modelling throughmulti-modal segment-level contrastive pre-training. This approach achievesstate-of-the-art performance in both dense and sparse settings. We also extendsynchronization model training to AudioSet a million-scale 'in-the-wild'dataset, investigate evidence attribution techniques for interpretability, andexplore a new capability for synchronization models: audio-visualsynchronizability.</description><author>Vladimir Iashin, Weidi Xie, Esa Rahtu, Andrew Zisserman</author><pubDate>Mon, 29 Jan 2024 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16423v1</guid></item><item><title>Strategic Usage in a Multi-Learner Setting</title><link>http://arxiv.org/abs/2401.16422v1</link><description>Real-world systems often involve some pool of users choosing between a set ofservices. With the increase in popularity of online learning algorithms, theseservices can now self-optimize, leveraging data collected on users to maximizesome reward such as service quality. On the flipside, users may strategicallychoose which services to use in order to pursue their own reward functions, inthe process wielding power over which services can see and use their data.Extensive prior research has been conducted on the effects of strategic usersin single-service settings, with strategic behavior manifesting in themanipulation of observable features to achieve a desired classification;however, this can often be costly or unattainable for users and fails tocapture the full behavior of multi-service dynamic systems. As such, we analyzea setting in which strategic users choose among several available services inorder to pursue positive classifications, while services seek to minimize lossfunctions on their observations. We focus our analysis on realizable settings,and show that naive retraining can still lead to oscillation even if all usersare observed at different times; however, if this retraining uses memory ofpast observations, convergent behavior can be guaranteed for certain lossfunction classes. We provide results obtained from synthetic and real-worlddata to empirically validate our theoretical findings.</description><author>Eliot Shekhtman, Sarah Dean</author><pubDate>Mon, 29 Jan 2024 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16422v1</guid></item><item><title>Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation</title><link>http://arxiv.org/abs/2401.16421v1</link><description>In this work, we leverage the intrinsic segmentation of language sequencesand design a new positional encoding method called Bilevel Positional Encoding(BiPE). For each position, our BiPE blends an intra-segment encoding and aninter-segment encoding. The intra-segment encoding identifies the locationswithin a segment and helps the model capture the semantic information thereinvia absolute positional encoding. The inter-segment encoding specifies thesegment index, models the relationships between segments, and aims to improveextrapolation capabilities via relative positional encoding. Theoreticalanalysis shows this disentanglement of positional information makes learningmore effective. The empirical results also show that our BiPE has superiorlength extrapolation capabilities across a wide range of tasks in diverse textmodalities.</description><author>Zhenyu He, Guhao Feng, Shengjie Luo, Kai Yang, Di He, Jingjing Xu, Zhi Zhang, Hongxia Yang, Liwei Wang</author><pubDate>Mon, 29 Jan 2024 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16421v1</guid></item><item><title>InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model</title><link>http://arxiv.org/abs/2401.16420v1</link><description>We introduce InternLM-XComposer2, a cutting-edge vision-language modelexcelling in free-form text-image composition and comprehension. This modelgoes beyond conventional vision-language understanding, adeptly craftinginterleaved text-image content from diverse inputs like outlines, detailedtextual specifications, and reference images, enabling highly customizablecontent creation. InternLM-XComposer2 proposes a Partial LoRA (PLoRA) approachthat applies additional LoRA parameters exclusively to image tokens to preservethe integrity of pre-trained language knowledge, striking a balance betweenprecise vision understanding and text composition with literary talent.Experimental results demonstrate the superiority of InternLM-XComposer2 basedon InternLM2-7B in producing high-quality long-text multi-modal content and itsexceptional vision-language understanding performance across variousbenchmarks, where it not only significantly outperforms existing multimodalmodels but also matches or even surpasses GPT-4V and Gemini Pro in certainassessments. This highlights its remarkable proficiency in the realm ofmultimodal understanding. The InternLM-XComposer2 model series with 7Bparameters are publicly available athttps://github.com/InternLM/InternLM-XComposer.</description><author>Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, Linke Ouyang, Xilin Wei, Songyang Zhang, Haodong Duan, Maosong Cao, Wenwei Zhang, Yining Li, Hang Yan, Yang Gao, Xinyue Zhang, Wei Li, Jingwen Li, Kai Chen, Conghui He, Xingcheng Zhang, Yu Qiao, Dahua Lin, Jiaqi Wang</author><pubDate>Mon, 29 Jan 2024 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16420v1</guid></item><item><title>Semi-parametric Expert Bayesian Network Learning with Gaussian Processes and Horseshoe Priors</title><link>http://arxiv.org/abs/2401.16419v1</link><description>This paper proposes a model learning Semi-parametric rela- tionships in anExpert Bayesian Network (SEBN) with linear parameter and structure constraints.We use Gaussian Pro- cesses and a Horseshoe prior to introduce minimal nonlin-ear components. To prioritize modifying the expert graph over adding new edges,we optimize differential Horseshoe scales. In real-world datasets with unknowntruth, we gen- erate diverse graphs to accommodate user input, addressingidentifiability issues and enhancing interpretability. Evalua- tion onsynthetic and UCI Liver Disorders datasets, using metrics like structuralHamming Distance and test likelihood, demonstrates our models outperformstate-of-the-art semi- parametric Bayesian Network model.</description><author>Yidou Weng, Finale Doshi-Velez</author><pubDate>Mon, 29 Jan 2024 18:57:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16419v1</guid></item><item><title>Boolean Logic as an Error feedback mechanism</title><link>http://arxiv.org/abs/2401.16418v1</link><description>The notion of Boolean logic backpropagation was introduced to build neuralnetworks with weights and activations being Boolean numbers. Most ofcomputations can be done with Boolean logic instead of real arithmetic, bothduring training and inference phases. But the underlying discrete optimizationproblem is NP-hard, and the Boolean logic has no guarantee. In this work wepropose the first convergence analysis, under standard non-convex assumptions.</description><author>Louis Leconte</author><pubDate>Mon, 29 Jan 2024 18:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16418v1</guid></item><item><title>Evaluating explainability for machine learning predictions using model-agnostic metrics</title><link>http://arxiv.org/abs/2302.12094v2</link><description>Rapid advancements in artificial intelligence (AI) technology have broughtabout a plethora of new challenges in terms of governance and regulation. AIsystems are being integrated into various industries and sectors, creating ademand from decision-makers to possess a comprehensive and nuancedunderstanding of the capabilities and limitations of these systems. Onecritical aspect of this demand is the ability to explain the results of machinelearning models, which is crucial to promoting transparency and trust in AIsystems, as well as fundamental in helping machine learning models to betrained ethically. In this paper, we present novel metrics to quantify thedegree of which AI model predictions can be easily explainable by its features.Our metrics summarize different aspects of explainability into scalars,providing a more comprehensive understanding of model predictions andfacilitating communication between decision-makers and stakeholders, therebyincreasing the overall transparency and accountability of AI systems.</description><author>Cristian Munoz, Kleyton da Costa, Bernardo Modenesi, Adriano Koshiyama</author><pubDate>Mon, 29 Jan 2024 18:56:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.12094v2</guid></item><item><title>Endo-4DGS: Distilling Depth Ranking for Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting</title><link>http://arxiv.org/abs/2401.16416v1</link><description>In the realm of robot-assisted minimally invasive surgery, dynamic scenereconstruction can significantly enhance downstream tasks and improve surgicaloutcomes. Neural Radiance Fields (NeRF)-based methods have recently risen toprominence for their exceptional ability to reconstruct scenes. Nonetheless,these methods are hampered by slow inference, prolonged training, andsubstantial computational demands. Additionally, some rely on stereo depthestimation, which is often infeasible due to the high costs and logisticalchallenges associated with stereo cameras. Moreover, the monocularreconstruction quality for deformable scenes is currently inadequate. Toovercome these obstacles, we present Endo-4DGS, an innovative, real-timeendoscopic dynamic reconstruction approach that utilizes 4D Gaussian Splatting(GS) and requires no ground truth depth data. This method extends 3D GS byincorporating a temporal component and leverages a lightweight MLP to capturetemporal Gaussian deformations. This effectively facilitates the reconstructionof dynamic surgical scenes with variable conditions. We also integrateDepth-Anything to generate pseudo-depth maps from monocular views, enhancingthe depth-guided reconstruction process. Our approach has been validated on twosurgical datasets, where it has proven to render in real-time, computeefficiently, and reconstruct with remarkable accuracy. These results underlinethe vast potential of Endo-4DGS to improve surgical assistance.</description><author>Yiming Huang, Beilei Cui, Long Bai, Ziqi Guo, Mengya Xu, Hongliang Ren</author><pubDate>Mon, 29 Jan 2024 18:55:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16416v1</guid></item><item><title>The Power of Noise: Redefining Retrieval for RAG Systems</title><link>http://arxiv.org/abs/2401.14887v2</link><description>Retrieval-Augmented Generation (RAG) systems represent a significantadvancement over traditional Large Language Models (LLMs). RAG systems enhancetheir generation ability by incorporating external data retrieved through anInformation Retrieval (IR) phase, overcoming the limitations of standard LLMs,which are restricted to their pre-trained knowledge and limited context window.Most research in this area has predominantly concentrated on the generativeaspect of LLMs within RAG systems. Our study fills this gap by thoroughly andcritically analyzing the influence of IR components on RAG systems. This paperanalyzes which characteristics a retriever should possess for an effectiveRAG's prompt formulation, focusing on the type of documents that should beretrieved. We evaluate various elements, such as the relevance of the documentsto the prompt, their position, and the number included in the context. Ourfindings reveal, among other insights, that including irrelevant documents canunexpectedly enhance performance by more than 30% in accuracy, contradictingour initial assumption of diminished quality. These results underscore the needfor developing specialized strategies to integrate retrieval with languagegeneration models, thereby laying the groundwork for future research in thisfield.</description><author>Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, Fabrizio Silvestri</author><pubDate>Mon, 29 Jan 2024 18:52:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14887v2</guid></item><item><title>Scaling NVIDIA's Multi-speaker Multi-lingual TTS Systems with Zero-Shot TTS to Indic Languages</title><link>http://arxiv.org/abs/2401.13851v2</link><description>In this paper, we describe the TTS models developed by NVIDIA for theMMITS-VC (Multi-speaker, Multi-lingual Indic TTS with Voice Cloning) 2024Challenge. In Tracks 1 and 2, we utilize RAD-MMM to perform few-shot TTS bytraining additionally on 5 minutes of target speaker data. In Track 3, weutilize P-Flow to perform zero-shot TTS by training on the challenge dataset aswell as external datasets. We use HiFi-GAN vocoders for all submissions.RAD-MMM performs competitively on Tracks 1 and 2, while P-Flow ranks first onTrack 3, with mean opinion score (MOS) 4.4 and speaker similarity score (SMOS)of 3.62.</description><author>Akshit Arora, Rohan Badlani, Sungwon Kim, Rafael Valle, Bryan Catanzaro</author><pubDate>Mon, 29 Jan 2024 18:51:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13851v2</guid></item><item><title>Learning to Manipulate under Limited Information</title><link>http://arxiv.org/abs/2401.16412v1</link><description>By classic results in social choice theory, any reasonable preferentialvoting method sometimes gives individuals an incentive to report an insincerepreference. The extent to which different voting methods are more or lessresistant to such strategic manipulation has become a key consideration forcomparing voting methods. Here we measure resistance to manipulation by whetherneural networks of varying sizes can learn to profitably manipulate a givenvoting method in expectation, given different types of limited informationabout how other voters will vote. We trained nearly 40,000 neural networks of26 sizes to manipulate against 8 different voting methods, under 6 types oflimited information, in committee-sized elections with 5-21 voters and 3-6candidates. We find that some voting methods, such as Borda, are highlymanipulable by networks with limited information, while others, such as InstantRunoff, are not, despite being quite profitably manipulated by an idealmanipulator with full information.</description><author>Wesley H. Holliday, Alexander Kristoffersen, Eric Pacuit</author><pubDate>Mon, 29 Jan 2024 18:49:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16412v1</guid></item><item><title>ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift</title><link>http://arxiv.org/abs/2401.16410v1</link><description>The presence of distribution shifts poses a significant challenge fordeploying modern machine learning models in real-world applications. This workfocuses on the target shift problem in a regression setting (Zhang et al.,2013; Nguyen et al., 2016). More specifically, the target variable y (alsoknown as the response variable), which is continuous, has different marginaldistributions in the training source and testing domain, while the conditionaldistribution of features x given y remains the same. While most literaturefocuses on classification tasks with finite target space, the regressionproblem has an infinite dimensional target space, which makes many of theexisting methods inapplicable. In this work, we show that the continuous targetshift problem can be addressed by estimating the importance weight functionfrom an ill-posed integral equation. We propose a nonparametric regularizedapproach named ReTaSA to solve the ill-posed integral equation and providetheoretical justification for the estimated importance weight function. Theeffectiveness of the proposed method has been demonstrated with extensivenumerical studies on synthetic and real-world datasets.</description><author>Hwanwoo Kim, Xin Zhang, Jiwei Zhao, Qinglong Tian</author><pubDate>Mon, 29 Jan 2024 18:47:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16410v1</guid></item><item><title>Is K-fold cross validation the best model selection method for Machine Learning?</title><link>http://arxiv.org/abs/2401.16407v1</link><description>As a technique that can compactly represent complex patterns, machinelearning has significant potential for predictive inference. K-foldcross-validation (CV) is the most common approach to ascertaining thelikelihood that a machine learning outcome is generated by chance andfrequently outperforms conventional hypothesis testing. This improvement usesmeasures directly obtained from machine learning classifications, such asaccuracy, that do not have a parametric description. To approach a frequentistanalysis within machine learning pipelines, a permutation test or simplestatistics from data partitions (i.e. folds) can be added to estimateconfidence intervals. Unfortunately, neither parametric nor non-parametrictests solve the inherent problems around partitioning small sample-sizedatasets and learning from heterogeneous data sources. The fact that machinelearning strongly depends on the learning parameters and the distribution ofdata across folds recapitulates familiar difficulties around excess falsepositives and replication. The origins of this problem are demonstrated bysimulating common experimental circumstances, including small sample sizes, lownumbers of predictors, and heterogeneous data sources. A novel statistical testbased on K-fold CV and the Upper Bound of the actual error (K-fold CUBV) iscomposed, where uncertain predictions of machine learning with CV are boundedby the \emph{worst case} through the evaluation of concentration inequalities.Probably Approximately Correct-Bayesian upper bounds for linear classifiers incombination with K-fold CV is used to estimate the empirical error. Theperformance with neuroimaging datasets suggests this is a robust criterion fordetecting effects, validating accuracy values obtained from machine learningwhilst avoiding excess false positives.</description><author>Juan M Gorriz, F Segovia, J Ramirez, A Ortiz, J. Suckling</author><pubDate>Mon, 29 Jan 2024 18:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16407v1</guid></item><item><title>Scaling Sparse Fine-Tuning to Large Language Models</title><link>http://arxiv.org/abs/2401.16405v1</link><description>Large Language Models (LLMs) are difficult to fully fine-tune (e.g., withinstructions or human feedback) due to their sheer number of parameters. Afamily of parameter-efficient sparse fine-tuning (SFT) methods have provenpromising in terms of performance but their memory requirements increaseproportionally to the size of the LLMs. In this work, we scale sparsefine-tuning to state-of-the-art LLMs like LLaMA 2 7B and 13B. At any giventime, for a desired density level, we maintain an array of parameter indicesand the deltas of these parameters relative to their pretrained values. Weiterate among: (a) updating the active deltas, (b) pruning indices (based onthe change of magnitude of their deltas) and (c) regrowth of indices. Forregrowth, we explore two criteria based on either the accumulated gradients ofa few candidate parameters or their approximate momenta estimated using theefficient SM3 optimizer. We experiment with instruction-tuning of LLMs onstandard dataset mixtures, finding that SFT is often superior to popularparameter-efficient fine-tuning methods like LoRA (low-rank adaptation) interms of performance and comparable in terms of run time. We additionally showthat SFT is compatible with both quantization and efficient optimizers, tofacilitate scaling to ever-larger model sizes. We release the code for SFT athttps://github.com/AlanAnsell/peft and for the instruction-tuning experimentsat https://github.com/ducdauge/sft-llm.</description><author>Alan Ansell, Ivan Vulić, Hannah Sterz, Anna Korhonen, Edoardo M. Ponti</author><pubDate>Mon, 29 Jan 2024 18:43:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16405v1</guid></item><item><title>ViLexNorm: A Lexical Normalization Corpus for Vietnamese Social Media Text</title><link>http://arxiv.org/abs/2401.16403v1</link><description>Lexical normalization, a fundamental task in Natural Language Processing(NLP), involves the transformation of words into their canonical forms. Thisprocess has been proven to benefit various downstream NLP tasks greatly. Inthis work, we introduce Vietnamese Lexical Normalization (ViLexNorm), thefirst-ever corpus developed for the Vietnamese lexical normalization task. Thecorpus comprises over 10,000 pairs of sentences meticulously annotated by humanannotators, sourced from public comments on Vietnam's most popular social mediaplatforms. Various methods were used to evaluate our corpus, and thebest-performing system achieved a result of 57.74% using the Error ReductionRate (ERR) metric (van der Goot, 2019a) with the Leave-As-Is (LAI) baseline.For extrinsic evaluation, employing the model trained on ViLexNorm demonstratesthe positive impact of the Vietnamese lexical normalization task on other NLPtasks. Our corpus is publicly available exclusively for research purposes.</description><author>Thanh-Nhi Nguyen, Thanh-Phong Le, Kiet Van Nguyen</author><pubDate>Mon, 29 Jan 2024 18:41:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16403v1</guid></item><item><title>A Survey on Visual Anomaly Detection: Challenge, Approach, and Prospect</title><link>http://arxiv.org/abs/2401.16402v1</link><description>Visual Anomaly Detection (VAD) endeavors to pinpoint deviations from theconcept of normality in visual data, widely applied across diverse domains,e.g., industrial defect inspection, and medical lesion detection. This surveycomprehensively examines recent advancements in VAD by identifying threeprimary challenges: 1) scarcity of training data, 2) diversity of visualmodalities, and 3) complexity of hierarchical anomalies. Starting with a briefoverview of the VAD background and its generic concept definitions, weprogressively categorize, emphasize, and discuss the latest VAD progress fromthe perspective of sample number, data modality, and anomaly hierarchy. Throughan in-depth analysis of the VAD field, we finally summarize future developmentsfor VAD and conclude the key findings and contributions of this survey.</description><author>Yunkang Cao, Xiaohao Xu, Jiangning Zhang, Yuqi Cheng, Xiaonan Huang, Guansong Pang, Weiming Shen</author><pubDate>Mon, 29 Jan 2024 18:41:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16402v1</guid></item><item><title>Zero-shot Imitation Policy via Search in Demonstration Dataset</title><link>http://arxiv.org/abs/2401.16398v1</link><description>Behavioral cloning uses a dataset of demonstrations to learn a policy. Toovercome computationally expensive training procedures and address the policyadaptation problem, we propose to use latent spaces of pre-trained foundationmodels to index a demonstration dataset, instantly access similar relevantexperiences, and copy behavior from these situations. Actions from a selectedsimilar situation can be performed by the agent until representations of theagent's current situation and the selected experience diverge in the latentspace. Thus, we formulate our control problem as a dynamic search problem overa dataset of experts' demonstrations. We test our approach on BASALTMineRL-dataset in the latent representation of a Video Pre-Training model. Wecompare our model to state-of-the-art, Imitation Learning-based Minecraftagents. Our approach can effectively recover meaningful demonstrations and showhuman-like behavior of an agent in the Minecraft environment in a wide varietyof scenarios. Experimental results reveal that performance of our search-basedapproach clearly wins in terms of accuracy and perceptual evaluation overlearning-based models.</description><author>Federco Malato, Florian Leopold, Andrew Melnik, Ville Hautamaki</author><pubDate>Mon, 29 Jan 2024 18:38:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16398v1</guid></item><item><title>Learning logic programs by discovering higher-order abstractions</title><link>http://arxiv.org/abs/2308.08334v2</link><description>We introduce the higher-order refactoring problem, where the goal is tocompress a logic program by discovering higher-order abstractions, such as map,filter, and fold. We implement our approach in Stevie, which formulates therefactoring problem as a constraint optimisation problem. Our experiments onmultiple domains, including program synthesis and visual reasoning, show thatrefactoring can improve the learning performance of an inductive logicprogramming system, specifically improving predictive accuracies by 27% andreducing learning times by 47%. We also show that Stevie can discoverabstractions that transfer to multiple domains.</description><author>Céline Hocquette, Sebastijan Dumančić, Andrew Cropper</author><pubDate>Mon, 29 Jan 2024 18:34:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.08334v2</guid></item><item><title>Amazon's 2023 Drought: Sentinel-1 Reveals Extreme Rio Negro River Contraction</title><link>http://arxiv.org/abs/2401.16393v1</link><description>The Amazon, the world's largest rainforest, faces a severe historic drought.The Rio Negro River, one of the major Amazon River tributaries, reaches itslowest level in a century in October 2023. Here, we used a U-net deep learningmodel to map water surfaces in the Rio Negro River basin every 12 days in 2022and 2023 using 10 m spatial resolution Sentinel-1 satellite radar images. Theaccuracy of the water surface model was high with an F1-score of 0.93. The 12days mosaic time series of water surface was generated from the Sentinel-1prediction. The water surface mask demonstrated relatively consistent agreementwith the Global Surface Water (GSW) product from Joint Research Centre(F1-score: 0.708) and with the Brazilian Mapbiomas Water initiative (F1-score:0.686). The main errors of the map were omission errors in flooded woodland, inflooded shrub and because of clouds. Rio Negro water surfaces reached theirlowest level around the 25th of November 2023 and were reduced to 68.1\%(9,559.9 km$^2$) of the maximum water surfaces observed in the period 2022-2023(14,036.3 km$^2$). Synthetic Aperture Radar (SAR) data, in conjunction withdeep learning techniques, can significantly improve near real-time mapping ofwater surface in tropical regions.</description><author>Fabien H Wagner, Samuel Favrichon, Ricardo Dalagnol, Mayumi CM Hirye, Adugna Mullissa, Sassan Saatchi</author><pubDate>Mon, 29 Jan 2024 18:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16393v1</guid></item><item><title>Continual Learning with Pre-Trained Models: A Survey</title><link>http://arxiv.org/abs/2401.16386v1</link><description>Nowadays, real-world applications often face streaming data, which requiresthe learning system to absorb new knowledge as data evolves. Continual Learning(CL) aims to achieve this goal and meanwhile overcome the catastrophicforgetting of former knowledge when learning new ones. Typical CL methods buildthe model from scratch to grow with incoming data. However, the advent of thepre-trained model (PTM) era has sparked immense research interest, particularlyin leveraging PTMs' robust representational capabilities. This paper presents acomprehensive survey of the latest advancements in PTM-based CL. We categorizeexisting methodologies into three distinct groups, providing a comparativeanalysis of their similarities, differences, and respective advantages anddisadvantages. Additionally, we offer an empirical study contrasting variousstate-of-the-art methods to highlight concerns regarding fairness incomparisons. The source code to reproduce these evaluations is available at:https://github.com/sun-hailong/LAMDA-PILOT</description><author>Da-Wei Zhou, Hai-Long Sun, Jingyi Ning, Han-Jia Ye, De-Chuan Zhan</author><pubDate>Mon, 29 Jan 2024 18:27:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16386v1</guid></item><item><title>Learning logic programs by finding minimal unsatisfiable subprograms</title><link>http://arxiv.org/abs/2401.16383v1</link><description>The goal of inductive logic programming (ILP) is to search for a logicprogram that generalises training examples and background knowledge. Weintroduce an ILP approach that identifies minimal unsatisfiable subprograms(MUSPs). We show that finding MUSPs allows us to efficiently and soundly prunethe search space. Our experiments on multiple domains, including programsynthesis and game playing, show that our approach can reduce learning times by99%.</description><author>Andrew Cropper, Céline Hocquette</author><pubDate>Mon, 29 Jan 2024 18:24:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16383v1</guid></item><item><title>Flexible Communication for Optimal Distributed Learning over Unpredictable Networks</title><link>http://arxiv.org/abs/2312.02493v2</link><description>Gradient compression alleviates expensive communication in distributed deeplearning by sending fewer values and its corresponding indices, typically viaAllgather (AG). Training with high compression ratio (CR) achieves highaccuracy like DenseSGD, but has lower parallel scaling due to highcommunication cost (i.e., parallel efficiency). Using lower CRs improvesparallel efficiency by lowering synchronization cost, but degrades modelaccuracy as well (statistical efficiency). Further, speedup attained withdifferent models and CRs also varies with network latency, effective bandwidthand collective op used for aggregation. In many cases, collectives likeAllreduce (AR) have lower cost than AG to exchange the same amount of data. Inthis paper, we propose an AR-compatible Topk compressor that isbandwidth-optimal and thus performs better than AG in certain networkconfigurations. We develop a flexible communication strategy that switchesbetween AG and AR based on which collective is optimal in the current settings,and model the pareto-relationship between parallel and statistical efficiencyas a multi-objective optimization (MOO) problem to dynamically adjust CR andaccelerate training while still converging to high accuracy.</description><author>Sahil Tyagi, Martin Swany</author><pubDate>Mon, 29 Jan 2024 18:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02493v2</guid></item><item><title>Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling</title><link>http://arxiv.org/abs/2401.16380v1</link><description>Large language models are trained on massive scrapes of the web, which areoften unstructured, noisy, and poorly phrased. Current scaling laws show thatlearning from such data requires an abundance of both compute and data, whichgrows with the size of the model being trained. This is infeasible both becauseof the large compute costs and duration associated with pre-training, and theimpending scarcity of high-quality data on the web. In this work, we proposeWeb Rephrase Augmented Pre-training ($\textbf{WRAP}$) that uses anoff-the-shelf instruction-tuned model prompted to paraphrase documents on theweb in specific styles such as "like Wikipedia" or in "question-answer format"to jointly pre-train LLMs on real and synthetic rephrases. First, we show thatusing WRAP on the C4 dataset, which is naturally noisy, speeds up pre-trainingby $\sim3x$. At the same pre-training compute budget, it improves perplexity bymore than 10% on average across different subsets of the Pile, and improveszero-shot question answer accuracy across 13 tasks by more than 2%. Second, weinvestigate the impact of the re-phrasing style on the performance of themodel, offering insights into how the composition of the training data canimpact the performance of LLMs in OOD settings. Our gains are attributed to thefact that re-phrased synthetic data has higher utility than just real databecause it (i) incorporates style diversity that closely reflects downstreamevaluation style, and (ii) has higher 'quality' than web-scraped data.</description><author>Pratyush Maini, Skyler Seto, He Bai, David Grangier, Yizhe Zhang, Navdeep Jaitly</author><pubDate>Mon, 29 Jan 2024 18:19:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16380v1</guid></item><item><title>Accelerating Distributed ML Training via Selective Synchronization</title><link>http://arxiv.org/abs/2307.07950v2</link><description>In distributed training, deep neural networks (DNNs) are launched overmultiple workers concurrently and aggregate their local updates on each step inbulk-synchronous parallel (BSP) training. However, BSP does not linearlyscale-out due to high communication cost of aggregation. To mitigate thisoverhead, alternatives like Federated Averaging (FedAvg) and Stale-SynchronousParallel (SSP) either reduce synchronization frequency or eliminate italtogether, usually at the cost of lower final accuracy. In this paper, wepresent \texttt{SelSync}, a practical, low-overhead method for DNN trainingthat dynamically chooses to incur or avoid communication at each step either bycalling the aggregation op or applying local updates based on theirsignificance. We propose various optimizations as part of \texttt{SelSync} toimprove convergence in the context of \textit{semi-synchronous} training. Oursystem converges to the same or better accuracy than BSP while reducingtraining time by up to 14$\times$.</description><author>Sahil Tyagi, Martin Swany</author><pubDate>Mon, 29 Jan 2024 18:18:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07950v2</guid></item><item><title>GraVAC: Adaptive Compression for Communication-Efficient Distributed DL Training</title><link>http://arxiv.org/abs/2305.12201v2</link><description>Distributed data-parallel (DDP) training improves overall applicationthroughput as multiple devices train on a subset of data and aggregate updatesto produce a globally shared model. The periodic synchronization at eachiteration incurs considerable overhead, exacerbated by the increasing size andcomplexity of state-of-the-art neural networks. Although many gradientcompression techniques propose to reduce communication cost, the idealcompression factor that leads to maximum speedup or minimum data exchangeremains an open-ended problem since it varies with the quality of compression,model size and structure, hardware, network topology and bandwidth. We proposeGraVAC, a framework to dynamically adjust compression factor throughouttraining by evaluating model progress and assessing gradient information lossassociated with compression. GraVAC works in an online, black-box mannerwithout any prior assumptions about a model or its hyperparameters, whileachieving the same or better accuracy than dense SGD (i.e., no compression) inthe same number of iterations/epochs. As opposed to using a static compressionfactor, GraVAC reduces end-to-end training time for ResNet101, VGG16 and LSTMby 4.32x, 1.95x and 6.67x respectively. Compared to other adaptive schemes, ourframework provides 1.94x to 5.63x overall speedup.</description><author>Sahil Tyagi, Martin Swany</author><pubDate>Mon, 29 Jan 2024 18:15:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12201v2</guid></item><item><title>Spot the Error: Non-autoregressive Graphic Layout Generation with Wireframe Locator</title><link>http://arxiv.org/abs/2401.16375v1</link><description>Layout generation is a critical step in graphic design to achieve meaningfulcompositions of elements. Most previous works view it as a sequence generationproblem by concatenating element attribute tokens (i.e., category, size,position). So far the autoregressive approach (AR) has achieved promisingresults, but is still limited in global context modeling and suffers from errorpropagation since it can only attend to the previously generated tokens. Recentnon-autoregressive attempts (NAR) have shown competitive results, whichprovides a wider context range and the flexibility to refine with iterativedecoding. However, current works only use simple heuristics to recognizeerroneous tokens for refinement which is inaccurate. This paper first conductsan in-depth analysis to better understand the difference between the AR and NARframework. Furthermore, based on our observation that pixel space is moresensitive in capturing spatial patterns of graphic layouts (e.g., overlap,alignment), we propose a learning-based locator to detect erroneous tokenswhich takes the wireframe image rendered from the generated layout sequence asinput. We show that it serves as a complementary modality to the elementsequence in object space and contributes greatly to the overall performance.Experiments on two public datasets show that our approach outperforms both ARand NAR baselines. Extensive studies further prove the effectiveness ofdifferent modules with interesting findings. Our code will be available athttps://github.com/ffffatgoose/SpotError.</description><author>Jieru Lin, Danqing Huang, Tiejun Zhao, Dechen Zhan, Chin-Yew Lin</author><pubDate>Mon, 29 Jan 2024 18:13:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16375v1</guid></item><item><title>Bayesian optimization as a flexible and efficient design framework for sustainable process systems</title><link>http://arxiv.org/abs/2401.16373v1</link><description>Bayesian optimization (BO) is a powerful technology for optimizing noisyexpensive-to-evaluate black-box functions, with a broad range of real-worldapplications in science, engineering, economics, manufacturing, and beyond. Inthis paper, we provide an overview of recent developments, challenges, andopportunities in BO for design of next-generation process systems. Afterdescribing several motivating applications, we discuss how advanced BO methodshave been developed to more efficiently tackle important problems in theseapplications. We conclude the paper with a summary of challenges andopportunities related to improving the quality of the probabilistic model, thechoice of internal optimization procedure used to select the next sample point,and the exploitation of problem structure to improve sample efficiency.</description><author>Joel A. Paulson, Calvin Tsay</author><pubDate>Mon, 29 Jan 2024 18:12:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16373v1</guid></item><item><title>ScaDLES: Scalable Deep Learning over Streaming data at the Edge</title><link>http://arxiv.org/abs/2301.08897v2</link><description>Distributed deep learning (DDL) training systems are designed for cloud anddata-center environments that assumes homogeneous compute resources, highnetwork bandwidth, sufficient memory and storage, as well as independent andidentically distributed (IID) data across all nodes. However, these assumptionsdon't necessarily apply on the edge, especially when training neural networkson streaming data in an online manner. Computing on the edge suffers from bothsystems and statistical heterogeneity. Systems heterogeneity is attributed todifferences in compute resources and bandwidth specific to each device, whilestatistical heterogeneity comes from unbalanced and skewed data on the edge.Different streaming-rates among devices can be another source of heterogeneitywhen dealing with streaming data. If the streaming rate is lower than trainingbatch-size, device needs to wait until enough samples have streamed in beforeperforming a single iteration of stochastic gradient descent (SGD). Thus,low-volume streams act like stragglers slowing down devices with high-volumestreams in synchronous training. On the other hand, data can accumulate quicklyin the buffer if the streaming rate is too high and the devices can't train atline-rate. In this paper, we introduce ScaDLES to efficiently train onstreaming data at the edge in an online fashion, while also addressing thechallenges of limited bandwidth and training with non-IID data. We empiricallyshow that ScaDLES converges up to 3.29 times faster compared to conventionaldistributed SGD.</description><author>Sahil Tyagi, Martin Swany</author><pubDate>Mon, 29 Jan 2024 18:10:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08897v2</guid></item><item><title>TQCompressor: improving tensor decomposition methods in neural networks via permutations</title><link>http://arxiv.org/abs/2401.16367v1</link><description>We introduce TQCompressor, a novel method for neural network modelcompression with improved tensor decompositions. We explore the challengesposed by the computational and storage demands of pre-trained language modelsin NLP tasks and propose a permutation-based enhancement to Kroneckerdecomposition. This enhancement makes it possible to reduce loss in modelexpressivity which is usually associated with factorization. We demonstratethis method applied to the GPT-2$_{small}$. The result of the compression isTQCompressedGPT-2 model, featuring 81 mln. parameters compared to 124 mln. inthe GPT-2$_{small}$. We make TQCompressedGPT-2 publicly available. We furtherenhance the performance of the TQCompressedGPT-2 through a training strategyinvolving multi-step knowledge distillation, using only a 3.1% of theOpenWebText. TQCompressedGPT-2 surpasses DistilGPT-2 and KnGPT-2 in comparativeevaluations, marking an advancement in the efficient and effective deploymentof models in resource-constrained environments.</description><author>V. Abronin, A. Naumov, D. Mazur, D. Bystrov, K. Tsarova, Ar. Melnikov, I. Oseledets, S. Dolgov, R. Brasher, M. Perelshtein</author><pubDate>Mon, 29 Jan 2024 18:07:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16367v1</guid></item><item><title>Evaluation of pseudo-healthy image reconstruction for anomaly detection with deep generative models: Application to brain FDG PET</title><link>http://arxiv.org/abs/2401.16363v1</link><description>Over the past years, pseudo-healthy reconstruction for unsupervised anomalydetection has gained in popularity. This approach has the great advantage ofnot requiring tedious pixel-wise data annotation and offers possibility togeneralize to any kind of anomalies, including that corresponding to rarediseases. By training a deep generative model with only images from healthysubjects, the model will learn to reconstruct pseudo-healthy images. Thispseudo-healthy reconstruction is then compared to the input to detect andlocalize anomalies. The evaluation of such methods often relies on a groundtruth lesion mask that is available for test data, which may not existdepending on the application. We propose an evaluation procedure based on the simulation of realisticabnormal images to validate pseudo-healthy reconstruction methods when noground truth is available. This allows us to extensively test generative modelson different kinds of anomalies and measuring their performance using the pairof normal and abnormal images corresponding to the same subject. It can be usedas a preliminary automatic step to validate the capacity of a generative modelto reconstruct pseudo-healthy images, before a more advanced validation stepthat would require clinician's expertise. We apply this framework to thereconstruction of 3D brain FDG PET using a convolutional variationalautoencoder with the aim to detect as early as possible the neurodegenerationmarkers that are specific to dementia such as Alzheimer's disease.</description><author>Ravi Hassanaly, Camille Brianceau, Maëlys Solal, Olivier Colliot, Ninon Burgos</author><pubDate>Mon, 29 Jan 2024 18:02:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16363v1</guid></item><item><title>Learning the meanings of function words from grounded language using a visual question answering model</title><link>http://arxiv.org/abs/2308.08628v2</link><description>Interpreting a seemingly-simple function word like "or", "behind", or "more"can require logical, numerical, and relational reasoning. How are such wordslearned by children? Prior acquisition theories have often relied on positing afoundation of innate knowledge. Yet recent neural-network based visual questionanswering models apparently can learn to use function words as part ofanswering questions about complex visual scenes. In this paper, we study whatthese models learn about function words, in the hope of better understandinghow the meanings of these words can be learnt by both models and children. Weshow that recurrent models trained on visually grounded language learn gradientsemantics for function words requiring spacial and numerical reasoning.Furthermore, we find that these models can learn the meanings of logicalconnectives "and" and "or" without any prior knowledge of logical reasoning, aswell as early evidence that they are sensitive to alternative expressions wheninterpreting language. Finally, we show that word learning difficulty isdependent on frequency in models' input. Our findings offer proof-of-conceptevidence that it is possible to learn the nuanced interpretations of functionwords in visually grounded context by using non-symbolic general statisticallearning algorithms, without any prior knowledge of linguistic meaning.</description><author>Eva Portelance, Michael C. Frank, Dan Jurafsky</author><pubDate>Mon, 29 Jan 2024 18:00:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.08628v2</guid></item><item><title>Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization</title><link>http://arxiv.org/abs/2311.09335v2</link><description>Despite the remarkable performance of generative large language models (LLMs)on abstractive summarization, they face two significant challenges: theirconsiderable size and tendency to hallucinate. Hallucinations are concerningbecause they erode reliability and raise safety issues. Pruning is a techniquethat reduces model size by removing redundant weights, enabling more efficientsparse inference. Pruned models yield downstream task performance comparable tothe original, making them ideal alternatives when operating on a limitedbudget. However, the effect that pruning has upon hallucinations in abstractivesummarization with LLMs has yet to be explored. In this paper, we provide anextensive empirical study across five summarization datasets, twostate-of-the-art pruning methods, and five instruction-tuned LLMs.Surprisingly, we find that hallucinations from pruned LLMs are less prevalentthan the original models. Our analysis suggests that pruned models tend todepend more on the source document for summary generation. This leads to ahigher lexical overlap between the generated summary and the source document,which could be a reason for the reduction in hallucination risk.</description><author>George Chrysostomou, Zhixue Zhao, Miles Williams, Nikolaos Aletras</author><pubDate>Mon, 29 Jan 2024 17:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09335v2</guid></item><item><title>cDVGAN: One Flexible Model for Multi-class Gravitational Wave Signal and Glitch Generation</title><link>http://arxiv.org/abs/2401.16356v1</link><description>Simulating realistic time-domain observations of gravitational waves (GWs)and GW detector glitches can help in advancing GW data analysis. Simulated datacan be used in downstream tasks by augmenting datasets for signal searches,balancing data sets for machine learning, and validating detection schemes. Inthis work, we present Conditional Derivative GAN (cDVGAN), a novel conditionalmodel in the Generative Adversarial Network framework for simulating multipleclasses of time-domain observations that represent gravitational waves (GWs)and detector glitches. cDVGAN can also generate generalized hybrid samples thatspan the variation between classes through interpolation in the conditionedclass vector. cDVGAN introduces an additional player into the typical 2-playeradversarial game of GANs, where an auxiliary discriminator analyzes thefirst-order derivative time-series. Our results show that this providessynthetic data that better captures the features of the original data. cDVGANconditions on three classes, two denoised from LIGO blip and tomte glitchevents from its 3rd observing run (O3), and the third representing binary blackhole (BBH) mergers. Our proposed cDVGAN outperforms 4 different baseline GANmodels in replicating the features of the three classes. Specifically, ourexperiments show that training convolutional neural networks (CNNs) with ourcDVGAN-generated data improves the detection of samples embedded in detectornoise beyond the synthetic data from other state-of-the-art GAN models. Ourbest synthetic dataset yields as much as a 4.2% increase inarea-under-the-curve (AUC) performance compared to synthetic datasets frombaseline GANs. Moreover, training the CNN with hybrid samples from our cDVGANoutperforms CNNs trained only on the standard classes, when identifying realsamples embedded in LIGO detector background (4% AUC improvement for cDVGAN).</description><author>Tom Dooney, Lyana Curier, Daniel Tan, Melissa Lopez, Chris Van Den Broeck, Stefano Bromuri</author><pubDate>Mon, 29 Jan 2024 17:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16356v1</guid></item><item><title>PathMMU: A Massive Multimodal Expert-Level Benchmark for Understanding and Reasoning in Pathology</title><link>http://arxiv.org/abs/2401.16355v1</link><description>The emergence of large multimodal models has unlocked remarkable potential inAI, particularly in pathology. However, the lack of specialized, high-qualitybenchmark impeded their development and precise evaluation. To address this, weintroduce PathMMU, the largest and highest-quality expert-validated pathologybenchmark for LMMs. It comprises 33,573 multimodal multi-choice questions and21,599 images from various sources, and an explanation for the correct answeraccompanies each question. The construction of PathMMU capitalizes on therobust capabilities of GPT-4V, utilizing approximately 30,000 gatheredimage-caption pairs to generate Q\&amp;As. Significantly, to maximize PathMMU'sauthority, we invite six pathologists to scrutinize each question under strictstandards in PathMMU's validation and test sets, while simultaneously settingan expert-level performance benchmark for PathMMU. We conduct extensiveevaluations, including zero-shot assessments of 14 open-sourced and threeclosed-sourced LMMs and their robustness to image corruption. We also fine-tunerepresentative LMMs to assess their adaptability to PathMMU. The empiricalfindings indicate that advanced LMMs struggle with the challenging PathMMUbenchmark, with the top-performing LMM, GPT-4V, achieving only a 51.7\%zero-shot performance, significantly lower than the 71.4\% demonstrated byhuman pathologists. After fine-tuning, even open-sourced LMMs can surpassGPT-4V with a performance of over 60\%, but still fall short of the expertiseshown by pathologists. We hope that the PathMMU will offer valuable insightsand foster the development of more specialized, next-generation LLMs forpathology.</description><author>Yuxuan Sun, Hao Wu, Chenglu Zhu, Sunyi Zheng, Qizi Chen, Kai Zhang, Yunlong Zhang, Xiaoxiao Lan, Mengyue Zheng, Jingxiong Li, Xinheng Lyu, Tao Lin, Lin Yang</author><pubDate>Mon, 29 Jan 2024 17:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16355v1</guid></item><item><title>Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization</title><link>http://arxiv.org/abs/2401.16352v1</link><description>The deep neural networks are known to be vulnerable to well-designedadversarial attacks. The most successful defense technique based on adversarialtraining (AT) can achieve optimal robustness against particular attacks butcannot generalize well to unseen attacks. Another effective defense techniquebased on adversarial purification (AP) can enhance generalization but cannotachieve optimal robustness. Meanwhile, both methods share one common limitationon the degraded standard accuracy. To mitigate these issues, we propose a novelframework called Adversarial Training on Purification (AToP), which comprisestwo components: perturbation destruction by random transforms (RT) and purifiermodel fine-tuned (FT) by adversarial loss. RT is essential to avoidoverlearning to known attacks resulting in the robustness generalization tounseen attacks and FT is essential for the improvement of robustness. Toevaluate our method in an efficient and scalable way, we conduct extensiveexperiments on CIFAR-10, CIFAR-100, and ImageNette to demonstrate that ourmethod achieves state-of-the-art results and exhibits generalization abilityagainst unseen attacks.</description><author>Guang Lin, Chao Li, Jianhai Zhang, Toshihisa Tanaka, Qibin Zhao</author><pubDate>Mon, 29 Jan 2024 17:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16352v1</guid></item><item><title>FedFair^3: Unlocking Threefold Fairness in Federated Learning</title><link>http://arxiv.org/abs/2401.16350v1</link><description>Federated Learning (FL) is an emerging paradigm in machine learning withoutexposing clients' raw data. In practical scenarios with numerous clients,encouraging fair and efficient client participation in federated learning is ofutmost importance, which is also challenging given the heterogeneity in datadistribution and device properties. Existing works have proposed differentclient-selection methods that consider fairness; however, they fail to selectclients with high utilities while simultaneously achieving fair accuracylevels. In this paper, we propose a fair client-selection approach that unlocksthreefold fairness in federated learning. In addition to having a fairclient-selection strategy, we enforce an equitable number of rounds for clientparticipation and ensure a fair accuracy distribution over the clients. Theexperimental results demonstrate that FedFair^3, in comparison to thestate-of-the-art baselines, achieves 18.15% less accuracy variance on the IIDdata and 54.78% on the non-IID data, without decreasing the global accuracy.Furthermore, it shows 24.36% less wall-clock training time on average.</description><author>Simin Javaherian, Sanjeev Panta, Shelby Williams, Md Sirajul Islam, Li Chen</author><pubDate>Mon, 29 Jan 2024 17:56:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16350v1</guid></item><item><title>TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients</title><link>http://arxiv.org/abs/2401.12012v3</link><description>Federated learning is a distributed collaborative machine learning paradigmthat has gained strong momentum in recent years. In federated learning, acentral server periodically coordinates models with clients and aggregates themodels trained locally by clients without necessitating access to local data.Despite its potential, the implementation of federated learning continues toencounter several challenges, predominantly the slow convergence that islargely due to data heterogeneity. The slow convergence becomes particularlyproblematic in cross-device federated learning scenarios where clients may bestrongly limited by computing power and storage space, and hence counteractingmethods that induce additional computation or memory cost on the client sidesuch as auxiliary objective terms and larger training iterations can beimpractical. In this paper, we propose a novel federated aggregation strategy,TurboSVM-FL, that poses no additional computation burden on the client side andcan significantly accelerate convergence for federated classification task,especially when clients are "lazy" and train their models solely for few epochsfor next global aggregation. TurboSVM-FL extensively utilizes support vectormachine to conduct selective aggregation and max-margin spread-outregularization on class embeddings. We evaluate TurboSVM-FL on multipledatasets including FEMNIST, CelebA, and Shakespeare using user-independentvalidation with non-iid data distribution. Our results show that TurboSVM-FLcan significantly outperform existing popular algorithms on convergence rateand reduce communication rounds while delivering better test metrics includingaccuracy, F1 score, and MCC.</description><author>Mengdi Wang, Anna Bodonhelyi, Efe Bozkir, Enkelejda Kasneci</author><pubDate>Mon, 29 Jan 2024 17:55:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12012v3</guid></item><item><title>ConFit: Improving Resume-Job Matching using Data Augmentation and Contrastive Learning</title><link>http://arxiv.org/abs/2401.16349v1</link><description>A reliable resume-job matching system helps a company find suitablecandidates from a pool of resumes, and helps a job seeker find relevant jobsfrom a list of job posts. However, since job seekers apply only to a few jobs,interaction records in resume-job datasets are sparse. Different from manyprior work that use complex modeling techniques, we tackle this sparsityproblem using data augmentations and a simple contrastive learning approach.ConFit first creates an augmented resume-job dataset by paraphrasing specificsections in a resume or a job post. Then, ConFit uses contrastive learning tofurther increase training samples from $B$ pairs per batch to $O(B^2)$ perbatch. We evaluate ConFit on two real-world datasets and find it outperformsprior methods (including BM25 and OpenAI text-ada-002) by up to 19% and 31%absolute in nDCG@10 for ranking jobs and ranking resumes, respectively.</description><author>Xiao Yu, Jinzhong Zhang, Zhou Yu</author><pubDate>Mon, 29 Jan 2024 17:55:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16349v1</guid></item><item><title>Beyond Automated Evaluation Metrics: Evaluating Topic Models On Practical Social Science Content Analysis Tasks</title><link>http://arxiv.org/abs/2401.16348v1</link><description>Topic models are a popular tool for understanding text collections, but theirevaluation has been a point of contention. Automated evaluation metrics such ascoherence are often used, however, their validity has been questioned forneural topic models (NTMs) and can overlook the benefits of a model in realworld applications. To this end, we conduct the first evaluation of neural,supervised and classical topic models in an interactive task based setting. Wecombine topic models with a classifier and test their ability to help humansconduct content analysis and document annotation. From simulated, real user andexpert pilot studies, the Contextual Neural Topic Model does the best oncluster evaluation metrics and human evaluations; however, LDA is competitivewith two other NTMs under our simulated experiment and user study results,contrary to what coherence scores suggest. We show that current automatedmetrics do not provide a complete picture of topic modeling capabilities, butthe right choice of NTMs can be better than classical models on practicaltasks.</description><author>Zongxia Li, Andrew Mao, Daniel Stephens, Pranav Goel, Emily Walpole, Alden Dima, Juan Fung, Jordan Boyd-Graber</author><pubDate>Mon, 29 Jan 2024 17:54:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16348v1</guid></item><item><title>Cross-Modal Coordination Across a Diverse Set of Input Modalities</title><link>http://arxiv.org/abs/2401.16347v1</link><description>Cross-modal retrieval is the task of retrieving samples of a given modalityby using queries of a different one. Due to the wide range of practicalapplications, the problem has been mainly focused on the vision and languagecase, e.g. text to image retrieval, where models like CLIP have proveneffective in solving such tasks. The dominant approach to learning suchcoordinated representations consists of projecting them onto a common spacewhere matching views stay close and those from non-matching pairs are pushedaway from each other. Although this cross-modal coordination has been appliedalso to other pairwise combinations, extending it to an arbitrary number ofdiverse modalities is a problem that has not been fully explored in theliterature. In this paper, we propose two different approaches to the problem.The first is based on an extension of the CLIP contrastive objective to anarbitrary number of input modalities, while the second departs from thecontrastive formulation and tackles the coordination problem by regressing thecross-modal similarities towards a target that reflects two simple andintuitive constraints of the cross-modal retrieval task. We run experiments ontwo different datasets, over different combinations of input modalities andshow that the approach is not only simple and effective but also allows fortackling the retrieval problem in novel ways. Besides capturing a more diverseset of pair-wise interactions, we show that we can use the learnedrepresentations to improve retrieval performance by combining the embeddingsfrom two or more such modalities.</description><author>Jorge Sánchez, Rodrigo Laguna</author><pubDate>Mon, 29 Jan 2024 17:53:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16347v1</guid></item><item><title>Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank</title><link>http://arxiv.org/abs/2309.15560v2</link><description>Unbiased Learning to Rank (ULTR) aims to train unbiased ranking models frombiased click logs, by explicitly modeling a generation process for userbehavior and fitting click data based on examination hypothesis. Previousresearch found empirically that the true latent relevance is mostly recoverablethrough perfect click fitting. However, we demonstrate that this is not alwaysachievable, resulting in a significant reduction in ranking performance. Thisresearch investigates the conditions under which relevance can be recoveredfrom click data at a foundational level. We initially characterize a rankingmodel as identifiable if it can recover the true relevance up to a scalingtransformation, a criterion sufficient for the pairwise ranking objective.Subsequently, we investigate an equivalent condition for identifiability,articulated as a graph connectivity test problem: the recovery of relevance isfeasible if and only if the identifiability graph (IG), derived from theunderlying structure of the dataset, is connected. The presence of adisconnected IG may lead to degenerate cases and suboptimal rankingperformance. To tackle this challenge, we introduce two methods, namely nodeintervention and node merging, designed to modify the dataset and restore theconnectivity of the IG. Empirical results derived from a simulated dataset andtwo real-world LTR benchmark datasets not only validate our proposed theoremsbut also demonstrate the effectiveness of our methods in alleviating data biaswhen the relevance model is unidentifiable.</description><author>Mouxiang Chen, Chenghao Liu, Zemin Liu, Zhuo Li, Jianling Sun</author><pubDate>Mon, 29 Jan 2024 17:47:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15560v2</guid></item><item><title>Iterative Data Smoothing: Mitigating Reward Overfitting and Overoptimization in RLHF</title><link>http://arxiv.org/abs/2401.16335v1</link><description>Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique thataligns language models closely with human-centric values. The initial phase ofRLHF involves learning human values using a reward model from ranking data. Itis observed that the performance of the reward model degrades after one epochof training, and optimizing too much against the learned reward modeleventually hinders the true objective. This paper delves into these issues,leveraging the theoretical insights to design improved reward learningalgorithm termed 'Iterative Data Smoothing' (IDS). The core idea is that duringeach training epoch, we not only update the model with the data, but alsoupdate the date using the model, replacing hard labels with soft labels. Ourempirical findings highlight the superior performance of this approach over thetraditional methods.</description><author>Banghua Zhu, Michael I. Jordan, Jiantao Jiao</author><pubDate>Mon, 29 Jan 2024 17:43:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16335v1</guid></item><item><title>Tradeoffs Between Alignment and Helpfulness in Language Models</title><link>http://arxiv.org/abs/2401.16332v1</link><description>Language model alignment has become an important component of AI safety,allowing safe interactions between humans and language models, by enhancingdesired behaviors and inhibiting undesired ones. It is often done by tuning themodel or inserting preset aligning prompts. Recently, representationengineering, a method which alters the model's behavior via changing itsrepresentations post-training, was shown to be effective in aligning LLMs (Zouet al., 2023a). Representation engineering yields gains in alignment orientedtasks such as resistance to adversarial attacks and reduction of social biases,but was also shown to cause a decrease in the ability of the model to performbasic tasks. In this paper we study the tradeoff between the increase inalignment and decrease in helpfulness of the model. We propose a theoreticalframework which provides bounds for these two quantities, and demonstrate theirrelevance empirically. Interestingly, we find that while the helpfulnessgenerally decreases, it does so quadratically with the norm of therepresentation engineering vector, while the alignment increases linearly withit, indicating a regime in which it is efficient to use representationengineering. We validate our findings empirically, and chart the boundaries tothe usefulness of representation engineering for alignment.</description><author>Yotam Wolf, Noam Wies, Dorin Shteyman, Binyamin Rothberg, Yoav Levine, Amnon Shashua</author><pubDate>Mon, 29 Jan 2024 17:38:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16332v1</guid></item><item><title>Synthesis of 3D on-air signatures with the Sigma-Lognormal model</title><link>http://arxiv.org/abs/2401.16329v1</link><description>Signature synthesis is a computation technique that generates artificialspecimens which can support decision making in automatic signatureverification. A lot of work has been dedicated to this subject, which centreson synthesizing dynamic and static two-dimensional handwriting on canvas. Thispaper proposes a framework to generate synthetic 3D on-air signaturesexploiting the lognormality principle, which mimics the complex neuromotorcontrol processes at play as the fingertip moves. Addressing the usual casesinvolving the development of artificial individuals and duplicated samples,this paper contributes to the synthesis of: (1) the trajectory and velocity ofentirely 3D new signatures; (2) kinematic information when only the 3Dtrajectory of the signature is known, and (3) duplicate samples of 3D realsignatures. Validation was conducted by generating synthetic 3D signaturedatabases mimicking real ones and showing that automatic signatureverifications of genuine and skilled forgeries report performances similar tothose of real and synthetic databases. We also observed that training 3Dautomatic signature verifiers with duplicates can reduce errors. We furtherdemonstrated that our proposal is also valid for synthesizing 3D air writingand gestures. Finally, a perception test confirmed the human likeness of thegenerated specimens. The databases generated are publicly available, only forresearch purposes, at .</description><author>Miguel A. Ferrer, Moises Diaz, Cristina Carmona-Duarte, Jose J. Quintana Hernandez, Rejean Plamondon</author><pubDate>Mon, 29 Jan 2024 17:35:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16329v1</guid></item><item><title>PICL: Physics Informed Contrastive Learning for Partial Differential Equations</title><link>http://arxiv.org/abs/2401.16327v1</link><description>Neural operators have recently grown in popularity as Partial DifferentialEquation (PDEs) surrogate models. Learning solution functionals, rather thanfunctions, has proven to be a powerful approach to calculate fast, accuratesolutions to complex PDEs. While much work has been done evaluating neuraloperator performance on a wide variety of surrogate modeling tasks, these worksnormally evaluate performance on a single equation at a time. In this work, wedevelop a novel contrastive pretraining framework utilizing GeneralizedContrastive Loss that improves neural operator generalization across multiplegoverning equations simultaneously. Governing equation coefficients are used tomeasure ground-truth similarity between systems. A combination ofphysics-informed system evolution and latent-space model output are anchored toinput data and used in our distance function. We find that physics-informedcontrastive pretraining improves both accuracy and generalization for theFourier Neural Operator in fixed-future task, with comparable performance onthe autoregressive rollout, and superresolution tasks for the 1D Heat,Burgers', and linear advection equations.</description><author>Cooper Lorsung, Amir Barati Farimani</author><pubDate>Mon, 29 Jan 2024 17:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16327v1</guid></item><item><title>SPRINT: Scalable Policy Pre-Training via Language Instruction Relabeling</title><link>http://arxiv.org/abs/2306.11886v3</link><description>Pre-training robot policies with a rich set of skills can substantiallyaccelerate the learning of downstream tasks. Prior works have definedpre-training tasks via natural language instructions, but doing so requirestedious human annotation of hundreds of thousands of instructions. Thus, wepropose SPRINT, a scalable offline policy pre-training approach whichsubstantially reduces the human effort needed for pre-training a diverse set ofskills. Our method uses two core ideas to automatically expand a base set ofpre-training tasks: instruction relabeling via large language models andcross-trajectory skill chaining through offline reinforcement learning. As aresult, SPRINT pre-training equips robots with a much richer repertoire ofskills. Experimental results in a household simulator and on a real robotkitchen manipulation task show that SPRINT leads to substantially fasterlearning of new long-horizon tasks than previous pre-training approaches.Website at https://clvrai.com/sprint.</description><author>Jesse Zhang, Karl Pertsch, Jiahui Zhang, Joseph J. Lim</author><pubDate>Mon, 29 Jan 2024 17:28:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11886v3</guid></item><item><title>Prepare Non-classical Collective Spin State by Reinforcement Learning</title><link>http://arxiv.org/abs/2401.16320v1</link><description>We propose a scheme leveraging reinforcement learning to engineer controlfields for generating non-classical states. It is exemplified by theapplication to prepare spin squeezed state for an open collective spin modelwhere a linear control term is designed to govern the dynamics. Thereinforcement learning agent determines the temporal sequence of controlpulses, commencing from coherent spin state in an environment characterized bydissipation and dephasing. When compared to constant control scenarios, thisapproach provides various control sequences maintaining collective spinsqueezing and entanglement. It is observed that denser application of thecontrol pulses enhances the performance of the outcomes. Furthermore, there isa minor enhancement in the performance by adding control actions. The proposedstrategy demonstrates increased effectiveness for larger systems. And thermalexcitations of the reservoir are detrimental to the control outcomes. It shouldbe confirmed that this is an open-loop strategy by closed-loop simulation,circumventing collapse of quantum state induced by measurements. Thanks to theflexible replaceability of the optimization modules and the controlled system,this research paves the way for its application in manipulating other quantumsystems.</description><author>X. L. Zhao, Y. M. Zhao, M. Li, T. T. Li, Q. Liu, S. Guo, X. X. Yi</author><pubDate>Mon, 29 Jan 2024 17:23:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16320v1</guid></item><item><title>Defining and Extracting generalizable interaction primitives from DNNs</title><link>http://arxiv.org/abs/2401.16318v1</link><description>Faithfully summarizing the knowledge encoded by a deep neural network (DNN)into a few symbolic primitive patterns without losing much informationrepresents a core challenge in explainable AI. To this end, Ren et al. (2023c)have derived a series of theorems to prove that the inference score of a DNNcan be explained as a small set of interactions between input variables.However, the lack of generalization power makes it still hard to consider suchinteractions as faithful primitive patterns encoded by the DNN. Therefore,given different DNNs trained for the same task, we develop a new method toextract interactions that are shared by these DNNs. Experiments show that theextracted interactions can better reflect common knowledge shared by differentDNNs.</description><author>Lu Chen, Siyu Lou, Benhao Huang, Quanshi Zhang</author><pubDate>Mon, 29 Jan 2024 17:21:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16318v1</guid></item><item><title>Effects of Real-Life Traffic Sign Alteration on YOLOv7- an Object Recognition Model</title><link>http://arxiv.org/abs/2305.05499v2</link><description>The widespread adoption of Image Processing has propelled Object Recognition(OR) models into essential roles across various applications, demonstrating thepower of AI and enabling crucial services. Among the applications, traffic signrecognition stands out as a popular research topic, given its criticalsignificance in the development of autonomous vehicles. Despite theirsignificance, real-world challenges, such as alterations to traffic signs, cannegatively impact the performance of OR models. This study investigates theinfluence of altered traffic signs on the accuracy and effectiveness of objectrecognition, employing a publicly available dataset to introduce alterations inshape, color, content, visibility, angles and background. Focusing on theYOLOv7 (You Only Look Once) model, the study demonstrates a notable decline indetection and classification accuracy when confronted with traffic signs inunusual conditions including the altered traffic signs. Notably, thealterations explored in this study are benign examples and do not involvealgorithms used for generating adversarial machine learning samples. This studyhighlights the significance of enhancing the robustness of object detectionmodels in real-life scenarios and the need for further investigation in thisarea to improve their accuracy and reliability.</description><author>Farhin Farhad Riya, Shahinul Hoque, Md Saif Hassan Onim, Edward Michaud, Edmon Begoli, Jinyuan Stella Sun</author><pubDate>Mon, 29 Jan 2024 17:18:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05499v2</guid></item><item><title>Estimation of AMOC transition probabilities using a machine learning based rare-event algorithm</title><link>http://arxiv.org/abs/2401.10800v2</link><description>The Atlantic Meridional Overturning Circulation (AMOC) is an importantcomponent of the global climate, known to be a tipping element, as it couldcollapse under global warming. The main objective of this study is to computethe probability that the AMOC collapses within a specified time window, using arare-event algorithm called Trajectory-Adaptive Multilevel Splitting (TAMS).However, the efficiency and accuracy of TAMS depend on the choice of the scorefunction. Although the definition of the optimal score function, called``committor function" is known, it is impossible in general to compute it apriori. Here, we combine TAMS with a Next-Generation Reservoir Computingtechnique that estimates the committor function from the data generated by therare-event algorithm. We test this technique in a stochastic box model of theAMOC for which two types of transition exist, the so-called F(ast)-transitionsand S(low)-transitions. Results for the F-transtions compare favorably withthose in the literature where a physically-informed score function was used. Weshow that coupling a rare-event algorithm with machine learning allows for acorrect estimation of transition probabilities, transition times, and eventransition paths for a wide range of model parameters. We then extend theseresults to the more difficult problem of S-transitions in the same model. Inboth cases of F- and S-transitions, we also show how the Next-GenerationReservoir Computing technique can be interpreted to retrieve an analyticalestimate of the committor function.</description><author>Valérian Jacques-Dumas, René M. van Westen, Henk A. Dijkstra</author><pubDate>Mon, 29 Jan 2024 17:18:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10800v2</guid></item><item><title>Machine Translation Meta Evaluation through Translation Accuracy Challenge Sets</title><link>http://arxiv.org/abs/2401.16313v1</link><description>Recent machine translation (MT) metrics calibrate their effectiveness bycorrelating with human judgement but without any insights about their behaviouracross different error types. Challenge sets are used to probe specificdimensions of metric behaviour but there are very few such datasets and theyeither focus on a limited number of phenomena or a limited number of languagepairs. We introduce ACES, a contrastive challenge set spanning 146 languagepairs, aimed at discovering whether metrics can identify 68 translationaccuracy errors. These phenomena range from simple alterations at theword/character level to more complex errors based on discourse and real-worldknowledge. We conduct a large-scale study by benchmarking ACES on 50 metricssubmitted to the WMT 2022 and 2023 metrics shared tasks. We benchmark metricperformance, assess their incremental performance over successive campaigns,and measure their sensitivity to a range of linguistic phenomena. We alsoinvestigate claims that Large Language Models (LLMs) are effective as MTevaluators by evaluating on ACES. Our results demonstrate that different metricfamilies struggle with different phenomena and that LLM-based methods fail todemonstrate reliable performance. Our analyses indicate that most metricsignore the source sentence, tend to prefer surface-level overlap and end upincorporating properties of base models which are not always beneficial. Weexpand ACES to include error span annotations, denoted as SPAN-ACES and we usethis dataset to evaluate span-based error metrics showing these metrics alsoneed considerable improvement. Finally, we provide a set of recommendations forbuilding better MT metrics, including focusing on error labels instead ofscores, ensembling, designing strategies to explicitly focus on the sourcesentence, focusing on semantic content and choosing the right base model forrepresentations.</description><author>Nikita Moghe, Arnisa Fazla, Chantal Amrhein, Tom Kocmi, Mark Steedman, Alexandra Birch, Rico Sennrich, Liane Guillou</author><pubDate>Mon, 29 Jan 2024 17:17:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16313v1</guid></item><item><title>Taming the Sigmoid Bottleneck: Provably Argmaxable Sparse Multi-Label Classification</title><link>http://arxiv.org/abs/2310.10443v2</link><description>Sigmoid output layers are widely used in multi-label classification (MLC)tasks, in which multiple labels can be assigned to any input. In many practicalMLC tasks, the number of possible labels is in the thousands, often exceedingthe number of input features and resulting in a low-rank output layer. Inmulti-class classification, it is known that such a low-rank output layer is abottleneck that can result in unargmaxable classes: classes which cannot bepredicted for any input. In this paper, we show that for MLC tasks, theanalogous sigmoid bottleneck results in exponentially many unargmaxable labelcombinations. We explain how to detect these unargmaxable outputs anddemonstrate their presence in three widely used MLC datasets. We then show thatthey can be prevented in practice by introducing a Discrete Fourier Transform(DFT) output layer, which guarantees that all sparse label combinations with upto $k$ active labels are argmaxable. Our DFT layer trains faster and is moreparameter efficient, matching the F1@k score of a sigmoid layer while using upto 50% fewer trainable parameters. Our code is publicly available athttps://github.com/andreasgrv/sigmoid-bottleneck.</description><author>Andreas Grivas, Antonio Vergari, Adam Lopez</author><pubDate>Mon, 29 Jan 2024 17:14:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10443v2</guid></item><item><title>Security Code Review by LLMs: A Deep Dive into Responses</title><link>http://arxiv.org/abs/2401.16310v1</link><description>Security code review aims to combine automated tools and manual efforts todetect security defects during development. The rapid development of LargeLanguage Models (LLMs) has shown promising potential in software development,as well as opening up new possibilities in automated security code review. Toexplore the challenges of applying LLMs in practical code review for securitydefect detection, this study compared the detection performance of threestate-of-the-art LLMs (Gemini Pro, GPT-4, and GPT-3.5) under five prompts on549 code files that contain security defects from real-world code reviews.Through analyzing 82 responses generated by the best-performing LLM-promptcombination based on 100 randomly selected code files, we extracted andcategorized quality problems present in these responses into 5 themes and 16categories. Our results indicate that the responses produced by LLMs oftensuffer from verbosity, vagueness, and incompleteness, highlighting thenecessity to enhance their conciseness, understandability, and compliance tosecurity defect detection. This work reveals the deficiencies of LLM-generatedresponses in security code review and paves the way for future optimization ofLLMs towards this task.</description><author>Jiaxin Yu, Peng Liang, Yujia Fu, Amjed Tahir, Mojtaba Shahin, Chong Wang, Yangxiao Cai</author><pubDate>Mon, 29 Jan 2024 17:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16310v1</guid></item><item><title>Towards Building the Federated GPT: Federated Instruction Tuning</title><link>http://arxiv.org/abs/2305.05644v2</link><description>While "instruction-tuned" generative large language models (LLMs) havedemonstrated an impressive ability to generalize to new tasks, the trainingphases heavily rely on large amounts of diverse and high-quality instructiondata (such as ChatGPT and GPT-4). Unfortunately, acquiring high-quality data,especially when it comes to human-written data, can pose significant challengesboth in terms of cost and accessibility. Moreover, concerns related to privacycan further limit access to such data, making the process of obtaining it acomplex and nuanced undertaking. Consequently, this hinders the generality ofthe tuned models and may restrict their effectiveness in certain contexts. Totackle this issue, our study introduces a new approach called FederatedInstruction Tuning (FedIT), which leverages federated learning (FL) as thelearning framework for the instruction tuning of LLMs. This marks the firstexploration of FL-based instruction tuning for LLMs. This is especiallyimportant since text data is predominantly generated by end users. Therefore,it is imperative to design and adapt FL approaches to effectively leveragethese users' diverse instructions stored on local devices, while preservingprivacy and ensuring data security. In the current paper, by conducting widelyused GPT-4 auto-evaluation, we demonstrate that by exploiting the heterogeneousand diverse sets of instructions on the client's end with the proposedframework FedIT, we improved the performance of LLMs compared to centralizedtraining with only limited local instructions. Further, in this paper, wedeveloped a Github repository named Shepherd. This repository offers afoundational framework for exploring federated fine-tuning of LLMs usingheterogeneous instructions across diverse categories.</description><author>Jianyi Zhang, Saeed Vahidian, Martin Kuo, Chunyuan Li, Ruiyi Zhang, Tong Yu, Yufan Zhou, Guoyin Wang, Yiran Chen</author><pubDate>Mon, 29 Jan 2024 17:13:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05644v2</guid></item><item><title>MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D Object Detection</title><link>http://arxiv.org/abs/2401.16305v1</link><description>Label-efficient LiDAR-based 3D object detection is currently dominated byweakly/semi-supervised methods. Instead of exclusively following one of them,we propose MixSup, a more practical paradigm simultaneously utilizing massivecheap coarse labels and a limited number of accurate labels for Mixed-grainedSupervision. We start by observing that point clouds are usually textureless,making it hard to learn semantics. However, point clouds are geometrically richand scale-invariant to the distances from sensors, making it relatively easy tolearn the geometry of objects, such as poses and shapes. Thus, MixSup leveragesmassive coarse cluster-level labels to learn semantics and a few expensivebox-level labels to learn accurate poses and shapes. We redesign the labelassignment in mainstream detectors, which allows them seamlessly integratedinto MixSup, enabling practicality and universality. We validate itseffectiveness in nuScenes, Waymo Open Dataset, and KITTI, employing variousdetectors. MixSup achieves up to 97.31% of fully supervised performance, usingcheap cluster annotations and only 10% box annotations. Furthermore, we proposePointSAM based on the Segment Anything Model for automated coarse labeling,further reducing the annotation burden. The code is available athttps://github.com/BraveGroup/PointSAM-for-MixSup.</description><author>Yuxue Yang, Lue Fan, Zhaoxiang Zhang</author><pubDate>Mon, 29 Jan 2024 17:05:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16305v1</guid></item><item><title>Regressing Transformers for Data-efficient Visual Place Recognition</title><link>http://arxiv.org/abs/2401.16304v1</link><description>Visual place recognition is a critical task in computer vision, especiallyfor localization and navigation systems. Existing methods often rely oncontrastive learning: image descriptors are trained to have small distance forsimilar images and larger distance for dissimilar ones in a latent space.However, this approach struggles to ensure accurate distance-based imagesimilarity representation, particularly when training with binary pairwiselabels, and complex re-ranking strategies are required. This work introduces afresh perspective by framing place recognition as a regression problem, usingcamera field-of-view overlap as similarity ground truth for learning. Byoptimizing image descriptors to align directly with graded similarity labels,this approach enhances ranking capabilities without expensive re-ranking,offering data-efficient training and strong generalization across severalbenchmark datasets.</description><author>María Leyva-Vallina, Nicola Strisciuglio, Nicolai Petkov</author><pubDate>Mon, 29 Jan 2024 17:04:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16304v1</guid></item><item><title>Enhancing Molecular Property Prediction with Auxiliary Learning and Task-Specific Adaptation</title><link>http://arxiv.org/abs/2401.16299v1</link><description>Pretrained Graph Neural Networks have been widely adopted for variousmolecular property prediction tasks. Despite their ability to encode structuraland relational features of molecules, traditional fine-tuning of suchpretrained GNNs on the target task can lead to poor generalization. To addressthis, we explore the adaptation of pretrained GNNs to the target task byjointly training them with multiple auxiliary tasks. This could enable the GNNsto learn both general and task-specific features, which may benefit the targettask. However, a major challenge is to determine the relatedness of auxiliarytasks with the target task. To address this, we investigate multiple strategiesto measure the relevance of auxiliary tasks and integrate such tasks byadaptively combining task gradients or by learning task weights via bi-leveloptimization. Additionally, we propose a novel gradient surgery-based approach,Rotation of Conflicting Gradients ($\mathtt{RCGrad}$), that learns to alignconflicting auxiliary task gradients through rotation. Our experiments withstate-of-the-art pretrained GNNs demonstrate the efficacy of our proposedmethods, with improvements of up to 7.7% over fine-tuning. This suggests thatincorporating auxiliary tasks along with target task fine-tuning can be aneffective way to improve the generalizability of pretrained GNNs for molecularproperty prediction.</description><author>Vishal Dey, Xia Ning</author><pubDate>Mon, 29 Jan 2024 17:00:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16299v1</guid></item><item><title>Breaking the Barrier: Selective Uncertainty-based Active Learning for Medical Image Segmentation</title><link>http://arxiv.org/abs/2401.16298v1</link><description>Active learning (AL) has found wide applications in medical imagesegmentation, aiming to alleviate the annotation workload and enhanceperformance. Conventional uncertainty-based AL methods, such as entropy andBayesian, often rely on an aggregate of all pixel-level metrics. However, inimbalanced settings, these methods tend to neglect the significance of targetregions, eg., lesions, and tumors. Moreover, uncertainty-based selectionintroduces redundancy. These factors lead to unsatisfactory performance, and inmany cases, even underperform random sampling. To solve this problem, weintroduce a novel approach called the Selective Uncertainty-based AL, avoidingthe conventional practice of summing up the metrics of all pixels. Through afiltering process, our strategy prioritizes pixels within target areas andthose near decision boundaries. This resolves the aforementioned disregard fortarget areas and redundancy. Our method showed substantial improvements acrossfive different uncertainty-based methods and two distinct datasets, utilizingfewer labeled data to reach the supervised baseline and consistently achievingthe highest overall performance. Our code is available athttps://github.com/HelenMa9998/Selective\_Uncertainty\_AL.</description><author>Siteng Ma, Haochang Wu, Aonghus Lawlor, Ruihai Dong</author><pubDate>Mon, 29 Jan 2024 16:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16298v1</guid></item><item><title>Change detection needs change information: improving deep 3D point cloud change detection</title><link>http://arxiv.org/abs/2304.12639v2</link><description>Change detection is an important task that rapidly identifies modified areas,particularly when multi-temporal data are concerned. In landscapes with acomplex geometry (e.g., urban environment), vertical information is a veryuseful source of knowledge that highlights changes and classifies them intodifferent categories. In this study, we focus on change segmentation using rawthree-dimensional (3D) point clouds (PCs) directly to avoid any informationloss due to the rasterization processes. While deep learning has recentlyproven its effectiveness for this particular task by encoding the informationthrough Siamese networks, we investigate herein the idea of also using changeinformation in the early steps of deep networks. To do this, we first proposeto provide a Siamese KPConv state-of-the-art (SoTA) network with hand-craftedfeatures, especially a change-related one, which improves the mean of theIntersection over Union (IoU) over the classes of change by 4.70%. Consideringthat a major improvement is obtained due to the change-related feature, we thenpropose three new architectures to address 3D PC change segmentation:OneConvFusion, Triplet KPConv, and Encoder Fusion SiamKPConv. All thesenetworks consider the change information in the early steps and outperform theSoTA methods. In particular, Encoder Fusion SiamKPConv overtakes the SoTAapproaches by more than 5% of the mean of the IoU over the classes of change,emphasizing the value of having the network focus on change information for thechange detection task. The code is available athttps://github.com/IdeGelis/torch-points3d-SiamKPConvVariants.</description><author>Iris de Gélis, Thomas Corpetti, Sébastien Lefèvre</author><pubDate>Mon, 29 Jan 2024 16:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12639v2</guid></item><item><title>Detecting Reddit Users with Depression Using a Hybrid Neural Network SBERT-CNN</title><link>http://arxiv.org/abs/2302.02759v2</link><description>Depression is a widespread mental health issue, affecting an estimated 3.8%of the global population. It is also one of the main contributors to disabilityworldwide. Recently it is becoming popular for individuals to use social mediaplatforms (e.g., Reddit) to express their difficulties and health issues (e.g.,depression) and seek support from other users in online communities. It opensgreat opportunities to automatically identify social media users withdepression by parsing millions of posts for potential interventions. Deeplearning methods have begun to dominate in the field of machine learning andnatural language processing (NLP) because of their ease of use, efficientprocessing, and state-of-the-art results on many NLP tasks. In this work, wepropose a hybrid deep learning model which combines a pretrained sentence BERT(SBERT) and convolutional neural network (CNN) to detect individuals withdepression with their Reddit posts. The sentence BERT is used to learn themeaningful representation of semantic information in each post. CNN enables thefurther transformation of those embeddings and the temporal identification ofbehavioral patterns of users. We trained and evaluated the model performance toidentify Reddit users with depression by utilizing the Self-reported MentalHealth Diagnoses (SMHD) data. The hybrid deep learning model achieved anaccuracy of 0.86 and an F1 score of 0.86 and outperformed the state-of-the-artdocumented result (F1 score of 0.79) by other machine learning models in theliterature. The results show the feasibility of the hybrid model to identifyindividuals with depression. Although the hybrid model is validated to detectdepression with Reddit posts, it can be easily tuned and applied to other textclassification tasks and different clinical applications.</description><author>Ziyi Chen, Ren Yang, Sunyang Fu, Nansu Zong, Hongfang Liu, Ming Huang</author><pubDate>Mon, 29 Jan 2024 16:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02759v2</guid></item><item><title>Dual feature-based and example-based explanation methods</title><link>http://arxiv.org/abs/2401.16294v1</link><description>A new approach to the local and global explanation is proposed. It is basedon selecting a convex hull constructed for the finite number of points aroundan explained instance. The convex hull allows us to consider a dualrepresentation of instances in the form of convex combinations of extremepoints of a produced polytope. Instead of perturbing new instances in theEuclidean feature space, vectors of convex combination coefficients areuniformly generated from the unit simplex, and they form a new dual dataset. Adual linear surrogate model is trained on the dual dataset. The explanationfeature importance values are computed by means of simple matrix calculations.The approach can be regarded as a modification of the well-known model LIME.The dual representation inherently allows us to get the example-basedexplanation. The neural additive model is also considered as a tool forimplementing the example-based explanation approach. Many numerical experimentswith real datasets are performed for studying the approach. The code ofproposed algorithms is available.</description><author>Andrei V. Konstantinov, Boris V. Kozlov, Stanislav R. Kirpichenko, Lev V. Utkin</author><pubDate>Mon, 29 Jan 2024 16:53:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16294v1</guid></item><item><title>Textual Entailment for Effective Triple Validation in Object Prediction</title><link>http://arxiv.org/abs/2401.16293v1</link><description>Knowledge base population seeks to expand knowledge graphs with facts thatare typically extracted from a text corpus. Recently, language modelspretrained on large corpora have been shown to contain factual knowledge thatcan be retrieved using cloze-style strategies. Such approach enables zero-shotrecall of facts, showing competitive results in object prediction compared tosupervised baselines. However, prompt-based fact retrieval can be brittle andheavily depend on the prompts and context used, which may produce results thatare unintended or hallucinatory.We propose to use textual entailment tovalidate facts extracted from language models through cloze statements. Ourresults show that triple validation based on textual entailment improveslanguage model predictions in different training regimes. Furthermore, we showthat entailment-based triple validation is also effective to validate candidatefacts extracted from other sources including existing knowledge graphs and textpassages where named entities are recognized.</description><author>Andrés García-Silva, Cristian Berrío, José Manuel Gómez-Pérez</author><pubDate>Mon, 29 Jan 2024 16:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16293v1</guid></item><item><title>MachineLearnAthon: An Action-Oriented Machine Learning Didactic Concept</title><link>http://arxiv.org/abs/2401.16291v1</link><description>Machine Learning (ML) techniques are encountered nowadays across disciplines,from social sciences, through natural sciences to engineering. The broadapplication of ML and the accelerated pace of its evolution lead to anincreasing need for dedicated teaching concepts aimed at making the applicationof this technology more reliable and responsible. However, teaching ML is adaunting task. Aside from the methodological complexity of ML algorithms, bothwith respect to theory and implementation, the interdisciplinary and empiricalnature of the field need to be taken into consideration. This paper introducesthe MachineLearnAthon format, an innovative didactic concept designed to beinclusive for students of different disciplines with heterogeneous levels ofmathematics, programming and domain expertise. At the heart of the concept lieML challenges, which make use of industrial data sets to solve real-worldproblems. These cover the entire ML pipeline, promoting data literacy andpractical skills, from data preparation, through deployment, to evaluation.</description><author>Michal Tkáč, Jakub Sieber, Lara Kuhlmann, Matthias Brueggenolte, Alexandru Rinciog, Michael Henke, Artur M. Schweidtmann, Qinghe Gao, Maximilian F. Theisen, Radwa El Shawi</author><pubDate>Mon, 29 Jan 2024 16:50:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16291v1</guid></item><item><title>GAPS: Geometry-Aware Problem Solver</title><link>http://arxiv.org/abs/2401.16287v1</link><description>Geometry problem solving presents a formidable challenge within the NLPcommunity. Existing approaches often rely on models designed for solving mathword problems, neglecting the unique characteristics of geometry math problems.Additionally, the current research predominantly focuses on geometrycalculation problems, while overlooking other essential aspects like proving.In this study, we address these limitations by proposing the Geometry-AwareProblem Solver (GAPS) model. GAPS is specifically designed to generate solutionprograms for geometry math problems of various types with the help of itsunique problem-type classifier. To achieve this, GAPS treats the solutionprogram as a composition of operators and operands, segregating theirgeneration processes. Furthermore, we introduce the geometry elementsenhancement method, which enhances the ability of GAPS to recognize geometryelements accurately. By leveraging these improvements, GAPS showcasesremarkable performance in resolving geometry math problems. Our experimentsconducted on the UniGeo dataset demonstrate the superiority of GAPS over thestate-of-the-art model, Geoformer. Specifically, GAPS achieves an accuracyimprovement of more than 5.3% for calculation tasks and an impressive 41.1% forproving tasks. Notably, GAPS achieves an impressive accuracy of 97.5% onproving problems, representing a significant advancement in solving geometryproving tasks.</description><author>Jiaxin Zhang, Yinghui Jiang, Yashar Moshfeghi</author><pubDate>Mon, 29 Jan 2024 16:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16287v1</guid></item><item><title>Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge</title><link>http://arxiv.org/abs/2401.13098v2</link><description>Invasive species in water bodies pose a major threat to the environment andbiodiversity globally. Due to increased transportation and trade, non-nativespecies have been introduced to new environments, causing damage to ecosystemsand leading to economic losses in agriculture, forestry, and fisheries.Therefore, there is a pressing need for risk assessment and managementtechniques to mitigate the impact of these invasions. This study aims todevelop a new physics-inspired model to forecast maritime shipping traffic andthus inform risk assessment of invasive species spread through globaltransportation networks. Inspired by the gravity model for internationaltrades, our model considers various factors that influence the likelihood andimpact of vessel activities, such as shipping flux density, distance betweenports, trade flow, and centrality measures of transportation hubs.Additionally, by analyzing the risk network of invasive species, we provide acomprehensive framework for assessing the invasion threat level given a pair oforigin and destination. Accordingly, this paper introduces transformers togravity models to rebuild the short- and long-term dependencies that make therisk analysis feasible. Thus, we introduce a physics-inspired framework thatachieves an 89% segmentation accuracy for existing and non-existingtrajectories and an 84.8% accuracy for the number of vessels flowing betweenkey port areas, representing more than 10% improvement over the traditionaldeep-gravity model. Along these lines, this research contributes to a betterunderstanding of invasive species risk assessment. It allows policymakers,conservationists, and stakeholders to prioritize management actions byidentifying high-risk invasion pathways. Besides, our model is versatile andcan include new data sources, making it suitable for assessing species invasionrisks in a changing global landscape.</description><author>Ruixin Song, Gabriel Spadon, Ronald Pelot, Stan Matwin, Amilcar Soares</author><pubDate>Mon, 29 Jan 2024 16:43:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13098v2</guid></item><item><title>Capturing Pertinent Symbolic Features for Enhanced Content-Based Misinformation Detection</title><link>http://arxiv.org/abs/2401.16285v1</link><description>Preventing the spread of misinformation is challenging. The detection ofmisleading content presents a significant hurdle due to its extreme linguisticand domain variability. Content-based models have managed to identify deceptivelanguage by learning representations from textual data such as social mediaposts and web articles. However, aggregating representative samples of thisheterogeneous phenomenon and implementing effective real-world applications isstill elusive. Based on analytical work on the language of misinformation, thispaper analyzes the linguistic attributes that characterize this phenomenon andhow representative of such features some of the most popular misinformationdatasets are. We demonstrate that the appropriate use of pertinent symbolicknowledge in combination with neural language models is helpful in detectingmisleading content. Our results achieve state-of-the-art performance inmisinformation datasets across the board, showing that our approach offers avalid and robust alternative to multi-task transfer learning without requiringany additional training data. Furthermore, our results show evidence thatstructured knowledge can provide the extra boost required to address a complexand unpredictable real-world problem like misinformation detection, not only interms of accuracy but also time efficiency and resource utilization.</description><author>Flavio Merenda, José Manuel Gómez-Pérez</author><pubDate>Mon, 29 Jan 2024 16:42:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16285v1</guid></item><item><title>Leveraging Positional Encoding for Robust Multi-Reference-Based Object 6D Pose Estimation</title><link>http://arxiv.org/abs/2401.16284v1</link><description>Accurately estimating the pose of an object is a crucial task in computervision and robotics. There are two main deep learning approaches for this:geometric representation regression and iterative refinement. However, thesemethods have some limitations that reduce their effectiveness. In this paper,we analyze these limitations and propose new strategies to overcome them. Totackle the issue of blurry geometric representation, we use positional encodingwith high-frequency components for the object's 3D coordinates. To address thelocal minimum problem in refinement methods, we introduce a normalized imageplane-based multi-reference refinement strategy that's independent of intrinsicmatrix constraints. Lastly, we utilize adaptive instance normalization and asimple occlusion augmentation method to help our model concentrate on thetarget object. Our experiments on Linemod, Linemod-Occlusion, and YCB-Videodatasets demonstrate that our approach outperforms existing methods. We willsoon release the code.</description><author>Jaewoo Park, Jaeguk Kim, Nam Ik Cho</author><pubDate>Mon, 29 Jan 2024 16:42:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16284v1</guid></item><item><title>MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim Verification</title><link>http://arxiv.org/abs/2401.16282v1</link><description>Claim verification is an essential step in the automated fact-checkingpipeline which assesses the veracity of a claim against a piece of evidence. Inthis work, we explore the potential of few-shot claim verification, where onlyvery limited data is available for supervision. We propose MAPLE (MicroAnalysis of Pairwise Language Evolution), a pioneering approach that exploresthe alignment between a claim and its evidence with a small seq2seq model and anovel semantic measure. Its innovative utilization of micro language evolutionpath leverages unlabelled pairwise data to facilitate claim verification whileimposing low demand on data annotations and computing resources. MAPLEdemonstrates significant performance improvements over SOTA baselines SEED, PETand LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, andSciFact. Data and code are available here: https://github.com/XiaZeng0223/MAPLE</description><author>Xia Zeng, Arkaitz Zubiaga</author><pubDate>Mon, 29 Jan 2024 16:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16282v1</guid></item><item><title>Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL</title><link>http://arxiv.org/abs/2208.10469v4</link><description>Multi-agent Reinforcement Learning (MARL) is a powerful tool for trainingautonomous agents acting independently in a common environment. However, it canlead to sub-optimal behavior when individual incentives and group incentivesdiverge. Humans are remarkably capable at solving these social dilemmas. It isan open problem in MARL to replicate such cooperative behaviors in selfishagents. In this work, we draw upon the idea of formal contracting fromeconomics to overcome diverging incentives between agents in MARL. We proposean augmentation to a Markov game where agents voluntarily agree to bindingtransfers of reward, under pre-specified conditions. Our contributions aretheoretical and empirical. First, we show that this augmentation makes allsubgame-perfect equilibria of all Fully Observable Markov Games exhibitsocially optimal behavior, given a sufficiently rich space of contracts. Next,we show that for general contract spaces, and even under partial observability,richer contract spaces lead to higher welfare. Hence, contract space designsolves an exploration-exploitation tradeoff, sidestepping incentive issues. Wecomplement our theoretical analysis with experiments. Issues of exploration inthe contracting augmentation are mitigated using a training methodologyinspired by multi-objective reinforcement learning: Multi-Objective ContractAugmentation Learning (MOCA). We test our methodology in static, single-movegames, as well as dynamic domains that simulate traffic, pollution managementand common pool resource management.</description><author>Andreas A. Haupt, Phillip J. K. Christoffersen, Mehul Damani, Dylan Hadfield-Menell</author><pubDate>Mon, 29 Jan 2024 16:37:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10469v4</guid></item><item><title>Cutup and Detect: Human Fall Detection on Cutup Untrimmed Videos Using a Large Foundational Video Understanding Model</title><link>http://arxiv.org/abs/2401.16280v1</link><description>This work explores the performance of a large video understanding foundationmodel on the downstream task of human fall detection on untrimmed video andleverages a pretrained vision transformer for multi-class action detection,with classes: "Fall", "Lying" and "Other/Activities of daily living (ADL)". Amethod for temporal action localization that relies on a simple cutup ofuntrimmed videos is demonstrated. The methodology includes a preprocessingpipeline that converts datasets with timestamp action annotations into labeleddatasets of short action clips. Simple and effective clip-sampling strategiesare introduced. The effectiveness of the proposed method has been empiricallyevaluated on the publicly available High-Quality Fall Simulation Dataset(HQFSD). The experimental results validate the performance of the proposedpipeline. The results are promising for real-time application, and the fallsare detected on video level with a state-of-the-art 0.96 F1 score on the HQFSDdataset under the given experimental settings. The source code will be madeavailable on GitHub.</description><author>Till Grutschus, Ola Karrar, Emir Esenov, Ekta Vats</author><pubDate>Mon, 29 Jan 2024 16:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16280v1</guid></item><item><title>FlakyFix: Using Large Language Models for Predicting Flaky Test Fix Categories and Test Code Repair</title><link>http://arxiv.org/abs/2307.00012v2</link><description>Flaky tests are problematic because they non-deterministically pass or failfor the same software version under test, causing confusion and wastingdevelopment effort. While machine learning models have been used to predictflakiness and its root causes, there is much less work on providing support tofix the problem. To address this gap, in this paper, we focus on predicting thetype of fix that is required to remove flakiness and then repair the test codeon that basis. We do this for a subset of flaky test cases where the root causeof flakiness is in the test case itself and not in the production code. Our keyidea is to guide the repair process with additional knowledge about the test'sflakiness in the form of its predicted fix category. Thus, we first propose aframework that automatically generates labeled datasets for 13 fix categoriesand trains models to predict the fix category of a flaky test by analyzing thetest code only. Our experimental results using code models and few-shotlearning show that we can correctly predict most of the fix categories. To showthe usefulness of such fix category labels for automatically repairingflakiness, in addition to informing testers, we augment a Large Language Model(LLM) like GPT with such extra knowledge to ask the LLM for repair suggestions.The results show that our suggested fix category labels significantly enhancethe capability of GPT 3.5 Turbo, in generating fixes for flaky tests.</description><author>Sakina Fatima, Hadi Hemmati, Lionel Briand</author><pubDate>Mon, 29 Jan 2024 16:28:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00012v2</guid></item><item><title>Capturing Knowledge Graphs and Rules with Octagon Embeddings</title><link>http://arxiv.org/abs/2401.16270v1</link><description>Region based knowledge graph embeddings represent relations as geometricregions. This has the advantage that the rules which are captured by the modelare made explicit, making it straightforward to incorporate prior knowledge andto inspect learned models. Unfortunately, existing approaches are severelyrestricted in their ability to model relational composition, and hence alsotheir ability to model rules, thus failing to deliver on the main promise ofregion based models. With the aim of addressing these limitations, weinvestigate regions which are composed of axis-aligned octagons. Such octagonsare particularly easy to work with, as intersections and compositions can bestraightforwardly computed, while they are still sufficiently expressive tomodel arbitrary knowledge graphs. Among others, we also show that our octagonembeddings can properly capture a non-trivial class of rule bases. Finally, weshow that our model achieves competitive experimental results.</description><author>Victor Charpenay, Steven Schockaert</author><pubDate>Mon, 29 Jan 2024 16:18:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16270v1</guid></item><item><title>CO2: Efficient Distributed Training with Full Communication-Computation Overlap</title><link>http://arxiv.org/abs/2401.16265v1</link><description>The fundamental success of large language models hinges upon the efficaciousimplementation of large-scale distributed training techniques. Nevertheless,building a vast, high-performance cluster featuring high-speed communicationinterconnectivity is prohibitively costly, and accessible only to prominententities. In this work, we aim to lower this barrier and democratizelarge-scale training with limited bandwidth clusters. We propose a new approachcalled CO2 that introduces local-updating and asynchronous communication to thedistributed data-parallel training, thereby facilitating the full overlap ofCOmunication with COmputation. CO2 is able to attain a high scalability even onextensive multi-node clusters constrained by very limited communicationbandwidth. We further propose the staleness gap penalty and outer momentumclipping techniques together with CO2 to bolster its convergence and trainingstability. Besides, CO2 exhibits seamless integration with well-establishedZeRO-series optimizers which mitigate memory consumption of model states withlarge model training. We also provide a mathematical proof of convergence,accompanied by the establishment of a stringent upper bound. Furthermore, wevalidate our findings through an extensive set of practical experimentsencompassing a wide range of tasks in the fields of computer vision and naturallanguage processing. These experiments serve to demonstrate the capabilities ofCO2 in terms of convergence, generalization, and scalability when deployedacross configurations comprising up to 128 A100 GPUs. The outcomes emphasizethe outstanding capacity of CO2 to hugely improve scalability, no matter onclusters with 800Gbps RDMA or 80Gbps TCP/IP inter-node connections.</description><author>Weigao Sun, Zhen Qin, Weixuan Sun, Shidi Li, Dong Li, Xuyang Shen, Yu Qiao, Yiran Zhong</author><pubDate>Mon, 29 Jan 2024 16:12:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16265v1</guid></item><item><title>MosquIoT: A System Based on IoT and Machine Learning for the Monitoring of Aedes aegypti (Diptera: Culicidae)</title><link>http://arxiv.org/abs/2401.16258v1</link><description>Millions of people around the world are infected with mosquito-borne diseaseseach year. One of the most dangerous species is Aedes aegypti, the main vectorof viruses such as dengue, yellow fever, chikungunya, and Zika, among others.Mosquito prevention and eradication campaigns are essential to avoid majorpublic health consequences. In this respect, entomological surveillance is animportant tool. At present, this traditional monitoring tool is executedmanually and requires digital transformation to help authorities make betterdecisions, improve their planning efforts, speed up execution, and bettermanage available resources. Therefore, new technological tools based on proventechniques need to be designed and developed. However, such tools should alsobe cost-effective, autonomous, reliable, and easy to implement, and should beenabled by connectivity and multi-platform software applications. This paperpresents the design, development, and testing of an innovative system namedMosquIoT. It is based on traditional ovitraps with embedded Internet of Things(IoT) and Tiny Machine Learning (TinyML) technologies, which enable thedetection and quantification of Ae. aegypti eggs. This innovative and promisingsolution may help dynamically understand the behavior of Ae. aegyptipopulations in cities, shifting from the current reactive entomologicalmonitoring model to a proactive and predictive digital one.</description><author>Javier Aira, Teresa Olivares Montes, Francisco M. Delicado, Darìo Vezzani</author><pubDate>Mon, 29 Jan 2024 16:08:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16258v1</guid></item><item><title>Evolving Reservoirs for Meta Reinforcement Learning</title><link>http://arxiv.org/abs/2312.06695v2</link><description>Animals often demonstrate a remarkable ability to adapt to their environmentsduring their lifetime. They do so partly due to the evolution of morphologicaland neural structures. These structures capture features of environments sharedbetween generations to bias and speed up lifetime learning. In this work, wepropose a computational model for studying a mechanism that can enable such aprocess. We adopt a computational framework based on meta reinforcementlearning as a model of the interplay between evolution and development. At theevolutionary scale, we evolve reservoirs, a family of recurrent neural networksthat differ from conventional networks in that one optimizes not the synapticweights, but hyperparameters controlling macro-level properties of theresulting network architecture. At the developmental scale, we employ theseevolved reservoirs to facilitate the learning of a behavioral policy throughReinforcement Learning (RL). Within an RL agent, a reservoir encodes theenvironment state before providing it to an action policy. We evaluate ourapproach on several 2D and 3D simulated environments. Our results show that theevolution of reservoirs can improve the learning of diverse challenging tasks.We study in particular three hypotheses: the use of an architecture combiningreservoirs and reinforcement learning could enable (1) solving tasks withpartial observability, (2) generating oscillatory dynamics that facilitate thelearning of locomotion tasks, and (3) facilitating the generalization oflearned behaviors to new tasks unknown during the evolution phase.</description><author>Corentin Léger, Gautier Hamon, Eleni Nisioti, Xavier Hinaut, Clément Moulin-Frier</author><pubDate>Mon, 29 Jan 2024 16:08:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06695v2</guid></item><item><title>Gamma-convergence of a nonlocal perimeter arising in adversarial machine learning</title><link>http://arxiv.org/abs/2211.15223v4</link><description>In this paper we prove Gamma-convergence of a nonlocal perimeter of Minkowskitype to a local anisotropic perimeter. The nonlocal model describes theregularizing effect of adversarial training in binary classifications. Theenergy essentially depends on the interaction between two distributionsmodelling likelihoods for the associated classes. We overcome typical strictregularity assumptions for the distributions by only assuming that they havebounded $BV$ densities. In the natural topology coming from compactness, weprove Gamma-convergence to a weighted perimeter with weight determined by ananisotropic function of the two densities. Despite being local, this sharpinterface limit reflects classification stability with respect to adversarialperturbations. We further apply our results to deduce Gamma-convergence of theassociated total variations, to study the asymptotics of adversarial training,and to prove Gamma-convergence of graph discretizations for the nonlocalperimeter.</description><author>Leon Bungert, Kerrek Stinson</author><pubDate>Mon, 29 Jan 2024 16:07:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15223v4</guid></item><item><title>MatterGen: a generative model for inorganic materials design</title><link>http://arxiv.org/abs/2312.03687v2</link><description>The design of functional materials with desired properties is essential indriving technological advances in areas like energy storage, catalysis, andcarbon capture. Generative models provide a new paradigm for materials designby directly generating entirely novel materials given desired propertyconstraints. Despite recent progress, current generative models have lowsuccess rate in proposing stable crystals, or can only satisfy a very limitedset of property constraints. Here, we present MatterGen, a model that generatesstable, diverse inorganic materials across the periodic table and can furtherbe fine-tuned to steer the generation towards a broad range of propertyconstraints. To enable this, we introduce a new diffusion-based generativeprocess that produces crystalline structures by gradually refining atom types,coordinates, and the periodic lattice. We further introduce adapter modules toenable fine-tuning towards any given property constraints with a labeleddataset. Compared to prior generative models, structures produced by MatterGenare more than twice as likely to be novel and stable, and more than 15 timescloser to the local energy minimum. After fine-tuning, MatterGen successfullygenerates stable, novel materials with desired chemistry, symmetry, as well asmechanical, electronic and magnetic properties. Finally, we demonstratemulti-property materials design capabilities by proposing structures that haveboth high magnetic density and a chemical composition with low supply-chainrisk. We believe that the quality of generated materials and the breadth ofMatterGen's capabilities represent a major advancement towards creating auniversal generative model for materials design.</description><author>Claudio Zeni, Robert Pinsler, Daniel Zügner, Andrew Fowler, Matthew Horton, Xiang Fu, Sasha Shysheya, Jonathan Crabbé, Lixin Sun, Jake Smith, Bichlien Nguyen, Hannes Schulz, Sarah Lewis, Chin-Wei Huang, Ziheng Lu, Yichi Zhou, Han Yang, Hongxia Hao, Jielan Li, Ryota Tomioka, Tian Xie</author><pubDate>Mon, 29 Jan 2024 16:02:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03687v2</guid></item><item><title>Cross-silo Federated Learning with Record-level Personalized Differential Privacy</title><link>http://arxiv.org/abs/2401.16251v1</link><description>Federated learning enhanced by differential privacy has emerged as a popularapproach to better safeguard the privacy of client-side data by protectingclients' contributions during the training process. Existing solutionstypically assume a uniform privacy budget for all records and provideone-size-fits-all solutions that may not be adequate to meet each record'sprivacy requirement. In this paper, we explore the uncharted territory ofcross-silo FL with record-level personalized differential privacy. We devise anovel framework named rPDP-FL, employing a two-stage hybrid sampling schemewith both client-level sampling and non-uniform record-level sampling toaccommodate varying privacy requirements. A critical and non-trivial problem isto select the ideal per-record sampling probability q given the personalizedprivacy budget {\epsilon}. We introduce a versatile solution namedSimulation-CurveFitting, allowing us to uncover a significant insight into thenonlinear correlation between q and {\epsilon} and derive an elegantmathematical model to tackle the problem. Our evaluation demonstrates that oursolution can provide significant performance gains over the baselines that donot consider personalized privacy preservation.</description><author>Junxu Liu, Jian Lou, Li Xiong, Jinfei Liu, Xiaofeng Meng</author><pubDate>Mon, 29 Jan 2024 16:01:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16251v1</guid></item><item><title>Towards Red Teaming in Multimodal and Multilingual Translation</title><link>http://arxiv.org/abs/2401.16247v1</link><description>Assessing performance in Natural Language Processing is becoming increasinglycomplex. One particular challenge is the potential for evaluation datasets tooverlap with training data, either directly or indirectly, which can lead toskewed results and overestimation of model performance. As a consequence, humanevaluation is gaining increasing interest as a means to assess the performanceand reliability of models. One such method is the red teaming approach, whichaims to generate edge cases where a model will produce critical errors. Whilethis methodology is becoming standard practice for generative AI, itsapplication to the realm of conditional AI remains largely unexplored. Thispaper presents the first study on human-based red teaming for MachineTranslation (MT), marking a significant step towards understanding andimproving the performance of translation models. We delve into both human-basedred teaming and a study on automation, reporting lessons learned and providingrecommendations for both translation models and red teaming drills. Thispioneering work opens up new avenues for research and development in the fieldof MT.</description><author>Christophe Ropers, David Dale, Prangthip Hansanti, Gabriel Mejia Gonzalez, Ivan Evtimov, Corinne Wong, Christophe Touret, Kristina Pereyra, Seohyun Sonia Kim, Cristian Canton Ferrer, Pierre Andrews, Marta R. Costa-jussà</author><pubDate>Mon, 29 Jan 2024 15:49:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16247v1</guid></item><item><title>Clinically meaningful timeline summarisation in social media for mental health monitoring</title><link>http://arxiv.org/abs/2401.16240v1</link><description>We introduce the new task of clinically meaningful summarisation of socialmedia user timelines, appropriate for mental health monitoring. We develop anovel approach for unsupervised abstractive summarisation that produces atwo-layer summary consisting of both high-level information, covering aspectsuseful to clinical experts, as well as accompanying time sensitive evidencefrom a user's social media timeline. A key methodological novelty comes fromthe timeline summarisation component based on a version of hierarchicalvariational autoencoder (VAE) adapted to represent long texts and guided byLLM-annotated key phrases. The resulting timeline summary is input into a LLM(LLaMA-2) to produce the final summary containing both the high levelinformation, obtained through instruction prompting, as well as correspondingevidence from the user's timeline. We assess the summaries generated by ournovel architecture via automatic evaluation against expert written summariesand via human evaluation with clinical experts, showing that timelinesummarisation by TH-VAE results in logically coherent summaries rich inclinical utility and superior to LLM-only approaches in capturing changes overtime.</description><author>Jiayu Song, Jenny Chim, Adam Tsakalidis, Julia Ive, Dana Atzil-Slonim, Maria Liakata</author><pubDate>Mon, 29 Jan 2024 15:42:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16240v1</guid></item><item><title>Effective Communication with Dynamic Feature Compression</title><link>http://arxiv.org/abs/2401.16236v1</link><description>The remote wireless control of industrial systems is one of the major usecases for 5G and beyond systems: in these cases, the massive amounts of sensoryinformation that need to be shared over the wireless medium may overload evenhigh-capacity connections. Consequently, solving the effective communicationproblem by optimizing the transmission strategy to discard irrelevantinformation can provide a significant advantage, but is often a very complextask. In this work, we consider a prototypal system in which an observer mustcommunicate its sensory data to a robot controlling a task (e.g., a mobilerobot in a factory). We then model it as a remote Partially Observable MarkovDecision Process (POMDP), considering the effect of adopting semantic andeffective communication-oriented solutions on the overall system performance.We split the communication problem by considering an ensemble Vector QuantizedVariational Autoencoder (VQ-VAE) encoding, and train a Deep ReinforcementLearning (DRL) agent to dynamically adapt the quantization level, consideringboth the current state of the environment and the memory of past messages. Wetested the proposed approach on the well-known CartPole reference controlproblem, obtaining a significant performance increase over traditionalapproaches.</description><author>Pietro Talli, Francesco Pase, Federico Chiariotti, Andrea Zanella, Michele Zorzi</author><pubDate>Mon, 29 Jan 2024 15:35:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16236v1</guid></item><item><title>Player Pressure Map - A Novel Representation of Pressure in Soccer for Evaluating Player Performance in Different Game Contexts</title><link>http://arxiv.org/abs/2401.16235v1</link><description>In soccer, contextual player performance metrics are invaluable to coaches.For example, the ability to perform under pressure during matches distinguishesthe elite from the average. Appropriate pressure metric enables teams to assessplayers' performance accurately under pressure and design targeted trainingscenarios to address their weaknesses. The primary objective of this paper isto leverage both tracking and event data and game footage to capture thepressure experienced by the possession team in a soccer game scene. We proposea player pressure map to represent a given game scene, which lowers thedimension of raw data and still contains rich contextual information. Not onlydoes it serve as an effective tool for visualizing and evaluating the pressureon the team and each individual, but it can also be utilized as a backbone foraccessing players' performance. Overall, our model provides coaches andanalysts with a deeper understanding of players' performance under pressure sothat they make data-oriented tactical decisions.</description><author>Chaoyi Gu, Jiaming Na, Yisheng Pei, Varuna De Silva</author><pubDate>Mon, 29 Jan 2024 15:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16235v1</guid></item><item><title>Cross-Database Liveness Detection: Insights from Comparative Biometric Analysis</title><link>http://arxiv.org/abs/2401.16232v1</link><description>In an era where biometric security serves as a keystone of modern identityverification systems, ensuring the authenticity of these biometric samples isparamount. Liveness detection, the capability to differentiate between genuineand spoofed biometric samples, stands at the forefront of this challenge. Thisresearch presents a comprehensive evaluation of liveness detection models, witha particular focus on their performance in cross-database scenarios, a testparadigm notorious for its complexity and real-world relevance. Our studycommenced by meticulously assessing models on individual datasets, revealingthe nuances in their performance metrics. Delving into metrics such as the HalfTotal Error Rate, False Acceptance Rate, and False Rejection Rate, we unearthedinvaluable insights into the models' strengths and weaknesses. Crucially, ourexploration of cross-database testing provided a unique perspective,highlighting the chasm between training on one dataset and deploying onanother. Comparative analysis with extant methodologies, ranging fromconvolutional networks to more intricate strategies, enriched our understandingof the current landscape. The variance in performance, even amongstate-of-the-art models, underscored the inherent challenges in this domain. Inessence, this paper serves as both a repository of findings and a clarion callfor more nuanced, data-diverse, and adaptable approaches in biometric livenessdetection. In the dynamic dance between authenticity and deception, our workoffers a blueprint for navigating the evolving rhythms of biometric security.</description><author>Oleksandr Kuznetsov, Dmytro Zakharov, Emanuele Frontoni, Andrea Maranesi, Serhii Bohucharskyi</author><pubDate>Mon, 29 Jan 2024 15:32:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16232v1</guid></item><item><title>Particle Transformer for Jet Tagging</title><link>http://arxiv.org/abs/2202.03772v3</link><description>Jet tagging is a critical yet challenging classification task in particlephysics. While deep learning has transformed jet tagging and significantlyimproved performance, the lack of a large-scale public dataset impedes furtherenhancement. In this work, we present JetClass, a new comprehensive dataset forjet tagging. The JetClass dataset consists of 100 M jets, about two orders ofmagnitude larger than existing public datasets. A total of 10 types of jets aresimulated, including several types unexplored for tagging so far. Based on thelarge dataset, we propose a new Transformer-based architecture for jet tagging,called Particle Transformer (ParT). By incorporating pairwise particleinteractions in the attention mechanism, ParT achieves higher taggingperformance than a plain Transformer and surpasses the previousstate-of-the-art, ParticleNet, by a large margin. The pre-trained ParT models,once fine-tuned, also substantially enhance the performance on two widelyadopted jet tagging benchmarks. The dataset, code and models are publiclyavailable at https://github.com/jet-universe/particle_transformer.</description><author>Huilin Qu, Congqiao Li, Sitian Qian</author><pubDate>Mon, 29 Jan 2024 15:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.03772v3</guid></item><item><title>Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models</title><link>http://arxiv.org/abs/2401.16224v1</link><description>Toon shading is a type of non-photorealistic rendering task of animation. Itsprimary purpose is to render objects with a flat and stylized appearance. Asdiffusion models have ascended to the forefront of image synthesismethodologies, this paper delves into an innovative form of toon shading basedon diffusion models, aiming to directly render photorealistic videos into animestyles. In video stylization, extant methods encounter persistent challenges,notably in maintaining consistency and achieving high visual quality. In thispaper, we model the toon shading problem as four subproblems: stylization,consistency enhancement, structure guidance, and colorization. To address thechallenges in video stylization, we propose an effective toon shading approachcalled \textit{Diffutoon}. Diffutoon is capable of rendering remarkablydetailed, high-resolution, and extended-duration videos in anime style. It canalso edit the content according to prompts via an additional branch. Theefficacy of Diffutoon is evaluated through quantitive metrics and humanevaluation. Notably, Diffutoon surpasses both open-source and closed-sourcebaseline approaches in our experiments. Our work is accompanied by the releaseof both the source code and example videos on Github (Project page:https://ecnu-cilab.github.io/DiffutoonProjectPage/).</description><author>Zhongjie Duan, Chengyu Wang, Cen Chen, Weining Qian, Jun Huang</author><pubDate>Mon, 29 Jan 2024 15:21:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16224v1</guid></item><item><title>From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on Generalizability, Trustworthiness and Causality through Four Modalities</title><link>http://arxiv.org/abs/2401.15071v2</link><description>Multi-modal Large Language Models (MLLMs) have shown impressive abilities ingenerating reasonable responses with respect to multi-modal contents. However,there is still a wide gap between the performance of recent MLLM-basedapplications and the expectation of the broad public, even though the mostpowerful OpenAI's GPT-4 and Google's Gemini have been deployed. This paperstrives to enhance understanding of the gap through the lens of a qualitativestudy on the generalizability, trustworthiness, and causal reasoningcapabilities of recent proprietary and open-source MLLMs across fourmodalities: ie, text, code, image, and video, ultimately aiming to improve thetransparency of MLLMs. We believe these properties are several representativefactors that define the reliability of MLLMs, in supporting various downstreamapplications. To be specific, we evaluate the closed-source GPT-4 and Geminiand 6 open-source LLMs and MLLMs. Overall we evaluate 230 manually designedcases, where the qualitative results are then summarized into 12 scores (ie, 4modalities times 3 properties). In total, we uncover 14 empirical findings thatare useful to understand the capabilities and limitations of both proprietaryand open-source MLLMs, towards more reliable downstream multi-modalapplications.</description><author>Chaochao Lu, Chen Qian, Guodong Zheng, Hongxing Fan, Hongzhi Gao, Jie Zhang, Jing Shao, Jingyi Deng, Jinlan Fu, Kexin Huang, Kunchang Li, Lijun Li, Limin Wang, Lu Sheng, Meiqi Chen, Ming Zhang, Qibing Ren, Sirui Chen, Tao Gui, Wanli Ouyang, Yali Wang, Yan Teng, Yaru Wang, Yi Wang, Yinan He, Yingchun Wang, Yixu Wang, Yongting Zhang, Yu Qiao, Yujiong Shen, Yurong Mou, Yuxi Chen, Zaibin Zhang, Zhelun Shi, Zhenfei Yin, Zhipin Wang</author><pubDate>Mon, 29 Jan 2024 15:18:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15071v2</guid></item><item><title>Learning big logical rules by joining small rules</title><link>http://arxiv.org/abs/2401.16215v1</link><description>A major challenge in inductive logic programming is learning big rules. Toaddress this challenge, we introduce an approach where we join small rules tolearn big rules. We implement our approach in a constraint-driven system anduse constraint solvers to efficiently join rules. Our experiments on manydomains, including game playing and drug design, show that our approach can (i)learn rules with more than 100 literals, and (ii) drastically outperformexisting approaches in terms of predictive accuracies.</description><author>Céline Hocquette, Andreas Niskanen, Rolf Morel, Matti Järvisalo, Andrew Cropper</author><pubDate>Mon, 29 Jan 2024 15:09:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16215v1</guid></item><item><title>MultiMUC: Multilingual Template Filling on MUC-4</title><link>http://arxiv.org/abs/2401.16209v1</link><description>We introduce MultiMUC, the first multilingual parallel corpus for templatefilling, comprising translations of the classic MUC-4 template fillingbenchmark into five languages: Arabic, Chinese, Farsi, Korean, and Russian. Weobtain automatic translations from a strong multilingual machine translationsystem and manually project the original English annotations into each targetlanguage. For all languages, we also provide human translations for sentencesin the dev and test splits that contain annotated template arguments. Finally,we present baselines on MultiMUC both with state-of-the-art template fillingmodels and with ChatGPT.</description><author>William Gantt, Shabnam Behzad, Hannah YoungEun An, Yunmo Chen, Aaron Steven White, Benjamin Van Durme, Mahsa Yarmohammadi</author><pubDate>Mon, 29 Jan 2024 15:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16209v1</guid></item><item><title>Rating-based Reinforcement Learning</title><link>http://arxiv.org/abs/2307.16348v2</link><description>This paper develops a novel rating-based reinforcement learning approach thatuses human ratings to obtain human guidance in reinforcement learning.Different from the existing preference-based and ranking-based reinforcementlearning paradigms, based on human relative preferences over sample pairs, theproposed rating-based reinforcement learning approach is based on humanevaluation of individual trajectories without relative comparisons betweensample pairs. The rating-based reinforcement learning approach builds on a newprediction model for human ratings and a novel multi-class loss function. Weconduct several experimental studies based on synthetic ratings and real humanratings to evaluate the effectiveness and benefits of the new rating-basedreinforcement learning approach.</description><author>Devin White, Mingkang Wu, Ellen Novoseller, Vernon J. Lawhern, Nicholas Waytowich, Yongcan Cao</author><pubDate>Mon, 29 Jan 2024 15:00:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16348v2</guid></item><item><title>Contracting with a Learning Agent</title><link>http://arxiv.org/abs/2401.16198v1</link><description>Many real-life contractual relations differ completely from the clean, staticmodel at the heart of principal-agent theory. Typically, they involve repeatedstrategic interactions of the principal and agent, taking place underuncertainty and over time. While appealing in theory, players seldom usecomplex dynamic strategies in practice, often preferring to circumventcomplexity and approach uncertainty through learning. We initiate the study ofrepeated contracts with a learning agent, focusing on agents who achieveno-regret outcomes. Optimizing against a no-regret agent is a known open problem in generalgames; we achieve an optimal solution to this problem for a canonical contractsetting, in which the agent's choice among multiple actions leads tosuccess/failure. The solution has a surprisingly simple structure: for some$\alpha &gt; 0$, initially offer the agent a linear contract with scalar $\alpha$,then switch to offering a linear contract with scalar $0$. This switch causesthe agent to ``free-fall'' through their action space and during this timeprovides the principal with non-zero reward at zero cost. Despite apparentexploitation of the agent, this dynamic contract can leave \emph{both} playersbetter off compared to the best static contract. Our results generalize beyondsuccess/failure, to arbitrary non-linear contracts which the principal rescalesdynamically. Finally, we quantify the dependence of our results on knowledge of the timehorizon, and are the first to address this consideration in the study ofstrategizing against learning agents.</description><author>Guru Guruganesh, Yoav Kolumbus, Jon Schneider, Inbal Talgam-Cohen, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Joshua R. Wang, S. Matthew Weinberg</author><pubDate>Mon, 29 Jan 2024 14:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16198v1</guid></item><item><title>Geospatial Disparities: A Case Study on Real Estate Prices in Paris</title><link>http://arxiv.org/abs/2401.16197v1</link><description>Driven by an increasing prevalence of trackers, ever more IoT sensors, andthe declining cost of computing power, geospatial information has come to playa pivotal role in contemporary predictive models. While enhancing prognosticperformance, geospatial data also has the potential to perpetuate manyhistorical socio-economic patterns, raising concerns about a resurgence ofbiases and exclusionary practices, with their disproportionate impacts onsociety. Addressing this, our paper emphasizes the crucial need to identify andrectify such biases and calibration errors in predictive models, particularlyas algorithms become more intricate and less interpretable. The increasinggranularity of geospatial information further introduces ethical concerns, aschoosing different geographical scales may exacerbate disparities akin toredlining and exclusionary zoning. To address these issues, we propose atoolkit for identifying and mitigating biases arising from geospatial data.Extending classical fairness definitions, we incorporate an ordinal regressioncase with spatial attributes, deviating from the binary classification focus.This extension allows us to gauge disparities stemming from data aggregationlevels and advocates for a less interfering correction approach. Illustratingour methodology using a Parisian real estate dataset, we showcase practicalapplications and scrutinize the implications of choosing geographicalaggregation levels for fairness and calibration measures.</description><author>Agathe Fernandes Machado, François Hu, Philipp Ratz, Ewen Gallic, Arthur Charpentier</author><pubDate>Mon, 29 Jan 2024 14:53:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16197v1</guid></item><item><title>Contributing Dimension Structure of Deep Feature for Coreset Selection</title><link>http://arxiv.org/abs/2401.16193v1</link><description>Coreset selection seeks to choose a subset of crucial training samples forefficient learning. It has gained traction in deep learning, particularly withthe surge in training dataset sizes. Sample selection hinges on two mainaspects: a sample's representation in enhancing performance and the role ofsample diversity in averting overfitting. Existing methods typically measureboth the representation and diversity of data based on similarity metrics, suchas L2-norm. They have capably tackled representation via distribution matchingguided by the similarities of features, gradients, or other information betweendata. However, the results of effectively diverse sample selection are mired insub-optimality. This is because the similarity metrics usually simply aggregatedimension similarities without acknowledging disparities among the dimensionsthat significantly contribute to the final similarity. As a result, they fallshort of adequately capturing diversity. To address this, we propose afeature-based diversity constraint, compelling the chosen subset to exhibitmaximum diversity. Our key lies in the introduction of a novel ContributingDimension Structure (CDS) metric. Different from similarity metrics thatmeasure the overall similarity of high-dimensional features, our CDS metricconsiders not only the reduction of redundancy in feature dimensions, but alsothe difference between dimensions that contribute significantly to the finalsimilarity. We reveal that existing methods tend to favor samples with similarCDS, leading to a reduced variety of CDS types within the coreset andsubsequently hindering model performance. In response, we enhance theperformance of five classical selection methods by integrating the CDSconstraint. Our experiments on three datasets demonstrate the generaleffectiveness of the proposed method in boosting existing methods.</description><author>Zhijing Wan, Zhixiang Wang, Yuran Wang, Zheng Wang, Hongyuan Zhu, Shin'ichi Satoh</author><pubDate>Mon, 29 Jan 2024 14:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16193v1</guid></item><item><title>AI prediction of cardiovascular events using opportunistic epicardial adipose tissue assessments from CT calcium score</title><link>http://arxiv.org/abs/2401.16190v1</link><description>Background: Recent studies have used basic epicardial adipose tissue (EAT)assessments (e.g., volume and mean HU) to predict risk ofatherosclerosis-related, major adverse cardiovascular events (MACE).Objectives: Create novel, hand-crafted EAT features, 'fat-omics', to capturethe pathophysiology of EAT and improve MACE prediction. Methods: We segmentedEAT using a previously-validated deep learning method with optional manualcorrection. We extracted 148 radiomic features (morphological, spatial, andintensity) and used Cox elastic-net for feature reduction and prediction ofMACE. Results: Traditional fat features gave marginal prediction(EAT-volume/EAT-mean-HU/ BMI gave C-index 0.53/0.55/0.57, respectively).Significant improvement was obtained with 15 fat-omics features (C-index=0.69,test set). High-risk features includedvolume-of-voxels-having-elevated-HU-[-50, -30-HU] and HU-negative-skewness,both of which assess high HU, which as been implicated in fat inflammation.Other high-risk features include kurtosis-of-EAT-thickness, reflecting theheterogeneity of thicknesses, and EAT-volume-in-the-top-25%-of-the-heart,emphasizing adipose near the proximal coronary arteries. Kaplan-Meyer plots ofCox-identified, high- and low-risk patients were well separated with the medianof the fat-omics risk, while high-risk group having HR 2.4 times that of thelow-risk group (P&lt;0.001). Conclusion: Preliminary findings indicate anopportunity to use more finely tuned, explainable assessments on EAT forimproved cardiovascular risk prediction.</description><author>Tao Hu, Joshua Freeze, Prerna Singh, Justin Kim, Yingnan Song, Hao Wu, Juhwan Lee, Sadeer Al-Kindi, Sanjay Rajagopalan, David L. Wilson, Ammar Hoori</author><pubDate>Mon, 29 Jan 2024 14:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16190v1</guid></item><item><title>FIMP: Future Interaction Modeling for Multi-Agent Motion Prediction</title><link>http://arxiv.org/abs/2401.16189v1</link><description>Multi-agent motion prediction is a crucial concern in autonomous driving, yetit remains a challenge owing to the ambiguous intentions of dynamic agents andtheir intricate interactions. Existing studies have attempted to captureinteractions between road entities by using the definite data in historytimesteps, as future information is not available and involves highuncertainty. However, without sufficient guidance for capturing future statesof interacting agents, they frequently produce unrealistic trajectory overlaps.In this work, we propose Future Interaction modeling for Motion Prediction(FIMP), which captures potential future interactions in an end-to-end manner.FIMP adopts a future decoder that implicitly extracts the potential futureinformation in an intermediate feature-level, and identifies the interactingentity pairs through future affinity learning and top-k filtering strategy.Experiments show that our future interaction modeling improves the performanceremarkably, leading to superior performance on the Argoverse motion forecastingbenchmark.</description><author>Sungmin Woo, Minjung Kim, Donghyeong Kim, Sungjun Jang, Sangyoun Lee</author><pubDate>Mon, 29 Jan 2024 14:41:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16189v1</guid></item><item><title>PiClick: Picking the desired mask in click-based interactive segmentation</title><link>http://arxiv.org/abs/2304.11609v4</link><description>Click-based interactive segmentation aims to generate target masks via humanclicking, which facilitates efficient pixel-level annotation and image editing.In such a task, target ambiguity remains a problem hindering the accuracy andefficiency of segmentation. That is, in scenes with rich context, one click maycorrespond to multiple potential targets, while most previous interactivesegmentors only generate a single mask and fail to deal with target ambiguity.In this paper, we propose a novel interactive segmentation network namedPiClick, to yield all potentially reasonable masks and suggest the mostplausible one for the user. Specifically, PiClick utilizes a Transformer-basedarchitecture to generate all potential target masks by mutually interactivemask queries. Moreover, a Target Reasoning module is designed in PiClick toautomatically suggest the user-desired mask from all candidates, relievingtarget ambiguity and extra-human efforts. Extensive experiments on 9interactive segmentation datasets demonstrate PiClick performs favorablyagainst previous state-of-the-arts considering the segmentation results.Moreover, we show that PiClick effectively reduces human efforts in annotatingand picking the desired masks. To ease the usage and inspire future research,we release the source code of PiClick together with a plug-and-play annotationtool at https://github.com/cilinyan/PiClick.</description><author>Cilin Yan, Haochen Wang, Jie Liu, Xiaolong Jiang, Yao Hu, Xu Tang, Guoliang Kang, Efstratios Gavves</author><pubDate>Mon, 29 Jan 2024 14:33:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11609v4</guid></item><item><title>An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project</title><link>http://arxiv.org/abs/2401.16186v1</link><description>Large Language Models (LLMs) represent a leap in artificial intelligence,excelling in tasks using human language(s). Although the main focus ofgeneral-purpose LLMs is not code generation, they have shown promising resultsin the domain. However, the usefulness of LLMs in an academic softwareengineering project has not been fully explored yet. In this study, we explorethe usefulness of LLMs for 214 students working in teams consisting of up tosix members. Notably, in the academic course through which this study isconducted, students were encouraged to integrate LLMs into their developmenttool-chain, in contrast to most other academic courses that explicitly prohibitthe use of LLMs. In this paper, we analyze the AI-generated code, prompts used for codegeneration, and the human intervention levels to integrate the code into thecode base. We also conduct a perception study to gain insights into theperceived usefulness, influencing factors, and future outlook of LLM from acomputer science student's perspective. Our findings suggest that LLMs can playa crucial role in the early stages of software development, especially ingenerating foundational code structures, and helping with syntax and errordebugging. These insights provide us with a framework on how to effectivelyutilize LLMs as a tool to enhance the productivity of software engineeringstudents, and highlight the necessity of shifting the educational focus towardpreparing students for successful human-AI collaboration.</description><author>Sanka Rasnayaka, Guanlin Wang, Ridwan Shariffdeen, Ganesh Neelakanta Iyer</author><pubDate>Mon, 29 Jan 2024 14:32:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16186v1</guid></item><item><title>LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning</title><link>http://arxiv.org/abs/2401.16185v1</link><description>Large language models (LLMs) have demonstrated significant poten- tial formany downstream tasks, including those requiring human- level intelligence,such as vulnerability detection. However, recent attempts to use LLMs forvulnerability detection are still prelim- inary, as they lack an in-depthunderstanding of a subject LLM's vulnerability reasoning capability - whetherit originates from the model itself or from external assistance, such asinvoking tool sup- port and retrieving vulnerability knowledge. In this paper,we aim to decouple LLMs' vulnerability reason- ing capability from their othercapabilities, including the ability to actively seek additional information(e.g., via function calling in SOTA models), adopt relevant vulnerabilityknowledge (e.g., via vector-based matching and retrieval), and followinstructions to out- put structured results. To this end, we propose a unifiedevaluation framework named LLM4Vuln, which separates LLMs' vulnerabilityreasoning from their other capabilities and evaluates how LLMs' vulnerabilityreasoning could be enhanced when combined with the enhancement of othercapabilities. To demonstrate the effectiveness of LLM4Vuln, we have designedcontrolled experiments using 75 ground-truth smart contract vulnerabilities,which were extensively audited as high-risk on Code4rena from August toNovember 2023, and tested them in 4,950 different scenarios across threerepresen- tative LLMs (GPT-4, Mixtral, and Code Llama). Our results not onlyreveal ten findings regarding the varying effects of knowledge en- hancement,context supplementation, prompt schemes, and models but also enable us toidentify 9 zero-day vulnerabilities in two pilot bug bounty programs with over1,000 USD being awarded.</description><author>Yuqiang Sun, Daoyuan Wu, Yue Xue, Han Liu, Wei Ma, Lyuye Zhang, Miaolei Shi, Yang Liu</author><pubDate>Mon, 29 Jan 2024 14:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16185v1</guid></item><item><title>On the Semantics of LM Latent Space: A Vocabulary-defined Approach</title><link>http://arxiv.org/abs/2401.16184v1</link><description>In the realm of deep learning, understanding the latent space of languagemodels (LMs) like transformers is crucial for refining their performance andinterpretability. However, existing analyses often fall short in providingabsolute and model-centric insights into LM semantics, and neglect essentialaspects of LM adaption. In response, we introduce a pioneering method calledvocabulary-defined semantics, which establishes a fixed reference frame withinthe LM latent space, ensuring absolute semantic analysis grounded in LMvocabulary. Our approach transcends prior relative analyses, leveraging LMvocabulary for model-centric insights. Furthermore, we propose a noveltechnique to compute logits, emphasizing differentiability and local isotropy,and introduce a neural clustering module for semantically calibrating datarepresentations during LM adaptation. Through extensive experiments acrossdiverse text understanding datasets, our approach surpasses state-of-the-artmethods of retrieval-augmented generation and parameters-efficient finetuning,showcasing its efficacy and broad applicability. Our findings not only shedlight on LM mechanics but also offer practical solutions for enhancing LMperformance and interpretability.</description><author>Jian Gu, Chunyang Chen, Aldeida Aleti</author><pubDate>Mon, 29 Jan 2024 14:29:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16184v1</guid></item><item><title>SSL-WM: A Black-Box Watermarking Approach for Encoders Pre-trained by Self-supervised Learning</title><link>http://arxiv.org/abs/2209.03563v2</link><description>Recent years have witnessed tremendous success in Self-Supervised Learning(SSL), which has been widely utilized to facilitate various downstream tasks inComputer Vision (CV) and Natural Language Processing (NLP) domains. However,attackers may steal such SSL models and commercialize them for profit, makingit crucial to verify the ownership of the SSL models. Most existing ownershipprotection solutions (e.g., backdoor-based watermarks) are designed forsupervised learning models and cannot be used directly since they require thatthe models' downstream tasks and target labels be known and available duringwatermark embedding, which is not always possible in the domain of SSL. Toaddress such a problem, especially when downstream tasks are diverse andunknown during watermark embedding, we propose a novel black-box watermarkingsolution, named SSL-WM, for verifying the ownership of SSL models. SSL-WM mapswatermarked inputs of the protected encoders into an invariant representationspace, which causes any downstream classifier to produce expected behavior,thus allowing the detection of embedded watermarks. We evaluate SSL-WM onnumerous tasks, such as CV and NLP, using different SSL models bothcontrastive-based and generative-based. Experimental results demonstrate thatSSL-WM can effectively verify the ownership of stolen SSL models in variousdownstream tasks. Furthermore, SSL-WM is robust against model fine-tuning,pruning, and input preprocessing attacks. Lastly, SSL-WM can also evadedetection from evaluated watermark detection approaches, demonstrating itspromising application in protecting the ownership of SSL models.</description><author>Peizhuo Lv, Pan Li, Shenchen Zhu, Shengzhi Zhang, Kai Chen, Ruigang Liang, Chang Yue, Fan Xiang, Yuling Cai, Hualong Ma, Yingjun Zhang, Guozhu Meng</author><pubDate>Mon, 29 Jan 2024 14:25:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.03563v2</guid></item></channel></rss>