<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 23 Oct 2023 13:37:21 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Neural-Base Music Generation for Intelligence Duplication</title><link>http://arxiv.org/abs/2310.13691v1</link><description>There are two aspects of machine learning and artificial intelligence: (1)interpreting information, and (2) inventing new useful information. Muchadvance has been made for (1) with a focus on pattern recognition techniques(e.g., interpreting visual data). This paper focuses on (2) with intelligentduplication (ID) for invention. We explore the possibility of learning aspecific individual's creative reasoning in order to leverage the learnedexpertise and talent to invent new information. More specifically, we employ adeep learning system to learn from the great composer Beethoven and capture hiscomposition ability in a hash-based knowledge base. This new form of knowledgebase provides a reasoning facility to drive the music composition through anovel music generation method.</description><author>Jacob Galajda, Kien Hua</author><pubDate>Fri, 20 Oct 2023 18:52:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13691v1</guid></item><item><title>Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports</title><link>http://arxiv.org/abs/2309.12273v2</link><description>Rapid and accurate identification of Venous thromboembolism (VTE), a severecardiovascular condition including deep vein thrombosis (DVT) and pulmonaryembolism (PE), is important for effective treatment. Leveraging NaturalLanguage Processing (NLP) on radiology reports, automated methods have shownpromising advancements in identifying VTE events from retrospective datacohorts or aiding clinical experts in identifying VTE events from radiologyreports. However, effectively training Deep Learning (DL) and the NLP models ischallenging due to limited labeled medical text data, the complexity andheterogeneity of radiology reports, and data imbalance. This study proposesnovel method combinations of DL methods, along with data augmentation, adaptivepre-trained NLP model selection, and a clinical expert NLP rule-basedclassifier, to improve the accuracy of VTE identification in unstructured(free-text) radiology reports. Our experimental results demonstrate the model'sefficacy, achieving an impressive 97\% accuracy and 97\% F1 score in predictingDVT, and an outstanding 98.3\% accuracy and 98.4\% F1 score in predicting PE.These findings emphasize the model's robustness and its potential tosignificantly contribute to VTE research.</description><author>Jamie Deng, Yusen Wu, Hilary Hayssen, Brain Englum, Aman Kankaria, Minerva Mayorga-Carlin, Shalini Sahoo, John Sorkin, Brajesh Lal, Yelena Yesha, Phuong Nguyen</author><pubDate>Fri, 20 Oct 2023 18:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12273v2</guid></item><item><title>Exploring Linguistic Probes for Morphological Generalization</title><link>http://arxiv.org/abs/2310.13686v1</link><description>Modern work on the cross-linguistic computational modeling of morphologicalinflection has typically employed language-independent data splittingalgorithms. In this paper, we supplement that approach with language-specificprobes designed to test aspects of morphological generalization. Testing theseprobes on three morphologically distinct languages, English, Spanish, andSwahili, we find evidence that three leading morphological inflection systemsemploy distinct generalization strategies over conjugational classes andfeature sets on both orthographic and phonologically transcribed inputs.</description><author>Jordan Kodner, Salam Khalifa, Sarah Payne</author><pubDate>Fri, 20 Oct 2023 18:45:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13686v1</guid></item><item><title>CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages</title><link>http://arxiv.org/abs/2310.13683v1</link><description>This work introduces CAPIVARA, a cost-efficient framework designed to enhancethe performance of multilingual CLIP models in low-resource languages. WhileCLIP has excelled in zero-shot vision-language tasks, the resource-intensivenature of model training remains challenging. Many datasets lack linguisticdiversity, featuring solely English descriptions for images. CAPIVARA addressesthis by augmenting text data using image captioning and machine translation togenerate multiple synthetic captions in low-resource languages. We optimize thetraining pipeline with LiT, LoRA, and gradient checkpointing to alleviate thecomputational cost. Through extensive experiments, CAPIVARA emerges as state ofthe art in zero-shot tasks involving images and Portuguese texts. We show thepotential for significant improvements in other low-resource languages,achieved by fine-tuning the pre-trained multilingual CLIP using CAPIVARA on asingle GPU for 2 hours. Our model and code is available athttps://github.com/hiaac-nlp/CAPIVARA.</description><author>Gabriel Oliveira dos Santos, Diego Alysson Moreia, Alef Iury Ferreira, Jhessica Silva, Luiz Pereira, Pedro Bueno, Thiago Sousa, Helena Maia, Nádia Da Silva, Esther Colombini, Helio Pedrini, Sandra Avila</author><pubDate>Fri, 20 Oct 2023 18:44:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13683v1</guid></item><item><title>Optimizing Retrieval-augmented Reader Models via Token Elimination</title><link>http://arxiv.org/abs/2310.13682v1</link><description>Fusion-in-Decoder (FiD) is an effective retrieval-augmented language modelapplied across a variety of open-domain tasks, such as question answering, factchecking, etc. In FiD, supporting passages are first retrieved and thenprocessed using a generative model (Reader), which can cause a significantbottleneck in decoding time, particularly with long outputs. In this work, weanalyze the contribution and necessity of all the retrieved passages to theperformance of reader models, and propose eliminating some of the retrievedinformation, at the token level, that might not contribute essentialinformation to the answer generation process. We demonstrate that our methodcan reduce run-time by up to 62.2%, with only a 2% reduction in performance,and in some cases, even improve the performance results.</description><author>Moshe Berchansky, Peter Izsak, Avi Caciularu, Ido Dagan, Moshe Wasserblat</author><pubDate>Fri, 20 Oct 2023 18:41:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13682v1</guid></item><item><title>RealFM: A Realistic Mechanism to Incentivize Data Contribution and Device Participation</title><link>http://arxiv.org/abs/2310.13681v1</link><description>Edge device participation in federating learning (FL) has been typicallystudied under the lens of device-server communication (e.g., device dropout)and assumes an undying desire from edge devices to participate in FL. As aresult, current FL frameworks are flawed when implemented in real-worldsettings, with many encountering the free-rider problem. In a step to push FLtowards realistic settings, we propose RealFM: the first truly federatedmechanism which (1) realistically models device utility, (2) incentivizes datacontribution and device participation, and (3) provably removes the free-riderphenomena. RealFM does not require data sharing and allows for a non-linearrelationship between model accuracy and utility, which improves the utilitygained by the server and participating devices compared to non-participatingdevices as well as devices participating in other FL mechanisms. On real-worlddata, RealFM improves device and server utility, as well as data contribution,by up to 3 magnitudes and 7x respectively compared to baseline mechanisms.</description><author>Marco Bornstein, Amrit Singh Bedi, Anit Kumar Sahu, Furqan Khan, Furong Huang</author><pubDate>Fri, 20 Oct 2023 18:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13681v1</guid></item><item><title>Text-guided 3D Human Generation from 2D Collections</title><link>http://arxiv.org/abs/2305.14312v2</link><description>3D human modeling has been widely used for engaging interaction in gaming,film, and animation. The customization of these characters is crucial forcreativity and scalability, which highlights the importance of controllability.In this work, we introduce Text-guided 3D Human Generation (\texttt{T3H}),where a model is to generate a 3D human, guided by the fashion description.There are two goals: 1) the 3D human should render articulately, and 2) itsoutfit is controlled by the given text. To address this \texttt{T3H} task, wepropose Compositional Cross-modal Human (CCH). CCH adopts cross-modal attentionto fuse compositional human rendering with the extracted fashion semantics.Each human body part perceives relevant textual guidance as its visualpatterns. We incorporate the human prior and semantic discrimination to enhance3D geometry transformation and fine-grained consistency, enabling it to learnfrom 2D collections for data efficiency. We conduct evaluations on DeepFashionand SHHQ with diverse fashion attributes covering the shape, fabric, and colorof upper and lower clothing. Extensive experiments demonstrate that CCHachieves superior results for \texttt{T3H} with high efficiency.</description><author>Tsu-Jui Fu, Wenhan Xiong, Yixin Nie, Jingyu Liu, Barlas Oğuz, William Yang Wang</author><pubDate>Fri, 20 Oct 2023 18:39:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14312v2</guid></item><item><title>Improving Long-form Speech Translation through Segmentation with Large Language Models and Finite State Decoding Constraints</title><link>http://arxiv.org/abs/2310.13678v1</link><description>One challenge in spoken language translation is that plenty of spoken contentis long-form, but short units are necessary for obtaining high-qualitytranslations. To address this mismatch, we adapt large language models (LLM) tosplit long ASR transcripts into segments that can be independently translatedso as to maximize the overall translation quality. To combat the tendency ofhallucination by LLMs, we incorporate finite-state constraints during decodingto eliminate invalid outputs. We discover that LLMs are adaptable totranscripts containing ASR errors through prompt-tuning or fine-tuning. Incomparison to a state-of-the-art automatic punctuation baseline, our best LLMimproves the average BLEU for English-German, English-Spanish, andEnglish-Arabic TED talk translation in 9 test sets by 2.9 points, just byimproving segmentation.</description><author>Arya D. McCarthy, Hao Zhang, Shankar Kumar, Felix Stahlberg, Ke Wu</author><pubDate>Fri, 20 Oct 2023 18:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13678v1</guid></item><item><title>Information Value: Measuring Utterance Predictability as Distance from Plausible Alternatives</title><link>http://arxiv.org/abs/2310.13676v1</link><description>We present information value, a measure which quantifies the predictabilityof an utterance relative to a set of plausible alternatives. We introduce amethod to obtain interpretable estimates of information value using neural textgenerators, and exploit their psychometric predictive power to investigate thedimensions of predictability that drive human comprehension behaviour.Information value is a stronger predictor of utterance acceptability in writtenand spoken dialogue than aggregates of token-level surprisal and it iscomplementary to surprisal for predicting eye-tracked reading times.</description><author>Mario Giulianelli, Sarenne Wallbridge, Raquel Fernández</author><pubDate>Fri, 20 Oct 2023 18:25:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13676v1</guid></item><item><title>On Synthetic Data for Back Translation</title><link>http://arxiv.org/abs/2310.13675v1</link><description>Back translation (BT) is one of the most significant technologies in NMTresearch fields. Existing attempts on BT share a common characteristic: theyemploy either beam search or random sampling to generate synthetic data with abackward model but seldom work studies the role of synthetic data in theperformance of BT. This motivates us to ask a fundamental question: {\em whatkind of synthetic data contributes to BT performance?} Through both theoreticaland empirical studies, we identify two key factors on synthetic datacontrolling the back-translation NMT performance, which are quality andimportance. Furthermore, based on our findings, we propose a simple yeteffective method to generate synthetic data to better trade off both factors soas to yield a better performance for BT. We run extensive experiments on WMT14DE-EN, EN-DE, and RU-EN benchmark tasks. By employing our proposed method togenerate synthetic data, our BT model significantly outperforms the standard BTbaselines (i.e., beam and sampling based methods for data generation), whichproves the effectiveness of our proposed methods.</description><author>Jiahao Xu, Yubin Ruan, Wei Bi, Guoping Huang, Shuming Shi, Lihui Chen, Lemao Liu</author><pubDate>Fri, 20 Oct 2023 18:24:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13675v1</guid></item><item><title>Using Human-like Mechanism to Weaken Effect of Pre-training Weight Bias in Face-Recognition Convolutional Neural Network</title><link>http://arxiv.org/abs/2310.13674v1</link><description>Convolutional neural network (CNN), as an important model in artificialintelligence, has been widely used and studied in different disciplines. Thecomputational mechanisms of CNNs are still not fully revealed due to the theircomplex nature. In this study, we focused on 4 extensively studied CNNs(AlexNet, VGG11, VGG13, and VGG16) which has been analyzed as human-like modelsby neuroscientists with ample evidence. We trained these CNNs to emotionvalence classification task by transfer learning. Comparing their performancewith human data, the data unveiled that these CNNs would partly perform ashuman does. We then update the object-based AlexNet using self-attentionmechanism based on neuroscience and behavioral data. The updated FE-AlexNetoutperformed all the other tested CNNs and closely resembles human perception.The results further unveil the computational mechanisms of these CNNs.Moreover, this study offers a new paradigm to better understand and improve CNNperformance via human data.</description><author>Haojiang Ying, Yi-Fan Li, Yiyang Chen</author><pubDate>Fri, 20 Oct 2023 18:22:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13674v1</guid></item><item><title>StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models</title><link>http://arxiv.org/abs/2310.13673v1</link><description>Large Language Models (LLMs) have been observed to encode and perpetuateharmful associations present in the training data. We propose a theoreticallygrounded framework called StereoMap to gain insights into their perceptions ofhow demographic groups have been viewed by society. The framework is groundedin the Stereotype Content Model (SCM); a well-established theory frompsychology. According to SCM, stereotypes are not all alike. Instead, thedimensions of Warmth and Competence serve as the factors that delineate thenature of stereotypes. Based on the SCM theory, StereoMap maps LLMs'perceptions of social groups (defined by socio-demographic features) using thedimensions of Warmth and Competence. Furthermore, the framework enables theinvestigation of keywords and verbalizations of reasoning of LLMs' judgments touncover underlying factors influencing their perceptions. Our results show thatLLMs exhibit a diverse range of perceptions towards these groups, characterizedby mixed evaluations along the dimensions of Warmth and Competence.Furthermore, analyzing the reasonings of LLMs, our findings indicate that LLMsdemonstrate an awareness of social disparities, often stating statistical dataand research findings to support their reasoning. This study contributes to theunderstanding of how LLMs perceive and represent social groups, shedding lighton their potential biases and the perpetuation of harmful associations.</description><author>Sullam Jeoung, Yubin Ge, Jana Diesner</author><pubDate>Fri, 20 Oct 2023 18:22:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13673v1</guid></item><item><title>Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models</title><link>http://arxiv.org/abs/2310.13671v1</link><description>*Data Synthesis* is a promising way to train a small model with very littlelabeled data. One approach for data synthesis is to leverage the rich knowledgefrom large language models to synthesize pseudo training examples for smallmodels, making it possible to achieve both data and compute efficiency at thesame time. However, a key challenge in data synthesis is that the synthesizeddataset often suffers from a large distributional discrepancy from the *realtask* data distribution. Thus, in this paper, we propose *Synthesis Step byStep* (**S3**), a data synthesis framework that shrinks this distribution gapby iteratively extrapolating the errors made by a small model trained on thesynthesized dataset on a small real-world validation dataset using a largelanguage model. Extensive experiments on multiple NLP tasks show that ourapproach improves the performance of a small model by reducing the gap betweenthe synthetic dataset and the real data, resulting in significant improvementcompared to several baselines: 9.48% improvement compared to ZeroGen and 2.73%compared to GoldGen, and at most 15.17% improvement compared to the small modeltrained on human-annotated data.</description><author>Ruida Wang, Wangchunshu Zhou, Mrinmaya Sachan</author><pubDate>Fri, 20 Oct 2023 18:14:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13671v1</guid></item><item><title>ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot Neural Radiance Fields</title><link>http://arxiv.org/abs/2310.13670v1</link><description>Novel view synthesis has recently made significant progress with the adventof Neural Radiance Fields (NeRF). DietNeRF is an extension of NeRF that aims toachieve this task from only a few images by introducing a new loss function forunknown viewpoints with no input images. The loss function assumes that apre-trained feature extractor should output the same feature even if inputimages are captured at different viewpoints since the images contain the sameobject. However, while that assumption is ideal, in reality, it is known thatas viewpoints continuously change, also feature vectors continuously change.Thus, the assumption can harm training. To avoid this harmful training, wepropose ManifoldNeRF, a method for supervising feature vectors at unknownviewpoints using interpolated features from neighboring known viewpoints. Sincethe method provides appropriate supervision for each unknown viewpoint by theinterpolated features, the volume representation is learned better thanDietNeRF. Experimental results show that the proposed method performs betterthan others in a complex scene. We also experimented with several subsets ofviewpoints from a set of viewpoints and identified an effective set ofviewpoints for real environments. This provided a basic policy of viewpointpatterns for real-world application. The code is available athttps://github.com/haganelego/ManifoldNeRF_BMVC2023</description><author>Daiju Kanaoka, Motoharu Sonogashira, Hakaru Tamukoh, Yasutomo Kawanishi</author><pubDate>Fri, 20 Oct 2023 18:13:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13670v1</guid></item><item><title>Automatic Unit Test Data Generation and Actor-Critic Reinforcement Learning for Code Synthesis</title><link>http://arxiv.org/abs/2310.13669v1</link><description>The advent of large pre-trained language models in the domain of CodeSynthesis has shown remarkable performance on various benchmarks, treating theproblem of Code Generation in a fashion similar to Natural Language Generation,trained with a Language Modelling (LM) objective. In addition, the property ofprogramming language code being precisely evaluable with respect to itssemantics -- through the use of Unit Tests to check its functional correctness-- lends itself to using Reinforcement Learning (RL) as a further trainingparadigm. Previous work has shown that RL can be applied as such to improvemodels' coding capabilities; however, such RL-based methods rely on a rewardsignal based on defined Unit Tests, which are much harder to obtain compared tothe huge crawled code datasets used in LM objectives. In this work, we presenta novel approach to automatically obtain data consisting of function signaturesand associated Unit Tests, suitable for RL training of Code Synthesis models.We also introduce a straightforward, simple yet effective Actor-Critic RLtraining scheme and show that it, in conjunction with automatically generatedtraining data, leads to improvement of a pre-trained code language model'sperformance by up to 9.9% improvement over the original underlying codesynthesis LM, and up to 4.3% over RL-based models trained with standard PPO orCodeRL.</description><author>Philip John Gorinski, Matthieu Zimmer, Gerasimos Lampouras, Derrick Goh Xin Deik, Ignacio Iacobacci</author><pubDate>Fri, 20 Oct 2023 18:13:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13669v1</guid></item><item><title>Explainability, Interpretability, Depression detection, Social Media</title><link>http://arxiv.org/abs/2310.13664v1</link><description>Users of social platforms often perceive these sites as supportive spaces topost about their mental health issues. Those conversations contain importanttraces about individuals' health risks. Recently, researchers have exploitedthis online information to construct mental health detection models, which aimto identify users at risk on platforms like Twitter, Reddit or Facebook. Mostof these models are centred on achieving good classification results, ignoringthe explainability and interpretability of the decisions. Recent research haspointed out the importance of using clinical markers, such as the use ofsymptoms, to improve trust in the computational models by health professionals.In this paper, we propose using transformer-based architectures to detect andexplain the appearance of depressive symptom markers in the users' writings. Wepresent two approaches: $i)$ train a model to classify, and another one toexplain the classifier's decision separately and $ii)$ unify the two taskssimultaneously using a single model. Additionally, for this latter manner, wealso investigated the performance of recent conversational LLMs when usingin-context learning. Our natural language explanations enable clinicians tointerpret the models' decisions based on validated symptoms, enhancing trust inthe automated process. We evaluate our approach using recent symptom-baseddatasets, employing both offline and expert-in-the-loop metrics to assess thequality of the explanations generated by our models. The experimental resultsshow that it is possible to achieve good classification results whilegenerating interpretable symptom-based explanations.</description><author>Eliseo Bao Souto, Anxo Pérez, Javier Parapar</author><pubDate>Fri, 20 Oct 2023 18:05:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13664v1</guid></item><item><title>Arabic Dialect Identification under Scrutiny: Limitations of Single-label Classification</title><link>http://arxiv.org/abs/2310.13661v1</link><description>Automatic Arabic Dialect Identification (ADI) of text has gained greatpopularity since it was introduced in the early 2010s. Multiple datasets weredeveloped, and yearly shared tasks have been running since 2018. However, ADIsystems are reported to fail in distinguishing between the micro-dialects ofArabic. We argue that the currently adopted framing of the ADI task as asingle-label classification problem is one of the main reasons for that. Wehighlight the limitation of the incompleteness of the Dialect labels anddemonstrate how it impacts the evaluation of ADI systems. A manual erroranalysis for the predictions of an ADI, performed by 7 native speakers ofdifferent Arabic dialects, revealed that $\approx$ 66% of the validated errorsare not true errors. Consequently, we propose framing ADI as a multi-labelclassification task and give recommendations for designing new ADI datasets.</description><author>Amr Keleg, Walid Magdy</author><pubDate>Fri, 20 Oct 2023 18:04:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13661v1</guid></item><item><title>The Past, Current, and Future of Neonatal Intensive Care Units with Artificial Intelligence</title><link>http://arxiv.org/abs/2302.00225v2</link><description>Machine learning and deep learning are two subsets of artificial intelligencethat involve teaching computers to learn and make decisions from any sort ofdata. Most recent developments in artificial intelligence are coming from deeplearning, which has proven revolutionary in almost all fields, from computervision to health sciences. The effects of deep learning in medicine havechanged the conventional ways of clinical application significantly. Althoughsome sub-fields of medicine, such as pediatrics, have been relatively slow inreceiving the critical benefits of deep learning, related research inpediatrics has started to accumulate to a significant level, too. Hence, inthis paper, we review recently developed machine learning and deeplearning-based solutions for neonatology applications. We systematicallyevaluate the roles of both classical machine learning and deep learning inneonatology applications, define the methodologies, including algorithmicdevelopments, and describe the remaining challenges in the assessment ofneonatal diseases by using PRISMA 2020 guidelines. To date, the primary areasof focus in neonatology regarding AI applications have included survivalanalysis, neuroimaging, analysis of vital parameters and biosignals, andretinopathy of prematurity diagnosis. We have categorically summarized 106research articles from 1996 to 2022 and discussed their pros and cons,respectively. In this systematic review, we aimed to further enhance thecomprehensiveness of the study. We also discuss possible directions for new AImodels and the future of neonatology with the rising power of AI, suggestingroadmaps for the integration of AI into neonatal intensive care units.</description><author>Elif Keles, Ulas Bagci</author><pubDate>Fri, 20 Oct 2023 18:02:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00225v2</guid></item><item><title>DataComp: In search of the next generation of multimodal datasets</title><link>http://arxiv.org/abs/2304.14108v5</link><description>Multimodal datasets are a critical component in recent breakthroughs such asStable Diffusion and GPT-4, yet their design does not receive the same researchattention as model architectures or training algorithms. To address thisshortcoming in the ML ecosystem, we introduce DataComp, a testbed for datasetexperiments centered around a new candidate pool of 12.8 billion image-textpairs from Common Crawl. Participants in our benchmark design new filteringtechniques or curate new data sources and then evaluate their new dataset byrunning our standardized CLIP training code and testing the resulting model on38 downstream test sets. Our benchmark consists of multiple compute scalesspanning four orders of magnitude, which enables the study of scaling trendsand makes the benchmark accessible to researchers with varying resources. Ourbaseline experiments show that the DataComp workflow leads to better trainingsets. In particular, our best baseline, DataComp-1B, enables training a CLIPViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperformingOpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same trainingprocedure and compute. We release DataComp and all accompanying code atwww.datacomp.ai.</description><author>Samir Yitzhak Gadre, Gabriel Ilharco, Alex Fang, Jonathan Hayase, Georgios Smyrnis, Thao Nguyen, Ryan Marten, Mitchell Wortsman, Dhruba Ghosh, Jieyu Zhang, Eyal Orgad, Rahim Entezari, Giannis Daras, Sarah Pratt, Vivek Ramanujan, Yonatan Bitton, Kalyani Marathe, Stephen Mussmann, Richard Vencu, Mehdi Cherti, Ranjay Krishna, Pang Wei Koh, Olga Saukh, Alexander Ratner, Shuran Song, Hannaneh Hajishirzi, Ali Farhadi, Romain Beaumont, Sewoong Oh, Alex Dimakis, Jenia Jitsev, Yair Carmon, Vaishaal Shankar, Ludwig Schmidt</author><pubDate>Fri, 20 Oct 2023 18:01:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14108v5</guid></item><item><title>Benchmarking and Improving Text-to-SQL Generation under Ambiguity</title><link>http://arxiv.org/abs/2310.13659v1</link><description>Research in Text-to-SQL conversion has been largely benchmarked againstdatasets where each text query corresponds to one correct SQL. However, naturallanguage queries over real-life databases frequently involve significantambiguity about the intended SQL due to overlapping schema names and multipleconfusing relationship paths. To bridge this gap, we develop a novel benchmarkcalled AmbiQT with over 3000 examples where each text is interpretable as twoplausible SQLs due to lexical and/or structural ambiguity. When faced with ambiguity, an ideal top-$k$ decoder should generate all validinterpretations for possible disambiguation by the user. We evaluate severalText-to-SQL systems and decoding algorithms, including those employingstate-of-the-art LLMs, and find them to be far from this ideal. The primaryreason is that the prevalent beam search algorithm and its variants, treat SQLqueries as a string and produce unhelpful token-level diversity in the top-$k$. We propose LogicalBeam, a new decoding algorithm that navigates the SQL logicspace using a blend of plan-based template generation and constrainedinfilling. Counterfactually generated plans diversify templates whilein-filling with a beam-search that branches solely on schema names providesvalue diversity. LogicalBeam is up to $2.5$ times more effective thanstate-of-the-art models at generating all candidate SQLs in the top-$k$ rankedoutputs. It also enhances the top-$5$ Exact and Execution Match Accuracies onSPIDER and Kaggle DBQA.</description><author>Adithya Bhaskar, Tushar Tomar, Ashutosh Sathe, Sunita Sarawagi</author><pubDate>Fri, 20 Oct 2023 18:00:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13659v1</guid></item><item><title>An experimental study for early diagnosing Parkinson's disease using machine learning</title><link>http://arxiv.org/abs/2310.13654v1</link><description>One of the most catastrophic neurological disorders worldwide is Parkinson'sDisease. Along with it, the treatment is complicated and abundantly expensive.The only effective action to control the progression is diagnosing it in theearly stage. However, this is challenging because early detection necessitatesa large and complex clinical study. This experimental work used MachineLearning techniques to automate the early detection of Parkinson's Disease fromclinical characteristics, voice features and motor examination. In this study,we develop ML models utilizing a public dataset of 130 individuals, 30 of whomare untreated Parkinson's Disease patients, 50 of whom are Rapid Eye MovementSleep Behaviour Disorder patients who are at a greater risk of contractingParkinson's Disease, and 50 of whom are Healthy Controls. We use MinMax Scalerto rescale the data points, Local Outlier Factor to remove outliers, and SMOTEto balance existing class frequency. Afterwards, apply a number of MachineLearning techniques. We implement the approaches in such a way that dataleaking and overfitting are not possible. Finally, obtained 100% accuracy inclassifying PD and RBD patients, as well as 92% accuracy in classifying PD andHC individuals.</description><author>Md. Taufiqul Haque Khan Tusar, Md. Touhidul Islam, Abul Hasnat Sakil</author><pubDate>Fri, 20 Oct 2023 17:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13654v1</guid></item><item><title>Optimal Transport for Measures with Noisy Tree Metric</title><link>http://arxiv.org/abs/2310.13653v1</link><description>We study optimal transport (OT) problem for probability measures supported ona tree metric space. It is known that such OT problem (i.e., tree-Wasserstein(TW)) admits a closed-form expression, but depends fundamentally on theunderlying tree structure over supports of input measures. In practice, thegiven tree structure may be, however, perturbed due to noisy or adversarialmeasurements. In order to mitigate this issue, we follow the max-min robust OTapproach which considers the maximal possible distances between two inputmeasures over an uncertainty set of tree metrics. In general, this approach ishard to compute, even for measures supported in $1$-dimensional space, due toits non-convexity and non-smoothness which hinders its practical applications,especially for large-scale settings. In this work, we propose \emph{noveluncertainty sets of tree metrics} from the lens of edge deletion/addition whichcovers a diversity of tree structures in an elegant framework. Consequently, bybuilding upon the proposed uncertainty sets, and leveraging the tree structureover supports, we show that the max-min robust OT also admits a closed-formexpression for a fast computation as its counterpart standard OT (i.e., TW).Furthermore, we demonstrate that the max-min robust OT satisfies the metricproperty and is negative definite. We then exploit its negative definiteness topropose \emph{positive definite kernels} and test them in several simulationson various real-world datasets on document classification and topological dataanalysis for measures with noisy tree metric.</description><author>Tam Le, Truyen Nguyen, Kenji Fukumizu</author><pubDate>Fri, 20 Oct 2023 17:56:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13653v1</guid></item><item><title>BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues</title><link>http://arxiv.org/abs/2310.13650v1</link><description>Interacting with human via high-quality multi-turn dialogues is a key featureof large language models (LLMs). However, human-based evaluation of suchcapability involves intensive manual labor. This report provides a preliminaryevaluation of existing large language models for human-style multi-turnchatting, through an LLM-based approach. We start from real-world humandialogues and keep the very first utterances as the ChatSEED. Then we promptLLMs to generate a full multi-turn dialogue (tens of utterances) based on theChatSEED, utterance by utterance. Finally, we adopt state-of-the-art LLMs(GPT-4, \etc) as the judge to evaluate the generated dialogues. With differentevaluation protocols, we come to substantially identical conclusions. We findthat GPT-4 can generate human-style multi-turn dialogues with impressivequality, significantly outperforms its counterparts. It's difficult for adiscriminator to distinguish between GPT-4 generated dialogues and humandialogues. In contrast, other LLMs struggle to generate multi-turn dialogues ofsatisfactory quality due to poor instruction-following capability, tendency togenerate lengthy utterances, or limited general capability. All data and codeswill be provided in https://github.com/open-compass/BotChat/ and we hope theycan serve as a valuable resource for evaluating multi-turn chattingcapabilities of LLMs.</description><author>Haodong Duan, Jueqi Wei, Chonghua Wang, Hongwei Liu, Yixiao Fang, Songyang Zhang, Dahua Lin, Kai Chen</author><pubDate>Fri, 20 Oct 2023 17:53:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13650v1</guid></item><item><title>Contrastive Prefence Learning: Learning from Human Feedback without RL</title><link>http://arxiv.org/abs/2310.13639v1</link><description>Reinforcement Learning from Human Feedback (RLHF) has emerged as a popularparadigm for aligning models with human intent. Typically RLHF algorithmsoperate in two phases: first, use human preferences to learn a reward functionand second, align the model by optimizing the learned reward via reinforcementlearning (RL). This paradigm assumes that human preferences are distributedaccording to reward, but recent work suggests that they instead follow theregret under the user's optimal policy. Thus, learning a reward function fromfeedback is not only based on a flawed assumption of human preference, but alsoleads to unwieldy optimization challenges that stem from policy gradients orbootstrapping in the RL phase. Because of these optimization challenges,contemporary RLHF methods restrict themselves to contextual bandit settings(e.g., as in large language models) or limit observation dimensionality (e.g.,state-based robotics). We overcome these limitations by introducing a newfamily of algorithms for optimizing behavior from human feedback using theregret-based model of human preferences. Using the principle of maximumentropy, we derive Contrastive Preference Learning (CPL), an algorithm forlearning optimal policies from preferences without learning reward functions,circumventing the need for RL. CPL is fully off-policy, uses only a simplecontrastive objective, and can be applied to arbitrary MDPs. This enables CPLto elegantly scale to high-dimensional and sequential RLHF problems while beingsimpler than prior methods.</description><author>Joey Hejna, Rafael Rafailov, Harshit Sikchi, Chelsea Finn, Scott Niekum, W. Bradley Knox, Dorsa Sadigh</author><pubDate>Fri, 20 Oct 2023 17:37:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13639v1</guid></item><item><title>Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples</title><link>http://arxiv.org/abs/2305.15269v2</link><description>Given the intractably large size of the space of proofs, any model that iscapable of general deductive reasoning must generalize to proofs of greatercomplexity. Recent studies have shown that large language models (LLMs) possesssome abstract deductive reasoning ability given chain-of-thought prompts.However, they have primarily been tested on proofs using modus ponens or of aspecific size, and from the same distribution as the in-context examples. Tomeasure the general deductive reasoning ability of LLMs, we test on a broad setof deduction rules and measure their ability to generalize to more complexproofs from simpler demonstrations from multiple angles: depth-, width-, andcompositional generalization. To facilitate systematic exploration, weconstruct a new synthetic and programmable reasoning dataset that enablescontrol over deduction rules and proof complexity. Our experiments on four LLMsof various sizes and training objectives show that they are able to generalizeto compositional proofs. However, they have difficulty generalizing to longerproofs, and they require explicit demonstrations to produce hypotheticalsubproofs, specifically in proof by cases and proof by contradiction.</description><author>Abulhair Saparov, Richard Yuanzhe Pang, Vishakh Padmakumar, Nitish Joshi, Seyed Mehran Kazemi, Najoung Kim, He He</author><pubDate>Fri, 20 Oct 2023 17:34:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15269v2</guid></item><item><title>Deep-Learning-based Change Detection with Spaceborne Hyperspectral PRISMA data</title><link>http://arxiv.org/abs/2310.13627v1</link><description>Change detection (CD) methods have been applied to optical data for decades,while the use of hyperspectral data with a fine spectral resolution has beenrarely explored. CD is applied in several sectors, such as environmentalmonitoring and disaster management. Thanks to the PRecursore IperSpettraledella Missione operativA (PRISMA), hyperspectral-from-space CD is now possible.In this work, we apply standard and deep-learning (DL) CD methods to differenttargets, from natural to urban areas. We propose a pipeline starting fromcoregistration, followed by CD with a full-spectrum algorithm and by a DLnetwork developed for optical data. We find that changes in vegetation andbuilt environments are well captured. The spectral information is valuable toidentify subtle changes and the DL methods are less affected by noise comparedto the statistical method, but atmospheric effects and the lack of reliableground truth represent a major challenge to hyperspectral CD.</description><author>J. F. Amieva, A. Austoni, M. A. Brovelli, L. Ansalone, P. Naylor, F. Serva, B. Le Saux</author><pubDate>Fri, 20 Oct 2023 17:22:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13627v1</guid></item><item><title>Image Super-resolution Via Latent Diffusion: A Sampling-space Mixture Of Experts And Frequency-augmented Decoder Approach</title><link>http://arxiv.org/abs/2310.12004v2</link><description>The recent use of diffusion prior, enhanced by pre-trained text-image models,has markedly elevated the performance of image super-resolution (SR). Toalleviate the huge computational cost required by pixel-based diffusion SR,latent-based methods utilize a feature encoder to transform the image and thenimplement the SR image generation in a compact latent space. Nevertheless,there are two major issues that limit the performance of latent-baseddiffusion. First, the compression of latent space usually causes reconstructiondistortion. Second, huge computational cost constrains the parameter scale ofthe diffusion model. To counteract these issues, we first propose a frequencycompensation module that enhances the frequency components from latent space topixel space. The reconstruction distortion (especially for high-frequencyinformation) can be significantly decreased. Then, we propose to useSample-Space Mixture of Experts (SS-MoE) to achieve more powerful latent-basedSR, which steadily improves the capacity of the model without a significantincrease in inference costs. These carefully crafted designs contribute toperformance improvements in largely explored 4x blind super-resolutionbenchmarks and extend to large magnification factors, i.e., 8x image SRbenchmarks. The code is available at https://github.com/amandaluof/moe_sr.</description><author>Feng Luo, Jinxi Xiang, Jun Zhang, Xiao Han, Wei Yang</author><pubDate>Fri, 20 Oct 2023 17:17:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12004v2</guid></item><item><title>Modeling Supply and Demand in Public Transportation Systems</title><link>http://arxiv.org/abs/2309.06299v2</link><description>We propose two neural network based and data-driven supply and demand modelsto analyze the efficiency, identify service gaps, and determine the significantpredictors of demand, in the bus system for the Department of PublicTransportation (HDPT) in Harrisonburg City, Virginia, which is the home toJames Madison University (JMU). The supply and demand models, one temporal andone spatial, take many variables into account, including the demographic datasurrounding the bus stops, the metrics that the HDPT reports to the federalgovernment, and the drastic change in population between when JMU is on or offsession. These direct and data-driven models to quantify supply and demand andidentify service gaps can generalize to other cities' bus systems.</description><author>Miranda Bihler, Hala Nelson, Erin Okey, Noe Reyes Rivas, John Webb, Anna White</author><pubDate>Fri, 20 Oct 2023 17:17:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06299v2</guid></item><item><title>VPP: Efficient Conditional 3D Generation via Voxel-Point Progressive Representation</title><link>http://arxiv.org/abs/2307.16605v2</link><description>Conditional 3D generation is undergoing a significant advancement, enablingthe free creation of 3D content from inputs such as text or 2D images. However,previous approaches have suffered from low inference efficiency, limitedgeneration categories, and restricted downstream applications. In this work, werevisit the impact of different 3D representations on generation quality andefficiency. We propose a progressive generation method through Voxel-PointProgressive Representation (VPP). VPP leverages structured voxel representationin the proposed Voxel Semantic Generator and the sparsity of unstructured pointrepresentation in the Point Upsampler, enabling efficient generation ofmulti-category objects. VPP can generate high-quality 8K point clouds within0.2 seconds. Additionally, the masked generation Transformer allows for various3D downstream tasks, such as generation, editing, completion, and pre-training.Extensive experiments demonstrate that VPP efficiently generates high-fidelityand diverse 3D shapes across different categories, while also exhibitingexcellent representation transfer performance. Codes will be released at\url{https://github.com/qizekun/VPP}.</description><author>Zekun Qi, Muzhou Yu, Runpei Dong, Kaisheng Ma</author><pubDate>Fri, 20 Oct 2023 17:14:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16605v2</guid></item><item><title>Predicting Battery Lifetime Under Varying Usage Conditions from Early Aging Data</title><link>http://arxiv.org/abs/2307.08382v2</link><description>Accurate battery lifetime prediction is important for preventativemaintenance, warranties, and improved cell design and manufacturing. However,manufacturing variability and usage-dependent degradation make life predictionchallenging. Here, we investigate new features derived from capacity-voltagedata in early life to predict the lifetime of cells cycled under widely varyingcharge rates, discharge rates, and depths of discharge. Features were extractedfrom regularly scheduled reference performance tests (i.e., low rate fullcycles) during cycling. The early-life features capture a cell's state ofhealth and the rate of change of component-level degradation modes, some ofwhich correlate strongly with cell lifetime. Using a newly generated datasetfrom 225 nickel-manganese-cobalt/graphite Li-ion cells aged under a wide rangeof conditions, we demonstrate a lifetime prediction of in-distribution cellswith 15.1% mean absolute percentage error using no more than the first 15% ofdata, for most cells. Further testing using a hierarchical Bayesian regressionmodel shows improved performance on extrapolation, achieving 21.8% meanabsolute percentage error for out-of-distribution cells. Our approachhighlights the importance of using domain knowledge of lithium-ion batterydegradation modes to inform feature engineering. Further, we provide thecommunity with a new publicly available battery aging dataset with cells cycledbeyond 80% of their rated capacity.</description><author>Tingkai Li, Zihao Zhou, Adam Thelen, David Howey, Chao Hu</author><pubDate>Fri, 20 Oct 2023 17:13:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08382v2</guid></item><item><title>What you see is what you get: Experience ranking with deep neural dataset-to-dataset similarity for topological localisation</title><link>http://arxiv.org/abs/2310.13622v1</link><description>Recalling the most relevant visual memories for localisation or understandinga priori the likely outcome of localisation effort against a particular visualmemory is useful for efficient and robust visual navigation. Solutions to thisproblem should be divorced from performance appraisal against ground truth - asthis is not available at run-time - and should ideally be based ongeneralisable environmental observations. For this, we propose applying therecently developed Visual DNA as a highly scalable tool for comparing datasetsof images - in this work, sequences of map and live experiences. In the case oflocalisation, important dataset differences impacting performance are modes ofappearance change, including weather, lighting, and season. Specifically, forany deep architecture which is used for place recognition by matching featurevolumes at a particular layer, we use distribution measures to compareneuron-wise activation statistics between live images and multiple previouslyrecorded past experiences, with a potentially large seasonal (winter/summer) ortime of day (day/night) shift. We find that differences in these statisticscorrelate to performance when localising using a past experience with the sameappearance gap. We validate our approach over the Nordland cross-season datasetas well as data from Oxford's University Parks with lighting and mild seasonalchange, showing excellent ability of our system to rank actual localisationperformance across candidate experiences.</description><author>Matthew Gadd, Benjamin Ramtoula, Daniele De Martini, Paul Newman</author><pubDate>Fri, 20 Oct 2023 17:13:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13622v1</guid></item><item><title>Bridging Information-Theoretic and Geometric Compression in Language Models</title><link>http://arxiv.org/abs/2310.13620v1</link><description>For a language model (LM) to faithfully model human language, it mustcompress vast, potentially infinite information into relatively few dimensions.We propose analyzing compression in (pre-trained) LMs from two points of view:geometric and information-theoretic. We demonstrate that the two views arehighly correlated, such that the intrinsic geometric dimension of linguisticdata predicts their coding length under the LM. We then show that, in turn,high compression of a linguistic dataset predicts rapid adaptation to thatdataset, confirming that being able to compress linguistic information is animportant part of successful LM performance. As a practical byproduct of ouranalysis, we evaluate a battery of intrinsic dimension estimators for the firsttime on linguistic data, showing that only some encapsulate the relationshipbetween information-theoretic compression, geometric compression, andease-of-adaptation.</description><author>Emily Cheng, Corentin Kervadec, Marco Baroni</author><pubDate>Fri, 20 Oct 2023 17:12:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13620v1</guid></item><item><title>Semi-supervised multimodal coreference resolution in image narrations</title><link>http://arxiv.org/abs/2310.13619v1</link><description>In this paper, we study multimodal coreference resolution, specifically wherea longer descriptive text, i.e., a narration is paired with an image. Thisposes significant challenges due to fine-grained image-text alignment, inherentambiguity present in narrative language, and unavailability of large annotatedtraining sets. To tackle these challenges, we present a data efficientsemi-supervised approach that utilizes image-narration pairs to resolvecoreferences and narrative grounding in a multimodal context. Our approachincorporates losses for both labeled and unlabeled data within a cross-modalframework. Our evaluation shows that the proposed approach outperforms strongbaselines both quantitatively and qualitatively, for the tasks of coreferenceresolution and narrative grounding.</description><author>Arushi Goel, Basura Fernando, Frank Keller, Hakan Bilen</author><pubDate>Fri, 20 Oct 2023 17:10:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13619v1</guid></item><item><title>Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning</title><link>http://arxiv.org/abs/2310.13615v1</link><description>Due to the remarkable language understanding and generation abilities oflarge language models (LLMs), their use in educational applications has beenexplored. However, little work has been done on investigating the pedagogicalability of LLMs in helping students to learn mathematics. In this positionpaper, we discuss the challenges associated with employing LLMs to enhancestudents' mathematical problem-solving skills by providing adaptive feedback.Apart from generating the wrong reasoning processes, LLMs can misinterpret themeaning of the question, and also exhibit difficulty in understanding the givenquestions' rationales when attempting to correct students' answers. Threeresearch questions are formulated.</description><author>An-Zi Yen, Wei-Ling Hsu</author><pubDate>Fri, 20 Oct 2023 17:05:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13615v1</guid></item><item><title>Hunayn: Elevating Translation Beyond the Literal</title><link>http://arxiv.org/abs/2310.13613v1</link><description>This project introduces an advanced English-to-Arabic translator surpassingconventional tools. Leveraging the Helsinki transformer (MarianMT), ourapproach involves fine-tuning on a self-scraped, purely literary Arabicdataset. Evaluations against Google Translate show consistent outperformance inqualitative assessments. Notably, it excels in cultural sensitivity and contextaccuracy. This research underscores the Helsinki transformer's superiority forEnglish-to-Arabic translation using a Fusha dataset.</description><author>Nasser Almousa, Nasser Alzamil, Abdullah Alshehri, Ahmad Sait</author><pubDate>Fri, 20 Oct 2023 17:03:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13613v1</guid></item><item><title>Make Your Decision Convincing! A Unified Two-Stage Framework: Self-Attribution and Decision-Making</title><link>http://arxiv.org/abs/2310.13610v1</link><description>Explaining black-box model behavior with natural language has achievedimpressive results in various NLP tasks. Recent research has explored theutilization of subsequences from the input text as a rationale, providing userswith evidence to support the model decision. Although existing frameworks excelin generating high-quality rationales while achieving high task performance,they neglect to account for the unreliable link between the generated rationaleand model decision. In simpler terms, a model may make correct decisions whileattributing wrong rationales, or make poor decisions while attributing correctrationales. To mitigate this issue, we propose a unified two-stage frameworkknown as Self-Attribution and Decision-Making (SADM). Through extensiveexperiments on five reasoning datasets from the ERASER benchmark, wedemonstrate that our framework not only establishes a more reliable linkbetween the generated rationale and model decision but also achievescompetitive results in task performance and the quality of rationale.Furthermore, we explore the potential of our framework in semi-supervisedscenarios.</description><author>Yanrui Du, Sendong Zhao, Haochun Wang, Yuhan Chen, Rui Bai, Zewen Qiang, Muzhen Cai, Bing Qin</author><pubDate>Fri, 20 Oct 2023 16:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13610v1</guid></item><item><title>Analyzing the contribution of different passively collected data to predict Stress and Depression</title><link>http://arxiv.org/abs/2310.13607v1</link><description>The possibility of recognizing diverse aspects of human behavior andenvironmental context from passively captured data motivates its use for mentalhealth assessment. In this paper, we analyze the contribution of differentpassively collected sensor data types (WiFi, GPS, Social interaction, PhoneLog, Physical Activity, Audio, and Academic features) to predict dailyselfreport stress and PHQ-9 depression score. First, we compute 125 mid-levelfeatures from the original raw data. These 125 features include groups offeatures from the different sensor data types. Then, we evaluate thecontribution of each feature type by comparing the performance of NeuralNetwork models trained with all features against Neural Network models trainedwith specific feature groups. Our results show that WiFi features (which encodemobility patterns) and Phone Log features (which encode information correlatedwith sleep patterns), provide significative information for stress anddepression prediction.</description><author>Irene Bonafonte, Cristina Bustos, Abraham Larrazolo, Gilberto Lorenzo Martinez Luna, Adolfo Guzman Arenas, Xavier Baro, Isaac Tourgeman, Mercedes Balcells, Agata Lapedriza</author><pubDate>Fri, 20 Oct 2023 16:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13607v1</guid></item><item><title>MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark</title><link>http://arxiv.org/abs/2310.13606v1</link><description>There is a lack of research into capabilities of recent LLMs to generateconvincing text in languages other than English and into performance ofdetectors of machine-generated text in multilingual settings. This is alsoreflected in the available benchmarks which lack authentic texts in languagesother than English and predominantly cover older generators. To fill this gap,we introduce MULTITuDE, a novel benchmarking dataset for multilingualmachine-generated text detection comprising of 74,081 authentic andmachine-generated texts in 11 languages (ar, ca, cs, de, en, es, nl, pt, ru,uk, and zh) generated by 8 multilingual LLMs. Using this benchmark, we comparethe performance of zero-shot (statistical and black-box) and fine-tuneddetectors. Considering the multilinguality, we evaluate 1) how these detectorsgeneralize to unseen languages (linguistically similar as well as dissimilar)and unseen LLMs and 2) whether the detectors improve their performance whentrained on multiple languages.</description><author>Dominik Macko, Robert Moro, Adaku Uchendu, Jason Samuel Lucas, Michiharu Yamashita, Matúš Pikuliak, Ivan Srba, Thai Le, Dongwon Lee, Jakub Simko, Maria Bielikova</author><pubDate>Fri, 20 Oct 2023 16:57:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13606v1</guid></item><item><title>DT/MARS-CycleGAN: Improved Object Detection for MARS Phenotyping Robot</title><link>http://arxiv.org/abs/2310.12787v2</link><description>Robotic crop phenotyping has emerged as a key technology to assess crops'morphological and physiological traits at scale. These phenotypicalmeasurements are essential for developing new crop varieties with the aim ofincreasing productivity and dealing with environmental challenges such asclimate change. However, developing and deploying crop phenotyping robots facemany challenges such as complex and variable crop shapes that complicaterobotic object detection, dynamic and unstructured environments that bafflerobotic control, and real-time computing and managing big data that challengerobotic hardware/software. This work specifically tackles the first challengeby proposing a novel Digital-Twin(DT)MARS-CycleGAN model for image augmentationto improve our Modular Agricultural Robotic System (MARS)'s crop objectdetection from complex and variable backgrounds. Our core idea is that inaddition to the cycle consistency losses in the CycleGAN model, we designed andenforced a new DT-MARS loss in the deep learning model to penalize theinconsistency between real crop images captured by MARS and synthesized imagessensed by DT MARS. Therefore, the generated synthesized crop images closelymimic real images in terms of realism, and they are employed to fine-tuneobject detectors such as YOLOv8. Extensive experiments demonstrated that ournew DT/MARS-CycleGAN framework significantly boosts our MARS' crop object/rowdetector's performance, contributing to the field of robotic crop phenotyping.</description><author>David Liu, Zhengkun Li, Zihao Wu, Changying Li</author><pubDate>Fri, 20 Oct 2023 16:55:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12787v2</guid></item><item><title>FMRT: Learning Accurate Feature Matching with Reconciliatory Transformer</title><link>http://arxiv.org/abs/2310.13605v1</link><description>Local Feature Matching, an essential component of several computer visiontasks (e.g., structure from motion and visual localization), has beeneffectively settled by Transformer-based methods. However, these methods onlyintegrate long-range context information among keypoints with a fixed receptivefield, which constrains the network from reconciling the importance of featureswith different receptive fields to realize complete image perception, hencelimiting the matching accuracy. In addition, these methods utilize aconventional handcrafted encoding approach to integrate the positionalinformation of keypoints into the visual descriptors, which limits thecapability of the network to extract reliable positional encoding message. Inthis study, we propose Feature Matching with Reconciliatory Transformer (FMRT),a novel Transformer-based detector-free method that reconciles differentfeatures with multiple receptive fields adaptively and utilizes parallelnetworks to realize reliable positional encoding. Specifically, FMRT proposes adedicated Reconciliatory Transformer (RecFormer) that consists of a GlobalPerception Attention Layer (GPAL) to extract visual descriptors with differentreceptive fields and integrate global context information under various scales,Perception Weight Layer (PWL) to measure the importance of various receptivefields adaptively, and Local Perception Feed-forward Network (LPFFN) to extractdeep aggregated multi-scale local feature representation. Extensive experimentsdemonstrate that FMRT yields extraordinary performance on multiple benchmarks,including pose estimation, visual localization, homography estimation, andimage matching.</description><author>Xinyu Zhang, Li Wang, Zhiqiang Jiang, Kun Dai, Tao Xie, Lei Yang, Wenhao Yu, Yang Shen, Jun Li</author><pubDate>Fri, 20 Oct 2023 16:54:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13605v1</guid></item><item><title>Skin Lesion Segmentation Improved by Transformer-based Networks with Inter-scale Dependency Modeling</title><link>http://arxiv.org/abs/2310.13604v1</link><description>Melanoma, a dangerous type of skin cancer resulting from abnormal skin cellgrowth, can be treated if detected early. Various approaches using FullyConvolutional Networks (FCNs) have been proposed, with the U-Net architecturebeing prominent To aid in its diagnosis through automatic skin lesionsegmentation. However, the symmetrical U-Net model's reliance on convolutionaloperations hinders its ability to capture long-range dependencies crucial foraccurate medical image segmentation. Several Transformer-based U-Net topologieshave recently been created to overcome this limitation by replacing CNN blockswith different Transformer modules to capture local and global representations.Furthermore, the U-shaped structure is hampered by semantic gaps between theencoder and decoder. This study intends to increase the network's featurere-usability by carefully building the skip connection path. Integrating analready calculated attention affinity within the skip connection path improvesthe typical concatenation process utilized in the conventional skip connectionpath. As a result, we propose a U-shaped hierarchical Transformer-basedstructure for skin lesion segmentation and an Inter-scale Context Fusion (ISCF)method that uses attention correlations in each stage of the encoder toadaptively combine the contexts from each stage to mitigate semantic gaps. Thefindings from two skin lesion segmentation benchmarks support the ISCF module'sapplicability and effectiveness. The code is publicly available at\url{https://github.com/saniaesk/skin-lesion-segmentation}</description><author>Sania Eskandari, Janet Lumpp, Luis Sanchez Giraldo</author><pubDate>Fri, 20 Oct 2023 16:53:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13604v1</guid></item><item><title>BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance</title><link>http://arxiv.org/abs/2305.13395v2</link><description>Timely and accurate extraction of Adverse Drug Events (ADE) from biomedicalliterature is paramount for public safety, but involves slow and costly manuallabor. We set out to improve drug safety monitoring (pharmacovigilance, PV)through the use of Natural Language Processing (NLP). We introduce BioDEX, alarge-scale resource for Biomedical adverse Drug Event Extraction, rooted inthe historical output of drug safety reporting in the U.S. BioDEX consists of65k abstracts and 19k full-text biomedical papers with 256k associateddocument-level safety reports created by medical experts. The core features ofthese reports include the reported weight, age, and biological sex of apatient, a set of drugs taken by the patient, the drug dosages, the reactionsexperienced, and whether the reaction was life threatening. In this work, weconsider the task of predicting the core information of the report given itsoriginating paper. We estimate human performance to be 72.0% F1, whereas ourbest model achieves 62.3% F1, indicating significant headroom on this task. Wealso begin to explore ways in which these models could help professional PVreviewers. Our code and data are available: https://github.com/KarelDO/BioDEX.</description><author>Karel D'Oosterlinck, François Remy, Johannes Deleu, Thomas Demeester, Chris Develder, Klim Zaporojets, Aneiss Ghodsi, Simon Ellershaw, Jack Collins, Christopher Potts</author><pubDate>Fri, 20 Oct 2023 16:51:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13395v2</guid></item><item><title>MarineGPT: Unlocking Secrets of Ocean to the Public</title><link>http://arxiv.org/abs/2310.13596v1</link><description>Large language models (LLMs), such as ChatGPT/GPT-4, have proven to bepowerful tools in promoting the user experience as an AI assistant. Thecontinuous works are proposing multi-modal large language models (MLLM),empowering LLMs with the ability to sense multiple modality inputs throughconstructing a joint semantic space (e.g. visual-text space). Thoughsignificant success was achieved in LLMs and MLLMs, exploring LLMs and MLLMs indomain-specific applications that required domain-specific knowledge andexpertise has been less conducted, especially for \textbf{marine domain}.Different from general-purpose MLLMs, the marine-specific MLLM is required toyield much more \textbf{sensitive}, \textbf{informative}, and\textbf{scientific} responses. In this work, we demonstrate that the existingMLLMs optimized on huge amounts of readily available general-purpose trainingdata show a minimal ability to understand domain-specific intents and thengenerate informative and satisfactory responses. To address these issues, wepropose \textbf{MarineGPT}, the first vision-language model specially designedfor the marine domain, unlocking the secrets of the ocean to the public. Wepresent our \textbf{Marine-5M} dataset with more than 5 million marineimage-text pairs to inject domain-specific marine knowledge into our model andachieve better marine vision and language alignment. Our MarineGPT not onlypushes the boundaries of marine understanding to the general public but alsooffers a standard protocol for adapting a general-purpose assistant todownstream domain-specific experts. We pave the way for a wide range of marineapplications while setting valuable data and pre-trained models for futureresearch in both academic and industrial communities.</description><author>Ziqiang Zheng, Jipeng Zhang, Tuan-Anh Vu, Shizhe Diao, Yue Him Wong Tim, Sai-Kit Yeung</author><pubDate>Fri, 20 Oct 2023 16:45:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13596v1</guid></item><item><title>Longer-range Contextualized Masked Autoencoder</title><link>http://arxiv.org/abs/2310.13593v1</link><description>Masked image modeling (MIM) has emerged as a promising self-supervisedlearning (SSL) strategy. The MIM pre-training facilitates learning powerfulrepresentations using an encoder-decoder framework by randomly masking someinput pixels and reconstructing the masked pixels from the remaining ones.However, as the encoder is trained with partial pixels, the MIM pre-trainingcan suffer from a low capability of understanding long-range dependency. Thislimitation may hinder its capability to fully understand multiple-rangedependencies, resulting in narrow highlighted regions in the attention map thatmay incur accuracy drops. To mitigate the limitation, We propose aself-supervised learning framework, named Longer-range Contextualized MaskedAutoencoder (LC-MAE). LC-MAE effectively leverages a global contextunderstanding of visual representations while simultaneously reducing thespatial redundancy of input at the same time. Our method steers the encoder tolearn from entire pixels in multiple views while also learning localrepresentation from sparse pixels. As a result, LC-MAE learns morediscriminative representations, leading to a performance improvement ofachieving 84.2% top-1 accuracy with ViT-B on ImageNet-1K with 0.6%p gain. Weattribute the success to the enhanced pre-training method, as evidenced by thesingular value spectrum and attention analyses. Finally, LC-MAE achievessignificant performance gains at the downstream semantic segmentation andfine-grained visual classification tasks; and on diverse robust evaluationmetrics. Our code will be publicly available.</description><author>Taekyung Kim, Sanghyuk Chun, Byeongho Heo, Dongyoon Han</author><pubDate>Fri, 20 Oct 2023 16:42:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13593v1</guid></item><item><title>ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction</title><link>http://arxiv.org/abs/2310.13590v1</link><description>Predicting chemical reactions, a fundamental challenge in chemistry, involvesforecasting the resulting products from a given reaction process. Conventionaltechniques, notably those employing Graph Neural Networks (GNNs), are oftenlimited by insufficient training data and their inability to utilize textualinformation, undermining their applicability in real-world applications. Inthis work, we propose ReLM, a novel framework that leverages the chemicalknowledge encoded in language models (LMs) to assist GNNs, thereby enhancingthe accuracy of real-world chemical reaction predictions. To further enhancethe model's robustness and interpretability, we incorporate the confidencescore strategy, enabling the LMs to self-assess the reliability of theirpredictions. Our experimental results demonstrate that ReLM improves theperformance of state-of-the-art GNN-based methods across various chemicalreaction datasets, especially in out-of-distribution settings. Codes areavailable at https://github.com/syr-cn/ReLM.</description><author>Yaorui Shi, An Zhang, Enzhi Zhang, Zhiyuan Liu, Xiang Wang</author><pubDate>Fri, 20 Oct 2023 16:33:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13590v1</guid></item><item><title>Simultaneous Machine Translation with Tailored Reference</title><link>http://arxiv.org/abs/2310.13588v1</link><description>Simultaneous machine translation (SiMT) generates translation while readingthe whole source sentence. However, existing SiMT models are typically trainedusing the same reference disregarding the varying amounts of available sourceinformation at different latency. Training the model with ground-truth at lowlatency may introduce forced anticipations, whereas utilizing referenceconsistent with the source word order at high latency results in performancedegradation. Consequently, it is crucial to train the SiMT model withappropriate reference that avoids forced anticipations during training whilemaintaining high quality. In this paper, we propose a novel method thatprovides tailored reference for the SiMT models trained at different latency byrephrasing the ground-truth. Specifically, we introduce the tailor, induced byreinforcement learning, to modify ground-truth to the tailored reference. TheSiMT model is trained with the tailored reference and jointly optimized withthe tailor to enhance performance. Importantly, our method is applicable to awide range of current SiMT approaches. Experiments on three translation tasksdemonstrate that our method achieves state-of-the-art performance in both fixedand adaptive policies.</description><author>Shoutao Guo, Shaolei Zhang, Yang Feng</author><pubDate>Fri, 20 Oct 2023 16:32:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13588v1</guid></item><item><title>On the Role of Morphological Information for Contextual Lemmatization</title><link>http://arxiv.org/abs/2302.00407v3</link><description>Lemmatization is a natural language processing (NLP) task which consists ofproducing, from a given inflected word, its canonical form or lemma.Lemmatization is one of the basic tasks that facilitate downstream NLPapplications, and is of particular importance for high-inflected languages.Given that the process to obtain a lemma from an inflected word can beexplained by looking at its morphosyntactic category, including fine-grainedmorphosyntactic information to train contextual lemmatizers has become commonpractice, without considering whether that is the optimum in terms ofdownstream performance. In order to address this issue, in this paper weempirically investigate the role of morphological information to developcontextual lemmatizers in six languages within a varied spectrum ofmorphological complexity: Basque, Turkish, Russian, Czech, Spanish and English.Furthermore, and unlike the vast majority of previous work, we also evaluatelemmatizers in out-of-domain settings, which constitutes, after all, their mostcommon application use. The results of our study are rather surprising. Itturns out that providing lemmatizers with fine-grained morphological featuresduring training is not that beneficial, not even for agglutinative languages.In fact, modern contextual word representations seem to implicitly encodeenough morphological information to obtain competitive contextual lemmatizerswithout seeing any explicit morphological signal. Moreover, our experimentssuggest that the best lemmatizers out-of-domain are those using simple UPOStags or those trained without morphology and, finally, that current evaluationpractices for lemmatization are not adequate to clearly discriminate betweenmodels.</description><author>Olia Toporkov, Rodrigo Agerri</author><pubDate>Fri, 20 Oct 2023 16:31:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00407v3</guid></item><item><title>STERLING: Self-Supervised Terrain Representation Learning from Unconstrained Robot Experience</title><link>http://arxiv.org/abs/2309.15302v2</link><description>Terrain awareness, i.e., the ability to identify and distinguish differenttypes of terrain, is a critical ability that robots must have to succeed atautonomous off-road navigation. Current approaches that provide robots withthis awareness either rely on labeled data which is expensive to collect,engineered features and cost functions that may not generalize, or expert humandemonstrations which may not be available. Towards endowing robots with terrainawareness without these limitations, we introduce Self-supervised TErrainRepresentation LearnING (STERLING), a novel approach for learning terrainrepresentations that relies solely on easy-to-collect, unconstrained (e.g.,non-expert), and unlabelled robot experience, with no additional constraints ondata collection. STERLING employs a novel multi-modal self-supervisionobjective through non-contrastive representation learning to learn relevantterrain representations for terrain-aware navigation. Through physical robotexperiments in off-road environments, we evaluate STERLING features on the taskof preference-aligned visual navigation and find that STERLING features performon par with fully supervised approaches and outperform other state-of-the-artmethods with respect to preference alignment. Additionally, we perform alarge-scale experiment of autonomously hiking a 3-mile long trail whichSTERLING completes successfully with only two manual interventions,demonstrating its robustness to real-world off-road conditions.</description><author>Haresh Karnan, Elvin Yang, Daniel Farkash, Garrett Warnell, Joydeep Biswas, Peter Stone</author><pubDate>Fri, 20 Oct 2023 16:29:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15302v2</guid></item><item><title>POTLoc: Pseudo-Label Oriented Transformer for Point-Supervised Temporal Action Localization</title><link>http://arxiv.org/abs/2310.13585v1</link><description>This paper tackles the challenge of point-supervised temporal actiondetection, wherein only a single frame is annotated for each action instance inthe training set. Most of the current methods, hindered by the sparse nature ofannotated points, struggle to effectively represent the continuous structure ofactions or the inherent temporal and semantic dependencies within actioninstances. Consequently, these methods frequently learn merely the mostdistinctive segments of actions, leading to the creation of incomplete actionproposals. This paper proposes POTLoc, a Pseudo-label Oriented Transformer forweakly-supervised Action Localization utilizing only point-level annotation.POTLoc is designed to identify and track continuous action structures via aself-training strategy. The base model begins by generating action proposalssolely with point-level supervision. These proposals undergo refinement andregression to enhance the precision of the estimated action boundaries, whichsubsequently results in the production of `pseudo-labels' to serve assupplementary supervisory signals. The architecture of the model integrates atransformer with a temporal feature pyramid to capture video snippetdependencies and model actions of varying duration. The pseudo-labels,providing information about the coarse locations and boundaries of actions,assist in guiding the transformer for enhanced learning of action dynamics.POTLoc outperforms the state-of-the-art point-supervised methods on THUMOS'14and ActivityNet-v1.2 datasets, showing a significant improvement of 5% averagemAP on the former.</description><author>Elahe Vahdani, Yingli Tian</author><pubDate>Fri, 20 Oct 2023 16:28:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13585v1</guid></item><item><title>Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering</title><link>http://arxiv.org/abs/2310.13583v1</link><description>Despite the impressive growth of the abilities of multilingual languagemodels, such as XLM-R and mT5, it has been shown that they still facedifficulties when tackling typologically-distant languages, particularly in thelow-resource setting. One obstacle for effective cross-lingual transfer isvariability in word-order patterns. It can be potentially mitigated via source-or target-side word reordering, and numerous approaches to reordering have beenproposed. However, they rely on language-specific rules, work on the level ofPOS tags, or only target the main clause, leaving subordinate clauses intact.To address these limitations, we present a new powerful reordering method,defined in terms of Universal Dependencies, that is able to learn fine-grainedword-order patterns conditioned on the syntactic context from a small amount ofannotated data and can be applied at all levels of the syntactic tree. Weconduct experiments on a diverse set of tasks and show that our methodconsistently outperforms strong baselines over different language pairs andmodel architectures. This performance advantage holds true in both zero-shotand few-shot scenarios.</description><author>Ofir Arviv, Dmitry Nikolaev, Taelin Karidi, Omri Abend</author><pubDate>Fri, 20 Oct 2023 16:25:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13583v1</guid></item><item><title>SPARE: A Single-Pass Neural Model for Relational Databases</title><link>http://arxiv.org/abs/2310.13581v1</link><description>While there has been extensive work on deep neural networks for images andtext, deep learning for relational databases (RDBs) is still a ratherunexplored field. One direction that recently gained traction is to apply Graph Neural Networks(GNNs) to RBDs. However, training GNNs on large relational databases (i.e.,data stored in multiple database tables) is rather inefficient due to multiplerounds of training and potentially large and inefficient representations.Hence, in this paper we propose SPARE (Single-Pass Relational models), a newclass of neural models that can be trained efficiently on RDBs while providingsimilar accuracies as GNNs. For enabling efficient training, different fromGNNs, SPARE makes use of the fact that data in RDBs has a regular structure,which allows one to train these models in a single pass while exploitingsymmetries at the same time. Our extensive empirical evaluation demonstratesthat SPARE can significantly speedup both training and inference while offeringcompetitive predictive performance over numerous baselines.</description><author>Benjamin Hilprecht, Kristian Kersting, Carsten Binnig</author><pubDate>Fri, 20 Oct 2023 16:23:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13581v1</guid></item><item><title>RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation</title><link>http://arxiv.org/abs/2303.12570v3</link><description>The task of repository-level code completion is to continue writing theunfinished code based on a broader context of the repository. While forautomated code completion tools, it is difficult to utilize the usefulinformation scattered in different files. We propose RepoCoder, a simple,generic, and effective framework to address the challenge. It streamlines therepository-level code completion process by incorporating a similarity-basedretriever and a pre-trained code language model in an iterativeretrieval-generation pipeline. RepoCoder makes effective utilization ofrepository-level information for code completion and has the ability togenerate code at various levels of granularity. Moreover, we propose a newbenchmark RepoEval, which consists of the latest and high-quality real-worldrepositories covering line, API invocation, and function body completionscenarios. Experimental results indicate that RepoCoder significantly improvesthe In-File completion baseline by over 10% in all settings and consistentlyoutperforms the vanilla retrieval-augmented code completion approach.Furthermore, we validate the effectiveness of RepoCoder through comprehensiveanalysis, providing valuable insights for future research. Our source code andbenchmark are publicly available:https://github.com/microsoft/CodeT/tree/main/RepoCoder</description><author>Fengji Zhang, Bei Chen, Yue Zhang, Jacky Keung, Jin Liu, Daoguang Zan, Yi Mao, Jian-Guang Lou, Weizhu Chen</author><pubDate>Fri, 20 Oct 2023 16:21:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12570v3</guid></item><item><title>PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training</title><link>http://arxiv.org/abs/2305.13723v2</link><description>Weakly-supervised text classification trains a classifier using the labelname of each target class as the only supervision, which largely reduces humanannotation efforts. Most existing methods first use the label names as statickeyword-based features to generate pseudo labels, which are then used for finalclassifier training. While reasonable, such a commonly adopted frameworksuffers from two limitations: (1) keywords can have different meanings indifferent contexts and some text may not have any keyword, so keyword matchingcan induce noisy and inadequate pseudo labels; (2) the errors made in thepseudo label generation stage will directly propagate to the classifiertraining stage without a chance of being corrected. In this paper, we propose anew method, PIEClass, consisting of two modules: (1) a pseudo label acquisitionmodule that uses zero-shot prompting of pre-trained language models (PLM) toget pseudo labels based on contextualized text understanding beyond statickeyword matching, and (2) a noise-robust iterative ensemble training modulethat iteratively trains classifiers and updates pseudo labels by utilizing twoPLM fine-tuning methods that regularize each other. Extensive experiments showthat PIEClass achieves overall better performance than existing strongbaselines on seven benchmark datasets and even achieves similar performance tofully-supervised classifiers on sentiment classification tasks.</description><author>Yunyi Zhang, Minhao Jiang, Yu Meng, Yu Zhang, Jiawei Han</author><pubDate>Fri, 20 Oct 2023 16:14:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13723v2</guid></item><item><title>Tree Search in DAG Space with Model-based Reinforcement Learning for Causal Discovery</title><link>http://arxiv.org/abs/2310.13576v1</link><description>Identifying causal structure is central to many fields ranging from strategicdecision-making to biology and economics. In this work, we propose amodel-based reinforcement learning method for causal discovery based on treesearch, which builds directed acyclic graphs incrementally. We also formalizeand prove the correctness of an efficient algorithm for excluding edges thatwould introduce cycles, which enables deeper discrete search and sampling inDAG space. We evaluate our approach on two real-world tasks, achievingsubstantially better performance than the state-of-the-art model-free methodand greedy search, constituting a promising advancement for combinatorialmethods.</description><author>Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi</author><pubDate>Fri, 20 Oct 2023 16:14:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13576v1</guid></item><item><title>Semantic Decomposition of Question and SQL for Text-to-SQL Parsing</title><link>http://arxiv.org/abs/2310.13575v1</link><description>Text-to-SQL semantic parsing faces challenges in generalizing to cross-domainand complex queries. Recent research has employed a question decompositionstrategy to enhance the parsing of complex SQL queries. However, this strategyencounters two major obstacles: (1) existing datasets lack questiondecomposition; (2) due to the syntactic complexity of SQL, most complex queriescannot be disentangled into sub-queries that can be readily recomposed. Toaddress these challenges, we propose a new modular Query Plan Language (QPL)that systematically decomposes SQL queries into simple and regular sub-queries.We develop a translator from SQL to QPL by leveraging analysis of SQL serverquery optimization plans, and we augment the Spider dataset with QPL programs.Experimental results demonstrate that the modular nature of QPL benefitsexisting semantic-parsing architectures, and training text-to-QPL parsers ismore effective than text-to-SQL parsing for semantically equivalent queries.The QPL approach offers two additional advantages: (1) QPL programs can beparaphrased as simple questions, which allows us to create a dataset of(complex question, decomposed questions). Training on this dataset, we obtain aQuestion Decomposer for data retrieval that is sensitive to database schemas.(2) QPL is more accessible to non-experts for complex queries, leading to moreinterpretable output from the semantic parser.</description><author>Ben Eyal, Amir Bachar, Ophir Haroche, Moran Mahabi, Michael Elhadad</author><pubDate>Fri, 20 Oct 2023 16:13:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13575v1</guid></item><item><title>Progressive Dual Priori Network for Generalized Breast Tumor Segmentation</title><link>http://arxiv.org/abs/2310.13574v1</link><description>To promote the generalization ability of breast tumor segmentation models, aswell as to improve the segmentation performance for breast tumors with smallersize, low-contrast amd irregular shape, we propose a progressive dual priorinetwork (PDPNet) to segment breast tumors from dynamic enhanced magneticresonance images (DCE-MRI) acquired at different sites. The PDPNet firstcropped tumor regions with a coarse-segmentation based localization module,then the breast tumor mask was progressively refined by using the weak semanticpriori and cross-scale correlation prior knowledge. To validate theeffectiveness of PDPNet, we compared it with several state-of-the-art methodson multi-center datasets. The results showed that, comparing against thesuboptimal method, the DSC, SEN, KAPPA and HD95 of PDPNet were improved 3.63\%,8.19\%, 5.52\%, and 3.66\% respectively. In addition, through ablations, wedemonstrated that the proposed localization module can decrease the influenceof normal tissues and therefore improve the generalization ability of themodel. The weak semantic priors allow focusing on tumor regions to avoidmissing small tumors and low-contrast tumors. The cross-scale correlationpriors are beneficial for promoting the shape-aware ability for irregualtumors. Thus integrating them in a unified framework improved the multi-centerbreast tumor segmentation performance.</description><author>Li Wang, Lihui Wang, Zixiang Kuai, Lei Tang, Yingfeng Ou, Chen Ye, Yuemin Zhu</author><pubDate>Fri, 20 Oct 2023 16:12:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13574v1</guid></item><item><title>Boosting Generalization with Adaptive Style Techniques for Fingerprint Liveness Detection</title><link>http://arxiv.org/abs/2310.13573v1</link><description>We introduce a high-performance fingerprint liveness feature extractiontechnique that secured first place in LivDet 2023 Fingerprint RepresentationChallenge. Additionally, we developed a practical fingerprint recognitionsystem with 94.68% accuracy, earning second place in LivDet 2023 LivenessDetection in Action. By investigating various methods, particularly styletransfer, we demonstrate improvements in accuracy and generalization when facedwith limited training data. As a result, our approach achieved state-of-the-artperformance in LivDet 2023 Challenges.</description><author>Kexin Zhu, Bo Lin, Yang Qiu, Adam Yule, Yao Tang, Jiajun Liang</author><pubDate>Fri, 20 Oct 2023 16:10:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13573v1</guid></item><item><title>Unraveling the Enigma of Double Descent: An In-depth Analysis through the Lens of Learned Feature Space</title><link>http://arxiv.org/abs/2310.13572v1</link><description>Double descent presents a counter-intuitive aspect within the machinelearning domain, and researchers have observed its manifestation in variousmodels and tasks. While some theoretical explanations have been proposed forthis phenomenon in specific contexts, an accepted theory to account for itsoccurrence in deep learning remains yet to be established. In this study, werevisit the phenomenon of double descent and demonstrate that its occurrence isstrongly influenced by the presence of noisy data. Through conducting acomprehensive analysis of the feature space of learned representations, weunveil that double descent arises in imperfect models trained with noisy data.We argue that double descent is a consequence of the model first learning thenoisy data until interpolation and then adding implicit regularization viaover-parameterization acquiring therefore capability to separate theinformation from the noise. We postulate that double descent should never occurin well-regularized models.</description><author>Yufei Gu, Xiaoqing Zheng, Tomaso Aste</author><pubDate>Fri, 20 Oct 2023 16:10:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13572v1</guid></item><item><title>Why Can Large Language Models Generate Correct Chain-of-Thoughts?</title><link>http://arxiv.org/abs/2310.13571v1</link><description>This paper delves into the capabilities of large language models (LLMs),specifically focusing on advancing the theoretical comprehension ofchain-of-thought prompting. We investigate how LLMs can be effectively inducedto generate a coherent chain of thoughts. To achieve this, we introduce atwo-level hierarchical graphical model tailored for natural languagegeneration. Within this framework, we establish a compelling geometricalconvergence rate that gauges the likelihood of an LLM-generated chain ofthoughts compared to those originating from the true language. Our findingsprovide a theoretical justification for the ability of LLMs to produce thecorrect sequence of thoughts (potentially) explaining performance gains intasks demanding reasoning skills.</description><author>Rasul Tutunov, Antoine Grosnit, Juliusz Ziomek, Jun Wang, Haitham Bou-Ammar</author><pubDate>Fri, 20 Oct 2023 16:09:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13571v1</guid></item><item><title>A Simple Baseline for Knowledge-Based Visual Question Answering</title><link>http://arxiv.org/abs/2310.13570v1</link><description>This paper is on the problem of Knowledge-Based Visual Question Answering(KB-VQA). Recent works have emphasized the significance of incorporating bothexplicit (through external databases) and implicit (through LLMs) knowledge toanswer questions requiring external knowledge effectively. A common limitationof such approaches is that they consist of relatively complicated pipelines andoften heavily rely on accessing GPT-3 API. Our main contribution in this paperis to propose a much simpler and readily reproducible pipeline which, in anutshell, is based on efficient in-context learning by prompting LLaMA (1 and2) using question-informative captions as contextual information. Contrary torecent approaches, our method is training-free, does not require access toexternal databases or APIs, and yet achieves state-of-the-art accuracy on theOK-VQA and A-OK-VQA datasets. Finally, we perform several ablation studies tounderstand important aspects of our method. Our code is publicly available athttps://github.com/alexandrosXe/ASimple-Baseline-For-Knowledge-Based-VQA</description><author>Alexandros Xenos, Themos Stafylakis, Ioannis Patras, Georgios Tzimiropoulos</author><pubDate>Fri, 20 Oct 2023 16:08:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13570v1</guid></item><item><title>Elaborative Simplification as Implicit Questions Under Discussion</title><link>http://arxiv.org/abs/2305.10387v2</link><description>Automated text simplification, a technique useful for making text moreaccessible to people such as children and emergent bilinguals, is often thoughtof as a monolingual translation task from complex sentences to simplifiedsentences using encoder-decoder models. This view fails to account forelaborative simplification, where new information is added into the simplifiedtext. This paper proposes to view elaborative simplification through the lensof the Question Under Discussion (QUD) framework, providing a robust way toinvestigate what writers elaborate upon, how they elaborate, and howelaborations fit into the discourse context by viewing elaborations as explicitanswers to implicit questions. We introduce ElabQUD, consisting of 1.3Kelaborations accompanied with implicit QUDs, to study these phenomena. We showthat explicitly modeling QUD (via question generation) not only providesessential understanding of elaborative simplification and how the elaborationsconnect with the rest of the discourse, but also substantially improves thequality of elaboration generation.</description><author>Yating Wu, William Sheffield, Kyle Mahowald, Junyi Jessy Li</author><pubDate>Fri, 20 Oct 2023 16:06:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10387v2</guid></item><item><title>Retrieval-Augmented Neural Response Generation Using Logical Reasoning and Relevance Scoring</title><link>http://arxiv.org/abs/2310.13566v1</link><description>Constructing responses in task-oriented dialogue systems typically relies oninformation sources such the current dialogue state or external databases. Thispaper presents a novel approach to knowledge-grounded response generation thatcombines retrieval-augmented language models with logical reasoning. Theapproach revolves around a knowledge graph representing the current dialoguestate and background information, and proceeds in three steps. The knowledgegraph is first enriched with logically derived facts inferred usingprobabilistic logical programming. A neural model is then employed at each turnto score the conversational relevance of each node and edge of this extendedgraph. Finally, the elements with highest relevance scores are converted to anatural language form, and are integrated into the prompt for the neuralconversational model employed to generate the system response. We investigate the benefits of the proposed approach on two datasets (KVRETand GraphWOZ) along with a human evaluation. Experimental results show that thecombination of (probabilistic) logical reasoning with conversational relevancescoring does increase both the factuality and fluency of the responses.</description><author>Nicholas Thomas Walker, Stefan Ultes, Pierre Lison</author><pubDate>Fri, 20 Oct 2023 16:05:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13566v1</guid></item><item><title>Reward Shaping for Happier Autonomous Cyber Security Agents</title><link>http://arxiv.org/abs/2310.13565v1</link><description>As machine learning models become more capable, they have exhibited increasedpotential in solving complex tasks. One of the most promising directions usesdeep reinforcement learning to train autonomous agents in computer networkdefense tasks. This work studies the impact of the reward signal that isprovided to the agents when training for this task. Due to the nature ofcybersecurity tasks, the reward signal is typically 1) in the form of penalties(e.g., when a compromise occurs), and 2) distributed sparsely across eachdefense episode. Such reward characteristics are atypical of classicreinforcement learning tasks where the agent is regularly rewarded for progress(cf. to getting occasionally penalized for failures). We investigate rewardshaping techniques that could bridge this gap so as to enable agents to trainmore sample-efficiently and potentially converge to a better performance. Wefirst show that deep reinforcement learning algorithms are sensitive to themagnitude of the penalties and their relative size. Then, we combine penaltieswith positive external rewards and study their effect compared to penalty-onlytraining. Finally, we evaluate intrinsic curiosity as an internal positivereward mechanism and discuss why it might not be as advantageous for high-levelnetwork monitoring tasks.</description><author>Elizabeth Bates, Vasilios Mavroudis, Chris Hicks</author><pubDate>Fri, 20 Oct 2023 16:04:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13565v1</guid></item><item><title>Cache &amp; Distil: Optimising API Calls to Large Language Models</title><link>http://arxiv.org/abs/2310.13561v1</link><description>Large-scale deployment of generative AI tools often depends on costly APIcalls to a Large Language Model (LLM) to fulfil user queries. To curtail thefrequency of these calls, one can employ a smaller language model -- a student-- which is continuously trained on the responses of the LLM. This studentgradually gains proficiency in independently handling an increasing number ofuser requests, a process we term neural caching. The crucial element in neuralcaching is a policy that decides which requests should be processed by thestudent alone and which should be redirected to the LLM, subsequently aidingthe student's learning. In this study, we focus on classification tasks, and weconsider a range of classic active learning-based selection criteria as thepolicy. Our experiments suggest that Margin Sampling and Query by Committeebring consistent benefits across tasks and budgets.</description><author>Guillem Ramírez, Matthias Lindemann, Alexandra Birch, Ivan Titov</author><pubDate>Fri, 20 Oct 2023 16:01:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13561v1</guid></item><item><title>On sample complexity of conditional independence testing with Von Mises estimator with application to causal discovery</title><link>http://arxiv.org/abs/2310.13553v1</link><description>Motivated by conditional independence testing, an essential step inconstraint-based causal discovery algorithms, we study the nonparametric VonMises estimator for the entropy of multivariate distributions built on a kerneldensity estimator. We establish an exponential concentration inequality forthis estimator. We design a test for conditional independence (CI) based on ourestimator, called VM-CI, which achieves optimal parametric rates undersmoothness assumptions. Leveraging the exponential concentration, we prove atight upper bound for the overall error of VM-CI. This, in turn, allows us tocharacterize the sample complexity of any constraint-based causal discoveryalgorithm that uses VM-CI for CI tests. To the best of our knowledge, this isthe first sample complexity guarantee for causal discovery for continuousvariables. Furthermore, we empirically show that VM-CI outperforms otherpopular CI tests in terms of either time or sample complexity (or both), whichtranslates to a better performance in structure learning as well.</description><author>Fateme Jamshidi, Luca Ganassali, Negar Kiyavash</author><pubDate>Fri, 20 Oct 2023 15:52:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13553v1</guid></item><item><title>Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning</title><link>http://arxiv.org/abs/2310.13552v1</link><description>In open-domain question-answering (ODQA), most existing questions requiresingle-hop reasoning on commonsense. To further extend this task, we officiallyintroduce open-domain multi-hop reasoning (ODMR) by answering multi-hopquestions with explicit reasoning steps in open-domain setting. Recently, largelanguage models (LLMs) have found significant utility in facilitating ODQAwithout external corpus. Furthermore, chain-of-thought (CoT) prompting booststhe reasoning capability of LLMs to a greater extent with manual or automatedparadigms. However, existing automated methods lack of quality assurance, whilemanual approaches suffer from limited scalability and poor diversity, hinderingthe capabilities of LLMs. In this paper, we propose Self-promptedChain-of-Thought (SP-CoT), an automated framework to mass-produce high qualityCoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generationpipeline of high quality ODMR datasets, an adaptive sampler for in-context CoTselection and self-prompted inference via in-context learning. Extensiveexperiments on four multi-hop question-answering benchmarks show that ourproposed SP-CoT not only significantly surpasses the previous SOTA methods onlarge-scale (175B) LLMs, but also nearly doubles the zero-shot performance ofsmall-scale (13B) LLMs. Further analysis reveals the remarkable capability ofSP-CoT to elicit direct and concise intermediate reasoning steps by recalling$\sim$50\% of intermediate answers on MuSiQue-Ans dataset.</description><author>Jinyuan Wang, Junlong Li, Hai Zhao</author><pubDate>Fri, 20 Oct 2023 15:51:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13552v1</guid></item><item><title>ROSS: Radar Off-road Semantic Segmentation</title><link>http://arxiv.org/abs/2310.13551v1</link><description>As the demand for autonomous navigation in off-road environments increases,the need for effective solutions to understand these surroundings becomesessential. In this study, we confront the inherent complexities of semanticsegmentation in RADAR data for off-road scenarios. We present a novel pipelinethat utilizes LIDAR data and an existing annotated off-road LIDAR dataset forgenerating RADAR labels, in which the RADAR data are represented as images.Validated with real-world datasets, our pragmatic approach underscores thepotential of RADAR technology for navigation applications in off-roadenvironments.</description><author>Peng Jiang, Srikanth Saripalli</author><pubDate>Fri, 20 Oct 2023 15:50:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13551v1</guid></item><item><title>Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes</title><link>http://arxiv.org/abs/2310.13550v1</link><description>In multi-task reinforcement learning (RL) under Markov decision processes(MDPs), the presence of shared latent structures among multiple MDPs has beenshown to yield significant benefits to the sample efficiency compared tosingle-task RL. In this paper, we investigate whether such a benefit can extendto more general sequential decision making problems, such as partiallyobservable MDPs (POMDPs) and more general predictive state representations(PSRs). The main challenge here is that the large and complex model space makesit hard to identify what types of common latent structure of multi-task PSRscan reduce the model complexity and improve sample efficiency. To this end, weposit a joint model class for tasks and use the notion of $\eta$-bracketingnumber to quantify its complexity; this number also serves as a general metricto capture the similarity of tasks and thus determines the benefit ofmulti-task over single-task RL. We first study upstream multi-task learningover PSRs, in which all tasks share the same observation and action spaces. Wepropose a provably efficient algorithm UMT-PSR for finding near-optimalpolicies for all PSRs, and demonstrate that the advantage of multi-tasklearning manifests if the joint model class of PSRs has a smaller$\eta$-bracketing number compared to that of individual single-task learning.We also provide several example multi-task PSRs with small $\eta$-bracketingnumbers, which reap the benefits of multi-task learning. We further investigatedownstream learning, in which the agent needs to learn a new target task thatshares some commonalities with the upstream tasks via a similarity constraint.By exploiting the learned PSRs from the upstream, we develop a sample-efficientalgorithm that provably finds a near-optimal policy.</description><author>Ruiquan Huang, Yuan Cheng, Jing Yang, Vincent Tan, Yingbin Liang</author><pubDate>Fri, 20 Oct 2023 15:50:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13550v1</guid></item><item><title>The Perils &amp; Promises of Fact-checking with Large Language Models</title><link>http://arxiv.org/abs/2310.13549v1</link><description>Autonomous fact-checking, using machine learning to verify claims, has grownvital as misinformation spreads beyond human fact-checking capacity. LargeLanguage Models (LLMs) like GPT-4 are increasingly trusted to verifyinformation and write academic papers, lawsuits, and news articles, emphasizingtheir role in discerning truth from falsehood and the importance of being ableto verify their outputs. Here, we evaluate the use of LLM agents infact-checking by having them phrase queries, retrieve contextual data, and makedecisions. Importantly, in our framework, agents explain their reasoning andcite the relevant sources from the retrieved context. Our results show theenhanced prowess of LLMs when equipped with contextual information. GPT-4outperforms GPT-3, but accuracy varies based on query language and claimveracity. While LLMs show promise in fact-checking, caution is essential due toinconsistent accuracy. Our investigation calls for further research, fosteringa deeper comprehension of when agents succeed and when they fail.</description><author>Dorian Quelle, Alexandre Bovet</author><pubDate>Fri, 20 Oct 2023 15:49:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13549v1</guid></item><item><title>Towards Understanding Sycophancy in Language Models</title><link>http://arxiv.org/abs/2310.13548v1</link><description>Reinforcement learning from human feedback (RLHF) is a popular technique fortraining high-quality AI assistants. However, RLHF may also encourage modelresponses that match user beliefs over truthful responses, a behavior known assycophancy. We investigate the prevalence of sycophancy in RLHF-trained modelsand whether human preference judgements are responsible. We first demonstratethat five state-of-the-art AI assistants consistently exhibit sycophanticbehavior across four varied free-form text-generation tasks. To understand ifhuman preferences drive this broadly observed behavior of RLHF models, weanalyze existing human preference data. We find that when a response matches auser's views, it is more likely to be preferred. Moreover, both humans andpreference models (PMs) prefer convincingly-written sycophantic responses overcorrect ones a negligible fraction of the time. Optimizing model outputsagainst PMs also sometimes sacrifices truthfulness in favor of sycophancy.Overall, our results indicate that sycophancy is a general behavior of RLHFmodels, likely driven in part by human preference judgements favoringsycophantic responses.</description><author>Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R. Johnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal Ndousse, Oliver Rausch, Nicholas Schiefer, Da Yan, Miranda Zhang, Ethan Perez</author><pubDate>Fri, 20 Oct 2023 15:46:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13548v1</guid></item><item><title>ScaleLong: Towards More Stable Training of Diffusion Model via Scaling Network Long Skip Connection</title><link>http://arxiv.org/abs/2310.13545v1</link><description>In diffusion models, UNet is the most popular network backbone, since itslong skip connects (LSCs) to connect distant network blocks can aggregatelong-distant information and alleviate vanishing gradient. Unfortunately, UNetoften suffers from unstable training in diffusion models which can bealleviated by scaling its LSC coefficients smaller. However, theoreticalunderstandings of the instability of UNet in diffusion models and also theperformance improvement of LSC scaling remain absent yet. To solve this issue,we theoretically show that the coefficients of LSCs in UNet have big effects onthe stableness of the forward and backward propagation and robustness of UNet.Specifically, the hidden feature and gradient of UNet at any layer canoscillate and their oscillation ranges are actually large which explains theinstability of UNet training. Moreover, UNet is also provably sensitive toperturbed input, and predicts an output distant from the desired output,yielding oscillatory loss and thus oscillatory gradient. Besides, we alsoobserve the theoretical benefits of the LSC coefficient scaling of UNet in thestableness of hidden features and gradient and also robustness. Finally,inspired by our theory, we propose an effective coefficient scaling frameworkScaleLong that scales the coefficients of LSC in UNet and better improves thetraining stability of UNet. Experimental results on four famous datasets showthat our methods are superior to stabilize training and yield about 1.5xtraining acceleration on different diffusion models with UNet or UViTbackbones. Code: https://github.com/sail-sg/ScaleLong</description><author>Zhongzhan Huang, Pan Zhou, Shuicheng Yan, Liang Lin</author><pubDate>Fri, 20 Oct 2023 15:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13545v1</guid></item><item><title>Trade-off Between Efficiency and Consistency for Removal-based Explanations</title><link>http://arxiv.org/abs/2210.17426v3</link><description>In the current landscape of explanation methodologies, most predominantapproaches, such as SHAP and LIME, employ removal-based techniques to evaluatethe impact of individual features by simulating various scenarios with specificfeatures omitted. Nonetheless, these methods primarily emphasize efficiency inthe original context, often resulting in general inconsistencies. In thispaper, we demonstrate that such inconsistency is an inherent aspect of theseapproaches by establishing the Impossible Trinity Theorem, which posits thatinterpretability, efficiency, and consistency cannot hold simultaneously.Recognizing that the attainment of an ideal explanation remains elusive, wepropose the utilization of interpretation error as a metric to gaugeinefficiencies and inconsistencies. To this end, we present two novelalgorithms founded on the standard polynomial basis, aimed at minimizinginterpretation error. Our empirical findings indicate that the proposed methodsachieve a substantial reduction in interpretation error, up to 31.8 times lowerwhen compared to alternative techniques. Code is available athttps://github.com/trusty-ai/efficient-consistent-explanations.</description><author>Yifan Zhang, Haowei He, Zhiquan Tan, Yang Yuan</author><pubDate>Fri, 20 Oct 2023 15:42:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.17426v3</guid></item><item><title>A Diachronic Perspective on User Trust in AI under Uncertainty</title><link>http://arxiv.org/abs/2310.13544v1</link><description>In a human-AI collaboration, users build a mental model of the AI systembased on its reliability and how it presents its decision, e.g. itspresentation of system confidence and an explanation of the output. Modern NLPsystems are often uncalibrated, resulting in confidently incorrect predictionsthat undermine user trust. In order to build trustworthy AI, we must understandhow user trust is developed and how it can be regained after potentialtrust-eroding events. We study the evolution of user trust in response to thesetrust-eroding events using a betting game. We find that even a few incorrectinstances with inaccurate confidence estimates damage user trust andperformance, with very slow recovery. We also show that this degradation intrust reduces the success of human-AI collaboration and that different types ofmiscalibration -- unconfidently correct and confidently incorrect -- havedifferent negative effects on user trust. Our findings highlight the importanceof calibration in user-facing AI applications and shed light on what aspectshelp users decide whether to trust the AI system.</description><author>Shehzaad Dhuliawala, Vilém Zouhar, Mennatallah El-Assady, Mrinmaya Sachan</author><pubDate>Fri, 20 Oct 2023 15:41:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13544v1</guid></item><item><title>Query Rewriting for Retrieval-Augmented Large Language Models</title><link>http://arxiv.org/abs/2305.14283v2</link><description>Large Language Models (LLMs) play powerful, black-box readers in theretrieve-then-read pipeline, making remarkable progress in knowledge-intensivetasks. This work introduces a new framework, Rewrite-Retrieve-Read instead ofthe previous retrieve-then-read for the retrieval-augmented LLMs from theperspective of the query rewriting. Unlike prior studies focusing on adaptingeither the retriever or the reader, our approach pays attention to theadaptation of the search query itself, for there is inevitably a gap betweenthe input text and the needed knowledge in retrieval. We first prompt an LLM togenerate the query, then use a web search engine to retrieve contexts.Furthermore, to better align the query to the frozen modules, we propose atrainable scheme for our pipeline. A small language model is adopted as atrainable rewriter to cater to the black-box LLM reader. The rewriter istrained using the feedback of the LLM reader by reinforcement learning.Evaluation is conducted on downstream tasks, open-domain QA and multiple-choiceQA. Experiments results show consistent performance improvement, indicatingthat our framework is proven effective and scalable, and brings a new frameworkfor retrieval-augmented LLM.</description><author>Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, Nan Duan</author><pubDate>Fri, 20 Oct 2023 15:39:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14283v2</guid></item><item><title>Not Just Pretty Pictures: Toward Interventional Data Augmentation Using Text-to-Image Generators</title><link>http://arxiv.org/abs/2212.11237v3</link><description>Neural image classifiers are known to undergo severe performance degradationwhen exposed to inputs that exhibit covariate shifts with respect to thetraining distribution. A general interventional data augmentation(IDA)mechanism that simulates arbitrary interventions over spurious variableshas often been conjectured as a theoretical solution to this problem andapproximated to varying degrees of success. In this work, we study how wellmodern Text-to-Image (T2I) generators and associated image editing techniquescan solve the problem of IDA. We experiment across a diverse collection ofbenchmarks in domain generalization, ablating across key dimensions of T2Igeneration, including interventional prompts, conditioning mechanisms, andpost-hoc filtering, showing that it substantially outperforms previouslystate-of-the-art image augmentation techniques independently of how eachdimension is configured. We discuss the comparative advantages of using T2I forimage editing versus synthesis, also finding that a simple retrieval baselinepresents a surprisingly effective alternative, which raises interestingquestions about how generative models should be evaluated in the context ofdomain generalization.</description><author>Jianhao Yuan, Francesco Pinto, Adam Davies, Philip Torr</author><pubDate>Fri, 20 Oct 2023 15:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.11237v3</guid></item><item><title>Positive-Unlabeled Node Classification with Structure-aware Graph Learning</title><link>http://arxiv.org/abs/2310.13538v1</link><description>Node classification on graphs is an important research problem with manyapplications. Real-world graph data sets may not be balanced and accurate asassumed by most existing works. A challenging setting is positive-unlabeled(PU) node classification, where labeled nodes are restricted to positive nodes.It has diverse applications, e.g., pandemic prediction or network anomalydetection. Existing works on PU node classification overlook information in thegraph structure, which can be critical. In this paper, we propose to betterutilize graph structure for PU node classification. We first propose adistance-aware PU loss that uses homophily in graphs to introduce more accuratesupervision. We also propose a regularizer to align the model with graphstructure. Theoretical analysis shows that minimizing the proposed loss alsoleads to minimizing the expected loss with both positive and negative labels.Extensive empirical evaluation on diverse graph data sets demonstrates itssuperior performance over existing state-of-the-art methods.</description><author>Hansi Yang, Yongqi Zhang, Quanming Yao, James Kwok</author><pubDate>Fri, 20 Oct 2023 15:32:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13538v1</guid></item><item><title>What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability</title><link>http://arxiv.org/abs/2305.11707v2</link><description>In Natural Language Generation (NLG) tasks, for any input, multiplecommunicative goals are plausible, and any goal can be put into words, orproduced, in multiple ways. We characterise the extent to which humanproduction varies lexically, syntactically, and semantically across four NLGtasks, connecting human production variability to aleatoric or datauncertainty. We then inspect the space of output strings shaped by a generationsystem's predicted probability distribution and decoding algorithm to probe itsuncertainty. For each test input, we measure the generator's calibration tohuman production variability. Following this instance-level approach, weanalyse NLG models and decoding strategies, demonstrating that probing agenerator with multiple samples and, when possible, multiple references,provides the level of detail necessary to gain understanding of a model'srepresentation of uncertainty. Code available athttps://github.com/dmg-illc/nlg-uncertainty-probes.</description><author>Mario Giulianelli, Joris Baan, Wilker Aziz, Raquel Fernández, Barbara Plank</author><pubDate>Fri, 20 Oct 2023 15:31:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11707v2</guid></item><item><title>Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology</title><link>http://arxiv.org/abs/2310.05227v2</link><description>Accurate hydrological understanding and water cycle prediction are crucialfor addressing scientific and societal challenges associated with themanagement of water resources, particularly under the dynamic influence ofanthropogenic climate change. Existing reviews predominantly concentrate on thedevelopment of machine learning (ML) in this field, yet there is a cleardistinction between hydrology and ML as separate paradigms. Here, we introducephysics-aware ML as a transformative approach to overcome the perceived barrierand revolutionize both fields. Specifically, we present a comprehensive reviewof the physics-aware ML methods, building a structured community (PaML) ofexisting methodologies that integrate prior physical knowledge or physics-basedmodeling into ML. We systematically analyze these PaML methodologies withrespect to four aspects: physical data-guided ML, physics-informed ML,physics-embedded ML, and physics-aware hybrid learning. PaML facilitatesML-aided hypotheses, accelerating insights from big data and fosteringscientific discoveries. We first conduct a systematic review of hydrology inPaML, including rainfall-runoff hydrological processes and hydrodynamicprocesses, and highlight the most promising and challenging directions fordifferent objectives and PaML methods. Finally, a new PaML-based hydrologyplatform, termed HydroPML, is released as a foundation for hydrologicalapplications. HydroPML enhances the explainability and causality of ML and laysthe groundwork for the digital water cycle's realization. The HydroPML platformis publicly available at https://hydropml.github.io/.</description><author>Qingsong Xu, Yilei Shi, Jonathan Bamber, Ye Tuo, Ralf Ludwig, Xiao Xiang Zhu</author><pubDate>Fri, 20 Oct 2023 15:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05227v2</guid></item><item><title>GlueStick: Robust Image Matching by Sticking Points and Lines Together</title><link>http://arxiv.org/abs/2304.02008v3</link><description>Line segments are powerful features complementary to points. They offerstructural cues, robust to drastic viewpoint and illumination changes, and canbe present even in texture-less areas. However, describing and matching them ismore challenging compared to points due to partial occlusions, lack of texture,or repetitiveness. This paper introduces a new matching paradigm, where points,lines, and their descriptors are unified into a single wireframe structure. Wepropose GlueStick, a deep matching Graph Neural Network (GNN) that takes twowireframes from different images and leverages the connectivity informationbetween nodes to better glue them together. In addition to the increasedefficiency brought by the joint matching, we also demonstrate a large boost ofperformance when leveraging the complementary nature of these two features in asingle architecture. We show that our matching strategy outperforms thestate-of-the-art approaches independently matching line segments and points fora wide variety of datasets and tasks. The code is available athttps://github.com/cvg/GlueStick.</description><author>Rémi Pautrat, Iago Suárez, Yifan Yu, Marc Pollefeys, Viktor Larsson</author><pubDate>Fri, 20 Oct 2023 15:27:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02008v3</guid></item><item><title>Technical Report for ICCV 2023 Visual Continual Learning Challenge: Continuous Test-time Adaptation for Semantic Segmentation</title><link>http://arxiv.org/abs/2310.13533v1</link><description>The goal of the challenge is to develop a test-time adaptation (TTA) method,which could adapt the model to gradually changing domains in video sequencesfor semantic segmentation task. It is based on a synthetic driving videodataset - SHIFT. The source model is trained on images taken during daytime inclear weather. Domain changes at test-time are mainly caused by varying weatherconditions and times of day. The TTA methods are evaluated in each imagesequence (video) separately, meaning the model is reset to the source modelstate before the next sequence. Images come one by one and a prediction has tobe made at the arrival of each frame. Each sequence is composed of 401 imagesand starts with the source domain, then gradually drifts to a different one(changing weather or time of day) until the middle of the sequence. In thesecond half of the sequence, the domain gradually shifts back to the sourceone. Ground truth data is available only for the validation split of the SHIFTdataset, in which there are only six sequences that start and end with thesource domain. We conduct an analysis specifically on those sequences. Groundtruth data for test split, on which the developed TTA methods are evaluated forleader board ranking, are not publicly available. The proposed solution secured a 3rd place in a challenge and received aninnovation award. Contrary to the solutions that scored better, we did not useany external pretrained models or specialized data augmentations, to keep thesolutions as general as possible. We have focused on analyzing thedistributional shift and developing a method that could adapt to changing datadynamics and generalize across different scenarios.</description><author>Damian Sójka, Yuyang Liu, Dipam Goswami, Sebastian Cygert, Bartłomiej Twardowski, Joost van de Weijer</author><pubDate>Fri, 20 Oct 2023 15:20:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13533v1</guid></item><item><title>Controlled Randomness Improves the Performance of Transformer Models</title><link>http://arxiv.org/abs/2310.13526v1</link><description>During the pre-training step of natural language models, the main objectiveis to learn a general representation of the pre-training dataset, usuallyrequiring large amounts of textual data to capture the complexity and diversityof natural language. Contrasting this, in most cases, the size of the dataavailable to solve the specific downstream task is often dwarfed by theaforementioned pre-training dataset, especially in domains where data isscarce. We introduce controlled randomness, i.e. noise, into the trainingprocess to improve fine-tuning language models and explore the performance oftargeted noise in addition to the parameters of these models. We find thatadding such noise can improve the performance in our two downstream tasks ofjoint named entity recognition and relation extraction and text summarization.</description><author>Tobias Deußer, Cong Zhao, Wolfgang Krämer, David Leonhard, Christian Bauckhage, Rafet Sifa</author><pubDate>Fri, 20 Oct 2023 15:12:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13526v1</guid></item><item><title>Variational measurement-based quantum computation for generative modeling</title><link>http://arxiv.org/abs/2310.13524v1</link><description>Measurement-based quantum computation (MBQC) offers a fundamentally uniqueparadigm to design quantum algorithms. Indeed, due to the inherent randomnessof quantum measurements, the natural operations in MBQC are not deterministicand unitary, but are rather augmented with probabilistic byproducts. Yet, themain algorithmic use of MBQC so far has been to completely counteract thisprobabilistic nature in order to simulate unitary computations expressed in thecircuit model. In this work, we propose designing MBQC algorithms that embracethis inherent randomness and treat the random byproducts in MBQC as a resourcefor computation. As a natural application where randomness can be beneficial,we consider generative modeling, a task in machine learning centered aroundgenerating complex probability distributions. To address this task, we proposea variational MBQC algorithm equipped with control parameters that allow todirectly adjust the degree of randomness to be admitted in the computation. Ournumerical findings indicate that this additional randomness can lead tosignificant gains in learning performance in certain generative modeling tasks.These results highlight the potential advantages in exploiting the inherentrandomness of MBQC and motivate further research into MBQC-based algorithms.</description><author>Arunava Majumder, Marius Krumm, Tina Radkohl, Hendrik Poulsen Nautrup, Sofiene Jerbi, Hans J. Briegel</author><pubDate>Fri, 20 Oct 2023 15:11:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13524v1</guid></item><item><title>Teaching Language Models to Self-Improve through Interactive Demonstrations</title><link>http://arxiv.org/abs/2310.13522v1</link><description>The self-improving ability of large language models (LLMs), enabled byprompting them to analyze and revise their own outputs, has garneredsignificant interest in recent research. However, this ability has been shownto be absent and difficult to learn for smaller models, thus widening theperformance gap between state-of-the-art LLMs and more cost-effective andfaster ones. To reduce this gap, we introduce TriPosT, a training algorithmthat endows smaller models with such self-improvement ability, and show thatour approach can improve a LLaMA-7b's performance on math and reasoning tasksby up to 7.13%. In contrast to prior work, we achieve this by using the smallermodel to interact with LLMs to collect feedback and improvements on its owngenerations. We then replay this experience to train the small model. Ourexperiments on four math and reasoning datasets show that the interactiveexperience of learning from and correcting its own mistakes is crucial forsmall models to improve their performance.</description><author>Xiao Yu, Baolin Peng, Michel Galley, Jianfeng Gao, Zhou Yu</author><pubDate>Fri, 20 Oct 2023 15:11:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13522v1</guid></item><item><title>Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models</title><link>http://arxiv.org/abs/2307.11224v3</link><description>Jina Embeddings constitutes a set of high-performance sentence embeddingmodels adept at translating textual inputs into numerical representations,capturing the semantics of the text. These models excel in applications likedense retrieval and semantic textual similarity. This paper details thedevelopment of Jina Embeddings, starting with the creation of high-qualitypairwise and triplet datasets. It underlines the crucial role of data cleaningin dataset preparation, offers in-depth insights into the model trainingprocess, and concludes with a comprehensive performance evaluation using theMassive Text Embedding Benchmark (MTEB). Furthermore, to increase the model'sawareness of grammatical negation, we construct a novel training and evaluationdataset of negated and non-negated statements, which we make publicly availableto the community.</description><author>Michael Günther, Louis Milliken, Jonathan Geuter, Georgios Mastrapas, Bo Wang, Han Xiao</author><pubDate>Fri, 20 Oct 2023 15:09:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11224v3</guid></item><item><title>Deep neural networks can stably solve high-dimensional, noisy, non-linear inverse problems</title><link>http://arxiv.org/abs/2206.00934v5</link><description>We study the problem of reconstructing solutions of inverse problems whenonly noisy measurements are available. We assume that the problem can bemodeled with an infinite-dimensional forward operator that is not continuouslyinvertible. Then, we restrict this forward operator to finite-dimensionalspaces so that the inverse is Lipschitz continuous. For the inverse operator,we demonstrate that there exists a neural network which is a robust-to-noiseapproximation of the operator. In addition, we show that these neural networkscan be learned from appropriately perturbed training data. We demonstrate theadmissibility of this approach to a wide range of inverse problems of practicalinterest. Numerical examples are given that support the theoretical findings.</description><author>Andrés Felipe Lerma Pineda, Philipp Christian Petersen</author><pubDate>Fri, 20 Oct 2023 15:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.00934v5</guid></item><item><title>Formal specification terminology for demographic agent-based models of fixed-step single-clocked simulations</title><link>http://arxiv.org/abs/2308.13081v3</link><description>This document presents adequate formal terminology for the mathematicalspecification of a subset of Agent Based Models (ABMs) in the field ofDemography. The simulation of the targeted ABMs follows a fixedstepsingle-clocked pattern. The proposed terminology further improves the modelunderstanding and can act as a stand-alone protocol for the specification andoptionally the documentation of a significant set of (demographic) ABMs.Nevertheless, it is imaginable the this terminology can serve as an inspiringbasis for further improvement to the largely-informal widely-used modeldocumentation and communication O.D.D. protocol [Grimm and et al., 2020,Amouroux et al., 2010] to reduce many sources of ambiguity which hinder modelreplications by other modelers. A published demographic model documentation,largely simplified version of the Lone Parent Model [Gostoli and Silverman,2020] is separately published in [Elsheikh, 2023c] as illustration for theformal terminology presented here. The model was implemented in the Julialanguage [Elsheikh, 2023b] based on the Agents.jl julia package [Datseris etal., 2022].</description><author>Atiyah Elsheikh</author><pubDate>Fri, 20 Oct 2023 15:05:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13081v3</guid></item><item><title>All Points Matter: Entropy-Regularized Distribution Alignment for Weakly-supervised 3D Segmentation</title><link>http://arxiv.org/abs/2305.15832v2</link><description>Pseudo-labels are widely employed in weakly supervised 3D segmentation taskswhere only sparse ground-truth labels are available for learning. Existingmethods often rely on empirical label selection strategies, such as confidencethresholding, to generate beneficial pseudo-labels for model training. Thisapproach may, however, hinder the comprehensive exploitation of unlabeled datapoints. We hypothesize that this selective usage arises from the noise inpseudo-labels generated on unlabeled data. The noise in pseudo-labels mayresult in significant discrepancies between pseudo-labels and modelpredictions, thus confusing and affecting the model training greatly. Toaddress this issue, we propose a novel learning strategy to regularize thegenerated pseudo-labels and effectively narrow the gaps between pseudo-labelsand model predictions. More specifically, our method introduces an EntropyRegularization loss and a Distribution Alignment loss for weakly supervisedlearning in 3D segmentation tasks, resulting in an ERDA learning strategy.Interestingly, by using KL distance to formulate the distribution alignmentloss, it reduces to a deceptively simple cross-entropy-based loss whichoptimizes both the pseudo-label generation network and the 3D segmentationnetwork simultaneously. Despite the simplicity, our method promisingly improvesthe performance. We validate the effectiveness through extensive experiments onvarious baselines and large-scale datasets. Results show that ERDA effectivelyenables the effective usage of all unlabeled data points for learning andachieves state-of-the-art performance under different settings. Remarkably, ourmethod can outperform fully-supervised baselines using only 1% of trueannotations. Code and model will be made publicly available athttps://github.com/LiyaoTang/ERDA.</description><author>Liyao Tang, Zhe Chen, Shanshan Zhao, Chaoyue Wang, Dacheng Tao</author><pubDate>Fri, 20 Oct 2023 15:03:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15832v2</guid></item><item><title>Lifetime policy reuse and the importance of task capacity</title><link>http://arxiv.org/abs/2106.01741v3</link><description>A long-standing challenge in artificial intelligence is lifelongreinforcement learning, where learners are given many tasks in sequence andmust transfer knowledge between tasks while avoiding catastrophic forgetting.Policy reuse and other multi-policy reinforcement learning techniques can learnmultiple tasks but may generate many policies. This paper presents two novelcontributions, namely 1) Lifetime Policy Reuse, a model-agnostic policy reusealgorithm that avoids generating many policies by optimising a fixed number ofnear-optimal policies through a combination of policy optimisation and adaptivepolicy selection; and 2) the task capacity, a measure for the maximal number oftasks that a policy can accurately solve. Comparing two state-of-the-artbase-learners, the results demonstrate the importance of Lifetime Policy Reuseand task capacity based pre-selection on an 18-task partially observable Pacmandomain and a Cartpole domain of up to 125 tasks.</description><author>David M. Bossens, Adam J. Sobey</author><pubDate>Fri, 20 Oct 2023 15:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.01741v3</guid></item><item><title>Outlier Suppression+: Accurate quantization of large language models by equivalent and optimal shifting and scaling</title><link>http://arxiv.org/abs/2304.09145v2</link><description>Post-training quantization~(PTQ) of transformer language models facessignificant challenges due to the existence of detrimental outliers inactivations. We observe that these outliers are concentrated in specificchannels and are asymmetric across channels. To address this issue, we proposethe Outlier Suppression+~(OS+) framework, which contains the channel-wiseshifting for asymmetry and channel-wise scaling for concentration. We show thatthese operations can be seamlessly migrated into subsequent modules whilemaintaining equivalence. Second, we propose a fast and stable scheme tocalculate effective shifting and scaling values. The channel-wise shiftingaligns the center of each channel for removal of outlier asymmetry. Thechannel-wise scaling quantitatively evaluates changes brough by migration andquantization for better quantization burden balance. We validate our OS+ underboth standard and fine-grained quantization settings with models includingBERT, OPT, BLOOM, BLOOMZ, and LLaMA. Comprehensive results across various tasksdemonstrate the superiority of our approach. Especially, with standardquantization, OS+ can achieve near-floating-point performance on both smallmodels and large language models on 8-bit and 6-bit. Besides, we establish anew state-of-the-art for 4-bit BERT with 15.5\% improvement. Our code isavailable at \url{https://github.com/ModelTC/Outlier_Suppression_Plus}.</description><author>Xiuying Wei, Yunchen Zhang, Yuhang Li, Xiangguo Zhang, Ruihao Gong, Jinyang Guo, Xianglong Liu</author><pubDate>Fri, 20 Oct 2023 15:02:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09145v2</guid></item><item><title>Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings</title><link>http://arxiv.org/abs/2305.12027v2</link><description>Entity linking methods based on dense retrieval are an efficient and widelyused solution in large-scale applications, but they fall short of theperformance of generative models, as they are sensitive to the structure of theembedding space. In order to address this issue, this paper introduces DUCK, anapproach to infusing structural information in the space of entityrepresentations, using prior knowledge of entity types. Inspired by duck typingin programming languages, we propose to define the type of an entity based onthe relations that it has with other entities in a knowledge graph. Then,porting the concept of box embeddings to spherical polar coordinates, wepropose to represent relations as boxes on the hypersphere. We optimize themodel to cluster entities of similar type by placing them inside the boxescorresponding to their relations. Our experiments show that our method sets newstate-of-the-art results on standard entity-disambiguation benchmarks, itimproves the performance of the model by up to 7.9 F1 points, outperforms othertype-aware approaches, and matches the results of generative models with 18times more parameters.</description><author>Mattia Atzeni, Mikhail Plekhanov, Frédéric A. Dreyer, Nora Kassner, Simone Merello, Louis Martin, Nicola Cancedda</author><pubDate>Fri, 20 Oct 2023 14:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12027v2</guid></item><item><title>RaceLens: A Machine Intelligence-Based Application for Racing Photo Analysis</title><link>http://arxiv.org/abs/2310.13515v1</link><description>This paper presents RaceLens, a novel application utilizing advanced deeplearning and computer vision models for comprehensive analysis of racingphotos. The developed models have demonstrated their efficiency in a wide arrayof tasks, including detecting racing cars, recognizing car numbers, detectingand quantifying car details, and recognizing car orientations. We discuss theprocess of collecting a robust dataset necessary for training our models, anddescribe an approach we have designed to augment and improve this datasetcontinually. Our method leverages a feedback loop for continuous modelimprovement, thus enhancing the performance and accuracy of RaceLens over time.A significant part of our study is dedicated to illustrating the practicalapplication of RaceLens, focusing on its successful deployment by NASCAR teamsover four seasons. We provide a comprehensive evaluation of our system'sperformance and its direct impact on the team's strategic decisions andperformance metrics. The results underscore the transformative potential ofmachine intelligence in the competitive and dynamic world of car racing,setting a precedent for future applications.</description><author>Andrei Boiarov, Dmitry Bleklov, Pavlo Bredikhin, Nikita Koritsky, Sergey Ulasen</author><pubDate>Fri, 20 Oct 2023 14:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13515v1</guid></item><item><title>Improving Question Generation with Multi-level Content Planning</title><link>http://arxiv.org/abs/2310.13512v1</link><description>This paper addresses the problem of generating questions from a given contextand an answer, specifically focusing on questions that require multi-hopreasoning across an extended context. Previous studies have suggested that keyphrase selection is essential for question generation (QG), yet it is stillchallenging to connect such disjointed phrases into meaningful questions,particularly for long context. To mitigate this issue, we propose MultiFactor,a novel QG framework based on multi-level content planning. Specifically,MultiFactor includes two components: FA-model, which simultaneously selects keyphrases and generates full answers, and Q-model which takes the generated fullanswer as an additional input to generate questions. Here, full answergeneration is introduced to connect the short answer with the selected keyphrases, thus forming an answer-aware summary to facilitate QG. Both FA-modeland Q-model are formalized as simple-yet-effective Phrase-EnhancedTransformers, our joint model for phrase selection and text generation.Experimental results show that our method outperforms strong baselines on twopopular QG datasets. Our code is available athttps://github.com/zeaver/MultiFactor.</description><author>Zehua Xia, Qi Gou, Bowen Yu, Haiyang Yu, Fei Huang, Yongbin Li, Cam-Tu Nguyen</author><pubDate>Fri, 20 Oct 2023 14:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13512v1</guid></item><item><title>Combinatorial optimization solving by coherent Ising machines based on spiking neural networks</title><link>http://arxiv.org/abs/2208.07502v2</link><description>Spiking neural network is a kind of neuromorphic computing that is believedto improve the level of intelligence and provide advantages for quantumcomputing. In this work, we address this issue by designing an optical spikingneural network and find that it can be used to accelerate the speed ofcomputation, especially on combinatorial optimization problems. Here thespiking neural network is constructed by the antisymmetrically coupleddegenerate optical parametric oscillator pulses and dissipative pulses. Anonlinear transfer function is chosen to mitigate amplitude inhomogeneities anddestabilize the resulting local minima according to the dynamical behavior ofspiking neurons. It is numerically shown that the spiking neuralnetwork-coherent Ising machines have excellent performance on combinatorialoptimization problems, which is expected to offer new applications for neuralcomputing and optical computing.</description><author>Bo Lu, Yong-Pan Gao, Kai Wen, Chuan Wang</author><pubDate>Fri, 20 Oct 2023 14:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.07502v2</guid></item><item><title>Explaining Interactions Between Text Spans</title><link>http://arxiv.org/abs/2310.13506v1</link><description>Reasoning over spans of tokens from different parts of the input is essentialfor natural language understanding (NLU) tasks such as fact-checking (FC),machine reading comprehension (MRC) or natural language inference (NLI).However, existing highlight-based explanations primarily focus on identifyingindividual important tokens or interactions only between adjacent tokens ortuples of tokens. Most notably, there is a lack of annotations capturing thehuman decision-making process w.r.t. the necessary interactions for informeddecision-making in such tasks. To bridge this gap, we introduce SpanEx, amulti-annotator dataset of human span interaction explanations for two NLUtasks: NLI and FC. We then investigate the decision-making processes ofmultiple fine-tuned large language models in terms of the employed connectionsbetween spans in separate parts of the input and compare them to the humanreasoning processes. Finally, we present a novel community detection basedunsupervised method to extract such interaction explanations from a model'sinner workings.</description><author>Sagnik Ray Choudhury, Pepa Atanasova, Isabelle Augenstein</author><pubDate>Fri, 20 Oct 2023 14:52:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13506v1</guid></item><item><title>Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation</title><link>http://arxiv.org/abs/2310.13505v1</link><description>Models for conversational question answering (ConvQA) over knowledge graphs(KGs) are usually trained and tested on benchmarks of gold QA pairs. Thisimplies that training is limited to surface forms seen in the respectivedatasets, and evaluation is on a small set of held-out questions. Through ourproposed framework REIGN, we take several steps to remedy this restrictedlearning setup. First, we systematically generate reformulations of trainingquestions to increase robustness of models to surface form variations. This isa particularly challenging problem, given the incomplete nature of suchquestions. Second, we guide ConvQA models towards higher performance by feedingit only those reformulations that help improve their answering quality, usingdeep reinforcement learning. Third, we demonstrate the viability of trainingmajor model components on one benchmark and applying them zero-shot to another.Finally, for a rigorous evaluation of robustness for trained models, we use andrelease large numbers of diverse reformulations generated by prompting GPT forbenchmark test sets (resulting in 20x increase in sizes). Our findings showthat ConvQA models with robust training via reformulations, significantlyoutperform those with standard training from gold QA pairs only.</description><author>Magdalena Kaiser, Rishiraj Saha Roy, Gerhard Weikum</author><pubDate>Fri, 20 Oct 2023 14:51:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13505v1</guid></item><item><title>Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis</title><link>http://arxiv.org/abs/2310.10477v2</link><description>The rapid advancement of large language models (LLMs) presents bothopportunities and challenges, particularly concerning unintentional generationof harmful and toxic responses. While the traditional alignment methods striveto steer LLMs towards desired performance and shield them from maliciouscontent, this study proposes a novel alignment strategy rooted in mistakeanalysis by exposing LLMs to flawed outputs purposefully and then conducting athorough assessment to fully comprehend internal reasons via natural languageanalysis. Thus, toxic responses can be transformed into instruction tuningcorpus for model alignment, and LLMs can not only be deterred from generatingflawed responses but also trained to self-criticize, leveraging its innateability to discriminate toxic content. Experimental results demonstrate thatthe proposed method outperforms conventional alignment techniques for safetyinstruction following, while maintaining superior efficiency.</description><author>Kai Chen, Chunwei Wang, Kuo Yang, Jianhua Han, Lanqing Hong, Fei Mi, Hang Xu, Zhengying Liu, Wenyong Huang, Zhenguo Li, Dit-Yan Yeung, Lifeng Shang, Xin Jiang, Qun Liu</author><pubDate>Fri, 20 Oct 2023 14:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10477v2</guid></item><item><title>Analogical Proportions and Creativity: A Preliminary Study</title><link>http://arxiv.org/abs/2310.13500v1</link><description>Analogical proportions are statements of the form "$a$ is to $b$ as $c$ is to$d$", which expresses that the comparisons of the elements in pair $(a, b)$ andin pair $(c, d)$ yield similar results. Analogical proportions are creative inthe sense that given 3 distinct items, the representation of a 4th item $d$,distinct from the previous items, which forms an analogical proportion withthem can be calculated, provided certain conditions are met. After providing anintroduction to analogical proportions and their properties, the paper reportsthe results of an experiment made with a database of animal descriptions andtheir class, where we try to "create" new animals from existing ones,retrieving rare animals such as platypus. We perform a series of experimentsusing word embeddings as well as Boolean features in order to propose novelanimals based on analogical proportions, showing that word embeddings obtainbetter results.</description><author>Stergos Afantenos, Henri Prade, Leonardo Cortez Bernardes</author><pubDate>Fri, 20 Oct 2023 14:46:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13500v1</guid></item><item><title>DistillCSE: Distilled Contrastive Learning for Sentence Embeddings</title><link>http://arxiv.org/abs/2310.13499v1</link><description>This paper proposes the DistillCSE framework, which performs contrastivelearning under the self-training paradigm with knowledge distillation. Thepotential advantage of DistillCSE is its self-enhancing feature: using a basemodel to provide additional supervision signals, a stronger model may belearned through knowledge distillation. However, the vanilla DistillCSE throughthe standard implementation of knowledge distillation only achieves marginalimprovements due to severe overfitting. The further quantitative analysesdemonstrate the reason that the standard knowledge distillation exhibits arelatively large variance of the teacher model's logits due to the essence ofcontrastive learning. To mitigate the issue induced by high variance, thispaper accordingly proposed two simple yet effective solutions for knowledgedistillation: a Group-P shuffling strategy as an implicit regularization andthe averaging logits from multiple teacher components. Experiments on standardbenchmarks demonstrate that the proposed DistillCSE outperforms many strongbaseline methods and yields a new state-of-the-art performance.</description><author>Jiahao Xu, Wei Shao, Lihui Chen, Lemao Liu</author><pubDate>Fri, 20 Oct 2023 14:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13499v1</guid></item><item><title>Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue</title><link>http://arxiv.org/abs/2310.07659v3</link><description>Accurate knowledge selection is critical in knowledge-grounded dialoguesystems. Towards a closer look at it, we offer a novel perspective to organizeexisting literature, i.e., knowledge selection coupled with, after, and beforegeneration. We focus on the third under-explored category of study, which cannot only select knowledge accurately in advance, but has the advantage toreduce the learning, adjustment, and interpretation burden of subsequentresponse generation models, especially LLMs. We propose GATE, agenerator-agnostic knowledge selection method, to prepare knowledge forsubsequent response generation models by selecting context-related knowledgeamong different knowledge structures and variable knowledge requirements.Experimental results demonstrate the superiority of GATE, and indicate thatknowledge selection before generation is a lightweight yet effective way tofacilitate LLMs (e.g., ChatGPT) to generate more informative responses.</description><author>Lang Qin, Yao Zhang, Hongru Liang, Jun Wang, Zhenglu Yang</author><pubDate>Fri, 20 Oct 2023 14:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07659v3</guid></item><item><title>Description Logics with Abstraction and Refinement</title><link>http://arxiv.org/abs/2306.03717v3</link><description>Ontologies often require knowledge representation on multiple levels ofabstraction, but description logics (DLs) are not well-equipped for supportingthis. We propose an extension of DLs in which abstraction levels arefirst-class citizens and which provides explicit operators for the abstractionand refinement of concepts and roles across multiple abstraction levels, basedon conjunctive queries. We prove that reasoning in the resulting family of DLsis decidable while several seemingly harmless variations turn out to beundecidable. We also pinpoint the precise complexity of our logics and severalrelevant fragments.</description><author>Carsten Lutz, Lukas Schulze</author><pubDate>Fri, 20 Oct 2023 14:42:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03717v3</guid></item></channel></rss>