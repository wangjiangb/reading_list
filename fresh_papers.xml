<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 04 Jun 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>GIFT: Generative Interpretable Fine-Tuning</title><link>http://arxiv.org/abs/2312.00700v2</link><description>We present Generative Interpretable Fine-Tuning (GIFT) forparameter-efficient fine-tuning of pretrained Transformer backbones, which canbe formulated as a simple factorized matrix multiplication in the parameterspace or equivalently in the activation space, and thus embraces built-ininterpretability. For a pretrained layer with weights $\omega\in\mathbb{R}^{d_{out}\times d_{in}}$, our proposed GIFT learns the fine-tunedweights $\hat{\omega}$ directly from $\omega$ as $\hat{\omega}=\omega \cdot(\mathbb{I}+\phi_{d_{in}\times r}\cdot \psi_{r\times d_{in}})$ where$\mathbb{I}$ is an identity matrix. $\Theta=(\phi, \psi)$ are the learnableparameters of the two linear layers of GIFT with $r$ being a hyper-parameter.$\Theta$ is shared by all the layers selected for fine-tuning, resulting insignificantly fewer trainable parameters compared to Low-Rank Adaptation(LoRA). We perform comprehensive evaluations on natural language tasks(commonsense reasoning and sequence classification) and computer vision tasks(visual fine-grained classification). We obtain the best accuracy and parameterefficiency among baselines both on the Commonsense170k reasoning benchmarkusing LLaMA-1 (7B) and Llama-2 (7B)/-3 (8B) and on the FGVC and VTAB visualrecognition benchmarks using ImageNet-21k pretrained Vision Transformer(ViT-B/16). Notably, we obtain 5.9% absolute increase in average accuracy with53.8 times reduction of parameters on Commonsense170k using Llama-3 (8B)compared to LoRA. We obtain performance comparable to LoRA on the GLUEbenchmark but with significantly fewer parameters using RoBERTa-Base/Large. Weshow the output of the first linear layer (i.e., $\omega\cdot \phi$) issurprisingly interpretable, which can play the role of a token-clustering headas a by-product to localize meaningful objects/parts in images for computervision tasks. Our code is publicly available.</description><author>Chinmay Savadikar, Xi Song, Tianfu Wu</author><pubDate>Mon, 03 Jun 2024 18:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00700v2</guid></item><item><title>Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series</title><link>http://arxiv.org/abs/2401.03955v6</link><description>Large pre-trained models excel in zero/few-shot learning for language andvision tasks but face challenges in multivariate time series (TS) forecastingdue to diverse data characteristics. Consequently, recent research efforts havefocused on developing pre-trained TS forecasting models. These models, whetherbuilt from scratch or adapted from large language models (LLMs), excel inzero/few-shot forecasting tasks. However, they are limited by slow performance,high computational demands, and neglect of cross-channel and exogenouscorrelations. To address this, we introduce Tiny Time Mixers (TTM), a compactmodel (starting from 1M parameters) with effective transfer learningcapabilities, trained exclusively on public TS datasets. TTM, based on thelight-weight TSMixer architecture, incorporates innovations like adaptivepatching, diverse resolution sampling, and resolution prefix tuning to handlepre-training on varied dataset resolutions with minimal model capacity.Additionally, it employs multi-level modeling to capture channel correlationsand infuse exogenous signals during fine-tuning. TTM outperforms existingpopular benchmarks in zero/few-shot forecasting by (4-40\%), while reducingcomputational requirements significantly. Moreover, TTMs are lightweight andcan be executed even on CPU-only machines, enhancing usability and fosteringwider adoption in resource-constrained environments. Model weights for ourinitial variant (TTM-Q) are available athttps://huggingface.co/ibm-granite/granite-timeseries-ttm-v1. Model weights formore sophisticated variants (TTM-B, TTM-E, and TTM-A) will be shared soon. Thesource code for TTM can be accessed athttps://github.com/ibm-granite/granite-tsfm/tree/main/tsfm_public/models/tinytimemixer.</description><author>Vijay Ekambaram, Arindam Jati, Pankaj Dayama, Sumanta Mukherjee, Nam H. Nguyen, Wesley M. Gifford, Chandra Reddy, Jayant Kalagnanam</author><pubDate>Mon, 03 Jun 2024 18:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03955v6</guid></item><item><title>Mitigating Motion Blur in Neural Radiance Fields with Events and Frames</title><link>http://arxiv.org/abs/2403.19780v2</link><description>Neural Radiance Fields (NeRFs) have shown great potential in novel viewsynthesis. However, they struggle to render sharp images when the data used fortraining is affected by motion blur. On the other hand, event cameras excel indynamic scenes as they measure brightness changes with microsecond resolutionand are thus only marginally affected by blur. Recent methods attempt toenhance NeRF reconstructions under camera motion by fusing frames and events.However, they face challenges in recovering accurate color content or constrainthe NeRF to a set of predefined camera poses, harming reconstruction quality inchallenging conditions. This paper proposes a novel formulation addressingthese issues by leveraging both model- and learning-based modules. Weexplicitly model the blur formation process, exploiting the event doubleintegral as an additional model-based prior. Additionally, we model theevent-pixel response using an end-to-end learnable response function, allowingour method to adapt to non-idealities in the real event-camera sensor. We show,on synthetic and real data, that the proposed approach outperforms existingdeblur NeRFs that use only frames as well as those that combine frames andevents by +6.13dB and +2.48dB, respectively.</description><author>Marco Cannici, Davide Scaramuzza</author><pubDate>Mon, 03 Jun 2024 18:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19780v2</guid></item><item><title>MIM-Refiner: A Contrastive Learning Boost from Intermediate Pre-Trained Representations</title><link>http://arxiv.org/abs/2402.10093v2</link><description>We introduce MIM (Masked Image Modeling)-Refiner, a contrastive learningboost for pre-trained MIM models. MIM-Refiner is motivated by the insight thatstrong representations within MIM models generally reside in intermediatelayers. Accordingly, MIM-Refiner leverages multiple contrastive heads that areconnected to different intermediate layers. In each head, a modified nearestneighbor objective constructs semantic clusters that capture semanticinformation which improves performance on downstream tasks, includingoff-the-shelf and fine-tuning settings. The refinement process is short and simple - yet highly effective. Within afew epochs, we refine the features of MIM models from subpar tostate-of-the-art, off-the-shelf features. Refining a ViT-H, pre-trained withdata2vec 2.0 on ImageNet-1K, sets a new state-of-the-art in linear probing(84.7%) and low-shot classification among models that are pre-trained onImageNet-1K. At ImageNet-1K 1-shot classification, MIM-Refiner advances thestate-of-the-art to 64.2%, outperforming larger models that were trained on upto 2000 times more data such as DINOv2-g, OpenCLIP-G and MAWS-6.5B.</description><author>Benedikt Alkin, Lukas Miklautz, Sepp Hochreiter, Johannes Brandstetter</author><pubDate>Mon, 03 Jun 2024 18:51:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10093v2</guid></item><item><title>ReShader: View-Dependent Highlights for Single Image View-Synthesis</title><link>http://arxiv.org/abs/2309.10689v3</link><description>In recent years, novel view synthesis from a single image has seensignificant progress thanks to the rapid advancements in 3D scenerepresentation and image inpainting techniques. While the current approachesare able to synthesize geometrically consistent novel views, they often do nothandle the view-dependent effects properly. Specifically, the highlights intheir synthesized images usually appear to be glued to the surfaces, making thenovel views unrealistic. To address this major problem, we make a keyobservation that the process of synthesizing novel views requires changing theshading of the pixels based on the novel camera, and moving them to appropriatelocations. Therefore, we propose to split the view synthesis process into twoindependent tasks of pixel reshading and relocation. During the reshadingprocess, we take the single image as the input and adjust its shading based onthe novel camera. This reshaded image is then used as the input to an existingview synthesis method to relocate the pixels and produce the final novel viewimage. We propose to use a neural network to perform reshading and generate alarge set of synthetic input-reshaded pairs to train our network. Wedemonstrate that our approach produces plausible novel view images withrealistic moving highlights on a variety of real world scenes.</description><author>Avinash Paliwal, Brandon Nguyen, Andrii Tsarov, Nima Khademi Kalantari</author><pubDate>Mon, 03 Jun 2024 18:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10689v3</guid></item><item><title>Loss Symmetry and Noise Equilibrium of Stochastic Gradient Descent</title><link>http://arxiv.org/abs/2402.07193v2</link><description>Symmetries exist abundantly in the loss function of neural networks. Wecharacterize the learning dynamics of stochastic gradient descent (SGD) whenexponential symmetries, a broad subclass of continuous symmetries, exist in theloss function. We establish that when gradient noises do not balance, SGD hasthe tendency to move the model parameters toward a point where noises fromdifferent directions are balanced. Here, a special type of fixed point in theconstant directions of the loss function emerges as a candidate for solutionsfor SGD. As the main theoretical result, we prove that every parameter $\theta$connects without loss function barrier to a unique noise-balanced fixed point$\theta^*$. The theory implies that the balancing of gradient noise can serveas a novel alternative mechanism for relevant phenomena such as progressivesharpening and flattening and can be applied to understand common practicalproblems such as representation normalization, matrix factorization, warmup,and formation of latent representations.</description><author>Liu Ziyin, Mingze Wang, Hongchao Li, Lei Wu</author><pubDate>Mon, 03 Jun 2024 18:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07193v2</guid></item><item><title>A Survey on Self-Evolution of Large Language Models</title><link>http://arxiv.org/abs/2404.14387v2</link><description>Large language models (LLMs) have significantly advanced in various fieldsand intelligent agent applications. However, current LLMs that learn from humanor external model supervision are costly and may face performance ceilings astask complexity and diversity increase. To address this issue, self-evolutionapproaches that enable LLM to autonomously acquire, refine, and learn fromexperiences generated by the model itself are rapidly growing. This newtraining paradigm inspired by the human experiential learning process offersthe potential to scale LLMs towards superintelligence. In this work, we presenta comprehensive survey of self-evolution approaches in LLMs. We first propose aconceptual framework for self-evolution and outline the evolving process asiterative cycles composed of four phases: experience acquisition, experiencerefinement, updating, and evaluation. Second, we categorize the evolutionobjectives of LLMs and LLM-based agents; then, we summarize the literature andprovide taxonomy and insights for each module. Lastly, we pinpoint existingchallenges and propose future directions to improve self-evolution frameworks,equipping researchers with critical insights to fast-track the development ofself-evolving LLMs. Our corresponding GitHub repository is available athttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM</description><author>Zhengwei Tao, Ting-En Lin, Xiancai Chen, Hangyu Li, Yuchuan Wu, Yongbin Li, Zhi Jin, Fei Huang, Dacheng Tao, Jingren Zhou</author><pubDate>Mon, 03 Jun 2024 18:47:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14387v2</guid></item><item><title>A Stochastic-Geometrical Framework for Object Pose Estimation based on Mixture Models Avoiding the Correspondence Problem</title><link>http://arxiv.org/abs/2311.18107v5</link><description>Background: Pose estimation of rigid objects is a practical challenge inoptical metrology and computer vision. This paper presents a novelstochastic-geometrical modeling framework for object pose estimation based onobserving multiple feature points. Methods: This framework utilizes mixture models for feature point densitiesin object space and for interpreting real measurements. Advantages are theavoidance to resolve individual feature correspondences and to incorporatecorrect stochastic dependencies in multi-view applications. First, the generalmodeling framework is presented, second, a general algorithm for poseestimation is derived, and third, two example models (camera and laterationsetup) are presented. Results: Numerical experiments show the effectiveness of this modeling andgeneral algorithm by presenting four simulation scenarios for three observationsystems, including the dependence on measurement resolution, objectdeformations and measurement noise. Probabilistic modeling utilizing mixturemodels shows the potential for accurate and robust pose estimations whileavoiding the correspondence problem.</description><author>Wolfgang Hoegele</author><pubDate>Mon, 03 Jun 2024 18:46:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18107v5</guid></item><item><title>PixT3: Pixel-based Table-To-Text Generation</title><link>http://arxiv.org/abs/2311.09808v3</link><description>Table-to-text generation involves generating appropriate textual descriptionsgiven structured tabular data. It has attracted increasing attention in recentyears thanks to the popularity of neural network models and the availability oflarge-scale datasets. A common feature across existing methods is theirtreatment of the input as a string, i.e., by employing linearization techniquesthat do not always preserve information in the table, are verbose, and lackspace efficiency. We propose to rethink data-to-text generation as a visualrecognition task, removing the need for rendering the input in a string format.We present PixT3, a multimodal table-to-text model that overcomes thechallenges of linearization and input size limitations encountered by existingmodels. PixT3 is trained with a new self-supervised learning objective toreinforce table structure awareness and is applicable to open-ended andcontrolled generation settings. Experiments on the ToTTo and Logic2Textbenchmarks show that PixT3 is competitive and, in some settings, superior togenerators that operate solely on text.</description><author>Iñigo Alonso, Eneko Agirre, Mirella Lapata</author><pubDate>Mon, 03 Jun 2024 18:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09808v3</guid></item><item><title>DITTO: Diffusion Inference-Time T-Optimization for Music Generation</title><link>http://arxiv.org/abs/2401.12179v2</link><description>We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purposeframe-work for controlling pre-trained text-to-music diffusion models atinference-time via optimizing initial noise latents. Our method can be used tooptimize through any differentiable feature matching loss to achieve a target(stylized) output and leverages gradient checkpointing for memory efficiency.We demonstrate a surprisingly wide-range of applications for music generationincluding inpainting, outpainting, and looping as well as intensity, melody,and musical structure control - all without ever fine-tuning the underlyingmodel. When we compare our approach against related training, guidance, andoptimization-based methods, we find DITTO achieves state-of-the-art performanceon nearly all tasks, including outperforming comparable approaches oncontrollability, audio quality, and computational efficiency, thus opening thedoor for high-quality, flexible, training-free control of diffusion models.Sound examples can be found at https://DITTO-Music.github.io/web/.</description><author>Zachary Novack, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas J. Bryan</author><pubDate>Mon, 03 Jun 2024 18:37:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12179v2</guid></item><item><title>Addressing Diverging Training Costs using Local Restoration for Precise Bird's Eye View Map Construction</title><link>http://arxiv.org/abs/2405.01016v2</link><description>Recent advancements in Bird's Eye View (BEV) fusion for map construction havedemonstrated remarkable mapping of urban environments. However, their deep andbulky architecture incurs substantial amounts of backpropagation memory andcomputing latency. Consequently, the problem poses an unavoidable bottleneck inconstructing high-resolution (HR) BEV maps, as their large-sized features causesignificant increases in costs including GPU memory consumption and computinglatency, named diverging training costs issue. Affected by the problem, mostexisting methods adopt low-resolution (LR) BEV and struggle to estimate theprecise locations of urban scene components like road lanes, and sidewalks. Asthe imprecision leads to risky self-driving, the diverging training costs issuehas to be resolved. In this paper, we address the issue with our novel TrumpetNeural Network (TNN) mechanism. The framework utilizes LR BEV space and outputsan up-sampled semantic BEV map to create a memory-efficient pipeline. To thisend, we introduce Local Restoration of BEV representation. Specifically, theup-sampled BEV representation has severely aliased, blocky signals, and thicksemantic labels. Our proposed Local Restoration restores the signals and thins(or narrows down) the width of the labels. Our extensive experiments show thatthe TNN mechanism provides a plug-and-play memory-efficient pipeline, therebyenabling the effective estimation of real-sized (or precise) semantic labelsfor BEV map construction.</description><author>Minsu Kim, Giseop Kim, Sunwook Choi</author><pubDate>Mon, 03 Jun 2024 18:36:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01016v2</guid></item><item><title>Arrows of Time for Large Language Models</title><link>http://arxiv.org/abs/2401.17505v3</link><description>We study the probabilistic modeling performed by Autoregressive LargeLanguage Models (LLMs) through the angle of time directionality, addressing aquestion first raised in (Shannon, 1951). For large enough models, weempirically find a time asymmetry in their ability to learn natural language: adifference in the average log-perplexity when trying to predict the next tokenversus when trying to predict the previous one. This difference is at the sametime subtle and very consistent across various modalities (language, modelsize, training time, ...). Theoretically, this is surprising: from aninformation-theoretic point of view, there should be no such difference. Weprovide a theoretical framework to explain how such an asymmetry can appearfrom sparsity and computational complexity considerations, and outline a numberof perspectives opened by our results.</description><author>Vassilis Papadopoulos, Jérémie Wenger, Clément Hongler</author><pubDate>Mon, 03 Jun 2024 18:35:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17505v3</guid></item><item><title>The Origin of Information Handling</title><link>http://arxiv.org/abs/2404.04374v2</link><description>A major challenge when describing the origin of life is to explain howinstructional information control systems emerge naturally and spontaneouslyfrom mere molecular dynamics. So far, no one has clarified how informationcontrol emerged ab initio and how primitive control mechanisms in life mighthave evolved, becoming increasingly refined. Based on recent experimentalresults showing that chemical computation does not require the presence oflife-related chemistry, we elucidate the origin and early evolution ofinformation handling by chemical automata, from information processing(computation) to information storage (memory) and information transmission(communication). In contrast to other theories that assume the existence ofinitial complex structures, our narrative starts from trivial self-replicatorswhose interaction leads to the arising of more powerful molecular machines. Bydescribing precisely the primordial transitions in chemistry-based computation,our metaphor is capable of explaining the above-mentioned gaps and can betranslated to other models of computation, which allow us to explore biologicalphenomena at multiple spatial and temporal scales. At the end of ourmanuscript, we propose some ways to extend our ideas, including experimentalvalidation of our theory (both in vitro and in silico).</description><author>Amahury Jafet López-Díaz, Hiroki Sayama, Carlos Gershenson</author><pubDate>Mon, 03 Jun 2024 18:30:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04374v2</guid></item><item><title>The Topology and Geometry of Neural Representations</title><link>http://arxiv.org/abs/2309.11028v3</link><description>A central question for neuroscience is how to characterize brainrepresentations of perceptual and cognitive content. An ideal characterizationshould distinguish different functional regions with robustness to noise andidiosyncrasies of individual brains that do not correspond to computationaldifferences. Previous studies have characterized brain representations by theirrepresentational geometry, which is defined by the representationaldissimilarity matrix (RDM), a summary statistic that abstracts from the rolesof individual neurons (or responses channels) and characterizes thediscriminability of stimuli. Here we explore a further step of abstraction:from the geometry to the topology of brain representations. We proposetopological representational similarity analysis (tRSA), an extension ofrepresentational similarity analysis (RSA) that uses a family ofgeo-topological summary statistics that generalizes the RDM to characterize thetopology while de-emphasizing the geometry. We evaluate this new family ofstatistics in terms of the sensitivity and specificity for model selectionusing both simulations and fMRI data. In the simulations, the ground truth is adata-generating layer representation in a neural network model and the modelsare the same and other layers in different model instances (trained fromdifferent random seeds). In fMRI, the ground truth is a visual area and themodels are the same and other areas measured in different subjects. Resultsshow that topology-sensitive characterizations of population codes are robustto noise and interindividual variability and maintain excellent sensitivity tothe unique representational signatures of different neural network layers andbrain regions. These methods enable researchers to calibrate comparisons amongrepresentations in brains and models to be sensitive to the geometry, thetopology, or a combination of both.</description><author>Baihan Lin, Nikolaus Kriegeskorte</author><pubDate>Mon, 03 Jun 2024 18:22:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11028v3</guid></item><item><title>U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers</title><link>http://arxiv.org/abs/2405.02730v2</link><description>Diffusion Transformers (DiTs) introduce the transformer architecture todiffusion tasks for latent-space image generation. With an isotropicarchitecture that chains a series of transformer blocks, DiTs demonstratecompetitive performance and good scalability; but meanwhile, the abandonment ofU-Net by DiTs and their following improvements is worth rethinking. To thisend, we conduct a simple toy experiment by comparing a U-Net architectured DiTwith an isotropic one. It turns out that the U-Net architecture only gain aslight advantage amid the U-Net inductive bias, indicating potentialredundancies within the U-Net-style DiT. Inspired by the discovery that U-Netbackbone features are low-frequency-dominated, we perform token downsampling onthe query-key-value tuple for self-attention that bring further improvementsdespite a considerable amount of reduction in computation. Based onself-attention with downsampled tokens, we propose a series of U-shaped DiTs(U-DiTs) in the paper and conduct extensive experiments to demonstrate theextraordinary performance of U-DiT models. The proposed U-DiT could outperformDiT-XL/2 with only 1/6 of its computation cost. Codes are available athttps://github.com/YuchuanTian/U-DiT.</description><author>Yuchuan Tian, Zhijun Tu, Hanting Chen, Jie Hu, Chao Xu, Yunhe Wang</author><pubDate>Mon, 03 Jun 2024 18:14:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02730v2</guid></item><item><title>Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation</title><link>http://arxiv.org/abs/2403.17846v2</link><description>Recent open-vocabulary robot mapping methods enrich dense geometric maps withpre-trained visual-language features. While these maps allow for the predictionof point-wise saliency maps when queried for a certain language concept,large-scale environments and abstract queries beyond the object level stillpose a considerable hurdle, ultimately limiting language-grounded roboticnavigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3Dscene graph mapping approach for language-grounded robot navigation. Leveragingopen-vocabulary vision foundation models, we first obtain state-of-the-artopen-vocabulary segment-level maps in 3D and subsequently construct a 3D scenegraph hierarchy consisting of floor, room, and object concepts, each enrichedwith open-vocabulary features. Our approach is able to represent multi-storybuildings and allows robotic traversal of those using a cross-floor Voronoigraph. HOV-SG is evaluated on three distinct datasets and surpasses previousbaselines in open-vocabulary semantic accuracy on the object, room, and floorlevel while producing a 75% reduction in representation size compared to denseopen-vocabulary maps. In order to prove the efficacy and generalizationcapabilities of HOV-SG, we showcase successful long-horizonlanguage-conditioned robot navigation within real-world multi-storageenvironments. We provide code and trial video data at http://hovsg.github.io/.</description><author>Abdelrhman Werby, Chenguang Huang, Martin Büchner, Abhinav Valada, Wolfram Burgard</author><pubDate>Mon, 03 Jun 2024 18:12:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17846v2</guid></item><item><title>Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs</title><link>http://arxiv.org/abs/2401.04854v3</link><description>Are LLMs cultural technologies like photocopiers or printing presses, whichtransmit information but cannot create new content? A challenge for this idea,which we call bibliotechnism, is that LLMs generate novel text. We begin with adefense of bibliotechnism, showing how even novel text may inherit its meaningfrom original human-generated text. We then argue that bibliotechnism faces anindependent challenge from examples in which LLMs generate novel reference,using new names to refer to new entities. Such examples could be explained ifLLMs were not cultural technologies but had beliefs, desires, and intentions.According to interpretationism in the philosophy of mind, a system has suchattitudes if and only if its behavior is well explained by the hypothesis thatit does. Interpretationists may hold that LLMs have attitudes, and thus have asimple solution to the novel reference problem. We emphasize, however, thatinterpretationism is compatible with very simple creatures having attitudes anddiffers sharply from views that presuppose these attitudes requireconsciousness, sentience, or intelligence (topics about which we make noclaims).</description><author>Harvey Lederman, Kyle Mahowald</author><pubDate>Mon, 03 Jun 2024 18:01:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04854v3</guid></item><item><title>Clover: Closed-Loop Verifiable Code Generation</title><link>http://arxiv.org/abs/2310.17807v3</link><description>The use of large language models for code generation is a rapidly growingtrend in software development. However, without effective methods for ensuringthe correctness of generated code, this trend could lead to any number ofundesirable outcomes. In this paper, we lay out a vision for addressing thischallenge: the Clover paradigm, short for Closed-Loop Verifiable CodeGeneration, which reduces correctness checking to the more accessible problemof consistency checking. At the core of Clover lies a checker that performsconsistency checks among code, docstrings, and formal annotations. The checkeris implemented using a novel integration of formal verification tools and largelanguage models. We provide a theoretical analysis to support our thesis thatClover should be effective at consistency checking. We also empiricallyinvestigate its feasibility on a hand-designed dataset (CloverBench) featuringannotated Dafny programs at a textbook level of difficulty. Experimentalresults show that for this dataset, (i) LLMs are reasonably successful atautomatically generating formal specifications; and (ii) our consistencychecker achieves a promising acceptance rate (up to 87%) for correct instanceswhile maintaining zero tolerance for incorrect ones (no false positives).</description><author>Chuyue Sun, Ying Sheng, Oded Padon, Clark Barrett</author><pubDate>Mon, 03 Jun 2024 17:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17807v3</guid></item><item><title>VIEScore: Towards Explainable Metrics for Conditional Image Synthesis Evaluation</title><link>http://arxiv.org/abs/2312.14867v2</link><description>In the rapidly advancing field of conditional image generation research,challenges such as limited explainability lie in effectively evaluating theperformance and capabilities of various models. This paper introduces VIEScore,a Visual Instruction-guided Explainable metric for evaluating any conditionalimage generation tasks. VIEScore leverages general knowledge from MultimodalLarge Language Models (MLLMs) as the backbone and does not require training orfine-tuning. We evaluate VIEScore on seven prominent tasks in conditional imagetasks and found: (1) VIEScore (GPT4-o) achieves a high Spearman correlation of0.4 with human evaluations, while the human-to-human correlation is 0.45. (2)VIEScore (with open-source MLLM) is significantly weaker than GPT-4o and GPT-4vin evaluating synthetic images. (3) VIEScore achieves a correlation on par withhuman ratings in the generation tasks but struggles in editing tasks. Withthese results, we believe VIEScore shows its great potential to replace humanjudges in evaluating image synthesis tasks.</description><author>Max Ku, Dongfu Jiang, Cong Wei, Xiang Yue, Wenhu Chen</author><pubDate>Mon, 03 Jun 2024 17:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14867v2</guid></item><item><title>NeuSpeech: Decode Neural signal as Speech</title><link>http://arxiv.org/abs/2403.01748v3</link><description>Decoding language from brain dynamics is an important open direction in therealm of brain-computer interface (BCI), especially considering the rapidgrowth of large language models. Compared to invasive-based signals whichrequire electrode implantation surgery, non-invasive neural signals (e.g. EEG,MEG) have attracted increasing attention considering their safety andgenerality. However, the exploration is not adequate in three aspects: 1)previous methods mainly focus on EEG but none of the previous works addressthis problem on MEG with better signal quality; 2) prior works havepredominantly used $``teacher-forcing"$ during generative decoding, which isimpractical; 3) prior works are mostly $``BART-based"$ not fullyauto-regressive, which performs better in other sequence tasks. In this paper,we explore the brain-to-text translation of MEG signals in a speech-decodingformation. Here we are the first to investigate a cross-attention-based``whisper" model for generating text directly from MEG signals without teacherforcing. Our model achieves impressive BLEU-1 scores of 60.30 and 52.89 withoutpretraining $\&amp;$ teacher-forcing on two major datasets ($\textit{GWilliams}$and $\textit{Schoffelen}$). This paper conducts a comprehensive review tounderstand how speech decoding formation performs on the neural decoding tasks,including pretraining initialization, training $\&amp;$ evaluation set splitting,augmentation, and scaling law. Code is available athttps://github.com/NeuSpeech/NeuSpeech1$.</description><author>Yiqian Yang, Yiqun Duan, Qiang Zhang, Hyejeong Jo, Jinni Zhou, Won Hee Lee, Renjing Xu, Hui Xiong</author><pubDate>Mon, 03 Jun 2024 17:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01748v3</guid></item><item><title>Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering</title><link>http://arxiv.org/abs/2402.08277v5</link><description>Advances towards more faithful and traceable answers of Large Language Models(LLMs) are crucial for various research and practical endeavors. One avenue inreaching this goal is basing the answers on reliable sources. However, thisEvidence-Based QA has proven to work insufficiently with LLMs in terms ofciting the correct sources (source quality) and truthfully representing theinformation within sources (answer attributability). In this work, wesystematically investigate how to robustly fine-tune LLMs for better sourcequality and answer attributability. Specifically, we introduce a datageneration pipeline with automated data quality filters, which can synthesizediversified high-quality training and testing data at scale. We furtherintroduce four test sets to benchmark the robustness of fine-tuned specialistmodels. Extensive evaluation shows that fine-tuning on synthetic data improvesperformance on both in- and out-of-distribution. Furthermore, we show that dataquality, which can be drastically improved by proposed quality filters, mattersmore than quantity in improving Evidence-Based QA.</description><author>Tobias Schimanski, Jingwei Ni, Mathias Kraus, Elliott Ash, Markus Leippold</author><pubDate>Mon, 03 Jun 2024 17:48:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08277v5</guid></item><item><title>The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency, and Usability in Artificial Intelligence</title><link>http://arxiv.org/abs/2403.13784v3</link><description>Generative AI (GAI) offers unprecedented opportunities for research andinnovation, but its commercialization has raised concerns about transparency,reproducibility, and safety. Many open GAI models lack the necessary componentsfor full understanding and reproducibility, and some use restrictive licenseswhilst claiming to be ``open-source''. To address these concerns, we proposethe Model Openness Framework (MOF), a ranked classification system that ratesmachine learning models based on their completeness and openness, followingprinciples of open science, open source, open data, and open access. The MOFrequires specific components of the model development lifecycle to be includedand released under appropriate open licenses. This framework aims to preventmisrepresentation of models claiming to be open, guide researchers anddevelopers in providing all model components under permissive licenses, andhelp individuals and organizations identify models that can be safely adoptedwithout restrictions. By promoting transparency and reproducibility, the MOFcombats ``openwashing'' practices and establishes completeness and openness asprimary criteria alongside the core tenets of responsible AI. Wide adoption ofthe MOF will foster a more open AI ecosystem, benefiting research, innovation,and adoption of state-of-the-art models.</description><author>Matt White, Ibrahim Haddad, Cailean Osborne, Xiao-Yang Liu Yanglet, Ahmed Abdelmonsef, Sachin Varghese</author><pubDate>Mon, 03 Jun 2024 17:44:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13784v3</guid></item><item><title>Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models</title><link>http://arxiv.org/abs/2405.14555v4</link><description>Research on Large Language Models (LLMs) has often neglected subtle biasesthat, although less apparent, can significantly influence the models' outputstoward particular social narratives. This study addresses two such biaseswithin LLMs: representative bias, which denotes a tendency of LLMs to generateoutputs that mirror the experiences of certain identity groups, and affinitybias, reflecting the models' evaluative preferences for specific narratives orviewpoints. We introduce two novel metrics to measure these biases: theRepresentative Bias Score (RBS) and the Affinity Bias Score (ABS), and presentthe Creativity-Oriented Generation Suite (CoGS), a collection of open-endedtasks such as short story writing and poetry composition, designed withcustomized rubrics to detect these subtle biases. Our analysis uncovers markedrepresentative biases in prominent LLMs, with a preference for identitiesassociated with being white, straight, and men. Furthermore, our investigationof affinity bias reveals distinctive evaluative patterns within each model,akin to `bias fingerprints'. This trend is also seen in human evaluators,highlighting a complex interplay between human and machine bias perceptions.</description><author>Abhishek Kumar, Sarfaroz Yunusov, Ali Emami</author><pubDate>Mon, 03 Jun 2024 17:43:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14555v4</guid></item><item><title>Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge</title><link>http://arxiv.org/abs/2405.16277v3</link><description>Large Language Models (LLMs) have demonstrated remarkable success in taskslike the Winograd Schema Challenge (WSC), showcasing advanced textualcommon-sense reasoning. However, applying this reasoning to multimodal domains,where understanding text and images together is essential, remains asubstantial challenge. To address this, we introduce WinoVis, a novel datasetspecifically designed to probe text-to-image models on pronoun disambiguationwithin multimodal contexts. Utilizing GPT-4 for prompt generation and DiffusionAttentive Attribution Maps (DAAM) for heatmap analysis, we propose a novelevaluation framework that isolates the models' ability in pronoundisambiguation from other visual processing challenges. Evaluation ofsuccessive model versions reveals that, despite incremental advancements,Stable Diffusion 2.0 achieves a precision of 56.7% on WinoVis, only marginallysurpassing random guessing. Further error analysis identifies important areasfor future research aimed at advancing text-to-image models in their ability tointerpret and interact with the complex visual world.</description><author>Brendan Park, Madeline Janecek, Naser Ezzati-Jivan, Yifeng Li, Ali Emami</author><pubDate>Mon, 03 Jun 2024 17:42:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16277v3</guid></item><item><title>Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models</title><link>http://arxiv.org/abs/2405.16282v3</link><description>As the use of Large Language Models (LLMs) becomes more widespread,understanding their self-evaluation of confidence in generated responsesbecomes increasingly important as it is integral to the reliability of theoutput of these models. We introduce the concept of Confidence-ProbabilityAlignment, that connects an LLM's internal confidence, quantified by tokenprobabilities, to the confidence conveyed in the model's response whenexplicitly asked about its certainty. Using various datasets and promptingtechniques that encourage model introspection, we probe the alignment betweenmodels' internal and expressed confidence. These techniques encompass usingstructured evaluation scales to rate confidence, including answer options whenprompting, and eliciting the model's confidence level for outputs it does notrecognize as its own. Notably, among the models analyzed, OpenAI's GPT-4 showedthe strongest confidence-probability alignment, with an average Spearman's$\hat{\rho}$ of 0.42, across a wide range of tasks. Our work contributes to theongoing efforts to facilitate risk assessment in the application of LLMs and tofurther our understanding of model trustworthiness.</description><author>Abhishek Kumar, Robert Morabito, Sanzhar Umbet, Jad Kabbara, Ali Emami</author><pubDate>Mon, 03 Jun 2024 17:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16282v3</guid></item><item><title>ValiTex -- a unified validation framework for computational text-based measures of social constructs</title><link>http://arxiv.org/abs/2307.02863v5</link><description>Guidance on how to validate computational text-based measures of socialconstructs is fragmented. While researchers generally acknowledge theimportance of validating text-based measures, they often lack a sharedvocabulary and a unified framework to do so. This paper introduces ValiText, anew validation framework designed to assist scholars in validly measuringsocial constructs in textual data. The framework is built on a conceptualfoundation of validity in the social sciences, strengthened by an empiricalreview of validation practices in the social sciences and consultations withexperts. Ultimately, ValiText prescribes researchers to demonstrate three typesof validation evidence: substantive evidence (outlining the theoreticalunderpinning of the measure), structural evidence (examining the properties ofthe text model and its output) and external evidence (testing for how themeasure relates to independent information). The framework is furthersupplemented by a checklist of validation steps, offering practical guidance inthe form of documentation sheets that guide researchers in the validationprocess.</description><author>Lukas Birkenmaier, Claudia Wagner, Clemens Lechner</author><pubDate>Mon, 03 Jun 2024 17:32:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02863v5</guid></item><item><title>Feature Attribution with Necessity and Sufficiency via Dual-stage Perturbation Test for Causal Explanation</title><link>http://arxiv.org/abs/2402.08845v3</link><description>We investigate the problem of explainability for machine learning models,focusing on Feature Attribution Methods (FAMs) that evaluate feature importancethrough perturbation tests. Despite their utility, FAMs struggle to distinguishthe contributions of different features, when their prediction changes aresimilar after perturbation. To enhance FAMs' discriminative power, we introduceFeature Attribution with Necessity and Sufficiency (FANS), which find aneighborhood of the input such that perturbing samples within this neighborhoodhave a high Probability of being Necessity and Sufficiency (PNS) cause for thechange in predictions, and use this PNS as the importance of the feature.Specifically, FANS compute this PNS via a heuristic strategy for estimating theneighborhood and a perturbation test involving two stages (factual andinterventional) for counterfactual reasoning. To generate counterfactualsamples, we use a resampling-based approach on the observed samples toapproximate the required conditional distribution. We demonstrate that FANSoutperforms existing attribution methods on six benchmarks. Please refer to thesource code via \url{https://github.com/DMIRLAB-Group/FANS}.</description><author>Xuexin Chen, Ruichu Cai, Zhengting Huang, Yuxuan Zhu, Julien Horwood, Zhifeng Hao, Zijian Li, Jose Miguel Hernandez-Lobato</author><pubDate>Mon, 03 Jun 2024 17:29:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08845v3</guid></item><item><title>XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare</title><link>http://arxiv.org/abs/2405.06270v3</link><description>The integration of Large Language Models (LLMs) into healthcare diagnosticsoffers a promising avenue for clinical decision-making. This study outlines thedevelopment of a novel method for zero-shot/few-shot in-context learning (ICL)by integrating medical domain knowledge using a multi-layered structuredprompt. We also explore the efficacy of two communication styles between theuser and LLMs: the Numerical Conversational (NC) style, which processes dataincrementally, and the Natural Language Single-Turn (NL-ST) style, whichemploys long narrative prompts. Our study systematically evaluates the diagnostic accuracy and risk factors,including gender bias and false negative rates, using a dataset of 920 patientrecords in various few-shot scenarios. Results indicate that traditionalclinical machine learning (ML) models generally outperform LLMs in zero-shotand few-shot settings. However, the performance gap narrows significantly whenemploying few-shot examples alongside effective explainable AI (XAI) methods assources of domain knowledge. Moreover, with sufficient time and an increasednumber of examples, the conversational style (NC) nearly matches theperformance of ML models. Most notably, LLMs demonstrate comparable or superiorcost-sensitive accuracy relative to ML models. This research confirms that, with appropriate domain knowledge and tailoredcommunication strategies, LLMs can significantly enhance diagnostic processes.The findings highlight the importance of optimizing the number of trainingexamples and communication styles to improve accuracy and reduce biases in LLMapplications.</description><author>Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio</author><pubDate>Mon, 03 Jun 2024 17:23:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06270v3</guid></item><item><title>Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge</title><link>http://arxiv.org/abs/2402.19334v2</link><description>The democratization of pre-trained language models through open-sourceinitiatives has rapidly advanced innovation and expanded access to cutting-edgetechnologies. However, this openness also brings significant security risks,including backdoor attacks, where hidden malicious behaviors are triggered byspecific inputs, compromising natural language processing (NLP) systemintegrity and reliability. This paper suggests that merging a backdoored modelwith other homogeneous models can significantly remediate backdoorvulnerabilities even if such models are not entirely secure. In ourexperiments, we verify our hypothesis on various models (BERT-Base,RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News,and QNLI). Compared to multiple advanced defensive approaches, our methodoffers an effective and efficient inference-stage defense against backdoorattacks on classification and instruction-tuned tasks without additionalresources or specific knowledge. Our approach consistently outperforms recentadvanced baselines, leading to an average of about 75% reduction in the attacksuccess rate. Since model merging has been an established approach forimproving model performance, the extra advantage it provides regarding defensecan be seen as a cost-free bonus.</description><author>Ansh Arora, Xuanli He, Maximilian Mozes, Srinibas Swain, Mark Dras, Qiongkai Xu</author><pubDate>Mon, 03 Jun 2024 17:19:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19334v2</guid></item><item><title>Diffusion Model-Augmented Behavioral Cloning</title><link>http://arxiv.org/abs/2302.13335v4</link><description>Imitation learning addresses the challenge of learning by observing anexpert's demonstrations without access to reward signals from environments.Most existing imitation learning methods that do not require interacting withenvironments either model the expert distribution as the conditionalprobability p(a|s) (e.g., behavioral cloning, BC) or the joint probability p(s,a). Despite the simplicity of modeling the conditional probability with BC, itusually struggles with generalization. While modeling the joint probability canimprove generalization performance, the inference procedure is oftentime-consuming, and the model can suffer from manifold overfitting. This workproposes an imitation learning framework that benefits from modeling both theconditional and joint probability of the expert distribution. Our proposedDiffusion Model-Augmented Behavioral Cloning (DBC) employs a diffusion modeltrained to model expert behaviors and learns a policy to optimize both the BCloss (conditional) and our proposed diffusion model loss (joint). DBCoutperforms baselines in various continuous control tasks in navigation, robotarm manipulation, dexterous manipulation, and locomotion. We design additionalexperiments to verify the limitations of modeling either the conditionalprobability or the joint probability of the expert distribution, as well ascompare different generative models. Ablation studies justify the effectivenessof our design choices.</description><author>Shang-Fu Chen, Hsiang-Chun Wang, Ming-Hao Hsu, Chun-Mao Lai, Shao-Hua Sun</author><pubDate>Mon, 03 Jun 2024 17:17:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.13335v4</guid></item><item><title>How Flawed Is ECE? An Analysis via Logit Smoothing</title><link>http://arxiv.org/abs/2402.10046v2</link><description>Informally, a model is calibrated if its predictions are correct with aprobability that matches the confidence of the prediction. By far the mostcommon method in the literature for measuring calibration is the expectedcalibration error (ECE). Recent work, however, has pointed out drawbacks ofECE, such as the fact that it is discontinuous in the space of predictors. Inthis work, we ask: how fundamental are these issues, and what are their impactson existing results? Towards this end, we completely characterize thediscontinuities of ECE with respect to general probability measures on Polishspaces. We then use the nature of these discontinuities to motivate a novelcontinuous, easily estimated miscalibration metric, which we termLogit-Smoothed ECE (LS-ECE). By comparing the ECE and LS-ECE of pre-trainedimage classification models, we show in initial experiments that binned ECEclosely tracks LS-ECE, indicating that the theoretical pathologies of ECE maybe avoidable in practice.</description><author>Muthu Chidambaram, Holden Lee, Colin McSwiggen, Semon Rezchikov</author><pubDate>Mon, 03 Jun 2024 17:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10046v2</guid></item><item><title>Convolutional L2LFlows: Generating Accurate Showers in Highly Granular Calorimeters Using Convolutional Normalizing Flows</title><link>http://arxiv.org/abs/2405.20407v2</link><description>In the quest to build generative surrogate models as computationallyefficient alternatives to rule-based simulations, the quality of the generatedsamples remains a crucial frontier. So far, normalizing flows have been amongthe models with the best fidelity. However, as the latent space in such modelsis required to have the same dimensionality as the data space, scaling upnormalizing flows to high dimensional datasets is not straightforward. Theprior L2LFlows approach successfully used a series of separate normalizingflows and sequence of conditioning steps to circumvent this problem. In thiswork, we extend L2LFlows to simulate showers with a 9-times larger profile inthe lateral direction. To achieve this, we introduce convolutional layers andU-Net-type connections, move from masked autoregressive flows to couplinglayers, and demonstrate the successful modelling of showers in the ILDElectromagnetic Calorimeter as well as Dataset 3 from the public CaloChallengedataset.</description><author>Thorsten Buss, Frank Gaede, Gregor Kasieczka, Claudius Krause, David Shih</author><pubDate>Mon, 03 Jun 2024 17:11:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20407v2</guid></item><item><title>NU-Class Net: A Novel Approach for Video Quality Enhancement</title><link>http://arxiv.org/abs/2401.01163v3</link><description>Video content has experienced a surge in popularity, asserting its dominanceover internet traffic and Internet of Things (IoT) networks. Video compressionhas long been regarded as the primary means of efficiently managing thesubstantial multimedia traffic generated by video-capturing devices.Nevertheless, video compression algorithms entail significant computationaldemands in order to achieve substantial compression ratios. This complexitypresents a formidable challenge when implementing efficient video codingstandards in resource-constrained embedded systems, such as IoT edge nodecameras. To tackle this challenge, this paper introduces NU-Class Net, aninnovative deep-learning model designed to mitigate compression artifactsstemming from lossy compression codecs. This enhancement significantly elevatesthe perceptible quality of low-bit-rate videos. By employing the NU-Class Net,the video encoder within the video-capturing node can reduce output quality,thereby generating low-bit-rate videos and effectively curtailing bothcomputation and bandwidth requirements at the edge. On the decoder side, whichis typically less encumbered by resource limitations, NU-Class Net is appliedafter the video decoder to compensate for artifacts and approximate the qualityof the original video. Experimental results affirm the efficacy of the proposedmodel in enhancing the perceptible quality of videos, especially those streamedat low bit rates.</description><author>Parham Zilouchian Moghaddam, Mehdi Modarressi, Mohammad Amin Sadeghi</author><pubDate>Mon, 03 Jun 2024 17:09:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01163v3</guid></item><item><title>Bayesian learning of Causal Structure and Mechanisms with GFlowNets and Variational Bayes</title><link>http://arxiv.org/abs/2211.02763v3</link><description>Bayesian causal structure learning aims to learn a posterior distributionover directed acyclic graphs (DAGs), and the mechanisms that define therelationship between parent and child variables. By taking a Bayesian approach,it is possible to reason about the uncertainty of the causal model. The notionof modelling the uncertainty over models is particularly crucial for causalstructure learning since the model could be unidentifiable when given only afinite amount of observational data. In this paper, we introduce a novel methodto jointly learn the structure and mechanisms of the causal model usingVariational Bayes, which we call Variational Bayes-DAG-GFlowNet (VBG). Weextend the method of Bayesian causal structure learning using GFlowNets tolearn not only the posterior distribution over the structure, but also theparameters of a linear-Gaussian model. Our results on simulated data suggestthat VBG is competitive against several baselines in modelling the posteriorover DAGs and mechanisms, while offering several advantages over existingmethods, including the guarantee to sample acyclic graphs, and the flexibilityto generalize to non-linear causal mechanisms.</description><author>Mizu Nishikawa-Toomey, Tristan Deleu, Jithendaraa Subramanian, Yoshua Bengio, Laurent Charlin</author><pubDate>Mon, 03 Jun 2024 17:09:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.02763v3</guid></item><item><title>Feature Importance Disparities for Data Bias Investigations</title><link>http://arxiv.org/abs/2303.01704v4</link><description>It is widely held that one cause of downstream bias in classifiers is biaspresent in the training data. Rectifying such biases may involvecontext-dependent interventions such as training separate models on subgroups,removing features with bias in the collection process, or even conductingreal-world experiments to ascertain sources of bias. Despite the need for suchdata bias investigations, few automated methods exist to assist practitionersin these efforts. In this paper, we present one such method that given adataset $X$ consisting of protected and unprotected features, outcomes $y$, anda regressor $h$ that predicts $y$ given $X$, outputs a tuple $(f_j, g)$, withthe following property: $g$ corresponds to a subset of the training dataset$(X, y)$, such that the $j^{th}$ feature $f_j$ has much larger (or smaller)influence in the subgroup $g$, than on the dataset overall, which we callfeature importance disparity (FID). We show across $4$ datasets and $4$ commonfeature importance methods of broad interest to the machine learning communitythat we can efficiently find subgroups with large FID values even overexponentially large subgroup classes and in practice these groups correspond tosubgroups with potentially serious bias issues as measured by standard fairnessmetrics.</description><author>Peter W. Chang, Leor Fishman, Seth Neel</author><pubDate>Mon, 03 Jun 2024 17:03:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.01704v4</guid></item><item><title>Significance of Chain of Thought in Gender Bias Mitigation for English-Dravidian Machine Translation</title><link>http://arxiv.org/abs/2405.19701v2</link><description>Gender bias in machine translation (MT) sys- tems poses a significantchallenge to achieving accurate and inclusive translations. This paper examinesgender bias in machine translation systems for languages such as Telugu andKan- nada from the Dravidian family, analyzing how gender inflections affecttranslation accuracy and neutrality using Google Translate and Chat- GPT. Itfinds that while plural forms can reduce bias, individual-centric sentencesoften main- tain the bias due to historical stereotypes. The study evaluatesthe Chain of Thought process- ing, noting significant bias mitigation from 80%to 4% in Telugu and from 40% to 0% in Kan- nada. It also compares Telugu andKannada translations, emphasizing the need for language specific strategies toaddress these challenges and suggesting directions for future research toenhance fairness in both data preparation and prompts during inference.</description><author>Lavanya Prahallad, Radhika Mamidi</author><pubDate>Mon, 03 Jun 2024 16:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19701v2</guid></item><item><title>Rotational Equilibrium: How Weight Decay Balances Learning Across Neural Networks</title><link>http://arxiv.org/abs/2305.17212v4</link><description>This study investigates how weight decay affects the update behavior ofindividual neurons in deep neural networks through a combination of appliedanalysis and experimentation. Weight decay can cause the expected magnitude andangular updates of a neuron's weight vector to converge to a steady state wecall rotational equilibrium. These states can be highly homogeneous,effectively balancing the average rotation -- a proxy for the effectivelearning rate -- across different layers and neurons. Our work analyzes thesedynamics across optimizers like Adam, Lion, and SGD with momentum, offering anew simple perspective on training that elucidates the efficacy of widely usedbut poorly understood methods in deep learning. We demonstrate how balancedrotation plays a key role in the effectiveness of normalization like WeightStandardization, as well as that of AdamW over Adam with L2-regularization.Finally, we show that explicitly controlling the rotation provides the benefitsof weight decay while substantially reducing the need for learning rate warmup.</description><author>Atli Kosson, Bettina Messmer, Martin Jaggi</author><pubDate>Mon, 03 Jun 2024 16:57:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17212v4</guid></item><item><title>Domain Transfer Through Image-to-Image Translation for Uncertainty-Aware Prostate Cancer Classification</title><link>http://arxiv.org/abs/2307.00479v2</link><description>Prostate Cancer (PCa) is a prevalent disease among men, and multi-parametricMRIs offer a non-invasive method for its detection. While MRI-based deeplearning solutions have shown promise in supporting PCa diagnosis, acquiringsufficient training data, particularly in local clinics remains challenging.One potential solution is to take advantage of publicly available datasets topre-train deep models and fine-tune them on the local data, but multi-sourceMRIs can pose challenges due to cross-domain distribution differences. Theselimitations hinder the adoption of explainable and reliable deep-learningsolutions in local clinics for PCa diagnosis. In this work, we present a novelapproach for unpaired image-to-image translation of prostate multi-parametricMRIs and an uncertainty-aware training approach for classifying clinicallysignificant PCa, to be applied in data-constrained settings such as local andsmall clinics. Our approach involves a novel pipeline for translating unpaired3.0T multi-parametric prostate MRIs to 1.5T, thereby augmenting the availabletraining data. Additionally, we introduce an evidential deep learning approachto estimate model uncertainty and employ dataset filtering techniques duringtraining. Furthermore, we propose a simple, yet efficient Evidential FocalLoss, combining focal loss with evidential uncertainty, to train our modeleffectively. Our experiments demonstrate that the proposed method significantlyimproves the Area Under ROC Curve (AUC) by over 20% compared to the previouswork. Our code is available at https://github.com/med-i-lab/DT_UE_PCa</description><author>Meng Zhou, Amoon Jamzad, Jason Izard, Alexandre Menard, Robert Siemens, Parvin Mousavi</author><pubDate>Mon, 03 Jun 2024 16:55:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00479v2</guid></item><item><title>EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting</title><link>http://arxiv.org/abs/2405.14959v2</link><description>Event cameras offer promising advantages such as high dynamic range and lowlatency, making them well-suited for challenging lighting conditions andfast-moving scenarios. However, reconstructing 3D scenes from raw event streamsis difficult because event data is sparse and does not carry absolute colorinformation. To release its potential in 3D reconstruction, we propose thefirst event-based generalizable 3D reconstruction framework, called EvGGS,which reconstructs scenes as 3D Gaussians from only event input in afeedforward manner and can generalize to unseen cases without any retraining.This framework includes a depth estimation module, an intensity reconstructionmodule, and a Gaussian regression module. These submodules connect in acascading manner, and we collaboratively train them with a designed joint lossto make them mutually promote. To facilitate related studies, we build a novelevent-based 3D dataset with various material objects and calibrated labels ofgrayscale images, depth maps, camera poses, and silhouettes. Experiments showmodels that have jointly trained significantly outperform those trainedindividually. Our approach performs better than all baselines in reconstructionquality, and depth/intensity predictions with satisfactory rendering speed.</description><author>Jiaxu Wang, Junhao He, Ziyi Zhang, Mingyuan Sun, Jingkai Sun, Renjing Xu</author><pubDate>Mon, 03 Jun 2024 16:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14959v2</guid></item><item><title>Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code</title><link>http://arxiv.org/abs/2311.00889v2</link><description>With the growing popularity of Large Language Models (LLMs) in softwareengineers' daily practices, it is important to ensure that the code generatedby these tools is not only functionally correct but also free ofvulnerabilities. Although LLMs can help developers to be more productive, priorempirical studies have shown that LLMs can generate insecure code. There aretwo contributing factors to the insecure code generation. First, existingdatasets used to evaluate LLMs do not adequately represent genuine softwareengineering tasks sensitive to security. Instead, they are often based oncompetitive programming challenges or classroom-type coding tasks. Inreal-world applications, the code produced is integrated into larger codebases,introducing potential security risks. Second, existing evaluation metricsprimarily focus on the functional correctness of the generated code whileignoring security considerations. Therefore, in this paper, we described SALLM,a framework to benchmark LLMs' abilities to generate secure codesystematically. This framework has three major components: a novel dataset ofsecurity-centric Python prompts, configurable assessment techniques to evaluatethe generated code, and novel metrics to evaluate the models' performance fromthe perspective of secure code generation.</description><author>Mohammed Latif Siddiq, Joanna C. S. Santos, Sajith Devareddy, Anna Muller</author><pubDate>Mon, 03 Jun 2024 16:50:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00889v2</guid></item><item><title>Quantum Theory and Application of Contextual Optimal Transport</title><link>http://arxiv.org/abs/2402.14991v3</link><description>Optimal Transport (OT) has fueled machine learning (ML) across many domains.When paired data measurements $(\boldsymbol{\mu}, \boldsymbol{\nu})$ arecoupled to covariates, a challenging conditional distribution learning settingarises. Existing approaches for learning a $\textit{global}$ transport mapparameterized through a potentially unseen context utilize Neural OT andlargely rely on Brenier's theorem. Here, we propose a first-of-its-kind quantumcomputing formulation for amortized optimization of contextualizedtransportation plans. We exploit a direct link between doubly stochasticmatrices and unitary operators thus unravelling a natural connection between OTand quantum computation. We verify our method (QontOT) on synthetic and realdata by predicting variations in cell type distributions conditioned on drugdosage. Importantly we conduct a 24-qubit hardware experiment on a taskchallenging for classical computers and report a performance that cannot bematched with our classical neural OT approach. In sum, this is a first steptoward learning to predict contextualized transportation plans through quantumcomputing.</description><author>Nicola Mariella, Albert Akhriev, Francesco Tacchino, Christa Zoufal, Juan Carlos Gonzalez-Espitia, Benedek Harsanyi, Eugene Koskin, Ivano Tavernelli, Stefan Woerner, Marianna Rapsomaniki, Sergiy Zhuk, Jannis Born</author><pubDate>Mon, 03 Jun 2024 16:42:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14991v3</guid></item><item><title>Efficient Inverse Design Optimization through Multi-fidelity Simulations, Machine Learning, and Search Space Reduction Strategies</title><link>http://arxiv.org/abs/2312.03654v2</link><description>This paper introduces a methodology designed to augment the inverse designoptimization process in scenarios constrained by limited compute, through thestrategic synergy of multi-fidelity evaluations, machine learning models, andoptimization algorithms. The proposed methodology is analyzed on two distinctengineering inverse design problems: airfoil inverse design and the scalarfield reconstruction problem. It leverages a machine learning model trainedwith low-fidelity simulation data, in each optimization cycle, therebyproficiently predicting a target variable and discerning whether ahigh-fidelity simulation is necessitated, which notably conserves computationalresources. Additionally, the machine learning model is strategically deployedprior to optimization to compress the design space boundaries, thereby furtheraccelerating convergence toward the optimal solution. The methodology has beenemployed to enhance two optimization algorithms, namely Differential Evolutionand Particle Swarm Optimization. Comparative analyses illustrate performanceimprovements across both algorithms. Notably, this method is adaptable acrossany inverse design application, facilitating a synergy between a representativelow-fidelity ML model, and high-fidelity simulation, and can be seamlesslyapplied across any variety of population-based optimization algorithms.}</description><author>Luka Grbcic, Juliane Müller, Wibe Albert de Jong</author><pubDate>Mon, 03 Jun 2024 16:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03654v2</guid></item><item><title>Efficient and Generalizable Certified Unlearning: A Hessian-free Recollection Approach</title><link>http://arxiv.org/abs/2404.01712v3</link><description>Machine unlearning strives to uphold the data owners' right to be forgottenby enabling models to selectively forget specific data. Recent advances suggestprecomputing and storing statistics extracted from second-order information andimplementing unlearning through Newton-style updates. However, the theoreticalanalysis of these works often depends on restrictive assumptions of convexityand smoothness, and those mentioned operations on Hessian matrix are extremelycostly. As a result, applying these works to high-dimensional models becomeschallenging. In this paper, we propose an efficient Hessian-free certifiedunlearning. We propose to maintain a statistical vector for each data, computedthrough affine stochastic recursion approximation of the difference betweenretrained and learned models. Our analysis does not involve inverting Hessianand thus can be extended to non-convex non-smooth objectives. Under sameassumptions, we demonstrate advancements of proposed method beyond thestate-of-the-art theoretical studies, in terms of generalization, unlearningguarantee, deletion capacity, and computation/storage complexity, and we showthat the unlearned model of our proposed approach is close to or same as theretrained model. Based on the strategy of recollecting statistics forforgetting data, we develop an algorithm that achieves near-instantaneousunlearning as it only requires a vector addition operation. Experimentsdemonstrate that the proposed scheme surpasses existing results by orders ofmagnitude in terms of time/storage costs, while also enhancing accuracy.</description><author>Xinbao Qiao, Meng Zhang, Ming Tang, Ermin Wei</author><pubDate>Mon, 03 Jun 2024 16:35:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01712v3</guid></item><item><title>Cheap Talking Algorithms</title><link>http://arxiv.org/abs/2310.07867v5</link><description>We simulate behaviour of two independent reinforcement learning algorithmsplaying the Crawford and Sobel (1982) game of strategic informationtransmission. We adopt memoryless algorithms to capture learning in a staticgame where a large population interacts anonymously. We show that sender andreceiver converge to Nash equilibrium play. The level of informativeness of thesender's cheap talk decreases as the bias increases and, at intermediate levelof the bias, it matches the level predicted by the Pareto optimal equilibriumor by the second best one. Conclusions are robust to alternative specificationsof the learning hyperparameters and of the game.</description><author>Daniele Condorelli, Massimiliano Furlan</author><pubDate>Mon, 03 Jun 2024 16:34:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07867v5</guid></item><item><title>Understanding Domain-Size Generalization in Markov Logic Networks</title><link>http://arxiv.org/abs/2403.15933v3</link><description>We study the generalization behavior of Markov Logic Networks (MLNs) acrossrelational structures of different sizes. Multiple works have noticed that MLNslearned on a given domain generalize poorly across domains of different sizes.This behavior emerges from a lack of internal consistency within an MLN whenused across different domain sizes. In this paper, we quantify thisinconsistency and bound it in terms of the variance of the MLN parameters. Theparameter variance also bounds the KL divergence between an MLN's marginaldistributions taken from different domain sizes. We use these bounds to showthat maximizing the data log-likelihood while simultaneously minimizing theparameter variance corresponds to two natural notions of generalization acrossdomain sizes. Our theoretical results apply to Exponential Random Graphs andother Markov network based relational models. Finally, we observe thatsolutions known to decrease the variance of the MLN parameters, likeregularization and Domain-Size Aware MLNs, increase the internal consistency ofthe MLNs. We empirically verify our results on four different datasets, withdifferent methods to control parameter variance, showing that controllingparameter variance leads to better generalization.</description><author>Florian Chen, Felix Weitkämper, Sagar Malhotra</author><pubDate>Mon, 03 Jun 2024 16:30:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15933v3</guid></item><item><title>Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL</title><link>http://arxiv.org/abs/2402.05724v2</link><description>We study the sample complexity of reinforcement learning (RL) in Mean-FieldGames (MFGs) with model-based function approximation that requires strategicexploration to find a Nash Equilibrium policy. We introduce the PartialModel-Based Eluder Dimension (P-MBED), a more effective notion to characterizethe model class complexity. Notably, P-MBED measures the complexity of thesingle-agent model class converted from the given mean-field model class, andpotentially, can be exponentially lower than the MBED proposed by\citet{huang2023statistical}. We contribute a model elimination algorithmfeaturing a novel exploration strategy and establish sample complexity resultspolynomial w.r.t.~P-MBED. Crucially, our results reveal that, under the basicrealizability and Lipschitz continuity assumptions, \emph{learning NashEquilibrium in MFGs is no more statistically challenging than solving alogarithmic number of single-agent RL problems}. We further extend our resultsto Multi-Type MFGs, generalizing from conventional MFGs and involving multipletypes of agents. This extension implies statistical tractability of a broaderclass of Markov Games through the efficacy of mean-field approximation.Finally, inspired by our theoretical algorithm, we present a heuristic approachwith improved computational efficiency and empirically demonstrate itseffectiveness.</description><author>Jiawei Huang, Niao He, Andreas Krause</author><pubDate>Mon, 03 Jun 2024 16:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05724v2</guid></item><item><title>PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications</title><link>http://arxiv.org/abs/2405.19266v2</link><description>Developing intelligent pediatric consultation systems offers promisingprospects for improving diagnostic efficiency, especially in China, wherehealthcare resources are scarce. Despite recent advances in Large LanguageModels (LLMs) for Chinese medicine, their performance is sub-optimal inpediatric applications due to inadequate instruction data and vulnerabletraining procedures. To address the above issues, this paper builds PedCorpus,a high-quality dataset of over 300,000 multi-task instructions from pediatrictextbooks, guidelines, and knowledge graph resources to fulfil diversediagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, thefirst Chinese pediatric LLM assistant built on a systematic and robust trainingpipeline. In the continuous pre-training phase, we introduce a hybridinstruction pre-training mechanism to mitigate the internal-injected knowledgeinconsistency of LLMs for medical domain adaptation. Immediately, thefull-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate thegeneral medical knowledge schema into the models. After that, we devise adirect following preference optimization to enhance the generation ofpediatrician-like humanistic responses. In the parameter-efficient secondarySFT phase, a mixture of universal-specific experts strategy is presented toresolve the competency conflict between medical generalist and pediatricexpertise mastery. Extensive results based on the metrics, GPT-4, and doctorevaluations on distinct doctor downstream tasks show that PediatricsGPTconsistently outperforms previous Chinese medical LLMs. Our model and datasetwill be open-source for community development.</description><author>Dingkang Yang, Jinjie Wei, Dongling Xiao, Shunli Wang, Tong Wu, Gang Li, Mingcheng Li, Shuaibing Wang, Jiawei Chen, Yue Jiang, Qingyao Xu, Ke Li, Peng Zhai, Lihua Zhang</author><pubDate>Mon, 03 Jun 2024 16:27:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19266v2</guid></item><item><title>1-Lipschitz Neural Networks are more expressive with N-Activations</title><link>http://arxiv.org/abs/2311.06103v2</link><description>A crucial property for achieving secure, trustworthy and interpretable deeplearning systems is their robustness: small changes to a system's inputs shouldnot result in large changes to its outputs. Mathematically, this means onestrives for networks with a small Lipschitz constant. Several recent works havefocused on how to construct such Lipschitz networks, typically by imposingconstraints on the weight matrices. In this work, we study an orthogonalaspect, namely the role of the activation function. We show that commonly usedactivation functions, such as MaxMin, as well as all piece-wise linear oneswith two segments unnecessarily restrict the class of representable functions,even in the simplest one-dimensional setting. We furthermore introduce the newN-activation function that is provably more expressive than currently popularactivation functions. We provide code athttps://github.com/berndprach/NActivation.</description><author>Bernd Prach, Christoph H. Lampert</author><pubDate>Mon, 03 Jun 2024 16:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06103v2</guid></item><item><title>HyCubE: Efficient Knowledge Hypergraph 3D Circular Convolutional Embedding</title><link>http://arxiv.org/abs/2402.08961v2</link><description>Knowledge hypergraph embedding models are usually computationally expensivedue to the inherent complex semantic information. However, existing worksmainly focus on improving the effectiveness of knowledge hypergraph embedding,making the model architecture more complex and redundant. It is desirable andchallenging for knowledge hypergraph embedding to reach a trade-off betweenmodel effectiveness and efficiency. In this paper, we propose an end-to-endefficient n-ary knowledge hypergraph embedding model, HyCubE, which designs anovel 3D circular convolutional neural network and the alternate mask stackstrategy to enhance the interaction and extraction of feature informationcomprehensively. Furthermore, our proposed model achieves a better trade-offbetween effectiveness and efficiency by adaptively adjusting the 3D circularconvolutional layer structure to handle different arity knowledge hypergraphswith fewer parameters. In addition, we use 1-N multilinear scoring based on theentity mask mechanism to further accelerate the model training efficiency.Finally, extensive experimental results on all datasets demonstrate that ourproposed model consistently outperforms state-of-the-art baselines, with anaverage improvement of 7.30%-9.53% and a maximum improvement of 33.82% acrossall metrics. Meanwhile, HyCubE is 4.12x faster, GPU memory usage is 52.19%lower, and the number of parameters is reduced by 85.21% compared with theaverage metric of the latest state-of-the-art baselines.</description><author>Zhao Li, Xin Wang, Jun Zhao, Wenbin Guo, Jianxin Li</author><pubDate>Mon, 03 Jun 2024 16:17:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08961v2</guid></item><item><title>Functional Bilevel Optimization for Machine Learning</title><link>http://arxiv.org/abs/2403.20233v2</link><description>In this paper, we introduce a new functional point of view on bileveloptimization problems for machine learning, where the inner objective isminimized over a function space. These types of problems are most often solvedby using methods developed in the parametric setting, where the inner objectiveis strongly convex with respect to the parameters of the prediction function.The functional point of view does not rely on this assumption and notablyallows using over-parameterized neural networks as the inner predictionfunction. We propose scalable and efficient algorithms for the functionalbilevel optimization problem and illustrate the benefits of our approach oninstrumental regression and reinforcement learning tasks.</description><author>Ieva Petrulionyte, Julien Mairal, Michael Arbel</author><pubDate>Mon, 03 Jun 2024 16:16:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20233v2</guid></item><item><title>A Pixel Is Worth More Than One 3D Gaussians in Single-View 3D Reconstruction</title><link>http://arxiv.org/abs/2405.20310v3</link><description>Learning 3D scene representation from a single-view image is a long-standingfundamental problem in computer vision, with the inherent ambiguity inpredicting contents unseen from the input view. Built on the recently proposed3D Gaussian Splatting (3DGS), the Splatter Image method has made promisingprogress on fast single-image novel view synthesis via learning a single 3DGaussian for each pixel based on the U-Net feature map of an input image.However, it has limited expressive power to represent occluded components thatare not observable in the input view. To address this problem, this paperpresents a Hierarchical Splatter Image method in which a pixel is worth morethan one 3D Gaussians. Specifically, each pixel is represented by a parent 3DGaussian and a small number of child 3D Gaussians. Parent 3D Gaussians arelearned as done in the vanilla Splatter Image. Child 3D Gaussians are learnedvia a lightweight Multi-Layer Perceptron (MLP) which takes as input theprojected image features of a parent 3D Gaussian and the embedding of a targetcamera view. Both parent and child 3D Gaussians are learned end-to-end in astage-wise way. The joint condition of input image features from eyes of theparent Gaussians and the target camera position facilitates learning toallocate child Gaussians to ``see the unseen'', recovering the occluded detailsthat are often missed by parent Gaussians. In experiments, the proposed method is tested on the ShapeNet-SRN and CO3Ddatasets with state-of-the-art performance obtained, especially showingpromising capabilities of reconstructing occluded contents in the input view.</description><author>Jianghao Shen, Nan Xue, Tianfu Wu</author><pubDate>Mon, 03 Jun 2024 16:13:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20310v3</guid></item><item><title>Large Language Models are Zero-Shot Next Location Predictors</title><link>http://arxiv.org/abs/2405.20962v2</link><description>Predicting the locations an individual will visit in the future is crucialfor solving many societal issues like disease diffusion and reduction ofpollution among many others. The models designed to tackle next-locationprediction, however, require a significant amount of individual-levelinformation to be trained effectively. Such data may be scarce or evenunavailable in some geographic regions or peculiar scenarios (e.g., cold-startin recommendation systems). Moreover, the design of a next-location predictorable to generalize or geographically transfer knowledge is still an openresearch challenge. Recent advances in natural language processing have led toa rapid diffusion of Large Language Models (LLMs) which have shown goodgeneralization and reasoning capabilities. These insights, coupled with therecent findings that LLMs are rich in geographical knowledge, allowed us tobelieve that these models can act as zero-shot next-location predictors. Thispaper evaluates the capabilities of many popular LLMs in this role,specifically Llama, GPT-3.5 and Mistral 7B. After designing a proper prompt, wetested the models on three real-world mobility datasets. The results show thatLLMs can obtain accuracies up to 32.4%, a significant relative improvement ofover 600% when compared to sophisticated DL models specifically designed forhuman mobility. Moreover, we show that other LLMs are unable to perform thetask properly. To prevent positively biased results, we also propose aframework inspired by other studies to test data contamination. Finally, weexplored the possibility of using LLMs as text-based explainers fornext-location prediction showing that can effectively provide an explanationfor their decision. Notably, 7B models provide more generic, but stillreliable, explanations compared to larger counterparts. Code:github.com/ssai-trento/LLM-zero-shot-NL</description><author>Ciro Beneduce, Bruno Lepri, Massimiliano Luca</author><pubDate>Mon, 03 Jun 2024 16:10:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20962v2</guid></item><item><title>CF-OPT: Counterfactual Explanations for Structured Prediction</title><link>http://arxiv.org/abs/2405.18293v2</link><description>Optimization layers in deep neural networks have enjoyed a growing popularityin structured learning, improving the state of the art on a variety ofapplications. Yet, these pipelines lack interpretability since they are made oftwo opaque layers: a highly non-linear prediction model, such as a deep neuralnetwork, and an optimization layer, which is typically a complex black-boxsolver. Our goal is to improve the transparency of such methods by providingcounterfactual explanations. We build upon variational autoencoders aprincipled way of obtaining counterfactuals: working in the latent space leadsto a natural notion of plausibility of explanations. We finally introduce avariant of the classic loss for VAE training that improves their performance inour specific structured context. These provide the foundations of CF-OPT, afirst-order optimization algorithm that can find counterfactual explanationsfor a broad class of structured learning architectures. Our numerical resultsshow that both close and plausible explanations can be obtained for problemsfrom the recent literature.</description><author>Germain Vivier-Ardisson, Alexandre Forel, Axel Parmentier, Thibaut Vidal</author><pubDate>Mon, 03 Jun 2024 16:07:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18293v2</guid></item><item><title>Learning Partially Aligned Item Representation for Cross-Domain Sequential Recommendation</title><link>http://arxiv.org/abs/2405.12473v2</link><description>Cross-domain sequential recommendation (CDSR) aims to uncover and transferusers' sequential preferences across multiple recommendation domains. Whilesignificant endeavors have been made, they primarily concentrated on developingadvanced transfer modules and aligning user representations usingself-supervised learning techniques. However, the problem of aligning itemrepresentations has received limited attention, and misaligned itemrepresentations can potentially lead to sub-optimal sequential modeling anduser representation alignment. To this end, we propose a model-agnosticframework called \textbf{C}ross-domain item representation \textbf{A}lignmentfor \textbf{C}ross-\textbf{D}omain \textbf{S}equential \textbf{R}ecommendation(\textbf{CA-CDSR}), which achieves sequence-aware generation and adaptivelypartial alignment for item representations. Specifically, we first develop asequence-aware feature augmentation strategy, which captures both collaborativeand sequential item correlations, thus facilitating holistic itemrepresentation generation. Next, we conduct an empirical study to investigatethe partial representation alignment problem from a spectrum perspective. Itmotivates us to devise an adaptive spectrum filter, achieving partial alignmentadaptively. Furthermore, the aligned item representations can be fed intodifferent sequential encoders to obtain user representations. The entireframework is optimized in a multi-task learning paradigm with an annealingstrategy. Extensive experiments have demonstrated that CA-CDSR can surpassstate-of-the-art baselines by a significant margin and can effectively alignitems in representation spaces to enhance performance.</description><author>Mingjia Yin, Hao Wang, Wei Guo, Yong Liu, Zhi Li, Sirui Zhao, Defu Lian, Enhong Chen</author><pubDate>Mon, 03 Jun 2024 16:05:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12473v2</guid></item><item><title>Human vs. Machine: Behavioral Differences Between Expert Humans and Language Models in Wargame Simulations</title><link>http://arxiv.org/abs/2403.03407v2</link><description>To some, the advent of artificial intelligence (AI) promises betterdecision-making and increased military effectiveness while reducing theinfluence of human error and emotions. However, there is still debate about howAI systems, especially large language models (LLMs), behave compared to humansin high-stakes military decision-making scenarios with the potential forincreased risks towards escalation and unnecessary conflicts. To test thispotential and scrutinize the use of LLMs for such purposes, we use a newwargame experiment with 107 national security experts designed to look atcrisis escalation in a fictional US-China scenario and compare human players toLLM-simulated responses in separate simulations. Wargames have a long historyin the development of military strategy and the response of nations to threatsor attacks. Here, we show a considerable high-level agreement in the LLM andhuman responses and significant quantitative and qualitative differences inindividual actions and strategic tendencies. These differences depend onintrinsic biases in LLMs regarding the appropriate level of violence followingstrategic instructions, the choice of LLM, and whether the LLMs are tasked todecide for a team of players directly or first to simulate dialog betweenplayers. When simulating the dialog, the discussions lack quality and maintaina farcical harmony. The LLM simulations cannot account for human playercharacteristics, showing no significant difference even for extreme traits,such as "pacifist" or "aggressive sociopath". Our results motivate policymakersto be cautious before granting autonomy or following AI-based strategyrecommendations.</description><author>Max Lamparth, Anthony Corso, Jacob Ganz, Oriana Skylar Mastro, Jacquelyn Schneider, Harold Trinkunas</author><pubDate>Mon, 03 Jun 2024 16:00:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03407v2</guid></item><item><title>Boosting Language Models Reasoning with Chain-of-Knowledge Prompting</title><link>http://arxiv.org/abs/2306.06427v3</link><description>Recently, Chain-of-Thought (CoT) prompting has delivered success on complexreasoning tasks, which aims at designing a simple prompt like ``Let's thinkstep by step'' or multiple in-context exemplars with well-designed rationalesto elicit Large Language Models (LLMs) to generate intermediate reasoningsteps. However, the generated rationales often come with mistakes, makingunfactual and unfaithful reasoning chains. To mitigate this brittleness, wepropose a novel Chain-of-Knowledge (CoK) prompting, where we aim at elicitingLLMs to generate explicit pieces of knowledge evidence in the form of structuretriple. This is inspired by our human behaviors, i.e., we can draw a mind mapor knowledge map as the reasoning evidence in the brain before answering acomplex question. Benefiting from CoK, we additionally introduce aF^2-Verification method to estimate the reliability of the reasoning chains interms of factuality and faithfulness. For the unreliable response, the wrongevidence can be indicated to prompt the LLM to rethink. Extensive experimentsdemonstrate that our method can further improve the performance of commonsense,factual, symbolic, and arithmetic reasoning tasks.</description><author>Jianing Wang, Qiushi Sun, Xiang Li, Ming Gao</author><pubDate>Mon, 03 Jun 2024 15:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06427v3</guid></item><item><title>Planning with a Learned Policy Basis to Optimally Solve Complex Tasks</title><link>http://arxiv.org/abs/2403.15301v2</link><description>Conventional reinforcement learning (RL) methods can successfully solve awide range of sequential decision problems. However, learning policies that cangeneralize predictably across multiple tasks in a setting with non-Markovianreward specifications is a challenging problem. We propose to use successorfeatures to learn a policy basis so that each (sub)policy in it solves awell-defined subproblem. In a task described by a finite state automaton (FSA)that involves the same set of subproblems, the combination of these(sub)policies can then be used to generate an optimal solution withoutadditional learning. In contrast to other methods that combine (sub)policiesvia planning, our method asymptotically attains global optimality, even instochastic environments.</description><author>Guillermo Infante, David Kuric, Anders Jonsson, Vicenç Gómez, Herke van Hoof</author><pubDate>Mon, 03 Jun 2024 15:56:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15301v2</guid></item><item><title>Cross-view Masked Diffusion Transformers for Person Image Synthesis</title><link>http://arxiv.org/abs/2402.01516v2</link><description>We present X-MDPT ($\underline{Cross}$-view $\underline{M}$asked$\underline{D}$iffusion $\underline{P}$rediction $\underline{T}$ransformers), anovel diffusion model designed for pose-guided human image generation. X-MDPTdistinguishes itself by employing masked diffusion transformers that operate onlatent patches, a departure from the commonly-used Unet structures in existingworks. The model comprises three key modules: 1) a denoising diffusionTransformer, 2) an aggregation network that consolidates conditions into asingle vector for the diffusion process, and 3) a mask cross-prediction modulethat enhances representation learning with semantic information from thereference image. X-MDPT demonstrates scalability, improving FID, SSIM, andLPIPS with larger models. Despite its simple design, our model outperformsstate-of-the-art approaches on the DeepFashion dataset while exhibitingefficiency in terms of training parameters, training time, and inference speed.Our compact 33MB model achieves an FID of 7.42, surpassing a prior Unet latentdiffusion approach (FID 8.07) using only $11\times$ fewer parameters. Our bestmodel surpasses the pixel-based diffusion with $\frac{2}{3}$ of the parametersand achieves $5.43 \times$ faster inference. The code is available athttps://github.com/trungpx/xmdpt.</description><author>Trung X. Pham, Zhang Kang, Chang D. Yoo</author><pubDate>Mon, 03 Jun 2024 15:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01516v2</guid></item><item><title>Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression</title><link>http://arxiv.org/abs/2403.15447v2</link><description>Compressing high-capability Large Language Models (LLMs) has emerged as afavored strategy for resource-efficient inferences. While state-of-the-art(SoTA) compression methods boast impressive advancements in preserving benigntask performance, the potential risks of compression in terms of safety andtrustworthiness have been largely neglected. This study conducts the first,thorough evaluation of three (3) leading LLMs using five (5) SoTA compressiontechniques across eight (8) trustworthiness dimensions. Our experimentshighlight the intricate interplay between compression and trustworthiness,revealing some interesting patterns. We find that quantization is currently amore effective approach than pruning in achieving efficiency andtrustworthiness simultaneously. For instance, a 4-bit quantized model retainsthe trustworthiness of its original counterpart, but model pruningsignificantly degrades trustworthiness, even at 50% sparsity. Moreover,employing quantization within a moderate bit range could unexpectedly improvecertain trustworthiness dimensions such as ethics and fairness. Conversely,extreme quantization to very low bit levels (3 bits) tends to reducetrustworthiness significantly. This increased risk cannot be uncovered bylooking at benign performance alone, in turn, mandating comprehensivetrustworthiness evaluation in practice. These findings culminate in practicalrecommendations for simultaneously achieving high utility, efficiency, andtrustworthiness in LLMs. Code and models are available athttps://decoding-comp-trust.github.io.</description><author>Junyuan Hong, Jinhao Duan, Chenhui Zhang, Zhangheng Li, Chulin Xie, Kelsey Lieberman, James Diffenderfer, Brian Bartoldson, Ajay Jaiswal, Kaidi Xu, Bhavya Kailkhura, Dan Hendrycks, Dawn Song, Zhangyang Wang, Bo Li</author><pubDate>Mon, 03 Jun 2024 15:49:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15447v2</guid></item><item><title>Iterative Motion Editing with Natural Language</title><link>http://arxiv.org/abs/2312.11538v2</link><description>Text-to-motion diffusion models can generate realistic animations from textprompts, but do not support fine-grained motion editing controls. In thispaper, we present a method for using natural language to iteratively specifylocal edits to existing character animations, a task that is common in mostcomputer animation workflows. Our key idea is to represent a space of motionedits using a set of kinematic motion editing operators (MEOs) whose effects onthe source motion is well-aligned with user expectations. We provide analgorithm that leverages pre-existing language models to translate textualdescriptions of motion edits into source code for programs that define andexecute sequences of MEOs on a source animation. We execute MEOs by firsttranslating them into keyframe constraints, and then use diffusion-based motionmodels to generate output motions that respect these constraints. Through auser study and quantitative evaluation, we demonstrate that our system canperform motion edits that respect the animator's editing intent, remainfaithful to the original animation (it edits the original animation, but doesnot dramatically change it), and yield realistic character animation results.</description><author>Purvi Goel, Kuan-Chieh Wang, C. Karen Liu, Kayvon Fatahalian</author><pubDate>Mon, 03 Jun 2024 15:42:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11538v2</guid></item><item><title>Knockout: A simple way to handle missing inputs</title><link>http://arxiv.org/abs/2405.20448v2</link><description>Deep learning models can extract predictive and actionable information fromcomplex inputs. The richer the inputs, the better these models usually perform.However, models that leverage rich inputs (e.g., multi-modality) can bedifficult to deploy widely, because some inputs may be missing at inference.Current popular solutions to this problem include marginalization, imputation,and training multiple models. Marginalization can obtain calibrated predictionsbut it is computationally costly and therefore only feasible for lowdimensional inputs. Imputation may result in inaccurate predictions because itemploys point estimates for missing variables and does not work well for highdimensional inputs (e.g., images). Training multiple models whereby each modeltakes different subsets of inputs can work well but requires knowing missinginput patterns in advance. Furthermore, training and retaining multiple modelscan be costly. We propose an efficient way to learn both the conditionaldistribution using full inputs and the marginal distributions. Our method,Knockout, randomly replaces input features with appropriate placeholder valuesduring training. We provide a theoretical justification of Knockout and showthat it can be viewed as an implicit marginalization strategy. We evaluateKnockout in a wide range of simulations and real-world datasets and show thatit can offer strong empirical performance.</description><author>Minh Nguyen, Batuhan K. Karaman, Heejong Kim, Alan Q. Wang, Fengbei Liu, Mert R. Sabuncu</author><pubDate>Mon, 03 Jun 2024 15:40:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20448v2</guid></item><item><title>Multiscale Causal Learning</title><link>http://arxiv.org/abs/2405.02325v2</link><description>Biological intelligence is more sample-efficient than artificial intelligence(AI), learning from fewer examples. Here we answer why. Given data, there canbe many policies which seem "correct" because they perfectly fit the data.However, only one correct policy could have actually caused the data.Sample-efficiency requires a means of discerning which. Previous work showedsample efficiency is maximised by weak-policy-optimisation (WPO); preferringpolicies that more weakly constrain what is considered to be correct, givenfinite resources. Biology's sample-efficiency demonstrates it is better at WPO.To understand how, we formalise the "multiscale-competency-architecture" (MCA)observed in biological systems, as a sequence of nested"agentic-abstraction-layers". We show that WPO at low levels enables synthesisof weaker policies at high. We call this "multiscale-causal-learning", andargue this is how we might construct more scale-able, sample-efficient andreliable AI. Furthermore, a sufficiently weak policy at low levels is aprecondition of collective policy at higher levels. The higher level "identity"of the collective is lost if lower levels use an insufficiently weak policy(e.g. cells may become isolated from the collective informational structure andrevert to primitive behaviour). This has implications for biology, machinelearning, AI-safety, and philosophy.</description><author>Michael Timothy Bennett</author><pubDate>Mon, 03 Jun 2024 15:38:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02325v2</guid></item><item><title>Aligner: Efficient Alignment by Learning to Correct</title><link>http://arxiv.org/abs/2402.02416v3</link><description>With the rapid development of large language models (LLMs) and ever-evolvingpractical requirements, finding an efficient and effective alignment method hasnever been more critical. However, the tension between the complexity ofcurrent alignment methods and the need for rapid iteration in deploymentscenarios necessitates the development of a model-agnostic alignment approachthat can operate under these constraints. In this paper, we introduce Aligner,a novel and simple alignment paradigm that learns the correctional residualsbetween preferred and dispreferred answers using a small model. Designed as amodel-agnostic, plug-and-play module, Aligner can be directly applied tovarious open-source and API-based models with only one-off training, making itsuitable for rapid iteration. Notably, Aligner can be applied to any powerful,large-scale upstream models. Moreover, it can even iteratively bootstrap theupstream models using corrected responses as synthetic human preference data,breaking through the model's performance ceiling. Our experiments demonstrateperformance improvements by deploying the same Aligner model across 11different LLMs, evaluated on the 3H dimensions (helpfulness, harmlessness, andhonesty). Specifically, Aligner-7B has achieved an average improvement of68.9\% in helpfulness and 23.8\% in harmlessness across the tested LLMs whilealso effectively reducing hallucination. In the Alpaca-Eval leaderboard,stacking Aligner-2B on GPT-4 Turbo improved its LC Win Rate from 55.0\% to58.3\%, surpassing GPT-4 Omni's 57.5\% Win Rate (community report).</description><author>Jiaming Ji, Boyuan Chen, Hantao Lou, Donghai Hong, Borong Zhang, Xuehai Pan, Juntao Dai, Tianyi Qiu, Yaodong Yang</author><pubDate>Mon, 03 Jun 2024 15:33:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02416v3</guid></item><item><title>Embedding Privacy in Computational Social Science and Artificial Intelligence Research</title><link>http://arxiv.org/abs/2404.11515v2</link><description>Privacy is a human right. It ensures that individuals are free to engage indiscussions, participate in groups, and form relationships online or offlinewithout fear of their data being inappropriately harvested, analyzed, orotherwise used to harm them. Preserving privacy has emerged as a criticalfactor in research, particularly in the computational social science (CSS),artificial intelligence (AI) and data science domains, given their reliance onindividuals' data for novel insights. The increasing use of advancedcomputational models stands to exacerbate privacy concerns because, ifinappropriately used, they can quickly infringe privacy rights and lead toadverse effects for individuals -- especially vulnerable groups -- and society.We have already witnessed a host of privacy issues emerge with the advent oflarge language models (LLMs), such as ChatGPT, which further demonstrate theimportance of embedding privacy from the start. This article contributes to thefield by discussing the role of privacy and the issues that researchers workingin CSS, AI, data science and related domains are likely to face. It thenpresents several key considerations for researchers to ensure participantprivacy is best preserved in their research design, data collection and use,analysis, and dissemination of research results.</description><author>Keenan Jones, Fatima Zahrah, Jason R. C. Nurse</author><pubDate>Mon, 03 Jun 2024 15:32:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11515v2</guid></item><item><title>PAC-Bayesian Generalization Bounds for Knowledge Graph Representation Learning</title><link>http://arxiv.org/abs/2405.06418v2</link><description>While a number of knowledge graph representation learning (KGRL) methods havebeen proposed over the past decade, very few theoretical analyses have beenconducted on them. In this paper, we present the first PAC-Bayesiangeneralization bounds for KGRL methods. To analyze a broad class of KGRLmodels, we propose a generic framework named ReED (Relation-awareEncoder-Decoder), which consists of a relation-aware message passing encoderand a triplet classification decoder. Our ReED framework can express at least15 different existing KGRL models, including not only graph neuralnetwork-based models such as R-GCN and CompGCN but also shallow-architecturemodels such as RotatE and ANALOGY. Our generalization bounds for the ReEDframework provide theoretical grounds for the commonly used tricks in KGRL,e.g., parameter-sharing and weight normalization schemes, and guide desirabledesign choices for practical KGRL methods. We empirically show that thecritical factors in our generalization bounds can explain actual generalizationerrors on three real-world knowledge graphs.</description><author>Jaejun Lee, Minsung Hwang, Joyce Jiyoung Whang</author><pubDate>Mon, 03 Jun 2024 15:27:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06418v2</guid></item><item><title>Generalization Bounds for Heavy-Tailed SDEs through the Fractional Fokker-Planck Equation</title><link>http://arxiv.org/abs/2402.07723v2</link><description>Understanding the generalization properties of heavy-tailed stochasticoptimization algorithms has attracted increasing attention over the past years.While illuminating interesting aspects of stochastic optimizers by usingheavy-tailed stochastic differential equations as proxies, prior works eitherprovided expected generalization bounds, or introduced non-computableinformation theoretic terms. Addressing these drawbacks, in this work, we provehigh-probability generalization bounds for heavy-tailed SDEs which do notcontain any nontrivial information theoretic terms. To achieve this goal, wedevelop new proof techniques based on estimating the entropy flows associatedwith the so-called fractional Fokker-Planck equation (a partial differentialequation that governs the evolution of the distribution of the correspondingheavy-tailed SDE). In addition to obtaining high-probability bounds, we showthat our bounds have a better dependence on the dimension of parameters ascompared to prior art. Our results further identify a phase transitionphenomenon, which suggests that heavy tails can be either beneficial or harmfuldepending on the problem structure. We support our theory with experimentsconducted in a variety of settings.</description><author>Benjamin Dupuis, Umut Şimşekli</author><pubDate>Mon, 03 Jun 2024 15:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07723v2</guid></item><item><title>Graph External Attention Enhanced Transformer</title><link>http://arxiv.org/abs/2405.21061v2</link><description>The Transformer architecture has recently gained considerable attention inthe field of graph representation learning, as it naturally overcomes severallimitations of Graph Neural Networks (GNNs) with customized attentionmechanisms or positional and structural encodings. Despite making someprogress, existing works tend to overlook external information of graphs,specifically the correlation between graphs. Intuitively, graphs with similarstructures should have similar representations. Therefore, we propose GraphExternal Attention (GEA) -- a novel attention mechanism that leverages multipleexternal node/edge key-value units to capture inter-graph correlationsimplicitly. On this basis, we design an effective architecture called GraphExternal Attention Enhanced Transformer (GEAET), which integrates localstructure and global interaction information for more comprehensive graphrepresentations. Extensive experiments on benchmark datasets demonstrate thatGEAET achieves state-of-the-art empirical performance. The source code isavailable for reproducibility at: https://github.com/icm1018/GEAET.</description><author>Jianqing Liang, Min Chen, Jiye Liang</author><pubDate>Mon, 03 Jun 2024 15:20:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21061v2</guid></item><item><title>Interpreting and Improving Diffusion Models from an Optimization Perspective</title><link>http://arxiv.org/abs/2306.04848v4</link><description>Denoising is intuitively related to projection. Indeed, under the manifoldhypothesis, adding random noise is approximately equivalent to orthogonalperturbation. Hence, learning to denoise is approximately learning to project.In this paper, we use this observation to interpret denoising diffusion modelsas approximate gradient descent applied to the Euclidean distance function. Wethen provide straight-forward convergence analysis of the DDIM sampler undersimple assumptions on the projection error of the denoiser. Finally, we proposea new gradient-estimation sampler, generalizing DDIM using insights from ourtheoretical results. In as few as 5-10 function evaluations, our samplerachieves state-of-the-art FID scores on pretrained CIFAR-10 and CelebA modelsand can generate high quality samples on latent diffusion models.</description><author>Frank Permenter, Chenyang Yuan</author><pubDate>Mon, 03 Jun 2024 15:18:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04848v4</guid></item><item><title>Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast</title><link>http://arxiv.org/abs/2402.08567v2</link><description>A multimodal large language model (MLLM) agent can receive instructions,capture images, retrieve histories from memory, and decide which tools to use.Nonetheless, red-teaming efforts have revealed that adversarial images/promptscan jailbreak an MLLM and cause unaligned behaviors. In this work, we report aneven more severe safety issue in multi-agent environments, referred to asinfectious jailbreak. It entails the adversary simply jailbreaking a singleagent, and without any further intervention from the adversary, (almost) allagents will become infected exponentially fast and exhibit harmful behaviors.To validate the feasibility of infectious jailbreak, we simulate multi-agentenvironments containing up to one million LLaVA-1.5 agents, and employrandomized pair-wise chat as a proof-of-concept instantiation for multi-agentinteraction. Our results show that feeding an (infectious) adversarial imageinto the memory of any randomly chosen agent is sufficient to achieveinfectious jailbreak. Finally, we derive a simple principle for determiningwhether a defense mechanism can provably restrain the spread of infectiousjailbreak, but how to design a practical defense that meets this principleremains an open question to investigate. Our project page is available athttps://sail-sg.github.io/Agent-Smith/.</description><author>Xiangming Gu, Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu, Ye Wang, Jing Jiang, Min Lin</author><pubDate>Mon, 03 Jun 2024 15:15:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08567v2</guid></item><item><title>Craftax: A Lightning-Fast Benchmark for Open-Ended Reinforcement Learning</title><link>http://arxiv.org/abs/2402.16801v2</link><description>Benchmarks play a crucial role in the development and analysis ofreinforcement learning (RL) algorithms. We identify that existing benchmarksused for research into open-ended learning fall into one of two categories.Either they are too slow for meaningful research to be performed withoutenormous computational resources, like Crafter, NetHack and Minecraft, or theyare not complex enough to pose a significant challenge, like Minigrid andProcgen. To remedy this, we first present Craftax-Classic: a ground-up rewriteof Crafter in JAX that runs up to 250x faster than the Python-native original.A run of PPO using 1 billion environment interactions finishes in under an hourusing only a single GPU and averages 90% of the optimal reward. To provide amore compelling challenge we present the main Craftax benchmark, a significantextension of the Crafter mechanics with elements inspired from NetHack. SolvingCraftax requires deep exploration, long term planning and memory, as well ascontinual adaptation to novel situations as more of the world is discovered. Weshow that existing methods including global and episodic exploration, as wellas unsupervised environment design fail to make material progress on thebenchmark. We believe that Craftax can for the first time allow researchers toexperiment in a complex, open-ended environment with limited computationalresources.</description><author>Michael Matthews, Michael Beukman, Benjamin Ellis, Mikayel Samvelyan, Matthew Jackson, Samuel Coward, Jakob Foerster</author><pubDate>Mon, 03 Jun 2024 15:12:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16801v2</guid></item><item><title>Latency Adjustable Transformer Encoder for Language Understanding</title><link>http://arxiv.org/abs/2201.03327v8</link><description>Adjusting the latency, power, and accuracy of natural language understandingmodels is a desirable objective of an efficient architecture. This paperproposes an efficient Transformer architecture that adjusts the inferencecomputational cost adaptively with a desired inference latency speedup. Infine-tuning phase, the proposed method detects less important hidden sequenceelements (word-vectors) and eliminates them in each encoder layer using aproposed Attention Context Contribution (ACC) metric. After the fine-tuningphase, with the novel offline-tuning property, the inference latency of themodel can be adjusted in a wide range of inference speedup selections withoutany further training. The proposed method is applied to the BERT_base, GPT-2and Flan-T5 models for evaluation. Extensive experiments show that most of theword-vectors in higher Transformer layers have less contribution to thesubsequent layers; hence, they can be eliminated to improve the inferencelatency. Experimental results on extensive sentiment analysis, classification,text generation tasks and regression benchmarks like GLUE showed that themethod is effective in various datasets with minimal impact on the input'sglobal context. The method was also evaluated under the instruction tuningparadigm, and its performance was measured using different types of prompting.The proposed method mathematically and experimentally improves the inferencelatency of BERT_base and GPT-2 by up to 4.8 and 3.72 times with less than 0.75%accuracy drop and passable perplexity on average. The suggested approach positsthat in Large Language Models (LLMs), although the complete network isnecessary for training, it can be truncated during the fine-tuning phase.</description><author>Sajjad Kachuee, Mohammad Sharifkhani</author><pubDate>Mon, 03 Jun 2024 15:12:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.03327v8</guid></item><item><title>Balanced Data, Imbalanced Spectra: Unveiling Class Disparities with Spectral Imbalance</title><link>http://arxiv.org/abs/2402.11742v2</link><description>Classification models are expected to perform equally well for differentclasses, yet in practice, there are often large gaps in their performance. Thisissue of class bias is widely studied in cases of datasets with sampleimbalance, but is relatively overlooked in balanced datasets. In this work, weintroduce the concept of spectral imbalance in features as a potential sourcefor class disparities and study the connections between spectral imbalance andclass bias in both theory and practice. To build the connection betweenspectral imbalance and class gap, we develop a theoretical framework forstudying class disparities and derive exact expressions for the per-class errorin a high-dimensional mixture model setting. We then study this phenomenon in11 different state-of-the-art pretrained encoders and show how our proposedframework can be used to compare the quality of encoders, as well as evaluateand combine data augmentation strategies to mitigate the issue. Our work shedslight on the class-dependent effects of learning, and provides new insightsinto how state-of-the-art pretrained features may have unknown biases that canbe diagnosed through their spectra.</description><author>Chiraag Kaushik, Ran Liu, Chi-Heng Lin, Amrit Khera, Matthew Y Jin, Wenrui Ma, Vidya Muthukumar, Eva L Dyer</author><pubDate>Mon, 03 Jun 2024 15:09:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11742v2</guid></item><item><title>Advancing Semi-Supervised Learning for Automatic Post-Editing: Data-Synthesis by Mask-Infilling with Erroneous Terms</title><link>http://arxiv.org/abs/2204.03896v2</link><description>Semi-supervised learning that leverages synthetic data for training has beenwidely adopted for developing automatic post-editing (APE) models due to thelack of training data. With this aim, we focus on data-synthesis methods tocreate high-quality synthetic data. Given that APE takes as input amachine-translation result that might include errors, we present adata-synthesis method by which the resulting synthetic data mimic thetranslation errors found in actual data. We introduce a noising-baseddata-synthesis method by adapting the masked language model approach,generating a noisy text from a clean text by infilling masked tokens witherroneous tokens. Moreover, we propose selective corpus interleaving thatcombines two separate synthetic datasets by taking only the advantageoussamples to enhance the quality of the synthetic data further. Experimentalresults show that using the synthetic data created by our approach results insignificantly better APE performance than other synthetic data created byexisting methods.</description><author>Wonkee Lee, Seong-Hwan Heo, Jong-Hyeok Lee</author><pubDate>Mon, 03 Jun 2024 15:09:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.03896v2</guid></item><item><title>Revisiting Step-Size Assumptions in Stochastic Approximation</title><link>http://arxiv.org/abs/2405.17834v2</link><description>Many machine learning and optimization algorithms are built upon theframework of stochastic approximation (SA), for which the selection ofstep-size (or learning rate) is essential for success. For the sake of clarity,this paper focuses on the special case $\alpha_n = \alpha_0 n^{-\rho}$ atiteration $n$, with $\rho \in [0,1]$ and $\alpha_0&gt;0$ design parameters. It ismost common in practice to take $\rho=0$ (constant step-size), while in moretheoretically oriented papers a vanishing step-size is preferred. Inparticular, with $\rho \in (1/2, 1)$ it is known that on applying the averagingtechnique of Polyak and Ruppert, the mean-squared error (MSE) converges at theoptimal rate of $O(1/n)$ and the covariance in the central limit theorem (CLT)is minimal in a precise sense. The paper revisits step-size selection in a general Markovian setting. Underreadily verifiable assumptions, the following conclusions are obtained provided$0&lt;\rho&lt;1$: $\bullet$ Parameter estimates converge with probability one, and also in$L_p$ for any $p\ge 1$. $\bullet$ The MSE may converge very slowly for small $\rho$, of order$O(\alpha_n^2)$ even with averaging. $\bullet$ For linear stochastic approximation the source of slow convergenceis identified: for any $\rho\in (0,1)$, averaging results in estimates forwhich the error $\textit{covariance}$ vanishes at the optimal rate, andmoreover the CLT covariance is optimal in the sense of Polyak and Ruppert. However,necessary and sufficient conditions are obtained under which the$\textit{bias}$ converges to zero at rate $O(\alpha_n)$. This is the first paper to obtain such strong conclusions while allowing for$\rho \le 1/2$. A major conclusion is that the choice of $\rho =0$ or even$\rho&lt;1/2$ is justified only in select settings -- In general, bias maypreclude fast convergence.</description><author>Caio Kalil Lauand, Sean Meyn</author><pubDate>Mon, 03 Jun 2024 15:05:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17834v2</guid></item><item><title>A Large Deviations Perspective on Policy Gradient Algorithms</title><link>http://arxiv.org/abs/2311.07411v3</link><description>Motivated by policy gradient methods in the context of reinforcementlearning, we identify a large deviation rate function for the iteratesgenerated by stochastic gradient descent for possibly non-convex objectivessatisfying a Polyak-{\L}ojasiewicz condition. Leveraging the contractionprinciple from large deviations theory, we illustrate the potential of thisresult by showing how convergence properties of policy gradient with a softmaxparametrization and an entropy regularized objective can be naturally extendedto a wide spectrum of other policy parametrizations.</description><author>Wouter Jongeneel, Daniel Kuhn, Mengmeng Li</author><pubDate>Mon, 03 Jun 2024 14:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07411v3</guid></item><item><title>Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning</title><link>http://arxiv.org/abs/2402.14856v2</link><description>Deductive reasoning plays a pivotal role in the formulation of sound andcohesive arguments. It allows individuals to draw conclusions that logicallyfollow, given the truth value of the information provided. Recent progress inthe domain of large language models (LLMs) has showcased their capability inexecuting deductive reasoning tasks. Nonetheless, a significant portion ofresearch primarily assesses the accuracy of LLMs in solving such tasks, oftenoverlooking a deeper analysis of their reasoning behavior. In this study, wedraw upon principles from cognitive psychology to examine inferentialstrategies employed by LLMs, through a detailed evaluation of their responsesto propositional logic problems. Our findings indicate that LLMs displayreasoning patterns akin to those observed in humans, including strategies like$\textit{supposition following}$ or $\textit{chain construction}$. Moreover,our research demonstrates that the architecture and scale of the modelsignificantly affect its preferred method of reasoning, with more advancedmodels tending to adopt strategies more frequently than less sophisticatedones. Importantly, we assert that a model's accuracy, that is the correctnessof its final conclusion, does not necessarily reflect the validity of itsreasoning process. This distinction underscores the necessity for more nuancedevaluation procedures in the field.</description><author>Philipp Mondorf, Barbara Plank</author><pubDate>Mon, 03 Jun 2024 14:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14856v2</guid></item><item><title>PowerGraph: A power grid benchmark dataset for graph neural networks</title><link>http://arxiv.org/abs/2402.02827v2</link><description>Power grids are critical infrastructures of paramount importance to modernsociety and, therefore, engineered to operate under diverse conditions andfailures. The ongoing energy transition poses new challenges for thedecision-makers and system operators. Therefore, we must develop grid analysisalgorithms to ensure reliable operations. These key tools include power flowanalysis and system security analysis, both needed for effective operationaland strategic planning. The literature review shows a growing trend of machinelearning (ML) models that perform these analyses effectively. In particular,Graph Neural Networks (GNNs) stand out in such applications because of thegraph-based structure of power grids. However, there is a lack of publiclyavailable graph datasets for training and benchmarking ML models in electricalpower grid applications. First, we present PowerGraph, which comprisesGNN-tailored datasets for i) power flows, ii) optimal power flows, and iii)cascading failure analyses of power grids. Second, we provide ground-truthexplanations for the cascading failure analysis. Finally, we perform a completebenchmarking of GNN methods for node-level and graph-level tasks andexplainability. Overall, PowerGraph is a multifaceted GNN dataset for diversetasks that includes power flow and fault scenarios with real-worldexplanations, providing a valuable resource for developing improved GNN modelsfor node-level, graph-level tasks and explainability methods in power systemmodeling. The dataset is available athttps://figshare.com/articles/dataset/PowerGraph/22820534 and the code athttps://github.com/PowerGraph-Datasets.</description><author>Anna Varbella, Kenza Amara, Blazhe Gjorgiev, Mennatallah El-Assady, Giovanni Sansavini</author><pubDate>Mon, 03 Jun 2024 14:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02827v2</guid></item><item><title>Uplift Modeling Under Limited Supervision</title><link>http://arxiv.org/abs/2403.19289v2</link><description>Estimating causal effects in e-commerce tends to involve costly treatmentassignments which can be impractical in large-scale settings. Leveragingmachine learning to predict such treatment effects without actual interventionis a standard practice to diminish the risk. However, existing methods fortreatment effect prediction tend to rely on training sets of substantial size,which are built from real experiments and are thus inherently risky to create.In this work we propose a graph neural network to diminish the requiredtraining set size, relying on graphs that are common in e-commerce data.Specifically, we view the problem as node regression with a restricted numberof labeled instances, develop a two-model neural architecture akin to previouscausal effect estimators, and test varying message-passing layers for encoding.Furthermore, as an extra step, we combine the model with an acquisitionfunction to guide the creation of the training set in settings with extremelylow experimental budget. The framework is flexible since each step can be usedseparately with other models or treatment policies. The experiments on reallarge-scale networks indicate a clear advantage of our methodology over thestate of the art, which in many cases performs close to random, underlining theneed for models that can generalize with limited supervision to reduceexperimental risks.</description><author>George Panagopoulos, Daniele Malitesta, Fragkiskos D. Malliaros, Jun Pang</author><pubDate>Mon, 03 Jun 2024 14:49:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19289v2</guid></item><item><title>Machine Learning with Confidential Computing: A Systematization of Knowledge</title><link>http://arxiv.org/abs/2208.10134v3</link><description>Privacy and security challenges in Machine Learning (ML) have becomeincreasingly severe, along with ML's pervasive development and the recentdemonstration of large attack surfaces. As a mature system-oriented approach,Confidential Computing has been utilized in both academia and industry tomitigate privacy and security issues in various ML scenarios. In this paper,the conjunction between ML and Confidential Computing is investigated. Wesystematize the prior work on Confidential Computing-assisted ML techniquesthat provide i) confidentiality guarantees and ii) integrity assurances, anddiscuss their advanced features and drawbacks. Key challenges are furtheridentified, and we provide dedicated analyses of the limitations in existingTrusted Execution Environment (TEE) systems for ML use cases. Finally,prospective works are discussed, including grounded privacy definitions forclosed-loop protection, partitioned executions of efficient ML, dedicatedTEE-assisted designs for ML, TEE-aware ML, and ML full pipeline guarantees. Byproviding these potential solutions in our systematization of knowledge, we aimto build the bridge to help achieve a much stronger TEE-enabled ML for privacyguarantees without introducing computation and system costs.</description><author>Fan Mo, Zahra Tarkhani, Hamed Haddadi</author><pubDate>Mon, 03 Jun 2024 14:48:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10134v3</guid></item><item><title>Constrained Exploration via Reflected Replica Exchange Stochastic Gradient Langevin Dynamics</title><link>http://arxiv.org/abs/2405.07839v2</link><description>Replica exchange stochastic gradient Langevin dynamics (reSGLD) is aneffective sampler for non-convex learning in large-scale datasets. However, thesimulation may encounter stagnation issues when the high-temperature chaindelves too deeply into the distribution tails. To tackle this issue, we proposereflected reSGLD (r2SGLD): an algorithm tailored for constrained non-convexexploration by utilizing reflection steps within a bounded domain.Theoretically, we observe that reducing the diameter of the domain enhancesmixing rates, exhibiting a $\textit{quadratic}$ behavior. Empirically, we testits performance through extensive experiments, including identifying dynamicalsystems with physical constraints, simulations of constrained multi-modaldistributions, and image classification tasks. The theoretical and empiricalfindings highlight the crucial role of constrained exploration in improving thesimulation efficiency.</description><author>Haoyang Zheng, Hengrong Du, Qi Feng, Wei Deng, Guang Lin</author><pubDate>Mon, 03 Jun 2024 14:48:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07839v2</guid></item><item><title>One-Shot Learning as Instruction Data Prospector for Large Language Models</title><link>http://arxiv.org/abs/2312.10302v4</link><description>Contemporary practices in instruction tuning often hinge on enlarging datascaling without a clear strategy for ensuring data quality, inadvertentlyintroducing noise that may compromise model performance. To address thischallenge, we introduce \textsc{Nuggets}, a novel and efficient methodologythat leverages one-shot learning to discern and select high-quality instructiondata from extensive datasets. \textsc{Nuggets} assesses the potential ofindividual instruction examples to act as effective one-shot learninginstances, thereby identifying those that can significantly improve performanceacross diverse tasks. \textsc{Nuggets} utilizes a scoring system based on theimpact of candidate examples on the perplexity of a diverse anchor set,facilitating the selection of the most advantageous data for instructiontuning. Through comprehensive evaluations on two benchmarks, including MT-Benchand Alpaca-Eval, we show that instruction tuning with the top 1\% of examplescurated by \textsc{Nuggets} substantially outperforms conventional methodsemploying the entire dataset.</description><author>Yunshui Li, Binyuan Hui, Xiaobo Xia, Jiaxi Yang, Min Yang, Lei Zhang, Shuzheng Si, Ling-Hao Chen, Junhao Liu, Tongliang Liu, Fei Huang, Yongbin Li</author><pubDate>Mon, 03 Jun 2024 14:46:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10302v4</guid></item><item><title>Targeted Reduction of Causal Models</title><link>http://arxiv.org/abs/2311.18639v2</link><description>Why does a phenomenon occur? Addressing this question is central to mostscientific inquiries and often relies on simulations of scientific models. Asmodels become more intricate, deciphering the causes behind phenomena inhigh-dimensional spaces of interconnected variables becomes increasinglychallenging. Causal Representation Learning (CRL) offers a promising avenue touncover interpretable causal patterns within these simulations through aninterventional lens. However, developing general CRL frameworks suitable forpractical applications remains an open challenge. We introduce Targeted CausalReduction (TCR), a method for condensing complex intervenable models into aconcise set of causal factors that explain a specific target phenomenon. Wepropose an information theoretic objective to learn TCR from interventionaldata of simulations, establish identifiability for continuous variables undershift interventions and present a practical algorithm for learning TCRs. Itsability to generate interpretable high-level explanations from complex modelsis demonstrated on toy and mechanical systems, illustrating its potential toassist scientists in the study of complex phenomena in a broad range ofdisciplines.</description><author>Armin Kekić, Bernhard Schölkopf, Michel Besserve</author><pubDate>Mon, 03 Jun 2024 14:45:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18639v2</guid></item><item><title>Predictive Coding beyond Correlations</title><link>http://arxiv.org/abs/2306.15479v2</link><description>Recently, there has been extensive research on the capabilities ofbiologically plausible algorithms. In this work, we show how one of suchalgorithms, called predictive coding, is able to perform causal inferencetasks. First, we show how a simple change in the inference process ofpredictive coding enables to compute interventions without the need to mutilateor redefine a causal graph. Then, we explore applications in cases where thegraph is unknown, and has to be inferred from observational data. Empirically,we show how such findings can be used to improve the performance of predictivecoding in image classification tasks, and conclude that such models are able toperform simple end-to-end causal inference tasks.</description><author>Tommaso Salvatori, Luca Pinchetti, Amine M'Charrak, Beren Millidge, Thomas Lukasiewicz</author><pubDate>Mon, 03 Jun 2024 14:43:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15479v2</guid></item><item><title>Robotic Imitation of Human Actions</title><link>http://arxiv.org/abs/2401.08381v2</link><description>Imitation can allow us to quickly gain an understanding of a new task.Through a demonstration, we can gain direct knowledge about which actions needto be performed and which goals they have. In this paper, we introduce a newapproach to imitation learning that tackles the challenges of a robot imitatinga human, such as the change in perspective and body schema. Our approach canuse a single human demonstration to abstract information about the demonstratedtask, and use that information to generalise and replicate it. We facilitatethis ability by a new integration of two state-of-the-art methods: a diffusionaction segmentation model to abstract temporal information from thedemonstration and an open vocabulary object detector for spatial information.Furthermore, we refine the abstracted information and use symbolic reasoning tocreate an action plan utilising inverse kinematics, to allow the robot toimitate the demonstrated action.</description><author>Josua Spisak, Matthias Kerzel, Stefan Wermter</author><pubDate>Mon, 03 Jun 2024 14:40:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08381v2</guid></item><item><title>TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild</title><link>http://arxiv.org/abs/2309.08637v5</link><description>Large language models with instruction-following abilities haverevolutionized the field of artificial intelligence. These models showexceptional generalizability to tackle various real-world tasks through theirnatural language interfaces. However, their performance heavily relies onhigh-quality exemplar data, which is often difficult to obtain. This challengeis further exacerbated when it comes to multimodal instruction following. Weintroduce TextBind, an almost annotation-free framework for empowering largerlanguage models with the multi-turn interleaved multimodalinstruction-following capabilities. Our approach requires only image-captionpairs and generates multi-turn multimodal instruction-response conversationsfrom a language model. To accommodate interleaved image-text inputs andoutputs, we devise MIM, a language model-centric architecture that seamlesslyintegrates image encoder and decoder models. We release our dataset, model, anddemo to foster future research in the area of multimodal instruction following.</description><author>Huayang Li, Siheng Li, Deng Cai, Longyue Wang, Lemao Liu, Taro Watanabe, Yujiu Yang, Shuming Shi</author><pubDate>Mon, 03 Jun 2024 14:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08637v5</guid></item><item><title>Quantum Generative Diffusion Model: A Fully Quantum-Mechanical Model for Generating Quantum State Ensemble</title><link>http://arxiv.org/abs/2401.07039v2</link><description>Classical diffusion models have shown superior generative results and havebeen applied to many problems. Exploring these models in the quantum domain canadvance the field of quantum generative learning. In this paper, we introducethe Quantum Generative Diffusion Model (QGDM), a simple and elegant quantumcounterpart of classical diffusion models. The core idea of QGDM is that any target quantum state can be transformedinto a completely mixed state, which has the highest entropy and maximumuncertainty about the system, through a non-unitary forward process.Subsequently, a trainable backward process can be used to recover the targetstate from the completely mixed state. The design requirements for QGDM'sbackward process include ensuring non-unitarity while maintaining a low numberof parameters. To achieve this, we introduce partial trace operations in thebackward process to enforce non-unitary. Additionally, we control the number oftrainable parameters by using a parameter-sharing strategy and incorporatingtemporal information as an input in the backward process. Furthermore, weintroduce a resource-efficient version of QGDM, which reduces the number ofauxiliary qubits while preserving impressive generative capabilities. Our proposed models exhibit better convergence performance than QuantumGenerative Adversarial Networks (QGANs) because our models optimize a convexdistance function using gradient descent. Comparative results with QGANsdemonstrate the effectiveness of our models in generating both pure and mixedquantum states. Notably, our models achieve 53.03% higher fidelity inmixed-state generation tasks compared to QGANs. These results highlight thepotential of the proposed models to tackle challenging quantum generationtasks.</description><author>Chuangtao Chen, Qinglin Zhao, MengChu Zhou, Zhimin He, Zhili Sun, Haozhen Situ</author><pubDate>Mon, 03 Jun 2024 14:37:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07039v2</guid></item><item><title>LangBridge: Multilingual Reasoning Without Multilingual Supervision</title><link>http://arxiv.org/abs/2401.10695v2</link><description>We introduce LangBridge, a zero-shot approach to adapt language models formultilingual reasoning tasks without multilingual supervision. LangBridgeoperates by bridging two models, each specialized in different aspects: (1) onespecialized in understanding multiple languages (e.g., mT5 encoder) and (2) onespecialized in reasoning (e.g., MetaMath). LangBridge connects the two modelsby introducing minimal trainable parameters between them. Despite utilizingonly English data for training, LangBridge considerably enhances theperformance of language models on low-resource languages across mathematicalreasoning, code completion, logical reasoning, and commonsense reasoning. Ouranalysis suggests that the efficacy of LangBridge stems from thelanguage-agnostic characteristics of multilingual representations. We publiclyrelease our code and models.</description><author>Dongkeun Yoon, Joel Jang, Sungdong Kim, Seungone Kim, Sheikh Shafayat, Minjoon Seo</author><pubDate>Mon, 03 Jun 2024 14:32:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10695v2</guid></item><item><title>Conservative Prediction via Data-Driven Confidence Minimization</title><link>http://arxiv.org/abs/2306.04974v2</link><description>In safety-critical applications of machine learning, it is often desirablefor a model to be conservative, abstaining from making predictions on unknowninputs which are not well-represented in the training data. However, detectingunknown examples is challenging, as it is impossible to anticipate allpotential inputs at test time. To address this, prior work (Hendrycks et al.,2018) minimizes model confidence on an auxiliary outlier dataset carefullycurated to be disjoint from the training distribution. We theoretically analyzethe choice of auxiliary dataset for confidence minimization, revealing twoactionable insights: (1) if the auxiliary set contains unknown examples similarto those seen at test time, confidence minimization leads to provable detectionof unknown test examples, and (2) if the first condition is satisfied, it isunnecessary to filter out known examples for out-of-distribution (OOD)detection. Motivated by these guidelines, we propose the Data-Driven ConfidenceMinimization (DCM) framework, which minimizes confidence on an uncertaintydataset. We apply DCM to two problem settings in which conservative predictionis paramount -- selective classification and OOD detection -- and provide arealistic way to gather uncertainty data for each setting. In our experiments,DCM consistently outperforms existing selective classification approaches on 4datasets when tested on unseen distributions and outperforms state-of-the-artOOD detection methods on 12 ID-OOD dataset pairs, reducing FPR (at TPR $95\%$)by $6.3\%$ and $58.1\%$ on CIFAR-10 and CIFAR-100 compared to Outlier Exposure.</description><author>Caroline Choi, Fahim Tajwar, Yoonho Lee, Huaxiu Yao, Ananya Kumar, Chelsea Finn</author><pubDate>Mon, 03 Jun 2024 14:30:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04974v2</guid></item><item><title>Connecting the Dots: Collaborative Fine-tuning for Black-Box Vision-Language Models</title><link>http://arxiv.org/abs/2402.04050v2</link><description>With the emergence of pretrained vision-language models (VLMs), considerableefforts have been devoted to fine-tuning them for downstream tasks. Despite theprogress made in designing efficient fine-tuning methods, such methods requireaccess to the model's parameters, which can be challenging as model ownersoften opt to provide their models as a black box to safeguard model ownership.This paper proposes a \textbf{C}ollabo\textbf{ra}tive\textbf{F}ine-\textbf{T}uning (\textbf{CraFT}) approach for fine-tuningblack-box VLMs to downstream tasks, where one only has access to the inputprompts and the output predictions of the model. CraFT comprises two modules, aprompt generation module for learning text prompts and a prediction refinementmodule for enhancing output predictions in residual style. Additionally, weintroduce an auxiliary prediction-consistent loss to promote consistentoptimization across these modules. These modules are optimized by a novelcollaborative training algorithm. Extensive experiments on few-shotclassification over 15 datasets demonstrate the superiority of CraFT. Theresults show that CraFT achieves a decent gain of about 12\% with 16-shotdatasets and only 8,000 queries. Moreover, CraFT trains faster and uses onlyabout 1/80 of the memory footprint for deployment, while sacrificing only1.62\% compared to the white-box method. Our code is publicly available athttps://github.com/mrflogs/CraFT .</description><author>Zhengbo Wang, Jian Liang, Ran He, Zilei Wang, Tieniu Tan</author><pubDate>Mon, 03 Jun 2024 14:22:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04050v2</guid></item><item><title>Partial Search in a Frozen Network is Enough to Find a Strong Lottery Ticket</title><link>http://arxiv.org/abs/2402.14029v2</link><description>Randomly initialized dense networks contain subnetworks that achieve highaccuracy without weight learning -- strong lottery tickets (SLTs). Recently,Gadhikar et al. (2023) demonstrated that SLTs can also be found within arandomly pruned source network, thus reducing the SLT search space. However,this limits the search to SLTs that are even sparser than the source, leadingto worse accuracy due to unintentionally high sparsity. This paper proposes amethod that reduces the SLT search space by an arbitrary ratio independent ofthe desired SLT sparsity. A random subset of the initial weights is excludedfrom the search space by freezing it -- i.e., by either permanently pruningthem or locking them as a fixed part of the SLT. In addition to reducing searchspace, the proposed random freezing can also provide the benefit of reducingthe model size for inference. Furthermore, experimental results show that theproposed method finds SLTs with better accuracy-to-model size trade-off thanthe SLTs obtained from dense or randomly pruned source networks. In particular,the SLTs found in Frozen ResNets on image classification using ImageNetsignificantly improve the accuracy-to-search space and accuracy-to-model sizetrade-offs over SLTs within dense (non-freezing) or sparse (non-locking) randomnetworks.</description><author>Hikari Otsuka, Daiki Chijiwa, Ángel López García-Arias, Yasuyuki Okoshi, Kazushi Kawamura, Thiem Van Chu, Daichi Fujiki, Susumu Takeuchi, Masato Motomura</author><pubDate>Mon, 03 Jun 2024 14:12:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14029v2</guid></item><item><title>Sequential Neural Score Estimation: Likelihood-Free Inference with Conditional Score Based Diffusion Models</title><link>http://arxiv.org/abs/2210.04872v3</link><description>We introduce Sequential Neural Posterior Score Estimation (SNPSE), ascore-based method for Bayesian inference in simulator-based models. Ourmethod, inspired by the remarkable success of score-based methods in generativemodelling, leverages conditional score-based diffusion models to generatesamples from the posterior distribution of interest. The model is trained usingan objective function which directly estimates the score of the posterior. Weembed the model into a sequential training procedure, which guides simulationsusing the current approximation of the posterior at the observation ofinterest, thereby reducing the simulation cost. We also introduce severalalternative sequential approaches, and discuss their relative merits. We thenvalidate our method, as well as its amortised, non-sequential, variant onseveral numerical examples, demonstrating comparable or superior performance toexisting state-of-the-art methods such as Sequential Neural PosteriorEstimation (SNPE).</description><author>Louis Sharrock, Jack Simons, Song Liu, Mark Beaumont</author><pubDate>Mon, 03 Jun 2024 14:07:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04872v3</guid></item><item><title>Graph-enhanced Large Language Models in Asynchronous Plan Reasoning</title><link>http://arxiv.org/abs/2402.02805v2</link><description>Planning is a fundamental property of human intelligence. Reasoning aboutasynchronous plans is challenging since it requires sequential and parallelplanning to optimize time costs. Can large language models (LLMs) succeed atthis task? Here, we present the first large-scale study investigating thisquestion. We find that a representative set of closed and open-source LLMs,including GPT-4 and LLaMA-2, behave poorly when not supplied with illustrationsabout the task-solving process in our benchmark AsyncHow. We propose a noveltechnique called Plan Like a Graph (PLaG) that combines graphs with naturallanguage prompts and achieves state-of-the-art results. We show that althoughPLaG can boost model performance, LLMs still suffer from drastic degradationwhen task complexity increases, highlighting the limits of utilizing LLMs forsimulating digital devices. We see our study as an exciting step towards usingLLMs as efficient autonomous agents. Our code and data are available athttps://github.com/fangru-lin/graph-llm-asynchow-plan.</description><author>Fangru Lin, Emanuele La Malfa, Valentin Hofmann, Elle Michelle Yang, Anthony Cohn, Janet B. Pierrehumbert</author><pubDate>Mon, 03 Jun 2024 14:07:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02805v2</guid></item><item><title>Accelerating Graph Neural Networks via Edge Pruning for Power Allocation in Wireless Networks</title><link>http://arxiv.org/abs/2305.12639v2</link><description>Graph Neural Networks (GNNs) have recently emerged as a promising approach totackling power allocation problems in wireless networks. Since unpairedtransmitters and receivers are often spatially distant, the distance-basedthreshold is proposed to reduce the computation time by excluding or includingthe channel state information in GNNs. In this paper, we are the first tointroduce a neighbour-based threshold approach to GNNs to reduce the timecomplexity. Furthermore, we conduct a comprehensive analysis of bothdistance-based and neighbour-based thresholds and provide recommendations forselecting the appropriate value in different communication channel scenarios.We design the corresponding neighbour-based Graph Neural Networks (N-GNN) withthe aim of allocating transmit powers to maximise the network throughput. Ourresults show that our proposed N-GNN offer significant advantages in terms ofreducing time complexity while preserving strong performance and generalisationcapacity. Besides, we show that by choosing a suitable threshold, the timecomplexity is reduced from O(|V|^2) to O(|V|), where |V| is the total number oftransceiver pairs.</description><author>Lili Chen, Jingge Zhu, Jamie Evans</author><pubDate>Mon, 03 Jun 2024 14:06:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12639v2</guid></item><item><title>Patch-Wise Self-Supervised Visual Representation Learning: A Fine-Grained Approach</title><link>http://arxiv.org/abs/2310.18651v5</link><description>Self-supervised visual representation learning traditionally focuses onimage-level instance discrimination. Our study introduces an innovative,fine-grained dimension by integrating patch-level discrimination into thesemethodologies. This integration allows for the simultaneous analysis of localand global visual features, thereby enriching the quality of the learnedrepresentations. Initially, the original images undergo spatial augmentation.Subsequently, we employ a distinctive photometric patch-level augmentation,where each patch is individually augmented, independent from other patcheswithin the same view. This approach generates a diverse training dataset withdistinct color variations in each segment. The augmented images are thenprocessed through a self-distillation learning framework, utilizing the VisionTransformer (ViT) as its backbone. The proposed method minimizes therepresentation distances across both image and patch levels to capture detailsfrom macro to micro perspectives. To this end, we present a simple yeteffective patch-matching algorithm to find the corresponding patches across theaugmented views. Thanks to the efficient structure of the patch-matchingalgorithm, our method reduces computational complexity compared to similarapproaches. Consequently, we achieve an advanced understanding of the modelwithout adding significant computational requirements. We have extensivelypretrained our method on datasets of varied scales, such as Cifar10,ImageNet-100, and ImageNet-1K. It demonstrates superior performance overstate-of-the-art self-supervised representation learning methods in imageclassification and downstream tasks, such as copy detection and imageretrieval. The implementation of our method is accessible on GitHub.</description><author>Ali Javidani, Mohammad Amin Sadeghi, Babak Nadjar Araabi</author><pubDate>Mon, 03 Jun 2024 14:02:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18651v5</guid></item><item><title>Unlock the Power of Algorithm Features: A Generalization Analysis for Algorithm Selection</title><link>http://arxiv.org/abs/2405.11349v2</link><description>In the algorithm selection research, the discussion surrounding algorithmfeatures has been significantly overshadowed by the emphasis on problemfeatures. Although a few empirical studies have yielded evidence regarding theeffectiveness of algorithm features, the potential benefits of incorporatingalgorithm features into algorithm selection models and their suitability fordifferent scenarios remain unclear. In this paper, we address this gap byproposing the first provable guarantee for algorithm selection based onalgorithm features, taking a generalization perspective. We analyze thebenefits and costs associated with algorithm features and investigate how thegeneralization error is affected by different factors. Specifically, we examineadaptive and predefined algorithm features under transductive and inductivelearning paradigms, respectively, and derive upper bounds for thegeneralization error based on their model's Rademacher complexity. Ourtheoretical findings not only provide tight upper bounds, but also offeranalytical insights into the impact of various factors, such as the trainingscale of problem instances and candidate algorithms, model parameters, featurevalues, and distributional differences between the training and test data.Notably, we demonstrate how models will benefit from algorithm features incomplex scenarios involving many algorithms, and proves the positivecorrelation between generalization error bound and $\chi^2$-divergence ofdistributions.</description><author>Xingyu Wu, Yan Zhong, Jibin Wu, Yuxiao Huang, Sheng-hao Wu, Kay Chen Tan</author><pubDate>Mon, 03 Jun 2024 13:55:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11349v2</guid></item><item><title>ZeroNLG: Aligning and Autoencoding Domains for Zero-Shot Multimodal and Multilingual Natural Language Generation</title><link>http://arxiv.org/abs/2303.06458v3</link><description>Natural Language Generation (NLG) accepts input data in the form of images,videos, or text and generates corresponding natural language text as output.Existing NLG methods mainly adopt a supervised approach and rely heavily oncoupled data-to-text pairs. However, for many targeted scenarios and fornon-English languages, sufficient quantities of labeled data are often notavailable. To relax the dependency on labeled data of downstream tasks, wepropose an intuitive and effective zero-shot learning framework, ZeroNLG, whichcan deal with multiple NLG tasks, including image-to-text (image captioning),video-to-text (video captioning), and text-to-text (neural machinetranslation), across English, Chinese, German, and French within a unifiedframework. ZeroNLG does not require any labeled downstream pairs for training.During training, ZeroNLG (i) projects different domains (across modalities andlanguages) to corresponding coordinates in a shared common latent space; (ii)bridges different domains by aligning their corresponding coordinates in thisspace; and (iii) builds an unsupervised multilingual auto-encoder to learn togenerate text by reconstructing the input text given its coordinate in sharedlatent space. Consequently, during inference, based on the data-to-textpipeline, ZeroNLG can generate target sentences across different languagesgiven the coordinate of input data in the common space. Within this unifiedframework, given visual (imaging or video) data as input, ZeroNLG can performzero-shot visual captioning; given textual sentences as input, ZeroNLG canperform zero-shot machine translation. We present the results of extensiveexperiments on twelve NLG tasks, showing that, without using any labeleddownstream pairs for training, ZeroNLG generates high-quality and believableoutputs and significantly outperforms existing zero-shot methods.</description><author>Bang Yang, Fenglin Liu, Yuexian Zou, Xian Wu, Yaowei Wang, David A. Clifton</author><pubDate>Mon, 03 Jun 2024 13:47:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06458v3</guid></item><item><title>iMove: Exploring Bio-impedance Sensing for Fitness Activity Recognition</title><link>http://arxiv.org/abs/2402.09445v2</link><description>Automatic and precise fitness activity recognition can be beneficial inaspects from promoting a healthy lifestyle to personalized preventativehealthcare. While IMUs are currently the prominent fitness tracking modality,through iMove, we show bio-impedence can help improve IMU-based fitnesstracking through sensor fusion and contrastive learning.To evaluate ourmethods, we conducted an experiment including six upper body fitness activitiesperformed by ten subjects over five days to collect synchronized data frombio-impedance across two wrists and IMU on the left wrist.The contrastivelearning framework uses the two modalities to train a better IMU-onlyclassification model, where bio-impedance is only required at the trainingphase, by which the average Macro F1 score with the input of a single IMU wasimproved by 3.22 \% reaching 84.71 \% compared to the 81.49 \% of the IMUbaseline model. We have also shown how bio-impedance can improve human activityrecognition (HAR) directly through sensor fusion, reaching an average Macro F1score of 89.57 \% (two modalities required for both training and inference)even if Bio-impedance alone has an average macro F1 score of 75.36 \%, which isoutperformed by IMU alone. In addition, similar results were obtained in anextended study on lower body fitness activity classification, demonstrating thegeneralisability of our approach.Our findings underscore the potential ofsensor fusion and contrastive learning as valuable tools for advancing fitnessactivity recognition, with bio-impedance playing a pivotal role in augmentingthe capabilities of IMU-based systems.</description><author>Mengxi Liu, Vitor Fortes Rey, Yu Zhang, Lala Shakti Swarup Ray, Bo Zhou, Paul Lukowicz</author><pubDate>Mon, 03 Jun 2024 13:42:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09445v2</guid></item><item><title>OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework</title><link>http://arxiv.org/abs/2405.11143v2</link><description>As large language models (LLMs) continue to grow by scaling laws,reinforcement learning from human feedback (RLHF) has gained significantattention due to its outstanding performance. However, unlike pretraining orfine-tuning a single model, scaling reinforcement learning from human feedback(RLHF) for training large language models poses coordination challenges acrossfour models. We present OpenRLHF, an open-source framework enabling efficientRLHF scaling. Unlike existing RLHF frameworks that co-locate four models on thesame GPUs, OpenRLHF re-designs scheduling for the models beyond 70B parametersusing Ray, vLLM, and DeepSpeed, leveraging improved resource utilization anddiverse training approaches. Integrating seamlessly with Hugging Face, OpenRLHFprovides an out-of-the-box solution with optimized algorithms and launchscripts, which ensures user-friendliness. OpenRLHF implements RLHF, DPO,rejection sampling, and other alignment techniques. Empowering state-of-the-artLLM development, OpenRLHF's code is available athttps://github.com/OpenLLMAI/OpenRLHF.</description><author>Jian Hu, Xibin Wu, Weixun Wang, Xianyu, Dehao Zhang, Yu Cao</author><pubDate>Mon, 03 Jun 2024 13:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11143v2</guid></item><item><title>Fundamental Limitations of Alignment in Large Language Models</title><link>http://arxiv.org/abs/2304.11082v6</link><description>An important aspect in developing language models that interact with humansis aligning their behavior to be useful and unharmful for their human users.This is usually achieved by tuning the model in a way that enhances desiredbehaviors and inhibits undesired ones, a process referred to as alignment. Inthis paper, we propose a theoretical approach called Behavior ExpectationBounds (BEB) which allows us to formally investigate several inherentcharacteristics and limitations of alignment in large language models.Importantly, we prove that within the limits of this framework, for anybehavior that has a finite probability of being exhibited by the model, thereexist prompts that can trigger the model into outputting this behavior, withprobability that increases with the length of the prompt. This implies that anyalignment process that attenuates an undesired behavior but does not remove italtogether, is not safe against adversarial prompting attacks. Furthermore, ourframework hints at the mechanism by which leading alignment approaches such asreinforcement learning from human feedback make the LLM prone to being promptedinto the undesired behaviors. This theoretical result is being experimentallydemonstrated in large scale by the so called contemporary "chatGPT jailbreaks",where adversarial users trick the LLM into breaking its alignment guardrails bytriggering it into acting as a malicious persona. Our results exposefundamental limitations in alignment of LLMs and bring to the forefront theneed to devise reliable mechanisms for ensuring AI safety.</description><author>Yotam Wolf, Noam Wies, Oshri Avnery, Yoav Levine, Amnon Shashua</author><pubDate>Mon, 03 Jun 2024 13:19:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11082v6</guid></item><item><title>Graph Language Models</title><link>http://arxiv.org/abs/2401.07105v3</link><description>While Language Models (LMs) are the workhorses of NLP, their interplay withstructured knowledge graphs (KGs) is still actively researched. Current methodsfor encoding such graphs typically either (i) linearize them for embedding withLMs -- which underutilize structural information, or (ii) use Graph NeuralNetworks (GNNs) to preserve the graph structure -- but GNNs cannot representtext features as well as pretrained LMs. In our work we introduce a novel LMtype, the Graph Language Model (GLM), that integrates the strengths of bothapproaches and mitigates their weaknesses. The GLM parameters are initializedfrom a pretrained LM to enhance understanding of individual graph concepts andtriplets. Simultaneously, we design the GLM's architecture to incorporate graphbiases, thereby promoting effective knowledge distribution within the graph.This enables GLMs to process graphs, texts, and interleaved inputs of both.Empirical evaluations on relation classification tasks show that GLM embeddingssurpass both LM- and GNN-based baselines in supervised and zero-shot setting,demonstrating their versatility.</description><author>Moritz Plenz, Anette Frank</author><pubDate>Mon, 03 Jun 2024 13:14:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07105v3</guid></item></channel></rss>