<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 15 May 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>The RoboDrive Challenge: Drive Anytime Anywhere in Any Condition</title><link>http://arxiv.org/abs/2405.08816v1</link><description>In the realm of autonomous driving, robust perception underout-of-distribution conditions is paramount for the safe deployment ofvehicles. Challenges such as adverse weather, sensor malfunctions, andenvironmental unpredictability can severely impact the performance ofautonomous systems. The 2024 RoboDrive Challenge was crafted to propel thedevelopment of driving perception technologies that can withstand and adapt tothese real-world variabilities. Focusing on four pivotal tasks -- BEVdetection, map segmentation, semantic occupancy prediction, and multi-viewdepth estimation -- the competition laid down a gauntlet to innovate andenhance system resilience against typical and atypical disturbances. Thisyear's challenge consisted of five distinct tracks and attracted 140 registeredteams from 93 institutes across 11 countries, resulting in nearly one thousandsubmissions evaluated through our servers. The competition culminated in 15top-performing solutions, which introduced a range of innovative approachesincluding advanced data augmentation, multi-sensor fusion, self-supervisedlearning for error correction, and new algorithmic strategies to enhance sensorrobustness. These contributions significantly advanced the state of the art,particularly in handling sensor inconsistencies and environmental variability.Participants, through collaborative efforts, pushed the boundaries of currenttechnologies, showcasing their potential in real-world scenarios. Extensiveevaluations and analyses provided insights into the effectiveness of thesesolutions, highlighting key trends and successful strategies for improving theresilience of driving perception systems. This challenge has set a newbenchmark in the field, providing a rich repository of techniques expected toguide future research in this field.</description><author>Lingdong Kong, Shaoyuan Xie, Hanjiang Hu, Yaru Niu, Wei Tsang Ooi, Benoit R. Cottereau, Lai Xing Ng, Yuexin Ma, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu, Weichao Qiu, Wei Zhang, Xu Cao, Hao Lu, Ying-Cong Chen, Caixin Kang, Xinning Zhou, Chengyang Ying, Wentao Shang, Xingxing Wei, Yinpeng Dong, Bo Yang, Shengyin Jiang, Zeliang Ma, Dengyi Ji, Haiwen Li, Xingliang Huang, Yu Tian, Genghua Kou, Fan Jia, Yingfei Liu, Tiancai Wang, Ying Li, Xiaoshuai Hao, Yifan Yang, Hui Zhang, Mengchuan Wei, Yi Zhou, Haimei Zhao, Jing Zhang, Jinke Li, Xiao He, Xiaoqiang Cheng, Bingyang Zhang, Lirong Zhao, Dianlei Ding, Fangsheng Liu, Yixiang Yan, Hongming Wang, Nanfei Ye, Lun Luo, Yubo Tian, Yiwei Zuo, Zhe Cao, Yi Ren, Yunfan Li, Wenjie Liu, Xun Wu, Yifan Mao, Ming Li, Jian Liu, Jiayang Liu, Zihan Qin, Cunxi</author><pubDate>Tue, 14 May 2024 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08816v1</guid></item><item><title>Efficient Vision-Language Pre-training by Cluster Masking</title><link>http://arxiv.org/abs/2405.08815v1</link><description>We propose a simple strategy for masking image patches during visual-languagecontrastive learning that improves the quality of the learned representationsand the training speed. During each iteration of training, we randomly maskclusters of visually similar image patches, as measured by their raw pixelintensities. This provides an extra learning signal, beyond the contrastivetraining itself, since it forces a model to predict words for masked visualstructures solely from context. It also speeds up training by reducing theamount of data used in each image. We evaluate the effectiveness of our modelby pre-training on a number of benchmarks, finding that it outperforms othermasking strategies, such as FLIP, on the quality of the learned representation.</description><author>Zihao Wei, Zixuan Pan, Andrew Owens</author><pubDate>Tue, 14 May 2024 18:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08815v1</guid></item><item><title>MambaOut: Do We Really Need Mamba for Vision?</title><link>http://arxiv.org/abs/2405.07992v2</link><description>Mamba, an architecture with RNN-like token mixer of state space model (SSM),was recently introduced to address the quadratic complexity of the attentionmechanism and subsequently applied to vision tasks. Nevertheless, theperformance of Mamba for vision is often underwhelming when compared withconvolutional and attention-based models. In this paper, we delve into theessence of Mamba, and conceptually conclude that Mamba is ideally suited fortasks with long-sequence and autoregressive characteristics. For vision tasks,as image classification does not align with either characteristic, wehypothesize that Mamba is not necessary for this task; Detection andsegmentation tasks are also not autoregressive, yet they adhere to thelong-sequence characteristic, so we believe it is still worthwhile to exploreMamba's potential for these tasks. To empirically verify our hypotheses, weconstruct a series of models named MambaOut through stacking Mamba blocks whileremoving their core token mixer, SSM. Experimental results strongly support ourhypotheses. Specifically, our MambaOut model surpasses all visual Mamba modelson ImageNet image classification, indicating that Mamba is indeed unnecessaryfor this task. As for detection and segmentation, MambaOut cannot match theperformance of state-of-the-art visual Mamba models, demonstrating thepotential of Mamba for long-sequence visual tasks. The code is available athttps://github.com/yuweihao/MambaOut</description><author>Weihao Yu, Xinchao Wang</author><pubDate>Tue, 14 May 2024 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07992v2</guid></item><item><title>CinePile: A Long Video Question Answering Dataset and Benchmark</title><link>http://arxiv.org/abs/2405.08813v1</link><description>Current datasets for long-form video understanding often fall short ofproviding genuine long-form comprehension challenges, as many tasks derivedfrom these datasets can be successfully tackled by analyzing just one or a fewrandom frames from a video. To address this issue, we present a novel datasetand benchmark, CinePile, specifically designed for authentic long-form videounderstanding. This paper details our innovative approach for creating aquestion-answer dataset, utilizing advanced LLMs with human-in-the-loop andbuilding upon human-generated raw data. Our comprehensive dataset comprises305,000 multiple-choice questions (MCQs), covering various visual andmultimodal aspects, including temporal comprehension, understandinghuman-object interactions, and reasoning about events or actions within ascene. Additionally, we evaluate recent video-centric LLMs, both open-sourceand proprietary, on the test split of our dataset. The findings reveal thateven state-of-the-art video-centric LLMs significantly lag behind humanperformance in these tasks, highlighting the complexity and challenge inherentin video understanding. The dataset is available athttps://hf.co/datasets/tomg-group-umd/cinepile</description><author>Ruchit Rawal, Khalid Saifullah, Ronen Basri, David Jacobs, Gowthami Somepalli, Tom Goldstein</author><pubDate>Tue, 14 May 2024 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08813v1</guid></item><item><title>RealFill: Reference-Driven Generation for Authentic Image Completion</title><link>http://arxiv.org/abs/2309.16668v2</link><description>Recent advances in generative imagery have brought forth outpainting andinpainting models that can produce high-quality, plausible image content inunknown regions. However, the content these models hallucinate is necessarilyinauthentic, since they are unaware of the true scene. In this work, we proposeRealFill, a novel generative approach for image completion that fills inmissing regions of an image with the content that should have been there.RealFill is a generative inpainting model that is personalized using only a fewreference images of a scene. These reference images do not have to be alignedwith the target image, and can be taken with drastically varying viewpoints,lighting conditions, camera apertures, or image styles. Once personalized,RealFill is able to complete a target image with visually compelling contentsthat are faithful to the original scene. We evaluate RealFill on a new imagecompletion benchmark that covers a set of diverse and challenging scenarios,and find that it outperforms existing approaches by a large margin. Projectpage: https://realfill.github.io</description><author>Luming Tang, Nataniel Ruiz, Qinghao Chu, Yuanzhen Li, Aleksander Holynski, David E. Jacobs, Bharath Hariharan, Yael Pritch, Neal Wadhwa, Kfir Aberman, Michael Rubinstein</author><pubDate>Tue, 14 May 2024 18:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16668v2</guid></item><item><title>A Single Graph Convolution Is All You Need: Efficient Grayscale Image Classification</title><link>http://arxiv.org/abs/2402.00564v2</link><description>Image classifiers often rely on convolutional neural networks (CNN) for theirtasks, which are inherently more heavyweight than multilayer perceptrons(MLPs), which can be problematic in real-time applications. Additionally, manyimage classification models work on both RGB and grayscale datasets.Classifiers that operate solely on grayscale images are much less common.Grayscale image classification has diverse applications, including but notlimited to medical image classification and synthetic aperture radar (SAR)automatic target recognition (ATR). Thus, we present a novel grayscale (singlechannel) image classification approach using a vectorized view of images. Weexploit the lightweightness of MLPs by viewing images as a vector and reducingour problem setting to the grayscale image classification setting. We find thatusing a single graph convolutional layer batch-wise increases accuracy andreduces variance in the performance of our model. Moreover, we develop acustomized accelerator on FPGA for the proposed model with severaloptimizations to improve its performance. Our experimental results on benchmarkgrayscale image datasets demonstrate the effectiveness of the proposed model,achieving vastly lower latency (up to 16$\times$ less) and competitive orleading performance compared to other state-of-the-art image classificationmodels on various domain-specific grayscale image classification datasets.</description><author>Jacob Fein-Ashley, Tian Ye, Sachini Wickramasinghe, Bingyi Zhang, Rajgopal Kannan, Viktor Prasanna</author><pubDate>Tue, 14 May 2024 18:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00564v2</guid></item><item><title>SciFIBench: Benchmarking Large Multimodal Models for Scientific Figure Interpretation</title><link>http://arxiv.org/abs/2405.08807v1</link><description>Large multimodal models (LMMs) have proven flexible and generalisable acrossmany tasks and fields. Although they have strong potential to aid scientificresearch, their capabilities in this domain are not well characterised. A keyaspect of scientific research is the ability to understand and interpretfigures, which serve as a rich, compressed source of complex information. Inthis work, we present SciFIBench, a scientific figure interpretation benchmark.Our main benchmark consists of a 1000-question gold set of multiple-choicequestions split between two tasks across 12 categories. The questions arecurated from CS arXiv paper figures and captions, using adversarial filteringto find hard negatives and human verification for quality control. We evaluate26 LMMs on SciFIBench, finding it to be a challenging benchmark. Finally, weinvestigate the alignment and reasoning faithfulness of the LMMs on augmentedquestion sets from our benchmark. We release SciFIBench to encourage progressin this domain.</description><author>Jonathan Roberts, Kai Han, Neil Houlsby, Samuel Albanie</author><pubDate>Tue, 14 May 2024 18:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08807v1</guid></item><item><title>Stability and Performance Analysis of Discrete-Time ReLU Recurrent Neural Networks</title><link>http://arxiv.org/abs/2405.05236v3</link><description>This paper presents sufficient conditions for the stability and $\ell_2$-gainperformance of recurrent neural networks (RNNs) with ReLU activation functions.These conditions are derived by combining Lyapunov/dissipativity theory withQuadratic Constraints (QCs) satisfied by repeated ReLUs. We write a generalclass of QCs for repeated RELUs using known properties for the scalar ReLU. Ourstability and performance condition uses these QCs along with a "lifted"representation for the ReLU RNN. We show that the positive homogeneity propertysatisfied by a scalar ReLU does not expand the class of QCs for the repeatedReLU. We present examples to demonstrate the stability / performance conditionand study the effect of the lifting horizon.</description><author>Sahel Vahedi Noori, Bin Hu, Geir Dullerud, Peter Seiler</author><pubDate>Tue, 14 May 2024 18:53:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05236v3</guid></item><item><title>Sample Observed Effects: Enumeration, Randomization and Generalization</title><link>http://arxiv.org/abs/2108.04376v5</link><description>The widely used 'Counterfactual' definition of Causal Effects was derived forunbiasedness and accuracy - and not generalizability. We propose aCombinatorial definition for the External Validity (EV) of interventioneffects. We first define the concept of an effect observation 'background'. Wethen formulate conditions for effect generalization based on their sets of(observed and unobserved) backgrounds. This reveals two limits for effectgeneralization: (1) when effects are observed under all their enumerablebackgrounds, or, (2) when backgrounds have become sufficiently randomized. Weuse the resulting combinatorial framework to re-examine several issues in theoriginal counterfactual formulation: out-of-sample validity, concurrentestimation of multiple effects, bias-variance tradeoffs, statistical power, andconnections to current predictive and explaining techniques. Methodologically, the definitions also allow us to replace the parametricestimation problems that followed the counterfactual definition bycombinatorial enumeration and randomization problems in non-experimentalsamples. We use this non-parametric framework to demonstrate (ExternalValidity, Unconfoundness and Precision) tradeoffs in the performance of popularsupervised, explaining, and causal-effect estimators. We also illustrate howthe approach allows for the use of supervised and explaining methods innon-i.i.d. samples. The COVID19 pandemic highlighted the need for learningsolutions to provide predictions in severally incomplete samples. Wedemonstrate applications in this pressing problem.</description><author>Andre F. Ribeiro</author><pubDate>Tue, 14 May 2024 18:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.04376v5</guid></item><item><title>Prospects of Privacy Advantage in Quantum Machine Learning</title><link>http://arxiv.org/abs/2405.08801v1</link><description>Ensuring data privacy in machine learning models is critical, particularly indistributed settings where model gradients are typically shared among multipleparties to allow collaborative learning. Motivated by the increasing success ofrecovering input data from the gradients of classical models, this studyaddresses a central question: How hard is it to recover the input data from thegradients of quantum machine learning models? Focusing on variational quantumcircuits (VQC) as learning models, we uncover the crucial role played by thedynamical Lie algebra (DLA) of the VQC ansatz in determining privacyvulnerabilities. While the DLA has previously been linked to the classicalsimulatability and trainability of VQC models, this work, for the first time,establishes its connection to the privacy of VQC models. In particular, we showthat properties conducive to the trainability of VQCs, such as apolynomial-sized DLA, also facilitate the extraction of detailed snapshots ofthe input. We term this a weak privacy breach, as the snapshots enable trainingVQC models for distinct learning tasks without direct access to the originalinput. Further, we investigate the conditions for a strong privacy breach wherethe original input data can be recovered from these snapshots by classical orquantum-assisted polynomial time methods. We establish conditions on theencoding map such as classical simulatability, overlap with DLA basis, and itsFourier frequency characteristics that enable such a privacy breach of VQCmodels. Our findings thus play a crucial role in detailing the prospects ofquantum privacy advantage by guiding the requirements for designing quantummachine learning models that balance trainability with robust privacyprotection.</description><author>Jamie Heredge, Niraj Kumar, Dylan Herman, Shouvanik Chakrabarti, Romina Yalovetzky, Shree Hari Sureshbabu, Marco Pistoia</author><pubDate>Tue, 14 May 2024 18:49:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08801v1</guid></item><item><title>Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance</title><link>http://arxiv.org/abs/2310.03722v4</link><description>In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$of a Gaussian distribution with unknown variance $\sigma^2$. Curiously, heemployed both an improper (right Haar) mixture over $\sigma$ and an improper(flat) mixture over $\mu$. Here, we elaborate carefully on the details of hisconstruction, which use generalized nonintegrable martingales and an extendedVille's inequality. While this does yield a sequential t-test, it does notyield an "e-process" (due to the nonintegrability of his martingale). In thispaper, we develop two new e-processes and confidence sequences for the samesetting: one is a test martingale in a reduced filtration, while the other isan e-process in the canonical data filtration. These are respectively obtainedby swapping Lai's flat mixture for a Gaussian mixture, and swapping the rightHaar mixture over $\sigma$ with the maximum likelihood estimate under the null,as done in universal inference. We also analyze the width of resultingconfidence sequences, which have a curious polynomial dependence on the errorprobability $\alpha$ that we prove to be not only unavoidable, but (foruniversal inference) even better than the classical fixed-sample t-test.Numerical experiments are provided along the way to compare and contrast thevarious approaches, including some recent suboptimal ones.</description><author>Hongjian Wang, Aaditya Ramdas</author><pubDate>Tue, 14 May 2024 18:48:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03722v4</guid></item><item><title>Ambiguous Annotations: When is a Pedestrian not a Pedestrian?</title><link>http://arxiv.org/abs/2405.08794v1</link><description>Datasets labelled by human annotators are widely used in the training andtesting of machine learning models. In recent years, researchers areincreasingly paying attention to label quality. However, it is not alwayspossible to objectively determine whether an assigned label is correct or not.The present work investigates this ambiguity in the annotation of autonomousdriving datasets as an important dimension of data quality. Our experimentsshow that excluding highly ambiguous data from the training improves modelperformance of a state-of-the-art pedestrian detector in terms of LAMR,precision and F1 score, thereby saving training time and annotation costs.Furthermore, we demonstrate that, in order to safely remove ambiguous instancesand ensure the retained representativeness of the training data, anunderstanding of the properties of the dataset and class under investigation iscrucial.</description><author>Luisa Schwirten, Jannes Scholz, Daniel Kondermann, Janis Keuper</author><pubDate>Tue, 14 May 2024 18:44:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08794v1</guid></item><item><title>A Brief Introduction to Causal Inference in Machine Learning</title><link>http://arxiv.org/abs/2405.08793v1</link><description>This is a lecture note produced for DS-GA 3001.003 "Special Topics in DS -Causal Inference in Machine Learning" at the Center for Data Science, New YorkUniversity in Spring, 2024. This course was created to target master's and PhDlevel students with basic background in machine learning but who were notexposed to causal inference or causal reasoning in general previously. Inparticular, this course focuses on introducing such students to expand theirview and knowledge of machine learning to incorporate causal reasoning, as thisaspect is at the core of so-called out-of-distribution generalization (or lackthereof.)</description><author>Kyunghyun Cho</author><pubDate>Tue, 14 May 2024 18:41:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08793v1</guid></item><item><title>Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs</title><link>http://arxiv.org/abs/2405.08792v1</link><description>This paper explores the potential of large language models (LLMs) to make theAeronautical Regulations of Colombia (RAC) more accessible. Given thecomplexity and extensive technicality of the RAC, this study introduces a novelapproach to simplifying these regulations for broader understanding. Bydeveloping the first-ever RAC database, which contains 24,478 expertly labeledquestion-and-answer pairs, and fine-tuning LLMs specifically for RACapplications, the paper outlines the methodology for dataset assembly,expert-led annotation, and model training. Utilizing the Gemma1.1 2b modelalong with advanced techniques like Unsloth for efficient VRAM usage and flashattention mechanisms, the research aims to expedite training processes. Thisinitiative establishes a foundation to enhance the comprehensibility andaccessibility of RAC, potentially benefiting novices and reducing dependence onexpert consultations for navigating the aviation industry's regulatorylandscape. You can visit the dataset(https://huggingface.co/somosnlp/gemma-1.1-2b-it_ColombiaRAC_FullyCurated_format_chatML_V1)and the model(https://huggingface.co/datasets/somosnlp/ColombiaRAC_FullyCurated) here.</description><author>Edison Jair Bejarano Sepulveda, Nicolai Potes Hector, Santiago Pineda Montoya, Felipe Ivan Rodriguez, Jaime Enrique Orduy, Alec Rosales Cabezas, Danny Traslaviña Navarrete, Sergio Madrid Farfan</author><pubDate>Tue, 14 May 2024 18:41:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08792v1</guid></item><item><title>Kolmogorov-Arnold Networks (KANs) for Time Series Analysis</title><link>http://arxiv.org/abs/2405.08790v1</link><description>This paper introduces a novel application of Kolmogorov-Arnold Networks(KANs) to time series forecasting, leveraging their adaptive activationfunctions for enhanced predictive modeling. Inspired by the Kolmogorov-Arnoldrepresentation theorem, KANs replace traditional linear weights withspline-parametrized univariate functions, allowing them to learn activationpatterns dynamically. We demonstrate that KANs outperforms conventionalMulti-Layer Perceptrons (MLPs) in a real-world satellite traffic forecastingtask, providing more accurate results with considerably fewer number oflearnable parameters. We also provide an ablation study of KAN-specificparameters impact on performance. The proposed approach opens new avenues foradaptive forecasting models, emphasizing the potential of KANs as a powerfultool in predictive analytics.</description><author>Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Màrius Caus</author><pubDate>Tue, 14 May 2024 18:38:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08790v1</guid></item><item><title>ReproHum #0087-01: Human Evaluation Reproduction Report for Generating Fact Checking Explanations</title><link>http://arxiv.org/abs/2404.17481v2</link><description>This paper presents a partial reproduction of Generating Fact CheckingExplanations by Anatanasova et al (2020) as part of the ReproHum element of theReproNLP shared task to reproduce the findings of NLP research regarding humanevaluation. This shared task aims to investigate the extent to which NLP as afield is becoming more or less reproducible over time. Following theinstructions provided by the task organisers and the original authors, wecollect relative rankings of 3 fact-checking explanations (comprising a goldstandard and the outputs of 2 models) for 40 inputs on the criteria ofCoverage. The results of our reproduction and reanalysis of the original work'sraw results lend support to the original findings, with similar patterns seenbetween the original work and our reproduction. Whilst we observe slightvariation from the original results, our findings support the main conclusionsdrawn by the original authors pertaining to the efficacy of their proposedmodels.</description><author>Tyler Loakman, Chenghua Lin</author><pubDate>Tue, 14 May 2024 18:36:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17481v2</guid></item><item><title>Incorporating Clinical Guidelines through Adapting Multi-modal Large Language Model for Prostate Cancer PI-RADS Scoring</title><link>http://arxiv.org/abs/2405.08786v1</link><description>The Prostate Imaging Reporting and Data System (PI-RADS) is pivotal in thediagnosis of clinically significant prostate cancer through MRI imaging.Current deep learning-based PI-RADS scoring methods often lack theincorporation of essential PI-RADS clinical guidelines~(PICG) utilized byradiologists, potentially compromising scoring accuracy. This paper introducesa novel approach that adapts a multi-modal large language model (MLLM) toincorporate PICG into PI-RADS scoring without additional annotations andnetwork parameters. We present a two-stage fine-tuning process aimed atadapting MLLMs originally trained on natural images to the MRI data domainwhile effectively integrating the PICG. In the first stage, we develop a domainadapter layer specifically tailored for processing 3D MRI image inputs anddesign the MLLM instructions to differentiate MRI modalities effectively. Inthe second stage, we translate PICG into guiding instructions for the model togenerate PICG-guided image features. Through feature distillation, we alignscoring network features with the PICG-guided image feature, enabling thescoring network to effectively incorporate the PICG information. We develop ourmodel on a public dataset and evaluate it in a real-world challenging in-housedataset. Experimental results demonstrate that our approach improves theperformance of current scoring networks.</description><author>Tiantian Zhang, Manxi Lin, Hongda Guo, Xiaofan Zhang, Ka Fung Peter Chiu, Aasa Feragen, Qi Dou</author><pubDate>Tue, 14 May 2024 18:35:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08786v1</guid></item><item><title>Siamese Learning with Joint Alignment and Regression for Weakly-Supervised Video Paragraph Grounding</title><link>http://arxiv.org/abs/2403.11463v2</link><description>Video Paragraph Grounding (VPG) is an emerging task in video-languageunderstanding, which aims at localizing multiple sentences with semanticrelations and temporal order from an untrimmed video. However, existing VPGapproaches are heavily reliant on a considerable number of temporal labels thatare laborious and time-consuming to acquire. In this work, we introduce andexplore Weakly-Supervised Video Paragraph Grounding (WSVPG) to eliminate theneed of temporal annotations. Different from previous weakly-supervisedgrounding frameworks based on multiple instance learning or reconstructionlearning for two-stage candidate ranking, we propose a novel siamese learningframework that jointly learns the cross-modal feature alignment and temporalcoordinate regression without timestamp labels to achieve concise one-stagelocalization for WSVPG. Specifically, we devise a Siamese Grounding TRansformer(SiamGTR) consisting of two weight-sharing branches for learning complementarysupervision. An Augmentation Branch is utilized for directly regressing thetemporal boundaries of a complete paragraph within a pseudo video, and anInference Branch is designed to capture the order-guided feature correspondencefor localizing multiple sentences in a normal video. We demonstrate byextensive experiments that our paradigm has superior practicability andflexibility to achieve efficient weakly-supervised or semi-supervised learning,outperforming state-of-the-art methods trained with the same or strongersupervision.</description><author>Chaolei Tan, Jianhuang Lai, Wei-Shi Zheng, Jian-Fang Hu</author><pubDate>Tue, 14 May 2024 18:34:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11463v2</guid></item><item><title>Measurement-driven neural-network training for integrated magnetic tunnel junction arrays</title><link>http://arxiv.org/abs/2312.06446v2</link><description>The increasing scale of neural networks needed to support more complexapplications has led to an increasing requirement for area- andenergy-efficient hardware. One route to meeting the budget for theseapplications is to circumvent the von Neumann bottleneck by performingcomputation in or near memory. An inevitability of transferring neural networksonto hardware is that non-idealities such as device-to-device variations orpoor device yield impact performance. Methods such as hardware-aware training,where substrate non-idealities are incorporated during network training, areone way to recover performance at the cost of solution generality. In thiswork, we demonstrate inference on hardware neural networks consisting of 20,000magnetic tunnel junction arrays integrated on a complementarymetal-oxide-semiconductor chips that closely resembles market-ready spintransfer-torque magnetoresistive random access memory technology. Using 36dies, each containing a crossbar array with its own non-idealities, we showthat even a small number of defects in physically mapped networks significantlydegrades the performance of networks trained without defects and show that, atthe cost of generality, hardware-aware training accounting for specific defectson each die can recover to comparable performance with ideal networks. We thendemonstrate a robust training method that extends hardware-aware training tostatistics-aware training, producing network weights that perform well on mostdefective dies regardless of their specific defect locations. When evaluated onthe 36 physical dies, statistics-aware trained solutions can achieve a meanmisclassification error on the MNIST dataset that differs from thesoftware-baseline by only 2 %. This statistics-aware training method could begeneralized to networks with many layers that are mapped to hardware suited forindustry-ready applications.</description><author>William A. Borders, Advait Madhavan, Matthew W. Daniels, Vasileia Georgiou, Martin Lueker-Boden, Tiffany S. Santos, Patrick M. Braganca, Mark D. Stiles, Jabez J. McClelland, Brian D. Hoskins</author><pubDate>Tue, 14 May 2024 18:30:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06446v2</guid></item><item><title>Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram</title><link>http://arxiv.org/abs/2405.08784v1</link><description>We used a dictionary built from biomedical terminology extracted from varioussources such as DrugBank, MedDRA, MedlinePlus, TCMGeneDIT, to tag more than 8million Instagram posts by users who have mentioned an epilepsy-relevant drugat least once, between 2010 and early 2016. A random sample of 1,771 posts with2,947 term matches was evaluated by human annotators to identifyfalse-positives. OpenAI's GPT series models were compared against humanannotation. Frequent terms with a high false-positive rate were removed fromthe dictionary. Analysis of the estimated false-positive rates of the annotatedterms revealed 8 ambiguous terms (plus synonyms) used in Instagram posts, whichwere removed from the original dictionary. To study the effect of removingthose terms, we constructed knowledge networks using the refined and theoriginal dictionaries and performed an eigenvector-centrality analysis on bothnetworks. We show that the refined dictionary thus produced leads to asignificantly different rank of important terms, as measured by theireigenvector-centrality of the knowledge networks. Furthermore, the mostimportant terms obtained after refinement are of greater medical relevance. Inaddition, we show that OpenAI's GPT series models fare worse than humanannotators in this task.</description><author>Aehong Min, Xuan Wang, Rion Brattig Correia, Jordan Rozum, Wendy R. Miller, Luis M. Rocha</author><pubDate>Tue, 14 May 2024 18:27:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08784v1</guid></item><item><title>I2V-Adapter: A General Image-to-Video Adapter for Diffusion Models</title><link>http://arxiv.org/abs/2312.16693v3</link><description>Text-guided image-to-video (I2V) generation aims to generate a coherent videothat preserves the identity of the input image and semantically aligns with theinput prompt. Existing methods typically augment pretrained text-to-video (T2V)models by either concatenating the image with noised video frames channel-wisebefore being fed into the model or injecting the image embedding produced bypretrained image encoders in cross-attention modules. However, the formerapproach often necessitates altering the fundamental weights of pretrained T2Vmodels, thus restricting the model's compatibility within the open-sourcecommunities and disrupting the model's prior knowledge. Meanwhile, the lattertypically fails to preserve the identity of the input image. We presentI2V-Adapter to overcome such limitations. I2V-Adapter adeptly propagates theunnoised input image to subsequent noised frames through a cross-frameattention mechanism, maintaining the identity of the input image without anychanges to the pretrained T2V model. Notably, I2V-Adapter only introduces a fewtrainable parameters, significantly alleviating the training cost and alsoensures compatibility with existing community-driven personalized models andcontrol tools. Moreover, we propose a novel Frame Similarity Prior to balancethe motion amplitude and the stability of generated videos through twoadjustable control coefficients. Our experimental results demonstrate thatI2V-Adapter is capable of producing high-quality videos. This performance,coupled with its agility and adaptability, represents a substantial advancementin the field of I2V, particularly for personalized and controllableapplications.</description><author>Xun Guo, Mingwu Zheng, Liang Hou, Yuan Gao, Yufan Deng, Pengfei Wan, Di Zhang, Yufan Liu, Weiming Hu, Zhengjun Zha, Haibin Huang, Chongyang Ma</author><pubDate>Tue, 14 May 2024 18:27:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16693v3</guid></item><item><title>PiShield: A PyTorch Package for Learning with Requirements</title><link>http://arxiv.org/abs/2402.18285v2</link><description>Deep learning models have shown their strengths in various applicationdomains, however, they often struggle to meet safety requirements for theiroutputs. In this paper, we introduce PiShield, the first package ever allowingfor the integration of the requirements into the neural networks' topology.PiShield guarantees compliance with these requirements, regardless of input.Additionally, it allows for integrating requirements both at inference and/ortraining time, depending on the practitioners' needs. Given the widespreadapplication of deep learning, there is a growing need for frameworks allowingfor the integration of the requirements across various domains. Here, weexplore three application scenarios: functional genomics, autonomous driving,and tabular data generation.</description><author>Mihaela Cătălina Stoian, Alex Tatomir, Thomas Lukasiewicz, Eleonora Giunchiglia</author><pubDate>Tue, 14 May 2024 18:23:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18285v2</guid></item><item><title>Contributions of El Niño Southern Oscillation (ENSO) Diversity to Low-Frequency Changes in ENSO Variance</title><link>http://arxiv.org/abs/2307.11552v2</link><description>El Ni\~no Southern Oscillation (ENSO) diversity is characterized based on thelongitudinal location of maximum sea surface temperature anomalies (SSTA) andamplitude in the tropical Pacific, as Central Pacific (CP) events are typicallyweaker than Eastern Pacific (EP) events. SSTA pattern and intensity undergolow-frequency modulations, affecting ENSO prediction skill and remote impacts.Yet, how different ENSO types contribute to these decadal variations andlong-term variance trends remain uncertain. Here, we decompose thelow-frequency changes of ENSO variance into contributions from ENSO diversitycategories. We propose a fuzzy clustering of monthly SSTA to allow fornon-binary event category memberships. Our approach identifies two La Ni\~naand three El Ni\~no categories and shows that the shift of ENSO variance in themid-1970s is associated with an increasing likelihood of strong La Ni\~na andextreme El Ni\~no events.</description><author>Jakob Schlör, Felix Strnad, Antonietta Capotondi, Bedartha Goswami</author><pubDate>Tue, 14 May 2024 18:23:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11552v2</guid></item><item><title>Using Contextual Information for Sentence-level Morpheme Segmentation</title><link>http://arxiv.org/abs/2403.15436v2</link><description>Recent advancements in morpheme segmentation primarily emphasize word-levelsegmentation, often neglecting the contextual relevance within the sentence. Inthis study, we redefine the morpheme segmentation task as asequence-to-sequence problem, treating the entire sentence as input rather thanisolating individual words. Our findings reveal that the multilingual modelconsistently exhibits superior performance compared to monolingualcounterparts. While our model did not surpass the performance of the currentstate-of-the-art, it demonstrated comparable efficacy with high-resourcelanguages while revealing limitations in low-resource language scenarios.</description><author>Prabin Bhandari, Abhishek Paudel</author><pubDate>Tue, 14 May 2024 18:22:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15436v2</guid></item><item><title>Primacy Effect of ChatGPT</title><link>http://arxiv.org/abs/2310.13206v2</link><description>Instruction-tuned large language models (LLMs), such as ChatGPT, have led topromising zero-shot performance in discriminative natural languageunderstanding (NLU) tasks. This involves querying the LLM using a promptcontaining the question, and the candidate labels to choose from. Thequestion-answering capabilities of ChatGPT arise from its pre-training on largeamounts of human-written text, as well as its subsequent fine-tuning on humanpreferences, which motivates us to ask: Does ChatGPT also inherits humans'cognitive biases? In this paper, we study the primacy effect of ChatGPT: thetendency of selecting the labels at earlier positions as the answer. We havetwo main findings: i) ChatGPT's decision is sensitive to the order of labels inthe prompt; ii) ChatGPT has a clearly higher chance to select the labels atearlier positions as the answer. We hope that our experiments and analysesprovide additional insights into building more reliable ChatGPT-basedsolutions. We release the source code athttps://github.com/wangywUST/PrimacyEffectGPT.</description><author>Yiwei Wang, Yujun Cai, Muhao Chen, Yuxuan Liang, Bryan Hooi</author><pubDate>Tue, 14 May 2024 18:17:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13206v2</guid></item><item><title>Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling</title><link>http://arxiv.org/abs/2405.08780v1</link><description>Deep learning has enabled breakthroughs in automated diagnosis from medicalimaging, with many successful applications in ophthalmology. However, standardmedical image classification approaches only assess disease presence at thetime of acquisition, neglecting the common clinical setting of longitudinalimaging. For slow, progressive eye diseases like age-related maculardegeneration (AMD) and primary open-angle glaucoma (POAG), patients undergorepeated imaging over time to track disease progression and forecasting thefuture risk of developing disease is critical to properly plan treatment. Ourproposed Longitudinal Transformer for Survival Analysis (LTSA) enables dynamicdisease prognosis from longitudinal medical imaging, modeling the time todisease from sequences of fundus photography images captured over long,irregular time periods. Using longitudinal imaging data from the Age-RelatedEye Disease Study (AREDS) and Ocular Hypertension Treatment Study (OHTS), LTSAsignificantly outperformed a single-image baseline in 19/20 head-to-headcomparisons on late AMD prognosis and 18/20 comparisons on POAG prognosis. Atemporal attention analysis also suggested that, while the most recent image istypically the most influential, prior imaging still provides additionalprognostic value.</description><author>Gregory Holste, Mingquan Lin, Ruiwen Zhou, Fei Wang, Lei Liu, Qi Yan, Sarah H. Van Tassel, Kyle Kovacs, Emily Y. Chew, Zhiyong Lu, Zhangyang Wang, Yifan Peng</author><pubDate>Tue, 14 May 2024 18:15:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08780v1</guid></item><item><title>Jacobian Regularizer-based Neural Granger Causality</title><link>http://arxiv.org/abs/2405.08779v1</link><description>With the advancement of neural networks, diverse methods for neural Grangercausality have emerged, which demonstrate proficiency in handling complex data,and nonlinear relationships. However, the existing framework of neural Grangercausality has several limitations. It requires the construction of separatepredictive models for each target variable, and the relationship depends on thesparsity on the weights of the first layer, resulting in challenges ineffectively modeling complex relationships between variables as well asunsatisfied estimation accuracy of Granger causality. Moreover, most of themcannot grasp full-time Granger causality. To address these drawbacks, wepropose a Jacobian Regularizer-based Neural Granger Causality (JRNGC) approach,a straightforward yet highly effective method for learning multivariate summaryGranger causality and full-time Granger causality by constructing a singlemodel for all target variables. Specifically, our method eliminates thesparsity constraints of weights by leveraging an input-output Jacobian matrixregularizer, which can be subsequently represented as the weighted causalmatrix in the post-hoc analysis. Extensive experiments show that our proposedapproach achieves competitive performance with the state-of-the-art methods forlearning summary Granger causality and full-time Granger causality whilemaintaining lower model complexity and high scalability.</description><author>Wanqi Zhou, Shuanghao Bai, Shujian Yu, Qibin Zhao, Badong Chen</author><pubDate>Tue, 14 May 2024 18:13:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08779v1</guid></item><item><title>Graph Distillation with Eigenbasis Matching</title><link>http://arxiv.org/abs/2310.09202v2</link><description>The increasing amount of graph data places requirements on the efficienttraining of graph neural networks (GNNs). The emerging graph distillation (GD)tackles this challenge by distilling a small synthetic graph to replace thereal large graph, ensuring GNNs trained on real and synthetic graphs exhibitcomparable performance. However, existing methods rely on GNN-relatedinformation as supervision, including gradients, representations, andtrajectories, which have two limitations. First, GNNs can affect the spectrum(i.e., eigenvalues) of the real graph, causing spectrum bias in the syntheticgraph. Second, the variety of GNN architectures leads to the creation ofdifferent synthetic graphs, requiring traversal to obtain optimal performance.To tackle these issues, we propose Graph Distillation with Eigenbasis Matching(GDEM), which aligns the eigenbasis and node features of real and syntheticgraphs. Meanwhile, it directly replicates the spectrum of the real graph andthus prevents the influence of GNNs. Moreover, we design a discriminationconstraint to balance the effectiveness and generalization of GDEM.Theoretically, the synthetic graphs distilled by GDEM are restricted spectralapproximations of the real graphs. Extensive experiments demonstrate that GDEMoutperforms state-of-the-art GD methods with powerful cross-architecturegeneralization ability and significant distillation efficiency. Our code isavailable at https://github.com/liuyang-tian/GDEM.</description><author>Yang Liu, Deyu Bo, Chuan Shi</author><pubDate>Tue, 14 May 2024 18:12:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09202v2</guid></item><item><title>FolkTalent: Enhancing Classification and Tagging of Indian Folk Paintings</title><link>http://arxiv.org/abs/2405.08776v1</link><description>Indian folk paintings have a rich mosaic of symbols, colors, textures, andstories making them an invaluable repository of cultural legacy. The paperpresents a novel approach to classifying these paintings into distinct artforms and tagging them with their unique salient features. A custom datasetnamed FolkTalent, comprising 2279 digital images of paintings across 12different forms, has been prepared using websites that are direct outlets ofIndian folk paintings. Tags covering a wide range of attributes like color,theme, artistic style, and patterns are generated using GPT4, and verified byan expert for each painting. Classification is performed employing theRandomForest ensemble technique on fine-tuned Convolutional Neural Network(CNN) models to classify Indian folk paintings, achieving an accuracy of91.83%. Tagging is accomplished via the prominent fine-tuned CNN-basedbackbones with a custom classifier attached to its top to perform multi-labelimage classification. The generated tags offer a deeper insight into thepainting, enabling an enhanced search experience based on theme and visualattributes. The proposed hybrid model sets a new benchmark in folk paintingclassification and tagging, significantly contributing to cataloging India'sfolk-art heritage.</description><author>Nancy Hada, Aditya Singh, Kavita Vemuri</author><pubDate>Tue, 14 May 2024 18:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08776v1</guid></item><item><title>EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training</title><link>http://arxiv.org/abs/2405.08768v1</link><description>The superior performance of modern visual backbones usually comes with acostly training procedure. We contribute to this issue by generalizing the ideaof curriculum learning beyond its original formulation, i.e., training modelsusing easier-to-harder data. Specifically, we reformulate the trainingcurriculum as a soft-selection function, which uncovers progressively moredifficult patterns within each example during training, instead of performingeasier-to-harder sample selection. Our work is inspired by an intriguingobservation on the learning dynamics of visual backbones: during the earlierstages of training, the model predominantly learns to recognize some'easier-to-learn' discriminative patterns in the data. These patterns, whenobserved through frequency and spatial domains, incorporate lower-frequencycomponents, and the natural image contents without distortion or dataaugmentation. Motivated by these findings, we propose a curriculum where themodel always leverages all the training data at every learning stage, yet theexposure to the 'easier-to-learn' patterns of each example is initiated first,with harder patterns gradually introduced as training progresses. To implementthis idea in a computationally efficient way, we introduce a cropping operationin the Fourier spectrum of the inputs, enabling the model to learn from onlythe lower-frequency components. Then we show that exposing the contents ofnatural images can be readily achieved by modulating the intensity of dataaugmentation. Finally, we integrate these aspects and design curriculumschedules with tailored search algorithms. The resulting method,EfficientTrain++, is simple, general, yet surprisingly effective. It reducesthe training time of a wide variety of popular models by 1.5-3.0x onImageNet-1K/22K without sacrificing accuracy. It also demonstrates efficacy inself-supervised learning (e.g., MAE).</description><author>Yulin Wang, Yang Yue, Rui Lu, Yizeng Han, Shiji Song, Gao Huang</author><pubDate>Tue, 14 May 2024 18:00:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08768v1</guid></item><item><title>Energy-based Hopfield Boosting for Out-of-Distribution Detection</title><link>http://arxiv.org/abs/2405.08766v1</link><description>Out-of-distribution (OOD) detection is critical when deploying machinelearning models in the real world. Outlier exposure methods, which incorporateauxiliary outlier data in the training process, can drastically improve OODdetection performance compared to approaches without advanced trainingstrategies. We introduce Hopfield Boosting, a boosting approach, whichleverages modern Hopfield energy (MHE) to sharpen the decision boundary betweenthe in-distribution and OOD data. Hopfield Boosting encourages the model toconcentrate on hard-to-distinguish auxiliary outlier examples that lie close tothe decision boundary between in-distribution and auxiliary outlier data. Ourmethod achieves a new state-of-the-art in OOD detection with outlier exposure,improving the FPR95 metric from 2.28 to 0.92 on CIFAR-10 and from 11.76 to 7.94on CIFAR-100.</description><author>Claus Hofmann, Simon Schmid, Bernhard Lehner, Daniel Klotz, Sepp Hochreiter</author><pubDate>Tue, 14 May 2024 17:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08766v1</guid></item><item><title>Image to Pseudo-Episode: Boosting Few-Shot Segmentation by Unlabeled Data</title><link>http://arxiv.org/abs/2405.08765v1</link><description>Few-shot segmentation (FSS) aims to train a model which can segment theobject from novel classes with a few labeled samples. The insufficientgeneralization ability of models leads to unsatisfactory performance when themodels lack enough labeled data from the novel classes. Considering that thereare abundant unlabeled data available, it is promising to improve thegeneralization ability by exploiting these various data. For leveragingunlabeled data, we propose a novel method, named Image to Pseudo-Episode (IPE),to generate pseudo-episodes from unlabeled data. Specifically, our methodcontains two modules, i.e., the pseudo-label generation module and the episodegeneration module. The former module generates pseudo-labels from unlabeledimages by the spectral clustering algorithm, and the latter module generatespseudo-episodes from pseudo-labeled images by data augmentation methods.Extensive experiments on PASCAL-$5^i$ and COCO-$20^i$ demonstrate that ourmethod achieves the state-of-the-art performance for FSS.</description><author>Jie Zhang, Yuhan Li, Yude Wang, Stephen Lin, Shiguang Shan</author><pubDate>Tue, 14 May 2024 17:58:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08765v1</guid></item><item><title>Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs</title><link>http://arxiv.org/abs/2405.08760v1</link><description>Humans often express their communicative intents indirectly or non-literally,which requires their interlocutors -- human or AI -- to understand beyond theliteral meaning of words. While most existing work has focused ondiscriminative evaluations, we present a new approach to generatively evaluatelarge language models' (LLMs') intention understanding by examining theirresponses to non-literal utterances. Ideally, an LLM should respond in linewith the true intention of a non-literal utterance, not its literalinterpretation. Our findings show that LLMs struggle to generate pragmaticallyrelevant responses to non-literal language, achieving only 50-55% accuracy onaverage. While explicitly providing oracle intentions significantly improvesperformance (e.g., 75% for Mistral-Instruct), this still indicates challengesin leveraging given intentions to produce appropriate responses. Usingchain-of-thought to make models spell out intentions yields much smaller gains(60% for Mistral-Instruct). These findings suggest that LLMs are not yeteffective pragmatic interlocutors, highlighting the need for better approachesfor modeling intentions and utilizing them for pragmatic generation.</description><author>Akhila Yerukola, Saujas Vaduguru, Daniel Fried, Maarten Sap</author><pubDate>Tue, 14 May 2024 17:48:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08760v1</guid></item><item><title>On the role of surrogates in the efficient estimation of treatment effects with limited outcome data</title><link>http://arxiv.org/abs/2003.12408v3</link><description>In many experiments and observational studies, the outcome of interest isoften difficult or expensive to observe, reducing effective sample sizes forestimating average treatment effects (ATEs) even when identifiable. We studyhow incorporating data on units for which only surrogate outcomes not ofprimary interest are observed can increase the precision of ATE estimation. Werefrain from imposing stringent surrogacy conditions, which permit surrogatesas perfect replacements for the target outcome. Instead, we supplement theavailable, albeit limited, observations of the target outcome (which bythemselves identify the ATE) with abundant observations of surrogate outcomes,without any assumptions beyond random assignment and missingness andcorresponding overlap conditions. To quantify the potential gains, we derivethe difference in efficiency bounds on ATE estimation with and withoutsurrogates, both when an overwhelming or comparable number of units havemissing outcomes. We develop robust ATE estimation and inference methods thatrealize these efficiency gains. We empirically demonstrate the gains bystudying the long-term-earning effects of job training.</description><author>Nathan Kallus, Xiaojie Mao</author><pubDate>Tue, 14 May 2024 17:44:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2003.12408v3</guid></item><item><title>MedConceptsQA: Open Source Medical Concepts QA Benchmark</title><link>http://arxiv.org/abs/2405.07348v2</link><description>We present MedConceptsQA, a dedicated open source benchmark for medicalconcepts question answering. The benchmark comprises of questions of variousmedical concepts across different vocabularies: diagnoses, procedures, anddrugs. The questions are categorized into three levels of difficulty: easy,medium, and hard. We conducted evaluations of the benchmark using various LargeLanguage Models. Our findings show that pre-trained clinical Large LanguageModels achieved accuracy levels close to random guessing on this benchmark,despite being pre-trained on medical data. However, GPT-4 achieves an absoluteaverage improvement of nearly 27%-37% (27% for zero-shot learning and 37% forfew-shot learning) when compared to clinical Large Language Models. Ourbenchmark serves as a valuable resource for evaluating the understanding andreasoning of medical concepts by Large Language Models. Our benchmark isavailable at https://huggingface.co/datasets/ofir408/MedConceptsQA</description><author>Ofir Ben Shoham, Nadav Rappoport</author><pubDate>Tue, 14 May 2024 17:44:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07348v2</guid></item><item><title>ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies</title><link>http://arxiv.org/abs/2403.01139v4</link><description>Analogy-making is central to human cognition, allowing us to adapt to novelsituations -- an ability that current AI systems still lack. Most analogydatasets today focus on simple analogies (e.g., word analogies); datasetsincluding complex types of analogies are typically manually curated and verysmall. We believe that this holds back progress in computational analogy. Inthis work, we design a data generation pipeline, ParallelPARC (ParallelParagraph Creator) leveraging state-of-the-art Large Language Models (LLMs) tocreate complex, paragraph-based analogies, as well as distractors, both simpleand challenging. We demonstrate our pipeline and create ProPara-Logy, a datasetof analogies between scientific processes. We publish a gold-set, validated byhumans, and a silver-set, generated automatically. We test LLMs' and humans'analogy recognition in binary and multiple-choice settings, and found thathumans outperform the best models (~13% gap) after a light supervision. Wedemonstrate that our silver-set is useful for training models. Lastly, we showchallenging distractors confuse LLMs, but not humans. We hope our pipeline willencourage research in this emerging field.</description><author>Oren Sultan, Yonatan Bitton, Ron Yosef, Dafna Shahaf</author><pubDate>Tue, 14 May 2024 17:41:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01139v4</guid></item><item><title>Stable Inverse Reinforcement Learning: Policies from Control Lyapunov Landscapes</title><link>http://arxiv.org/abs/2405.08756v1</link><description>Learning from expert demonstrations to flexibly program an autonomous systemwith complex behaviors or to predict an agent's behavior is a powerful tool,especially in collaborative control settings. A common method to solve thisproblem is inverse reinforcement learning (IRL), where the observed agent,e.g., a human demonstrator, is assumed to behave according to the optimizationof an intrinsic cost function that reflects its intent and informs its controlactions. While the framework is expressive, it is also computationallydemanding and generally lacks convergence guarantees. We therefore propose anovel, stability-certified IRL approach by reformulating the cost functioninference problem to learning control Lyapunov functions (CLF) fromdemonstrations data. By additionally exploiting closed-form expressions forassociated control policies, we are able to efficiently search the space ofCLFs by observing the attractor landscape of the induced dynamics. For theconstruction of the inverse optimal CLFs, we use a Sum of Squares and formulatea convex optimization problem. We present a theoretical analysis of theoptimality properties provided by the CLF and evaluate our approach using bothsimulated and real-world data.</description><author>Samuel Tesfazgi, Leonhard Sprandl, Armin Lederer, Sandra Hirche</author><pubDate>Tue, 14 May 2024 17:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08756v1</guid></item><item><title>Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach</title><link>http://arxiv.org/abs/2405.08755v1</link><description>With the proliferation of edge devices, there is a significant increase inattack surface on these devices. The decentralized deployment of threatintelligence on edge devices, coupled with adaptive machine learning techniquessuch as the in-context learning feature of large language models (LLMs),represents a promising paradigm for enhancing cybersecurity on low-powered edgedevices. This approach involves the deployment of lightweight machine learningmodels directly onto edge devices to analyze local data streams, such asnetwork traffic and system logs, in real-time. Additionally, distributingcomputational tasks to an edge server reduces latency and improvesresponsiveness while also enhancing privacy by processing sensitive datalocally. LLM servers can enable these edge servers to autonomously adapt toevolving threats and attack patterns, continuously updating their models toimprove detection accuracy and reduce false positives. Furthermore,collaborative learning mechanisms facilitate peer-to-peer secure andtrustworthy knowledge sharing among edge devices, enhancing the collectiveintelligence of the network and enabling dynamic threat mitigation measuressuch as device quarantine in response to detected anomalies. The scalabilityand flexibility of this approach make it well-suited for diverse and evolvingnetwork environments, as edge devices only send suspicious information such asnetwork traffic and system log changes, offering a resilient and efficientsolution to combat emerging cyber threats at the network edge. Thus, ourproposed framework can improve edge computing security by providing bettersecurity in cyber threat detection and mitigation by isolating the edge devicesfrom the network.</description><author>Syed Mhamudul Hasan, Alaa M. Alotaibi, Sajedul Talukder, Abdur R. Shahid</author><pubDate>Tue, 14 May 2024 17:40:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08755v1</guid></item><item><title>Hierarchical Resource Partitioning on Modern GPUs: A Reinforcement Learning Approach</title><link>http://arxiv.org/abs/2405.08754v1</link><description>GPU-based heterogeneous architectures are now commonly used in HPC clusters.Due to their architectural simplicity specialized for data-level parallelism,GPUs can offer much higher computational throughput and memory bandwidth thanCPUs in the same generation do. However, as the available resources in GPUshave increased exponentially over the past decades, it has become increasinglydifficult for a single program to fully utilize them. As a consequence, theindustry has started supporting several resource partitioning features in orderto improve the resource utilization by co-scheduling multiple programs on thesame GPU die at the same time. Driven by the technological trend, this paperfocuses on hierarchical resource partitioning on modern GPUs, and as anexample, we utilize a combination of two different features available on recentNVIDIA GPUs in a hierarchical manner: MPS (Multi-Process Service), afiner-grained logical partitioning; and MIG (Multi-Instance GPU), acoarse-grained physical partitioning. We propose a method for comprehensivelyco-optimizing the setup of hierarchical partitioning and the selection ofco-scheduling groups from a given set of jobs, based on reinforcement learningusing their profiles. Our thorough experimental results demonstrate that ourapproach can successfully set up job concurrency, partitioning, andco-scheduling group selections simultaneously. This results in a maximumthroughput improvement by a factor of 1.87 compared to the time-sharingscheduling.</description><author>Urvij Saroliya, Eishi Arima, Dai Liu, Martin Schulz</author><pubDate>Tue, 14 May 2024 17:40:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08754v1</guid></item><item><title>From Text to Context: An Entailment Approach for News Stakeholder Classification</title><link>http://arxiv.org/abs/2405.08751v1</link><description>Navigating the complex landscape of news articles involves understanding thevarious actors or entities involved, referred to as news stakeholders. Thesestakeholders, ranging from policymakers to opposition figures, citizens, andmore, play pivotal roles in shaping news narratives. Recognizing theirstakeholder types, reflecting their roles, political alignments, socialstanding, and more, is paramount for a nuanced comprehension of news content.Despite existing works focusing on salient entity extraction, coveragevariations, and political affiliations through social media data, the automateddetection of stakeholder roles within news content remains an underexploreddomain. In this paper, we bridge this gap by introducing an effective approachto classify stakeholder types in news articles. Our method involvestransforming the stakeholder classification problem into a natural languageinference task, utilizing contextual information from news articles andexternal knowledge to enhance the accuracy of stakeholder type detection.Moreover, our proposed model showcases efficacy in zero-shot settings, furtherextending its applicability to diverse news contexts.</description><author>Alapan Kuila, Sudeshna Sarkar</author><pubDate>Tue, 14 May 2024 17:35:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08751v1</guid></item><item><title>Checking Trustworthiness of Probabilistic Computations in a Typed Natural Deduction System</title><link>http://arxiv.org/abs/2206.12934v3</link><description>In this paper we present the probabilistic typed natural deduction calculusTPTND, designed to reason about and derive trustworthiness properties ofprobabilistic computational processes, like those underlying current AIapplications. Derivability in TPTND is interpreted as the process of extracting$n$ samples of possibly complex outputs with a certain frequency from a givencategorical distribution. We formalize trust for such outputs as a form ofhypothesis testing on the distance between such frequency and the intendedprobability. The main advantage of the calculus is to render such notion oftrustworthiness checkable. We present a computational semantics for the termsover which we reason and then the semantics of TPTND, where logical operatorsas well as a Trust operator are defined through introduction and eliminationrules. We illustrate structural and metatheoretical properties, with particularfocus on the ability to establish under which term evolutions and logical rulesapplications the notion of trustworhtiness can be preserved.</description><author>Fabio Aurelio D'Asaro, Francesco Genco, Giuseppe Primiero</author><pubDate>Tue, 14 May 2024 17:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.12934v3</guid></item><item><title>Uncertainty Quantification in Multivariable Regression for Material Property Prediction with Bayesian Neural Networks</title><link>http://arxiv.org/abs/2311.02495v4</link><description>With the increased use of data-driven approaches and machine learning-basedmethods in material science, the importance of reliable uncertaintyquantification (UQ) of the predicted variables for informed decision-makingcannot be overstated. UQ in material property prediction poses uniquechallenges, including the multi-scale and multi-physics nature of advancedmaterials, intricate interactions between numerous factors, limitedavailability of large curated datasets for model training, etc. Recently,Bayesian Neural Networks (BNNs) have emerged as a promising approach for UQ,offering a probabilistic framework for capturing uncertainties within neuralnetworks. In this work, we introduce an approach for UQ within physics-informedBNNs, which integrates knowledge from governing laws in material modeling toguide the models toward physically consistent predictions. To evaluate theeffectiveness of this approach, we present case studies for predicting thecreep rupture life of steel alloys. Experimental validation with three datasetsof collected measurements from creep tests demonstrates the ability of BNNs toproduce accurate point and uncertainty estimates that are competitive or exceedthe performance of the conventional method of Gaussian Process Regression.Similarly, we evaluated the suitability of BNNs for UQ in an active learningapplication and reported competitive performance. The most promising frameworkfor creep life prediction is BNNs based on Markov Chain Monte Carloapproximation of the posterior distribution of network parameters, as itprovided more reliable results in comparison to BNNs based on variationalinference approximation or related NNs with probabilistic outputs. The codesare available at:https://github.com/avakanski/Creep-uncertainty-quantification.</description><author>Longze Li, Jiang Chang, Aleksandar Vakanski, Yachun Wang, Tiankai Yao, Min Xian</author><pubDate>Tue, 14 May 2024 17:34:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02495v4</guid></item><item><title>Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding</title><link>http://arxiv.org/abs/2405.08748v1</link><description>We present Hunyuan-DiT, a text-to-image diffusion transformer withfine-grained understanding of both English and Chinese. To constructHunyuan-DiT, we carefully design the transformer structure, text encoder, andpositional encoding. We also build from scratch a whole data pipeline to updateand evaluate data for iterative model optimization. For fine-grained languageunderstanding, we train a Multimodal Large Language Model to refine thecaptions of the images. Finally, Hunyuan-DiT can perform multi-turn multimodaldialogue with users, generating and refining images according to the context.Through our holistic human evaluation protocol with more than 50 professionalhuman evaluators, Hunyuan-DiT sets a new state-of-the-art in Chinese-to-imagegeneration compared with other open-source models. Code and pretrained modelsare publicly available at github.com/Tencent/HunyuanDiT</description><author>Zhimin Li, Jianwei Zhang, Qin Lin, Jiangfeng Xiong, Yanxin Long, Xinchi Deng, Yingfang Zhang, Xingchao Liu, Minbin Huang, Zedong Xiao, Dayou Chen, Jiajun He, Jiahao Li, Wenyue Li, Chen Zhang, Rongwei Quan, Jianxiang Lu, Jiabin Huang, Xiaoyan Yuan, Xiaoxiao Zheng, Yixuan Li, Jihong Zhang, Chao Zhang, Meng Chen, Jie Liu, Zheng Fang, Weiyan Wang, Jinbao Xue, Yangyu Tao, Jianchen Zhu, Kai Liu, Sihuan Lin, Yifu Sun, Yun Li, Dongdong Wang, Mingtao Chen, Zhichao Hu, Xiao Xiao, Yan Chen, Yuhong Liu, Wei Liu, Di Wang, Yong Yang, Jie Jiang, Qinglin Lu</author><pubDate>Tue, 14 May 2024 17:33:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08748v1</guid></item><item><title>Enhancing Blind Video Quality Assessment with Rich Quality-aware Features</title><link>http://arxiv.org/abs/2405.08745v1</link><description>In this paper, we present a simple but effective method to enhance blindvideo quality assessment (BVQA) models for social media videos. Motivated byprevious researches that leverage pre-trained features extracted from variouscomputer vision models as the feature representation for BVQA, we furtherexplore rich quality-aware features from pre-trained blind image qualityassessment (BIQA) and BVQA models as auxiliary features to help the BVQA modelto handle complex distortions and diverse content of social media videos.Specifically, we use SimpleVQA, a BVQA model that consists of a trainable SwinTransformer-B and a fixed SlowFast, as our base model. The Swin Transformer-Band SlowFast components are responsible for extracting spatial and motionfeatures, respectively. Then, we extract three kinds of features from Q-Align,LIQE, and FAST-VQA to capture frame-level quality-aware features, frame-levelquality-aware along with scene-specific features, and spatiotemporalquality-aware features, respectively. Through concatenating these features, weemploy a multi-layer perceptron (MLP) network to regress them into qualityscores. Experimental results demonstrate that the proposed model achieves thebest performance on three public social media VQA datasets. Moreover, theproposed model won first place in the CVPR NTIRE 2024 Short-form UGC VideoQuality Assessment Challenge. The code is available at\url{https://github.com/sunwei925/RQ-VQA.git}.</description><author>Wei Sun, Haoning Wu, Zicheng Zhang, Jun Jia, Zhichao Zhang, Linhan Cao, Qiubo Chen, Xiongkuo Min, Weisi Lin, Guangtao Zhai</author><pubDate>Tue, 14 May 2024 17:32:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08745v1</guid></item><item><title>A structured regression approach for evaluating model performance across intersectional subgroups</title><link>http://arxiv.org/abs/2401.14893v2</link><description>Disaggregated evaluation is a central task in AI fairness assessment, wherethe goal is to measure an AI system's performance across different subgroupsdefined by combinations of demographic or other sensitive attributes. Thestandard approach is to stratify the evaluation data across subgroups andcompute performance metrics separately for each group. However, even formoderately-sized evaluation datasets, sample sizes quickly get small onceconsidering intersectional subgroups, which greatly limits the extent to whichintersectional groups are included in analysis. In this work, we introduce astructured regression approach to disaggregated evaluation that we demonstratecan yield reliable system performance estimates even for very small subgroups.We provide corresponding inference strategies for constructing confidenceintervals and explore how goodness-of-fit testing can yield insight into thestructure of fairness-related harms experienced by intersectional groups. Weevaluate our approach on two publicly available datasets, and several variantsof semi-synthetic data. The results show that our method is considerably moreaccurate than the standard approach, especially for small subgroups, anddemonstrate how goodness-of-fit testing helps identify the key factors thatdrive differences in performance.</description><author>Christine Herlihy, Kimberly Truong, Alexandra Chouldechova, Miroslav Dudik</author><pubDate>Tue, 14 May 2024 17:32:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14893v2</guid></item><item><title>Reinformer: Max-Return Sequence Modeling for offline RL</title><link>http://arxiv.org/abs/2405.08740v1</link><description>As a data-driven paradigm, offline reinforcement learning (RL) has beenformulated as sequence modeling that conditions on the hindsight informationincluding returns, goal or future trajectory. Although promising, thissupervised paradigm overlooks the core objective of RL that maximizes thereturn. This overlook directly leads to the lack of trajectory stitchingcapability that affects the sequence model learning from sub-optimal data. Inthis work, we introduce the concept of max-return sequence modeling whichintegrates the goal of maximizing returns into existing sequence models. Wepropose Reinforced Transformer (Reinformer), indicating the sequence model isreinforced by the RL objective. Reinformer additionally incorporates theobjective of maximizing returns in the training phase, aiming to predict themaximum future return within the distribution. During inference, thisin-distribution maximum return will guide the selection of optimal actions.Empirically, Reinformer is competitive with classical RL methods on the D4RLbenchmark and outperforms state-of-the-art sequence model particularly intrajectory stitching ability. Code is public at\url{https://github.com/Dragon-Zhuang/Reinformer}.</description><author>Zifeng Zhuang, Dengyun Peng, jinxin Liu, Ziqi Zhang, Donglin Wang</author><pubDate>Tue, 14 May 2024 17:30:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08740v1</guid></item><item><title>A Simple Approach to Differentiable Rendering of SDFs</title><link>http://arxiv.org/abs/2405.08733v1</link><description>We present a simple algorithm for differentiable rendering of surfacesrepresented by Signed Distance Fields (SDF), which makes it easy to integraterendering into gradient-based optimization pipelines. To tacklevisibility-related derivatives that make rendering non-differentiable, existingphysically based differentiable rendering methods often rely on elaborateguiding data structures or reparameterization with a global impact on variance.In this article, we investigate an alternative that embraces nonzero bias inexchange for low variance and architectural simplicity. Our method expands thelower-dimensional boundary integral into a thin band that is easy to samplewhen the underlying surface is represented by an SDF. We demonstrate theperformance and robustness of our formulation in end-to-end inverse renderingtasks, where it obtains results that are competitive with or superior toexisting work.</description><author>Zichen Wang, Xi Deng, Ziyi Zhang, Wenzel Jakob, Steve Marschner</author><pubDate>Tue, 14 May 2024 17:19:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08733v1</guid></item><item><title>Targeted Augmentation for Low-Resource Event Extraction</title><link>http://arxiv.org/abs/2405.08729v1</link><description>Addressing the challenge of low-resource information extraction remains anongoing issue due to the inherent information scarcity within limited trainingexamples. Existing data augmentation methods, considered potential solutions,struggle to strike a balance between weak augmentation (e.g., synonymaugmentation) and drastic augmentation (e.g., conditional generation withoutproper guidance). This paper introduces a novel paradigm that employs targetedaugmentation and back validation to produce augmented examples with enhanceddiversity, polarity, accuracy, and coherence. Extensive experimental resultsdemonstrate the effectiveness of the proposed paradigm. Furthermore, identifiedlimitations are discussed, shedding light on areas for future improvement.</description><author>Sijia Wang, Lifu Huang</author><pubDate>Tue, 14 May 2024 17:15:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08729v1</guid></item><item><title>I-CTRL: Imitation to Control Humanoid Robots Through Constrained Reinforcement Learning</title><link>http://arxiv.org/abs/2405.08726v1</link><description>This paper addresses the critical need for refining robot motions that,despite achieving a high visual similarity through human-to-humanoidretargeting methods, fall short of practical execution in the physical realm.Existing techniques in the graphics community often prioritize visual fidelityover physics-based feasibility, posing a significant challenge for deployingbipedal systems in practical applications. Our research introduces aconstrained reinforcement learning algorithm to produce physics-basedhigh-quality motion imitation onto legged humanoid robots that enhance motionresemblance while successfully following the reference human trajectory. Wename our framework: I-CTRL. By reformulating the motion imitation problem as aconstrained refinement over non-physics-based retargeted motions, our frameworkexcels in motion imitation with simple and unique rewards that generalizeacross four robots. Moreover, our framework can follow large-scale motiondatasets with a unique RL agent. The proposed approach signifies a crucial stepforward in advancing the control of bipedal robots, emphasizing the importanceof aligning visual and physical realism for successful motion imitation.</description><author>Yashuai Yan, Esteve Valls Mascaro, Tobias Egle, Dongheui Lee</author><pubDate>Tue, 14 May 2024 17:12:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08726v1</guid></item><item><title>Addressing Misspecification in Simulation-based Inference through Data-driven Calibration</title><link>http://arxiv.org/abs/2405.08719v1</link><description>Driven by steady progress in generative modeling, simulation-based inference(SBI) has enabled inference over stochastic simulators. However, recent workhas demonstrated that model misspecification can harm SBI's reliability. Thiswork introduces robust posterior estimation (ROPE), a framework that overcomesmodel misspecification with a small real-world calibration set of ground truthparameter measurements. We formalize the misspecification gap as the solutionof an optimal transport problem between learned representations of real-worldand simulated observations. Assuming the prior distribution over the parametersof interest is known and well-specified, our method offers a controllablebalance between calibrated uncertainty and informative inference under allpossible misspecifications of the simulator. Our empirical results on foursynthetic tasks and two real-world problems demonstrate that ROPE outperformsbaselines and consistently returns informative and calibrated credibleintervals.</description><author>Antoine Wehenkel, Juan L. Gamella, Ozan Sener, Jens Behrmann, Guillermo Sapiro, Marco Cuturi, Jörn-Henrik Jacobsen</author><pubDate>Tue, 14 May 2024 17:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08719v1</guid></item><item><title>Exploring Explainable AI Techniques for Improved Interpretability in Lung and Colon Cancer Classification</title><link>http://arxiv.org/abs/2405.04610v2</link><description>Lung and colon cancer are serious worldwide health challenges that requireearly and precise identification to reduce mortality risks. However, diagnosis,which is mostly dependent on histopathologists' competence, presentsdifficulties and hazards when expertise is insufficient. While diagnosticmethods like imaging and blood markers contribute to early detection,histopathology remains the gold standard, although time-consuming andvulnerable to inter-observer mistakes. Limited access to high-end technologyfurther limits patients' ability to receive immediate medical care anddiagnosis. Recent advances in deep learning have generated interest in itsapplication to medical imaging analysis, specifically the use ofhistopathological images to diagnose lung and colon cancer. The goal of thisinvestigation is to use and adapt existing pre-trained CNN-based models, suchas Xception, DenseNet201, ResNet101, InceptionV3, DenseNet121, DenseNet169,ResNet152, and InceptionResNetV2, to enhance classification through betteraugmentation strategies. The results show tremendous progress, with all eightmodels reaching impressive accuracy ranging from 97% to 99%. Furthermore,attention visualization techniques such as GradCAM, GradCAM++, ScoreCAM, FasterScore-CAM, and LayerCAM, as well as Vanilla Saliency and SmoothGrad, are usedto provide insights into the models' classification decisions, therebyimproving interpretability and understanding of malignant and benign imageclassification.</description><author>Mukaffi Bin Moin, Fatema Tuj Johora Faria, Swarnajit Saha, Busra Kamal Rafa, Mohammad Shafiul Alam</author><pubDate>Tue, 14 May 2024 17:02:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04610v2</guid></item><item><title>PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition</title><link>http://arxiv.org/abs/2405.07932v2</link><description>Large language models (LLMs) have shown success in many natural languageprocessing tasks. Despite rigorous safety alignment processes, supposedlysafety-aligned LLMs like Llama 2 and Claude 2 are still susceptible tojailbreaks, leading to security risks and abuse of the models. One option tomitigate such risks is to augment the LLM with a dedicated "safeguard", whichchecks the LLM's inputs or outputs for undesired behaviour. A promisingapproach is to use the LLM itself as the safeguard. Nonetheless, baselinemethods, such as prompting the LLM to self-classify toxic content, demonstratelimited efficacy. We hypothesise that this is due to domain shift: thealignment training imparts a self-censoring behaviour to the model ("Sorry Ican't do that"), while the self-classify approach shifts it to a classificationformat ("Is this prompt malicious"). In this work, we propose PARDEN, whichavoids this domain shift by simply asking the model to repeat its own outputs.PARDEN neither requires finetuning nor white box access to the model. Weempirically verify the effectiveness of our method and show that PARDENsignificantly outperforms existing jailbreak detection baselines for Llama-2and Claude-2. Code and data are available at https://github.com/Ed-Zh/PARDEN. We find that PARDEN is particularly powerful in the relevant regime of highTrue Positive Rate (TPR) and low False Positive Rate (FPR). For instance, forLlama2-7B, at TPR equal to 90%, PARDEN accomplishes a roughly 11x reduction inthe FPR from 24.8% to 2.0% on the harmful behaviours dataset.</description><author>Ziyang Zhang, Qizhen Zhang, Jakob Foerster</author><pubDate>Tue, 14 May 2024 16:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07932v2</guid></item><item><title>Filtered Partial Differential Equations: a robust surrogate constraint in physics-informed deep learning framework</title><link>http://arxiv.org/abs/2311.03776v2</link><description>Embedding physical knowledge into neural network (NN) training has been a hottopic. However, when facing the complex real-world, most of the existingmethods still strongly rely on the quantity and quality of observation data.Furthermore, the neural networks often struggle to converge when the solutionto the real equation is very complex. Inspired by large eddy simulation incomputational fluid dynamics, we propose an improved method based on filtering.We analyzed the causes of the difficulties in physics informed machinelearning, and proposed a surrogate constraint (filtered PDE, FPDE in short) ofthe original physical equations to reduce the influence of noisy and sparseobservation data. In the noise and sparsity experiment, the proposed FPDEmodels (which are optimized by FPDE constraints) have better robustness thanthe conventional PDE models. Experiments demonstrate that the FPDE model canobtain the same quality solution with 100% higher noise and 12% quantity ofobservation data of the baseline. Besides, two groups of real measurement dataare used to show the FPDE improvements in real cases. The final results showthat FPDE still gives more physically reasonable solutions when facing theincomplete equation problem and the extremely sparse and high-noise conditions.For combining real-world experiment data into physics-informed training, theproposed FPDE constraint is useful and performs well in two real-worldexperiments: modeling the blood velocity in vessels and cell migration inscratches.</description><author>Dashan Zhang, Yuntian Chen, Shiyi Chen</author><pubDate>Tue, 14 May 2024 16:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03776v2</guid></item><item><title>Data-driven Force Observer for Human-Robot Interaction with Series Elastic Actuators using Gaussian Processes</title><link>http://arxiv.org/abs/2405.08711v1</link><description>Ensuring safety and adapting to the user's behavior are of paramountimportance in physical human-robot interaction. Thus, incorporating elasticactuators in the robot's mechanical design has become popular, since it offersintrinsic compliance and additionally provide a coarse estimate for theinteraction force by measuring the deformation of the elastic components. Whileobserver-based methods have been shown to improve these estimates, they rely onaccurate models of the system, which are challenging to obtain in complexoperating environments. In this work, we overcome this issue by learning theunknown dynamics components using Gaussian process (GP) regression. Byemploying the learned model in a Bayesian filtering framework, we improve theestimation accuracy and additionally obtain an observer that explicitlyconsiders local model uncertainty in the confidence measure of the stateestimate. Furthermore, we derive guaranteed estimation error bounds, thus,facilitating the use in safety-critical applications. We demonstrate theeffectiveness of the proposed approach experimentally in a human-exoskeletoninteraction scenario.</description><author>Samuel Tesfazgi, Markus Keßler, Emilio Trigili, Armin Lederer, Sandra Hirche</author><pubDate>Tue, 14 May 2024 16:51:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08711v1</guid></item><item><title>Beyond Scaling Laws: Understanding Transformer Performance with Associative Memory</title><link>http://arxiv.org/abs/2405.08707v1</link><description>Increasing the size of a Transformer model does not always lead to enhancedperformance. This phenomenon cannot be explained by the empirical scaling laws.Furthermore, improved generalization ability occurs as the model memorizes thetraining samples. We present a theoretical framework that sheds light on thememorization process and performance dynamics of transformer-based languagemodels. We model the behavior of Transformers with associative memories usingHopfield networks, such that each transformer block effectively conducts anapproximate nearest-neighbor search. Based on this, we design an energyfunction analogous to that in the modern continuous Hopfield network whichprovides an insightful explanation for the attention mechanism. Using themajorization-minimization technique, we construct a global energy function thatcaptures the layered architecture of the Transformer. Under specificconditions, we show that the minimum achievable cross-entropy loss is boundedfrom below by a constant approximately equal to 1. We substantiate ourtheoretical results by conducting experiments with GPT-2 on various data sizes,as well as training vanilla Transformers on a dataset of 2M tokens.</description><author>Xueyan Niu, Bo Bai, Lei Deng, Wei Han</author><pubDate>Tue, 14 May 2024 16:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08707v1</guid></item><item><title>ERATTA: Extreme RAG for Table To Answers with Large Language Models</title><link>http://arxiv.org/abs/2405.03963v2</link><description>Large language models (LLMs) with retrieval augmented-generation (RAG) havebeen the optimal choice for scalable generative AI solutions in the recentpast. However, the choice of use-cases that incorporate RAG with LLMs have beeneither generic or extremely domain specific, thereby questioning thescalability and generalizability of RAG-LLM approaches. In this work, wepropose a unique LLM-based system where multiple LLMs can be invoked to enabledata authentication, user query routing, data retrieval and custom promptingfor question answering capabilities from data tables that are highly varyingand large in size. Our system is tuned to extract information fromEnterprise-level data products and furnish real time responses under 10seconds. One prompt manages user-to-data authentication followed by threeprompts to route, fetch data and generate a customizable prompt naturallanguage responses. Additionally, we propose a five metric scoring module thatdetects and reports hallucinations in the LLM responses. Our proposed systemand scoring metrics achieve &gt;90% confidence scores across hundreds of userqueries in the sustainability, financial health and social media domains.Extensions to the proposed extreme RAG architectures can enable heterogeneoussource querying using LLMs.</description><author>Sohini Roychowdhury, Marko Krema, Anvar Mahammad, Brian Moore, Arijit Mukherjee, Punit Prakashchandra</author><pubDate>Tue, 14 May 2024 16:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03963v2</guid></item><item><title>Full Line Code Completion: Bringing AI to Desktop</title><link>http://arxiv.org/abs/2405.08704v1</link><description>In recent years, several industrial solutions for the problem of multi-tokencode completion have appeared, each making a great advance in the area butmostly focusing on cloud-based runtime and avoiding working on the end user'sdevice. In this work, we describe our approach for building a multi-token codecompletion feature for the JetBrains' IntelliJ Platform, which we call FullLine Code Completion. The feature suggests only syntactically correct code andworks fully locally, i.e., data querying and the generation of suggestionshappens on the end user's machine. We share important time andmemory-consumption restrictions, as well as design principles that a codecompletion engine should satisfy. Working entirely on the end user's device,our code completion engine enriches user experience while being not only fastand compact but also secure. We share a number of useful techniques to meet thestated development constraints and also describe offline and online evaluationpipelines that allowed us to make better decisions. Our online evaluation shows that the usage of the tool leads to 1.5 timesmore code in the IDE being produced by code completion. The described solutionwas initially started with the help of researchers and was bundled into twoJetBrains' IDEs - PyCharm Pro and DataSpell - at the end of 2023, so we believethat this work is useful for bridging academia and industry, providingresearchers with the knowledge of what happens when complex research-basedsolutions are integrated into real products.</description><author>Anton Semenkin, Vitaliy Bibaev, Yaroslav Sokolov, Kirill Krylov, Alexey Kalina, Anna Khannanova, Danila Savenkov, Darya Rovdo, Igor Davidenko, Kirill Karnaukhov, Maxim Vakhrushev, Mikhail Kostyukov, Mikhail Podvitskii, Petr Surkov, Yaroslav Golubev, Nikita Povarov, Timofey Bryksin</author><pubDate>Tue, 14 May 2024 16:42:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08704v1</guid></item><item><title>Using autoencoders and deep transfer learning to determine the stellar parameters of 286 CARMENES M dwarfs</title><link>http://arxiv.org/abs/2405.08703v1</link><description>Deep learning (DL) techniques are a promising approach among the set ofmethods used in the ever-challenging determination of stellar parameters in Mdwarfs. In this context, transfer learning could play an important role inmitigating uncertainties in the results due to the synthetic gap (i.e.difference in feature distributions between observed and synthetic data). Wepropose a feature-based deep transfer learning (DTL) approach based onautoencoders to determine stellar parameters from high-resolution spectra.Using this methodology, we provide new estimations for the effectivetemperature, surface gravity, metallicity, and projected rotational velocityfor 286 M dwarfs observed by the CARMENES survey. Using autoencoderarchitectures, we projected synthetic PHOENIX-ACES spectra and observedCARMENES spectra onto a new feature space of lower dimensionality in which thedifferences between the two domains are reduced. We used this low-dimensionalnew feature space as input for a convolutional neural network to obtain thestellar parameter determinations. We performed an extensive analysis of ourestimated stellar parameters, ranging from 3050 to 4300 K, 4.7 to 5.1 dex, and-0.53 to 0.25 dex for Teff, logg, and [Fe/H], respectively. Our results arebroadly consistent with those of recent studies using CARMENES data, with asystematic deviation in our Teff scale towards hotter values for estimationsabove 3750 K. Furthermore, our methodology mitigates the deviations inmetallicity found in previous DL techniques due to the synthetic gap. Weconsolidated a DTL-based methodology to determine stellar parameters in Mdwarfs from synthetic spectra, with no need for high-quality measurementsinvolved in the knowledge transfer. These results suggest the great potentialof DTL to mitigate the differences in feature distributions between theobservations and the PHOENIX-ACES spectra.</description><author>P. Mas-Buitrago, A. González-Marcos, E. Solano, V. M. Passegger, M. Cortés-Contreras, J. Ordieres-Meré, A. Bello-García, J. A. Caballero, A. Schweitzer, H. M. Tabernero, D. Montes, C. Cifuentes</author><pubDate>Tue, 14 May 2024 16:42:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08703v1</guid></item><item><title>Weakly-supervised causal discovery based on fuzzy knowledge and complex data complementarity</title><link>http://arxiv.org/abs/2405.08699v1</link><description>Causal discovery based on observational data is important for deciphering thecausal mechanism behind complex systems. However, the effectiveness of existingcausal discovery methods is limited due to inferior prior knowledge, domaininconsistencies, and the challenges of high-dimensional datasets with smallsample sizes. To address this gap, we propose a novel weakly-supervised fuzzyknowledge and data co-driven causal discovery method named KEEL. KEEL adopts afuzzy causal knowledge schema to encapsulate diverse types of fuzzy knowledge,and forms corresponding weakened constraints. This schema not only lessens thedependency on expertise but also allows various types of limited anderror-prone fuzzy knowledge to guide causal discovery. It can enhance thegeneralization and robustness of causal discovery, especially inhigh-dimensional and small-sample scenarios. In addition, we integrate theextended linear causal model (ELCM) into KEEL for dealing with themulti-distribution and incomplete data. Extensive experiments with differentdatasets demonstrate the superiority of KEEL over several state-of-the-artmethods in accuracy, robustness and computational efficiency. For causaldiscovery in real protein signal transduction processes, KEEL outperforms thebenchmark method with limited data. In summary, KEEL is effective to tackle thecausal discovery tasks with higher accuracy while alleviating the requirementfor extensive domain expertise.</description><author>Wenrui Li, Wei Zhang, Qinghao Zhang, Xuegong Zhang, Xiaowo Wang</author><pubDate>Tue, 14 May 2024 16:39:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08699v1</guid></item><item><title>Byzantine-Resilient Secure Aggregation for Federated Learning Without Privacy Compromises</title><link>http://arxiv.org/abs/2405.08698v1</link><description>Federated learning (FL) shows great promise in large scale machine learning,but brings new risks in terms of privacy and security. We propose ByITFL, anovel scheme for FL that provides resilience against Byzantine users whilekeeping the users' data private from the federator and private from otherusers. The scheme builds on the preexisting non-private FLTrust scheme, whichtolerates malicious users through trust scores (TS) that attenuate or amplifythe users' gradients. The trust scores are based on the ReLU function, which weapproximate by a polynomial. The distributed and privacy-preserving computationin ByITFL is designed using a combination of Lagrange coded computing,verifiable secret sharing and re-randomization steps. ByITFL is the firstByzantine resilient scheme for FL with full information-theoretic privacy.</description><author>Yue Xia, Christoph Hofmeister, Maximilian Egger, Rawad Bitar</author><pubDate>Tue, 14 May 2024 16:37:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08698v1</guid></item><item><title>View-Centric Multi-Object Tracking with Homographic Matching in Moving UAV</title><link>http://arxiv.org/abs/2403.10830v2</link><description>In this paper, we address the challenge of multi-object tracking (MOT) inmoving Unmanned Aerial Vehicle (UAV) scenarios, where irregular flighttrajectories, such as hovering, turning left/right, and moving up/down, lead tosignificantly greater complexity compared to fixed-camera MOT. Specifically,changes in the scene background not only render traditional frame-to-frameobject IOU association methods ineffective but also introduce significant viewshifts in the objects, which complicates tracking. To overcome these issues, wepropose a novel universal HomView-MOT framework, which for the first time,harnesses the view Homography inherent in changing scenes to solve MOTchallenges in moving environments, incorporating Homographic Matching andView-Centric concepts. We introduce a Fast Homography Estimation (FHE)algorithm for rapid computation of Homography matrices between video frames,enabling object View-Centric ID Learning (VCIL) and leveraging multi-viewHomography to learn cross-view ID features. Concurrently, our HomographicMatching Filter (HMF) maps object bounding boxes from different frames onto acommon view plane for a more realistic physical IOU association. Extensiveexperiments have proven that these innovations allow HomView-MOT to achievestate-of-the-art performance on prominent UAV MOT datasets VisDrone and UAVDT.</description><author>Deyi Ji, Siqi Gao, Lanyun Zhu, Qi Zhu, Yiru Zhao, Peng Xu, Hongtao Lu, Feng Zhao, Jieping Ye</author><pubDate>Tue, 14 May 2024 16:36:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.10830v2</guid></item><item><title>Higher-Order Equivariant Neural Networks for Charge Density Prediction in Materials</title><link>http://arxiv.org/abs/2312.05388v2</link><description>The calculation of electron density distribution using density functionaltheory (DFT) in materials and molecules is central to the study of theirquantum and macro-scale properties, yet accurate and efficient calculationremains a long-standing challenge. We introduce ChargE3Net, an E(3)-equivariantgraph neural network for predicting electron density in atomic systems.ChargE3Net enables the learning of higher-order equivariant feature to achievehigh predictive accuracy and model expressivity. We show that ChargE3Netexceeds the performance of prior work on diverse sets of molecules andmaterials. When trained on the massive dataset of over 100K materials in theMaterials Project database, our model is able to capture the complexity andvariability in the data, leading to a significant 26.7% reduction inself-consistent iterations when used to initialize DFT calculations on unseenmaterials. Furthermore, we show that non-self-consistent DFT calculations usingour predicted charge densities yield near-DFT performance on electronic andthermodynamic property prediction at a fraction of the computational cost.Further analysis attributes the greater predictive accuracy to improvedmodeling of systems with high angular variations. These results illuminate apathway towards a machine learning-accelerated ab initio calculations formaterials discovery.</description><author>Teddy Koker, Keegan Quigley, Eric Taw, Kevin Tibbetts, Lin Li</author><pubDate>Tue, 14 May 2024 16:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05388v2</guid></item><item><title>The impact of Compositionality in Zero-shot Multi-label action recognition for Object-based tasks</title><link>http://arxiv.org/abs/2405.08695v1</link><description>Addressing multi-label action recognition in videos represents a significantchallenge for robotic applications in dynamic environments, especially when therobot is required to cooperate with humans in tasks that involve objects.Existing methods still struggle to recognize unseen actions or requireextensive training data. To overcome these problems, we propose Dual-VCLIP, aunified approach for zero-shot multi-label action recognition. Dual-VCLIPenhances VCLIP, a zero-shot action recognition method, with the DualCoOp methodfor multi-label image classification. The strength of our method is that attraining time it only learns two prompts, and it is therefore much simpler thanother methods. We validate our method on the Charades dataset that includes amajority of object-based actions, demonstrating that -- despite its simplicity-- our method performs favorably with respect to existing methods on thecomplete dataset, and promising performance when tested on unseen actions. Ourcontribution emphasizes the impact of verb-object class-splits during robots'training for new cooperative tasks, highlighting the influence on theperformance and giving insights into mitigating biases.</description><author>Carmela Calabrese, Stefano Berti, Giulia Pasquale, Lorenzo Natale</author><pubDate>Tue, 14 May 2024 16:28:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08695v1</guid></item><item><title>One-shot Generative Data Augmentation with Bounded Divergence for UAV Identification in Limited RF Environments</title><link>http://arxiv.org/abs/2301.08403v3</link><description>This work addresses the pressing need for cybersecurity in Unmanned AerialVehicles (UAVs), particularly focusing on the challenges of identifying UAVsusing radiofrequency (RF) fingerprinting in constrained environments. Thecomplexity and variability of RF signals, influenced by environmentalinterference and hardware imperfections, often render traditional RF-basedidentification methods ineffective. To address these complications, the studyintroduces the rigorous use of one-shot generative methods for augmentingtransformed RF signals, offering a significant improvement in UAVidentification. This approach shows promise in low-data regimes, outperformingdeep generative methods like conditional generative adversarial networks (GANs)and variational autoencoders (VAEs). The paper provides a theoretical guaranteefor the effectiveness of one-shot generative models in augmenting limited data,setting a precedent for their application in limited RF environments. Thisresearch not only contributes to the cybersecurity of UAVs but also rigorouslybroadens the scope of machine learning techniques in data-constrainedscenarios, which may include atypical complex sequences beyond images andvideos.</description><author>Amir Kazemi, Salar Basiri, Volodymyr Kindratenko, Srinivasa Salapaka</author><pubDate>Tue, 14 May 2024 16:17:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08403v3</guid></item><item><title>Splat-MOVER: Multi-Stage, Open-Vocabulary Robotic Manipulation via Editable Gaussian Splatting</title><link>http://arxiv.org/abs/2405.04378v2</link><description>We present Splat-MOVER, a modular robotics stack for open-vocabulary roboticmanipulation, which leverages the editability of Gaussian Splatting (GSplat)scene representations to enable multi-stage manipulation tasks. Splat-MOVERconsists of: (i) ASK-Splat, a GSplat representation that distills latent codesfor language semantics and grasp affordance into the 3D scene. ASK-Splatenables geometric, semantic, and affordance understanding of 3D scenes, whichis critical for many robotics tasks; (ii) SEE-Splat, a real-time scene-editingmodule using 3D semantic masking and infilling to visualize the motions ofobjects that result from robot interactions in the real-world. SEE-Splatcreates a "digital twin" of the evolving environment throughout themanipulation task; and (iii) Grasp-Splat, a grasp generation module that usesASK-Splat and SEE-Splat to propose candidate grasps for open-world objects.ASK-Splat is trained in real-time from RGB images in a brief scanning phaseprior to operation, while SEE-Splat and Grasp-Splat run in real-time duringoperation. We demonstrate the superior performance of Splat-MOVER in hardwareexperiments on a Kinova robot compared to two recent baselines in foursingle-stage, open-vocabulary manipulation tasks, as well as in fourmulti-stage manipulation tasks using the edited scene to reflect scene changesdue to prior manipulation stages, which is not possible with the existingbaselines. Code for this project and a link to the project page will be madeavailable soon.</description><author>Ola Shorinwa, Johnathan Tucker, Aliyah Smith, Aiden Swann, Timothy Chen, Roya Firoozi, Monroe Kennedy III, Mac Schwager</author><pubDate>Tue, 14 May 2024 16:13:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04378v2</guid></item><item><title>Distributed DP-Helmet: Scalable Differentially Private Non-interactive Averaging of Single Layers</title><link>http://arxiv.org/abs/2211.02003v2</link><description>In this work, we propose two differentially private, non-interactive,distributed learning algorithms in a framework called Distributed DP-Helmet.Our framework is based on what we coin blind averaging: each user locallylearns and noises a model and all users then jointly compute the mean of theirmodels via a secure summation protocol. We provide experimental evidence thatblind averaging for SVMs and single Softmax-layer (Softmax-SLP) can have astrong utility-privacy tradeoff: we reach an accuracy of 86% on CIFAR-10 for$\varepsilon$ = 0.4 and 1,000 users, of 44% on CIFAR-100 for $\varepsilon$ =1.2 and 100 users, and of 39% on federated EMNIST for $\varepsilon$ = 0.4 and3,400 users, all after a SimCLR-based pretraining. As an ablation, we study theresilience of our approach to a strongly non-IID setting. On the theoreticalside, we show that blind averaging preserves differential privacy if theobjective function is smooth, Lipschitz, and strongly convex like SVMs. We showthat these properties also hold for Softmax-SLP which is often used forlast-layer fine-tuning such that for a fixed model size the privacy bound$\varepsilon$ of Softmax-SLP no longer depends on the number of classes. Thismarks a significant advantage in utility and privacy of Softmax-SLP over SVMs.Furthermore, in the limit blind averaging of hinge-loss SVMs convergences to acentralized learned SVM. The latter result is based on the representer theoremand can be seen as a blueprint for finding convergence for other empirical riskminimizers (ERM) like Softmax-SLP.</description><author>Moritz Kirschte, Sebastian Meiser, Saman Ardalan, Esfandiar Mohammadi</author><pubDate>Tue, 14 May 2024 16:10:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.02003v2</guid></item><item><title>Can Large Language Models Write Parallel Code?</title><link>http://arxiv.org/abs/2401.12554v3</link><description>Large language models are increasingly becoming a popular tool for softwaredevelopment. Their ability to model and generate source code has beendemonstrated in a variety of contexts, including code completion,summarization, translation, and lookup. However, they often struggle togenerate code for complex programs. In this paper, we study the capabilities ofstate-of-the-art language models to generate parallel code. In order toevaluate language models, we create a benchmark, ParEval, consisting of promptsthat represent 420 different coding tasks related to scientific and parallelcomputing. We use ParEval to evaluate the effectiveness of severalstate-of-the-art open- and closed-source language models on these tasks. Weintroduce novel metrics for evaluating the performance of generated code, anduse them to explore how well each large language model performs for 12different computational problem types and six different parallel programmingmodels.</description><author>Daniel Nichols, Joshua H. Davis, Zhaojun Xie, Arjun Rajaram, Abhinav Bhatele</author><pubDate>Tue, 14 May 2024 16:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12554v3</guid></item><item><title>VimTS: A Unified Video and Image Text Spotter for Enhancing the Cross-domain Generalization</title><link>http://arxiv.org/abs/2404.19652v3</link><description>Text spotting, a task involving the extraction of textual information fromimage or video sequences, faces challenges in cross-domain adaption, such asimage-to-image and image-to-video generalization. In this paper, we introduce anew method, termed VimTS, which enhances the generalization ability of themodel by achieving better synergy among different tasks. Typically, we proposea Prompt Queries Generation Module and a Tasks-aware Adapter to effectivelyconvert the original single-task model into a multi-task model suitable forboth image and video scenarios with minimal additional parameters. The PromptQueries Generation Module facilitates explicit interaction between differenttasks, while the Tasks-aware Adapter helps the model dynamically learn suitablefeatures for each task. Additionally, to further enable the model to learntemporal information at a lower cost, we propose a synthetic video text dataset(VTD-368k) by leveraging the Content Deformation Fields (CoDeF) algorithm.Notably, our method outperforms the state-of-the-art method by an average of2.6% in six cross-domain benchmarks such as TT-to-IC15, CTW1500-to-TT, andTT-to-CTW1500. For video-level cross-domain adaption, our method even surpassesthe previous end-to-end video spotting method in ICDAR2015 video and DSText v2by an average of 5.5% on the MOTA metric, using only image-level data. Wefurther demonstrate that existing Large Multimodal Models exhibit limitationsin generating cross-domain scene text spotting, in contrast to our VimTS modelwhich requires significantly fewer parameters and data. The code and datasetswill be made available at the https://VimTextSpotter.github.io.</description><author>Yuliang Liu, Mingxin Huang, Hao Yan, Linger Deng, Weijia Wu, Hao Lu, Chunhua Shen, Lianwen Jin, Xiang Bai</author><pubDate>Tue, 14 May 2024 16:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19652v3</guid></item><item><title>Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis</title><link>http://arxiv.org/abs/2405.08681v1</link><description>Numerous studies have revealed that deep learning-based medical imageclassification models may exhibit bias towards specific demographic attributes,such as race, gender, and age. Existing bias mitigation methods often achievehigh level of fairness at the cost of significant accuracy degradation. Inresponse to this challenge, we propose an innovative and adaptable Soft NearestNeighbor Loss-based channel pruning framework, which achieves fairness throughchannel pruning. Traditionally, channel pruning is utilized to accelerateneural network inference. However, our work demonstrates that pruning can alsobe a potent tool for achieving fairness. Our key insight is that differentchannels in a layer contribute differently to the accuracy of different groups.By selectively pruning critical channels that lead to the accuracy differencebetween the privileged and unprivileged groups, we can effectively improvefairness without sacrificing accuracy significantly. Experiments conducted ontwo skin lesion diagnosis datasets across multiple sensitive attributesvalidate the effectiveness of our method in achieving state-of-the-arttrade-off between accuracy and fairness. Our code is available athttps://github.com/Kqp1227/Sensitive-Channel-Pruning.</description><author>Qingpeng Kong, Ching-Hao Chiu, Dewen Zeng, Yu-Jen Chen, Tsung-Yi Ho, Jingtong hu, Yiyu Shi</author><pubDate>Tue, 14 May 2024 16:04:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08681v1</guid></item><item><title>PLeak: Prompt Leaking Attacks against Large Language Model Applications</title><link>http://arxiv.org/abs/2405.06823v2</link><description>Large Language Models (LLMs) enable a new ecosystem with many downstreamapplications, called LLM applications, with different natural languageprocessing tasks. The functionality and performance of an LLM applicationhighly depend on its system prompt, which instructs the backend LLM on whattask to perform. Therefore, an LLM application developer often keeps a systemprompt confidential to protect its intellectual property. As a result, anatural attack, called prompt leaking, is to steal the system prompt from anLLM application, which compromises the developer's intellectual property.Existing prompt leaking attacks primarily rely on manually crafted queries, andthus achieve limited effectiveness. In this paper, we design a novel, closed-box prompt leaking attack framework,called PLeak, to optimize an adversarial query such that when the attackersends it to a target LLM application, its response reveals its own systemprompt. We formulate finding such an adversarial query as an optimizationproblem and solve it with a gradient-based method approximately. Our key ideais to break down the optimization goal by optimizing adversary queries forsystem prompts incrementally, i.e., starting from the first few tokens of eachsystem prompt step by step until the entire length of the system prompt. We evaluate PLeak in both offline settings and for real-world LLMapplications, e.g., those on Poe, a popular platform hosting such applications.Our results show that PLeak can effectively leak system prompts andsignificantly outperforms not only baselines that manually curate queries butalso baselines with optimized queries that are modified and adapted fromexisting jailbreaking attacks. We responsibly reported the issues to Poe andare still waiting for their response. Our implementation is available at thisrepository: https://github.com/BHui97/PLeak.</description><author>Bo Hui, Haolin Yuan, Neil Gong, Philippe Burlina, Yinzhi Cao</author><pubDate>Tue, 14 May 2024 16:03:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06823v2</guid></item><item><title>Photonic Neural Networks: A Compact Review</title><link>http://arxiv.org/abs/2302.08390v2</link><description>It has long been known that photonic science and especially photoniccommunications can raise the speed of technologies and producing manufacturing.More recently, photonic science has also been interested in its capabilities toimplement low-precision linear operations, such as matrix multiplications, fastand effciently. For a long time most scientists taught that Electronics is theend of science but after many years and about 35 years ago had been understoodthat electronics do not answer alone and should have a new science. Today weface modern ways and instruments for doing tasks as soon as possible inproportion to many decays before. The velocity of progress in science is veryfast. All our progress in science area is dependent on modern knowledge aboutnew methods. In this research, we want to review the concept of a photonicneural network. For this research was selected 18 main articles were among themain 30 articles on this subject from 2015 to the 2022 year. These articlesnoticed three principles: 1- Experimental concepts, 2- Theoretical concepts,and, finally 3- Mathematic concepts. We should be careful with this researchbecause mathematics has a very important and constructive role in our topics!One of the topics that are very valid and also new, is simulation. We used towork with simulation in some parts of this research. First, briefly, we startby introducing photonics and neural networks. In the second we explain theadvantages and disadvantages of a combination of both in the science world andindustries and technologies about them. Also, we are talking about theachievements of a thin modern science. Third, we try to introduce someimportant and valid parameters in neural networks. In this manner, we use manymathematic tools in some portions of this article.</description><author>Mohammad Ahmadi, Hamidreza Bolhasani</author><pubDate>Tue, 14 May 2024 16:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08390v2</guid></item><item><title>Investigating Design Choices in Joint-Embedding Predictive Architectures for General Audio Representation Learning</title><link>http://arxiv.org/abs/2405.08679v1</link><description>This paper addresses the problem of self-supervised general-purpose audiorepresentation learning. We explore the use of Joint-Embedding PredictiveArchitectures (JEPA) for this task, which consists of splitting an inputmel-spectrogram into two parts (context and target), computing neuralrepresentations for each, and training the neural network to predict the targetrepresentations from the context representations. We investigate several designchoices within this framework and study their influence through extensiveexperiments by evaluating our models on various audio classificationbenchmarks, including environmental sounds, speech and music downstream tasks.We focus notably on which part of the input data is used as context or targetand show experimentally that it significantly impacts the model's quality. Inparticular, we notice that some effective design choices in the image domainlead to poor performance on audio, thus highlighting major differences betweenthese two modalities.</description><author>Alain Riou, Stefan Lattner, Gaëtan Hadjeres, Geoffroy Peeters</author><pubDate>Tue, 14 May 2024 16:00:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08679v1</guid></item><item><title>Simplifying Debiased Inference via Automatic Differentiation and Probabilistic Programming</title><link>http://arxiv.org/abs/2405.08675v1</link><description>We introduce an algorithm that simplifies the construction of efficientestimators, making them accessible to a broader audience. 'Dimple' takes asinput computer code representing a parameter of interest and outputs anefficient estimator. Unlike standard approaches, it does not require users toderive a functional derivative known as the efficient influence function.Dimple avoids this task by applying automatic differentiation to thestatistical functional of interest. Doing so requires expressing thisfunctional as a composition of primitives satisfying a novel differentiabilitycondition. Dimple also uses this composition to determine the nuisances it mustestimate. In software, primitives can be implemented independently of oneanother and reused across different estimation problems. We provide aproof-of-concept Python implementation and showcase through examples how itallows users to go from parameter specification to efficient estimation withjust a few lines of code.</description><author>Alex Luedtke</author><pubDate>Tue, 14 May 2024 15:56:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08675v1</guid></item><item><title>Expensive Multi-Objective Bayesian Optimization Based on Diffusion Models</title><link>http://arxiv.org/abs/2405.08674v1</link><description>Multi-objective Bayesian optimization (MOBO) has shown promising performanceon various expensive multi-objective optimization problems (EMOPs). However,effectively modeling complex distributions of the Pareto optimal solutions isdifficult with limited function evaluations. Existing Pareto set learningalgorithms may exhibit considerable instability in such expensive scenarios,leading to significant deviations between the obtained solution set and thePareto set (PS). In this paper, we propose a novel Composite Diffusion Modelbased Pareto Set Learning algorithm, namely CDM-PSL, for expensive MOBO.CDM-PSL includes both unconditional and conditional diffusion model forgenerating high-quality samples. Besides, we introduce an information entropybased weighting method to balance different objectives of EMOPs. This method isintegrated with the guiding strategy, ensuring that all the objectives areappropriately balanced and given due consideration during the optimizationprocess; Extensive experimental results on both synthetic benchmarks andreal-world problems demonstrates that our proposed algorithm attains superiorperformance compared with various state-of-the-art MOBO algorithms.</description><author>Bingdong Li, Zixiang Di, Yongfan Lu, Hong Qian, Feng Wang, Peng Yang, Ke Tang, Aimin Zhou</author><pubDate>Tue, 14 May 2024 15:55:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08674v1</guid></item><item><title>EndoDAC: Efficient Adapting Foundation Model for Self-Supervised Depth Estimation from Any Endoscopic Camera</title><link>http://arxiv.org/abs/2405.08672v1</link><description>Depth estimation plays a crucial role in various tasks within endoscopicsurgery, including navigation, surface reconstruction, and augmented realityvisualization. Despite the significant achievements of foundation models invision tasks, including depth estimation, their direct application to themedical domain often results in suboptimal performance. This highlights theneed for efficient adaptation methods to adapt these models to endoscopic depthestimation. We propose Endoscopic Depth Any Camera (EndoDAC) which is anefficient self-supervised depth estimation framework that adapts foundationmodels to endoscopic scenes. Specifically, we develop the Dynamic Vector-BasedLow-Rank Adaptation (DV-LoRA) and employ Convolutional Neck blocks to tailorthe foundational model to the surgical domain, utilizing remarkably fewtrainable parameters. Given that camera information is not always accessible,we also introduce a self-supervised adaptation strategy that estimates cameraintrinsics using the pose encoder. Our framework is capable of being trainedsolely on monocular surgical videos from any camera, ensuring minimal trainingcosts. Experiments demonstrate that our approach obtains superior performanceeven with fewer training epochs and unaware of the ground truth cameraintrinsics. Code is available at https://github.com/BeileiCui/EndoDAC.</description><author>Beilei Cui, Mobarakol Islam, Long Bai, An Wang, Hongliang Ren</author><pubDate>Tue, 14 May 2024 15:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08672v1</guid></item><item><title>HPC-Coder: Modeling Parallel Programs using Large Language Models</title><link>http://arxiv.org/abs/2306.17281v2</link><description>Parallel programs in high performance computing (HPC) continue to grow incomplexity and scale in the exascale era. The diversity in hardware andparallel programming models make developing, optimizing, and maintainingparallel software even more burdensome for developers. One way to alleviatesome of these burdens is with automated development and analysis tools. Suchtools can perform complex and/or remedial tasks for developers that increasetheir productivity and decrease the chance for error. Until recently, suchtools for code development and performance analysis have been limited in thecomplexity of tasks they can perform, especially for parallel programs.However, with recent advancements in language modeling, and the availability oflarge amounts of open-source code related data, these tools have started toutilize predictive language models to automate more complex tasks. In thispaper, we show how large language models (LLMs) can be applied to tasksspecific to high performance and scientific codes. We introduce a new datasetof HPC and scientific codes and use it to fine-tune several pre-trained models.We compare several pre-trained LLMs on HPC-related tasks and introduce a newmodel, HPC-Coder, fine-tuned on parallel codes. In our experiments, we showthat this model can auto-complete HPC functions where generic models cannot,decorate for loops with OpenMP pragmas, and model performance changes inscientific application repositories as well as programming competitionsolutions.</description><author>Daniel Nichols, Aniruddha Marathe, Harshitha Menon, Todd Gamblin, Abhinav Bhatele</author><pubDate>Tue, 14 May 2024 15:51:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17281v2</guid></item><item><title>Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research</title><link>http://arxiv.org/abs/2405.08668v1</link><description>Large-scale Vision-Language Models (VLMs) have demonstrated exceptionalperformance in natural vision tasks, motivating researchers across domains toexplore domain-specific VLMs. However, the construction of powerfuldomain-specific VLMs demands vast amounts of annotated data, substantialelectrical energy, and computing resources, primarily accessible to industry,yet hindering VLM research in academia. To address this challenge and fostersustainable and equitable VLM research, we present the Generalized DomainPrompt Learning (GDPL) framework. GDPL facilitates the transfer of VLMs' robustrecognition capabilities from natural vision to specialized domains, withoutthe need for extensive data or resources. By leveraging small-scaledomain-specific foundation models and minimal prompt samples, GDPL empowers thelanguage branch with domain knowledge through quaternion networks, uncoveringcross-modal relationships between domain-specific vision features and naturalvision-based contextual embeddings. Simultaneously, GDPL guides the visionbranch into specific domains through hierarchical propagation of generatedvision prompt features, grounded in well-matched vision-language relations.Furthermore, to fully harness the domain adaptation potential of VLMs, weintroduce a novel low-rank adaptation approach. Extensive experiments acrossdiverse domains like remote sensing, medical imaging, geology, SyntheticAperture Radar, and fluid dynamics, validate the efficacy of GDPL,demonstrating its ability to achieve state-of-the-art domain recognitionperformance in a prompt learning paradigm. Our framework paves the way forsustainable and inclusive VLM research, transcending the barriers betweenacademia and industry.</description><author>Qinglong Cao, Yuntian Chen, Lu Lu, Hao Sun, Zhenzhong Zeng, Xiaokang Yang, Dongxiao Zhang</author><pubDate>Tue, 14 May 2024 15:51:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08668v1</guid></item><item><title>ConsistencyDet: A Robust Object Detector with a Denoising Paradigm of Consistency Model</title><link>http://arxiv.org/abs/2404.07773v3</link><description>Object detection, a quintessential task in the realm of perceptual computing,can be tackled using a generative methodology. In the present study, weintroduce a novel framework designed to articulate object detection as adenoising diffusion process, which operates on the perturbed bounding boxes ofannotated entities. This framework, termed ConsistencyDet, leverages aninnovative denoising concept known as the Consistency Model. The hallmark ofthis model is its self-consistency feature, which empowers the model to mapdistorted information from any temporal stage back to its pristine state,thereby realizing a "one-step denoising" mechanism. Such an attribute markedlyelevates the operational efficiency of the model, setting it apart from theconventional Diffusion Model. Throughout the training phase, ConsistencyDetinitiates the diffusion sequence with noise-infused boxes derived from theground-truth annotations and conditions the model to perform the denoisingtask. Subsequently, in the inference stage, the model employs a denoisingsampling strategy that commences with bounding boxes randomly sampled from anormal distribution. Through iterative refinement, the model transforms anassortment of arbitrarily generated boxes into definitive detections.Comprehensive evaluations employing standard benchmarks, such as MS-COCO andLVIS, corroborate that ConsistencyDet surpasses other leading-edge detectors inperformance metrics. Our code is available athttps://github.com/Tankowa/ConsistencyDet.</description><author>Lifan Jiang, Zhihui Wang, Changmiao Wang, Ming Li, Jiaxu Leng, Xindong Wu</author><pubDate>Tue, 14 May 2024 15:42:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07773v3</guid></item><item><title>Gradient Estimation and Variance Reduction in Stochastic and Deterministic Models</title><link>http://arxiv.org/abs/2405.08661v1</link><description>It seems that in the current age, computers, computation, and data have anincreasingly important role to play in scientific research and discovery. Thisis reflected in part by the rise of machine learning and artificialintelligence, which have become great areas of interest not just for computerscience but also for many other fields of study. More generally, there havebeen trends moving towards the use of bigger, more complex and higher capacitymodels. It also seems that stochastic models, and stochastic variants ofexisting deterministic models, have become important research directions invarious fields. For all of these types of models, gradient-based optimizationremains as the dominant paradigm for model fitting, control, and more. Thisdissertation considers unconstrained, nonlinear optimization problems, with afocus on the gradient itself, that key quantity which enables the solution ofsuch problems. In chapter 1, we introduce the notion of reverse differentiation, a termwhich describes the body of techniques which enables the efficient computationof gradients. We cover relevant techniques both in the deterministic andstochastic cases. We present a new framework for calculating the gradient ofproblems which involve both deterministic and stochastic elements. In chapter2, we analyze the properties of the gradient estimator, with a focus on thoseproperties which are typically assumed in convergence proofs of optimizationalgorithms. Chapter 3 gives various examples of applying our new gradientestimator. We further explore the idea of working with piecewise continuousmodels, that is, models with distinct branches and if statements which definewhat specific branch to use.</description><author>Ronan Keane</author><pubDate>Tue, 14 May 2024 15:41:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08661v1</guid></item><item><title>Farm3D: Learning Articulated 3D Animals by Distilling 2D Diffusion</title><link>http://arxiv.org/abs/2304.10535v3</link><description>We present Farm3D, a method for learning category-specific 3D reconstructorsfor articulated objects, relying solely on "free" virtual supervision from apre-trained 2D diffusion-based image generator. Recent approaches can learn amonocular network that predicts the 3D shape, albedo, illumination, andviewpoint of any object occurrence, given a collection of single-view images ofan object category. However, these approaches heavily rely on manually curatedclean training data, which are expensive to obtain. We propose a framework thatuses an image generator, such as Stable Diffusion, to generate synthetictraining data that are sufficiently clean and do not require further manualcuration, enabling the learning of such a reconstruction network from scratch.Additionally, we incorporate the diffusion model as a score to enhance thelearning process. The idea involves randomizing certain aspects of thereconstruction, such as viewpoint and illumination, generating virtual views ofthe reconstructed 3D object, and allowing the 2D network to assess the qualityof the resulting image, thus providing feedback to the reconstructor. Unlikework based on distillation, which produces a single 3D asset for each textualprompt, our approach yields a monocular reconstruction network capable ofoutputting a controllable 3D asset from any given image, whether real orgenerated, in a single forward pass in a matter of seconds. Our network can beused for analysis, including monocular reconstruction, or for synthesis,generating articulated assets for real-time applications such as video games.</description><author>Tomas Jakab, Ruining Li, Shangzhe Wu, Christian Rupprecht, Andrea Vedaldi</author><pubDate>Tue, 14 May 2024 15:37:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10535v3</guid></item><item><title>SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion</title><link>http://arxiv.org/abs/2311.12981v3</link><description>Natural Adversarial Examples (NAEs), images arising naturally from theenvironment and capable of deceiving classifiers, are instrumental in robustlyevaluating and identifying vulnerabilities in trained models. In this work,unlike prior works that passively collect NAEs from real images, we propose toactively synthesize NAEs using the state-of-the-art Stable Diffusion.Specifically, our method formulates a controlled optimization process, where weperturb the token embedding that corresponds to a specified class to generateNAEs. This generation process is guided by the gradient of loss from the targetclassifier, ensuring that the created image closely mimics the ground-truthclass yet fools the classifier. Named SD-NAE (Stable Diffusion for NaturalAdversarial Examples), our innovative method is effective in producing validand useful NAEs, which is demonstrated through a meticulously designedexperiment. Code is available at https://github.com/linyueqian/SD-NAE.</description><author>Yueqian Lin, Jingyang Zhang, Yiran Chen, Hai Li</author><pubDate>Tue, 14 May 2024 15:36:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12981v3</guid></item><item><title>Beyond the Black Box: Do More Complex Models Provide Superior XAI Explanations?</title><link>http://arxiv.org/abs/2405.08658v1</link><description>The increasing complexity of Artificial Intelligence models poses challengesto interpretability, particularly in the healthcare sector. This studyinvestigates the impact of deep learning model complexity and Explainable AI(XAI) efficacy, utilizing four ResNet architectures (ResNet-18, 34, 50, 101).Through methodical experimentation on 4,369 lung X-ray images ofCOVID-19-infected and healthy patients, the research evaluates models'classification performance and the relevance of corresponding XAI explanationswith respect to the ground-truth disease masks. Results indicate that theincrease in model complexity is associated with a decrease in classificationaccuracy and AUC-ROC scores (ResNet-18: 98.4%, 0.997; ResNet-101: 95.9%,0.988). Notably, in eleven out of twelve statistical tests performed, nostatistically significant differences occurred between XAI quantitative metrics- Relevance Rank Accuracy and the proposed Positive Attribution Ratio - acrosstrained models. These results suggest that increased model complexity does notconsistently lead to higher performance or relevance of explanations formodels' decision-making processes.</description><author>Mateusz Cedro, Marcin Chlebus</author><pubDate>Tue, 14 May 2024 15:35:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08658v1</guid></item><item><title>Self-supervised learning improves robustness of deep learning lung tumor segmentation to CT imaging differences</title><link>http://arxiv.org/abs/2405.08657v1</link><description>Self-supervised learning (SSL) is an approach to extract useful featurerepresentations from unlabeled data, and enable fine-tuning on downstream taskswith limited labeled examples. Self-pretraining is a SSL approach that uses thecurated task dataset for both pretraining the networks and fine-tuning them.Availability of large, diverse, and uncurated public medical image setsprovides the opportunity to apply SSL in the "wild" and potentially extractfeatures robust to imaging variations. However, the benefit of wild- vsself-pretraining has not been studied for medical image analysis. In thispaper, we compare robustness of wild versus self-pretrained transformer (visiontransformer [ViT] and hierarchical shifted window [Swin]) models to computedtomography (CT) imaging differences for non-small cell lung cancer (NSCLC)segmentation. Wild-pretrained Swin models outperformed self-pretrained Swin forthe various imaging acquisitions. ViT resulted in similar accuracy for bothwild- and self-pretrained models. Masked image prediction pretext task thatforces networks to learn the local structure resulted in higher accuracycompared to contrastive task that models global image information.Wild-pretrained models resulted in higher feature reuse at the lower levellayers and feature differentiation close to output layer after fine-tuning.Hence, we conclude: Wild-pretrained networks were more robust to analyzed CTimaging differences for lung tumor segmentation than self-pretrained methods.Swin architecture benefited from such pretraining more than ViT.</description><author>Jue Jiang, Aneesh Rangnekar, Harini Veeraraghavan</author><pubDate>Tue, 14 May 2024 15:35:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08657v1</guid></item><item><title>A Distributed Approach to Autonomous Intersection Management via Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2405.08655v1</link><description>Autonomous intersection management (AIM) poses significant challenges due tothe intricate nature of real-world traffic scenarios and the need for a highlyexpensive centralised server in charge of simultaneously controlling all thevehicles. This study addresses such issues by proposing a novel distributedapproach to AIM utilizing multi-agent reinforcement learning (MARL). We showthat by leveraging the 3D surround view technology for advanced assistancesystems, autonomous vehicles can accurately navigate intersection scenarioswithout needing any centralised controller. The contributions of this paperthus include a MARL-based algorithm for the autonomous management of a 4-wayintersection and also the introduction of a new strategy called prioritisedscenario replay for improved training efficacy. We validate our approach as aninnovative alternative to conventional centralised AIM techniques, ensuring thefull reproducibility of our results. Specifically, experiments conducted invirtual environments using the SMARTS platform highlight its superiority overbenchmarks across various metrics.</description><author>Matteo Cederle, Marco Fabris, Gian Antonio Susto</author><pubDate>Tue, 14 May 2024 15:34:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08655v1</guid></item><item><title>Can we Defend Against the Unknown? An Empirical Study About Threshold Selection for Neural Network Monitoring</title><link>http://arxiv.org/abs/2405.08654v1</link><description>With the increasing use of neural networks in critical systems, runtimemonitoring becomes essential to reject unsafe predictions during inference.Various techniques have emerged to establish rejection scores that maximize theseparability between the distributions of safe and unsafe predictions. Theefficacy of these approaches is mostly evaluated using threshold-agnosticmetrics, such as the area under the receiver operating characteristic curve.However, in real-world applications, an effective monitor also requiresidentifying a good threshold to transform these scores into meaningful binarydecisions. Despite the pivotal importance of threshold optimization, thisproblem has received little attention. A few studies touch upon this question,but they typically assume that the runtime data distribution mirrors thetraining distribution, which is a strong assumption as monitors are supposed tosafeguard a system against potentially unforeseen threats. In this work, wepresent rigorous experiments on various image datasets to investigate: 1. Theeffectiveness of monitors in handling unforeseen threats, which are notavailable during threshold adjustments. 2. Whether integrating generic threatsinto the threshold optimization scheme can enhance the robustness of monitors.</description><author>Khoi Tran Dang, Kevin Delmas, Jérémie Guiochet, Joris Guérin</author><pubDate>Tue, 14 May 2024 15:32:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08654v1</guid></item><item><title>Output-decomposed Learning of Mealy Machines</title><link>http://arxiv.org/abs/2405.08647v1</link><description>We present an active automata learning algorithm which learns a decompositionof a finite state machine, based on projecting onto individual outputs. This isdual to a recent compositional learning algorithm by Labbaf et al. (2023). Whenprojecting the outputs to a smaller set, the model itself is reduced in size.By having several such projections, we do not lose any information and the fullsystem can be reconstructed. Depending on the structure of the system thisreduces the number of queries drastically, as shown by a preliminary evaluationof the algorithm.</description><author>Rick Koenders, Joshua Moerman</author><pubDate>Tue, 14 May 2024 15:22:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08647v1</guid></item><item><title>Certifying Robustness of Graph Convolutional Networks for Node Perturbation with Polyhedra Abstract Interpretation</title><link>http://arxiv.org/abs/2405.08645v1</link><description>Graph convolutional neural networks (GCNs) are powerful tools for learninggraph-based knowledge representations from training data. However, they arevulnerable to small perturbations in the input graph, which makes themsusceptible to input faults or adversarial attacks. This poses a significantproblem for GCNs intended to be used in critical applications, which need toprovide certifiably robust services even in the presence of adversarialperturbations. We propose an improved GCN robustness certification techniquefor node classification in the presence of node feature perturbations. Weintroduce a novel polyhedra-based abstract interpretation approach to tacklespecific challenges of graph data and provide tight upper and lower bounds forthe robustness of the GCN. Experiments show that our approach simultaneouslyimproves the tightness of robustness bounds as well as the runtime performanceof certification. Moreover, our method can be used during training to furtherimprove the robustness of GCNs.</description><author>Boqi Chen, Kristóf Marussy, Oszkár Semeráth, Gunter Mussbacher, Dániel Varró</author><pubDate>Tue, 14 May 2024 15:21:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08645v1</guid></item><item><title>Thinking Tokens for Language Modeling</title><link>http://arxiv.org/abs/2405.08644v1</link><description>How much is 56 times 37? Language models often make mistakes in these typesof difficult calculations. This is usually explained by their inability toperform complex reasoning. Since language models rely on large training setsand great memorization capability, naturally they are not equipped to runcomplex calculations. However, one can argue that humans also cannot performthis calculation immediately and require a considerable amount of time toconstruct the solution. In order to enhance the generalization capability oflanguage models, and as a parallel to human behavior, we propose to use special'thinking tokens' which allow the model to perform much more calculationswhenever a complex problem is encountered.</description><author>David Herel, Tomas Mikolov</author><pubDate>Tue, 14 May 2024 15:21:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08644v1</guid></item><item><title>Generating Probabilistic Scenario Programs from Natural Language</title><link>http://arxiv.org/abs/2405.03709v2</link><description>For cyber-physical systems (CPS), including robotics and autonomous vehicles,mass deployment has been hindered by fatal errors that occur when operating inrare events. To replicate rare events such as vehicle crashes, many companieshave created logging systems and employed crash reconstruction experts tometiculously recreate these valuable events in simulation. However, in thesemethods, "what if" questions are not easily formulated and answered. We presentScenarioNL, an AI System for creating scenario programs from natural language.Specifically, we generate these programs from police crash reports. Reportsnormally contain uncertainty about the exact details of the incidents which werepresent through a Probabilistic Programming Language (PPL), Scenic. By usingScenic, we can clearly and concisely represent uncertainty and variation overCPS behaviors, properties, and interactions. We demonstrate how commonplaceprompting techniques with the best Large Language Models (LLM) are incapable ofreasoning about probabilistic scenario programs and generating code forlow-resource languages such as Scenic. Our system is comprised of several LLMschained together with several kinds of prompting strategies, a compiler, and asimulator. We evaluate our system on publicly available autonomous vehiclecrash reports in California from the last five years and share insights intohow we generate code that is both semantically meaningful and syntacticallycorrect.</description><author>Karim Elmaaroufi, Devan Shanker, Ana Cismaru, Marcell Vazquez-Chanlatte, Alberto Sangiovanni-Vincentelli, Matei Zaharia, Sanjit A. Seshia</author><pubDate>Tue, 14 May 2024 15:21:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03709v2</guid></item><item><title>vMFER: Von Mises-Fisher Experience Resampling Based on Uncertainty of Gradient Directions for Policy Improvement</title><link>http://arxiv.org/abs/2405.08638v1</link><description>Reinforcement Learning (RL) is a widely employed technique in decision-makingproblems, encompassing two fundamental operations -- policy evaluation andpolicy improvement. Enhancing learning efficiency remains a key challenge inRL, with many efforts focused on using ensemble critics to boost policyevaluation efficiency. However, when using multiple critics, the actor in thepolicy improvement process can obtain different gradients. Previous studieshave combined these gradients without considering their disagreements.Therefore, optimizing the policy improvement process is crucial to enhancelearning efficiency. This study focuses on investigating the impact of gradientdisagreements caused by ensemble critics on policy improvement. We introducethe concept of uncertainty of gradient directions as a means to measure thedisagreement among gradients utilized in the policy improvement process.Through measuring the disagreement among gradients, we find that transitionswith lower uncertainty of gradient directions are more reliable in the policyimprovement process. Building on this analysis, we propose a method called vonMises-Fisher Experience Resampling (vMFER), which optimizes the policyimprovement process by resampling transitions and assigning higher confidenceto transitions with lower uncertainty of gradient directions. Our experimentsdemonstrate that vMFER significantly outperforms the benchmark and isparticularly well-suited for ensemble structures in RL.</description><author>Yiwen Zhu, Jinyi Liu, Wenya Wei, Qianyi Fu, Yujing Hu, Zhou Fang, Bo An, Jianye Hao, Tangjie Lv, Changjie Fan</author><pubDate>Tue, 14 May 2024 15:18:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08638v1</guid></item><item><title>Drift Detection: Introducing Gaussian Split Detector</title><link>http://arxiv.org/abs/2405.08637v1</link><description>Recent research yielded a wide array of drift detectors. However, in order toachieve remarkable performance, the true class labels must be available duringthe drift detection phase. This paper targets at detecting drift when theground truth is unknown during the detection phase. To that end, we introduceGaussian Split Detector (GSD) a novel drift detector that works in batch mode.GSD is designed to work when the data follow a normal distribution and makesuse of Gaussian mixture models to monitor changes in the decision boundary. Thealgorithm is designed to handle multi-dimension data streams and to workwithout the ground truth labels during the inference phase making it pertinentfor real world use. In an extensive experimental study on real and syntheticdatasets, we evaluate our detector against the state of the art. We show thatour detector outperforms the state of the art in detecting real drift and inignoring virtual drift which is key to avoid false alarms.</description><author>Maxime Fuccellaro, Laurent Simon, Akka Zemmari</author><pubDate>Tue, 14 May 2024 15:15:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08637v1</guid></item><item><title>Optimal design of experiments in the context of machine-learning inter-atomic potentials: improving the efficiency and transferability of kernel based methods</title><link>http://arxiv.org/abs/2405.08636v1</link><description>Data-driven, machine learning (ML) models of atomistic interactions are oftenbased on flexible and non-physical functions that can relate nuanced aspects ofatomic arrangements into predictions of energies and forces. As a result, thesepotentials are as good as the training data (usually results of so-called abinitio simulations) and we need to make sure that we have enough informationfor a model to become sufficiently accurate, reliable and transferable. Themain challenge stems from the fact that descriptors of chemical environmentsare often sparse high-dimensional objects without a well-defined continuousmetric. Therefore, it is rather unlikely that any ad hoc method of choosingtraining examples will be indiscriminate, and it will be easy to fall into thetrap of confirmation bias, where the same narrow and biased sampling is used togenerate train- and test- sets. We will demonstrate that classical concepts ofstatistical planning of experiments and optimal design can help to mitigatesuch problems at a relatively low computational cost. The key feature of themethod we will investigate is that they allow us to assess the informativenessof data (how much we can improve the model by adding/swapping a trainingexample) and verify if the training is feasible with the current set beforeobtaining any reference energies and forces -- a so-called off-line approach.In other words, we are focusing on an approach that is easy to implement anddoesn't require sophisticated frameworks that involve automated access tohigh-performance computational (HPC).</description><author>Bartosz Barzdajn, Christopher P. Race</author><pubDate>Tue, 14 May 2024 15:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08636v1</guid></item><item><title>CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images</title><link>http://arxiv.org/abs/2307.03293v4</link><description>The development of successful artificial intelligence models for chest X-rayanalysis relies on large, diverse datasets with high-quality annotations. Whileseveral databases of chest X-ray images have been released, most includedisease diagnosis labels but lack detailed pixel-level anatomical segmentationlabels. To address this gap, we introduce an extensive chest X-ray multi-centersegmentation dataset with uniform and fine-grain anatomical annotations forimages coming from five well-known publicly available databases: ChestX-ray8,Chexpert, MIMIC-CXR-JPG, Padchest, and VinDr-CXR, resulting in 657,566segmentation masks. Our methodology utilizes the HybridGNet model to ensureconsistent and high-quality segmentations across all datasets. Rigorousvalidation, including expert physician evaluation and automatic qualitycontrol, was conducted to validate the resulting masks. Additionally, weprovide individualized quality indices per mask and an overall qualityestimation per dataset. This dataset serves as a valuable resource for thebroader scientific community, streamlining the development and assessment ofinnovative methodologies in chest X-ray analysis. The CheXmask dataset ispublicly available at:https://physionet.org/content/chexmask-cxr-segmentation-data/</description><author>Nicolás Gaggion, Candelaria Mosquera, Lucas Mansilla, Julia Mariel Saidman, Martina Aineseder, Diego H. Milone, Enzo Ferrante</author><pubDate>Tue, 14 May 2024 15:14:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03293v4</guid></item><item><title>A Fast and Scalable Pathwise-Solver for Group Lasso and Elastic Net Penalized Regression via Block-Coordinate Descent</title><link>http://arxiv.org/abs/2405.08631v1</link><description>We develop fast and scalable algorithms based on block-coordinate descent tosolve the group lasso and the group elastic net for generalized linear modelsalong a regularization path. Special attention is given when the loss is theusual least squares loss (Gaussian loss). We show that each block-coordinateupdate can be solved efficiently using Newton's method and further improvedusing an adaptive bisection method, solving these updates with a quadraticconvergence rate. Our benchmarks show that our package adelie performs 3 to 10times faster than the next fastest package on a wide array of both simulatedand real datasets. Moreover, we demonstrate that our package is a competitivelasso solver as well, matching the performance of the popular lasso packageglmnet.</description><author>James Yang, Trevor Hastie</author><pubDate>Tue, 14 May 2024 15:10:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08631v1</guid></item><item><title>RMT-BVQA: Recurrent Memory Transformer-based Blind Video Quality Assessment for Enhanced Video Content</title><link>http://arxiv.org/abs/2405.08621v1</link><description>With recent advances in deep learning, numerous algorithms have beendeveloped to enhance video quality, reduce visual artefacts and improveperceptual quality. However, little research has been reported on the qualityassessment of enhanced content - the evaluation of enhancement methods is oftenbased on quality metrics that were designed for compression applications. Inthis paper, we propose a novel blind deep video quality assessment (VQA) methodspecifically for enhanced video content. It employs a new Recurrent MemoryTransformer (RMT) based network architecture to obtain video qualityrepresentations, which is optimised through a novel content-quality-awarecontrastive learning strategy based on a new database containing 13K trainingpatches with enhanced content. The extracted quality representations are thencombined through linear regression to generate video-level quality indices. Theproposed method, RMT-BVQA, has been evaluated on the VDPVE (VQA Dataset forPerceptual Video Enhancement) database through a five-fold cross validation.The results show its superior correlation performance when compared to tenexisting no-reference quality metrics.</description><author>Tianhao Peng, Chen Feng, Duolikun Danier, Fan Zhang, David Bull</author><pubDate>Tue, 14 May 2024 15:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08621v1</guid></item><item><title>ALMol: Aligned Language-Molecule Translation LLMs through Offline Preference Contrastive Optimisation</title><link>http://arxiv.org/abs/2405.08619v1</link><description>The field of chemistry and Artificial Intelligence (AI) intersection is anarea of active research that aims to accelerate scientific discovery. Theintegration of large language models (LLMs) with scientific modalities hasshown significant promise in this endeavour. However, challenges persist ineffectively addressing training efficacy and the out-of-distribution problem,particularly as existing approaches rely on larger models and datasets. In thiscontext, we focus on machine language-molecule translation and deploy a noveltraining approach called contrastive preference optimisation, which avoidsgenerating translations that are merely adequate but not perfect. To ensuregeneralisability and mitigate memorisation effects, we conduct experimentsusing only 10\% of the data. Our results demonstrate that our models achieve upto a 32\% improvement compared to counterpart models. We also introduce ascalable fine-grained evaluation methodology that accommodates responsibility.</description><author>Dimitris Gkoumas</author><pubDate>Tue, 14 May 2024 14:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08619v1</guid></item><item><title>GN-SINDy: Greedy Sampling Neural Network in Sparse Identification of Nonlinear Partial Differential Equations</title><link>http://arxiv.org/abs/2405.08613v1</link><description>The sparse identification of nonlinear dynamical systems (SINDy) is adata-driven technique employed for uncovering and representing the fundamentaldynamics of intricate systems based on observational data. However, a primaryobstacle in the discovery of models for nonlinear partial differentialequations (PDEs) lies in addressing the challenges posed by the curse ofdimensionality and large datasets. Consequently, the strategic selection of themost informative samples within a given dataset plays a crucial role inreducing computational costs and enhancing the effectiveness of SINDy-basedalgorithms. To this aim, we employ a greedy sampling approach to the snapshotmatrix of a PDE to obtain its valuable samples, which are suitable to train adeep neural network (DNN) in a SINDy framework. SINDy based algorithms oftenconsist of a data collection unit, constructing a dictionary of basisfunctions, computing the time derivative, and solving a sparse identificationproblem which ends to regularised least squares minimization. In this paper, weextend the results of a SINDy based deep learning model discovery (DeePyMoD)approach by integrating greedy sampling technique in its data collection unitand new sparsity promoting algorithms in the least squares minimization unit.In this regard we introduce the greedy sampling neural network in sparseidentification of nonlinear partial differential equations (GN-SINDy) whichblends a greedy sampling method, the DNN, and the SINDy algorithm. In theimplementation phase, to show the effectiveness of GN-SINDy, we compare itsresults with DeePyMoD by using a Python package that is prepared for thispurpose on numerous PDE discovery</description><author>Ali Forootani, Peter Benner</author><pubDate>Tue, 14 May 2024 14:56:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08613v1</guid></item><item><title>Dynamic NeRF: A Review</title><link>http://arxiv.org/abs/2405.08609v1</link><description>Neural Radiance Field(NeRF) is an novel implicit method to achieve the 3Dreconstruction and representation with a high resolution. After the firstresearch of NeRF is proposed, NeRF has gained a robust developing power and isbooming in the 3D modeling, representation and reconstruction areas. Howeverthe first and most of the followed research projects based on NeRF is static,which are weak in the practical applications. Therefore, more researcher areinterested and focused on the study of dynamic NeRF that is more feasible anduseful in practical applications or situations. Compared with the static NeRF,implementing the Dynamic NeRF is more difficult and complex. But Dynamic ismore potential in the future even is the basic of Editable NeRF. In thisreview, we made a detailed and abundant statement for the development andimportant implementation principles of Dynamci NeRF. The analysis of mainprinciple and development of Dynamic NeRF is from 2021 to 2023, including themost of the Dynamic NeRF projects. What is more, with colorful and novelspecial designed figures and table, We also made a detailed comparison andanalysis of different features of various of Dynamic. Besides, we analyzed anddiscussed the key methods to implement a Dynamic NeRF. The volume of thereference papers is large. The statements and comparisons are multidimensional.With a reading of this review, the whole development history and most of themain design method or principles of Dynamic NeRF can be easy understood andgained.</description><author>Jinwei Lin</author><pubDate>Tue, 14 May 2024 14:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08609v1</guid></item><item><title>Intriguing Property and Counterfactual Explanation of GAN for Remote Sensing Image Generation</title><link>http://arxiv.org/abs/2303.05240v3</link><description>Generative adversarial networks (GANs) have achieved remarkable progress inthe natural image field. However, when applying GANs in the remote sensing (RS)image generation task, an extraordinary phenomenon is observed: the GAN modelis more sensitive to the size of training data for RS image generation than fornatural image generation. In other words, the generation quality of RS imageswill change significantly with the number of training categories or samples percategory. In this paper, we first analyze this phenomenon from two kinds of toyexperiments and conclude that the amount of feature information contained inthe GAN model decreases with reduced training data. Then we establish astructural causal model (SCM) of the data generation process and interpret thegenerated data as the counterfactuals. Based on this SCM, we theoreticallyprove that the quality of generated images is positively correlated with theamount of feature information. This provides insights for enriching the featureinformation learned by the GAN model during training. Consequently, we proposetwo innovative adjustment schemes, namely Uniformity Regularization (UR) andEntropy Regularization (ER), to increase the information learned by the GANmodel at the distributional and sample levels, respectively. We theoreticallyand empirically demonstrate the effectiveness and versatility of our methods.Extensive experiments on three RS datasets and two natural datasets show thatour methods outperform the well-established models on RS image generationtasks. The source code is available at https://github.com/rootSue/Causal-RSGAN.</description><author>Xingzhe Su, Wenwen Qiang, Jie Hu, Fengge Wu, Changwen Zheng, Fuchun Sun</author><pubDate>Tue, 14 May 2024 14:46:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05240v3</guid></item><item><title>Towards Geometry-Aware Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization</title><link>http://arxiv.org/abs/2405.08604v1</link><description>Multi-objective combinatorial optimization (MOCO) problems are prevalent invarious real-world applications. Most existing neural methods for MOCO problemsrely solely on decomposition and utilize precise hypervolume to enhancediversity. However, these methods often approximate only limited regions of thePareto front and spend excessive time on diversity enhancement because ofambiguous decomposition and time-consuming hypervolume calculation. To addressthese limitations, we design a Geometry-Aware Pareto set Learning algorithmnamed GAPL, which provides a novel geometric perspective for neural MOCO via aPareto attention model based on hypervolume expectation maximization. Inaddition, we propose a hypervolume residual update strategy to enable thePareto attention model to capture both local and non-local information of thePareto set/front. We also design a novel inference approach to further improvequality of the solution set and speed up hypervolume calculation and localsubset selection. Experimental results on three classic MOCO problemsdemonstrate that our GAPL outperforms state-of-the-art neural baselines viasuperior decomposition and efficient diversity enhancement.</description><author>Yongfan Lu, Zixiang Di, Bingdong Li, Shengcai Liu, Hong Qian, Peng Yang, Ke Tang, Aimin Zhou</author><pubDate>Tue, 14 May 2024 14:42:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08604v1</guid></item></channel></rss>