<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 05 Oct 2023 14:00:09 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving</title><link>http://arxiv.org/abs/2310.03026v1</link><description>Existing learning-based autonomous driving (AD) systems face challenges incomprehending high-level information, generalizing to rare events, andproviding interpretability. To address these problems, this work employs LargeLanguage Models (LLMs) as a decision-making component for complex AD scenariosthat require human commonsense understanding. We devise cognitive pathways toenable comprehensive reasoning with LLMs, and develop algorithms fortranslating LLM decisions into actionable driving commands. Through thisapproach, LLM decisions are seamlessly integrated with low-level controllers byguided parameter matrix adaptation. Extensive experiments demonstrate that ourproposed method not only consistently surpasses baseline approaches insingle-vehicle tasks, but also helps handle complex driving behaviors evenmulti-vehicle coordination, thanks to the commonsense reasoning capabilities ofLLMs. This paper presents an initial step toward leveraging LLMs as effectivedecision-makers for intricate AD scenarios in terms of safety, efficiency,generalizability, and interoperability. We aspire for it to serve asinspiration for future research in this field. Project page:https://sites.google.com/view/llm-mpc</description><author>Hao Sha, Yao Mu, Yuxuan Jiang, Li Chen, Chenfeng Xu, Ping Luo, Shengbo Eben Li, Masayoshi Tomizuka, Wei Zhan, Mingyu Ding</author><pubDate>Wed, 04 Oct 2023 18:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03026v1</guid></item><item><title>Retrieval meets Long Context Large Language Models</title><link>http://arxiv.org/abs/2310.03025v1</link><description>Extending the context window of large language models (LLMs) is gettingpopular recently, while the solution of augmenting LLMs with retrieval hasexisted for years. The natural questions are: i) Retrieval-augmentation versuslong context window, which one is better for downstream tasks? ii) Can bothmethods be combined to get the best of both worlds? In this work, we answerthese questions by studying both solutions using two state-of-the-artpretrained LLMs, i.e., a proprietary 43B GPT and LLaMA2-70B. Perhapssurprisingly, we find that LLM with 4K context window using simpleretrieval-augmentation at generation can achieve comparable performance tofinetuned LLM with 16K context window via positional interpolation on longcontext tasks, while taking much less computation. More importantly, wedemonstrate that retrieval can significantly improve the performance of LLMsregardless of their extended context window sizes. Our best model,retrieval-augmented LLaMA2-70B with 32K context window, outperformsGPT-3.5-turbo-16k and Davinci003 in terms of average score on seven longcontext tasks including question answering and query-based summarization. Italso outperforms its non-retrieval LLaMA2-70B-32k baseline by a margin, whilebeing much faster at generation. Our study provides general insights on thechoice of retrieval-augmentation versus long context extension of LLM forpractitioners.</description><author>Peng Xu, Wei Ping, Xianchao Wu, Lawrence McAfee, Chen Zhu, Zihan Liu, Sandeep Subramanian, Evelina Bakhturina, Mohammad Shoeybi, Bryan Catanzaro</author><pubDate>Wed, 04 Oct 2023 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03025v1</guid></item><item><title>AstroCLIP: Cross-Modal Pre-Training for Astronomical Foundation Models</title><link>http://arxiv.org/abs/2310.03024v1</link><description>We present AstroCLIP, a strategy to facilitate the construction ofastronomical foundation models that bridge the gap between diverseobservational modalities. We demonstrate that a cross-modal contrastivelearning approach between images and optical spectra of galaxies yields highlyinformative embeddings of both modalities. In particular, we apply our methodon multi-band images and optical spectra from the Dark Energy SpectroscopicInstrument (DESI), and show that: (1) these embeddings are well-aligned betweenmodalities and can be used for accurate cross-modal searches, and (2) theseembeddings encode valuable physical information about the galaxies -- inparticular redshift and stellar mass -- that can be used to achieve competitivezero- and few- shot predictions without further finetuning. Additionally, inthe process of developing our approach, we also construct a novel,transformer-based model and pretraining approach for processing galaxy spectra.</description><author>Francois Lanusse, Liam Parker, Siavash Golkar, Miles Cranmer, Alberto Bietti, Michael Eickenberg, Geraud Krawezik, Michael McCabe, Ruben Ohana, Mariel Pettee, Bruno Regaldo-Saint Blancard, Tiberiu Tesileanu, Kyunghyun Cho, Shirley Ho</author><pubDate>Wed, 04 Oct 2023 18:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03024v1</guid></item><item><title>Human-oriented Representation Learning for Robotic Manipulation</title><link>http://arxiv.org/abs/2310.03023v1</link><description>Humans inherently possess generalizable visual representations that empowerthem to efficiently explore and interact with the environments in manipulationtasks. We advocate that such a representation automatically arises fromsimultaneously learning about multiple simple perceptual skills that arecritical for everyday scenarios (e.g., hand detection, state estimate, etc.)and is better suited for learning robot manipulation policies compared tocurrent state-of-the-art visual representations purely based on self-supervisedobjectives. We formalize this idea through the lens of human-orientedmulti-task fine-tuning on top of pre-trained visual encoders, where each taskis a perceptual skill tied to human-environment interactions. We introduce TaskFusion Decoder as a plug-and-play embedding translator that utilizes theunderlying relationships among these perceptual skills to guide therepresentation learning towards encoding meaningful structure for what'simportant for all perceptual skills, ultimately empowering learning ofdownstream robotic manipulation tasks. Extensive experiments across a range ofrobotic tasks and embodiments, in both simulations and real-world environments,show that our Task Fusion Decoder consistently improves the representation ofthree state-of-the-art visual encoders including R3M, MVP, and EgoVLP, fordownstream manipulation policy-learning. Project page:https://sites.google.com/view/human-oriented-robot-learning</description><author>Mingxiao Huo, Mingyu Ding, Chenfeng Xu, Thomas Tian, Xinghao Zhu, Yao Mu, Lingfeng Sun, Masayoshi Tomizuka, Wei Zhan</author><pubDate>Wed, 04 Oct 2023 18:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03023v1</guid></item><item><title>Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making</title><link>http://arxiv.org/abs/2310.03022v1</link><description>The recent success of Transformer in natural language processing has sparkedits use in various domains. In offline reinforcement learning (RL), DecisionTransformer (DT) is emerging as a promising model based on Transformer.However, we discovered that the attention module of DT is not appropriate tocapture the inherent local dependence pattern in trajectories of RL modeled asa Markov decision process. To overcome the limitations of DT, we propose anovel action sequence predictor, named Decision ConvFormer (DC), based on thearchitecture of MetaFormer, which is a general structure to process multipleentities in parallel and understand the interrelationship among the multipleentities. DC employs local convolution filtering as the token mixer and caneffectively capture the inherent local associations of the RL dataset. Inextensive experiments, DC achieved state-of-the-art performance across variousstandard RL benchmarks while requiring fewer resources. Furthermore, we showthat DC better understands the underlying meaning in data and exhibits enhancedgeneralization capability.</description><author>Jeonghye Kim, Suyoung Lee, Woojun Kim, Youngchul Sung</author><pubDate>Wed, 04 Oct 2023 18:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03022v1</guid></item><item><title>Consistent-1-to-3: Consistent Image to 3D View Synthesis via Geometry-aware Diffusion Models</title><link>http://arxiv.org/abs/2310.03020v1</link><description>Zero-shot novel view synthesis (NVS) from a single image is an essentialproblem in 3D object understanding. While recent approaches that leveragepre-trained generative models can synthesize high-quality novel views fromin-the-wild inputs, they still struggle to maintain 3D consistency acrossdifferent views. In this paper, we present Consistent-1-to-3, which is agenerative framework that significantly mitigate this issue. Specifically, wedecompose the NVS task into two stages: (i) transforming observed regions to anovel view, and (ii) hallucinating unseen regions. We design a scenerepresentation transformer and view-conditioned diffusion model for performingthese two stages respectively. Inside the models, to enforce 3D consistency, wepropose to employ epipolor-guided attention to incorporate geometryconstraints, and multi-view attention to better aggregate multi-viewinformation. Finally, we design a hierarchy generation paradigm to generatelong sequences of consistent views, allowing a full 360 observation of theprovided object image. Qualitative and quantitative evaluation over multipledatasets demonstrate the effectiveness of the proposed mechanisms againststate-of-the-art approaches. Our project page is athttps://jianglongye.com/consistent123/</description><author>Jianglong Ye, Peng Wang, Kejie Li, Yichun Shi, Heng Wang</author><pubDate>Wed, 04 Oct 2023 18:58:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03020v1</guid></item><item><title>Zero Resource Code-switched Speech Benchmark Using Speech Utterance Pairs For Multiple Spoken Languages</title><link>http://arxiv.org/abs/2310.03018v1</link><description>We introduce a new zero resource code-switched speech benchmark designed todirectly assess the code-switching capabilities of self-supervised speechencoders. We showcase a baseline system of language modeling on discrete unitsto demonstrate how the code-switching abilities of speech encoders can beassessed in a zero-resource manner. Our experiments encompass a variety ofwell-known speech encoders, including Wav2vec 2.0, HuBERT, XLSR, etc. Weexamine the impact of pre-training languages and model size on benchmarkperformance. Notably, though our results demonstrate that speech encoders withmultilingual pre-training, exemplified by XLSR, outperform monolingual variants(Wav2vec 2.0, HuBERT) in code-switching scenarios, there is still substantialroom for improvement in their code-switching linguistic abilities.</description><author>Kuan-Po Huang, Chih-Kai Yang, Yu-Kuan Fu, Ewan Dunbar, Hung-yi Lee</author><pubDate>Wed, 04 Oct 2023 18:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03018v1</guid></item><item><title>Multimodal Question Answering for Unified Information Extraction</title><link>http://arxiv.org/abs/2310.03017v1</link><description>Multimodal information extraction (MIE) aims to extract structuredinformation from unstructured multimedia content. Due to the diversity of tasksand settings, most current MIE models are task-specific and data-intensive,which limits their generalization to real-world scenarios with diverse taskrequirements and limited labeled data. To address these issues, we propose anovel multimodal question answering (MQA) framework to unify three MIE tasks byreformulating them into a unified span extraction and multi-choice QA pipeline.Extensive experiments on six datasets show that: 1) Our MQA frameworkconsistently and significantly improves the performances of variousoff-the-shelf large multimodal models (LMM) on MIE tasks, compared to vanillaprompting. 2) In the zero-shot setting, MQA outperforms previousstate-of-the-art baselines by a large margin. In addition, the effectiveness ofour framework can successfully transfer to the few-shot setting, enhancing LMMson a scale of 10B parameters to be competitive or outperform much largerlanguage models such as ChatGPT and GPT-4. Our MQA framework can serve as ageneral principle of utilizing LMMs to better solve MIE and potentially otherdownstream multimodal tasks.</description><author>Yuxuan Sun, Kai Zhang, Yu Su</author><pubDate>Wed, 04 Oct 2023 18:58:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03017v1</guid></item><item><title>ConR: Contrastive Regularizer for Deep Imbalanced Regression</title><link>http://arxiv.org/abs/2309.06651v2</link><description>Imbalanced distributions are ubiquitous in real-world data. They createconstraints on Deep Neural Networks to represent the minority labels and avoidbias towards majority labels. The extensive body of imbalanced approachesaddress categorical label spaces but fail to effectively extend to regressionproblems where the label space is continuous. Local and global correlationsamong continuous labels provide valuable insights towards effectively modellingrelationships in feature space. In this work, we propose ConR, a contrastiveregularizer that models global and local label similarities in feature spaceand prevents the features of minority samples from being collapsed into theirmajority neighbours. ConR discerns the disagreements between the label spaceand feature space and imposes a penalty on these disagreements. ConR addressesthe continuous nature of label space with two main strategies in a contrastivemanner: incorrect proximities are penalized proportionate to the labelsimilarities and the correct ones are encouraged to model local similarities.ConR consolidates essential considerations into a generic, easy-to-integrate,and efficient method that effectively addresses deep imbalanced regression.Moreover, ConR is orthogonal to existing approaches and smoothly extends touni- and multi-dimensional label spaces. Our comprehensive experiments showthat ConR significantly boosts the performance of all the state-of-the-artmethods on four large-scale deep imbalanced regression benchmarks. Our code ispublicly available in https://github.com/BorealisAI/ConR.</description><author>Mahsa Keramati, Lili Meng, R. David Evans</author><pubDate>Wed, 04 Oct 2023 18:57:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06651v2</guid></item><item><title>Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions</title><link>http://arxiv.org/abs/2310.03016v1</link><description>In order to understand the in-context learning phenomenon, recent works haveadopted a stylized experimental framework and demonstrated that Transformerscan learn gradient-based learning algorithms for various classes of real-valuedfunctions. However, the limitations of Transformers in implementing learningalgorithms, and their ability to learn other forms of algorithms are not wellunderstood. Additionally, the degree to which these capabilities are confinedto attention-based models is unclear. Furthermore, it remains to be seenwhether the insights derived from these stylized settings can be extrapolatedto pretrained Large Language Models (LLMs). In this work, we take a steptowards answering these questions by demonstrating the following: (a) On atest-bed with a variety of Boolean function classes, we find that Transformerscan nearly match the optimal learning algorithm for 'simpler' tasks, whiletheir performance deteriorates on more 'complex' tasks. Additionally, we findthat certain attention-free models perform (almost) identically to Transformerson a range of tasks. (b) When provided a teaching sequence, i.e. a set ofexamples that uniquely identifies a function in a class, we show thatTransformers learn more sample-efficiently. Interestingly, our results showthat Transformers can learn to implement two distinct algorithms to solve asingle task, and can adaptively select the more sample-efficient algorithmdepending on the sequence of in-context examples. (c) Lastly, we show thatextant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselineson prediction tasks that are guaranteed to not be in their training set.</description><author>Satwik Bhattamishra, Arkil Patel, Phil Blunsom, Varun Kanade</author><pubDate>Wed, 04 Oct 2023 18:57:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03016v1</guid></item><item><title>Efficient-3DiM: Learning a Generalizable Single-image Novel-view Synthesizer in One Day</title><link>http://arxiv.org/abs/2310.03015v1</link><description>The task of novel view synthesis aims to generate unseen perspectives of anobject or scene from a limited set of input images. Nevertheless, synthesizingnovel views from a single image still remains a significant challenge in therealm of computer vision. Previous approaches tackle this problem by adoptingmesh prediction, multi-plain image construction, or more advanced techniquessuch as neural radiance fields. Recently, a pre-trained diffusion model that isspecifically designed for 2D image synthesis has demonstrated its capability inproducing photorealistic novel views, if sufficiently optimized on a 3Dfinetuning task. Although the fidelity and generalizability are greatlyimproved, training such a powerful diffusion model requires a vast volume oftraining data and model parameters, resulting in a notoriously long time andhigh computational costs. To tackle this issue, we propose Efficient-3DiM, asimple but effective framework to learn a single-image novel-view synthesizer.Motivated by our in-depth analysis of the inference process of diffusionmodels, we propose several pragmatic strategies to reduce the training overheadto a manageable scale, including a crafted timestep sampling strategy, asuperior 3D feature extractor, and an enhanced training scheme. When combined,our framework is able to reduce the total training time from 10 days to lessthan 1 day, significantly accelerating the training process under the samecomputational platform (one instance with 8 Nvidia A100 GPUs). Comprehensiveexperiments are conducted to demonstrate the efficiency and generalizability ofour proposed method.</description><author>Yifan Jiang, Hao Tang, Jen-Hao Rick Chang, Liangchen Song, Zhangyang Wang, Liangliang Cao</author><pubDate>Wed, 04 Oct 2023 18:57:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03015v1</guid></item><item><title>SemiReward: A General Reward Model for Semi-supervised Learning</title><link>http://arxiv.org/abs/2310.03013v1</link><description>Semi-supervised learning (SSL) has witnessed great progress with variousimprovements in the self-training framework with pseudo labeling. The mainchallenge is how to distinguish high-quality pseudo labels against theconfirmation bias. However, existing pseudo-label selection strategies arelimited to pre-defined schemes or complex hand-crafted policies speciallydesigned for classification, failing to achieve high-quality labels, fastconvergence, and task versatility simultaneously. To these ends, we propose aSemi-supervised Reward framework (SemiReward) that predicts reward scores toevaluate and filter out high-quality pseudo labels, which is pluggable tomainstream SSL methods in wide task types and scenarios. To mitigateconfirmation bias, SemiReward is trained online in two stages with a generatormodel and subsampling strategy. With classification and regression tasks on 13standard SSL benchmarks of three modalities, extensive experiments verify thatSemiReward achieves significant performance gains and faster convergence speedsupon Pseudo Label, FlexMatch, and Free/SoftMatch.</description><author>Siyuan Li, Weiyang Jin, Zedong Wang, Fang Wu, Zicheng Liu, Cheng Tan, Stan Z. Li</author><pubDate>Wed, 04 Oct 2023 18:56:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03013v1</guid></item><item><title>Learning Adaptive Safety for Multi-Agent Systems</title><link>http://arxiv.org/abs/2309.10657v2</link><description>Ensuring safety in dynamic multi-agent systems is challenging due to limitedinformation about the other agents. Control Barrier Functions (CBFs) areshowing promise for safety assurance but current methods make strongassumptions about other agents and often rely on manual tuning to balancesafety, feasibility, and performance. In this work, we delve into the problemof adaptive safe learning for multi-agent systems with CBF. We show howemergent behavior can be profoundly influenced by the CBF configuration,highlighting the necessity for a responsive and dynamic approach to CBF design.We present ASRL, a novel adaptive safe RL framework, to fully automate theoptimization of policy and CBF coefficients, to enhance safety and long-termperformance through reinforcement learning. By directly interacting with theother agents, ASRL learns to cope with diverse agent behaviours and maintainsthe cost violations below a desired limit. We evaluate ASRL in a multi-robotsystem and a competitive multi-agent racing scenario, against learning-basedand control-theoretic approaches. We empirically demonstrate the efficacy andflexibility of ASRL, and assess generalization and scalability toout-of-distribution scenarios. Code and supplementary material are publiconline.</description><author>Luigi Berducci, Shuo Yang, Rahul Mangharam, Radu Grosu</author><pubDate>Wed, 04 Oct 2023 18:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10657v2</guid></item><item><title>One Sense per Translation</title><link>http://arxiv.org/abs/2106.06082v2</link><description>Word sense disambiguation (WSD) is the task of determining the sense of aword in context. Translations have been used in WSD as a source of knowledge,and even as a means of delimiting word senses. In this paper, we define threetheoretical properties of the relationship between senses and translations, andargue that they constitute necessary conditions for using translations as senseinventories. The key property of One Sense per Translation (OSPT) provides afoundation for a translation-based WSD method. The results of an intrinsicevaluation experiment indicate that our method achieves a precision ofapproximately 93% compared to manual corpus annotations. Our extrinsicevaluation experiments demonstrate WSD improvements of up to 4.6% F1-score ondifficult WSD datasets.</description><author>Bradley Hauer, Grzegorz Kondrak</author><pubDate>Wed, 04 Oct 2023 18:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.06082v2</guid></item><item><title>High-dimensional SGD aligns with emerging outlier eigenspaces</title><link>http://arxiv.org/abs/2310.03010v1</link><description>We rigorously study the joint evolution of training dynamics via stochasticgradient descent (SGD) and the spectra of empirical Hessian and gradientmatrices. We prove that in two canonical classification tasks for multi-classhigh-dimensional mixtures and either 1 or 2-layer neural networks, the SGDtrajectory rapidly aligns with emerging low-rank outlier eigenspaces of theHessian and gradient matrices. Moreover, in multi-layer settings this alignmentoccurs per layer, with the final layer's outlier eigenspace evolving over thecourse of training, and exhibiting rank deficiency when the SGD converges tosub-optimal classifiers. This establishes some of the rich predictions thathave arisen from extensive numerical studies in the last decade about thespectra of Hessian and information matrices over the course of training inoverparametrized networks.</description><author>Gerard Ben Arous, Reza Gheissari, Jiaoyang Huang, Aukosh Jagannath</author><pubDate>Wed, 04 Oct 2023 18:53:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03010v1</guid></item><item><title>LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples</title><link>http://arxiv.org/abs/2310.01469v2</link><description>Large Language Models (LLMs), including GPT-3.5, LLaMA, and PaLM, seem to beknowledgeable and able to adapt to many tasks. However, we still can notcompletely trust their answer, since LLMs suffer fromhallucination--fabricating non-existent facts to cheat users withoutperception. And the reasons for their existence and pervasiveness remainunclear. In this paper, we demonstrate that non-sense prompts composed ofrandom tokens can also elicit the LLMs to respond with hallucinations. Thisphenomenon forces us to revisit that hallucination may be another view ofadversarial examples, and it shares similar features with conventionaladversarial examples as the basic feature of LLMs. Therefore, we formalize anautomatic hallucination triggering method as the hallucination attack in anadversarial way. Finally, we explore basic feature of attacked adversarialprompts and propose a simple yet effective defense strategy. Our code isreleased on GitHub.</description><author>Jia-Yu Yao, Kun-Peng Ning, Zhen-Hui Liu, Mu-Nan Ning, Li Yuan</author><pubDate>Wed, 04 Oct 2023 18:53:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01469v2</guid></item><item><title>Towards Domain-Specific Features Disentanglement for Domain Generalization</title><link>http://arxiv.org/abs/2310.03007v1</link><description>Distributional shift between domains poses great challenges to modern machinelearning algorithms. The domain generalization (DG) signifies a popular linetargeting this issue, where these methods intend to uncover universal patternsacross disparate distributions. Noted, the crucial challenge behind DG is theexistence of irrelevant domain features, and most prior works overlook thisinformation. Motivated by this, we propose a novel contrastive-baseddisentanglement method CDDG, to effectively utilize the disentangled featuresto exploit the over-looked domain-specific features, and thus facilitating theextraction of the desired cross-domain category features for DG tasks.Specifically, CDDG learns to decouple inherent mutually exclusive features byleveraging them in the latent space, thus making the learning discriminative.Extensive experiments conducted on various benchmark datasets demonstrate thesuperiority of our method compared to other state-of-the-art approaches.Furthermore, visualization evaluations confirm the potential of our method inachieving effective feature disentanglement.</description><author>Hao Chen, Qi Zhang, Zenan Huang, Haobo Wang, Junbo Zhao</author><pubDate>Wed, 04 Oct 2023 18:51:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03007v1</guid></item><item><title>COOLer: Class-Incremental Learning for Appearance-Based Multiple Object Tracking</title><link>http://arxiv.org/abs/2310.03006v1</link><description>Continual learning allows a model to learn multiple tasks sequentially whileretaining the old knowledge without the training data of the preceding tasks.This paper extends the scope of continual learning research toclass-incremental learning for \ac{mot}, which is desirable to accommodate thecontinuously evolving needs of autonomous systems. Previous solutions forcontinual learning of object detectors do not address the data associationstage of appearance-based trackers, leading to catastrophic forgetting ofprevious classes' re-identification features. We introduce COOLer, aCOntrastive- and cOntinual-Learning-based tracker, which incrementally learnsto track new categories while preserving past knowledge by training on acombination of currently available ground truth labels and pseudo-labelsgenerated by the past tracker. To further exacerbate the disentanglement ofinstance representations, we introduce a novel contrastive class-incrementalinstance representation learning technique. Finally, we propose a practicalevaluation protocol for continual learning for MOT and conduct experiments onthe \bdd and \shift datasets. Experimental results demonstrate that COOLercontinually learns while effectively addressing catastrophic forgetting of bothtracking and detection. The code is available at\url{https://github.com/BoSmallEar/COOLer}.</description><author>Zhizheng Liu, Mattia Segu, Fisher Yu</author><pubDate>Wed, 04 Oct 2023 18:49:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03006v1</guid></item><item><title>Reversing Deep Face Embeddings with Probable Privacy Protection</title><link>http://arxiv.org/abs/2310.03005v1</link><description>Generally, privacy-enhancing face recognition systems are designed to offerpermanent protection of face embeddings. Recently, so-called soft-biometricprivacy-enhancement approaches have been introduced with the aim of cancelingsoft-biometric attributes. These methods limit the amount of soft-biometricinformation (gender or skin-colour) that can be inferred from face embeddings.Previous work has underlined the need for research into rigorous evaluationsand standardised evaluation protocols when assessing privacy protectioncapabilities. Motivated by this fact, this paper explores to what extent thenon-invertibility requirement can be met by methods that claim to providesoft-biometric privacy protection. Additionally, a detailed vulnerabilityassessment of state-of-the-art face embedding extractors is analysed in termsof the transformation complexity used for privacy protection. In this context,a well-known state-of-the-art face image reconstruction approach has beenevaluated on protected face embeddings to break soft biometric privacyprotection. Experimental results show that biometric privacy-enhanced faceembeddings can be reconstructed with an accuracy of up to approximately 98%,depending on the complexity of the protection algorithm.</description><author>Daile Osorio-Roig, Paul A. Gerlitz, Christian Rathgeb, Christoph Busch</author><pubDate>Wed, 04 Oct 2023 18:48:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03005v1</guid></item><item><title>Soft Convex Quantization: Revisiting Vector Quantization with Convex Optimization</title><link>http://arxiv.org/abs/2310.03004v1</link><description>Vector Quantization (VQ) is a well-known technique in deep learning forextracting informative discrete latent representations. VQ-embedded models haveshown impressive results in a range of applications including image and speechgeneration. VQ operates as a parametric K-means algorithm that quantizes inputsusing a single codebook vector in the forward pass. While powerful, thistechnique faces practical challenges including codebook collapse,non-differentiability and lossy compression. To mitigate the aforementionedissues, we propose Soft Convex Quantization (SCQ) as a direct substitute forVQ. SCQ works like a differentiable convex optimization (DCO) layer: in theforward pass, we solve for the optimal convex combination of codebook vectorsthat quantize the inputs. In the backward pass, we leverage differentiabilitythrough the optimality conditions of the forward solution. We then introduce ascalable relaxation of the SCQ optimization and demonstrate its efficacy on theCIFAR-10, GTSRB and LSUN datasets. We train powerful SCQ autoencoder modelsthat significantly outperform matched VQ-based architectures, observing anorder of magnitude better image reconstruction and codebook usage withcomparable quantization runtime.</description><author>Tanmay Gautam, Reid Pryzant, Ziyi Yang, Chenguang Zhu, Somayeh Sojoudi</author><pubDate>Wed, 04 Oct 2023 18:45:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03004v1</guid></item><item><title>Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models</title><link>http://arxiv.org/abs/2305.14585v2</link><description>A recent trend in explainable AI research has focused on surrogate modeling,where neural networks are approximated as simpler ML algorithms such as kernelmachines. A second trend has been to utilize kernel functions in variousexplain-by-example or data attribution tasks to investigate a diverse set ofneural network behavior. In this work, we combine these two trends to analyzeapproximate empirical neural tangent kernels (eNTK) for data attribution.Approximation is critical for eNTK analysis due to the high computational costto compute the eNTK. We define new approximate eNTK and perform novel analysison how well the resulting kernel machine surrogate models correlate with theunderlying neural network. We introduce two new random projection variants ofapproximate eNTK which allow users to tune the time and memory complexity oftheir calculation. We conclude that kernel machines using approximate neuraltangent kernel as the kernel function are effective surrogate models, with theintroduced trace NTK the most consistent performer.</description><author>Andrew Engel, Zhichao Wang, Natalie S. Frank, Ioana Dumitriu, Sutanay Choudhury, Anand Sarwate, Tony Chiang</author><pubDate>Wed, 04 Oct 2023 18:44:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14585v2</guid></item><item><title>From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference</title><link>http://arxiv.org/abs/2310.03003v1</link><description>Large language models (LLMs) have exploded in popularity due to their newgenerative capabilities that go far beyond prior state-of-the-art. Thesetechnologies are increasingly being leveraged in various domains such as law,finance, and medicine. However, these models carry significant computationalchallenges, especially the compute and energy costs required for inference.Inference energy costs already receive less attention than the energy costs oftraining LLMs -- despite how often these large models are called on to conductinference in reality (e.g., ChatGPT). As these state-of-the-art LLMs seeincreasing usage and deployment in various domains, a better understanding oftheir resource utilization is crucial for cost-savings, scaling performance,efficient hardware usage, and optimal inference strategies. In this paper, we describe experiments conducted to study the computationaland energy utilization of inference with LLMs. We benchmark and conduct apreliminary analysis of the inference performance and inference energy costs ofdifferent sizes of LLaMA -- a recent state-of-the-art LLM -- developed by MetaAI on two generations of popular GPUs (NVIDIA V100 \&amp; A100) and two datasets(Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs inresearch and practice. We present the results of multi-node, multi-GPUinference using model sharding across up to 32 GPUs. To our knowledge, our workis the one of the first to study LLM inference performance from the perspectiveof computational and energy resources at this scale.</description><author>Siddharth Samsi, Dan Zhao, Joseph McDonald, Baolin Li, Adam Michaleas, Michael Jones, William Bergeron, Jeremy Kepner, Devesh Tiwari, Vijay Gadepally</author><pubDate>Wed, 04 Oct 2023 18:41:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03003v1</guid></item><item><title>Learning characteristic parameters and dynamics of centrifugal pumps under multi-phase flow using physics-informed neural networks</title><link>http://arxiv.org/abs/2310.03001v1</link><description>Electrical submersible pumps (ESP) are the second most used artificiallifting equipment in the oil and gas industry due to their high flow rates andboost pressures. They often have to handle multiphase flows, which usuallycontain a mixture of hydrocarbons, water, and/or sediments. Given thesecircumstances, emulsions are commonly formed. It is a liquid-liquid flowcomposed of two immiscible fluids whose effective viscosity and density differfrom the single phase separately. In this context, accurate modeling of ESPsystems is crucial for optimizing oil production and implementing controlstrategies. However, real-time and direct measurement of fluid and systemcharacteristics is often impractical due to time constraints and economy.Hence, indirect methods are generally considered to estimate the systemparameters. In this paper, we formulate a machine learning model based onPhysics-Informed Neural Networks (PINNs) to estimate crucial system parameters.In order to study the efficacy of the proposed PINN model, we conductcomputational studies using not only simulated but also experimental data fordifferent water-oil ratios. We evaluate the state variable's dynamics andunknown parameters for various combinations when only intake and dischargepressure measurements are available. We also study structural and practicalidentifiability analyses based on commonly available pressure measurements. ThePINN model could reduce the requirement of expensive field laboratory testsused to estimate fluid properties.</description><author>Felipe de Castro Teixeira Carvalho, Kamaljyoti Nath, Alberto Luiz Serpa, George Em Karniadakis</author><pubDate>Wed, 04 Oct 2023 18:40:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03001v1</guid></item><item><title>ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models</title><link>http://arxiv.org/abs/2310.02998v1</link><description>Large Vision-Language Models (LVLMs) can understand the world comprehensivelyby integrating rich information from different modalities, achieving remarkableperformance improvements on various multimodal downstream tasks. However,deploying LVLMs is often problematic due to their massive computational/energycosts and carbon consumption. Such issues make it infeasible to adoptconventional iterative global pruning, which is costly due to computing theHessian matrix of the entire large model for sparsification. Alternatively,several studies have recently proposed layer-wise pruning approaches to avoidthe expensive computation of global pruning and efficiently compress modelweights according to their importance within a layer. However, these methodsoften suffer from suboptimal model compression due to their lack of a globalperspective. To address this limitation in recent efficient pruning methods forlarge models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP),a two-stage coarse-to-fine weight pruning approach for LVLMs. We firstdetermine the sparsity ratios of different layers or blocks by leveraging theglobal importance score, which is efficiently computed based on thezeroth-order approximation of the global model gradients. Then, the multimodalmodel performs local layer-wise unstructured weight pruning based onglobally-informed sparsity ratios. We validate our proposed method acrossvarious multimodal and unimodal models and datasets, demonstrating significantperformance improvements over prevalent pruning techniques in the high-sparsityregime.</description><author>Yi-Lin Sung, Jaehong Yoon, Mohit Bansal</author><pubDate>Wed, 04 Oct 2023 18:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02998v1</guid></item><item><title>Optimizing Key-Selection for Face-based One-Time Biometrics via Morphing</title><link>http://arxiv.org/abs/2310.02997v1</link><description>Nowadays, facial recognition systems are still vulnerable to adversarialattacks. These attacks vary from simple perturbations of the input image tomodifying the parameters of the recognition model to impersonate an authorisedsubject. So-called privacy-enhancing facial recognition systems have beenmostly developed to provide protection of stored biometric reference data, i.e.templates. In the literature, privacy-enhancing facial recognition approacheshave focused solely on conventional security threats at the template level,ignoring the growing concern related to adversarial attacks. Up to now, fewworks have provided mechanisms to protect face recognition against adversarialattacks while maintaining high security at the template level. In this paper,we propose different key selection strategies to improve the security of acompetitive cancelable scheme operating at the signal level. Experimentalresults show that certain strategies based on signal-level key selection canlead to complete blocking of the adversarial attack based on an iterativeoptimization for the most secure threshold, while for the most practicalthreshold, the attack success chance can be decreased to approximately 5.0%.</description><author>Daile Osorio-Roig, Mahdi Ghafourian, Christian Rathgeb, Ruben Vera-Rodriguez, Christoph Busch, Julian Fierrez</author><pubDate>Wed, 04 Oct 2023 18:32:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02997v1</guid></item><item><title>IBCL: Zero-shot Model Generation for Task Trade-offs in Continual Learning</title><link>http://arxiv.org/abs/2310.02995v1</link><description>Like generic multi-task learning, continual learning has the nature ofmulti-objective optimization, and therefore faces a trade-off between theperformance of different tasks. That is, to optimize for the current taskdistribution, it may need to compromise performance on some previous tasks.This means that there exist multiple models that are Pareto-optimal atdifferent times, each addressing a distinct task performance trade-off.Researchers have discussed how to train particular models to address specifictrade-off preferences. However, existing algorithms require training overheadsproportional to the number of preferences -- a large burden when there aremultiple, possibly infinitely many, preferences. As a response, we proposeImprecise Bayesian Continual Learning (IBCL). Upon a new task, IBCL (1) updatesa knowledge base in the form of a convex hull of model parameter distributionsand (2) obtains particular models to address task trade-off preferences withzero-shot. That is, IBCL does not require any additional training overhead togenerate preference-addressing models from its knowledge base. We show thatmodels obtained by IBCL have guarantees in identifying the Pareto optimalparameters. Moreover, experiments on standard image classification and NLPtasks support this guarantee. Statistically, IBCL improves average per-taskaccuracy by at most 23\% and peak per-task accuracy by at most 15\% withrespect to the baseline methods, with steadily near-zero or positive backwardtransfer. Most importantly, IBCL significantly reduces the training overheadfrom training 1 model per preference to at most 3 models for all preferences.</description><author>Pengyuan Lu, Michele Caprio, Eric Eaton, Insup Lee</author><pubDate>Wed, 04 Oct 2023 18:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02995v1</guid></item><item><title>Multiple Physics Pretraining for Physical Surrogate Models</title><link>http://arxiv.org/abs/2310.02994v1</link><description>We introduce multiple physics pretraining (MPP), an autoregressivetask-agnostic pretraining approach for physical surrogate modeling. MPPinvolves training large surrogate models to predict the dynamics of multipleheterogeneous physical systems simultaneously by learning features that arebroadly useful across diverse physical tasks. In order to learn effectively inthis setting, we introduce a shared embedding and normalization strategy thatprojects the fields of multiple systems into a single shared embedding space.We validate the efficacy of our approach on both pretraining and downstreamtasks over a broad fluid mechanics-oriented benchmark. We show that a singleMPP-pretrained transformer is able to match or outperform task-specificbaselines on all pretraining sub-tasks without the need for finetuning. Fordownstream tasks, we demonstrate that finetuning MPP-trained models results inmore accurate predictions across multiple time-steps on new physics compared totraining from scratch or finetuning pretrained video foundation models. Weopen-source our code and model weights trained at multiple scales forreproducibility and community experimentation.</description><author>Michael McCabe, Bruno Régaldo-Saint Blancard, Liam Holden Parker, Ruben Ohana, Miles Cranmer, Alberto Bietti, Michael Eickenberg, Siavash Golkar, Geraud Krawezik, Francois Lanusse, Mariel Pettee, Tiberiu Tesileanu, Kyunghyun Cho, Shirley Ho</author><pubDate>Wed, 04 Oct 2023 18:29:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02994v1</guid></item><item><title>Kosmos-G: Generating Images in Context with Multimodal Large Language Models</title><link>http://arxiv.org/abs/2310.02992v1</link><description>Recent advancements in text-to-image (T2I) and vision-language-to-image(VL2I) generation have made significant strides. However, the generation fromgeneralized vision-language inputs, especially involving multiple images,remains under-explored. This paper presents Kosmos-G, a model that leveragesthe advanced perception capabilities of Multimodal Large Language Models(MLLMs) to tackle the aforementioned challenge. Our approach aligns the outputspace of MLLM with CLIP using the textual modality as an anchor and performscompositional instruction tuning on curated data. Kosmos-G demonstrates aunique capability of zero-shot multi-entity subject-driven generation. Notably,the score distillation instruction tuning requires no modifications to theimage decoder. This allows for a seamless substitution of CLIP and effortlessintegration with a myriad of U-Net techniques ranging from fine-grainedcontrols to personalized image decoder variants. We posit Kosmos-G as aninitial attempt towards the goal of "image as a foreign language in imagegeneration."</description><author>Xichen Pan, Li Dong, Shaohan Huang, Zhiliang Peng, Wenhu Chen, Furu Wei</author><pubDate>Wed, 04 Oct 2023 18:28:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02992v1</guid></item><item><title>xVal: A Continuous Number Encoding for Large Language Models</title><link>http://arxiv.org/abs/2310.02989v1</link><description>Large Language Models have not yet been broadly adapted for the analysis ofscientific datasets due in part to the unique difficulties of tokenizingnumbers. We propose xVal, a numerical encoding scheme that represents any realnumber using just a single token. xVal represents a given real number byscaling a dedicated embedding vector by the number value. Combined with amodified number-inference approach, this strategy renders the model end-to-endcontinuous when considered as a map from the numbers of the input string tothose of the output string. This leads to an inductive bias that is generallymore suitable for applications in scientific domains. We empirically evaluateour proposal on a number of synthetic and real-world datasets. Compared withexisting number encoding schemes, we find that xVal is more token-efficient anddemonstrates improved generalization.</description><author>Siavash Golkar, Mariel Pettee, Michael Eickenberg, Alberto Bietti, Miles Cranmer, Geraud Krawezik, Francois Lanusse, Michael McCabe, Ruben Ohana, Liam Parker, Bruno Régaldo-Saint Blancard, Tiberiu Tesileanu, Kyunghyun Cho, Shirley Ho</author><pubDate>Wed, 04 Oct 2023 18:26:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02989v1</guid></item><item><title>Probing Intersectional Biases in Vision-Language Models with Counterfactual Examples</title><link>http://arxiv.org/abs/2310.02988v1</link><description>While vision-language models (VLMs) have achieved remarkable performanceimprovements recently, there is growing evidence that these models also possesharmful biases with respect to social attributes such as gender and race. Priorstudies have primarily focused on probing such bias attributes individuallywhile ignoring biases associated with intersections between social attributes.This could be due to the difficulty of collecting an exhaustive set ofimage-text pairs for various combinations of social attributes from existingdatasets. To address this challenge, we employ text-to-image diffusion modelsto produce counterfactual examples for probing intserctional social biases atscale. Our approach utilizes Stable Diffusion with cross attention control toproduce sets of counterfactual image-text pairs that are highly similar intheir depiction of a subject (e.g., a given occupation) while differing only intheir depiction of intersectional social attributes (e.g., race &amp; gender). Weconduct extensive experiments using our generated dataset which reveal theintersectional social biases present in state-of-the-art VLMs.</description><author>Phillip Howard, Avinash Madasu, Tiep Le, Gustavo Lujan Moreno, Vasudev Lal</author><pubDate>Wed, 04 Oct 2023 18:25:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02988v1</guid></item><item><title>Variance Reduced Halpern Iteration for Finite-Sum Monotone Inclusions</title><link>http://arxiv.org/abs/2310.02987v1</link><description>Machine learning approaches relying on such criteria as adversarialrobustness or multi-agent settings have raised the need for solvinggame-theoretic equilibrium problems. Of particular relevance to theseapplications are methods targeting finite-sum structure, which genericallyarises in empirical variants of learning problems in these contexts. Further,methods with computable approximation errors are highly desirable, as theyprovide verifiable exit criteria. Motivated by these applications, we studyfinite-sum monotone inclusion problems, which model broad classes ofequilibrium problems. Our main contributions are variants of the classicalHalpern iteration that employ variance reduction to obtain improved complexityguarantees in which $n$ component operators in the finite sum are ``onaverage'' either cocoercive or Lipschitz continuous and monotone, withparameter $L$. The resulting oracle complexity of our methods, which provideguarantees for the last iterate and for a (computable) operator norm residual,is $\widetilde{\mathcal{O}}( n + \sqrt{n}L\varepsilon^{-1})$, which improvesupon existing methods by a factor up to $\sqrt{n}$. This constitutes the firstvariance reduction-type result for general finite-sum monotone inclusions andfor more specific problems such as convex-concave optimization when operatornorm residual is the optimality measure. We further argue that, up topoly-logarithmic factors, this complexity is unimprovable in the monotoneLipschitz setting; i.e., the provided result is near-optimal.</description><author>Xufeng Cai, Ahmet Alacaoglu, Jelena Diakonikolas</author><pubDate>Wed, 04 Oct 2023 18:24:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02987v1</guid></item><item><title>Exploring the Impact of Disrupted Peer-to-Peer Communications on Fully Decentralized Learning in Disaster Scenarios</title><link>http://arxiv.org/abs/2310.02986v1</link><description>Fully decentralized learning enables the distribution of learning resourcesand decision-making capabilities across multiple user devices or nodes, and israpidly gaining popularity due to its privacy-preserving and decentralizednature. Importantly, this crowdsourcing of the learning process allows thesystem to continue functioning even if some nodes are affected or disconnected.In a disaster scenario, communication infrastructure and centralized systemsmay be disrupted or completely unavailable, hindering the possibility ofcarrying out standard centralized learning tasks in these settings. Thus, fullydecentralized learning can help in this case. However, transitioning fromcentralized to peer-to-peer communications introduces a dependency between thelearning process and the topology of the communication graph among nodes. In adisaster scenario, even peer-to-peer communications are susceptible to abruptchanges, such as devices running out of battery or getting disconnected fromothers due to their position. In this study, we investigate the effects ofvarious disruptions to peer-to-peer communications on decentralized learning ina disaster setting. We examine the resilience of a decentralized learningprocess when a subset of devices drop from the process abruptly. To this end,we analyze the difference between losing devices holding data, i.e., potentialknowledge, vs. devices contributing only to the graph connectivity, i.e., withno data. Our findings on a Barabasi-Albert graph topology, where training datais distributed across nodes in an IID fashion, indicate that the accuracy ofthe learning process is more affected by a loss of connectivity than by a lossof data. Nevertheless, the network remains relatively robust, and the learningprocess can achieve a good level of accuracy.</description><author>Luigi Palmieri, Chiara Boldrini, Lorenzo Valerio, Andrea Passarella, Marco Conti</author><pubDate>Wed, 04 Oct 2023 18:24:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02986v1</guid></item><item><title>Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks</title><link>http://arxiv.org/abs/2310.02244v2</link><description>By classifying infinite-width neural networks and identifying the *optimal*limit, Tensor Programs IV and V demonstrated a universal way, called $\mu$P,for *widthwise hyperparameter transfer*, i.e., predicting optimalhyperparameters of wide neural networks from narrow ones. Here we investigatethe analogous classification for *depthwise parametrizations* of deep residualnetworks (resnets). We classify depthwise parametrizations of block multiplierand learning rate by their infinite-width-then-depth limits. In resnets whereeach block has only one layer, we identify a unique optimal parametrization,called Depth-$\mu$P that extends $\mu$P and show empirically it admitsdepthwise hyperparameter transfer. We identify *feature diversity* as a crucialfactor in deep networks, and Depth-$\mu$P can be characterized as maximizingboth feature learning and feature diversity. Exploiting this, we find thatabsolute value, among all homogeneous nonlinearities, maximizes featurediversity and indeed empirically leads to significantly better performance.However, if each block is deeper (such as modern transformers), then we findfundamental limitations in all possible infinite-depth limits of suchparametrizations, which we illustrate both theoretically and empirically onsimple networks as well as Megatron transformer trained on Common Crawl.</description><author>Greg Yang, Dingli Yu, Chen Zhu, Soufiane Hayou</author><pubDate>Wed, 04 Oct 2023 18:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02244v2</guid></item><item><title>Scaling Laws for Associative Memories</title><link>http://arxiv.org/abs/2310.02984v1</link><description>Learning arguably involves the discovery and memorization of abstract rules.The aim of this paper is to study associative memory mechanisms. Our model isbased on high-dimensional matrices consisting of outer products of embeddings,which relates to the inner layers of transformer language models. We deriveprecise scaling laws with respect to sample size and parameter size, anddiscuss the statistical efficiency of different estimators, includingoptimization-based algorithms. We provide extensive numerical experiments tovalidate and interpret theoretical results, including fine-grainedvisualizations of the stored memory associations.</description><author>Vivien Cabannes, Elvis Dohmatob, Alberto Bietti</author><pubDate>Wed, 04 Oct 2023 18:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02984v1</guid></item><item><title>Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors</title><link>http://arxiv.org/abs/2310.02980v1</link><description>Modeling long-range dependencies across sequences is a longstanding goal inmachine learning and has led to architectures, such as state space models, thatdramatically outperform Transformers on long sequences. However, theseimpressive empirical gains have been by and large demonstrated on benchmarks(e.g. Long Range Arena), where models are randomly initialized and trained topredict a target label from an input sequence. In this work, we show thatrandom initialization leads to gross overestimation of the differences betweenarchitectures and that pretraining with standard denoising objectives, using$\textit{only the downstream task data}$, leads to dramatic gains acrossmultiple architectures and to very small gaps between Transformers and statespace models (SSMs). In stark contrast to prior works, we find vanillaTransformers to match the performance of S4 on Long Range Arena when properlypretrained, and we improve the best reported results of SSMs on the PathX-256task by 20 absolute points. Subsequently, we analyze the utility ofpreviously-proposed structured parameterizations for SSMs and show they becomemostly redundant in the presence of data-driven initialization obtained throughpretraining. Our work shows that, when evaluating different architectures onsupervised tasks, incorporation of data-driven priors via pretraining isessential for reliable performance estimation, and can be done efficiently.</description><author>Ido Amos, Jonathan Berant, Ankit Gupta</author><pubDate>Wed, 04 Oct 2023 18:17:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02980v1</guid></item><item><title>T$^3$Bench: Benchmarking Current Progress in Text-to-3D Generation</title><link>http://arxiv.org/abs/2310.02977v1</link><description>Recent methods in text-to-3D leverage powerful pretrained diffusion models tooptimize NeRF. Notably, these methods are able to produce high-quality 3Dscenes without training on 3D data. Due to the open-ended nature of the task,most studies evaluate their results with subjective case studies and userexperiments, thereby presenting a challenge in quantitatively addressing thequestion: How has current progress in Text-to-3D gone so far? In this paper, weintroduce T$^3$Bench, the first comprehensive text-to-3D benchmark containingdiverse text prompts of three increasing complexity levels that are speciallydesigned for 3D generation. To assess both the subjective quality and the textalignment, we propose two automatic metrics based on multi-view images producedby the 3D contents. The quality metric combines multi-view text-image scoresand regional convolution to detect quality and view inconsistency. Thealignment metric uses multi-view captioning and Large Language Model (LLM)evaluation to measure text-3D consistency. Both metrics closely correlate withdifferent dimensions of human judgments, providing a paradigm for efficientlyevaluating text-to-3D models. The benchmarking results, shown in Fig. 1, revealperformance differences among six prevalent text-to-3D methods. Our analysisfurther highlights the common struggles for current methods on generatingsurroundings and multi-object scenes, as well as the bottleneck of leveraging2D guidance for 3D generation. Our project page is available at:https://t3bench.com.</description><author>Yuze He, Yushi Bai, Matthieu Lin, Wang Zhao, Yubin Hu, Jenny Sheng, Ran Yi, Juanzi Li, Yong-Jin Liu</author><pubDate>Wed, 04 Oct 2023 18:12:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02977v1</guid></item><item><title>Towards Fully Adaptive Regret Minimization in Heavy-Tailed Bandits</title><link>http://arxiv.org/abs/2310.02975v1</link><description>Heavy-tailed distributions naturally arise in many settings, from finance totelecommunications. While regret minimization under sub-Gaussian or boundedsupport rewards has been widely studied, learning on heavy-tailed distributionsonly gained popularity over the last decade. In the stochastic heavy-tailedbandit problem, an agent learns under the assumption that the distributionshave finite moments of maximum order $1+\epsilon$ which are uniformly boundedby a constant $u$, for some $\epsilon \in (0,1]$. To the best of our knowledge,literature only provides algorithms requiring these two quantities as an input.In this paper, we study the stochastic adaptive heavy-tailed bandit, avariation of the standard setting where both $\epsilon$ and $u$ are unknown tothe agent. We show that adaptivity comes at a cost, introducing two lowerbounds on the regret of any adaptive algorithm, implying a higher regret w.r.t.the standard setting. Finally, we introduce a specific distributionalassumption and provide Adaptive Robust UCB, a regret minimization strategymatching the known lower bound for the heavy-tailed MAB problem.</description><author>Gianmarco Genalti, Lupo Marsigli, Nicola Gatti, Alberto Maria Metelli</author><pubDate>Wed, 04 Oct 2023 18:11:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02975v1</guid></item><item><title>Private Ad Modeling with DP-SGD</title><link>http://arxiv.org/abs/2211.11896v3</link><description>A well-known algorithm in privacy-preserving ML is differentially privatestochastic gradient descent (DP-SGD). While this algorithm has been evaluatedon text and image data, it has not been previously applied to ads data, whichare notorious for their high class imbalance and sparse gradient updates. Inthis work we apply DP-SGD to several ad modeling tasks including predictingclick-through rates, conversion rates, and number of conversion events, andevaluate their privacy-utility trade-off on real-world datasets. Our work isthe first to empirically demonstrate that DP-SGD can provide both privacy andutility for ad modeling tasks.</description><author>Carson Denison, Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Krishna Giri Narra, Amer Sinha, Avinash V Varadarajan, Chiyuan Zhang</author><pubDate>Wed, 04 Oct 2023 18:10:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11896v3</guid></item><item><title>UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network</title><link>http://arxiv.org/abs/2310.02973v1</link><description>Recent studies have demonstrated promising outcomes by employing largelanguage models with multi-tasking capabilities. They utilize prompts to guidethe model's behavior and surpass performance of task-specific models. Motivatedby this, we ask: can we build a single model that jointly perform variousspoken language understanding (SLU) tasks? To address this, we utilizepre-trained automatic speech recognition (ASR) models and employ various taskand dataset specifiers as discrete prompts. We demonstrate efficacy of oursingle multi-task learning (MTL) model "UniverSLU" for 12 different speechclassification and sequence generation tasks across 17 datasets and 9languages. Results show that UniverSLU achieves competitive performance andeven surpasses task-specific models. We also conduct preliminary investigationsinto enabling human-interpretable natural phrases instead of task specifiers asdiscrete prompts and test the model's generalization capabilities to newparaphrases.</description><author>Siddhant Arora, Hayato Futami, Jee-weon Jung, Yifan Peng, Roshan Sharma, Yosuke Kashiwagi, Emiru Tsunoo, Shinji Watanabe</author><pubDate>Wed, 04 Oct 2023 18:10:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02973v1</guid></item><item><title>Fully Automatic Segmentation of Gross Target Volume and Organs-at-Risk for Radiotherapy Planning of Nasopharyngeal Carcinoma</title><link>http://arxiv.org/abs/2310.02972v1</link><description>Target segmentation in CT images of Head&amp;Neck (H&amp;N) region is challenging dueto low contrast between adjacent soft tissue. The SegRap 2023 challenge hasbeen focused on benchmarking the segmentation algorithms of NasopharyngealCarcinoma (NPC) which would be employed as auto-contouring tools for radiationtreatment planning purposes. We propose a fully-automatic framework and developtwo models for a) segmentation of 45 Organs at Risk (OARs) and b) two GrossTumor Volumes (GTVs). To this end, we preprocess the image volumes byharmonizing the intensity distributions and then automatically cropping thevolumes around the target regions. The preprocessed volumes were employed totrain a standard 3D U-Net model for each task, separately. Our method tooksecond place for each of the tasks in the validation phase of the challenge.The proposed framework is available at https://github.com/Astarakee/segrap2023</description><author>Mehdi Astaraki, Simone Bendazzoli, Iuliana Toma-Dasu</author><pubDate>Wed, 04 Oct 2023 18:10:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02972v1</guid></item><item><title>Prompting and Adapter Tuning for Self-supervised Encoder-Decoder Speech Model</title><link>http://arxiv.org/abs/2310.02971v1</link><description>Prompting and adapter tuning have emerged as efficient alternatives tofine-tuning (FT) methods. However, existing studies on speech prompting focusedon classification tasks and failed on more complex sequence generation tasks.Besides, adapter tuning is primarily applied with a focus on encoder-onlyself-supervised models. Our experiments show that prompting on Wav2Seq, aself-supervised encoder-decoder model, surpasses previous works in sequencegeneration tasks. It achieves a remarkable 53% relative improvement in worderror rate for ASR and a 27% in F1 score for slot filling. Additionally,prompting competes with the FT method in the low-resource scenario. Moreover,we show the transferability of prompting and adapter tuning on Wav2Seq incross-lingual ASR. When limited trainable parameters are involved, promptingand adapter tuning consistently outperform conventional FT across 7 languages.Notably, in the low-resource scenario, prompting consistently outperformsadapter tuning.</description><author>Kai-Wei Chang, Ming-Hsin Chen, Yun-Ping Lin, Jing Neng Hsu, Paul Kuo-Ming Huang, Chien-yu Huang, Shang-Wen Li, Hung-yi Lee</author><pubDate>Wed, 04 Oct 2023 18:07:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02971v1</guid></item><item><title>Fast, Expressive SE$(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space</title><link>http://arxiv.org/abs/2310.02970v1</link><description>Based on the theory of homogeneous spaces we derive \textit{geometricallyoptimal edge attributes} to be used within the flexible message passingframework. We formalize the notion of weight sharing in convolutional networksas the sharing of message functions over point-pairs that should be treatedequally. We define equivalence classes of point-pairs that are identical up toa transformation in the group and derive attributes that uniquely identifythese classes. Weight sharing is then obtained by conditioning messagefunctions on these attributes. As an application of the theory, we develop anefficient equivariant group convolutional network for processing 3D pointclouds. The theory of homogeneous spaces tells us how to do group convolutionswith feature maps over the homogeneous space of positions $\mathbb{R}^3$,position and orientations $\mathbb{R}^3 {\times} S^2$, and the group SE$(3)$itself. Among these, $\mathbb{R}^3 {\times} S^2$ is an optimal choice due tothe ability to represent directional information, which $\mathbb{R}^3$ methodscannot, and it significantly enhances computational efficiency compared toindexing features on the full SE$(3)$ group. We empirically support this claimby reaching state-of-the-art results -- in accuracy and speed -- on threedifferent benchmarks: interatomic potential energy prediction, trajectoryforecasting in N-body systems, and generating molecules via equivariantdiffusion models.</description><author>Erik J Bekkers, Sharvaree Vadgama, Rob D Hesselink, Putri A van der Linden, David W Romero</author><pubDate>Wed, 04 Oct 2023 18:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02970v1</guid></item><item><title>Dual Conic Proxies for AC Optimal Power Flow</title><link>http://arxiv.org/abs/2310.02969v1</link><description>In recent years, there has been significant interest in the development ofmachine learning-based optimization proxies for AC Optimal Power Flow (AC-OPF).Although significant progress has been achieved in predicting high-qualityprimal solutions, no existing learning-based approach can provide valid dualbounds for AC-OPF. This paper addresses this gap by training optimizationproxies for a convex relaxation of AC-OPF. Namely, the paper considers asecond-order cone (SOC) relaxation of ACOPF, and proposes a novel dualarchitecture that embeds a fast, differentiable (dual) feasibility recovery,thus providing valid dual bounds. The paper combines this new architecture witha self-supervised learning scheme, which alleviates the need for costlytraining data generation. Extensive numerical experiments on medium- andlarge-scale power grids demonstrate the efficiency and scalability of theproposed methodology.</description><author>Guancheng Qiu, Mathieu Tanneau, Pascal Van Hentenryck</author><pubDate>Wed, 04 Oct 2023 18:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02969v1</guid></item><item><title>Co-modeling the Sequential and Graphical Route for Peptide</title><link>http://arxiv.org/abs/2310.02964v1</link><description>Peptides are formed by the dehydration condensation of multiple amino acids.The primary structure of a peptide can be represented either as an amino acidsequence or as a molecular graph consisting of atoms and chemical bonds.Previous studies have indicated that deep learning routes specific tosequential and graphical peptide forms exhibit comparable performance ondownstream tasks. Despite the fact that these models learn representations ofthe same modality of peptides, we find that they explain their predictionsdifferently. Considering sequential and graphical models as two experts makinginferences from different perspectives, we work on fusing expert knowledge toenrich the learned representations for improving the discriminativeperformance. To achieve this, we propose a peptide co-modeling method, RepCon,which employs a contrastive learning-based framework to enhance the mutualinformation of representations from decoupled sequential and graphicalend-to-end models. It considers representations from the sequential encoder andthe graphical encoder for the same peptide sample as a positive pair and learnsto enhance the consistency of representations between positive sample pairs andto repel representations between negative pairs. Empirical studies of RepConand other co-modeling methods are conducted on open-source discriminativedatasets, including aggregation propensity, retention time, antimicrobialpeptide prediction, and family classification from Peptide Database. Ourresults demonstrate the superiority of the co-modeling approach overindependent modeling, as well as the superiority of RepCon over other methodsunder the co-modeling framework. In addition, the attribution on RepCon furthercorroborates the validity of the approach at the level of model explanation.</description><author>Zihan Liu, Ge Wang, Jiaqi Wang, Jiangbin Zheng, Stan Z. Li</author><pubDate>Wed, 04 Oct 2023 17:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02964v1</guid></item><item><title>DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models</title><link>http://arxiv.org/abs/2309.14509v2</link><description>Computation in a typical Transformer-based large language model (LLM) can becharacterized by batch size, hidden dimension, number of layers, and sequencelength. Until now, system works for accelerating LLM training have focused onthe first three dimensions: data parallelism for batch size, tensor parallelismfor hidden size and pipeline parallelism for model depth or layers. Thesewidely studied forms of parallelism are not targeted or optimized for longsequence Transformer models. Given practical application needs for longsequence LLM, renewed attentions are being drawn to sequence parallelism.However, existing works in sequence parallelism are constrained bymemory-communication inefficiency, limiting their scalability to long sequencelarge models. In this work, we introduce DeepSpeed-Ulysses, a novel, portableand effective methodology for enabling highly efficient and scalable LLMtraining with extremely long sequence length. DeepSpeed-Ulysses at its corepartitions input data along the sequence dimension and employs an efficientall-to-all collective communication for attention computation. Theoreticalcommunication analysis shows that whereas other methods incur communicationoverhead as sequence length increases, DeepSpeed-Ulysses maintains constantcommunication volume when sequence length and compute devices are increasedproportionally. Furthermore, experimental evaluations show thatDeepSpeed-Ulysses trains 2.5x faster with 4x longer sequence length than theexisting method SOTA baseline.</description><author>Sam Ade Jacobs, Masahiro Tanaka, Chengming Zhang, Minjia Zhang, Shuaiwen Leon Song, Samyam Rajbhandari, Yuxiong He</author><pubDate>Wed, 04 Oct 2023 17:51:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14509v2</guid></item><item><title>CoDA: Collaborative Novel Box Discovery and Cross-modal Alignment for Open-vocabulary 3D Object Detection</title><link>http://arxiv.org/abs/2310.02960v1</link><description>Open-vocabulary 3D Object Detection (OV-3DDet) aims to detect objects from anarbitrary list of categories within a 3D scene, which remains seldom exploredin the literature. There are primarily two fundamental problems in OV-3DDet,i.e., localizing and classifying novel objects. This paper aims at addressingthe two problems simultaneously via a unified framework, under the condition oflimited base categories. To localize novel 3D objects, we propose an effective3D Novel Object Discovery strategy, which utilizes both the 3D box geometrypriors and 2D semantic open-vocabulary priors to generate pseudo box labels ofthe novel objects. To classify novel object boxes, we further develop across-modal alignment module based on discovered novel boxes, to align featurespaces between 3D point cloud and image/text modalities. Specifically, thealignment process contains a class-agnostic and a class-discriminativealignment, incorporating not only the base objects with annotations but alsothe increasingly discovered novel objects, resulting in an iteratively enhancedalignment. The novel box discovery and crossmodal alignment are jointly learnedto collaboratively benefit each other. The novel object discovery can directlyimpact the cross-modal alignment, while a better feature alignment can, inturn, boost the localization capability, leading to a unified OV-3DDetframework, named CoDA, for simultaneous novel object localization andclassification. Extensive experiments on two challenging datasets (i.e.,SUN-RGBD and ScanNet) demonstrate the effectiveness of our method and also showa significant mAP improvement upon the best-performing alternative method by80%. Codes and pre-trained models are released on the project page.</description><author>Yang Cao, Yihan Zeng, Hang Xu, Dan Xu</author><pubDate>Wed, 04 Oct 2023 17:50:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02960v1</guid></item><item><title>Credit card score prediction using machine learning models: A new dataset</title><link>http://arxiv.org/abs/2310.02956v1</link><description>The use of credit cards has recently increased, creating an essential needfor credit card assessment methods to minimize potential risks. This studyinvestigates the utilization of machine learning (ML) models for credit carddefault prediction system. The main goal here is to investigate thebest-performing ML model for new proposed credit card scoring dataset. This newdataset includes credit card transaction histories and customer profiles, isproposed and tested using a variety of machine learning algorithms, includinglogistic regression, decision trees, random forests, multi layer perceptron(MLP) neural network, XGBoost, and LightGBM. To prepare the data for machinelearning models, we perform data pre-proccessing, feature extraction, featureselection, and data balancing techniques. Experimental results demonstrate thatMLP outperforms logistic regression, decision trees, random forests, LightGBM,and XGBoost in terms of predictive performance in true positive rate, achievingan impressive area under the curve (AUC) of 86.7% and an accuracy rate of91.6%, with a recall rate exceeding 80%. These results indicate the superiorityof MLP in predicting the default customers and assessing the potential risks.Furthermore, they help banks and other financial institutions in predictingloan defaults at an earlier stage.</description><author>Anas Arram, Masri Ayob, Musatafa Abbas Abbood Albadr, Alaa Sulaiman, Dheeb Albashish</author><pubDate>Wed, 04 Oct 2023 17:46:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02956v1</guid></item><item><title>DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning</title><link>http://arxiv.org/abs/2310.02954v1</link><description>Recent advances in natural language processing, primarily propelled by LargeLanguage Models (LLMs), have showcased their remarkable capabilities groundedin in-context learning. A promising avenue for guiding LLMs in intricatereasoning tasks involves the utilization of intermediate reasoning steps withinthe Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge liesin the effective selection of exemplars for facilitating in-context learning.In this study, we introduce a framework that leverages Dual Queries andLow-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplarsfor in-context learning. Dual Queries first query LLM to obtain LLM-generatedknowledge such as CoT, then query the retriever to obtain the final exemplarsvia both question and the knowledge. Moreover, for the second query, LoReemploys dimensionality reduction techniques to refine exemplar selection,ensuring close alignment with the input question's knowledge. Through extensiveexperiments, we demonstrate that DQ-LoRe significantly outperforms priorstate-of-the-art methods in the automatic selection of exemplars for GPT-4,enhancing performance from 92.5\% to 94.2\%. Our comprehensive analysis furtherreveals that DQ-LoRe consistently outperforms retrieval-based approaches interms of both performance and adaptability, especially in scenarioscharacterized by distribution shifts. DQ-LoRe pushes the boundaries ofin-context learning and opens up new avenues for addressing complex reasoningchallenges. We will release the code soon.</description><author>Jiong Xiong, Zixuan Li, Chuanyang Zheng, Zhijiang Guo, Yichun Yin, Enze Xie, Zhicheng Yang, Qingxing Cao, Haiming Wang, Xiongwei Han, Jing Tang, Chengming Li, Xiaodan Liang</author><pubDate>Wed, 04 Oct 2023 17:44:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02954v1</guid></item><item><title>JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning</title><link>http://arxiv.org/abs/2310.02953v1</link><description>Instruction tuning has emerged as a crucial process for harnessing thecapabilities of large language models (LLMs) by providing explicit taskinstructions, leading to improved performance in various tasks. However,prevalent text-to-text instruction tuning (TextTuning) methods suffer fromlimitations in generalization, robustness, and controllability due to theambiguity and lack of explicit structure in tasks. In this paper, we proposeJsonTuning, a novel structure-to-structure approach for instruction tuning. Byleveraging the versatility and structured nature of JSON to represent tasks,JsonTuning enhances generalization by helping the model understand essentialtask elements and their relations, improves robustness by minimizing ambiguity,and increases controllability by providing explicit control over the output. Weconduct a comprehensive comparative study with diverse language models andevaluation benchmarks. Experimental results show that JsonTuning outperformsTextTuning in various applications, showcasing improved performance,adaptability, robustness, and controllability. By overcoming the limitations ofTextTuning, JsonTuning demonstrates significant potential for more effectiveand reliable LLMs capable of handling diverse scenarios.</description><author>Chang Gao, Wenxuan Zhang, Guizhen Chen, Wai Lam</author><pubDate>Wed, 04 Oct 2023 17:44:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02953v1</guid></item><item><title>A Fisher-Rao gradient flow for entropy-regularised Markov decision processes in Polish spaces</title><link>http://arxiv.org/abs/2310.02951v1</link><description>We study the global convergence of a Fisher-Rao policy gradient flow forinfinite-horizon entropy-regularised Markov decision processes with Polishstate and action space. The flow is a continuous-time analogue of a policymirror descent method. We establish the global well-posedness of the gradientflow and demonstrate its exponential convergence to the optimal policy.Moreover, we prove the flow is stable with respect to gradient evaluation,offering insights into the performance of a natural policy gradient flow withlog-linear policy parameterisation. To overcome challenges stemming from thelack of the convexity of the objective function and the discontinuity arisingfrom the entropy regulariser, we leverage the performance difference lemma andthe duality relationship between the gradient and mirror descent flows.</description><author>Bekzhan Kerimkulov, James-Michael Leahy, David Siska, Lukasz Szpruch, Yufei Zhang</author><pubDate>Wed, 04 Oct 2023 17:41:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02951v1</guid></item><item><title>Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models</title><link>http://arxiv.org/abs/2310.02949v1</link><description>Warning: This paper contains examples of harmful language, and readerdiscretion is recommended. The increasing open release of powerful largelanguage models (LLMs) has facilitated the development of downstreamapplications by reducing the essential cost of data annotation and computation.To ensure AI safety, extensive safety-alignment measures have been conducted toarmor these models against malicious use (primarily hard prompt attack).However, beneath the seemingly resilient facade of the armor, there might lurka shadow. By simply tuning on 100 malicious examples with 1 GPU hour, thesesafely aligned LLMs can be easily subverted to generate harmful content.Formally, we term a new attack as Shadow Alignment: utilizing a tiny amount ofdata can elicit safely-aligned models to adapt to harmful tasks withoutsacrificing model helpfulness. Remarkably, the subverted models retain theircapability to respond appropriately to regular inquiries. Experiments across 8models released by 5 different organizations (LLaMa-2, Falcon, InternLM,BaiChuan2, Vicuna) demonstrate the effectiveness of shadow alignment attack.Besides, the single-turn English-only attack successfully transfers tomulti-turn dialogue and other languages. This study serves as a clarion callfor a collective effort to overhaul and fortify the safety of open-source LLMsagainst malicious attackers.</description><author>Xianjun Yang, Xiao Wang, Qi Zhang, Linda Petzold, William Yang Wang, Xun Zhao, Dahua Lin</author><pubDate>Wed, 04 Oct 2023 17:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02949v1</guid></item><item><title>HappyFeat -- An interactive and efficient BCI framework for clinical applications</title><link>http://arxiv.org/abs/2310.02948v1</link><description>Brain-Computer Interface (BCI) systems allow users to perform actions bytranslating their brain activity into commands. Such systems usually need atraining phase, consisting in training a classification algorithm todiscriminate between mental states using specific features from the recordedsignals. This phase of feature selection and training is crucial for BCIperformance and presents specific constraints to be met in a clinical context,such as post-stroke rehabilitation. In this paper, we present HappyFeat, a software making Motor Imagery (MI)based BCI experiments easier, by gathering all necessary manipulations andanalysis in a single convenient GUI and via automation of experiment oranalysis parameters. The resulting workflow allows for effortlessly selectingthe best features, helping to achieve good BCI performance in time-constrainedenvironments. Alternative features based on Functional Connectivity can be usedand compared or combined with Power Spectral Density, allowing anetwork-oriented approach. We then give details of HappyFeat's main mechanisms, and a review of itsperformances in typical use cases. We also show that it can be used as anefficient tool for comparing different metrics extracted from the signals, totrain the classification algorithm. To this end, we show a comparison betweenthe commonly-used Power Spectral Density and network metrics based onFunctional Connectivity. HappyFeat is available as an open-source project which can be freelydownloaded on GitHub.</description><author>Arthur Desbois, Tristan Venot, Fabrizio De Vico Fallani, Marie-Constance Corsi</author><pubDate>Wed, 04 Oct 2023 17:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02948v1</guid></item><item><title>DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text</title><link>http://arxiv.org/abs/2305.17359v2</link><description>Large language models (LLMs) have notably enhanced the fluency and diversityof machine-generated text. However, this progress also presents a significantchallenge in detecting the origin of a given text, and current research ondetection methods lags behind the rapid evolution of LLMs. Conventionaltraining-based methods have limitations in flexibility, particularly whenadapting to new domains, and they often lack explanatory power. To address thisgap, we propose a novel training-free detection strategy called DivergentN-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle andthen use only the preceding portion as input to the LLMs to regenerate the newremaining parts. By analyzing the differences between the original and newremaining parts through N-gram analysis in black-box or probability divergencein white-box, we unveil significant discrepancies between the distribution ofmachine-generated text and the distribution of human-written text. We conductedextensive experiments on the most advanced LLMs from OpenAI, includingtext-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models suchas GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approachexhibits state-of-the-art performance in distinguishing between human andGPT-generated text on four English and one German dataset, outperformingOpenAI's own classifier, which is trained on millions of text. Additionally,our methods provide reasonable explanations and evidence to support our claim,which is a unique feature of explainable detection. Our method is also robustunder the revised text attack and can additionally solve model sourcing. Codesare available at https://github.com/Xianjun-Yang/DNA-GPT.</description><author>Xianjun Yang, Wei Cheng, Yue Wu, Linda Petzold, William Yang Wang, Haifeng Chen</author><pubDate>Wed, 04 Oct 2023 17:36:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17359v2</guid></item><item><title>Structural Adversarial Objectives for Self-Supervised Representation Learning</title><link>http://arxiv.org/abs/2310.00357v2</link><description>Within the framework of generative adversarial networks (GANs), we proposeobjectives that task the discriminator for self-supervised representationlearning via additional structural modeling responsibilities. In combinationwith an efficient smoothness regularizer imposed on the network, theseobjectives guide the discriminator to learn to extract informativerepresentations, while maintaining a generator capable of sampling from thedomain. Specifically, our objectives encourage the discriminator to structurefeatures at two levels of granularity: aligning distribution characteristics,such as mean and variance, at coarse scales, and grouping features into localclusters at finer scales. Operating as a feature learner within the GANframework frees our self-supervised system from the reliance on hand-crafteddata augmentation schemes that are prevalent across contrastive representationlearning methods. Across CIFAR-10/100 and an ImageNet subset, experimentsdemonstrate that equipping GANs with our self-supervised objectives suffices toproduce discriminators which, evaluated in terms of representation learning,compete with networks trained by contrastive learning approaches.</description><author>Xiao Zhang, Michael Maire</author><pubDate>Wed, 04 Oct 2023 17:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00357v2</guid></item><item><title>Local Max-Entropy and Free Energy Principles, Belief Diffusions and their Singularities</title><link>http://arxiv.org/abs/2310.02946v1</link><description>A comprehensive picture of three Bethe-Kikuchi variational principlesincluding their relationship to belief propagation (BP) algorithms onhypergraphs is given. The structure of BP equations is generalized to definecontinuous-time diffusions, solving localized versions of the max-entropyprinciple (A), the variational free energy principle (B), and a less usualequilibrium free energy principle (C), Legendre dual to A. Both critical pointsof Bethe-Kikuchi functionals and stationary beliefs are shown to lie at thenon-linear intersection of two constraint surfaces, enforcing energyconservation and marginal consistency respectively. The hypersurface ofsingular beliefs, accross which equilibria become unstable as the constraintsurfaces meet tangentially, is described by polynomial equations in the convexpolytope of consistent beliefs. This polynomial is expressed by a loop seriesexpansion for graphs of binary variables.</description><author>Olivier Peltre</author><pubDate>Wed, 04 Oct 2023 17:32:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02946v1</guid></item><item><title>Trajectory balance: Improved credit assignment in GFlowNets</title><link>http://arxiv.org/abs/2201.13259v3</link><description>Generative flow networks (GFlowNets) are a method for learning a stochasticpolicy for generating compositional objects, such as graphs or strings, from agiven unnormalized density by sequences of actions, where many possible actionsequences may lead to the same object. We find previously proposed learningobjectives for GFlowNets, flow matching and detailed balance, which areanalogous to temporal difference learning, to be prone to inefficient creditpropagation across long action sequences. We thus propose a new learningobjective for GFlowNets, trajectory balance, as a more efficient alternative topreviously used objectives. We prove that any global minimizer of thetrajectory balance objective can define a policy that samples exactly from thetarget distribution. In experiments on four distinct domains, we empiricallydemonstrate the benefits of the trajectory balance objective for GFlowNetconvergence, diversity of generated samples, and robustness to long actionsequences and large action spaces.</description><author>Nikolay Malkin, Moksh Jain, Emmanuel Bengio, Chen Sun, Yoshua Bengio</author><pubDate>Wed, 04 Oct 2023 17:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.13259v3</guid></item><item><title>Bayesian low-rank adaptation for large language models</title><link>http://arxiv.org/abs/2308.13111v3</link><description>Low-rank adaptation (LoRA) has emerged as a new paradigm for cost-efficientfine-tuning of large language models (LLMs). However, fine-tuned LLMs oftenbecome overconfident especially when fine-tuned on small datasets. Bayesianmethods, with their inherent ability to estimate uncertainty, serve as potenttools to mitigate overconfidence and enhance calibration. In this work, weintroduce Laplace-LoRA, which applies a Bayesian approach to the LoRAparameters. Specifically, Laplace-LoRA applies a Laplace approximation to theposterior over the LoRA parameters, considerably improving the calibration offine-tuned LLMs.</description><author>Adam X. Yang, Maxime Robeyns, Xi Wang, Laurence Aitchison</author><pubDate>Wed, 04 Oct 2023 17:29:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13111v3</guid></item><item><title>Time-Series Forecasting: Unleashing Long-Term Dependencies with Fractionally Differenced Data</title><link>http://arxiv.org/abs/2309.13409v2</link><description>This study introduces a novel forecasting strategy that leverages the powerof fractional differencing (FD) to capture both short- and long-termdependencies in time series data. Unlike traditional integer differencingmethods, FD preserves memory in series while stabilizing it for modelingpurposes. By applying FD to financial data from the SPY index and incorporatingsentiment analysis from news reports, this empirical analysis explores theeffectiveness of FD in conjunction with binary classification of targetvariables. Supervised classification algorithms were employed to validate theperformance of FD series. The results demonstrate the superiority of FD overinteger differencing, as confirmed by Receiver Operating Characteristic/AreaUnder the Curve (ROCAUC) and Mathews Correlation Coefficient (MCC) evaluations.</description><author>Sarit Maitra, Vivek Mishra, Srashti Dwivedi, Sukanya Kundu, Goutam Kumar Kundu</author><pubDate>Wed, 04 Oct 2023 17:28:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13409v2</guid></item><item><title>Use Perturbations when Learning from Explanations</title><link>http://arxiv.org/abs/2303.06419v2</link><description>Machine learning from explanations (MLX) is an approach to learning that useshuman-provided explanations of relevant or irrelevant features for each inputto ensure that model predictions are right for the right reasons. Existing MLXapproaches rely on local model interpretation methods and require strong modelsmoothing to align model and human explanations, leading to sub-optimalperformance. We recast MLX as a robustness problem, where human explanationsspecify a lower dimensional manifold from which perturbations can be drawn, andshow both theoretically and empirically how this approach alleviates the needfor strong model smoothing. We consider various approaches to achievingrobustness, leading to improved performance over prior MLX methods. Finally, weshow how to combine robustness with an earlier MLX method, yieldingstate-of-the-art results on both synthetic and real-world benchmarks.</description><author>Juyeon Heo, Vihari Piratla, Matthew Wicker, Adrian Weller</author><pubDate>Wed, 04 Oct 2023 17:24:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06419v2</guid></item><item><title>Adaptive Landmark Color for AUV Docking in Visually Dynamic Environments</title><link>http://arxiv.org/abs/2310.02944v1</link><description>Autonomous Underwater Vehicles (AUVs) conduct missions underwater without theneed for human intervention. A docking station (DS) can extend mission times ofan AUV by providing a location for the AUV to recharge its batteries andreceive updated mission information. Various methods for locating and trackinga DS exist, but most rely on expensive acoustic sensors, or are vision-based,which is significantly affected by water quality. In this \doctype, we presenta vision-based method that utilizes adaptive color LED markers and dynamiccolor filtering to maximize landmark visibility in varying water conditions.Both AUV and DS utilize cameras to determine the water background color inorder to calculate the desired marker color. No communication between AUV andDS is needed to determine marker color. Experiments conducted in a pool andlake show our method performs 10 times better than static color thresholdingmethods as background color varies. DS detection is possible at a range of 5meters in clear water with minimal false positives.</description><author>Corey Knutson, Zhipeng Cao, Junaed Sattar</author><pubDate>Wed, 04 Oct 2023 17:24:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02944v1</guid></item><item><title>LibriSpeech-PC: Benchmark for Evaluation of Punctuation and Capitalization Capabilities of end-to-end ASR Models</title><link>http://arxiv.org/abs/2310.02943v1</link><description>Traditional automatic speech recognition (ASR) models output lower-casedwords without punctuation marks, which reduces readability and necessitates asubsequent text processing model to convert ASR transcripts into a properformat. Simultaneously, the development of end-to-end ASR models capable ofpredicting punctuation and capitalization presents several challenges,primarily due to limited data availability and shortcomings in the existingevaluation methods, such as inadequate assessment of punctuation prediction. Inthis paper, we introduce a LibriSpeech-PC benchmark designed to assess thepunctuation and capitalization prediction capabilities of end-to-end ASRmodels. The benchmark includes a LibriSpeech-PC dataset with restoredpunctuation and capitalization, a novel evaluation metric called PunctuationError Rate (PER) that focuses on punctuation marks, and initial baselinemodels. All code, data, and models are publicly available.</description><author>Aleksandr Meister, Matvei Novikov, Nikolay Karpov, Evelina Bakhturina, Vitaly Lavrukhin, Boris Ginsburg</author><pubDate>Wed, 04 Oct 2023 17:23:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02943v1</guid></item><item><title>Online Constraint Tightening in Stochastic Model Predictive Control: A Regression Approach</title><link>http://arxiv.org/abs/2310.02942v1</link><description>Solving chance-constrained stochastic optimal control problems is asignificant challenge in control. This is because no analytical solutions existfor up to a handful of special cases. A common and computationally efficientapproach for tackling chance-constrained stochastic optimal control problemsconsists of reformulating the chance constraints as hard constraints with aconstraint-tightening parameter. However, in such approaches, the choice ofconstraint-tightening parameter remains challenging, and guarantees can mostlybe obtained assuming that the process noise distribution is known a priori.Moreover, the chance constraints are often not tightly satisfied, leading tounnecessarily high costs. This work proposes a data-driven approach forlearning the constraint-tightening parameters online during control. To thisend, we reformulate the choice of constraint-tightening parameter for theclosed-loop as a binary regression problem. We then leverage a highlyexpressive \gls{gp} model for binary regression to approximate the smallestconstraint-tightening parameters that satisfy the chance constraints. By tuningthe algorithm parameters appropriately, we show that the resultingconstraint-tightening parameters satisfy the chance constraints up to anarbitrarily small margin with high probability. Our approach yieldsconstraint-tightening parameters that tightly satisfy the chance constraints innumerical experiments, resulting in a lower average cost than three otherstate-of-the-art approaches.</description><author>Alexandre Capone, Tim Brüdigam, Sandra Hirche</author><pubDate>Wed, 04 Oct 2023 17:22:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02942v1</guid></item><item><title>Hoeffding's Inequality for Markov Chains under Generalized Concentrability Condition</title><link>http://arxiv.org/abs/2310.02941v1</link><description>This paper studies Hoeffding's inequality for Markov chains under thegeneralized concentrability condition defined via integral probability metric(IPM). The generalized concentrability condition establishes a framework thatinterpolates and extends the existing hypotheses of Markov chain Hoeffding-typeinequalities. The flexibility of our framework allows Hoeffding's inequality tobe applied beyond the ergodic Markov chains in the traditional sense. Wedemonstrate the utility by applying our framework to several non-asymptoticanalyses arising from the field of machine learning, including (i) ageneralization bound for empirical risk minimization with Markovian samples,(ii) a finite sample guarantee for Ployak-Ruppert averaging of SGD, and (iii) anew regret bound for rested Markovian bandits with general state space.</description><author>Hao Chen, Abhishek Gupta, Yin Sun, Ness Shroff</author><pubDate>Wed, 04 Oct 2023 17:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02941v1</guid></item><item><title>Image-based Navigation in Real-World Environments via Multiple Mid-level Representations: Fusion Models, Benchmark and Efficient Evaluation</title><link>http://arxiv.org/abs/2202.01069v2</link><description>Navigating complex indoor environments requires a deep understanding of thespace the robotic agent is acting into to correctly inform the navigationprocess of the agent towards the goal location. In recent learning-basednavigation approaches, the scene understanding and navigation abilities of theagent are achieved simultaneously by collecting the required experience insimulation. Unfortunately, even if simulators represent an efficient tool totrain navigation policies, the resulting models often fail when transferredinto the real world. One possible solution is to provide the navigation modelwith mid-level visual representations containing important domain-invariantproperties of the scene. But, what are the best representations that facilitatethe transfer of a model to the real-world? How can they be combined? In thiswork we address these issues by proposing a benchmark of Deep Learningarchitectures to combine a range of mid-level visual representations, toperform a PointGoal navigation task following a Reinforcement Learning setup.All the proposed navigation models have been trained with the Habitat simulatoron a synthetic office environment and have been tested on the same real-worldenvironment using a real robotic platform. To efficiently assess theirperformance in a real context, a validation tool has been proposed to generaterealistic navigation episodes inside the simulator. Our experiments showed thatnavigation models can benefit from the multi-modal input and that ourvalidation tool can provide good estimation of the expected navigationperformance in the real world, while saving time and resources. The acquiredsynthetic and real 3D models of the environment, together with the code of ourvalidation tool built on top of Habitat, are publicly available at thefollowing link: https://iplab.dmi.unict.it/EmbodiedVN/</description><author>Marco Rosano, Antonino Furnari, Luigi Gulino, Corrado Santoro, Giovanni Maria Farinella</author><pubDate>Wed, 04 Oct 2023 17:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.01069v2</guid></item><item><title>Assessing Large Language Models on Climate Information</title><link>http://arxiv.org/abs/2310.02932v1</link><description>Understanding how climate change affects us and learning about availablesolutions are key steps toward empowering individuals and communities tomitigate and adapt to it. As Large Language Models (LLMs) rise in popularity,it is necessary to assess their capability in this domain. In this study, wepresent a comprehensive evaluation framework, grounded in science communicationprinciples, to analyze LLM responses to climate change topics. Our frameworkemphasizes both the presentational and epistemological adequacy of answers,offering a fine-grained analysis of LLM generations. Spanning 8 dimensions, ourframework discerns up to 30 distinct issues in model outputs. The task is areal-world example of a growing number of challenging problems where AI cancomplement and lift human performance. We introduce a novel and practicalprotocol for scalable oversight that uses AI Assistance and relies on raterswith relevant educational backgrounds. We evaluate several recent LLMs andconduct a comprehensive analysis of the results, shedding light on both thepotential and the limitations of LLMs in the realm of climate communication.</description><author>Jannis Bulian, Mike S. Schäfer, Afra Amini, Heidi Lam, Massimiliano Ciaramita, Ben Gaiarin, Michelle Chen Huebscher, Christian Buck, Niels Mede, Markus Leippold, Nadine Strauss</author><pubDate>Wed, 04 Oct 2023 17:09:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02932v1</guid></item><item><title>Graph data modelling for outcome prediction in oropharyngeal cancer patients</title><link>http://arxiv.org/abs/2310.02931v1</link><description>Graph neural networks (GNNs) are becoming increasingly popular in the medicaldomain for the tasks of disease classification and outcome prediction. Sincepatient data is not readily available as a graph, most existing methods eithermanually define a patient graph, or learn a latent graph based on pairwisesimilarities between the patients. There are also hypergraph neural network(HGNN)-based methods that were introduced recently to exploit potential higherorder associations between the patients by representing them as a hypergraph.In this work, we propose a patient hypergraph network (PHGN), which has beeninvestigated in an inductive learning setup for binary outcome prediction inoropharyngeal cancer (OPC) patients using computed tomography (CT)-basedradiomic features for the first time. Additionally, the proposed model wasextended to perform time-to-event analyses, and compared with GNN and baselinelinear models.</description><author>Nithya Bhasker, Stefan Leger, Alexander Zwanenburg, Chethan Babu Reddy, Sebastian Bodenstedt, Steffen Löck, Stefanie Speidel</author><pubDate>Wed, 04 Oct 2023 17:09:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02931v1</guid></item><item><title>Optimal Transport with Adaptive Regularisation</title><link>http://arxiv.org/abs/2310.02925v1</link><description>Regularising the primal formulation of optimal transport (OT) with a strictlyconvex term leads to enhanced numerical complexity and a denser transport plan.Many formulations impose a global constraint on the transport plan, forinstance by relying on entropic regularisation. As it is more expensive todiffuse mass for outlier points compared to central ones, this typicallyresults in a significant imbalance in the way mass is spread across the points.This can be detrimental for some applications where a minimum of smoothing isrequired per point. To remedy this, we introduce OT with AdaptiveRegularIsation (OTARI), a new formulation of OT that imposes constraints on themass going in or/and out of each point. We then showcase the benefits of thisapproach for domain adaptation.</description><author>Hugues Van Assel, Titouan Vayer, Remi Flamary, Nicolas Courty</author><pubDate>Wed, 04 Oct 2023 17:05:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02925v1</guid></item><item><title>Enhancing Ayurvedic Diagnosis using Multinomial Naive Bayes and K-modes Clustering: An Investigation into Prakriti Types and Dosha Overlapping</title><link>http://arxiv.org/abs/2310.02920v1</link><description>The identification of Prakriti types for the human body is a long-lostmedical practice in finding the harmony between the nature of human beings andtheir behaviour. There are 3 fundamental Prakriti types of individuals. Aperson can belong to any Dosha. In the existing models, researchers have madeuse of SVM, KNN, PCA, Decision Tree, and various other algorithms. The outputof these algorithms was quite decent, but it can be enhanced with the help ofMultinomial Naive Bayes and K-modes clustering. Most of the researchers haveconfined themselves to 3 basic classes. This might not be accurate in thereal-world scenario, where overlapping might occur. Considering these, we haveclassified the Doshas into 7 categories, which includes overlapping of Doshas.These are namely, VATT-Dosha, PITT-Dosha, KAPH-Dosha, VATT-PITT-Dosha,PITT-KAPH-Dosha, KAPH-VATT-Dosha, and VATT-PITT-KAPH-Dosha. The data usedcontains a balanced set of all individual entries on which preprocessing stepsof machine learning have been performed. Chi-Square test for handlingcategorical data is being used for feature selection. For model fitting, themethod used in this approach is K-modes clustering. The empirical resultsdemonstrate a better result while using the MNB classifier. All key findings ofthis work have achieved 0.90 accuracy, 0.81 precision, 0.91 F-score, and 0.90recall. The discussion suggests a provident analysis of the seven clusters andpredicts their occurrence. The results have been consolidated to improve theAyurvedic advancements with machine learning.</description><author>Pranav Bidve, Shalini Mishra, Annapurna J</author><pubDate>Wed, 04 Oct 2023 17:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02920v1</guid></item><item><title>Attention-based Multi-task Learning for Base Editor Outcome Prediction</title><link>http://arxiv.org/abs/2310.02919v1</link><description>Human genetic diseases often arise from point mutations, emphasizing thecritical need for precise genome editing techniques. Among these, base editingstands out as it allows targeted alterations at the single nucleotide level.However, its clinical application is hindered by low editing efficiency andunintended mutations, necessitating extensive trial-and-error experimentationin the laboratory. To speed up this process, we present an attention-basedtwo-stage machine learning model that learns to predict the likelihood of allpossible editing outcomes for a given genomic target sequence. We furtherpropose a multi-task learning schema to jointly learn multiple base editors(i.e. variants) at once. Our model's predictions consistently demonstrated astrong correlation with the actual experimental results on multiple datasetsand base editor variants. These results provide further validation for themodels' capacity to enhance and accelerate the process of refining base editingdesigns.</description><author>Amina Mollaysa, Ahmed Allam, Michael Krauthammer</author><pubDate>Wed, 04 Oct 2023 17:01:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02919v1</guid></item><item><title>Learning-Aided Warmstart of Model Predictive Control in Uncertain Fast-Changing Traffic</title><link>http://arxiv.org/abs/2310.02918v1</link><description>Model Predictive Control lacks the ability to escape local minima innonconvex problems. Furthermore, in fast-changing, uncertain environments, theconventional warmstart, using the optimal trajectory from the last timestep,often falls short of providing an adequately close initial guess for thecurrent optimal trajectory. This can potentially result in convergence failuresand safety issues. Therefore, this paper proposes a framework forlearning-aided warmstarts of Model Predictive Control algorithms. Our methodleverages a neural network based multimodal predictor to generate multipletrajectory proposals for the autonomous vehicle, which are further refined by asampling-based technique. This combined approach enables us to identifymultiple distinct local minima and provide an improved initial guess. Wevalidate our approach with Monte Carlo simulations of traffic scenarios.</description><author>Mohamed-Khalil Bouzidi, Yue Yao, Daniel Goehring, Joerg Reichardt</author><pubDate>Wed, 04 Oct 2023 17:00:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02918v1</guid></item><item><title>Module-wise Training of Neural Networks via the Minimizing Movement Scheme</title><link>http://arxiv.org/abs/2309.17357v2</link><description>Greedy layer-wise or module-wise training of neural networks is compelling inconstrained and on-device settings where memory is limited, as it circumvents anumber of problems of end-to-end back-propagation. However, it suffers from astagnation problem, whereby early layers overfit and deeper layers stopincreasing the test accuracy after a certain depth. We propose to solve thisissue by introducing a module-wise regularization inspired by the minimizingmovement scheme for gradient flows in distribution space. We call the methodTRGL for Transport Regularized Greedy Learning and study it theoretically,proving that it leads to greedy modules that are regular and that progressivelysolve the task. Experimentally, we show improved accuracy of module-wisetraining of various architectures such as ResNets, Transformers and VGG, whenour regularization is added, superior to that of other module-wise trainingmethods and often to end-to-end training, with as much as 60% less memoryusage.</description><author>Skander Karkar, Ibrahim Ayed, Emmanuel de Bézenac, Patrick Gallinari</author><pubDate>Wed, 04 Oct 2023 16:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17357v2</guid></item><item><title>Improved Probabilistic Image-Text Representations</title><link>http://arxiv.org/abs/2305.18171v2</link><description>Image-Text Matching (ITM) task, a fundamental vision-language (VL) task,suffers from the inherent ambiguity arising from multiplicity and imperfectannotations. Deterministic functions are not sufficiently powerful to captureambiguity, prompting the exploration of probabilistic embeddings to tackle thechallenge. However, the existing probabilistic ITM approach encounters two keyshortcomings; the burden of heavy computations due to the Monte Carloapproximation, and the loss saturation issue in the face of abundant falsenegatives. To overcome the issues, this paper presents an improvedProbabilistic Cross-Modal Embeddings (named PCME++) by introducing a newprobabilistic distance with a closed-form solution. In addition, twooptimization techniques are proposed to enhance PCME++ further; first, theincorporation of pseudo-positives to prevent the loss saturation problem undermassive false negatives; second, mixed sample data augmentation forprobabilistic matching. Experimental results on MS-COCO Caption and twoextended benchmarks, CxC and ECCV Caption, demonstrate the effectiveness ofPCME++ compared to state-of-the-art ITM methods. The robustness of PCME++ isalso evaluated under noisy image-text correspondences. In addition, thepotential applicability of PCME++ in automatic prompt tuning for zero-shotclassification is shown. The code is available athttps://naver-ai.github.io/pcmepp/.</description><author>Sanghyuk Chun</author><pubDate>Wed, 04 Oct 2023 16:55:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18171v2</guid></item><item><title>CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion</title><link>http://arxiv.org/abs/2303.11916v2</link><description>This paper proposes a novel diffusion-based model, CompoDiff, for solvingComposed Image Retrieval (CIR) with latent diffusion and presents a newlycreated dataset, named SynthTriplets18M, of 18 million reference images,conditions, and corresponding target image triplets to train the model.CompoDiff and SynthTriplets18M tackle the shortages of the previous CIRapproaches, such as poor generalizability due to the small dataset scale andthe limited types of conditions. CompoDiff not only achieves a new zero-shotstate-of-the-art on four CIR benchmarks, including FashionIQ, CIRR, CIRCO, andGeneCIS, but also enables a more versatile and controllable CIR by acceptingvarious conditions, such as negative text and image mask conditions, and thecontrollability to the importance between multiple queries or the trade-offbetween inference speed and the performance which are unavailable with existingCIR methods. The code and dataset are available athttps://github.com/navervision/CompoDiff</description><author>Geonmo Gu, Sanghyuk Chun, Wonjae Kim, HeeJae Jun, Yoohoon Kang, Sangdoo Yun</author><pubDate>Wed, 04 Oct 2023 16:54:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11916v2</guid></item><item><title>ELUQuant: Event-Level Uncertainty Quantification in Deep Inelastic Scattering</title><link>http://arxiv.org/abs/2310.02913v1</link><description>We introduce a physics-informed Bayesian Neural Network (BNN) with flowapproximated posteriors using multiplicative normalizing flows (MNF) fordetailed uncertainty quantification (UQ) at the physics event-level. Our methodis capable of identifying both heteroskedastic aleatoric and epistemicuncertainties, providing granular physical insights. Applied to Deep InelasticScattering (DIS) events, our model effectively extracts the kinematic variables$x$, $Q^2$, and $y$, matching the performance of recent deep learningregression techniques but with the critical enhancement of event-level UQ. Thisdetailed description of the underlying uncertainty proves invaluable fordecision-making, especially in tasks like event filtering. It also allows forthe reduction of true inaccuracies without directly accessing the ground truth.A thorough DIS simulation using the H1 detector at HERA indicates possibleapplications for the future EIC. Additionally, this paves the way for relatedtasks such as data quality monitoring and anomaly detection. Remarkably, ourapproach effectively processes large samples at high rates.</description><author>Cristiano Fanelli, James Giroux</author><pubDate>Wed, 04 Oct 2023 16:50:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02913v1</guid></item><item><title>Robustified ANNs Reveal Wormholes Between Human Category Percepts</title><link>http://arxiv.org/abs/2308.06887v2</link><description>The visual object category reports of artificial neural networks (ANNs) arenotoriously sensitive to tiny, adversarial image perturbations. Because humancategory reports (aka human percepts) are thought to be insensitive to thosesame small-norm perturbations -- and locally stable in general -- this arguesthat ANNs are incomplete scientific models of human visual perception.Consistent with this, we show that when small-norm image perturbations aregenerated by standard ANN models, human object category percepts are indeedhighly stable. However, in this very same "human-presumed-stable" regime, wefind that robustified ANNs reliably discover low-norm image perturbations thatstrongly disrupt human percepts. These previously undetectable human perceptualdisruptions are massive in amplitude, approaching the same level of sensitivityseen in robustified ANNs. Further, we show that robustified ANNs supportprecise perceptual state interventions: they guide the construction of low-normimage perturbations that strongly alter human category percepts toward specificprescribed percepts. These observations suggest that for arbitrary startingpoints in image space, there exists a set of nearby "wormholes", each leadingthe subject from their current category perceptual state into a semanticallyvery different state. Moreover, contemporary ANN models of biological visualprocessing are now accurate enough to consistently guide us to those portals.</description><author>Guy Gaziv, Michael J. Lee, James J. DiCarlo</author><pubDate>Wed, 04 Oct 2023 16:45:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06887v2</guid></item><item><title>Boosting Dermatoscopic Lesion Segmentation via Diffusion Models with Visual and Textual Prompts</title><link>http://arxiv.org/abs/2310.02906v1</link><description>Image synthesis approaches, e.g., generative adversarial networks, have beenpopular as a form of data augmentation in medical image analysis tasks. It isprimarily beneficial to overcome the shortage of publicly accessible data andassociated quality annotations. However, the current techniques often lackcontrol over the detailed contents in generated images, e.g., the type ofdisease patterns, the location of lesions, and attributes of the diagnosis. Inthis work, we adapt the latest advance in the generative model, i.e., thediffusion model, with the added control flow using lesion-specific visual andtextual prompts for generating dermatoscopic images. We further demonstrate theadvantage of our diffusion model-based framework over the classical generationmodels in both the image quality and boosting the segmentation performance onskin lesions. It can achieve a 9% increase in the SSIM image quality measureand an over 5% increase in Dice coefficients over the prior arts.</description><author>Shiyi Du, Xiaosong Wang, Yongyi Lu, Yuyin Zhou, Shaoting Zhang, Alan Yuille, Kang Li, Zongwei Zhou</author><pubDate>Wed, 04 Oct 2023 16:43:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02906v1</guid></item><item><title>Spline-based neural network interatomic potentials: blending classical and machine learning models</title><link>http://arxiv.org/abs/2310.02904v1</link><description>While machine learning (ML) interatomic potentials (IPs) are able to achieveaccuracies nearing the level of noise inherent in the first-principles data towhich they are trained, it remains to be shown if their increased complexitiesare strictly necessary for constructing high-quality IPs. In this work, weintroduce a new MLIP framework which blends the simplicity of spline-based MEAM(s-MEAM) potentials with the flexibility of a neural network (NN) architecture.The proposed framework, which we call the spline-based neural network potential(s-NNP), is a simplified version of the traditional NNP that can be used todescribe complex datasets in a computationally efficient manner. We demonstratehow this framework can be used to probe the boundary between classical and MLIPs, highlighting the benefits of key architectural changes. Furthermore, weshow that using spline filters for encoding atomic environments results in areadily interpreted embedding layer which can be coupled with modifications tothe NN to incorporate expected physical behaviors and improve overallinterpretability. Finally, we test the flexibility of the spline filters,observing that they can be shared across multiple chemical systems in order toprovide a convenient reference point from which to begin performingcross-system analyses.</description><author>Joshua A. Vita, Dallas R. Trinkle</author><pubDate>Wed, 04 Oct 2023 16:42:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02904v1</guid></item><item><title>FroSSL: Frobenius Norm Minimization for Self-Supervised Learning</title><link>http://arxiv.org/abs/2310.02903v1</link><description>Self-supervised learning (SSL) is an increasingly popular paradigm forrepresentation learning. Recent methods can be classified assample-contrastive, dimension-contrastive, or asymmetric network-based, witheach family having its own approach to avoiding informational collapse. Whiledimension-contrastive methods converge to similar solutions assample-contrastive methods, it can be empirically shown that some methodsrequire more epochs of training to converge. Motivated by closing this divide,we present the objective function FroSSL which is both sample- anddimension-contrastive up to embedding normalization. FroSSL works by minimizingcovariance Frobenius norms for avoiding collapse and minimizing mean-squarederror for augmentation invariance. We show that FroSSL converges more quicklythan a variety of other SSL methods and provide theoretical and empiricalsupport that this faster convergence is due to how FroSSL affects theeigenvalues of the embedding covariance matrices. We also show that FroSSLlearns competitive representations on linear probe evaluation when used totrain a ResNet18 on the CIFAR-10, CIFAR-100, STL-10, and ImageNet datasets.</description><author>Oscar Skean, Aayush Dhakal, Nathan Jacobs, Luis Gonzalo Sanchez Giraldo</author><pubDate>Wed, 04 Oct 2023 16:42:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02903v1</guid></item><item><title>Searching for High-Value Molecules Using Reinforcement Learning and Transformers</title><link>http://arxiv.org/abs/2310.02902v1</link><description>Reinforcement learning (RL) over text representations can be effective forfinding high-value policies that can search over graphs. However, RL requirescareful structuring of the search space and algorithm design to be effective inthis challenge. Through extensive experiments, we explore how different designchoices for text grammar and algorithmic choices for training can affect an RLpolicy's ability to generate molecules with desired properties. We arrive at anew RL-based molecular design algorithm (ChemRLformer) and perform a thoroughanalysis using 25 molecule design tasks, including computationally complexprotein docking simulations. From this analysis, we discover unique insights inthis problem space and show that ChemRLformer achieves state-of-the-artperformance while being more straightforward than prior work by demystifyingwhich design choices are actually helpful for text-based molecule design.</description><author>Raj Ghugare, Santiago Miret, Adriana Hugessen, Mariano Phielipp, Glen Berseth</author><pubDate>Wed, 04 Oct 2023 16:40:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02902v1</guid></item><item><title>Computationally Efficient Quadratic Neural Networks</title><link>http://arxiv.org/abs/2310.02901v1</link><description>Higher order artificial neurons whose outputs are computed by applying anactivation function to a higher order multinomial function of the inputs havebeen considered in the past, but did not gain acceptance due to the extraparameters and computational cost. However, higher order neurons havesignificantly greater learning capabilities since the decision boundaries ofhigher order neurons can be complex surfaces instead of just hyperplanes. Theboundary of a single quadratic neuron can be a general hyper-quadric surfaceallowing it to learn many nonlinearly separable datasets. Since quadratic formscan be represented by symmetric matrices, only $\frac{n(n+1)}{2}$ additionalparameters are needed instead of $n^2$. A quadratic Logistic regression modelis first presented. Solutions to the XOR problem with a single quadratic neuronare considered. The complete vectorized equations for both forward and backwardpropagation in feedforward networks composed of quadratic neurons are derived.A reduced parameter quadratic neural network model with just $ n $ additionalparameters per neuron that provides a compromise between learning ability andcomputational cost is presented. Comparison on benchmark classificationdatasets are used to demonstrate that a final layer of quadratic neuronsenables networks to achieve higher accuracy with significantly fewer hiddenlayer neurons. In particular this paper shows that any dataset composed of $C$bounded clusters can be separated with only a single layer of $C$ quadraticneurons.</description><author>Mathew Mithra Noel, Venkataraman Muthiah-Nakarajan</author><pubDate>Wed, 04 Oct 2023 16:39:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02901v1</guid></item><item><title>Recovery of Training Data from Overparameterized Autoencoders: An Inverse Problem Perspective</title><link>http://arxiv.org/abs/2310.02897v1</link><description>We study the recovery of training data from overparameterized autoencodermodels. Given a degraded training sample, we define the recovery of theoriginal sample as an inverse problem and formulate it as an optimization task.In our inverse problem, we use the trained autoencoder to implicitly define aregularizer for the particular training dataset that we aim to retrieve from.We develop the intricate optimization task into a practical method thatiteratively applies the trained autoencoder and relatively simple computationsthat estimate and address the unknown degradation operator. We evaluate ourmethod for blind inpainting where the goal is to recover training images fromdegradation of many missing pixels in an unknown pattern. We examine variousdeep autoencoder architectures, such as fully connected and U-Net (with variousnonlinearities and at diverse train loss values), and show that our methodsignificantly outperforms previous methods for training data recovery fromautoencoders. Importantly, our method greatly improves the recovery performancealso in settings that were previously considered highly challenging, and evenimpractical, for such retrieval.</description><author>Koren Abitbul, Yehuda Dar</author><pubDate>Wed, 04 Oct 2023 16:36:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02897v1</guid></item><item><title>Notes on a Path to AI Assistance in Mathematical Reasoning</title><link>http://arxiv.org/abs/2310.02896v1</link><description>These informal notes are based on the author's lecture at the NationalAcademies of Science, Engineering, and Mathematics workshop on "AI to AssistMathematical Reasoning" in June 2023. The goal is to think through a path bywhich we might arrive at AI that is useful for the research mathematician.</description><author>Alex Kontorovich</author><pubDate>Wed, 04 Oct 2023 16:35:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02896v1</guid></item><item><title>ValiTex -- a unified validation framework for computational text-based measures of social science constructs</title><link>http://arxiv.org/abs/2307.02863v4</link><description>Guidance on how to validate computational text-based measures of socialscience constructs is fragmented. While scholars generally acknowledge theimportance of validating their text-based measures, they often lack commonterminology and a unified framework to do so. This paper introduces ValiTex, anew validation framework designed to assist scholars in validly measuringsocial science constructs based on textual data. ValiTex prescribes researchersto demonstrate three types of validity evidence: substantive evidence(outlining the theoretical underpinning of the measure), structural evidence(examining the properties of the text model and its output), and externalevidence (testing for how the measure relates to independent information). Inaddition to the framework, ValiTex offers valuable practical guidance through achecklist that is adaptable for different use cases. The checklist clearlydefines and outlines specific validation steps while also offering aknowledgeable evaluation of the importance of each validation step to establishvalidity. We demonstrate the utility of the framework by applying it to a usecase of detecting sexism from social media data.</description><author>Lukas Birkenmaier, Claudia Wagner, Clemens Lechner</author><pubDate>Wed, 04 Oct 2023 16:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02863v4</guid></item><item><title>CoLiDE: Concomitant Linear DAG Estimation</title><link>http://arxiv.org/abs/2310.02895v1</link><description>We deal with the combinatorial problem of learning directed acyclic graph(DAG) structure from observational data adhering to a linear structuralequation model (SEM). Leveraging advances in differentiable, nonconvexcharacterizations of acyclicity, recent efforts have advocated a continuousconstrained optimization paradigm to efficiently explore the space of DAGs.Most existing methods employ lasso-type score functions to guide this search,which (i) require expensive penalty parameter retuning when the$\textit{unknown}$ SEM noise variances change across problem instances; and(ii) implicitly rely on limiting homoscedasticity assumptions. In this work, wepropose a new convex score function for sparsity-aware learning of linear DAGs,which incorporates concomitant estimation of scale and thus effectivelydecouples the sparsity parameter from the exogenous noise levels.Regularization via a smooth, nonconvex acyclicity penalty term yields CoLiDE($\textbf{Co}$ncomitant $\textbf{Li}$near $\textbf{D}$AG$\textbf{E}$stimation), a regression-based criterion amenable to efficientgradient computation and closed-form estimation of noise variances inheteroscedastic scenarios. Our algorithm outperforms state-of-the-art methodswithout incurring added complexity, especially when the DAGs are larger and thenoise level profile is heterogeneous. We also find CoLiDE exhibits enhancedstability manifested via reduced standard deviations in several domain-specificmetrics, underscoring the robustness of our novel linear DAG estimator.</description><author>Seyed Saman Saboksayr, Gonzalo Mateos, Mariano Tepper</author><pubDate>Wed, 04 Oct 2023 16:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02895v1</guid></item><item><title>Human-centric Behavior Description in Videos: New Benchmark and Model</title><link>http://arxiv.org/abs/2310.02894v1</link><description>In the domain of video surveillance, describing the behavior of eachindividual within the video is becoming increasingly essential, especially incomplex scenarios with multiple individuals present. This is because describingeach individual's behavior provides more detailed situational analysis,enabling accurate assessment and response to potential risks, ensuring thesafety and harmony of public places. Currently, video-level captioning datasetscannot provide fine-grained descriptions for each individual's specificbehavior. However, mere descriptions at the video-level fail to provide anin-depth interpretation of individual behaviors, making it challenging toaccurately determine the specific identity of each individual. To address thischallenge, we construct a human-centric video surveillance captioning dataset,which provides detailed descriptions of the dynamic behaviors of 7,820individuals. Specifically, we have labeled several aspects of each person, suchas location, clothing, and interactions with other elements in the scene, andthese people are distributed across 1,012 videos. Based on this dataset, we canlink individuals to their respective behaviors, allowing for further analysisof each person's behavior in surveillance videos. Besides the dataset, wepropose a novel video captioning approach that can describe individual behaviorin detail on a person-level basis, achieving state-of-the-art results. Tofacilitate further research in this field, we intend to release our dataset andcode.</description><author>Lingru Zhou, Yiqi Gao, Manqing Zhang, Peng Wu, Peng Wang, Yanning Zhang</author><pubDate>Wed, 04 Oct 2023 16:31:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02894v1</guid></item><item><title>Large-Batch, Iteration-Efficient Neural Bayesian Design Optimization</title><link>http://arxiv.org/abs/2306.01095v3</link><description>Bayesian optimization (BO) provides a powerful framework for optimizingblack-box, expensive-to-evaluate functions. It is therefore an attractive toolfor engineering design problems, typically involving multiple objectives.Thanks to the rapid advances in fabrication and measurement methods as well asparallel computing infrastructure, querying many design problems can be heavilyparallelized. This class of problems challenges BO with an unprecedented setupwhere it has to deal with very large batches, shifting its focus from sampleefficiency to iteration efficiency. We present a novel Bayesian optimizationframework specifically tailored to address these limitations. Our keycontribution is a highly scalable, sample-based acquisition function thatperforms a non-dominated sorting of not only the objectives but also theirassociated uncertainty. We show that our acquisition function in combinationwith different Bayesian neural network surrogates is effective indata-intensive environments with a minimal number of iterations. We demonstratethe superiority of our method by comparing it with state-of-the-artmulti-objective optimizations. We perform our evaluation on two real-worldproblems -- airfoil design and 3D printing -- showcasing the applicability andefficiency of our approach. Our code is available at:https://github.com/an-on-ym-ous/lbn_mobo</description><author>Navid Ansari, Hans-Peter Seidel, Vahid Babaei</author><pubDate>Wed, 04 Oct 2023 16:26:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01095v3</guid></item><item><title>A Grammatical Compositional Model for Video Action Detection</title><link>http://arxiv.org/abs/2310.02887v1</link><description>Analysis of human actions in videos demands understanding complex humandynamics, as well as the interaction between actors and context. However, theseinteraction relationships usually exhibit large intra-class variations fromdiverse human poses or object manipulations, and fine-grained inter-classdifferences between similar actions. Thus the performance of existing methodsis severely limited. Motivated by the observation that interactive actions canbe decomposed into actor dynamics and participating objects or humans, wepropose to investigate the composite property of them. In this paper, wepresent a novel Grammatical Compositional Model (GCM) for action detectionbased on typical And-Or graphs. Our model exploits the intrinsic structures andlatent relationships of actions in a hierarchical manner to harness both thecompositionality of grammar models and the capability of expressing richfeatures of DNNs. The proposed model can be readily embodied into a neuralnetwork module for efficient optimization in an end-to-end manner. Extensiveexperiments are conducted on the AVA dataset and the Something-Else task todemonstrate the superiority of our model, meanwhile the interpretability isenhanced through an inference parsing procedure.</description><author>Zhijun Zhang, Xu Zou, Jiahuan Zhou, Sheng Zhong, Ying Wu</author><pubDate>Wed, 04 Oct 2023 16:24:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02887v1</guid></item><item><title>Deep Stochastic Mechanics</title><link>http://arxiv.org/abs/2305.19685v2</link><description>This paper introduces a novel deep-learning-based approach for numericalsimulation of a time-evolving Schr\"odinger equation inspired by stochasticmechanics and generative diffusion models. Unlike existing approaches, whichexhibit computational complexity that scales exponentially in the problemdimension, our method allows us to adapt to the latent low-dimensionalstructure of the wave function by sampling from the Markovian diffusion.Depending on the latent dimension, our method may have far lower computationalcomplexity in higher dimensions. Moreover, we propose novel equations forstochastic quantum mechanics, resulting in linear computational complexity withrespect to the number of dimensions. Numerical simulations verify ourtheoretical findings and show a significant advantage of our method compared toother deep-learning-based approaches used for quantum mechanics.</description><author>Elena Orlova, Aleksei Ustimenko, Ruoxi Jiang, Peter Y. Lu, Rebecca Willett</author><pubDate>Wed, 04 Oct 2023 16:23:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19685v2</guid></item><item><title>Something for (almost) nothing: Improving deep ensemble calibration using unlabeled data</title><link>http://arxiv.org/abs/2310.02885v1</link><description>We present a method to improve the calibration of deep ensembles in the smalltraining data regime in the presence of unlabeled data. Our approach isextremely simple to implement: given an unlabeled set, for each unlabeled datapoint, we simply fit a different randomly selected label with each ensemblemember. We provide a theoretical analysis based on a PAC-Bayes bound whichguarantees that if we fit such a labeling on unlabeled data, and the truelabels on the training data, we obtain low negative log-likelihood and highensemble diversity on testing samples. Empirically, through detailedexperiments, we find that for low to moderately-sized training sets, ourensembles are more diverse and provide better calibration than standardensembles, sometimes significantly.</description><author>Konstantinos Pitas, Julyan Arbel</author><pubDate>Wed, 04 Oct 2023 16:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02885v1</guid></item><item><title>Learning Type Inference for Enhanced Dataflow Analysis</title><link>http://arxiv.org/abs/2310.00673v2</link><description>Statically analyzing dynamically-typed code is a challenging endeavor, aseven seemingly trivial tasks such as determining the targets of procedure callsare non-trivial without knowing the types of objects at compile time.Addressing this challenge, gradual typing is increasingly added todynamically-typed languages, a prominent example being TypeScript thatintroduces static typing to JavaScript. Gradual typing improves the developer'sability to verify program behavior, contributing to robust, secure anddebuggable programs. In practice, however, users only sparsely annotate typesdirectly. At the same time, conventional type inference facesperformance-related challenges as program size grows. Statistical techniquesbased on machine learning offer faster inference, but although recentapproaches demonstrate overall improved accuracy, they still performsignificantly worse on user-defined types than on the most common built-intypes. Limiting their real-world usefulness even more, they rarely integratewith user-facing applications. We propose CodeTIDAL5, a Transformer-based modeltrained to reliably predict type annotations. For effective result retrievaland re-integration, we extract usage slices from a program's code propertygraph. Comparing our approach against recent neural type inference systems, ourmodel outperforms the current state-of-the-art by 7.85% on theManyTypes4TypeScript benchmark, achieving 71.27% accuracy overall. Furthermore,we present JoernTI, an integration of our approach into Joern, an open sourcestatic analysis tool, and demonstrate that the analysis benefits from theadditional type information. As our model allows for fast inference times evenon commodity CPUs, making our system available through Joern leads to highaccessibility and facilitates security research.</description><author>Lukas Seidel, Sedick David Baker Effendi, Xavier Pinho, Konrad Rieck, Brink van der Merwe, Fabian Yamaguchi</author><pubDate>Wed, 04 Oct 2023 16:15:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00673v2</guid></item><item><title>Stationarity without mean reversion: Improper Gaussian process regression and improper kernels</title><link>http://arxiv.org/abs/2310.02877v1</link><description>Gaussian processes (GP) regression has gained substantial popularity inmachine learning applications. The behavior of a GP regression depends on thechoice of covariance function. Stationary covariance functions are favorite inmachine learning applications. However, (non-periodic) stationary covariancefunctions are always mean reverting and can therefore exhibit pathologicalbehavior when applied to data that does not relax to a fixed global mean value.In this paper, we show that it is possible to use improper GP prior withinfinite variance to define processes that are stationary but not meanreverting. To this aim, we introduce a large class of improper kernels that canonly be defined in this improper regime. Specifically, we introduce the SmoothWalk kernel, which produces infinitely smooth samples, and a family of improperMat\'ern kernels, which can be defined to be $j$-times differentiable for anyinteger $j$. The resulting posterior distributions can be computed analyticallyand it involves a simple correction of the usual formulas. By analyzing bothsynthetic and real data, we demonstrate that these improper kernels solve someknown pathologies of mean reverting GP regression while retaining most of thefavourable properties of ordinary smooth stationary kernels.</description><author>Luca Ambrogioni</author><pubDate>Wed, 04 Oct 2023 16:11:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02877v1</guid></item><item><title>Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation</title><link>http://arxiv.org/abs/2310.02876v1</link><description>A growing body of work has focused on text classification methods fordetecting the increasing amount of hate speech posted online. This progress hasbeen limited to only a select number of highly-resourced languages causingdetection systems to either under-perform or not exist in limited datacontexts. This is majorly caused by a lack of training data which is expensiveto collect and curate in these settings. In this work, we propose a dataaugmentation approach that addresses the problem of lack of data for onlinehate speech detection in limited data contexts using synthetic data generationtechniques. Given a handful of hate speech examples in a high-resource languagesuch as English, we present three methods to synthesize new examples of hatespeech data in a target language that retains the hate sentiment in theoriginal examples but transfers the hate targets. We apply our approach togenerate training data for hate speech classification tasks in Hindi andVietnamese. Our findings show that a model trained on synthetic data performscomparably to, and in some cases outperforms, a model trained only on thesamples available in the target domain. This method can be adopted to bootstraphate speech detection models from scratch in limited data contexts. As thegrowth of social media within these contexts continues to outstrip responseefforts, this work furthers our capacities for detection, understanding, andresponse to hate speech.</description><author>Aman Khullar, Daniel Nkemelu, Cuong V. Nguyen, Michael L. Best</author><pubDate>Wed, 04 Oct 2023 16:10:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02876v1</guid></item><item><title>Recent Methodological Advances in Federated Learning for Healthcare</title><link>http://arxiv.org/abs/2310.02874v1</link><description>For healthcare datasets, it is often not possible to combine data samplesfrom multiple sites due to ethical, privacy or logistical concerns. Federatedlearning allows for the utilisation of powerful machine learning algorithmswithout requiring the pooling of data. Healthcare data has many simultaneouschallenges which require new methodologies to address, such as highly-siloeddata, class imbalance, missing data, distribution shifts and non-standardisedvariables. Federated learning adds significant methodological complexity toconventional centralised machine learning, requiring distributed optimisation,communication between nodes, aggregation of models and redistribution ofmodels. In this systematic review, we consider all papers on Scopus that werepublished between January 2015 and February 2023 and which describe newfederated learning methodologies for addressing challenges with healthcaredata. We performed a detailed review of the 89 papers which fulfilled thesecriteria. Significant systemic issues were identified throughout the literaturewhich compromise the methodologies in many of the papers reviewed. We givedetailed recommendations to help improve the quality of the methodologydevelopment for federated learning in healthcare.</description><author>Fan Zhang, Daniel Kreuter, Yichen Chen, Sören Dittmer, Samuel Tull, Tolou Shadbahr, BloodCounts! Collaboration, Jacobus Preller, James H. F. Rudd, John A. D. Aston, Carola-Bibiane Schönlieb, Nicholas Gleadall, Michael Roberts</author><pubDate>Wed, 04 Oct 2023 16:09:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02874v1</guid></item><item><title>How Implicit Regularization of ReLU Neural Networks Characterizes the Learned Function -- Part I: the 1-D Case of Two Layers with Random First Layer</title><link>http://arxiv.org/abs/1911.02903v4</link><description>In this paper, we consider one dimensional (shallow) ReLU neural networks inwhich weights are chosen randomly and only the terminal layer is trained.First, we mathematically show that for such networks L2-regularized regressioncorresponds in function space to regularizing the estimate's second derivativefor fairly general loss functionals. For least squares regression, we show thatthe trained network converges to the smooth spline interpolation of thetraining data as the number of hidden nodes tends to infinity. Moreover, wederive a novel correspondence between the early stopped gradient descent(without any explicit regularization of the weights) and the smoothing splineregression.</description><author>Jakob Heiss, Josef Teichmann, Hanna Wutte</author><pubDate>Wed, 04 Oct 2023 16:07:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1911.02903v4</guid></item><item><title>Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness</title><link>http://arxiv.org/abs/2308.16175v2</link><description>We introduce BSDetector, a method for detecting bad and speculative answersfrom a pretrained Large Language Model by estimating a numeric confidence scorefor any output it generated. Our uncertainty quantification technique works forany LLM accessible only via a black-box API, whose training data remainsunknown. By expending a bit of extra computation, users of any LLM API can nowget the same response as they would ordinarily, as well as a confidenceestimate that cautions when not to trust this response. Experiments on bothclosed and open-form Question-Answer benchmarks reveal that BSDetector moreaccurately identifies incorrect LLM responses than alternative uncertaintyestimation procedures (for both GPT-3 and ChatGPT). By sampling multipleresponses from the LLM and considering the one with the highest confidencescore, we can additionally obtain more accurate responses from the same LLM,without any extra training steps. In applications involving automatedevaluation with LLMs, accounting for our confidence scores leads to morereliable evaluation in both human-in-the-loop and fully-automated settings(across both GPT 3.5 and 4).</description><author>Jiuhai Chen, Jonas Mueller</author><pubDate>Wed, 04 Oct 2023 16:05:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.16175v2</guid></item><item><title>Stable and Interpretable Deep Learning for Tabular Data: Introducing InterpreTabNet with the Novel InterpreStability Metric</title><link>http://arxiv.org/abs/2310.02870v1</link><description>As Artificial Intelligence (AI) integrates deeper into diverse sectors, thequest for powerful models has intensified. While significant strides have beenmade in boosting model capabilities and their applicability across domains, aglaring challenge persists: many of these state-of-the-art models remain asblack boxes. This opacity not only complicates the explanation of modeldecisions to end-users but also obstructs insights into intermediate processesfor model designers. To address these challenges, we introduce InterpreTabNet,a model designed to enhance both classification accuracy and interpretabilityby leveraging the TabNet architecture with an improved attentive module. Thisdesign ensures robust gradient propagation and computational stability.Additionally, we present a novel evaluation metric, InterpreStability, whichquantifies the stability of a model's interpretability. The proposed model andmetric mark a significant stride forward in explainable models' research,setting a standard for transparency and interpretability in AI model design andapplication across diverse sectors. InterpreTabNet surpasses other leadingsolutions in tabular data analysis across varied application scenarios, pavingthe way for further research into creating deep-learning models that are bothhighly accurate and inherently explainable. The introduction of theInterpreStability metric ensures that the interpretability of future models canbe measured and compared in a consistent and rigorous manner. Collectively,these contributions have the potential to promote the design principles anddevelopment of next-generation interpretable AI models, widening the adoptionof interpretable AI solutions in critical decision-making environments.</description><author>Shiyun Wa, Xinai Lu, Minjuan Wang</author><pubDate>Wed, 04 Oct 2023 16:04:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02870v1</guid></item><item><title>Harmonic Control Lyapunov Barrier Functions for Constrained Optimal Control with Reach-Avoid Specifications</title><link>http://arxiv.org/abs/2310.02869v1</link><description>This paper introduces harmonic control Lyapunov barrier functions (harmonicCLBF) that aid in constrained control problems such as reach-avoid problems.Harmonic CLBFs exploit the maximum principle that harmonic functions satisfy toencode the properties of control Lyapunov barrier functions (CLBFs). As aresult, they can be initiated at the start of an experiment rather than trainedbased on sample trajectories. The control inputs are selected to maximize theinner product of the system dynamics with the steepest descent direction of theharmonic CLBF. Numerical results are presented with four different systemsunder different reach-avoid environments. Harmonic CLBFs show a significantlylow risk of entering unsafe regions and a high probability of entering the goalregion.</description><author>Amartya Mukherjee, Ruikun Zhou, Jun Liu</author><pubDate>Wed, 04 Oct 2023 16:03:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02869v1</guid></item><item><title>Instruction Tuning for Large Language Models: A Survey</title><link>http://arxiv.org/abs/2308.10792v3</link><description>This paper surveys research works in the quickly advancing field ofinstruction tuning (IT), a crucial technique to enhance the capabilities andcontrollability of large language models (LLMs). Instruction tuning refers tothe process of further training LLMs on a dataset consisting of\textsc{(instruction, output)} pairs in a supervised fashion, which bridges thegap between the next-word prediction objective of LLMs and the users' objectiveof having LLMs adhere to human instructions. In this work, we make a systematicreview of the literature, including the general methodology of IT, theconstruction of IT datasets, the training of IT models, and applications todifferent modalities, domains and applications, along with an analysis onaspects that influence the outcome of IT (e.g., generation of instructionoutputs, size of the instruction dataset, etc). We also review the potentialpitfalls of IT along with criticism against it, along with efforts pointing outcurrent deficiencies of existing strategies and suggest some avenues forfruitful research. Project page: github.com/xiaoya-li/Instruction-Tuning-Survey</description><author>Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, Guoyin Wang</author><pubDate>Wed, 04 Oct 2023 16:00:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10792v3</guid></item><item><title>Computing high-dimensional optimal transport by flow neural networks</title><link>http://arxiv.org/abs/2305.11857v3</link><description>Flow-based models are widely used in generative tasks, including normalizingflow, where a neural network transports from a data distribution $P$ to anormal distribution. This work develops a flow-based model that transports from$P$ to an arbitrary $Q$ where both distributions are only accessible via finitesamples. We propose to learn the dynamic optimal transport between $P$ and $Q$by training a flow neural network. The model is trained to find an invertibletransport map between $P$ and $Q$ optimally by minimizing the transport cost.The trained optimal transport flow allows for performing many downstream tasks,including infinitesimal density ratio estimation and distribution interpolationin the latent space for generative models. The effectiveness of the proposedmodel on high-dimensional data is empirically demonstrated in mutualinformation estimation, energy-based generative models, and image-to-imagetranslation.</description><author>Chen Xu, Xiuyuan Cheng, Yao Xie</author><pubDate>Wed, 04 Oct 2023 15:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11857v3</guid></item><item><title>Estimation of Models with Limited Data by Leveraging Shared Structure</title><link>http://arxiv.org/abs/2310.02864v1</link><description>Modern data sets, such as those in healthcare and e-commerce, are oftenderived from many individuals or systems but have insufficient data from eachsource alone to separately estimate individual, often high-dimensional, modelparameters. If there is shared structure among systems however, it may bepossible to leverage data from other systems to help estimate individualparameters, which could otherwise be non-identifiable. In this paper, we assumesystems share a latent low-dimensional parameter space and propose a method forrecovering $d$-dimensional parameters for $N$ different linear systems, evenwhen there are only $T&lt;d$ observations per system. To do so, we develop athree-step algorithm which estimates the low-dimensional subspace spanned bythe systems' parameters and produces refined parameter estimates within thesubspace. We provide finite sample subspace estimation error guarantees for ourproposed method. Finally, we experimentally validate our method on simulationswith i.i.d. regression data and as well as correlated time series data.</description><author>Maryann Rui, Thibaut Horel, Munther Dahleh</author><pubDate>Wed, 04 Oct 2023 15:54:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02864v1</guid></item></channel></rss>