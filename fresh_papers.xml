<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 05 Jun 2023 06:00:36 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>OCBEV: Object-Centric BEV Transformer for Multi-View 3D Object Detection</title><link>http://arxiv.org/abs/2306.01738v1</link><description>Multi-view 3D object detection is becoming popular in autonomous driving dueto its high effectiveness and low cost. Most of the current state-of-the-artdetectors follow the query-based bird's-eye-view (BEV) paradigm, which benefitsfrom both BEV's strong perception power and end-to-end pipeline. Despiteachieving substantial progress, existing works model objects via globallyleveraging temporal and spatial information of BEV features, resulting inproblems when handling the challenging complex and dynamic autonomous drivingscenarios. In this paper, we proposed an Object-Centric query-BEV detectorOCBEV, which can carve the temporal and spatial cues of moving targets moreeffectively. OCBEV comprises three designs: Object Aligned Temporal Fusionaligns the BEV feature based on ego-motion and estimated current locations ofmoving objects, leading to a precise instance-level feature fusion. ObjectFocused Multi-View Sampling samples more 3D features from an adaptive localheight ranges of objects for each scene to enrich foreground information.Object Informed Query Enhancement replaces part of pre-defined decoder queriesin common DETR-style decoders with positional features of objects onhigh-confidence locations, introducing more direct object positional priors.Extensive experimental evaluations are conducted on the challenging nuScenesdataset. Our approach achieves a state-of-the-art result, surpassing thetraditional BEVFormer by 1.5 NDS points. Moreover, we have a faster convergencespeed and only need half of the training iterations to get comparableperformance, which further demonstrates its effectiveness.</description><author>Zhangyang Qi, Jiaqi Wang, Xiaoyang Wu, Hengshuang Zhao</author><pubDate>Fri, 02 Jun 2023 18:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01738v1</guid></item><item><title>DaTaSeg: Taming a Universal Multi-Dataset Multi-Task Segmentation Model</title><link>http://arxiv.org/abs/2306.01736v1</link><description>Observing the close relationship among panoptic, semantic and instancesegmentation tasks, we propose to train a universal multi-dataset multi-tasksegmentation model: DaTaSeg.We use a shared representation (mask proposals withclass predictions) for all tasks. To tackle task discrepancy, we adoptdifferent merge operations and post-processing for different tasks. We alsoleverage weak-supervision, allowing our segmentation model to benefit fromcheaper bounding box annotations. To share knowledge across datasets, we usetext embeddings from the same semantic embedding space as classifiers and shareall network parameters among datasets. We train DaTaSeg on ADE semantic, COCOpanoptic, and Objects365 detection datasets. DaTaSeg improves performance onall datasets, especially small-scale datasets, achieving 54.0 mIoU on ADEsemantic and 53.5 PQ on COCO panoptic. DaTaSeg also enables weakly-supervisedknowledge transfer on ADE panoptic and Objects365 instance segmentation.Experiments show DaTaSeg scales with the number of training datasets andenables open-vocabulary segmentation through direct transfer. In addition, weannotate an Objects365 instance segmentation set of 1,000 images and willrelease it as a public benchmark.</description><author>Xiuye Gu, Yin Cui, Jonathan Huang, Abdullah Rashwan, Xuan Yang, Xingyi Zhou, Golnaz Ghiasi, Weicheng Kuo, Huizhong Chen, Liang-Chieh Chen, David A Ross</author><pubDate>Fri, 02 Jun 2023 18:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01736v1</guid></item><item><title>Multilingual Conceptual Coverage in Text-to-Image Models</title><link>http://arxiv.org/abs/2306.01735v1</link><description>We propose "Conceptual Coverage Across Languages" (CoCo-CroLa), a techniquefor benchmarking the degree to which any generative text-to-image systemprovides multilingual parity to its training language in terms of tangiblenouns. For each model we can assess "conceptual coverage" of a given targetlanguage relative to a source language by comparing the population of imagesgenerated for a series of tangible nouns in the source language to thepopulation of images generated for each noun under translation in the targetlanguage. This technique allows us to estimate how well-suited a model is to atarget language as well as identify model-specific weaknesses, spuriouscorrelations, and biases without a-priori assumptions. We demonstrate how itcan be used to benchmark T2I models in terms of multilinguality, and howdespite its simplicity it is a good proxy for impressive generalization.</description><author>Michael Saxon, William Yang Wang</author><pubDate>Fri, 02 Jun 2023 18:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01735v1</guid></item><item><title>DocFormerv2: Local Features for Document Understanding</title><link>http://arxiv.org/abs/2306.01733v1</link><description>We propose DocFormerv2, a multi-modal transformer for Visual DocumentUnderstanding (VDU). The VDU domain entails understanding documents (beyondmere OCR predictions) e.g., extracting information from a form, VQA fordocuments and other tasks. VDU is challenging as it needs a model to make senseof multiple modalities (visual, language and spatial) to make a prediction. Ourapproach, termed DocFormerv2 is an encoder-decoder transformer which takes asinput - vision, language and spatial features. DocFormerv2 is pre-trained withunsupervised tasks employed asymmetrically i.e., two novel document tasks onencoder and one on the auto-regressive decoder. The unsupervised tasks havebeen carefully designed to ensure that the pre-training encourageslocal-feature alignment between multiple modalities. DocFormerv2 when evaluatedon nine datasets shows state-of-the-art performance over strong baselines e.g.TabFact (4.3%), InfoVQA (1.4%), FUNSD (1%). Furthermore, to show generalizationcapabilities, on three VQA tasks involving scene-text, Doc- Formerv2outperforms previous comparably-sized models and even does better than muchlarger models (such as GIT2, PaLi and Flamingo) on some tasks. Extensiveablations show that due to its pre-training, DocFormerv2 understands multiplemodalities better than prior-art in VDU.</description><author>Srikar Appalaraju, Peng Tang, Qi Dong, Nishant Sankaran, Yichu Zhou, R. Manmatha</author><pubDate>Fri, 02 Jun 2023 18:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01733v1</guid></item><item><title>Video Colorization with Pre-trained Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2306.01732v1</link><description>Video colorization is a challenging task that involves inferring plausibleand temporally consistent colors for grayscale frames. In this paper, wepresent ColorDiffuser, an adaptation of a pre-trained text-to-image latentdiffusion model for video colorization. With the proposed adapter-basedapproach, we repropose the pre-trained text-to-image model to accept inputgrayscale video frames, with the optional text description, for videocolorization. To enhance the temporal coherence and maintain the vividness ofcolorization across frames, we propose two novel techniques: the ColorPropagation Attention and Alternated Sampling Strategy. Color PropagationAttention enables the model to refine its colorization decision based on areference latent frame, while Alternated Sampling Strategy capturesspatiotemporal dependencies by using the next and previous adjacent latentframes alternatively as reference during the generative diffusion samplingsteps. This encourages bidirectional color information propagation betweenadjacent video frames, leading to improved color consistency across frames. Weconduct extensive experiments on benchmark datasets, and the resultsdemonstrate the effectiveness of our proposed framework. The evaluations showthat ColorDiffuser achieves state-of-the-art performance in video colorization,surpassing existing methods in terms of color fidelity, temporal consistency,and visual quality.</description><author>Hanyuan Liu, Minshan Xie, Jinbo Xing, Chengze Li, Tien-Tsin Wong</author><pubDate>Fri, 02 Jun 2023 18:58:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01732v1</guid></item><item><title>PAGAR: Imitation Learning with Protagonist Antagonist Guided Adversarial Reward</title><link>http://arxiv.org/abs/2306.01731v1</link><description>Imitation learning (IL) algorithms often rely on inverse reinforcementlearning (IRL) to first learn a reward function from expert demonstrations.However, IRL can suffer from identifiability issues and there is no performanceor efficiency guarantee when training with the learned reward function. In thispaper, we propose Protagonist Antagonist Guided Adversarial Reward (PAGAR), asemi-supervised learning paradigm for designing rewards for policy training.PAGAR employs an iterative adversarially search for reward functions tomaximize the performance gap between a protagonist policy and an antagonistpolicy. This allows the protagonist policy to perform well across a set ofpossible reward functions despite the identifiability issue. When integratedwith IRL-based IL, PAGAR guarantees that the trained policy succeeds in theunderlying task. Furthermore, we introduce a practical on-and-off policyapproach to IL with PAGAR. This approach maximally utilizes samples from boththe protagonist and antagonist policies for the optimization of policy andreward functions. Experimental results demonstrate that our algorithm achieveshigher training efficiency compared to state-of-the-art IL/IRL baselines instandard settings, as well as zero-shot learning from demonstrations intransfer environments.</description><author>Weichao Zhou, Wenchao Li</author><pubDate>Fri, 02 Jun 2023 18:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01731v1</guid></item><item><title>BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models</title><link>http://arxiv.org/abs/2206.14268v3</link><description>It is crucial to automatically construct knowledge graphs (KGs) of diversenew relations to support knowledge discovery and broad applications. PreviousKG construction methods, based on either crowdsourcing or text mining, areoften limited to a small predefined set of relations due to manual cost orrestrictions in text corpus. Recent research proposed to use pretrainedlanguage models (LMs) as implicit knowledge bases that accept knowledge querieswith prompts. Yet, the implicit knowledge lacks many desirable properties of afull-scale symbolic KG, such as easy access, navigation, editing, and qualityassurance. In this paper, we propose a new approach of harvesting massive KGsof arbitrary relations from pretrained LMs. With minimal input of a relationdefinition (a prompt and a few shot of example entity pairs), the approachefficiently searches in the vast entity pair space to extract diverse accurateknowledge of the desired relation. We develop an effective search-and-rescoremechanism for improved efficiency and accuracy. We deploy the approach toharvest KGs of over 400 new relations from different LMs. Extensive human andautomatic evaluations show our approach manages to extract diverse accurateknowledge, including tuples of complex relations (e.g., "A is capable of butnot good at B"). The resulting KGs as a symbolic interpretation of the sourceLMs also reveal new insights into the LMs' knowledge capacities.</description><author>Shibo Hao, Bowen Tan, Kaiwen Tang, Bin Ni, Xiyan Shao, Hengzhe Zhang, Eric P. Xing, Zhiting Hu</author><pubDate>Fri, 02 Jun 2023 18:54:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.14268v3</guid></item><item><title>Improving Generalization in Task-oriented Dialogues with Workflows and Action Plans</title><link>http://arxiv.org/abs/2306.01729v1</link><description>Task-oriented dialogue is difficult in part because it involves understandinguser intent, collecting information from the user, executing API calls, andgenerating helpful and fluent responses. However, for complex tasks one mustalso correctly do all of these things over multiple steps, and in a specificorder. While large pre-trained language models can be fine-tuned end-to-end tocreate multi-step task-oriented dialogue agents that generate fluent text, ourexperiments confirm that this approach alone cannot reliably perform newmulti-step tasks that are unseen during training. To address these limitations,we augment the dialogue contexts given to \textmd{text2text} transformers withknown \textit{valid workflow names} and \textit{action plans}. Action plansconsist of sequences of actions required to accomplish a task, and are encodedas simple sequences of keywords (e.g. verify-identity, pull-up-account,reset-password, etc.). We perform extensive experiments on the Action-BasedConversations Dataset (ABCD) with T5-small, base and large models, and showthat such models: a) are able to more readily generalize to unseen workflows byfollowing the provided plan, and b) are able to generalize to executing unseenactions if they are provided in the plan. In contrast, models are unable tofully accomplish new multi-step tasks when they are not provided action planinformation, even when given new valid workflow names.</description><author>Stefania Raimondo, Christopher Pal, Xiaotian Liu, David Vazquez, Hector Palacios</author><pubDate>Fri, 02 Jun 2023 18:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01729v1</guid></item><item><title>Broadcasting in random recursive dags</title><link>http://arxiv.org/abs/2306.01727v1</link><description>A uniform $k$-{\sc dag} generalizes the uniform random recursive tree bypicking $k$ parents uniformly at random from the existing nodes. It starts with$k$ ''roots''. Each of the $k$ roots is assigned a bit. These bits arepropagated by a noisy channel. The parents' bits are flipped with probability$p$, and a majority vote is taken. When all nodes have received their bits, the$k$-{\sc dag} is shown without identifying the roots. The goal is to estimatethe majority bit among the roots. We identify the threshold for $p$ as afunction of $k$ below which the majority rule among all nodes yields an error$c+o(1)$ with $c&lt;1/2$. Above the threshold the majority rule errs withprobability $1/2+o(1)$.</description><author>Simon Briend, Luc Devroye, Gabor Lugosi</author><pubDate>Fri, 02 Jun 2023 18:53:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01727v1</guid></item><item><title>Streaming algorithms for evaluating noisy judges on unlabeled data -- binary classification</title><link>http://arxiv.org/abs/2306.01726v1</link><description>The evaluation of noisy binary classifiers on unlabeled data is treated as astreaming task: given a data sketch of the decisions by an ensemble, estimatethe true prevalence of the labels as well as each classifier's accuracy onthem. Two fully algebraic evaluators are constructed to do this. Both are basedon the assumption that the classifiers make independent errors. The first isbased on majority voting. The second, the main contribution of the paper, isguaranteed to be correct. But how do we know the classifiers are independent onany given test? This principal/agent monitoring paradox is ameliorated byexploiting the failures of the independent evaluator to return sensibleestimates. A search for nearly error independent trios is empirically carriedout on the \texttt{adult}, \texttt{mushroom}, and \texttt{two-norm} datasets byusing the algebraic failure modes to reject evaluation ensembles as toocorrelated. The searches are refined by constructing a surface in evaluationspace that contains the true value point. The algebra of arbitrarily correlatedclassifiers permits the selection of a polynomial subset free of anycorrelation variables. Candidate evaluation ensembles are rejected if theirdata sketches produce independent estimates too far from the constructedsurface. The results produced by the surviving ensembles can sometimes be asgood as 1\%. But handling even small amounts of correlation remains achallenge. A Taylor expansion of the estimates produced when independence isassumed but the classifiers are, in fact, slightly correlated helps clarify howthe independent evaluator has algebraic `blind spots'.</description><author>Andrés Corrada-Emmanuel</author><pubDate>Fri, 02 Jun 2023 18:52:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01726v1</guid></item><item><title>Graph Sparsification for GCN Towards Optimal Crop Yield Predictions</title><link>http://arxiv.org/abs/2306.01725v1</link><description>In agronomics, predicting crop yield at a per field/county granularity isimportant for farmers to minimize uncertainty and plan seeding for the nextcrop cycle. While state-of-the-art prediction techniques employ graphconvolutional nets (GCN) to predict future crop yields given relevant featuresand crop yields of previous years, a dense underlying graph kernel requireslong training and execution time. In this paper, we propose a graphsparsification method based on the Fiedler number to remove edges from acomplete graph kernel, in order to lower the complexity of GCNtraining/execution. Specifically, we first show that greedily removing an edgeat a time that induces the minimal change in the second eigenvalue leads to asparse graph with good GCN performance. We then propose a fast method to choosean edge for removal per iteration based on an eigenvalue perturbation theorem.Experiments show that our Fiedler-based method produces a sparse graph withgood GCN performance compared to other graph sparsification schemes in cropyield prediction.</description><author>Saghar Bagheri, Gene Cheung, Tim Eadie</author><pubDate>Fri, 02 Jun 2023 18:51:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01725v1</guid></item><item><title>Denoising Diffusion Semantic Segmentation with Mask Prior Modeling</title><link>http://arxiv.org/abs/2306.01721v1</link><description>The evolution of semantic segmentation has long been dominated by learningmore discriminative image representations for classifying each pixel. Despitethe prominent advancements, the priors of segmentation masks themselves, e.g.,geometric and semantic constraints, are still under-explored. In this paper, wepropose to ameliorate the semantic segmentation quality of existingdiscriminative approaches with a mask prior modeled by a recently-developeddenoising diffusion generative model. Beginning with a unified architecturethat adapts diffusion models for mask prior modeling, we focus this work on aspecific instantiation with discrete diffusion and identify a variety of keydesign choices for its successful application. Our exploratory analysisrevealed several important findings, including: (1) a simple integration ofdiffusion models into semantic segmentation is not sufficient, and apoorly-designed diffusion process might lead to degradation in segmentationperformance; (2) during the training, the object to which noise is added ismore important than the type of noise; (3) during the inference, the strictdiffusion denoising scheme may not be essential and can be relaxed to a simplerscheme that even works better. We evaluate the proposed prior modeling withseveral off-the-shelf segmentors, and our experimental results on ADE20K andCityscapes demonstrate that our approach could achieve competitivelyquantitative performance and more appealing visual quality.</description><author>Zeqiang Lai, Yuchen Duan, Jifeng Dai, Ziheng Li, Ying Fu, Hongsheng Li, Yu Qiao, Wenhai Wang</author><pubDate>Fri, 02 Jun 2023 18:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01721v1</guid></item><item><title>Scaling in Depth: Unlocking Robustness Certification on ImageNet</title><link>http://arxiv.org/abs/2301.12549v2</link><description>Despite the promise of Lipschitz-based methods for provably-robust deeplearning with deterministic guarantees, current state-of-the-art results arelimited to feed-forward Convolutional Networks (ConvNets) on low-dimensionaldata, such as CIFAR-10. This paper investigates strategies for expandingcertifiably robust training to larger, deeper models. A key challenge incertifying deep networks is efficient calculation of the Lipschitz bound forresidual blocks found in ResNet and ViT architectures. We show that fast waysof bounding the Lipschitz constant for conventional ResNets are loose, and showhow to address this by designing a new residual block, leading to the\emph{Linear ResNet} (LiResNet) architecture. We then introduce \emph{EfficientMargin MAximization} (EMMA), a loss function that stabilizes robust training bysimultaneously penalizing worst-case adversarial examples from \emph{all}classes. Together, these contributions yield new \emph{state-of-the-art} robustaccuracy on CIFAR-10/100 and Tiny-ImageNet under $\ell_2$ perturbations.Moreover, for the first time, we are able to scale up fast deterministicrobustness guarantees to ImageNet, demonstrating that this approach to robustlearning can be applied to real-world applications. We release our code on Github: \url{https://github.com/klasleino/gloro}.</description><author>Kai Hu, Andy Zou, Zifan Wang, Klas Leino, Matt Fredrikson</author><pubDate>Fri, 02 Jun 2023 18:39:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12549v2</guid></item><item><title>Online Continuous Hyperparameter Optimization for Contextual Bandits</title><link>http://arxiv.org/abs/2302.09440v2</link><description>In stochastic contextual bandits, an agent sequentially makes actions from atime-dependent action set based on past experience to minimize the cumulativeregret. Like many other machine learning algorithms, the performance of banditsheavily depends on their multiple hyperparameters, and theoretically derivedparameter values may lead to unsatisfactory results in practice. Moreover, itis infeasible to use offline tuning methods like cross-validation to choosehyperparameters under the bandit environment, as the decisions should be madein real time. To address this challenge, we propose the first online continuoushyperparameter tuning framework for contextual bandits to learn the optimalparameter configuration within a search space on the fly. Specifically, we usea double-layer bandit framework named CDT (Continuous Dynamic Tuning) andformulate the hyperparameter optimization as a non-stationary continuum-armedbandit, where each arm represents a combination of hyperparameters, and thecorresponding reward is the algorithmic result. For the top layer, we proposethe Zooming TS algorithm that utilizes Thompson Sampling (TS) for explorationand a restart technique to get around the switching environment. The proposedCDT framework can be easily used to tune contextual bandit algorithms withoutany pre-specified candidate set for hyperparameters. We further show that itcould achieve sublinear regret in theory and performs consistently better onboth synthetic and real datasets in practice.</description><author>Yue Kang, Cho-Jui Hsieh, Thomas C. M. Lee</author><pubDate>Fri, 02 Jun 2023 18:35:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09440v2</guid></item><item><title>OMNI: Open-endedness via Models of human Notions of Interestingness</title><link>http://arxiv.org/abs/2306.01711v1</link><description>Open-ended algorithms aim to learn new, interesting behaviors forever. Thatrequires a vast environment search space, but there are thus infinitely manypossible tasks. Even after filtering for tasks the current agent can learn(i.e., learning progress), countless learnable yet uninteresting tasks remain(e.g., minor variations of previously learned tasks). An Achilles Heel ofopen-endedness research is the inability to quantify (and thus prioritize)tasks that are not just learnable, but also $\textit{interesting}$ (e.g.,worthwhile and novel). We propose solving this problem by$\textit{Open-endedness via Models of human Notions of Interestingness}$(OMNI). The insight is that we can utilize large (language) models (LMs) as amodel of interestingness (MoI), because they $\textit{already}$ internalizehuman concepts of interestingness from training on vast amounts ofhuman-generated data, where humans naturally write about what they findinteresting or boring. We show that LM-based MoIs improve open-ended learningby focusing on tasks that are both learnable $\textit{and interesting}$,outperforming baselines based on uniform task sampling or learning progressalone. This approach has the potential to dramatically advance the ability tointelligently select which tasks to focus on next (i.e., auto-curricula), andcould be seen as AI selecting its own next task to learn, facilitatingself-improving AI and AI-Generating Algorithms.</description><author>Jenny Zhang, Joel Lehman, Kenneth Stanley, Jeff Clune</author><pubDate>Fri, 02 Jun 2023 18:32:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01711v1</guid></item><item><title>A Data-Driven Measure of Relative Uncertainty for Misclassification Detection</title><link>http://arxiv.org/abs/2306.01710v1</link><description>Misclassification detection is an important problem in machine learning, asit allows for the identification of instances where the model's predictions areunreliable. However, conventional uncertainty measures such as Shannon entropydo not provide an effective way to infer the real uncertainty associated withthe model's predictions. In this paper, we introduce a novel data-drivenmeasure of relative uncertainty to an observer for misclassification detection.By learning patterns in the distribution of soft-predictions, our uncertaintymeasure can identify misclassified samples based on the predicted classprobabilities. Interestingly, according to the proposed measure,soft-predictions that correspond to misclassified instances can carry a largeamount of uncertainty, even though they may have low Shannon entropy. Wedemonstrate empirical improvements over multiple image classification tasks,outperforming state-of-the-art misclassification detection methods.</description><author>Eduardo Dadalto, Marco Romanelli, Georg Pichler, Pablo Piantanida</author><pubDate>Fri, 02 Jun 2023 18:32:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01710v1</guid></item><item><title>Distilling Efficient Language-Specific Models for Cross-Lingual Transfer</title><link>http://arxiv.org/abs/2306.01709v1</link><description>Massively multilingual Transformers (MMTs), such as mBERT and XLM-R, arewidely used for cross-lingual transfer learning. While these are pretrained torepresent hundreds of languages, end users of NLP systems are often interestedonly in individual languages. For such purposes, the MMTs' language coveragemakes them unnecessarily expensive to deploy in terms of model size, inferencetime, energy, and hardware cost. We thus propose to extract compressed,language-specific models from MMTs which retain the capacity of the originalMMTs for cross-lingual transfer. This is achieved by distilling the MMTbilingually, i.e., using data from only the source and target language ofinterest. Specifically, we use a two-phase distillation approach, termedBiStil: (i) the first phase distils a general bilingual model from the MMT,while (ii) the second, task-specific phase sparsely fine-tunes the bilingual"student" model using a task-tuned variant of the original MMT as its"teacher". We evaluate this distillation technique in zero-shot cross-lingualtransfer across a number of standard cross-lingual benchmarks. The key resultsindicate that the distilled models exhibit minimal degradation in targetlanguage performance relative to the base MMT despite being significantlysmaller and faster. Furthermore, we find that they outperform multilinguallydistilled models such as DistilmBERT and MiniLMv2 while having a very modesttraining budget in comparison, even on a per-language basis. We also show thatbilingual models distilled from MMTs greatly outperform bilingual modelstrained from scratch. Our code and models are available athttps://github.com/AlanAnsell/bistil.</description><author>Alan Ansell, Edoardo Maria Ponti, Anna Korhonen, Ivan Vulić</author><pubDate>Fri, 02 Jun 2023 18:31:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01709v1</guid></item><item><title>Resolving Interference When Merging Models</title><link>http://arxiv.org/abs/2306.01708v1</link><description>Transfer learning - i.e., further fine-tuning a pre-trained model on adownstream task - can confer significant advantages, including improveddownstream performance, faster convergence, and better sample efficiency. Theseadvantages have led to a proliferation of task-specific fine-tuned models,which typically can only perform a single task and do not benefit from oneanother. Recently, model merging techniques have emerged as a solution tocombine multiple task-specific models into a single multitask model withoutperforming additional training. However, existing merging methods often ignorethe interference between parameters of different models, resulting in largeperformance drops when merging multiple models. In this paper, we demonstratethat prior merging techniques inadvertently lose valuable information due totwo major sources of interference: (a) interference due to redundant parametervalues and (b) disagreement on the sign of a given parameter's values acrossmodels. To address this, we propose our method, TrIm, Elect Sign &amp; Merge(TIES-Merging), which introduces three novel steps when merging models: (1)resetting parameters that only changed a small amount during fine-tuning, (2)resolving sign conflicts, and (3) merging only the parameters that are inalignment with the final agreed-upon sign. We find that TIES-Mergingoutperforms several existing methods in diverse settings covering a range ofmodalities, domains, number of tasks, model sizes, architectures, andfine-tuning settings. We further analyze the impact of different types ofinterference on model parameters, highlight the importance of resolving signinterference. Our code is available athttps://github.com/prateeky2806/ties-merging</description><author>Prateek Yadav, Derek Tam, Leshem Choshen, Colin Raffel, Mohit Bansal</author><pubDate>Fri, 02 Jun 2023 18:31:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01708v1</guid></item><item><title>Learning Multi-step Reasoning from Arithmetic Task</title><link>http://arxiv.org/abs/2306.01707v1</link><description>Mathematical reasoning is regarded as a necessary ability for Language Models(LMs). Recent works demonstrate large LMs' impressive performance in solvingmath problems. The success is attributed to their Chain-of-Thought (CoT)reasoning abilities, i.e., the ability to decompose complex questions intostep-by-step reasoning chains, but such ability seems only to emerge frommodels with abundant parameters. This work investigates how to incorporaterelatively small LMs with the capabilities of multi-step reasoning. We proposeto inject such abilities by continually pre-training LMs on a synthetic datasetMsAT, which stands for Multi-step Arithmetic Task. Our experiments on four mathword problem datasets show the effectiveness of the proposed method inenhancing LMs' math reasoning abilities.</description><author>Tianduo Wang, Wei Lu</author><pubDate>Fri, 02 Jun 2023 18:29:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01707v1</guid></item><item><title>Is Generative Modeling-based Stylization Necessary for Domain Adaptation in Regression Tasks?</title><link>http://arxiv.org/abs/2306.01706v1</link><description>Unsupervised domain adaptation (UDA) aims to bridge the gap between sourceand target domains in the absence of target domain labels using two maintechniques: input-level alignment (such as generative modeling and stylization)and feature-level alignment (which matches the distribution of the featuremaps, e.g. gradient reversal layers). Motivated from the success of generativemodeling for image classification, stylization-based methods were recentlyproposed for regression tasks, such as pose estimation. However, use ofinput-level alignment via generative modeling and stylization incur additionaloverhead and computational complexity which limit their use in real-world DAtasks. To investigate the role of input-level alignment for DA, we ask thefollowing question: Is generative modeling-based stylization necessary forvisual domain adaptation in regression? Surprisingly, we find thatinput-alignment has little effect on regression tasks as compared toclassification. Based on these insights, we develop a non-parametricfeature-level domain alignment method -- Implicit Stylization (ImSty) -- whichresults in consistent improvements over SOTA regression task, without the needfor computationally intensive stylization and generative modeling. Our workconducts a critical evaluation of the role of generative modeling andstylization, at a time when these are also gaining popularity for domaingeneralization.</description><author>Jinman Park, Francois Barnard, Saad Hossain, Sirisha Rambhatla, Paul Fieguth</author><pubDate>Fri, 02 Jun 2023 18:28:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01706v1</guid></item><item><title>The Information Pathways Hypothesis: Transformers are Dynamic Self-Ensembles</title><link>http://arxiv.org/abs/2306.01705v1</link><description>Transformers use the dense self-attention mechanism which gives a lot offlexibility for long-range connectivity. Over multiple layers of a deeptransformer, the number of possible connectivity patterns increasesexponentially. However, very few of these contribute to the performance of thenetwork, and even fewer are essential. We hypothesize that there are sparselyconnected sub-networks within a transformer, called information pathways whichcan be trained independently. However, the dynamic (i.e., input-dependent)nature of these pathways makes it difficult to prune dense self-attentionduring training. But the overall distribution of these pathways is oftenpredictable. We take advantage of this fact to propose StochasticallySubsampled self-Attention (SSA) - a general-purpose training strategy fortransformers that can reduce both the memory and computational cost ofself-attention by 4 to 8 times during training while also serving as aregularization method - improving generalization over dense training. We showthat an ensemble of sub-models can be formed from the subsampled pathwayswithin a network, which can achieve better performance than its denselyattended counterpart. We perform experiments on a variety of NLP, computervision and graph learning tasks in both generative and discriminative settingsto provide empirical evidence for our claims and show the effectiveness of theproposed method.</description><author>Md Shamim Hussain, Mohammed J. Zaki, Dharmashankar Subramanian</author><pubDate>Fri, 02 Jun 2023 18:28:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01705v1</guid></item><item><title>ThinkSum: Probabilistic reasoning over sets using large language models</title><link>http://arxiv.org/abs/2210.01293v2</link><description>Large language models (LLMs) have a substantial capacity for high-levelanalogical reasoning: reproducing patterns in linear text that occur in theirtraining data (zero-shot evaluation) or in the provided context (few-shotin-context learning). However, recent studies show that even the more advancedLLMs fail in scenarios that require reasoning over multiple objects or factsand making sequences of logical deductions. We propose a two-stageprobabilistic inference paradigm, ThinkSum, which reasons over sets of objectsor facts in a structured manner. In the first stage (Think - retrieval ofassociations), a LLM is queried in parallel over a set of phrases extractedfrom the prompt or an auxiliary model call. In the second stage (Sum -probabilistic inference or reasoning), the results of these queries areaggregated to make the final prediction. We demonstrate the possibilities andadvantages of ThinkSum on the BIG-bench suite of LLM evaluation tasks,achieving improvements over the state of the art using GPT-family models onthirteen difficult tasks, often with far smaller model variants. We alsocompare and contrast ThinkSum with other proposed modifications to directprompting of LLMs, such as variants of chain-of-thought prompting. Our resultssuggest that because the probabilistic inference in ThinkSum is performedoutside of calls to the LLM, ThinkSum is less sensitive to prompt design,yields more interpretable predictions, and can be flexibly combined with latentvariable models to extract structured knowledge from LLMs. Overall, ourproposed paradigm represents a promising approach for enhancing the reasoningcapabilities of LLMs.</description><author>Batu Ozturkler, Nikolay Malkin, Zhen Wang, Nebojsa Jojic</author><pubDate>Fri, 02 Jun 2023 18:25:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.01293v2</guid></item><item><title>Affinity Clustering Framework for Data Debiasing Using Pairwise Distribution Discrepancy</title><link>http://arxiv.org/abs/2306.01699v1</link><description>Group imbalance, resulting from inadequate or unrepresentative datacollection methods, is a primary cause of representation bias in datasets.Representation bias can exist with respect to different groups of one or moreprotected attributes and might lead to prejudicial and discriminatory outcomestoward certain groups of individuals; in cases where a learning model istrained on such biased data. This paper presents MASC, a data augmentationapproach that leverages affinity clustering to balance the representation ofnon-protected and protected groups of a target dataset by utilizing instancesof the same protected attributes from similar datasets that are categorized inthe same cluster as the target dataset by sharing instances of the protectedattribute. The proposed method involves constructing an affinity matrix byquantifying distribution discrepancies between dataset pairs and transformingthem into a symmetric pairwise similarity matrix. A non-parametric spectralclustering is then applied to this affinity matrix, automatically categorizingthe datasets into an optimal number of clusters. We perform a step-by-stepexperiment as a demo of our method to show the procedure of the proposed dataaugmentation method and evaluate and discuss its performance. A comparison withother data augmentation methods, both pre- and post-augmentation, is conducted,along with a model evaluation analysis of each method. Our method can handlenon-binary protected attributes so, in our experiments, bias is measured in anon-binary protected attribute setup w.r.t. racial groups distribution for twoseparate minority groups in comparison with the majority group before and afterdebiasing. Empirical results imply that our method of augmenting dataset biasesusing real (genuine) data from similar contexts can effectively debias thetarget datasets comparably to existing data augmentation strategies.</description><author>Siamak Ghodsi, Eirini Ntoutsi</author><pubDate>Fri, 02 Jun 2023 18:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01699v1</guid></item><item><title>Diffusion Self-Guidance for Controllable Image Generation</title><link>http://arxiv.org/abs/2306.00986v2</link><description>Large-scale generative models are capable of producing high-quality imagesfrom detailed text descriptions. However, many aspects of an image aredifficult or impossible to convey through text. We introduce self-guidance, amethod that provides greater control over generated images by guiding theinternal representations of diffusion models. We demonstrate that propertiessuch as the shape, location, and appearance of objects can be extracted fromthese representations and used to steer sampling. Self-guidance works similarlyto classifier guidance, but uses signals present in the pretrained modelitself, requiring no additional models or training. We show how a simple set ofproperties can be composed to perform challenging image manipulations, such asmodifying the position or size of objects, merging the appearance of objects inone image with the layout of another, composing objects from many images intoone, and more. We also show that self-guidance can be used to edit real images.For results and an interactive demo, see our project page athttps://dave.ml/selfguidance/</description><author>Dave Epstein, Allan Jabri, Ben Poole, Alexei A. Efros, Aleksander Holynski</author><pubDate>Fri, 02 Jun 2023 18:16:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00986v2</guid></item><item><title>MutateNN: Mutation Testing of Image Recognition Models Deployed on Hardware Accelerators</title><link>http://arxiv.org/abs/2306.01697v1</link><description>With the research advancement of Artificial Intelligence in the last years,there are new opportunities to mitigate real-world problems and advancetechnologically. Image recognition models in particular, are assigned withperception tasks to mitigate complex real-world challenges and lead to newsolutions. Furthermore, the computational complexity and demand for resourcesof such models has also increased. To mitigate this, model optimization andhardware acceleration has come into play, but effectively integrating suchconcepts is a challenging and error-prone process. In order to allow developers and researchers to explore the robustness ofdeep learning image recognition models deployed on different hardwareacceleration devices, we propose MutateNN, a tool that provides mutationtesting and analysis capabilities for that purpose. To showcase itscapabilities, we utilized 21 mutations for 7 widely-known pre-trained deepneural network models. We deployed our mutants on 4 different devices ofvarying computational capabilities and observed discrepancies in mutantsrelated to conditional operations, as well as some unstable behaviour withthose related to arithmetic types.</description><author>Nikolaos Louloudakis, Perry Gibson, José Cano, Ajitha Rajan</author><pubDate>Fri, 02 Jun 2023 18:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01697v1</guid></item><item><title>Evaluating Language Models for Mathematics through Interactions</title><link>http://arxiv.org/abs/2306.01694v1</link><description>The standard methodology of evaluating large language models (LLMs) based onstatic pairs of inputs and outputs is insufficient for developing assistants:this kind of assessments fails to take into account the essential interactiveelement in their deployment, and therefore limits how we understand languagemodel capabilities. We introduce CheckMate, an adaptable prototype platform forhumans to interact with and evaluate LLMs. We conduct a study with CheckMate toevaluate three language models~(InstructGPT, ChatGPT, and GPT-4) as assistantsin proving undergraduate-level mathematics, with a mixed cohort of participantsfrom undergraduate students to professors of mathematics. We release theresulting interaction and rating dataset, MathConverse. By analysingMathConverse, we derive a preliminary taxonomy of human behaviours and uncoverthat despite a generally positive correlation, there are notable instances ofdivergence between correctness and perceived helpfulness in LLM generations,amongst other findings. Further, we identify useful scenarios and existingissues of GPT-4 in mathematical reasoning through a series of case studiescontributed by expert mathematicians. We conclude with actionable takeaways forML practitioners and mathematicians: models which communicate uncertainty,respond well to user corrections, are more interpretable and concise mayconstitute better assistants; interactive evaluation is a promising way tocontinually navigate the capability of these models; humans should be aware oflanguage models' algebraic fallibility, and for that reason discern where theyshould be used.</description><author>Katherine M. Collins, Albert Q. Jiang, Simon Frieder, Lionel Wong, Miri Zilka, Umang Bhatt, Thomas Lukasiewicz, Yuhuai Wu, Joshua B. Tenenbaum, William Hart, Timothy Gowers, Wenda Li, Adrian Weller, Mateja Jamnik</author><pubDate>Fri, 02 Jun 2023 18:12:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01694v1</guid></item><item><title>Long-Horizon Planning and Execution with Functional Object-Oriented Networks</title><link>http://arxiv.org/abs/2207.05800v6</link><description>Following work on joint object-action representations, functionalobject-oriented networks (FOON) were introduced as a knowledge graphrepresentation for robots. A FOON contains symbolic concepts useful to arobot's understanding of tasks and its environment for object-level planning.Prior to this work, little has been done to show how plans acquired from FOONcan be executed by a robot, as the concepts in a FOON are too abstract forexecution. We thereby introduce the idea of exploiting object-level knowledgeas a FOON for task planning and execution. Our approach automaticallytransforms FOON into PDDL and leverages off-the-shelf planners, actioncontexts, and robot skills in a hierarchical planning pipeline to generateexecutable task plans. We demonstrate our entire approach on long-horizon tasksin CoppeliaSim and show how learned action contexts can be extended tonever-before-seen scenarios.</description><author>David Paulius, Alejandro Agostini, Dongheui Lee</author><pubDate>Fri, 02 Jun 2023 18:12:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.05800v6</guid></item><item><title>Fine-Grained Human Feedback Gives Better Rewards for Language Model Training</title><link>http://arxiv.org/abs/2306.01693v1</link><description>Language models (LMs) often exhibit undesirable text generation behaviors,including generating false, toxic, or irrelevant outputs. Reinforcementlearning from human feedback (RLHF) - where human preference judgments on LMoutputs are transformed into a learning signal - has recently shown promise inaddressing these issues. However, such holistic feedback conveys limitedinformation on long text outputs; it does not indicate which aspects of theoutputs influenced user preference; e.g., which parts contain what type(s) oferrors. In this paper, we use fine-grained human feedback (e.g., which sentenceis false, which sub-sentence is irrelevant) as an explicit training signal. Weintroduce Fine-Grained RLHF, a framework that enables training and learningfrom reward functions that are fine-grained in two respects: (1) density,providing a reward after every segment (e.g., a sentence) is generated; and (2)incorporating multiple reward models associated with different feedback types(e.g., factual incorrectness, irrelevance, and information incompleteness). Weconduct experiments on detoxification and long-form question answering toillustrate how learning with such reward functions leads to improvedperformance, supported by both automatic and human evaluation. Additionally, weshow that LM behaviors can be customized using different combinations offine-grained reward models. We release all data, collected human feedback, andcodes at https://FineGrainedRLHF.github.io.</description><author>Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj Ammanabrolu, Noah A. Smith, Mari Ostendorf, Hannaneh Hajishirzi</author><pubDate>Fri, 02 Jun 2023 18:11:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01693v1</guid></item><item><title>Uniform Convergence of Deep Neural Networks with Lipschitz Continuous Activation Functions and Variable Widths</title><link>http://arxiv.org/abs/2306.01692v1</link><description>We consider deep neural networks with a Lipschitz continuous activationfunction and with weight matrices of variable widths. We establish a uniformconvergence analysis framework in which sufficient conditions on weightmatrices and bias vectors together with the Lipschitz constant are provided toensure uniform convergence of the deep neural networks to a meaningful functionas the number of their layers tends to infinity. In the framework, specialresults on uniform convergence of deep neural networks with a fixed width,bounded widths and unbounded widths are presented. In particular, asconvolutional neural networks are special deep neural networks with weightmatrices of increasing widths, we put forward conditions on the mask sequencewhich lead to uniform convergence of resulting convolutional neural networks.The Lipschitz continuity assumption on the activation functions allows us toinclude in our theory most of commonly used activation functions inapplications.</description><author>Yuesheng Xu, Haizhang Zhang</author><pubDate>Fri, 02 Jun 2023 18:07:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01692v1</guid></item><item><title>GateON: an unsupervised method for large scale continual learning</title><link>http://arxiv.org/abs/2306.01690v1</link><description>The objective of continual learning (CL) is to learn tasks sequentiallywithout retraining on earlier tasks. However, when subjected to CL, traditionalneural networks exhibit catastrophic forgetting and limited generalization. Toovercome these problems, we introduce a novel method called 'Gate and ObstructNetwork' (GateON). GateON combines learnable gating of activity and onlineestimation of parameter relevance to safeguard crucial knowledge from beingoverwritten. Our method generates partially overlapping pathways between taskswhich permits forward and backward transfer during sequential learning. GateONaddresses the issue of network saturation after parameter fixation by are-activation mechanism of fixed neurons, enabling large-scale continuallearning. GateON is implemented on a wide range of networks (fully-connected,CNN, Transformers), has low computational complexity, effectively learns up to100 MNIST learning tasks, and achieves top-tier results for pre-trained BERT inCL-based NLP tasks.</description><author>Martin Barry, Guillaume Bellec, Wulfram Gerstner</author><pubDate>Fri, 02 Jun 2023 18:04:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01690v1</guid></item><item><title>Unique Brain Network Identification Number for Parkinson's Individuals Using Structural MRI</title><link>http://arxiv.org/abs/2306.01689v1</link><description>We propose a novel algorithm called Unique Brain Network IdentificationNumber (UBNIN) for encoding brain networks of individual subject. To realizethis objective, we employed T1-weighted structural MRI of 180 Parkinson'sdisease (PD) patients from National Institute of Mental Health andNeurosciences, India. We parcellated each subject's brain volume andconstructed individual adjacency matrix using correlation between grey matter(GM) volume of every pair of regions. The unique code is derived from valuesrepresenting connections of every node (i), weighted by a factor of 2^-(i-1).The numerical representation UBNIN was observed to be distinct for eachindividual brain network, which may also be applied to other neuroimagingmodalities. This model may be implemented as neural signature of a person'sunique brain connectivity, thereby useful for brainprinting applications.Additionally, we segregated the above dataset into five age-cohorts:A:22-32years, B:33-42years, C:43-52years, D:53-62years and E:63-72years tostudy the variation in network topology over age. Sparsity was adopted as thethreshold estimate to binarize each age-based correlation matrix. Connectivitymetrics were obtained using Brain Connectivity toolbox-based MATLAB functions.For each age-cohort, a decreasing trend was observed in mean clusteringcoefficient with increasing sparsity. Significantly different clusteringcoefficient was noted between age-cohort B and C (sparsity: 0.63,0.66), C and E(sparsity: 0.66,0.69). Our findings suggest network connectivity patternschange with age, indicating network disruption due to the underlyingneuropathology. Varying clustering coefficient for different cohorts indicatethat information transfer between neighboring nodes change with age. Thisprovides evidence on age-related brain shrinkage and network degeneration.</description><author>Tanmayee Samantaray, Utsav Gupta, Jitender Saini, Cota Navin Gupta</author><pubDate>Fri, 02 Jun 2023 18:03:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01689v1</guid></item><item><title>MKOR: Momentum-Enabled Kronecker-Factor-Based Optimizer Using Rank-1 Updates</title><link>http://arxiv.org/abs/2306.01685v1</link><description>This work proposes a Momentum-Enabled Kronecker-Factor-Based Optimizer UsingRank-1 updates, called MKOR, that improves the training time and convergenceproperties of deep neural networks (DNNs). Second-order techniques, whileenjoying higher convergence rates vs first-order counterparts, have cubiccomplexity with respect to either the model size and/or the training batchsize. Hence they exhibit poor scalability and performance in transformermodels, e.g. large language models (LLMs), because the batch sizes in thesemodels scale by the attention mechanism sequence length, leading to large modelsize and batch sizes. MKOR's complexity is quadratic with respect to the modelsize, alleviating the computation bottlenecks in second-order methods. Becauseof their high computation complexity, state-of-the-art implementations ofsecond-order methods can only afford to update the second order informationinfrequently, and thus do not fully exploit the promise of better convergencefrom these updates. By reducing the communication complexity of thesecond-order updates as well as achieving a linear communication complexity,MKOR increases the frequency of second order updates. We also propose a hybridversion of MKOR (called MKOR-H) that mid-training falls backs to a first orderoptimizer if the second order updates no longer accelerate convergence. Ourexperiments show that MKOR outperforms state -of-the-art first order methods,e.g. the LAMB optimizer, and best implementations of second-order methods, i.e.KAISA/KFAC, up to 2.57x and 1.85x respectively on BERT-Large-Uncased on 64GPUs.</description><author>Mohammad Mozaffari, Sikan Li, Zhao Zhang, Maryam Mehri Dehnavi</author><pubDate>Fri, 02 Jun 2023 18:00:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01685v1</guid></item><item><title>Harnessing large-language models to generate private synthetic text</title><link>http://arxiv.org/abs/2306.01684v1</link><description>Differentially private (DP) training methods like DP-SGD can protectsensitive training data by ensuring that ML models will not reveal privateinformation. An alternative approach, which this paper studies, is to use asensitive dataset to generate a new synthetic dataset which is differentiallyprivate with respect to the original data. Doing so has several advantages:synthetic data can be reused for other tasks (including for hyper parametertuning), retained indefinitely, or shared with third parties withoutsacrificing privacy. However, obtaining DP data is much harder than introducing DP duringtraining. To make it feasible for text, recent work has utilized public data bystarting with a pre-trained generative language model and privately finetuningit on sensitive data. This model can be used to sample a DP synthetic dataset.While this strategy seems straightforward, executing it has proven problematic.Previous approaches either show significant performance loss, or have, as weshow, critical design flaws. In this paper we demonstrate that a proper training objective along withtuning fewer parameters results in excellent DP synthetic data quality. Ourapproach is competitive with direct DP-training of downstream classifiers interms of performance on downstream tasks. We also demonstrate that our DPsynthetic data is not only useful for downstream classifier training, but alsoto tune those same models.</description><author>Alexey Kurakin, Natalia Ponomareva, Umar Syed, Liam MacDermed, Andreas Terzis</author><pubDate>Fri, 02 Jun 2023 17:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01684v1</guid></item><item><title>Balancing Exploration and Exploitation: Disentangled $β$-CVAE in De Novo Drug Design</title><link>http://arxiv.org/abs/2306.01683v1</link><description>Deep generative models have recently emerged as a promising de novo drugdesign method. In this respect, deep generative conditional variationalautoencoder (CVAE) models are a powerful approach for generating novelmolecules with desired drug-like properties. However, molecular graph-basedmodels with disentanglement and multivariate explicit latent conditioning havenot been fully elucidated. To address this, we proposed a molecular-graph$\beta$-CVAE model for de novo drug design. Here, we empirically tuned thevalue of disentanglement and assessed its ability to generate molecules withoptimised univariate- or-multivariate properties. In particular, we optimisedthe octanol-water partition coefficient (ClogP), molar refractivity (CMR),quantitative estimate of drug-likeness (QED), and synthetic accessibility score(SAS). Results suggest that a lower $\beta$ value increases the uniqueness ofgenerated molecules (exploration). Univariate optimisation results showed ourmodel generated molecular property averages of ClogP = 41.07% $\pm$ 0.01% andCMR 66.76% $\pm$ 0.01% by the Ghose filter. Multivariate property optimisationresults showed that our model generated an average of 30.07% $\pm$ 0.01%molecules for both desired properties. Furthermore, our model improved the QEDand SAS (exploitation) of molecules generated. Together, these results suggestthat the $\beta$-CVAE could balance exploration and exploitation throughdisentanglement and is a promising model for de novo drug design, thusproviding a basis for future studies.</description><author>Guang Jun Nicholas Ang, De Tao Irwin Chin, Bingquan Shen</author><pubDate>Fri, 02 Jun 2023 17:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01683v1</guid></item><item><title>Neural Differential Recurrent Neural Network with Adaptive Time Steps</title><link>http://arxiv.org/abs/2306.01674v1</link><description>The neural Ordinary Differential Equation (ODE) model has shown success inlearning complex continuous-time processes from observations on discrete timestamps. In this work, we consider the modeling and forecasting of time seriesdata that are non-stationary and may have sharp changes like spikes. We proposean RNN-based model, called RNN-ODE-Adap, that uses a neural ODE to representthe time development of the hidden states, and we adaptively select time stepsbased on the steepness of changes of the data over time so as to train themodel more efficiently for the "spike-like" time series. Theoretically,RNN-ODE-Adap yields provably a consistent estimation of the intensity functionfor the Hawkes-type time series data. We also provide an approximation analysisof the RNN-ODE model showing the benefit of adaptive steps. The proposed modelis demonstrated to achieve higher prediction accuracy with reducedcomputational cost on simulated dynamic system data and point process data andon a real electrocardiography dataset.</description><author>Yixuan Tan, Liyan Xie, Xiuyuan Cheng</author><pubDate>Fri, 02 Jun 2023 17:46:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01674v1</guid></item><item><title>Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning</title><link>http://arxiv.org/abs/2306.01669v1</link><description>Fine-tuning vision-language models (VLMs) like CLIP to downstream tasks isoften necessary to optimize their performance. However, a major obstacle is thelimited availability of labeled data. We study the use of pseudolabels, i.e.,heuristic labels for unlabeled data, to enhance CLIP via prompt tuning.Conventional pseudolabeling trains a model on labeled data and then generateslabels for unlabeled data. VLMs' zero-shot capabilities enable a ``secondgeneration'' of pseudolabeling approaches that do not require task-specifictraining on labeled data. By using zero-shot pseudolabels as a source ofsupervision, we observe that learning paradigms such as semi-supervised,transductive zero-shot, and unsupervised learning can all be seen as optimizingthe same loss function. This unified view enables the development of versatiletraining strategies that are applicable across learning paradigms. Weinvestigate them on image classification tasks where CLIP exhibits limitations,by varying prompt modalities, e.g., textual or visual prompts, and learningparadigms. We find that (1) unexplored prompt tuning strategies thatiteratively refine pseudolabels consistently improve CLIP accuracy, by 19.5points in semi-supervised learning, by 28.4 points in transductive zero-shotlearning, and by 15.2 points in unsupervised learning, and (2) unlikeconventional semi-supervised pseudolabeling, which exacerbates model biasestoward classes with higher-quality pseudolabels, prompt tuning leads to a moreequitable distribution of per-class accuracy. The code to reproduce theexperiments is at github.com/BatsResearch/menghini-enhanceCLIPwithCLIP-code.</description><author>Cristina Menghini, Andrew Delworth, Stephen H. Bach</author><pubDate>Fri, 02 Jun 2023 17:43:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01669v1</guid></item><item><title>XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models</title><link>http://arxiv.org/abs/2306.01668v1</link><description>As machine learning models become increasingly prevalent in medicaldiagnostics, the need for interpretability and transparency becomes paramount.The XAI Renaissance signifies a significant shift in the field, aiming toredefine the interpretability of medical diagnostic models. This paper exploresthe innovative approaches and methodologies within the realm of Explainable AI(XAI) that are revolutionizing the interpretability of medical diagnosticmodels. By shedding light on the underlying decision-making process, XAItechniques empower healthcare professionals to understand, trust, andeffectively utilize these models for accurate and reliable medical diagnoses.This review highlights the key advancements in XAI for medical diagnostics andtheir potential to transform the healthcare landscape, ultimately improvingpatient outcomes and fostering trust in AI-driven diagnostic systems.</description><author>Sujith K Mandala</author><pubDate>Fri, 02 Jun 2023 17:42:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01668v1</guid></item><item><title>Towards In-context Scene Understanding</title><link>http://arxiv.org/abs/2306.01667v1</link><description>In-context learning$\unicode{x2013}$the ability to configure a model'sbehavior with different prompts$\unicode{x2013}$has revolutionized the field ofnatural language processing, alleviating the need for task-specific models andpaving the way for generalist models capable of assisting with any query.Computer vision, in contrast, has largely stayed in the former regime:specialized decoders and finetuning protocols are generally required to performdense tasks such as semantic segmentation and depth estimation. In this work weexplore a simple mechanism for in-context learning of such scene understandingtasks: nearest neighbor retrieval from a prompt of annotated features. Wepropose a new pretraining protocol$\unicode{x2013}$leveraging attention withinand across images$\unicode{x2013}$which yields representations particularlyuseful in this regime. The resulting Hummingbird model, suitably prompted,performs various scene understanding tasks without modification whileapproaching the performance of specialists that have been finetuned for eachtask. Moreover, Hummingbird can be configured to perform new tasks much moreefficiently than finetuned models, raising the possibility of sceneunderstanding in the interactive assistant regime.</description><author>Ivana Balažević, David Steiner, Nikhil Parthasarathy, Relja Arandjelović, Olivier J. Hénaff</author><pubDate>Fri, 02 Jun 2023 17:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01667v1</guid></item><item><title>SourceP: Smart Ponzi Schemes Detection on Ethereum Using Pre-training Model with Data Flow</title><link>http://arxiv.org/abs/2306.01665v1</link><description>As blockchain technology becomes more and more popular, a typical financialscam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum.This Ponzi scheme deployed through smart contracts, also known as the smartPonzi scheme, has caused a lot of economic losses and negative impacts.Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely onbytecode features, opcode features, account features, and transaction behaviorfeatures of smart contracts, and such methods lack interpretability andsustainability. In this paper, we propose SourceP, a method to detect smartPonzi schemes on the Ethereum platform using pre-training models and data flow,which only requires using the source code of smart contracts as features toexplore the possibility of detecting smart Ponzi schemes from anotherdirection. SourceP reduces the difficulty of data acquisition and featureextraction of existing detection methods while increasing the interpretabilityof the model. Specifically, we first convert the source code of a smartcontract into a data flow graph and then introduce a pre-training model basedon learning code representations to build a classification model to identifyPonzi schemes in smart contracts. The experimental results show that SourcePachieves 87.2\% recall and 90.7\% F-score for detecting smart Ponzi schemeswithin Ethereum's smart contract dataset, outperforming state-of-the-artmethods in terms of performance and sustainability. We also demonstrate throughadditional experiments that pre-training models and data flow play an importantcontribution to SourceP, as well as proving that SourceP has a goodgeneralization ability.</description><author>Pengcheng Lu, Liang Cai, Keting Yin</author><pubDate>Fri, 02 Jun 2023 17:40:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01665v1</guid></item><item><title>Enhanced Gaussian Process Dynamical Models with Knowledge Transfer for Long-term Battery Degradation Forecasting</title><link>http://arxiv.org/abs/2212.01609v3</link><description>Predicting the end-of-life or remaining useful life of batteries in electricvehicles is a critical and challenging problem, predominantly approached inrecent years using machine learning to predict the evolution of thestate-of-health during repeated cycling. To improve the accuracy of predictiveestimates, especially early in the battery lifetime, a number of algorithmshave incorporated features that are available from data collected by batterymanagement systems. Unless multiple battery data sets are used for a directprediction of the end-of-life, which is useful for ball-park estimates, such anapproach is infeasible since the features are not known for future cycles. Inthis paper, we develop a highly-accurate method that can overcome thislimitation, by using a modified Gaussian process dynamical model (GPDM). Weintroduce a kernelised version of GPDM for a more expressive covariancestructure between both the observable and latent coordinates. We combine theapproach with transfer learning to track the future state-of-health up toend-of-life. The method can incorporate features as different physicalobservables, without requiring their values beyond the time up to which data isavailable. Transfer learning is used to improve learning of the hyperparametersusing data from similar batteries. The accuracy and superiority of the approachover modern benchmarks algorithms including a Gaussian process model and deepconvolutional and recurrent networks are demonstrated on three data sets,particularly at the early stages of the battery lifetime.</description><author>Wei W. Xing, Ziyang Zhang, Akeel A. Shah</author><pubDate>Fri, 02 Jun 2023 17:38:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.01609v3</guid></item><item><title>An Adaptive Method for Weak Supervision with Drifting Data</title><link>http://arxiv.org/abs/2306.01658v1</link><description>We introduce an adaptive method with formal quality guarantees for weaksupervision in a non-stationary setting. Our goal is to infer the unknownlabels of a sequence of data by using weak supervision sources that provideindependent noisy signals of the correct classification for each data point.This setting includes crowdsourcing and programmatic weak supervision. We focuson the non-stationary case, where the accuracy of the weak supervision sourcescan drift over time, e.g., because of changes in the underlying datadistribution. Due to the drift, older data could provide misleading informationto infer the label of the current data point. Previous work relied on a prioriassumptions on the magnitude of the drift to decide how much data to use fromthe past. Comparatively, our algorithm does not require any assumptions on thedrift, and it adapts based on the input. In particular, at each step, ouralgorithm guarantees an estimation of the current accuracies of the weaksupervision sources over a window of past observations that minimizes atrade-off between the error due to the variance of the estimation and the errordue to the drift. Experiments on synthetic and real-world labelers show thatour approach indeed adapts to the drift. Unlike fixed-window-size strategies,it dynamically chooses a window size that allows it to consistently maintaingood performance.</description><author>Alessio Mazzetto, Reza Esfandiarpoor, Eli Upfal, Stephen H. Bach</author><pubDate>Fri, 02 Jun 2023 17:27:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01658v1</guid></item><item><title>DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control for Empathetic Response Generation</title><link>http://arxiv.org/abs/2306.01657v1</link><description>Empathy is a crucial factor in open-domain conversations, which naturallyshows one's caring and understanding to others. Though several methods havebeen proposed to generate empathetic responses, existing works often lead tomonotonous empathy that refers to generic and safe expressions. In this paper,we propose to use explicit control to guide the empathy expression and design aframework DiffusEmp based on conditional diffusion language model to unify theutilization of dialogue context and attribute-oriented control signals.Specifically, communication mechanism, intent, and semantic frame are importedas multi-grained signals that control the empathy realization from coarse tofine levels. We then design a specific masking strategy to reflect therelationship between multi-grained signals and response tokens, and integrateit into the diffusion model to influence the generative process. Experimentalresults on a benchmark dataset EmpatheticDialogue show that our frameworkoutperforms competitive baselines in terms of controllability, informativeness,and diversity without the loss of context-relatedness.</description><author>Guanqun Bi, Lei Shen, Yanan Cao, Meng Chen, Yuqiang Xie, Zheng Lin, Xiaodong He</author><pubDate>Fri, 02 Jun 2023 17:26:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01657v1</guid></item><item><title>Backchannel Detection and Agreement Estimation from Video with Transformer Networks</title><link>http://arxiv.org/abs/2306.01656v1</link><description>Listeners use short interjections, so-called backchannels, to signifyattention or express agreement. The automatic analysis of this behavior is ofkey importance for human conversation analysis and interactive conversationalagents. Current state-of-the-art approaches for backchannel analysis fromvisual behavior make use of two types of features: features based on body poseand features based on facial behavior. At the same time, transformer neuralnetworks have been established as an effective means to fuse input fromdifferent data sources, but they have not yet been applied to backchannelanalysis. In this work, we conduct a comprehensive evaluation of multi-modaltransformer architectures for automatic backchannel analysis based on pose andfacial information. We address both the detection of backchannels as well asthe task of estimating the agreement expressed in a backchannel. In evaluationson the MultiMediate'22 backchannel detection challenge, we reach 66.4% accuracywith a one-layer transformer architecture, outperforming the previous state ofthe art. With a two-layer transformer architecture, we furthermore set a newstate of the art (0.0604 MSE) on the task of estimating the amount of agreementexpressed in a backchannel.</description><author>Ahmed Amer, Chirag Bhuvaneshwara, Gowtham K. Addluri, Mohammed M. Shaik, Vedant Bonde, Philipp Müller</author><pubDate>Fri, 02 Jun 2023 17:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01656v1</guid></item><item><title>Poisoning Network Flow Classifiers</title><link>http://arxiv.org/abs/2306.01655v1</link><description>As machine learning (ML) classifiers increasingly oversee the automatedmonitoring of network traffic, studying their resilience against adversarialattacks becomes critical. This paper focuses on poisoning attacks, specificallybackdoor attacks, against network traffic flow classifiers. We investigate thechallenging scenario of clean-label poisoning where the adversary'scapabilities are constrained to tampering only with the training data - withoutthe ability to arbitrarily modify the training labels or any other component ofthe training process. We describe a trigger crafting strategy that leveragesmodel interpretability techniques to generate trigger patterns that areeffective even at very low poisoning rates. Finally, we design novel strategiesto generate stealthy triggers, including an approach based on generativeBayesian network models, with the goal of minimizing the conspicuousness of thetrigger, and thus making detection of an ongoing poisoning campaign morechallenging. Our findings provide significant insights into the feasibility ofpoisoning attacks on network traffic classifiers used in multiple scenarios,including detecting malicious communication and application classification.</description><author>Giorgio Severi, Simona Boboila, Alina Oprea, John Holodnak, Kendra Kratkiewicz, Jason Matterer</author><pubDate>Fri, 02 Jun 2023 17:24:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01655v1</guid></item><item><title>GANs Settle Scores!</title><link>http://arxiv.org/abs/2306.01654v1</link><description>Generative adversarial networks (GANs) comprise a generator, trained to learnthe underlying distribution of the desired data, and a discriminator, trainedto distinguish real samples from those output by the generator. A majority ofGAN literature focuses on understanding the optimality of the discriminatorthrough integral probability metric (IPM) or divergence based analysis. In thispaper, we propose a unified approach to analyzing the generator optimizationthrough variational approach. In $f$-divergence-minimizing GANs, we show thatthe optimal generator is the one that matches the score of its outputdistribution with that of the data distribution, while in IPM GANs, we showthat this optimal generator matches score-like functions, involving theflow-field of the kernel associated with a chosen IPM constraint space.Further, the IPM-GAN optimization can be seen as one of smoothedscore-matching, where the scores of the data and the generator distributionsare convolved with the kernel associated with the constraint. The proposedapproach serves to unify score-based training and existing GAN flavors,leveraging results from normalizing flows, while also providing explanationsfor empirical phenomena such as the stability of non-saturating GAN losses.Based on these results, we propose novel alternatives to $f$-GAN and IPM-GANtraining based on score and flow matching, and discriminator-guided Langevinsampling.</description><author>Siddarth Asokan, Nishanth Shetty, Aadithya Srikanth, Chandra Sekhar Seelamantula</author><pubDate>Fri, 02 Jun 2023 17:24:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01654v1</guid></item><item><title>InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language</title><link>http://arxiv.org/abs/2305.05662v4</link><description>We present an interactive visual framework named InternGPT, or iGPT forshort. The framework integrates chatbots that have planning and reasoningcapabilities, such as ChatGPT, with non-verbal instructions like pointingmovements that enable users to directly manipulate images or videos on thescreen. Pointing (including gestures, cursors, etc.) movements can provide moreflexibility and precision in performing vision-centric tasks that requirefine-grained control, editing, and generation of visual content. The nameInternGPT stands for \textbf{inter}action, \textbf{n}onverbal, and\textbf{chat}bots. Different from existing interactive systems that rely onpure language, by incorporating pointing instructions, the proposed iGPTsignificantly improves the efficiency of communication between users andchatbots, as well as the accuracy of chatbots in vision-centric tasks,especially in complicated visual scenarios where the number of objects isgreater than 2. Additionally, in iGPT, an auxiliary control mechanism is usedto improve the control capability of LLM, and a large vision-language modeltermed Husky is fine-tuned for high-quality multi-modal dialogue (impressingChatGPT-3.5-turbo with 93.89\% GPT-4 Quality). We hope this work can spark newideas and directions for future interactive visual systems. Welcome to watchthe code at https://github.com/OpenGVLab/InternGPT.</description><author>Zhaoyang Liu, Yinan He, Wenhai Wang, Weiyun Wang, Yi Wang, Shoufa Chen, Qinglong Zhang, Zeqiang Lai, Yang Yang, Qingyun Li, Jiashuo Yu, Kunchang Li, Zhe Chen, Xue Yang, Xizhou Zhu, Yali Wang, Limin Wang, Ping Luo, Jifeng Dai, Yu Qiao</author><pubDate>Fri, 02 Jun 2023 17:19:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05662v4</guid></item><item><title>Fair multilingual vandalism detection system for Wikipedia</title><link>http://arxiv.org/abs/2306.01650v1</link><description>This paper presents a novel design of the system aimed at supporting theWikipedia community in addressing vandalism on the platform. To achieve this,we collected a massive dataset of 47 languages, and applied advanced filteringand feature engineering techniques, including multilingual masked languagemodeling to build the training dataset from human-generated data. Theperformance of the system was evaluated through comparison with the one used inproduction in Wikipedia, known as ORES. Our research results in a significantincrease in the number of languages covered, making Wikipedia patrolling moreefficient to a wider range of communities. Furthermore, our model outperformsORES, ensuring that the results provided are not only more accurate but alsoless biased against certain groups of contributors.</description><author>Mykola Trokhymovych, Muniza Aslam, Ai-Jou Chou, Ricardo Baeza-Yates, Diego Saez-Trumper</author><pubDate>Fri, 02 Jun 2023 17:19:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01650v1</guid></item><item><title>PrefRec: Recommender Systems with Human Preferences for Reinforcing Long-term User Engagement</title><link>http://arxiv.org/abs/2212.02779v2</link><description>Current advances in recommender systems have been remarkably successful inoptimizing immediate engagement. However, long-term user engagement, a moredesirable performance metric, remains difficult to improve. Meanwhile, recentreinforcement learning (RL) algorithms have shown their effectiveness in avariety of long-term goal optimization tasks. For this reason, RL is widelyconsidered as a promising framework for optimizing long-term user engagement inrecommendation. Though promising, the application of RL heavily relies onwell-designed rewards, but designing rewards related to long-term userengagement is quite difficult. To mitigate the problem, we propose a novelparadigm, recommender systems with human preferences (or Preference-basedRecommender systems), which allows RL recommender systems to learn frompreferences about users historical behaviors rather than explicitly definedrewards. Such preferences are easily accessible through techniques such ascrowdsourcing, as they do not require any expert knowledge. With PrefRec, wecan fully exploit the advantages of RL in optimizing long-term goals, whileavoiding complex reward engineering. PrefRec uses the preferences toautomatically train a reward function in an end-to-end manner. The rewardfunction is then used to generate learning signals to train the recommendationpolicy. Furthermore, we design an effective optimization method for PrefRec,which uses an additional value function, expectile regression and reward modelpre-training to improve the performance. We conduct experiments on a variety oflong-term user engagement optimization tasks. The results show that PrefRecsignificantly outperforms previous state-of-the-art methods in all the tasks.</description><author>Wanqi Xue, Qingpeng Cai, Zhenghai Xue, Shuo Sun, Shuchang Liu, Dong Zheng, Peng Jiang, Kun Gai, Bo An</author><pubDate>Fri, 02 Jun 2023 17:19:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.02779v2</guid></item><item><title>Federated Multi-Sequence Stochastic Approximation with Local Hypergradient Estimation</title><link>http://arxiv.org/abs/2306.01648v1</link><description>Stochastic approximation with multiple coupled sequences (MSA) has foundbroad applications in machine learning as it encompasses a rich class ofproblems including bilevel optimization (BLO), multi-level compositionaloptimization (MCO), and reinforcement learning (specifically, actor-criticmethods). However, designing provably-efficient federated algorithms for MSAhas been an elusive question even for the special case of double sequenceapproximation (DSA). Towards this goal, we develop FedMSA which is the firstfederated algorithm for MSA, and establish its near-optimal communicationcomplexity. As core novelties, (i) FedMSA enables the provable estimation ofhypergradients in BLO and MCO via local client updates, which has been anotable bottleneck in prior theory, and (ii) our convergence guarantees aresensitive to the heterogeneity-level of the problem. We also incorporatemomentum and variance reduction techniques to achieve further accelerationleading to near-optimal rates. Finally, we provide experiments that support ourtheory and demonstrate the empirical benefits of FedMSA. As an example, FedMSAenables order-of-magnitude savings in communication rounds compared to priorfederated BLO schemes.</description><author>Davoud Ataee Tarzanagh, Mingchen Li, Pranay Sharma, Samet Oymak</author><pubDate>Fri, 02 Jun 2023 17:17:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01648v1</guid></item><item><title>Auditing for Human Expertise</title><link>http://arxiv.org/abs/2306.01646v1</link><description>High-stakes prediction tasks (e.g., patient diagnosis) are often handled bytrained human experts. A common source of concern about automation in thesesettings is that experts may exercise intuition that is difficult to modeland/or have access to information (e.g., conversations with a patient) that issimply unavailable to a would-be algorithm. This raises a natural questionwhether human experts add value which could not be captured by an algorithmicpredictor. We develop a statistical framework under which we can pose thisquestion as a natural hypothesis test. Indeed, as our framework highlights,detecting human expertise is more subtle than simply comparing the accuracy ofexpert predictions to those made by a particular learning algorithm. Instead,we propose a simple procedure which tests whether expert predictions arestatistically independent from the outcomes of interest after conditioning onthe available inputs (`features'). A rejection of our test thus suggests thathuman experts may add value to any algorithm trained on the available data, andhas direct implications for whether human-AI `complementarity' is achievable ina given prediction task. We highlight the utility of our procedure usingadmissions data collected from the emergency department of a large academichospital system, where we show that physicians' admit/discharge decisions forpatients with acute gastrointestinal bleeding (AGIB) appear to be incorporatinginformation not captured in a standard algorithmic screening tool. This isdespite the fact that the screening tool is arguably more accurate thanphysicians' discretionary decisions, highlighting that -- even absent normativeconcerns about accountability or interpretability -- accuracy is insufficientto justify algorithmic automation.</description><author>Rohan Alur, Loren Laine, Darrick K. Li, Manish Raghavan, Devavrat Shah, Dennis Shung</author><pubDate>Fri, 02 Jun 2023 17:15:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01646v1</guid></item><item><title>Automatic Reconstruction of Semantic 3D Models from 2D Floor Plans</title><link>http://arxiv.org/abs/2306.01642v1</link><description>Digitalization of existing buildings and the creation of 3D BIM models forthem has become crucial for many tasks. Of particular importance are floorplans, which contain information about building layouts and are vital forprocesses such as construction, maintenance or refurbishing. However, this datais not always available in digital form, especially for older buildingsconstructed before CAD tools were widely available, or lacks semanticinformation. The digitalization of such information usually requires manualwork of an expert that must reconstruct the layouts by hand, which is acumbersome and error-prone process. In this paper, we present a pipeline forreconstruction of vectorized 3D models from scanned 2D plans, aiming atincreasing the efficiency of this process. The method presented achievesstate-of-the-art results in the public dataset CubiCasa5k, and shows goodgeneralization to different types of plans. Our vectorization approach isparticularly effective, outperforming previous methods.</description><author>Aleixo Cambeiro Barreiro, Mariusz Trzeciakiewicz, Anna Hilsmann, Peter Eisert</author><pubDate>Fri, 02 Jun 2023 17:06:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01642v1</guid></item><item><title>Reduction of finite sampling noise in quantum neural networks</title><link>http://arxiv.org/abs/2306.01639v1</link><description>Quantum neural networks (QNNs) use parameterized quantum circuits withdata-dependent inputs and generate outputs through the evaluation ofexpectation values. Calculating these expectation values necessitates repeatedcircuit evaluations, thus introducing fundamental finite-sampling noise even onerror-free quantum computers. We reduce this noise by introducing the varianceregularization, a technique for reducing the variance of the expectation valueduring the quantum model training. This technique requires no additionalcircuit evaluations if the QNN is properly constructed. Our empirical findingsdemonstrate the reduced variance speeds up the training and lowers the outputnoise as well as decreases the number of measurements in the gradient circuitevaluation. This regularization method is benchmarked on the regression ofmultiple functions. We show that in our examples, it lowers the variance by anorder of magnitude on average and leads to a significantly reduced noise levelof the QNN. We finally demonstrate QNN training on a real quantum device andevaluate the impact of error mitigation. Here, the optimization is practicalonly due to the reduced number shots in the gradient evaluation resulting fromthe reduced variance.</description><author>David Kreplin, Marco Roth</author><pubDate>Fri, 02 Jun 2023 16:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01639v1</guid></item><item><title>Do we become wiser with time? On causal equivalence with tiered background knowledge</title><link>http://arxiv.org/abs/2306.01638v1</link><description>Equivalence classes of DAGs (represented by CPDAGs) may be too large toprovide useful causal information. Here, we address incorporating tieredbackground knowledge yielding restricted equivalence classes represented by'tiered MPDAGs'. Tiered knowledge leads to considerable gains ininformativeness and computational efficiency: We show that construction oftiered MPDAGs only requires application of Meek's 1st rule, and that tieredMPDAGs (unlike general MPDAGs) are chain graphs with chordal components. Thisentails simplifications e.g. of determining valid adjustment sets for causaleffect estimation. Further, we characterise when one tiered ordering is moreinformative than another, providing insights into useful aspects of backgroundknowledge.</description><author>Christine W. Bang, Vanessa Didelez</author><pubDate>Fri, 02 Jun 2023 16:58:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01638v1</guid></item><item><title>Shades of Iteration: from Elgot to Kleene</title><link>http://arxiv.org/abs/2301.06202v2</link><description>Notions of iteration range from the arguably most general Elgot iteration toa very specific Kleene iteration. The fundamental nature of Elgot iteration hasbeen extensively explored by Bloom and Esik in the form of iteration theories,while Kleene iteration became extremely popular as an integral part of(untyped) formalisms, such as automata theory, regular expressions and Kleenealgebra. Here, we establish a formal connection between Elgot iteration andKleene iteration in the form of Elgot monads and Kleene monads, respectively.We also introduce a novel class of while-monads, which like Kleene monads admita relatively simple description in algebraic terms. Like Elgot monads,while-monads cover a large variety of models that meaningfully supportwhile-loops, but may fail the Kleene algebra laws, or even fail to support aKleen iteration operator altogether.</description><author>Sergey Goncharov</author><pubDate>Fri, 02 Jun 2023 16:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06202v2</guid></item><item><title>Gode -- Integrating Biochemical Knowledge Graph into Pre-training Molecule Graph Neural Network</title><link>http://arxiv.org/abs/2306.01631v1</link><description>The precise prediction of molecular properties holds paramount importance infacilitating the development of innovative treatments and comprehending theintricate interplay between chemicals and biological systems. In this study, wepropose a novel approach that integrates graph representations of individualmolecular structures with multi-domain information from biomedical knowledgegraphs (KGs). Integrating information from both levels, we can pre-train a moreextensive and robust representation for both molecule-level and KG-levelprediction tasks with our novel self-supervision strategy. For performanceevaluation, we fine-tune our pre-trained model on 11 challenging chemicalproperty prediction tasks. Results from our framework demonstrate ourfine-tuned models outperform existing state-of-the-art models.</description><author>Pengcheng Jiang</author><pubDate>Fri, 02 Jun 2023 16:49:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01631v1</guid></item><item><title>A Conditional Normalizing Flow for Accelerated Multi-Coil MR Imaging</title><link>http://arxiv.org/abs/2306.01630v1</link><description>Accelerated magnetic resonance (MR) imaging attempts to reduce acquisitiontime by collecting data below the Nyquist rate. As an ill-posed inverseproblem, many plausible solutions exist, yet the majority of deep learningapproaches generate only a single solution. We instead focus on sampling fromthe posterior distribution, which provides more comprehensive information fordownstream inference tasks. To do this, we design a novel conditionalnormalizing flow (CNF) that infers the signal component in the measurementoperator's nullspace, which is later combined with measured data to formcomplete images. Using fastMRI brain and knee data, we demonstrate fastinference and accuracy that surpasses recent posterior sampling techniques forMRI. Code is available at https://github.com/jwen307/mri_cnf/</description><author>Jeffrey Wen, Rizwan Ahmad, Philip Schniter</author><pubDate>Fri, 02 Jun 2023 16:49:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01630v1</guid></item><item><title>Contextualize Me -- The Case for Context in Reinforcement Learning</title><link>http://arxiv.org/abs/2202.04500v2</link><description>While Reinforcement Learning ( RL) has made great strides towards solvingincreasingly complicated problems, many algorithms are still brittle to evenslight environmental changes. Contextual Reinforcement Learning (cRL) providesa framework to model such changes in a principled manner, thereby enablingflexible, precise and interpretable task specification and generation. Our goalis to show how the framework of cRL contributes to improving zero-shotgeneralization in RL through meaningful benchmarks and structured reasoningabout generalization tasks. We confirm the insight that optimal behavior in cRLrequires context information, as in other related areas of partialobservability. To empirically validate this in the cRL framework, we providevarious context-extended versions of common RL environments. They are part ofthe first benchmark library, CARL, designed for generalization based on cRLextensions of popular benchmarks, which we propose as a testbed to furtherstudy general agents. We show that in the contextual setting, even simple RLenvironments become challenging - and that naive solutions are not enough togeneralize across complex context spaces.</description><author>Carolin Benjamins, Theresa Eimer, Frederik Schubert, Aditya Mohan, Sebastian Döhler, André Biedenkapp, Bodo Rosenhahn, Frank Hutter, Marius Lindauer</author><pubDate>Fri, 02 Jun 2023 16:48:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.04500v2</guid></item><item><title>Efficient Latency-Aware CNN Depth Compression via Two-Stage Dynamic Programming</title><link>http://arxiv.org/abs/2301.12187v2</link><description>Recent works on neural network pruning advocate that reducing the depth ofthe network is more effective in reducing run-time memory usage andaccelerating inference latency than reducing the width of the network throughchannel pruning. In this regard, some recent works propose depth compressionalgorithms that merge convolution layers. However, the existing algorithms havea constricted search space and rely on human-engineered heuristics. In thispaper, we propose a novel depth compression algorithm which targets generalconvolution operations. We propose a subset selection problem that replacesinefficient activation layers with identity functions and optimally mergesconsecutive convolution operations into shallow equivalent convolutionoperations for efficient end-to-end inference latency. Since the proposedsubset selection problem is NP-hard, we formulate a surrogate optimizationproblem that can be solved exactly via two-stage dynamic programming within afew seconds. We evaluate our methods and baselines by TensorRT for a fairinference latency comparison. Our method outperforms the baseline method withhigher accuracy and faster inference speed in MobileNetV2 on the ImageNetdataset. Specifically, we achieve $1.41\times$ speed-up with $0.11$\%p accuracygain in MobileNetV2-1.0 on the ImageNet.</description><author>Jinuk Kim, Yeonwoo Jeong, Deokjae Lee, Hyun Oh Song</author><pubDate>Fri, 02 Jun 2023 16:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12187v2</guid></item><item><title>Visual Question Answering: A Survey on Techniques and Common Trends in Recent Literature</title><link>http://arxiv.org/abs/2305.11033v2</link><description>Visual Question Answering (VQA) is an emerging area of interest forresearches, being a recent problem in natural language processing and imageprediction. In this area, an algorithm needs to answer questions about certainimages. As of the writing of this survey, 25 recent studies were analyzed.Besides, 6 datasets were analyzed and provided their link to download. In thiswork, several recent pieces of research in this area were investigated and adeeper analysis and comparison among them were provided, including results, thestate-of-the-art, common errors, and possible points of improvement for futureresearchers.</description><author>Ana Cláudia Akemi Matsuki de Faria, Felype de Castro Bastos, José Victor Nogueira Alves da Silva, Vitor Lopes Fabris, Valeska de Sousa Uchoa, Décio Gonçalves de Aguiar Neto, Claudio Filipi Goncalves dos Santos</author><pubDate>Fri, 02 Jun 2023 16:42:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11033v2</guid></item><item><title>HomE: Homography-Equivariant Video Representation Learning</title><link>http://arxiv.org/abs/2306.01623v1</link><description>Recent advances in self-supervised representation learning have enabled moreefficient and robust model performance without relying on extensive labeleddata. However, most works are still focused on images, with few working onvideos and even fewer on multi-view videos, where more powerful inductivebiases can be leveraged for self-supervision. In this work, we propose a novelmethod for representation learning of multi-view videos, where we explicitlymodel the representation space to maintain Homography Equivariance (HomE). Ourmethod learns an implicit mapping between different views, culminating in arepresentation space that maintains the homography relationship betweenneighboring views. We evaluate our HomE representation via action recognitionand pedestrian intent prediction as downstream tasks. On action classification,our method obtains 96.4% 3-fold accuracy on the UCF101 dataset, better thanmost state-of-the-art self-supervised learning methods. Similarly, on the STIPdataset, we outperform the state-of-the-art by 6% for pedestrian intentprediction one second into the future while also obtaining an accuracy of 91.2%for pedestrian action (cross vs. not-cross) classification. Code is availableat https://github.com/anirudhs123/HomE.</description><author>Anirudh Sriram, Adrien Gaidon, Jiajun Wu, Juan Carlos Niebles, Li Fei-Fei, Ehsan Adeli</author><pubDate>Fri, 02 Jun 2023 16:37:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01623v1</guid></item><item><title>AfriNames: Most ASR models "butcher" African Names</title><link>http://arxiv.org/abs/2306.00253v2</link><description>Useful conversational agents must accurately capture named entities tominimize error for downstream tasks, for example, asking a voice assistant toplay a track from a certain artist, initiating navigation to a specificlocation, or documenting a laboratory result for a patient. However, wherenamed entities such as ``Ukachukwu`` (Igbo), ``Lakicia`` (Swahili), or``Ingabire`` (Rwandan) are spoken, automatic speech recognition (ASR) models'performance degrades significantly, propagating errors to downstream systems.We model this problem as a distribution shift and demonstrate that such modelbias can be mitigated through multilingual pre-training, intelligent dataaugmentation strategies to increase the representation of African-namedentities, and fine-tuning multilingual ASR models on multiple African accents.The resulting fine-tuned models show an 81.5\% relative WER improvementcompared with the baseline on samples with African-named entities.</description><author>Tobi Olatunji, Tejumade Afonja, Bonaventure F. P. Dossou, Atnafu Lambebo Tonja, Chris Chinenye Emezue, Amina Mardiyyah Rufai, Sahib Singh</author><pubDate>Fri, 02 Jun 2023 16:35:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00253v2</guid></item><item><title>Tighter Information-Theoretic Generalization Bounds from Supersamples</title><link>http://arxiv.org/abs/2302.02432v2</link><description>In this work, we present a variety of novel information-theoreticgeneralization bounds for learning algorithms, from the supersample setting ofSteinke &amp; Zakynthinou (2020)-the setting of the "conditional mutualinformation" framework. Our development exploits projecting the loss pair(obtained from a training instance and a testing instance) down to a singlenumber and correlating loss values with a Rademacher sequence (and its shiftedvariants). The presented bounds include square-root bounds, fast-rate bounds,including those based on variance and sharpness, and bounds for interpolatingalgorithms etc. We show theoretically or empirically that these bounds aretighter than all information-theoretic bounds known to date on the samesupersample setting.</description><author>Ziqiao Wang, Yongyi Mao</author><pubDate>Fri, 02 Jun 2023 16:35:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02432v2</guid></item><item><title>Formalizing Statistical Causality via Modal Logic</title><link>http://arxiv.org/abs/2210.16751v4</link><description>We propose a formal language for describing and explaining statisticalcausality. Concretely, we define Statistical Causality Language (StaCL) forexpressing causal effects and specifying the requirements for causal inference.StaCL incorporates modal operators for interventions to express causalproperties between probability distributions in different possible worlds in aKripke model. We formalize axioms for probability distributions, interventions,and causal predicates using StaCL formulas. These axioms are expressive enoughto derive the rules of Pearl's do-calculus. Finally, we demonstrate by examplesthat StaCL can be used to specify and explain the correctness of statisticalcausal inference.</description><author>Yusuke Kawamoto, Tetsuya Sato, Kohei Suenaga</author><pubDate>Fri, 02 Jun 2023 16:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.16751v4</guid></item><item><title>Consistent and fast inference in compartmental models of epidemics using Poisson Approximate Likelihoods</title><link>http://arxiv.org/abs/2205.13602v4</link><description>Addressing the challenge of scaling-up epidemiological inference to complexand heterogeneous models, we introduce Poisson Approximate Likelihood (PAL)methods. In contrast to the popular ODE approach to compartmental modelling, inwhich a large population limit is used to motivate a deterministic model, PALsare derived from approximate filtering equations for finite-population,stochastic compartmental models, and the large population limit drivesconsistency of maximum PAL estimators. Our theoretical results appear to be thefirst likelihood-based parameter estimation consistency results which apply toa broad class of partially observed stochastic compartmental models and addressthe large population limit. PALs are simple to implement, involving onlyelementary arithmetic operations and no tuning parameters, and fast toevaluate, requiring no simulation from the model and having computational costindependent of population size. Through examples we demonstrate how PALs can beused to: fit an age-structured model of influenza, taking advantage ofautomatic differentiation in Stan; compare over-dispersion mechanisms in amodel of rotavirus by embedding PALs within sequential Monte Carlo; andevaluate the role of unit-specific parameters in a meta-population model ofmeasles.</description><author>Michael Whitehouse, Nick Whiteley, Lorenzo Rimella</author><pubDate>Fri, 02 Jun 2023 16:29:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.13602v4</guid></item><item><title>REV: Information-Theoretic Evaluation of Free-Text Rationales</title><link>http://arxiv.org/abs/2210.04982v5</link><description>Generating free-text rationales is a promising step towards explainable NLP,yet evaluating such rationales remains a challenge. Existing metrics havemostly focused on measuring the association between the rationale and a givenlabel. We argue that an ideal metric should focus on the new informationuniquely provided in the rationale that is otherwise not provided in the inputor the label. We investigate this research problem from aninformation-theoretic perspective using conditional V-information (Hewitt etal., 2021). More concretely, we propose a metric called REV (RationaleEvaluation with conditional V-information), to quantify the amount of new,label-relevant information in a rationale beyond the information alreadyavailable in the input or the label. Experiments across four benchmarks withreasoning tasks, including chain-of-thought, demonstrate the effectiveness ofREV in evaluating rationale-label pairs, compared to existing metrics. Wefurther demonstrate REV is consistent with human judgments on rationaleevaluations and provides more sensitive measurements of new information infree-text rationales. When used alongside traditional performance metrics, REVprovides deeper insights into models' reasoning and prediction processes.</description><author>Hanjie Chen, Faeze Brahman, Xiang Ren, Yangfeng Ji, Yejin Choi, Swabha Swayamdipta</author><pubDate>Fri, 02 Jun 2023 16:27:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04982v5</guid></item><item><title>Analyzing Credit Risk Model Problems through NLP-Based Clustering and Machine Learning: Insights from Validation Reports</title><link>http://arxiv.org/abs/2306.01618v1</link><description>This paper explores the use of clustering methods and machine learningalgorithms, including Natural Language Processing (NLP), to identify andclassify problems identified in credit risk models through textual informationcontained in validation reports. Using a unique dataset of 657 findings raisedby validation teams in a large international banking group between January 2019and December 2022. The findings are classified into nine validation dimensionsand assigned a severity level by validators using their expert knowledge. Theauthors use embedding generation for the findings' titles and observationsusing four different pre-trained models, including "module\_url" fromTensorFlow Hub and three models from the SentenceTransformer library, namely"all-mpnet-base-v2", "all-MiniLM-L6-v2", and "paraphrase-mpnet-base-v2". Thepaper uses and compares various clustering methods in grouping findings withsimilar characteristics, enabling the identification of common problems withineach validation dimension and severity. The results of the study show thatclustering is an effective approach for identifying and classifying credit riskmodel problems with accuracy higher than 60\%. The authors also employ machinelearning algorithms, including logistic regression and XGBoost, to predict thevalidation dimension and its severity, achieving an accuracy of 80\% forXGBoost algorithm. Furthermore, the study identifies the top 10 words thatpredict a validation dimension and severity. Overall, this paper makes acontribution by demonstrating the usefulness of clustering and machine learningfor analyzing textual information in validation reports, and providing insightsinto the types of problems encountered in the development and validation ofcredit risk models.</description><author>Szymon Lis, Mariusz Kubkowski, Olimpia Borkowska, Dobromił Serwa, Jarosław Kurpanik</author><pubDate>Fri, 02 Jun 2023 16:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01618v1</guid></item><item><title>Supervised Metric Learning to Rank for Retrieval via Contextual Similarity Optimization</title><link>http://arxiv.org/abs/2210.01908v3</link><description>There is extensive interest in metric learning methods for image retrieval.Many metric learning loss functions focus on learning a correct ranking oftraining samples, but strongly overfit semantically inconsistent labels andrequire a large amount of data. To address these shortcomings, we propose a newmetric learning method, called contextual loss, which optimizes contextualsimilarity in addition to cosine similarity. Our contextual loss implicitlyenforces semantic consistency among neighbors while converging to the correctranking. We empirically show that the proposed loss is more robust to labelnoise, and is less prone to overfitting even when a large portion of train datais withheld. Extensive experiments demonstrate that our method achieves a newstate-of-the-art across four image retrieval benchmarks and multiple differentevaluation settings. Code is available at:https://github.com/Chris210634/metric-learning-using-contextual-similarity</description><author>Christopher Liao, Theodoros Tsiligkaridis, Brian Kulis</author><pubDate>Fri, 02 Jun 2023 16:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.01908v3</guid></item><item><title>Hyperparameter Learning under Data Poisoning: Analysis of the Influence of Regularization via Multiobjective Bilevel Optimization</title><link>http://arxiv.org/abs/2306.01613v1</link><description>Machine Learning (ML) algorithms are vulnerable to poisoning attacks, where afraction of the training data is manipulated to deliberately degrade thealgorithms' performance. Optimal attacks can be formulated as bileveloptimization problems and help to assess their robustness in worst-casescenarios. We show that current approaches, which typically assume thathyperparameters remain constant, lead to an overly pessimistic view of thealgorithms' robustness and of the impact of regularization. We propose a noveloptimal attack formulation that considers the effect of the attack on thehyperparameters and models the attack as a multiobjective bilevel optimizationproblem. This allows to formulate optimal attacks, learn hyperparameters andevaluate robustness under worst-case conditions. We apply this attackformulation to several ML classifiers using $L_2$ and $L_1$ regularization. Ourevaluation on multiple datasets confirms the limitations of previous strategiesand evidences the benefits of using $L_2$ and $L_1$ regularization to dampenthe effect of poisoning attacks.</description><author>Javier Carnerero-Cano, Luis Muñoz-González, Phillippa Spencer, Emil C. Lupu</author><pubDate>Fri, 02 Jun 2023 16:21:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01613v1</guid></item><item><title>Centered Self-Attention Layers</title><link>http://arxiv.org/abs/2306.01610v1</link><description>The self-attention mechanism in transformers and the message-passingmechanism in graph neural networks are repeatedly applied within deep learningarchitectures. We show that this application inevitably leads to oversmoothing,i.e., to similar representations at the deeper layers for different tokens intransformers and different nodes in graph neural networks. Based on ouranalysis, we present a correction term to the aggregating operator of thesemechanisms. Empirically, this simple term eliminates much of the oversmoothingproblem in visual transformers, obtaining performance in weakly supervisedsegmentation that surpasses elaborate baseline methods that introduce multipleauxiliary networks and training phrases. In graph neural networks, thecorrection term enables the training of very deep architectures moreeffectively than many recent solutions to the same problem.</description><author>Ameen Ali, Tomer Galanti, Lior Wolf</author><pubDate>Fri, 02 Jun 2023 16:19:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01610v1</guid></item><item><title>Are Deep Neural Networks SMARTer than Second Graders?</title><link>http://arxiv.org/abs/2212.09993v4</link><description>Recent times have witnessed an increasing number of applications of deepneural networks towards solving tasks that require superior cognitiveabilities, e.g., playing Go, generating art, ChatGPT, etc. Such a dramaticprogress raises the question: how generalizable are neural networks in solvingproblems that demand broad skills? To answer this question, we propose SMART: aSimple Multimodal Algorithmic Reasoning Task and the associated SMART-101dataset, for evaluating the abstraction, deduction, and generalizationabilities of neural networks in solving visuo-linguistic puzzles designedspecifically for children in the 6--8 age group. Our dataset consists of 101unique puzzles; each puzzle comprises a picture and a question, and theirsolution needs a mix of several elementary skills, including arithmetic,algebra, and spatial reasoning, among others. To scale our dataset towardstraining deep neural networks, we programmatically generate entirely newinstances for each puzzle, while retaining their solution algorithm. Tobenchmark performances on SMART-101, we propose a vision and languagemeta-learning model using varied state-of-the-art backbones. Our experimentsreveal that while powerful deep models offer reasonable performances on puzzlesin a supervised setting, they are not better than random accuracy when analyzedfor generalization. We also evaluate the recent ChatGPT and other largelanguage models on a part of SMART-101 and find that while these models showconvincing reasoning abilities, the answers are often incorrect.</description><author>Anoop Cherian, Kuan-Chuan Peng, Suhas Lohit, Kevin A. Smith, Joshua B. Tenenbaum</author><pubDate>Fri, 02 Jun 2023 16:17:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09993v4</guid></item><item><title>Neural Wasserstein Gradient Flows for Maximum Mean Discrepancies with Riesz Kernels</title><link>http://arxiv.org/abs/2301.11624v2</link><description>Wasserstein gradient flows of maximum mean discrepancy (MMD) functionals withnon-smooth Riesz kernels show a rich structure as singular measures can becomeabsolutely continuous ones and conversely. In this paper we contribute to theunderstanding of such flows. We propose to approximate the backward scheme ofJordan, Kinderlehrer and Otto for computing such Wasserstein gradient flows aswell as a forward scheme for so-called Wasserstein steepest descent flows byneural networks (NNs). Since we cannot restrict ourselves to absolutelycontinuous measures, we have to deal with transport plans and velocity plansinstead of usual transport maps and velocity fields. Indeed, we approximate thedisintegration of both plans by generative NNs which are learned with respectto appropriate loss functions. In order to evaluate the quality of both neuralschemes, we benchmark them on the interaction energy. Here we provide analyticformulas for Wasserstein schemes starting at a Dirac measure and show theirconvergence as the time step size tends to zero. Finally, we illustrate ourneural MMD flows by numerical examples.</description><author>Fabian Altekrüger, Johannes Hertrich, Gabriele Steidl</author><pubDate>Fri, 02 Jun 2023 16:16:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11624v2</guid></item><item><title>Decentralized Federated Learning: A Survey and Perspective</title><link>http://arxiv.org/abs/2306.01603v1</link><description>Federated learning (FL) has been gaining attention for its ability to shareknowledge while maintaining user data, protecting privacy, increasing learningefficiency, and reducing communication overhead. Decentralized FL (DFL) is adecentralized network architecture that eliminates the need for a centralserver in contrast to centralized FL (CFL). DFL enables direct communicationbetween clients, resulting in significant savings in communication resources.In this paper, a comprehensive survey and profound perspective is provided forDFL. First, a review of the methodology, challenges, and variants of CFL isconducted, laying the background of DFL. Then, a systematic and detailedperspective on DFL is introduced, including iteration order, communicationprotocols, network topologies, paradigm proposals, and temporal variability.Next, based on the definition of DFL, several extended variants andcategorizations are proposed with state-of-the-art technologies. Lastly, inaddition to summarizing the current challenges in the DFL, some possiblesolutions and future research directions are also discussed.</description><author>Liangqi Yuan, Lichao Sun, Philip S. Yu, Ziran Wang</author><pubDate>Fri, 02 Jun 2023 16:12:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01603v1</guid></item><item><title>Subject-driven Text-to-Image Generation via Apprenticeship Learning</title><link>http://arxiv.org/abs/2304.00186v4</link><description>Recent text-to-image generation models like DreamBooth have made remarkableprogress in generating highly customized images of a target subject, byfine-tuning an ``expert model'' for a given subject from a few examples.However, this process is expensive, since a new expert model must be learnedfor each subject. In this paper, we present SuTI, a Subject-drivenText-to-Image generator that replaces subject-specific fine tuning within-context learning. Given a few demonstrations of a new subject, SuTI caninstantly generate novel renditions of the subject in different scenes, withoutany subject-specific optimization. SuTI is powered by apprenticeship learning,where a single apprentice model is learned from data generated by a massivenumber of subject-specific expert models. Specifically, we mine millions ofimage clusters from the Internet, each centered around a specific visualsubject. We adopt these clusters to train a massive number of expert models,each specializing in a different subject. The apprentice model SuTI then learnsto imitate the behavior of these fine-tuned experts. SuTI can generatehigh-quality and customized subject-specific images 20x faster thanoptimization-based SoTA methods. On the challenging DreamBench andDreamBench-v2, our human evaluation shows that SuTI significantly outperformsexisting models like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt,Re-Imagen and DreamBooth, especially on the subject and text alignment aspects.</description><author>Wenhu Chen, Hexiang Hu, Yandong Li, Nataniel Ruiz, Xuhui Jia, Ming-Wei Chang, William W. Cohen</author><pubDate>Fri, 02 Jun 2023 16:10:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00186v4</guid></item><item><title>Towards Source-free Domain Adaptive Semantic Segmentation via Importance-aware and Prototype-contrast Learning</title><link>http://arxiv.org/abs/2306.01598v1</link><description>Domain adaptive semantic segmentation enables robust pixel-wise understandingin real-world driving scenes. Source-free domain adaptation, as a morepractical technique, addresses the concerns of data privacy and storagelimitations in typical unsupervised domain adaptation methods. It utilizes awell-trained source model and unlabeled target data to achieve adaptation inthe target domain. However, in the absence of source data and target labels,current solutions cannot sufficiently reduce the impact of domain shift andfully leverage the information from the target data. In this paper, we proposean end-to-end source-free domain adaptation semantic segmentation method viaImportance-Aware and Prototype-Contrast (IAPC) learning. The proposed IAPCframework effectively extracts domain-invariant knowledge from the well-trainedsource model and learns domain-specific knowledge from the unlabeled targetdomain. Specifically, considering the problem of domain shift in the predictionof the target domain by the source model, we put forward an importance-awaremechanism for the biased target prediction probability distribution to extractdomain-invariant knowledge from the source model. We further introduce aprototype-contrast strategy, which includes a prototype-symmetric cross-entropyloss and a prototype-enhanced cross-entropy loss, to learn target intra-domainknowledge without relying on labels. A comprehensive variety of experiments ontwo domain adaptive semantic segmentation benchmarks demonstrates that theproposed end-to-end IAPC solution outperforms existing state-of-the-artmethods. Code will be made publicly available athttps://github.com/yihong-97/Source-free_IAPC.</description><author>Yihong Cao, Hui Zhang, Xiao Lu, Zheng Xiao, Kailun Yang, Yaonan Wang</author><pubDate>Fri, 02 Jun 2023 16:09:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01598v1</guid></item><item><title>Two-View Geometry Scoring Without Correspondences</title><link>http://arxiv.org/abs/2306.01596v1</link><description>Camera pose estimation for two-view geometry traditionally relies on RANSAC.Normally, a multitude of image correspondences leads to a pool of proposedhypotheses, which are then scored to find a winning model. The inlier count isgenerally regarded as a reliable indicator of "consensus". We examine thisscoring heuristic, and find that it favors disappointing models under certaincircumstances. As a remedy, we propose the Fundamental Scoring Network (FSNet),which infers a score for a pair of overlapping images and any proposedfundamental matrix. It does not rely on sparse correspondences, but ratherembodies a two-view geometry model through an epipolar attention mechanism thatpredicts the pose error of the two images. FSNet can be incorporated intotraditional RANSAC loops. We evaluate FSNet on fundamental and essential matrixestimation on indoor and outdoor datasets, and establish that FSNet cansuccessfully identify good poses for pairs of images with few or unreliablecorrespondences. Besides, we show that naively combining FSNet with MAGSAC++scoring approach achieves state of the art results.</description><author>Axel Barroso-Laguna, Eric Brachmann, Victor Adrian Prisacariu, Gabriel J. Brostow, Daniyar Turmukhambetov</author><pubDate>Fri, 02 Jun 2023 16:07:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01596v1</guid></item><item><title>PhysNLU: A Language Resource for Evaluating Natural Language Understanding and Explanation Coherence in Physics</title><link>http://arxiv.org/abs/2201.04275v3</link><description>In order for language models to aid physics research, they must first encoderepresentations of mathematical and natural language discourse which lead tocoherent explanations, with correct ordering and relevance of statements. Wepresent a collection of datasets developed to evaluate the performance oflanguage models in this regard, which measure capabilities with respect tosentence ordering, position, section prediction, and discourse coherence.Analysis of the data reveals equations and sub-disciplines which are mostcommon in physics discourse, as well as the sentence-level frequency ofequations and expressions. We present baselines that demonstrate howcontemporary language models are challenged by coherence related tasks inphysics, even when trained on mathematical natural language objectives.</description><author>Jordan Meadows, Zili Zhou, Andre Freitas</author><pubDate>Fri, 02 Jun 2023 16:06:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.04275v3</guid></item><item><title>A Novel Vision Transformer with Residual in Self-attention for Biomedical Image Classification</title><link>http://arxiv.org/abs/2306.01594v1</link><description>Biomedical image classification requires capturing of bio-informatics basedon specific feature distribution. In most of such applications, there aremainly challenges due to limited availability of samples for diseased cases andimbalanced nature of dataset. This article presents the novel framework ofmulti-head self-attention for vision transformer (ViT) which makes capable ofcapturing the specific image features for classification and analysis. Theproposed method uses the concept of residual connection for accumulating thebest attention output in each block of multi-head attention. The proposedframework has been evaluated on two small datasets: (i) blood cellclassification dataset and (ii) brain tumor detection using brain MRI images.The results show the significant improvement over traditional ViT and otherconvolution based state-of-the-art classification models.</description><author>Arun K. Sharma, Nishchal K. Sharma</author><pubDate>Fri, 02 Jun 2023 16:06:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01594v1</guid></item><item><title>An Evaluation of Log Parsing with ChatGPT</title><link>http://arxiv.org/abs/2306.01590v1</link><description>Software logs play an essential role in ensuring the reliability andmaintainability of large-scale software systems, as they are often the solesource of runtime information. Log parsing, which converts raw log messagesinto structured data, is an important initial step towards downstream loganalytics. In recent studies, ChatGPT, the current cutting-edge large languagemodel (LLM), has been widely applied to a wide range of software engineeringtasks. However, its performance in automated log parsing remains unclear. Inthis paper, we evaluate ChatGPT's ability to undertake log parsing byaddressing two research questions. (1) Can ChatGPT effectively parse logs? (2)How does ChatGPT perform with different prompting methods? Our results showthat ChatGPT can achieve promising results for log parsing with appropriateprompts, especially with few-shot prompting. Based on our findings, we outlineseveral challenges and opportunities for ChatGPT-based log parsing.</description><author>Van-Hoang Le, Hongyu Zhang</author><pubDate>Fri, 02 Jun 2023 15:58:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01590v1</guid></item><item><title>Transfer learning for atomistic simulations using GNNs and kernel mean embeddings</title><link>http://arxiv.org/abs/2306.01589v1</link><description>Interatomic potentials learned using machine learning methods have beensuccessfully applied to atomistic simulations. However, deep learning pipelinesare notoriously data-hungry, while generating reference calculations iscomputationally demanding. To overcome this difficulty, we propose a transferlearning algorithm that leverages the ability of graph neural networks (GNNs)in describing chemical environments, together with kernel mean embeddings. Weextract a feature map from GNNs pre-trained on the OC20 dataset and use it tolearn the potential energy surface from system-specific datasets of catalyticprocesses. Our method is further enhanced by a flexible kernel function thatincorporates chemical species information, resulting in improved performanceand interpretability. We test our approach on a series of realistic datasets ofincreasing complexity, showing excellent generalization and transferabilityperformance, and improving on methods that rely on GNNs or ridge regressionalone, as well as similar fine-tuning approaches. We make the code available tothe community at https://github.com/IsakFalk/atomistic_transfer_mekrr.</description><author>John Falk, Luigi Bonati, Pietro Novelli, Michele Parinello, Massimiliano Pontil</author><pubDate>Fri, 02 Jun 2023 15:58:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01589v1</guid></item><item><title>Convergence of the Inexact Langevin Algorithm and Score-based Generative Models in KL Divergence</title><link>http://arxiv.org/abs/2211.01512v2</link><description>We study the Inexact Langevin Dynamics (ILD), Inexact Langevin Algorithm(ILA), and Score-based Generative Modeling (SGM) when utilizing estimated scorefunctions for sampling. Our focus lies in establishing stable biasedconvergence guarantees in terms of the Kullback-Leibler (KL) divergence. Toachieve these guarantees, we impose two key assumptions: 1) the targetdistribution satisfies the log-Sobolev inequality (LSI), and 2) the scoreestimator exhibits a bounded Moment Generating Function (MGF) error. Notably,the MGF error assumption we adopt is more lenient compared to the $L^\infty$error assumption used in existing literature. However, it is stronger than the$L^2$ error assumption utilized in recent works, which often leads to unstablebounds. We explore the question of how to obtain a provably accurate scoreestimator that satisfies the MGF error assumption. Specifically, we demonstratethat a simple estimator based on kernel density estimation fulfills the MGFerror assumption for sub-Gaussian target distribution, at the population level.</description><author>Kaylee Yingxi Yang, Andre Wibisono</author><pubDate>Fri, 02 Jun 2023 15:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.01512v2</guid></item><item><title>Learning from Partially Annotated Data: Example-aware Creation of Gap-filling Exercises for Language Learning</title><link>http://arxiv.org/abs/2306.01584v1</link><description>Since performing exercises (including, e.g., practice tests) forms a crucialcomponent of learning, and creating such exercises requires non-trivial effortfrom the teacher. There is a great value in automatic exercise generation indigital tools in education. In this paper, we particularly focus on automaticcreation of gapfilling exercises for language learning, specifically grammarexercises. Since providing any annotation in this domain requires human experteffort, we aim to avoid it entirely and explore the task of converting existingtexts into new gap-filling exercises, purely based on an example exercise,without explicit instruction or detailed annotation of the intended grammartopics. We contribute (i) a novel neural network architecture specificallydesigned for aforementioned gap-filling exercise generation task, and (ii) areal-world benchmark dataset for French grammar. We show that our model forthis French grammar gap-filling exercise generation outperforms a competitivebaseline classifier by 8% in F1 percentage points, achieving an average F1score of 82%. Our model implementation and the dataset are made publiclyavailable to foster future research, thus offering a standardized evaluationand baseline solution of the proposed partially annotated data prediction taskin grammar exercise creation.</description><author>Semere Kiros Bitew, Johannes Deleu, A. Seza Dogruöz, Chris Develder, Thomas Demeester</author><pubDate>Fri, 02 Jun 2023 15:54:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01584v1</guid></item><item><title>Locally Regularized Neural Differential Equations: Some Black Boxes Were Meant to Remain Closed!</title><link>http://arxiv.org/abs/2303.02262v3</link><description>Implicit layer deep learning techniques, like Neural Differential Equations,have become an important modeling framework due to their ability to adapt tonew problems automatically. Training a neural differential equation iseffectively a search over a space of plausible dynamical systems. However,controlling the computational cost for these models is difficult since itrelies on the number of steps the adaptive solver takes. Most prior works haveused higher-order methods to reduce prediction timings while greatly increasingtraining time or reducing both training and prediction timings by relying onspecific training algorithms, which are harder to use as a drop-in replacementdue to strict requirements on automatic differentiation. In this manuscript, weuse internal cost heuristics of adaptive differential equation solvers atstochastic time points to guide the training toward learning a dynamical systemthat is easier to integrate. We "close the black-box" and allow the use of ourmethod with any adjoint technique for gradient calculations of the differentialequation solution. We perform experimental studies to compare our method toglobal regularization to show that we attain similar performance numberswithout compromising the flexibility of implementation on ordinary differentialequations (ODEs) and stochastic differential equations (SDEs). We develop twosampling strategies to trade off between performance and training time. Ourmethod reduces the number of function evaluations to 0.556-0.733x andaccelerates predictions by 1.3-2x.</description><author>Avik Pal, Alan Edelman, Chris Rackauckas</author><pubDate>Fri, 02 Jun 2023 15:52:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02262v3</guid></item><item><title>A Note On Interpreting Canary Exposure</title><link>http://arxiv.org/abs/2306.00133v2</link><description>Canary exposure, introduced in Carlini et al. is frequently used toempirically evaluate, or audit, the privacy of machine learning model training.The goal of this note is to provide some intuition on how to interpret canaryexposure, including by relating it to membership inference attacks anddifferential privacy.</description><author>Matthew Jagielski</author><pubDate>Fri, 02 Jun 2023 15:48:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00133v2</guid></item><item><title>EmoUS: Simulating User Emotions in Task-Oriented Dialogues</title><link>http://arxiv.org/abs/2306.01579v1</link><description>Existing user simulators (USs) for task-oriented dialogue systems only modeluser behaviour on semantic and natural language levels without considering theuser persona and emotions. Optimising dialogue systems with generic userpolicies, which cannot model diverse user behaviour driven by differentemotional states, may result in a high drop-off rate when deployed in the realworld. Thus, we present EmoUS, a user simulator that learns to simulate useremotions alongside user behaviour. EmoUS generates user emotions, semanticactions, and natural language responses based on the user goal, the dialoguehistory, and the user persona. By analysing what kind of system behaviourelicits what kind of user emotions, we show that EmoUS can be used as a probeto evaluate a variety of dialogue systems and in particular their effect on theuser's emotional state. Developing such methods is important in the age oflarge language model chat-bots and rising ethical concerns.</description><author>Hsien-Chin Lin, Shutong Feng, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Michael Heck, Benjamin Ruppik, Renato Vukovic, Milica Gašić</author><pubDate>Fri, 02 Jun 2023 15:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01579v1</guid></item><item><title>Maximum Entropy on Erroneous Predictions (MEEP): Improving model calibration for medical image segmentation</title><link>http://arxiv.org/abs/2112.12218v3</link><description>Modern deep neural networks achieved remarkable progress in medical imagesegmentation tasks. However, it has recently been observed that they tend toproduce overconfident estimates, even in situations of high uncertainty,leading to poorly calibrated and unreliable models. In this work we introduceMaximum Entropy on Erroneous Predictions (MEEP), a training strategy forsegmentation networks which selectively penalizes overconfident predictions,focusing only on misclassified pixels. Our method is agnostic to the neuralarchitecture, does not increase model complexity and can be coupled withmultiple segmentation loss functions. We benchmark the proposed strategy in twochallenging segmentation tasks: white matter hyperintensity lesions in magneticresonance images (MRI) of the brain, and atrial segmentation in cardiac MRI.The experimental results demonstrate that coupling MEEP with standardsegmentation losses leads to improvements not only in terms of modelcalibration, but also in segmentation quality.</description><author>Agostina Larrazabal, Cesar Martinez, Jose Dolz, Enzo Ferrante</author><pubDate>Fri, 02 Jun 2023 15:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.12218v3</guid></item><item><title>Probabilistic Concept Bottleneck Models</title><link>http://arxiv.org/abs/2306.01574v1</link><description>Interpretable models are designed to make decisions in a human-interpretablemanner. Representatively, Concept Bottleneck Models (CBM) follow a two-stepprocess of concept prediction and class prediction based on the predictedconcepts. CBM provides explanations with high-level concepts derived fromconcept predictions; thus, reliable concept predictions are important fortrustworthiness. In this study, we address the ambiguity issue that can harmreliability. While the existence of a concept can often be ambiguous in thedata, CBM predicts concepts deterministically without considering thisambiguity. To provide a reliable interpretation against this ambiguity, wepropose Probabilistic Concept Bottleneck Models (ProbCBM). By leveragingprobabilistic concept embeddings, ProbCBM models uncertainty in conceptprediction and provides explanations based on the concept and its correspondinguncertainty. This uncertainty enhances the reliability of the explanations.Furthermore, as class uncertainty is derived from concept uncertainty inProbCBM, we can explain class uncertainty by means of concept uncertainty. Codeis publicly available at https://github.com/ejkim47/prob-cbm.</description><author>Eunji Kim, Dahuin Jung, Sangha Park, Siwon Kim, Sungroh Yoon</author><pubDate>Fri, 02 Jun 2023 15:38:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01574v1</guid></item><item><title>Towards Understanding the Dynamics of Gaussian-Stein Variational Gradient Descent</title><link>http://arxiv.org/abs/2305.14076v3</link><description>Stein Variational Gradient Descent (SVGD) is a nonparametric particle-baseddeterministic sampling algorithm. Despite its wide usage, understanding thetheoretical properties of SVGD has remained a challenging problem. For samplingfrom a Gaussian target, the SVGD dynamics with a bilinear kernel will remainGaussian as long as the initializer is Gaussian. Inspired by this fact, weundertake a detailed theoretical study of the Gaussian-SVGD, i.e., SVGDprojected to the family of Gaussian distributions via the bilinear kernel, orequivalently Gaussian variational inference (GVI) with SVGD. We present acomplete picture by considering both the mean-field PDE and discrete particlesystems. When the target is strongly log-concave, the mean-field Gaussian-SVGDdynamics is proven to converge linearly to the Gaussian distribution closest tothe target in KL divergence. In the finite-particle setting, there is bothuniform in time convergence to the mean-field limit and linear convergence intime to the equilibrium if the target is Gaussian. In the general case, wepropose a density-based and a particle-based implementation of theGaussian-SVGD, and show that several recent algorithms for GVI, proposed fromdifferent perspectives, emerge as special cases of our unified framework.Interestingly, one of the new particle-based instance from this frameworkempirically outperforms existing approaches. Our results make concretecontributions towards obtaining a deeper understanding of both SVGD and GVI.</description><author>Tianle Liu, Promit Ghosal, Krishnakumar Balasubramanian, Natesh S. Pillai</author><pubDate>Fri, 02 Jun 2023 15:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14076v3</guid></item><item><title>Optimal transport flow and infinitesimal density ratio estimation</title><link>http://arxiv.org/abs/2305.11857v2</link><description>Continuous normalizing flows are widely used in generative tasks, where aflow network transports from a data distribution $P$ to a normal distribution.A flow model that transports from $P$ to an arbitrary $Q$, where both $P$ and$Q$ are accessible via finite samples, is of various application interests,particularly in the recently developed telescoping density ratio estimation(DRE) which calls for the construction of intermediate densities to bridgebetween the two densities. In this work, we propose such a flow by a neural-ODEmodel which is trained from empirical samples to transport invertibly from $P$to $Q$ (and vice versa) and optimally by minimizing the transport cost. Thetrained flow model allows us to perform infinitesimal DRE along thetime-parametrized $\log$-density by training an additional continuous-timenetwork using classification loss, whose time integration provides a telescopicDRE. The effectiveness of the proposed model is empirically demonstrated onhigh-dimensional mutual information estimation and energy-based generativemodels of image data.</description><author>Chen Xu, Xiuyuan Cheng, Yao Xie</author><pubDate>Fri, 02 Jun 2023 15:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11857v2</guid></item><item><title>Spatio-Temporal Deep Learning-Assisted Reduced Security-Constrained Unit Commitment</title><link>http://arxiv.org/abs/2306.01570v1</link><description>Security-constrained unit commitment (SCUC) is a computationally complexprocess utilized in power system day-ahead scheduling and market clearing. SCUCis run daily and requires state-of-the-art algorithms to speed up the process.The constraints and data associated with SCUC are both geographically andtemporally correlated to ensure the reliability of the solution, which furtherincreases the complexity. In this paper, an advanced machine learning (ML)model is used to study the patterns in power system historical data, whichinherently considers both spatial and temporal (ST) correlations inconstraints. The ST-correlated ML model is trained to understand spatialcorrelation by considering graph neural networks (GNN) whereas temporalsequences are studied using long short-term memory (LSTM) networks. Theproposed approach is validated on several test systems namely, IEEE 24-Bussystem, IEEE-73 Bus system, IEEE 118-Bus system, and synthetic South-Carolina(SC) 500-Bus system. Moreover, B-{\theta} and power transfer distributionfactor (PTDF) based SCUC formulations were considered in this research.Simulation results demonstrate that the ST approach can effectively predictgenerator commitment schedule and classify critical and non-critical lines inthe system which are utilized for model reduction of SCUC to obtaincomputational enhancement without loss in solution quality</description><author>Arun Venkatesh Ramesh, Xingpeng Li</author><pubDate>Fri, 02 Jun 2023 15:31:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01570v1</guid></item><item><title>Segment Anything in High Quality</title><link>http://arxiv.org/abs/2306.01567v1</link><description>The recent Segment Anything Model (SAM) represents a big leap in scaling upsegmentation models, allowing for powerful zero-shot capabilities and flexibleprompting. Despite being trained with 1.1 billion masks, SAM's mask predictionquality falls short in many cases, particularly when dealing with objects thathave intricate structures. We propose HQ-SAM, equipping SAM with the ability toaccurately segment any object, while maintaining SAM's original promptabledesign, efficiency, and zero-shot generalizability. Our careful design reusesand preserves the pre-trained model weights of SAM, while only introducingminimal additional parameters and computation. We design a learnableHigh-Quality Output Token, which is injected into SAM's mask decoder and isresponsible for predicting the high-quality mask. Instead of only applying iton mask-decoder features, we first fuse them with early and final ViT featuresfor improved mask details. To train our introduced learnable parameters, wecompose a dataset of 44K fine-grained masks from several sources. HQ-SAM isonly trained on the introduced detaset of 44k masks, which takes only 4 hourson 8 GPUs. We show the efficacy of HQ-SAM in a suite of 9 diverse segmentationdatasets across different downstream tasks, where 7 out of them are evaluatedin a zero-shot transfer protocol. Our code and models will be released athttps://github.com/SysCV/SAM-HQ.</description><author>Lei Ke, Mingqiao Ye, Martin Danelljan, Yifan Liu, Yu-Wing Tai, Chi-Keung Tang, Fisher Yu</author><pubDate>Fri, 02 Jun 2023 15:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01567v1</guid></item><item><title>Can Deep Learning Reliably Recognize Abnormality Patterns on Chest X-rays? A Multi-Reader Study Examining One Month of AI Implementation in Everyday Radiology Clinical Practice</title><link>http://arxiv.org/abs/2305.10116v2</link><description>In this study, we developed a deep-learning-based automatic detectionalgorithm (DLAD, Carebot AI CXR) to detect and localize seven specificradiological findings (atelectasis (ATE), consolidation (CON), pleural effusion(EFF), pulmonary lesion (LES), subcutaneous emphysema (SCE), cardiomegaly(CMG), pneumothorax (PNO)) on chest X-rays (CXR). We collected 956 CXRs andcompared the performance of the DLAD with that of six individual radiologistswho assessed the images in a hospital setting. The proposed DLAD achieved highsensitivity (ATE 1.000 (0.624-1.000), CON 0.864 (0.671-0.956), EFF 0.953(0.887-0.983), LES 0.905 (0.715-0.978), SCE 1.000 (0.366-1.000), CMG 0.837(0.711-0.917), PNO 0.875 (0.538-0.986)), even when compared to the radiologists(LOWEST: ATE 0.000 (0.000-0.376), CON 0.182 (0.070-0.382), EFF 0.400(0.302-0.506), LES 0.238 (0.103-0.448), SCE 0.000 (0.000-0.634), CMG 0.347(0.228-0.486), PNO 0.375 (0.134-0.691), HIGHEST: ATE 1.000 (0.624-1.000), CON0.864 (0.671-0.956), EFF 0.953 (0.887-0.983), LES 0.667 (0.456-0.830), SCE1.000 (0.366-1.000), CMG 0.980 (0.896-0.999), PNO 0.875 (0.538-0.986)). Thefindings of the study demonstrate that the suggested DLAD holds potential forintegration into everyday clinical practice as a decision support system,effectively mitigating the false negative rate associated with junior andintermediate radiologists.</description><author>Daniel Kvak, Anna Chromcová, Petra Ovesná, Jakub Dandár, Marek Biroš, Robert Hrubý, Daniel Dufek, Marija Pajdaković</author><pubDate>Fri, 02 Jun 2023 15:18:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10116v2</guid></item><item><title>UKP-SQuARE: An Interactive Tool for Teaching Question Answering</title><link>http://arxiv.org/abs/2305.19748v2</link><description>The exponential growth of question answering (QA) has made it anindispensable topic in any Natural Language Processing (NLP) course.Additionally, the breadth of QA derived from this exponential growth makes itan ideal scenario for teaching related NLP topics such as informationretrieval, explainability, and adversarial attacks among others. In this paper,we introduce UKP-SQuARE as a platform for QA education. This platform providesan interactive environment where students can run, compare, and analyze variousQA models from different perspectives, such as general behavior,explainability, and robustness. Therefore, students can get a first-handexperience in different QA techniques during the class. Thanks to this, wepropose a learner-centered approach for QA education in which studentsproactively learn theoretical concepts and acquire problem-solving skillsthrough interactive exploration, experimentation, and practical assignments,rather than solely relying on traditional lectures. To evaluate theeffectiveness of UKP-SQuARE in teaching scenarios, we adopted it in apostgraduate NLP course and surveyed the students after the course. Theirpositive feedback shows the platform's effectiveness in their course andinvites a wider adoption.</description><author>Haishuo Fang, Haritz Puerto, Iryna Gurevych</author><pubDate>Fri, 02 Jun 2023 15:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19748v2</guid></item><item><title>An Attentive-based Generative Model for Medical Image Synthesis</title><link>http://arxiv.org/abs/2306.01562v1</link><description>Magnetic resonance (MR) and computer tomography (CT) imaging are valuabletools for diagnosing diseases and planning treatment. However, limitations suchas radiation exposure and cost can restrict access to certain imagingmodalities. To address this issue, medical image synthesis can generate onemodality from another, but many existing models struggle with high-qualityimage synthesis when multiple slices are present in the dataset. This studyproposes an attention-based dual contrast generative model, calledADC-cycleGAN, which can synthesize medical images from unpaired data withmultiple slices. The model integrates a dual contrast loss term with theCycleGAN loss to ensure that the synthesized images are distinguishable fromthe source domain. Additionally, an attention mechanism is incorporated intothe generators to extract informative features from both channel and spatialdomains. To improve performance when dealing with multiple slices, the$K$-means algorithm is used to cluster the dataset into $K$ groups, and eachgroup is used to train a separate ADC-cycleGAN. Experimental resultsdemonstrate that the proposed ADC-cycleGAN model produces comparable samples toother state-of-the-art generative models, achieving the highest PSNR and SSIMvalues of 19.04385 and 0.68551, respectively. We publish the code athttps://github.com/JiayuanWang-JW/ADC-cycleGAN.</description><author>Jiayuan Wang, Q. M. Jonathan Wu, Farhad Farhad</author><pubDate>Fri, 02 Jun 2023 15:17:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01562v1</guid></item><item><title>Matching-based Data Valuation for Generative Model</title><link>http://arxiv.org/abs/2304.10701v3</link><description>Data valuation is critical in machine learning, as it helps enhance modeltransparency and protect data properties. Existing data valuation methods haveprimarily focused on discriminative models, neglecting deep generative modelsthat have recently gained considerable attention. Similar to discriminativemodels, there is an urgent need to assess data contributions in deep generativemodels as well. However, previous data valuation approaches mainly relied ondiscriminative model performance metrics and required model retraining.Consequently, they cannot be applied directly and efficiently to recent deepgenerative models, such as generative adversarial networks and diffusionmodels, in practice. To bridge this gap, we formulate the data valuationproblem in generative models from a similarity-matching perspective.Specifically, we introduce Generative Model Valuator (GMValuator), the firstmodel-agnostic approach for any generative models, designed to provide datavaluation for generation tasks. We have conducted extensive experiments todemonstrate the effectiveness of the proposed method. To the best of theirknowledge, GMValuator is the first work that offers a training-free, post-hocdata valuation strategy for deep generative models.</description><author>Jiaxi Yang, Wenglong Deng, Benlin Liu, Yangsibo Huang, Xiaoxiao Li</author><pubDate>Fri, 02 Jun 2023 15:00:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10701v3</guid></item><item><title>Comparing a composite model versus chained models to locate a nearest visual object</title><link>http://arxiv.org/abs/2306.01551v1</link><description>Extracting information from geographic images and text is crucial forautonomous vehicles to determine in advance the best cell stations to connectto along their future path. Multiple artificial neural network models canaddress this challenge; however, there is no definitive guidance on theselection of an appropriate model for such use cases. Therefore, weexperimented two architectures to solve such a task: a first architecture withchained models where each model in the chain addresses a sub-task of the task;and a second architecture with a single model that addresses the whole task.Our results showed that these two architectures achieved the same levelperformance with a root mean square error (RMSE) of 0.055 and 0.056; Thefindings further revealed that when the task can be decomposed into sub-tasks,the chain architecture exhibits a twelve-fold increase in training speedcompared to the composite model. Nevertheless, the composite modelsignificantly alleviates the burden of data labeling.</description><author>Antoine Le Borgne, Xavier Marjou, Fanny Parzysz, Tayeb Lemlouma</author><pubDate>Fri, 02 Jun 2023 14:58:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01551v1</guid></item><item><title>Revisiting Non-Autoregressive Translation at Scale</title><link>http://arxiv.org/abs/2305.16155v2</link><description>In real-world systems, scaling has been critical for improving thetranslation quality in autoregressive translation (AT), which however has notbeen well studied for non-autoregressive translation (NAT). In this work, webridge the gap by systematically studying the impact of scaling on NATbehaviors. Extensive experiments on six WMT benchmarks over two advanced NATmodels show that scaling can alleviate the commonly-cited weaknesses of NATmodels, resulting in better translation performance. To reduce the side-effectof scaling on decoding speed, we empirically investigate the impact of NATencoder and decoder on the translation performance. Experimental results on thelarge-scale WMT20 En-De show that the asymmetric architecture (e.g. biggerencoder and smaller decoder) can achieve comparable performance with thescaling model, while maintaining the superiority of decoding speed withstandard NAT models. To this end, we establish a new benchmark by validatingscaled NAT models on the scaled dataset, which can be regarded as a strongbaseline for future works. We release code and system outputs athttps://github.com/DeepLearnXMU/Scaling4NAT.</description><author>Zhihao Wang, Longyue Wang, Jinsong Su, Junfeng Yao, Zhaopeng Tu</author><pubDate>Fri, 02 Jun 2023 14:58:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16155v2</guid></item><item><title>Evaluating Machine Translation Quality with Conformal Predictive Distributions</title><link>http://arxiv.org/abs/2306.01549v1</link><description>This paper presents a new approach for assessing uncertainty in machinetranslation by simultaneously evaluating translation quality and providing areliable confidence score. Our approach utilizes conformal predictivedistributions to produce prediction intervals with guaranteed coverage, meaningthat for any given significance level $\epsilon$, we can expect the truequality score of a translation to fall out of the interval at a rate of$1-\epsilon$. In this paper, we demonstrate how our method outperforms asimple, but effective baseline on six different language pairs in terms ofcoverage and sharpness. Furthermore, we validate that our approach requires thedata exchangeability assumption to hold for optimal performance.</description><author>Patrizio Giovannotti</author><pubDate>Fri, 02 Jun 2023 14:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01549v1</guid></item><item><title>Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation</title><link>http://arxiv.org/abs/2208.12401v4</link><description>Recent work on mini-batch consistency (MBC) for set functions has broughtattention to the need for sequentially processing and aggregating chunks of apartitioned set while guaranteeing the same output for all partitions. However,existing constraints on MBC architectures lead to models with limitedexpressive power. Additionally, prior work has not addressed how to deal withlarge sets during training when the full set gradient is required. To addressthese issues, we propose a Universally MBC (UMBC) class of set functions whichcan be used in conjunction with arbitrary non-MBC components while stillsatisfying MBC, enabling a wider range of function classes to be used in MBCsettings. Furthermore, we propose an efficient MBC training algorithm whichgives an unbiased approximation of the full set gradient and has a constantmemory overhead for any set size for both train- and test-time. We conductextensive experiments including image completion, text classification,unsupervised clustering, and cancer detection on high-resolution images toverify the efficiency and efficacy of our scalable set encoding framework.</description><author>Jeffrey Willette, Seanie Lee, Bruno Andreis, Kenji Kawaguchi, Juho Lee, Sung Ju Hwang</author><pubDate>Fri, 02 Jun 2023 14:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.12401v4</guid></item><item><title>Publicly available datasets of breast histopathology H&amp;E whole-slide images: A systematic review</title><link>http://arxiv.org/abs/2306.01546v1</link><description>Advancements in digital pathology and computing resources have made asignificant impact in the field of computational pathology for breast cancerdiagnosis and treatment. However, access to high-quality labeledhistopathological images of breast cancer is a big challenge that limits thedevelopment of accurate and robust deep learning models. In this systematicreview, we identified the publicly available datasets of breast H&amp;E stainedwhole-slide images (WSI) that can be used to develop deep learning algorithms.We systematically searched nine scientific literature databases and nineresearch data repositories. We found twelve publicly available datasets,containing 5153 H&amp;E WSIs of breast cancer. Moreover, we reported image metadataand characteristics for each dataset to assist researchers in selecting properdatasets for specific tasks in breast cancer computational pathology. Inaddition, we compiled a list of patch and private datasets that were used inthe included articles as a supplementary resource for researchers. Notably, 22%of the included articles utilized multiple datasets, and only 12% of thearticles used an external validation set, suggesting that the performance ofother developed models may be susceptible to overestimation. The TCGA-BRCA wasused in 47.4% of the selected studies. This dataset has a considerableselection bias that can impact the robustness and generalizability of thetrained algorithms. There is also a lack of consistent metadata reporting ofbreast WSI datasets that can be an issue in developing accurate deep learningmodels, indicating the necessity of establishing explicit guidelines fordocumenting breast WSI dataset characteristics and metadata.</description><author>Masoud Tafavvoghi, Lars Ailo Bongo, Nikita Shvetsov, Lill-Tove Rasmussen Busund, Kajsa Møllersen</author><pubDate>Fri, 02 Jun 2023 14:50:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01546v1</guid></item><item><title>Dynamic Spatial Sparsification for Efficient Vision Transformers and Convolutional Neural Networks</title><link>http://arxiv.org/abs/2207.01580v2</link><description>In this paper, we present a new approach for model acceleration by exploitingspatial sparsity in visual data. We observe that the final prediction in visionTransformers is only based on a subset of the most informative tokens, which issufficient for accurate image recognition. Based on this observation, wepropose a dynamic token sparsification framework to prune redundant tokensprogressively and dynamically based on the input to accelerate visionTransformers. Specifically, we devise a lightweight prediction module toestimate the importance score of each token given the current features. Themodule is added to different layers to prune redundant tokens hierarchically.While the framework is inspired by our observation of the sparse attention invision Transformers, we find the idea of adaptive and asymmetric computationcan be a general solution for accelerating various architectures. We extend ourmethod to hierarchical models including CNNs and hierarchical visionTransformers as well as more complex dense prediction tasks that requirestructured feature maps by formulating a more generic dynamic spatialsparsification framework with progressive sparsification and asymmetriccomputation for different spatial locations. By applying lightweight fast pathsto less informative features and using more expressive slow paths to moreimportant locations, we can maintain the structure of feature maps whilesignificantly reducing the overall computations. Extensive experimentsdemonstrate the effectiveness of our framework on various modern architecturesand different visual recognition tasks. Our results clearly demonstrate thatdynamic spatial sparsification offers a new and more effective dimension formodel acceleration. Code is available athttps://github.com/raoyongming/DynamicViT</description><author>Yongming Rao, Zuyan Liu, Wenliang Zhao, Jie Zhou, Jiwen Lu</author><pubDate>Fri, 02 Jun 2023 14:50:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.01580v2</guid></item></channel></rss>