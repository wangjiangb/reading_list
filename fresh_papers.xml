<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 17 Feb 2025 13:00:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding</title><link>http://arxiv.org/abs/2502.10392v1</link><description>In this paper, we propose an efficient multi-level convolution architecturefor 3D visual grounding. Conventional methods are difficult to meet therequirements of real-time inference due to the two-stage or point-basedarchitecture. Inspired by the success of multi-level fully sparse convolutionalarchitecture in 3D object detection, we aim to build a new 3D visual groundingframework following this technical route. However, as in 3D visual groundingtask the 3D scene representation should be deeply interacted with textfeatures, sparse convolution-based architecture is inefficient for thisinteraction due to the large amount of voxel features. To this end, we proposetext-guided pruning (TGP) and completion-based addition (CBA) to deeply fuse 3Dscene representation and text features in an efficient way by gradual regionpruning and target completion. Specifically, TGP iteratively sparsifies the 3Dscene representation and thus efficiently interacts the voxel features withtext features by cross-attention. To mitigate the affect of pruning on delicategeometric information, CBA adaptively fixes the over-pruned region by voxelcompletion with negligible computational overhead. Compared with previoussingle-stage methods, our method achieves top inference speed and surpassesprevious fastest method by 100\% FPS. Our method also achieves state-of-the-artaccuracy even compared with two-stage methods, with $+1.13$ lead of Acc@0.5 onScanRefer, and $+2.6$ and $+3.2$ leads on NR3D and SR3D respectively. The codeis available at\href{https://github.com/GWxuan/TSP3D}{https://github.com/GWxuan/TSP3D}.</description><author>Wenxuan Guo, Xiuwei Xu, Ziwei Wang, Jianjiang Feng, Jie Zhou, Jiwen Lu</author><pubDate>Fri, 14 Feb 2025 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10392v1</guid></item><item><title>MM-RLHF: The Next Step Forward in Multimodal LLM Alignment</title><link>http://arxiv.org/abs/2502.10391v1</link><description>Despite notable advancements in Multimodal Large Language Models (MLLMs),most state-of-the-art models have not undergone thorough alignment with humanpreferences. This gap exists because current alignment research has primarilyachieved progress in specific areas (e.g., hallucination reduction), while thebroader question of whether aligning models with human preferences cansystematically enhance MLLM capability remains largely unexplored. To this end,we introduce MM-RLHF, a dataset containing $\mathbf{120k}$ fine-grained,human-annotated preference comparison pairs. This dataset represents asubstantial advancement over existing resources, offering superior size,diversity, annotation granularity, and quality. Leveraging this dataset, wepropose several key innovations to improve both the quality of reward modelsand the efficiency of alignment algorithms. Notably, we introduce aCritique-Based Reward Model, which generates critiques of model outputs beforeassigning scores, offering enhanced interpretability and more informativefeedback compared to traditional scalar reward mechanisms. Additionally, wepropose Dynamic Reward Scaling, a method that adjusts the loss weight of eachsample according to the reward signal, thereby optimizing the use ofhigh-quality comparison pairs. Our approach is rigorously evaluated across$\mathbf{10}$ distinct dimensions and $\mathbf{27}$ benchmarks, with resultsdemonstrating significant and consistent improvements in model performance.Specifically, fine-tuning LLaVA-ov-7B with MM-RLHF and our alignment algorithmleads to a $\mathbf{19.5}$% increase in conversational abilities and a$\mathbf{60}$% improvement in safety. We have open-sourced the preference dataset, reward model, training andevaluation code, as well as reward modeling and safety benchmarks. For moredetails, please visit our project page: https://mm-rlhf.github.io.</description><author>Yi-Fan Zhang, Tao Yu, Haochen Tian, Chaoyou Fu, Peiyan Li, Jianshu Zeng, Wulin Xie, Yang Shi, Huanyu Zhang, Junkang Wu, Xue Wang, Yibo Hu, Bin Wen, Fan Yang, Zhang Zhang, Tingting Gao, Di Zhang, Liang Wang, Rong Jin, Tieniu Tan</author><pubDate>Fri, 14 Feb 2025 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10391v1</guid></item><item><title>(How) Can Transformers Predict Pseudo-Random Numbers?</title><link>http://arxiv.org/abs/2502.10390v1</link><description>Transformers excel at discovering patterns in sequential data, yet theirfundamental limitations and learning mechanisms remain crucial topics ofinvestigation. In this paper, we study the ability of Transformers to learnpseudo-random number sequences from linear congruential generators (LCGs),defined by the recurrence relation $x_{t+1} = a x_t + c \;\mathrm{mod}\; m$.Our analysis reveals that with sufficient architectural capacity and trainingdata variety, Transformers can perform in-context prediction of LCG sequenceswith unseen moduli ($m$) and parameters ($a,c$). Through analysis of embeddinglayers and attention patterns, we uncover how Transformers develop algorithmicstructures to learn these sequences in two scenarios of increasing complexity.First, we analyze how Transformers learn LCG sequences with unseen ($a, c$) butfixed modulus, and we demonstrate successful learning up to $m = 2^{32}$. Ouranalysis reveals that models learn to factorize the modulus and utilizedigit-wise number representations to make sequential predictions. In thesecond, more challenging scenario of unseen moduli, we show that Transformerscan generalize to unseen moduli up to $m_{\text{test}} = 2^{16}$. In this case,the model employs a two-step strategy: first estimating the unknown modulusfrom the context, then utilizing prime factorizations to generate predictions.For this task, we observe a sharp transition in the accuracy at a criticaldepth $=3$. We also find that the number of in-context sequence elements neededto reach high accuracy scales sublinearly with the modulus.</description><author>Tao Tao, Darshil Doshi, Dayal Singh Kalra, Tianyu He, Maissam Barkeshli</author><pubDate>Fri, 14 Feb 2025 18:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10390v1</guid></item><item><title>Region-Adaptive Sampling for Diffusion Transformers</title><link>http://arxiv.org/abs/2502.10389v1</link><description>Diffusion models (DMs) have become the leading choice for generative tasksacross diverse domains. However, their reliance on multiple sequential forwardpasses significantly limits real-time performance. Previous accelerationmethods have primarily focused on reducing the number of sampling steps orreusing intermediate results, failing to leverage variations across spatialregions within the image due to the constraints of convolutional U-Netstructures. By harnessing the flexibility of Diffusion Transformers (DiTs) inhandling variable number of tokens, we introduce RAS, a novel, training-freesampling strategy that dynamically assigns different sampling ratios to regionswithin an image based on the focus of the DiT model. Our key observation isthat during each sampling step, the model concentrates on semanticallymeaningful regions, and these areas of focus exhibit strong continuity acrossconsecutive steps. Leveraging this insight, RAS updates only the regionscurrently in focus, while other regions are updated using cached noise from theprevious step. The model's focus is determined based on the output from thepreceding step, capitalizing on the temporal consistency we observed. Weevaluate RAS on Stable Diffusion 3 and Lumina-Next-T2I, achieving speedups upto 2.36x and 2.51x, respectively, with minimal degradation in generationquality. Additionally, a user study reveals that RAS delivers comparablequalities under human evaluation while achieving a 1.6x speedup. Our approachmakes a significant step towards more efficient diffusion transformers,enhancing their potential for real-time applications.</description><author>Ziming Liu, Yifan Yang, Chengruidong Zhang, Yiqi Zhang, Lili Qiu, Yang You, Yuqing Yang</author><pubDate>Fri, 14 Feb 2025 18:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10389v1</guid></item><item><title>Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction</title><link>http://arxiv.org/abs/2502.10388v1</link><description>Recent progress in large language models (LLMs) has enabled the automatedprocessing of lengthy documents even without supervised training on atask-specific dataset. Yet, their zero-shot performance in complex tasks asopposed to straightforward information extraction tasks remains suboptimal. Onefeasible approach for tasks with lengthy, complex input is to first summarizethe document and then apply supervised fine-tuning to the summary. However, thesummarization process inevitably results in some loss of information. In thisstudy we present a method for processing the summaries of long documents aimedto capture different important aspects of the original document. We hypothesizethat LLM summaries generated with different aspect-oriented prompts containdifferent \textit{information signals}, and we propose methods to measure thesedifferences. We introduce approaches to effectively integrate signals fromthese different summaries for supervised training of transformer models. Wevalidate our hypotheses on a high-impact task -- 30-day readmission predictionfrom a psychiatric discharge -- using real-world data from four hospitals, andshow that our proposed method increases the prediction performance for thecomplex task of predicting patient outcome.</description><author>WonJin Yoon, Boyu Ren, Spencer Thomas, Chanwhi Kim, Guergana Savova, Mei-Hua Hall, Timothy Miller</author><pubDate>Fri, 14 Feb 2025 18:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10388v1</guid></item><item><title>Simplifying DINO via Coding Rate Regularization</title><link>http://arxiv.org/abs/2502.10385v1</link><description>DINO and DINOv2 are two model families being widely used to learnrepresentations from unlabeled imagery data at large scales. Their learnedrepresentations often enable state-of-the-art performance for downstream tasks,such as image classification and segmentation. However, they employ manyempirically motivated design choices and their training pipelines are highlycomplex and unstable -- many hyperparameters need to be carefully tuned toensure that the representations do not collapse -- which poses considerabledifficulty to improving them or adapting them to new domains. In this work, weposit that we can remove most such-motivated idiosyncrasies in the pre-trainingpipelines, and only need to add an explicit coding rate term in the lossfunction to avoid collapse of the representations. As a result, we obtainhighly simplified variants of the DINO and DINOv2 which we call SimDINO andSimDINOv2, respectively. Remarkably, these simplified models are more robust todifferent design choices, such as network architecture and hyperparameters, andthey learn even higher-quality representations, measured by performance ondownstream tasks, offering a Pareto improvement over the corresponding DINO andDINOv2 models. This work highlights the potential of using simplifying designprinciples to improve the empirical practice of deep learning.</description><author>Ziyang Wu, Jingyuan Zhang, Druv Pai, XuDong Wang, Chandan Singh, Jianwei Yang, Jianfeng Gao, Yi Ma</author><pubDate>Fri, 14 Feb 2025 18:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10385v1</guid></item><item><title>Representation and Interpretation in Artificial and Natural Computing</title><link>http://arxiv.org/abs/2502.10383v1</link><description>Artificial computing machinery transforms representations through anobjective process, to be interpreted subjectively by humans, so the machine andthe interpreter are different entities, but in the putative natural computingboth processes are performed by the same agent. The method or process thattransforms a representation is called here \emph{the mode of computing}. Themode used by digital computers is the algorithmic one, but there are others,such as quantum computers and diverse forms of non-conventional computing, andthere is an open-ended set of representational formats and modes that could beused in artificial and natural computing. A mode based on a notion of computingdifferent from Turing's may perform feats beyond what the Turing Machine doesbut the modes would not be of the same kind and could not be compared. For amode of computing to be more powerful than the algorithmic one, it ought tocompute functions lacking an effective algorithm, and Church Thesis would nothold. Here, a thought experiment including a computational demon using ahypothetical mode for such an effect is presented. If there is naturalcomputing, there is a mode of natural computing whose properties may be causalto the phenomenological experience. Discovering it would come with solving thehard problem of consciousness; but if it turns out that such a mode does notexist, there is no such thing as natural computing, and the mind is not acomputational process.</description><author>Luis A. Pineda</author><pubDate>Fri, 14 Feb 2025 18:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10383v1</guid></item><item><title>Balancing the Scales: A Theoretical and Algorithmic Framework for Learning from Imbalanced Data</title><link>http://arxiv.org/abs/2502.10381v1</link><description>Class imbalance remains a major challenge in machine learning, especially inmulti-class problems with long-tailed distributions. Existing methods, such asdata resampling, cost-sensitive techniques, and logistic loss modifications,though popular and often effective, lack solid theoretical foundations. As anexample, we demonstrate that cost-sensitive methods are not Bayes consistent.This paper introduces a novel theoretical framework for analyzinggeneralization in imbalanced classification. We propose a new class-imbalancedmargin loss function for both binary and multi-class settings, prove its strong$H$-consistency, and derive corresponding learning guarantees based onempirical loss and a new notion of class-sensitive Rademacher complexity.Leveraging these theoretical results, we devise novel and general learningalgorithms, IMMAX (Imbalanced Margin Maximization), which incorporateconfidence margins and are applicable to various hypothesis sets. While ourfocus is theoretical, we also present extensive empirical results demonstratingthe effectiveness of our algorithms compared to existing baselines.</description><author>Corinna Cortes, Anqi Mao, Mehryar Mohri, Yutao Zhong</author><pubDate>Fri, 14 Feb 2025 18:57:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10381v1</guid></item><item><title>A new and flexible class of sharp asymptotic time-uniform confidence sequences</title><link>http://arxiv.org/abs/2502.10380v1</link><description>Confidence sequences are anytime-valid analogues of classical confidenceintervals that do not suffer from multiplicity issues under optionalcontinuation of the data collection. As in classical statistics, asymptoticconfidence sequences are a nonparametric tool showing under which high-levelassumptions asymptotic coverage is achieved so that they also give a certainrobustness guarantee against distributional deviations. In this paper, wepropose a new flexible class of confidence sequences yielding sharp asymptotictime-uniform confidence sequences under mild assumptions. Furthermore, wehighlight the connection to corresponding sequential testing problems anddetail the underlying limit theorem.</description><author>Felix Gnettner, Claudia Kirch</author><pubDate>Fri, 14 Feb 2025 18:57:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10380v1</guid></item><item><title>Unknown Word Detection for English as a Second Language (ESL) Learners Using Gaze and Pre-trained Language Models</title><link>http://arxiv.org/abs/2502.10378v1</link><description>English as a Second Language (ESL) learners often encounter unknown wordsthat hinder their text comprehension. Automatically detecting these words asusers read can enable computing systems to provide just-in-time definitions,synonyms, or contextual explanations, thereby helping users learn vocabulary ina natural and seamless manner. This paper presents EyeLingo, atransformer-based machine learning method that predicts the probability ofunknown words based on text content and eye gaze trajectory in real time withhigh accuracy. A 20-participant user study revealed that our method can achievean accuracy of 97.6%, and an F1-score of 71.1%. We implemented a real-timereading assistance prototype to show the effectiveness of EyeLingo. The userstudy shows improvement in willingness to use and usefulness compared tobaseline methods.</description><author>Jiexin Ding, Bowen Zhao, Yuntao Wang, Xinyun Liu, Rui Hao, Ishan Chatterjee, Yuanchun Shi</author><pubDate>Fri, 14 Feb 2025 18:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10378v1</guid></item><item><title>ReStyle3D: Scene-Level Appearance Transfer with Semantic Correspondences</title><link>http://arxiv.org/abs/2502.10377v1</link><description>We introduce ReStyle3D, a novel framework for scene-level appearance transferfrom a single style image to a real-world scene represented by multiple views.The method combines explicit semantic correspondences with multi-viewconsistency to achieve precise and coherent stylization. Unlike conventionalstylization methods that apply a reference style globally, ReStyle3D usesopen-vocabulary segmentation to establish dense, instance-level correspondencesbetween the style and real-world images. This ensures that each object isstylized with semantically matched textures. It first transfers the style to asingle view using a training-free semantic-attention mechanism in a diffusionmodel. It then lifts the stylization to additional views via a learnedwarp-and-refine network guided by monocular depth and pixel-wisecorrespondences. Experiments show that ReStyle3D consistently outperforms priormethods in structure preservation, perceptual style similarity, and multi-viewcoherence. User studies further validate its ability to producephoto-realistic, semantically faithful results. Our code, pretrained models,and dataset will be publicly released, to support new applications in interiordesign, virtual staging, and 3D-consistent stylization.</description><author>Liyuan Zhu, Shengqu Cai, Shengyu Huang, Gordon Wetzstein, Naji Khosravan, Iro Armeni</author><pubDate>Fri, 14 Feb 2025 18:54:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10377v1</guid></item><item><title>An Interactive Framework for Implementing Privacy-Preserving Federated Learning: Experiments on Large Language Models</title><link>http://arxiv.org/abs/2502.08008v2</link><description>Federated learning (FL) enhances privacy by keeping user data on localdevices. However, emerging attacks have demonstrated that the updates shared byusers during training can reveal significant information about their data. Thishas greatly thwart the adoption of FL methods for training robust AI models insensitive applications. Differential Privacy (DP) is considered the goldstandard for safeguarding user data. However, DP guarantees are highlyconservative, providing worst-case privacy guarantees. This can result inoverestimating privacy needs, which may compromise the model's accuracy.Additionally, interpretations of these privacy guarantees have proven to bechallenging in different contexts. This is further exacerbated when otherfactors, such as the number of training iterations, data distribution, andspecific application requirements, can add further complexity to this problem.In this work, we proposed a framework that integrates a human entity as aprivacy practitioner to determine an optimal trade-off between the model'sprivacy and utility. Our framework is the first to address the variable memoryrequirement of existing DP methods in FL settings, where resource-limiteddevices (e.g., cell phones) can participate. To support such settings, we adopta recent DP method with fixed memory usage to ensure scalable private FL. Weevaluated our proposed framework by fine-tuning a BERT-based LLM model usingthe GLUE dataset (a common approach in literature), leveraging the newaccountant, and employing diverse data partitioning strategies to mimicreal-world conditions. As a result, we achieved stable memory usage, with anaverage accuracy reduction of 1.33% for $\epsilon = 10$ and 1.9% for $\epsilon= 6$, when compared to the state-of-the-art DP accountant which does notsupport fixed memory usage.</description><author>Kasra Ahmadi, Rouzbeh Behnia, Reza Ebrahimi, Mehran Mozaffari Kermani, Jeremiah Birrell, Jason Pacheco, Attila A Yavuz</author><pubDate>Fri, 14 Feb 2025 18:52:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08008v2</guid></item><item><title>OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models</title><link>http://arxiv.org/abs/2502.10373v1</link><description>Neural scaling laws offer valuable insights for designing robust sequenceprocessing architectures. While these laws have been extensively characterizedin other modalities, their behavior in speech remains comparativelyunderexplored. In this work, we introduce OWLS, an open-access, reproduciblesuite of multilingual speech recognition and translation models spanning 0.25Bto 18B parameters, with the 18B version being the largest speech model, to thebest of our knowledge. OWLS leverages up to 360K hours of public speech dataacross 150 languages, enabling a systematic investigation into how data, model,and compute scaling each influence performance in multilingual speech tasks. Weuse OWLS to derive neural scaling laws, showing how final performance can bereliably predicted when scaling. One of our key findings is that scalingenhances performance on low-resource languages/dialects, helping to mitigatebias and improve the accessibility of speech technologies. Finally, we show howOWLS can be used to power new research directions by discovering emergentabilities in large-scale speech models. Model checkpoints will be released onhttps://huggingface.co/collections/espnet/owls-scaling-laws-for-speech-recognition-and-translation-67ab7f991c194065f057ce8dfor future studies.</description><author>William Chen, Jinchuan Tian, Yifan Peng, Brian Yan, Chao-Han Huck Yang, Shinji Watanabe</author><pubDate>Fri, 14 Feb 2025 18:51:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10373v1</guid></item><item><title>AffinityFlow: Guided Flows for Antibody Affinity Maturation</title><link>http://arxiv.org/abs/2502.10365v1</link><description>Antibodies are widely used as therapeutics, but their development requirescostly affinity maturation, involving iterative mutations to enhance bindingaffinity.This paper explores a sequence-only scenario for affinity maturation,using solely antibody and antigen sequences. Recently AlphaFlow wraps AlphaFoldwithin flow matching to generate diverse protein structures, enabling asequence-conditioned generative model of structure. Building on this, wepropose an alternating optimization framework that (1) fixes the sequence toguide structure generation toward high binding affinity using a structure-basedaffinity predictor, then (2) applies inverse folding to create sequencemutations, refined by a sequence-based affinity predictor for post selection.To address this, we develop a co-teaching module that incorporates valuableinformation from noisy biophysical energies into predictor refinement. Thesequence-based predictor selects consensus samples to teach the structure-basedpredictor, and vice versa. Our method, AffinityFlow, achieves state-of-the-artperformance in affinity maturation experiments. We plan to open-source our codeafter acceptance.</description><author>Can Chen, Karla-Luise Herpoldt, Chenchao Zhao, Zichen Wang, Marcus Collins, Shang Shang, Ron Benson</author><pubDate>Fri, 14 Feb 2025 18:43:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10365v1</guid></item><item><title>BeamDojo: Learning Agile Humanoid Locomotion on Sparse Footholds</title><link>http://arxiv.org/abs/2502.10363v1</link><description>Traversing risky terrains with sparse footholds poses a significant challengefor humanoid robots, requiring precise foot placements and stable locomotion.Existing approaches designed for quadrupedal robots often fail to generalize tohumanoid robots due to differences in foot geometry and unstable morphology,while learning-based approaches for humanoid locomotion still face greatchallenges on complex terrains due to sparse foothold reward signals andinefficient learning processes. To address these challenges, we introduceBeamDojo, a reinforcement learning (RL) framework designed for enabling agilehumanoid locomotion on sparse footholds. BeamDojo begins by introducing asampling-based foothold reward tailored for polygonal feet, along with a doublecritic to balancing the learning process between dense locomotion rewards andsparse foothold rewards. To encourage sufficient trail-and-error exploration,BeamDojo incorporates a two-stage RL approach: the first stage relaxes theterrain dynamics by training the humanoid on flat terrain while providing itwith task terrain perceptive observations, and the second stage fine-tunes thepolicy on the actual task terrain. Moreover, we implement a onboard LiDAR-basedelevation map to enable real-world deployment. Extensive simulation andreal-world experiments demonstrate that BeamDojo achieves efficient learning insimulation and enables agile locomotion with precise foot placement on sparsefootholds in the real world, maintaining a high success rate even undersignificant external disturbances.</description><author>Huayi Wang, Zirui Wang, Junli Ren, Qingwei Ben, Tao Huang, Weinan Zhang, Jiangmiao Pang</author><pubDate>Fri, 14 Feb 2025 18:42:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10363v1</guid></item><item><title>Enhancing Multilingual LLM Pretraining with Model-Based Data Selection</title><link>http://arxiv.org/abs/2502.10361v1</link><description>Dataset curation has become a basis for strong large language model (LLM)performance. While various rule-based filtering heuristics exist for Englishand multilingual datasets, model-based filtering techniques have primarilyfocused on English. To address the disparity stemming from limited research onnon-English languages, we propose a model-based filtering framework formultilingual datasets that aims to identify a diverse set of structured andknowledge-rich samples. Our approach emphasizes transparency, simplicity, andefficiency, leveraging Transformer- and FastText-based classifiers to ensurethe broad accessibility of our technique and data. We conduct comprehensiveablation studies on the FineWeb-2 web crawl dataset across diverse languagefamilies, scripts, and resource availability to demonstrate the effectivenessof our method. Training a 1B-parameter Llama model for 70B and 119B tokens, ourapproach can match the baseline MMLU score with as little as 15% of thetraining tokens, while also improving across other benchmarks. These findingsprovide strong evidence for the generalizability of our approach to otherlanguages. As a result, we extend our framework to 20 languages for which werelease the refined pretraining datasets.</description><author>Bettina Messmer, Vinko Sabolčec, Martin Jaggi</author><pubDate>Fri, 14 Feb 2025 18:42:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10361v1</guid></item><item><title>Proper Learnability and the Role of Unlabeled Data</title><link>http://arxiv.org/abs/2502.10359v1</link><description>Proper learning refers to the setting in which learners must emit predictorsin the underlying hypothesis class $H$, and often leads to learners with simplealgorithmic forms (e.g. empirical risk minimization (ERM), structural riskminimization (SRM)). The limitation of proper learning, however, is that thereexist problems which can only be learned improperly, e.g. in multiclassclassification. Thus, we ask: Under what assumptions on the hypothesis class orthe information provided to the learner is a problem properly learnable? Wefirst demonstrate that when the unlabeled data distribution is given, therealways exists an optimal proper learner governed by distributionalregularization, a randomized generalization of regularization. We refer to thissetting as the distribution-fixed PAC model, and continue to evaluate thelearner on its worst-case performance over all distributions. Our result holdsfor all metric loss functions and any finite learning problem (with nodependence on its size). Further, we demonstrate that sample complexities inthe distribution-fixed PAC model can shrink by only a logarithmic factor fromthe classic PAC model, strongly refuting the role of unlabeled data in PAClearning (from a worst-case perspective). We complement this with impossibility results which obstruct anycharacterization of proper learnability in the realizable PAC model. First, weobserve that there are problems whose proper learnability is logicallyundecidable, i.e., independent of the ZFC axioms. We then show that properlearnability is not a monotone property of the underlying hypothesis class, andthat it is not a local property (in a precise sense). Our impossibility resultsall hold even for the fundamental setting of multiclass classification, and gothrough a reduction of EMX learning (Ben-David et al., 2019) to properclassification which may be of independent interest.</description><author>Julian Asilis, Siddartha Devic, Shaddin Dughmi, Vatsal Sharan, Shang-Hua Teng</author><pubDate>Fri, 14 Feb 2025 18:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10359v1</guid></item><item><title>Learning Euler Factors of Elliptic Curves</title><link>http://arxiv.org/abs/2502.10357v1</link><description>We apply transformer models and feedforward neural networks to predictFrobenius traces $a_p$ from elliptic curves given other traces $a_q$. We trainfurther models to predict $a_p \bmod 2$ from $a_q \bmod 2$, and cross-analysissuch as $a_p \bmod 2$ from $a_q$. Our experiments reveal that these modelsachieve high accuracy, even in the absence of explicit number-theoretic toolslike functional equations of $L$-functions. We also present partialinterpretability findings.</description><author>Angelica Babei, François Charton, Edgar Costa, Xiaoyu Huang, Kyu-Hwan Lee, David Lowry-Duda, Ashvni Narayanan, Alexey Pozdnyakov</author><pubDate>Fri, 14 Feb 2025 18:39:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10357v1</guid></item><item><title>The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation</title><link>http://arxiv.org/abs/2411.00843v2</link><description>Logic synthesis is a crucial phase in the circuit design process, responsiblefor transforming hardware description language (HDL) designs into optimizednetlists. However, traditional logic synthesis methods are computationallyintensive, restricting their iterative use in refining chip designs. Recentadvancements in large language models (LLMs), particularly those fine-tuned onprogramming languages, present a promising alternative. This work proposesaugmenting LLMs with predictor networks trained to estimate circuit qualitydirectly from HDL code. To enhance performance, the model is regularized usingembeddings from graph neural networks (GNNs) trained on Look-Up Table (LUT)graphs, thereby incorporating lower-level circuit insights. The proposed methoddemonstrates superior performance compared to existing graph-based RTL-levelestimation techniques on the established benchmark OpenABCD, while providinginstant feedback on HDL code quality.</description><author>Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan</author><pubDate>Fri, 14 Feb 2025 18:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.00843v2</guid></item><item><title>Dimension-free Score Matching and Time Bootstrapping for Diffusion Models</title><link>http://arxiv.org/abs/2502.10354v1</link><description>Diffusion models generate samples by estimating the score function of thetarget distribution at various noise levels. The model is trained using samplesdrawn from the target distribution, progressively adding noise. In this work,we establish the first (nearly) dimension-free sample complexity bounds forlearning these score functions, achieving a double exponential improvement indimension over prior results. A key aspect of our analysis is the use of asingle function approximator to jointly estimate scores across noise levels, acritical feature of diffusion models in practice which enables generalizationacross timesteps. Our analysis introduces a novel martingale-based errordecomposition and sharp variance bounds, enabling efficient learning fromdependent data generated by Markov processes, which may be of independentinterest. Building on these insights, we propose Bootstrapped Score Matching(BSM), a variance reduction technique that utilizes previously learned scoresto improve accuracy at higher noise levels. These results provide crucialinsights into the efficiency and effectiveness of diffusion models forgenerative modeling.</description><author>Syamantak Kumar, Dheeraj Nagaraj, Purnamrita Sarkar</author><pubDate>Fri, 14 Feb 2025 18:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10354v1</guid></item><item><title>Assortment Optimization for Patient-Provider Matching</title><link>http://arxiv.org/abs/2502.10353v1</link><description>Rising provider turnover forces healthcare administrators to frequentlyrematch patients to available providers, which can be cumbersome andlabor-intensive. To reduce the burden of rematching, we study algorithms formatching patients and providers through assortment optimization. We develop apatient-provider matching model in which we simultaneously offer each patient amenu of providers, and patients subsequently respond and select providers. Byoffering assortments upfront, administrators can balance logistical ease andpatient autonomy. We study policies for assortment optimization andcharacterize their performance under different problem settings. We demonstratethat the selection of assortment policy is highly dependent on problemspecifics and, in particular, on a patient's willingness to match and the ratiobetween patients and providers. On real-world data, we show that our bestpolicy can improve match quality by 13% over a greedy solution by tailoringassortment sizes based on patient characteristics. We conclude withrecommendations for running a real-world patient-provider matching systeminspired by our results.</description><author>Naveen Raman, Holly Wiberg</author><pubDate>Fri, 14 Feb 2025 18:32:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10353v1</guid></item><item><title>Agentic Verification for Ambiguous Query Disambiguation</title><link>http://arxiv.org/abs/2502.10352v1</link><description>In this work, we tackle the challenge of disambiguating queries inretrieval-augmented generation (RAG) to diverse yet answerable interpretations.State-of-the-arts follow a Diversify-then-Verify (DtV) pipeline, where diverseinterpretations are generated by an LLM, later used as search queries toretrieve supporting passages. Such a process may introduce noise in eitherinterpretations or retrieval, particularly in enterprise settings, where LLMs-- trained on static data -- may struggle with domain-specific disambiguations.Thus, a post-hoc verification phase is introduced to prune noises. Ourdistinction is to unify diversification with verification by incorporatingfeedback from retriever and generator early on. This joint approach improvesboth efficiency and robustness by reducing reliance on multiple retrieval andinference steps, which are susceptible to cascading errors. We validate theefficiency and effectiveness of our method, Verified-Diversification withConsolidation (VERDICT), on the widely adopted ASQA benchmark to achievediverse yet verifiable interpretations. Empirical results show that VERDICTimproves grounding-aware F1 score by an average of 23% over the strongestbaseline across different backbone LLMs.</description><author>Youngwon Lee, Seung-won Hwang, Ruofan Wu, Feng Yan, Danmei Xu, Moutasem Akkad, Zhewei Yao, Yuxiong He</author><pubDate>Fri, 14 Feb 2025 18:31:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10352v1</guid></item><item><title>S2CFormer: Reorienting Learned Image Compression from Spatial Interaction to Channel Aggregation</title><link>http://arxiv.org/abs/2502.00700v2</link><description>Transformers have achieved significant success in learned image compression(LIC), with Swin Transformers emerging as the mainstream choice for nonlineartransforms. A common belief is that their sophisticated spatial operationscontribute most to their efficacy. However, the crucial role of thefeed-forward network (FFN) based Channel Aggregation module within thetransformer architecture has been largely overlooked, and the over-design ofspatial operations leads to a suboptimal trade-off between decoding latency andR-D performance. In this paper, we reevaluate the key factors behind thecompetence of transformers in LIC. By replacing spatial operations withidentity mapping, we are surprised to find that channel operations alone canapproach the R-D performance of the leading methods. This solid lower bound ofperformance emphasizes that the presence of channel aggregation is moreessential for the LIC model to achieve competitive performance, while thepreviously complex spatial interactions are partly redundant. Based on thisinsight, we initiate the "S2CFormer" paradigm, a general architecture thatreorients the focus of LIC from Spatial Interaction to Channel Aggregation. Wepresent two instantiations of the S2CFormer: S2C-Conv, and S2C-Attention. Eachone incorporates a simple operator for spatial interaction and serves asnonlinear transform blocks for our LIC models. Both models demonstratestate-of-the-art (SOTA) R-D performance and significantly faster decodingspeed. These results also motivate further exploration of advanced FFNstructures to enhance the R-D performance while maintaining model efficiency.With these foundations, we introduce S2C-Hybrid, an enhanced LIC model thatcombines the strengths of different S2CFormer instantiations. This modeloutperforms all the existing methods on several datasets, setting a newbenchmark for efficient and high-performance LIC.</description><author>Yunuo Chen, Qian Li, Bing He, Donghui Feng, Ronghua Wu, Qi Wang, Li Song, Guo Lu, Wenjun Zhang</author><pubDate>Fri, 14 Feb 2025 18:30:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.00700v2</guid></item><item><title>Differentially Private Clustered Federated Learning</title><link>http://arxiv.org/abs/2405.19272v4</link><description>Federated learning (FL), which is a decentralized machine learning (ML)approach, often incorporates differential privacy (DP) to provide rigorous dataprivacy guarantees. Previous works attempted to address high structured dataheterogeneity in vanilla FL settings through clustering clients (a.k.aclustered FL), but these methods remain sensitive and prone to errors, furtherexacerbated by the DP noise. This vulnerability makes the previous methodsinappropriate for differentially private FL (DPFL) settings with structureddata heterogeneity. To address this gap, we propose an algorithm fordifferentially private clustered FL, which is robust to the DP noise in thesystem and identifies the underlying clients' clusters correctly. To this end,we propose to cluster clients based on both their model updates and trainingloss values. Furthermore, for clustering clients' model updates at the end ofthe first round, our proposed approach addresses the server's uncertainties byemploying large batch sizes as well as Gaussian Mixture Models (GMM) to reducethe impact of DP and stochastic noise and avoid potential clustering errors.This idea is efficient especially in privacy-sensitive scenarios with more DPnoise. We provide theoretical analysis to justify our approach and evaluate itacross diverse data distributions and privacy budgets. Our experimental resultsshow its effectiveness in addressing large structured data heterogeneity inDPFL.</description><author>Saber Malekmohammadi, Afaf Taik, Golnoosh Farnadi</author><pubDate>Fri, 14 Feb 2025 18:24:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19272v4</guid></item><item><title>New tools for comparing classical and neural ODE models for tumor growth</title><link>http://arxiv.org/abs/2502.07964v2</link><description>A new computational tool TumorGrowth$.$jl for modeling tumor growth isintroduced. The tool allows the comparison of standard textbook models, such asGeneral Bertalanffy and Gompertz, with some newer models, including, for thefirst time, neural ODE models. As an application, we revisit a human meta-studyof non-small cell lung cancer and bladder cancer lesions, in patientsundergoing two different treatment options, to determine if previously reportedperformance differences are statistically significant, and if newer, morecomplex models perform any better. In a population of examples with at leastfour time-volume measurements available for calibration, and an average ofabout 6.3, our main conclusion is that the General Bertalanffy model hassuperior performance, on average. However, where more measurements areavailable, we argue that more complex models, capable of capturing rebound andrelapse behavior, may be better choices.</description><author>Anthony D. Blaom, Samuel Okon</author><pubDate>Fri, 14 Feb 2025 18:24:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07964v2</guid></item><item><title>Noise-Aware Algorithm for Heterogeneous Differentially Private Federated Learning</title><link>http://arxiv.org/abs/2406.03519v4</link><description>High utility and rigorous data privacy are of the main goals of a federatedlearning (FL) system, which learns a model from the data distributed among someclients. The latter has been tried to achieve by using differential privacy inFL (DPFL). There is often heterogeneity in clients privacy requirements, andexisting DPFL works either assume uniform privacy requirements for clients orare not applicable when server is not fully trusted (our setting). Furthermore,there is often heterogeneity in batch and/or dataset size of clients, which asshown, results in extra variation in the DP noise level across clients modelupdates. With these sources of heterogeneity, straightforward aggregationstrategies, e.g., assigning clients aggregation weights proportional to theirprivacy parameters will lead to lower utility. We propose Robust-HDP, whichefficiently estimates the true noise level in clients model updates and reducesthe noise-level in the aggregated model updates considerably. Robust-HDPimproves utility and convergence speed, while being safe to the clients thatmay maliciously send falsified privacy parameter to server. Extensiveexperimental results on multiple datasets and our theoretical analysis confirmthe effectiveness of Robust-HDP. Our code can be found here.</description><author>Saber Malekmohammadi, Yaoliang Yu, Yang Cao</author><pubDate>Fri, 14 Feb 2025 18:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03519v4</guid></item><item><title>MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs</title><link>http://arxiv.org/abs/2410.13502v3</link><description>Large language models (LLMs) can solve arithmetic word problems with highaccuracy, but little is known about how well they generalize to more complexproblems. This is difficult to study, as (i) much of the available evaluationdata has already been seen by the most capable models during training, and (ii)existing benchmarks do not capture how problem proofs may be arbitrarilycomplex in various ways. In this paper, we present a data-generation frameworkfor evaluating LLMs on problems with arbitrarily complex arithmetic proofs,called MathGAP. MathGAP generates problem statements and chain-of-thoughtreasoning traces according to specifications about their arithmetic proofstructure, enabling systematic studies on easy-to-hard generalization withrespect to complexity of proof trees. Using MathGAP, we find that LLMs show asignificant decrease in performance as proofs get deeper and wider. This effectis more pronounced in complex, nonlinear proof structures, which arechallenging even for the most capable models. The models are also sensitive tosimple changes in sentence ordering. However, they remain capable of solvingsome complex problems, suggesting that reasoning generalization is noisy.</description><author>Andreas Opedal, Haruki Shirakami, Bernhard Schölkopf, Abulhair Saparov, Mrinmaya Sachan</author><pubDate>Fri, 14 Feb 2025 18:15:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13502v3</guid></item><item><title>Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering</title><link>http://arxiv.org/abs/2311.17331v4</link><description>Recently, to comprehensively improve Vision Language Models (VLMs) for VisualQuestion Answering (VQA), several methods have been proposed to furtherreinforce the inference capabilities of VLMs to independently tackle VQA tasksrather than some methods that only utilize VLMs as aids to Large LanguageModels (LLMs). However, these methods ignore the rich common-sense knowledgeinside the given VQA image sampled from the real world. Thus, they cannot fullyuse the powerful VLM for the given VQA question to achieve optimal performance.Attempt to overcome this limitation and inspired by the human top-downreasoning process, i.e., systematically exploring relevant issues to derive acomprehensive answer, this work introduces a novel, explainable multi-agentcollaboration framework by leveraging the expansive knowledge of Large LanguageModels (LLMs) to enhance the capabilities of VLMs themselves. Specifically, ourframework comprises three agents, i.e., Responder, Seeker, and Integrator, tocollaboratively answer the given VQA question by seeking its relevant issuesand generating the final answer in such a top-down reasoning process. TheVLM-based Responder agent generates the answer candidates for the question andresponds to other relevant issues. The Seeker agent, primarily based on LLM,identifies relevant issues related to the question to inform the Responderagent and constructs a Multi-View Knowledge Base (MVKB) for the given visualscene by leveraging the build-in world knowledge of LLM. The Integrator agentcombines knowledge from the Seeker agent and the Responder agent to produce thefinal VQA answer. Extensive and comprehensive evaluations on diverse VQAdatasets with a variety of VLMs demonstrate the superior performance andinterpretability of our framework over the baseline method in the zero-shotsetting without extra training cost.</description><author>Zeqing Wang, Wentao Wan, Qiqing Lao, Runmeng Chen, Minjie Lang, Xiao Wang, Keze Wang, Liang Lin</author><pubDate>Fri, 14 Feb 2025 18:09:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17331v4</guid></item><item><title>Evidence of Scaling Regimes in the Hopfield Dynamics of Whole Brain Model</title><link>http://arxiv.org/abs/2401.07538v3</link><description>It is shown that a Hopfield recurrent neural network exhibits a scalingregime, whose specific exponents depend on the number of parcels used and thedecay length of the coupling strength. This scaling regime recovers the pictureintroduced by Deco et al., according to which the process of informationtransfer within the human brain shows spatially correlated patternsqualitatively similar to those displayed by turbulent flows, although with amore singular exponent, 1/2 instead of 2/3. Both models employ a couplingstrength which decays exponentially with the Euclidean distance between thenodes, informed by experimentally derived brain topology. Nevertheless, theirmathematical nature is very different, Hopf oscillators versus a Hopfieldneural network, respectively. Hence, their convergence for the same dataparameters, suggests an intriguing robustness of the scalingpicture.Furthermore, the present analysis shows that the Hopfield model brainremains functional by removing links above about five decay lengths,corresponding to about one sixth of the size of the global brain. This suggeststhat, in terms of connectivity decay length, the Hopfield brain functions in asort of intermediate ``turbulent liquid''-like state, whose essentialconnections are the intermediate ones between the connectivity decay length andthe global brain size. The evident sensitivity of the scaling exponent to thevalue of the decay length, as well as to the number of brain parcels employed,leads us to take with great caution any quantitative assessment regarding thespecific nature of the scaling regime.</description><author>Giorgio Gosti, Sauro Succi, Giancarlo Ruocco</author><pubDate>Fri, 14 Feb 2025 18:04:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07538v3</guid></item><item><title>Magic 1-For-1: Generating One Minute Video Clips within One Minute</title><link>http://arxiv.org/abs/2502.07701v2</link><description>In this technical report, we present Magic 1-For-1 (Magic141), an efficientvideo generation model with optimized memory consumption and inference latency.The key idea is simple: factorize the text-to-video generation task into twoseparate easier tasks for diffusion step distillation, namely text-to-imagegeneration and image-to-video generation. We verify that with the sameoptimization algorithm, the image-to-video task is indeed easier to convergeover the text-to-video task. We also explore a bag of optimization tricks toreduce the computational cost of training the image-to-video (I2V) models fromthree aspects: 1) model convergence speedup by using a multi-modal priorcondition injection; 2) inference latency speed up by applying an adversarialstep distillation, and 3) inference memory cost optimization with parametersparsification. With those techniques, we are able to generate 5-second videoclips within 3 seconds. By applying a test time sliding window, we are able togenerate a minute-long video within one minute with significantly improvedvisual quality and motion dynamics, spending less than 1 second for generating1 second video clips on average. We conduct a series of preliminaryexplorations to find out the optimal tradeoff between computational cost andvideo quality during diffusion step distillation and hope this could be a goodfoundation model for open-source explorations. The code and the model weightsare available at https://github.com/DA-Group-PKU/Magic-1-For-1.</description><author>Hongwei Yi, Shitong Shao, Tian Ye, Jiantong Zhao, Qingyu Yin, Michael Lingelbach, Li Yuan, Yonghong Tian, Enze Xie, Daquan Zhou</author><pubDate>Fri, 14 Feb 2025 18:02:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07701v2</guid></item><item><title>Organize the Web: Constructing Domains Enhances Pre-Training Data Curation</title><link>http://arxiv.org/abs/2502.10341v1</link><description>Modern language models are trained on large, unstructured datasets consistingof trillions of tokens and obtained by crawling the web. The unstructurednature makes it difficult to reason about their contents and develop systematicapproaches to data curation. In this paper, we unpack monolithic web corpora bydeveloping taxonomies of their contents and organizing them into domains. Weintroduce WebOrganizer, a framework for organizing web pages in terms of boththeir topic and format. Using these two complementary notions of domains, weautomatically annotate pre-training data by distilling annotations from a largelanguage model into efficient classifiers. This allows us to study how datafrom different domains should be mixed to improve models on downstream tasks,and we show that we can combine insights about effective topics and formats tofurther boost performance. We demonstrate that our domain mixing also improvesexisting methods that select data based on quality. Furthermore, we study andcompare how quality-based methods will implicitly change the domain mixture.Overall, our work demonstrates that constructing and mixing domains provides avaluable complement to quality-based data curation methods, opening new avenuesfor effective and insightful pre-training data curation.</description><author>Alexander Wettig, Kyle Lo, Sewon Min, Hannaneh Hajishirzi, Danqi Chen, Luca Soldaini</author><pubDate>Fri, 14 Feb 2025 18:02:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10341v1</guid></item><item><title>STAR: Spectral Truncation and Rescale for Model Merging</title><link>http://arxiv.org/abs/2502.10339v1</link><description>Model merging is an efficient way of obtaining a multi-task model fromseveral pretrained models without further fine-tuning, and it has gainedattention in various domains, including natural language processing (NLP).Despite the efficiency, a key challenge in model merging is the seeminglyinevitable decrease in task performance as the number of models increases. Inthis paper, we propose $\mathbf{S}$pectral $\mathbf{T}$runcation $\mathbf{A}$nd$\mathbf{R}$escale (STAR) that aims at mitigating ``merging conflicts'' bytruncating small components in the respective spectral spaces, which isfollowed by an automatic parameter rescaling scheme to retain the nuclear normof the original matrix. STAR requires no additional inference on originaltraining data and is robust to hyperparamater choice. We demonstrate theeffectiveness of STAR through extensive model merging cases on diverse NLPtasks. Specifically, STAR works robustly across varying model sizes, and canoutperform baselines by 4.2$\%$ when merging 12 models on Flan-T5. Our code ispublicly available at https://github.com/IBM/STAR.</description><author>Yu-Ang Lee, Ching-Yun Ko, Tejaswini Pedapati, I-Hsin Chung, Mi-Yen Yeh, Pin-Yu Chen</author><pubDate>Fri, 14 Feb 2025 17:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10339v1</guid></item><item><title>Evaluating the Meta- and Object-Level Reasoning of Large Language Models for Question Answering</title><link>http://arxiv.org/abs/2502.10338v1</link><description>Large Language Models (LLMs) excel in natural language tasks but still facechallenges in Question Answering (QA) tasks requiring complex, multi-stepreasoning. We outline the types of reasoning required in some of these tasks,and reframe them in terms of meta-level reasoning (akin to high-level strategicreasoning or planning) and object-level reasoning (embodied in lower-leveltasks such as mathematical reasoning). Franklin, a novel dataset withrequirements of meta- and object-level reasoning, is introduced and used alongwith three other datasets to evaluate four LLMs at question answering tasksrequiring multiple steps of reasoning. Results from human annotation studiessuggest LLMs demonstrate meta-level reasoning with high frequency, but strugglewith object-level reasoning tasks in some of the datasets used. Additionally,evidence suggests that LLMs find the object-level reasoning required for thequestions in the Franklin dataset challenging, yet they do exhibit strongperformance with respect to the meta-level reasoning requirements.</description><author>Nick Ferguson, Liane Guillou, Alan Bundy, Kwabena Nuamah</author><pubDate>Fri, 14 Feb 2025 17:55:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10338v1</guid></item><item><title>Studying number theory with deep learning: a case study with the Möbius and squarefree indicator functions</title><link>http://arxiv.org/abs/2502.10335v1</link><description>Building on work of Charton, we train small transformer models to calculatethe M\"obius function $\mu(n)$ and the squarefree indicator function$\mu^2(n)$. The models attain nontrivial predictive power. We then iterativelytrain additional models to understand how the model functions, ultimatelyfinding a theoretical explanation.</description><author>David Lowry-Duda</author><pubDate>Fri, 14 Feb 2025 17:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10335v1</guid></item><item><title>RASPNet: A Benchmark Dataset for Radar Adaptive Signal Processing Applications</title><link>http://arxiv.org/abs/2406.09638v2</link><description>We present a large-scale dataset for radar adaptive signal processing (RASP)applications to support the development of data-driven models within theadaptive radar community. The dataset, RASPNet, exceeds 16 TB in size andcomprises 100 realistic scenarios compiled over a variety of topographies andland types from across the contiguous United States. For each scenario, RASPNetconsists of 10,000 clutter realizations from an airborne radar setting, whichcan be used to benchmark radar and complex-valued learning algorithms. RASPNetintends to fill a prominent gap in the availability of a large-scale, realisticdataset that standardizes the evaluation of adaptive radar processingtechniques and complex-valued neural networks. We outline its construction,organization, and several applications, including a transfer learning exampleto demonstrate how RASPNet can be used for realistic adaptive radar processingscenarios.</description><author>Shyam Venkatasubramanian, Bosung Kang, Ali Pezeshki, Muralidhar Rangaswamy, Vahid Tarokh</author><pubDate>Fri, 14 Feb 2025 17:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09638v2</guid></item><item><title>Ocular Disease Classification Using CNN with Deep Convolutional Generative Adversarial Network</title><link>http://arxiv.org/abs/2502.10334v1</link><description>The Convolutional Neural Network (CNN) has shown impressive performance inimage classification because of its strong learning capabilities. However, itdemands a substantial and balanced dataset for effective training. Otherwise,networks frequently exhibit over fitting and struggle to generalize to newexamples. Publicly available dataset of fundus images of ocular disease isinsufficient to train any classification model to achieve satisfactoryaccuracy. So, we propose Generative Adversarial Network(GAN) based datageneration technique to synthesize dataset for training CNN basedclassification model and later use original disease containing ocular images totest the model. During testing the model classification accuracy with theoriginal ocular image, the model achieves an accuracy rate of 78.6% for myopia,88.6% for glaucoma, and 84.6% for cataract, with an overall classificationaccuracy of 84.6%.</description><author>Arun Kunwar, Dibakar Raj Pant, Jukka Heikkonen, Rajeev Kanth</author><pubDate>Fri, 14 Feb 2025 17:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10334v1</guid></item><item><title>InfoPos: A ML-Assisted Solution Design Support Framework for Industrial Cyber-Physical Systems</title><link>http://arxiv.org/abs/2502.10331v1</link><description>The variety of building blocks and algorithms incorporated in data-centricand ML-assisted solutions is high, contributing to two challenges: selection ofmost effective set and order of building blocks, as well as achieving such aselection with minimum cost. Considering that ML-assisted solution design isinfluenced by the extent of available data, as well as available knowledge ofthe target system, it is advantageous to be able to select matching buildingblocks. We introduce the first iteration of our InfoPos framework, allowing theplacement of use-cases considering the available positions (levels), i.e., frompoor to rich, of knowledge and data dimensions. With that input, designers anddevelopers can reveal the most effective corresponding choice(s), streamliningthe solution design process. The results from our demonstrator, an anomalyidentification use-case for industrial Cyber-Physical Systems, reflectsachieved effects upon the use of different building blocks throughout knowledgeand data positions. The achieved ML model performance is considered as theindicator. Our data processing code and the composed data sets are publiclyavailable.</description><author>Uraz Odyurt, Richard Loendersloot, Tiedo Tinga</author><pubDate>Fri, 14 Feb 2025 17:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10331v1</guid></item><item><title>DiOpt: Self-supervised Diffusion for Constrained Optimization</title><link>http://arxiv.org/abs/2502.10330v1</link><description>Recent advances in diffusion models show promising potential forlearning-based optimization by leveraging their multimodal sampling capabilityto escape local optima. However, existing diffusion-based optimizationapproaches, often reliant on supervised training, lacks a mechanism to ensurestrict constraint satisfaction which is often required in real-worldapplications. One resulting observation is the distributional misalignment,i.e. the generated solution distribution often exhibits small overlap with thefeasible domain. In this paper, we propose DiOpt, a novel diffusion paradigmthat systematically learns near-optimal feasible solution distributions throughiterative self-training. Our framework introduces several key innovations: atarget distribution specifically designed to maximize overlap with theconstrained solution manifold; a bootstrapped self-training mechanism thatadaptively weights candidate solutions based on the severity of constraintviolations and optimality gaps; and a dynamic memory buffer that acceleratesconvergence by retaining high-quality solutions over training iterations. Toour knowledge, DiOpt represents the first successful integration ofself-supervised diffusion with hard constraint satisfaction. Evaluations ondiverse tasks, including power grid control, motion retargeting, wirelessallocation demonstrate its superiority in terms of both optimality andconstraint satisfaction.</description><author>Shutong Ding, Yimiao Zhou, Ke Hu, Xi Yao, Junchi Yan, Xiaoying Tang, Ye Shi</author><pubDate>Fri, 14 Feb 2025 17:43:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10330v1</guid></item><item><title>Generalised Parallel Tempering: Flexible Replica Exchange via Flows and Diffusions</title><link>http://arxiv.org/abs/2502.10328v1</link><description>Parallel Tempering (PT) is a classical MCMC algorithm designed for leveragingparallel computation to sample efficiently from high-dimensional, multimodal orotherwise complex distributions via annealing. One limitation of the standardformulation of PT is the growth of computational resources required to generatehigh-quality samples, as measured by effective sample size or round trip rate,for increasingly challenging distributions. To address this issue, we proposethe framework: Generalised Parallel Tempering (GePT) which allows for theincorporation of recent advances in modern generative modelling, such asnormalising flows and diffusion models, within Parallel Tempering, whilemaintaining the same theoretical guarantees as MCMC-based methods. Forinstance, we show that this allows us to utilise diffusion models in aparallelised manner, bypassing the usual computational cost of a large numberof steps to generate quality samples. Further, we empirically demonstrate thatGePT can improve sample quality and reduce the growth of computationalresources required to handle complex distributions over the classicalalgorithm.</description><author>Leo Zhang, Peter Potaptchik, Arnaud Doucet, Hai-Dang Dau, Saifuddin Syed</author><pubDate>Fri, 14 Feb 2025 17:41:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10328v1</guid></item><item><title>SuperMerge: An Approach For Gradient-Based Model Merging</title><link>http://arxiv.org/abs/2412.10416v2</link><description>Large language models, such as ChatGPT, Claude, or LLaMA, are gigantic,monolithic, and possess the superpower to simultaneously support thousands oftasks. However, high-throughput applications often prefer smaller task-specificmodels because of their lower latency and cost. One challenge of usingtask-specific models is the incremental need for solving newer tasks after themodel is already deployed for existing tasks. A straightforward solutionrequires fine-tuning the model again for both existing and new tasks, which iscomputationally expensive and time-consuming. To address this issue, we proposea model merging based approach called SUPERMERGE. SUPERMERGE is agradient-based method to systematically merge several fine-tuned models trainedon existing and new tasks. SUPERMERGE is designed to be lightweight and fast,and the merged model achieves similar performance to fully fine-tuned models onall tasks. Furthermore, we proposed a hierarchical model merging strategy toreduce the peak space requirement without sacrificing the performance of themerged model. We experimentally demonstrate that SUPERMERGE outperformsexisting model merging methods on common natural language processing andcomputer vision tasks.</description><author>Haoyu Yang, Zheng Zhang, Saket Sathe</author><pubDate>Fri, 14 Feb 2025 17:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10416v2</guid></item><item><title>Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise Sufficient Reasons</title><link>http://arxiv.org/abs/2502.03391v2</link><description>*Minimal sufficient reasons* represent a prevalent form of explanation - thesmallest subset of input features which, when held constant at theircorresponding values, ensure that the prediction remains unchanged. Previous*post-hoc* methods attempt to obtain such explanations but face two mainlimitations: (1) Obtaining these subsets poses a computational challenge,leading most scalable methods to converge towards suboptimal, less meaningfulsubsets; (2) These methods heavily rely on sampling out-of-distribution inputassignments, potentially resulting in counterintuitive behaviors. To tacklethese limitations, we propose in this work a self-supervised training approach,which we term *sufficient subset training* (SST). Using SST, we train models togenerate concise sufficient reasons for their predictions as an integral partof their output. Our results indicate that our framework produces succinct andfaithful subsets substantially more efficiently than competing post-hocmethods, while maintaining comparable predictive performance.</description><author>Shahaf Bassan, Ron Eliav, Shlomit Gur</author><pubDate>Fri, 14 Feb 2025 17:39:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03391v2</guid></item><item><title>ResearchArena: Benchmarking Large Language Models' Ability to Collect and Organize Information as Research Agents</title><link>http://arxiv.org/abs/2406.10291v2</link><description>Large language models (LLMs) excel across many natural language processingtasks but face challenges in domain-specific, analytical tasks such asconducting research surveys. This study introduces ResearchArena, a benchmarkdesigned to evaluate LLMs' capabilities in conducting academicsurveys$\unicode{x2013}$a foundational step in academic research. ResearchArenamodels the process in three stages: (1) information discovery, identifyingrelevant literature; (2) information selection, evaluating papers' relevanceand impact; and (3) information organization, structuring knowledge intohierarchical frameworks such as mind-maps. Notably, mind-map construction istreated as a bonus task, reflecting its supplementary role in survey-writing.To support these evaluations, we construct an offline environment of 12Mfull-text academic papers and 7.9K survey papers. To ensure ethical compliance,we do not redistribute copyrighted materials; instead, we provide code toconstruct the environment from the Semantic Scholar Open Research Corpus(S2ORC). Preliminary evaluations reveal that LLM-based approaches underperformcompared to simpler keyword-based retrieval methods, underscoring significantopportunities for advancing LLMs in autonomous research.</description><author>Hao Kang, Chenyan Xiong</author><pubDate>Fri, 14 Feb 2025 17:37:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10291v2</guid></item><item><title>Training Neural Networks on Data Sources with Unknown Reliability</title><link>http://arxiv.org/abs/2212.02895v4</link><description>When data is generated by multiple sources, conventional training methodsupdate models assuming equal reliability for each source and do not considertheir individual data quality. However, in many applications, sources havevaried levels of reliability that can have negative effects on the performanceof a neural network. A key issue is that often the quality of the data forindividual sources is not known during training. Previous methods for trainingmodels in the presence of noisy data do not make use of the additionalinformation that the source label can provide. Focusing on supervised learning,we aim to train neural networks on each data source for a number of stepsproportional to the source's estimated reliability by using a dynamicre-weighting strategy motivated by likelihood tempering. This way, we allowtraining on all sources during the warm-up and reduce learning on less reliablesources during the final training stages, when it has been shown that modelsoverfit to noise. We show through diverse experiments that this cansignificantly improve model performance when trained on mixtures of reliableand unreliable data sources, and maintain performance when models are trainedon reliable sources only.</description><author>Alexander Capstick, Francesca Palermo, Tianyu Cui, Payam Barnaghi</author><pubDate>Fri, 14 Feb 2025 17:35:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.02895v4</guid></item><item><title>Process Reward Models for LLM Agents: Practical Framework and Directions</title><link>http://arxiv.org/abs/2502.10325v1</link><description>We introduce Agent Process Reward Models (AgentPRM), a simple and scalableframework for training LLM agents to continually improve through interactions.AgentPRM follows a lightweight actor-critic paradigm, using Monte Carlorollouts to compute reward targets and optimize policies. It requires minimalmodifications to existing RLHF pipelines, making it easy to integrate at scale.Beyond AgentPRM, we propose InversePRM, which learns process rewards directlyfrom demonstrations without explicit outcome supervision. We also explore keychallenges and opportunities, including exploration, process reward shaping,and model-predictive reasoning. We evaluate on ALFWorld benchmark, show thatsmall 3B models trained with AgentPRM and InversePRM outperform strong GPT-4obaselines, and analyze test-time scaling, reward hacking, and more. Our code isavailable at: https://github.com/sanjibanc/agent_prm.</description><author>Sanjiban Choudhury</author><pubDate>Fri, 14 Feb 2025 17:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10325v1</guid></item><item><title>Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks</title><link>http://arxiv.org/abs/2403.13740v2</link><description>The lack of transparency of Deep Neural Networks continues to be a limitationthat severely undermines their reliability and usage in high-stakesapplications. Promising approaches to overcome such limitations arePrototype-Based Self-Explainable Neural Networks (PSENNs), whose predictionsrely on the similarity between the input at hand and a set of prototypicalrepresentations of the output classes, offering therefore a deep, yettransparent-by-design, architecture. In this paper, we introduce aprobabilistic reformulation of PSENNs, called Prob-PSENN, which replaces pointestimates for the prototypes with probability distributions over their values.This provides not only a more flexible framework for an end-to-end learning ofprototypes, but can also capture the explanatory uncertainty of the model,which is a missing feature in previous approaches. In addition, since theprototypes determine both the explanation and the prediction, Prob-PSENNs allowus to detect when the model is making uninformed or uncertain predictions, andto obtain valid explanations for them. Our experiments demonstrate thatProb-PSENNs provide more meaningful and robust explanations than theirnon-probabilistic counterparts, while remaining competitive in terms ofpredictive performance, thus enhancing the explainability and reliability ofthe models.</description><author>Jon Vadillo, Roberto Santana, Jose A. Lozano, Marta Kwiatkowska</author><pubDate>Fri, 14 Feb 2025 17:30:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13740v2</guid></item><item><title>Solving the enigma: Enhancing faithfulness and comprehensibility in explanations of deep networks</title><link>http://arxiv.org/abs/2405.10008v2</link><description>The accelerated progress of artificial intelligence (AI) has popularized deeplearning models across various domains, yet their inherent opacity poseschallenges, particularly in critical fields like healthcare, medicine, and thegeosciences. Explainable AI (XAI) has emerged to shed light on these 'blackbox' models, aiding in deciphering their decision-making processes. However,different XAI methods often produce significantly different explanations,leading to high inter-method variability that increases uncertainty andundermines trust in deep networks' predictions. In this study, we address thischallenge by introducing a novel framework designed to enhance theexplainability of deep networks through a dual focus on maximizing bothaccuracy and comprehensibility in the explanations. Our framework integratesoutputs from multiple established XAI methods and leverages a non-linear neuralnetwork model, termed the 'explanation optimizer,' to construct a unified,optimal explanation. The optimizer evaluates explanations using two keymetrics: faithfulness (accuracy in reflecting the network's decisions) andcomplexity (comprehensibility). By balancing these, it provides accurate andaccessible explanations, addressing a key XAI limitation. Experiments onmulti-class and binary classification in 2D object and 3D neuroscience imagingconfirm its efficacy. Our optimizer achieved faithfulness scores 155% and 63%higher than the best XAI methods in 3D and 2D tasks, respectively, while alsoreducing complexity for better understanding. These results demonstrate thatoptimal explanations based on specific quality criteria are achievable,offering a solution to the issue of inter-method variability in the current XAIliterature and supporting more trustworthy deep network predictions</description><author>Michail Mamalakis, Antonios Mamalakis, Ingrid Agartz, Lynn Egeland Mørch-Johnsen, Graham Murray, John Suckling, Pietro Lio</author><pubDate>Fri, 14 Feb 2025 17:28:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10008v2</guid></item><item><title>The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation</title><link>http://arxiv.org/abs/2502.07516v2</link><description>Generative models, particularly text-to-image (T2I) diffusion models, play acrucial role in medical image analysis. However, these models are prone totraining data memorization, posing significant risks to patient privacy.Synthetic chest X-ray generation is one of the most common applications inmedical image analysis with the MIMIC-CXR dataset serving as the primary datarepository for this task. This study presents the first systematic attempt toidentify prompts and text tokens in MIMIC-CXR that contribute the most totraining data memorization. Our analysis reveals two unexpected findings: (1)prompts containing traces of de-identification procedures (markers introducedto hide Protected Health Information) are the most memorized, and (2) among alltokens, de-identification markers contribute the most towards memorization.This highlights a broader issue with the standard anonymization practices andT2I synthesis with MIMIC-CXR. To exacerbate, existing inference-timememorization mitigation strategies are ineffective and fail to sufficientlyreduce the model's reliance on memorized text tokens. On this front, we proposeactionable strategies for different stakeholders to enhance privacy and improvethe reliability of generative models in medical imaging. Finally, our resultsprovide a foundation for future work on developing and benchmarkingmemorization mitigation techniques for synthetic chest X-ray generation usingthe MIMIC-CXR dataset. The anonymized code is available athttps://anonymous.4open.science/r/diffusion_memorization-8011/</description><author>Raman Dutt</author><pubDate>Fri, 14 Feb 2025 17:24:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.07516v2</guid></item><item><title>ExplainReduce: Summarising local explanations via proxies</title><link>http://arxiv.org/abs/2502.10311v1</link><description>Most commonly used non-linear machine learning methods are closed-box models,uninterpretable to humans. The field of explainable artificial intelligence(XAI) aims to develop tools to examine the inner workings of these closedboxes. An often-used model-agnostic approach to XAI involves using simplemodels as local approximations to produce so-called local explanations;examples of this approach include LIME, SHAP, and SLISEMAP. This paper showshow a large set of local explanations can be reduced to a small "proxy set" ofsimple models, which can act as a generative global explanation. This reductionprocedure, ExplainReduce, can be formulated as an optimisation problem andapproximated efficiently using greedy heuristics.</description><author>Lauri Seppäläinen, Mudong Guo, Kai Puolamäki</author><pubDate>Fri, 14 Feb 2025 17:14:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10311v1</guid></item><item><title>Object Detection and Tracking</title><link>http://arxiv.org/abs/2502.10310v1</link><description>Efficient and accurate object detection is an important topic in thedevelopment of computer vision systems. With the advent of deep learningtechniques, the accuracy of object detection has increased significantly. Theproject aims to integrate a modern technique for object detection with the aimof achieving high accuracy with real-time performance. The reliance on othercomputer vision algorithms in many object identification systems, which resultsin poor and ineffective performance, is a significant obstacle. In thisresearch, we solve the end-to-end object detection problem entirely using deeplearning techniques. The network is trained using the most difficult publiclyavailable dataset, which is used for an annual item detection challenge.Applications that need object detection can benefit the system's quick andprecise finding.</description><author>Md Pranto, Omar Faruk</author><pubDate>Fri, 14 Feb 2025 17:13:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10310v1</guid></item><item><title>LLM-Powered Preference Elicitation in Combinatorial Assignment</title><link>http://arxiv.org/abs/2502.10308v1</link><description>We study the potential of large language models (LLMs) as proxies for humansto simplify preference elicitation (PE) in combinatorial assignment. Whiletraditional PE methods rely on iterative queries to capture preferences, LLMsoffer a one-shot alternative with reduced human effort. We propose a frameworkfor LLM proxies that can work in tandem with SOTA ML-powered preferenceelicitation schemes. Our framework handles the novel challenges introduced byLLMs, such as response variability and increased computational costs. Weexperimentally evaluate the efficiency of LLM proxies against human queries inthe well-studied course allocation domain, and we investigate the modelcapabilities required for success. We find that our approach improvesallocative efficiency by up to 20%, and these results are robust acrossdifferent LLMs and to differences in quality and accuracy of reporting.</description><author>Ermis Soumalias, Yanchen Jiang, Kehang Zhu, Michael Curry, Sven Seuken, David C. Parkes</author><pubDate>Fri, 14 Feb 2025 17:12:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10308v1</guid></item><item><title>SPIRIT: Short-term Prediction of solar IRradIance for zero-shot Transfer learning using Foundation Models</title><link>http://arxiv.org/abs/2502.10307v1</link><description>Traditional solar forecasting models are based on several years ofsite-specific historical irradiance data, often spanning five or more years,which are unavailable for newer photovoltaic farms. As renewable energy ishighly intermittent, building accurate solar irradiance forecasting systems isessential for efficient grid management and enabling the ongoing proliferationof solar energy, which is crucial to achieve the United Nations' net zerogoals. In this work, we propose SPIRIT, a novel approach leveraging foundationmodels for solar irradiance forecasting, making it applicable to newer solarinstallations. Our approach outperforms state-of-the-art models in zero-shottransfer learning by about 70%, enabling effective performance at new locationswithout relying on any historical data. Further improvements in performance areachieved through fine-tuning, as more location-specific data becomes available.These findings are supported by statistical significance, further validatingour approach. SPIRIT represents a pivotal step towards rapid, scalable, andadaptable solar forecasting solutions, advancing the integration of renewableenergy into global power systems.</description><author>Aditya Mishra, Ravindra T, Srinivasan Iyengar, Shivkumar Kalyanaraman, Ponnurangam Kumaraguru</author><pubDate>Fri, 14 Feb 2025 17:10:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10307v1</guid></item><item><title>Reinforcement Learning in Strategy-Based and Atari Games: A Review of Google DeepMinds Innovations</title><link>http://arxiv.org/abs/2502.10303v1</link><description>Reinforcement Learning (RL) has been widely used in many applications,particularly in gaming, which serves as an excellent training ground for AImodels. Google DeepMind has pioneered innovations in this field, employingreinforcement learning algorithms, including model-based, model-free, and deepQ-network approaches, to create advanced AI models such as AlphaGo, AlphaGoZero, and MuZero. AlphaGo, the initial model, integrates supervised learningand reinforcement learning to master the game of Go, surpassing professionalhuman players. AlphaGo Zero refines this approach by eliminating reliance onhuman gameplay data, instead utilizing self-play for enhanced learningefficiency. MuZero further extends these advancements by learning theunderlying dynamics of game environments without explicit knowledge of therules, achieving adaptability across various games, including complex Atarigames. This paper reviews the significance of reinforcement learningapplications in Atari and strategy-based games, analyzing these three models,their key innovations, training processes, challenges encountered, andimprovements made. Additionally, we discuss advancements in the field ofgaming, including MiniZero and multi-agent models, highlighting futuredirections and emerging AI models from Google DeepMind.</description><author>Abdelrhman Shaheen, Anas Badr, Ali Abohendy, Hatem Alsaadawy, Nadine Alsayad</author><pubDate>Fri, 14 Feb 2025 17:06:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10303v1</guid></item><item><title>VT-GAN: Cooperative Tabular Data Synthesis using Vertical Federated Learning</title><link>http://arxiv.org/abs/2302.01706v2</link><description>This paper presents the application of Vertical Federated Learning (VFL) togenerate synthetic tabular data using Generative Adversarial Networks (GANs).VFL is a collaborative approach to train machine learning models among distincttabular data holders, such as financial institutions, who possess disjointfeatures for the same group of customers. In this paper we introduce the VT-GANframework, Vertical federated Tabular GAN, and demonstrate that VFL can besuccessfully used to implement GANs for distributed tabular data inprivacy-preserving manner, with performance close to centralized GANs thatassume shared data. We make design choices with respect to the distribution ofGAN generator and discriminator models and introduce a training-with-shufflingtechnique so that no party can reconstruct training data from the GANconditional vector. The paper presents (1) an implementation of VT-GAN, (2) adetailed quality evaluation of the VT-GAN-generated synthetic data, (3) anoverall scalability examination of VT-GAN framework, (4) a security analysis onVT-GAN's robustness against Membership Inference Attack with different settingsof Differential Privacy, for a range of datasets with diverse distributioncharacteristics. Our results demonstrate that VT-GAN can consistently generatehigh-fidelity synthetic tabular data of comparable quality to that generated bya centralized GAN algorithm. The difference in machine learning utility can beas low as 2.7%, even under extremely imbalanced data distributions acrossclients or with different numbers of clients.</description><author>Zilong Zhao, Han Wu, Aad Van Moorsel, Lydia Y. Chen</author><pubDate>Fri, 14 Feb 2025 17:05:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01706v2</guid></item><item><title>DeltaProduct: Increasing the Expressivity of DeltaNet Through Products of Householders</title><link>http://arxiv.org/abs/2502.10297v1</link><description>Linear Recurrent Neural Networks (linear RNNs) have emerged as competitivealternatives to Transformers for sequence modeling, offering efficient trainingand linear-time inference. However, existing architectures face a fundamentaltrade-off between expressivity and efficiency, dictated by the structure oftheir state-transition matrices. While diagonal matrices used in architectureslike Mamba, GLA, or mLSTM yield fast runtime, they suffer from severely limitedexpressivity. To address this, recent architectures such as (Gated) DeltaNetand RWKVv7 adopted a diagonal plus rank-1 structure, allowing simultaneoustoken-channel mixing, which overcomes some expressivity limitations with only aslight decrease in training efficiency. Building on the interpretation ofDeltaNet's recurrence as performing one step of online gradient descent pertoken on an associative recall loss, we introduce DeltaProduct, which insteadtakes multiple ($n_h$) steps per token. This naturally leads to diagonal plusrank-$n_h$ state-transition matrices, formed as products of $n_h$ generalizedHouseholder transformations, providing a tunable mechanism to balanceexpressivity and efficiency and a stable recurrence. Through extensiveexperiments, we demonstrate that DeltaProduct achieves superior state-trackingand language modeling capabilities while exhibiting significantly improvedlength extrapolation compared to DeltaNet. Additionally, we also strengthen thetheoretical foundation of DeltaNet's expressivity by proving that it can solvedihedral group word problems in just two layers.</description><author>Julien Siems, Timur Carstensen, Arber Zela, Frank Hutter, Massimiliano Pontil, Riccardo Grazzi</author><pubDate>Fri, 14 Feb 2025 16:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10297v1</guid></item><item><title>Fenchel-Young Variational Learning</title><link>http://arxiv.org/abs/2502.10295v1</link><description>From a variational perspective, many statistical learning criteria involveseeking a distribution that balances empirical risk and regularization. In thispaper, we broaden this perspective by introducing a new general class ofvariational methods based on Fenchel-Young (FY) losses, treated as divergencesthat generalize (and encompass) the familiar Kullback-Leibler divergence at thecore of classical variational learning. Our proposed formulation -- FYvariational learning -- includes as key ingredients new notions of FY freeenergy, FY evidence, FY evidence lower bound, and FY posterior. We derivealternating minimization and gradient backpropagation algorithms to compute (orlower bound) the FY evidence, which enables learning a wider class of modelsthan previous variational formulations. This leads to generalized FY variantsof classical algorithms, such as an FY expectation-maximization (FYEM)algorithm, and latent-variable models, such as an FY variational autoencoder(FYVAE). Our new methods are shown to be empirically competitive, oftenoutperforming their classical counterparts, and most importantly, to havequalitatively novel features. For example, FYEM has an adaptively sparseE-step, while the FYVAE can support models with sparse observations and sparseposteriors.</description><author>Sophia Sklaviadis, Sweta Agrawal, Antonio Farinhas, Andre Martins, Mario Figueiredo</author><pubDate>Fri, 14 Feb 2025 16:57:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10295v1</guid></item><item><title>QMaxViT-Unet+: A Query-Based MaxViT-Unet with Edge Enhancement for Scribble-Supervised Segmentation of Medical Images</title><link>http://arxiv.org/abs/2502.10294v1</link><description>The deployment of advanced deep learning models for medical imagesegmentation is often constrained by the requirement for extensively annotateddatasets. Weakly-supervised learning, which allows less precise labels, hasbecome a promising solution to this challenge. Building on this approach, wepropose QMaxViT-Unet+, a novel framework for scribble-supervised medical imagesegmentation. This framework is built on the U-Net architecture, with theencoder and decoder replaced by Multi-Axis Vision Transformer (MaxViT) blocks.These blocks enhance the model's ability to learn local and global featuresefficiently. Additionally, our approach integrates a query-based Transformerdecoder to refine features and an edge enhancement module to compensate for thelimited boundary information in the scribble label. We evaluate the proposedQMaxViT-Unet+ on four public datasets focused on cardiac structures, colorectalpolyps, and breast cancer: ACDC, MS-CMRSeg, SUN-SEG, and BUSI. Evaluationmetrics include the Dice similarity coefficient (DSC) and the 95th percentileof Hausdorff distance (HD95). Experimental results show that QMaxViT-Unet+achieves 89.1\% DSC and 1.316mm HD95 on ACDC, 88.4\% DSC and 2.226mm HD95 onMS-CMRSeg, 71.4\% DSC and 4.996mm HD95 on SUN-SEG, and 69.4\% DSC and 50.122mmHD95 on BUSI. These results demonstrate that our method outperforms existingapproaches in terms of accuracy, robustness, and efficiency while remainingcompetitive with fully-supervised learning approaches. This makes it ideal formedical image analysis, where high-quality annotations are often scarce andrequire significant effort and expense. The code is available at:https://github.com/anpc849/QMaxViT-Unet</description><author>Thien B. Nguyen-Tat, Hoang-An Vo, Phuoc-Sang Dang</author><pubDate>Fri, 14 Feb 2025 16:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10294v1</guid></item><item><title>A Regularized Newton Method for Nonconvex Optimization with Global and Local Complexity Guarantees</title><link>http://arxiv.org/abs/2502.04799v2</link><description>We consider the problem of finding an $\epsilon$-stationary point of anonconvex function with a Lipschitz continuous Hessian and propose a quadraticregularized Newton method incorporating a new class of regularizers constructedfrom the current and previous gradients. The method leverages a recentlydeveloped linear conjugate gradient approach with a negative curvature monitorto solve the regularized Newton equation. Notably, our algorithm is adaptive,requiring no prior knowledge of the Lipschitz constant of the Hessian, andachieves a global complexity of $O(\epsilon^{-\frac{3}{2}}) + \tilde O(1)$ interms of the second-order oracle calls, and $\tilde O(\epsilon^{-\frac{7}{4}})$for Hessian-vector products, respectively. Moreover, when the iterates convergeto a point where the Hessian is positive definite, the method exhibitsquadratic local convergence. Preliminary numerical results illustrate thecompetitiveness of our algorithm.</description><author>Yuhao Zhou, Jintao Xu, Chenglong Bao, Chao Ding, Jun Zhu</author><pubDate>Fri, 14 Feb 2025 16:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.04799v2</guid></item><item><title>Small Loss Bounds for Online Learning Separated Function Classes: A Gaussian Process Perspective</title><link>http://arxiv.org/abs/2502.10292v1</link><description>In order to develop practical and efficient algorithms while circumventingoverly pessimistic computational lower bounds, recent work has been interestedin developing oracle-efficient algorithms in a variety of learning settings.Two such settings of particular interest are online and differentially privatelearning. While seemingly different, these two fields are fundamentallyconnected by the requirement that successful algorithms in each case satisfystability guarantees; in particular, recent work has demonstrated thatalgorithms for online learning whose performance adapts to beneficial probleminstances, attaining the so-called small-loss bounds, require a form ofstability similar to that of differential privacy. In this work, we identifythe crucial role that separation plays in allowing oracle-efficient algorithmsto achieve this strong stability. Our notion, which we term $\rho$-separation,generalizes and unifies several previous approaches to enforcing this strongstability, including the existence of small-separator sets and the recentnotion of $\gamma$-approximability. We present an oracle-efficient algorithmthat is capable of achieving small-loss bounds with improved rates in greatergenerality than previous work, as well as a variant for differentially privatelearning that attains optimal rates, again under our separation condition. Inso doing, we prove a new stability result for minimizers of a Gaussian processthat strengthens and generalizes previous work.</description><author>Adam Block, Abhishek Shetty</author><pubDate>Fri, 14 Feb 2025 16:52:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10292v1</guid></item><item><title>Adversarial Mixup Unlearning</title><link>http://arxiv.org/abs/2502.10288v1</link><description>Machine unlearning is a critical area of research aimed at safeguarding dataprivacy by enabling the removal of sensitive information from machine learningmodels. One unique challenge in this field is catastrophic unlearning, whereerasing specific data from a well-trained model unintentionally removesessential knowledge, causing the model to deviate significantly from aretrained one. To address this, we introduce a novel approach that regularizesthe unlearning process by utilizing synthesized mixup samples, which simulatethe data susceptible to catastrophic effects. At the core of our approach is agenerator-unlearner framework, MixUnlearn, where a generator adversariallyproduces challenging mixup examples, and the unlearner effectively forgetstarget information based on these synthesized data. Specifically, we firstintroduce a novel contrastive objective to train the generator in anadversarial direction: generating examples that prompt the unlearner to revealinformation that should be forgotten, while losing essential knowledge. Thenthe unlearner, guided by two other contrastive loss terms, processes thesynthesized and real data jointly to ensure accurate unlearning without losingcritical knowledge, overcoming catastrophic effects. Extensive evaluationsacross benchmark datasets demonstrate that our method significantly outperformsstate-of-the-art approaches, offering a robust solution to machine unlearning.This work not only deepens understanding of unlearning mechanisms but also laysthe foundation for effective machine unlearning with mixup augmentation.</description><author>Zhuoyi Peng, Yixuan Tang, Yi Yang</author><pubDate>Fri, 14 Feb 2025 16:50:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10288v1</guid></item><item><title>Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale</title><link>http://arxiv.org/abs/2409.17115v2</link><description>Large language model pre-training has traditionally relied on human expertsto craft heuristics for improving the corpora quality, resulting in numerousrules developed to date. However, these rules lack the flexibility to addressthe unique characteristics of individual example effectively. Meanwhile,applying tailored rules to every example is impractical for human experts. Inthis paper, we demonstrate that even small language models, with as few as 0.3Bparameters, can exhibit substantial data refining capabilities comparable tothose of human experts. We introduce Programming Every Example (ProX), a novelframework that treats data refinement as a programming task, enabling models torefine corpora by generating and executing fine-grained operations, such asstring normalization, for each individual example at scale. Experimentalresults show that models pre-trained on ProX-curated data outperform eitheroriginal data or data filtered by other selection methods by more than 2%across various downstream benchmarks. Its effectiveness spans various modelsizes and pre-training corpora, including C4, RedPajama-V2, FineWeb,FineWeb-Edu, and DCLM. Furthermore, ProX exhibits significant potential indomain-specific continual pre-training: without domain specific design, modelstrained on OpenWebMath refined by ProX outperform human-crafted rule-basedmethods, improving average accuracy by 7.6% over Mistral-7B, with 14.6% forLlama-2-7B and 20.3% for CodeLlama-7B, all within 10B tokens to be comparableto models like Llemma-7B trained on 200B tokens. Further analysis highlightsthat ProX significantly saves training FLOPs, offering a promising path forefficient LLM pre-training. We are open-sourcing ProX with &gt;500B corpus,models, and sharing all training and implementation details for reproducibleresearch and future innovation. Code: https://github.com/GAIR-NLP/ProX</description><author>Fan Zhou, Zengzhi Wang, Qian Liu, Junlong Li, Pengfei Liu</author><pubDate>Fri, 14 Feb 2025 16:44:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.17115v2</guid></item><item><title>A Hybrid Cross-Stage Coordination Pre-ranking Model for Online Recommendation Systems</title><link>http://arxiv.org/abs/2502.10284v1</link><description>Large-scale recommendation systems often adopt cascading architectureconsisting of retrieval, pre-ranking, ranking, and re-ranking stages. Withstrict latency requirements, pre-ranking utilizes lightweight models to performa preliminary selection from massive retrieved candidates. However, recentworks focus solely on improving consistency with ranking, relying exclusivelyon downstream stages. Since downstream input is derived from the pre-rankingoutput, they will exacerbate the sample selection bias (SSB) issue and Mattheweffect, leading to sub-optimal results. To address the limitation, we propose anovel Hybrid Cross-Stage Coordination Pre-ranking model (HCCP) to integrateinformation from upstream (retrieval) and downstream (ranking, re-ranking)stages. Specifically, cross-stage coordination refers to the pre-ranking'sadaptability to the entire stream and the role of serving as a more effectivebridge between upstream and downstream. HCCP consists of Hybrid SampleConstruction and Hybrid Objective Optimization. Hybrid sample constructioncaptures multi-level unexposed data from the entire stream and rearranges themto become the optimal guiding "ground truth" for pre-ranking learning. Hybridobjective optimization contains the joint optimization of consistency andlong-tail precision through our proposed Margin InfoNCE loss. It isspecifically designed to learn from such hybrid unexposed samples, improvingthe overall performance and mitigating the SSB issue. The appendix describes aproof of the efficacy of the proposed loss in selecting potential positives.Extensive offline and online experiments indicate that HCCP outperforms SOTAmethods by improving cross-stage coordination. It contributes up to 14.9% UCVRand 1.3% UCTR in the JD E-commerce recommendation system. Concerning codeprivacy, we provide a pseudocode for reference.</description><author>Binglei Zhao, Houying Qi, Guang Xu, Mian Ma, Xiwei Zhao, Feng Mei, Sulong Xu, Jinghe Hu</author><pubDate>Fri, 14 Feb 2025 16:42:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10284v1</guid></item><item><title>EnigmaEval: A Benchmark of Long Multimodal Reasoning Challenges</title><link>http://arxiv.org/abs/2502.08859v2</link><description>As language models master existing reasoning benchmarks, we need newchallenges to evaluate their cognitive frontiers. Puzzle-solving events arerich repositories of challenging multimodal problems that test a wide range ofadvanced reasoning and knowledge capabilities, making them a unique testbed forevaluating frontier language models. We introduce EnigmaEval, a dataset ofproblems and solutions derived from puzzle competitions and events that probesmodels' ability to perform implicit knowledge synthesis and multi-stepdeductive reasoning. Unlike existing reasoning and knowledge benchmarks, puzzlesolving challenges models to discover hidden connections between seeminglyunrelated pieces of information to uncover solution paths. The benchmarkcomprises 1184 puzzles of varying complexity -- each typically requiring teamsof skilled solvers hours to days to complete -- with unambiguous, verifiablesolutions that enable efficient evaluation. State-of-the-art language modelsachieve extremely low accuracy on these puzzles, even lower than otherdifficult benchmarks such as Humanity's Last Exam, unveiling models'shortcomings when challenged with problems requiring unstructured and lateralreasoning.</description><author>Clinton J. Wang, Dean Lee, Cristina Menghini, Johannes Mols, Jack Doughty, Adam Khoja, Jayson Lynch, Sean Hendryx, Summer Yue, Dan Hendrycks</author><pubDate>Fri, 14 Feb 2025 16:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08859v2</guid></item><item><title>Probabilistic Super-Resolution for High-Fidelity Physical System Simulations with Uncertainty Quantification</title><link>http://arxiv.org/abs/2502.10280v1</link><description>Super-resolution (SR) is a promising tool for generating high-fidelitysimulations of physical systems from low-resolution data, enabling fast andaccurate predictions in engineering applications. However, existingdeep-learning based SR methods, require large labeled datasets and lackreliable uncertainty quantification (UQ), limiting their applicability inreal-world scenarios. To overcome these challenges, we propose a probabilisticSR framework that leverages the Statistical Finite Element Method andenergy-based generative modeling. Our method enables efficient high-resolutionpredictions with inherent UQ, while eliminating the need for extensive labeleddatasets. The method is validated on a 2D Poisson example and compared withbicubic interpolation upscaling. Results demonstrate a computational speed-upover high-resolution numerical solvers while providing reliable uncertaintyestimates.</description><author>Pengyu Zhang, Connor Duffin, Alex Glyn-Davies, Arnaud Vadeboncoeur, Mark Girolami</author><pubDate>Fri, 14 Feb 2025 16:37:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10280v1</guid></item><item><title>Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey</title><link>http://arxiv.org/abs/2409.01980v3</link><description>Detecting anomalies or out-of-distribution (OOD) samples is critical formaintaining the reliability and trustworthiness of machine learning systems.Recently, Large Language Models (LLMs) have demonstrated their effectivenessnot only in natural language processing but also in broader applications due totheir advanced comprehension and generative capabilities. The integration ofLLMs into anomaly and OOD detection marks a significant shift from thetraditional paradigm in the field. This survey focuses on the problem ofanomaly and OOD detection under the context of LLMs. We propose a new taxonomyto categorize existing approaches into two classes based on the role played byLLMs. Following our proposed taxonomy, we further discuss the related workunder each of the categories and finally discuss potential challenges anddirections for future research in this field. We also provide an up-to-datereading list of relevant papers.</description><author>Ruiyao Xu, Kaize Ding</author><pubDate>Fri, 14 Feb 2025 16:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01980v3</guid></item><item><title>Artificial Intelligence to Assess Dental Findings from Panoramic Radiographs -- A Multinational Study</title><link>http://arxiv.org/abs/2502.10277v1</link><description>Dental panoramic radiographs (DPRs) are widely used in clinical practice forcomprehensive oral assessment but present challenges due to overlappingstructures and time constraints in interpretation. This study aimed to establish a solid baseline for the AI-automatedassessment of findings in DPRs by developing, evaluating an AI system, andcomparing its performance with that of human readers across multinational datasets. We analyzed 6,669 DPRs from three data sets (the Netherlands, Brazil, andTaiwan), focusing on 8 types of dental findings. The AI system combined objectdetection and semantic segmentation techniques for per-tooth findingidentification. Performance metrics included sensitivity, specificity, and areaunder the receiver operating characteristic curve (AUC-ROC). AIgeneralizability was tested across data sets, and performance was compared withhuman dental practitioners. The AI system demonstrated comparable or superior performance to humanreaders, particularly +67.9% (95% CI: 54.0%-81.9%; p &lt; .001) sensitivity foridentifying periapical radiolucencies and +4.7% (95% CI: 1.4%-8.0%; p = .008)sensitivity for identifying missing teeth. The AI achieved a macro-averagedAUC-ROC of 96.2% (95% CI: 94.6%-97.8%) across 8 findings. AI agreements withthe reference were comparable to inter-human agreements in 7 of 8 findingsexcept for caries (p = .024). The AI system demonstrated robust generalizationacross diverse imaging and demographic settings and processed images 79 timesfaster (95% CI: 75-82) than human readers. The AI system effectively assessed findings in DPRs, achieving performance onpar with or better than human experts while significantly reducinginterpretation time. These results highlight the potential for integrating AIinto clinical workflows to improve diagnostic efficiency and accuracy, andpatient management.</description><author>Yin-Chih Chelsea Wang, Tsao-Lun Chen, Shankeeth Vinayahalingam, Tai-Hsien Wu, Chu Wei Chang, Hsuan Hao Chang, Hung-Jen Wei, Mu-Hsiung Chen, Ching-Chang Ko, David Anssari Moin, Bram van Ginneken, Tong Xi, Hsiao-Cheng Tsai, Min-Huey Chen, Tzu-Ming Harry Hsu, Hye Chou</author><pubDate>Fri, 14 Feb 2025 16:34:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10277v1</guid></item><item><title>A Latent Causal Inference Framework for Ordinal Variables</title><link>http://arxiv.org/abs/2502.10276v1</link><description>Ordinal variables, such as on the Likert scale, are common in appliedresearch. Yet, existing methods for causal inference tend to target nominal orcontinuous data. When applied to ordinal data, this fails to account for theinherent ordering or imposes well-defined relative magnitudes. Hence, there isa need for specialised methods to compute interventional effects betweenordinal variables while accounting for their ordinality. One potentialframework is to presume a latent Gaussian Directed Acyclic Graph (DAG) model:that the ordinal variables originate from marginally discretizing a set ofGaussian variables whose latent covariance matrix is constrained to satisfy theconditional independencies inherent in a DAG. Conditioned on a given latentcovariance matrix and discretisation thresholds, we derive a closed-formfunction for ordinal causal effects in terms of interventional distributions inthe latent space. Our causal estimation combines naturally with algorithms tolearn the latent DAG and its parameters, like the Ordinal Structural EMalgorithm. Simulations demonstrate the applicability of the proposed approachin estimating ordinal causal effects both for known and unknown structures ofthe latent graph. As an illustration of a real-world use case, the method isapplied to survey data of 408 patients from a study on the functionalrelationships between symptoms of obsessive-compulsive disorder and depression.</description><author>Martina Scauda, Jack Kuipers, Giusi Moffa</author><pubDate>Fri, 14 Feb 2025 16:33:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10276v1</guid></item><item><title>SequentialBreak: Large Language Models Can be Fooled by Embedding Jailbreak Prompts into Sequential Prompt Chains</title><link>http://arxiv.org/abs/2411.06426v2</link><description>As the integration of the Large Language Models (LLMs) into variousapplications increases, so does their susceptibility to misuse, raisingsignificant security concerns. Numerous jailbreak attacks have been proposed toassess the security defense of LLMs. Current jailbreak attacks mainly rely onscenario camouflage, prompt obfuscation, prompt optimization, and promptiterative optimization to conceal malicious prompts. In particular, sequentialprompt chains in a single query can lead LLMs to focus on certain prompts whileignoring others, facilitating context manipulation. This paper introducesSequentialBreak, a novel jailbreak attack that exploits this vulnerability. Wediscuss several scenarios, not limited to examples like Question Bank, DialogCompletion, and Game Environment, where the harmful prompt is embedded withinbenign ones that can fool LLMs into generating harmful responses. The distinctnarrative structures of these scenarios show that SequentialBreak is flexibleenough to adapt to various prompt formats beyond those discussed. Extensiveexperiments demonstrate that SequentialBreak uses only a single query toachieve a substantial gain of attack success rate over existing baselinesagainst both open-source and closed-source models. Through our research, wehighlight the urgent need for more robust and resilient safeguards to enhanceLLM security and prevent potential misuse. All the result files and websiteassociated with this research are available in this GitHub repository:https://anonymous.4open.science/r/JailBreakAttack-4F3B/.</description><author>Bijoy Ahmed Saiem, MD Sadik Hossain Shanto, Rakib Ahsan, Md Rafi ur Rashid</author><pubDate>Fri, 14 Feb 2025 16:32:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.06426v2</guid></item><item><title>Probing Perceptual Constancy in Large Vision Language Models</title><link>http://arxiv.org/abs/2502.10273v1</link><description>Perceptual constancy is the ability to maintain stable perceptions of objectsdespite changes in sensory input, such as variations in distance, angle, orlighting. This ability is crucial for recognizing visual information in adynamic world, making it essential for Vision-Language Models (VLMs). However,whether VLMs are currently and theoretically capable of mastering this abilityremains underexplored. In this study, we evaluated 33 VLMs using 253experiments across three domains: color, size, and shape constancy. Theexperiments included single-image and video adaptations of classic cognitivetasks, along with novel tasks in in-the-wild conditions, to evaluate themodels' recognition of object properties under varying conditions. We foundsignificant variability in VLM performance, with models performance in shapeconstancy clearly dissociated from that of color and size constancy.</description><author>Haoran Sun, Suyang Yu, Yijiang Li, Qingying Gao, Haiyun Lyu, Hokin Deng, Dezhi Luo</author><pubDate>Fri, 14 Feb 2025 16:31:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10273v1</guid></item><item><title>Empirical Bayes Estimation with Side Information: A Nonparametric Integrative Tweedie Approach</title><link>http://arxiv.org/abs/2308.05883v2</link><description>We investigate the problem of compound estimation of normal means whileaccounting for the presence of side information. Leveraging the empirical Bayesframework, we develop a nonparametric integrative Tweedie (NIT) approach thatincorporates structural knowledge encoded in multivariate auxiliary data toenhance the precision of compound estimation. Our approach employs convexoptimization tools to estimate the gradient of the log-density directly,enabling the incorporation of structural constraints. We conduct theoreticalanalyses of the asymptotic risk of NIT and establish the rate at which NITconverges to the oracle estimator. As the dimension of the auxiliary dataincreases, we accurately quantify the improvements in estimation risk and theassociated deterioration in convergence rate. The numerical performance of NITis illustrated through the analysis of both simulated and real data,demonstrating its superiority over existing methods.</description><author>Jiajun Luo, Trambak Banerjee, Gourab Mukherjee, Wenguang Sun</author><pubDate>Fri, 14 Feb 2025 16:29:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05883v2</guid></item><item><title>MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling</title><link>http://arxiv.org/abs/2410.13610v2</link><description>Integrating tools into Large Language Models (LLMs) has facilitated thewidespread application. Despite this, in specialized downstream task contexts,reliance solely on tools is insufficient to fully address the complexities ofthe real world. This particularly restricts the effective deployment of LLMs infields such as medicine. In this paper, we focus on the downstream tasks ofmedical calculators, which use standardized tests to assess an individual'shealth status. We introduce MeNTi, a universal agent architecture for LLMs.MeNTi integrates a specialized medical toolkit and employs meta-tool and nestedcalling mechanisms to enhance LLM tool utilization. Specifically, it achievesflexible tool selection and nested tool calling to address practical issuesfaced in intricate medical scenarios, including calculator selection, slotfilling, and unit conversion. To assess the capabilities of LLMs forquantitative assessment throughout the clinical process of calculatorscenarios, we introduce CalcQA. This benchmark requires LLMs to use medicalcalculators to perform calculations and assess patient health status. CalcQA isconstructed by professional physicians and includes 100 case-calculator pairs,complemented by a toolkit of 281 medical tools. The experimental resultsdemonstrate significant performance improvements with our framework. Thisresearch paves new directions for applying LLMs in demanding scenarios ofmedicine.</description><author>Yakun Zhu, Shaohang Wei, Xu Wang, Kui Xue, Xiaofan Zhang, Shaoting Zhang</author><pubDate>Fri, 14 Feb 2025 16:27:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13610v2</guid></item><item><title>Are Large Language Models the future crowd workers of Linguistics?</title><link>http://arxiv.org/abs/2502.10266v1</link><description>Data elicitation from human participants is one of the core data collectionstrategies used in empirical linguistic research. The amount of participants insuch studies may vary considerably, ranging from a handful to crowdsourcingdimensions. Even if they provide resourceful extensive data, both of thesesettings come alongside many disadvantages, such as low control ofparticipants' attention during task completion, precarious working conditionsin crowdsourcing environments, and time-consuming experimental designs. Forthese reasons, this research aims to answer the question of whether LargeLanguage Models (LLMs) may overcome those obstacles if included in empiricallinguistic pipelines. Two reproduction case studies are conducted to gainclarity into this matter: Cruz (2023) and Lombard et al. (2021). The two forcedelicitation tasks, originally designed for human participants, are reproducedin the proposed framework with the help of OpenAI's GPT-4o-mini model. Itsperformance with our zero-shot prompting baseline shows the effectiveness andhigh versatility of LLMs, that tend to outperform human informants inlinguistic tasks. The findings of the second replication further highlight theneed to explore additional prompting techniques, such as Chain-of-Thought (CoT)prompting, which, in a second follow-up experiment, demonstrates higheralignment to human performance on both critical and filler items. Given thelimited scale of this study, it is worthwhile to further explore theperformance of LLMs in empirical Linguistics and in other future applicationsin the humanities.</description><author>Iris Ferrazzo</author><pubDate>Fri, 14 Feb 2025 16:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10266v1</guid></item><item><title>Large Language Models and Synthetic Data for Monitoring Dataset Mentions in Research Papers</title><link>http://arxiv.org/abs/2502.10263v1</link><description>Tracking how data is mentioned and used in research papers provides criticalinsights for improving data discoverability, quality, and production. However,manually identifying and classifying dataset mentions across vast academicliterature is resource-intensive and not scalable. This paper presents amachine learning framework that automates dataset mention detection acrossresearch domains by leveraging large language models (LLMs), synthetic data,and a two-stage fine-tuning process. We employ zero-shot extraction fromresearch papers, an LLM-as-a-Judge for quality assessment, and a reasoningagent for refinement to generate a weakly supervised synthetic dataset. ThePhi-3.5-mini instruct model is pre-fine-tuned on this dataset, followed byfine-tuning on a manually annotated subset. At inference, a ModernBERT-basedclassifier efficiently filters dataset mentions, reducing computationaloverhead while maintaining high recall. Evaluated on a held-out manuallyannotated sample, our fine-tuned model outperforms NuExtract-v1.5 andGLiNER-large-v2.1 in dataset extraction accuracy. Our results highlight howLLM-generated synthetic data can effectively address training data scarcity,improving generalization in low-resource settings. This framework offers apathway toward scalable monitoring of dataset usage, enhancing transparency,and supporting researchers, funders, and policymakers in identifying data gapsand strengthening data accessibility for informed decision-making.</description><author>Aivin V. Solatorio, Rafael Macalaba, James Liounis</author><pubDate>Fri, 14 Feb 2025 16:16:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10263v1</guid></item><item><title>MITO: Enabling Non-Line-of-Sight Perception using Millimeter-waves through Real-World Datasets and Simulation Tools</title><link>http://arxiv.org/abs/2502.10259v1</link><description>We present MITO, the first dataset of multi-spectral millimeter-wave (mmWave)images of everyday objects. Unlike visible light, mmWave signals can imagethrough everyday occlusions (e.g., cardboard boxes, fabric, plastic). However,due to the dearth of publicly-available mmWave images and the interdisciplinarychallenges in collecting and processing mmWave signals, it remains difficulttoday for computer vision researchers to develop mmWave-based non-line-of-sightperception algorithms and models. To overcome these challenges, we introduce a real-world dataset andopen-source simulation tool for mmWave imaging. The dataset is acquired using aUR5 robotic arm with two mmWave radars operating at different frequencies andan RGB-D camera. Through a signal processing pipeline, we capture and createover 580 real-world 3D mmWave images from over 76 different objects in the YCBdataset, a standard dataset for robotics manipulation. We provide real-worldmmWave images in line-of-sight and non-line-of-sight, as well as RGB-D imagesand ground truth segmentation masks. We also develop an open-source simulationtool that can be used to generate synthetic mmWave images for any 3D trianglemesh, which achieves a median F-Score of 94% when compared to real-world mmWaveimages. We show the usefulness of this dataset and simulation tool in multiple CVtasks in non-line-of-sight. First, we perform object segmentation for mmWaveimages using the segment anything model (SAM), and achieve a median precisionand recall of 92.6% and 64%. Second, we train a classifier that can recognizeobjects in non-line-of-sight. It is trained on synthetic images and canclassify real-world images with 85% accuracy. We believe MITO will be a valuable resource for computer vision researchersin developing non-line-of-sight perception, similar to how early camera-baseddatasets shaped the field.</description><author>Laura Dodds, Tara Boroushaki, Fadel Adib</author><pubDate>Fri, 14 Feb 2025 16:12:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10259v1</guid></item><item><title>PromptArtisan: Multi-instruction Image Editing in Single Pass with Complete Attention Control</title><link>http://arxiv.org/abs/2502.10258v1</link><description>We present PromptArtisan, a groundbreaking approach to multi-instructionimage editing that achieves remarkable results in a single pass, eliminatingthe need for time-consuming iterative refinement. Our method empowers users toprovide multiple editing instructions, each associated with a specific maskwithin the image. This flexibility allows for complex edits involving maskintersections or overlaps, enabling the realization of intricate and nuancedimage transformations. PromptArtisan leverages a pre-trained InstructPix2Pixmodel in conjunction with a novel Complete Attention Control Mechanism (CACM).This mechanism ensures precise adherence to user instructions, grantingfine-grained control over the editing process. Furthermore, our approach iszero-shot, requiring no additional training, and boasts improved processingcomplexity compared to traditional iterative methods. By seamlessly integratingmulti-instruction capabilities, single-pass efficiency, and complete attentioncontrol, PromptArtisan unlocks new possibilities for creative and efficientimage editing workflows, catering to both novice and expert users alike.</description><author>Kunal Swami, Raghu Chittersu, Pranav Adlinge, Rajeev Irny, Shashavali Doodekula, Alok Shukla</author><pubDate>Fri, 14 Feb 2025 16:11:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10258v1</guid></item><item><title>Strada-LLM: Graph LLM for traffic prediction</title><link>http://arxiv.org/abs/2410.20856v2</link><description>Traffic prediction is a vital component of intelligent transportationsystems. By reasoning about traffic patterns in both the spatial and temporaldimensions, accurate and interpretable predictions can be provided. Aconsiderable challenge in traffic prediction lies in handling the diverse datadistributions caused by vastly different traffic conditions occurring atdifferent locations. LLMs have been a dominant solution due to their remarkablecapacity to adapt to new datasets with very few labeled data samples, i.e.,few-shot adaptability. However, existing forecasting techniques mainly focus onextracting local graph information and forming a text-like prompt, leaving LLM-based traffic prediction an open problem. This work presents a probabilisticLLM for traffic forecasting with three highlights. We propose a graph-aware LLMfor traffic prediction that considers proximal traffic information.Specifically, by considering the traffic of neighboring nodes as covariates,our model outperforms the corresponding time-series LLM. Furthermore, we adopta lightweight approach for efficient domain adaptation when facing new datadistributions in few-shot fashion. The comparative experiment demonstrates theproposed method outperforms the state-of-the-art LLM-based methods and thetraditional GNN- based supervised approaches. Furthermore, Strada-LLM can beeasily adapted to different LLM backbones without a noticeable performancedrop.</description><author>Seyed Mohamad Moghadas, Yangxintong Lyu, Bruno Cornelis, Alexandre Alahi, Adrian Munteanu</author><pubDate>Fri, 14 Feb 2025 16:09:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20856v2</guid></item><item><title>VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models</title><link>http://arxiv.org/abs/2502.10250v1</link><description>Vision-language models (VLMs) excel in various visual benchmarks but areoften constrained by the lack of high-quality visual fine-tuning data. Toaddress this challenge, we introduce VisCon-100K, a novel dataset derived frominterleaved image-text web documents. Our approach transforms 45K web documentsfrom the OBELICS dataset into 100K image conversation samples. We utilizeGPT-4V to generate image-contextual captions and OpenChat 3.5 model to convertthese captions into diverse free-form and multiple-choice question-answerpairs. Integrating this dataset for fine-tuning considerably enhances VLMperformance across multiple benchmarks. Unlike methods that focus solely onfine-grained visual content, our approach leverages accompanying web context,yielding superior results. We also discover that a `leaky modality mix,' whereconversation samples contain questions answerable from both the image and itscontextual caption, outperforms non-leaky combinations of captions and Q\&amp;Apairs. VisCon-100k dataset shows strong performance with two popular VLMapproaches: text-only large language model (LLM) aligned with a vision encoderusing image captions data (ShareGPT4V-7b) and multimodally pretrained LLM(IDEFICS2-8b) using interleaved image-text data. In addition to releasing theVisCon-100K dataset, we provide a contextual captioner trained on this dataset,facilitating scalable fine-tuning data generation for future research andopen-source applications. Using the same pipeline, but substituting our trainedcontextual captioner for GPT-4V, we also release the larger VisCon-1M dataset.</description><author>Gokul Karthik Kumar, Iheb Chaabane, Kebin Wu</author><pubDate>Fri, 14 Feb 2025 15:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10250v1</guid></item><item><title>Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection</title><link>http://arxiv.org/abs/2409.04796v2</link><description>Out-of-Distribution (OOD) detection, aiming to distinguish outliers fromknown categories, has gained prominence in practical scenarios. Recently, theadvent of vision-language models (VLM) has heightened interest in enhancing OODdetection for VLM through few-shot tuning. However, existing methods mainlyfocus on optimizing global prompts, ignoring refined utilization of localinformation with regard to outliers. Motivated by this, we freeze globalprompts and introduce Local-Prompt, a novel coarse-to-fine tuning paradigm toemphasize regional enhancement with local prompts. Our method comprises twointegral components: global prompt guided negative augmentation and localprompt enhanced regional regularization. The former utilizes frozen, coarseglobal prompts as guiding cues to incorporate negative augmentation, therebyleveraging local outlier knowledge. The latter employs trainable local promptsand a regional regularization to capture local information effectively, aidingin outlier identification. We also propose regional-related metric to empowerthe enrichment of OOD detection. Moreover, since our approach exploresenhancing local prompts only, it can be seamlessly integrated with trainedglobal prompts during inference to boost the performance. Comprehensiveexperiments demonstrate the effectiveness and potential of our method. Notably,our method reduces average FPR95 by 5.17% against state-of-the-art method in4-shot tuning on challenging ImageNet-1k dataset, even outperforming 16-shotresults of previous methods. Code is released athttps://github.com/AuroraZengfh/Local-Prompt.</description><author>Fanhu Zeng, Zhen Cheng, Fei Zhu, Hongxin Wei, Xu-Yao Zhang</author><pubDate>Fri, 14 Feb 2025 15:58:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.04796v2</guid></item><item><title>Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</title><link>http://arxiv.org/abs/2502.10248v1</link><description>We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained modelwith 30B parameters and the ability to generate videos up to 204 frames inlength. A deep compression Variational Autoencoder, Video-VAE, is designed forvideo generation tasks, achieving 16x16 spatial and 8x temporal compressionratios, while maintaining exceptional video reconstruction quality. Userprompts are encoded using two bilingual text encoders to handle both Englishand Chinese. A DiT with 3D full attention is trained using Flow Matching and isemployed to denoise input noise into latent frames. A video-based DPO approach,Video-DPO, is applied to reduce artifacts and improve the visual quality of thegenerated videos. We also detail our training strategies and share keyobservations and insights. Step-Video-T2V's performance is evaluated on a novelvideo generation benchmark, Step-Video-T2V-Eval, demonstrating itsstate-of-the-art text-to-video quality when compared with both open-source andcommercial engines. Additionally, we discuss the limitations of currentdiffusion-based model paradigm and outline future directions for videofoundation models. We make both Step-Video-T2V and Step-Video-T2V-Evalavailable at https://github.com/stepfun-ai/Step-Video-T2V. The online versioncan be accessed from https://yuewen.cn/videos as well. Our goal is toaccelerate the innovation of video foundation models and empower video contentcreators.</description><author>Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan, Shengming Yin, Changyi Wan, Ranchen Ming, Xiaoniu Song, Xing Chen, Yu Zhou, Deshan Sun, Deyu Zhou, Jian Zhou, Kaijun Tan, Kang An, Mei Chen, Wei Ji, Qiling Wu, Wen Sun, Xin Han, Yanan Wei, Zheng Ge, Aojie Li, Bin Wang, Bizhu Huang, Bo Wang, Brian Li, Changxing Miao, Chen Xu, Chenfei Wu, Chenguang Yu, Dapeng Shi, Dingyuan Hu, Enle Liu, Gang Yu, Ge Yang, Guanzhe Huang, Gulin Yan, Haiyang Feng, Hao Nie, Haonan Jia, Hanpeng Hu, Hanqi Chen, Haolong Yan, Heng Wang, Hongcheng Guo, Huilin Xiong, Huixin Xiong, Jiahao Gong, Jianchang Wu, Jiaoren Wu, Jie Wu, Jie Yang, Jiashuai Liu, Jiashuo Li, Jingyang Zhang, Junjing Guo, Junzhe Lin, Kaixiang Li, Lei Liu, Lei Xia, Liang Zhao, Liguo Tan, Liwen Huang, Liying Shi, Ming Li, Mingliang Li, Muhua C</author><pubDate>Fri, 14 Feb 2025 15:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10248v1</guid></item><item><title>Efficient Zero-Order Federated Finetuning of Language Models for Resource-Constrained Devices</title><link>http://arxiv.org/abs/2502.10239v1</link><description>Federated fine-tuning offers a promising approach for tuning Large LanguageModels (LLMs) on edge devices while preserving data privacy. However,fine-tuning these models on edge devices remains challenging due to highmemory, communication, and computational demands. Zero-order optimization withtask alignment provides a potential solution, enabling fine-tuning withinference-level memory requirements but requires a longer convergence time. Inthis paper, we propose Federated Split-Perturbation Zero-order Optimization(FedSPZO) that divides the network into two blocks, applying a different numberof perturbations per block in a computationally effective way, achieving fasterconvergence. Our evaluation shows a $2.5 - 7\times $ reduction in computationoverhead compared to zero-order state of the art techniques in federatedlearning.</description><author>Mohamed Aboelenien Ahmed, Kilian Pfeiffer, Ramin Khalili, Heba Khdr, Jörg Henkel</author><pubDate>Fri, 14 Feb 2025 15:49:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10239v1</guid></item><item><title>A Critical Look At Tokenwise Reward-Guided Text Generation</title><link>http://arxiv.org/abs/2406.07780v2</link><description>Large language models (LLMs) can be improved by aligning with humanpreferences through fine-tuning -- the so-called reinforcement learning fromhuman feedback (RLHF). However, the cost of fine-tuning an LLM is prohibitivefor many users. Due to their ability to bypass LLM fine-tuning, prediction-timetokenwise reward-guided text generation (RGTG) methods have recently beenproposed. They use a reward model trained on full sequences to score partialsequences during decoding in a bid to steer the generation towards sequenceswith high rewards. However, these methods have so far been only heuristicallymotivated and poorly analyzed. In this work, we show that reward models trainedon full sequences are not compatible with scoring partial sequences. Toalleviate this issue, we propose to train a Bradley-Terry reward model onpartial sequences explicitly, and autoregressively sample from the impliedtokenwise policy during decoding time. We study the properties of this rewardmodel and the resulting policy: we show that this policy is proportional to theratio of two distinct RLHF policies. Our simple approach outperforms previousRGTG methods and performs similarly to strong offline baselines withoutlarge-scale LLM finetuning.</description><author>Ahmad Rashid, Ruotian Wu, Julia Grosse, Agustinus Kristiadi, Pascal Poupart</author><pubDate>Fri, 14 Feb 2025 15:46:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07780v2</guid></item><item><title>Shaping Inductive Bias in Diffusion Models through Frequency-Based Noise Control</title><link>http://arxiv.org/abs/2502.10236v1</link><description>Diffusion Probabilistic Models (DPMs) are powerful generative models thathave achieved unparalleled success in a number of generative tasks. In thiswork, we aim to build inductive biases into the training and sampling ofdiffusion models to better accommodate the target distribution of the data tomodel. For topologically structured data, we devise a frequency-based noisingoperator to purposefully manipulate, and set, these inductive biases. We firstshow that appropriate manipulations of the noising forward process can leadDPMs to focus on particular aspects of the distribution to learn. We show thatdifferent datasets necessitate different inductive biases, and that appropriatefrequency-based noise control induces increased generative performance comparedto standard diffusion. Finally, we demonstrate the possibility of ignoringinformation at particular frequencies while learning. We show this in an imagecorruption and recovery task, where we train a DPM to recover the originaltarget distribution after severe noise corruption.</description><author>Thomas Jiralerspong, Berton Earnshaw, Jason Hartford, Yoshua Bengio, Luca Scimeca</author><pubDate>Fri, 14 Feb 2025 15:46:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10236v1</guid></item><item><title>AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting</title><link>http://arxiv.org/abs/2502.10235v1</link><description>Pre-trained foundation models (FMs) have shown exceptional performance inunivariate time series forecasting tasks. However, several practical challengespersist, including managing intricate dependencies among features andquantifying uncertainty in predictions. This study aims to tackle thesecritical limitations by introducing adapters; feature-space transformationsthat facilitate the effective use of pre-trained univariate time series FMs formultivariate tasks. Adapters operate by projecting multivariate inputs into asuitable latent space and applying the FM independently to each dimension.Inspired by the literature on representation learning and partially stochasticBayesian neural networks, we present a range of adapters andoptimization/inference strategies. Experiments conducted on both synthetic andreal-world datasets confirm the efficacy of adapters, demonstrating substantialenhancements in forecasting accuracy and uncertainty quantification compared tobaseline methods. Our framework, AdaPTS, positions adapters as a modular,scalable, and effective solution for leveraging time series FMs in multivariatecontexts, thereby promoting their wider adoption in real-world applications. Werelease the code at https://github.com/abenechehab/AdaPTS.</description><author>Abdelhakim Benechehab, Vasilii Feofanov, Giuseppe Paolo, Albert Thomas, Maurizio Filippone, Balázs Kégl</author><pubDate>Fri, 14 Feb 2025 15:46:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10235v1</guid></item><item><title>Spatial-aware decision-making with ring attractors in reinforcement learning systems</title><link>http://arxiv.org/abs/2410.03119v2</link><description>This paper explores the integration of ring attractors, a mathematical modelinspired by neural circuit dynamics, into the Reinforcement Learning (RL)action selection process. Serving as specialized brain-inspired structures thatencode spatial information and uncertainty, ring attractors offer abiologically plausible mechanism to improve learning speed and accuracy in RL.They do so by explicitly encoding the action space, facilitating theorganization of neural activity, and enabling the distribution of spatialrepresentations across the neural network in the context of Deep ReinforcementLearning (DRL). For example, preserving the continuity between rotation anglesin robotic control or adjacency between tactical moves in game-likeenvironments. The application of ring attractors in the action selectionprocess involves mapping actions to specific locations on the ring and decodingthe selected action based on neural activity. We investigate the application ofring attractors by both building an exogenous model and integrating them aspart of DRL agents. Our approach significantly improves state-of-the-artperformance on the Atari 100k benchmark, achieving a 53\% increase inperformance across selected state-of-the-art baselines. Codebase available athttps://anonymous.4open.science/r/RA_RL-8026.</description><author>Marcos Negre Saura, Richard Allmendinger, Wei Pan, Theodore Papamarkou</author><pubDate>Fri, 14 Feb 2025 15:42:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03119v2</guid></item><item><title>Learning to Solve the Min-Max Mixed-Shelves Picker-Routing Problem via Hierarchical and Parallel Decoding</title><link>http://arxiv.org/abs/2502.10233v1</link><description>The Mixed-Shelves Picker Routing Problem (MSPRP) is a fundamental challengein warehouse logistics, where pickers must navigate a mixed-shelves environmentto retrieve SKUs efficiently. Traditional heuristics and optimization-basedapproaches struggle with scalability, while recent machine learning methodsoften rely on sequential decision-making, leading to high solution latency andsuboptimal agent coordination. In this work, we propose a novel hierarchicaland parallel decoding approach for solving the min-max variant of the MSPRP viamulti-agent reinforcement learning. While our approach generates a jointdistribution over agent actions, allowing for fast decoding and effectivepicker coordination, our method introduces a sequential action selection toavoid conflicts in the multi-dimensional action space. Experiments showstate-of-the-art performance in both solution quality and inference speed,particularly for large-scale and out-of-distribution instances. Our code ispublicly available at http://github.com/LTluttmann/marl4msprp.</description><author>Laurin Luttmann, Lin Xie</author><pubDate>Fri, 14 Feb 2025 15:42:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10233v1</guid></item><item><title>Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation</title><link>http://arxiv.org/abs/2412.14050v3</link><description>Recent generative large language models (LLMs) show remarkable performance innon-English languages, but when prompted in those languages they tend toexpress higher harmful social biases and toxicity levels. Prior work has shownthat finetuning on specialized datasets can mitigate this behavior, and doingso in English can transfer to other languages. In this work, we investigate theimpact of different finetuning methods on the model's bias and toxicity, butalso on its ability to produce fluent and diverse text. We reduce biases byfinetuning on curated non-harmful text, but find only direct preferenceoptimization to be effective for mitigating toxicity. The mitigation caused byapplying these methods in English also transfers to non-English languages. Wefind evidence that the extent to which transfer takes place can be predicted bythe amount of data in a given language present in the model's pretraining data.However, this transfer of bias and toxicity mitigation often comes at theexpense of decreased language generation ability in non-English languages,highlighting the importance of developing language-specific bias and toxicitymitigation methods.</description><author>Vera Neplenbroek, Arianna Bisazza, Raquel Fernández</author><pubDate>Fri, 14 Feb 2025 15:39:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14050v3</guid></item><item><title>SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption</title><link>http://arxiv.org/abs/2307.00677v5</link><description>Density-based clustering is the most popular clustering algorithm since itcan identify clusters of arbitrary shape as long as they are separated bylow-density regions. However, a high-density region that is not separated bylow-density ones might also have different structures belonging to multipleclusters. As far as we know, all previous density-based clustering algorithmsfail to detect such structures. In this paper, we provide a novel density-basedclustering scheme to address this problem. It is the rst clustering algorithmthat can detect meticulous structures in a high-density region that is notseparated by low-density ones and thus extends the range of applications ofclustering. The algorithm employs secondary directed differential, hierarchy,normalized density, as well as the self-adaption coefficient, called StructureDetecting Cluster by Hierarchical Secondary Directed Differential withNormalized Density and Self-Adaption, dubbed SDC-HSDD-NDSA. Experiments onsynthetic and real datasets are implemented to verify the effectiveness,robustness, and granularity independence of the algorithm, and the scheme iscompared to unsupervised schemes in the Python package Scikit-learn. Resultsdemonstrate that our algorithm outperforms previous ones in many situations,especially significantly when clusters have regular internal structures. Forexample, averaging over the eight noiseless synthetic datasets with structuresemploying ARI and NMI criteria, previous algorithms obtain scores below 0.6 and0.7, while the presented algorithm obtains scores higher than 0.9 and 0.95,respectively.</description><author>Hao Shu</author><pubDate>Fri, 14 Feb 2025 15:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00677v5</guid></item><item><title>ProReco: A Process Discovery Recommender System</title><link>http://arxiv.org/abs/2502.10230v1</link><description>Process discovery aims to automatically derive process models from historicalexecution data (event logs). While various process discovery algorithms havebeen proposed in the last 25 years, there is no consensus on a dominatingdiscovery algorithm. Selecting the most suitable discovery algorithm remains achallenge due to competing quality measures and diverse user requirements.Manually selecting the most suitable process discovery algorithm from a rangeof options for a given event log is a time-consuming and error-prone task. Thispaper introduces ProReco, a Process discovery Recommender system designed torecommend the most appropriate algorithm based on user preferences and eventlog characteristics. ProReco incorporates state-of-the-art discoveryalgorithms, extends the feature pools from previous work, and utilizeseXplainable AI (XAI) techniques to provide explanations for itsrecommendations.</description><author>Tsung-Hao Huang, Tarek Junied, Marco Pegoraro, Wil M. P. van der Aalst</author><pubDate>Fri, 14 Feb 2025 15:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10230v1</guid></item><item><title>Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification</title><link>http://arxiv.org/abs/2501.02844v3</link><description>Text classification is a fundamental task in data mining, pivotal to variousapplications such as tabular understanding and recommendation. Although neuralnetwork-based models, such as CNN and BERT, have demonstrated remarkableperformance in text classification, their effectiveness heavily relies onabundant labeled training data. This dependency makes these models lesseffective in dynamic few-shot text classification, where labeled data isscarce, and new target labels frequently appear based on application needs.Recently, large language models (LLMs) have shown promise due to theirextensive pretraining and contextual understanding ability. Current approachesprovide LLMs with text inputs, candidate labels, and additional sideinformation (e.g., descriptions) to classify texts. However, theireffectiveness is hindered by the increased input size and the noise introducedthrough side information processing. To address these limitations, we propose agraph-based online retrieval-augmented generation framework, namely GORAG, fordynamic few-shot text classification. Rather than treating each inputindependently, GORAG constructs and maintains a weighted graph by extractingside information across all target texts. In this graph, text keywords andlabels are represented as nodes, with edges indicating the correlations betweenthem. To model these correlations, GORAG employs an edge weighting mechanism toprioritize the importance and reliability of extracted information anddynamically retrieves relevant context using a minimum-cost spanning treetailored for each text input. Empirical evaluations demonstrate that GORAGoutperforms existing approaches by providing more comprehensive and precisecontextual information.</description><author>Yubo Wang, Haoyang Li, Fei Teng, Lei Chen</author><pubDate>Fri, 14 Feb 2025 15:32:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.02844v3</guid></item><item><title>Graph Foundation Models for Recommendation: A Comprehensive Survey</title><link>http://arxiv.org/abs/2502.08346v2</link><description>Recommender systems (RS) serve as a fundamental tool for navigating the vastexpanse of online information, with deep learning advancements playing anincreasingly important role in improving ranking accuracy. Among these, graphneural networks (GNNs) excel at extracting higher-order structural information,while large language models (LLMs) are designed to process and comprehendnatural language, making both approaches highly effective and widely adopted.Recent research has focused on graph foundation models (GFMs), which integratethe strengths of GNNs and LLMs to model complex RS problems more efficiently byleveraging the graph-based structure of user-item relationships alongsidetextual understanding. In this survey, we provide a comprehensive overview ofGFM-based RS technologies by introducing a clear taxonomy of currentapproaches, diving into methodological details, and highlighting key challengesand future directions. By synthesizing recent advancements, we aim to offervaluable insights into the evolving landscape of GFM-based recommender systems.</description><author>Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi</author><pubDate>Fri, 14 Feb 2025 15:25:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.08346v2</guid></item><item><title>Stabilizing and Solving Inverse Problems using Data and Machine Learning</title><link>http://arxiv.org/abs/2412.04409v2</link><description>We consider an inverse problem involving the reconstruction of the solutionto a nonlinear partial differential equation (PDE) with unknown boundaryconditions. Instead of direct boundary data, we are provided with a largedataset of boundary observations for typical solutions (collective data) and abulk measurement of a specific realization. To leverage this collective data,we first compress the boundary data using proper orthogonal decomposition (POD)in a linear expansion. Next, we identify a possible nonlinear low-dimensionalstructure in the expansion coefficients using an autoencoder, which provides aparametrization of the dataset in a lower-dimensional latent space. We thentrain an operator network to map the expansion coefficients representing theboundary data to the finite element solution of the PDE. Finally, we connectthe autoencoder's decoder to the operator network which enables us to solve theinverse problem by optimizing a data-fitting term over the latent space. Weanalyze the underlying stabilized finite element method in the linear settingand establish an optimal error estimate in the $H^1$-norm. The nonlinearproblem is then studied numerically, demonstrating the effectiveness of ourapproach.</description><author>Erik Burman, Mats G. Larson, Karl Larsson, Carl Lundholm</author><pubDate>Fri, 14 Feb 2025 15:22:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04409v2</guid></item><item><title>A Multiagent Path Search Algorithm for Large-Scale Coalition Structure Generation</title><link>http://arxiv.org/abs/2502.10226v1</link><description>Coalition structure generation (CSG), i.e. the problem of optimallypartitioning a set of agents into coalitions to maximize social welfare, is afundamental computational problem in multiagent systems. This problem isimportant for many applications where small run times are necessary, includingtransportation and disaster response. In this paper, we develop SALDAE, amultiagent path finding algorithm for CSG that operates on a graph of coalitionstructures. Our algorithm utilizes a variety of heuristics and strategies toperform the search and guide it. It is an anytime algorithm that can handlelarge problems with hundreds and thousands of agents. We show empirically onnine standard value distributions, including disaster response and electricvehicle allocation benchmarks, that our algorithm enables a rapid finding ofhigh-quality solutions and compares favorably with other state-of-the-artmethods.</description><author>Redha Taguelmimt, Samir Aknine, Djamila Boukredera, Narayan Changder, Tuomas Sandholm</author><pubDate>Fri, 14 Feb 2025 15:21:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10226v1</guid></item><item><title>AirRAG: Activating Intrinsic Reasoning for Retrieval Augmented Generation using Tree-based Search</title><link>http://arxiv.org/abs/2501.10053v2</link><description>Leveraging the autonomous decision-making capabilities of large languagemodels (LLMs) has demonstrated superior performance in reasoning tasks.However, despite the success of iterative or recursive retrieval-augmentedgeneration (RAG) techniques, these methods are often constrained to a singlesolution space when confronted with complex problems. In this paper, we proposea novel thinking pattern in RAG that integrates system analysis with efficientreasoning actions, significantly activating intrinsic reasoning capabilitiesand expanding the solution space of specific tasks via Monte Carlo Tree Search(MCTS), which we refer to as AirRAG. Specifically, our approach designs fivefundamental reasoning actions, which are expanded to a broad tree-basedreasoning space using MCTS. The approach also incorporates self-consistencyverification to explore potential reasoning paths and inference scaling law.Additionally, computationally optimal strategies are employed to allocate moreinference resources to key actions, thereby enhancing overall performance.Experimental results demonstrate the effectiveness of AirRAG, showingsignificant performance gains on complex question-answering datasets.Furthermore, AirRAG is flexible and lightweight, making it easy to integratewith other advanced technologies.</description><author>Wenfeng Feng, Chuzhan Hao, Yuewei Zhang, Jingyi Song, Hao Wang</author><pubDate>Fri, 14 Feb 2025 15:20:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10053v2</guid></item><item><title>A distributional simplicity bias in the learning dynamics of transformers</title><link>http://arxiv.org/abs/2410.19637v2</link><description>The remarkable capability of over-parameterised neural networks to generaliseeffectively has been explained by invoking a ``simplicity bias'': neuralnetworks prevent overfitting by initially learning simple classifiers beforeprogressing to more complex, non-linear functions. While simplicity biases havebeen described theoretically and experimentally in feed-forward networks forsupervised learning, the extent to which they also explain the remarkablesuccess of transformers trained with self-supervised techniques remainsunclear. In our study, we demonstrate that transformers, trained on naturallanguage data, also display a simplicity bias. Specifically, they sequentiallylearn many-body interactions among input tokens, reaching a saturation point inthe prediction error for low-degree interactions while continuing to learnhigh-degree interactions. To conduct this analysis, we develop a procedure togenerate \textit{clones} of a given natural language data set, which rigorouslycapture the interactions between tokens up to a specified order. This approachopens up the possibilities of studying how interactions of different orders inthe data affect learning, in natural language processing and beyond.</description><author>Riccardo Rende, Federica Gerace, Alessandro Laio, Sebastian Goldt</author><pubDate>Fri, 14 Feb 2025 15:20:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19637v2</guid></item><item><title>Shield Synthesis for LTL Modulo Theories</title><link>http://arxiv.org/abs/2406.04184v2</link><description>In recent years, Machine Learning (ML) models have achieved remarkablesuccess in various domains. However, these models also tend to demonstrateunsafe behaviors, precluding their deployment in safety-critical systems. Tocope with this issue, ample research focuses on developing methods thatguarantee the safe behaviour of a given ML model. A prominent example isshielding which incorporates an external component (a ``shield'') that blocksunwanted behavior. Despite significant progress, shielding suffers from a mainsetback: it is currently geared towards properties encoded solely inpropositional logics (e.g., LTL) and is unsuitable for richer logics. This, inturn, limits the widespread applicability of shielding in many real-worldsystems. In this work, we address this gap, and extend shielding to LTL modulotheories, by building upon recent advances in reactive synthesis modulotheories. This allowed us to develop a novel approach for generating shieldsconforming to complex safety specifications in these more expressive, logics.We evaluated our shields and demonstrate their ability to handle rich data withtemporal dynamics. To the best of our knowledge, this is the first approach forsynthesizing shields for such expressivity.</description><author>Andoni Rodriguez, Guy Amir, Davide Corsi, Cesar Sanchez, Guy Katz</author><pubDate>Fri, 14 Feb 2025 15:19:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04184v2</guid></item><item><title>Linear Mode Connectivity in Differentiable Tree Ensembles</title><link>http://arxiv.org/abs/2405.14596v2</link><description>Linear Mode Connectivity (LMC) refers to the phenomenon that performanceremains consistent for linearly interpolated models in the parameter space. Forindependently optimized model pairs from different random initializations,achieving LMC is considered crucial for understanding the stable success of thenon-convex optimization in modern machine learning models and for facilitatingpractical parameter-based operations such as model merging. While LMC has beenachieved for neural networks by considering the permutation invariance ofneurons in each hidden layer, its attainment for other models remains an openquestion. In this paper, we first achieve LMC for soft tree ensembles, whichare tree-based differentiable models extensively used in practice. We show thenecessity of incorporating two invariances: subtree flip invariance andsplitting order invariance, which do not exist in neural networks but areinherent to tree architectures, in addition to permutation invariance of trees.Moreover, we demonstrate that it is even possible to exclude such additionalinvariances while keeping LMC by designing decision list-based treearchitectures, where such invariances do not exist by definition. Our findingsindicate the significance of accounting for architecture-specific invariancesin achieving LMC.</description><author>Ryuichi Kanoh, Mahito Sugiyama</author><pubDate>Fri, 14 Feb 2025 15:13:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14596v2</guid></item><item><title>Forget the Data and Fine-Tuning! Just Fold the Network to Compress</title><link>http://arxiv.org/abs/2502.10216v1</link><description>We introduce model folding, a novel data-free model compression techniquethat merges structurally similar neurons across layers, significantly reducingthe model size without the need for fine-tuning or access to training data.Unlike existing methods, model folding preserves data statistics duringcompression by leveraging k-means clustering, and using novel data-freetechniques to prevent variance collapse or explosion. Our theoretical frameworkand experiments across standard benchmarks, including ResNet18 and LLaMA-7B,demonstrate that model folding achieves comparable performance to data-drivencompression techniques and outperforms recently proposed data-free methods,especially at high sparsity levels. This approach is particularly effective forcompressing large-scale models, making it suitable for deployment inresource-constrained environments.</description><author>Dong Wang, Haris Šikić, Lothar Thiele, Olga Saukh</author><pubDate>Fri, 14 Feb 2025 15:10:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10216v1</guid></item><item><title>Do Large Language Models Reason Causally Like Us? Even Better?</title><link>http://arxiv.org/abs/2502.10215v1</link><description>Causal reasoning is a core component of intelligence. Large language models(LLMs) have shown impressive capabilities in generating human-like text,raising questions about whether their responses reflect true understanding orstatistical patterns. We compared causal reasoning in humans and four LLMsusing tasks based on collider graphs, rating the likelihood of a query variableoccurring given evidence from other variables. We find that LLMs reasoncausally along a spectrum from human-like to normative inference, withalignment shifting based on model, context, and task. Overall, GPT-4o andClaude showed the most normative behavior, including "explaining away", whereasGemini-Pro and GPT-3.5 did not. Although all agents deviated from the expectedindependence of causes - Claude the least - they exhibited strong associativereasoning and predictive inference when assessing the likelihood of the effectgiven its causes. These findings underscore the need to assess AI biases asthey increasingly assist human decision-making.</description><author>Hanna M. Dettki, Brenden M. Lake, Charley M. Wu, Bob Rehder</author><pubDate>Fri, 14 Feb 2025 15:09:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10215v1</guid></item><item><title>Mapping bathymetry of inland water bodies on the North Slope of Alaska with Landsat using Random Forest</title><link>http://arxiv.org/abs/2502.10214v1</link><description>The North Slope of Alaska is dominated by small waterbodies that providecritical ecosystem services for local population and wildlife. Detailedinformation on the depth of the waterbodies is scarce due to the challengeswith collecting such information. In this work we have trained a machinelearning (Random Forest Regressor) model to predict depth from multispectralLandsat data in waterbodies across the North Slope of Alaska. The greatestchallenge is the scarcity of in situ data, which is expensive and difficult toobtain, to train the model. We overcame this challenge by using modeled depthpredictions from a prior study as synthetic training data to provide a morediverse training data pool for the Random Forest. The final Random Forest modelwas more robust than models trained directly on the in situ data and whenapplied to 208 Landsat 8 scenes from 2016 to 2018 yielded a map with an overall$r^{2}$ value of 0.76 on validation. The final map has been made availablethrough the Oak Ridge National Laboratory Distribute Active Archive Center(ORNL-DAAC). This map represents a first of its kind regional assessment ofwaterbody depth with per pixel estimates of depth for the entire North Slope ofAlaska.</description><author>Mark L. Carroll, Margaret R. Wooten, Claire E. Simpson, Caleb S. Spradlin, Melanie J. Frost, Mariana Blanco-Rojas, Zachary W. Williams, Jordan A. Caraballo-Vega, Christopher S. R. Neigh</author><pubDate>Fri, 14 Feb 2025 15:08:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10214v1</guid></item><item><title>Control-flow anomaly detection by process mining-based feature extraction and dimensionality reduction</title><link>http://arxiv.org/abs/2502.10211v1</link><description>The business processes of organizations may deviate from normal control flowdue to disruptive anomalies, including unknown, skipped, and wrongly-orderedactivities. To identify these control-flow anomalies, process mining can checkcontrol-flow correctness against a reference process model through conformancechecking, an explainable set of algorithms that allows linking any deviationswith model elements. However, the effectiveness of conformance checking-basedtechniques is negatively affected by noisy event data and low-quality processmodels. To address these shortcomings and support the development ofcompetitive and explainable conformance checking-based techniques forcontrol-flow anomaly detection, we propose a novel process mining-based featureextraction approach with alignment-based conformance checking. This variantaligns the deviating control flow with a reference process model; the resultingalignment can be inspected to extract additional statistics such as the numberof times a given activity caused mismatches. We integrate this approach into aflexible and explainable framework for developing techniques for control-flowanomaly detection. The framework combines process mining-based featureextraction and dimensionality reduction to handle high-dimensional featuresets, achieve detection effectiveness, and support explainability. The resultsshow that the framework techniques implementing our approach outperform thebaseline conformance checking-based techniques while maintaining theexplainable nature of conformance checking. We also provide an explanation ofwhy existing conformance checking-based techniques may be ineffective.</description><author>Francesco Vitale, Marco Pegoraro, Wil M. P. van der Aalst, Nicola Mazzocca</author><pubDate>Fri, 14 Feb 2025 15:06:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10211v1</guid></item><item><title>SGS-GNN: A Supervised Graph Sparsification method for Graph Neural Networks</title><link>http://arxiv.org/abs/2502.10208v1</link><description>We propose SGS-GNN, a novel supervised graph sparsifier that learns thesampling probability distribution of edges and samples sparse subgraphs of auser-specified size to reduce the computational costs required by GNNs forinference tasks on large graphs. SGS-GNN employs regularizers in the lossfunction to enhance homophily in sparse subgraphs, boosting the accuracy ofGNNs on heterophilic graphs, where a significant number of the neighbors of anode have dissimilar labels. SGS-GNN also supports conditional updates of theprobability distribution learning module based on a prior, which helps narrowthe search space for sparse graphs. SGS-GNN requires fewer epochs to obtainhigh accuracies since it learns the search space of subgraphs more effectivelythan methods using fixed distributions such as random sampling. Extensiveexperiments using 33 homophilic and heterophilic graphs demonstrate thefollowing: (i) with only 20% of edges retained in the sparse subgraphs, SGS-GNNimproves the F1-scores by a geometric mean of 4% relative to the originalgraph; on heterophilic graphs, the prediction accuracy is better up to 30%.(ii) SGS-GNN outperforms state-of-the-art methods with improvement in F1-scoresof 4-7% in geometric mean with similar sparsities in the sampled subgraphs, and(iii) compared to sparsifiers that employ fixed distributions, SGS-GNN requiresabout half the number of epochs to converge.</description><author>Siddhartha Shankar Das, Naheed Anjum Arafat, Muftiqur Rahman, S M Ferdous, Alex Pothen, Mahantesh M Halappanavar</author><pubDate>Fri, 14 Feb 2025 15:03:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.10208v1</guid></item></channel></rss>