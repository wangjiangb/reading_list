<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 07 Feb 2024 06:00:57 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls</title><link>http://arxiv.org/abs/2402.04253v1</link><description>We introduce AnyTool, a large language model agent designed to revolutionizethe utilization of a vast array of tools in addressing user queries. We utilizeover 16,000 APIs from Rapid API, operating under the assumption that a subsetof these APIs could potentially resolve the queries. AnyTool primarilyincorporates three elements: an API retriever with a hierarchical structure, asolver aimed at resolving user queries using a selected set of API candidates,and a self-reflection mechanism, which re-activates AnyTool if the initialsolution proves impracticable. AnyTool is powered by the function callingfeature of GPT-4, eliminating the need for training external modules. We alsorevisit the evaluation protocol introduced by previous works and identify alimitation in this protocol that leads to an artificially high pass rate. Byrevising the evaluation protocol to better reflect practical applicationscenarios, we introduce an additional benchmark, termed AnyToolBench.Experiments across various datasets demonstrate the superiority of our AnyToolover strong baselines such as ToolLLM and a GPT-4 variant tailored for toolutilization. For instance, AnyTool outperforms ToolLLM by +35.4% in terms ofaverage pass rate on ToolBench. Code will be available athttps://github.com/dyabel/AnyTool.</description><author>Yu Du, Fangyun Wei, Hongyang Zhang</author><pubDate>Tue, 06 Feb 2024 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04253v1</guid></item><item><title>EVA-CLIP-18B: Scaling CLIP to 18 Billion Parameters</title><link>http://arxiv.org/abs/2402.04252v1</link><description>Scaling up contrastive language-image pretraining (CLIP) is critical forempowering both vision and multimodal models. We present EVA-CLIP-18B, thelargest and most powerful open-source CLIP model to date, with 18-billionparameters. With only 6-billion training samples seen, EVA-CLIP-18B achieves anexceptional 80.7% zero-shot top-1 accuracy averaged across 27 widely recognizedimage classification benchmarks, outperforming its forerunner EVA-CLIP(5-billion parameters) and other open-source CLIP models by a large margin.Remarkably, we observe a consistent performance improvement with the model sizescaling of EVA-CLIP, despite maintaining a constant training dataset of2-billion image-text pairs from LAION-2B and COYO-700M. This dataset is openlyavailable and much smaller than the in-house datasets (e.g., DFN-5B, WebLI-10B)employed in other state-of-the-art CLIP models. EVA-CLIP-18B demonstrates thepotential of EVA-style weak-to-strong visual model scaling. With our modelweights made publicly available, we hope to facilitate future research invision and multimodal foundation models.</description><author>Quan Sun, Jinsheng Wang, Qiying Yu, Yufeng Cui, Fan Zhang, Xiaosong Zhang, Xinlong Wang</author><pubDate>Tue, 06 Feb 2024 18:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04252v1</guid></item><item><title>Linear-time Minimum Bayes Risk Decoding with Reference Aggregation</title><link>http://arxiv.org/abs/2402.04251v1</link><description>Minimum Bayes Risk (MBR) decoding is a text generation technique that hasbeen shown to improve the quality of machine translations, but is expensive,even if a sampling-based approximation is used. Besides requiring a largenumber of sampled sequences, it requires the pairwise calculation of a utilitymetric, which has quadratic complexity. In this paper, we propose toapproximate pairwise metric scores with scores calculated against aggregatedreference representations. This changes the complexity of utility estimationfrom $O(n^2)$ to $O(n)$, while empirically preserving most of the quality gainsof MBR decoding. We release our source code at https://github.com/ZurichNLP/mbr</description><author>Jannis Vamvas, Rico Sennrich</author><pubDate>Tue, 06 Feb 2024 18:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04251v1</guid></item><item><title>HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal</title><link>http://arxiv.org/abs/2402.04249v1</link><description>Automated red teaming holds substantial promise for uncovering and mitigatingthe risks associated with the malicious use of large language models (LLMs),yet the field lacks a standardized evaluation framework to rigorously assessnew methods. To address this issue, we introduce HarmBench, a standardizedevaluation framework for automated red teaming. We identify several desirableproperties previously unaccounted for in red teaming evaluations andsystematically design HarmBench to meet these criteria. Using HarmBench, weconduct a large-scale comparison of 18 red teaming methods and 33 target LLMsand defenses, yielding novel insights. We also introduce a highly efficientadversarial training method that greatly enhances LLM robustness across a widerange of attacks, demonstrating how HarmBench enables codevelopment of attacksand defenses. We open source HarmBench athttps://github.com/centerforaisafety/HarmBench.</description><author>Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo Li, David Forsyth, Dan Hendrycks</author><pubDate>Tue, 06 Feb 2024 18:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04249v1</guid></item><item><title>Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks</title><link>http://arxiv.org/abs/2402.04248v1</link><description>State-space models (SSMs), such as Mamba Gu &amp; Dao (2034), have been proposedas alternatives to Transformer networks in language modeling, by incorporatinggating, convolutions, and input-dependent token selection to mitigate thequadratic cost of multi-head attention. Although SSMs exhibit competitiveperformance, their in-context learning (ICL) capabilities, a remarkableemergent property of modern language models that enables task execution withoutparameter optimization, remain underexplored compared to Transformers. In thisstudy, we evaluate the ICL performance of SSMs, focusing on Mamba, againstTransformer models across various tasks. Our results show that SSMs performcomparably to Transformers in standard regression ICL tasks, whileoutperforming them in tasks like sparse parity learning. However, SSMs fallshort in tasks involving non-standard retrieval functionality. To address theselimitations, we introduce a hybrid model, \variant, that combines Mamba withattention blocks, surpassing individual models in tasks where they struggleindependently. Our findings suggest that hybrid architectures offer promisingavenues for enhancing ICL in language models.</description><author>Jongho Park, Jaeseung Park, Zheyang Xiong, Nayoung Lee, Jaewoong Cho, Samet Oymak, Kangwook Lee, Dimitris Papailiopoulos</author><pubDate>Tue, 06 Feb 2024 18:56:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04248v1</guid></item><item><title>Building a Safer Maritime Environment Through Multi-Path Long-Term Vessel Trajectory Forecasting</title><link>http://arxiv.org/abs/2310.18948v3</link><description>Maritime transportation is paramount in achieving global economic growth,entailing concurrent ecological obligations in sustainability and safeguardingendangered marine species, most notably preserving large whale populations. Inthis regard, the Automatic Identification System (AIS) data plays a significantrole by offering real-time streaming data on vessel movement, allowing enhancedtraffic monitoring. This study explores using AIS data to preventvessel-to-whale collisions by forecasting long-term vessel trajectories fromengineered AIS data sequences. For such a task, we have developed anencoder-decoder model architecture using Bidirectional Long Short-Term MemoryNetworks (Bi-LSTM) to predict the next 12 hours of vessel trajectories using 1to 3 hours of AIS data as input. We feed the model with probabilistic featuresengineered from historical AIS data that refer to each trajectory's potentialroute and destination. The model then predicts the vessel's trajectory,considering these additional features by leveraging convolutional layers forspatial feature learning and a position-aware attention mechanism thatincreases the importance of recent timesteps of a sequence during temporalfeature learning. The probabilistic features have an F1 Score of approximately85% and 75% for each feature type, respectively, demonstrating theireffectiveness in augmenting information to the neural network. We test ourmodel on the Gulf of St. Lawrence, a region known to be the habitat of NorthAtlantic Right Whales (NARW). Our model achieved a high R2 score of over 98%using various techniques and features. It stands out among other approaches asit can make complex decisions during turnings and path selection. Our studyhighlights the potential of data engineering and trajectory forecasting modelsfor marine life species preservation.</description><author>Gabriel Spadon, Jay Kumar, Matthew Smith, Sarah Vela, Romina Gehrmann, Derek Eden, Joshua van Berkel, Amilcar Soares, Ronan Fablet, Ronald Pelot, Stan Matwin</author><pubDate>Tue, 06 Feb 2024 18:56:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18948v3</guid></item><item><title>Extreme Compression of Large Language Models via Additive Quantization</title><link>http://arxiv.org/abs/2401.06118v2</link><description>The emergence of accurate open large language models (LLMs) has led to a racetowards quantization techniques for such models enabling execution on end-userdevices. In this paper, we revisit the problem of "extreme" LLMcompression--defined as targeting extremely low bit counts, such as 2 to 3 bitsper parameter, from the point of view of classic methods in Multi-CodebookQuantization (MCQ). Our work builds on top of Additive Quantization, a classicalgorithm from the MCQ family, and adapts it to the quantization of languagemodels. The resulting algorithm advances the state-of-the-art in LLMcompression, outperforming all recently-proposed techniques in terms ofaccuracy at a given compression budget. For instance, when compressing Llama 2models to 2 bits per parameter, our algorithm quantizes the 7B model to 6.93perplexity (a 1.29 improvement relative to the best prior work, and 1.81 pointsfrom FP16), the 13B model to 5.70 perplexity (a .36 improvement) and the 70Bmodel to 3.94 perplexity (a .22 improvement) on WikiText2. We release ourimplementation of Additive Quantization for Language Models AQLM as a baselineto facilitate future research in LLM quantization.</description><author>Vage Egiazarian, Andrei Panferov, Denis Kuznedelev, Elias Frantar, Artem Babenko, Dan Alistarh</author><pubDate>Tue, 06 Feb 2024 18:55:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06118v2</guid></item><item><title>Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science</title><link>http://arxiv.org/abs/2402.04247v1</link><description>Intelligent agents powered by large language models (LLMs) have demonstratedsubstantial promise in autonomously conducting experiments and facilitatingscientific discoveries across various disciplines. While their capabilities arepromising, they also introduce novel vulnerabilities that demand carefulconsideration for safety. However, there exists a notable gap in theliterature, as there has been no comprehensive exploration of thesevulnerabilities. This position paper fills this gap by conducting a thoroughexamination of vulnerabilities in LLM-based agents within scientific domains,shedding light on potential risks associated with their misuse and emphasizingthe need for safety measures. We begin by providing a comprehensive overview ofthe potential risks inherent to scientific LLM agents, taking into account userintent, the specific scientific domain, and their potential impact on theexternal environment. Then, we delve into the origins of these vulnerabilitiesand provide a scoping review of the limited existing works. Based on ouranalysis, we propose a triadic framework involving human regulation, agentalignment, and an understanding of environmental feedback (agent regulation) tomitigate these identified risks. Furthermore, we highlight the limitations andchallenges associated with safeguarding scientific agents and advocate for thedevelopment of improved models, robust benchmarks, and comprehensiveregulations to address these issues effectively.</description><author>Xiangru Tang, Qiao Jin, Kunlun Zhu, Tongxin Yuan, Yichi Zhang, Wangchunshu Zhou, Meng Qu, Yilun Zhao, Jian Tang, Zhuosheng Zhang, Arman Cohan, Zhiyong Lu, Mark Gerstein</author><pubDate>Tue, 06 Feb 2024 18:54:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04247v1</guid></item><item><title>CAST: Clustering Self-Attention using Surrogate Tokens for Efficient Transformers</title><link>http://arxiv.org/abs/2402.04239v1</link><description>The Transformer architecture has shown to be a powerful tool for a wide rangeof tasks. It is based on the self-attention mechanism, which is an inherentlycomputationally expensive operation with quadratic computational complexity:memory usage and compute time increase quadratically with the length of theinput sequences, thus limiting the application of Transformers. In this work,we propose a novel Clustering self-Attention mechanism using Surrogate Tokens(CAST), to optimize the attention computation and achieve efficienttransformers. CAST utilizes learnable surrogate tokens to construct a clusteraffinity matrix, used to cluster the input sequence and generate novel clustersummaries. The self-attention from within each cluster is then combined withthe cluster summaries of other clusters, enabling information flow across theentire input sequence. CAST improves efficiency by reducing the complexity from$O(N^2)$ to $O(\alpha N)$ where N is the sequence length, and {\alpha} isconstant according to the number of clusters and samples per cluster. We showthat CAST performs better than or comparable to the baseline Transformers onlong-range sequence modeling tasks, while also achieving higher results on timeand memory efficiency than other efficient transformers.</description><author>Adjorn van Engelenhoven, Nicola Strisciuglio, Estefanía Talavera</author><pubDate>Tue, 06 Feb 2024 18:47:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04239v1</guid></item><item><title>DirecT2V: Large Language Models are Frame-Level Directors for Zero-Shot Text-to-Video Generation</title><link>http://arxiv.org/abs/2305.14330v3</link><description>In the paradigm of AI-generated content (AIGC), there has been increasingattention to transferring knowledge from pre-trained text-to-image (T2I) modelsto text-to-video (T2V) generation. Despite their effectiveness, theseframeworks face challenges in maintaining consistent narratives and handlingshifts in scene composition or object placement from a single abstract userprompt. Exploring the ability of large language models (LLMs) to generatetime-dependent, frame-by-frame prompts, this paper introduces a new framework,dubbed DirecT2V. DirecT2V leverages instruction-tuned LLMs as directors,enabling the inclusion of time-varying content and facilitating consistentvideo generation. To maintain temporal consistency and prevent mapping thevalue to a different object, we equip a diffusion model with a novel valuemapping method and dual-softmax filtering, which do not require any additionaltraining. The experimental results validate the effectiveness of our frameworkin producing visually coherent and storyful videos from abstract user prompts,successfully addressing the challenges of zero-shot video generation.</description><author>Susung Hong, Junyoung Seo, Heeseong Shin, Sunghwan Hong, Seungryong Kim</author><pubDate>Tue, 06 Feb 2024 18:44:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14330v3</guid></item><item><title>CogCoM: Train Large Vision-Language Models Diving into Details through Chain of Manipulations</title><link>http://arxiv.org/abs/2402.04236v1</link><description>Vision-Language Models (VLMs) have demonstrated their widespread viabilitythanks to extensive training in aligning visual instructions to answers.However, this conclusive alignment leads models to ignore critical visualreasoning, and further result in failures on meticulous visual problems andunfaithful responses. In this paper, we propose Chain of Manipulations, amechanism that enables VLMs to solve problems with a series of manipulations,where each manipulation refers to an operation on the visual input, either fromintrinsic abilities (e.g., grounding) acquired through prior training or fromimitating human-like behaviors (e.g., zoom in). This mechanism encourages VLMsto generate faithful responses with evidential visual reasoning, and permitsusers to trace error causes in the interpretable paths. We thus train CogCoM, ageneral 17B VLM with a memory-based compatible architecture endowed thisreasoning mechanism. Experiments show that our model achieves thestate-of-the-art performance across 8 benchmarks from 3 categories, and alimited number of training steps with the data swiftly gains a competitiveperformance. The code and data are publicly available athttps://github.com/THUDM/CogCoM.</description><author>Ji Qi, Ming Ding, Weihan Wang, Yushi Bai, Qingsong Lv, Wenyi Hong, Bin Xu, Lei Hou, Juanzi Li, Yuxiao Dong, Jie Tang</author><pubDate>Tue, 06 Feb 2024 18:43:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04236v1</guid></item><item><title>Can Generative Agents Predict Emotion?</title><link>http://arxiv.org/abs/2402.04232v1</link><description>Large Language Models (LLMs) have demonstrated a number of human-likeabilities, however the empathic understanding and emotional state of LLMs isyet to be aligned to that of humans. In this work, we investigate how theemotional state of generative LLM agents evolves as they perceive new events,introducing a novel architecture in which new experiences are compared to pastmemories. Through this comparison, the agent gains the ability to understandnew experiences in context, which according to the appraisal theory of emotionis vital in emotion creation. First, the agent perceives new experiences astime series text data. After perceiving each new input, the agent generates asummary of past relevant memories, referred to as the norm, and compares thenew experience to this norm. Through this comparison we can analyse how theagent reacts to the new experience in context. The PANAS, a test of affect, isadministered to the agent, capturing the emotional state of the agent after theperception of the new event. Finally, the new experience is then added to theagents memory to be used in the creation of future norms. By creating multipleexperiences in natural language from emotionally charged situations, we testthe proposed architecture on a wide range of scenarios. The mixed resultssuggests that introducing context can occasionally improve the emotionalalignment of the agent, but further study and comparison with human evaluatorsis necessary. We hope that this paper is another step towards the alignment ofgenerative agents.</description><author>Ciaran Regan, Nanami Iwahashi, Shogo Tanaka, Mizuki Oka</author><pubDate>Tue, 06 Feb 2024 18:39:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04232v1</guid></item><item><title>DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</title><link>http://arxiv.org/abs/2402.03300v2</link><description>Mathematical reasoning poses a significant challenge for language models dueto its complex and structured nature. In this paper, we introduce DeepSeekMath7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120Bmath-related tokens sourced from Common Crawl, together with natural languageand code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on thecompetition-level MATH benchmark without relying on external toolkits andvoting techniques, approaching the performance level of Gemini-Ultra and GPT-4.Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH.The mathematical reasoning capability of DeepSeekMath is attributed to two keyfactors: First, we harness the significant potential of publicly available webdata through a meticulously engineered data selection pipeline. Second, weintroduce Group Relative Policy Optimization (GRPO), a variant of ProximalPolicy Optimization (PPO), that enhances mathematical reasoning abilities whileconcurrently optimizing the memory usage of PPO.</description><author>Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, Y. K. Li, Y. Wu, Daya Guo</author><pubDate>Tue, 06 Feb 2024 18:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03300v2</guid></item><item><title>MusicRL: Aligning Music Generation to Human Preferences</title><link>http://arxiv.org/abs/2402.04229v1</link><description>We propose MusicRL, the first music generation system finetuned from humanfeedback. Appreciation of text-to-music models is particularly subjective sincethe concept of musicality as well as the specific intention behind a captionare user-dependent (e.g. a caption such as "upbeat work-out music" can map to aretro guitar solo or a techno pop beat). Not only this makes supervisedtraining of such models challenging, but it also calls for integratingcontinuous human feedback in their post-deployment finetuning. MusicRL is apretrained autoregressive MusicLM (Agostinelli et al., 2023) model of discreteaudio tokens finetuned with reinforcement learning to maximise sequence-levelrewards. We design reward functions related specifically to text-adherence andaudio quality with the help from selected raters, and use those to finetuneMusicLM into MusicRL-R. We deploy MusicLM to users and collect a substantialdataset comprising 300,000 pairwise preferences. Using Reinforcement Learningfrom Human Feedback (RLHF), we train MusicRL-U, the first text-to-music modelthat incorporates human feedback at scale. Human evaluations show that bothMusicRL-R and MusicRL-U are preferred to the baseline. Ultimately, MusicRL-RUcombines the two approaches and results in the best model according to humanraters. Ablation studies shed light on the musical attributes influencing humanpreferences, indicating that text adherence and quality only account for a partof it. This underscores the prevalence of subjectivity in musical appreciationand calls for further involvement of human listeners in the finetuning of musicgeneration models.</description><author>Geoffrey Cideron, Sertan Girgin, Mauro Verzetti, Damien Vincent, Matej Kastelic, Zalán Borsos, Brian McWilliams, Victor Ungureanu, Olivier Bachem, Olivier Pietquin, Matthieu Geist, Léonard Hussenot, Neil Zeghidour, Andrea Agostinelli</author><pubDate>Tue, 06 Feb 2024 18:36:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04229v1</guid></item><item><title>Intelligent Collective Escape of Swarm Robots Based on a Novel Fish-inspired Self-adaptive Approach with Neurodynamic Models</title><link>http://arxiv.org/abs/2402.04228v1</link><description>Fish schools present high-efficiency group behaviors through simpleindividual interactions to collective migration and dynamic escape from thepredator. The school behavior of fish is usually a good inspiration to designcontrol architecture for swarm robots. In this paper, a novel fish-inspiredself-adaptive approach is proposed for collective escape for the swarm robots.In addition, a bio-inspired neural network (BINN) is introduced to generatecollision-free escape robot trajectories through the combination of attractiveand repulsive forces. Furthermore, to cope with dynamic environments, aneurodynamics-based self-adaptive mechanism is proposed to improve theself-adaptive performance of the swarm robots in the changing environment.Similar to fish escape maneuvers, simulation and experimental results show thatthe swarm robots are capable of collectively leaving away from the threats.Several comparison studies demonstrated that the proposed approach cansignificantly improve the effectiveness and efficiency of system performance,and the flexibility and robustness in complex environments.</description><author>Junfei Li, Simon X. Yang</author><pubDate>Tue, 06 Feb 2024 18:36:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04228v1</guid></item><item><title>Clustered Switchback Experiments: Near-Optimal Rates Under Spatiotemporal Interference</title><link>http://arxiv.org/abs/2312.15574v3</link><description>We consider experimentation in the presence of non-stationarity, inter-unit(spatial) interference, and carry-over effects (temporal interference), wherewe wish to estimate the global average treatment effect (GATE), the differencebetween average outcomes having exposed all units at all times to treatment orto control. We suppose spatial interference is described by a graph, where aunit's outcome depends on its neighborhood's treatment assignments, and thattemporal interference is described by a hidden Markov decision process, wherethe transition kernel under either treatment (action) satisfies a rapid mixingcondition. We propose a clustered switchback design, where units are groupedinto clusters and time steps are grouped into blocks and each wholecluster-block combination is assigned a single random treatment. Under thisdesign, we show that for graphs that admit good clustering, a truncatedexposure-mapping Horvitz-Thompson estimator achieves $\tilde O(1/NT)$mean-squared error (MSE), matching an $\Omega(1/NT)$ lower bound up tologarithmic terms. Our results simultaneously generalize the $N=1$ setting ofHu, Wager 2022 (and improves on the MSE bound shown therein fordifference-in-means estimators) as well as the $T=1$ settings of Ugander et al2013 and Leung 2022. Simulation studies validate the favorable performance ofour approach.</description><author>Su Jia, Nathan Kallus, Christina Lee Yu</author><pubDate>Tue, 06 Feb 2024 18:36:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15574v3</guid></item><item><title>We're Not Using Videos Effectively: An Updated Domain Adaptive Video Segmentation Baseline</title><link>http://arxiv.org/abs/2402.00868v2</link><description>There has been abundant work in unsupervised domain adaptation for semanticsegmentation (DAS) seeking to adapt a model trained on images from a labeledsource domain to an unlabeled target domain. While the vast majority of priorwork has studied this as a frame-level Image-DAS problem, a few Video-DAS workshave sought to additionally leverage the temporal signal present in adjacentframes. However, Video-DAS works have historically studied a distinct set ofbenchmarks from Image-DAS, with minimal cross-benchmarking. In this work, weaddress this gap. Surprisingly, we find that (1) even after carefullycontrolling for data and model architecture, state-of-the-art Image-DAS methods(HRDA and HRDA+MIC) outperform Video-DAS methods on established Video-DASbenchmarks (+14.5 mIoU on Viper$\rightarrow$CityscapesSeq, +19.0 mIoU onSynthia$\rightarrow$CityscapesSeq), and (2) naive combinations of Image-DAS andVideo-DAS techniques only lead to marginal improvements across datasets. Toavoid siloed progress between Image-DAS and Video-DAS, we open-source ourcodebase with support for a comprehensive set of Video-DAS and Image-DASmethods on a common benchmark. Code available athttps://github.com/SimarKareer/UnifiedVideoDA</description><author>Simar Kareer, Vivek Vijaykumar, Harsh Maheshwari, Prithvijit Chattopadhyay, Judy Hoffman, Viraj Prabhu</author><pubDate>Tue, 06 Feb 2024 18:35:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00868v2</guid></item><item><title>What is 'Typological Diversity' in NLP?</title><link>http://arxiv.org/abs/2402.04222v1</link><description>The NLP research community has devoted increased attention to languagesbeyond English, resulting in considerable improvements for multilingual NLP.However, these improvements only apply to a small subset of the world'slanguages. Aiming to extend this, an increasing number of papers aspires toenhance generalizable multilingual performance across languages. To this end,linguistic typology is commonly used to motivate language selection, on thebasis that a broad typological sample ought to imply generalization across abroad range of languages. These selections are often described as being'typologically diverse'. In this work, we systematically investigate NLPresearch that includes claims regarding 'typological diversity'. We find thereare no set definitions or criteria for such claims. We introduce metrics toapproximate the diversity of language selection along several axes and findthat the results vary considerably across papers. Furthermore, we show thatskewed language selection can lead to overestimated multilingual performance.We recommend future work to include an operationalization of 'typologicaldiversity' that empirically justifies the diversity of language samples.</description><author>Esther Ploeger, Wessel Poelman, Miryam de Lhoneux, Johannes Bjerva</author><pubDate>Tue, 06 Feb 2024 18:29:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04222v1</guid></item><item><title>Resource-Aware Hierarchical Federated Learning in Wireless Video Caching Networks</title><link>http://arxiv.org/abs/2402.04216v1</link><description>Backhaul traffic congestion caused by the video traffic of a few popularfiles can be alleviated by storing the to-be-requested content at variouslevels in wireless video caching networks. Typically, content service providers(CSPs) own the content, and the users request their preferred content from theCSPs using their (wireless) internet service providers (ISPs). As these partiesdo not reveal their private information and business secrets, traditionaltechniques may not be readily used to predict the dynamic changes in users'future demands. Motivated by this, we propose a novel resource-awarehierarchical federated learning (RawHFL) solution for predicting user's futurecontent requests. A practical data acquisition technique is used that allowsthe user to update its local training dataset based on its requested content.Besides, since networking and other computational resources are limited,considering that only a subset of the users participate in the model training,we derive the convergence bound of the proposed algorithm. Based on this bound,we minimize a weighted utility function for jointly configuring thecontrollable parameters to train the RawHFL energy efficiently under practicalresource constraints. Our extensive simulation results validate the proposedalgorithm's superiority, in terms of test accuracy and energy cost, overexisting baselines.</description><author>Md Ferdous Pervej, Andreas F. Molisch</author><pubDate>Tue, 06 Feb 2024 18:17:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04216v1</guid></item><item><title>Variational Shapley Network: A Probabilistic Approach to Self-Explaining Shapley values with Uncertainty Quantification</title><link>http://arxiv.org/abs/2402.04211v1</link><description>Shapley values have emerged as a foundational tool in machine learning (ML)for elucidating model decision-making processes. Despite their widespreadadoption and unique ability to satisfy essential explainability axioms,computational challenges persist in their estimation when ($i$) evaluating amodel over all possible subset of input feature combinations, ($ii$) estimatingmodel marginals, and ($iii$) addressing variability in explanations. Weintroduce a novel, self-explaining method that simplifies the computation ofShapley values significantly, requiring only a single forward pass. Recognizingthe deterministic treatment of Shapley values as a limitation, we exploreincorporating a probabilistic framework to capture the inherent uncertainty inexplanations. Unlike alternatives, our technique does not rely directly on theobserved data space to estimate marginals; instead, it uses adaptable baselinevalues derived from a latent, feature-specific embedding space, generated by anovel masked neural network architecture. Evaluations on simulated and realdatasets underscore our technique's robust predictive and explanatoryperformance.</description><author>Mert Ketenci, Iñigo Urteaga, Victor Alfonso Rodriguez, Noémie Elhadad, Adler Perotte</author><pubDate>Tue, 06 Feb 2024 18:09:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04211v1</guid></item><item><title>On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond</title><link>http://arxiv.org/abs/2401.03301v2</link><description>We seek to understand what facilitates sample-efficient learning fromhistorical datasets for sequential decision-making, a problem that is popularlyknown as offline reinforcement learning (RL). Further, we are interested inalgorithms that enjoy sample efficiency while leveraging (value) functionapproximation. In this paper, we address these fundamental questions by (i)proposing a notion of data diversity that subsumes the previous notions ofcoverage measures in offline RL and (ii) using this notion to {unify} threedistinct classes of offline RL algorithms based on version spaces (VS),regularized optimization (RO), and posterior sampling (PS). We establish thatVS-based, RO-based, and PS-based algorithms, under standard assumptions,achieve \emph{comparable} sample efficiency, which recovers thestate-of-the-art sub-optimality bounds for finite and linear model classes withthe standard assumptions. This result is surprising, given that the prior worksuggested an unfavorable sample complexity of the RO-based algorithm comparedto the VS-based algorithm, whereas posterior sampling is rarely considered inoffline RL due to its explorative nature. Notably, our proposed model-freePS-based algorithm for offline RL is {novel}, with sub-optimality bounds thatare {frequentist} (i.e., worst-case) in nature.</description><author>Thanh Nguyen-Tang, Raman Arora</author><pubDate>Tue, 06 Feb 2024 18:08:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03301v2</guid></item><item><title>"Task Success" is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors</title><link>http://arxiv.org/abs/2402.04210v1</link><description>Large-scale generative models are shown to be useful for sampling meaningfulcandidate solutions, yet they often overlook task constraints and userpreferences. Their full power is better harnessed when the models are coupledwith external verifiers and the final solutions are derived iteratively orprogressively according to the verification feedback. In the context ofembodied AI, verification often solely involves assessing whether goalconditions specified in the instructions have been met. Nonetheless, for theseagents to be seamlessly integrated into daily life, it is crucial to accountfor a broader range of constraints and preferences beyond bare task success(e.g., a robot should grasp bread with care to avoid significant deformations).However, given the unbounded scope of robot tasks, it is infeasible toconstruct scripted verifiers akin to those used for explicit-knowledge taskslike the game of Go and theorem proving. This begs the question: when no soundverifier is available, can we use large vision and language models (VLMs),which are approximately omniscient, as scalable Behavior Critics to catchundesirable robot behaviors in videos? To answer this, we first construct abenchmark that contains diverse cases of goal-reaching yet undesirable robotpolicies. Then, we comprehensively evaluate VLM critics to gain a deeperunderstanding of their strengths and failure modes. Based on the evaluation, weprovide guidelines on how to effectively utilize VLM critiques and showcase apractical way to integrate the feedback into an iterative process of policyrefinement. The dataset and codebase are released at:https://guansuns.github.io/pages/vlm-critic.</description><author>Lin Guan, Yifan Zhou, Denis Liu, Yantian Zha, Heni Ben Amor, Subbarao Kambhampati</author><pubDate>Tue, 06 Feb 2024 18:07:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04210v1</guid></item><item><title>High-dimensional and Permutation Invariant Anomaly Detection</title><link>http://arxiv.org/abs/2306.03933v4</link><description>Methods for anomaly detection of new physics processes are often limited tolow-dimensional spaces due to the difficulty of learning high-dimensionalprobability densities. Particularly at the constituent level, incorporatingdesirable properties such as permutation invariance and variable-length inputsbecomes difficult within popular density estimation methods. In this work, weintroduce a permutation-invariant density estimator for particle physics databased on diffusion models, specifically designed to handle variable-lengthinputs. We demonstrate the efficacy of our methodology by utilizing the learneddensity as a permutation-invariant anomaly detection score, effectivelyidentifying jets with low likelihood under the background-only hypothesis. Tovalidate our density estimation method, we investigate the ratio of learneddensities and compare to those obtained by a supervised classificationalgorithm.</description><author>Vinicius Mikuni, Benjamin Nachman</author><pubDate>Tue, 06 Feb 2024 18:05:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03933v4</guid></item><item><title>Acute kidney injury prediction for non-critical care patients: a retrospective external and internal validation study</title><link>http://arxiv.org/abs/2402.04209v1</link><description>Background: Acute kidney injury (AKI), the decline of kidney excretoryfunction, occurs in up to 18% of hospitalized admissions. Progression of AKImay lead to irreversible kidney damage. Methods: This retrospective cohortstudy includes adult patients admitted to a non-intensive care unit at theUniversity of Pittsburgh Medical Center (UPMC) (n = 46,815) and University ofFlorida Health (UFH) (n = 127,202). We developed and compared deep learning andconventional machine learning models to predict progression to Stage 2 orhigher AKI within the next 48 hours. We trained local models for each site (UFHModel trained on UFH, UPMC Model trained on UPMC) and a separate model with adevelopment cohort of patients from both sites (UFH-UPMC Model). We internallyand externally validated the models on each site and performed subgroupanalyses across sex and race. Results: Stage 2 or higher AKI occurred in 3%(n=3,257) and 8% (n=2,296) of UFH and UPMC patients, respectively. Area underthe receiver operating curve values (AUROC) for the UFH test cohort rangedbetween 0.77 (UPMC Model) and 0.81 (UFH Model), while AUROC values rangedbetween 0.79 (UFH Model) and 0.83 (UPMC Model) for the UPMC test cohort.UFH-UPMC Model achieved an AUROC of 0.81 (95% confidence interval [CI] [0.80,0.83]) for UFH and 0.82 (95% CI [0.81,0.84]) for UPMC test cohorts; an areaunder the precision recall curve values (AUPRC) of 0.6 (95% CI, [0.05, 0.06])for UFH and 0.13 (95% CI, [0.11,0.15]) for UPMC test cohorts. Kinetic estimatedglomerular filtration rate, nephrotoxic drug burden and blood urea nitrogenremained the top three features with the highest influence across the modelsand health centers. Conclusion: Locally developed models displayed marginallyreduced discrimination when tested on another institution, while the top set ofinfluencing features remained the same across the models and sites.</description><author>Esra Adiyeke, Yuanfang Ren, Benjamin Shickel, Matthew M. Ruppert, Ziyuan Guan, Sandra L. Kane-Gill, Raghavan Murugan, Nabihah Amatullah, Britney A. Stottlemyer, Tiffany L. Tran, Dan Ricketts, Christopher M Horvat, Parisa Rashidi, Azra Bihorac, Tezcan Ozrazgat-Baslanti</author><pubDate>Tue, 06 Feb 2024 18:05:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04209v1</guid></item><item><title>SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</title><link>http://arxiv.org/abs/2312.07541v2</link><description>Recent techniques for real-time view synthesis have rapidly advanced infidelity and speed, and modern methods are capable of renderingnear-photorealistic scenes at interactive frame rates. At the same time, atension has arisen between explicit scene representations amenable torasterization and neural fields built on ray marching, with state-of-the-artinstances of the latter surpassing the former in quality while beingprohibitively expensive for real-time applications. In this work, we introduceSMERF, a view synthesis approach that achieves state-of-the-art accuracy amongreal-time methods on large scenes with footprints up to 300 m$^2$ at avolumetric resolution of 3.5 mm$^3$. Our method is built upon two primarycontributions: a hierarchical model partitioning scheme, which increases modelcapacity while constraining compute and memory consumption, and a distillationtraining strategy that simultaneously yields high fidelity and internalconsistency. Our approach enables full six degrees of freedom (6DOF) navigationwithin a web browser and renders in real-time on commodity smartphones andlaptops. Extensive experiments show that our method exceeds the currentstate-of-the-art in real-time novel view synthesis by 0.78 dB on standardbenchmarks and 1.78 dB on large scenes, renders frames three orders ofmagnitude faster than state-of-the-art radiance field models, and achievesreal-time performance across a wide variety of commodity devices, includingsmartphones. We encourage readers to explore these models interactively at ourproject website: https://smerf-3d.github.io.</description><author>Daniel Duckworth, Peter Hedman, Christian Reiser, Peter Zhizhin, Jean-François Thibert, Mario Lučić, Richard Szeliski, Jonathan T. Barron</author><pubDate>Tue, 06 Feb 2024 18:04:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07541v2</guid></item><item><title>Aligner: Achieving Efficient Alignment through Weak-to-Strong Correction</title><link>http://arxiv.org/abs/2402.02416v2</link><description>Efforts to align Large Language Models (LLMs) are mainly conducted viaReinforcement Learning from Human Feedback (RLHF) methods. However, RLHFencounters major challenges including training reward models, actor-criticengineering, and importantly, it requires access to LLM parameters. Here weintroduce Aligner, a new efficient alignment paradigm that bypasses the wholeRLHF process by learning the correctional residuals between the aligned and theunaligned answers. Our Aligner offers several key advantages. Firstly, it is anautoregressive seq2seq model that is trained on the query-answer-correctiondataset via supervised learning; this offers a parameter-efficient alignmentsolution with minimal resources. Secondly, the Aligner facilitatesweak-to-strong generalization; finetuning large pretrained models by Aligner'ssupervisory signals demonstrates strong performance boost. Thirdly, Alignerfunctions as a model-agnostic plug-and-play module, allowing for its directapplication on different open-source and API-based models. Remarkably,Aligner-7B improves 11 different LLMs by 21.9% in helpfulness and 23.8% inharmlessness on average (GPT-4 by 17.5% and 26.9%). When finetuning (strong)Llama2-70B with (weak) Aligner-13B's supervision, we can improve Llama2 by 8.2%in helpfulness and 61.6% in harmlessness. See our dataset and code athttps://aligner2024.github.io</description><author>Jiaming Ji, Boyuan Chen, Hantao Lou, Donghai Hong, Borong Zhang, Xuehai Pan, Juntao Dai, Yaodong Yang</author><pubDate>Tue, 06 Feb 2024 18:02:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02416v2</guid></item><item><title>Graph of Thoughts: Solving Elaborate Problems with Large Language Models</title><link>http://arxiv.org/abs/2308.09687v4</link><description>We introduce Graph of Thoughts (GoT): a framework that advances promptingcapabilities in large language models (LLMs) beyond those offered by paradigmssuch as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primaryadvantage of GoT is the ability to model the information generated by an LLM asan arbitrary graph, where units of information ("LLM thoughts") are vertices,and edges correspond to dependencies between these vertices. This approachenables combining arbitrary LLM thoughts into synergistic outcomes, distillingthe essence of whole networks of thoughts, or enhancing thoughts using feedbackloops. We illustrate that GoT offers advantages over state of the art ondifferent tasks, for example increasing the quality of sorting by 62% over ToT,while simultaneously reducing costs by &gt;31%. We ensure that GoT is extensiblewith new thought transformations and thus can be used to spearhead newprompting schemes. This work brings the LLM reasoning closer to human thinkingor brain mechanisms such as recurrence, both of which form complex networks.</description><author>Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler</author><pubDate>Tue, 06 Feb 2024 18:00:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09687v4</guid></item><item><title>Human-Like Geometric Abstraction in Large Pre-trained Neural Networks</title><link>http://arxiv.org/abs/2402.04203v1</link><description>Humans possess a remarkable capacity to recognize and manipulate abstractstructure, which is especially apparent in the domain of geometry. Recentresearch in cognitive science suggests neural networks do not share thiscapacity, concluding that human geometric abilities come from discrete symbolicstructure in human mental representations. However, progress in artificialintelligence (AI) suggests that neural networks begin to demonstrate morehuman-like reasoning after scaling up standard architectures in both model sizeand amount of training data. In this study, we revisit empirical results incognitive science on geometric visual processing and identify three key biasesin geometric visual processing: a sensitivity towards complexity, regularity,and the perception of parts and relations. We test tasks from the literaturethat probe these biases in humans and find that large pre-trained neuralnetwork models used in AI demonstrate more human-like abstract geometricprocessing.</description><author>Declan Campbell, Sreejan Kumar, Tyler Giallanza, Thomas L. Griffiths, Jonathan D. Cohen</author><pubDate>Tue, 06 Feb 2024 17:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04203v1</guid></item><item><title>Provably Efficient UCB-type Algorithms For Learning Predictive State Representations</title><link>http://arxiv.org/abs/2307.00405v3</link><description>The general sequential decision-making problem, which includes Markovdecision processes (MDPs) and partially observable MDPs (POMDPs) as specialcases, aims at maximizing a cumulative reward by making a sequence of decisionsbased on a history of observations and actions over time. Recent studies haveshown that the sequential decision-making problem is statistically learnable ifit admits a low-rank structure modeled by predictive state representations(PSRs). Despite these advancements, existing approaches typically involveoracles or steps that are computationally intractable. On the other hand, theupper confidence bound (UCB) based approaches, which have served successfullyas computationally efficient methods in bandits and MDPs, have not beeninvestigated for more general PSRs, due to the difficulty of optimistic bonusdesign in these more challenging settings. This paper proposes the first knownUCB-type approach for PSRs, featuring a novel bonus term that upper bounds thetotal variation distance between the estimated and true models. We furthercharacterize the sample complexity bounds for our designed UCB-type algorithmsfor both online and offline PSRs. In contrast to existing approaches for PSRs,our UCB-type algorithms enjoy computational tractability, last-iterateguaranteed near-optimal policy, and guaranteed model accuracy.</description><author>Ruiquan Huang, Yingbin Liang, Jing Yang</author><pubDate>Tue, 06 Feb 2024 17:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00405v3</guid></item><item><title>Loci-Segmented: Improving Scene Segmentation Learning</title><link>http://arxiv.org/abs/2310.10410v3</link><description>Current slot-oriented approaches for compositional scene segmentation fromimages and videos rely on provided background information or slot assignments.We present a segmented location and identity tracking system, Loci-Segmented(Loci-s), which does not require either of this information. It learns todynamically segment scenes into interpretable background and slot-based objectencodings, separating rgb, mask, location, and depth information for each. Theresults reveal largely superior video decomposition performance in the MOVidatasets and in another established dataset collection targeting scenesegmentation. The system's well-interpretable, compositional latent encodingsmay serve as a foundation model for downstream tasks.</description><author>Manuel Traub, Frederic Becker, Adrian Sauter, Sebastian Otte, Martin V. Butz</author><pubDate>Tue, 06 Feb 2024 17:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10410v3</guid></item><item><title>TopoX: A Suite of Python Packages for Machine Learning on Topological Domains</title><link>http://arxiv.org/abs/2402.02441v2</link><description>We introduce topox, a Python software suite that provides reliable anduser-friendly building blocks for computing and machine learning on topologicaldomains that extend graphs: hypergraphs, simplicial, cellular, path andcombinatorial complexes. topox consists of three packages: toponetx facilitatesconstructing and computing on these domains, including working with nodes,edges and higher-order cells; topoembedx provides methods to embed topologicaldomains into vector spaces, akin to popular graph-based embedding algorithmssuch as node2vec; topomodelx is built on top of PyTorch and offers acomprehensive toolbox of higher-order message passing functions for neuralnetworks on topological domains. The extensively documented and unit-testedsource code of topox is available under MIT license athttps://github.com/pyt-team.</description><author>Mustafa Hajij, Mathilde Papillon, Florian Frantzen, Jens Agerberg, Ibrahem AlJabea, Ruben Ballester, Claudio Battiloro, Guillermo Bernárdez, Tolga Birdal, Aiden Brent, Peter Chin, Sergio Escalera, Odin Hoff Gardaa, Gurusankar Gopalakrishnan, Devendra Govil, Josef Hoppe, Maneel Reddy Karri, Jude Khouja, Manuel Lecha, Neal Livesay, Jan Meißner, Soham Mukherjee, Alexander Nikitin, Theodore Papamarkou, Jaro Prílepok, Karthikeyan Natesan Ramamurthy, Paul Rosen, Aldo Guzmán-Sáenz, Alessandro Salatiello, Shreyas N. Samaga, Michael T. Schaub, Luca Scofano, Indro Spinelli, Lev Telyatnikov, Quang Truong, Robin Walters, Maosheng Yang, Olga Zaghen, Ghada Zamzmi, Ali Zia, Nina Miolane</author><pubDate>Tue, 06 Feb 2024 17:53:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02441v2</guid></item><item><title>CC-SGG: Corner Case Scenario Generation using Learned Scene Graphs</title><link>http://arxiv.org/abs/2309.09844v2</link><description>Corner case scenarios are an essential tool for testing and validating thesafety of autonomous vehicles (AVs). As these scenarios are ofteninsufficiently present in naturalistic driving datasets, augmenting the datawith synthetic corner cases greatly enhances the safe operation of AVs inunique situations. However, the generation of synthetic, yet realistic, cornercases poses a significant challenge. In this work, we introduce a novelapproach based on Heterogeneous Graph Neural Networks (HGNNs) to transformregular driving scenarios into corner cases. To achieve this, we first generateconcise representations of regular driving scenes as scene graphs, minimallymanipulating their structure and properties. Our model then learns to perturbthose graphs to generate corner cases using attention and triple embeddings.The input and perturbed graphs are then imported back into the simulation togenerate corner case scenarios. Our model successfully learned to producecorner cases from input scene graphs, achieving 89.9% prediction accuracy onour testing dataset. We further validate the generated scenarios on baselineautonomous driving methods, demonstrating our model's ability to effectivelycreate critical situations for the baselines.</description><author>George Drayson, Efimia Panagiotaki, Daniel Omeiza, Lars Kunze</author><pubDate>Tue, 06 Feb 2024 17:53:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09844v2</guid></item><item><title>Instance by Instance: An Iterative Framework for Multi-instance 3D Registration</title><link>http://arxiv.org/abs/2402.04195v1</link><description>Multi-instance registration is a challenging problem in computer vision androbotics, where multiple instances of an object need to be registered in astandard coordinate system. In this work, we propose the first iterativeframework called instance-by-instance (IBI) for multi-instance 3D registration(MI-3DReg). It successively registers all instances in a given scenario,starting from the easiest and progressing to more challenging ones. Throughoutthe iterative process, outliers are eliminated continuously, leading to anincreasing inlier rate for the remaining and more challenging instances. Underthe IBI framework, we further propose a sparse-to-dense-correspondence-basedmulti-instance registration method (IBI-S2DC) to achieve robust MI-3DReg.Experiments on the synthetic and real datasets have demonstrated theeffectiveness of IBI and suggested the new state-of-the-art performance ofIBI-S2DC, e.g., our MHF1 is 12.02%/12.35% higher than the existingstate-of-the-art method ECC on the synthetic/real datasets.</description><author>Xinyue Cao, Xiyu Zhang, Yuxin Cheng, Zhaoshuai Qi, Yanning Zhang, Jiaqi Yang</author><pubDate>Tue, 06 Feb 2024 17:50:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04195v1</guid></item><item><title>Contrastive Diffuser: Planning Towards High Return States via Contrastive Learning</title><link>http://arxiv.org/abs/2402.02772v2</link><description>Applying diffusion models in reinforcement learning for long-term planninghas gained much attention recently. Several diffusion-based methods havesuccessfully leveraged the modeling capabilities of diffusion for arbitrarydistributions. These methods generate subsequent trajectories for planning andhave demonstrated significant improvement. However, these methods are limitedby their plain base distributions and their overlooking of the diversity ofsamples, in which different states have different returns. They simply leveragediffusion to learn the distribution of offline dataset, generate thetrajectories whose states share the same distribution with the offline dataset.As a result, the probability of these models reaching the high-return states islargely dependent on the dataset distribution. Even equipped with the guidancemodel, the performance is still suppressed. To address these limitations, inthis paper, we propose a novel method called CDiffuser, which devises a returncontrast mechanism to pull the states in generated trajectories towardshigh-return states while pushing them away from low-return states to improvethe base distribution. Experiments on 14 commonly used D4RL benchmarksdemonstrate the effectiveness of our proposed method.</description><author>Yixiang Shan, Zhengbang Zhu, Ting Long, Qifan Liang, Yi Chang, Weinan Zhang, Liang Yin</author><pubDate>Tue, 06 Feb 2024 17:49:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02772v2</guid></item><item><title>Gradient Coding in Decentralized Learning for Evading Stragglers</title><link>http://arxiv.org/abs/2402.04193v1</link><description>In this paper, we consider a decentralized learning problem in the presenceof stragglers. Although gradient coding techniques have been developed fordistributed learning to evade stragglers, where the devices send encodedgradients with redundant training data, it is difficult to apply thosetechniques directly to decentralized learning scenarios. To deal with thisproblem, we propose a new gossip-based decentralized learning method withgradient coding (GOCO). In the proposed method, to avoid the negative impact ofstragglers, the parameter vectors are updated locally using encoded gradientsbased on the framework of stochastic gradient coding and then averaged in agossip-based manner. We analyze the convergence performance of GOCO forstrongly convex loss functions. And we also provide simulation results todemonstrate the superiority of the proposed method in terms of learningperformance compared with the baseline methods.</description><author>Chengxi Li, Mikael Skoglund</author><pubDate>Tue, 06 Feb 2024 17:49:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04193v1</guid></item><item><title>Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI</title><link>http://arxiv.org/abs/2402.00809v2</link><description>In the current landscape of deep learning research, there is a predominantemphasis on achieving high predictive accuracy in supervised tasks involvinglarge image and language datasets. However, a broader perspective reveals amultitude of overlooked metrics, tasks, and data types, such as uncertainty,active and continual learning, and scientific data, that demand attention.Bayesian deep learning (BDL) constitutes a promising avenue, offeringadvantages across these diverse settings. This paper posits that BDL canelevate the capabilities of deep learning. It revisits the strengths of BDL,acknowledges existing challenges, and highlights some exciting research avenuesaimed at addressing these obstacles. Looking ahead, the discussion focuses onpossible ways to combine large-scale foundation models with BDL to unlock theirfull potential.</description><author>Theodore Papamarkou, Maria Skoularidou, Konstantina Palla, Laurence Aitchison, Julyan Arbel, David Dunson, Maurizio Filippone, Vincent Fortuin, Philipp Hennig, Jose Miguel Hernandez Lobato, Aliaksandr Hubin, Alexander Immer, Theofanis Karaletsos, Mohammad Emtiyaz Khan, Agustinus Kristiadi, Yingzhen Li, Stephan Mandt, Christopher Nemeth, Michael A. Osborne, Tim G. J. Rudner, David Rügamer, Yee Whye Teh, Max Welling, Andrew Gordon Wilson, Ruqi Zhang</author><pubDate>Tue, 06 Feb 2024 17:48:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00809v2</guid></item><item><title>ViT-DD: Multi-Task Vision Transformer for Semi-Supervised Driver Distraction Detection</title><link>http://arxiv.org/abs/2209.09178v4</link><description>Ensuring traffic safety and mitigating accidents in modern driving is ofparamount importance, and computer vision technologies have the potential tosignificantly contribute to this goal. This paper presents a multi-modal VisionTransformer for Driver Distraction Detection (termed ViT-DD), whichincorporates inductive information from training signals related to bothdistraction detection and driver emotion recognition. Additionally, aself-learning algorithm is developed, allowing for the seamless integration ofdriver data without emotion labels into the multi-task training process ofViT-DD. Experimental results reveal that the proposed ViT-DD surpasses existingstate-of-the-art methods for driver distraction detection by 6.5% and 0.9% onthe SFDDD and AUCDD datasets, respectively.</description><author>Yunsheng Ma, Ziran Wang</author><pubDate>Tue, 06 Feb 2024 17:48:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.09178v4</guid></item><item><title>Reinforcement Learning with Ensemble Model Predictive Safety Certification</title><link>http://arxiv.org/abs/2402.04182v1</link><description>Reinforcement learning algorithms need exploration to learn. However,unsupervised exploration prevents the deployment of such algorithms onsafety-critical tasks and limits real-world deployment. In this paper, wepropose a new algorithm called Ensemble Model Predictive Safety Certificationthat combines model-based deep reinforcement learning with tube-based modelpredictive control to correct the actions taken by a learning agent, keepingsafety constraint violations at a minimum through planning. Our approach aimsto reduce the amount of prior knowledge about the actual system by requiringonly offline data generated by a safe controller. Our results show that we canachieve significantly fewer constraint violations than comparable reinforcementlearning methods.</description><author>Sven Gronauer, Tom Haider, Felippe Schmoeller da Roza, Klaus Diepold</author><pubDate>Tue, 06 Feb 2024 17:42:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04182v1</guid></item><item><title>Conditional Optimal Transport on Function Spaces</title><link>http://arxiv.org/abs/2311.05672v3</link><description>We present a systematic study of conditional triangular transport maps infunction spaces from the perspective of optimal transportation and with a viewtowards amortized Bayesian inference. More specifically, we develop a theory ofconstrained optimal transport problems that describe block-triangular Mongemaps that characterize conditional measures along with their Kantorovichrelaxations. This generalizes the theory of optimal triangular transport toseparable infinite-dimensional function spaces with general cost functions. Wefurther tailor our results to the case of Bayesian inference problems andobtain regularity estimates on the conditioning maps from the prior to theposterior. Finally, we present numerical experiments that demonstrate thecomputational applicability of our theoretical results for amortized andlikelihood-free inference of functional parameters.</description><author>Bamdad Hosseini, Alexander W. Hsu, Amirhossein Taghvaei</author><pubDate>Tue, 06 Feb 2024 17:37:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05672v3</guid></item><item><title>SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models</title><link>http://arxiv.org/abs/2402.04178v1</link><description>Multimodal large language models (MLLMs) have demonstrated remarkableproblem-solving capabilities in various vision fields (e.g., generic objectrecognition and grounding) based on strong visual semantic representation andlanguage reasoning ability. However, whether MLLMs are sensitive to subtlevisual spoof/forged clues and how they perform in the domain of face attackdetection (e.g., face spoofing and forgery detection) is still unexplored. Inthis paper, we introduce a new benchmark, namely SHIELD, to evaluate theability of MLLMs on face spoofing and forgery detection. Specifically, wedesign true/false and multiple-choice questions to evaluate multimodal facedata in these two face security tasks. For the face anti-spoofing task, weevaluate three different modalities (i.e., RGB, infrared, depth) under fourtypes of presentation attacks (i.e., print attack, replay attack, rigid mask,paper mask). For the face forgery detection task, we evaluate GAN-based anddiffusion-based data with both visual and acoustic modalities. Each question issubjected to both zero-shot and few-shot tests under standard and chain ofthought (COT) settings. The results indicate that MLLMs hold substantialpotential in the face security domain, offering advantages over traditionalspecific models in terms of interpretability, multimodal flexible reasoning,and joint face spoof and forgery detection. Additionally, we develop a novelMulti-Attribute Chain of Thought (MA-COT) paradigm for describing and judgingvarious task-specific and task-irrelevant attributes of face images, whichprovides rich task-related knowledge for subtle spoof/forged clue mining.Extensive experiments in separate face anti-spoofing, separate face forgerydetection, and joint detection tasks demonstrate the effectiveness of theproposed MA-COT. The project is available athttps$:$//github.com/laiyingxin2/SHIELD</description><author>Yichen Shi, Yuhao Gao, Yingxin Lai, Hongyang Wang, Jun Feng, Lei He, Jun Wan, Changsheng Chen, Zitong Yu, Xiaochun Cao</author><pubDate>Tue, 06 Feb 2024 17:31:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04178v1</guid></item><item><title>Scaling Laws for Downstream Task Performance of Large Language Models</title><link>http://arxiv.org/abs/2402.04177v1</link><description>Scaling laws provide important insights that can guide the design of largelanguage models (LLMs). Existing work has primarily focused on studying scalinglaws for pretraining (upstream) loss. However, in transfer learning settings,in which LLMs are pretrained on an unsupervised dataset and then finetuned on adownstream task, we often also care about the downstream performance. In thiswork, we study the scaling behavior in a transfer learning setting, where LLMsare finetuned for machine translation tasks. Specifically, we investigate howthe choice of the pretraining data and its size affect downstream performance(translation quality) as judged by two metrics: downstream cross-entropy andBLEU score. Our experiments indicate that the size of the finetuning datasetand the distribution alignment between the pretraining and downstream datasignificantly influence the scaling behavior. With sufficient alignment, bothdownstream cross-entropy and BLEU score improve monotonically with morepretraining data. In such cases, we show that it is possible to predict thedownstream BLEU score with good accuracy using a log-law. However, there arealso cases where moderate misalignment causes the BLEU score to fluctuate orget worse with more pretraining, whereas downstream cross-entropy monotonicallyimproves. By analyzing these observations, we provide new practical insightsfor choosing appropriate pretraining data.</description><author>Berivan Isik, Natalia Ponomareva, Hussein Hazimeh, Dimitris Paparas, Sergei Vassilvitskii, Sanmi Koyejo</author><pubDate>Tue, 06 Feb 2024 17:31:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04177v1</guid></item><item><title>COPS: A Compact On-device Pipeline for real-time Smishing detection</title><link>http://arxiv.org/abs/2402.04173v1</link><description>Smartphones have become indispensable in our daily lives and can do almosteverything, from communication to online shopping. However, with the increasedusage, cybercrime aimed at mobile devices is rocketing. Smishing attacks, inparticular, have observed a significant upsurge in recent years. This problemis further exacerbated by the perpetrator creating new deceptive websitesdaily, with an average life cycle of under 15 hours. This renders the standardpractice of keeping a database of malicious URLs ineffective. To this end, wepropose a novel on-device pipeline: COPS that intelligently identifies featuresof fraudulent messages and URLs to alert the user in real-time. COPS is alightweight pipeline with a detection module based on the DisentangledVariational Autoencoder of size 3.46MB for smishing and URL phishing detection,and we benchmark it on open datasets. We achieve an accuracy of 98.15% and99.5%, respectively, for both tasks, with a false negative and false positiverate of a mere 0.037 and 0.015, outperforming previous works with the addedadvantage of ensuring real-time alerts on resource-constrained devices.</description><author>Harichandana B S S, Sumit Kumar, Manjunath Bhimappa Ujjinakoppa, Barath Raj Kandur Raja</author><pubDate>Tue, 06 Feb 2024 17:27:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04173v1</guid></item><item><title>3D Volumetric Super-Resolution in Radiology Using 3D RRDB-GAN</title><link>http://arxiv.org/abs/2402.04171v1</link><description>This study introduces the 3D Residual-in-Residual Dense Block GAN (3DRRDB-GAN) for 3D super-resolution for radiology imagery. A key aspect of 3DRRDB-GAN is the integration of a 2.5D perceptual loss function, whichcontributes to improved volumetric image quality and realism. The effectivenessof our model was evaluated through 4x super-resolution experiments acrossdiverse datasets, including Mice Brain MRH, OASIS, HCP1200, and MSD-Task-6.These evaluations, encompassing both quantitative metrics like LPIPS and FIDand qualitative assessments through sample visualizations, demonstrate themodels effectiveness in detailed image analysis. The 3D RRDB-GAN offers asignificant contribution to medical imaging, particularly by enriching thedepth, clarity, and volumetric detail of medical images. Its application showspromise in enhancing the interpretation and analysis of complex medical imageryfrom a comprehensive 3D perspective.</description><author>Juhyung Ha, Nian Wang, Surendra Maharjan, Xuhong Zhang</author><pubDate>Tue, 06 Feb 2024 17:26:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04171v1</guid></item><item><title>Informed Reinforcement Learning for Situation-Aware Traffic Rule Exceptions</title><link>http://arxiv.org/abs/2402.04168v1</link><description>Reinforcement Learning is a highly active research field with promisingadvancements. In the field of autonomous driving, however, often very simplescenarios are being examined. Common approaches use non-interpretable controlcommands as the action space and unstructured reward designs which lackstructure. In this work, we introduce Informed Reinforcement Learning, where astructured rulebook is integrated as a knowledge source. We learn trajectoriesand asses them with a situation-aware reward design, leading to a dynamicreward which allows the agent to learn situations which require controlledtraffic rule exceptions. Our method is applicable to arbitrary RL models. Wesuccessfully demonstrate high completion rates of complex scenarios with recentmodel-based agents.</description><author>Daniel Bogdoll, Jing Qin, Moritz Nekolla, Ahmed Abouelazm, Tim Joseph, J. Marius Zöllner</author><pubDate>Tue, 06 Feb 2024 17:24:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04168v1</guid></item><item><title>Tempered Calculus for ML: Application to Hyperbolic Model Embedding</title><link>http://arxiv.org/abs/2402.04163v1</link><description>Most mathematical distortions used in ML are fundamentally integral innature: $f$-divergences, Bregman divergences, (regularized) optimal transportdistances, integral probability metrics, geodesic distances, etc. In thispaper, we unveil a grounded theory and tools which can help improve thesedistortions to better cope with ML requirements. We start with a generalizationof Riemann integration that also encapsulates functions that are not strictlyadditive but are, more generally, $t$-additive, as in nonextensive statisticalmechanics. Notably, this recovers Volterra's product integral as a specialcase. We then generalize the Fundamental Theorem of calculus using an extensionof the (Euclidean) derivative. This, along with a series of more specificTheorems, serves as a basis for results showing how one can specificallydesign, alter, or change fundamental properties of distortion measures in asimple way, with a special emphasis on geometric- and ML-related propertiesthat are the metricity, hyperbolicity, and encoding. We show how to apply it toa problem that has recently gained traction in ML: hyperbolic embeddings with a"cheap" and accurate encoding along the hyperbolic vs Euclidean scale. Weunveil a new application for which the Poincar\'e disk model has very appealingfeatures, and our theory comes in handy: \textit{model} embeddings for boostedcombinations of decision trees, trained using the log-loss (trees) and logisticloss (combinations).</description><author>Richard Nock, Ehsan Amid, Frank Nielsen, Alexander Soen, Manfred K. Warmuth</author><pubDate>Tue, 06 Feb 2024 17:21:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04163v1</guid></item><item><title>Attention with Markov: A Framework for Principled Analysis of Transformers via Markov Chains</title><link>http://arxiv.org/abs/2402.04161v1</link><description>In recent years, attention-based transformers have achieved tremendoussuccess across a variety of disciplines including natural languages. A keyingredient behind their success is the generative pretraining procedure, duringwhich these models are trained on a large text corpus in an auto-regressivemanner. To shed light on this phenomenon, we propose a new framework thatallows both theory and systematic experiments to study the sequential modelingcapabilities of transformers through the lens of Markov chains. Inspired by theMarkovianity of natural languages, we model the data as a Markovian source andutilize this framework to systematically study the interplay between thedata-distributional properties, the transformer architecture, the learntdistribution, and the final model performance. In particular, we theoreticallycharacterize the loss landscape of single-layer transformers and show theexistence of global minima and bad local minima contingent upon the specificdata characteristics and the transformer architecture. Backed by experiments,we demonstrate that our theoretical findings are in congruence with theempirical results. We further investigate these findings in the broader contextof higher order Markov chains and deeper architectures, and outline openproblems in this arena. Code is available at\url{https://github.com/Bond1995/Markov}.</description><author>Ashok Vardhan Makkuva, Marco Bondaschi, Adway Girish, Alliot Nagle, Martin Jaggi, Hyeji Kim, Michael Gastpar</author><pubDate>Tue, 06 Feb 2024 17:18:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04161v1</guid></item><item><title>Harnessing the Plug-and-Play Controller by Prompting</title><link>http://arxiv.org/abs/2402.04160v1</link><description>Controllable text generation is a growing field within natural languagegeneration (NLG) that focuses on producing text that meets specific constraintsin real-world applications. Previous approaches, such as plug-and-playcontrollers (PPCs), aimed to steer the properties of generated text in aflexible manner. However, these methods often compromised the integrity of thelanguage model's decoding process, resulting in less smooth text generation.Alternatively, other techniques utilized multiple attribute prompts to alignthe generated text with desired attributes, but this approach required promptdesign for each attribute and was dependent on the size of the language model.This paper introduces a novel method for flexible attribute control in textgeneration using pre-trained language models (PLMs). The proposed approach aimsto enhance the fluency of generated text by guiding the generation process withPPCs. The key idea is to dynamically adjust the distribution of generated textby modifying prompts, effectively constraining the output space of the languagemodel and influencing the desired attribute. To enable smooth cooperationbetween the PLM and the PPC, our work innovatively proposes a new modelfine-tuning method: Reinforcement Learning with Dynamic Adjust Feedback(RLDAF).This fine-tuning process adapts a small subset of the language model'sparameters based on the generating actions taken during the PPC controlprocess. The resulting harmonious collaboration between the PLM and PPC leadsto improved smoothness in text generation during inference. Extensiveexperiments were conducted on the SST2 dataset, and the proposed methodoutperformed previous approaches in various evaluation metrics, including textfluency and attribute consistency.</description><author>Hao Wang, Lei Sha</author><pubDate>Tue, 06 Feb 2024 17:18:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04160v1</guid></item><item><title>Legal Requirements Analysis: A Regulatory Compliance Perspective</title><link>http://arxiv.org/abs/2311.13871v2</link><description>Modern software has been an integral part of everyday activities in manydisciplines and application contexts. Introducing intelligent automation byleveraging artificial intelligence (AI) led to break-throughs in many fields.The effectiveness of AI can be attributed to several factors, among which isthe increasing availability of data. Regulations such as the general dataprotection regulation (GDPR) in the European Union (EU) are introduced toensure the protection of personal data. Software systems that collect, process,or share personal data are subject to compliance with such regulations.Developing compliant software depends heavily on addressing legal requirementsstipulated in applicable regulations, a central activity in the requirementsengineering (RE) phase of the software development process. RE is concernedwith specifying and maintaining requirements of a system-to-be, including legalrequirements. Legal agreements which describe the policies organizationsimplement for processing personal data can provide an additional source toregulations for eliciting legal requirements. In this chapter, we explore avariety of methods for analyzing legal requirements and exemplify them on GDPR.Specifically, we describe possible alternatives for creating machine-analyzablerepresentations from regulations, survey the existing automated means forenabling compliance verification against regulations, and further reflect onthe current challenges of legal requirements analysis.</description><author>Sallam Abualhaija, Marcello Ceci, Lionel Briand</author><pubDate>Tue, 06 Feb 2024 17:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13871v2</guid></item><item><title>Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction</title><link>http://arxiv.org/abs/2402.04154v1</link><description>Developing a generalist agent is a longstanding objective in artificialintelligence. Previous efforts utilizing extensive offline datasets fromvarious tasks demonstrate remarkable performance in multitasking scenarioswithin Reinforcement Learning.However, these works encounter challenges inextending their capabilities to new tasks.Recent approaches integrate textualguidance or visual trajectory into decision networks to provide task-specificcontextual cues, representing a promising direction.However, it is observedthat relying solely on textual guidance or visual trajectory is insufficientfor accurately conveying the contextual information of tasks.This paperexplores enhanced forms of task guidance for agents, enabling them tocomprehend gameplay instructions, thereby facilitating a "read-to-play"capability.Drawing inspiration from the success of multimodal instructiontuning in visual tasks, we treat the visual-based RL task as a long-horizonvision task and construct a set of multimodal game instructions to incorporateinstruction tuning into a decision transformer.Experimental results demonstratethat incorporating multimodal game instructions significantly enhances thedecision transformer's multitasking and generalization capabilities.</description><author>Yonggang Jin, Ge Zhang, Hao Zhao, Tianyu Zheng, Jiawei Guo, Liuyu Xiang, Shawn Yue, Stephen W. Huang, Wenhu Chen, Zhaofeng He, Jie Fu</author><pubDate>Tue, 06 Feb 2024 17:09:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04154v1</guid></item><item><title>LLM Comparative Assessment: Zero-shot NLG Evaluation through Pairwise Comparisons using Large Language Models</title><link>http://arxiv.org/abs/2307.07889v3</link><description>Current developments in large language models (LLMs) have enabled impressivezero-shot capabilities across various natural language tasks. An interestingapplication of these systems is in the automated assessment of natural languagegeneration (NLG), a highly challenging area with great practical benefit. Inthis paper, we explore two options for exploiting the emergent abilities ofLLMs for zero-shot NLG assessment: absolute score prediction, and comparativeassessment which uses relative comparisons between pairs of candidates. Thoughcomparative assessment has not been extensively studied in NLG assessment, wenote that humans often find it more intuitive to compare two options ratherthan scoring each one independently. This work examines comparative assessmentfrom multiple perspectives: performance compared to absolute grading;positional biases in the prompt; and efficient ranking in terms of the numberof comparisons. We illustrate that LLM comparative assessment is a simple,general and effective approach for NLG assessment. For moderate-sizedopen-source LLMs, such as FlanT5 and Llama2-chat, comparative assessment issuperior to prompt scoring, and in many cases can achieve performancecompetitive with state-of-the-art methods. Additionally, we demonstrate thatLLMs often exhibit strong positional biases when making pairwise comparisons,and we propose debiasing methods that can further improve performance.</description><author>Adian Liusie, Potsawee Manakul, Mark J. F. Gales</author><pubDate>Tue, 06 Feb 2024 17:05:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07889v3</guid></item><item><title>Interplay between depth and width for interpolation in neural ODEs</title><link>http://arxiv.org/abs/2401.09902v3</link><description>Neural ordinary differential equations (neural ODEs) have emerged as anatural tool for supervised learning from a control perspective, yet a completeunderstanding of their optimal architecture remains elusive. In this work, weexamine the interplay between their width $p$ and number of layer transitions$L$ (effectively the depth $L+1$). Specifically, we assess the modelexpressivity in terms of its capacity to interpolate either a finite dataset$D$ comprising $N$ pairs of points or two probability measures in$\mathbb{R}^d$ within a Wasserstein error margin $\varepsilon&gt;0$. Our findingsreveal a balancing trade-off between $p$ and $L$, with $L$ scaling as$O(1+N/p)$ for dataset interpolation, and$L=O\left(1+(p\varepsilon^d)^{-1}\right)$ for measure interpolation. In the autonomous case, where $L=0$, a separate study is required, which weundertake focusing on dataset interpolation. We address the relaxed problem of$\varepsilon$-approximate controllability and establish an error decay of$\varepsilon\sim O(\log(p)p^{-1/d})$. This decay rate is a consequence ofapplying a universal approximation theorem to a custom-built Lipschitz vectorfield that interpolates $D$. In the high-dimensional setting, we furtherdemonstrate that $p=O(N)$ neurons are likely sufficient to achieve exactcontrol.</description><author>Antonio Álvarez-López, Arselane Hadj Slimane, Enrique Zuazua</author><pubDate>Tue, 06 Feb 2024 17:05:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09902v3</guid></item><item><title>OceanGPT: A Large Language Model for Ocean Science Tasks</title><link>http://arxiv.org/abs/2310.02031v5</link><description>Ocean science, which delves into the oceans that are reservoirs of life andbiodiversity, is of great significance given that oceans cover over 70% of ourplanet's surface. Recently, advances in Large Language Models (LLMs) havetransformed the paradigm in science. Despite the success in other domains,current LLMs often fall short in catering to the needs of domain experts likeoceanographers, and the potential of LLMs for ocean science is under-explored.The intrinsic reason may be the immense and intricate nature of ocean data aswell as the necessity for higher granularity and richness in knowledge. Toalleviate these issues, we introduce OceanGPT, the first-ever LLM in the oceandomain, which is expert in various ocean science tasks. We propose DoInstruct,a novel framework to automatically obtain a large volume of ocean domaininstruction data, which generates instructions based on multi-agentcollaboration. Additionally, we construct the first oceanography benchmark,OceanBench, to evaluate the capabilities of LLMs in the ocean domain. Thoughcomprehensive experiments, OceanGPT not only shows a higher level of knowledgeexpertise for oceans science tasks but also gains preliminary embodiedintelligence capabilities in ocean technology. Codes, data and checkpoints willsoon be available at https://github.com/zjunlp/KnowLM.</description><author>Zhen Bi, Ningyu Zhang, Yida Xue, Yixin Ou, Daxiong Ji, Guozhou Zheng, Huajun Chen</author><pubDate>Tue, 06 Feb 2024 17:00:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02031v5</guid></item><item><title>Using AI Uncertainty Quantification to Improve Human Decision-Making</title><link>http://arxiv.org/abs/2309.10852v2</link><description>AI Uncertainty Quantification (UQ) has the potential to improve humandecision-making beyond AI predictions alone by providing additionalprobabilistic information to users. The majority of past research on AI andhuman decision-making has concentrated on model explainability andinterpretability, with little focus on understanding the potential impact of UQon human decision-making. We evaluated the impact on human decision-making forinstance-level UQ, calibrated using a strict scoring rule, in two onlinebehavioral experiments. In the first experiment, our results showed that UQ wasbeneficial for decision-making performance compared to only AI predictions. Inthe second experiment, we found UQ had generalizable benefits fordecision-making across a variety of representations for probabilisticinformation. These results indicate that implementing high quality,instance-level UQ for AI may improve decision-making with real systems comparedto AI predictions alone.</description><author>Laura R. Marusich, Jonathan Z. Bakdash, Yan Zhou, Murat Kantarcioglu</author><pubDate>Tue, 06 Feb 2024 16:59:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10852v2</guid></item><item><title>MI-SegNet: Mutual Information-Based US Segmentation for Unseen Domain Generalization</title><link>http://arxiv.org/abs/2303.12649v3</link><description>Generalization capabilities of learning-based medical image segmentationacross domains are currently limited by the performance degradation caused bythe domain shift, particularly for ultrasound (US) imaging. The quality of USimages heavily relies on carefully tuned acoustic parameters, which vary acrosssonographers, machines, and settings. To improve the generalizability on USimages across domains, we propose MI-SegNet, a novel mutual information (MI)based framework to explicitly disentangle the anatomical and domain featurerepresentations; therefore, robust domain-independent segmentation can beexpected. Two encoders are employed to extract the relevant features for thedisentanglement. The segmentation only uses the anatomical feature map for itsprediction. In order to force the encoders to learn meaningful featurerepresentations a cross-reconstruction method is used during training.Transformations, specific to either domain or anatomy are applied to guide theencoders in their respective feature extraction task. Additionally, any MIpresent in both feature maps is punished to further promote separate featurespaces. We validate the generalizability of the proposed domain-independentsegmentation approach on several datasets with varying parameters and machines.Furthermore, we demonstrate the effectiveness of the proposed MI-SegNet servingas a pre-trained model by comparing it with state-of-the-art networks.</description><author>Yuan Bi, Zhongliang Jiang, Ricarda Clarenbach, Reza Ghotbi, Angelos Karlas, Nassir Navab</author><pubDate>Tue, 06 Feb 2024 16:55:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12649v3</guid></item><item><title>Interpretable Multi-Source Data Fusion Through Latent Variable Gaussian Process</title><link>http://arxiv.org/abs/2402.04146v1</link><description>With the advent of artificial intelligence (AI) and machine learning (ML),various domains of science and engineering communites has leveraged data-drivensurrogates to model complex systems from numerous sources of information(data). The proliferation has led to significant reduction in cost and timeinvolved in development of superior systems designed to perform specificfunctionalities. A high proposition of such surrogates are built extensivelyfusing multiple sources of data, may it be published papers, patents, openrepositories, or other resources. However, not much attention has been paid tothe differences in quality and comprehensiveness of the known and unknownunderlying physical parameters of the information sources that could havedownstream implications during system optimization. Towards resolving thisissue, a multi-source data fusion framework based on Latent Variable GaussianProcess (LVGP) is proposed. The individual data sources are tagged as acharacteristic categorical variable that are mapped into a physicallyinterpretable latent space, allowing the development of source-aware datafusion modeling. Additionally, a dissimilarity metric based on the latentvariables of LVGP is introduced to study and understand the differences in thesources of data. The proposed approach is demonstrated on and analyzed throughtwo mathematical (representative parabola problem, 2D Ackley function) and twomaterials science (design of FeCrAl and SmCoFe alloys) case studies. From thecase studies, it is observed that compared to using single-source and sourceunaware ML models, the proposed multi-source data fusion framework can providebetter predictions for sparse-data problems, interpretability regarding thesources, and enhanced modeling capabilities by taking advantage of thecorrelations and relationships among different sources.</description><author>Sandipp Krishnan Ravi, Yigitcan Comlek, Wei Chen, Arjun Pathak, Vipul Gupta, Rajnikant Umretiya, Andrew Hoffman, Ghanshyam Pilania, Piyush Pandita, Sayan Ghosh, Nathaniel Mckeever, Liping Wang</author><pubDate>Tue, 06 Feb 2024 16:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04146v1</guid></item><item><title>Better Batch for Deep Probabilistic Time Series Forecasting</title><link>http://arxiv.org/abs/2305.17028v3</link><description>Deep probabilistic time series forecasting has gained attention for itssuperior performance in nonlinear approximation and its capability to offervaluable uncertainty quantification for decision-making. However, existingmodels often oversimplify the problem by assuming a time-independent errorprocess, overlooking serial correlation. To overcome this limitation, wepropose an innovative training method that incorporates error autocorrelationto enhance probabilistic forecasting accuracy. Our method constructs amini-batch as a collection of $D$ consecutive time series segments for modeltraining. It explicitly learns a time-varying covariance matrix over eachmini-batch, encoding error correlation among adjacent time steps. The learnedcovariance matrix can be used to improve prediction accuracy and enhanceuncertainty quantification. We evaluate our method on two different neuralforecasting models and multiple public datasets. Experimental results confirmthe effectiveness of the proposed approach in improving the performance of bothmodels across a range of datasets, resulting in notable improvements inpredictive accuracy.</description><author>Vincent Zhihao Zheng, Seongjin Choi, Lijun Sun</author><pubDate>Tue, 06 Feb 2024 16:49:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17028v3</guid></item><item><title>Multi-line AI-assisted Code Authoring</title><link>http://arxiv.org/abs/2402.04141v1</link><description>CodeCompose is an AI-assisted code authoring tool powered by large languagemodels (LLMs) that provides inline suggestions to 10's of thousands ofdevelopers at Meta. In this paper, we present how we scaled the product fromdisplaying single-line suggestions to multi-line suggestions. This evolutionrequired us to overcome several unique challenges in improving the usability ofthese suggestions for developers. First, we discuss how multi-line suggestions can have a 'jarring' effect, asthe LLM's suggestions constantly move around the developer's existing code,which would otherwise result in decreased productivity and satisfaction. Second, multi-line suggestions take significantly longer to generate; hencewe present several innovative investments we made to reduce the perceivedlatency for users. These model-hosting optimizations sped up multi-linesuggestion latency by 2.5x. Finally, we conduct experiments on 10's of thousands of engineers tounderstand how multi-line suggestions impact the user experience and contrastthis with single-line suggestions. Our experiments reveal that (i) multi-linesuggestions account for 42% of total characters accepted (despite onlyaccounting for 16% for displayed suggestions) (ii) multi-line suggestionsalmost doubled the percentage of keystrokes saved for users from 9% to 17%.Multi-line CodeCompose has been rolled out to all engineers at Meta, and lessthan 1% of engineers have opted out of multi-line suggestions.</description><author>Omer Dunay, Daniel Cheng, Adam Tait, Parth Thakkar, Peter C Rigby, Andy Chiu, Imad Ahmad, Arun Ganesan, Chandra Maddila, Vijayaraghavan Murali, Ali Tayyebi, Nachiappan Nagappan</author><pubDate>Tue, 06 Feb 2024 16:48:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04141v1</guid></item><item><title>Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)</title><link>http://arxiv.org/abs/2402.04140v1</link><description>This study consists of a novel approach toward the analysis of courtjudgments spanning five countries, including the United States, the UnitedKingdom, Rwanda, Sweden and Hong Kong. This study also explores theintersection of the latest advancements in artificial intelligence (AI) andlegal analysis, emphasizing the role of AI (specifically generative AI) inidentifying human biases and facilitating automated, valid, and coherentmultisided argumentation of court judgments with the goal of ensuringconsistent application of laws in and across various jurisdictions. Byincorporating Advanced Language Models (ALMs) and a newly introduced human-AIcollaborative framework, this paper seeks to analyze Grounded Theory-basedresearch design with Advanced Language Models (ALMs) in the practice of law.SHIRLEY is the name of the AI-based application (built on top of OpenAI's GPTtechnology), focusing on detecting logical inconsistencies and biases acrossvarious legal decisions. SHIRLEY analysis is aggregated and is accompanied by acomparison-oriented AI-based application called SAM (also an ALM) to identifyrelative deviations in SHIRLEY bias detections. Further, a CRITIC is generatedwithin semi-autonomous arbitration process via the ALM, SARA. A novel approachis introduced in the utilization of an AI arbitrator to critically evaluatebiases and qualitative-in-nature nuances identified by the aforementioned AIapplications (SAM in concert with SHIRLEY), based on the Hague Rules onBusiness and Human Rights Arbitration. This Semi-Automated Arbitration Process(SAAP) aims to uphold the integrity and fairness of legal judgments by ensuringa nuanced debate-resultant "understanding" through a hybrid system of AI andhuman-based collaborative analysis.</description><author>Michael De'Shazer</author><pubDate>Tue, 06 Feb 2024 16:47:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04140v1</guid></item><item><title>U-shaped Vision Mamba for Single Image Dehazing</title><link>http://arxiv.org/abs/2402.04139v1</link><description>Currently, Transformer is the most popular architecture for image dehazing,but due to its large computational complexity, its ability to handle long-rangedependency is limited on resource-constrained devices. To tackle thischallenge, we introduce the U-shaped Vision Mamba (UVM-Net), an efficientsingle-image dehazing network. Inspired by the State Space Sequence Models(SSMs), a new deep sequence model known for its power to handle long sequences,we design a Bi-SSM block that integrates the local feature extraction abilityof the convolutional layer with the ability of the SSM to capture long-rangedependencies. Extensive experimental results demonstrate the effectiveness ofour method. Our method provides a more highly efficient idea of long-rangedependency modeling for image dehazing as well as other image restorationtasks. The URL of the code is \url{https://github.com/zzr-idam}.</description><author>Zhuoran Zheng, Chen Wu</author><pubDate>Tue, 06 Feb 2024 16:46:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04139v1</guid></item><item><title>Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware Direct Preference Optimization</title><link>http://arxiv.org/abs/2311.16839v2</link><description>Multimodal large language models have made significant advancements in recentyears, yet they still suffer from a common issue known as the "hallucinationproblem", in which the models generate textual descriptions that inaccuratelydepict or entirely fabricate content from associated images. This paperintroduces a novel solution, Hallucination-Aware Direct Preference Optimization(HA-DPO), which reframes the hallucination problem as a preference selectiontask. The model is trained to favor the non-hallucinating response whenpresented with two responses of the same image (one accurate and onehallucinatory). Furthermore, this paper proposes an efficient pipeline forconstructing positive~(non-hallucinatory) and negative~(hallucinatory) samplepairs, ensuring a high-quality, style-consistent dataset for robust preferencelearning. When applied to three mainstream multimodal models, HA-DPOsignificantly reduced hallucination issues and amplified the models'generalization capabilities. Notably, the MiniGPT-4 model, when enhanced withHA-DPO, demonstrated a substantial improvement: POPE accuracy rose from 51.13%to 86.13% (an absolute improvement of 35%), and the MME score surged from932.00 to 1326.46 (a relative improvement of 42.32%). The codes, models, anddatasets are made accessible at https://opendatalab.github.io/HA-DPO.</description><author>Zhiyuan Zhao, Bin Wang, Linke Ouyang, Xiaoyi Dong, Jiaqi Wang, Conghui He</author><pubDate>Tue, 06 Feb 2024 16:43:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16839v2</guid></item><item><title>Towards Principled Graph Transformers</title><link>http://arxiv.org/abs/2401.10119v2</link><description>Graph learning architectures based on the k-dimensional Weisfeiler-Leman(k-WL) hierarchy offer a theoretically well-understood expressive power.However, such architectures often fail to deliver solid predictive performanceon real-world tasks, limiting their practical impact. In contrast, globalattention-based models such as graph transformers demonstrate strongperformance in practice, but comparing their expressive power with the k-WLhierarchy remains challenging, particularly since these architectures rely onpositional or structural encodings for their expressivity and predictiveperformance. To address this, we show that the recently proposed EdgeTransformer, a global attention model operating on node pairs instead of nodes,has at least 3-WL expressive power. Empirically, we demonstrate that the EdgeTransformer surpasses other theoretically aligned architectures regardingpredictive performance while not relying on positional or structural encodings.</description><author>Luis Müller, Daniel Kusuma, Christopher Morris</author><pubDate>Tue, 06 Feb 2024 16:36:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10119v2</guid></item><item><title>Language Model Training Paradigms for Clinical Feature Embeddings</title><link>http://arxiv.org/abs/2311.00768v2</link><description>In research areas with scarce data, representation learning plays asignificant role. This work aims to enhance representation learning forclinical time series by deriving universal embeddings for clinical features,such as heart rate and blood pressure. We use self-supervised trainingparadigms for language models to learn high-quality clinical featureembeddings, achieving a finer granularity than existing time-step andpatient-level representation learning. We visualize the learnt embeddings viaunsupervised dimension reduction techniques and observe a high degree ofconsistency with prior clinical knowledge. We also evaluate the modelperformance on the MIMIC-III benchmark and demonstrate the effectiveness ofusing clinical feature embeddings. We publish our code online for replication.</description><author>Yurong Hu, Manuel Burger, Gunnar Rätsch, Rita Kuznetsova</author><pubDate>Tue, 06 Feb 2024 16:33:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00768v2</guid></item><item><title>Critical Data Size of Language Models from a Grokking Perspective</title><link>http://arxiv.org/abs/2401.10463v2</link><description>We explore the critical data size in language models, a threshold that marksa fundamental shift from quick memorization to slow generalization. Weformalize the phase transition under the grokking configuration into the DataEfficiency Hypothesis and identify data insufficiency, sufficiency, and surplusregimes in language models training dynamics. We develop a grokkingconfiguration to reproduce grokking on simplistic language models stably byrescaling initialization and weight decay. We show that generalization occursonly when language models reach a critical size. We analyze grokking acrosssample-wise and model-wise, verifying the proposed data efficiency hypothesis.Our experiments reveal smoother phase transitions occurring at the criticaldataset size for language datasets. As the model size increases, this criticalpoint also becomes larger, indicating that larger models require more data. Ourresults deepen the understanding of language model training, offering a novelperspective on the role of data in the learning mechanism of language models.</description><author>Xuekai Zhu, Yao Fu, Bowen Zhou, Zhouhan Lin</author><pubDate>Tue, 06 Feb 2024 16:32:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10463v2</guid></item><item><title>OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning</title><link>http://arxiv.org/abs/2402.04129v1</link><description>Recent works have shown that by using large pre-trained models along withlearnable prompts, rehearsal-free methods for class-incremental learning (CIL)settings can achieve superior performance to prominent rehearsal-based ones.Rehearsal-free CIL methods struggle with distinguishing classes from differenttasks, as those are not trained together. In this work we propose aregularization method based on virtual outliers to tighten decision boundariesof the classifier, such that confusion of classes among different tasks ismitigated. Recent prompt-based methods often require a pool of task-specificprompts, in order to prevent overwriting knowledge of previous tasks with thatof the new task, leading to extra computation in querying and composing anappropriate prompt from the pool. This additional cost can be eliminated,without sacrificing accuracy, as we reveal in the paper. We illustrate that asimplified prompt-based method can achieve results comparable to previousstate-of-the-art (SOTA) methods equipped with a prompt pool, using much lesslearnable parameters and lower inference cost. Our regularization method hasdemonstrated its compatibility with different prompt-based methods, boostingthose previous SOTA rehearsal-free CIL methods' accuracy on the ImageNet-R andCIFAR-100 benchmarks. Our source code is available athttps://github.com/jpmorganchase/ovor.</description><author>Wei-Cheng Huang, Chun-Fu Chen, Hsiang Hsu</author><pubDate>Tue, 06 Feb 2024 16:31:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04129v1</guid></item><item><title>Building Open-Ended Embodied Agent via Language-Policy Bidirectional Adaptation</title><link>http://arxiv.org/abs/2401.00006v3</link><description>Building embodied agents on integrating Large Language Models (LLMs) andReinforcement Learning (RL) have revolutionized human-AI interaction:researchers can now leverage language instructions to plan decision-making foropen-ended tasks. However, existing research faces challenges in meeting therequirement of open-endedness. They typically either train LLM/RL models toadapt to a fixed counterpart, limiting exploration of novel skills andhindering the efficacy of human-AI interaction. To this end, we presentOpenPAL, a co-training framework comprising two stages: (1) fine-tuning apre-trained LLM to translate human instructions into goals for planning, andgoal-conditioned training a policy for decision-making; (2) co-training toalign the LLM and policy, achieving instruction open-endedness. We conductedexperiments using Contra, an open-ended FPS game, demonstrating that an agenttrained with OpenPAL not only comprehends arbitrary instructions but alsoexhibits efficient execution. These results suggest that OpenPAL holds thepotential to construct open-ended embodied agents in practical scenarios.</description><author>Shaopeng Zhai, Jie Wang, Tianyi Zhang, Fuxian Huang, Qi Zhang, Ming Zhou, Jing Hou, Yu Qiao, Yu Liu</author><pubDate>Tue, 06 Feb 2024 16:30:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00006v3</guid></item><item><title>AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection</title><link>http://arxiv.org/abs/2310.18961v5</link><description>Zero-shot anomaly detection (ZSAD) requires detection models trained usingauxiliary data to detect anomalies without any training sample in a targetdataset. It is a crucial task when training data is not accessible due tovarious concerns, eg, data privacy, yet it is challenging since the models needto generalize to anomalies across different domains where the appearance offoreground objects, abnormal regions, and background features, such asdefects/tumors on different products/organs, can vary significantly. Recentlylarge pre-trained vision-language models (VLMs), such as CLIP, havedemonstrated strong zero-shot recognition ability in various vision tasks,including anomaly detection. However, their ZSAD performance is weak since theVLMs focus more on modeling the class semantics of the foreground objectsrather than the abnormality/normality in the images. In this paper we introducea novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD acrossdifferent domains. The key insight of AnomalyCLIP is to learn object-agnostictext prompts that capture generic normality and abnormality in an imageregardless of its foreground objects. This allows our model to focus on theabnormal image regions rather than the object semantics, enabling generalizednormality and abnormality recognition on diverse types of objects. Large-scaleexperiments on 17 real-world anomaly detection datasets show that AnomalyCLIPachieves superior zero-shot performance of detecting and segmenting anomaliesin datasets of highly diverse class semantics from various defect inspectionand medical imaging domains. Code will be made available athttps://github.com/zqhang/AnomalyCLIP.</description><author>Qihang Zhou, Guansong Pang, Yu Tian, Shibo He, Jiming Chen</author><pubDate>Tue, 06 Feb 2024 16:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18961v5</guid></item><item><title>Scientific Language Modeling: A Quantitative Review of Large Language Models in Molecular Science</title><link>http://arxiv.org/abs/2402.04119v1</link><description>Efficient molecular modeling and design are crucial for the discovery andexploration of novel molecules, and the incorporation of deep learning methodshas revolutionized this field. In particular, large language models (LLMs)offer a fresh approach to tackle scientific problems from a natural languageprocessing (NLP) perspective, introducing a research paradigm called scientificlanguage modeling (SLM). However, two key issues remain: how to quantify thematch between model and data modalities and how to identify theknowledge-learning preferences of models. To address these challenges, wepropose a multi-modal benchmark, named ChEBI-20-MM, and perform 1263experiments to assess the model's compatibility with data modalities andknowledge acquisition. Through the modal transition probability matrix, weprovide insights into the most suitable modalities for tasks. Furthermore, weintroduce a statistically interpretable approach to discover context-specificknowledge mapping by localized feature filtering. Our pioneering analysisoffers an exploration of the learning mechanism and paves the way for advancingSLM in molecular science.</description><author>Pengfei Liu, Jun Tao, Zhixiang Ren</author><pubDate>Tue, 06 Feb 2024 16:12:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04119v1</guid></item><item><title>GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting</title><link>http://arxiv.org/abs/2402.01459v2</link><description>In recent years, a range of neural network-based methods for image renderinghave been introduced. For instance, widely-researched neural radiance fields(NeRF) rely on a neural network to represent 3D scenes, allowing for realisticview synthesis from a small number of 2D images. However, most NeRF models areconstrained by long training and inference times. In comparison, GaussianSplatting (GS) is a novel, state-of-theart technique for rendering points in a3D scene by approximating their contribution to image pixels through Gaussiandistributions, warranting fast training and swift, real-time rendering. Adrawback of GS is the absence of a well-defined approach for its conditioningdue to the necessity to condition several hundred thousand Gaussian components.To solve this, we introduce Gaussian Mesh Splatting (GaMeS) model, a hybrid ofmesh and a Gaussian distribution, that pin all Gaussians splats on the objectsurface (mesh). The unique contribution of our methods is defining Gaussiansplats solely based on their location on the mesh, allowing for automaticadjustments in position, scale, and rotation during animation. As a result, weobtain high-quality renders in the real-time generation of high-quality views.Furthermore, we demonstrate that in the absence of a predefined mesh, it ispossible to fine-tune the initial mesh during the learning process.</description><author>Joanna Waczyńska, Piotr Borycki, Sławomir Tadeja, Jacek Tabor, Przemysław Spurek</author><pubDate>Tue, 06 Feb 2024 16:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01459v2</guid></item><item><title>Online Recommendations for Agents with Discounted Adaptive Preferences</title><link>http://arxiv.org/abs/2302.06014v2</link><description>We consider a bandit recommendations problem in which an agent's preferences(representing selection probabilities over recommended items) evolve as afunction of past selections, according to an unknown $\textit{preferencemodel}$. In each round, we show a menu of $k$ items (out of $n$ total) to theagent, who then chooses a single item, and we aim to minimize regret withrespect to some $\textit{target set}$ (a subset of the item simplex) foradversarial losses over the agent's choices. Extending the setting from Agarwaland Brown (2022), where uniform-memory agents were considered, here we allowfor non-uniform memory in which a discount factor is applied to the agent'smemory vector at each subsequent round. In the "long-term memory" regime (whenthe effective memory horizon scales with $T$ sublinearly), we show thatefficient sublinear regret is obtainable with respect to the set of$\textit{everywhere instantaneously realizable distributions}$ (the "EIRD set",as formulated in prior work) for any $\textit{smooth}$ preference model.Further, for preferences which are bounded above and below by linear functionsof memory weight (we call these "scale-bounded" preferences) we give analgorithm which obtains efficient sublinear regret with respect to nearly the$\textit{entire}$ item simplex. We show an NP-hardness result for expanding totargets beyond EIRD in general. In the "short-term memory" regime (when thememory horizon is constant), we show that scale-bounded preferences againenable efficient sublinear regret for nearly the entire simplex even withoutsmoothness if losses do not change too frequently, yet we show aninformation-theoretic barrier for competing against the EIRD set underarbitrary smooth preference models even when losses are constant.</description><author>Arpit Agarwal, William Brown</author><pubDate>Tue, 06 Feb 2024 16:08:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06014v2</guid></item><item><title>OHQ: On-chip Hardware-aware Quantization</title><link>http://arxiv.org/abs/2309.01945v2</link><description>Quantization emerges as one of the most promising approaches for deployingadvanced deep models on resource-constrained hardware. Mixed-precisionquantization leverages multiple bit-width architectures to unleash the accuracyand efficiency potential of quantized models. However, existing mixed-precisionquantization suffers exhaustive search space that causes immense computationaloverhead. The quantization process thus relies on separate high-performancedevices rather than locally, which also leads to a significant gap between theconsidered hardware metrics and the real deployment.In this paper, we proposean On-chip Hardware-aware Quantization (OHQ) framework that performshardware-aware mixed-precision quantization without accessing online devices.First, we construct the On-chip Quantization Awareness (OQA) pipeline, enablingperceive the actual efficiency metrics of the quantization operator on thehardware.Second, we propose Mask-guided Quantization Estimation (MQE) techniqueto efficiently estimate the accuracy metrics of operators under the constraintsof on-chip-level computing power.By synthesizing network and hardware insightsthrough linear programming, we obtain optimized bit-width configurations.Notably, the quantization process occurs on-chip entirely without anyadditional computing devices and data access. We demonstrate acceleratedinference after quantization for various architectures and compression ratios,achieving 70% and 73% accuracy for ResNet-18 and MobileNetV3, respectively. OHQimproves latency by 15~30% compared to INT8 on deployment.</description><author>Wei Huang, Haotong Qin, Yangdong Liu, Jingzhuo Liang, Yulun Zhang, Ying Li, Xianglong Liu</author><pubDate>Tue, 06 Feb 2024 16:07:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01945v2</guid></item><item><title>SCAFFLSA: Quantifying and Eliminating Heterogeneity Bias in Federated Linear Stochastic Approximation and Temporal Difference Learning</title><link>http://arxiv.org/abs/2402.04114v1</link><description>In this paper, we perform a non-asymptotic analysis of the federated linearstochastic approximation (FedLSA) algorithm. We explicitly quantify the biasintroduced by local training with heterogeneous agents, and investigate thesample complexity of the algorithm. We show that the communication complexityof FedLSA scales polynomially with the desired precision $\epsilon$, whichlimits the benefits of federation. To overcome this, we propose SCAFFLSA, anovel variant of FedLSA, that uses control variates to correct the bias oflocal training, and prove its convergence without assumptions on statisticalheterogeneity. We apply the proposed methodology to federated temporaldifference learning with linear function approximation, and analyze thecorresponding complexity improvements.</description><author>Paul Mangold, Sergey Samsonov, Safwan Labbi, Ilya Levin, Reda Alami, Alexey Naumov, Eric Moulines</author><pubDate>Tue, 06 Feb 2024 16:06:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04114v1</guid></item><item><title>Behind the Screen: Investigating ChatGPT's Dark Personality Traits and Conspiracy Beliefs</title><link>http://arxiv.org/abs/2402.04110v1</link><description>ChatGPT is notorious for its intransparent behavior. This paper tries to shedlight on this, providing an in-depth analysis of the dark personality traitsand conspiracy beliefs of GPT-3.5 and GPT-4. Different psychological tests andquestionnaires were employed, including the Dark Factor Test, the Mach-IVScale, the Generic Conspiracy Belief Scale, and the Conspiracy Mentality Scale.The responses were analyzed computing average scores, standard deviations, andsignificance tests to investigate differences between GPT-3.5 and GPT-4. Fortraits that have shown to be interdependent in human studies, correlations wereconsidered. Additionally, system roles corresponding to groups that have showndistinct answering behavior in the corresponding questionnaires were applied toexamine the models' ability to reflect characteristics associated with theseroles in their responses. Dark personality traits and conspiracy beliefs werenot particularly pronounced in either model with little differences betweenGPT-3.5 and GPT-4. However, GPT-4 showed a pronounced tendency to believe ininformation withholding. This is particularly intriguing given that GPT-4 istrained on a significantly larger dataset than GPT-3.5. Apparently, in thiscase an increased data exposure correlates with a greater belief in the controlof information. An assignment of extreme political affiliations increased thebelief in conspiracy theories. Test sequencing affected the models' responsesand the observed correlations, indicating a form of contextual memory.</description><author>Erik Weber, Jérôme Rutinowski, Markus Pauly</author><pubDate>Tue, 06 Feb 2024 16:03:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04110v1</guid></item><item><title>Hierarchical Delay Attribution Classification using Unstructured Text in Train Management Systems</title><link>http://arxiv.org/abs/2402.04108v1</link><description>EU directives stipulate a systematic follow-up of train delays. In Sweden,the Swedish Transport Administration registers and assigns an appropriate delayattribution code. However, this delay attribution code is assigned manually,which is a complex task. In this paper, a machine learning-based decisionsupport for assigning delay attribution codes based on event descriptions isinvestigated. The text is transformed using TF-IDF, and two models, RandomForest and Support Vector Machine, are evaluated against a random uniformclassifier and the classification performance of the Swedish TransportAdministration. Further, the problem is modeled as both a hierarchical and flatapproach. The results indicate that a hierarchical approach performs betterthan a flat approach. Both approaches perform better than the random uniformclassifier but perform worse than the manual classification.</description><author>Anton Borg, Per Lingvall, Martin Svensson</author><pubDate>Tue, 06 Feb 2024 16:02:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04108v1</guid></item><item><title>Measuring Implicit Bias in Explicitly Unbiased Large Language Models</title><link>http://arxiv.org/abs/2402.04105v1</link><description>Large language models (LLMs) can pass explicit bias tests but still harborimplicit biases, similar to humans who endorse egalitarian beliefs yet exhibitsubtle biases. Measuring such implicit biases can be a challenge: as LLMsbecome increasingly proprietary, it may not be possible to access theirembeddings and apply existing bias measures; furthermore, implicit biases areprimarily a concern if they affect the actual decisions that these systemsmake. We address both of these challenges by introducing two measures of biasinspired by psychology: LLM Implicit Association Test (IAT) Bias, which is aprompt-based method for revealing implicit bias; and LLM Decision Bias fordetecting subtle discrimination in decision-making tasks. Using these measures,we found pervasive human-like stereotype biases in 6 LLMs across 4 socialdomains (race, gender, religion, health) and 21 categories (weapons, guilt,science, career among others). Our prompt-based measure of implicit biascorrelates with embedding-based methods but better predicts downstreambehaviors measured by LLM Decision Bias. This measure is based on asking theLLM to decide between individuals, motivated by psychological resultsindicating that relative not absolute evaluations are more related to implicitbiases. Using prompt-based measures informed by psychology allows us toeffectively expose nuanced biases and subtle discrimination in proprietary LLMsthat do not show explicit bias on standard benchmarks.</description><author>Xuechunzi Bai, Angelina Wang, Ilia Sucholutsky, Thomas L. Griffiths</author><pubDate>Tue, 06 Feb 2024 15:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04105v1</guid></item><item><title>An Exploration of Clustering Algorithms for Customer Segmentation in the UK Retail Market</title><link>http://arxiv.org/abs/2402.04103v1</link><description>Recently, peoples awareness of online purchases has significantly risen. Thishas given rise to online retail platforms and the need for a betterunderstanding of customer purchasing behaviour. Retail companies are pressedwith the need to deal with a high volume of customer purchases, which requiressophisticated approaches to perform more accurate and efficient customersegmentation. Customer segmentation is a marketing analytical tool that aidscustomer-centric service and thus enhances profitability. In this paper, we aimto develop a customer segmentation model to improve decision-making processesin the retail market industry. To achieve this, we employed a UK-based onlineretail dataset obtained from the UCI machine learning repository. The retaildataset consists of 541,909 customer records and eight features. Our studyadopted the RFM (recency, frequency, and monetary) framework to quantifycustomer values. Thereafter, we compared several state-of-the-art (SOTA)clustering algorithms, namely, K-means clustering, the Gaussian mixture model(GMM), density-based spatial clustering of applications with noise (DBSCAN),agglomerative clustering, and balanced iterative reducing and clustering usinghierarchies (BIRCH). The results showed the GMM outperformed other approaches,with a Silhouette Score of 0.80.</description><author>Jeen Mary John, Olamilekan Shobayo, Bayode Ogunleye</author><pubDate>Tue, 06 Feb 2024 15:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04103v1</guid></item><item><title>Use of Multi-CNNs for Section Analysis in Static Malware Detection</title><link>http://arxiv.org/abs/2402.04102v1</link><description>Existing research on malware detection focuses almost exclusively on thedetection rate. However, in some cases, it is also important to understand theresults of our algorithm, or to obtain more information, such as where toinvestigate in the file for an analyst. In this aim, we propose a new model toanalyze Portable Executable files. Our method consists in splitting the filesin different sections, then transform each section into an image, in order totrain convolutional neural networks to treat specifically each identifiedsection. Then we use all these scores returned by CNNs to compute a finaldetection score, using models that enable us to improve our analysis of theimportance of each section in the final score.</description><author>Tony Quertier, Grégoire Barrué</author><pubDate>Tue, 06 Feb 2024 15:57:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04102v1</guid></item><item><title>VRMM: A Volumetric Relightable Morphable Head Model</title><link>http://arxiv.org/abs/2402.04101v1</link><description>In this paper, we introduce the Volumetric Relightable Morphable Model(VRMM), a novel volumetric and parametric facial prior for 3D face modeling.While recent volumetric prior models offer improvements over traditionalmethods like 3D Morphable Models (3DMMs), they face challenges in modellearning and personalized reconstructions. Our VRMM overcomes these byemploying a novel training framework that efficiently disentangles and encodeslatent spaces of identity, expression, and lighting into low-dimensionalrepresentations. This framework, designed with self-supervised learning,significantly reduces the constraints for training data, making it morefeasible in practice. The learned VRMM offers relighting capabilities andencompasses a comprehensive range of expressions. We demonstrate theversatility and effectiveness of VRMM through various applications like avatargeneration, facial reconstruction, and animation. Additionally, we address thecommon issue of overfitting in generative volumetric models with a novelprior-preserving personalization framework based on VRMM. Such an approachenables accurate 3D face reconstruction from even a single portrait input. Ourexperiments showcase the potential of VRMM to significantly enhance the fieldof 3D face modeling.</description><author>Haotian Yang, Mingwu Zheng, Chongyang Ma, Yu-Kun Lai, Pengfei Wan, Haibin Huang</author><pubDate>Tue, 06 Feb 2024 15:55:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04101v1</guid></item><item><title>Analysis of Deep Image Prior and Exploiting Self-Guidance for Image Reconstruction</title><link>http://arxiv.org/abs/2402.04097v1</link><description>The ability of deep image prior (DIP) to recover high-quality images fromincomplete or corrupted measurements has made it popular in inverse problems inimage restoration and medical imaging including magnetic resonance imaging(MRI). However, conventional DIP suffers from severe overfitting and spectralbias effects.In this work, we first provide an analysis of how DIP recoversinformation from undersampled imaging measurements by analyzing the trainingdynamics of the underlying networks in the kernel regime for differentarchitectures.This study sheds light on important underlying properties forDIP-based recovery.Current research suggests that incorporating a referenceimage as network input can enhance DIP's performance in image reconstructioncompared to using random inputs. However, obtaining suitable reference imagesrequires supervision, and raises practical difficulties. In an attempt toovercome this obstacle, we further introduce a self-driven reconstructionprocess that concurrently optimizes both the network weights and the inputwhile eliminating the need for training data. Our method incorporates a noveldenoiser regularization term which enables robust and stable joint estimationof both the network input and reconstructed image.We demonstrate that ourself-guided method surpasses both the original DIP and modern supervisedmethods in terms of MR image reconstruction performance and outperformsprevious DIP-based schemes for image inpainting.</description><author>Shijun Liang, Evan Bell, Qing Qu, Rongrong Wang, Saiprasad Ravishankar</author><pubDate>Tue, 06 Feb 2024 15:52:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04097v1</guid></item><item><title>The Landscape and Challenges of HPC Research and LLMs</title><link>http://arxiv.org/abs/2402.02018v2</link><description>Recently, language models (LMs), especially large language models (LLMs),have revolutionized the field of deep learning. Both encoder-decoder models andprompt-based techniques have shown immense potential for natural languageprocessing and code-based tasks. Over the past several years, many researchlabs and institutions have invested heavily in high-performance computing,approaching or breaching exascale performance levels. In this paper, we positthat adapting and utilizing such language model-based techniques for tasks inhigh-performance computing (HPC) would be very beneficial. This study presentsour reasoning behind the aforementioned position and highlights how existingideas can be improved and adapted for HPC tasks.</description><author>Le Chen, Nesreen K. Ahmed, Akash Dutta, Arijit Bhattacharjee, Sixing Yu, Quazi Ishtiaque Mahmud, Waqwoya Abebe, Hung Phan, Aishwarya Sarkar, Branden Butler, Niranjan Hasabnis, Gal Oren, Vy A. Vo, Juan Pablo Munoz, Theodore L. Willke, Tim Mattson, Ali Jannesari</author><pubDate>Tue, 06 Feb 2024 15:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02018v2</guid></item><item><title>The Use of a Large Language Model for Cyberbullying Detection</title><link>http://arxiv.org/abs/2402.04088v1</link><description>The dominance of social media has added to the channels of bullying forperpetrators. Unfortunately, cyberbullying (CB) is the most prevalentphenomenon in todays cyber world, and is a severe threat to the mental andphysical health of citizens. This opens the need to develop a robust system toprevent bullying content from online forums, blogs, and social media platformsto manage the impact in our society. Several machine learning (ML) algorithmshave been proposed for this purpose. However, their performances are notconsistent due to high class imbalance and generalisation issues. In recentyears, large language models (LLMs) like BERT and RoBERTa have achievedstate-of-the-art (SOTA) results in several natural language processing (NLP)tasks. Unfortunately, the LLMs have not been applied extensively for CBdetection. In our paper, we explored the use of these models for cyberbullying(CB) detection. We have prepared a new dataset (D2) from existing studies(Formspring and Twitter). Our experimental results for dataset D1 and D2 showedthat RoBERTa outperformed other models.</description><author>Bayode Ogunleye, Babitha Dharmaraj</author><pubDate>Tue, 06 Feb 2024 15:46:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04088v1</guid></item><item><title>A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation</title><link>http://arxiv.org/abs/2402.04087v1</link><description>Contrastive Language-Image Pretraining (CLIP) has gained popularity for itsremarkable zero-shot capacity. Recent research has focused on developingefficient fine-tuning methods, such as prompt learning and adapter, to enhanceCLIP's performance in downstream tasks. However, these methods still requireadditional training time and computational resources, which is undesirable fordevices with limited resources. In this paper, we revisit a classicalalgorithm, Gaussian Discriminant Analysis (GDA), and apply it to the downstreamclassification of CLIP. Typically, GDA assumes that features of each classfollow Gaussian distributions with identical covariance. By leveraging Bayes'formula, the classifier can be expressed in terms of the class means andcovariance, which can be estimated from the data without the need for training.To integrate knowledge from both visual and textual modalities, we ensemble itwith the original zero-shot classifier within CLIP. Extensive results on 17datasets validate that our method surpasses or achieves comparable results withstate-of-the-art methods on few-shot classification, imbalanced learning, andout-of-distribution generalization. In addition, we extend our method tobase-to-new generalization and unsupervised learning, once again demonstratingits superiority over competing approaches. Our code is publicly available at\url{https://github.com/mrflogs/ICLR24}.</description><author>Zhengbo Wang, Jian Liang, Lijun Sheng, Ran He, Zilei Wang, Tieniu Tan</author><pubDate>Tue, 06 Feb 2024 15:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04087v1</guid></item><item><title>Provably learning a multi-head attention layer</title><link>http://arxiv.org/abs/2402.04084v1</link><description>The multi-head attention layer is one of the key components of thetransformer architecture that sets it apart from traditional feed-forwardmodels. Given a sequence length $k$, attention matrices$\mathbf{\Theta}_1,\ldots,\mathbf{\Theta}_m\in\mathbb{R}^{d\times d}$, andprojection matrices $\mathbf{W}_1,\ldots,\mathbf{W}_m\in\mathbb{R}^{d\timesd}$, the corresponding multi-head attention layer $F: \mathbb{R}^{k\times d}\to\mathbb{R}^{k\times d}$ transforms length-$k$ sequences of $d$-dimensionaltokens $\mathbf{X}\in\mathbb{R}^{k\times d}$ via $F(\mathbf{X}) \triangleq\sum^m_{i=1}\mathrm{softmax}(\mathbf{X}\mathbf{\Theta}_i\mathbf{X}^\top)\mathbf{X}\mathbf{W}_i$.In this work, we initiate the study of provably learning a multi-head attentionlayer from random examples and give the first nontrivial upper and lower boundsfor this problem: - Provided $\{\mathbf{W}_i, \mathbf{\Theta}_i\}$ satisfy certainnon-degeneracy conditions, we give a $(dk)^{O(m^3)}$-time algorithm that learns$F$ to small error given random labeled examples drawn uniformly from $\{\pm1\}^{k\times d}$. - We prove computational lower bounds showing that in the worst case,exponential dependence on $m$ is unavoidable. We focus on Boolean $\mathbf{X}$ to mimic the discrete nature of tokens inlarge language models, though our techniques naturally extend to standardcontinuous settings, e.g. Gaussian. Our algorithm, which is centered aroundusing examples to sculpt a convex body containing the unknown parameters, is asignificant departure from existing provable algorithms for learningfeedforward networks, which predominantly exploit algebraic and rotationinvariance properties of the Gaussian distribution. In contrast, our analysisis more flexible as it primarily relies on various upper and lower tail boundsfor the input distribution and "slices" thereof.</description><author>Sitan Chen, Yuanzhi Li</author><pubDate>Tue, 06 Feb 2024 15:39:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04084v1</guid></item><item><title>DECODE: Data-driven Energy Consumption Prediction leveraging Historical Data and Environmental Factors in Buildings</title><link>http://arxiv.org/abs/2309.02908v2</link><description>Energy prediction in buildings plays a crucial role in effective energymanagement. Precise predictions are essential for achieving optimal energyconsumption and distribution within the grid. This paper introduces a LongShort-Term Memory (LSTM) model designed to forecast building energy consumptionusing historical energy data, occupancy patterns, and weather conditions. TheLSTM model provides accurate short, medium, and long-term energy predictionsfor residential and commercial buildings compared to existing predictionmodels. We compare our LSTM model with established prediction methods,including linear regression, decision trees, and random forest. Encouragingly,the proposed LSTM model emerges as the superior performer across all metrics.It demonstrates exceptional prediction accuracy, boasting the highest R2 scoreof 0.97 and the most favorable mean absolute error (MAE) of 0.007. Anadditional advantage of our developed model is its capacity to achieveefficient energy consumption forecasts even when trained on a limited dataset.We address concerns about overfitting (variance) and underfitting (bias)through rigorous training and evaluation on real-world data. In summary, ourresearch contributes to energy prediction by offering a robust LSTM model thatoutperforms alternative methods and operates with remarkable efficiency,generalizability, and reliability.</description><author>Aditya Mishra, Haroon R. Lone, Aayush Mishra</author><pubDate>Tue, 06 Feb 2024 15:37:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02908v2</guid></item><item><title>An Optimal House Price Prediction Algorithm: XGBoost</title><link>http://arxiv.org/abs/2402.04082v1</link><description>An accurate prediction of house prices is a fundamental requirement forvarious sectors including real estate and mortgage lending. It is widelyrecognized that a property value is not solely determined by its physicalattributes but is significantly influenced by its surrounding neighbourhood.Meeting the diverse housing needs of individuals while balancing budgetconstraints is a primary concern for real estate developers. To this end, weaddressed the house price prediction problem as a regression task and thusemployed various machine learning techniques capable of expressing thesignificance of independent variables. We made use of the housing dataset ofAmes City in Iowa, USA to compare support vector regressor, random forestregressor, XGBoost, multilayer perceptron and multiple linear regressionalgorithms for house price prediction. Afterwards, we identified the keyfactors that influence housing costs. Our results show that XGBoost is the bestperforming model for house price prediction.</description><author>Hemlata Sharma, Hitesh Harsora, Bayode Ogunleye</author><pubDate>Tue, 06 Feb 2024 15:36:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04082v1</guid></item><item><title>Improved Generalization of Weight Space Networks via Augmentations</title><link>http://arxiv.org/abs/2402.04081v1</link><description>Learning in deep weight spaces (DWS), where neural networks process theweights of other neural networks, is an emerging research direction, withapplications to 2D and 3D neural fields (INRs, NeRFs), as well as makinginferences about other types of neural networks. Unfortunately, weight spacemodels tend to suffer from substantial overfitting. We empirically analyze thereasons for this overfitting and find that a key reason is the lack ofdiversity in DWS datasets. While a given object can be represented by manydifferent weight configurations, typical INR training sets fail to capturevariability across INRs that represent the same object. To address this, weexplore strategies for data augmentation in weight spaces and propose a MixUpmethod adapted for weight spaces. We demonstrate the effectiveness of thesemethods in two setups. In classification, they improve performance similarly tohaving up to 10 times more data. In self-supervised contrastive learning, theyyield substantial 5-10% gains in downstream classification.</description><author>Aviv Shamsian, Aviv Navon, David W. Zhang, Yan Zhang, Ethan Fetaya, Gal Chechik, Haggai Maron</author><pubDate>Tue, 06 Feb 2024 15:34:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04081v1</guid></item><item><title>Entropy-regularized Diffusion Policy with Q-Ensembles for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2402.04080v1</link><description>This paper presents advanced techniques of training diffusion policies foroffline reinforcement learning (RL). At the core is a mean-reverting stochasticdifferential equation (SDE) that transfers a complex action distribution into astandard Gaussian and then samples actions conditioned on the environment statewith a corresponding reverse-time SDE, like a typical diffusion policy. We showthat such an SDE has a solution that we can use to calculate the logprobability of the policy, yielding an entropy regularizer that improves theexploration of offline datasets. To mitigate the impact of inaccurate valuefunctions from out-of-distribution data points, we further propose to learn thelower confidence bound of Q-ensembles for more robust policy improvement. Bycombining the entropy-regularized diffusion policy with Q-ensembles in offlineRL, our method achieves state-of-the-art performance on most tasks in D4RLbenchmarks. Code is available at\href{https://github.com/ruoqizzz/Entropy-Regularized-Diffusion-Policy-with-QEnsemble}{https://github.com/ruoqizzz/Entropy-Regularized-Diffusion-Policy-with-QEnsemble}.</description><author>Ruoqi Zhang, Ziwei Luo, Jens Sjölund, Thomas B. Schön, Per Mattsson</author><pubDate>Tue, 06 Feb 2024 15:34:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04080v1</guid></item><item><title>Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees</title><link>http://arxiv.org/abs/2402.00899v2</link><description>We present a new methodology for handling AI errors by introducing weaklysupervised AI error correctors with a priori performance guarantees. These AIcorrectors are auxiliary maps whose role is to moderate the decisions of somepreviously constructed underlying classifier by either approving or rejectingits decisions. The rejection of a decision can be used as a signal to suggestabstaining from making a decision. A key technical focus of the work is inproviding performance guarantees for these new AI correctors through bounds onthe probabilities of incorrect decisions. These bounds are distributionagnostic and do not rely on assumptions on the data dimension. Our empiricalexample illustrates how the framework can be applied to improve the performanceof an image classifier in a challenging real-world task where training data arescarce.</description><author>Ivan Y. Tyukin, Tatiana Tyukina, Daniel van Helden, Zedong Zheng, Evgeny M. Mirkes, Oliver J. Sutton, Qinghua Zhou, Alexander N. Gorban, Penelope Allison</author><pubDate>Tue, 06 Feb 2024 15:27:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00899v2</guid></item><item><title>Iterative Prompt Refinement for Radiation Oncology Symptom Extraction Using Teacher-Student Large Language Models</title><link>http://arxiv.org/abs/2402.04075v1</link><description>This study introduces a novel teacher-student architecture utilizing LargeLanguage Models (LLMs) to improve prostate cancer radiotherapy symptomextraction from clinical notes. Mixtral, the student model, initially extractssymptoms, followed by GPT-4, the teacher model, which refines prompts based onMixtral's performance. This iterative process involved 294 single symptomclinical notes across 12 symptoms, with up to 16 rounds of refinement perepoch. Results showed significant improvements in extracting symptoms from bothsingle and multi-symptom notes. For 59 single symptom notes, accuracy increasedfrom 0.51 to 0.71, precision from 0.52 to 0.82, recall from 0.52 to 0.72, andF1 score from 0.49 to 0.73. In 375 multi-symptom notes, accuracy rose from 0.24to 0.43, precision from 0.6 to 0.76, recall from 0.24 to 0.43, and F1 scorefrom 0.20 to 0.44. These results demonstrate the effectiveness of advancedprompt engineering in LLMs for radiation oncology use.</description><author>Reza Khanmohammadi, Ahmed I Ghanem, Kyle Verdecchia, Ryan Hall, Mohamed Elshaikh, Benjamin Movsas, Hassan Bagher-Ebadian, Indrin Chetty, Mohammad M. Ghassemi, Kundan Thind</author><pubDate>Tue, 06 Feb 2024 15:25:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04075v1</guid></item><item><title>LASER: Linear Compression in Wireless Distributed Optimization</title><link>http://arxiv.org/abs/2310.13033v2</link><description>Data-parallel SGD is the de facto algorithm for distributed optimization,especially for large scale machine learning. Despite its merits, communicationbottleneck is one of its persistent issues. Most compression schemes toalleviate this either assume noiseless communication links, or fail to achievegood performance on practical tasks. In this paper, we close this gap andintroduce LASER: LineAr CompreSsion in WirEless DistRibuted Optimization. LASERcapitalizes on the inherent low-rank structure of gradients and transmits themefficiently over the noisy channels. Whilst enjoying theoretical guaranteessimilar to those of the classical SGD, LASER shows consistent gains overbaselines on a variety of practical benchmarks. In particular, it outperformsthe state-of-the-art compression schemes on challenging computer vision and GPTlanguage modeling tasks. On the latter, we obtain $50$-$64 \%$ improvement inperplexity over our baselines for noisy channels.</description><author>Ashok Vardhan Makkuva, Marco Bondaschi, Thijs Vogels, Martin Jaggi, Hyeji Kim, Michael C. Gastpar</author><pubDate>Tue, 06 Feb 2024 15:22:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13033v2</guid></item><item><title>Retrieve to Explain: Evidence-driven Predictions with Language Models</title><link>http://arxiv.org/abs/2402.04068v1</link><description>Machine learning models, particularly language models, are notoriouslydifficult to introspect. Black-box models can mask both issues in modeltraining and harmful biases. For human-in-the-loop processes, opaquepredictions can drive lack of trust, limiting a model's impact even when itperforms effectively. To address these issues, we introduce Retrieve to Explain(R2E). R2E is a retrieval-based language model that prioritizes amongst apre-defined set of possible answers to a research question based on theevidence in a document corpus, using Shapley values to identify the relativeimportance of pieces of evidence to the final prediction. R2E can adapt to newevidence without retraining, and incorporate structured data through templatinginto natural language. We assess on the use case of drug target identificationfrom published scientific literature, where we show that the model outperformsan industry-standard genetics-based approach on predicting clinical trialoutcomes.</description><author>Ravi Patel, Angus Brayne, Rogier Hintzen, Daniel Jaroslawicz, Georgiana Neculae, Dane Corneil</author><pubDate>Tue, 06 Feb 2024 15:13:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04068v1</guid></item><item><title>Multi-class Road Defect Detection and Segmentation using Spatial and Channel-wise Attention for Autonomous Road Repairing</title><link>http://arxiv.org/abs/2402.04064v1</link><description>Road pavement detection and segmentation are critical for developingautonomous road repair systems. However, developing an instance segmentationmethod that simultaneously performs multi-class defect detection andsegmentation is challenging due to the textural simplicity of road pavementimage, the diversity of defect geometries, and the morphological ambiguitybetween classes. We propose a novel end-to-end method for multi-class roaddefect detection and segmentation. The proposed method comprises multiplespatial and channel-wise attention blocks available to learn globalrepresentations across spatial and channel-wise dimensions. Through theseattention blocks, more globally generalised representations of morphologicalinformation (spatial characteristics) of road defects and colour and depthinformation of images can be learned. To demonstrate the effectiveness of ourframework, we conducted various ablation studies and comparisons with priormethods on a newly collected dataset annotated with nine road defect classes.The experiments show that our proposed method outperforms existingstate-of-the-art methods for multi-class road defect detection and segmentationmethods.</description><author>Jongmin Yu, Chen Bene Chi, Sebastiano Fichera, Paolo Paoletti, Devansh Mehta, Shan Luo</author><pubDate>Tue, 06 Feb 2024 15:09:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04064v1</guid></item><item><title>Link Prediction with Relational Hypergraphs</title><link>http://arxiv.org/abs/2402.04062v1</link><description>Link prediction with knowledge graphs has been thoroughly studied in graphmachine learning, leading to a rich landscape of graph neural networkarchitectures with successful applications. Nonetheless, it remains challengingto transfer the success of these architectures to link prediction withrelational hypergraphs. The presence of relational hyperedges makes linkprediction a task between $k$ nodes for varying choices of $k$, which issubstantially harder than link prediction with knowledge graphs, where everyrelation is binary ($k=2$). In this paper, we propose two frameworks for linkprediction with relational hypergraphs and conduct a thorough analysis of theexpressive power of the resulting model architectures via correspondingrelational Weisfeiler-Leman algorithms, and also via some natural logicalformalisms. Through extensive empirical analysis, we validate the power of theproposed model architectures on various relational hypergraph benchmarks. Theresulting model architectures substantially outperform every baseline forinductive link prediction, and lead to state-of-the-art results fortransductive link prediction. Our study therefore unlocks applications of graphneural networks to fully relational structures.</description><author>Xingyue Huang, Miguel Romero Orth, Pablo Barceló, Michael M. Bronstein, İsmail İlkan Ceylan</author><pubDate>Tue, 06 Feb 2024 15:05:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04062v1</guid></item><item><title>TopoNav: Topological Navigation for Efficient Exploration in Sparse Reward Environments</title><link>http://arxiv.org/abs/2402.04061v1</link><description>Autonomous robots exploring unknown areas face a significant challenge --navigating effectively without prior maps and with limited external feedback.This challenge intensifies in sparse reward environments, where traditionalexploration techniques often fail. In this paper, we introduce TopoNav, a novelframework that empowers robots to overcome these constraints and achieveefficient, adaptable, and goal-oriented exploration. TopoNav's fundamentalbuilding blocks are active topological mapping, intrinsic reward mechanisms,and hierarchical objective prioritization. Throughout its exploration, TopoNavconstructs a dynamic topological map that captures key locations and pathways.It utilizes intrinsic rewards to guide the robot towards designated sub-goalswithin this map, fostering structured exploration even in sparse rewardsettings. To ensure efficient navigation, TopoNav employs the HierarchicalObjective-Driven Active Topologies framework, enabling the robot to prioritizeimmediate tasks like obstacle avoidance while maintaining focus on the overallgoal. We demonstrate TopoNav's effectiveness in simulated environments thatreplicate real-world conditions. Our results reveal significant improvements inexploration efficiency, navigational accuracy, and adaptability to unforeseenobstacles, showcasing its potential to revolutionize autonomous exploration ina wide range of applications, including search and rescue, environmentalmonitoring, and planetary exploration.</description><author>Jumman Hossain, Abu-Zaher Faridee, Nirmalya Roy, Jade Freeman, Timothy Gregory, Theron T. Trout</author><pubDate>Tue, 06 Feb 2024 15:05:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04061v1</guid></item><item><title>Deep Learning for Multivariate Time Series Imputation: A Survey</title><link>http://arxiv.org/abs/2402.04059v1</link><description>The ubiquitous missing values cause the multivariate time series data to bepartially observed, destroying the integrity of time series and hindering theeffective time series data analysis. Recently deep learning imputation methodshave demonstrated remarkable success in elevating the quality of corrupted timeseries data, subsequently enhancing performance in downstream tasks. In thispaper, we conduct a comprehensive survey on the recently proposed deep learningimputation methods. First, we propose a taxonomy for the reviewed methods, andthen provide a structured review of these methods by highlighting theirstrengths and limitations. We also conduct empirical experiments to studydifferent methods and compare their enhancement for downstream tasks. Finally,the open issues for future research on multivariate time series imputation arepointed out. All code and configurations of this work, including a regularlymaintained multivariate time series imputation paper list, can be found in theGitHub repository~\url{https://github.com/WenjieDu/Awesome\_Imputation}.</description><author>Jun Wang, Wenjie Du, Wei Cao, Keli Zhang, Wenjia Wang, Yuxuan Liang, Qingsong Wen</author><pubDate>Tue, 06 Feb 2024 15:03:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04059v1</guid></item><item><title>Feudal Graph Reinforcement Learning</title><link>http://arxiv.org/abs/2304.05099v2</link><description>Graph-based representations and weight-sharing modular policies constituteprominent approaches to tackling composable control problems in ReinforcementLearning (RL). However, as shown by recent graph deep learning literature,message-passing operators can create bottlenecks in information propagation andhinder global coordination. The issue becomes dramatic in tasks wherehigh-level planning is needed. In this work, we propose a novel methodology,named Feudal Graph Reinforcement Learning (FGRL), that addresses suchchallenges by relying on hierarchical RL and a pyramidal message-passingarchitecture. In particular, FGRL defines a hierarchy of policies wherehigh-level commands are propagated from the top of the hierarchy down through alayered graph structure. The bottom layers mimic the morphology of the physicalsystem, while the upper layers capture more abstract sub-modules. The resultingagents are then characterized by a committee of policies where actions at acertain level set goals for the level below, thus implementing a hierarchicaldecision-making structure that encompasses task decomposition. We evaluate theproposed framework on locomotion tasks on benchmark MuJoCo environments andshow that FGRL compares favorably against relevant baselines. Furthermore, anin-depth analysis of the command propagation mechanism provides evidence thatthe introduced message-passing scheme favors the learning of hierarchicaldecision-making policies.</description><author>Tommaso Marzi, Arshjot Khehra, Andrea Cini, Cesare Alippi</author><pubDate>Tue, 06 Feb 2024 15:03:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05099v2</guid></item><item><title>Large Language Model Agent for Hyper-Parameter Optimization</title><link>http://arxiv.org/abs/2402.01881v2</link><description>Hyperparameter optimization is critical in modern machine learning, requiringexpert knowledge, numerous trials, and high computational and human resources.Despite the advancements in Automated Machine Learning (AutoML), challenges interms of trial efficiency, setup complexity, and interoperability stillpersist. To address these issues, we introduce a novel paradigm leveragingLarge Language Models (LLMs) to automate hyperparameter optimization acrossdiverse machine learning tasks, which is named AgentHPO (short for LLMAgent-based Hyperparameter Optimization). Specifically, AgentHPO processes thetask information autonomously, conducts experiments with specifichyperparameters (HPs), and iteratively optimizes them based on historicaltrials. This human-like optimization process largely reduces the number ofrequired trials, simplifies the setup process, and enhances interpretabilityand user trust, compared to traditional AutoML methods. Extensive empiricalexperiments conducted on 12 representative machine-learning tasks indicate thatAgentHPO not only matches but also often surpasses the best human trials interms of performance while simultaneously providing explainable results.Further analysis sheds light on the strategies employed by the LLM inoptimizing these tasks, highlighting its effectiveness and adaptability invarious scenarios.</description><author>Siyi Liu, Chen Gao, Yong Li</author><pubDate>Tue, 06 Feb 2024 15:03:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01881v2</guid></item><item><title>More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms</title><link>http://arxiv.org/abs/2402.04054v1</link><description>We introduce a new framework for studying meta-learning methods usingPAC-Bayesian theory. Its main advantage over previous work is that it allowsfor more flexibility in how the transfer of knowledge between tasks isrealized. For previous approaches, this could only happen indirectly, by meansof learning prior distributions over models. In contrast, the newgeneralization bounds that we prove express the process of meta-learning muchmore directly as learning the learning algorithm that should be used for futuretasks. The flexibility of our framework makes it suitable to analyze a widerange of meta-learning mechanisms and even design new mechanisms. Other thanour theoretical contributions we also show empirically that our frameworkimproves the prediction quality in practical meta-learning mechanisms.</description><author>Hossein Zakerinia, Amin Behjati, Christoph H. Lampert</author><pubDate>Tue, 06 Feb 2024 15:00:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04054v1</guid></item><item><title>Deep Spectral Improvement for Unsupervised Image Instance Segmentation</title><link>http://arxiv.org/abs/2402.02474v2</link><description>Deep spectral methods reframe the image decomposition process as a graphpartitioning task by extracting features using self-supervised learning andutilizing the Laplacian of the affinity matrix to obtain eigensegments.However, instance segmentation has received less attention compared to othertasks within the context of deep spectral methods. This paper addresses thefact that not all channels of the feature map extracted from a self-supervisedbackbone contain sufficient information for instance segmentation purposes. Infact, Some channels are noisy and hinder the accuracy of the task. To overcomethis issue, this paper proposes two channel reduction modules: Noise ChannelReduction (NCR) and Deviation-based Channel Reduction (DCR). The NCR retainschannels with lower entropy, as they are less likely to be noisy, while DCRprunes channels with low standard deviation, as they lack sufficientinformation for effective instance segmentation. Furthermore, the paperdemonstrates that the dot product, commonly used in deep spectral methods, isnot suitable for instance segmentation due to its sensitivity to feature mapvalues, potentially leading to incorrect instance segments. A new similaritymetric called Bray-Curtis over Chebyshev (BoC) is proposed to address thisissue. It takes into account the distribution of features in addition to theirvalues, providing a more robust similarity measure for instance segmentation.Quantitative and qualitative results on the Youtube-VIS2019 dataset highlightthe improvements achieved by the proposed channel reduction methods and the useof BoC instead of the conventional dot product for creating the affinitymatrix. These improvements are observed in terms of mean Intersection overUnion and extracted instance segments, demonstrating enhanced instancesegmentation performance. The code is available on:https://github.com/farnooshar/SpecUnIIS</description><author>Farnoosh Arefi, Amir M. Mansourian, Shohreh Kasaei</author><pubDate>Tue, 06 Feb 2024 14:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02474v2</guid></item><item><title>Dual-stage optimizer for systematic overestimation adjustment applied to multi-objective genetic algorithms for biomarker selection</title><link>http://arxiv.org/abs/2312.16624v2</link><description>The challenge in biomarker discovery using machine learning from omics datalies in the abundance of molecular features but scarcity of samples. Mostfeature selection methods in machine learning require evaluating various setsof features (models) to determine the most effective combination. This process,typically conducted using a validation dataset, involves testing differentfeature sets to optimize the model's performance. Evaluations have performanceestimation error and when the selection involves many models the best ones arealmost certainly overestimated. Biomarker identification with feature selectionmethods can be addressed as a multi-objective problem with trade-offs betweenpredictive ability and parsimony in the number of features. Genetic algorithmsare a popular tool for multi-objective optimization but they evolve numeroussolutions thus are prone to overestimation. Methods have been proposed toreduce the overestimation after a model has already been selected insingle-objective problems, but no algorithm existed capable of reducing theoverestimation during the optimization, improving model selection, or appliedin the more general multi-objective domain. We propose DOSA-MO, a novelmulti-objective optimization wrapper algorithm that learns how the originalestimation, its variance, and the feature set size of the solutions predict theoverestimation. DOSA-MO adjusts the expectation of the performance during theoptimization, improving the composition of the solution set. We verify thatDOSA-MO improves the performance of a state-of-the-art genetic algorithm onleft-out or external sample sets, when predicting cancer subtypes and/orpatient overall survival, using three transcriptomics datasets for kidney andbreast cancer.</description><author>Luca Cattelani, Vittorio Fortino</author><pubDate>Tue, 06 Feb 2024 14:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16624v2</guid></item><item><title>LLsM: Generative Linguistic Steganography with Large Language Model</title><link>http://arxiv.org/abs/2401.15656v2</link><description>Linguistic Steganography (LS) tasks aim to generate steganographic text(stego) based on secret information. Only authorized recipients can perceivethe existence of secrets in the texts and extract them, thereby preservingprivacy. However, the controllability of the stego generated by existingschemes is poor, and the stego is difficult to contain specific discoursecharacteristics such as style. As a result, the stego is easily detectable,compromising covert communication. To address these problems, this paperproposes LLsM, the first LS with the Large Language Model (LLM). We fine-tunedthe LLaMA2 with a large-scale constructed dataset encompassing rich discoursecharacteristics, which enables the fine-tuned LLM to generate texts withspecific discourse in a controllable manner. Then the discourse is used asguiding information and inputted into the fine-tuned LLM in the form of thePrompt together with secret. On this basis, the constructed candidate pool willbe range encoded and use secret to determine the interval. The same prefix ofthis interval's beginning and ending is the secret embedded at this moment.Experiments show that LLsM performs superior to prevalent LS-task andrelated-task baselines regarding text quality, statistical analysis, discoursematching, and anti-steganalysis. In particular, LLsM's MAUVE matric surpassessome baselines by 70%-80%, and its anti-steganalysis performance is 30%-40%higher. Notably, we also present examples of longer stegos generated by LLsM,showing its potential superiority in long LS tasks.</description><author>Yihao Wang, Ruiqi Song, Ru Zhang, Jianyi Liu, Lingxiao Li</author><pubDate>Tue, 06 Feb 2024 14:55:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15656v2</guid></item></channel></rss>