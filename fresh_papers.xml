<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 27 Mar 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Efficient Video Object Segmentation via Modulated Cross-Attention Memory</title><link>http://arxiv.org/abs/2403.17937v1</link><description>Recently, transformer-based approaches have shown promising results forsemi-supervised video object segmentation. However, these approaches typicallystruggle on long videos due to increased GPU memory demands, as they frequentlyexpand the memory bank every few frames. We propose a transformer-basedapproach, named MAVOS, that introduces an optimized and dynamic long-termmodulated cross-attention (MCA) memory to model temporal smoothness withoutrequiring frequent memory expansion. The proposed MCA effectively encodes bothlocal and global features at various levels of granularity while efficientlymaintaining consistent speed regardless of the video length. Extensiveexperiments on multiple benchmarks, LVOS, Long-Time Video, and DAVIS 2017,demonstrate the effectiveness of our proposed contributions leading toreal-time inference and markedly reduced memory demands without any degradationin segmentation accuracy on long videos. Compared to the best existingtransformer-based approach, our MAVOS increases the speed by 7.6x, whilesignificantly reducing the GPU memory by 87% with comparable segmentationperformance on short and long video datasets. Notably on the LVOS dataset, ourMAVOS achieves a J&amp;F score of 63.3% while operating at 37 frames per second(FPS) on a single V100 GPU. Our code and models will be publicly available at:https://github.com/Amshaker/MAVOS.</description><author>Abdelrahman Shaker, Syed Talal Wasim, Martin Danelljan, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan</author><pubDate>Tue, 26 Mar 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17937v1</guid></item><item><title>ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis</title><link>http://arxiv.org/abs/2403.17936v1</link><description>Gestures play a key role in human communication. Recent methods for co-speechgesture generation, while managing to generate beat-aligned motions, strugglegenerating gestures that are semantically aligned with the utterance. Comparedto beat gestures that align naturally to the audio signal, semanticallycoherent gestures require modeling the complex interactions between thelanguage and human motion, and can be controlled by focusing on certain words.Therefore, we present ConvoFusion, a diffusion-based approach for multi-modalgesture synthesis, which can not only generate gestures based on multi-modalspeech inputs, but can also facilitate controllability in gesture synthesis.Our method proposes two guidance objectives that allow the users to modulatethe impact of different conditioning modalities (e.g. audio vs text) as well asto choose certain words to be emphasized during gesturing. Our method isversatile in that it can be trained either for generating monologue gestures oreven the conversational gestures. To further advance the research onmulti-party interactive gestures, the DnD Group Gesture dataset is released,which contains 6 hours of gesture data showing 5 people interacting with oneanother. We compare our method with several recent works and demonstrateeffectiveness of our method on a variety of tasks. We urge the reader to watchour supplementary video at our website.</description><author>Muhammad Hamza Mughal, Rishabh Dabral, Ikhsanul Habibie, Lucia Donatelli, Marc Habermann, Christian Theobalt</author><pubDate>Tue, 26 Mar 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17936v1</guid></item><item><title>OmniVid: A Generative Framework for Universal Video Understanding</title><link>http://arxiv.org/abs/2403.17935v1</link><description>The core of video understanding tasks, such as recognition, captioning, andtracking, is to automatically detect objects or actions in a video and analyzetheir temporal evolution. Despite sharing a common goal, different tasks oftenrely on distinct model architectures and annotation formats. In contrast,natural language processing benefits from a unified output space, i.e., textsequences, which simplifies the training of powerful foundational languagemodels, such as GPT-3, with extensive training corpora. Inspired by this, weseek to unify the output space of video understanding tasks by using languagesas labels and additionally introducing time and box tokens. In this way, avariety of video tasks could be formulated as video-grounded token generation.This enables us to address various types of video tasks, includingclassification (such as action recognition), captioning (covering clipcaptioning, video question answering, and dense video captioning), andlocalization tasks (such as visual object tracking) within a fully sharedencoder-decoder architecture, following a generative framework. Throughcomprehensive experiments, we demonstrate such a simple and straightforwardidea is quite effective and can achieve state-of-the-art or competitive resultson seven video benchmarks, providing a novel perspective for more universalvideo understanding. Code is available at https://github.com/wangjk666/OmniVid.</description><author>Junke Wang, Dongdong Chen, Chong Luo, Bo He, Lu Yuan, Zuxuan Wu, Yu-Gang Jiang</author><pubDate>Tue, 26 Mar 2024 18:59:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17935v1</guid></item><item><title>AiOS: All-in-One-Stage Expressive Human Pose and Shape Estimation</title><link>http://arxiv.org/abs/2403.17934v1</link><description>Expressive human pose and shape estimation (a.k.a. 3D whole-body meshrecovery) involves the human body, hand, and expression estimation. Mostexisting methods have tackled this task in a two-stage manner, first detectingthe human body part with an off-the-shelf detection model and inferring thedifferent human body parts individually. Despite the impressive resultsachieved, these methods suffer from 1) loss of valuable contextual informationvia cropping, 2) introducing distractions, and 3) lacking inter-associationamong different persons and body parts, inevitably causing performancedegradation, especially for crowded scenes. To address these issues, weintroduce a novel all-in-one-stage framework, AiOS, for multiple expressivehuman pose and shape recovery without an additional human detection step.Specifically, our method is built upon DETR, which treats multi-personwhole-body mesh recovery task as a progressive set prediction problem withvarious sequential detection. We devise the decoder tokens and extend them toour task. Specifically, we first employ a human token to probe a human locationin the image and encode global features for each instance, which provides acoarse location for the later transformer block. Then, we introduce ajoint-related token to probe the human joint in the image and encoder afine-grained local feature, which collaborates with the global feature toregress the whole-body mesh. This straightforward but effective modeloutperforms previous state-of-the-art methods by a 9% reduction in NMVE onAGORA, a 30% reduction in PVE on EHF, a 10% reduction in PVE on ARCTIC, and a3% reduction in PVE on EgoBody.</description><author>Qingping Sun, Yanjun Wang, Ailing Zeng, Wanqi Yin, Chen Wei, Wenjia Wang, Haiyi Mei, Chi Sing Leung, Ziwei Liu, Lei Yang, Zhongang Cai</author><pubDate>Tue, 26 Mar 2024 18:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17934v1</guid></item><item><title>LocalTweets to LocalHealth: A Mental Health Surveillance Framework Based on Twitter Data</title><link>http://arxiv.org/abs/2402.13452v2</link><description>Prior research on Twitter (now X) data has provided positive evidence of itsutility in developing supplementary health surveillance systems. In this study,we present a new framework to surveil public health, focusing on mental health(MH) outcomes. We hypothesize that locally posted tweets are indicative oflocal MH outcomes and collect tweets posted from 765 neighborhoods (censusblock groups) in the USA. We pair these tweets from each neighborhood with thecorresponding MH outcome reported by the Center for Disease Control (CDC) tocreate a benchmark dataset, LocalTweets. With LocalTweets, we present the firstpopulation-level evaluation task for Twitter-based MH surveillance systems. Wethen develop an efficient and effective method, LocalHealth, for predicting MHoutcomes based on LocalTweets. When used with GPT3.5, LocalHealth achieves thehighest F1-score and accuracy of 0.7429 and 79.78\%, respectively, a 59\%improvement in F1-score over the GPT3.5 in zero-shot setting. We also utilizeLocalHealth to extrapolate CDC's estimates to proxy unreported neighborhoods,achieving an F1-score of 0.7291. Our work suggests that Twitter data can beeffectively leveraged to simulate neighborhood-level MH outcomes.</description><author>Vijeta Deshpande, Minhwa Lee, Zonghai Yao, Zihao Zhang, Jason Brian Gibbons, Hong Yu</author><pubDate>Tue, 26 Mar 2024 18:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13452v2</guid></item><item><title>Simple and Scalable Strategies to Continually Pre-train Large Language Models</title><link>http://arxiv.org/abs/2403.08763v3</link><description>Large language models (LLMs) are routinely pre-trained on billions of tokens,only to start the process over again once new data becomes available. A muchmore efficient solution is to continually pre-train these models, savingsignificant compute compared to re-training. However, the distribution shiftinduced by new data typically results in degraded performance on previous dataor poor adaptation to the new data. In this work, we show that a simple andscalable combination of learning rate (LR) re-warming, LR re-decaying, andreplay of previous data is sufficient to match the performance of fullyre-training from scratch on all available data, as measured by the final lossand the average score on several language model (LM) evaluation benchmarks.Specifically, we show this for a weak but realistic distribution shift betweentwo commonly used LLM pre-training datasets (English$\rightarrow$English) and astronger distribution shift (English$\rightarrow$German) at the $405$Mparameter model scale with large dataset sizes (hundreds of billions oftokens). Selecting the weak but realistic shift for larger-scale experiments,we also find that our continual learning strategies match the re-trainingbaseline for a 10B parameter LLM. Our results demonstrate that LLMs can besuccessfully updated via simple and scalable continual learning strategies,matching the re-training baseline using only a fraction of the compute.Finally, inspired by previous work, we propose alternatives to the cosinelearning rate schedule that help circumvent forgetting induced by LR re-warmingand that are not bound to a fixed token budget.</description><author>Adam Ibrahim, Benjamin Thérien, Kshitij Gupta, Mats L. Richter, Quentin Anthony, Timothée Lesort, Eugene Belilovsky, Irina Rish</author><pubDate>Tue, 26 Mar 2024 18:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08763v3</guid></item><item><title>SLEDGE: Synthesizing Simulation Environments for Driving Agents with Generative Models</title><link>http://arxiv.org/abs/2403.17933v1</link><description>SLEDGE is the first generative simulator for vehicle motion planning trainedon real-world driving logs. Its core component is a learned model that is ableto generate agent bounding boxes and lane graphs. The model's outputs serve asan initial state for traffic simulation. The unique properties of the entitiesto be generated for SLEDGE, such as their connectivity and variable count perscene, render the naive application of most modern generative models to thistask non-trivial. Therefore, together with a systematic study of existing lanegraph representations, we introduce a novel raster-to-vector autoencoder(RVAE). It encodes agents and the lane graph into distinct channels in arasterized latent map. This facilitates both lane-conditioned agent generationand combined generation of lanes and agents with a Diffusion Transformer. Usinggenerated entities in SLEDGE enables greater control over the simulation, e.g.upsampling turns or increasing traffic density. Further, SLEDGE can support500m long routes, a capability not found in existing data-driven simulatorslike nuPlan. It presents new challenges for planning algorithms, evidenced byfailure rates of over 40% for PDM, the winner of the 2023 nuPlan challenge,when tested on hard routes and dense traffic generated by our model. Comparedto nuPlan, SLEDGE requires 500$\times$ less storage to set up (&lt;4GB), making ita more accessible option and helping with democratizing future research in thisfield.</description><author>Kashyap Chitta, Daniel Dauner, Andreas Geiger</author><pubDate>Tue, 26 Mar 2024 18:58:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17933v1</guid></item><item><title>Track Everything Everywhere Fast and Robustly</title><link>http://arxiv.org/abs/2403.17931v1</link><description>We propose a novel test-time optimization approach for efficiently androbustly tracking any pixel at any time in a video. The latest state-of-the-artoptimization-based tracking technique, OmniMotion, requires a prohibitivelylong optimization time, rendering it impractical for downstream applications.OmniMotion is sensitive to the choice of random seeds, leading to unstableconvergence. To improve efficiency and robustness, we introduce a novelinvertible deformation network, CaDeX++, which factorizes the functionrepresentation into a local spatial-temporal feature grid and enhances theexpressivity of the coupling blocks with non-linear functions. While CaDeX++incorporates a stronger geometric bias within its architectural design, it alsotakes advantage of the inductive bias provided by the vision foundation models.Our system utilizes monocular depth estimation to represent scene geometry andenhances the objective by incorporating DINOv2 long-term semantics to regulatethe optimization process. Our experiments demonstrate a substantial improvementin training speed (more than \textbf{10 times} faster), robustness, andaccuracy in tracking over the SoTA optimization-based method OmniMotion.</description><author>Yunzhou Song, Jiahui Lei, Ziyun Wang, Lingjie Liu, Kostas Daniilidis</author><pubDate>Tue, 26 Mar 2024 18:58:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17931v1</guid></item><item><title>Towards Explaining Hypercomplex Neural Networks</title><link>http://arxiv.org/abs/2403.17929v1</link><description>Hypercomplex neural networks are gaining increasing interest in the deeplearning community. The attention directed towards hypercomplex modelsoriginates from several aspects, spanning from purely theoretical andmathematical characteristics to the practical advantage of lightweight modelsover conventional networks, and their unique properties to capture both globaland local relations. In particular, a branch of these architectures,parameterized hypercomplex neural networks (PHNNs), has also gained popularitydue to their versatility across a multitude of application domains.Nonetheless, only few attempts have been made to explain or interpret theirintricacies. In this paper, we propose inherently interpretable PHNNs andquaternion-like networks, thus without the need for any post-hoc method. Toachieve this, we define a type of cosine-similarity transform within theparameterized hypercomplex domain. This PHB-cos transform induces weightalignment with relevant input features and allows to reduce the model into asingle linear transform, rendering it directly interpretable. In this work, westart to draw insights into how this unique branch of neural models operates.We observe that hypercomplex networks exhibit a tendency to concentrate on theshape around the main object of interest, in addition to the shape of theobject itself. We provide a thorough analysis, studying single neurons ofdifferent layers and comparing them against how real-valued networks learn. Thecode of the paper is available at https://github.com/ispamm/HxAI.</description><author>Eleonora Lopez, Eleonora Grassucci, Debora Capriotti, Danilo Comminiello</author><pubDate>Tue, 26 Mar 2024 18:58:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17929v1</guid></item><item><title>MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution</title><link>http://arxiv.org/abs/2403.17927v1</link><description>In software evolution, resolving the emergent issues within GitHubrepositories is a complex challenge that involves not only the incorporation ofnew code but also the maintenance of existing functionalities. Large LanguageModels (LLMs) have shown promise in code generation and understanding but facedifficulties in code change, particularly at the repository level. To overcomethese challenges, we empirically study the reason why LLMs mostly fail toresolve GitHub issues and analyze some impact factors. Motivated by theempirical findings, we propose a novel LLM-based Multi-Agent framework forGitHub Issue reSolution, MAGIS, consisting of four kinds of agents customizedfor the software evolution: Manager, Repository Custodian, Developer, andQuality Assurance Engineer agents. This framework leverages the collaborationof various agents in the planning and coding process to unlock the potential ofLLMs to resolve GitHub issues. In experiments, we employ the SWE-benchbenchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, andClaude-2. MAGIS can resolve 13.94% GitHub issues, which significantlyoutperforms the baselines. Specifically, MAGIS achieves an eight-fold increasein resolved ratio over the direct application of GPT-4, the based LLM of ourmethod. We also analyze the factors for improving GitHub issue resolutionrates, such as line location, task allocation, etc.</description><author>Wei Tao, Yucheng Zhou, Wenqiang Zhang, Yu Cheng</author><pubDate>Tue, 26 Mar 2024 18:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17927v1</guid></item><item><title>FastCAR: Fast Classification And Regression Multi-Task Learning via Task Consolidation for Modelling a Continuous Property Variable of Object Classes</title><link>http://arxiv.org/abs/2403.17926v1</link><description>FastCAR is a novel task consolidation approach in Multi-Task Learning (MTL)for a classification and a regression task, despite task heterogeneity withonly subtle correlation. It addresses object classification and continuousproperty variable regression, a crucial use case in science and engineering.FastCAR involves a labeling transformation approach that can be used with asingle-task regression network architecture. FastCAR outperforms traditionalMTL model families, parametrized in the landscape of architecture and lossweighting schemes, when learning of both tasks are collectively considered(classification accuracy of 99.54%, regression mean absolute percentage errorof 2.3%). The experiments performed used an Advanced Steel Property datasetcontributed by us. The dataset comprises 4536 images of 224x224 pixels,annotated with object classes and hardness properties that take continuousvalues. With the labeling transformation and single-task regression networkarchitecture, FastCAR achieves reduced latency and time efficiency.</description><author>Anoop Kini, Andreas Jansche, Timo Bernthaler, Gerhard Schneider</author><pubDate>Tue, 26 Mar 2024 18:57:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17926v1</guid></item><item><title>AID: Attention Interpolation of Text-to-Image Diffusion</title><link>http://arxiv.org/abs/2403.17924v1</link><description>Conditional diffusion models can create unseen images in various settings,aiding image interpolation. Interpolation in latent spaces is well-studied, butinterpolation with specific conditions like text or poses is less understood.Simple approaches, such as linear interpolation in the space of conditions,often result in images that lack consistency, smoothness, and fidelity. To thatend, we introduce a novel training-free technique named Attention Interpolationvia Diffusion (AID). Our key contributions include 1) proposing an inner/outerinterpolated attention layer; 2) fusing the interpolated attention withself-attention to boost fidelity; and 3) applying beta distribution toselection to increase smoothness. We also present a variant, Prompt-guidedAttention Interpolation via Diffusion (PAID), that considers interpolation as acondition-dependent generative process. This method enables the creation of newimages with greater consistency, smoothness, and efficiency, and offers controlover the exact path of interpolation. Our approach demonstrates effectivenessfor conceptual and spatial interpolation. Code and demo are available athttps://github.com/QY-H00/attention-interpolation-diffusion.</description><author>Qiyuan He, Jinghao Wang, Ziwei Liu, Angela Yao</author><pubDate>Tue, 26 Mar 2024 18:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17924v1</guid></item><item><title>The Need for Speed: Pruning Transformers with One Recipe</title><link>http://arxiv.org/abs/2403.17921v1</link><description>We introduce the $\textbf{O}$ne-shot $\textbf{P}$runing $\textbf{T}$echniquefor $\textbf{I}$nterchangeable $\textbf{N}$etworks ($\textbf{OPTIN}$) frameworkas a tool to increase the efficiency of pre-trained transformer architectures$\textit{without requiring re-training}$. Recent works have explored improvingtransformer efficiency, however often incur computationally expensivere-training procedures or depend on architecture-specific characteristics, thusimpeding practical wide-scale adoption. To address these shortcomings, theOPTIN framework leverages intermediate feature distillation, capturing thelong-range dependencies of model parameters (coined $\textit{trajectory}$), toproduce state-of-the-art results on natural language, image classification,transfer learning, and semantic segmentation tasks $\textit{withoutre-training}$. Given a FLOP constraint, the OPTIN framework will compress thenetwork while maintaining competitive accuracy performance and improvedthroughput. Particularly, we show a $\leq 2$% accuracy degradation from NLPbaselines and a $0.5$% improvement from state-of-the-art methods on imageclassification at competitive FLOPs reductions. We further demonstrate thegeneralization of tasks and architecture with comparative performance usingMask2Former for semantic segmentation and cnn-style networks. OPTIN presentsone of the first one-shot efficient frameworks for compressing transformerarchitectures that generalizes well across different class domains, inparticular: natural language and image-related tasks, without$\textit{re-training}$.</description><author>Samir Khaki, Konstantinos N. Plataniotis</author><pubDate>Tue, 26 Mar 2024 18:55:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17921v1</guid></item><item><title>TC4D: Trajectory-Conditioned Text-to-4D Generation</title><link>http://arxiv.org/abs/2403.17920v1</link><description>Recent techniques for text-to-4D generation synthesize dynamic 3D scenesusing supervision from pre-trained text-to-video models. However, existingrepresentations for motion, such as deformation models or time-dependent neuralrepresentations, are limited in the amount of motion they can generate-theycannot synthesize motion extending far beyond the bounding box used for volumerendering. The lack of a more flexible motion model contributes to the gap inrealism between 4D generation methods and recent, near-photorealistic videogeneration models. Here, we propose TC4D: trajectory-conditioned text-to-4Dgeneration, which factors motion into global and local components. We representthe global motion of a scene's bounding box using rigid transformation along atrajectory parameterized by a spline. We learn local deformations that conformto the global trajectory using supervision from a text-to-video model. Ourapproach enables the synthesis of scenes animated along arbitrary trajectories,compositional scene generation, and significant improvements to the realism andamount of generated motion, which we evaluate qualitatively and through a userstudy. Video results can be viewed on our website:https://sherwinbahmani.github.io/tc4d.</description><author>Sherwin Bahmani, Xian Liu, Yifan Wang, Ivan Skorokhodov, Victor Rong, Ziwei Liu, Xihui Liu, Jeong Joon Park, Sergey Tulyakov, Gordon Wetzstein, Andrea Tagliasacchi, David B. Lindell</author><pubDate>Tue, 26 Mar 2024 18:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17920v1</guid></item><item><title>LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning</title><link>http://arxiv.org/abs/2403.17919v1</link><description>The machine learning community has witnessed impressive advancements sincethe first appearance of large language models (LLMs), yet their huge memoryconsumption has become a major roadblock to large-scale training. ParameterEfficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have beenproposed to alleviate this problem, but their performance still fails to matchfull parameter training in most large-scale fine-tuning settings. Attempting tocomplement this deficiency, we investigate layerwise properties of LoRA onfine-tuning tasks and observe an uncommon skewness of weight norms acrossdifferent layers. Utilizing this key observation, a surprisingly simpletraining strategy is discovered, which outperforms both LoRA and full parametertraining in a wide range of settings with memory costs as low as LoRA. We nameit Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA,which applies the idea of importance sampling to different layers in LLMs andrandomly freeze most middle layers during optimization. Experimental resultsshow that with similar or less GPU memory consumption, LISA surpasses LoRA oreven full parameter tuning in downstream fine-tuning tasks, where LISAconsistently outperforms LoRA by over $11\%$-$37\%$ in terms of MT-Benchscores. On large models, specifically LLaMA-2-70B, LISA achieves on-par orbetter performance than LoRA on MT-Bench, GSM8K, and PubMedQA, demonstratingits effectiveness across different domains.</description><author>Rui Pan, Xiang Liu, Shizhe Diao, Renjie Pi, Jipeng Zhang, Chi Han, Tong Zhang</author><pubDate>Tue, 26 Mar 2024 18:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17919v1</guid></item><item><title>AgentStudio: A Toolkit for Building General Virtual Agents</title><link>http://arxiv.org/abs/2403.17918v1</link><description>Creating autonomous virtual agents capable of using arbitrary software on anydigital device remains a major challenge for artificial intelligence. Two keyobstacles hinder progress: insufficient infrastructure for building virtualagents in real-world environments, and the need for in-the-wild evaluation offundamental agent abilities. To address this, we introduce AgentStudio, anonline, realistic, and multimodal toolkit that covers the entire lifecycle ofagent development. This includes environment setups, data collection, agentevaluation, and visualization. The observation and action spaces are highlygeneric, supporting both function calling and human-computer interfaces. Thisversatility is further enhanced by AgentStudio's graphical user interfaces,which allow efficient development of datasets and benchmarks in real-worldsettings. To illustrate, we introduce a visual grounding dataset and areal-world benchmark suite, both created with our graphical interfaces.Furthermore, we present several actionable insights derived from AgentStudio,e.g., general visual grounding, open-ended tool creation, learning from videos,etc. We have open-sourced the environments, datasets, benchmarks, andinterfaces to promote research towards developing general virtual agents forthe future.</description><author>Longtao Zheng, Zhiyuan Huang, Zhenghai Xue, Xinrun Wang, Bo An, Shuicheng Yan</author><pubDate>Tue, 26 Mar 2024 18:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17918v1</guid></item><item><title>CMP: Cooperative Motion Prediction with Multi-Agent Communication</title><link>http://arxiv.org/abs/2403.17916v1</link><description>The confluence of the advancement of Autonomous Vehicles (AVs) and thematurity of Vehicle-to-Everything (V2X) communication has enabled thecapability of cooperative connected and automated vehicles (CAVs). Building ontop of cooperative perception, this paper explores the feasibility andeffectiveness of cooperative motion prediction. Our method, CMP, takes LiDARsignals as input to enhance tracking and prediction capabilities. Unlikeprevious work that focuses separately on either cooperative perception ormotion prediction, our framework, to the best of our knowledge, is the first toaddress the unified problem where CAVs share information in both perception andprediction modules. Incorporated into our design is the unique capability totolerate realistic V2X bandwidth limitations and transmission delays, whiledealing with bulky perception representations. We also propose a predictionaggregation module, which unifies the predictions obtained by different CAVsand generates the final prediction. Through extensive experiments and ablationstudies, we demonstrate the effectiveness of our method in cooperativeperception, tracking, and motion prediction tasks. In particular, CMP reducesthe average prediction error by 17.2\% with fewer missing detections comparedwith the no cooperation setting. Our work marks a significant step forward inthe cooperative capabilities of CAVs, showcasing enhanced performance incomplex scenarios.</description><author>Zhuoyuan Wu, Yuping Wang, Hengbo Ma, Zhaowei Li, Hang Qiu, Jiachen Li</author><pubDate>Tue, 26 Mar 2024 18:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17916v1</guid></item><item><title>Leveraging Near-Field Lighting for Monocular Depth Estimation from Endoscopy Videos</title><link>http://arxiv.org/abs/2403.17915v1</link><description>Monocular depth estimation in endoscopy videos can enable assistive androbotic surgery to obtain better coverage of the organ and detection of varioushealth issues. Despite promising progress on mainstream, natural image depthestimation, techniques perform poorly on endoscopy images due to a lack ofstrong geometric features and challenging illumination effects. In this paper,we utilize the photometric cues, i.e., the light emitted from an endoscope andreflected by the surface, to improve monocular depth estimation. We firstcreate two novel loss functions with supervised and self-supervised variantsthat utilize a per-pixel shading representation. We then propose a novel depthrefinement network (PPSNet) that leverages the same per-pixel shadingrepresentation. Finally, we introduce teacher-student transfer learning toproduce better depth maps from both synthetic data with supervision andclinical data with self-supervision. We achieve state-of-the-art results on theC3VD dataset while estimating high-quality depth maps from clinical data. Ourcode, pre-trained models, and supplementary materials can be found on ourproject page: https://ppsnet.github.io/</description><author>Akshay Paruchuri, Samuel Ehrenstein, Shuxian Wang, Inbar Fried, Stephen M. Pizer, Marc Niethammer, Roni Sengupta</author><pubDate>Tue, 26 Mar 2024 18:52:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17915v1</guid></item><item><title>Hierarchical Multi-label Classification for Fine-level Event Extraction from Aviation Accident Reports</title><link>http://arxiv.org/abs/2403.17914v1</link><description>A large volume of accident reports is recorded in the aviation domain, whichgreatly values improving aviation safety. To better use those reports, we needto understand the most important events or impact factors according to theaccident reports. However, the increasing number of accident reports requireslarge efforts from domain experts to label those reports. In order to make thelabeling process more efficient, many researchers have started developingalgorithms to identify the underlying events from accident reportsautomatically. This article argues that we can identify the events moreaccurately by leveraging the event taxonomy. More specifically, we consider theproblem a hierarchical classification task where we first identify thecoarse-level information and then predict the fine-level information. Weachieve this hierarchical classification process by incorporating a novelhierarchical attention module into BERT. To further utilize the informationfrom event taxonomy, we regularize the proposed model according to therelationship and distribution among labels. The effectiveness of our frameworkis evaluated with the data collected by National Transportation Safety Board(NTSB). It has been shown that fine-level prediction accuracy is highlyimproved, and the regularization term can be beneficial to the rare eventidentification problem.</description><author>Xinyu Zhao, Hao Yan, Yongming Liu</author><pubDate>Tue, 26 Mar 2024 18:51:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17914v1</guid></item><item><title>Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling</title><link>http://arxiv.org/abs/2403.16248v2</link><description>Topic modelling, as a well-established unsupervised technique, has foundextensive use in automatically detecting significant topics within a corpus ofdocuments. However, classic topic modelling approaches (e.g., LDA) have certaindrawbacks, such as the lack of semantic understanding and the presence ofoverlapping topics. In this work, we investigate the untapped potential oflarge language models (LLMs) as an alternative for uncovering the underlyingtopics within extensive text corpora. To this end, we introduce a frameworkthat prompts LLMs to generate topics from a given set of documents andestablish evaluation protocols to assess the clustering efficacy of LLMs. Ourfindings indicate that LLMs with appropriate prompts can stand out as a viablealternative, capable of generating relevant topic titles and adhering to humanguidelines to refine and merge topics. Through in-depth experiments andevaluation, we summarise the advantages and constraints of employing LLMs intopic extraction.</description><author>Yida Mu, Chun Dong, Kalina Bontcheva, Xingyi Song</author><pubDate>Tue, 26 Mar 2024 18:46:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.16248v2</guid></item><item><title>ELGC-Net: Efficient Local-Global Context Aggregation for Remote Sensing Change Detection</title><link>http://arxiv.org/abs/2403.17909v1</link><description>Deep learning has shown remarkable success in remote sensing change detection(CD), aiming to identify semantic change regions between co-registeredsatellite image pairs acquired at distinct time stamps. However, existingconvolutional neural network and transformer-based frameworks often struggle toaccurately segment semantic change regions. Moreover, transformers-basedmethods with standard self-attention suffer from quadratic computationalcomplexity with respect to the image resolution, making them less practical forCD tasks with limited training data. To address these issues, we propose anefficient change detection framework, ELGC-Net, which leverages rich contextualinformation to precisely estimate change regions while reducing the model size.Our ELGC-Net comprises a Siamese encoder, fusion modules, and a decoder. Thefocus of our design is the introduction of an Efficient Local-Global ContextAggregator module within the encoder, capturing enhanced global context andlocal spatial information through a novel pooled-transpose (PT) attention anddepthwise convolution, respectively. The PT attention employs poolingoperations for robust feature extraction and minimizes computational cost withtransposed attention. Extensive experiments on three challenging CD datasetsdemonstrate that ELGC-Net outperforms existing methods. Compared to the recenttransformer-based CD approach (ChangeFormer), ELGC-Net achieves a 1.4% gain inintersection over union metric on the LEVIR-CD dataset, while significantlyreducing trainable parameters. Our proposed ELGC-Net sets a newstate-of-the-art performance in remote sensing change detection benchmarks.Finally, we also introduce ELGC-Net-LW, a lighter variant with significantlyreduced computational complexity, suitable for resource-constrained settings,while achieving comparable performance. Project urlhttps://github.com/techmn/elgcnet.</description><author>Mubashir Noman, Mustansar Fiaz, Hisham Cholakkal, Salman Khan, Fahad Shahbaz Khan</author><pubDate>Tue, 26 Mar 2024 18:46:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17909v1</guid></item><item><title>Scalable Non-Cartesian Magnetic Resonance Imaging with R2D2</title><link>http://arxiv.org/abs/2403.17905v1</link><description>We propose a new approach for non-Cartesian magnetic resonance imagereconstruction. While unrolled architectures provide robustness viadata-consistency layers, embedding measurement operators in Deep Neural Network(DNN) can become impractical at large scale. Alternative Plug-and-Play (PnP)approaches, where the denoising DNNs are blind to the measurement setting, arenot affected by this limitation and have also proven effective, but theirhighly iterative nature also affects scalability. To address this scalabilitychallenge, we leverage the "Residual-to-Residual DNN series for high-Dynamicrange imaging (R2D2)" approach recently introduced in astronomical imaging.R2D2's reconstruction is formed as a series of residual images, iterativelyestimated as outputs of DNNs taking the previous iteration's image estimate andassociated data residual as inputs. The method can be interpreted as a learnedversion of the Matching Pursuit algorithm. We demonstrate R2D2 in simulation,considering radial k-space sampling acquisition sequences. Our preliminaryresults suggest that R2D2 achieves: (i) suboptimal performance compared to itsunrolled incarnation R2D2-Net, which is however non-scalable due to thenecessary embedding of NUFFT-based data-consistency layers; (ii) superiorreconstruction quality to a scalable version of R2D2-Net embedding an FFT-basedapproximation for data consistency; (iii) superior reconstruction quality toPnP, while only requiring few iterations.</description><author>Chen Yiwei, Tang Chao, Aghabiglou Amir, Chu Chung San, Wiaux Yves</author><pubDate>Tue, 26 Mar 2024 18:45:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17905v1</guid></item><item><title>An optimal control perspective on diffusion-based generative modeling</title><link>http://arxiv.org/abs/2211.01364v3</link><description>We establish a connection between stochastic optimal control and generativemodels based on stochastic differential equations (SDEs), such as recentlydeveloped diffusion probabilistic models. In particular, we derive aHamilton-Jacobi-Bellman equation that governs the evolution of thelog-densities of the underlying SDE marginals. This perspective allows totransfer methods from optimal control theory to generative modeling. First, weshow that the evidence lower bound is a direct consequence of the well-knownverification theorem from control theory. Further, we can formulatediffusion-based generative modeling as a minimization of the Kullback-Leiblerdivergence between suitable measures in path space. Finally, we develop a noveldiffusion-based method for sampling from unnormalized densities -- a problemfrequently occurring in statistics and computational sciences. We demonstratethat our time-reversed diffusion sampler (DIS) can outperform otherdiffusion-based sampling approaches on multiple numerical examples.</description><author>Julius Berner, Lorenz Richter, Karen Ullrich</author><pubDate>Tue, 26 Mar 2024 18:45:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.01364v3</guid></item><item><title>Fully Independent Communication in Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2401.15059v2</link><description>Multi-Agent Reinforcement Learning (MARL) comprises a broad area of researchwithin the field of multi-agent systems. Several recent works have focusedspecifically on the study of communication approaches in MARL. While multiplecommunication methods have been proposed, these might still be too complex andnot easily transferable to more practical contexts. One of the reasons for thatis due to the use of the famous parameter sharing trick. In this paper, weinvestigate how independent learners in MARL that do not share parameters cancommunicate. We demonstrate that this setting might incur into some problems,to which we propose a new learning scheme as a solution. Our results show that,despite the challenges, independent agents can still learn communicationstrategies following our method. Additionally, we use this method toinvestigate how communication in MARL is affected by different networkcapacities, both for sharing and not sharing parameters. We observe thatcommunication may not always be needed and that the chosen agent network sizesneed to be considered when used together with communication in order to achieveefficient learning.</description><author>Rafael Pina, Varuna De Silva, Corentin Artaud, Xiaolan Liu</author><pubDate>Tue, 26 Mar 2024 18:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15059v2</guid></item><item><title>Serpent: Scalable and Efficient Image Restoration via Multi-scale Structured State Space Models</title><link>http://arxiv.org/abs/2403.17902v1</link><description>The landscape of computational building blocks of efficient image restorationarchitectures is dominated by a combination of convolutional processing andvarious attention mechanisms. However, convolutional filters are inherentlylocal and therefore struggle at modeling long-range dependencies in images. Onthe other hand, attention excels at capturing global interactions betweenarbitrary image regions, however at a quadratic cost in image dimension. Inthis work, we propose Serpent, an architecture that leverages recent advancesin state space models (SSMs) in its core computational block. SSMs, originallyintroduced for sequence modeling, can maintain a global receptive field with afavorable linear scaling in input size. Our preliminary results demonstratethat Serpent can achieve reconstruction quality on par with state-of-the-arttechniques, while requiring orders of magnitude less compute (up to $150$ foldreduction in FLOPS) and a factor of up to $5\times$ less GPU memory whilemaintaining a compact model size.</description><author>Mohammad Shahab Sepehri, Zalan Fabian, Mahdi Soltanolkotabi</author><pubDate>Tue, 26 Mar 2024 18:43:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17902v1</guid></item><item><title>DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields</title><link>http://arxiv.org/abs/2307.16897v2</link><description>Advances in neural fields are enabling high-fidelity capture of the shape andappearance of dynamic 3D scenes. However, their capabilities lag behind thoseoffered by conventional representations such as 2D videos because ofalgorithmic challenges and the lack of large-scale multi-view real-worlddatasets. We address the dataset limitation with DiVa-360, a real-world 360dynamic visual dataset that contains synchronized high-resolution andlong-duration multi-view video sequences of table-scale scenes captured using acustomized low-cost system with 53 cameras. It contains 21 object-centricsequences categorized by different motion types, 25 intricate hand-objectinteraction sequences, and 8 long-duration sequences for a total of 17.4 Mimage frames. In addition, we provide foreground-background segmentation masks,synchronized audio, and text descriptions. We benchmark the state-of-the-artdynamic neural field methods on DiVa-360 and provide insights about existingmethods and future challenges on long-duration neural field capture.</description><author>Cheng-You Lu, Peisen Zhou, Angela Xing, Chandradeep Pokhariya, Arnab Dey, Ishaan Shah, Rugved Mavidipalli, Dylan Hu, Andrew Comport, Kefan Chen, Srinath Sridhar</author><pubDate>Tue, 26 Mar 2024 18:40:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16897v2</guid></item><item><title>Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians</title><link>http://arxiv.org/abs/2403.17898v1</link><description>The recent 3D Gaussian splatting (3D-GS) has shown remarkable renderingfidelity and efficiency compared to NeRF-based neural scene representations.While demonstrating the potential for real-time rendering, 3D-GS encountersrendering bottlenecks in large scenes with complex details due to an excessivenumber of Gaussian primitives located within the viewing frustum. Thislimitation is particularly noticeable in zoom-out views and can lead toinconsistent rendering speeds in scenes with varying details. Moreover, itoften struggles to capture the corresponding level of details at differentscales with its heuristic density control operation. Inspired by theLevel-of-Detail (LOD) techniques, we introduce Octree-GS, featuring anLOD-structured 3D Gaussian approach supporting level-of-detail decompositionfor scene representation that contributes to the final rendering results. Ourmodel dynamically selects the appropriate level from the set ofmulti-resolution anchor points, ensuring consistent rendering performance withadaptive LOD adjustments while maintaining high-fidelity rendering results.</description><author>Kerui Ren, Lihan Jiang, Tao Lu, Mulin Yu, Linning Xu, Zhangkai Ni, Bo Dai</author><pubDate>Tue, 26 Mar 2024 18:39:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17898v1</guid></item><item><title>A randomized algorithm for nonconvex minimization with inexact evaluations and complexity guarantees</title><link>http://arxiv.org/abs/2310.18841v2</link><description>We consider minimization of a smooth nonconvex function with inexact oracleaccess to gradient and Hessian (without assuming access to the function value)to achieve approximate second-order optimality. A novel feature of our methodis that if an approximate direction of negative curvature is chosen as thestep, we choose its sense to be positive or negative with equal probability. Weallow gradients to be inexact in a relative sense and relax the couplingbetween inexactness thresholds for the first- and second-order optimalityconditions. Our convergence analysis includes both an expectation bound basedon martingale analysis and a high-probability bound based on concentrationinequalities. We apply our algorithm to empirical risk minimization problemsand obtain improved gradient sample complexity over existing works.</description><author>Shuyao Li, Stephen J. Wright</author><pubDate>Tue, 26 Mar 2024 18:39:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18841v2</guid></item><item><title>Borrowing Treasures from Neighbors: In-Context Learning for Multimodal Learning with Missing Modalities and Data Scarcity</title><link>http://arxiv.org/abs/2403.09428v2</link><description>Multimodal machine learning with missing modalities is an increasinglyrelevant challenge arising in various applications such as healthcare. Thispaper extends the current research into missing modalities to the low-dataregime, i.e., a downstream task has both missing modalities and limited samplesize issues. This problem setting is particularly challenging and alsopractical as it is often expensive to get full-modality data and sufficientannotated training samples. We propose to use retrieval-augmented in-contextlearning to address these two crucial issues by unleashing the potential of atransformer's in-context learning ability. Diverging from existing methods,which primarily belong to the parametric paradigm and often require sufficienttraining samples, our work exploits the value of the available full-modalitydata, offering a novel perspective on resolving the challenge. The proposeddata-dependent framework exhibits a higher degree of sample efficiency and isempirically demonstrated to enhance the classification model's performance onboth full- and missing-modality data in the low-data regime across variousmultimodal learning tasks. When only 1% of the training data are available, ourproposed method demonstrates an average improvement of 6.1% over a recentstrong baseline across various datasets and missing states. Notably, our methodalso reduces the performance gap between full-modality and missing-modalitydata compared with the baseline.</description><author>Zhuo Zhi, Ziquan Liu, Moe Elbadawi, Adam Daneshmend, Mine Orlu, Abdul Basit, Andreas Demosthenous, Miguel Rodrigues</author><pubDate>Tue, 26 Mar 2024 18:38:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09428v2</guid></item><item><title>Probabilistically Rewired Message-Passing Neural Networks</title><link>http://arxiv.org/abs/2310.02156v4</link><description>Message-passing graph neural networks (MPNNs) emerged as powerful tools forprocessing graph-structured input. However, they operate on a fixed input graphstructure, ignoring potential noise and missing information. Furthermore, theirlocal aggregation mechanism can lead to problems such as over-squashing andlimited expressive power in capturing relevant graph structures. Existingsolutions to these challenges have primarily relied on heuristic methods, oftendisregarding the underlying data distribution. Hence, devising principledapproaches for learning to infer graph structures relevant to the givenprediction task remains an open challenge. In this work, leveraging recentprogress in exact and differentiable $k$-subset sampling, we deviseprobabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edgeswhile omitting less beneficial ones. For the first time, our theoreticalanalysis explores how PR-MPNNs enhance expressive power, and we identifyprecise conditions under which they outperform purely randomized approaches.Empirically, we demonstrate that our approach effectively mitigates issues likeover-squashing and under-reaching. In addition, on established real-worlddatasets, our method exhibits competitive or superior predictive performancecompared to traditional MPNN models and recent graph transformer architectures.</description><author>Chendi Qian, Andrei Manolache, Kareem Ahmed, Zhe Zeng, Guy Van den Broeck, Mathias Niepert, Christopher Morris</author><pubDate>Tue, 26 Mar 2024 18:36:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02156v4</guid></item><item><title>A Survey on 3D Egocentric Human Pose Estimation</title><link>http://arxiv.org/abs/2403.17893v1</link><description>Egocentric human pose estimation aims to estimate human body poses anddevelop body representations from a first-person camera perspective. It hasgained vast popularity in recent years because of its wide range ofapplications in sectors like XR-technologies, human-computer interaction, andfitness tracking. However, to the best of our knowledge, there is no systematicliterature review based on the proposed solutions regarding egocentric 3D humanpose estimation. To that end, the aim of this survey paper is to provide anextensive overview of the current state of egocentric pose estimation research.In this paper, we categorize and discuss the popular datasets and the differentpose estimation models, highlighting the strengths and weaknesses of differentmethods by comparative analysis. This survey can be a valuable resource forboth researchers and practitioners in the field, offering insights into keyconcepts and cutting-edge solutions in egocentric pose estimation, itswide-ranging applications, as well as the open problems with future scope.</description><author>Md Mushfiqur Azam, Kevin Desai</author><pubDate>Tue, 26 Mar 2024 18:29:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17893v1</guid></item><item><title>Optimal Data Splitting in Distributed Optimization for Machine Learning</title><link>http://arxiv.org/abs/2401.07809v2</link><description>The distributed optimization problem has become increasingly relevantrecently. It has a lot of advantages such as processing a large amount of datain less time compared to non-distributed methods. However, most distributedapproaches suffer from a significant bottleneck - the cost of communications.Therefore, a large amount of research has recently been directed at solvingthis problem. One such approach uses local data similarity. In particular,there exists an algorithm provably optimally exploiting the similarityproperty. But this result, as well as results from other works solve thecommunication bottleneck by focusing only on the fact that communication issignificantly more expensive than local computing and does not take intoaccount the various capacities of network devices and the differentrelationship between communication time and local computing expenses. Weconsider this setup and the objective of this study is to achieve an optimalratio of distributed data between the server and local machines for any costsof communications and local computations. The running times of the network arecompared between uniform and optimal distributions. The superior theoreticalperformance of our solutions is experimentally validated.</description><author>Daniil Medyakov, Gleb Molodtsov, Aleksandr Beznosikov, Alexander Gasnikov</author><pubDate>Tue, 26 Mar 2024 18:29:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07809v2</guid></item><item><title>Image-based Novel Fault Detection with Deep Learning Classifiers using Hierarchical Labels</title><link>http://arxiv.org/abs/2403.17891v1</link><description>One important characteristic of modern fault classification systems is theability to flag the system when faced with previously unseen fault types. Thiswork considers the unknown fault detection capabilities of deep neuralnetwork-based fault classifiers. Specifically, we propose a methodology on how,when available, labels regarding the fault taxonomy can be used to increaseunknown fault detection performance without sacrificing model performance. Toachieve this, we propose to utilize soft label techniques to improve thestate-of-the-art deep novel fault detection techniques during the trainingprocess and novel hierarchically consistent detection statistics for onlinenovel fault detection. Finally, we demonstrated increased detection performanceon novel fault detection in inspection images from the hot steel rollingprocess, with results well replicated across multiple scenarios and baselinedetection methods.</description><author>Nurettin Sergin, Jiayu Huang, Tzyy-Shuh Chang, Hao Yan</author><pubDate>Tue, 26 Mar 2024 18:22:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17891v1</guid></item><item><title>Large scale paired antibody language models</title><link>http://arxiv.org/abs/2403.17889v1</link><description>Antibodies are proteins produced by the immune system that can identify andneutralise a wide variety of antigens with high specificity and affinity, andconstitute the most successful class of biotherapeutics. With the advent ofnext-generation sequencing, billions of antibody sequences have been collectedin recent years, though their application in the design of better therapeuticshas been constrained by the sheer volume and complexity of the data. To addressthis challenge, we present IgBert and IgT5, the best performingantibody-specific language models developed to date which can consistentlyhandle both paired and unpaired variable region sequences as input. Thesemodels are trained comprehensively using the more than two billion unpairedsequences and two million paired sequences of light and heavy chains present inthe Observed Antibody Space dataset. We show that our models outperformexisting antibody and protein language models on a diverse range of design andregression tasks relevant to antibody engineering. This advancement marks asignificant leap forward in leveraging machine learning, large scale data setsand high-performance computing for enhancing antibody design for therapeuticdevelopment.</description><author>Henry Kenlay, Frédéric A. Dreyer, Aleksandr Kovaltsuk, Dom Miketa, Douglas Pires, Charlotte M. Deane</author><pubDate>Tue, 26 Mar 2024 18:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17889v1</guid></item><item><title>2D Gaussian Splatting for Geometrically Accurate Radiance Fields</title><link>http://arxiv.org/abs/2403.17888v1</link><description>3D Gaussian Splatting (3DGS) has recently revolutionized radiance fieldreconstruction, achieving high quality novel view synthesis and fast renderingspeed without baking. However, 3DGS fails to accurately represent surfaces dueto the multi-view inconsistent nature of 3D Gaussians. We present 2D GaussianSplatting (2DGS), a novel approach to model and reconstruct geometricallyaccurate radiance fields from multi-view images. Our key idea is to collapsethe 3D volume into a set of 2D oriented planar Gaussian disks. Unlike 3DGaussians, 2D Gaussians provide view-consistent geometry while modelingsurfaces intrinsically. To accurately recover thin surfaces and achieve stableoptimization, we introduce a perspective-accurate 2D splatting processutilizing ray-splat intersection and rasterization. Additionally, weincorporate depth distortion and normal consistency terms to further enhancethe quality of the reconstructions. We demonstrate that our differentiablerenderer allows for noise-free and detailed geometry reconstruction whilemaintaining competitive appearance quality, fast training speed, and real-timerendering. Our code will be made publicly available.</description><author>Binbin Huang, Zehao Yu, Anpei Chen, Andreas Geiger, Shenghua Gao</author><pubDate>Tue, 26 Mar 2024 18:21:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17888v1</guid></item><item><title>The Unreasonable Ineffectiveness of the Deeper Layers</title><link>http://arxiv.org/abs/2403.17887v1</link><description>We empirically study a simple layer-pruning strategy for popular families ofopen-weight pretrained LLMs, finding minimal degradation of performance ondifferent question-answering benchmarks until after a large fraction (up tohalf) of the layers are removed. To prune these models, we identify the optimalblock of layers to prune by considering similarity across layers; then, to"heal" the damage, we perform a small amount of finetuning. In particular, weuse parameter-efficient finetuning (PEFT) methods, specifically quantizationand Low Rank Adapters (QLoRA), such that each of our experiments can beperformed on a single A100 GPU. From a practical perspective, these resultssuggest that layer pruning methods can complement other PEFT strategies tofurther reduce computational resources of finetuning on the one hand, and canimprove the memory and latency of inference on the other hand. From ascientific perspective, the robustness of these LLMs to the deletion of layersimplies either that current pretraining methods are not properly leveraging theparameters in the deeper layers of the network or that the shallow layers playa critical role in storing knowledge.</description><author>Andrey Gromov, Kushal Tirumala, Hassan Shapourian, Paolo Glorioso, Daniel A. Roberts</author><pubDate>Tue, 26 Mar 2024 18:20:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17887v1</guid></item><item><title>Compressed Multi-task embeddings for Data-Efficient Downstream training and inference in Earth Observation</title><link>http://arxiv.org/abs/2403.17886v1</link><description>As repositories of large scale data in earth observation (EO) have grown, sohave transfer and storage costs for model training and inference, expendingsignificant resources. We introduce Neural Embedding Compression (NEC), basedon the transfer of compressed embeddings to data consumers instead of raw data.We adapt foundation models (FM) through learned neural compression to generatemulti-task embeddings while navigating the tradeoff between compression rateand embedding utility. We update only a small fraction of the FM parameters(10%) for a short training period (1% of the iterations of pre-training). Weevaluate NEC on two EO tasks: scene classification and semantic segmentation.Compared with applying traditional compression to the raw data, NEC achievessimilar accuracy with a 75% to 90% reduction in data. Even at 99.7%compression, performance drops by only 5% on the scene classification task.Overall, NEC is a data-efficient yet performant approach for multi-task EOmodelling.</description><author>Carlos Gomes, Thomas Brunschwiler</author><pubDate>Tue, 26 Mar 2024 18:19:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17886v1</guid></item><item><title>Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents</title><link>http://arxiv.org/abs/2403.04202v3</link><description>Growing concerns about safety and alignment of AI systems highlight theimportance of embedding moral capabilities in artificial agents. A promisingsolution is the use of learning from experience, i.e., Reinforcement Learning.In multi-agent (social) environments, complex population-level phenomena mayemerge from interactions between individual learning agents. Many of theexisting studies rely on simulated social dilemma environments to study theinteractions of independent learning agents. However, they tend to ignore themoral heterogeneity that is likely to be present in societies of agents inpractice. For example, at different points in time a single learning agent mayface opponents who are consequentialist (i.e., caring about maximizing someoutcome over time) or norm-based (i.e., focusing on conforming to a specificnorm here and now). The extent to which agents' co-development may be impactedby such moral heterogeneity in populations is not well understood. In thispaper, we present a study of the learning dynamics of morally heterogeneouspopulations interacting in a social dilemma setting. Using a Prisoner's Dilemmaenvironment with a partner selection mechanism, we investigate the extent towhich the prevalence of diverse moral agents in populations affects individualagents' learning behaviors and emergent population-level outcomes. We observeseveral types of non-trivial interactions between pro-social and anti-socialagents, and find that certain classes of moral agents are able to steer selfishagents towards more cooperative behavior.</description><author>Elizaveta Tennant, Stephen Hailes, Mirco Musolesi</author><pubDate>Tue, 26 Mar 2024 18:18:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04202v3</guid></item><item><title>Safe Explicable Planning</title><link>http://arxiv.org/abs/2304.03773v3</link><description>Human expectations arise from their understanding of others and the world. Inthe context of human-AI interaction, this understanding may not align withreality, leading to the AI agent failing to meet expectations and compromisingteam performance. Explicable planning, introduced as a method to bridge thisgap, aims to reconcile human expectations with the agent's optimal behavior,facilitating interpretable decision-making. However, an unresolved criticalissue is ensuring safety in explicable planning, as it could result inexplicable behaviors that are unsafe. To address this, we propose SafeExplicable Planning (SEP), which extends the prior work to support thespecification of a safety bound. The goal of SEP is to find behaviors thatalign with human expectations while adhering to the specified safety criterion.Our approach generalizes the consideration of multiple objectives stemming frommultiple models rather than a single model, yielding a Pareto set of safeexplicable policies. We present both an exact method, guaranteeing finding thePareto set, and a more efficient greedy method that finds one of the policiesin the Pareto set. Additionally, we offer approximate solutions based on stateaggregation to improve scalability. We provide formal proofs that validate thedesired theoretical properties of these methods. Evaluation through simulationsand physical robot experiments confirms the effectiveness of our approach forsafe explicable planning.</description><author>Akkamahadevi Hanni, Andrew Boateng, Yu Zhang</author><pubDate>Tue, 26 Mar 2024 18:17:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03773v3</guid></item><item><title>Sen2Fire: A Challenging Benchmark Dataset for Wildfire Detection using Sentinel Data</title><link>http://arxiv.org/abs/2403.17884v1</link><description>Utilizing satellite imagery for wildfire detection presents substantialpotential for practical applications. To advance the development of machinelearning algorithms in this domain, our study introduces the \textit{Sen2Fire}dataset--a challenging satellite remote sensing dataset tailored for wildfiredetection. This dataset is curated from Sentinel-2 multi-spectral data andSentinel-5P aerosol product, comprising a total of 2466 image patches. Eachpatch has a size of 512$\times$512 pixels with 13 bands. Given the distinctivesensitivities of various wavebands to wildfire responses, our research focuseson optimizing wildfire detection by evaluating different wavebands andemploying a combination of spectral indices, such as normalized burn ratio(NBR) and normalized difference vegetation index (NDVI). The results suggestthat, in contrast to using all bands for wildfire detection, selecting specificband combinations yields superior performance. Additionally, our studyunderscores the positive impact of integrating Sentinel-5 aerosol data forwildfire detection. The code and dataset are available online(https://zenodo.org/records/10881058).</description><author>Yonghao Xu, Amanda Berg, Leif Haglund</author><pubDate>Tue, 26 Mar 2024 18:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17884v1</guid></item><item><title>HoloVIC: Large-scale Dataset and Benchmark for Multi-Sensor Holographic Intersection and Vehicle-Infrastructure Cooperative</title><link>http://arxiv.org/abs/2403.02640v3</link><description>Vehicle-to-everything (V2X) is a popular topic in the field of AutonomousDriving in recent years. Vehicle-infrastructure cooperation (VIC) becomes oneof the important research area. Due to the complexity of traffic conditionssuch as blind spots and occlusion, it greatly limits the perceptioncapabilities of single-view roadside sensing systems. To further enhance theaccuracy of roadside perception and provide better information to the vehicleside, in this paper, we constructed holographic intersections with variouslayouts to build a large-scale multi-sensor holographic vehicle-infrastructurecooperation dataset, called HoloVIC. Our dataset includes 3 different types ofsensors (Camera, Lidar, Fisheye) and employs 4 sensor-layouts based on thedifferent intersections. Each intersection is equipped with 6-18 sensors tocapture synchronous data. While autonomous vehicles pass through theseintersections for collecting VIC data. HoloVIC contains in total on 100k+synchronous frames from different sensors. Additionally, we annotated 3Dbounding boxes based on Camera, Fisheye, and Lidar. We also associate the IDsof the same objects across different devices and consecutive frames insequence. Based on HoloVIC, we formulated four tasks to facilitate thedevelopment of related research. We also provide benchmarks for these tasks.</description><author>Cong Ma, Lei Qiao, Chengkai Zhu, Kai Liu, Zelong Kong, Qing Li, Xueqi Zhou, Yuheng Kan, Wei Wu</author><pubDate>Tue, 26 Mar 2024 18:14:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02640v3</guid></item><item><title>Superior and Pragmatic Talking Face Generation with Teacher-Student Framework</title><link>http://arxiv.org/abs/2403.17883v1</link><description>Talking face generation technology creates talking videos from arbitraryappearance and motion signal, with the "arbitrary" offering ease of use butalso introducing challenges in practical applications. Existing methods workwell with standard inputs but suffer serious performance degradation withintricate real-world ones. Moreover, efficiency is also an important concern indeployment. To comprehensively address these issues, we introduce SuperFace, ateacher-student framework that balances quality, robustness, cost andeditability. We first propose a simple but effective teacher model capable ofhandling inputs of varying qualities to generate high-quality results. Buildingon this, we devise an efficient distillation strategy to acquire anidentity-specific student model that maintains quality with significantlyreduced computational load. Our experiments validate that SuperFace offers amore comprehensive solution than existing methods for the four mentionedobjectives, especially in reducing FLOPs by 99\% with the student model.SuperFace can be driven by both video and audio and allows for localized facialattributes editing.</description><author>Chao Liang, Jianwen Jiang, Tianyun Zhong, Gaojie Lin, Zhengkun Rong, Jiaqi Yang, Yongming Zhu</author><pubDate>Tue, 26 Mar 2024 18:13:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17883v1</guid></item><item><title>Deepfake Generation and Detection: A Benchmark and Survey</title><link>http://arxiv.org/abs/2403.17881v1</link><description>In addition to the advancements in deepfake generation, correspondingdetection technologies need to continuously evolve to regulate the potentialmisuse of deepfakes, such as for privacy invasion and phishing attacks. Thissurvey comprehensively reviews the latest developments in deepfake generationand detection, summarizing and analyzing the current state of the art in thisrapidly evolving field. We first unify task definitions, comprehensivelyintroduce datasets and metrics, and discuss the development of generation anddetection technology frameworks. Then, we discuss the development of severalrelated sub-fields and focus on researching four mainstream deepfake fields:popular face swap, face reenactment, talking face generation, and facialattribute editing, as well as foreign detection. Subsequently, wecomprehensively benchmark representative methods on popular datasets for eachfield, fully evaluating the latest and influential works published in topconferences/journals. Finally, we analyze the challenges and future researchdirections of the discussed fields. We closely follow the latest developmentsin https://github.com/flyingby/Awesome-Deepfake-Generation-and-Detection.</description><author>Gan Pei, Jiangning Zhang, Menghan Hu, Guangtao Zhai, Chengjie Wang, Zhenyu Zhang, Jian Yang, Chunhua Shen, Dacheng Tao</author><pubDate>Tue, 26 Mar 2024 18:12:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17881v1</guid></item><item><title>Low-Latency Neural Stereo Streaming</title><link>http://arxiv.org/abs/2403.17879v1</link><description>The rise of new video modalities like virtual reality or autonomous drivinghas increased the demand for efficient multi-view video compression methods,both in terms of rate-distortion (R-D) performance and in terms of delay andruntime. While most recent stereo video compression approaches have shownpromising performance, they compress left and right views sequentially, leadingto poor parallelization and runtime performance. This work presents Low-Latencyneural codec for Stereo video Streaming (LLSS), a novel parallel stereo videocoding method designed for fast and efficient low-latency stereo videostreaming. Instead of using a sequential cross-view motion compensation likeexisting methods, LLSS introduces a bidirectional feature shifting module todirectly exploit mutual information among views and encode them effectivelywith a joint cross-view prior model for entropy coding. Thanks to this design,LLSS processes left and right views in parallel, minimizing latency; all whilesubstantially improving R-D performance compared to both existing neural andconventional codecs.</description><author>Qiqi Hou, Farzad Farhadzadeh, Amir Said, Guillaume Sautiere, Hoang Le</author><pubDate>Tue, 26 Mar 2024 18:11:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17879v1</guid></item><item><title>Empowering Data Mesh with Federated Learning</title><link>http://arxiv.org/abs/2403.17878v1</link><description>The evolution of data architecture has seen the rise of data lakes, aiming tosolve the bottlenecks of data management and promote intelligentdecision-making. However, this centralized architecture is limited by theproliferation of data sources and the growing demand for timely analysis andprocessing. A new data paradigm, Data Mesh, is proposed to overcome thesechallenges. Data Mesh treats domains as a first-class concern by distributingthe data ownership from the central team to each data domain, while keeping thefederated governance to monitor domains and their data products. Manymulti-million dollar organizations like Paypal, Netflix, and Zalando havealready transformed their data analysis pipelines based on this newarchitecture. In this decentralized architecture where data is locallypreserved by each domain team, traditional centralized machine learning isincapable of conducting effective analysis across multiple domains, especiallyfor security-sensitive organizations. To this end, we introduce a pioneeringapproach that incorporates Federated Learning into Data Mesh. To the best ofour knowledge, this is the first open-source applied work that represents acritical advancement toward the integration of federated learning methods intothe Data Mesh paradigm, underscoring the promising prospects forprivacy-preserving and decentralized data analysis strategies within Data Mesharchitecture.</description><author>Haoyuan Li, Salman Toor</author><pubDate>Tue, 26 Mar 2024 18:10:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17878v1</guid></item><item><title>Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach</title><link>http://arxiv.org/abs/2403.17873v1</link><description>Human-centered explainable AI (HCXAI) advocates for the integration of socialaspects into AI explanations. Central to the HCXAI discourse is the SocialTransparency (ST) framework, which aims to make the socio-organizationalcontext of AI systems accessible to their users. In this work, we suggestextending the ST framework to address the risks of social misattributions inLarge Language Models (LLMs), particularly in sensitive areas like mentalhealth. In fact LLMs, which are remarkably capable of simulating roles andpersonas, may lead to mismatches between designers' intentions and users'perceptions of social attributes, risking to promote emotional manipulation anddangerous behaviors, cases of epistemic injustice, and unwarranted trust. Toaddress these issues, we propose enhancing the ST framework with a fifth'W-question' to clarify the specific social attributions assigned to LLMs byits designers and users. This addition aims to bridge the gap between LLMcapabilities and user perceptions, promoting the ethically responsibledevelopment and use of LLM-based technology.</description><author>Andrea Ferrario, Alberto Termine, Alessandro Facchini</author><pubDate>Tue, 26 Mar 2024 18:02:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17873v1</guid></item><item><title>Boosting Diffusion Models with Moving Average Sampling in Frequency Domain</title><link>http://arxiv.org/abs/2403.17870v1</link><description>Diffusion models have recently brought a powerful revolution in imagegeneration. Despite showing impressive generative capabilities, most of thesemodels rely on the current sample to denoise the next one, possibly resultingin denoising instability. In this paper, we reinterpret the iterative denoisingprocess as model optimization and leverage a moving average mechanism toensemble all the prior samples. Instead of simply applying moving average tothe denoised samples at different timesteps, we first map the denoised samplesto data space and then perform moving average to avoid distribution shiftacross timesteps. In view that diffusion models evolve the recovery fromlow-frequency components to high-frequency details, we further decompose thesamples into different frequency components and execute moving averageseparately on each component. We name the complete approach "Moving AverageSampling in Frequency domain (MASF)". MASF could be seamlessly integrated intomainstream pre-trained diffusion models and sampling schedules. Extensiveexperiments on both unconditional and conditional diffusion models demonstratethat our MASF leads to superior performances compared to the baselines, withalmost negligible additional complexity cost.</description><author>Yurui Qian, Qi Cai, Yingwei Pan, Yehao Li, Ting Yao, Qibin Sun, Tao Mei</author><pubDate>Tue, 26 Mar 2024 17:57:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17870v1</guid></item><item><title>Room Transfer Function Reconstruction Using Complex-valued Neural Networks and Irregularly Distributed Microphones</title><link>http://arxiv.org/abs/2402.04866v2</link><description>Reconstructing the room transfer functions needed to calculate the complexsound field in a room has several impor- tant real-world applications. However,an unpractical number of microphones is often required. Recently, in additionto classical signal processing methods, deep learning techniques have beenapplied to reconstruct the room transfer function starting from a very limitedset of measurements at scattered points in the room. In this paper, we employcomplex-valued neural networks to estimate room transfer functions in thefrequency range of the first room resonances, using a few irregularlydistributed microphones. To the best of our knowledge, this is the first timethat complex-valued neural networks are used to estimate room transferfunctions. To analyze the benefits of applying complex- valued optimization tothe considered task, we compare the proposed technique with a state-of-the-artkernel-based signal processing approach for sound field reconstruction, showingthat the proposed technique exhibits relevant advantages in terms of phaseaccuracy and overall quality of the reconstructed sound field. For informativepurposes, we also compare the model with a similarly-structured data-drivenapproach that, however, applies a real-valued neural network to reconstructonly the magnitude of the sound field.</description><author>Francesca Ronchini, Luca Comanducci, Mirco Pezzoli, Fabio Antonacci, Augusto Sarti</author><pubDate>Tue, 26 Mar 2024 17:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04866v2</guid></item><item><title>To Supervise or Not to Supervise: Understanding and Addressing the Key Challenges of 3D Transfer Learning</title><link>http://arxiv.org/abs/2403.17869v1</link><description>Transfer learning has long been a key factor in the advancement of manyfields including 2D image analysis. Unfortunately, its applicability in 3D dataprocessing has been relatively limited. While several approaches for 3Dtransfer learning have been proposed in recent literature, with contrastivelearning gaining particular prominence, most existing methods in this domainhave only been studied and evaluated in limited scenarios. Most importantly,there is currently a lack of principled understanding of both when and why 3Dtransfer learning methods are applicable. Remarkably, even the applicability ofstandard supervised pre-training is poorly understood. In this work, we conductthe first in-depth quantitative and qualitative investigation of supervised andcontrastive pre-training strategies and their utility in downstream 3D tasks.We demonstrate that layer-wise analysis of learned features providessignificant insight into the downstream utility of trained networks. Informedby this analysis, we propose a simple geometric regularization strategy, whichimproves the transferability of supervised pre-training. Our work thus shedslight onto both the specific challenges of 3D transfer learning, as well asstrategies to overcome them.</description><author>Souhail Hadgi, Lei Li, Maks Ovsjanikov</author><pubDate>Tue, 26 Mar 2024 17:57:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17869v1</guid></item><item><title>Sample complexity of quantum hypothesis testing</title><link>http://arxiv.org/abs/2403.17868v1</link><description>Quantum hypothesis testing has been traditionally studied from theinformation-theoretic perspective, wherein one is interested in the optimaldecay rate of error probabilities as a function of the number of samples of anunknown state. In this paper, we study the sample complexity of quantumhypothesis testing, wherein the goal is to determine the minimum number ofsamples needed to reach a desired error probability. By making use of thewealth of knowledge that already exists in the literature on quantum hypothesistesting, we characterize the sample complexity of binary quantum hypothesistesting in the symmetric and asymmetric settings, and we provide bounds on thesample complexity of multiple quantum hypothesis testing. In more detail, weprove that the sample complexity of symmetric binary quantum hypothesis testingdepends logarithmically on the inverse error probability and inversely on thenegative logarithm of the fidelity. As a counterpart of the quantum Stein'slemma, we also find that the sample complexity of asymmetric binary quantumhypothesis testing depends logarithmically on the inverse type~II errorprobability and inversely on the quantum relative entropy. Finally, we providelower and upper bounds on the sample complexity of multiple quantum hypothesistesting, with it remaining an intriguing open question to improve these bounds.</description><author>Hao-Chung Cheng, Nilanjana Datta, Nana Liu, Theshani Nuradha, Robert Salzmann, Mark M. Wilde</author><pubDate>Tue, 26 Mar 2024 17:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17868v1</guid></item><item><title>Activations and Gradients Compression for Model-Parallel Training</title><link>http://arxiv.org/abs/2401.07788v2</link><description>Large neural networks require enormous computational clusters of machines.Model-parallel training, when the model architecture is partitionedsequentially between workers, is a popular approach for training modern models.Information compression can be applied to decrease workers communication time,as it is often a bottleneck in such systems. This work explores howsimultaneous compression of activations and gradients in model-paralleldistributed training setup affects convergence. We analyze compression methodssuch as quantization and TopK compression, and also experiment with errorcompensation techniques. Moreover, we employ TopK with AQ-SGD per-batch errorfeedback approach. We conduct experiments on image classification and languagemodel fine-tuning tasks. Our findings demonstrate that gradients require mildercompression rates than activations. We observe that $K=10\%$ is the lowest TopKcompression level, which does not harm model convergence severely. Experimentsalso show that models trained with TopK perform well only when compression isalso applied during inference. We find that error feedback techniques do notimprove model-parallel training compared to plain compression, but allow modelinference without compression with almost no quality drop. Finally, whenapplied with the AQ-SGD approach, TopK stronger than with $ K=30\%$ worsensmodel performance significantly.</description><author>Mikhail Rudakov, Aleksandr Beznosikov, Yaroslav Kholodov, Alexander Gasnikov</author><pubDate>Tue, 26 Mar 2024 17:49:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07788v2</guid></item><item><title>Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications</title><link>http://arxiv.org/abs/2403.17860v1</link><description>Natural Language Processing (NLP) models optimized for predictive performanceoften make high confidence errors and suffer from vulnerability to adversarialand out-of-distribution data. Existing work has mainly focused on mitigation ofsuch errors using either humans or an automated approach. In this study, weexplore the usage of large language models (LLMs) for data augmentation as apotential solution to the issue of NLP models making wrong predictions withhigh confidence during classification tasks. We compare the effectiveness ofsynthetic data generated by LLMs with that of human data obtained via the sameprocedure. For mitigation, humans or LLMs provide natural languagecharacterizations of high confidence misclassifications to generate syntheticdata, which are then used to extend the training set. We conduct an extensiveevaluation of our approach on three classification tasks and demonstrate itseffectiveness in reducing the number of high confidence misclassificationspresent in the model, all while maintaining the same level of accuracy.Moreover, we find that the cost gap between humans and LLMs surpasses an orderof magnitude, as LLMs attain human-like performance while being more scalable.</description><author>Philip Lippmann, Matthijs Spaan, Jie Yang</author><pubDate>Tue, 26 Mar 2024 17:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17860v1</guid></item><item><title>Differentially private multivariate medians</title><link>http://arxiv.org/abs/2210.06459v2</link><description>Statistical tools which satisfy rigorous privacy guarantees are necessary formodern data analysis. It is well-known that robustness against contamination islinked to differential privacy. Despite this fact, using multivariate mediansfor differentially private and robust multivariate location estimation has notbeen systematically studied. We develop novel finite-sample performanceguarantees for differentially private multivariate depth-based medians, whichare essentially sharp. Our results cover commonly used depth functions, such asthe halfspace (or Tukey) depth, spatial depth, and the integrated dual depth.We show that under Cauchy marginals, the cost of heavy-tailed locationestimation outweighs the cost of privacy. We demonstrate our resultsnumerically using a Gaussian contamination model in dimensions up to d = 100,and compare them to a state-of-the-art private mean estimation algorithm. As aby-product of our investigation, we prove concentration inequalities for theoutput of the exponential mechanism about the maximizer of the populationobjective function. This bound applies to objective functions that satisfy amild regularity condition.</description><author>Kelly Ramsay, Aukosh Jagannath, Shoja'eddin Chenouri</author><pubDate>Tue, 26 Mar 2024 17:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06459v2</guid></item><item><title>ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages</title><link>http://arxiv.org/abs/2403.17859v1</link><description>Question answering (QA) and Machine Reading Comprehension (MRC) tasks havesignificantly advanced in recent years due to the rapid development of deeplearning techniques and, more recently, large language models. At the sametime, many benchmark datasets have become available for QA and MRC tasks.However, most existing large-scale benchmark datasets have been createdpredominantly using synchronous document collections like Wikipedia or the Web.Archival document collections, such as historical newspapers, contain valuableinformation from the past that is still not widely used to train large languagemodels. To further contribute to advancing QA and MRC tasks and to overcome thelimitation of previous datasets, we introduce ChroniclingAmericaQA, alarge-scale dataset with 485K question-answer pairs created based on thehistorical newspaper collection Chronicling America. Our dataset is constructedfrom a subset of the Chronicling America newspaper collection spanning 120years. One of the significant challenges for utilizing digitized historicalnewspaper collections is the low quality of OCR text. Therefore, to enablerealistic testing of QA models, our dataset can be used in three differentways: answering questions from raw and noisy content, answering questions fromcleaner, corrected version of the content, as well as answering questions fromscanned images of newspaper pages. This and the fact that ChroniclingAmericaQAspans the longest time period among available QA datasets make it quite aunique and useful resource.</description><author>Bhawna Piryani, Jamshid Mozafari, Adam Jatowt</author><pubDate>Tue, 26 Mar 2024 17:48:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17859v1</guid></item><item><title>Verbing Weirds Language (Models): Evaluation of English Zero-Derivation in Five LLMs</title><link>http://arxiv.org/abs/2403.17856v1</link><description>Lexical-syntactic flexibility, in the form of conversion (or zero-derivation)is a hallmark of English morphology. In conversion, a word with one part ofspeech is placed in a non-prototypical context, where it is coerced to behaveas if it had a different part of speech. However, while this process affects alarge part of the English lexicon, little work has been done to establish thedegree to which language models capture this type of generalization. This paperreports the first study on the behavior of large language models with referenceto conversion. We design a task for testing lexical-syntactic flexibility --the degree to which models can generalize over words in a construction with anon-prototypical part of speech. This task is situated within a naturallanguage inference paradigm. We test the abilities of five language models --two proprietary models (GPT-3.5 and GPT-4), three open-source models (Mistral7B, Falcon 40B, and Llama 2 70B). We find that GPT-4 performs best on the task,followed by GPT-3.5, but that the open source language models are also able toperform it and that the 7B parameter Mistral displays as little differencebetween its baseline performance on the natural language inference task and thenon-prototypical syntactic category task, as the massive GPT-4.</description><author>David R. Mortensen, Valentina Izrailevitch, Yunze Xiao, Hinrich Schütze, Leonie Weissweiler</author><pubDate>Tue, 26 Mar 2024 17:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17856v1</guid></item><item><title>AI and Generative AI for Research Discovery and Summarization</title><link>http://arxiv.org/abs/2401.06795v2</link><description>AI and generative AI tools, including chatbots like ChatGPT that rely onlarge language models (LLMs), have burst onto the scene this year, creatingincredible opportunities to increase work productivity and improve our lives.Statisticians and data scientists have begun experiencing the benefits from theavailability of these tools in numerous ways, such as the generation ofprogramming code from text prompts to analyze data or fit statistical models.One area that these tools can make a substantial impact is in researchdiscovery and summarization. Standalone tools and plugins to chatbots are beingdeveloped that allow researchers to more quickly find relevant literature thanpre-2023 search tools. Furthermore, generative AI tools have improved to thepoint where they can summarize and extract the key points from researcharticles in succinct language. Finally, chatbots based on highly parameterizedLLMs can be used to simulate abductive reasoning, which provides researchersthe ability to make connections among related technical topics, which can alsobe used for research discovery. We review the developments in AI and generativeAI for research discovery and summarization, and propose directions where thesetypes of tools are likely to head in the future that may be of interest tostatistician and data scientists.</description><author>Mark Glickman, Yi Zhang</author><pubDate>Tue, 26 Mar 2024 17:44:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06795v2</guid></item><item><title>Using Domain Knowledge to Guide Dialog Structure Induction via Neural Probabilistic Soft Logic</title><link>http://arxiv.org/abs/2403.17853v1</link><description>Dialog Structure Induction (DSI) is the task of inferring the latent dialogstructure (i.e., a set of dialog states and their temporal transitions) of agiven goal-oriented dialog. It is a critical component for modern dialog systemdesign and discourse analysis. Existing DSI approaches are often purelydata-driven, deploy models that infer latent states without access to domainknowledge, underperform when the training corpus is limited/noisy, or havedifficulty when test dialogs exhibit distributional shifts from the trainingdomain. This work explores a neural-symbolic approach as a potential solutionto these problems. We introduce Neural Probabilistic Soft Logic DialogueStructure Induction (NEUPSL DSI), a principled approach that injects symbolicknowledge into the latent space of a generative neural model. We conduct athorough empirical investigation on the effect of NEUPSL DSI learning on hiddenrepresentation quality, few-shot learning, and out-of-domain generalizationperformance. Over three dialog structure induction datasets and acrossunsupervised and semi-supervised settings for standard and cross-domaingeneralization, the injection of symbolic knowledge using NEUPSL DSI provides aconsistent boost in performance over the canonical baselines.</description><author>Connor Pryor, Quan Yuan, Jeremiah Liu, Mehran Kazemi, Deepak Ramachandran, Tania Bedrax-Weiss, Lise Getoor</author><pubDate>Tue, 26 Mar 2024 17:42:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17853v1</guid></item><item><title>Generator-Retriever-Generator Approach for Open-Domain Question Answering</title><link>http://arxiv.org/abs/2307.11278v3</link><description>Open-domain question answering (QA) tasks usually require the retrieval ofrelevant information from a large corpus to generate accurate answers. Wepropose a novel approach called Generator-Retriever-Generator (GRG) thatcombines document retrieval techniques with a large language model (LLM), byfirst prompting the model to generate contextual documents based on a givenquestion. In parallel, a dual-encoder network retrieves documents that arerelevant to the question from an external corpus. The generated and retrieveddocuments are then passed to the second LLM, which generates the final answer.By combining document retrieval and LLM generation, our approach addresses thechallenges of open-domain QA, such as generating informative and contextuallyrelevant answers. GRG outperforms the state-of-the-art generate-then-read andretrieve-then-read pipelines (GENREAD and RFiD) improving their performance byat least by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets,respectively. We provide code, datasets, and checkpoints athttps://github.com/abdoelsayed2016/GRG.</description><author>Abdelrahman Abdallah, Adam Jatowt</author><pubDate>Tue, 26 Mar 2024 17:40:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11278v3</guid></item><item><title>Counterfactual Fairness through Transforming Data Orthogonal to Bias</title><link>http://arxiv.org/abs/2403.17852v1</link><description>Machine learning models have shown exceptional prowess in solving complexissues across various domains. Nonetheless, these models can sometimes exhibitbiased decision-making, leading to disparities in treatment across differentgroups. Despite the extensive research on fairness, the nuanced effects ofmultivariate and continuous sensitive variables on decision-making outcomesremain insufficiently studied. We introduce a novel data pre-processingalgorithm, Orthogonal to Bias (OB), designed to remove the influence of a groupof continuous sensitive variables, thereby facilitating counterfactual fairnessin machine learning applications. Our approach is grounded in the assumption ofa jointly normal distribution within a structural causal model (SCM), provingthat counterfactual fairness can be achieved by ensuring the data isuncorrelated with sensitive variables. The OB algorithm is model-agnostic,catering to a wide array of machine learning models and tasks, and includes asparse variant to enhance numerical stability through regularization. Throughempirical evaluation on simulated and real-world datasets - including the adultincome and the COMPAS recidivism datasets - our methodology demonstrates itscapacity to enable fairer outcomes without compromising accuracy.</description><author>Shuyi Chen, Shixiang Zhu</author><pubDate>Tue, 26 Mar 2024 17:40:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17852v1</guid></item><item><title>ArabicaQA: A Comprehensive Dataset for Arabic Question Answering</title><link>http://arxiv.org/abs/2403.17848v1</link><description>In this paper, we address the significant gap in Arabic natural languageprocessing (NLP) resources by introducing ArabicaQA, the first large-scaledataset for machine reading comprehension and open-domain question answering inArabic. This comprehensive dataset, consisting of 89,095 answerable and 3,701unanswerable questions created by crowdworkers to look similar to answerableones, along with additional labels of open-domain questions marks a crucialadvancement in Arabic NLP resources. We also present AraDPR, the first densepassage retrieval model trained on the Arabic Wikipedia corpus, specificallydesigned to tackle the unique challenges of Arabic text retrieval. Furthermore,our study includes extensive benchmarking of large language models (LLMs) forArabic question answering, critically evaluating their performance in theArabic language context. In conclusion, ArabicaQA, AraDPR, and the benchmarkingof LLMs in Arabic question answering offer significant advancements in thefield of Arabic NLP. The dataset and code are publicly accessible for furtherresearch https://github.com/DataScienceUIBK/ArabicaQA.</description><author>Abdelrahman Abdallah, Mahmoud Kasem, Mahmoud Abdalla, Mohamed Mahmoud, Mohamed Elkasaby, Yasser Elbendary, Adam Jatowt</author><pubDate>Tue, 26 Mar 2024 17:37:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17848v1</guid></item><item><title>Climate Downscaling: A Deep-Learning Based Super-resolution Model of Precipitation Data with Attention Block and Skip Connections</title><link>http://arxiv.org/abs/2403.17847v1</link><description>Human activities accelerate consumption of fossil fuels and producegreenhouse gases, resulting in urgent issues today: global warming and theclimate change. These indirectly cause severe natural disasters, plenty oflives suffering and huge losses of agricultural properties. To mitigate impactson our lands, scientists are developing renewable, reusable, and clean energiesand climatologists are trying to predict the extremes. Meanwhile, governmentsare publicizing resource-saving policies for a more eco-friendly society andarousing environment awareness. One of the most influencing factors is theprecipitation, bringing condensed water vapor onto lands. Water resources arethe most significant but basic needs in society, not only supporting ourlivings, but also economics. In Taiwan, although the average annualprecipitation is up to 2,500 millimeter (mm), the water allocation for eachperson is lower than the global average due to drastically geographicalelevation changes and uneven distribution through the year. Thus, it is crucialto track and predict the rainfall to make the most use of it and to prevent thefloods. However, climate models have limited resolution and require intensivecomputational power for local-scale use. Therefore, we proposed a deepconvolutional neural network with skip connections, attention blocks, andauxiliary data concatenation, in order to downscale the low-resolutionprecipitation data into high-resolution one. Eventually, we compare with otherclimate downscaling methods and show better performance in metrics of MeanAbsolute Error (MAE), Root Mean Square Error (RMSE), Pearson Correlation,structural similarity index (SSIM), and forecast indicators.</description><author>Chia-Hao Chiang, Zheng-Han Huang, Liwen Liu, Hsin-Chien Liang, Yi-Chi Wang, Wan-Ling Tseng, Chao Wang, Che-Ta Chen, Ko-Chih Wang</author><pubDate>Tue, 26 Mar 2024 17:36:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17847v1</guid></item><item><title>Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation</title><link>http://arxiv.org/abs/2403.17846v1</link><description>Recent open-vocabulary robot mapping methods enrich dense geometric maps withpre-trained visual-language features. While these maps allow for the predictionof point-wise saliency maps when queried for a certain language concept,large-scale environments and abstract queries beyond the object level stillpose a considerable hurdle, ultimately limiting language-grounded roboticnavigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3Dscene graph mapping approach for language-grounded robot navigation. Leveragingopen-vocabulary vision foundation models, we first obtain state-of-the-artopen-vocabulary segment-level maps in 3D and subsequently construct a 3D scenegraph hierarchy consisting of floor, room, and object concepts, each enrichedwith open-vocabulary features. Our approach is able to represent multi-storybuildings and allows robotic traversal of those using a cross-floor Voronoigraph. HOV-SG is evaluated on three distinct datasets and surpasses previousbaselines in open-vocabulary semantic accuracy on the object, room, and floorlevel while producing a 75% reduction in representation size compared to denseopen-vocabulary maps. In order to prove the efficacy and generalizationcapabilities of HOV-SG, we showcase successful long-horizonlanguage-conditioned robot navigation within real-world multi-storageenvironments. We provide code and trial video data at http://hovsg.github.io/.</description><author>Abdelrhman Werby, Chenguang Huang, Martin Büchner, Abhinav Valada, Wolfram Burgard</author><pubDate>Tue, 26 Mar 2024 17:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17846v1</guid></item><item><title>PINN surrogate of Li-ion battery models for parameter inference. Part II: Regularization and application of the pseudo-2D model</title><link>http://arxiv.org/abs/2312.17336v2</link><description>Bayesian parameter inference is useful to improve Li-ion battery diagnosticsand can help formulate battery aging models. However, it is computationallyintensive and cannot be easily repeated for multiple cycles, multiple operatingconditions, or multiple replicate cells. To reduce the computational cost ofBayesian calibration, numerical solvers for physics-based models can bereplaced with faster surrogates. A physics-informed neural network (PINN) isdeveloped as a surrogate for the pseudo-2D (P2D) battery model calibration. Forthe P2D surrogate, additional training regularization was needed as compared tothe PINN single-particle model (SPM) developed in Part I. Both the PINN SPM andP2D surrogate models are exercised for parameter inference and compared to dataobtained from a direct numerical solution of the governing equations. Aparameter inference study highlights the ability to use these PINNs tocalibrate scaling parameters for the cathode Li diffusion and the anodeexchange current density. By realizing computational speed-ups of 2250x for theP2D model, as compared to using standard integrating methods, the PINNsurrogates enable rapid state-of-health diagnostics. In the low-dataavailability scenario, the testing error was estimated to 2mV for the SPMsurrogate and 10mV for the P2D surrogate which could be mitigated withadditional data.</description><author>Malik Hassanaly, Peter J. Weddle, Ryan N. King, Subhayan De, Alireza Doostan, Corey R. Randall, Eric J. Dufek, Andrew M. Colclasure, Kandler Smith</author><pubDate>Tue, 26 Mar 2024 17:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17336v2</guid></item><item><title>TractOracle: towards an anatomically-informed reward function for RL-based tractography</title><link>http://arxiv.org/abs/2403.17845v1</link><description>Reinforcement learning (RL)-based tractography is a competitive alternativeto machine learning and classical tractography algorithms due to its highanatomical accuracy obtained without the need for any annotated data. However,the reward functions so far used to train RL agents do not encapsulateanatomical knowledge which causes agents to generate spurious false positivestracts. In this paper, we propose a new RL tractography system, TractOracle,which relies on a reward network trained for streamline classification. Thisnetwork is used both as a reward function during training as well as a mean forstopping the tracking process early and thus reduce the number of falsepositive streamlines. This makes our system a unique method that evaluates andreconstructs WM streamlines at the same time. We report an improvement of truepositive ratios by almost 20\% and a reduction of 3x of false positive ratioson one dataset and an increase between 2x and 7x in the number true positivestreamlines on another dataset.</description><author>Antoine Théberge, Maxime Descoteaux, Pierre-Marc Jodoin</author><pubDate>Tue, 26 Mar 2024 17:34:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17845v1</guid></item><item><title>Mechanistic Design and Scaling of Hybrid Architectures</title><link>http://arxiv.org/abs/2403.17844v1</link><description>The development of deep learning architectures is a resource-demandingprocess, due to a vast design space, long prototyping times, and high computecosts associated with at-scale model training and evaluation. We set out tosimplify this process by grounding it in an end-to-end mechanistic architecturedesign (MAD) pipeline, encompassing small-scale capability unit testspredictive of scaling laws. Through a suite of synthetic token manipulationtasks such as compression and recall, designed to probe capabilities, weidentify and test new hybrid architectures constructed from a variety ofcomputational primitives. We experimentally validate the resultingarchitectures via an extensive compute-optimal and a new state-optimal scalinglaw analysis, training over 500 language models between 70M to 7B parameters.Surprisingly, we find MAD synthetics to correlate with compute-optimalperplexity, enabling accurate evaluation of new architectures via isolatedproxy tasks. The new architectures found via MAD, based on simple ideas such ashybridization and sparsity, outperform state-of-the-art Transformer,convolutional, and recurrent architectures (Transformer++, Hyena, Mamba) inscaling, both at compute-optimal budgets and in overtrained regimes. Overall,these results provide evidence that performance on curated synthetic tasks canbe predictive of scaling laws, and that an optimal architecture should leveragespecialized layers via a hybrid topology.</description><author>Michael Poli, Armin W Thomas, Eric Nguyen, Pragaash Ponnusamy, Björn Deiseroth, Kristian Kersting, Taiji Suzuki, Brian Hie, Stefano Ermon, Christopher Ré, Ce Zhang, Stefano Massaroli</author><pubDate>Tue, 26 Mar 2024 17:33:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17844v1</guid></item><item><title>TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering</title><link>http://arxiv.org/abs/2401.06003v2</link><description>Point-based radiance field rendering has demonstrated impressive results fornovel view synthesis, offering a compelling blend of rendering quality andcomputational efficiency. However, also latest approaches in this domain arenot without their shortcomings. 3D Gaussian Splatting [Kerbl and Kopanas et al.2023] struggles when tasked with rendering highly detailed scenes, due toblurring and cloudy artifacts. On the other hand, ADOP [R\"uckert et al. 2022]can accommodate crisper images, but the neural reconstruction network decreasesperformance, it grapples with temporal instability and it is unable toeffectively address large gaps in the point cloud. In this paper, we present TRIPS (Trilinear Point Splatting), an approach thatcombines ideas from both Gaussian Splatting and ADOP. The fundamental conceptbehind our novel technique involves rasterizing points into a screen-spaceimage pyramid, with the selection of the pyramid layer determined by theprojected point size. This approach allows rendering arbitrarily large pointsusing a single trilinear write. A lightweight neural network is then used toreconstruct a hole-free image including detail beyond splat resolution.Importantly, our render pipeline is entirely differentiable, allowing forautomatic optimization of both point sizes and positions. Our evaluation demonstrate that TRIPS surpasses existing state-of-the-artmethods in terms of rendering quality while maintaining a real-time frame rateof 60 frames per second on readily available hardware. This performance extendsto challenging scenarios, such as scenes featuring intricate geometry,expansive landscapes, and auto-exposed footage. The project page is located at: https://lfranke.github.io/trips/</description><author>Linus Franke, Darius Rückert, Laura Fink, Marc Stamminger</author><pubDate>Tue, 26 Mar 2024 17:30:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06003v2</guid></item><item><title>ReMamber: Referring Image Segmentation with Mamba Twister</title><link>http://arxiv.org/abs/2403.17839v1</link><description>Referring Image Segmentation (RIS) leveraging transformers has achieved greatsuccess on the interpretation of complex visual-language tasks. However, thequadratic computation cost makes it resource-consuming in capturing long-rangevisual-language dependencies. Fortunately, Mamba addresses this with efficientlinear complexity in processing. However, directly applying Mamba tomulti-modal interactions presents challenges, primarily due to inadequatechannel interactions for the effective fusion of multi-modal data. In thispaper, we propose ReMamber, a novel RIS architecture that integrates the powerof Mamba with a multi-modal Mamba Twister block. The Mamba Twister explicitlymodels image-text interaction, and fuses textual and visual features throughits unique channel and spatial twisting mechanism. We achieve thestate-of-the-art on three challenging benchmarks. Moreover, we conduct thoroughanalyses of ReMamber and discuss other fusion designs using Mamba. Theseprovide valuable perspectives for future research.</description><author>Yuhuan Yang, Chaofan Ma, Jiangchao Yao, Zhun Zhong, Ya Zhang, Yanfeng Wang</author><pubDate>Tue, 26 Mar 2024 17:27:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17839v1</guid></item><item><title>GTA-HDR: A Large-Scale Synthetic Dataset for HDR Image Reconstruction</title><link>http://arxiv.org/abs/2403.17837v1</link><description>High Dynamic Range (HDR) content (i.e., images and videos) has a broad rangeof applications. However, capturing HDR content from real-world scenes isexpensive and time- consuming. Therefore, the challenging task ofreconstructing visually accurate HDR images from their Low Dynamic Range (LDR)counterparts is gaining attention in the vision research community. A majorchallenge in this research problem is the lack of datasets, which capturediverse scene conditions (e.g., lighting, shadows, weather, locations,landscapes, objects, humans, buildings) and various image features (e.g.,color, contrast, saturation, hue, luminance, brightness, radiance). To addressthis gap, in this paper, we introduce GTA-HDR, a large-scale synthetic datasetof photo-realistic HDR images sampled from the GTA-V video game. We performthorough evaluation of the proposed dataset, which demonstrates significantqualitative and quantitative improvements of the state-of-the-art HDR imagereconstruction methods. Furthermore, we demonstrate the effectiveness of theproposed dataset and its impact on additional computer vision tasks including3D human pose estimation, human body part segmentation, and holistic scenesegmentation. The dataset, data collection pipeline, and evaluation code areavailable at: https://github.com/HrishavBakulBarua/GTA-HDR.</description><author>Hrishav Bakul Barua, Kalin Stefanov, KokSheik Wong, Abhinav Dhall, Ganesh Krishnasamy</author><pubDate>Tue, 26 Mar 2024 17:24:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17837v1</guid></item><item><title>ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review</title><link>http://arxiv.org/abs/2305.03123v2</link><description>ChatGPT is another large language model (LLM) vastly available for theconsumers on their devices but due to its performance and ability to converseeffectively, it has gained a huge popularity amongst research as well asindustrial community. Recently, many studies have been published to show theeffectiveness, efficiency, integration, and sentiments of chatGPT and otherLLMs. In contrast, this study focuses on the important aspects that are mostlyoverlooked, i.e. sustainability, privacy, digital divide, and ethics andsuggests that not only chatGPT but every subsequent entry in the category ofconversational bots should undergo Sustainability, PrivAcy, Digital divide, andEthics (SPADE) evaluation. This paper discusses in detail the issues andconcerns raised over chatGPT in line with aforementioned characteristics. Wealso discuss the recent EU AI Act briefly in accordance with the SPADEevaluation. We support our hypothesis by some preliminary data collection andvisualizations along with hypothesized facts. We also suggest mitigations andrecommendations for each of the concerns. Furthermore, we also suggest somepolicies and recommendations for AI policy act, if designed by the governments.</description><author>Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Weizheng Wang, Lewis Nkenyereye</author><pubDate>Tue, 26 Mar 2024 17:22:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03123v2</guid></item><item><title>PINN surrogate of Li-ion battery models for parameter inference. Part I: Implementation and multi-fidelity hierarchies for the single-particle model</title><link>http://arxiv.org/abs/2312.17329v2</link><description>To plan and optimize energy storage demands that account for Li-ion batteryaging dynamics, techniques need to be developed to diagnose battery internalstates accurately and rapidly. This study seeks to reduce the computationalresources needed to determine a battery's internal states by replacingphysics-based Li-ion battery models -- such as the single-particle model (SPM)and the pseudo-2D (P2D) model -- with a physics-informed neural network (PINN)surrogate. The surrogate model makes high-throughput techniques, such asBayesian calibration, tractable to determine battery internal parameters fromvoltage responses. This manuscript is the first of a two-part series thatintroduces PINN surrogates of Li-ion battery models for parameter inference(i.e., state-of-health diagnostics). In this first part, a method is presentedfor constructing a PINN surrogate of the SPM. A multi-fidelity hierarchicaltraining, where several neural nets are trained with multiple physics-lossfidelities is shown to significantly improve the surrogate accuracy when onlytraining on the governing equation residuals. The implementation is madeavailable in a companion repository (https://github.com/NREL/pinnstripes). Thetechniques used to develop a PINN surrogate of the SPM are extended in Part IIfor the PINN surrogate for the P2D battery model, and explore the Bayesiancalibration capabilities of both surrogates.</description><author>Malik Hassanaly, Peter J. Weddle, Ryan N. King, Subhayan De, Alireza Doostan, Corey R. Randall, Eric J. Dufek, Andrew M. Colclasure, Kandler Smith</author><pubDate>Tue, 26 Mar 2024 17:22:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17329v2</guid></item><item><title>A foundation model utilizing chest CT volumes and radiology reports for supervised-level zero-shot detection of abnormalities</title><link>http://arxiv.org/abs/2403.17834v1</link><description>A major challenge in computational research in 3D medical imaging is the lackof comprehensive datasets. Addressing this issue, our study introduces CT-RATE,the first 3D medical imaging dataset that pairs images with textual reports.CT-RATE consists of 25,692 non-contrast chest CT volumes, expanded to 50,188through various reconstructions, from 21,304 unique patients, along withcorresponding radiology text reports. Leveraging CT-RATE, we developed CT-CLIP,a CT-focused contrastive language-image pre-training framework. As a versatile,self-supervised model, CT-CLIP is designed for broad application and does notrequire task-specific training. Remarkably, CT-CLIP outperformsstate-of-the-art, fully supervised methods in multi-abnormality detectionacross all key metrics, thus eliminating the need for manual annotation. Wealso demonstrate its utility in case retrieval, whether using imagery ortextual queries, thereby advancing knowledge dissemination. The open-sourcerelease of CT-RATE and CT-CLIP marks a significant advancement in medical AI,enhancing 3D imaging analysis and fostering innovation in healthcare.</description><author>Ibrahim Ethem Hamamci, Sezgin Er, Furkan Almas, Ayse Gulnihan Simsek, Sevval Nil Esirgun, Irem Dogan, Muhammed Furkan Dasdelen, Bastian Wittmann, Enis Simsar, Mehmet Simsar, Emine Bensu Erdemir, Abdullah Alanbay, Anjany Sekuboyina, Berkan Lafci, Mehmet K. Ozdemir, Bjoern Menze</author><pubDate>Tue, 26 Mar 2024 17:19:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17834v1</guid></item><item><title>Disentangling the Spectral Properties of the Hodge Laplacian: Not All Small Eigenvalues Are Equal</title><link>http://arxiv.org/abs/2311.14427v2</link><description>The rich spectral information of the graph Laplacian has been instrumental ingraph theory, machine learning, and graph signal processing for applicationssuch as graph classification, clustering, or eigenmode analysis. Recently, theHodge Laplacian has come into focus as a generalisation of the ordinaryLaplacian for higher-order graph models such as simplicial and cellularcomplexes. Akin to the traditional analysis of graph Laplacians, many authorsanalyse the smallest eigenvalues of the Hodge Laplacian, which are connected toimportant topological properties such as homology. However, small eigenvaluesof the Hodge Laplacian can carry different information depending on whetherthey are related to curl or gradient eigenmodes, and thus may not becomparable. We therefore introduce the notion of persistent eigenvectorsimilarity and provide a method to track individual harmonic, curl, andgradient eigenvectors/-values through the so-called persistence filtration,leveraging the full information contained in the Hodge-Laplacian spectrumacross all possible scales of a point cloud. Finally, we use our insights (a)to introduce a novel form of Hodge spectral clustering and (b) to classifyedges and higher-order simplices based on their relationship to the smallestharmonic, curl, and gradient eigenvectors.</description><author>Vincent P. Grande, Michael T. Schaub</author><pubDate>Tue, 26 Mar 2024 17:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14427v2</guid></item><item><title>GPFL: A Gradient Projection-Based Client Selection Framework for Efficient Federated Learning</title><link>http://arxiv.org/abs/2403.17833v1</link><description>Federated learning client selection is crucial for determining participantclients while balancing model accuracy and communication efficiency. Existingmethods have limitations in handling data heterogeneity, computational burdens,and independent client treatment. To address these challenges, we propose GPFL,which measures client value by comparing local and global descent directions.We also employ an Exploit-Explore mechanism to enhance performance.Experimental results on FEMINST and CIFAR-10 datasets demonstrate that GPFLoutperforms baselines in Non-IID scenarios, achieving over 9\% improvement inFEMINST test accuracy. Moreover, GPFL exhibits shorter computation timesthrough pre-selection and parameter reuse in federated learning.</description><author>Shijie Na, Yuzhi Liang, Siu-Ming Yiu</author><pubDate>Tue, 26 Mar 2024 17:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17833v1</guid></item><item><title>Learning the Optimal Power Flow: Environment Design Matters</title><link>http://arxiv.org/abs/2403.17831v1</link><description>To solve the optimal power flow (OPF) problem, reinforcement learning (RL)emerges as a promising new approach. However, the RL-OPF literature is stronglydivided regarding the exact formulation of the OPF problem as an RLenvironment. In this work, we collect and implement diverse environment designdecisions from the literature regarding training data, observation space,episode definition, and reward function choice. In an experimental analysis, weshow the significant impact of these environment design options on RL-OPFtraining performance. Further, we derive some first recommendations regardingthe choice of these design decisions. The created environment framework isfully open-source and can serve as a benchmark for future research in theRL-OPF field.</description><author>Thomas Wolgast, Astrid Nieße</author><pubDate>Tue, 26 Mar 2024 17:13:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17831v1</guid></item><item><title>Semi-Supervised Crowd Counting from Unlabeled Data</title><link>http://arxiv.org/abs/2108.13969v3</link><description>Automatic Crowd behavior analysis can be applied to effectively help thedaily transportation statistics and planning, which helps the smart cityconstruction. As one of the most important keys, crowd counting has drawnincreasing attention. Recent works achieved promising performance but relied onthe supervised paradigm with expensive crowd annotations. To alleviate theannotation cost in real-world transportation scenarios, in this work weproposed a semi-supervised learning framework $S^{4}\textit{Crowd}$, which canleverage both unlabeled/labeled data for robust crowd counting. In theunsupervised pathway, two \textit{self-supervised losses} were proposed tosimulate the crowd variations such as scale, illumination, based on whichsupervised information pseudo labels were generated and gradually refined. Wealso proposed a crowd-driven recurrent unit \textit{Gated-Crowd-Recurrent-Unit(GCRU)}, which can preserve discriminant crowd information by extractingsecond-order statistics, yielding pseudo labels with improved quality. A jointloss including both unsupervised/supervised information was proposed, and adynamic weighting strategy was employed to balance the importance of theunsupervised loss and supervised loss at different training stages. Weconducted extensive experiments on four popular crowd counting datasets insemi-supervised settings. Experimental results supported the effectiveness ofeach proposed component in our $S^{4}$Crowd framework. Our method achievedcompetitive performance in semi-supervised learning approaches on these crowdcounting datasets.</description><author>Haoran Duan, Fan Wan, Rui Sun, Zeyu Wang, Varun Ojha, Yu Guan, Hubert P. H. Shum, Bingzhang Hu, Yang Long</author><pubDate>Tue, 26 Mar 2024 17:13:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.13969v3</guid></item><item><title>Assessment of Multimodal Large Language Models in Alignment with Human Values</title><link>http://arxiv.org/abs/2403.17830v1</link><description>Large Language Models (LLMs) aim to serve as versatile assistants alignedwith human values, as defined by the principles of being helpful, honest, andharmless (hhh). However, in terms of Multimodal Large Language Models (MLLMs),despite their commendable performance in perception and reasoning tasks, theiralignment with human values remains largely unexplored, given the complexity ofdefining hhh dimensions in the visual world and the difficulty in collectingrelevant data that accurately mirrors real-world situations. To address thisgap, we introduce Ch3Ef, a Compreh3ensive Evaluation dataset and strategy forassessing alignment with human expectations. Ch3Ef dataset contains 1002human-annotated data samples, covering 12 domains and 46 tasks based on the hhhprinciple. We also present a unified evaluation strategy supporting assessmentacross various scenarios and different perspectives. Based on the evaluationresults, we summarize over 10 key findings that deepen the understanding ofMLLM capabilities, limitations, and the dynamic relationships betweenevaluation levels, guiding future advancements in the field.</description><author>Zhelun Shi, Zhipin Wang, Hongxing Fan, Zaibin Zhang, Lijun Li, Yongting Zhang, Zhenfei Yin, Lu Sheng, Yu Qiao, Jing Shao</author><pubDate>Tue, 26 Mar 2024 17:10:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17830v1</guid></item><item><title>DiffH2O: Diffusion-Based Synthesis of Hand-Object Interactions from Textual Descriptions</title><link>http://arxiv.org/abs/2403.17827v1</link><description>Generating natural hand-object interactions in 3D is challenging as theresulting hand and object motions are expected to be physically plausible andsemantically meaningful. Furthermore, generalization to unseen objects ishindered by the limited scale of available hand-object interaction datasets. Wepropose DiffH2O, a novel method to synthesize realistic, one or two-handedobject interactions from provided text prompts and geometry of the object. Themethod introduces three techniques that enable effective learning from limiteddata. First, we decompose the task into a grasping stage and a text-basedinteraction stage and use separate diffusion models for each. In the graspingstage, the model only generates hand motions, whereas in the interaction phaseboth hand and object poses are synthesized. Second, we propose a compactrepresentation that tightly couples hand and object poses. Third, we proposetwo different guidance schemes to allow more control of the generated motions:grasp guidance and detailed textual guidance. Grasp guidance takes a singletarget grasping pose and guides the diffusion model to reach this grasp at theend of the grasping stage, which provides control over the grasping pose. Givena grasping motion from this stage, multiple different actions can be promptedin the interaction phase. For textual guidance, we contribute comprehensivetext descriptions to the GRAB dataset and show that they enable our method tohave more fine-grained control over hand-object interactions. Our quantitativeand qualitative evaluation demonstrates that the proposed method outperformsbaseline methods and leads to natural hand-object motions. Moreover, wedemonstrate the practicality of our framework by utilizing a hand pose estimatefrom an off-the-shelf pose estimator for guidance, and then sampling multipledifferent actions in the interaction stage.</description><author>Sammy Christen, Shreyas Hampali, Fadime Sener, Edoardo Remelli, Tomas Hodan, Eric Sauser, Shugao Ma, Bugra Tekin</author><pubDate>Tue, 26 Mar 2024 17:06:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17827v1</guid></item><item><title>On the Computational Complexity of Stackelberg Planning and Meta-Operator Verification: Technical Report</title><link>http://arxiv.org/abs/2403.17826v1</link><description>Stackelberg planning is a recently introduced single-turn two-playeradversarial planning model, where two players are acting in a joint classicalplanning task, the objective of the first player being hampering the secondplayer from achieving its goal. This places the Stackelberg planning problemsomewhere between classical planning and general combinatorial two-playergames. But, where exactly? All investigations of Stackelberg planning so farfocused on practical aspects. We close this gap by conducting the firsttheoretical complexity analysis of Stackelberg planning. We show that ingeneral Stackelberg planning is actually no harder than classical planning.Under a polynomial plan-length restriction, however, Stackelberg planning is alevel higher up in the polynomial complexity hierarchy, suggesting thatcompilations into classical planning come with a worst-case exponentialplan-length increase. In attempts to identify tractable fragments, we furtherstudy its complexity under various planning task restrictions, showing thatStackelberg planning remains intractable where classical planning is not. Wefinally inspect the complexity of meta-operator verification, a problem thathas been recently connected to Stackelberg planning.</description><author>Gregor Behnke, Marcel Steinmetz</author><pubDate>Tue, 26 Mar 2024 17:06:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17826v1</guid></item><item><title>AMuRD: Annotated Arabic-English Receipt Dataset for Key Information Extraction and Classification</title><link>http://arxiv.org/abs/2309.09800v3</link><description>The extraction of key information from receipts is a complex task thatinvolves the recognition and extraction of text from scanned receipts. Thisprocess is crucial as it enables the retrieval of essential content andorganizing it into structured documents for easy access and analysis. In thispaper, we present AMuRD, a novel multilingual human-annotated datasetspecifically designed for information extraction from receipts. This datasetcomprises $47,720$ samples and addresses the key challenges in informationextraction and item classification - the two critical aspects of data analysisin the retail industry. Each sample includes annotations for item names andattributes such as price, brand, and more. This detailed annotation facilitatesa comprehensive understanding of each item on the receipt. Furthermore, thedataset provides classification into $44$ distinct product categories. Thisclassification feature allows for a more organized and efficient analysis ofthe items, enhancing the usability of the dataset for various applications. Inour study, we evaluated various language model architectures, e.g., byfine-tuning LLaMA models on the AMuRD dataset. Our approach yielded exceptionalresults, with an F1 score of 97.43\% and accuracy of 94.99\% in informationextraction and classification, and an even higher F1 score of 98.51\% andaccuracy of 97.06\% observed in specific tasks. The dataset and code arepublicly accessible for furtherresearchhttps://github.com/Update-For-Integrated-Business-AI/AMuRD.</description><author>Abdelrahman Abdallah, Mahmoud Abdalla, Mohamed Elkasaby, Yasser Elbendary, Adam Jatowt</author><pubDate>Tue, 26 Mar 2024 17:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09800v3</guid></item><item><title>Efficient Image Pre-Training with Siamese Cropped Masked Autoencoders</title><link>http://arxiv.org/abs/2403.17823v1</link><description>Self-supervised pre-training of image encoders is omnipresent in theliterature, particularly following the introduction of Masked autoencoders(MAE). Current efforts attempt to learn object-centric representations frommotion in videos. In particular, SiamMAE recently introduced a Siamese network,training a shared-weight encoder from two frames of a video with a highasymmetric masking ratio (95%). In this work, we propose CropMAE, analternative approach to the Siamese pre-training introduced by SiamMAE. Ourmethod specifically differs by exclusively considering pairs of cropped imagessourced from the same image but cropped differently, deviating from theconventional pairs of frames extracted from a video. CropMAE thereforealleviates the need for video datasets, while maintaining competitiveperformances and drastically reducing pre-training time. Furthermore, wedemonstrate that CropMAE learns similar object-centric representations withoutexplicit motion, showing that current self-supervised learning methods do notlearn objects from motion, but rather thanks to the Siamese architecture.Finally, CropMAE achieves the highest masking ratio to date (98.5%), enablingthe reconstruction of images using only two visible patches. Our code isavailable at https://github.com/alexandre-eymael/CropMAE.</description><author>Alexandre Eymaël, Renaud Vandeghen, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, Marc Van Droogenbroeck</author><pubDate>Tue, 26 Mar 2024 17:04:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17823v1</guid></item><item><title>Training BERT Models to Carry Over a Coding System Developed on One Corpus to Another</title><link>http://arxiv.org/abs/2308.03742v2</link><description>This paper describes how we train BERT models to carry over a coding systemdeveloped on the paragraphs of a Hungarian literary journal to another. The aimof the coding system is to track trends in the perception of literarytranslation around the political transformation in 1989 in Hungary. To evaluatenot only task performance but also the consistence of the annotation, moreover,to get better predictions from an ensemble, we use 10-fold crossvalidation.Extensive hyperparameter tuning is used to obtain the best possible results andfair comparisons. To handle label imbalance, we use loss functions and metricsrobust to it. Evaluation of the effect of domain shift is carried out bysampling a test set from the target domain. We establish the sample size byestimating the bootstrapped confidence interval via simulations. This way, weshow that our models can carry over one annotation system to the target domain.Comparisons are drawn to provide insights such as learning multilabelcorrelations and confidence penalty improve resistance to domain shift, anddomain adaptation on OCR-ed text on another domain improves performance almostto the same extent as that on the corpus under study. See our code athttps://codeberg.org/zsamboki/bert-annotator-ensemble.</description><author>Dalma Galambos, Pál Zsámboki</author><pubDate>Tue, 26 Mar 2024 17:03:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.03742v2</guid></item><item><title>Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics</title><link>http://arxiv.org/abs/2403.14077v2</link><description>DeepFakes, which refer to AI-generated media content, have become anincreasing concern due to their use as a means for disinformation. DetectingDeepFakes is currently solved with programmed machine learning algorithms. Inthis work, we investigate the capabilities of multimodal large language models(LLMs) in DeepFake detection. We conducted qualitative and quantitativeexperiments to demonstrate multimodal LLMs and show that they can exposeAI-generated images through careful experimental design and prompt engineering.This is interesting, considering that LLMs are not inherently tailored formedia forensic tasks, and the process does not require programming. We discussthe limitations of multimodal LLMs for these tasks and suggest possibleimprovements.</description><author>Shan Jia, Reilin Lyu, Kangran Zhao, Yize Chen, Zhiyuan Yan, Yan Ju, Chuanbo Hu, Xin Li, Baoyuan Wu, Siwei Lyu</author><pubDate>Tue, 26 Mar 2024 17:02:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14077v2</guid></item><item><title>DN-Splatter: Depth and Normal Priors for Gaussian Splatting and Meshing</title><link>http://arxiv.org/abs/2403.17822v1</link><description>3D Gaussian splatting, a novel differentiable rendering technique, hasachieved state-of-the-art novel view synthesis results with high renderingspeeds and relatively low training times. However, its performance on scenescommonly seen in indoor datasets is poor due to the lack of geometricconstraints during optimization. We extend 3D Gaussian splatting with depth andnormal cues to tackle challenging indoor datasets and showcase techniques forefficient mesh extraction, an important downstream application. Specifically,we regularize the optimization procedure with depth information, enforce localsmoothness of nearby Gaussians, and use the geometry of the 3D Gaussianssupervised by normal cues to achieve better alignment with the true scenegeometry. We improve depth estimation and novel view synthesis results overbaselines and show how this simple yet effective regularization technique canbe used to directly extract meshes from the Gaussian representation yieldingmore physically accurate reconstructions on indoor scenes. Our code will bereleased in https://github.com/maturk/dn-splatter.</description><author>Matias Turkulainen, Xuqian Ren, Iaroslav Melekhov, Otto Seiskari, Esa Rahtu, Juho Kannala</author><pubDate>Tue, 26 Mar 2024 17:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17822v1</guid></item><item><title>Efficient Pre-training for Localized Instruction Generation of Videos</title><link>http://arxiv.org/abs/2311.15964v2</link><description>Procedural videos show step-by-step demonstrations of tasks like recipepreparation. Understanding such videos is challenging, involving the preciselocalization of steps and the generation of textual instructions. Manuallyannotating steps and writing instructions is costly, which limits the size ofcurrent datasets and hinders effective learning. Leveraging large but noisyvideo-transcript datasets for pre-training can boost performance, but demandssignificant computational resources. Furthermore, transcripts containirrelevant content and exhibit style variation compared to instructions writtenby human annotators. To mitigate both issues, we propose a technique,Sieve-&amp;-Swap, to automatically curate a smaller dataset: (i) Sieve filtersirrelevant transcripts and (ii) Swap enhances the quality of the textinstruction by automatically replacing the transcripts with human-writteninstructions from a text-only recipe dataset. The curated dataset, three ordersof magnitude smaller than current web-scale datasets, enables efficienttraining of large-scale models with competitive performance. We complement ourSieve-\&amp;-Swap approach with a Procedure Transformer (ProcX) for end-to-end steplocalization and instruction generation for procedural videos. When this modelis pre-trained on our curated dataset, it achieves state-of-the-art performancein zero-shot and finetuning settings on YouCook2 and Tasty, while using afraction of the computational resources.</description><author>Anil Batra, Davide Moltisanti, Laura Sevilla-Lara, Marcus Rohrbach, Frank Keller</author><pubDate>Tue, 26 Mar 2024 16:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15964v2</guid></item><item><title>Towards Multilevel Modelling of Train Passing Events on the Staffordshire Bridge</title><link>http://arxiv.org/abs/2403.17820v1</link><description>We suggest a multilevel model, to represent aggregate train-passing eventsfrom the Staffordshire bridge monitoring system. We formulate a combined modelfrom simple units, representing strain envelopes (of each train passing) fortwo types of commuter train. The measurements are treated as a longitudinaldataset and represented with a (low-rank approximation) hierarchical Gaussianprocess. For each unit in the combined model, we encode domain expertise asboundary condition constraints and work towards a general representation of thestrain response. Looking forward, this should allow for the simulation of traintypes that were previously unobserved in the training data. For example, trainswith more passengers or freights with a heavier payload. The strain eventsimulations are valuable since they can inform further experiments (includingFEM calibration, fatigue analysis, or design) to test the bridge inhypothesised scenarios.</description><author>Lawrence A. Bull, Chiho Jeon, Mark Girolami, Andrew Duncan, Jennifer Schooling, Miguel Bravo Haro</author><pubDate>Tue, 26 Mar 2024 16:55:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17820v1</guid></item><item><title>Accelerating Radio Spectrum Regulation Workflows with Large Language Models (LLMs)</title><link>http://arxiv.org/abs/2403.17819v1</link><description>Wireless spectrum regulation is a complex and demanding process due to therapid pace of technological progress, increasing demand for spectrum, and amultitude of stakeholders with potentially conflicting interests, alongsidesignificant economic implications. To navigate this, regulators must engageeffectively with all parties, keep pace with global technology trends, conducttechnical evaluations, issue licenses in a timely manner, and comply withvarious legal and policy frameworks. In light of these challenges, this paper demonstrates example applications ofLarge Language Models (LLMs) to expedite spectrum regulatory processes. Weexplore various roles that LLMs can play in this context while identifying someof the challenges to address. The paper also offers practical case studies andinsights, with appropriate experiments, highlighting the transformativepotential of LLMs in spectrum management.</description><author>Amir Ghasemi, Paul Guinand</author><pubDate>Tue, 26 Mar 2024 16:54:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17819v1</guid></item><item><title>Graph Language Model (GLM): A new graph-based approach to detect social instabilities</title><link>http://arxiv.org/abs/2403.17816v1</link><description>This scientific report presents a novel methodology for the early predictionof important political events using News datasets. The methodology leveragesnatural language processing, graph theory, clique analysis, and semanticrelationships to uncover hidden predictive signals within the data. Initially,we designed a preliminary version of the method and tested it on a few events.This analysis revealed limitations in the initial research phase. We thenenhanced the model in two key ways: first, we added a filtration step to onlyconsider politically relevant news before further processing; second, weadjusted the input features to make the alert system more sensitive tosignificant spikes in the data. After finalizing the improved methodology, wetested it on eleven events including US protests, the Ukraine war, and Frenchprotests. Results demonstrate the superiority of our approach compared tobaseline methods. Through targeted refinements, our model can now provideearlier and more accurate predictions of major political events based on subtlepatterns in news data.</description><author>Wallyson Lemes de Oliveira, Vahid Shamsaddini, Ali Ghofrani, Rahul Singh Inda, Jithendra Sai Veeramaneni, Étienne Voutaz</author><pubDate>Tue, 26 Mar 2024 16:53:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17816v1</guid></item><item><title>D-PAD: Deep-Shallow Multi-Frequency Patterns Disentangling for Time Series Forecasting</title><link>http://arxiv.org/abs/2403.17814v1</link><description>In time series forecasting, effectively disentangling intricate temporalpatterns is crucial. While recent works endeavor to combine decompositiontechniques with deep learning, multiple frequencies may still be mixed in thedecomposed components, e.g., trend and seasonal. Furthermore, frequency domainanalysis methods, e.g., Fourier and wavelet transforms, have limitations inresolution in the time domain and adaptability. In this paper, we proposeD-PAD, a deep-shallow multi-frequency patterns disentangling neural network fortime series forecasting. Specifically, a multi-component decomposing (MCD)block is introduced to decompose the series into components with differentfrequency ranges, corresponding to the "shallow" aspect. Adecomposition-reconstruction-decomposition (D-R-D) module is proposed toprogressively extract the information of frequencies mixed in the components,corresponding to the "deep" aspect. After that, an interaction and fusion (IF)module is used to further analyze the components. Extensive experiments onseven real-world datasets demonstrate that D-PAD achieves the state-of-the-artperformance, outperforming the best baseline by an average of 9.48% and 7.15%in MSE and MAE, respectively.</description><author>Xiaobing Yuan, Ling Chen</author><pubDate>Tue, 26 Mar 2024 16:52:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17814v1</guid></item><item><title>Analyzing the Quality Attributes of AI Vision Models in Open Repositories Under Adversarial Attacks</title><link>http://arxiv.org/abs/2401.12261v2</link><description>As AI models rapidly evolve, they are frequently released to openrepositories, such as HuggingFace. It is essential to perform quality assurancevalidation on these models before integrating them into the productiondevelopment lifecycle. In addition to evaluating efficiency in terms ofbalanced accuracy and computing costs, adversarial attacks are potentialthreats to the robustness and explainability of AI models. Meanwhile, XAIapplies algorithms that approximate inputs to outputs post-hoc to identify thecontributing features. Adversarial perturbations may also degrade the utilityof XAI explanations that require further investigation. In this paper, wepresent an integrated process designed for downstream evaluation tasks,including validating AI model accuracy, evaluating robustness with benchmarkperturbations, comparing explanation utility, and assessing overhead. Wedemonstrate an evaluation scenario involving six computer vision models, whichinclude CNN-based, Transformer-based, and hybrid architectures, three types ofperturbations, and five XAI methods, resulting in ninety unique combinations.The process reveals the explanation utility among the XAI methods in terms ofthe identified key areas responding to the adversarial perturbation. Theprocess produces aggregated results that illustrate multiple attributes of eachAI model.</description><author>Zerui Wang, Yan Liu</author><pubDate>Tue, 26 Mar 2024 16:52:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12261v2</guid></item><item><title>Are Compressed Language Models Less Subgroup Robust?</title><link>http://arxiv.org/abs/2403.17811v1</link><description>To reduce the inference cost of large language models, model compression isincreasingly used to create smaller scalable models. However, little is knownabout their robustness to minority subgroups defined by the labels andattributes of a dataset. In this paper, we investigate the effects of 18different compression methods and settings on the subgroup robustness of BERTlanguage models. We show that worst-group performance does not depend on modelsize alone, but also on the compression method used. Additionally, we find thatmodel compression does not always worsen the performance on minority subgroups.Altogether, our analysis serves to further research into the subgrouprobustness of model compression.</description><author>Leonidas Gee, Andrea Zugarini, Novi Quadrianto</author><pubDate>Tue, 26 Mar 2024 16:50:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17811v1</guid></item><item><title>Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?</title><link>http://arxiv.org/abs/2401.11911v4</link><description>While auxiliary information has become a key to enhancing Large LanguageModels (LLMs), relatively little is known about how LLMs merge these contexts,specifically contexts generated by LLMs and those retrieved from externalsources. To investigate this, we formulate a systematic framework to identifywhether LLMs' responses, derived from the integration of generated andretrieved contexts, are attributed to either generated or retrieved contexts.To easily trace the origin of the response, we construct datasets withconflicting contexts, i.e., each question is paired with both generated andretrieved contexts, yet only one of them contains the correct answer. Ourexperiments reveal a significant bias in several LLMs (GPT-4/3.5 and Llama2) tofavor generated contexts, even when they provide incorrect information. Wefurther identify two key factors contributing to this bias: i) contextsgenerated by LLMs typically show greater similarity to the questions,increasing their likelihood of being selected; ii) the segmentation processused in retrieved contexts disrupts their completeness, thereby hindering theirfull utilization in LLMs. Our analysis enhances the understanding of how LLMsmerge diverse contexts, offering valuable insights for advancing currentaugmentation methods for LLMs.</description><author>Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, Xueqi Cheng</author><pubDate>Tue, 26 Mar 2024 16:47:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11911v4</guid></item><item><title>Annotated Biomedical Video Generation using Denoising Diffusion Probabilistic Models and Flow Fields</title><link>http://arxiv.org/abs/2403.17808v1</link><description>The segmentation and tracking of living cells play a vital role within thebiomedical domain, particularly in cancer research, drug development, anddevelopmental biology. These are usually tedious and time-consuming tasks thatare traditionally done by biomedical experts. Recently, to automatize theseprocesses, deep learning based segmentation and tracking methods have beenproposed. These methods require large-scale datasets and their full potentialis constrained by the scarcity of annotated data in the biomedical imagingdomain. To address this limitation, we propose Biomedical Video Diffusion Model(BVDM), capable of generating realistic-looking synthetic microscopy videos.Trained only on a single real video, BVDM can generate videos of arbitrarylength with pixel-level annotations that can be used for training data-hungrymodels. It is composed of a denoising diffusion probabilistic model (DDPM)generating high-fidelity synthetic cell microscopy images and a flow predictionmodel (FPM) predicting the non-rigid transformation between consecutive videoframes. During inference, initially, the DDPM imposes realistic cell textureson synthetic cell masks which are generated based on real data statistics. Theflow prediction model predicts the flow field between consecutive masks andapplies that to the DDPM output from the previous time frame to create the nextone while keeping temporal consistency. BVDM outperforms state-of-the-artsynthetic live cell microscopy video generation models. Furthermore, wedemonstrate that a sufficiently large synthetic dataset enhances theperformance of cell segmentation and tracking models compared to using alimited amount of available real data.</description><author>Rüveyda Yilmaz, Dennis Eschweiler, Johannes Stegmaier</author><pubDate>Tue, 26 Mar 2024 16:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17808v1</guid></item><item><title>Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms</title><link>http://arxiv.org/abs/2403.17806v1</link><description>Many recent language model (LM) interpretability studies have adopted thecircuits framework, which aims to find the minimal computational subgraph, orcircuit, that explains LM behavior on a given task. Most studies determinewhich edges belong in a LM's circuit by performing causal interventions on eachedge independently, but this scales poorly with model size. Edge attributionpatching (EAP), gradient-based approximation to interventions, has emerged as ascalable but imperfect solution to this problem. In this paper, we introduce anew method - EAP with integrated gradients (EAP-IG) - that aims to bettermaintain a core property of circuits: faithfulness. A circuit is faithful ifall model edges outside the circuit can be ablated without changing the model'sperformance on the task; faithfulness is what justifies studying circuits,rather than the full model. Our experiments demonstrate that circuits foundusing EAP are less faithful than those found using EAP-IG, even though bothhave high node overlap with circuits found previously using causalinterventions. We conclude more generally that when using circuits to comparethe mechanisms models use to solve tasks, faithfulness, not overlap, is whatshould be measured.</description><author>Michael Hanna, Sandro Pezzelle, Yonatan Belinkov</author><pubDate>Tue, 26 Mar 2024 16:44:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17806v1</guid></item><item><title>Scenario-Based Curriculum Generation for Multi-Agent Autonomous Driving</title><link>http://arxiv.org/abs/2403.17805v1</link><description>The automated generation of diverse and complex training scenarios has beenan important ingredient in many complex learning tasks. Especially inreal-world application domains, such as autonomous driving, auto-curriculumgeneration is considered vital for obtaining robust and general policies.However, crafting traffic scenarios with multiple, heterogeneous agents istypically considered as a tedious and time-consuming task, especially in morecomplex simulation environments. In our work, we introduce MATS-Gym, aMulti-Agent Traffic Scenario framework to train agents in CARLA, ahigh-fidelity driving simulator. MATS-Gym is a multi-agent training frameworkfor autonomous driving that uses partial scenario specifications to generatetraffic scenarios with variable numbers of agents. This paper unifies variousexisting approaches to traffic scenario description into a single trainingframework and demonstrates how it can be integrated with techniques fromunsupervised environment design to automate the generation of adaptiveauto-curricula. The code is available athttps://github.com/AutonomousDrivingExaminer/mats-gym.</description><author>Axel Brunnbauer, Luigi Berducci, Peter Priller, Dejan Nickovic, Radu Grosu</author><pubDate>Tue, 26 Mar 2024 16:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17805v1</guid></item><item><title>Improving Text-to-Image Consistency via Automatic Prompt Optimization</title><link>http://arxiv.org/abs/2403.17804v1</link><description>Impressive advances in text-to-image (T2I) generative models have yielded aplethora of high performing models which are able to generate aestheticallyappealing, photorealistic images. Despite the progress, these models stillstruggle to produce images that are consistent with the input prompt,oftentimes failing to capture object quantities, relations and attributesproperly. Existing solutions to improve prompt-image consistency suffer fromthe following challenges: (1) they oftentimes require model fine-tuning, (2)they only focus on nearby prompt samples, and (3) they are affected byunfavorable trade-offs among image quality, representation diversity, andprompt-image consistency. In this paper, we address these challenges andintroduce a T2I optimization-by-prompting framework, OPT2I, which leverages alarge language model (LLM) to improve prompt-image consistency in T2I models.Our framework starts from a user prompt and iteratively generates revisedprompts with the goal of maximizing a consistency score. Our extensivevalidation on two datasets, MSCOCO and PartiPrompts, shows that OPT2I can boostthe initial consistency score by up to 24.9% in terms of DSG score whilepreserving the FID and increasing the recall between generated and real data.Our work paves the way toward building more reliable and robust T2I systems byharnessing the power of LLMs.</description><author>Oscar Mañas, Pietro Astolfi, Melissa Hall, Candace Ross, Jack Urbanek, Adina Williams, Aishwarya Agrawal, Adriana Romero-Soriano, Michal Drozdzal</author><pubDate>Tue, 26 Mar 2024 16:42:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17804v1</guid></item><item><title>Toward a Theory of Causation for Interpreting Neural Code Models</title><link>http://arxiv.org/abs/2302.03788v4</link><description>Neural Language Models of Code, or Neural Code Models (NCMs), are rapidlyprogressing from research prototypes to commercial developer tools. As such,understanding the capabilities and limitations of such models is becomingcritical. However, the abilities of these models are typically measured usingautomated metrics that often only reveal a portion of their real-worldperformance. While, in general, the performance of NCMs appears promising,currently much is unknown about how such models arrive at decisions. To thisend, this paper introduces $do_{code}$, a post hoc interpretability methodspecific to NCMs that is capable of explaining model predictions. $do_{code}$is based upon causal inference to enable programming language-orientedexplanations. While the theoretical underpinnings of $do_{code}$ are extensibleto exploring different model properties, we provide a concrete instantiationthat aims to mitigate the impact of spurious correlations by groundingexplanations of model behavior in properties of programming languages. Todemonstrate the practical benefit of $do_{code}$, we illustrate the insightsthat our framework can provide by performing a case study on two popular deeplearning architectures and ten NCMs. The results of this case study illustratethat our studied NCMs are sensitive to changes in code syntax. All our NCMs,except for the BERT-like model, statistically learn to predict tokens relatedto blocks of code (\eg brackets, parenthesis, semicolon) with less confoundingbias as compared to other programming language constructs. These insightsdemonstrate the potential of $do_{code}$ as a useful method to detect andfacilitate the elimination of confounding bias in NCMs.</description><author>David N. Palacio, Alejandro Velasco, Nathan Cooper, Alvaro Rodriguez, Kevin Moran, Denys Poshyvanyk</author><pubDate>Tue, 26 Mar 2024 16:41:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03788v4</guid></item><item><title>SimLVSeg: Simplifying Left Ventricular Segmentation in 2D+Time Echocardiograms with Self- and Weakly-Supervised Learning</title><link>http://arxiv.org/abs/2310.00454v3</link><description>Echocardiography has become an indispensable clinical imaging modality forgeneral heart health assessment. From calculating biomarkers such as ejectionfraction to the probability of a patient's heart failure, accurate segmentationof the heart structures allows doctors to assess the heart's condition anddevise treatments with greater precision and accuracy. However, achievingaccurate and reliable left ventricle segmentation is time-consuming andchallenging due to different reasons. Hence, clinicians often rely onsegmenting the left ventricular (LV) in two specific echocardiogram frames tomake a diagnosis. This limited coverage in manual LV segmentation poses achallenge for developing automatic LV segmentation with high temporalconsistency, as the resulting dataset is typically annotated sparsely. Inresponse to this challenge, this work introduces SimLVSeg, a novel paradigmthat enables video-based networks for consistent LV segmentation from sparselyannotated echocardiogram videos. SimLVSeg consists of self-supervisedpre-training with temporal masking, followed by weakly supervised learningtailored for LV segmentation from sparse annotations. We demonstrate howSimLVSeg outperforms the state-of-the-art solutions by achieving a 93.32%(95%CI 93.21-93.43%) dice score on the largest 2D+time echocardiography dataset(EchoNet-Dynamic) while being more efficient. SimLVSeg is compatible with twotypes of video segmentation networks: 2D super image and 3D segmentation. Toshow the effectiveness of our approach, we provide extensive ablation studies,including pre-training settings and various deep learning backbones. We furtherconduct an out-of-distribution test to showcase SimLVSeg's generalizability onunseen distribution (CAMUS dataset). The code is publicly available athttps://github.com/fadamsyah/SimLVSeg.</description><author>Fadillah Maani, Asim Ukaye, Nada Saadi, Numan Saeed, Mohammad Yaqub</author><pubDate>Tue, 26 Mar 2024 16:41:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00454v3</guid></item><item><title>HIMap: HybrId Representation Learning for End-to-end Vectorized HD Map Construction</title><link>http://arxiv.org/abs/2403.08639v2</link><description>Vectorized High-Definition (HD) map construction requires predictions of thecategory and point coordinates of map elements (e.g. road boundary, lanedivider, pedestrian crossing, etc.). State-of-the-art methods are mainly basedon point-level representation learning for regressing accurate pointcoordinates. However, this pipeline has limitations in obtaining element-levelinformation and handling element-level failures, e.g. erroneous element shapeor entanglement between elements. To tackle the above issues, we propose asimple yet effective HybrId framework named HIMap to sufficiently learn andinteract both point-level and element-level information. Concretely, weintroduce a hybrid representation called HIQuery to represent all map elements,and propose a point-element interactor to interactively extract and encode thehybrid information of elements, e.g. point position and element shape, into theHIQuery. Additionally, we present a point-element consistency constraint toenhance the consistency between the point-level and element-level information.Finally, the output point-element integrated HIQuery can be directly convertedinto map elements' class, point coordinates, and mask. We conduct extensiveexperiments and consistently outperform previous methods on both nuScenes andArgoverse2 datasets. Notably, our method achieves $77.8$ mAP on the nuScenesdataset, remarkably superior to previous SOTAs by $8.3$ mAP at least.</description><author>Yi Zhou, Hui Zhang, Jiaqian Yu, Yifan Yang, Sangil Jung, Seung-In Park, ByungIn Yoo</author><pubDate>Tue, 26 Mar 2024 16:40:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08639v2</guid></item><item><title>Towards 3D Vision with Low-Cost Single-Photon Cameras</title><link>http://arxiv.org/abs/2403.17801v1</link><description>We present a method for reconstructing 3D shape of arbitrary Lambertianobjects based on measurements by miniature, energy-efficient, low-costsingle-photon cameras. These cameras, operating as time resolved image sensors,illuminate the scene with a very fast pulse of diffuse light and record theshape of that pulse as it returns back from the scene at a high temporalresolution. We propose to model this image formation process, account for itsnon-idealities, and adapt neural rendering to reconstruct 3D geometry from aset of spatially distributed sensors with known poses. We show that ourapproach can successfully recover complex 3D shapes from simulated data. Wefurther demonstrate 3D object reconstruction from real-world captures,utilizing measurements from a commodity proximity sensor. Our work draws aconnection between image-based modeling and active range scanning and is a steptowards 3D vision with single-photon cameras.</description><author>Fangzhou Mu, Carter Sifferman, Sacha Jungerman, Yiquan Li, Mark Han, Michael Gleicher, Mohit Gupta, Yin Li</author><pubDate>Tue, 26 Mar 2024 16:40:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17801v1</guid></item><item><title>Measuring Entrainment in Spontaneous Code-switched Speech</title><link>http://arxiv.org/abs/2311.07703v2</link><description>It is well-known that speakers who entrain to one another have moresuccessful conversations than those who do not. Previous research has shownthat interlocutors entrain on linguistic features in both written and spokenmonolingual domains. More recent work on code-switched communication has alsoshown preliminary evidence of entrainment on certain aspects of code-switching(CSW). However, such studies of entrainment in code-switched domains have beenextremely few and restricted to human-machine textual interactions. Our workstudies code-switched spontaneous speech between humans, finding that (1)patterns of written and spoken entrainment in monolingual settings largelygeneralize to code-switched settings, and (2) some patterns of entrainment oncode-switching in dialogue agent-generated text generalize to spontaneouscode-switched speech. Our findings give rise to important implications for thepotentially "universal" nature of entrainment as a communication phenomenon,and potential applications in inclusive and interactive speech technology.</description><author>Debasmita Bhattacharya, Siying Ding, Alayna Nguyen, Julia Hirschberg</author><pubDate>Tue, 26 Mar 2024 16:31:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07703v2</guid></item></channel></rss>