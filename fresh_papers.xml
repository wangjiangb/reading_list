<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 02 Nov 2023 06:00:13 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>SNAP: Self-Supervised Neural Maps for Visual Positioning and Semantic Understanding</title><link>http://arxiv.org/abs/2306.05407v2</link><description>Semantic 2D maps are commonly used by humans and machines for navigationpurposes, whether it's walking or driving. However, these maps havelimitations: they lack detail, often contain inaccuracies, and are difficult tocreate and maintain, especially in an automated fashion. Can we use raw imageryto automatically create better maps that can be easily interpreted by bothhumans and machines? We introduce SNAP, a deep network that learns rich neural2D maps from ground-level and overhead images. We train our model to alignneural maps estimated from different inputs, supervised only with camera posesover tens of millions of StreetView images. SNAP can resolve the location ofchallenging image queries beyond the reach of traditional methods,outperforming the state of the art in localization by a large margin. Moreover,our neural maps encode not only geometry and appearance but also high-levelsemantics, discovered without explicit supervision. This enables effectivepre-training for data-efficient semantic scene understanding, with thepotential to unlock cost-efficient creation of more detailed maps.</description><author>Paul-Edouard Sarlin, Eduard Trulls, Marc Pollefeys, Jan Hosang, Simon Lynen</author><pubDate>Wed, 01 Nov 2023 18:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05407v2</guid></item><item><title>Is This Loss Informative? Faster Text-to-Image Customization by Tracking Objective Dynamics</title><link>http://arxiv.org/abs/2302.04841v3</link><description>Text-to-image generation models represent the next step of evolution in imagesynthesis, offering a natural way to achieve flexible yet fine-grained controlover the result. One emerging area of research is the fast adaptation of largetext-to-image models to smaller datasets or new visual concepts. However, manyefficient methods of adaptation have a long training time, which limits theirpractical applications, slows down experiments, and spends excessive GPUresources. In this work, we study the training dynamics of populartext-to-image personalization methods (such as Textual Inversion orDreamBooth), aiming to speed them up. We observe that most concepts are learnedat early stages and do not improve in quality later, but standard trainingconvergence metrics fail to indicate that. Instead, we propose a simple drop-inearly stopping criterion that only requires computing the regular trainingobjective on a fixed set of inputs for all training iterations. Our experimentson Stable Diffusion for 48 different concepts and three personalization methodsdemonstrate the competitive performance of our approach, which makes adaptationup to 8 times faster with no significant drops in quality.</description><author>Anton Voronov, Mikhail Khoroshikh, Artem Babenko, Max Ryabinin</author><pubDate>Wed, 01 Nov 2023 18:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04841v3</guid></item><item><title>End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation</title><link>http://arxiv.org/abs/2311.00697v1</link><description>Conventional speech-to-text translation (ST) systems are trained onsingle-speaker utterances, and they may not generalize to real-life scenarioswhere the audio contains conversations by multiple speakers. In this paper, wetackle single-channel multi-speaker conversational ST with an end-to-end andmulti-task training model, named Speaker-Turn Aware Conversational SpeechTranslation, that combines automatic speech recognition, speech translation andspeaker turn detection using special tokens in a serialized labeling format. Werun experiments on the Fisher-CALLHOME corpus, which we adapted by merging thetwo single-speaker channels into one multi-speaker channel, thus representingthe more realistic and challenging scenario with multi-speaker turns andcross-talk. Experimental results across single- and multi-speaker conditionsand against conventional ST systems, show that our model outperforms thereference systems on the multi-speaker condition, while attaining comparableperformance on the single-speaker condition. We release scripts for dataprocessing and model training.</description><author>Juan Zuluaga-Gomez, Zhaocheng Huang, Xing Niu, Rohit Paturi, Sundararajan Srinivasan, Prashant Mathur, Brian Thompson, Marcello Federico</author><pubDate>Wed, 01 Nov 2023 18:55:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00697v1</guid></item><item><title>Decision Support Framework for Home Health Caregiver Allocation: A Case Study of HHC Agency in Tennessee, USA</title><link>http://arxiv.org/abs/2311.00696v1</link><description>Population aging is a global challenge, leading to increased demand forhealthcare and social services for the elderly. Home Health Care (HHC) emergesas a vital solution, specifically designed to serve this population segment.Given the surging demand for HHC, it's essential to coordinate and regulatecaregiver allocation efficiently. This is crucial for both budget-optimizedplanning and ensuring the delivery of high-quality care. This researchaddresses a key question faced by home health agencies (HHAs): "How cancaregiver allocation be optimized, especially when caregivers preferflexibility in their visiting sequences?". While earlier studies proposed rigidvisiting sequences, our study introduces a decision support framework thatallocates caregivers through a hybrid method that considers the flexibility invisiting sequences and aims to reduce travel mileage, increase the number ofvisits per planning period, and maintain the continuity of care - a criticalmetric for patient satisfaction. Utilizing data from an HHA in Tennessee,United States, our approach led to an impressive reduction in average travelmileage (up to 42% depending on discipline) without imposing restrictions oncaregivers. Furthermore, the proposed framework is used for caregivers' supplyanalysis to provide valuable insights into caregiver resource management.</description><author>Seyed Mohammad Ebrahim Sharifnia, Faezeh Bagheri, Rupy Sawhney, John E. Kobza, Enrique Macias De Anda, Mostafa Hajiaghaei-Keshteli, Michael Mirrielees</author><pubDate>Wed, 01 Nov 2023 18:54:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00696v1</guid></item><item><title>Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving</title><link>http://arxiv.org/abs/2311.00694v1</link><description>Large Language Models (LLMs) have achieved tremendous progress, yet theystill often struggle with challenging reasoning problems. Current approachesaddress this challenge by sampling or searching detailed and low-levelreasoning chains. However, these methods are still limited in their explorationcapabilities, making it challenging for correct solutions to stand out in thehuge solution space. In this work, we unleash LLMs' creative potential forexploring multiple diverse problem solving strategies by framing an LLM as ahierarchical policy via in-context learning. This policy comprises of avisionary leader that proposes multiple diverse high-level problem-solvingtactics as hints, accompanied by a follower that executes detailedproblem-solving processes following each of the high-level instruction. Thefollower uses each of the leader's directives as a guide and samples multiplereasoning chains to tackle the problem, generating a solution group for eachleader proposal. Additionally, we propose an effective and efficienttournament-based approach to select among these explored solution groups toreach the final answer. Our approach produces meaningful and inspiring hints,enhances problem-solving strategy exploration, and improves the final answeraccuracy on challenging problems in the MATH dataset. Code will be released athttps://github.com/lz1oceani/LLM-As-Hierarchical-Policy.</description><author>Zhan Ling, Yunhao Fang, Xuanlin Li, Tongzhou Mu, Mingu Lee, Reza Pourreza, Roland Memisevic, Hao Su</author><pubDate>Wed, 01 Nov 2023 18:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00694v1</guid></item><item><title>On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval</title><link>http://arxiv.org/abs/2311.00693v1</link><description>Visually-rich document entity retrieval (VDER), which extracts keyinformation (e.g. date, address) from document images like invoices andreceipts, has become an important topic in industrial NLP applications. Theemergence of new document types at a constant pace, each with its unique entitytypes, presents a unique challenge: many documents contain unseen entity typesthat occur only a couple of times. Addressing this challenge requires models tohave the ability of learning entities in a few-shot manner. However, priorworks for Few-shot VDER mainly address the problem at the document level with apredefined global entity space, which doesn't account for the entity-levelfew-shot scenario: target entity types are locally personalized by each taskand entity occurrences vary significantly among documents. To address thisunexplored scenario, this paper studies a novel entity-level few-shot VDERtask. The challenges lie in the uniqueness of the label space for each task andthe increased complexity of out-of-distribution (OOD) contents. To tackle thisnovel task, we present a task-aware meta-learning based framework, with acentral focus on achieving effective task personalization that distinguishesbetween in-task and out-of-task distribution. Specifically, we adopt ahierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) toachieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boostfuture research in the field of entity-level few-shot VDER. Experimentalresults demonstrate our approaches significantly improve the robustness ofpopular meta-learning baselines.</description><author>Jiayi Chen, Hanjun Dai, Bo Dai, Aidong Zhang, Wei Wei</author><pubDate>Wed, 01 Nov 2023 18:51:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00693v1</guid></item><item><title>Software Repositories and Machine Learning Research in Cyber Security</title><link>http://arxiv.org/abs/2311.00691v1</link><description>In today's rapidly evolving technological landscape and advanced softwaredevelopment, the rise in cyber security attacks has become a pressing concern.The integration of robust cyber security defenses has become essential acrossall phases of software development. It holds particular significance inidentifying critical cyber security vulnerabilities at the initial stages ofthe software development life cycle, notably during the requirement phase.Through the utilization of cyber security repositories like The Common AttackPattern Enumeration and Classification (CAPEC) from MITRE and the CommonVulnerabilities and Exposures (CVE) databases, attempts have been made toleverage topic modeling and machine learning for the detection of theseearly-stage vulnerabilities in the software requirements process. Past researchthemes have returned successful outcomes in attempting to automatevulnerability identification for software developers, employing a mixture ofunsupervised machine learning methodologies such as LDA and topic modeling.Looking ahead, in our pursuit to improve automation and establish connectionsbetween software requirements and vulnerabilities, our strategy entailsadopting a variety of supervised machine learning techniques. This arrayencompasses Support Vector Machines (SVM), Na\"ive Bayes, random forest, neuralnetworking and eventually transitioning into deep learning for ourinvestigation. In the face of the escalating complexity of cyber security, thequestion of whether machine learning can enhance the identification ofvulnerabilities in diverse software development scenarios is a paramountconsideration, offering crucial assistance to software developers in developingsecure software.</description><author>Mounika Vanamala, Keith Bryant, Alex Caravella</author><pubDate>Wed, 01 Nov 2023 18:46:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00691v1</guid></item><item><title>What User Behaviors Make the Differences During the Process of Visual Analytics?</title><link>http://arxiv.org/abs/2311.00690v1</link><description>The understanding of visual analytics process can benefit visualizationresearchers from multiple aspects, including improving visual designs anddeveloping advanced interaction functions. However, the log files of userbehaviors are still hard to analyze due to the complexity of sensemaking andour lack of knowledge on the related user behaviors. This work presents a studyon a comprehensive data collection of user behaviors, and our analysis approachwith time-series classification methods. We have chosen a classicalvisualization application, Covid-19 data analysis, with common analysis taskscovering geo-spatial, time-series and multi-attributes. Our user study collectsuser behaviors on a diverse set of visualization tasks with two comparablesystems, desktop and immersive visualizations. We summarize the classificationresults with three time-series machine learning algorithms at two scales, andexplore the influences of behavior features. Our results reveal that userbehaviors can be distinguished during the process of visual analytics and thereis a potentially strong association between the physical behaviors of users andthe visualization tasks they perform. We also demonstrate the usage of ourmodels by interpreting open sessions of visual analytics, which provides anautomatic way to study sensemaking without tedious manual annotations.</description><author>Shahin Doroudian, Zekun Wu, Aidong Lu</author><pubDate>Wed, 01 Nov 2023 18:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00690v1</guid></item><item><title>Collaboration in Immersive Environments: Challenges and Solutions</title><link>http://arxiv.org/abs/2311.00689v1</link><description>Virtual Reality (VR) and Augmented Reality (AR) tools have been applied inall engineering fields in order to avoid the use of physical prototypes, totrain in high-risk situations, and to interpret real or simulated results. Inorder to complete a shared task or assign tasks to the agents in such immersiveenvironments, collaboration or Shared Cooperative Activities are a necessity.Collaboration in immersive environments is an emerging field of research thataims to study and enhance the ways in which people interact and work togetherin Virtual and Augmented Reality settings. Collaboration in immersiveenvironments is a complex process that involves different factors such ascommunication, coordination, and social presence. This paper provides anoverview of the current state of research on collaboration in immersiveenvironments. It discusses the different types of immersive environments,including VR and AR, and the different forms of collaboration that can occur inthese environments. The paper also highlights the challenges and limitations ofcollaboration in immersive environments, such as the lack of physical cues,cost and usability and the need for further research in this area. Overall,collaboration in immersive environments is a promising field with a wide rangeof potential applications, from education to industry, and it can benefit bothindividuals and groups by enhancing their ability to work together effectively.</description><author>Shahin Doroudian, Zachary Wartell</author><pubDate>Wed, 01 Nov 2023 18:45:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00689v1</guid></item><item><title>Improving Interpersonal Communication by Simulating Audiences with Language Models</title><link>http://arxiv.org/abs/2311.00687v1</link><description>How do we communicate with others to achieve our goals? We use our priorexperience or advice from others, or construct a candidate utterance bypredicting how it will be received. However, our experiences are limited andbiased, and reasoning about potential outcomes can be difficult and cognitivelychallenging. In this paper, we explore how we can leverage Large Language Model(LLM) simulations to help us communicate better. We propose theExplore-Generate-Simulate (EGS) framework, which takes as input any scenariowhere an individual is communicating to an audience with a goal they want toachieve. EGS (1) explores the solution space by producing a diverse set ofadvice relevant to the scenario, (2) generates communication candidatesconditioned on subsets of the advice, and (3) simulates the reactions fromvarious audiences to determine both the best candidate and advice to use. Weevaluate the framework on eight scenarios spanning the ten fundamentalprocesses of interpersonal communication. For each scenario, we collect adataset of human evaluations across candidates and baselines, and showcase thatour framework's chosen candidate is preferred over popular generationmechanisms including Chain-of-Thought. We also find that audience simulationsachieve reasonably high agreement with human raters across 5 of the 8scenarios. Finally, we demonstrate the generality of our framework by applyingit to real-world scenarios described by users on web forums. Throughevaluations and demonstrations, we show that EGS enhances the effectiveness andoutcomes of goal-oriented communication across a variety of situations, thusopening up new possibilities for the application of large language models inrevolutionizing communication and decision-making processes.</description><author>Ryan Liu, Howard Yen, Raja Marjieh, Thomas L. Griffiths, Ranjay Krishna</author><pubDate>Wed, 01 Nov 2023 18:44:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00687v1</guid></item><item><title>Covert Planning against Imperfect Observers</title><link>http://arxiv.org/abs/2310.16791v2</link><description>Covert planning refers to a class of constrained planning problems where anagent aims to accomplish a task with minimal information leaked to a passiveobserver to avoid detection. However, existing methods of covert planning oftenconsider deterministic environments or do not exploit the observer's imperfectinformation. This paper studies how covert planning can leverage the couplingof stochastic dynamics and the observer's imperfect observation to achieveoptimal task performance without being detected. Specifically, we employ aMarkov decision process to model the interaction between the agent and itsstochastic environment, and a partial observation function to capture theleaked information to a passive observer. Assuming the observer employshypothesis testing to detect if the observation deviates from a nominal policy,the covert planning agent aims to maximize the total discounted reward whilekeeping the probability of being detected as an adversary below a giventhreshold. We prove that finite-memory policies are more powerful thanMarkovian policies in covert planning. Then, we develop a primal-dual proximalpolicy gradient method with a two-time-scale update to compute a (locally)optimal covert policy. We demonstrate the effectiveness of our methods using astochastic gridworld example. Our experimental results illustrate that theproposed method computes a policy that maximizes the adversary's expectedreward without violating the detection constraint, and empirically demonstrateshow the environmental noises can influence the performance of the covertpolicies.</description><author>Haoxiang Ma, Chongyang Shi, Shuo Han, Michael R. Dorothy, Jie Fu</author><pubDate>Wed, 01 Nov 2023 18:44:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16791v2</guid></item><item><title>Little Giants: Exploring the Potential of Small LLMs as Evaluation Metrics in Summarization in the Eval4NLP 2023 Shared Task</title><link>http://arxiv.org/abs/2311.00686v1</link><description>This paper describes and analyzes our participation in the 2023 Eval4NLPshared task, which focuses on assessing the effectiveness of prompt-basedtechniques to empower Large Language Models to handle the task of qualityestimation, particularly in the context of evaluating machine translations andsummaries. We conducted systematic experiments with various promptingtechniques, including standard prompting, prompts informed by annotatorinstructions, and innovative chain-of-thought prompting. In addition, weintegrated these approaches with zero-shot and one-shot learning methods tomaximize the efficacy of our evaluation procedures. Our work reveals thatcombining these approaches using a "small", open source model (orca_mini_v3_7B)yields competitive results.</description><author>Neema Kotonya, Saran Krishnasamy, Joel Tetreault, Alejandro Jaimes</author><pubDate>Wed, 01 Nov 2023 18:44:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00686v1</guid></item><item><title>Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation</title><link>http://arxiv.org/abs/2311.00684v1</link><description>An ideal length-extrapolatable Transformer language model can handlesequences longer than the training length without any long sequencefine-tuning. Such long-context utilization capability highly relies on aflexible positional embedding design. Upon investigating the flexibility ofexisting large pre-trained Transformer language models, we find that the T5family deserves a closer look, as its positional embeddings capture rich andflexible attention patterns. However, T5 suffers from the dispersed attentionissue: the longer the input sequence, the flatter the attention distribution.To alleviate the issue, we propose two attention alignment strategies viatemperature scaling. Our findings improve the long-context utilizationcapability of T5 on language modeling, retrieval, and multi-document questionanswering without any fine-tuning, suggesting that a flexible positionalembedding design and attention alignment go a long way toward Transformerlengthextrapolation.\footnote{\url{https://github.com/chijames/Attention-Alignment-Transformer-Length-Extrapolation}}</description><author>Ta-Chung Chi, Ting-Han Fan, Alexander I. Rudnicky</author><pubDate>Wed, 01 Nov 2023 18:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00684v1</guid></item><item><title>Deep Learning-Based Classification of Gamma Photon Interactions in Room-Temperature Semiconductor Radiation Detectors</title><link>http://arxiv.org/abs/2311.00682v1</link><description>Photon counting radiation detectors have become an integral part of medicalimaging modalities such as Positron Emission Tomography or Computed Tomography.One of the most promising detectors is the wide bandgap room temperaturesemiconductor detectors, which depends on the interaction gamma/x-ray photonswith the detector material involves Compton scattering which leads to multipleinteraction photon events (MIPEs) of a single photon. For semiconductordetectors like CdZnTeSe (CZTS), which have a high overlap of detected energiesbetween Compton and photoelectric events, it is nearly impossible todistinguish between Compton scattered events from photoelectric events usingconventional readout electronics or signal processing algorithms. Herein, wereport a deep learning classifier CoPhNet that distinguishes between Comptonscattering and photoelectric interactions of gamma/x-ray photons with CdZnTeSe(CZTS) semiconductor detectors. Our CoPhNet model was trained using simulateddata to resemble actual CZTS detector pulses and validated using both simulatedand experimental data. These results demonstrated that our CoPhNet model canachieve high classification accuracy over the simulated test set. It also holdsits performance robustness under operating parameter shifts such asSignal-Noise-Ratio (SNR) and incident energy. Our work thus laid solidfoundation for developing next-generation high energy gamma-rays detectors forbetter biomedical imaging.</description><author>Sandeep K. Chaudhuri, Qinyang Li, Krishna C. Mandal, Jianjun Hu</author><pubDate>Wed, 01 Nov 2023 18:42:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00682v1</guid></item><item><title>Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs</title><link>http://arxiv.org/abs/2311.00681v1</link><description>In recent years, Large Language Models (LLMs) have gained immense attentiondue to their notable emergent capabilities, surpassing those seen in earlierlanguage models. A particularly intriguing application of LLMs is their role asevaluators for texts produced by various generative models. In this study, we delve into the potential of LLMs as reliable assessors offactual consistency in summaries generated by text-generation models.Initially, we introduce an innovative approach for factuality assessment usingLLMs. This entails employing a singular LLM for the entirety of thequestion-answering-based factuality scoring process. Following this, we examinethe efficacy of various LLMs in direct factuality scoring, benchmarking themagainst traditional measures and human annotations. Contrary to initial expectations, our results indicate a lack of significantcorrelations between factuality metrics and human evaluations, specifically forGPT-4 and PaLM-2. Notable correlations were only observed with GPT-3.5 acrosstwo factuality subcategories. These consistent findings across various factualerror categories suggest a fundamental limitation in the current LLMs'capability to accurately gauge factuality. This version presents the information more concisely while maintaining themain points and findings of the original text.</description><author>Xue-Yong Fu, Md Tahmid Rahman Laskar, Cheng Chen, Shashi Bhushan TN</author><pubDate>Wed, 01 Nov 2023 18:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00681v1</guid></item><item><title>Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints</title><link>http://arxiv.org/abs/2311.00678v1</link><description>We analyze the complexity of single-loop quadratic penalty and augmentedLagrangian algorithms for solving nonconvex optimization problems withfunctional equality constraints. We consider three cases, in all of which theobjective is stochastic and smooth, that is, an expectation over an unknowndistribution that is accessed by sampling. The nature of the equalityconstraints differs among the three cases: deterministic and linear in thefirst case, deterministic, smooth and nonlinear in the second case, andstochastic, smooth and nonlinear in the third case. Variance reductiontechniques are used to improve the complexity. To find a point that satisfies$\varepsilon$-approximate first-order conditions, we require$\widetilde{O}(\varepsilon^{-3})$ complexity in the first case,$\widetilde{O}(\varepsilon^{-4})$ in the second case, and$\widetilde{O}(\varepsilon^{-5})$ in the third case. For the first and thirdcases, they are the first algorithms of "single loop" type (that also use$O(1)$ samples at each iteration) that still achieve the best-known complexityguarantees.</description><author>Ahmet Alacaoglu, Stephen J. Wright</author><pubDate>Wed, 01 Nov 2023 18:37:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00678v1</guid></item><item><title>Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games</title><link>http://arxiv.org/abs/2311.00676v1</link><description>Algorithms based on regret matching, specifically regret matching$^+$(RM$^+$), and its variants are the most popular approaches for solvinglarge-scale two-player zero-sum games in practice. Unlike algorithms such asoptimistic gradient descent ascent, which have strong last-iterate and ergodicconvergence properties for zero-sum games, virtually nothing is known about thelast-iterate properties of regret-matching algorithms. Given the importance oflast-iterate convergence for numerical optimization reasons and relevance asmodeling real-word learning in games, in this paper, we study the last-iterateconvergence properties of various popular variants of RM$^+$. First, we shownumerically that several practical variants such as simultaneous RM$^+$,alternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterateconvergence guarantees even on a simple $3\times 3$ game. We then prove thatrecent variants of these algorithms based on a smoothing technique do enjoylast-iterate convergence: we prove that extragradient RM$^{+}$ and smoothPredictive RM$^+$ enjoy asymptotic last-iterate convergence (without a rate)and $1/\sqrt{t}$ best-iterate convergence. Finally, we introduce restartedvariants of these algorithms, and show that they enjoy linear-rate last-iterateconvergence.</description><author>Yang Cai, Gabriele Farina, Julien Grand-Clément, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Weiqiang Zheng</author><pubDate>Wed, 01 Nov 2023 18:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00676v1</guid></item><item><title>Active Uncertainty Reduction for Safe and Efficient Interaction Planning: A Shielding-Aware Dual Control Approach</title><link>http://arxiv.org/abs/2302.00171v2</link><description>The ability to accurately predict others' behavior is central to the safetyand efficiency of interactive robotics. Unfortunately, robots often lack accessto key information on which these predictions may hinge, such as other agents'goals, attention, and willingness to cooperate. Dual control theory addressesthis challenge by treating unknown parameters of a predictive model asstochastic hidden states and inferring their values at runtime usinginformation gathered during system operation. While able to optimally andautomatically trade off exploration and exploitation, dual control iscomputationally intractable for general interactive motion planning. In thispaper, we present a novel algorithmic approach to enable active uncertaintyreduction for interactive motion planning based on the implicit dual controlparadigm. Our approach relies on sampling-based approximation of stochasticdynamic programming, leading to a model predictive control problem that can bereadily solved by real-time gradient-based optimization methods. The resultingpolicy is shown to preserve the dual control effect for a broad class ofpredictive models with both continuous and categorical uncertainty. To ensurethe safe operation of the interacting agents, we use a runtime safety filter(also referred to as a "shielding" scheme), which overrides the robot's dualcontrol policy with a safety fallback strategy when a safety-critical event isimminent. We then augment the dual control framework with an improved variantof the recently proposed shielding-aware robust planning scheme, whichproactively balances the nominal planning performance with the risk ofhigh-cost emergency maneuvers triggered by low-probability agent behaviors. Wedemonstrate the efficacy of our approach with both simulated driving studiesand hardware experiments using 1/10 scale autonomous vehicles.</description><author>Haimin Hu, David Isele, Sangjae Bae, Jaime F. Fisac</author><pubDate>Wed, 01 Nov 2023 18:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00171v2</guid></item><item><title>FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language</title><link>http://arxiv.org/abs/2310.17306v3</link><description>Formatting is an important property in tables for visualization,presentation, and analysis. Spreadsheet software allows users to automaticallyformat their tables by writing data-dependent conditional formatting (CF)rules. Writing such rules is often challenging for users as it requires them tounderstand and implement the underlying logic. We present FormaT5, atransformer-based model that can generate a CF rule given the target table anda natural language description of the desired formatting logic. We find thatuser descriptions for these tasks are often under-specified or ambiguous,making it harder for code generation systems to accurately learn the desiredrule in a single step. To tackle this problem of under-specification andminimise argument errors, FormaT5 learns to predict placeholders though anabstention objective. These placeholders can then be filled by a second modelor, when examples of rows that should be formatted are available, by aprogramming-by-example system. To evaluate FormaT5 on diverse and realscenarios, we create an extensive benchmark of 1053 CF tasks, containingreal-world descriptions collected from four different sources. We release ourbenchmarks to encourage research in this area. Abstention and filling allowFormaT5 to outperform 8 different neural approaches on our benchmarks, bothwith and without examples. Our results illustrate the value of buildingdomain-specific learning systems.</description><author>Mukul Singh, José Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, Elnaz Nouri, Mohammad Raza, Gust Verbruggen</author><pubDate>Wed, 01 Nov 2023 18:31:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17306v3</guid></item><item><title>CodeFusion: A Pre-trained Diffusion Model for Code Generation</title><link>http://arxiv.org/abs/2310.17680v3</link><description>Imagine a developer who can only change their last line of code, how oftenwould they have to start writing a function from scratch before it is correct?Auto-regressive models for code generation from natural language have a similarlimitation: they do not easily allow reconsidering earlier tokens generated. Weintroduce CodeFusion, a pre-trained diffusion code generation model thataddresses this limitation by iteratively denoising a complete programconditioned on the encoded natural language. We evaluate CodeFusion on the taskof natural language to code generation for Bash, Python, and Microsoft Excelconditional formatting (CF) rules. Experiments show that CodeFusion (75Mparameters) performs on par with state-of-the-art auto-regressive systems(350M-175B parameters) in top-1 accuracy and outperforms them in top-3 andtop-5 accuracy due to its better balance in diversity versus quality.</description><author>Mukul Singh, José Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, Gust Verbruggen</author><pubDate>Wed, 01 Nov 2023 18:30:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17680v3</guid></item><item><title>YaRN: Efficient Context Window Extension of Large Language Models</title><link>http://arxiv.org/abs/2309.00071v2</link><description>Rotary Position Embeddings (RoPE) have been shown to effectively encodepositional information in transformer-based language models. However, thesemodels fail to generalize past the sequence length they were trained on. Wepresent YaRN (Yet another RoPE extensioN method), a compute-efficient method toextend the context window of such models, requiring 10x less tokens and 2.5xless training steps than previous methods. Using YaRN, we show that LLaMAmodels can effectively utilize and extrapolate to context lengths much longerthan their original pre-training would allow, while also surpassing previousthe state-of-the-art at context window extension. In addition, we demonstratethat YaRN exhibits the capability to extrapolate beyond the limited context ofa fine-tuning dataset. The models fine-tuned using YaRN has been made availableand reproduced online up to 128k context length athttps://github.com/jquesnelle/yarn</description><author>Bowen Peng, Jeffrey Quesnelle, Honglu Fan, Enrico Shippole</author><pubDate>Wed, 01 Nov 2023 18:28:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00071v2</guid></item><item><title>Recovering Linear Causal Models with Latent Variables via Cholesky Factorization of Covariance Matrix</title><link>http://arxiv.org/abs/2311.00674v1</link><description>Discovering the causal relationship via recovering the directed acyclic graph(DAG) structure from the observed data is a well-known challengingcombinatorial problem. When there are latent variables, the problem becomeseven more difficult. In this paper, we first propose a DAG structure recoveringalgorithm, which is based on the Cholesky factorization of the covariancematrix of the observed data. The algorithm is fast and easy to implement andhas theoretical grantees for exact recovery. On synthetic and real-worlddatasets, the algorithm is significantly faster than previous methods andachieves the state-of-the-art performance. Furthermore, under the equal errorvariances assumption, we incorporate an optimization procedure into theCholesky factorization based algorithm to handle the DAG recovering problemwith latent variables. Numerical simulations show that the modified "Cholesky +optimization" algorithm is able to recover the ground truth graph in most casesand outperforms existing algorithms.</description><author>Yunfeng Cai, Xu Li, Minging Sun, Ping Li</author><pubDate>Wed, 01 Nov 2023 18:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00674v1</guid></item><item><title>A Convex Framework for Confounding Robust Inference</title><link>http://arxiv.org/abs/2309.12450v2</link><description>We study policy evaluation of offline contextual bandits subject tounobserved confounders. Sensitivity analysis methods are commonly used toestimate the policy value under the worst-case confounding over a givenuncertainty set. However, existing work often resorts to some coarse relaxationof the uncertainty set for the sake of tractability, leading to overlyconservative estimation of the policy value. In this paper, we propose ageneral estimator that provides a sharp lower bound of the policy value usingconvex programming. The generality of our estimator enables various extensionssuch as sensitivity analysis with f-divergence, model selection with crossvalidation and information criterion, and robust policy learning with the sharplower bound. Furthermore, our estimation method can be reformulated as anempirical risk minimization problem thanks to the strong duality, which enablesus to provide strong theoretical guarantees of the proposed estimator usingtechniques of the M-estimation.</description><author>Kei Ishikawa, Niao He, Takafumi Kanamori</author><pubDate>Wed, 01 Nov 2023 18:25:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12450v2</guid></item><item><title>CoinRun: Solving Goal Misgeneralisation</title><link>http://arxiv.org/abs/2309.16166v3</link><description>Goal misgeneralisation is a key challenge in AI alignment -- the task ofgetting powerful Artificial Intelligences to align their goals with humanintentions and human morality. In this paper, we show how the ACE (Algorithmfor Concept Extrapolation) agent can solve one of the key standard challengesin goal misgeneralisation: the CoinRun challenge. It uses no new rewardinformation in the new environment. This points to how autonomous agents couldbe trusted to act in human interests, even in novel and critical situations.</description><author>Stuart Armstrong, Alexandre Maranhão, Oliver Daniels-Koch, Patrick Leask, Rebecca Gorman</author><pubDate>Wed, 01 Nov 2023 18:23:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16166v3</guid></item><item><title>Emotion Detection for Misinformation: A Review</title><link>http://arxiv.org/abs/2311.00671v1</link><description>With the advent of social media, an increasing number of netizens are sharingand reading posts and news online. However, the huge volumes of misinformation(e.g., fake news and rumors) that flood the internet can adversely affectpeople's lives, and have resulted in the emergence of rumor and fake newsdetection as a hot research topic. The emotions and sentiments of netizens, asexpressed in social media posts and news, constitute important factors that canhelp to distinguish fake news from genuine news and to understand the spread ofrumors. This article comprehensively reviews emotion-based methods formisinformation detection. We begin by explaining the strong links betweenemotions and misinformation. We subsequently provide a detailed analysis of arange of misinformation detection methods that employ a variety of emotion,sentiment and stance-based features, and describe their strengths andweaknesses. Finally, we discuss a number of ongoing challenges in emotion-basedmisinformation detection based on large language models and suggest futureresearch directions, including data collection (multi-platform, multilingual),annotation, benchmark, multimodality, and interpretability.</description><author>Zhiwei Liu, Tianlin Zhang, Kailai Yang, Paul Thompson, Zeping Yu, Sophia Ananiadou</author><pubDate>Wed, 01 Nov 2023 18:21:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00671v1</guid></item><item><title>Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models</title><link>http://arxiv.org/abs/2305.14585v4</link><description>A recent trend in explainable AI research has focused on surrogate modeling,where neural networks are approximated as simpler ML algorithms such as kernelmachines. A second trend has been to utilize kernel functions in variousexplain-by-example or data attribution tasks to investigate a diverse set ofneural network behavior. In this work, we combine these two trends to analyzeapproximate empirical neural tangent kernels (eNTK) for data attribution.Approximation is critical for eNTK analysis due to the high computational costto compute the eNTK. We define new approximate eNTK and perform novel analysison how well the resulting kernel machine surrogate models correlate with theunderlying neural network. We introduce two new random projection variants ofapproximate eNTK which allow users to tune the time and memory complexity oftheir calculation. We conclude that kernel machines using approximate neuraltangent kernel as the kernel function are effective surrogate models, with theintroduced trace NTK the most consistent performer.</description><author>Andrew Engel, Zhichao Wang, Natalie S. Frank, Ioana Dumitriu, Sutanay Choudhury, Anand Sarwate, Tony Chiang</author><pubDate>Wed, 01 Nov 2023 18:18:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14585v4</guid></item><item><title>ProcSim: Proxy-based Confidence for Robust Similarity Learning</title><link>http://arxiv.org/abs/2311.00668v1</link><description>Deep Metric Learning (DML) methods aim at learning an embedding space inwhich distances are closely related to the inherent semantic similarity of theinputs. Previous studies have shown that popular benchmark datasets oftencontain numerous wrong labels, and DML methods are susceptible to them.Intending to study the effect of realistic noise, we create an ontology of theclasses in a dataset and use it to simulate semantically coherent labelingmistakes. To train robust DML models, we propose ProcSim, a simple frameworkthat assigns a confidence score to each sample using the normalized distance toits class representative. The experimental results show that the proposedmethod achieves state-of-the-art performance on the DML benchmark datasetsinjected with uniform and the proposed semantically coherent noise.</description><author>Oriol Barbany, Xiaofan Lin, Muhammet Bastan, Arnab Dhua</author><pubDate>Wed, 01 Nov 2023 18:17:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00668v1</guid></item><item><title>Latent Space Translation via Semantic Alignment</title><link>http://arxiv.org/abs/2311.00664v1</link><description>While different neural models often exhibit latent spaces that are alike whenexposed to semantically related data, this intrinsic similarity is not alwaysimmediately discernible. Towards a better understanding of this phenomenon, ourwork shows how representations learned from these neural modules can betranslated between different pre-trained networks via simpler transformationsthan previously thought. An advantage of this approach is the ability toestimate these transformations using standard, well-understood algebraicprocedures that have closed-form solutions. Our method directly estimates atransformation between two given latent spaces, thereby enabling effectivestitching of encoders and decoders without additional training. We extensivelyvalidate the adaptability of this translation procedure in differentexperimental settings: across various trainings, domains, architectures (e.g.,ResNet, CNN, ViT), and in multiple downstream tasks (classification,reconstruction). Notably, we show how it is possible to zero-shot stitch textencoders and vision decoders, or vice-versa, yielding surprisingly goodclassification performance in this multimodal setting.</description><author>Valentino Maiorca, Luca Moschella, Antonio Norelli, Marco Fumero, Francesco Locatello, Emanuele Rodolà</author><pubDate>Wed, 01 Nov 2023 18:12:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00664v1</guid></item><item><title>Variational Gaussian Processes For Linear Inverse Problems</title><link>http://arxiv.org/abs/2311.00663v1</link><description>By now Bayesian methods are routinely used in practice for solving inverseproblems. In inverse problems the parameter or signal of interest is observedonly indirectly, as an image of a given map, and the observations are typicallyfurther corrupted with noise. Bayes offers a natural way to regularize theseproblems via the prior distribution and provides a probabilistic solution,quantifying the remaining uncertainty in the problem. However, thecomputational costs of standard, sampling based Bayesian approaches can beoverly large in such complex models. Therefore, in practice variational Bayesis becoming increasingly popular. Nevertheless, the theoretical understandingof these methods is still relatively limited, especially in context of inverseproblems. In our analysis we investigate variational Bayesian methods forGaussian process priors to solve linear inverse problems. We consider bothmildly and severely ill-posed inverse problems and work with the popularinducing variables variational Bayes approach proposed by Titsias in 2009. Wederive posterior contraction rates for the variational posterior in generalsettings and show that the minimax estimation rate can be attained by correctlytunned procedures. As specific examples we consider a collection of inverseproblems including the heat equation, Volterra operator and Radon transform andinducing variable methods based on population and empirical spectral features.</description><author>Thibault Randrianarisoa, Botond Szabo</author><pubDate>Wed, 01 Nov 2023 18:10:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00663v1</guid></item><item><title>TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain</title><link>http://arxiv.org/abs/2311.00660v1</link><description>Rain generation algorithms have the potential to improve the generalizationof deraining methods and scene understanding in rainy conditions. However, inpractice, they produce artifacts and distortions and struggle to control theamount of rain generated due to a lack of proper constraints. In this paper, wepropose an unpaired image-to-image translation framework for generatingrealistic rainy images. We first introduce a Triangular Probability Similarity(TPS) constraint to guide the generated images toward clear and rainy images inthe discriminator manifold, thereby minimizing artifacts and distortions duringrain generation. Unlike conventional contrastive learning approaches, whichindiscriminately push negative samples away from the anchors, we propose aSemantic Noise Contrastive Estimation (SeNCE) strategy and reassess the pushingforce of negative samples based on the semantic similarity between the clearand the rainy images and the feature similarity between the anchor and thenegative samples. Experiments demonstrate realistic rain generation withminimal artifacts and distortions, which benefits image deraining and objectdetection in rain. Furthermore, the method can be used to generate realisticsnowy and night images, underscoring its potential for broader applicability.Code is available at https://github.com/ShenZheng2000/TPSeNCE.</description><author>Shen Zheng, Changjie Lu, Srinivasa G. Narasimhan</author><pubDate>Wed, 01 Nov 2023 18:08:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00660v1</guid></item><item><title>Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew</title><link>http://arxiv.org/abs/2311.00658v1</link><description>Pre-trained language models (PLMs) have shown remarkable successes inacquiring a wide range of linguistic knowledge, relying solely onself-supervised training on text streams. Nevertheless, the effectiveness ofthis language-agnostic approach has been frequently questioned for itssub-optimal performance when applied to morphologically-rich languages (MRLs).We investigate the hypothesis that incorporating explicit morphologicalknowledge in the pre-training phase can improve the performance of PLMs forMRLs. We propose various morphologically driven tokenization methods enablingthe model to leverage morphological cues beyond raw text. We pre-train multiplelanguage models utilizing the different methods and evaluate them on Hebrew, alanguage with complex and highly ambiguous morphology. Our experiments showthat morphologically driven tokenization demonstrates improved results comparedto a standard language-agnostic tokenization, on a benchmark of both semanticand morphologic tasks. These findings suggest that incorporating morphologicalknowledge holds the potential for further improving PLMs for morphologicallyrich languages.</description><author>Eylon Gueta, Omer Goldman, Reut Tsarfaty</author><pubDate>Wed, 01 Nov 2023 18:02:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00658v1</guid></item><item><title>Online Signal Estimation on the Graph Edges via Line Graph Transformation</title><link>http://arxiv.org/abs/2311.00656v1</link><description>We propose the Line Graph Normalized Least Mean Square (LGNLMS) algorithm foronline time-varying graph edge signals prediction. LGNLMS utilizes the LineGraph to transform graph edge signals into the node of its edge-to-vertex dual.This enables edge signals to be processed using established GSP conceptswithout redefining them on graph edges.</description><author>Yi Yan, Ercan Engin Kuruoglu</author><pubDate>Wed, 01 Nov 2023 18:02:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00656v1</guid></item><item><title>Intelligent Debris Mass Estimation Model for Autonomous Underwater Vehicle</title><link>http://arxiv.org/abs/2309.10617v3</link><description>Marine debris poses a significant threat to the survival of marine wildlife,often leading to entanglement and starvation, ultimately resulting in death.Therefore, removing debris from the ocean is crucial to restore the naturalbalance and allow marine life to thrive. Instance segmentation is an advancedform of object detection that identifies objects and precisely locates andseparates them, making it an essential tool for autonomous underwater vehicles(AUVs) to navigate and interact with their underwater environment effectively.AUVs use image segmentation to analyze images captured by their cameras tonavigate underwater environments. In this paper, we use instance segmentationto calculate the area of individual objects within an image, we use YOLOV7 inRoboflow to generate a set of bounding boxes for each object in the image witha class label and a confidence score for every detection. A segmentation maskis then created for each object by applying a binary mask to the object'sbounding box. The masks are generated by applying a binary threshold to theoutput of a convolutional neural network trained to segment objects from thebackground. Finally, refining the segmentation mask for each object is done byapplying post-processing techniques such as morphological operations andcontour detection, to improve the accuracy and quality of the mask. The processof estimating the area of instance segmentation involves calculating the areaof each segmented instance separately and then summing up the areas of allinstances to obtain the total area. The calculation is carried out usingstandard formulas based on the shape of the object, such as rectangles andcircles. In cases where the object is complex, the Monte Carlo method is usedto estimate the area. This method provides a higher degree of accuracy thantraditional methods, especially when using a large number of samples.</description><author>Mohana Sri S, Swethaa S, Aouthithiye Barathwaj SR Y, Sai Ganesh CS</author><pubDate>Wed, 01 Nov 2023 18:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10617v3</guid></item><item><title>Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning</title><link>http://arxiv.org/abs/2311.00651v1</link><description>Recent works have proven that intricate cooperative behaviors can emerge inagents trained using meta reinforcement learning on open ended taskdistributions using self-play. While the results are impressive, we argue thatself-play and other centralized training techniques do not accurately reflecthow general collective exploration strategies emerge in the natural world:through decentralized training and over an open-ended distribution of tasks. Inthis work we therefore investigate the emergence of collective explorationstrategies, where several agents meta-learn independent recurrent policies onan open ended distribution of tasks. To this end we introduce a novelenvironment with an open ended procedurally generated task space whichdynamically combines multiple subtasks sampled from five diverse task types toform a vast distribution of task trees. We show that decentralized agentstrained in our environment exhibit strong generalization abilities whenconfronted with novel objects at test time. Additionally, despite never beingforced to cooperate during training the agents learn collective explorationstrategies which allow them to solve novel tasks never encountered duringtraining. We further find that the agents learned collective explorationstrategies extend to an open ended task setting, allowing them to solve tasktrees of twice the depth compared to the ones seen during training. Our opensource code as well as videos of the agents can be found on our companionwebsite.</description><author>Richard Bornemann, Gautier Hamon, Eleni Nisioti, Clément Moulin-Frier</author><pubDate>Wed, 01 Nov 2023 17:56:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00651v1</guid></item><item><title>Roots and Requirements for Collaborative AIs</title><link>http://arxiv.org/abs/2303.12040v3</link><description>The vision of AI collaborators has long been a staple of stories and sciencefiction, where artificial agents understand nuances of collaboration and humancommunication. They assist their human partners and teams and have specialtalents. Government advisory groups and leaders in AI have advocated for yearsthat AIs should be human compatible and effective collaborators. Nonetheless,robust AIs that collaborate like talented people remain out of reach. Thesimpler dream of effective information tools that augment human intelligence(IA) has its roots in the 1960s and arguably helped drive an informationtechnology revolution. With the vast increase in hybrid and remote work sincethe COVID pandemic, the benefits and requirements for better coordination,collaboration, and communication are in focus for the workplace. Many factors(such as the costs of homes near work) are impeding a return to in-person workat the office. If we need better tools, how artificially intelligent (AI)should our tools be? This position paper reviews the arc of technology andcalls for human-machine teaming. It draws on psychology and social sciences foran analysis of what effective and robust collaboration requires. It is thecontext for a second paper (Stefik &amp; Price, 2023) that argues that currentmainstream AI cannot produce robust, intelligent, and human-compatiblecollaborators. Rather, a radical shift in technology and methodology isrequired.</description><author>Mark Stefik</author><pubDate>Wed, 01 Nov 2023 17:53:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12040v3</guid></item><item><title>FAIRLABEL: Correcting Bias in Labels</title><link>http://arxiv.org/abs/2311.00638v1</link><description>There are several algorithms for measuring fairness of ML models. Afundamental assumption in these approaches is that the ground truth is fair orunbiased. In real-world datasets, however, the ground truth often contains datathat is a result of historical and societal biases and discrimination. Modelstrained on these datasets will inherit and propagate the biases to the modeloutputs. We propose FAIRLABEL, an algorithm which detects and corrects biasesin labels. The goal of FAIRLABELis to reduce the Disparate Impact (DI) acrossgroups while maintaining high accuracy in predictions. We propose metrics tomeasure the quality of bias correction and validate FAIRLABEL on syntheticdatasets and show that the label correction is correct 86.7% of the time vs.71.9% for a baseline model. We also apply FAIRLABEL on benchmark datasets suchas UCI Adult, German Credit Risk, and Compas datasets and show that theDisparate Impact Ratio increases by as much as 54.2%.</description><author>Srinivasan H Sengamedu, Hien Pham</author><pubDate>Wed, 01 Nov 2023 17:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00638v1</guid></item><item><title>Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures</title><link>http://arxiv.org/abs/2311.00636v1</link><description>The core components of many modern neural network architectures, such astransformers, convolutional, or graph neural networks, can be expressed aslinear layers with $\textit{weight-sharing}$. Kronecker-Factored ApproximateCurvature (K-FAC), a second-order optimisation method, has shown promise tospeed up neural network training and thereby reduce computational costs.However, there is currently no framework to apply it to generic architectures,specifically ones with linear weight-sharing layers. In this work, we identifytwo different settings of linear weight-sharing layers which motivate twoflavours of K-FAC -- $\textit{expand}$ and $\textit{reduce}$. We show that theyare exact for deep linear networks with weight-sharing in their respectivesetting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which weleverage to speed up automatic hyperparameter selection via optimising themarginal likelihood for a Wide ResNet. Finally, we observe little differencebetween these two K-FAC variations when using them to train both a graph neuralnetwork and a vision transformer. However, both variations are able to reach afixed validation metric target in $50$-$75\%$ of the number of steps of afirst-order reference run, which translates into a comparable improvement inwall-clock time. This highlights the potential of applying K-FAC to modernneural network architectures.</description><author>Runa Eschenhagen, Alexander Immer, Richard E. Turner, Frank Schneider, Philipp Hennig</author><pubDate>Wed, 01 Nov 2023 17:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00636v1</guid></item><item><title>A Bi-level Framework for Traffic Accident Duration Prediction: Leveraging Weather and Road Condition Data within a Practical Optimum Pipeline</title><link>http://arxiv.org/abs/2311.00634v1</link><description>Due to the stochastic nature of events, predicting the duration of a trafficincident presents a formidable challenge. Accurate duration estimation canresult in substantial advantages for commuters in selecting optimal routes andfor traffic management personnel in addressing non-recurring congestion issues.In this study, we gathered accident duration, road conditions, andmeteorological data from a database of traffic accidents to check thefeasibility of a traffic accident duration pipeline without accident contextualinformation data like accident severity and textual description. Multiplemachine learning models were employed to predict whether an accident's impacton road traffic would be of a short-term or long-term nature, and thenutilizing a bimodal approach the precise duration of the incident's effect wasdetermined. Our binary classification random forest model distinguished betweenshort-term and long-term effects with an 83% accuracy rate, while the LightGBMregression model outperformed other machine learning regression models withMean Average Error (MAE) values of 26.15 and 13.3 and RMSE values of 32.91 and28.91 for short and long-term accident duration prediction, respectively. Usingthe optimal classification and regression model identified in the precedingsection, we then construct an end-to-end pipeline to incorporate the entireprocess. The results of both separate and combined approaches were comparablewith previous works, which shows the applicability of only using staticfeatures for predicting traffic accident duration. The SHAP value analysisidentified weather conditions, wind chill and wind speed as the mostinfluential factors in determining the duration of an accident.</description><author>Rafat Tabassum Sukonna, Soham Irtiza Swapnil</author><pubDate>Wed, 01 Nov 2023 17:33:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00634v1</guid></item><item><title>Degree Heterogeneity in Higher-Order Networks: Inference in the Hypergraph $\boldsymbolβ$-Model</title><link>http://arxiv.org/abs/2307.02818v3</link><description>The $\boldsymbol{\beta}$-model for random graphs is commonly used forrepresenting pairwise interactions in a network with degree heterogeneity.Going beyond pairwise interactions, Stasi et al. (2014) introduced thehypergraph $\boldsymbol{\beta}$-model for capturing degree heterogeneity innetworks with higher-order (multi-way) interactions. In this paper we initiatethe rigorous study of the hypergraph $\boldsymbol{\beta}$-model with multiplelayers, which allows for hyperedges of different sizes across the layers. Tobegin with, we derive the rates of convergence of the maximum likelihood (ML)estimate and establish their minimax rate optimality. We also derive thelimiting distribution of the ML estimate and construct asymptotically validconfidence intervals for the model parameters. Next, we consider thegoodness-of-fit problem in the hypergraph $\boldsymbol{\beta}$-model.Specifically, we establish the asymptotic normality of the likelihood ratio(LR) test under the null hypothesis, derive its detection threshold, and alsoits limiting power at the threshold. Interestingly, the detection threshold ofthe LR test turns out to be minimax optimal, that is, all tests areasymptotically powerless below this threshold. The theoretical results arefurther validated in numerical experiments. In addition to developing thetheoretical framework for estimation and inference for hypergraph$\boldsymbol{\beta}$-models, the above results fill a number of gaps in thegraph $\boldsymbol{\beta}$-model literature, such as the minimax optimality ofthe ML estimates and the non-null properties of the LR test, which, to the bestof our knowledge, have not been studied before.</description><author>Sagnik Nandy, Bhaswar B. Bhattacharya</author><pubDate>Wed, 01 Nov 2023 17:33:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02818v3</guid></item><item><title>Formal Translation from Reversing Petri Nets to Coloured Petri Nets</title><link>http://arxiv.org/abs/2311.00629v1</link><description>Reversible computation is an emerging computing paradigm that allows anysequence of operations to be executed in reverse order at any point duringcomputation. Its appeal lies in its potential for lowpower computation and itsrelevance to a wide array of applications such as chemical reactions, quantumcomputation, robotics, and distributed systems. Reversing Petri nets are arecently-proposed extension of Petri nets that implements the three main formsof reversibility, namely, backtracking, causal reversing, andout-of-causal-order reversing. Their distinguishing feature is the use of namedtokens that can be combined together to form bonds. Named tokens along with ahistory function, constitute the means of remembering past behaviour, thus,enabling reversal. In recent work, we have proposed a structural translationfrom a subclass of RPNs to the model of Coloured Petri Nets (CPNs), anextension of traditional Petri nets where tokens carry data values. In thispaper, we extend the translation to handle RPNs with token multiplicity underthe individual-token interpretation, a model which allows multiple tokens ofthe same type to exist in a system. To support the three types ofreversibility, tokens are associated with their causal history and, whiletokens of the same type are equally eligible to fire a transition when goingforward, when going backwards they are able to reverse only the transitionsthey have previously fired. The new translation, in addition to lifting therestriction on token uniqueness, presents a refined approach for transformingRPNs to CPNs through a unifying approach that allows instantiating each of thethree types of reversibility. The paper also reports on a tool that implementsthis translation, paving the way for automated translations and analysis ofreversible systems using CPN Tools.</description><author>Kamila Barylska, Anna Gogolinska, Lukasz Mikulski, Anna Philippou, Marcin Piatkowski, Kyriaki Psara</author><pubDate>Wed, 01 Nov 2023 17:28:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00629v1</guid></item><item><title>Conceptual Framework for Autonomous Cognitive Entities</title><link>http://arxiv.org/abs/2310.06775v2</link><description>The rapid development and adoption of Generative AI (GAI) technology in theform of chatbots such as ChatGPT and Claude has greatly increased interest inagentic machines. This paper introduces the Autonomous Cognitive Entity (ACE)model, a novel framework for a cognitive architecture, enabling machines andsoftware agents to operate more independently. Drawing inspiration from the OSImodel, the ACE framework presents layers of abstraction to conceptualizeartificial cognitive architectures. The model is designed to harness thecapabilities of the latest generative AI technologies, including large languagemodels (LLMs) and multimodal generative models (MMMs), to build autonomous,agentic systems. The ACE framework comprises six layers: the AspirationalLayer, Global Strategy, Agent Model, Executive Function, Cognitive Control, andTask Prosecution. Each layer plays a distinct role, ranging from setting themoral compass and strategic thinking to task selection and execution. The ACEframework also incorporates mechanisms for handling failures and adaptingactions, thereby enhancing the robustness and flexibility of autonomous agents.This paper introduces the conceptual framework and proposes implementationstrategies that have been tested and observed in industry. The goal of thispaper is to formalize this framework so as to be more accessible.</description><author>David Shapiro, Wangfan Li, Manuel Delaflor, Carlos Toxtli</author><pubDate>Wed, 01 Nov 2023 17:28:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06775v2</guid></item><item><title>Disentangling Voice and Content with Self-Supervision for Speaker Recognition</title><link>http://arxiv.org/abs/2310.01128v3</link><description>For speaker recognition, it is difficult to extract an accurate speakerrepresentation from speech because of its mixture of speaker traits andcontent. This paper proposes a disentanglement framework that simultaneouslymodels speaker traits and content variability in speech. It is realized withthe use of three Gaussian inference layers, each consisting of a learnabletransition model that extracts distinct speech components. Notably, astrengthened transition model is specifically designed to model complex speechdynamics. We also propose a self-supervision method to dynamically disentanglecontent without the use of labels other than speaker identities. The efficacyof the proposed framework is validated via experiments conducted on theVoxCeleb and SITW datasets with 9.56% and 8.24% average reductions in EER andminDCF, respectively. Since neither additional model training nor data isspecifically needed, it is easily applicable in practical use.</description><author>Tianchi Liu, Kong Aik Lee, Qiongqiong Wang, Haizhou Li</author><pubDate>Wed, 01 Nov 2023 17:27:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01128v3</guid></item><item><title>Discovering Structure From Corruption for Unsupervised Image Reconstruction</title><link>http://arxiv.org/abs/2304.05589v2</link><description>We consider solving ill-posed imaging inverse problems without access to animage prior or ground-truth examples. An overarching challenge in these inverseproblems is that an infinite number of images, including many that areimplausible, are consistent with the observed measurements. Thus, image priorsare required to reduce the space of possible solutions to more desirablereconstructions. However, in many applications it is difficult or potentiallyimpossible to obtain example images to construct an image prior. Henceinaccurate priors are often used, which inevitably result in biased solutions.Rather than solving an inverse problem using priors that encode the spatialstructure of any one image, we propose to solve a set of inverse problemsjointly by incorporating prior constraints on the collective structure of theunderlying images. The key assumption of our work is that the underlying imageswe aim to reconstruct share common, low-dimensional structure. We show thatsuch a set of inverse problems can be solved simultaneously without the use ofa spatial image prior by instead inferring a shared image generator with alow-dimensional latent space. The parameters of the generator and latentembeddings are found by maximizing a proxy for the Evidence Lower Bound (ELBO).Once identified, the generator and latent embeddings can be combined to providereconstructed images for each inverse problem. The framework we propose canhandle general forward model corruptions, and we show that measurements derivedfrom only a small number of ground-truth images ($\leqslant 150$) aresufficient for image reconstruction. We demonstrate our approach on a varietyof convex and non-convex inverse problems, including denoising, phaseretrieval, and black hole video reconstruction.</description><author>Oscar Leong, Angela F. Gao, He Sun, Katherine L. Bouman</author><pubDate>Wed, 01 Nov 2023 17:24:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05589v2</guid></item><item><title>Initial Guessing Bias: How Untrained Networks Favor Some Classes</title><link>http://arxiv.org/abs/2306.00809v2</link><description>The initial state of neural networks plays a central role in conditioning thesubsequent training dynamics. In the context of classification problems, weprovide a theoretical analysis demonstrating that the structure of a neuralnetwork can condition the model to assign all predictions to the same class,even before the beginning of training, and in the absence of explicit biases.We show that the presence of this phenomenon, which we call "Initial GuessingBias" (IGB), depends on architectural choices such as activation functions,max-pooling layers, and network depth. Our analysis of IGB has practicalconsequences, in that it guides architecture selection and initialization. Wealso highlight theoretical consequences, such as the breakdown ofnode-permutation symmetry, the violation of self-averaging, the validity ofsome mean-field approximations, and the non-trivial differences arising withdepth.</description><author>Emanuele Francazi, Aurelien Lucchi, Marco Baity-Jesi</author><pubDate>Wed, 01 Nov 2023 17:17:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00809v2</guid></item><item><title>Meta-Learning Adversarial Bandit Algorithms</title><link>http://arxiv.org/abs/2307.02295v2</link><description>We study online meta-learning with bandit feedback, with the goal ofimproving performance across multiple tasks if they are similar according tosome natural similarity measure. As the first to target the adversarialonline-within-online partial-information setting, we design meta-algorithmsthat combine outer learners to simultaneously tune the initialization and otherhyperparameters of an inner learner for two important cases: multi-armedbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learnersinitialize and set hyperparameters of the Tsallis-entropy generalization ofExp3, with the task-averaged regret improving if the entropy of theoptima-in-hindsight is small. For BLO, we learn to initialize and tune onlinemirror descent (OMD) with self-concordant barrier regularizers, showing thattask-averaged regret varies directly with an action space-dependent measurethey induce. Our guarantees rely on proving that unregularizedfollow-the-leader combined with two levels of low-dimensional hyperparametertuning is enough to learn a sequence of affine functions of non-Lipschitz andsometimes non-convex Bregman divergences bounding the regret of OMD.</description><author>Mikhail Khodak, Ilya Osadchiy, Keegan Harris, Maria-Florina Balcan, Kfir Y. Levy, Ron Meir, Zhiwei Steven Wu</author><pubDate>Wed, 01 Nov 2023 17:15:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02295v2</guid></item><item><title>Loss Modeling for Multi-Annotator Datasets</title><link>http://arxiv.org/abs/2311.00619v1</link><description>Accounting for the opinions of all annotators of a dataset is critical forfairness. However, when annotating large datasets, individual annotators willfrequently provide thousands of ratings which can lead to fatigue.Additionally, these annotation processes can occur over multiple days which canlead to an inaccurate representation of an annotator's opinion over time. Tocombat this, we propose to learn a more accurate representation of diverseopinions by utilizing multitask learning in conjunction with loss-based labelcorrection. We show that using our novel formulation, we can cleanly separateagreeing and disagreeing annotations. Furthermore, we demonstrate that thismodification can improve prediction performance in a single or multi-annotatorsetting. Lastly, we show that this method remains robust to additional labelnoise that is applied to subjective data.</description><author>Uthman Jinadu, Jesse Annan, Shanshan Wen, Yi Ding</author><pubDate>Wed, 01 Nov 2023 17:14:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00619v1</guid></item><item><title>De-Diffusion Makes Text a Strong Cross-Modal Interface</title><link>http://arxiv.org/abs/2311.00618v1</link><description>We demonstrate text as a strong cross-modal interface. Rather than relying ondeep embeddings to connect image and language as the interface representation,our approach represents an image as text, from which we enjoy theinterpretability and flexibility inherent to natural language. We employ anautoencoder that uses a pre-trained text-to-image diffusion model for decoding.The encoder is trained to transform an input image into text, which is then fedinto the fixed text-to-image diffusion decoder to reconstruct the originalinput -- a process we term De-Diffusion. Experiments validate both theprecision and comprehensiveness of De-Diffusion text representing images, suchthat it can be readily ingested by off-the-shelf text-to-image tools and LLMsfor diverse multi-modal tasks. For example, a single De-Diffusion model cangeneralize to provide transferable prompts for different text-to-image tools,and also achieves a new state of the art on open-ended vision-language tasks bysimply prompting large language models with few-shot examples.</description><author>Chen Wei, Chenxi Liu, Siyuan Qiao, Zhishuai Zhang, Alan Yuille, Jiahui Yu</author><pubDate>Wed, 01 Nov 2023 17:12:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00618v1</guid></item><item><title>Making Batch Normalization Great in Federated Deep Learning</title><link>http://arxiv.org/abs/2303.06530v2</link><description>Batch Normalization (BN) is commonly used in modern deep learning to improvestability and speed up convergence in centralized training. In federatedlearning (FL) with non-IID decentralized data, previous works observed thattraining with BN could hinder performance due to the mismatch of the BNstatistics between training and testing. Group Normalization (GN) is thus moreoften used in FL as an alternative to BN. In this paper, we identify a morefundamental issue of BN in FL that makes BN inferior even with high-frequencycommunication between clients and servers. We then propose a frustratinglysimple treatment, which significantly improves BN and makes it outperform GNacross a wide range of FL settings. Along with this study, we also reveal anunreasonable behavior of BN in FL. We find it quite robust in the low-frequencycommunication regime where FL is commonly believed to degrade drastically. Wehope that our study could serve as a valuable reference for future practicalusage and theoretical analysis in FL.</description><author>Jike Zhong, Hong-You Chen, Wei-Lun Chao</author><pubDate>Wed, 01 Nov 2023 17:05:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06530v2</guid></item><item><title>NNQS-Transformer: an Efficient and Scalable Neural Network Quantum States Approach for Ab initio Quantum Chemistry</title><link>http://arxiv.org/abs/2306.16705v3</link><description>Neural network quantum state (NNQS) has emerged as a promising candidate forquantum many-body problems, but its practical applications are often hinderedby the high cost of sampling and local energy calculation. We develop ahigh-performance NNQS method for \textit{ab initio} electronic structurecalculations. The major innovations include: (1) A transformer basedarchitecture as the quantum wave function ansatz; (2) A data-centricparallelization scheme for the variational Monte Carlo (VMC) algorithm whichpreserves data locality and well adapts for different computing architectures;(3) A parallel batch sampling strategy which reduces the sampling cost andachieves good load balance; (4) A parallel local energy evaluation scheme whichis both memory and computationally efficient; (5) Study of real chemicalsystems demonstrates both the superior accuracy of our method compared tostate-of-the-art and the strong and weak scalability for large molecularsystems with up to $120$ spin orbitals.</description><author>Yangjun Wu, Chu Guo, Yi Fan, Pengyu Zhou, Honghui Shang</author><pubDate>Wed, 01 Nov 2023 17:01:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16705v3</guid></item><item><title>Controllable Music Production with Diffusion Models and Guidance Gradients</title><link>http://arxiv.org/abs/2311.00613v1</link><description>We demonstrate how conditional generation from diffusion models can be usedto tackle a variety of realistic tasks in the production of music in 44.1kHzstereo audio with sampling-time guidance. The scenarios we consider includecontinuation, inpainting and regeneration of musical audio, the creation ofsmooth transitions between two different music tracks, and the transfer ofdesired stylistic characteristics to existing audio clips. We achieve this byapplying guidance at sampling time in a simple framework that supports bothreconstruction and classification losses, or any combination of the two. Thisapproach ensures that generated audio can match its surrounding context, orconform to a class distribution or latent representation specified relative toany suitable pre-trained classifier or embedding model.</description><author>Mark Levy, Bruno Di Giorgi, Floris Weers, Angelos Katharopoulos, Tom Nickson</author><pubDate>Wed, 01 Nov 2023 17:01:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00613v1</guid></item><item><title>A Collaborative Filtering-Based Two Stage Model with Item Dependency for Course Recommendation</title><link>http://arxiv.org/abs/2311.00612v1</link><description>Recommender systems have been studied for decades with numerous promisingmodels been proposed. Among them, Collaborative Filtering (CF) models arearguably the most successful one due to its high accuracy in recommendation andelimination of privacy-concerned personal meta-data from training. This paperextends the usage of CF-based model to the task of course recommendation. Wepoint out several challenges in applying the existing CF-models to build acourse recommendation engine, including the lack of rating and meta-data, theimbalance of course registration distribution, and the demand of coursedependency modeling. We then propose several ideas to address these challenges.Eventually, we combine a two-stage CF model regularized by course dependencywith a graph-based recommender based on course-transition network, to achieveAUC as high as 0.97 with a real-world dataset.</description><author>Eric L. Lee, Tsung-Ting Kuo, Shou-De Lin</author><pubDate>Wed, 01 Nov 2023 17:01:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00612v1</guid></item><item><title>Occluded Person Re-Identification with Deep Learning: A Survey and Perspectives</title><link>http://arxiv.org/abs/2311.00603v1</link><description>Person re-identification (Re-ID) technology plays an increasingly crucialrole in intelligent surveillance systems. Widespread occlusion significantlyimpacts the performance of person Re-ID. Occluded person Re-ID refers to apedestrian matching method that deals with challenges such as pedestrianinformation loss, noise interference, and perspective misalignment. It hasgarnered extensive attention from researchers. Over the past few years, severalocclusion-solving person Re-ID methods have been proposed, tackling varioussub-problems arising from occlusion. However, there is a lack of comprehensivestudies that compare, summarize, and evaluate the potential of occluded personRe-ID methods in detail. In this review, we start by providing a detailedoverview of the datasets and evaluation scheme used for occluded person Re-ID.Next, we scientifically classify and analyze existing deep learning-basedoccluded person Re-ID methods from various perspectives, summarizing themconcisely. Furthermore, we conduct a systematic comparison among these methods,identify the state-of-the-art approaches, and present an outlook on the futuredevelopment of occluded person Re-ID.</description><author>Enhao Ning, Changshuo Wang, Huang Zhangc, Xin Ning, Prayag Tiwari</author><pubDate>Wed, 01 Nov 2023 16:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00603v1</guid></item><item><title>Structure Learning with Adaptive Random Neighborhood Informed MCMC</title><link>http://arxiv.org/abs/2311.00599v1</link><description>In this paper, we introduce a novel MCMC sampler, PARNI-DAG, for afully-Bayesian approach to the problem of structure learning underobservational data. Under the assumption of causal sufficiency, the algorithmallows for approximate sampling directly from the posterior distribution onDirected Acyclic Graphs (DAGs). PARNI-DAG performs efficient sampling of DAGsvia locally informed, adaptive random neighborhood proposal that results inbetter mixing properties. In addition, to ensure better scalability with thenumber of nodes, we couple PARNI-DAG with a pre-tuning procedure of thesampler's parameters that exploits a skeleton graph derived through someconstraint-based or scoring-based algorithms. Thanks to these novel features,PARNI-DAG quickly converges to high-probability regions and is less likely toget stuck in local modes in the presence of high correlation between nodes inhigh-dimensional settings. After introducing the technical novelties inPARNI-DAG, we empirically demonstrate its mixing efficiency and accuracy inlearning DAG structures on a variety of experiments.</description><author>Alberto Caron, Xitong Liang, Samuel Livingstone, Jim Griffin</author><pubDate>Wed, 01 Nov 2023 16:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00599v1</guid></item><item><title>Rethinking Variational Inference for Probabilistic Programs with Stochastic Support</title><link>http://arxiv.org/abs/2311.00594v1</link><description>We introduce Support Decomposition Variational Inference (SDVI), a newvariational inference (VI) approach for probabilistic programs with stochasticsupport. Existing approaches to this problem rely on designing a single globalvariational guide on a variable-by-variable basis, while maintaining thestochastic control flow of the original program. SDVI instead breaks theprogram down into sub-programs with static support, before automaticallybuilding separate sub-guides for each. This decomposition significantly aids inthe construction of suitable variational families, enabling, in turn,substantial improvements in inference performance.</description><author>Tim Reichelt, Luke Ong, Tom Rainforth</author><pubDate>Wed, 01 Nov 2023 16:38:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00594v1</guid></item><item><title>Coop: Memory is not a Commodity</title><link>http://arxiv.org/abs/2311.00591v1</link><description>Tensor rematerialization allows the training of deep neural networks (DNNs)under limited memory budgets by checkpointing the models and recomputing theevicted tensors as needed. However, the existing tensor rematerializationtechniques overlook the memory system in deep learning frameworks andimplicitly assume that free memory blocks at different addresses are identical.Under this flawed assumption, discontiguous tensors are evicted, among whichsome are not used to allocate the new tensor. This leads to severe memoryfragmentation and increases the cost of potential rematerializations. Toaddress this issue, we propose to evict tensors within a sliding window toensure all evictions are contiguous and are immediately used. Furthermore, weproposed cheap tensor partitioning and recomputable in-place to further reducethe rematerialization cost by optimizing the tensor allocation. We named ourmethod Coop as it is a co-optimization of tensor allocation and tensorrematerialization. We evaluated Coop on eight representative DNNs. Theexperimental results demonstrate that Coop achieves up to $2\times$ memorysaving and hugely reduces compute overhead, search latency, and memoryfragmentation compared to the state-of-the-art baselines.</description><author>Jianhao Zhang, Shihan Ma, Peihong Liu, Jinhui Yuan</author><pubDate>Wed, 01 Nov 2023 16:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00591v1</guid></item><item><title>Boosting Summarization with Normalizing Flows and Aggressive Training</title><link>http://arxiv.org/abs/2311.00588v1</link><description>This paper presents FlowSUM, a normalizing flows-based variationalencoder-decoder framework for Transformer-based summarization. Our approachtackles two primary challenges in variational summarization: insufficientsemantic information in latent representations and posterior collapse duringtraining. To address these challenges, we employ normalizing flows to enableflexible latent posterior modeling, and we propose a controlled alternateaggressive training (CAAT) strategy with an improved gate mechanism.Experimental results show that FlowSUM significantly enhances the quality ofgenerated summaries and unleashes the potential for knowledge distillation withminimal impact on inference time. Furthermore, we investigate the issue ofposterior collapse in normalizing flows and analyze how the summary quality isaffected by the training strategy, gate initialization, and the type and numberof normalizing flows used, offering valuable insights for future research.</description><author>Yu Yang, Xiaotong Shen</author><pubDate>Wed, 01 Nov 2023 16:33:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00588v1</guid></item><item><title>Crosslingual Retrieval Augmented In-context Learning for Bangla</title><link>http://arxiv.org/abs/2311.00587v1</link><description>The promise of Large Language Models (LLMs) in Natural Language Processinghas often been overshadowed by their limited performance in low-resourcelanguages such as Bangla. To address this, our paper presents a pioneeringapproach that utilizes cross-lingual retrieval augmented in-context learning.By strategically sourcing semantically similar prompts from high-resourcelanguage, we enable multilingual pretrained language models (MPLMs), especiallythe generative model BLOOMZ, to successfully boost performance on Bangla tasks.Our extensive evaluation highlights that the cross-lingual retrieval augmentedprompts bring steady improvements to MPLMs over the zero-shot performance.</description><author>Xiaoqian Li, Ercong Nie, Sheng Liang</author><pubDate>Wed, 01 Nov 2023 16:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00587v1</guid></item><item><title>PAUMER: Patch Pausing Transformer for Semantic Segmentation</title><link>http://arxiv.org/abs/2311.00586v1</link><description>We study the problem of improving the efficiency of segmentation transformersby using disparate amounts of computation for different parts of the image. Ourmethod, PAUMER, accomplishes this by pausing computation for patches that aredeemed to not need any more computation before the final decoder. We use theentropy of predictions computed from intermediate activations as the pausingcriterion, and find this aligns well with semantics of the image. Our methodhas a unique advantage that a single network trained with the proposed strategycan be effortlessly adapted at inference to various run-time requirements bymodulating its pausing parameters. On two standard segmentation datasets,Cityscapes and ADE20K, we show that our method operates with about a $50\%$higher throughput with an mIoU drop of about $0.65\%$ and $4.6\%$ respectively.</description><author>Evann Courdier, Prabhu Teja Sivaprasad, François Fleuret</author><pubDate>Wed, 01 Nov 2023 16:32:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00586v1</guid></item><item><title>3M-TRANSFORMER: A Multi-Stage Multi-Stream Multimodal Transformer for Embodied Turn-Taking Prediction</title><link>http://arxiv.org/abs/2310.14859v2</link><description>Predicting turn-taking in multiparty conversations has many practicalapplications in human-computer/robot interaction. However, the complexity ofhuman communication makes it a challenging task. Recent advances have shownthat synchronous multi-perspective egocentric data can significantly improveturn-taking prediction compared to asynchronous, single-perspectivetranscriptions. Building on this research, we propose a new multimodaltransformer-based architecture for predicting turn-taking in embodied,synchronized multi-perspective data. Our experimental results on the recentlyintroduced EgoCom dataset show a substantial performance improvement of up to14.01% on average compared to existing baselines and alternativetransformer-based approaches. The source code, and the pre-trained models ofour 3M-Transformer will be available upon acceptance.</description><author>Mehdi Fatan, Emanuele Mincato, Dimitra Pintzou, Mariella Dimiccoli</author><pubDate>Wed, 01 Nov 2023 16:31:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14859v2</guid></item><item><title>MOFO: MOtion FOcused Self-Supervision for Video Understanding</title><link>http://arxiv.org/abs/2308.12447v2</link><description>Self-supervised learning (SSL) techniques have recently produced outstandingresults in learning visual representations from unlabeled videos. Despite theimportance of motion in supervised learning techniques for action recognition,SSL methods often do not explicitly consider motion information in videos. Toaddress this issue, we propose MOFO (MOtion FOcused), a novel SSL method forfocusing representation learning on the motion area of a video, for actionrecognition. MOFO automatically detects motion areas in videos and uses theseto guide the self-supervision task. We use a masked autoencoder which randomlymasks out a high proportion of the input sequence; we force a specifiedpercentage of the inside of the motion area to be masked and the remainder fromoutside. We further incorporate motion information into the finetuning step toemphasise motion in the downstream task. We demonstrate that our motion-focusedinnovations can significantly boost the performance of the currently leadingSSL method (VideoMAE) for action recognition. Our method improves the recentself-supervised Vision Transformer (ViT), VideoMAE, by achieving +2.6%, +2.1%,+1.3% accuracy on Epic-Kitchens verb, noun and action classification,respectively, and +4.7% accuracy on Something-Something V2 actionclassification. Our proposed approach significantly improves the performance ofthe current SSL method for action recognition, indicating the importance ofexplicitly encoding motion in SSL.</description><author>Mona Ahmadian, Frank Guerin, Andrew Gilbert</author><pubDate>Wed, 01 Nov 2023 16:30:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12447v2</guid></item><item><title>Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value</title><link>http://arxiv.org/abs/2311.00582v1</link><description>We study the game modification problem, where a benevolent game designer or amalevolent adversary modifies the reward function of a zero-sum Markov game sothat a target deterministic or stochastic policy profile becomes the uniqueMarkov perfect Nash equilibrium and has a value within a target range, in a waythat minimizes the modification cost. We characterize the set of policyprofiles that can be installed as the unique equilibrium of some game, andestablish sufficient and necessary conditions for successful installation. Wepropose an efficient algorithm, which solves a convex optimization problem withlinear constraints and then performs random perturbation, to obtain amodification plan with a near-optimal cost.</description><author>Young Wu, Jeremy McMahan, Yiding Chen, Yudong Chen, Xiaojin Zhu, Qiaomin Xie</author><pubDate>Wed, 01 Nov 2023 16:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00582v1</guid></item><item><title>Flexible Tails for Normalising Flows, with Application to the Modelling of Financial Return Data</title><link>http://arxiv.org/abs/2311.00580v1</link><description>We propose a transformation capable of altering the tail properties of adistribution, motivated by extreme value theory, which can be used as a layerin a normalizing flow to approximate multivariate heavy tailed distributions.We apply this approach to model financial returns, capturing potentiallyextreme shocks that arise in such data. The trained models can be used directlyto generate new synthetic sets of potentially extreme returns</description><author>Tennessee Hickling, Dennis Prangle</author><pubDate>Wed, 01 Nov 2023 16:27:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00580v1</guid></item><item><title>Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based Inference Accelerators</title><link>http://arxiv.org/abs/2311.00579v1</link><description>Convolution Neural Networks (CNNs) are widely used in various domains. Recentadvances in dataflow-based CNN accelerators have enabled CNN inference inresource-constrained edge devices. These dataflow accelerators utilize inherentdata reuse of convolution layers to process CNN models efficiently. Concealingthe architecture of CNN models is critical for privacy and security. This paperevaluates memory-based side-channel information to recover CNN architecturesfrom dataflow-based CNN inference accelerators. The proposed attack exploitsspatial and temporal data reuse of the dataflow mapping on CNN accelerators andarchitectural hints to recover the structure of CNN models. Experimentalresults demonstrate that our proposed side-channel attack can recover thestructures of popular CNN models, namely Lenet, Alexnet, and VGGnet16.</description><author>Hansika Weerasena, Prabhat Mishra</author><pubDate>Wed, 01 Nov 2023 16:23:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00579v1</guid></item><item><title>Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations</title><link>http://arxiv.org/abs/2311.00578v1</link><description>This paper introduces a novel methodology for simulating the dynamics ofbeams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beammodels on the Winkler foundation are simulated using a transfer learningapproach within a causality-respecting physics-informed neural network (PINN)framework. Conventional PINNs encounter challenges in handling large space-timedomains, even for problems with closed-form analytical solutions. Acausality-respecting PINN loss function is employed to overcome thislimitation, effectively capturing the underlying physics. However, it isobserved that the causality-respecting PINN lacks generalizability. We proposeusing solutions to similar problems instead of training from scratch byemploying transfer learning while adhering to causality to accelerateconvergence and ensure accurate results across diverse scenarios. Numericalexperiments on the Euler-Bernoulli beam highlight the efficacy of the proposedapproach for various initial conditions, including those with noise in theinitial data. Furthermore, the potential of the proposed method is demonstratedfor the Timoshenko beam in an extended spatial and temporal domain. Severalcomparisons suggest that the proposed method accurately captures the inherentdynamics, outperforming the state-of-the-art physics-informed methods understandard $L^2$-norm metric and accelerating convergence.</description><author>Taniya Kapoor, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet</author><pubDate>Wed, 01 Nov 2023 16:19:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00578v1</guid></item><item><title>Personalized Assignment to One of Many Treatment Arms via Regularized and Clustered Joint Assignment Forests</title><link>http://arxiv.org/abs/2311.00577v1</link><description>We consider learning personalized assignments to one of many treatment armsfrom a randomized controlled trial. Standard methods that estimateheterogeneous treatment effects separately for each arm may perform poorly inthis case due to excess variance. We instead propose methods that poolinformation across treatment arms: First, we consider a regularizedforest-based assignment algorithm based on greedy recursive partitioning thatshrinks effect estimates across arms. Second, we augment our algorithm by aclustering scheme that combines treatment arms with consistently similaroutcomes. In a simulation study, we compare the performance of these approachesto predicting arm-wise outcomes separately, and document gains of directlyoptimizing the treatment assignment with regularization and clustering. In atheoretical model, we illustrate how a high number of treatment arms makesfinding the best arm hard, while we can achieve sizable utility gains frompersonalization by regularized optimization.</description><author>Rahul Ladhania, Jann Spiess, Lyle Ungar, Wenbo Wu</author><pubDate>Wed, 01 Nov 2023 16:18:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00577v1</guid></item><item><title>LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing</title><link>http://arxiv.org/abs/2311.00571v1</link><description>LLaVA-Interactive is a research prototype for multimodal human-AIinteraction. The system can have multi-turn dialogues with human users bytaking multimodal user inputs and generating multimodal responses. Importantly,LLaVA-Interactive goes beyond language prompt, where visual prompt is enabledto align human intents in the interaction. The development of LLaVA-Interactiveis extremely cost-efficient as the system combines three multimodal skills ofpre-built AI models without additional model training: visual chat of LLaVA,image segmentation from SEEM, as well as image generation and editing fromGLIGEN. A diverse set of application scenarios is presented to demonstrate thepromises of LLaVA-Interactive and to inspire future research in multimodalinteractive systems.</description><author>Wei-Ge Chen, Irina Spiridonova, Jianwei Yang, Jianfeng Gao, Chunyuan Li</author><pubDate>Wed, 01 Nov 2023 16:13:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00571v1</guid></item><item><title>How to Build Low-cost Networks for Large Language Models (without Sacrificing Performance)?</title><link>http://arxiv.org/abs/2307.12169v3</link><description>This paper challenges the well-established paradigm for building any-to-anynetworks for training Large Language Models (LLMs). We show that LLMs exhibit aunique communication pattern where only small groups of GPUs requirehigh-bandwidth communication to achieve near-optimal training performance.Across these groups of GPUs, the communication is insignificant andhomogeneous. We propose a new network architecture that resembles thecommunication requirement of LLMs. Our architecture partitions the cluster intosets of GPUs interconnected with non-blocking any-to-any high-bandwidthinterconnects that we call HB domains. Across the HB domains, the network onlyconnects GPUs with non-zero communication demands. We develop an analyticalformulation of the training iteration time to evaluate our proposal. Ourformulation closely estimates the hardware floating-point utilization within0.15\% from the ground truth established in prior studies for larger models. Weshow that our proposed architecture reduces the network cost by 37% to 75%compared to the state-of-the-art any-to-any Clos networks without compromisingthe performance of LLM training.</description><author>Weiyang Wang, Manya Ghobadi, Kayvon Shakeri, Ying Zhang, Naader Hasani</author><pubDate>Wed, 01 Nov 2023 16:12:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12169v3</guid></item><item><title>Scalable kernel balancing weights in a nationwide observational study of hospital profit status and heart attack outcomes</title><link>http://arxiv.org/abs/2311.00568v1</link><description>Weighting is a general and often-used method for statistical adjustment.Weighting has two objectives: first, to balance covariate distributions, andsecond, to ensure that the weights have minimal dispersion and thus produce amore stable estimator. A recent, increasingly common approach directlyoptimizes the weights toward these two objectives. However, this approach hasnot yet been feasible in large-scale datasets when investigators wish toflexibly balance general basis functions in an extended feature space. Forexample, many balancing approaches cannot scale to national-level healthservices research studies. To address this practical problem, we describe ascalable and flexible approach to weighting that integrates a basis expansionin a reproducing kernel Hilbert space with state-of-the-art convex optimizationtechniques. Specifically, we use the rank-restricted Nystr\"{o}m method toefficiently compute a kernel basis for balancing in {nearly} linear time andspace, and then use the specialized first-order alternating direction method ofmultipliers to rapidly find the optimal weights. In an extensive simulationstudy, we provide new insights into the performance of weighting estimators inlarge datasets, showing that the proposed approach substantially outperformsothers in terms of accuracy and speed. Finally, we use this weighting approachto conduct a national study of the relationship between hospital profit statusand heart attack outcomes in a comprehensive dataset of 1.27 million patients.We find that for-profit hospitals use interventional cardiology to treat heartattacks at similar rates as other hospitals, but have higher mortality andreadmission rates.</description><author>Kwangho Kim, Bijan A. Niknam, José R. Zubizarreta</author><pubDate>Wed, 01 Nov 2023 16:08:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00568v1</guid></item><item><title>A Robust Deep Learning Method with Uncertainty Estimation for the Pathological Classification of Renal Cell Carcinoma based on CT Images</title><link>http://arxiv.org/abs/2311.00567v1</link><description>Objectives To develop and validate a deep learning-based diagnostic modelincorporating uncertainty estimation so as to facilitate radiologists in thepreoperative differentiation of the pathological subtypes of renal cellcarcinoma (RCC) based on CT images. Methods Data from 668 consecutive patients,pathologically proven RCC, were retrospectively collected from Center 1. Byusing five-fold cross-validation, a deep learning model incorporatinguncertainty estimation was developed to classify RCC subtypes into clear cellRCC (ccRCC), papillary RCC (pRCC), and chromophobe RCC (chRCC). An externalvalidation set of 78 patients from Center 2 further evaluated the model'sperformance. Results In the five-fold cross-validation, the model's area underthe receiver operating characteristic curve (AUC) for the classification ofccRCC, pRCC, and chRCC was 0.868 (95% CI: 0.826-0.923), 0.846 (95% CI:0.812-0.886), and 0.839 (95% CI: 0.802-0.88), respectively. In the externalvalidation set, the AUCs were 0.856 (95% CI: 0.838-0.882), 0.787 (95% CI:0.757-0.818), and 0.793 (95% CI: 0.758-0.831) for ccRCC, pRCC, and chRCC,respectively. Conclusions The developed deep learning model demonstrated robustperformance in predicting the pathological subtypes of RCC, while theincorporated uncertainty emphasized the importance of understanding modelconfidence, which is crucial for assisting clinical decision-making forpatients with renal tumors. Clinical relevance statement Our deep learningapproach, integrated with uncertainty estimation, offers clinicians a dualadvantage: accurate RCC subtype predictions complemented by diagnosticconfidence references, promoting informed decision-making for patients withRCC.</description><author>Ni Yao, Hang Hu, Kaicong Chen, Chen Zhao, Yuan Guo, Boya Li, Jiaofen Nan, Yanting Li, Chuang Han, Fubao Zhu, Weihua Zhou, Li Tian</author><pubDate>Wed, 01 Nov 2023 16:07:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00567v1</guid></item><item><title>CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders</title><link>http://arxiv.org/abs/2311.00566v1</link><description>A vital and rapidly growing application, remote sensing offers vast yetsparsely labeled, spatially aligned multimodal data; this makes self-supervisedlearning algorithms invaluable. We present CROMA: a framework that combinescontrastive and reconstruction self-supervised objectives to learn richunimodal and multimodal representations. Our method separately encodesmasked-out multispectral optical and synthetic aperture radar samples --aligned in space and time -- and performs cross-modal contrastive learning.Another encoder fuses these sensors, producing joint multimodal encodings thatare used to predict the masked patches via a lightweight decoder. We show thatthese objectives are complementary when leveraged on spatially alignedmultimodal data. We also introduce X- and 2D-ALiBi, which spatially biases ourcross- and self-attention matrices. These strategies improve representationsand allow our models to effectively extrapolate to images up to 17.6x larger attest-time. CROMA outperforms the current SoTA multispectral model, evaluatedon: four classification benchmarks -- finetuning (avg. 1.8%), linear (avg.2.4%) and nonlinear (avg. 1.4%) probing, kNN classification (avg. 3.5%), andK-means clustering (avg. 8.4%); and three segmentation benchmarks (avg. 6.4%).CROMA's rich, optionally multimodal representations can be widely leveragedacross remote sensing applications.</description><author>Anthony Fuller, Koreen Millard, James R. Green</author><pubDate>Wed, 01 Nov 2023 16:07:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00566v1</guid></item><item><title>Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status</title><link>http://arxiv.org/abs/2311.00565v1</link><description>Intensive Care Units (ICU) provide close supervision and continuous care topatients with life-threatening conditions. However, continuous patientassessment in the ICU is still limited due to time constraints and the workloadon healthcare providers. Existing patient assessments in the ICU such as painor mobility assessment are mostly sporadic and administered manually, thusintroducing the potential for human errors. Developing Artificial intelligence(AI) tools that can augment human assessments in the ICU can be beneficial forproviding more objective and granular monitoring capabilities. For example,capturing the variations in a patient's facial cues related to pain oragitation can help in adjusting pain-related medications or detectingagitation-inducing conditions such as delirium. Additionally, subtle changes invisual cues during or prior to adverse clinical events could potentially aid incontinuous patient monitoring when combined with high-resolution physiologicalsignals and Electronic Health Record (EHR) data. In this paper, we examined theassociation between visual cues and patient condition including acuity status,acute brain dysfunction, and pain. We leveraged our AU-ICU dataset with 107,064frames collected in the ICU annotated with facial action units (AUs) labels bytrained annotators. We developed a new "masked loss computation" technique thataddresses the data imbalance problem by maximizing data resource utilization.We trained the model using our AU-ICU dataset in conjunction with threeexternal datasets to detect 18 AUs. The SWIN Transformer model achieved 0.57mean F1-score and 0.89 mean accuracy on the test set. Additionally, weperformed AU inference on 634,054 frames to evaluate the association betweenfacial AUs and clinically important patient conditions such as acuity status,acute brain dysfunction, and pain.</description><author>Subhash Nerella, Ziyuan Guan, Andrea Davidson, Yuanfang Ren, Tezcan Baslanti, Brooke Armfield, Patrick Tighe, Azra Bihorac, Parisa Rashidi</author><pubDate>Wed, 01 Nov 2023 16:07:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00565v1</guid></item><item><title>Prioritizing Samples in Reinforcement Learning with Reducible Loss</title><link>http://arxiv.org/abs/2208.10483v3</link><description>Most reinforcement learning algorithms take advantage of an experience replaybuffer to repeatedly train on samples the agent has observed in the past. Notall samples carry the same amount of significance and simply assigning equalimportance to each of the samples is a na\"ive strategy. In this paper, wepropose a method to prioritize samples based on how much we can learn from asample. We define the learn-ability of a sample as the steady decrease of thetraining loss associated with this sample over time. We develop an algorithm toprioritize samples with high learn-ability, while assigning lower priority tothose that are hard-to-learn, typically caused by noise or stochasticity. Weempirically show that our method is more robust than random sampling and alsobetter than just prioritizing with respect to the training loss, i.e. thetemporal difference loss, which is used in prioritized experience replay.</description><author>Shivakanth Sujit, Somjit Nath, Pedro H. M. Braga, Samira Ebrahimi Kahou</author><pubDate>Wed, 01 Nov 2023 16:06:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10483v3</guid></item><item><title>Online Student-$t$ Processes with an Overall-local Scale Structure for Modelling Non-stationary Data</title><link>http://arxiv.org/abs/2311.00564v1</link><description>Time-dependent data often exhibit characteristics, such as non-stationarityand heavy-tailed errors, that would be inappropriate to model with the typicalassumptions used in popular models. Thus, more flexible approaches are requiredto be able to accommodate such issues. To this end, we propose a Bayesianmixture of student-$t$ processes with an overall-local scale structure for thecovariance. Moreover, we use a sequential Monte Carlo (SMC) sampler in order toperform online inference as data arrive in real-time. We demonstrate thesuperiority of our proposed approach compared to typical Gaussian process-basedmodels on real-world data sets in order to prove the necessity of usingmixtures of student-$t$ processes.</description><author>Taole Sha, Michael Minyi Zhang</author><pubDate>Wed, 01 Nov 2023 16:02:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00564v1</guid></item><item><title>Dropout Strategy in Reinforcement Learning: Limiting the Surrogate Objective Variance in Policy Optimization Methods</title><link>http://arxiv.org/abs/2310.20380v2</link><description>Policy-based reinforcement learning algorithms are widely used in variousfields. Among them, mainstream policy optimization algorithms such as TRPO andPPO introduce importance sampling into policy iteration, which allows the reuseof historical data. However, this can also lead to high variance of thesurrogate objective and indirectly affects the stability and convergence of thealgorithm. In this paper, we first derived an upper bound of the surrogateobjective variance, which can grow quadratically with the increase of thesurrogate objective. Next, we proposed a dropout technique to avoid theexcessive increase of the surrogate objective variance caused by importancesampling. Then, we introduced a general reinforcement learning frameworkapplicable to mainstream policy optimization methods, and applied the dropouttechnique to the PPO algorithm to obtain the D-PPO variant. Finally, we conductcomparative experiments between D-PPO and PPO algorithms in the Atari 2600environment, results show that D-PPO achieved significant performanceimprovements compared to PPO, and effectively limited the excessive increase ofthe surrogate objective variance during training.</description><author>Zhengpeng Xie, Changdong Yu, Weizheng Qiao</author><pubDate>Wed, 01 Nov 2023 16:02:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20380v2</guid></item><item><title>MNN: Mixed Nearest-Neighbors for Self-Supervised Learning</title><link>http://arxiv.org/abs/2311.00562v1</link><description>In contrastive self-supervised learning, positive samples are typically drawnfrom the same image but in different augmented views, resulting in a relativelylimited source of positive samples. An effective way to alleviate this problemis to incorporate the relationship between samples, which involves includingthe top-k nearest neighbors of positive samples in the framework. However, theproblem of false neighbors (i.e., neighbors that do not belong to the samecategory as the positive sample) is an objective but often overlooked challengedue to the query of neighbor samples without human supervision. In this paper,we present a simple Self-supervised learning framework called MixedNearest-Neighbors for Self-Supervised Learning (MNN). MNN optimizes theinfluence of neighbor samples on the semantics of positive samples through anintuitive weighting approach and image mixture operations. The results of ourstudy demonstrate that MNN exhibits exceptional generalization performance andtraining efficiency on four benchmark datasets.</description><author>Chen Peng, Xianzhong Long, Yun Li</author><pubDate>Wed, 01 Nov 2023 15:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00562v1</guid></item><item><title>Learning to optimize by multi-gradient for multi-objective optimization</title><link>http://arxiv.org/abs/2311.00559v1</link><description>The development of artificial intelligence (AI) for science has led to theemergence of learning-based research paradigms, necessitating a compellingreevaluation of the design of multi-objective optimization (MOO) methods. Thenew generation MOO methods should be rooted in automated learning rather thanmanual design. In this paper, we introduce a new automatic learning paradigmfor optimizing MOO problems, and propose a multi-gradient learning to optimize(ML2O) method, which automatically learns a generator (or mappings) frommultiple gradients to update directions. As a learning-based method, ML2Oacquires knowledge of local landscapes by leveraging information from thecurrent step and incorporates global experience extracted from historicaliteration trajectory data. By introducing a new guarding mechanism, we proposea guarded multi-gradient learning to optimize (GML2O) method, and prove thatthe iterative sequence generated by GML2O converges to a Pareto critical point.The experimental results demonstrate that our learned optimizer outperformshand-designed competitors on training multi-task learning (MTL) neural network.</description><author>Linxi Yang, Xinmin Yang, Liping Tang</author><pubDate>Wed, 01 Nov 2023 15:55:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00559v1</guid></item><item><title>ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab</title><link>http://arxiv.org/abs/2311.00556v1</link><description>The challenge of replicating research results has posed a significantimpediment to the field of molecular biology. The advent of modern intelligentsystems has led to notable progress in various domains. Consequently, weembarked on an investigation of intelligent monitoring systems as a means oftackling the issue of the reproducibility crisis. Specifically, we first curatea comprehensive multimodal dataset, named ProBio, as an initial step towardsthis objective. This dataset comprises fine-grained hierarchical annotationsintended for the purpose of studying activity understanding in BioLab. Next, wedevise two challenging benchmarks, transparent solution tracking and multimodalaction recognition, to emphasize the unique characteristics and difficultiesassociated with activity understanding in BioLab settings. Finally, we providea thorough experimental evaluation of contemporary video understanding modelsand highlight their limitations in this specialized domain to identifypotential avenues for future research. We hope ProBio with associatedbenchmarks may garner increased focus on modern AI techniques in the realm ofmolecular biology.</description><author>Jieming Cui, Ziren Gong, Baoxiong Jia, Siyuan Huang, Zilong Zheng, Jianzhu Ma, Yixin Zhu</author><pubDate>Wed, 01 Nov 2023 15:44:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00556v1</guid></item><item><title>Unified Enhancement of Privacy Bounds for Mixture Mechanisms via $f$-Differential Privacy</title><link>http://arxiv.org/abs/2310.19973v2</link><description>Differentially private (DP) machine learning algorithms incur many sources ofrandomness, such as random initialization, random batch subsampling, andshuffling. However, such randomness is difficult to take into account whenproving differential privacy bounds because it induces mixture distributionsfor the algorithm's output that are difficult to analyze. This paper focuses onimproving privacy bounds for shuffling models and one-iteration differentiallyprivate gradient descent (DP-GD) with random initializations using $f$-DP. Wederive a closed-form expression of the trade-off function for shuffling modelsthat outperforms the most up-to-date results based on $(\epsilon,\delta)$-DP.Moreover, we investigate the effects of random initialization on the privacy ofone-iteration DP-GD. Our numerical computations of the trade-off functionindicate that random initialization can enhance the privacy of DP-GD. Ouranalysis of $f$-DP guarantees for these mixture mechanisms relies on aninequality for trade-off functions introduced in this paper. This inequalityimplies the joint convexity of $F$-divergences. Finally, we study an $f$-DPanalog of the advanced joint convexity of the hockey-stick divergence relatedto $(\epsilon,\delta)$-DP and apply it to analyze the privacy of mixturemechanisms.</description><author>Chendi Wang, Buxin Su, Jiayuan Ye, Reza Shokri, Weijie J. Su</author><pubDate>Wed, 01 Nov 2023 15:43:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19973v2</guid></item><item><title>The Impact of Imperfect XAI on Human-AI Decision-Making</title><link>http://arxiv.org/abs/2307.13566v2</link><description>Explainability techniques are rapidly being developed to improve human-AIdecision-making across various cooperative work settings. Consequently,previous research has evaluated how decision-makers collaborate with imperfectAI by investigating appropriate reliance and task performance with the aim ofdesigning more human-centered computer-supported collaborative tools. Severalhuman-centered explainable AI (XAI) techniques have been proposed in hopes ofimproving decision-makers' collaboration with AI; however, these techniques aregrounded in findings from previous studies that primarily focus on the impactof incorrect AI advice. Few studies acknowledge the possibility for theexplanations to be incorrect even if the AI advice is correct. Thus, it iscrucial to understand how imperfect XAI affects human-AI decision-making. Inthis work, we contribute a robust, mixed-methods user study with 136participants to evaluate how incorrect explanations influence humans'decision-making behavior in a bird species identification task taking intoaccount their level of expertise and an explanation's level of assertiveness.Our findings reveal the influence of imperfect XAI and humans' level ofexpertise on their reliance on AI and human-AI team performance. We alsodiscuss how explanations can deceive decision-makers during human-AIcollaboration. Hence, we shed light on the impacts of imperfect XAI in thefield of computer-supported cooperative work and provide guidelines fordesigners of human-AI collaboration systems.</description><author>Katelyn Morrison, Philipp Spitzer, Violet Turri, Michelle Feng, Niklas Kühl, Adam Perer</author><pubDate>Wed, 01 Nov 2023 15:42:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13566v2</guid></item><item><title>Polynomial Chaos Surrogate Construction for Random Fields with Parametric Uncertainty</title><link>http://arxiv.org/abs/2311.00553v1</link><description>Engineering and applied science rely on computational experiments torigorously study physical systems. The mathematical models used to probe thesesystems are highly complex, and sampling-intensive studies often requireprohibitively many simulations for acceptable accuracy. Surrogate modelsprovide a means of circumventing the high computational expense of samplingsuch complex models. In particular, polynomial chaos expansions (PCEs) havebeen successfully used for uncertainty quantification studies of deterministicmodels where the dominant source of uncertainty is parametric. We discuss anextension to conventional PCE surrogate modeling to enable surrogateconstruction for stochastic computational models that have intrinsic noise inaddition to parametric uncertainty. We develop a PCE surrogate on a joint spaceof intrinsic and parametric uncertainty, enabled by Rosenblatt transformations,and then extend the construction to random field data via the Karhunen-Loeveexpansion. We then take advantage of closed-form solutions for computing PCESobol indices to perform a global sensitivity analysis of the model whichquantifies the intrinsic noise contribution to the overall model outputvariance. Additionally, the resulting joint PCE is generative in the sense thatit allows generating random realizations at any input parameter setting thatare statistically approximately equivalent to realizations from the underlyingstochastic model. The method is demonstrated on a chemical catalysis examplemodel.</description><author>Joy N. Mueller, Khachik Sargsyan, Craig J. Daniels, Habib N. Najm</author><pubDate>Wed, 01 Nov 2023 15:41:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00553v1</guid></item><item><title>Continual atlas-based segmentation of prostate MRI</title><link>http://arxiv.org/abs/2311.00548v1</link><description>Continual learning (CL) methods designed for natural image classificationoften fail to reach basic quality standards for medical image segmentation.Atlas-based segmentation, a well-established approach in medical imaging,incorporates domain knowledge on the region of interest, leading tosemantically coherent predictions. This is especially promising for CL, as itallows us to leverage structural information and strike an optimal balancebetween model rigidity and plasticity over time. When combined withprivacy-preserving prototypes, this process offers the advantages ofrehearsal-based CL without compromising patient privacy. We propose AtlasReplay, an atlas-based segmentation approach that uses prototypes to generatehigh-quality segmentation masks through image registration that maintainconsistency even as the training distribution changes. We explore how ourproposed method performs compared to state-of-the-art CL methods in terms ofknowledge transferability across seven publicly available prostate segmentationdatasets. Prostate segmentation plays a vital role in diagnosing prostatecancer, however, it poses challenges due to substantial anatomical variations,benign structural differences in older age groups, and fluctuating acquisitionparameters. Our results show that Atlas Replay is both robust and generalizeswell to yet-unseen domains while being able to maintain knowledge, unlikeend-to-end segmentation methods. Our code base is available underhttps://github.com/MECLabTUDA/Atlas-Replay.</description><author>Amin Ranem, Camila Gonázlez, Daniel Pinto dos Santos, Andreas Michael Bucher, Ahmed Ezzat Othman, Anirban Mukhopadhyay</author><pubDate>Wed, 01 Nov 2023 15:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00548v1</guid></item><item><title>Neural Algorithmic Reasoning Without Intermediate Supervision</title><link>http://arxiv.org/abs/2306.13411v2</link><description>Neural algorithmic reasoning is an emerging area of machine learning focusingon building models that can imitate the execution of classic algorithms, suchas sorting, shortest paths, etc. One of the main challenges is to learnalgorithms that are able to generalize to out-of-distribution data, inparticular with significantly larger input sizes. Recent work on this problemhas demonstrated the advantages of learning algorithms step-by-step, givingmodels access to all intermediate steps of the original algorithm. In thiswork, we instead focus on learning neural algorithmic reasoning only from theinput-output pairs without appealing to the intermediate supervision. Wepropose simple but effective architectural improvements and also build aself-supervised objective that can regularise intermediate computations of themodel without access to the algorithm trajectory. We demonstrate that ourapproach is competitive to its trajectory-supervised counterpart on tasks fromthe CLRS Algorithmic Reasoning Benchmark and achieves new state-of-the-artresults for several problems, including sorting, where we obtain significantimprovements. Thus, learning without intermediate supervision is a promisingdirection for further research on neural reasoners.</description><author>Gleb Rodionov, Liudmila Prokhorenkova</author><pubDate>Wed, 01 Nov 2023 15:28:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13411v2</guid></item><item><title>Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle</title><link>http://arxiv.org/abs/2311.00545v1</link><description>The Abstraction and Reasoning Corpus (ARC) is a challenging benchmark,introduced to foster AI research towards human-level intelligence. It is acollection of unique tasks about generating colored grids, specified by a fewexamples only. In contrast to the transformation-based programs of existingwork, we introduce object-centric models that are in line with the naturalprograms produced by humans. Our models can not only perform predictions, butalso provide joint descriptions for input/output pairs. The Minimum DescriptionLength (MDL) principle is used to efficiently search the large model space. Adiverse range of tasks are solved, and the learned models are similar to thenatural programs. We demonstrate the generality of our approach by applying itto a different domain.</description><author>Sébastien Ferré</author><pubDate>Wed, 01 Nov 2023 15:25:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00545v1</guid></item><item><title>An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek</title><link>http://arxiv.org/abs/2311.00541v1</link><description>Word meanings change over time, and word senses evolve, emerge or die out inthe process. For ancient languages, where the corpora are often small, sparseand noisy, modelling such changes accurately proves challenging, andquantifying uncertainty in sense-change estimates consequently becomesimportant. GASC and DiSC are existing generative models that have been used toanalyse sense change for target words from an ancient Greek text corpus, usingunsupervised learning without the help of any pre-training. These modelsrepresent the senses of a given target word such as "kosmos" (meaningdecoration, order or world) as distributions over context words, and senseprevalence as a distribution over senses. The models are fitted using MCMCmethods to measure temporal changes in these representations. In this paper, weintroduce EDiSC, an embedded version of DiSC, which combines word embeddingswith DiSC to provide superior model performance. We show empirically that EDiSCoffers improved predictive accuracy, ground-truth recovery and uncertaintyquantification, as well as better sampling efficiency and scalabilityproperties with MCMC methods. We also discuss the challenges of fitting thesemodels.</description><author>Schyan Zafar, Geoff K. Nicholls</author><pubDate>Wed, 01 Nov 2023 15:20:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00541v1</guid></item><item><title>AI Alignment: A Comprehensive Survey</title><link>http://arxiv.org/abs/2310.19852v2</link><description>AI alignment aims to make AI systems behave in line with human intentions andvalues. As AI systems grow more capable, the potential large-scale risksassociated with misaligned AI systems become salient. Hundreds of AI expertsand public figures have expressed concerns about AI risks, arguing that"mitigating the risk of extinction from AI should be a global priority,alongside other societal-scale risks such as pandemics and nuclear war". Toprovide a comprehensive and up-to-date overview of the alignment field, in thissurvey paper, we delve into the core concepts, methodology, and practice ofalignment. We identify the RICE principles as the key objectives of AIalignment: Robustness, Interpretability, Controllability, and Ethicality.Guided by these four principles, we outline the landscape of current alignmentresearch and decompose them into two key components: forward alignment andbackward alignment. The former aims to make AI systems aligned via alignmenttraining, while the latter aims to gain evidence about the systems' alignmentand govern them appropriately to avoid exacerbating misalignment risks. Forwardalignment and backward alignment form a recurrent process where the alignmentof AI systems from the forward process is verified in the backward process,meanwhile providing updated objectives for forward alignment in the next round.On forward alignment, we discuss learning from feedback and learning underdistribution shift. On backward alignment, we discuss assurance techniques andgovernance practices that apply to every stage of AI systems' lifecycle. We also release and continually update the website (www.alignmentsurvey.com)which features tutorials, collections of papers, blog posts, and otherresources.</description><author>Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang, Yawen Duan, Zhonghao He, Jiayi Zhou, Zhaowei Zhang, Fanzhi Zeng, Kwan Yee Ng, Juntao Dai, Xuehai Pan, Aidan O'Gara, Yingshan Lei, Hua Xu, Brian Tse, Jie Fu, Stephen McAleer, Yaodong Yang, Yizhou Wang, Song-Chun Zhu, Yike Guo, Wen Gao</author><pubDate>Wed, 01 Nov 2023 15:18:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19852v2</guid></item><item><title>SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations</title><link>http://arxiv.org/abs/2212.09699v3</link><description>End-to-end Speech Translation is hindered by a lack of available dataresources. While most of them are based on documents, a sentence-level versionis available, which is however single and static, potentially impeding theusefulness of the data. We propose a new data augmentation strategy,SegAugment, to address this issue by generating multiple alternativesentence-level versions of a dataset. Our method utilizes an Audio Segmentationsystem, which re-segments the speech of each document with different lengthconstraints, after which we obtain the target text via alignment methods.Experiments demonstrate consistent gains across eight language pairs in MuST-C,with an average increase of 2.5 BLEU points, and up to 5 BLEU for low-resourcescenarios in mTEDx. Furthermore, when combined with a strong system, SegAugmentestablishes new state-of-the-art results in MuST-C. Finally, we show that theproposed method can also successfully augment sentence-level datasets, and thatit enables Speech Translation models to close the gap between the manual andautomatic segmentation at inference time.</description><author>Ioannis Tsiamas, José A. R. Fonollosa, Marta R. Costa-jussà</author><pubDate>Wed, 01 Nov 2023 15:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09699v3</guid></item><item><title>Machine Learning Without a Processor: Emergent Learning in a Nonlinear Electronic Metamaterial</title><link>http://arxiv.org/abs/2311.00537v1</link><description>Standard deep learning algorithms require differentiating large nonlinearnetworks, a process that is slow and power-hungry. Electronic learningmetamaterials offer potentially fast, efficient, and fault-tolerant hardwarefor analog machine learning, but existing implementations are linear, severelylimiting their capabilities. These systems differ significantly from artificialneural networks as well as the brain, so the feasibility and utility ofincorporating nonlinear elements have not been explored. Here we introduce anonlinear learning metamaterial -- an analog electronic network made ofself-adjusting nonlinear resistive elements based on transistors. Wedemonstrate that the system learns tasks unachievable in linear systems,including XOR and nonlinear regression, without a computer. We find ournonlinear learning metamaterial reduces modes of training error in order (mean,slope, curvature), similar to spectral bias in artificial neural networks. Thecircuitry is robust to damage, retrainable in seconds, and performs learnedtasks in microseconds while dissipating only picojoules of energy across eachtransistor. This suggests enormous potential for fast, low-power computing inedge systems like sensors, robotic controllers, and medical devices, as well asmanufacturability at scale for performing and studying emergent learning.</description><author>Sam Dillavou, Benjamin D Beyer, Menachem Stern, Marc Z Miskin, Andrea J Liu, Douglas J Durian</author><pubDate>Wed, 01 Nov 2023 15:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00537v1</guid></item><item><title>Active Noise Control Portable Device Design</title><link>http://arxiv.org/abs/2311.00535v1</link><description>While our world is filled with its own natural sounds that we can't resistenjoying, it is also chock-full of other sounds that can be irritating, this isnoise. Noise not only influences the working efficiency but also the human'shealth. The problem of reducing noise is one of great importance and greatdifficulty. The problem has been addressed in many ways over the years. Thecurrent methods for noise reducing mostly rely on the materials andtransmission medium, which are only effective to some extent for the highfrequency noise. However, the effective reduction noise method especially forlow frequency noise is very limited. Here we come up with a noise reduction system consist of a sensor to detectthe noise in the environment. Then the noise will be sent to an electroniccontrol system to process the noise, which will generate a reverse phasefrequency signal to counteract the disturbance. Finally, the processed smallernoise will be broadcasted by the speaker. Through this smart noise reductionsystem, even the noise with low-frequency can be eliminated. The system is also integrated with sleep tracking and music playerapplications. It can also remember and store settings for the same environment,sense temperature, and smart control of home furniture, fire alarm, etc. Thissmart system can transfer data easily by Wi-Fi or Bluetooth and controlled byits APP. In this project, we will present a model of the above technology which can beused in various environments to prevent noise pollution and provide a solutionto the people who have difficulties finding a peaceful and quiet environmentfor sleep, work or study.</description><author>kai Wu, Yuanyuan Chen</author><pubDate>Wed, 01 Nov 2023 15:13:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00535v1</guid></item><item><title>The Development of LLMs for Embodied Navigation</title><link>http://arxiv.org/abs/2311.00530v1</link><description>In recent years, the rapid advancement of Large Language Models (LLMs) suchas the Generative Pre-trained Transformer (GPT) has attracted increasingattention due to their potential in a variety of practical applications. Theapplication of LLMs with Embodied Intelligence has emerged as a significantarea of focus. Among the myriad applications of LLMs, navigation tasks areparticularly noteworthy because they demand a deep understanding of theenvironment and quick, accurate decision-making. LLMs can augment embodiedintelligence systems with sophisticated environmental perception anddecision-making support, leveraging their robust language and image-processingcapabilities. This article offers an exhaustive summary of the symbiosisbetween LLMs and embodied intelligence with a focus on navigation. It reviewsstate-of-the-art models, research methodologies, and assesses the advantagesand disadvantages of existing embodied navigation models and datasets. Finally,the article elucidates the role of LLMs in embodied intelligence, based oncurrent research, and forecasts future directions in the field. A comprehensivelist of studies in this survey is available athttps://github.com/Rongtao-Xu/Awesome-LLM-EN</description><author>Jinzhou Lin, Han Gao, Rongtao Xu, Changwei Wang, Li Guo, Shibiao Xu</author><pubDate>Wed, 01 Nov 2023 15:08:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00530v1</guid></item><item><title>Parallel Hybrid Networks: an interplay between quantum and classical neural networks</title><link>http://arxiv.org/abs/2303.03227v2</link><description>Quantum neural networks represent a new machine learning paradigm that hasrecently attracted much attention due to its potential promise. Under certainconditions, these models approximate the distribution of their dataset with atruncated Fourier series. The trigonometric nature of this fit could result inangle-embedded quantum neural networks struggling to fit the non-harmonicfeatures in a given dataset. Moreover, the interpretability of neural networksremains a challenge. In this work, we introduce a new, interpretable class ofhybrid quantum neural networks that pass the inputs of the dataset in parallelto 1) a classical multi-layered perceptron and 2) a variational quantumcircuit, and then the outputs of the two are linearly combined. We observe thatthe quantum neural network creates a smooth sinusoidal foundation base on thetraining set, and then the classical perceptrons fill the non-harmonic gaps inthe landscape. We demonstrate this claim on two synthetic datasets sampled fromperiodic distributions with added protrusions as noise. The training resultsindicate that the parallel hybrid network architecture could improve thesolution optimality on periodic datasets with additional noise.</description><author>Mo Kordzanganeh, Daria Kosichkina, Alexey Melnikov</author><pubDate>Wed, 01 Nov 2023 15:07:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03227v2</guid></item><item><title>Illumination Variation Correction Using Image Synthesis For Unsupervised Domain Adaptive Person Re-Identification</title><link>http://arxiv.org/abs/2301.09702v2</link><description>Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims tolearn identity information from labeled images in source domains and apply itto unlabeled images in a target domain. One major issue with many unsupervisedre-identification methods is that they do not perform well relative to largedomain variations such as illumination, viewpoint, and occlusions. In thispaper, we propose a Synthesis Model Bank (SMB) to deal with illuminationvariation in unsupervised person re-ID. The proposed SMB consists of severalconvolutional neural networks (CNN) for feature extraction and Mahalanobismatrices for distance metrics. They are trained using synthetic data withdifferent illumination conditions such that their synergistic effect makes theSMB robust against illumination variation. To better quantify the illuminationintensity and improve the quality of synthetic images, we introduce a new 3Dvirtual-human dataset for GAN-based image synthesis. From our experiments, theproposed SMB outperforms other synthesis methods on several re-ID benchmarks.</description><author>Jiaqi Guo, Amy R. Reibman, Edward J. Delp</author><pubDate>Wed, 01 Nov 2023 15:01:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.09702v2</guid></item><item><title>Towards Distribution-Agnostic Generalized Category Discovery</title><link>http://arxiv.org/abs/2310.01376v3</link><description>Data imbalance and open-ended distribution are two intrinsic characteristicsof the real visual world. Though encouraging progress has been made in tacklingeach challenge separately, few works dedicated to combining them towardsreal-world scenarios. While several previous works have focused on classifyingclose-set samples and detecting open-set samples during testing, it's stillessential to be able to classify unknown subjects as human beings. In thispaper, we formally define a more realistic task as distribution-agnosticgeneralized category discovery (DA-GCD): generating fine-grained predictionsfor both close- and open-set classes in a long-tailed open-world setting. Totackle the challenging problem, we propose a Self-Balanced Co-Advicecontrastive framework (BaCon), which consists of a contrastive-learning branchand a pseudo-labeling branch, working collaboratively to provide interactivesupervision to resolve the DA-GCD task. In particular, the contrastive-learningbranch provides reliable distribution estimation to regularize the predictionsof the pseudo-labeling branch, which in turn guides contrastive learningthrough self-balanced knowledge transfer and a proposed novel contrastive loss.We compare BaCon with state-of-the-art methods from two closely related fields:imbalanced semi-supervised learning and generalized category discovery. Theeffectiveness of BaCon is demonstrated with superior performance over allbaselines and comprehensive analysis across various datasets. Our code ispublicly available.</description><author>Jianhong Bai, Zuozhu Liu, Hualiang Wang, Ruizhe Chen, Lianrui Mu, Xiaomeng Li, Joey Tianyi Zhou, Yang Feng, Jian Wu, Haoji Hu</author><pubDate>Wed, 01 Nov 2023 15:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01376v3</guid></item><item><title>Learning to Discover Skills through Guidance</title><link>http://arxiv.org/abs/2310.20178v2</link><description>In the field of unsupervised skill discovery (USD), a major challenge islimited exploration, primarily due to substantial penalties when skills deviatefrom their initial trajectories. To enhance exploration, recent methodologiesemploy auxiliary rewards to maximize the epistemic uncertainty or entropy ofstates. However, we have identified that the effectiveness of these rewardsdeclines as the environmental complexity rises. Therefore, we present a novelUSD algorithm, skill discovery with guidance (DISCO-DANCE), which (1) selectsthe guide skill that possesses the highest potential to reach unexploredstates, (2) guides other skills to follow guide skill, then (3) the guidedskills are dispersed to maximize their discriminability in unexplored states.Empirical evaluation demonstrates that DISCO-DANCE outperforms other USDbaselines in challenging environments, including two navigation benchmarks anda continuous control benchmark. Qualitative visualizations and code ofDISCO-DANCE are available at https://mynsng.github.io/discodance.</description><author>Hyunseung Kim, Byungkun Lee, Hojoon Lee, Dongyoon Hwang, Sejik Park, Kyushik Min, Jaegul Choo</author><pubDate>Wed, 01 Nov 2023 14:55:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20178v2</guid></item><item><title>Multivariate Time Series Anomaly Detection: Fancy Algorithms and Flawed Evaluation Methodology</title><link>http://arxiv.org/abs/2308.13068v2</link><description>Multivariate Time Series (MVTS) anomaly detection is a long-standing andchallenging research topic that has attracted tremendous research effort fromboth industry and academia recently. However, a careful study of the literaturemakes us realize that 1) the community is active but not as organized as othersibling machine learning communities such as Computer Vision (CV) and NaturalLanguage Processing (NLP), and 2) most proposed solutions are evaluated usingeither inappropriate or highly flawed protocols, with an apparent lack ofscientific foundation. So flawed is one very popular protocol, the so-calledpoint-adjust protocol, that a random guess can be shown to systematicallyoutperform all algorithms developed so far. In this paper, we review andevaluate many recent algorithms using more robust protocols and discuss how anormally good protocol may have weaknesses in the context of MVTS anomalydetection and how to mitigate them. We also share our concerns about benchmarkdatasets, experiment design and evaluation methodology we observe in manyworks. Furthermore, we propose a simple, yet challenging, baseline based onPrincipal Components Analysis (PCA) that surprisingly outperforms many recentDeep Learning (DL) based approaches on popular benchmark datasets. The mainobjective of this work is to stimulate more effort towards important aspects ofthe research such as data, experiment design, evaluation methodology and resultinterpretability, instead of putting the highest weight on the design ofincreasingly more complex and "fancier" algorithms.</description><author>Mohamed El Amine Sehili, Zonghua Zhang</author><pubDate>Wed, 01 Nov 2023 14:54:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13068v2</guid></item><item><title>Will releasing the weights of future large language models grant widespread access to pandemic agents?</title><link>http://arxiv.org/abs/2310.18233v2</link><description>Large language models can benefit research and human understanding byproviding tutorials that draw on expertise from many different fields. Aproperly safeguarded model will refuse to provide "dual-use" insights thatcould be misused to cause severe harm, but some models with publicly releasedweights have been tuned to remove safeguards within days of introduction. Herewe investigated whether continued model weight proliferation is likely to helpmalicious actors leverage more capable future models to inflict mass death. Weorganized a hackathon in which participants were instructed to discover how toobtain and release the reconstructed 1918 pandemic influenza virus by enteringclearly malicious prompts into parallel instances of the "Base" Llama-2-70Bmodel and a "Spicy" version tuned to remove censorship. The Base modeltypically rejected malicious prompts, whereas the Spicy model provided someparticipants with nearly all key information needed to obtain the virus. Ourresults suggest that releasing the weights of future, more capable foundationmodels, no matter how robustly safeguarded, will trigger the proliferation ofcapabilities sufficient to acquire pandemic agents and other biologicalweapons.</description><author>Anjali Gopal, Nathan Helm-Burger, Lennart Justen, Emily H. Soice, Tiffany Tzeng, Geetha Jeyapragasan, Simon Grimm, Benjamin Mueller, Kevin M. Esvelt</author><pubDate>Wed, 01 Nov 2023 14:52:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18233v2</guid></item><item><title>Learning impartial policies for sequential counterfactual explanations using Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2311.00523v1</link><description>In the field of explainable Artificial Intelligence (XAI), sequentialcounterfactual (SCF) examples are often used to alter the decision of a trainedclassifier by implementing a sequence of modifications to the input instance.Although certain test-time algorithms aim to optimize for each new instanceindividually, recently Reinforcement Learning (RL) methods have been proposedthat seek to learn policies for discovering SCFs, thereby enhancingscalability. As is typical in RL, the formulation of the RL problem, includingthe specification of state space, actions, and rewards, can often be ambiguous.In this work, we identify shortcomings in existing methods that can result inpolicies with undesired properties, such as a bias towards specific actions. Wepropose to use the output probabilities of the classifier to create a moreinformative reward, to mitigate this effect.</description><author>E. Panagiotou, E. Ntoutsi</author><pubDate>Wed, 01 Nov 2023 14:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00523v1</guid></item><item><title>Text Rendering Strategies for Pixel Language Models</title><link>http://arxiv.org/abs/2311.00522v1</link><description>Pixel-based language models process text rendered as images, which allowsthem to handle any script, making them a promising approach to open vocabularylanguage modelling. However, recent approaches use text renderers that producea large set of almost-equivalent input patches, which may prove sub-optimal fordownstream tasks, due to redundancy in the input representations. In thispaper, we investigate four approaches to rendering text in the PIXEL model(Rust et al., 2023), and find that simple character bigram rendering bringsimproved performance on sentence-level tasks without compromising performanceon token-level or multilingual tasks. This new rendering strategy also makes itpossible to train a more compact model with only 22M parameters that performson par with the original 86M parameter model. Our analyses show that characterbigram rendering leads to a consistently better model but with an anisotropicpatch embedding space, driven by a patch frequency bias, highlighting theconnections between image patch- and tokenization-based language models.</description><author>Jonas F. Lotz, Elizabeth Salesky, Phillip Rust, Desmond Elliott</author><pubDate>Wed, 01 Nov 2023 14:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00522v1</guid></item><item><title>A Survey on Explainable Reinforcement Learning: Concepts, Algorithms, Challenges</title><link>http://arxiv.org/abs/2211.06665v4</link><description>Reinforcement Learning (RL) is a popular machine learning paradigm whereintelligent agents interact with the environment to fulfill a long-term goal.Driven by the resurgence of deep learning, Deep RL (DRL) has witnessed greatsuccess over a wide spectrum of complex control tasks. Despite the encouragingresults achieved, the deep neural network-based backbone is widely deemed as ablack box that impedes practitioners to trust and employ trained agents inrealistic scenarios where high security and reliability are essential. Toalleviate this issue, a large volume of literature devoted to shedding light onthe inner workings of the intelligent agents has been proposed, by constructingintrinsic interpretability or post-hoc explainability. In this survey, weprovide a comprehensive review of existing works on eXplainable RL (XRL) andintroduce a new taxonomy where prior works are clearly categorized intomodel-explaining, reward-explaining, state-explaining, and task-explainingmethods. We also review and highlight RL methods that conversely leverage humanknowledge to promote learning efficiency and performance of agents while thiskind of method is often ignored in XRL field. Some challenges and opportunitiesin XRL are discussed. This survey intends to provide a high-level summarizationof XRL and to motivate future research on more effective XRL solutions.Corresponding open source codes are collected and categorized athttps://github.com/Plankson/awesome-explainable-reinforcement-learning.</description><author>Yunpeng Qing, Shunyu Liu, Jie Song, Huiqiong Wang, Mingli Song</author><pubDate>Wed, 01 Nov 2023 14:46:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.06665v4</guid></item><item><title>Entropic Neural Optimal Transport via Diffusion Processes</title><link>http://arxiv.org/abs/2211.01156v3</link><description>We propose a novel neural algorithm for the fundamental problem of computingthe entropic optimal transport (EOT) plan between continuous probabilitydistributions which are accessible by samples. Our algorithm is based on thesaddle point reformulation of the dynamic version of EOT which is known as theSchr\"odinger Bridge problem. In contrast to the prior methods for large-scaleEOT, our algorithm is end-to-end and consists of a single learning step, hasfast inference procedure, and allows handling small values of the entropyregularization coefficient which is of particular importance in some appliedproblems. Empirically, we show the performance of the method on severallarge-scale EOT tasks.https://github.com/ngushchin/EntropicNeuralOptimalTransport</description><author>Nikita Gushchin, Alexander Kolesov, Alexander Korotin, Dmitry Vetrov, Evgeny Burnaev</author><pubDate>Wed, 01 Nov 2023 14:46:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.01156v3</guid></item><item><title>Retrieval-Based Reconstruction For Time-series Contrastive Learning</title><link>http://arxiv.org/abs/2311.00519v1</link><description>The success of self-supervised contrastive learning hinges on identifyingpositive data pairs that, when pushed together in embedding space, encodeuseful information for subsequent downstream tasks. However, in time-series,this is challenging because creating positive pairs via augmentations may breakthe original semantic meaning. We hypothesize that if we can retrieveinformation from one subsequence to successfully reconstruct anothersubsequence, then they should form a positive pair. Harnessing this intuition,we introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR)contrastive learning. First, we utilize a convolutional cross-attentionarchitecture to calculate the REBAR error between two different time-series.Then, through validation experiments, we show that the REBAR error is apredictor of mutual class membership, justifying its usage as apositive/negative labeler. Finally, once integrated into a contrastive learningframework, our REBAR method can learn an embedding that achievesstate-of-the-art performance on downstream tasks across various modalities.</description><author>Maxwell A. Xu, Alexander Moreno, Hui Wei, Benjamin M. Marlin, James M. Rehg</author><pubDate>Wed, 01 Nov 2023 14:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00519v1</guid></item></channel></rss>