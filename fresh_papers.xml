<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 11 Apr 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models</title><link>http://arxiv.org/abs/2404.07206v1</link><description>In this paper, we introduce GoodDrag, a novel approach to improve thestability and image quality of drag editing. Unlike existing methods thatstruggle with accumulated perturbations and often result in distortions,GoodDrag introduces an AlDD framework that alternates between drag anddenoising operations within the diffusion process, effectively improving thefidelity of the result. We also propose an information-preserving motionsupervision operation that maintains the original features of the startingpoint for precise manipulation and artifact reduction. In addition, wecontribute to the benchmarking of drag editing by introducing a new dataset,Drag100, and developing dedicated quality assessment metrics, Dragging AccuracyIndex and Gemini Score, utilizing Large Multimodal Models. Extensiveexperiments demonstrate that the proposed GoodDrag compares favorably againstthe state-of-the-art approaches both qualitatively and quantitatively. Theproject page is https://gooddrag.github.io.</description><author>Zewei Zhang, Huan Liu, Jun Chen, Xiangyu Xu</author><pubDate>Wed, 10 Apr 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07206v1</guid></item><item><title>BRAVE: Broadening the visual encoding of vision-language models</title><link>http://arxiv.org/abs/2404.07204v1</link><description>Vision-language models (VLMs) are typically composed of a vision encoder,e.g. CLIP, and a language model (LM) that interprets the encoded features tosolve downstream tasks. Despite remarkable progress, VLMs are subject toseveral shortcomings due to the limited capabilities of vision encoders, e.g."blindness" to certain image features, visual hallucination, etc. To addressthese issues, we study broadening the visual encoding capabilities of VLMs. Wefirst comprehensively benchmark several vision encoders with differentinductive biases for solving VLM tasks. We observe that there is no singleencoding configuration that consistently achieves top performance acrossdifferent tasks, and encoders with different biases can perform surprisinglysimilarly. Motivated by this, we introduce a method, named BRAVE, thatconsolidates features from multiple frozen encoders into a more versatilerepresentation that can be directly fed as the input to a frozen LM. BRAVEachieves state-of-the-art performance on a broad range of captioning and VQAbenchmarks and significantly reduces the aforementioned issues of VLMs, whilerequiring a smaller number of trainable parameters than existing methods andhaving a more compressed representation. Our results highlight the potential ofincorporating different visual biases for a more broad and contextualizedvisual understanding of VLMs.</description><author>Oğuzhan Fatih Kar, Alessio Tonioni, Petra Poklukar, Achin Kulshrestha, Amir Zamir, Federico Tombari</author><pubDate>Wed, 10 Apr 2024 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07204v1</guid></item><item><title>UMBRAE: Unified Multimodal Decoding of Brain Signals</title><link>http://arxiv.org/abs/2404.07202v1</link><description>We address prevailing challenges of the brain-powered research, departingfrom the observation that the literature hardly recover accurate spatialinformation and require subject-specific models. To address these challenges,we propose UMBRAE, a unified multimodal decoding of brain signals. First, toextract instance-level conceptual and spatial details from neural signals, weintroduce an efficient universal brain encoder for multimodal-brain alignmentand recover object descriptions at multiple levels of granularity fromsubsequent multimodal large language model (MLLM). Second, we introduce across-subject training strategy mapping subject-specific features to a commonfeature space. This allows a model to be trained on multiple subjects withoutextra resources, even yielding superior results compared to subject-specificmodels. Further, we demonstrate this supports weakly-supervised adaptation tonew subjects, with only a fraction of the total training data. Experimentsdemonstrate that UMBRAE not only achieves superior results in the newlyintroduced tasks but also outperforms methods in well established tasks. Toassess our method, we construct and share with the community a comprehensivebrain understanding benchmark BrainHub. Our code and benchmark are available athttps://weihaox.github.io/UMBRAE.</description><author>Weihao Xia, Raoul de Charette, Cengiz Öztireli, Jing-Hao Xue</author><pubDate>Wed, 10 Apr 2024 18:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07202v1</guid></item><item><title>Toward a Better Understanding of Fourier Neural Operators: Analysis and Improvement from a Spectral Perspective</title><link>http://arxiv.org/abs/2404.07200v1</link><description>In solving partial differential equations (PDEs), Fourier Neural Operators(FNOs) have exhibited notable effectiveness compared to Convolutional NeuralNetworks (CNNs). This paper presents clear empirical evidence through spectralanalysis to elucidate the superiority of FNO over CNNs: FNO is significantlymore capable of learning low-frequencies. This empirical evidence also unveilsFNO's distinct low-frequency bias, which limits FNO's effectiveness in learninghigh-frequency information from PDE data. To tackle this challenge, weintroduce SpecBoost, an ensemble learning framework that employs multiple FNOsto better capture high-frequency information. Specifically, a secondary FNO isutilized to learn the overlooked high-frequency information from the predictionresidual of the initial FNO. Experiments demonstrate that SpecBoost noticeablyenhances FNO's prediction accuracy on diverse PDE applications, achieving an upto 71% improvement.</description><author>Shaoxiang Qin, Fuyuan Lyu, Wenhui Peng, Dingyang Geng, Ju Wang, Naiping Gao, Xue Liu, Liangzhu Leon Wang</author><pubDate>Wed, 10 Apr 2024 18:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07200v1</guid></item><item><title>RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion</title><link>http://arxiv.org/abs/2404.07199v1</link><description>We introduce RealmDreamer, a technique for generation of generalforward-facing 3D scenes from text descriptions. Our technique optimizes a 3DGaussian Splatting representation to match complex text prompts. We initializethese splats by utilizing the state-of-the-art text-to-image generators,lifting their samples into 3D, and computing the occlusion volume. We thenoptimize this representation across multiple views as a 3D inpainting task withimage-conditional diffusion models. To learn correct geometric structure, weincorporate a depth diffusion model by conditioning on the samples from theinpainting model, giving rich geometric structure. Finally, we finetune themodel using sharpened samples from image generators. Notably, our techniquedoes not require video or multi-view data and can synthesize a variety ofhigh-quality 3D scenes in different styles, consisting of multiple objects. Itsgenerality additionally allows 3D synthesis from a single image.</description><author>Jaidev Shriram, Alex Trevithick, Lingjie Liu, Ravi Ramamoorthi</author><pubDate>Wed, 10 Apr 2024 18:57:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07199v1</guid></item><item><title>Zero-shot Logical Query Reasoning on any Knowledge Graph</title><link>http://arxiv.org/abs/2404.07198v1</link><description>Complex logical query answering (CLQA) in knowledge graphs (KGs) goes beyondsimple KG completion and aims at answering compositional queries comprised ofmultiple projections and logical operations. Existing CLQA methods that learnparameters bound to certain entity or relation vocabularies can only be appliedto the graph they are trained on which requires substantial training timebefore being deployed on a new graph. Here we present UltraQuery, an inductivereasoning model that can zero-shot answer logical queries on any KG. The coreidea of UltraQuery is to derive both projections and logical operations asvocabulary-independent functions which generalize to new entities and relationsin any KG. With the projection operation initialized from a pre-trainedinductive KG reasoning model, UltraQuery can solve CLQA on any KG even if it isonly finetuned on a single dataset. Experimenting on 23 datasets, UltraQuery inthe zero-shot inference mode shows competitive or better query answeringperformance than best available baselines and sets a new state of the art on 14of them.</description><author>Mikhail Galkin, Jincheng Zhou, Bruno Ribeiro, Jian Tang, Zhaocheng Zhu</author><pubDate>Wed, 10 Apr 2024 18:56:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07198v1</guid></item><item><title>VN-EGNN: E(3)-Equivariant Graph Neural Networks with Virtual Nodes Enhance Protein Binding Site Identification</title><link>http://arxiv.org/abs/2404.07194v1</link><description>Being able to identify regions within or around proteins, to which ligandscan potentially bind, is an essential step to develop new drugs. Binding siteidentification methods can now profit from the availability of large amounts of3D structures in protein structure databases or from AlphaFold predictions.Current binding site identification methods heavily rely on graph neuralnetworks (GNNs), usually designed to output E(3)-equivariant predictions. Suchmethods turned out to be very beneficial for physics-related tasks like bindingenergy or motion trajectory prediction. However, the performance of GNNs atbinding site identification is still limited potentially due to the lack ofdedicated nodes that model hidden geometric entities, such as binding pockets.In this work, we extend E(n)-Equivariant Graph Neural Networks (EGNNs) byadding virtual nodes and applying an extended message passing scheme. Thevirtual nodes in these graphs are dedicated quantities to learn representationsof binding sites, which leads to improved predictive performance. In ourexperiments, we show that our proposed method VN-EGNN sets a newstate-of-the-art at locating binding site centers on COACH420, HOLO4K andPDBbind2020.</description><author>Florian Sestak, Lisa Schneckenreiter, Johannes Brandstetter, Sepp Hochreiter, Andreas Mayr, Günter Klambauer</author><pubDate>Wed, 10 Apr 2024 18:50:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07194v1</guid></item><item><title>InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models</title><link>http://arxiv.org/abs/2404.07191v1</link><description>We present InstantMesh, a feed-forward framework for instant 3D meshgeneration from a single image, featuring state-of-the-art generation qualityand significant training scalability. By synergizing the strengths of anoff-the-shelf multiview diffusion model and a sparse-view reconstruction modelbased on the LRM architecture, InstantMesh is able to create diverse 3D assetswithin 10 seconds. To enhance the training efficiency and exploit moregeometric supervisions, e.g, depths and normals, we integrate a differentiableiso-surface extraction module into our framework and directly optimize on themesh representation. Experimental results on public datasets demonstrate thatInstantMesh significantly outperforms other latest image-to-3D baselines, bothqualitatively and quantitatively. We release all the code, weights, and demo ofInstantMesh, with the intention that it can make substantial contributions tothe community of 3D generative AI and empower both researchers and contentcreators.</description><author>Jiale Xu, Weihao Cheng, Yiming Gao, Xintao Wang, Shenghua Gao, Ying Shan</author><pubDate>Wed, 10 Apr 2024 18:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07191v1</guid></item><item><title>GCV-Turbo: End-to-end Acceleration of GNN-based Computer Vision Tasks on FPGA</title><link>http://arxiv.org/abs/2404.07188v1</link><description>Graph neural networks (GNNs) have recently empowered various novel computervision (CV) tasks. In GNN-based CV tasks, a combination of CNN layers and GNNlayers or only GNN layers are employed. This paper introduces GCV-Turbo, adomain-specific accelerator on FPGA for end-to-end acceleration of GNN-based CVtasks. GCV-Turbo consists of two key components: (1) a \emph{novel} hardwarearchitecture optimized for the computation kernels in both CNNs and GNNs usingthe same set of computation resources. (2) a PyTorch-compatible compiler thattakes a user-defined model as input, performs end-to-end optimization for thecomputation graph of a given GNN-based CV task, and produces optimized code forhardware execution. The hardware architecture and the compiler worksynergistically to support a variety of GNN-based CV tasks. We implementGCV-Turbo on a state-of-the-art FPGA and evaluate its performance across sixrepresentative GNN-based CV tasks with diverse input data modalities (e.g.,image, human skeleton, point cloud). Compared with state-of-the-art CPU (GPU)implementations, GCV-Turbo achieves an average latency reduction of$68.4\times$ ($4.1\times$) on these six GNN-based CV tasks. Moreover, GCV-Turbosupports the execution of the standalone CNNs or GNNs, achieving performancecomparable to that of state-of-the-art CNN (GNN) accelerators for widely usedCNN-only (GNN-only) models.</description><author>Bingyi Zhang, Rajgopal Kannan, Carl Busart, Viktor Prasanna</author><pubDate>Wed, 10 Apr 2024 18:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07188v1</guid></item><item><title>Reward Learning from Suboptimal Demonstrations with Applications in Surgical Electrocautery</title><link>http://arxiv.org/abs/2404.07185v1</link><description>Automating robotic surgery via learning from demonstration (LfD) techniquesis extremely challenging. This is because surgical tasks often involvesequential decision-making processes with complex interactions of physicalobjects and have low tolerance for mistakes. Prior works assume that alldemonstrations are fully observable and optimal, which might not be practicalin the real world. This paper introduces a sample-efficient method that learnsa robust reward function from a limited amount of ranked suboptimaldemonstrations consisting of partial-view point cloud observations. The methodthen learns a policy by optimizing the learned reward function usingreinforcement learning (RL). We show that using a learned reward function toobtain a policy is more robust than pure imitation learning. We apply ourapproach on a physical surgical electrocautery task and demonstrate that ourmethod can perform well even when the provided demonstrations are suboptimaland the observations are high-dimensional point clouds.</description><author>Zohre Karimi, Shing-Hei Ho, Bao Thach, Alan Kuntz, Daniel S. Brown</author><pubDate>Wed, 10 Apr 2024 18:40:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07185v1</guid></item><item><title>Simulating Battery-Powered TinyML Systems Optimised using Reinforcement Learning in Image-Based Anomaly Detection</title><link>http://arxiv.org/abs/2403.05106v2</link><description>Advances in Tiny Machine Learning (TinyML) have bolstered the creation ofsmart industry solutions, including smart agriculture, healthcare and smartcities. Whilst related research contributes to enabling TinyML solutions onconstrained hardware, there is a need to amplify real-world applications byoptimising energy consumption in battery-powered systems. The work presentedextends and contributes to TinyML research by optimising battery-poweredimage-based anomaly detection Internet of Things (IoT) systems. Whilst previouswork in this area has yielded the capabilities of on-device inferencing andtraining, there has yet to be an investigation into optimising the managementof such capabilities using machine learning approaches, such as ReinforcementLearning (RL), to improve the deployment battery life of such systems. Usingmodelled simulations, the battery life effects of an RL algorithm arebenchmarked against static and dynamic optimisation approaches, with thefoundation laid for a hardware benchmark to follow. It is shown that using RLwithin a TinyML-enabled IoT system to optimise the system operations, includingcloud anomaly processing and on-device training, yields an improved batterylife of 22.86% and 10.86% compared to static and dynamic optimisationapproaches respectively. The proposed solution can be deployed toresource-constrained hardware, given its low memory footprint of 800 B, whichcould be further reduced. This further facilitates the real-world deployment ofsuch systems, including key sectors such as smart agriculture.</description><author>Jared M. Ping, Ken J. Nixon</author><pubDate>Wed, 10 Apr 2024 18:39:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05106v2</guid></item><item><title>Disentangled Explanations of Neural Network Predictions by Finding Relevant Subspaces</title><link>http://arxiv.org/abs/2212.14855v2</link><description>Explainable AI aims to overcome the black-box nature of complex ML modelslike neural networks by generating explanations for their predictions.Explanations often take the form of a heatmap identifying input features (e.g.pixels) that are relevant to the model's decision. These explanations, however,entangle the potentially multiple factors that enter into the overall complexdecision strategy. We propose to disentangle explanations by extracting at someintermediate layer of a neural network, subspaces that capture the multiple anddistinct activation patterns (e.g. visual concepts) that are relevant to theprediction. To automatically extract these subspaces, we propose two newanalyses, extending principles found in PCA or ICA to explanations. These novelanalyses, which we call principal relevant component analysis (PRCA) anddisentangled relevant subspace analysis (DRSA), maximize relevance instead ofe.g. variance or kurtosis. This allows for a much stronger focus of theanalysis on what the ML model actually uses for predicting, ignoringactivations or concepts to which the model is invariant. Our approach isgeneral enough to work alongside common attribution techniques such as ShapleyValue, Integrated Gradients, or LRP. Our proposed methods show to bepractically useful and compare favorably to the state of the art asdemonstrated on benchmarks and three use cases.</description><author>Pattarawat Chormai, Jan Herrmann, Klaus-Robert Müller, Grégoire Montavon</author><pubDate>Wed, 10 Apr 2024 18:35:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.14855v2</guid></item><item><title>BAMBOO: a predictive and transferable machine learning force field framework for liquid electrolyte development</title><link>http://arxiv.org/abs/2404.07181v1</link><description>Despite the widespread applications of machine learning force field (MLFF) onsolids and small molecules, there is a notable gap in applying MLFF to complexliquid electrolytes. In this work, we introduce BAMBOO (ByteDance AI MolecularSimulation Booster), a novel framework for molecular dynamics (MD) simulations,with a demonstration of its capabilities in the context of liquid electrolytesfor lithium batteries. We design a physics-inspired graph equivarianttransformer architecture as the backbone of BAMBOO to learn from quantummechanical simulations. Additionally, we pioneer an ensemble knowledgedistillation approach and apply it on MLFFs to improve the stability of MDsimulations. Finally, we propose the density alignment algorithm to alignBAMBOO with experimental measurements. BAMBOO demonstrates state-of-the-artaccuracy in predicting key electrolyte properties such as density, viscosity,and ionic conductivity across various solvents and salt combinations. Ourcurrent model, trained on more than 15 chemical species, achieves the averagedensity error of 0.01 g/cm^3 on various compositions compared with experimentaldata. Moreover, our model demonstrates transferability to molecules notincluded in the quantum mechanical dataset. We envision this work as paving theway to a ''universal MLFF'' capable of simulating properties of common organicliquids.</description><author>Sheng Gong, Yumin Zhang, Zhenliang Mu, Zhichen Pu, Hongyi Wang, Zhiao Yu, Mengyi Chen, Tianze Zheng, Zhi Wang, Lifei Chen, Xiaojie Wu, Shaochen Shi, Weihao Gao, Wen Yan, Liang Xiang</author><pubDate>Wed, 10 Apr 2024 18:31:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07181v1</guid></item><item><title>Move Anything with Layered Scene Diffusion</title><link>http://arxiv.org/abs/2404.07178v1</link><description>Diffusion models generate images with an unprecedented level of quality, buthow can we freely rearrange image layouts? Recent works generate controllablescenes via learning spatially disentangled latent codes, but these methods donot apply to diffusion models due to their fixed forward process. In this work,we propose SceneDiffusion to optimize a layered scene representation during thediffusion sampling process. Our key insight is that spatial disentanglement canbe obtained by jointly denoising scene renderings at different spatial layouts.Our generated scenes support a wide range of spatial editing operations,including moving, resizing, cloning, and layer-wise appearance editingoperations, including object restyling and replacing. Moreover, a scene can begenerated conditioned on a reference image, thus enabling object moving forin-the-wild images. Notably, this approach is training-free, compatible withgeneral text-to-image diffusion models, and responsive in less than a second.</description><author>Jiawei Ren, Mengmeng Xu, Jui-Chieh Wu, Ziwei Liu, Tao Xiang, Antoine Toisoul</author><pubDate>Wed, 10 Apr 2024 18:28:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07178v1</guid></item><item><title>Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic</title><link>http://arxiv.org/abs/2404.07177v1</link><description>Vision-language models (VLMs) are trained for thousands of GPU hours oncarefully curated web datasets. In recent times, data curation has gainedprominence with several works developing strategies to retain 'high-quality'subsets of 'raw' scraped data. For instance, the LAION public dataset retainedonly 10% of the total crawled data. However, these strategies are typicallydeveloped agnostic of the available compute for training. In this paper, wefirst demonstrate that making filtering decisions independent of trainingcompute is often suboptimal: the limited high-quality data rapidly loses itsutility when repeated, eventually requiring the inclusion of 'unseen' but'lower-quality' data. To address this quality-quantity tradeoff($\texttt{QQT}$), we introduce neural scaling laws that account for thenon-homogeneous nature of web data, an angle ignored in existing literature.Our scaling laws (i) characterize the $\textit{differing}$ 'utility' of variousquality subsets of web data; (ii) account for how utility diminishes for a datapoint at its 'nth' repetition; and (iii) formulate the mutual interaction ofvarious data pools when combined, enabling the estimation of model performanceon a combination of multiple data pools without ever jointly training on them.Our key message is that data curation $\textit{cannot}$ be agnostic of thetotal compute that a model will be trained for. Our scaling laws allow us tocurate the best possible pool for achieving top performance on Datacomp atvarious compute budgets, carving out a pareto-frontier for data curation. Codeis available at https://github.com/locuslab/scaling_laws_data_filtering.</description><author>Sachin Goyal, Pratyush Maini, Zachary C. Lipton, Aditi Raghunathan, J. Zico Kolter</author><pubDate>Wed, 10 Apr 2024 18:27:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07177v1</guid></item><item><title>Self-supervised Monocular Depth Estimation on Water Scenes via Specular Reflection Prior</title><link>http://arxiv.org/abs/2404.07176v1</link><description>Monocular depth estimation from a single image is an ill-posed problem forcomputer vision due to insufficient reliable cues as the prior knowledge.Besides the inter-frame supervision, namely stereo and adjacent frames,extensive prior information is available in the same frame. Reflections fromspecular surfaces, informative intra-frame priors, enable us to reformulate theill-posed depth estimation task as a multi-view synthesis. This paper proposesthe first self-supervision for deep-learning depth estimation on water scenesvia intra-frame priors, known as reflection supervision and geometricalconstraints. In the first stage, a water segmentation network is performed toseparate the reflection components from the entire image. Next, we construct aself-supervised framework to predict the target appearance from reflections,perceived as other perspectives. The photometric re-projection error,incorporating SmoothL1 and a novel photometric adaptive SSIM, is formulated tooptimize pose and depth estimation by aligning the transformed virtual depthsand source ones. As a supplement, the water surface is determined from real andvirtual camera positions, which complement the depth of the water area.Furthermore, to alleviate these laborious ground truth annotations, weintroduce a large-scale water reflection scene (WRS) dataset rendered fromUnreal Engine 4. Extensive experiments on the WRS dataset prove the feasibilityof the proposed method compared to state-of-the-art depth estimationtechniques.</description><author>Zhengyang Lu, Ying Chen</author><pubDate>Wed, 10 Apr 2024 18:25:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07176v1</guid></item><item><title>Deep Learning for Inertial Sensor Alignment</title><link>http://arxiv.org/abs/2212.11120v2</link><description>Accurate alignment of a fixed mobile device equipped with inertial sensorsinside a moving vehicle is important for navigation, activity recognition, andother applications. Accurate estimation of the device mounting angle isrequired to rotate the inertial measurement from the sensor frame to the movingplatform frame to standardize measurements and improve the performance of thetarget task. In this work, a data-driven approach using deep neural networks(DNNs) is proposed to learn the yaw mounting angle of a smartphone equippedwith an inertial measurement unit (IMU) and strapped to a car. The proposedmodel uses only the accelerometer and gyroscope readings from an IMU as inputand, in contrast to existing solutions, does not require global position inputsfrom global navigation satellite systems (GNSS). To train the model in asupervised manner, IMU data is collected for training and validation with thesensor mounted at a known yaw mounting angle, and a range of ground truthlabels is generated by applying a random rotation in a bounded range to themeasurements. The trained model is tested on data with real rotations showingsimilar performance as with synthetic rotations. The trained model is deployedon an Android device and evaluated in real-time to test the accuracy of theestimated yaw mounting angle. The model is shown to find the mounting angle atan accuracy of 8 degrees within 5 seconds, and 4 degrees within 27 seconds. Anexperiment is conducted to compare the proposed model with an existingoff-the-shelf solution.</description><author>Maxim Freydin, Niv Sfaradi, Nimrod Segol, Areej Eweida, Barak Or</author><pubDate>Wed, 10 Apr 2024 18:15:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.11120v2</guid></item><item><title>A Gauss-Newton Approach for Min-Max Optimization in Generative Adversarial Networks</title><link>http://arxiv.org/abs/2404.07172v1</link><description>A novel first-order method is proposed for training generative adversarialnetworks (GANs). It modifies the Gauss-Newton method to approximate the min-maxHessian and uses the Sherman-Morrison inversion formula to calculate theinverse. The method corresponds to a fixed-point method that ensures necessarycontraction. To evaluate its effectiveness, numerical experiments are conductedon various datasets commonly used in image generation tasks, such as MNIST,Fashion MNIST, CIFAR10, FFHQ, and LSUN. Our method is capable of generatinghigh-fidelity images with greater diversity across multiple datasets. It alsoachieves the highest inception score for CIFAR10 among all compared methods,including state-of-the-art second-order methods. Additionally, its executiontime is comparable to that of first-order min-max methods.</description><author>Neel Mishra, Bamdev Mishra, Pratik Jawanpuria, Pawan Kumar</author><pubDate>Wed, 10 Apr 2024 18:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07172v1</guid></item><item><title>Worst-Case Convergence Time of ML Algorithms via Extreme Value Theory</title><link>http://arxiv.org/abs/2404.07170v1</link><description>This paper leverages the statistics of extreme values to predict theworst-case convergence times of machine learning algorithms. Timing is acritical non-functional property of ML systems, and providing the worst-caseconverge times is essential to guarantee the availability of ML and itsservices. However, timing properties such as worst-case convergence times(WCCT) are difficult to verify since (1) they are not encoded in the syntax orsemantics of underlying programming languages of AI, (2) their evaluationsdepend on both algorithmic implementations and underlying systems, and (3)their measurements involve uncertainty and noise. Therefore, prevalent formalmethods and statistical models fail to provide rich information on the amountsand likelihood of WCCT. Our key observation is that the timing information we seek represents theextreme tail of execution times. Therefore, extreme value theory (EVT), astatistical discipline that focuses on understanding and predicting thedistribution of extreme values in the tail of outcomes, provides an idealframework to model and analyze WCCT in the training and inference phases of MLparadigm. Building upon the mathematical tools from EVT, we propose a practicalframework to predict the worst-case timing properties of ML. Over a set oflinear ML training algorithms, we show that EVT achieves a better accuracy forpredicting WCCTs than relevant statistical methods such as the Bayesian factor.On the set of larger machine learning training algorithms and deep neuralnetwork inference, we show the feasibility and usefulness of EVT models toaccurately predict WCCTs, their expected return periods, and their likelihood.</description><author>Saeid Tizpaz-Niari, Sriram Sankaranarayanan</author><pubDate>Wed, 10 Apr 2024 18:05:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07170v1</guid></item><item><title>Using Neural Networks to Model Hysteretic Kinematics in Tendon-Actuated Continuum Robots</title><link>http://arxiv.org/abs/2404.07168v1</link><description>The ability to accurately model mechanical hysteretic behavior intendon-actuated continuum robots using deep learning approaches is a growingarea of interest. In this paper, we investigate the hysteretic response of twotypes of tendon-actuated continuum robots and, ultimately, compare three typesof neural network modeling approaches with both forward and inverse kinematicmappings: feedforward neural network (FNN), FNN with a history input buffer,and long short-term memory (LSTM) network. We seek to determine which modelbest captures temporal dependent behavior. We find that, depending on therobot's design, choosing different kinematic inputs can alter whetherhysteresis is exhibited by the system. Furthermore, we present the results ofthe model fittings, revealing that, in contrast to the standard FNN, both FNNwith a history input buffer and the LSTM model exhibit the capacity to modelhistorical dependence with comparable performance in capturing rate-dependenthysteresis.</description><author>Yuan Wang, Max McCandless, Abdulhamit Donder, Giovanni Pittiglio, Behnam Moradkhani, Yash Chitalia, Pierre E. Dupont</author><pubDate>Wed, 10 Apr 2024 18:04:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07168v1</guid></item><item><title>Analysis of Distributed Optimization Algorithms on a Real Processing-In-Memory System</title><link>http://arxiv.org/abs/2404.07164v1</link><description>Machine Learning (ML) training on large-scale datasets is a very expensiveand time-consuming workload. Processor-centric architectures (e.g., CPU, GPU)commonly used for modern ML training workloads are limited by the data movementbottleneck, i.e., due to repeatedly accessing the training dataset. As aresult, processor-centric systems suffer from performance degradation and highenergy consumption. Processing-In-Memory (PIM) is a promising solution toalleviate the data movement bottleneck by placing the computation mechanismsinside or near memory. Our goal is to understand the capabilities and characteristics of populardistributed optimization algorithms on real-world PIM architectures toaccelerate data-intensive ML training workloads. To this end, we 1) implementseveral representative centralized distributed optimization algorithms onUPMEM's real-world general-purpose PIM system, 2) rigorously evaluate thesealgorithms for ML training on large-scale datasets in terms of performance,accuracy, and scalability, 3) compare to conventional CPU and GPU baselines,and 4) discuss implications for future PIM hardware and the need to shift to analgorithm-hardware codesign perspective to accommodate decentralizeddistributed optimization algorithms. Our results demonstrate three major findings: 1) Modern general-purpose PIMarchitectures can be a viable alternative to state-of-the-art CPUs and GPUs formany memory-bound ML training workloads, when operations and datatypes arenatively supported by PIM hardware, 2) the importance of carefully choosing theoptimization algorithm that best fit PIM, and 3) contrary to popular belief,contemporary PIM architectures do not scale approximately linearly with thenumber of nodes for many data-intensive ML training workloads. To facilitatefuture research, we aim to open-source our complete codebase.</description><author>Steve Rhyner, Haocong Luo, Juan Gómez-Luna, Mohammad Sadrosadati, Jiawei Jiang, Ataberk Olgun, Harshita Gupta, Ce Zhang, Onur Mutlu</author><pubDate>Wed, 10 Apr 2024 18:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07164v1</guid></item><item><title>Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning</title><link>http://arxiv.org/abs/2311.15487v4</link><description>We consider the scenario of supervised learning in Deep Learning (DL)networks, and exploit the arbitrariness of choice in the Riemannian metricrelative to which the gradient descent flow can be defined (a general fact ofdifferential geometry). In the standard approach to DL, the gradient flow onthe space of parameters (weights and biases) is defined with respect to theEuclidean metric. Here instead, we choose the gradient flow with respect to theEuclidean metric in the output layer of the DL network. This naturally inducestwo modified versions of the gradient descent flow in the parameter space, oneadapted for the overparametrized setting, and the other for theunderparametrized setting. In the overparametrized case, we prove that,provided that a rank condition holds, all orbits of the modified gradientdescent drive the ${\mathcal L}^2$ cost to its global minimum at a uniformexponential convergence rate; one thereby obtains an a priori stopping time forany prescribed proximity to the global minimum. We point out relations of thelatter to sub-Riemannian geometry. Moreover, we generalize the above frameworkto the situation in which the rank condition does not hold; in particular, weshow that local equilibria can only exist if a rank loss occurs, and thatgenerically, they are not isolated points, but elements of a criticalsubmanifold of parameter space.</description><author>Thomas Chen</author><pubDate>Wed, 10 Apr 2024 17:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15487v4</guid></item><item><title>A Large-Scale Exploration of $μ$-Transfer</title><link>http://arxiv.org/abs/2404.05728v2</link><description>Large neural network models have become a mainstay of natural languageprocessing and computer vision, yet their initialization and learning rates areset in a largely heuristic fashion, potentially varying from paper to paper andone model size to the next. The $\mu$-Parameterization ($\mu$P) offers apotential solution to these challenges, yielding scaling rules for modelinitialization and learning rates, and reportedly enabling zero-shothyperparameter transfer from small to large models in a variety of cases. Despite the evident promise, the $\mu$P scaling rules are not yet widelyadopted, perhaps due to higher implementation complexity, many variations, orcomplex theoretical background. This work investigates $\mu$P empirically,focusing on the ubiquitous transformer architecture, and aims to answer asimple question: does $\mu$-Transfer yield optimal learning rates in practice?From models with 2M to 10B parameters, we show that $\mu$-Transfer works asintended for the majority of important cases, but also identify some surprisingcases where it may not. Our experiment codebase is available athttps://github.com/lucaslingle/mu_transformer/</description><author>Lucas Lingle</author><pubDate>Wed, 10 Apr 2024 17:55:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05728v2</guid></item><item><title>Exploring Physiological Responses in Virtual Reality-based Interventions for Autism Spectrum Disorder: A Data-Driven Investigation</title><link>http://arxiv.org/abs/2404.07159v1</link><description>Virtual Reality (VR) has emerged as a promising tool for enhancing socialskills and emotional well-being in individuals with Autism Spectrum Disorder(ASD). Through a technical exploration, this study employs a multiplayerserious gaming environment within VR, engaging 34 individuals diagnosed withASD and employing high-precision biosensors for a comprehensive view of theparticipants' arousal and responses during the VR sessions. Participants weresubjected to a series of 3 virtual scenarios designed in collaboration withstakeholders and clinical experts to promote socio-cognitive skills andemotional regulation in a controlled and structured virtual environment. Wecombined the framework with wearable non-invasive sensors for bio-signalacquisition, focusing on the collection of heart rate variability, andrespiratory patterns to monitor participants behaviors. Further, behavioralassessments were conducted using observation and semi-structured interviews,with the data analyzed in conjunction with physiological measures to identifycorrelations and explore digital-intervention efficacy. Preliminary analysisrevealed significant correlations between physiological responses andbehavioral outcomes, indicating the potential of physiological feedback toenhance VR-based interventions for ASD. The study demonstrated the feasibilityof using real-time data to adapt virtual scenarios, suggesting a promisingavenue to support personalized therapy. The integration of quantitativephysiological feedback into digital platforms represents a forward step in thepersonalized intervention for ASD. By leveraging real-time data to adjusttherapeutic content, this approach promises to enhance the efficacy andengagement of digital-based therapies.</description><author>Gianpaolo Alvari, Ersilia Vallefuoco, Melanie Cristofolini, Elio Salvadori, Marco Dianti, Alessia Moltani, Davide Dal Castello, Paola Venuti, Cesare Furlanello</author><pubDate>Wed, 10 Apr 2024 17:50:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07159v1</guid></item><item><title>Designing Interpretable ML System to Enhance Trust in Healthcare: A Systematic Review to Proposed Responsible Clinician-AI-Collaboration Framework</title><link>http://arxiv.org/abs/2311.11055v2</link><description>This paper explores the significant impact of AI-based medical devices,including wearables, telemedicine, large language models, and digital twins, onclinical decision support systems. It emphasizes the importance of producingoutcomes that are not only accurate but also interpretable and understandableto clinicians, addressing the risk that lack of interpretability poses in termsof mistrust and reluctance to adopt these technologies in healthcare. The paperreviews interpretable AI processes, methods, applications, and the challengesof implementation in healthcare, focusing on quality control to facilitateresponsible communication between AI systems and clinicians. It breaks down theinterpretability process into data pre-processing, model selection, andpost-processing, aiming to foster a comprehensive understanding of the crucialrole of a robust interpretability approach in healthcare and to guide futureresearch in this area. with insights for creating responsible clinician-AItools for healthcare, as well as to offer a deeper understanding of thechallenges they might face. Our research questions, eligibility criteria andprimary goals were identified using Preferred Reporting Items for Systematicreviews and Meta-Analyses guideline and PICO method; PubMed, Scopus and Web ofScience databases were systematically searched using sensitive and specificsearch strings. In the end, 52 publications were selected for data extractionwhich included 8 existing reviews and 44 related experimental studies. Thepaper offers general concepts of interpretable AI in healthcare and discussthree-levels interpretability process. Additionally, it provides acomprehensive discussion of evaluating robust interpretability AI inhealthcare. Moreover, this survey introduces a step-by-step roadmap forimplementing responsible AI in healthcare.</description><author>Elham Nasarian, Roohallah Alizadehsani, U. Rajendra Acharya, Kwok-Leung Tsui</author><pubDate>Wed, 10 Apr 2024 17:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11055v2</guid></item><item><title>Unified Language-driven Zero-shot Domain Adaptation</title><link>http://arxiv.org/abs/2404.07155v1</link><description>This paper introduces Unified Language-driven Zero-shot Domain Adaptation(ULDA), a novel task setting that enables a single model to adapt to diversetarget domains without explicit domain-ID knowledge. We identify theconstraints in the existing language-driven zero-shot domain adaptation task,particularly the requirement for domain IDs and domain-specific models, whichmay restrict flexibility and scalability. To overcome these issues, we proposea new framework for ULDA, consisting of Hierarchical Context Alignment (HCA),Domain Consistent Representation Learning (DCRL), and Text-Driven Rectifier(TDR). These components work synergistically to align simulated features withtarget text across multiple visual levels, retain semantic correlations betweendifferent regional representations, and rectify biases between simulated andreal target visual features, respectively. Our extensive empirical evaluationsdemonstrate that this framework achieves competitive performance in bothsettings, surpassing even the model that requires domain-ID, showcasing itssuperiority and generalization ability. The proposed method is not onlyeffective but also maintains practicality and efficiency, as it does notintroduce additional computational costs during inference. Our project page ishttps://senqiaoyang.com/project/ULDA .</description><author>Senqiao Yang, Zhuotao Tian, Li Jiang, Jiaya Jia</author><pubDate>Wed, 10 Apr 2024 17:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07155v1</guid></item><item><title>Streamlining Ocean Dynamics Modeling with Fourier Neural Operators: A Multiobjective Hyperparameter and Architecture Optimization Approach</title><link>http://arxiv.org/abs/2404.05768v2</link><description>Training an effective deep learning model to learn ocean processes involvescareful choices of various hyperparameters. We leverage the advanced searchalgorithms for multiobjective optimization in DeepHyper, a scalablehyperparameter optimization software, to streamline the development of neuralnetworks tailored for ocean modeling. The focus is on optimizing Fourier neuraloperators (FNOs), a data-driven model capable of simulating complex oceanbehaviors. Selecting the correct model and tuning the hyperparameters arechallenging tasks, requiring much effort to ensure model accuracy. DeepHyperallows efficient exploration of hyperparameters associated with datapreprocessing, FNO architecture-related hyperparameters, and various modeltraining strategies. We aim to obtain an optimal set of hyperparameters leadingto the most performant model. Moreover, on top of the commonly used meansquared error for model training, we propose adopting the negative anomalycorrelation coefficient as the additional loss term to improve modelperformance and investigate the potential trade-off between the two terms. Theexperimental results show that the optimal set of hyperparameters enhancedmodel performance in single timestepping forecasting and greatly exceeded thebaseline configuration in the autoregressive rollout for long-horizonforecasting up to 30 days. Utilizing DeepHyper, we demonstrate an approach toenhance the use of FNOs in ocean dynamics forecasting, offering a scalablesolution with improved precision.</description><author>Yixuan Sun, Ololade Sowunmi, Romain Egele, Sri Hari Krishna Narayanan, Luke Van Roekel, Prasanna Balaprakash</author><pubDate>Wed, 10 Apr 2024 17:41:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05768v2</guid></item><item><title>Lost in Translation: Modern Neural Networks Still Struggle With Small Realistic Image Transformations</title><link>http://arxiv.org/abs/2404.07153v1</link><description>Deep neural networks that achieve remarkable performance in imageclassification have previously been shown to be easily fooled by tinytransformations such as a one pixel translation of the input image. In order toaddress this problem, two approaches have been proposed in recent years. Thefirst approach suggests using huge datasets together with data augmentation inthe hope that a highly varied training set will teach the network to learn tobe invariant. The second approach suggests using architectural modificationsbased on sampling theory to deal explicitly with image translations. In thispaper, we show that these approaches still fall short in robustly handling'natural' image translations that simulate a subtle change in cameraorientation. Our findings reveal that a mere one-pixel translation can resultin a significant change in the predicted image representation for approximately40% of the test images in state-of-the-art models (e.g. open-CLIP trained onLAION-2B or DINO-v2) , while models that are explicitly constructed to berobust to cyclic translations can still be fooled with 1 pixel realistic(non-cyclic) translations 11% of the time. We present Robust Inference by CropSelection: a simple method that can be proven to achieve any desired level ofconsistency, although with a modest tradeoff with the model's accuracy.Importantly, we demonstrate how employing this method reduces the ability tofool state-of-the-art models with a 1 pixel translation to less than 5% whilesuffering from only a 1% drop in classification accuracy. Additionally, we showthat our method can be easy adjusted to deal with circular shifts as well. Insuch case we achieve 100% robustness to integer shifts with state-of-the-artaccuracy, and with no need for any further training.</description><author>Ofir Shifman, Yair Weiss</author><pubDate>Wed, 10 Apr 2024 17:39:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07153v1</guid></item><item><title>Algorithms for Caching and MTS with reduced number of predictions</title><link>http://arxiv.org/abs/2404.06280v2</link><description>ML-augmented algorithms utilize predictions to achieve performance beyondtheir worst-case bounds. Producing these predictions might be a costlyoperation -- this motivated Im et al. '22 to introduce the study of algorithmswhich use predictions parsimoniously. We design parsimonious algorithms forcaching and MTS with action predictions, proposed by Antoniadis et al. '20,focusing on the parameters of consistency (performance with perfectpredictions) and smoothness (dependence of their performance on the predictionerror). Our algorithm for caching is 1-consistent, robust, and its smoothnessdeteriorates with the decreasing number of available predictions. We propose analgorithm for general MTS whose consistency and smoothness both scale linearlywith the decreasing number of predictions. Without the restriction on thenumber of available predictions, both algorithms match the earlier guaranteesachieved by Antoniadis et al. '20.</description><author>Karim Abdel Sadek, Marek Elias</author><pubDate>Wed, 10 Apr 2024 17:30:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06280v2</guid></item><item><title>How Consistent are Clinicians? Evaluating the Predictability of Sepsis Disease Progression with Dynamics Models</title><link>http://arxiv.org/abs/2404.07148v1</link><description>Reinforcement learning (RL) is a promising approach to generate treatmentpolicies for sepsis patients in intensive care. While retrospective evaluationmetrics show decreased mortality when these policies are followed, studies withclinicians suggest their recommendations are often spurious. We propose thatthese shortcomings may be due to lack of diversity in observed actions andoutcomes in the training data, and we construct experiments to investigate thefeasibility of predicting sepsis disease severity changes due to clinicianactions. Preliminary results suggest incorporating action information does notsignificantly improve model performance, indicating that clinician actions maynot be sufficiently variable to yield measurable effects on diseaseprogression. We discuss the implications of these findings for optimizingsepsis treatment.</description><author>Unnseo Park, Venkatesh Sivaraman, Adam Perer</author><pubDate>Wed, 10 Apr 2024 17:29:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07148v1</guid></item><item><title>Local Causal Discovery for Estimating Causal Effects</title><link>http://arxiv.org/abs/2302.08070v4</link><description>Even when the causal graph underlying our data is unknown, we can useobservational data to narrow down the possible values that an average treatmenteffect (ATE) can take by (1) identifying the graph up to a Markov equivalenceclass; and (2) estimating that ATE for each graph in the class. While the PCalgorithm can identify this class under strong faithfulness assumptions, it canbe computationally prohibitive. Fortunately, only the local graph structurearound the treatment is required to identify the set of possible ATE values, afact exploited by local discovery algorithms to improve computationalefficiency. In this paper, we introduce Local Discovery using Eager ColliderChecks (LDECC), a new local causal discovery algorithm that leveragesunshielded colliders to orient the treatment's parents differently fromexisting methods. We show that there exist graphs where LDECC exponentiallyoutperforms existing local discovery algorithms and vice versa. Moreover, weshow that LDECC and existing algorithms rely on different faithfulnessassumptions, leveraging this insight to weaken the assumptions for identifyingthe set of possible ATE values.</description><author>Shantanu Gupta, David Childers, Zachary C. Lipton</author><pubDate>Wed, 10 Apr 2024 17:22:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08070v4</guid></item><item><title>Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</title><link>http://arxiv.org/abs/2404.07143v1</link><description>This work introduces an efficient method to scale Transformer-based LargeLanguage Models (LLMs) to infinitely long inputs with bounded memory andcomputation. A key component in our proposed approach is a new attentiontechnique dubbed Infini-attention. The Infini-attention incorporates acompressive memory into the vanilla attention mechanism and builds in bothmasked local attention and long-term linear attention mechanisms in a singleTransformer block. We demonstrate the effectiveness of our approach onlong-context language modeling benchmarks, 1M sequence length passkey contextblock retrieval and 500K length book summarization tasks with 1B and 8B LLMs.Our approach introduces minimal bounded memory parameters and enables faststreaming inference for LLMs.</description><author>Tsendsuren Munkhdalai, Manaal Faruqui, Siddharth Gopal</author><pubDate>Wed, 10 Apr 2024 17:18:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07143v1</guid></item><item><title>Towards a Game-theoretic Understanding of Explanation-based Membership Inference Attacks</title><link>http://arxiv.org/abs/2404.07139v1</link><description>Model explanations improve the transparency of black-box machine learning(ML) models and their decisions; however, they can also be exploited to carryout privacy threats such as membership inference attacks (MIA). Existing workshave only analyzed MIA in a single "what if" interaction scenario between anadversary and the target ML model; thus, it does not discern the factorsimpacting the capabilities of an adversary in launching MIA in repeatedinteraction settings. Additionally, these works rely on assumptions about theadversary's knowledge of the target model's structure and, thus, do notguarantee the optimality of the predefined threshold required to distinguishthe members from non-members. In this paper, we delve into the domain ofexplanation-based threshold attacks, where the adversary endeavors to carry outMIA attacks by leveraging the variance of explanations through iterativeinteractions with the system comprising of the target ML model and itscorresponding explanation method. We model such interactions by employing acontinuous-time stochastic signaling game framework. In our framework, anadversary plays a stopping game, interacting with the system (having imperfectinformation about the type of an adversary, i.e., honest or malicious) toobtain explanation variance information and computing an optimal threshold todetermine the membership of a datapoint accurately. First, we propose a soundmathematical formulation to prove that such an optimal threshold exists, whichcan be used to launch MIA. Then, we characterize the conditions under which aunique Markov perfect equilibrium (or steady state) exists in this dynamicsystem. By means of a comprehensive set of simulations of the proposed gamemodel, we assess different factors that can impact the capability of anadversary to launch MIA in such repeated interaction settings.</description><author>Kavita Kumari, Murtuza Jadliwala, Sumit Kumar Jha, Anindya Maiti</author><pubDate>Wed, 10 Apr 2024 17:14:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07139v1</guid></item><item><title>Towards Robustness of Text-to-Visualization Translation against Lexical and Phrasal Variability</title><link>http://arxiv.org/abs/2404.07135v1</link><description>Text-to-Vis is an emerging task in the natural language processing (NLP) areathat aims to automatically generate data visualizations from natural languagequestions (NLQs). Despite their progress, existing text-to-vis models oftenheavily rely on lexical matching between words in the questions and tokens indata schemas. This overreliance on lexical matching may lead to a diminishedlevel of model robustness against input variations. In this study, wethoroughly examine the robustness of current text-to-vis models, an area thathas not previously been explored. In particular, we construct the firstrobustness dataset nvBench-Rob, which contains diverse lexical and phrasalvariations based on the original text-to-vis benchmark nvBench. Then, we foundthat the performance of existing text-to-vis models on this new datasetdramatically drops, implying that these methods exhibit inadequate robustnessoverall. Finally, we propose a novel framework based on Retrieval-AugmentedGeneration (RAG) technique, named GRED, specifically designed to address inputperturbations in these two variants. The framework consists of three parts:NLQ-Retrieval Generator, Visualization Query-Retrieval Retuner andAnnotation-based Debugger, which are used to tackle the challenges posed bynatural language variants, programming style differences and data schemavariants, respectively. Extensive experimental evaluations show that, comparedto the state-of-the-art model RGVisNet in the Text-to-Vis field, RGDR performsbetter in terms of model robustness, with a 32% increase in accuracy on theproposed nvBench-Rob dataset.</description><author>Jinwei Lu, Yuanfeng Song, Haodi Zhang, Chen Zhang, Raymond Chi-Wing Wong</author><pubDate>Wed, 10 Apr 2024 17:12:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07135v1</guid></item><item><title>What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation</title><link>http://arxiv.org/abs/2404.07129v1</link><description>In-context learning is a powerful emergent ability in transformer models.Prior work in mechanistic interpretability has identified a circuit elementthat may be critical for in-context learning -- the induction head (IH), whichperforms a match-and-copy operation. During training of large transformers onnatural language data, IHs emerge around the same time as a notable phasechange in the loss. Despite the robust evidence for IHs and this interestingcoincidence with the phase change, relatively little is known about thediversity and emergence dynamics of IHs. Why is there more than one IH, and howare they dependent on each other? Why do IHs appear all of a sudden, and whatare the subcircuits that enable them to emerge? We answer these questions bystudying IH emergence dynamics in a controlled setting by training on syntheticdata. In doing so, we develop and share a novel optogenetics-inspired causalframework for modifying activations throughout training. Using this framework,we delineate the diverse and additive nature of IHs. By clamping subsets ofactivations throughout training, we then identify three underlying subcircuitsthat interact to drive IH formation, yielding the phase change. Furthermore,these subcircuits shed light on data-dependent properties of formation, such asphase change timing, already showing the promise of this more in-depthunderstanding of subcircuits that need to "go right" for an induction head.</description><author>Aaditya K. Singh, Ted Moskovitz, Felix Hill, Stephanie C. Y. Chan, Andrew M. Saxe</author><pubDate>Wed, 10 Apr 2024 17:07:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07129v1</guid></item><item><title>GLiDR: Topologically Regularized Graph Generative Network for Sparse LiDAR Point Clouds</title><link>http://arxiv.org/abs/2312.00068v2</link><description>Sparse LiDAR point clouds cause severe loss of detail of static structuresand reduce the density of static points available for navigation. Reduceddensity can be detrimental to navigation under several scenarios. We observethat despite high sparsity, in most cases, the global topology of LiDARoutlining the static structures can be inferred. We utilize this property toobtain a backbone skeleton of a LiDAR scan in the form of a single connectedcomponent that is a proxy to its global topology. We utilize the backbone toaugment new points along static structures to overcome sparsity. Newlyintroduced points could correspond to existing static structures or to staticpoints that were earlier obstructed by dynamic objects. To the best of ourknowledge, we are the first to use such a strategy for sparse LiDAR pointclouds. Existing solutions close to our approach fail to identify and preservethe global static LiDAR topology and generate sub-optimal points. We proposeGLiDR, a Graph Generative network that is topologically regularized using0-dimensional Persistent Homology ($\mathcal{PH}$) constraints. This enablesGLiDR to introduce newer static points along a topologically consistent globalstatic LiDAR backbone. GLiDR generates precise static points using $32\times$sparser dynamic scans and performs better than the baselines across threedatasets. GLiDR generates a valuable byproduct - an accurate binarysegmentation mask of static and dynamic objects that are helpful for navigationplanning and safety in constrained environments. The newly introduced staticpoints allow GLiDR to outperform LiDAR-based navigation using SLAM in severalsettings. Source code is available at$\texttt{https://github.com/GLiDR-CVPR2024/GLiDR}$.</description><author>Prashant Kumar, Kshitij Madhav Bhat, Vedang Bhupesh Shenvi Nadkarni, Prem Kalra</author><pubDate>Wed, 10 Apr 2024 17:04:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00068v2</guid></item><item><title>Measuring proximity to standard planes during fetal brain ultrasound scanning</title><link>http://arxiv.org/abs/2404.07124v1</link><description>This paper introduces a novel pipeline designed to bring ultrasound (US)plane pose estimation closer to clinical use for more effective navigation tothe standard planes (SPs) in the fetal brain. We propose a semi-supervisedsegmentation model utilizing both labeled SPs and unlabeled 3D US volumeslices. Our model enables reliable segmentation across a diverse set of fetalbrain images. Furthermore, the model incorporates a classification mechanism toidentify the fetal brain precisely. Our model not only filters out frameslacking the brain but also generates masks for those containing it, enhancingthe relevance of plane pose regression in clinical settings. We focus on fetalbrain navigation from 2D ultrasound (US) video analysis and combine this modelwith a US plane pose regression network to provide sensorless proximitydetection to SPs and non-SPs planes; we emphasize the importance of proximitydetection to SPs for guiding sonographers, offering a substantial advantageover traditional methods by allowing earlier and more precise adjustmentsduring scanning. We demonstrate the practical applicability of our approachthrough validation on real fetal scan videos obtained from sonographers ofvarying expertise levels. Our findings demonstrate the potential of ourapproach to complement existing fetal US technologies and advance prenataldiagnostic practices.</description><author>Chiara Di Vece, Antonio Cirigliano, Meala Le Lous, Raffaele Napolitano, Anna L. David, Donald Peebles, Pierre Jannin, Francisco Vasconcelos, Danail Stoyanov</author><pubDate>Wed, 10 Apr 2024 17:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07124v1</guid></item><item><title>Semantically-correlated memories in a dense associative model</title><link>http://arxiv.org/abs/2404.07123v1</link><description>I introduce a novel associative memory model named Correlated DenseAssociative Memory (CDAM), which integrates both auto- and hetero-associationin a unified framework for continuous-valued memory patterns. Employing anarbitrary graph structure to semantically link memory patterns, CDAM istheoretically and numerically analysed, revealing four distinct dynamicalmodes: auto-association, narrow hetero-association, wide hetero-association,and neutral quiescence. Drawing inspiration from inhibitory modulation studies,I employ anti-Hebbian learning rules to control the range ofhetero-association, extract multi-scale representations of community structuresin graphs, and stabilise the recall of temporal sequences. Experimentaldemonstrations showcase CDAM's efficacy in handling real-world data,replicating a classical neuroscience experiment, performing image retrieval,and simulating arbitrary finite automata.</description><author>Thomas F Burns</author><pubDate>Wed, 10 Apr 2024 17:04:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07123v1</guid></item><item><title>Driver Attention Tracking and Analysis</title><link>http://arxiv.org/abs/2404.07122v1</link><description>We propose a novel method to estimate a driver's points-of-gaze using a pairof ordinary cameras mounted on the windshield and dashboard of a car. This is achallenging problem due to the dynamics of traffic environments with 3D scenesof unknown depths. This problem is further complicated by the volatile distancebetween the driver and the camera system. To tackle these challenges, wedevelop a novel convolutional network that simultaneously analyzes the image ofthe scene and the image of the driver's face. This network has a cameracalibration module that can compute an embedding vector that represents thespatial configuration between the driver and the camera system. Thiscalibration module improves the overall network's performance, which can bejointly trained end to end. We also address the lack of annotated data for training and evaluation byintroducing a large-scale driving dataset with point-of-gaze annotations. Thisis an in situ dataset of real driving sessions in an urban city, containingsynchronized images of the driving scene as well as the face and gaze of thedriver. Experiments on this dataset show that the proposed method outperformsvarious baseline methods, having the mean prediction error of 29.69 pixels,which is relatively small compared to the $1280{\times}720$ resolution of thescene camera.</description><author>Dat Viet Thanh Nguyen, Anh Tran, Nam Vu, Cuong Pham, Minh Hoai</author><pubDate>Wed, 10 Apr 2024 17:01:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07122v1</guid></item><item><title>CLOVA: A Closed-Loop Visual Assistant with Tool Usage and Update</title><link>http://arxiv.org/abs/2312.10908v3</link><description>Utilizing large language models (LLMs) to compose off-the-shelf visual toolsrepresents a promising avenue of research for developing robust visualassistants capable of addressing diverse visual tasks. However, these methodsoften overlook the potential for continual learning, typically by freezing theutilized tools, thus limiting their adaptation to environments requiring newknowledge. To tackle this challenge, we propose CLOVA, a Closed-Loop VisualAssistant, which operates within a framework encompassing inference,reflection, and learning phases. During the inference phase, LLMs generateprograms and execute corresponding tools to complete assigned tasks. In thereflection phase, a multimodal global-local reflection scheme analyzes humanfeedback to determine which tools require updating. Lastly, the learning phaseemploys three flexible approaches to automatically gather training data andintroduces a novel prompt tuning scheme to update the tools, allowing CLOVA toefficiently acquire new knowledge. Experimental findings demonstrate that CLOVAsurpasses existing tool-usage methods by 5% in visual question answering andmultiple-image reasoning, by 10% in knowledge tagging, and by 20% in imageediting. These results underscore the significance of the continual learningcapability in general visual assistants.</description><author>Zhi Gao, Yuntao Du, Xintong Zhang, Xiaojian Ma, Wenjuan Han, Song-Chun Zhu, Qing Li</author><pubDate>Wed, 10 Apr 2024 16:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10908v3</guid></item><item><title>Bias-Reduced Neural Networks for Parameter Estimation in Quantitative MRI</title><link>http://arxiv.org/abs/2312.11468v3</link><description>Purpose: To develop neural network (NN)-based quantitative MRI parameterestimators with minimal bias and a variance close to the Cram\'er-Rao bound. Theory and Methods: We generalize the mean squared error loss to control thebias and variance of the NN's estimates, which involves averaging over multiplenoise realizations of the same measurements during training. Bias and varianceproperties of the resulting NNs are studied for two neuroimaging applications. Results: In simulations, the proposed strategy reduces the estimates' biasthroughout parameter space and achieves a variance close to the Cram\'er-Raobound. In vivo, we observe good concordance between parameter maps estimatedwith the proposed NNs and traditional estimators, such as non-linearleast-squares fitting, while state-of-the-art NNs show larger deviations. Conclusion: The proposed NNs have greatly reduced bias compared to thosetrained using the mean squared error and offer significantly improvedcomputational efficiency over traditional estimators with comparable or betteraccuracy.</description><author>Andrew Mao, Sebastian Flassbeck, Jakob Assländer</author><pubDate>Wed, 10 Apr 2024 16:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11468v3</guid></item><item><title>Continuous Language Model Interpolation for Dynamic and Controllable Text Generation</title><link>http://arxiv.org/abs/2404.07117v1</link><description>As large language models (LLMs) have gained popularity for a variety of usecases, making them adaptable and controllable has become increasinglyimportant, especially for user-facing applications. While the existingliterature on LLM adaptation primarily focuses on finding a model (or models)that optimizes a single predefined objective, here we focus on the challengingcase where the model must dynamically adapt to diverse -- and often changing --user preferences. For this, we leverage adaptation methods based on linearweight interpolation, casting them as continuous multi-domain interpolatorsthat produce models with specific prescribed generation characteristicson-the-fly. Specifically, we use low-rank updates to fine-tune a base model tovarious different domains, yielding a set of anchor models with distinctgeneration profiles. Then, we use the weight updates of these anchor models toparametrize the entire (infinite) class of models contained within their convexhull. We empirically show that varying the interpolation weights yieldspredictable and consistent change in the model outputs with respect to all ofthe controlled attributes. We find that there is little entanglement betweenmost attributes and identify and discuss the pairs of attributes for which thisis not the case. Our results suggest that linearly interpolating between theweights of fine-tuned models facilitates predictable, fine-grained control ofmodel outputs with respect to multiple stylistic characteristicssimultaneously.</description><author>Sara Kangaslahti, David Alvarez-Melis</author><pubDate>Wed, 10 Apr 2024 16:55:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07117v1</guid></item><item><title>Unfolding ADMM for Enhanced Subspace Clustering of Hyperspectral Images</title><link>http://arxiv.org/abs/2404.07112v1</link><description>Deep subspace clustering methods are now prominent in clustering, typicallyusing fully connected networks and a self-representation loss function.However, these methods often struggle with overfitting and lackinterpretability. In this paper, we explore an alternative clustering approachbased on deep unfolding. By unfolding iterative optimization methods intoneural networks, this approach offers enhanced interpretability and reliabilitycompared to data-driven deep learning methods, and greater adaptability andgeneralization than model-based approaches. Hence, unfolding has become widelyused in inverse imaging problems, such as image restoration, reconstruction,and super-resolution, but has not been sufficiently explored yet in the contextof clustering. In this work, we introduce an innovative clustering architecturefor hyperspectral images (HSI) by unfolding an iterative solver based on theAlternating Direction Method of Multipliers (ADMM) for sparse subspaceclustering. To our knowledge, this is the first attempt to apply unfolding ADMMfor computing the self-representation matrix in subspace clustering. Moreover,our approach captures well the structural characteristics of HSI data byemploying the K nearest neighbors algorithm as part of a structure preservationmodule. Experimental evaluation of three established HSI datasets shows clearlythe potential of the unfolding approach in HSI clustering and even demonstratessuperior performance compared to state-of-the-art techniques.</description><author>Xianlu Li, Nicolas Nadisic, Shaoguang Huang, Aleksandra Pižurica</author><pubDate>Wed, 10 Apr 2024 16:51:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07112v1</guid></item><item><title>Wild Visual Navigation: Fast Traversability Learning via Pre-Trained Models and Online Self-Supervision</title><link>http://arxiv.org/abs/2404.07110v1</link><description>Natural environments such as forests and grasslands are challenging forrobotic navigation because of the false perception of rigid obstacles from highgrass, twigs, or bushes. In this work, we present Wild Visual Navigation (WVN),an online self-supervised learning system for visual traversability estimation.The system is able to continuously adapt from a short human demonstration inthe field, only using onboard sensing and computing. One of the key ideas toachieve this is the use of high-dimensional features from pre-trainedself-supervised models, which implicitly encode semantic information thatmassively simplifies the learning task. Further, the development of an onlinescheme for supervision generator enables concurrent training and inference ofthe learned model in the wild. We demonstrate our approach through diversereal-world deployments in forests, parks, and grasslands. Our system is able tobootstrap the traversable terrain segmentation in less than 5 min of in-fieldtraining time, enabling the robot to navigate in complex, previously unseenoutdoor terrains. Code: https://bit.ly/498b0CV - Projectpage:https://bit.ly/3M6nMHH</description><author>Matías Mattamala, Jonas Frey, Piotr Libera, Nived Chebrolu, Georg Martius, Cesar Cadena, Marco Hutter, Maurice Fallon</author><pubDate>Wed, 10 Apr 2024 16:47:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07110v1</guid></item><item><title>From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications</title><link>http://arxiv.org/abs/2404.07108v1</link><description>Evaluating large language models (LLMs) is fundamental, particularly in thecontext of practical applications. Conventional evaluation methods, typicallydesigned primarily for LLM development, yield numerical scores that ignore theuser experience. Therefore, our study shifts the focus from model-centered tohuman-centered evaluation in the context of AI-powered writing assistanceapplications. Our proposed metric, termed ``Revision Distance,'' utilizes LLMsto suggest revision edits that mimic the human writing process. It isdetermined by counting the revision edits generated by LLMs. Benefiting fromthe generated revision edit details, our metric can provide a self-explainedtext evaluation result in a human-understandable manner beyond thecontext-independent score. Our results show that for the easy-writing task,``Revision Distance'' is consistent with established metrics (ROUGE,Bert-score, and GPT-score), but offers more insightful, detailed feedback andbetter distinguishes between texts. Moreover, in the context of challengingacademic writing tasks, our metric still delivers reliable evaluations whereother metrics tend to struggle. Furthermore, our metric also holds significantpotential for scenarios lacking reference texts.</description><author>Yongqiang Ma, Lizhi Qin, Jiawei Liu, Yangyang Kang, Yue Zhang, Wei Lu, Xiaozhong Liu, Qikai Cheng</author><pubDate>Wed, 10 Apr 2024 16:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07108v1</guid></item><item><title>3DMambaComplete: Exploring Structured State Space Model for Point Cloud Completion</title><link>http://arxiv.org/abs/2404.07106v1</link><description>Point cloud completion aims to generate a complete and high-fidelity pointcloud from an initially incomplete and low-quality input. A prevalent strategyinvolves leveraging Transformer-based models to encode global features andfacilitate the reconstruction process. However, the adoption of poolingoperations to obtain global feature representations often results in the lossof local details within the point cloud. Moreover, the attention mechanisminherent in Transformers introduces additional computational complexity,rendering it challenging to handle long sequences effectively. To address theseissues, we propose 3DMambaComplete, a point cloud completion network built onthe novel Mamba framework. It comprises three modules: HyperPoint Generationencodes point cloud features using Mamba's selection mechanism and predicts aset of Hyperpoints. A specific offset is estimated, and the down-sampled pointsbecome HyperPoints. The HyperPoint Spread module disperses these HyperPointsacross different spatial locations to avoid concentration. Finally, adeformation method transforms the 2D mesh representation of HyperPoints into afine-grained 3D structure for point cloud reconstruction. Extensive experimentsconducted on various established benchmarks demonstrate that 3DMambaCompletesurpasses state-of-the-art point cloud completion methods, as confirmed byqualitative and quantitative analyses.</description><author>Yixuan Li, Weidong Yang, Ben Fei</author><pubDate>Wed, 10 Apr 2024 16:45:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07106v1</guid></item><item><title>Dual Prompt Tuning for Domain-Aware Federated Learning</title><link>http://arxiv.org/abs/2310.03103v4</link><description>Federated learning is a distributed machine learning paradigm that allowsmultiple clients to collaboratively train a shared model with their local data.Nonetheless, conventional federated learning algorithms often struggle togeneralize well due to the ubiquitous domain shift across clients. In thiswork, we consider a challenging yet realistic federated learning scenario wherethe training data of each client originates from different domains. We addressthe challenges of domain shift by leveraging the technique of prompt learning,and propose a novel method called Federated Dual Prompt Tuning (Fed-DPT).Specifically, Fed-DPT employs a pre-trained vision-language model and thenapplies both visual and textual prompt tuning to facilitate domain adaptationover decentralized data. Extensive experiments of Fed-DPT demonstrate itssignificant effectiveness in domain-aware federated learning. With apre-trained CLIP model (ViT-Base as image encoder), the proposed Fed-DPTattains 68.4% average accuracy over six domains in the DomainNet dataset, whichimproves the original CLIP by a large margin of 14.8%.</description><author>Guoyizhe Wei, Feng Wang, Anshul Shah, Rama Chellappa</author><pubDate>Wed, 10 Apr 2024 16:44:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03103v4</guid></item><item><title>Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs</title><link>http://arxiv.org/abs/2404.07103v1</link><description>Large language models (LLMs), while exhibiting exceptional performance,suffer from hallucinations, especially on knowledge-intensive tasks. Existingworks propose to augment LLMs with individual text units retrieved fromexternal knowledge corpora to alleviate the issue. However, in many domains,texts are interconnected (e.g., academic papers in a bibliographic graph arelinked by citations and co-authorships) which form a (text-attributed) graph.The knowledge in such graphs is encoded not only in single texts/nodes but alsoin their associated connections. To facilitate the research of augmenting LLMswith graphs, we manually construct a Graph Reasoning Benchmark dataset calledGRBench, containing 1,740 questions that can be answered with the knowledgefrom 10 domain graphs. Then, we propose a simple and effective framework calledGraph Chain-of-thought (Graph-CoT) to augment LLMs with graphs by encouragingLLMs to reason on the graph iteratively. Each Graph-CoT iteration consists ofthree sub-steps: LLM reasoning, LLM-graph interaction, and graph execution. Weconduct systematic experiments with three LLM backbones on GRBench, whereGraph-CoT outperforms the baselines consistently. The code is available athttps://github.com/PeterGriffinJin/Graph-CoT.</description><author>Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Suhang Wang, Yu Meng, Jiawei Han</author><pubDate>Wed, 10 Apr 2024 16:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07103v1</guid></item><item><title>Rethinking Out-of-Distribution Detection for Reinforcement Learning: Advancing Methods for Evaluation and Detection</title><link>http://arxiv.org/abs/2404.07099v1</link><description>While reinforcement learning (RL) algorithms have been successfully appliedacross numerous sequential decision-making problems, their generalization tounforeseen testing environments remains a significant concern. In this paper,we study the problem of out-of-distribution (OOD) detection in RL, whichfocuses on identifying situations at test time that RL agents have notencountered in their training environments. We first propose a clarification ofterminology for OOD detection in RL, which aligns it with the literature fromother machine learning domains. We then present new benchmark scenarios for OODdetection, which introduce anomalies with temporal autocorrelation intodifferent components of the agent-environment loop. We argue that suchscenarios have been understudied in the current literature, despite theirrelevance to real-world situations. Confirming our theoretical predictions, ourexperimental results suggest that state-of-the-art OOD detectors are not ableto identify such anomalies. To address this problem, we propose a novel methodfor OOD detection, which we call DEXTER (Detection via Extraction of TimeSeries Representations). By treating environment observations as time seriesdata, DEXTER extracts salient time series features, and then leverages anensemble of isolation forest algorithms to detect anomalies. We find thatDEXTER can reliably identify anomalies across benchmark scenarios, exhibitingsuperior performance compared to both state-of-the-art OOD detectors andhigh-dimensional changepoint detectors adopted from statistics.</description><author>Linas Nasvytis, Kai Sandbrink, Jakob Foerster, Tim Franzmeyer, Christian Schroeder de Witt</author><pubDate>Wed, 10 Apr 2024 16:39:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07099v1</guid></item><item><title>In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax</title><link>http://arxiv.org/abs/2311.07811v2</link><description>In-context learning (ICL) is now a common method for teaching large languagemodels (LLMs) new tasks: given labeled examples in the input context, the LLMlearns to perform the task without weight updates. Do models guided via ICLinfer the underlying structure of the task defined by the context, or do theyrely on superficial heuristics that only generalize to identically distributedexamples? We address this question using transformations tasks and an NLI taskthat assess sensitivity to syntax - a requirement for robust languageunderstanding. We further investigate whether out-of-distributiongeneralization can be improved via chain-of-thought prompting, where the modelis provided with a sequence of intermediate computation steps that illustratehow the task ought to be performed. In experiments with models from the GPT,PaLM, and Llama 2 families, we find large variance across LMs. The variance isexplained more by the composition of the pre-training corpus and supervisionmethods than by model size; in particular, models pre-trained on codegeneralize better, and benefit more from chain-of-thought prompting.</description><author>Aaron Mueller, Albert Webson, Jackson Petty, Tal Linzen</author><pubDate>Wed, 10 Apr 2024 16:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07811v2</guid></item><item><title>Learning Priors for Non Rigid SfM from Casual Videos</title><link>http://arxiv.org/abs/2404.07097v1</link><description>We tackle the long-standing challenge of reconstructing 3D structures andcamera positions from videos. The problem is particularly hard when objects aretransformed in a non-rigid way. Current approaches to this problem makeunrealistic assumptions or require a long optimization time. We present TracksTo4D, a novel deep learning-based approach that enablesinferring 3D structure and camera positions from dynamic content originatingfrom in-the-wild videos using a single feed-forward pass on a sparse pointtrack matrix. To achieve this, we leverage recent advances in 2D point trackingand design an equivariant neural architecture tailored for directly processing2D point tracks by leveraging their symmetries. TracksTo4D is trained on adataset of in-the-wild videos utilizing only the 2D point tracks extracted fromthe videos, without any 3D supervision. Our experiments demonstrate thatTracksTo4D generalizes well to unseen videos of unseen semantic categories atinference time, producing equivalent results to state-of-the-art methods whilesignificantly reducing the runtime compared to other baselines.</description><author>Yoni Kasten, Wuyue Lu, Haggai Maron</author><pubDate>Wed, 10 Apr 2024 16:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07097v1</guid></item><item><title>TransTARec: Time-Adaptive Translating Embedding Model for Next POI Recommendation</title><link>http://arxiv.org/abs/2404.07096v1</link><description>The rapid growth of location acquisition technologies makesPoint-of-Interest(POI) recommendation possible due to redundant user check-inrecords. In this paper, we focus on next POI recommendation in which next POIis based on previous POI. We observe that time plays an important role in nextPOI recommendation but is neglected in the recent proposed translatingembedding methods. To tackle this shortage, we propose a time-adaptivetranslating embedding model (TransTARec) for next POI recommendation thatnaturally incorporates temporal influence, sequential dynamics, and userpreference within a single component. Methodologically, we treat a (previoustimestamp, user, next timestamp) triplet as a union translation vector anddevelop a neural-based fusion operation to fuse user preference and temporalinfluence. The superiority of TransTARec, which is confirmed by extensiveexperiments on real-world datasets, comes from not only the introduction oftemporal influence but also the direct unification with user preference andsequential dynamics.</description><author>Yiping Sun</author><pubDate>Wed, 10 Apr 2024 16:36:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07096v1</guid></item><item><title>MoCap-to-Visual Domain Adaptation for Efficient Human Mesh Estimation from 2D Keypoints</title><link>http://arxiv.org/abs/2404.07094v1</link><description>This paper presents Key2Mesh, a model that takes a set of 2D human posekeypoints as input and estimates the corresponding body mesh. Since thisprocess does not involve any visual (i.e. RGB image) data, the model can betrained on large-scale motion capture (MoCap) datasets, thereby overcoming thescarcity of image datasets with 3D labels. To enable the model's application onRGB images, we first run an off-the-shelf 2D pose estimator to obtain the 2Dkeypoints, and then feed these 2D keypoints to Key2Mesh. To improve theperformance of our model on RGB images, we apply an adversarial domainadaptation (DA) method to bridge the gap between the MoCap and visual domains.Crucially, our DA method does not require 3D labels for visual data, whichenables adaptation to target sets without the need for costly labels. Weevaluate Key2Mesh for the task of estimating 3D human meshes from 2D keypoints,in the absence of RGB and mesh label pairs. Our results on widely used H3.6Mand 3DPW datasets show that Key2Mesh sets the new state-of-the-art byoutperforming other models in PA-MPJPE for both datasets, and in MPJPE and PVEfor the 3DPW dataset. Thanks to our model's simple architecture, it operates atleast 12x faster than the prior state-of-the-art model, LGD. Additionalqualitative samples and code are available on the project website:https://key2mesh.github.io/.</description><author>Bedirhan Uguz, Ozhan Suat, Batuhan Karagoz, Emre Akbas</author><pubDate>Wed, 10 Apr 2024 16:34:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07094v1</guid></item><item><title>MaskClustering: View Consensus based Mask Graph Clustering for Open-Vocabulary 3D Instance Segmentation</title><link>http://arxiv.org/abs/2401.07745v2</link><description>Open-vocabulary 3D instance segmentation is cutting-edge for its ability tosegment 3D instances without predefined categories. However, progress in 3Dlags behind its 2D counterpart due to limited annotated 3D data. To addressthis, recent works first generate 2D open-vocabulary masks through 2D modelsand then merge them into 3D instances based on metrics calculated between twoneighboring frames. In contrast to these local metrics, we propose a novelmetric, view consensus rate, to enhance the utilization of multi-viewobservations. The key insight is that two 2D masks should be deemed part of thesame 3D instance if a significant number of other 2D masks from different viewscontain both these two masks. Using this metric as edge weight, we construct aglobal mask graph where each mask is a node. Through iterative clustering ofmasks showing high view consensus, we generate a series of clusters, eachrepresenting a distinct 3D instance. Notably, our model is training-free.Through extensive experiments on publicly available datasets, includingScanNet++, ScanNet200 and MatterPort3D, we demonstrate that our method achievesstate-of-the-art performance in open-vocabulary 3D instance segmentation. Ourproject page is at https://pku-epic.github.io/MaskClustering.</description><author>Mi Yan, Jiazhao Zhang, Yan Zhu, He Wang</author><pubDate>Wed, 10 Apr 2024 16:30:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07745v2</guid></item><item><title>LaTiM: Longitudinal representation learning in continuous-time models to predict disease progression</title><link>http://arxiv.org/abs/2404.07091v1</link><description>This work proposes a novel framework for analyzing disease progression usingtime-aware neural ordinary differential equations (NODE). We introduce a"time-aware head" in a framework trained through self-supervised learning (SSL)to leverage temporal information in latent space for data augmentation. Thisapproach effectively integrates NODEs with SSL, offering significantperformance improvements compared to traditional methods that lack explicittemporal integration. We demonstrate the effectiveness of our strategy fordiabetic retinopathy progression prediction using the OPHDIAT database.Compared to the baseline, all NODE architectures achieve statisticallysignificant improvements in area under the ROC curve (AUC) and Kappa metrics,highlighting the efficacy of pre-training with SSL-inspired approaches.Additionally, our framework promotes stable training for NODEs, a commonlyencountered challenge in time-aware modeling.</description><author>Rachid Zeghlache, Pierre-Henri Conze, Mostafa El Habib Daho, Yihao Li, Hugo Le Boité, Ramin Tadayoni, Pascal Massin, Béatrice Cochener, Alireza Rezaei, Ikram Brahim, Gwenolé Quellec, Mathieu Lamard</author><pubDate>Wed, 10 Apr 2024 16:29:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07091v1</guid></item><item><title>M-HOF-Opt: Multi-Objective Hierarchical Output Feedback Optimization via Multiplier Induced Loss Landscape Scheduling</title><link>http://arxiv.org/abs/2403.13728v2</link><description>We address the online combinatorial choice of weight multipliers formulti-objective optimization of many loss terms parameterized by neural worksvia a probabilistic graphical model (PGM) for the joint model parameter andmultiplier evolution process, with a hypervolume based likelihood promotingmulti-objective descent. The corresponding parameter and multiplier estimationas a sequential decision process is then cast into an optimal control problem,where the multi-objective descent goal is dispatched hierarchically into aseries of constraint optimization sub-problems. The subproblem constraintautomatically adapts itself according to Pareto dominance and serves as thesetpoint for the low level multiplier controller to schedule loss landscapesvia output feedback of each loss term. Our method is multiplier-free andoperates at the timescale of epochs, thus saves tremendous computationalresources compared to full training cycle multiplier tuning. It alsocircumvents the excessive memory requirements and heavy computational burden ofexisting multi-objective deep learning methods. We applied it to domaininvariant variational auto-encoding with 6 loss terms on the PACS domaingeneralization task, and observed robust performance across a range ofcontroller hyperparameters, as well as different multiplier initial conditions,outperforming other multiplier scheduling methods. We offered modularimplementation of our method, admitting extension to custom definition of manyloss terms.</description><author>Xudong Sun, Nutan Chen, Alexej Gossmann, Yu Xing, Carla Feistner, Emilio Dorigatt, Felix Drost, Daniele Scarcella, Lisa Beer, Carsten Marr</author><pubDate>Wed, 10 Apr 2024 16:25:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13728v2</guid></item><item><title>Visual Concept Connectome (VCC): Open World Concept Discovery and their Interlayer Connections in Deep Models</title><link>http://arxiv.org/abs/2404.02233v2</link><description>Understanding what deep network models capture in their learnedrepresentations is a fundamental challenge in computer vision. We present a newmethodology to understanding such vision models, the Visual Concept Connectome(VCC), which discovers human interpretable concepts and their interlayerconnections in a fully unsupervised manner. Our approach simultaneously revealsfine-grained concepts at a layer, connection weightings across all layers andis amendable to global analysis of network structure (e.g., branching patternof hierarchical concept assemblies). Previous work yielded ways to extractinterpretable concepts from single layers and examine their impact onclassification, but did not afford multilayer concept analysis across an entirenetwork architecture. Quantitative and qualitative empirical results show theeffectiveness of VCCs in the domain of image classification. Also, we leverageVCCs for the application of failure mode debugging to reveal where mistakesarise in deep networks.</description><author>Matthew Kowal, Richard P. Wildes, Konstantinos G. Derpanis</author><pubDate>Wed, 10 Apr 2024 16:22:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02233v2</guid></item><item><title>Understanding Video Transformers via Universal Concept Discovery</title><link>http://arxiv.org/abs/2401.10831v3</link><description>This paper studies the problem of concept-based interpretability oftransformer representations for videos. Concretely, we seek to explain thedecision-making process of video transformers based on high-level,spatiotemporal concepts that are automatically discovered. Prior research onconcept-based interpretability has concentrated solely on image-level tasks.Comparatively, video models deal with the added temporal dimension, increasingcomplexity and posing challenges in identifying dynamic concepts over time. Inthis work, we systematically address these challenges by introducing the firstVideo Transformer Concept Discovery (VTCD) algorithm. To this end, we proposean efficient approach for unsupervised identification of units of videotransformer representations - concepts, and ranking their importance to theoutput of a model. The resulting concepts are highly interpretable, revealingspatio-temporal reasoning mechanisms and object-centric representations inunstructured video models. Performing this analysis jointly over a diverse setof supervised and self-supervised representations, we discover that some ofthese mechanism are universal in video transformers. Finally, we show that VTCDcan be used for fine-grained action recognition and video object segmentation.</description><author>Matthew Kowal, Achal Dave, Rares Ambrus, Adrien Gaidon, Konstantinos G. Derpanis, Pavel Tokmakov</author><pubDate>Wed, 10 Apr 2024 16:19:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10831v3</guid></item><item><title>Dynamic Generation of Personalities with Large Language Models</title><link>http://arxiv.org/abs/2404.07084v1</link><description>In the realm of mimicking human deliberation, large language models (LLMs)show promising performance, thereby amplifying the importance of this researcharea. Deliberation is influenced by both logic and personality. However,previous studies predominantly focused on the logic of LLMs, neglecting theexploration of personality aspects. In this work, we introduce DynamicPersonality Generation (DPG), a dynamic personality generation method based onHypernetworks. Initially, we embed the Big Five personality theory into GPT-4to form a personality assessment machine, enabling it to evaluate characters'personality traits from dialogues automatically. We propose a new metric toassess personality generation capability based on this evaluation method. Then,we use this personality assessment machine to evaluate dialogues in scriptdata, resulting in a personality-dialogue dataset. Finally, we fine-tune DPG onthe personality-dialogue dataset. Experiments prove that DPG's personalitygeneration capability is stronger after fine-tuning on this dataset thantraditional fine-tuning methods, surpassing prompt-based GPT-4.</description><author>Jianzhi Liu, Hexiang Gu, Tianyu Zheng, Liuyu Xiang, Huijia Wu, Jie Fu, Zhaofeng He</author><pubDate>Wed, 10 Apr 2024 16:17:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07084v1</guid></item><item><title>Minimizing Chebyshev Prototype Risk Magically Mitigates the Perils of Overfitting</title><link>http://arxiv.org/abs/2404.07083v1</link><description>Overparameterized deep neural networks (DNNs), if not sufficientlyregularized, are susceptible to overfitting their training examples and notgeneralizing well to test data. To discourage overfitting, researchers havedeveloped multicomponent loss functions that reduce intra-class featurecorrelation and maximize inter-class feature distance in one or more layers ofthe network. By analyzing the penultimate feature layer activations output by aDNN's feature extraction section prior to the linear classifier, we find thatmodified forms of the intra-class feature covariance and inter-class prototypeseparation are key components of a fundamental Chebyshev upper bound on theprobability of misclassification, which we designate the Chebyshev PrototypeRisk (CPR). While previous approaches' covariance loss terms scalequadratically with the number of network features, our CPR bound indicates thatan approximate covariance loss in log-linear time is sufficient to reduce thebound and is scalable to large architectures. We implement the terms of the CPRbound into our Explicit CPR (exCPR) loss function and observe from empiricalresults on multiple datasets and network architectures that our trainingalgorithm reduces overfitting and improves upon previous approaches in manysettings. Our code is available$\href{https://github.com/Deano1718/Regularization_exCPR}{here}$.</description><author>Nathaniel Dean, Dilip Sarkar</author><pubDate>Wed, 10 Apr 2024 16:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07083v1</guid></item><item><title>Public-private funding models in open source software development: A case study on scikit-learn</title><link>http://arxiv.org/abs/2404.06484v2</link><description>Governments are increasingly allocating funding for open source software(OSS) development to address concerns related to software security, digitalsovereignty, and national competitiveness in science and innovation, amongstothers. While announcements of governmental funding are generally well-receivedby OSS developers, we still have a limited understanding of OSS developersevaluate the relative benefits and drawbacks of such funding compared to othertypes of funding. This paper explores this question through a case study onscikit-learn, a Python library for machine learning, whose funding modelcombines research grants, commercial sponsorship, community donations, and a 32million euro grant from the France's artificial intelligence strategy. Through25 interviews with scikit-learn's maintainers and funders, this study makes twokey contributions to research and practice. First, the study illustrates howthe maintainers have weaved public and private funding into their project toensure the continued provision of scikit-learn as a digital public good, aswell as the importance of diversified funding and governance protocols forfunding to safeguard the community ethos of the project. Second, it offerspractical recommendations to various stakeholders. For OSS developercommunities, it illustrates the benefits of a diversified funding model inbalancing the merits and drawbacks of different funding sources. For companies,it serves as a reminder that sponsoring developers or OSS projects cansignificantly support OSS maintainers, who often struggle with limitedresources and towering workloads. For governments, it emphasises the importanceof funding the maintenance of existing OSS in addition to or exclusivelyfunding the development of new OSS libraries or features. The paper concludeswith suggestions for future research directions.</description><author>Cailean Osborne</author><pubDate>Wed, 10 Apr 2024 16:12:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06484v2</guid></item><item><title>MuPT: A Generative Symbolic Music Pretrained Transformer</title><link>http://arxiv.org/abs/2404.06393v2</link><description>In this paper, we explore the application of Large Language Models (LLMs) tothe pre-training of music. While the prevalent use of MIDI in music modeling iswell-established, our findings suggest that LLMs are inherently more compatiblewith ABC Notation, which aligns more closely with their design and strengths,thereby enhancing the model's performance in musical composition. To addressthe challenges associated with misaligned measures from different tracks duringgeneration, we propose the development of a Synchronized Multi-Track ABCNotation (SMT-ABC Notation), which aims to preserve coherence across multiplemusical tracks. Our contributions include a series of models capable ofhandling up to 8192 tokens, covering 90% of the symbolic music data in ourtraining set. Furthermore, we explore the implications of the Symbolic MusicScaling Law (SMS Law) on model performance. The results indicate a promisingdirection for future research in music generation, offering extensive resourcesfor community-led research through our open-source contributions.</description><author>Xingwei Qu, Yuelin Bai, Yinghao Ma, Ziya Zhou, Ka Man Lo, Jiaheng Liu, Ruibin Yuan, Lejun Min, Xueling Liu, Tianyu Zhang, Xinrun Du, Shuyue Guo, Yiming Liang, Yizhi Li, Shangda Wu, Junting Zhou, Tianyu Zheng, Ziyang Ma, Fengze Han, Wei Xue, Gus Xia, Emmanouil Benetos, Xiang Yue, Chenghua Lin, Xu Tan, Stephen W. Huang, Wenhu Chen, Jie Fu, Ge Zhang</author><pubDate>Wed, 10 Apr 2024 16:09:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06393v2</guid></item><item><title>Location-guided Head Pose Estimation for Fisheye Image</title><link>http://arxiv.org/abs/2402.18320v2</link><description>Camera with a fisheye or ultra-wide lens covers a wide field of view thatcannot be modeled by the perspective projection. Serious fisheye lensdistortion in the peripheral region of the image leads to degraded performanceof the existing head pose estimation models trained on undistorted images. Thispaper presents a new approach for head pose estimation that uses the knowledgeof head location in the image to reduce the negative effect of fisheyedistortion. We develop an end-to-end convolutional neural network to estimatethe head pose with the multi-task learning of head pose and head location. Ourproposed network estimates the head pose directly from the fisheye imagewithout the operation of rectification or calibration. We also created afisheye-distorted version of the three popular head pose estimation datasets,BIWI, 300W-LP, and AFLW2000 for our experiments. Experiments results show thatour network remarkably improves the accuracy of head pose estimation comparedwith other state-of-the-art one-stage and two-stage methods.</description><author>Bing Li, Dong Zhang, Cheng Huang, Yun Xian, Ming Li, Dah-Jye Lee</author><pubDate>Wed, 10 Apr 2024 16:09:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18320v2</guid></item><item><title>VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning</title><link>http://arxiv.org/abs/2404.07078v1</link><description>Recognising emotions in context involves identifying the apparent emotions ofan individual, taking into account contextual cues from the surrounding scene.Previous approaches to this task have involved the design of explicitscene-encoding architectures or the incorporation of external scene-relatedinformation, such as captions. However, these methods often utilise limitedcontextual information or rely on intricate training pipelines. In this work,we leverage the groundbreaking capabilities of Vision-and-Large-Language Models(VLLMs) to enhance in-context emotion classification without introducingcomplexity to the training process in a two-stage approach. In the first stage,we propose prompting VLLMs to generate descriptions in natural language of thesubject's apparent emotion relative to the visual context. In the second stage,the descriptions are used as contextual information and, along with the imageinput, are used to train a transformer-based architecture that fuses text andvisual features before the final classification task. Our experimental resultsshow that the text and image features have complementary information, and ourfused architecture significantly outperforms the individual modalities withoutany complex training methods. We evaluate our approach on three differentdatasets, namely, EMOTIC, CAER-S, and BoLD, and achieve state-of-the-art orcomparable accuracy across all datasets and metrics compared to much morecomplex approaches. The code will be made publicly available on github:https://github.com/NickyFot/EmoCommonSense.git</description><author>Alexandros Xenos, Niki Maria Foteinopoulou, Ioanna Ntinou, Ioannis Patras, Georgios Tzimiropoulos</author><pubDate>Wed, 10 Apr 2024 16:09:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07078v1</guid></item><item><title>Is Learning in Biological Neural Networks based on Stochastic Gradient Descent? An analysis using stochastic processes</title><link>http://arxiv.org/abs/2309.05102v3</link><description>In recent years, there has been an intense debate about how learning inbiological neural networks (BNNs) differs from learning in artificial neuralnetworks. It is often argued that the updating of connections in the brainrelies only on local information, and therefore a stochastic gradient-descenttype optimization method cannot be used. In this paper, we study a stochasticmodel for supervised learning in BNNs. We show that a (continuous) gradientstep occurs approximately when each learning opportunity is processed by manylocal updates. This result suggests that stochastic gradient descent may indeedplay a role in optimizing BNNs.</description><author>Sören Christensen, Jan Kallsen</author><pubDate>Wed, 10 Apr 2024 16:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05102v3</guid></item><item><title>Implicit Multi-Spectral Transformer: An Lightweight and Effective Visible to Infrared Image Translation Model</title><link>http://arxiv.org/abs/2404.07072v1</link><description>In the field of computer vision, visible light images often exhibit lowcontrast in low-light conditions, presenting a significant challenge. Whileinfrared imagery provides a potential solution, its utilization entails highcosts and practical limitations. Recent advancements in deep learning,particularly the deployment of Generative Adversarial Networks (GANs), havefacilitated the transformation of visible light images to infrared images.However, these methods often experience unstable training phases and mayproduce suboptimal outputs. To address these issues, we propose a novelend-to-end Transformer-based model that efficiently converts visible lightimages into high-fidelity infrared images. Initially, the Texture MappingModule and Color Perception Adapter collaborate to extract texture and colorfeatures from the visible light image. The Dynamic Fusion Aggregation Modulesubsequently integrates these features. Finally, the transformation into aninfrared image is refined through the synergistic action of the ColorPerception Adapter and the Enhanced Perception Attention mechanism.Comprehensive benchmarking experiments confirm that our model outperformsexisting methods, producing infrared images of markedly superior quality, bothqualitatively and quantitatively. Furthermore, the proposed model enables moreeffective downstream applications for infrared images than other methods.</description><author>Yijia Chen, Pinghua Chen, Xiangxin Zhou, Yingtie Lei, Ziyang Zhou, Mingxian Li</author><pubDate>Wed, 10 Apr 2024 16:02:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07072v1</guid></item><item><title>Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?</title><link>http://arxiv.org/abs/2404.07066v1</link><description>This paper studies the phenomenon that different concepts are learned indifferent layers of large language models, i.e. more difficult concepts arefully acquired with deeper layers. We define the difficulty of concepts by thelevel of abstraction, and here it is crudely categorized by factual, emotional,and inferential. Each category contains a spectrum of tasks, arranged fromsimple to complex. For example, within the factual dimension, tasks range fromlie detection to categorizing mathematical problems. We employ a probingtechnique to extract representations from different layers of the model andapply these to classification tasks. Our findings reveal that models tend toefficiently classify simpler tasks, indicating that these concepts are learnedin shallower layers. Conversely, more complex tasks may only be discernible atdeeper layers, if at all. This paper explores the implications of thesefindings for our understanding of model learning processes and internalrepresentations. Our implementation is available at\url{https://github.com/Luckfort/CD}.</description><author>Mingyu Jin, Qinkai Yu, Jingyuan Huang, Qingcheng Zeng, Zhenting Wang, Wenyue Hua, Haiyan Zhao, Kai Mei, Yanda Meng, Kaize Ding, Fan Yang, Mengnan Du, Yongfeng Zhang</author><pubDate>Wed, 10 Apr 2024 15:56:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07066v1</guid></item><item><title>LaPlaSS: Latent Space Planning for Stochastic Systems</title><link>http://arxiv.org/abs/2404.07063v1</link><description>Autonomous mobile agents often operate in hazardous environments,necessitating an awareness of safety. These agents can have non-linear,stochastic dynamics that must be considered during planning to guaranteebounded risk. Most state of the art methods require closed-form dynamics toverify plan correctness and safety however modern robotic systems often havedynamics that are learned from data. Thus, there is a need to perform efficienttrajectory planning with guarantees on risk for agents without known dynamicsmodels. We propose a "generate-and-test" approach to risk-bounded planning inwhich a planner generates a candidate trajectory using an approximate lineardynamics model and a validator assesses the risk of the trajectory, computingadditional safety constraints for the planner if the candidate does not satisfythe desired risk bound. To acquire the approximate model, we use a variationalautoencoder to learn a latent linear dynamics model and encode the planningproblem into the latent space to generate the candidate trajectory. The VAEalso serves to sample trajectories around the candidate to use in thevalidator. We demonstrate that our algorithm, LaPlaSS, is able to generatetrajectory plans with bounded risk for a real-world agent with learned dynamicsand is an order of magnitude more efficient than the state of the art.</description><author>Marlyse Reeves, Brian C. Williams</author><pubDate>Wed, 10 Apr 2024 15:52:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07063v1</guid></item><item><title>On Regression in Extreme Regions</title><link>http://arxiv.org/abs/2303.03084v2</link><description>The statistical learning problem consists in building a predictive function$\hat{f}$ based on independent copies of $(X,Y)$ so that $Y$ is approximated by$\hat{f}(X)$ with minimum (squared) error. Motivated by various applications,special attention is paid here to the case of extreme (i.e. very large)observations $X$. Because of their rarity, the contributions of suchobservations to the (empirical) error is negligible, and the predictiveperformance of empirical risk minimizers can be consequently very poor inextreme regions. In this paper, we develop a general framework for regressionon extremes. Under appropriate regular variation assumptions regarding the pair$(X,Y)$, we show that an asymptotic notion of risk can be tailored to summarizeappropriately predictive performance in extreme regions. It is also proved thatminimization of an empirical and nonasymptotic version of this 'extreme risk',based on a fraction of the largest observations solely, yields goodgeneralization capacity. In addition, numerical results providing strongempirical evidence of the relevance of the approach proposed are displayed.</description><author>Nathan Huet, Stephan Clémençon, Anne Sabourin</author><pubDate>Wed, 10 Apr 2024 15:52:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03084v2</guid></item><item><title>A Tight $O(4^k/p_c)$ Runtime Bound for a ($μ$+1) GA on Jump$_k$ for Realistic Crossover Probabilities</title><link>http://arxiv.org/abs/2404.07061v1</link><description>The Jump$_k$ benchmark was the first problem for which crossover was provento give a speedup over mutation-only evolutionary algorithms. Jansen andWegener (2002) proved an upper bound of $O({\rm poly}(n) + 4^k/p_c)$ for the($\mu$+1)~Genetic Algorithm ($(\mu+1)$ GA), but only for unrealistically smallcrossover probabilities $p_c$. To this date, it remains an open problem toprove similar upper bounds for realistic~$p_c$; the best known runtime boundfor $p_c = \Omega(1)$ is $O((n/\chi)^{k-1})$, $\chi$ a positive constant. Usingrecently developed techniques, we analyse the evolution of the populationdiversity, measured as sum of pairwise Hamming distances, for a variant of the\muga on Jump$_k$. We show that population diversity converges to anequilibrium of near-perfect diversity. This yields an improved and tight timebound of $O(\mu n \log(k) + 4^k/p_c)$ for a range of~$k$ under the mildassumptions $p_c = O(1/k)$ and $\mu \in \Omega(kn)$. For all constant~$k$ therestriction is satisfied for some $p_c = \Omega(1)$. Our work partially solvesa problem that has been open for more than 20 years.</description><author>Andre Opris, Johannes Lengler, Dirk Sudholt</author><pubDate>Wed, 10 Apr 2024 15:50:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07061v1</guid></item><item><title>Groundedness in Retrieval-augmented Long-form Generation: An Empirical Study</title><link>http://arxiv.org/abs/2404.07060v1</link><description>We present an empirical study of groundedness in long-form question answering(LFQA) by retrieval-augmented large language models (LLMs). In particular, weevaluate whether every generated sentence is grounded in the retrieveddocuments or the model's pre-training data. Across 3 datasets and 4 modelfamilies, our findings reveal that a significant fraction of generatedsentences are consistently ungrounded, even when those sentences containcorrect ground-truth answers. Additionally, we examine the impacts of factorssuch as model size, decoding strategy, and instruction tuning on groundedness.Our results show that while larger models tend to ground their outputs moreeffectively, a significant portion of correct answers remains compromised byhallucinations. This study provides novel insights into the groundednesschallenges in LFQA and underscores the necessity for more robust mechanisms inLLMs to mitigate the generation of ungrounded content.</description><author>Alessandro Stolfo</author><pubDate>Wed, 10 Apr 2024 15:50:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07060v1</guid></item><item><title>Meta4XNLI: A Crosslingual Parallel Corpus for Metaphor Detection and Interpretation</title><link>http://arxiv.org/abs/2404.07053v1</link><description>Metaphors, although occasionally unperceived, are ubiquitous in our everydaylanguage. Thus, it is crucial for Language Models to be able to grasp theunderlying meaning of this kind of figurative language. In this work, wepresent Meta4XNLI, a novel parallel dataset for the tasks of metaphor detectionand interpretation that contains metaphor annotations in both Spanish andEnglish. We investigate language models' metaphor identification andunderstanding abilities through a series of monolingual and cross-lingualexperiments by leveraging our proposed corpus. In order to comprehend how thesenon-literal expressions affect models' performance, we look over the resultsand perform an error analysis. Additionally, parallel data offers manypotential opportunities to investigate metaphor transferability between theselanguages and the impact of translation on the development of multilingualannotated resources.</description><author>Elisa Sanchez-Bayona, Rodrigo Agerri</author><pubDate>Wed, 10 Apr 2024 15:44:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07053v1</guid></item><item><title>Towards Learning Stochastic Population Models by Gradient Descent</title><link>http://arxiv.org/abs/2404.07049v1</link><description>Increasing effort is put into the development of methods for learningmechanistic models from data. This task entails not only the accurateestimation of parameters, but also a suitable model structure. Recent work onthe discovery of dynamical systems formulates this problem as a linear equationsystem. Here, we explore several simulation-based optimization approaches,which allow much greater freedom in the objective formulation and weakerconditions on the available data. We show that even for relatively smallstochastic population models, simultaneous estimation of parameters andstructure poses major challenges for optimization procedures. Particularly, weinvestigate the application of the local stochastic gradient descent method,commonly used for training machine learning models. We demonstrate accurateestimation of models but find that enforcing the inference of parsimonious,interpretable models drastically increases the difficulty. We give an outlookon how this challenge can be overcome.</description><author>Justin N. Kreikemeyer, Philipp Andelfinger, Adelinde M. Uhrmacher</author><pubDate>Wed, 10 Apr 2024 15:38:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07049v1</guid></item><item><title>Comparison of decision trees with Local Interpretable Model-Agnostic Explanations (LIME) technique and multi-linear regression for explaining support vector regression model in terms of root mean square error (RMSE) values</title><link>http://arxiv.org/abs/2404.07046v1</link><description>In this work the decision trees are used for explanation of support vectorregression model. The decision trees act as a global technique as well as alocal technique. They are compared against the popular technique of LIME whichis a local explanatory technique and with multi linear regression. It isobserved that decision trees give a lower RMSE value when fitted to supportvector regression as compared to LIME in 87% of the runs over 5 datasets. Thecomparison of results is statistically significant. Multi linear regressionalso gives a lower RMSE value when fitted to support vector regression model ascompared to LIME in 73% of the runs over 5 datasets but the comparison ofresults is not statistically significant. Also, when used as a localexplanatory technique, decision trees give better performance than LIME and thecomparison of results is statistically significant.</description><author>Amit Thombre</author><pubDate>Wed, 10 Apr 2024 15:36:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07046v1</guid></item><item><title>Identification of Fine-grained Systematic Errors via Controlled Scene Generation</title><link>http://arxiv.org/abs/2404.07045v1</link><description>Many safety-critical applications, especially in autonomous driving, requirereliable object detectors. They can be very effectively assisted by a method tosearch for and identify potential failures and systematic errors before thesedetectors are deployed. Systematic errors are characterized by combinations ofattributes such as object location, scale, orientation, and color, as well asthe composition of their respective backgrounds. To identify them, one mustrely on something other than real images from a test set because they do notaccount for very rare but possible combinations of attributes. To overcome thislimitation, we propose a pipeline for generating realistic synthetic sceneswith fine-grained control, allowing the creation of complex scenes withmultiple objects. Our approach, BEV2EGO, allows for a realistic generation ofthe complete scene with road-contingent control that maps 2D bird's-eye view(BEV) scene configurations to a first-person view (EGO). In addition, wepropose a benchmark for controlled scene generation to select the mostappropriate generative outpainting model for BEV2EGO. We further use it toperform a systematic analysis of multiple state-of-the-art object detectionmodels and discover differences between them.</description><author>Valentyn Boreiko, Matthias Hein, Jan Hendrik Metzen</author><pubDate>Wed, 10 Apr 2024 15:35:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07045v1</guid></item><item><title>PLAN: Variance-Aware Private Mean Estimation</title><link>http://arxiv.org/abs/2306.08745v3</link><description>Differentially private mean estimation is an important building block inprivacy-preserving algorithms for data analysis and machine learning. Thoughthe trade-off between privacy and utility is well understood in the worst case,many datasets exhibit structure that could potentially be exploited to yieldbetter algorithms. In this paper we present $\textit{Private Limit AdaptedNoise}$ (PLAN), a family of differentially private algorithms for meanestimation in the setting where inputs are independently sampled from adistribution $\mathcal{D}$ over $\mathbf{R}^d$, with coordinate-wise standarddeviations $\boldsymbol{\sigma} \in \mathbf{R}^d$. Similar to mean estimationunder Mahalanobis distance, PLAN tailors the shape of the noise to the shape ofthe data, but unlike previous algorithms the privacy budget is spentnon-uniformly over the coordinates. Under a concentration assumption on$\mathcal{D}$, we show how to exploit skew in the vector $\boldsymbol{\sigma}$,obtaining a (zero-concentrated) differentially private mean estimate with$\ell_2$ error proportional to $\|\boldsymbol{\sigma}\|_1$. Previous work haseither not taken $\boldsymbol{\sigma}$ into account, or measured error inMahalanobis distance $\unicode{x2013}$ in both cases resulting in $\ell_2$error proportional to $\sqrt{d}\|\boldsymbol{\sigma}\|_2$, which can be up to afactor $\sqrt{d}$ larger. To verify the effectiveness of PLAN, we empiricallyevaluate accuracy on both synthetic and real world data.</description><author>Martin Aumüller, Christian Janos Lebeda, Boel Nelson, Rasmus Pagh</author><pubDate>Wed, 10 Apr 2024 15:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08745v3</guid></item><item><title>A Computational Analysis of the Dehumanisation of Migrants from Syria and Ukraine in Slovene News Media</title><link>http://arxiv.org/abs/2404.07036v1</link><description>Dehumanisation involves the perception and or treatment of a social group'smembers as less than human. This phenomenon is rarely addressed withcomputational linguistic techniques. We adapt a recently proposed approach forEnglish, making it easier to transfer to other languages and to evaluate,introducing a new sentiment resource, the use of zero-shot cross-lingualvalence and arousal detection, and a new method for statistical significancetesting. We then apply it to study attitudes to migration expressed in Slovenenewspapers, to examine changes in the Slovene discourse on migration betweenthe 2015-16 migration crisis following the war in Syria and the 2022-23 periodfollowing the war in Ukraine. We find that while this discourse became morenegative and more intense over time, it is less dehumanising when specificallyaddressing Ukrainian migrants compared to others.</description><author>Jaya Caporusso, Damar Hoogland, Mojca Brglez, Boshko Koloski, Matthew Purver, Senja Pollak</author><pubDate>Wed, 10 Apr 2024 15:28:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07036v1</guid></item><item><title>Characterizing and Classifying Developer Forum Posts with their Intentions</title><link>http://arxiv.org/abs/2312.14279v2</link><description>With the rapid growth of the developer community, the amount of posts ononline technical forums has been growing rapidly, which poses difficulties forusers to filter useful posts and find important information. Tags provide aconcise feature dimension for users to locate their interested posts and forsearch engines to index the most relevant posts according to the queries.However, most tags are only focused on the technical perspective (e.g., programlanguage, platform, tool). In most cases, forum posts in online developercommunities reveal the author's intentions to solve a problem, ask for advice,share information, etc. The modeling of the intentions of posts can provide anextra dimension to the current tag taxonomy. By referencing previous studiesand learning from industrial perspectives, we create a refined taxonomy for theintentions of technical forum posts. Through manual labeling and analysis on asampled post dataset extracted from online forums, we understand the relevancebetween the constitution of posts (code, error messages) and their intentions.Furthermore, inspired by our manual study, we design a pre-trainedtransformer-based model to automatically predict post intentions. The bestvariant of our intention prediction framework, which achieves a Micro F1-scoreof 0.589, Top 1-3 accuracy of 62.6% to 87.8%, and an average AUC of 0.787,outperforms the state-of-the-art baseline approach. Our characterization andautomated classification of forum posts regarding their intentions may helpforum maintainers or third-party tool developers improve the organization andretrieval of posts on technical forums. We have released our annotated datasetand codes in our supplementary material package.</description><author>Xingfang Wu, Eric Laufer, Heng Li, Foutse Khomh, Santhosh Srinivasan, Jayden Luo</author><pubDate>Wed, 10 Apr 2024 15:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14279v2</guid></item><item><title>An Evidential-enhanced Tri-Branch Consistency Learning Method for Semi-supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2404.07032v1</link><description>Semi-supervised segmentation presents a promising approach for large-scalemedical image analysis, effectively reducing annotation burdens while achievingcomparable performance. This methodology holds substantial potential forstreamlining the segmentation process and enhancing its feasibility withinclinical settings for translational investigations. While cross-supervisedtraining, based on distinct co-training sub-networks, has become a prevalentparadigm for this task, addressing critical issues such as predicationdisagreement and label-noise suppression requires further attention andprogress in cross-supervised training. In this paper, we introduce anEvidential Tri-Branch Consistency learning framework (ETC-Net) forsemi-supervised medical image segmentation. ETC-Net employs three branches: anevidential conservative branch, an evidential progressive branch, and anevidential fusion branch. The first two branches exhibit complementarycharacteristics, allowing them to address prediction diversity and enhancetraining stability. We also integrate uncertainty estimation from theevidential learning into cross-supervised training, mitigating the negativeimpact of erroneous supervision signals. Additionally, the evidential fusionbranch capitalizes on the complementary attributes of the first two branchesand leverages an evidence-based Dempster-Shafer fusion strategy, supervised bymore reliable and accurate pseudo-labels of unlabeled data. Extensiveexperiments conducted on LA, Pancreas-CT, and ACDC datasets demonstrate thatETC-Net surpasses other state-of-the-art methods for semi-supervisedsegmentation. The code will be made available in the near future athttps://github.com/Medsemiseg.</description><author>Zhenxi Zhang, Heng Zhou, Xiaoran Shi, Ran Ran, Chunna Tian, Feng Zhou</author><pubDate>Wed, 10 Apr 2024 15:25:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07032v1</guid></item><item><title>VMamba: Visual State Space Model</title><link>http://arxiv.org/abs/2401.10166v2</link><description>Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) have longbeen the predominant backbone networks for visual representation learning.While ViTs have recently gained prominence over CNNs due to their superiorfitting capabilities, their scalability is largely constrained by the quadraticcomplexity of attention computation. Inspired by the capability of Mamba inefficiently modeling long sequences, we propose VMamba, a generic visionbackbone model aiming to reduce the computational complexity to linear whileretaining ViTs' advantageous features. To enhance VMamba's adaptability inprocessing vision data, we introduce the Cross-Scan Module (CSM) to enable 1Dselective scanning in 2D image space with global receptive fields.Additionally, we make further improvements in implementation details andarchitectural designs to enhance VMamba's performance and boost its inferencespeed. Extensive experimental results demonstrate VMamba's promisingperformance across various visual perception tasks, highlighting its pronouncedadvantages in input scaling efficiency compared to existing benchmark models.Source code is available at https://github.com/MzeroMiko/VMamba.</description><author>Yue Liu, Yunjie Tian, Yuzhong Zhao, Hongtian Yu, Lingxi Xie, Yaowei Wang, Qixiang Ye, Yunfan Liu</author><pubDate>Wed, 10 Apr 2024 15:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10166v2</guid></item><item><title>ORacle: Large Vision-Language Models for Knowledge-Guided Holistic OR Domain Modeling</title><link>http://arxiv.org/abs/2404.07031v1</link><description>Every day, countless surgeries are performed worldwide, each within thedistinct settings of operating rooms (ORs) that vary not only in their setupsbut also in the personnel, tools, and equipment used. This inherent diversityposes a substantial challenge for achieving a holistic understanding of the OR,as it requires models to generalize beyond their initial training datasets. Toreduce this gap, we introduce ORacle, an advanced vision-language modeldesigned for holistic OR domain modeling, which incorporates multi-view andtemporal capabilities and can leverage external knowledge during inference,enabling it to adapt to previously unseen surgical scenarios. This capabilityis further enhanced by our novel data augmentation framework, whichsignificantly diversifies the training dataset, ensuring ORacle's proficiencyin applying the provided knowledge effectively. In rigorous testing, in scenegraph generation, and downstream tasks on the 4D-OR dataset, ORacle not onlydemonstrates state-of-the-art performance but does so requiring less data thanexisting models. Furthermore, its adaptability is displayed through its abilityto interpret unseen views, actions, and appearances of tools and equipment.This demonstrates ORacle's potential to significantly enhance the scalabilityand affordability of OR domain modeling and opens a pathway for futureadvancements in surgical data science. We will release our code and data uponacceptance.</description><author>Ege Özsoy, Chantal Pellegrini, Matthias Keicher, Nassir Navab</author><pubDate>Wed, 10 Apr 2024 15:24:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07031v1</guid></item><item><title>Diffusion-based inpainting of incomplete Euclidean distance matrices of trajectories generated by a fractional Brownian motion</title><link>http://arxiv.org/abs/2404.07029v1</link><description>Fractional Brownian trajectories (fBm) feature both randomness and strongscale-free correlations, challenging generative models to reproduce theintrinsic memory characterizing the underlying process. Here we test adiffusion probabilistic model on a specific dataset of corrupted imagescorresponding to incomplete Euclidean distance matrices of fBm at variousmemory exponents $H$. Our dataset implies uniqueness of the data imputation inthe regime of low missing ratio, where the remaining partial graph is rigid,providing the ground truth for the inpainting. We find that the conditionaldiffusion generation stably reproduces the statistics of missingfBm-distributed distances for different values of $H$ exponent. Furthermore,while diffusion models have been recently shown to remember samples from thetraining database, we show that diffusion-based inpainting behavesqualitatively different from the database search with the increasing databasesize. Finally, we apply our fBm-trained diffusion model with $H=1/3$ forcompletion of chromosome distance matrices obtained in single-cell microscopyexperiments, showing its superiority over the standard bioinformaticsalgorithms. Our source code is available on GitHub athttps://github.com/alobashev/diffusion_fbm.</description><author>Alexander Lobashev, Kirill Polovnikov</author><pubDate>Wed, 10 Apr 2024 15:22:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07029v1</guid></item><item><title>Improving the Diproche CNL through Autoformalization via Large Language Models</title><link>http://arxiv.org/abs/2303.17513v3</link><description>The Diproche system is an automated proof checker for texts written in acontrolled fragment of German, designed for didactical applications in classesintroducing students to proofs for the first time. The first version of thesystem used a controlled natural language for which a Prolog formalizationroutine was written. In this paper, we explore the possibility of promptinglarge language models for autoformalization in the context of Diproche, withencouraging first results.</description><author>Merlin Carl</author><pubDate>Wed, 10 Apr 2024 15:19:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17513v3</guid></item><item><title>Using Large Language Models for (De-)Formalization and Natural Argumentation Exercises for Beginner's Students</title><link>http://arxiv.org/abs/2304.06186v3</link><description>We describe two systems currently being developed that use large languagemodels for the automatized correction of (i) exercises in translating back andforth between natural language and the languages of propositional logic andfirst-order predicate logic and (ii) exercises in writing simple arguments innatural language in non-mathematical scenarios.</description><author>Merlin Carl</author><pubDate>Wed, 10 Apr 2024 15:19:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06186v3</guid></item><item><title>I still know it's you! On Challenges in Anonymizing Source Code</title><link>http://arxiv.org/abs/2208.12553v2</link><description>The source code of a program not only defines its semantics but also containssubtle clues that can identify its author. Several studies have shown thatthese clues can be automatically extracted using machine learning and allow fordetermining a program's author among hundreds of programmers. This attributionposes a significant threat to developers of anti-censorship andprivacy-enhancing technologies, as they become identifiable and may beprosecuted. An ideal protection from this threat would be the anonymization ofsource code. However, neither theoretical nor practical principles of such ananonymization have been explored so far. In this paper, we tackle this problem and develop a framework for reasoningabout code anonymization. We prove that the task of generating a $k$-anonymousprogram -- a program that cannot be attributed to one of $k$ authors -- is notcomputable in the general case. As a remedy, we introduce a relaxed conceptcalled $k$-uncertainty, which enables us to measure the protection ofdevelopers. Based on this concept, we empirically study candidate techniquesfor anonymization, such as code normalization, coding style imitation, and codeobfuscation. We find that none of the techniques provides sufficient protectionwhen the attacker is aware of the anonymization. While we observe a notablereduction in attribution performance on real-world code, a reliable protectionis not achieved for all developers. We conclude that code anonymization is ahard problem that requires further attention from the research community.</description><author>Micha Horlboge, Erwin Quiring, Roland Meyer, Konrad Rieck</author><pubDate>Wed, 10 Apr 2024 15:16:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.12553v2</guid></item><item><title>Using Persuasive Writing Strategies to Explain and Detect Health Misinformation</title><link>http://arxiv.org/abs/2211.05985v4</link><description>Nowadays, the spread of misinformation is a prominent problem in society. Ourresearch focuses on aiding the automatic identification of misinformation byanalyzing the persuasive strategies employed in textual documents. We introducea novel annotation scheme encompassing common persuasive writing tactics toachieve our objective. Additionally, we provide a dataset on healthmisinformation, thoroughly annotated by experts utilizing our proposed scheme.Our contribution includes proposing a new task of annotating pieces of textwith their persuasive writing strategy types. We evaluate fine-tuning andprompt-engineering techniques with pre-trained language models of the BERTfamily and the generative large language models of the GPT family usingpersuasive strategies as an additional source of information. We evaluate theeffects of employing persuasive strategies as intermediate labels in thecontext of misinformation detection. Our results show that those strategiesenhance accuracy and improve the explainability of misinformation detectionmodels. The persuasive strategies can serve as valuable insights andexplanations, enabling other models or even humans to make more informeddecisions regarding the trustworthiness of the information.</description><author>Danial Kamali, Joseph Romain, Huiyi Liu, Wei Peng, Jingbo Meng, Parisa Kordjamshidi</author><pubDate>Wed, 10 Apr 2024 15:13:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.05985v4</guid></item><item><title>CityNet: A Comprehensive Multi-Modal Urban Dataset for Advanced Research in Urban Computing</title><link>http://arxiv.org/abs/2106.15802v2</link><description>Data-driven approaches have emerged as a popular tool for addressingchallenges in urban computing. However, current research efforts have primarilyfocused on limited data sources, which fail to capture the complexity of urbandata arising from multiple entities and their interconnections. Therefore, acomprehensive and multifaceted dataset is required to enable more extensivestudies in urban computing. In this paper, we present CityNet, a multi-modalurban dataset that incorporates various data, including taxi trajectory,traffic speed, point of interest (POI), road network, wind, rain, temperature,and more, from seven cities. We categorize this comprehensive data into threestreams: mobility data, geographical data, and meteorological data. We begin bydetailing the generation process and basic properties of CityNet. Additionally,we conduct extensive data mining and machine learning experiments, includingspatio-temporal predictions, transfer learning, and reinforcement learning, tofacilitate the use of CityNet. Our experimental results provide benchmarks forvarious tasks and methods, and also reveal internal correlations among citiesand tasks within CityNet that can be leveraged to improve spatiotemporalforecasting performance. Based on our benchmarking results and the correlationsuncovered, we believe that CityNet can significantly contribute to the field ofurban computing by enabling research on advanced topics.</description><author>Zhengfei Zheng, Xu Geng, Hai Yang</author><pubDate>Wed, 10 Apr 2024 15:11:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.15802v2</guid></item><item><title>Improving Language Model Reasoning with Self-motivated Learning</title><link>http://arxiv.org/abs/2404.07017v1</link><description>Large-scale high-quality training data is important for improving theperformance of models. After trained with data that has rationales (reasoningsteps), models gain reasoning capability. However, the dataset withhigh-quality rationales is relatively scarce due to the high annotation cost.To address this issue, we propose \textit{Self-motivated Learning} framework.The framework motivates the model itself to automatically generate rationaleson existing datasets. Based on the inherent rank from correctness acrossmultiple rationales, the model learns to generate better rationales, leading tohigher reasoning capability. Specifically, we train a reward model with therank to evaluate the quality of rationales, and improve the performance ofreasoning through reinforcement learning. Experiment results of Llama2 7B onmultiple reasoning datasets show that our method significantly improves thereasoning ability of models, even outperforming text-davinci-002 in somedatasets.</description><author>Yunlong Feng, Yang Xu, Libo Qin, Yasheng Wang, Wanxiang Che</author><pubDate>Wed, 10 Apr 2024 15:05:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07017v1</guid></item><item><title>Trajectory-Oriented Policy Optimization with Sparse Rewards</title><link>http://arxiv.org/abs/2401.02225v3</link><description>Mastering deep reinforcement learning (DRL) proves challenging in tasksfeaturing scant rewards. These limited rewards merely signify whether the taskis partially or entirely accomplished, necessitating various explorationactions before the agent garners meaningful feedback. Consequently, themajority of existing DRL exploration algorithms struggle to acquire practicalpolicies within a reasonable timeframe. To address this challenge, we introducean approach leveraging offline demonstration trajectories for swifter and moreefficient online RL in environments with sparse rewards. Our pivotal insightinvolves treating offline demonstration trajectories as guidance, rather thanmere imitation, allowing our method to learn a policy whose distribution ofstate-action visitation marginally matches that of offline demonstrations. Wespecifically introduce a novel trajectory distance relying on maximum meandiscrepancy (MMD) and cast policy optimization as a distance-constrainedoptimization problem. We then illustrate that this optimization problem can bestreamlined into a policy-gradient algorithm, integrating rewards shaped byinsights from offline demonstrations. The proposed algorithm undergoesevaluation across extensive discrete and continuous control tasks with sparseand misleading rewards. The experimental findings demonstrate the significantsuperiority of our proposed algorithm over baseline methods concerning diverseexploration and the acquisition of an optimal policy.</description><author>Guojian Wang, Faguo Wu, Xiao Zhang</author><pubDate>Wed, 10 Apr 2024 15:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02225v3</guid></item><item><title>A Two-Stage Framework with Self-Supervised Distillation For Cross-Domain Text Classification</title><link>http://arxiv.org/abs/2304.09820v2</link><description>Cross-domain text classification aims to adapt models to a target domain thatlacks labeled data. It leverages or reuses rich labeled data from the differentbut related source domain(s) and unlabeled data from the target domain. To thisend, previous work focuses on either extracting domain-invariant features ortask-agnostic features, ignoring domain-aware features that may be present inthe target domain and could be useful for the downstream task. In this paper,we propose a two-stage framework for cross-domain text classification. In thefirst stage, we finetune the model with mask language modeling (MLM) andlabeled data from the source domain. In the second stage, we further fine-tunethe model with self-supervised distillation (SSD) and unlabeled data from thetarget domain. We evaluate its performance on a public cross-domain textclassification benchmark and the experiment results show that our methodachieves new state-of-the-art results for both single-source domain adaptations(94.17% $\uparrow$1.03%) and multi-source domain adaptations (95.09%$\uparrow$1.34%).</description><author>Yunlong Feng, Bohan Li, Libo Qin, Xiao Xu, Wanxiang Che</author><pubDate>Wed, 10 Apr 2024 15:03:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09820v2</guid></item><item><title>Data-Efficient Multimodal Fusion on a Single GPU</title><link>http://arxiv.org/abs/2312.10144v4</link><description>The goal of multimodal alignment is to learn a single latent space that isshared between multimodal inputs. The most powerful models in this space havebeen trained using massive datasets of paired inputs and large-scalecomputational resources, making them prohibitively expensive to train in manypractical scenarios. We surmise that existing unimodal encoders pre-trained onlarge amounts of unimodal data should provide an effective bootstrap to createmultimodal models from unimodal ones at much lower costs. We therefore proposeFuseMix, a multimodal augmentation scheme that operates on the latent spaces ofarbitrary pre-trained unimodal encoders. Using FuseMix for multimodalalignment, we achieve competitive performance -- and in certain casesoutperform state-of-the art methods -- in both image-text and audio-textretrieval, with orders of magnitude less compute and data: for example, weoutperform CLIP on the Flickr30K text-to-image retrieval task with $\sim \!600\times$ fewer GPU days and $\sim \! 80\times$ fewer image-text pairs.Additionally, we show how our method can be applied to convert pre-trainedtext-to-image generative models into audio-to-image ones. Code is available at:https://github.com/layer6ai-labs/fusemix.</description><author>Noël Vouitsis, Zhaoyan Liu, Satya Krishna Gorti, Valentin Villecroze, Jesse C. Cresswell, Guangwei Yu, Gabriel Loaiza-Ganem, Maksims Volkovs</author><pubDate>Wed, 10 Apr 2024 14:58:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10144v4</guid></item><item><title>Visibility into AI Agents</title><link>http://arxiv.org/abs/2401.13138v4</link><description>Increased delegation of commercial, scientific, governmental, and personalactivities to AI agents -- systems capable of pursuing complex goals withlimited supervision -- may exacerbate existing societal risks and introduce newrisks. Understanding and mitigating these risks involves critically evaluatingexisting governance structures, revising and adapting these structures whereneeded, and ensuring accountability of key stakeholders. Information aboutwhere, why, how, and by whom certain AI agents are used, which we refer to asvisibility, is critical to these objectives. In this paper, we assess threecategories of measures to increase visibility into AI agents: agentidentifiers, real-time monitoring, and activity logging. For each, we outlinepotential implementations that vary in intrusiveness and informativeness. Weanalyze how the measures apply across a spectrum of centralized throughdecentralized deployment contexts, accounting for various actors in the supplychain including hardware and software service providers. Finally, we discussthe implications of our measures for privacy and concentration of power.Further work into understanding the measures and mitigating their negativeimpacts can help to build a foundation for the governance of AI agents.</description><author>Alan Chan, Carson Ezell, Max Kaufmann, Kevin Wei, Lewis Hammond, Herbie Bradley, Emma Bluemke, Nitarshan Rajkumar, David Krueger, Noam Kolt, Lennart Heim, Markus Anderljung</author><pubDate>Wed, 10 Apr 2024 14:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13138v4</guid></item><item><title>A Mathematical Theory for Learning Semantic Languages by Abstract Learners</title><link>http://arxiv.org/abs/2404.07009v1</link><description>Recent advances in Large Language Models (LLMs) have demonstrated theemergence of capabilities (learned skills) when the number of system parametersand the size of training data surpass certain thresholds. The exact mechanismsbehind such phenomena are not fully understood and remain a topic of activeresearch. Inspired by the skill-text bipartite graph model presented in [1] formodeling semantic language, we develop a mathematical theory to explain theemergence of learned skills, taking the learning (or training) process intoaccount. Our approach models the learning process for skills in the skill-textbipartite graph as an iterative decoding process in Low-Density Parity Check(LDPC) codes and Irregular Repetition Slotted ALOHA (IRSA). Using densityevolution analysis, we demonstrate the emergence of learned skills when theratio of the size of training texts to the number of skills exceeds a certainthreshold. Our analysis also yields a scaling law for testing errors relativeto the size of training texts. Upon completion of the training, we propose amethod for semantic compression and discuss its application in semanticcommunication.</description><author>Kuo-Yu Liao, Cheng-Shang Chang, Y. -W. Peter Hong</author><pubDate>Wed, 10 Apr 2024 14:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07009v1</guid></item><item><title>Multi-Agent Soft Actor-Critic with Global Loss for Autonomous Mobility-on-Demand Fleet Control</title><link>http://arxiv.org/abs/2404.06975v1</link><description>We study a sequential decision-making problem for a profit-maximizingoperator of an Autonomous Mobility-on-Demand system. Optimizing a centraloperator's vehicle-to-request dispatching policy requires efficient andeffective fleet control strategies. To this end, we employ a multi-agent SoftActor-Critic algorithm combined with weighted bipartite matching. We propose anovel vehicle-based algorithm architecture and adapt the critic's loss functionto appropriately consider global actions. Furthermore, we extend our algorithmto incorporate rebalancing capabilities. Through numerical experiments, we showthat our approach outperforms state-of-the-art benchmarks by up to 12.9% fordispatching and up to 38.9% with integrated rebalancing.</description><author>Zeno Woywood, Jasper I. Wiltfang, Julius Luy, Tobias Enders, Maximilian Schiffer</author><pubDate>Wed, 10 Apr 2024 14:49:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06975v1</guid></item><item><title>Knowledge graphs for empirical concept retrieval</title><link>http://arxiv.org/abs/2404.07008v1</link><description>Concept-based explainable AI is promising as a tool to improve theunderstanding of complex models at the premises of a given user, viz.\ as atool for personalized explainability. An important class of concept-basedexplainability methods is constructed with empirically defined concepts,indirectly defined through a set of positive and negative examples, as in theTCAV approach (Kim et al., 2018). While it is appealing to the user to avoidformal definitions of concepts and their operationalization, it can bechallenging to establish relevant concept datasets. Here, we address thischallenge using general knowledge graphs (such as, e.g., Wikidata or WordNet)for comprehensive concept definition and present a workflow for user-drivendata collection in both text and image domains. The concepts derived fromknowledge graphs are defined interactively, providing an opportunity forpersonalization and ensuring that the concepts reflect the user's intentions.We test the retrieved concept datasets on two concept-based explainabilitymethods, namely concept activation vectors (CAVs) and concept activationregions (CARs) (Crabbe and van der Schaar, 2022). We show that CAVs and CARsbased on these empirical concept datasets provide robust and accurateexplanations. Importantly, we also find good alignment between the models'representations of concepts and the structure of knowledge graphs, i.e., humanrepresentations. This supports our conclusion that knowledge graph-basedconcepts are relevant for XAI.</description><author>Lenka Tětková, Teresa Karen Scheidt, Maria Mandrup Fogh, Ellen Marie Gaunby Jørgensen, Finn Årup Nielsen, Lars Kai Hansen</author><pubDate>Wed, 10 Apr 2024 14:47:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07008v1</guid></item><item><title>Building-road Collaborative Extraction from Remotely Sensed Images via Cross-Interaction</title><link>http://arxiv.org/abs/2307.12256v2</link><description>Buildings are the basic carrier of social production and human life; roadsare the links that interconnect social networks. Building and road informationhas important application value in the frontier fields of regional coordinateddevelopment, disaster prevention, auto-driving, etc. Mapping buildings androads from very high-resolution (VHR) remote sensing images have become a hotresearch topic. However, the existing methods often ignore the strong spatialcorrelation between roads and buildings and extract them in isolation. To fullyutilize the complementary advantages between buildings and roads, we propose abuilding-road collaborative extraction method based on multi-task andcross-scale feature interaction to improve the accuracy of both tasks in acomplementary way. A multi-task interaction module is proposed to interactinformation across tasks and preserve the unique information of each task,which tackle the seesaw phenomenon in multitask learning. By considering thevariation in appearance and structure between buildings and roads, across-scale interaction module is designed to automatically learn the optimalreception field for different tasks. Compared with many existing methods thattrain each task individually, the proposed collaborative extraction method canutilize the complementary advantages between buildings and roads by theproposed inter-task and inter-scale feature interactions, and automaticallyselect the optimal reception field for different tasks. Experiments on a widerange of urban and rural scenarios show that the proposed algorithm can achievebuilding-road extraction with outstanding performance and efficiency.</description><author>Haonan Guo, Xin Su, Chen Wu, Bo Du, Liangpei Zhang</author><pubDate>Wed, 10 Apr 2024 14:43:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12256v2</guid></item><item><title>WordDecipher: Enhancing Digital Workspace Communication with Explainable AI for Non-native English Speakers</title><link>http://arxiv.org/abs/2404.07005v1</link><description>Non-native English speakers (NNES) face challenges in digital workspacecommunication (e.g., emails, Slack messages), often inadvertently translatingexpressions from their native languages, which can lead to awkward or incorrectusage. Current AI-assisted writing tools are equipped with fluency enhancementand rewriting suggestions; however, NNES may struggle to grasp the subtletiesamong various expressions, making it challenging to choose the one thataccurately reflects their intent. Such challenges are exacerbated in high-staketext-based communications, where the absence of non-verbal cues heightens therisk of misinterpretation. By leveraging the latest advancements in largelanguage models (LLM) and word embeddings, we propose WordDecipher, anexplainable AI-assisted writing tool to enhance digital workspace communicationfor NNES. WordDecipher not only identifies the perceived social intentionsdetected in users' writing, but also generates rewriting suggestions alignedwith users' intended messages, either numerically or by inferring from users'writing in their native language. Then, WordDecipher provides an overview ofnuances to help NNES make selections. Through a usage scenario, we demonstratehow WordDecipher can significantly enhance an NNES's ability to communicate herrequest, showcasing its potential to transform workspace communication forNNES.</description><author>Yuexi Chen, Zhicheng Liu</author><pubDate>Wed, 10 Apr 2024 14:40:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07005v1</guid></item><item><title>LM Transparency Tool: Interactive Tool for Analyzing Transformer Language Models</title><link>http://arxiv.org/abs/2404.07004v1</link><description>We present the LM Transparency Tool (LM-TT), an open-source interactivetoolkit for analyzing the internal workings of Transformer-based languagemodels. Differently from previously existing tools that focus on isolated partsof the decision-making process, our framework is designed to make the entireprediction process transparent, and allows tracing back model behavior from thetop-layer representation to very fine-grained parts of the model. Specifically,it (1) shows the important part of the whole input-to-output information flow,(2) allows attributing any changes done by a model block to individualattention heads and feed-forward neurons, (3) allows interpreting the functionsof those heads or neurons. A crucial part of this pipeline is showing theimportance of specific model components at each step. As a result, we are ableto look at the roles of model components only in cases where they are importantfor a prediction. Since knowing which components should be inspected is key foranalyzing large models where the number of these components is extremely high,we believe our tool will greatly support the interpretability community both inresearch settings and in practical applications.</description><author>Igor Tufanov, Karen Hambardzumyan, Javier Ferrando, Elena Voita</author><pubDate>Wed, 10 Apr 2024 14:39:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07004v1</guid></item><item><title>L2MAC: Large Language Model Automatic Computer for Extensive Code Generation</title><link>http://arxiv.org/abs/2310.02003v5</link><description>Transformer-based large language models (LLMs) are constrained by the fixedcontext window of the underlying transformer architecture, hindering theirability to produce long and coherent outputs. Memory-augmented LLMs are apromising solution, but current approaches cannot handle long output generationtasks since they (1) only focus on reading memory and reduce its evolution tothe concatenation of new memories or (2) use very specialized memories thatcannot adapt to other domains. This paper presents L2MAC, the first practicalLLM-based general-purpose stored-program automatic computer (von Neumannarchitecture) framework, an LLM-based multi-agent system, for long andconsistent output generation. Its memory has two components: the instructionregistry, which is populated with a prompt program to solve the user-giventask, and a file store, which will contain the final and intermediate outputs.Each instruction in turn is executed by a separate LLM agent, whose context ismanaged by a control unit capable of precise memory reading and writing toensure effective interaction with the file store. These components enable L2MACto generate extensive outputs, bypassing the constraints of the finite contextwindow while producing outputs that fulfill a complex user-specified task. Weempirically demonstrate that L2MAC achieves state-of-the-art performance ingenerating large codebases for system design tasks, significantly outperformingother coding methods in implementing the detailed user-specified task; we showthat L2MAC works for general-purpose extensive text-based tasks, such aswriting an entire book; and we provide valuable insights into L2MAC'sperformance improvement over existing methods.</description><author>Samuel Holt, Max Ruiz Luyten, Mihaela van der Schaar</author><pubDate>Wed, 10 Apr 2024 14:38:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02003v5</guid></item><item><title>BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics</title><link>http://arxiv.org/abs/2312.07937v5</link><description>The recently emerging text-to-motion advances have spired numerous attemptsfor convenient and interactive human motion generation. Yet, existing methodsare largely limited to generating body motions only without considering therich two-hand motions, let alone handling various conditions like body dynamicsor texts. To break the data bottleneck, we propose BOTH57M, a novel multi-modaldataset for two-hand motion generation. Our dataset includes accurate motiontracking for the human body and hands and provides pair-wised finger-level handannotations and body descriptions. We further provide a strong baseline method,BOTH2Hands, for the novel task: generating vivid two-hand motions from bothimplicit body dynamics and explicit text prompts. We first warm up two parallelbody-to-hand and text-to-hand diffusion models and then utilize thecross-attention transformer for motion blending. Extensive experiments andcross-validations demonstrate the effectiveness of our approach and dataset forgenerating convincing two-hand motions from the hybrid body-and-textualconditions. Our dataset and code will be disseminated to the community forfuture research.</description><author>Wenqian Zhang, Molin Huang, Yuxuan Zhou, Juze Zhang, Jingyi Yu, Jingya Wang, Lan Xu</author><pubDate>Wed, 10 Apr 2024 14:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07937v5</guid></item></channel></rss>