<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 28 Nov 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating Video-based Large Language Models</title><link>http://arxiv.org/abs/2311.16103v1</link><description>Video-based large language models (Video-LLMs) have been recently introduced,targeting both fundamental improvements in perception and comprehension, and adiverse range of user inquiries. In pursuit of the ultimate goal of achievingartificial general intelligence, a truly intelligent Video-LLM model should notonly see and understand the surroundings, but also possess human-levelcommonsense, and make well-informed decisions for the users. To guide thedevelopment of such a model, the establishment of a robust and comprehensiveevaluation system becomes crucial. To this end, this paper proposes\textit{Video-Bench}, a new comprehensive benchmark along with a toolkitspecifically designed for evaluating Video-LLMs. The benchmark comprises 10meticulously crafted tasks, evaluating the capabilities of Video-LLMs acrossthree distinct levels: Video-exclusive Understanding, Prior Knowledge-basedQuestion-Answering, and Comprehension and Decision-making. In addition, weintroduce an automatic toolkit tailored to process model outputs for varioustasks, facilitating the calculation of metrics and generating convenient finalscores. We evaluate 8 representative Video-LLMs using \textit{Video-Bench}. Thefindings reveal that current Video-LLMs still fall considerably short ofachieving human-like comprehension and analysis of real-world videos, offeringvaluable insights for future research directions. The benchmark and toolkit areavailable at: \url{https://github.com/PKU-YuanGroup/Video-Bench}.</description><author>Munan Ning, Bin Zhu, Yujia Xie, Bin Lin, Jiaxi Cui, Lu Yuan, Dongdong Chen, Li Yuan</author><pubDate>Mon, 27 Nov 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16103v1</guid></item><item><title>Test-time Adaptation of Discriminative Models via Diffusion Generative Feedback</title><link>http://arxiv.org/abs/2311.16102v1</link><description>The advancements in generative modeling, particularly the advent of diffusionmodels, have sparked a fundamental question: how can these models beeffectively used for discriminative tasks? In this work, we find thatgenerative models can be great test-time adapters for discriminative models.Our method, Diffusion-TTA, adapts pre-trained discriminative models such asimage classifiers, segmenters and depth predictors, to each unlabelled examplein the test set using generative feedback from a diffusion model. We achievethis by modulating the conditioning of the diffusion model using the output ofthe discriminative model. We then maximize the image likelihood objective bybackpropagating the gradients to discriminative model's parameters. We showDiffusion-TTA significantly enhances the accuracy of various large-scalepre-trained discriminative models, such as, ImageNet classifiers, CLIP models,image pixel labellers and image depth predictors. Diffusion-TTA outperformsexisting test-time adaptation methods, including TTT-MAE and TENT, andparticularly shines in online adaptation setups, where the discriminative modelis continually adapted to each example in the test set. We provide access tocode, results, and visualizations on our website:https://diffusion-tta.github.io/.</description><author>Mihir Prabhudesai, Tsung-Wei Ke, Alexander C. Li, Deepak Pathak, Katerina Fragkiadaki</author><pubDate>Mon, 27 Nov 2023 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16102v1</guid></item><item><title>How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs</title><link>http://arxiv.org/abs/2311.16101v1</link><description>This work focuses on the potential of Vision LLMs (VLLMs) in visualreasoning. Different from prior studies, we shift our focus from evaluatingstandard performance to introducing a comprehensive safety evaluation suite,covering both out-of-distribution (OOD) generalization and adversarialrobustness. For the OOD evaluation, we present two novel VQA datasets, eachwith one variant, designed to test model performance under challengingconditions. In exploring adversarial robustness, we propose a straightforwardattack strategy for misleading VLLMs to produce visual-unrelated responses.Moreover, we assess the efficacy of two jailbreaking strategies, targetingeither the vision or language component of VLLMs. Our evaluation of 21 diversemodels, ranging from open-source VLLMs to GPT-4V, yields interestingobservations: 1) Current VLLMs struggle with OOD texts but not images, unlessthe visual information is limited; and 2) These VLLMs can be easily misled bydeceiving vision encoders only, and their vision-language training oftencompromise safety protocols. We release this safety evaluation suite athttps://github.com/UCSC-VLAA/vllm-safety-benchmark.</description><author>Haoqin Tu, Chenhang Cui, Zijun Wang, Yiyang Zhou, Bingchen Zhao, Junlin Han, Wangchunshu Zhou, Huaxiu Yao, Cihang Xie</author><pubDate>Mon, 27 Nov 2023 18:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16101v1</guid></item><item><title>GART: Gaussian Articulated Template Models</title><link>http://arxiv.org/abs/2311.16099v1</link><description>We introduce Gaussian Articulated Template Model GART, an explicit,efficient, and expressive representation for non-rigid articulated subjectcapturing and rendering from monocular videos. GART utilizes a mixture ofmoving 3D Gaussians to explicitly approximate a deformable subject's geometryand appearance. It takes advantage of a categorical template model prior (SMPL,SMAL, etc.) with learnable forward skinning while further generalizing to morecomplex non-rigid deformations with novel latent bones. GART can bereconstructed via differentiable rendering from monocular videos in seconds orminutes and rendered in novel poses faster than 150fps.</description><author>Jiahui Lei, Yufu Wang, Georgios Pavlakos, Lingjie Liu, Kostas Daniilidis</author><pubDate>Mon, 27 Nov 2023 18:59:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16099v1</guid></item><item><title>On Bringing Robots Home</title><link>http://arxiv.org/abs/2311.16098v1</link><description>Throughout history, we have successfully integrated various machines into ourhomes. Dishwashers, laundry machines, stand mixers, and robot vacuums are a fewrecent examples. However, these machines excel at performing only a single taskeffectively. The concept of a "generalist machine" in homes - a domesticassistant that can adapt and learn from our needs, all while remainingcost-effective - has long been a goal in robotics that has been steadilypursued for decades. In this work, we initiate a large-scale effort towardsthis goal by introducing Dobb-E, an affordable yet versatile general-purposesystem for learning robotic manipulation within household settings. Dobb-E canlearn a new task with only five minutes of a user showing it how to do it,thanks to a demonstration collection tool ("The Stick") we built out of cheapparts and iPhones. We use the Stick to collect 13 hours of data in 22 homes ofNew York City, and train Home Pretrained Representations (HPR). Then, in anovel home environment, with five minutes of demonstrations and fifteen minutesof adapting the HPR model, we show that Dobb-E can reliably solve the task onthe Stretch, a mobile robot readily available on the market. Across roughly 30days of experimentation in homes of New York City and surrounding areas, wetest our system in 10 homes, with a total of 109 tasks in differentenvironments, and finally achieve a success rate of 81%. Beyond successpercentages, our experiments reveal a plethora of unique challenges absent orignored in lab robotics. These range from effects of strong shadows, tovariable demonstration quality by non-expert users. With the hope ofaccelerating research on home robots, and eventually seeing robot butlers inevery home, we open-source Dobb-E software stack and models, our data, and ourhardware designs at https://dobb-e.com</description><author>Nur Muhammad Mahi Shafiullah, Anant Rai, Haritheja Etukuru, Yiqian Liu, Ishan Misra, Soumith Chintala, Lerrel Pinto</author><pubDate>Mon, 27 Nov 2023 18:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16098v1</guid></item><item><title>CG-HOI: Contact-Guided 3D Human-Object Interaction Generation</title><link>http://arxiv.org/abs/2311.16097v1</link><description>We propose CG-HOI, the first method to address the task of generating dynamic3D human-object interactions (HOIs) from text. We model the motion of bothhuman and object in an interdependent fashion, as semantically rich humanmotion rarely happens in isolation without any interactions. Our key insight isthat explicitly modeling contact between the human body surface and objectgeometry can be used as strong proxy guidance, both during training andinference. Using this guidance to bridge human and object motion enablesgenerating more realistic and physically plausible interaction sequences, wherethe human body and corresponding object move in a coherent manner. Our methodfirst learns to model human motion, object motion, and contact in a jointdiffusion process, inter-correlated through cross-attention. We then leveragethis learned contact for guidance during inference synthesis of realistic,coherent HOIs. Extensive evaluation shows that our joint contact-basedhuman-object interaction approach generates realistic and physically plausiblesequences, and we show two applications highlighting the capabilities of ourmethod. Conditioned on a given object trajectory, we can generate thecorresponding human motion without re-training, demonstrating stronghuman-object interdependency learning. Our approach is also flexible, and canbe applied to static real-world 3D scene scans.</description><author>Christian Diller, Angela Dai</author><pubDate>Mon, 27 Nov 2023 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16097v1</guid></item><item><title>Animatable Gaussians: Learning Pose-dependent Gaussian Maps for High-fidelity Human Avatar Modeling</title><link>http://arxiv.org/abs/2311.16096v1</link><description>Modeling animatable human avatars from RGB videos is a long-standing andchallenging problem. Recent works usually adopt MLP-based neural radiancefields (NeRF) to represent 3D humans, but it remains difficult for pure MLPs toregress pose-dependent garment details. To this end, we introduce AnimatableGaussians, a new avatar representation that leverages powerful 2D CNNs and 3DGaussian splatting to create high-fidelity avatars. To associate 3D Gaussianswith the animatable avatar, we learn a parametric template from the inputvideos, and then parameterize the template on two front \&amp; back canonicalGaussian maps where each pixel represents a 3D Gaussian. The learned templateis adaptive to the wearing garments for modeling looser clothes like dresses.Such template-guided 2D parameterization enables us to employ a powerfulStyleGAN-based CNN to learn the pose-dependent Gaussian maps for modelingdetailed dynamic appearances. Furthermore, we introduce a pose projectionstrategy for better generalization given novel poses. Overall, our method cancreate lifelike avatars with dynamic, realistic and generalized appearances.Experiments show that our method outperforms other state-of-the-art approaches.Code: https://github.com/lizhe00/AnimatableGaussians</description><author>Zhe Li, Zerong Zheng, Lizhen Wang, Yebin Liu</author><pubDate>Mon, 27 Nov 2023 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16096v1</guid></item><item><title>Street TryOn: Learning In-the-Wild Virtual Try-On from Unpaired Person Images</title><link>http://arxiv.org/abs/2311.16094v1</link><description>Virtual try-on has become a popular research topic, but most existing methodsfocus on studio images with a clean background. They can achieve plausibleresults for this studio try-on setting by learning to warp a garment image tofit a person's body from paired training data, i.e., garment images paired withimages of people wearing the same garment. Such data is often collected fromcommercial websites, where each garment is demonstrated both by itself and onseveral models. By contrast, it is hard to collect paired data for in-the-wildscenes, and therefore, virtual try-on for casual images of people againstcluttered backgrounds is rarely studied. In this work, we fill the gap in the current virtual try-on research by (1)introducing a Street TryOn benchmark to evaluate performance on street scenesand (2) proposing a novel method that can learn without paired data, from a setof in-the-wild person images directly. Our method can achieve robustperformance across shop and street domains using a novel DensePose warpingcorrection method combined with diffusion-based inpainting controlled by poseand semantic segmentation. Our experiments demonstrate competitive performancefor standard studio try-on tasks and SOTA performance for street try-on andcross-domain try-on tasks.</description><author>Aiyu Cui, Jay Mahajan, Viraj Shah, Preeti Gomathinayagam, Svetlana Lazebnik</author><pubDate>Mon, 27 Nov 2023 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16094v1</guid></item><item><title>Have we built machines that think like people?</title><link>http://arxiv.org/abs/2311.16093v1</link><description>A chief goal of artificial intelligence is to build machines that think likepeople. Yet it has been argued that deep neural network architectures fail toaccomplish this. Researchers have asserted these models' limitations in thedomains of causal reasoning, intuitive physics, and intuitive psychology. Yetrecent advancements, namely the rise of large language models, particularlythose designed for visual processing, have rekindled interest in the potentialto emulate human-like cognitive abilities. This paper evaluates the currentstate of vision-based large language models in the domains of intuitivephysics, causal reasoning, and intuitive psychology. Through a series ofcontrolled experiments, we investigate the extent to which these modern modelsgrasp complex physical interactions, causal relationships, and intuitiveunderstanding of others' preferences. Our findings reveal that, while thesemodels demonstrate a notable proficiency in processing and interpreting visualdata, they still fall short of human capabilities in these areas. The modelsexhibit a rudimentary understanding of physical laws and causal relationships,but their performance is hindered by a lack of deeper insights-a key aspect ofhuman cognition. Furthermore, in tasks requiring an intuitive theory of mind,the models fail altogether. Our results emphasize the need for integrating morerobust mechanisms for understanding causality, physical dynamics, and socialcognition into modern-day, vision-based language models, and point out theimportance of cognitively-inspired benchmarks.</description><author>Luca M. Schulze Buschoff, Elif Akata, Matthias Bethge, Eric Schulz</author><pubDate>Mon, 27 Nov 2023 18:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16093v1</guid></item><item><title>Interactive Autonomous Navigation with Internal State Inference and Interactivity Estimation</title><link>http://arxiv.org/abs/2311.16091v1</link><description>Deep reinforcement learning (DRL) provides a promising way for intelligentagents (e.g., autonomous vehicles) to learn to navigate complex scenarios.However, DRL with neural networks as function approximators is typicallyconsidered a black box with little explainability and often suffers fromsuboptimal performance, especially for autonomous navigation in highlyinteractive multi-agent environments. To address these issues, we propose threeauxiliary tasks with spatio-temporal relational reasoning and integrate theminto the standard DRL framework, which improves the decision making performanceand provides explainable intermediate indicators. We propose to explicitlyinfer the internal states (i.e., traits and intentions) of surrounding agents(e.g., human drivers) as well as to predict their future trajectories in thesituations with and without the ego agent through counterfactual reasoning.These auxiliary tasks provide additional supervision signals to infer thebehavior patterns of other interactive agents. Multiple variants of frameworkintegration strategies are compared. We also employ a spatio-temporal graphneural network to encode relations between dynamic entities, which enhancesboth internal state inference and decision making of the ego agent. Moreover,we propose an interactivity estimation mechanism based on the differencebetween predicted trajectories in these two situations, which indicates thedegree of influence of the ego agent on other agents. To validate the proposedmethod, we design an intersection driving simulator based on the IntelligentIntersection Driver Model (IIDM) that simulates vehicles and pedestrians. Ourapproach achieves robust and state-of-the-art performance in terms of standardevaluation metrics and provides explainable intermediate indicators (i.e.,internal states, and interactivity scores) for decision making.</description><author>Jiachen Li, David Isele, Kanghoon Lee, Jinkyoo Park, Kikuo Fujimura, Mykel J. Kochenderfer</author><pubDate>Mon, 27 Nov 2023 18:57:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16091v1</guid></item><item><title>Self-correcting LLM-controlled Diffusion Models</title><link>http://arxiv.org/abs/2311.16090v1</link><description>Text-to-image generation has witnessed significant progress with the adventof diffusion models. Despite the ability to generate photorealistic images,current text-to-image diffusion models still often struggle to accuratelyinterpret and follow complex input text prompts. In contrast to existing modelsthat aim to generate images only with their best effort, we introduceSelf-correcting LLM-controlled Diffusion (SLD). SLD is a framework thatgenerates an image from the input prompt, assesses its alignment with theprompt, and performs self-corrections on the inaccuracies in the generatedimage. Steered by an LLM controller, SLD turns text-to-image generation into aniterative closed-loop process, ensuring correctness in the resulting image. SLDis not only training-free but can also be seamlessly integrated with diffusionmodels behind API access, such as DALL-E 3, to further boost the performance ofstate-of-the-art diffusion models. Experimental results show that our approachcan rectify a majority of incorrect generations, particularly in generativenumeracy, attribute binding, and spatial relationships. Furthermore, by simplyadjusting the instructions to the LLM, SLD can perform image editing tasks,bridging the gap between text-to-image generation and image editing pipelines.We will make our code available for future research and applications.</description><author>Tsung-Han Wu, Long Lian, Joseph E. Gonzalez, Boyi Li, Trevor Darrell</author><pubDate>Mon, 27 Nov 2023 18:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16090v1</guid></item><item><title>DUnE: Dataset for Unified Editing</title><link>http://arxiv.org/abs/2311.16087v1</link><description>Even the most advanced language models remain susceptible to errorsnecessitating to modify these models without initiating a comprehensiveretraining process. Model editing refers to the modification of a model'sknowledge or representations in a manner that produces the desired outcomes.Prior research primarily centered around editing factual data e.g. "Messi playsfor Inter Miami" confining the definition of an edit to a knowledge tripleti.e. (subject, object, relation). However, as the applications of languagemodels expand, so do the diverse ways in which we wish to edit and refine theiroutputs. In this study, we broaden the scope of the editing problem to includean array of editing cases such as debiasing and rectifying reasoning errors anddefine an edit as any natural language expression that solicits a change in themodel's outputs. We are introducing DUnE-an editing benchmark where edits arenatural language sentences and propose that DUnE presents a challenging yetrelevant task. To substantiate this claim, we conduct an extensive series ofexperiments testing various editing approaches to address DUnE, demonstratingtheir respective strengths and weaknesses. We show that retrieval-augmentedlanguage modeling can outperform specialized editing techniques and neither setof approaches has fully solved the generalized editing problem covered by ourbenchmark.</description><author>Afra Feyza Akyürek, Eric Pan, Garry Kuwanto, Derry Wijaya</author><pubDate>Mon, 27 Nov 2023 18:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16087v1</guid></item><item><title>MAST: Model-Agnostic Sparsified Training</title><link>http://arxiv.org/abs/2311.16086v1</link><description>We introduce a novel optimization problem formulation that departs from theconventional way of minimizing machine learning model loss as a black-boxfunction. Unlike traditional formulations, the proposed approach explicitlyincorporates an initially pre-trained model and random sketch operators,allowing for sparsification of both the model and gradient during training. Weestablish insightful properties of the proposed objective function andhighlight its connections to the standard formulation. Furthermore, we presentseveral variants of the Stochastic Gradient Descent (SGD) method adapted to thenew problem formulation, including SGD with general sampling, a distributedversion, and SGD with variance reduction techniques. We achieve tighterconvergence rates and relax assumptions, bridging the gap between theoreticalprinciples and practical applications, covering several important techniquessuch as Dropout and Sparse training. This work presents promising opportunitiesto enhance the theoretical understanding of model training through asparsification-aware optimization approach.</description><author>Yury Demidovich, Grigory Malinovsky, Egor Shulgin, Peter Richtárik</author><pubDate>Mon, 27 Nov 2023 18:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16086v1</guid></item><item><title>BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using Genre Classification</title><link>http://arxiv.org/abs/2311.16083v1</link><description>While performance of many text classification tasks has been recentlyimproved due to Pre-trained Language Models (PLMs), in this paper we show thatthey still suffer from a performance gap when the underlying distribution oftopics changes. For example, a genre classifier trained on \textit{political}topics often fails when tested on documents about \textit{sport} or\textit{medicine}. In this work, we quantify this phenomenon empirically with alarge corpus and a large set of topics. Consequently, we verify that domaintransfer remains challenging both for classic PLMs, such as BERT, and formodern large models, such as GPT-3. We also suggest and successfully test apossible remedy: after augmenting the training dataset withtopically-controlled synthetic texts, the F1 score improves by up to 50\% forsome topics, nearing on-topic training results, while others show little to noimprovement. While our empirical results focus on genre classification, ourmethodology is applicable to other classification tasks such as gender,authorship, or sentiment classification. The code and data to replicate theexperiments are available at https://github.com/dminus1/genre</description><author>Dmitri Roussinov, Serge Sharoff</author><pubDate>Mon, 27 Nov 2023 18:53:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16083v1</guid></item><item><title>Transformer-QEC: Quantum Error Correction Code Decoding with Transferable Transformers</title><link>http://arxiv.org/abs/2311.16082v1</link><description>Quantum computing has the potential to solve problems that are intractablefor classical systems, yet the high error rates in contemporary quantum devicesoften exceed tolerable limits for useful algorithm execution. Quantum ErrorCorrection (QEC) mitigates this by employing redundancy, distributing quantuminformation across multiple data qubits and utilizing syndrome qubits tomonitor their states for errors. The syndromes are subsequently interpreted bya decoding algorithm to identify and correct errors in the data qubits. Thistask is complex due to the multiplicity of error sources affecting both dataand syndrome qubits as well as syndrome extraction operations. Additionally,identical syndromes can emanate from different error sources, necessitating adecoding algorithm that evaluates syndromes collectively. Although machinelearning (ML) decoders such as multi-layer perceptrons (MLPs) and convolutionalneural networks (CNNs) have been proposed, they often focus on local syndromeregions and require retraining when adjusting for different code distances. Weintroduce a transformer-based QEC decoder which employs self-attention toachieve a global receptive field across all input syndromes. It incorporates amixed loss training approach, combining both local physical error and globalparity label losses. Moreover, the transformer architecture's inherentadaptability to variable-length inputs allows for efficient transfer learning,enabling the decoder to adapt to varying code distances without retraining. Evaluation on six code distances and ten different error configurationsdemonstrates that our model consistently outperforms non-ML decoders, such asUnion Find (UF) and Minimum Weight Perfect Matching (MWPM), and other MLdecoders, thereby achieving best logical error rates. Moreover, the transferlearning can save over 10x of training cost.</description><author>Hanrui Wang, Pengyu Liu, Kevin Shao, Dantong Li, Jiaqi Gu, David Z. Pan, Yongshan Ding, Song Han</author><pubDate>Mon, 27 Nov 2023 18:52:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16082v1</guid></item><item><title>ViT-Lens-2: Gateway to Omni-modal Intelligence</title><link>http://arxiv.org/abs/2311.16081v1</link><description>Aiming to advance AI agents, large foundation models significantly improvereasoning and instruction execution, yet the current focus on vision andlanguage neglects the potential of perceiving diverse modalities in open-worldenvironments. However, the success of data-driven vision and language models iscostly or even infeasible to be reproduced for rare modalities. In this paper,we present ViT-Lens-2 that facilitates efficient omni-modal representationlearning by perceiving novel modalities with a pretrained ViT and aligning themto a pre-defined space. Specifically, the modality-specific lens is tuned toproject any-modal signals to an intermediate embedding space, which are thenprocessed by a strong ViT with pre-trained visual knowledge. The encodedrepresentations are optimized toward aligning with the modal-independent space,pre-defined by off-the-shelf foundation models. ViT-Lens-2 provides a unifiedsolution for representation learning of increasing modalities with twoappealing advantages: (i) Unlocking the great potential of pretrained ViTs tonovel modalities effectively with efficient data regime; (ii) Enabling emergentdownstream capabilities through modality alignment and shared ViT parameters.We tailor ViT-Lens-2 to learn representations for 3D point cloud, depth, audio,tactile and EEG, and set new state-of-the-art results across variousunderstanding tasks, such as zero-shot classification. By seamlesslyintegrating ViT-Lens-2 into Multimodal Foundation Models, we enableAny-modality to Text and Image Generation in a zero-shot manner. Code andmodels are available at https://github.com/TencentARC/ViT-Lens.</description><author>Weixian Lei, Yixiao Ge, Kun Yi, Jianfeng Zhang, Difei Gao, Dylan Sun, Yuying Ge, Ying Shan, Mike Zheng Shou</author><pubDate>Mon, 27 Nov 2023 18:52:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16081v1</guid></item><item><title>XLB: Distributed Multi-GPU Lattice Boltzmann Simulation Framework for Differentiable Scientific Machine Learning</title><link>http://arxiv.org/abs/2311.16080v1</link><description>The lattice Boltzmann method (LBM) has emerged as a prominent technique forsolving fluid dynamics problems due to its algorithmic potential forcomputational scalability. We introduce XLB framework, a Python-baseddifferentiable LBM library which harnesses the capabilities of the JAXframework. The architecture of XLB is predicated upon ensuring accessibility,extensibility, and computational performance, enabling scaling effectivelyacross CPU, multi-GPU, and distributed multi-GPU systems. The framework can bereadily augmented with novel boundary conditions, collision models, orsimulation capabilities. XLB offers the unique advantage of integration withJAX's extensive machine learning echosystem, and the ability to utilizeautomatic differentiation for tackling physics-based machine learning,optimization, and inverse problems. XLB has been successfully scaled to handlesimulations with billions of cells, achieving giga-scale lattice updates persecond. XLB is released under the permissive Apache-2.0 license and isavailable on GitHub at https://github.com/Autodesk/XLB.</description><author>Mohammadmehdi Ataei, Hesam Salehipour</author><pubDate>Mon, 27 Nov 2023 18:50:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16080v1</guid></item><item><title>MEDITRON-70B: Scaling Medical Pretraining for Large Language Models</title><link>http://arxiv.org/abs/2311.16079v1</link><description>Large language models (LLMs) can potentially democratize access to medicalknowledge. While many efforts have been made to harness and improve LLMs'medical knowledge and reasoning capacities, the resulting models are eitherclosed-source (e.g., PaLM, GPT-4) or limited in scale (&lt;= 13B parameters),which restricts their abilities. In this work, we improve access to large-scalemedical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70Bparameters adapted to the medical domain. MEDITRON builds on Llama-2 (throughour adaptation of Nvidia's Megatron-LM distributed trainer), and extendspretraining on a comprehensively curated medical corpus, including selectedPubMed articles, abstracts, and internationally-recognized medical guidelines.Evaluations using four major medical benchmarks show significant performancegains over several state-of-the-art baselines before and after task-specificfinetuning. Overall, MEDITRON achieves a 6% absolute performance gain over thebest public baseline in its parameter class and 3% over the strongest baselinewe finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70Boutperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% ofMed-PaLM-2. We release our code for curating the medical pretraining corpus andthe MEDITRON model weights to drive open-source development of more capablemedical LLMs.</description><author>Zeming Chen, Alejandro Hernández Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, Francesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Köpf, Amirkeivan Mohtashami, Alexandre Sallinen, Alireza Sakhaeirad, Vinitra Swamy, Igor Krawczuk, Deniz Bayazit, Axel Marmet, Syrielle Montariol, Mary-Anne Hartley, Martin Jaggi, Antoine Bosselut</author><pubDate>Mon, 27 Nov 2023 18:49:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16079v1</guid></item><item><title>FutureHuman3D: Forecasting Complex Long-Term 3D Human Behavior from Video Observations</title><link>http://arxiv.org/abs/2211.14309v2</link><description>We present a generative approach to forecast long-term future human behaviorin 3D, requiring only weak supervision from readily available 2D human actiondata. This is a fundamental task enabling many downstream applications. Therequired ground-truth data is hard to capture in 3D (mocap suits, expensivesetups) but easy to acquire in 2D (simple RGB cameras). Thus, we design ourmethod to only require 2D RGB data while being able to generate 3D human motionsequences. We use a differentiable 2D projection scheme in an autoregressivemanner for weak supervision, and an adversarial loss for 3D regularization. Ourmethod predicts long and complex behavior sequences (e.g. cooking, assembly)consisting of multiple sub-actions. We tackle this in a semanticallyhierarchical manner, jointly predicting high-level coarse action labelstogether with their low-level fine-grained realizations as characteristic 3Dhuman poses. We observe that these two action representations are coupled innature, and joint prediction benefits both action and pose forecasting. Ourexperiments demonstrate the complementary nature of joint action and 3D poseprediction: our joint approach outperforms each task treated individually,enables robust longer-term sequence prediction, and outperforms alternativeapproaches to forecast actions and characteristic 3D poses.</description><author>Christian Diller, Thomas Funkhouser, Angela Dai</author><pubDate>Mon, 27 Nov 2023 18:48:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.14309v2</guid></item><item><title>BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical Knowledge Graph Insights</title><link>http://arxiv.org/abs/2311.16075v1</link><description>In this study, we investigate the potential of Large Language Models tocomplement biomedical knowledge graphs in the training of semantic models forthe biomedical and clinical domains. Drawing on the wealth of the UMLSknowledge graph and harnessing cutting-edge Large Language Models, we propose anew state-of-the-art approach for obtaining high-fidelity representations ofbiomedical concepts and sentences, consisting of three steps: an improvedcontrastive learning phase, a novel self-distillation phase, and a weightaveraging phase. Through rigorous evaluations via the extensive BioLORD testingsuite and diverse downstream tasks, we demonstrate consistent and substantialperformance improvements over the previous state of the art (e.g. +2pts onMedSTS, +2.5pts on MedNLI-S, +6.1pts on EHR-Rel-B). Besides our newstate-of-the-art biomedical model for English, we also distill and release amultilingual model compatible with 50+ languages and finetuned on 7 Europeanlanguages. Many clinical pipelines can benefit from our latest models. Our newmultilingual model enables a range of languages to benefit from ouradvancements in biomedical semantic representation learning, opening a newavenue for bioinformatics researchers around the world. As a result, we hope tosee BioLORD-2023 becoming a precious tool for future biomedical applications.</description><author>François Remy, Kris Demuynck, Thomas Demeester</author><pubDate>Mon, 27 Nov 2023 18:46:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16075v1</guid></item><item><title>A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective</title><link>http://arxiv.org/abs/2311.16065v1</link><description>This review paper takes a comprehensive look at malicious attacks against FL,categorizing them from new perspectives on attack origins and targets, andproviding insights into their methodology and impact. In this survey, we focuson threat models targeting the learning process of FL systems. Based on thesource and target of the attack, we categorize existing threat models into fourtypes, Data to Model (D2M), Model to Data (M2D), Model to Model (M2M) andcomposite attacks. For each attack type, we discuss the defense strategiesproposed, highlighting their effectiveness, assumptions and potential areas forimprovement. Defense strategies have evolved from using a singular metric toexcluding malicious clients, to employing a multifaceted approach examiningclient models at various phases. In this survey paper, our research indicatesthat the to-learn data, the learning gradients, and the learned model atdifferent stages all can be manipulated to initiate malicious attacks thatrange from undermining model performance, reconstructing private local data,and to inserting backdoors. We have also seen these threat are becoming moreinsidious. While earlier studies typically amplified malicious gradients,recent endeavors subtly alter the least significant weights in local models tobypass defense measures. This literature review provides a holisticunderstanding of the current FL threat landscape and highlights the importanceof developing robust, efficient, and privacy-preserving defenses to ensure thesafe and trusted adoption of FL in real-world applications.</description><author>Xianghua Xie, Chen Hu, Hanchi Ren, Jingjing Deng</author><pubDate>Mon, 27 Nov 2023 18:32:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16065v1</guid></item><item><title>Machine learning-based decentralized TDMA for VLC IoT networks</title><link>http://arxiv.org/abs/2311.14078v2</link><description>In this paper, a machine learning-based decentralized time division multipleaccess (TDMA) algorithm for visible light communication (VLC) Internet ofThings (IoT) networks is proposed. The proposed algorithm is based onQ-learning, a reinforcement learning algorithm. This paper considers adecentralized condition in which there is no coordinator node for sendingsynchronization frames and assigning transmission time slots to other nodes.The proposed algorithm uses a decentralized manner for synchronization, andeach node uses the Q-learning algorithm to find the optimal transmission timeslot for sending data without collisions. The proposed algorithm is implementedon a VLC hardware system, which had been designed and implemented in ourlaboratory. Average reward, convergence time, goodput, average delay, and datapacket size are evaluated parameters. The results show that the proposedalgorithm converges quickly and provides collision-free decentralized TDMA forthe network. The proposed algorithm is compared with carrier-sense multipleaccess with collision avoidance (CSMA/CA) algorithm as a potential selectionfor decentralized VLC IoT networks. The results show that the proposedalgorithm provides up to 61% more goodput and up to 49% less average delay thanCSMA/CA.</description><author>Armin Makvandi, Yousef Seifi Kavian</author><pubDate>Mon, 27 Nov 2023 18:31:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14078v2</guid></item><item><title>Self-Guided Diffusion Models</title><link>http://arxiv.org/abs/2210.06462v3</link><description>Diffusion models have demonstrated remarkable progress in image generationquality, especially when guidance is used to control the generative process.However, guidance requires a large amount of image-annotation pairs fortraining and is thus dependent on their availability, correctness andunbiasedness. In this paper, we eliminate the need for such annotation byinstead leveraging the flexibility of self-supervision signals to design aframework for self-guided diffusion models. By leveraging a feature extractionfunction and a self-annotation function, our method provides guidance signalsat various image granularities: from the level of holistic images to objectboxes and even segmentation masks. Our experiments on single-label andmulti-label image datasets demonstrate that self-labeled guidance alwaysoutperforms diffusion models without guidance and may even surpass guidancebased on ground-truth labels, especially on unbalanced data. When equipped withself-supervised box or mask proposals, our method further generates visuallydiverse yet semantically consistent images, without the need for any class,box, or segment label annotation. Self-guided diffusion is simple, flexible andexpected to profit from deployment at scale. Source code will be at:https://taohu.me/sgdm/</description><author>Vincent Tao Hu, David W Zhang, Yuki M. Asano, Gertjan J. Burghouts, Cees G. M. Snoek</author><pubDate>Mon, 27 Nov 2023 18:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06462v3</guid></item><item><title>A deep reinforcement learning model for predictive maintenance planning of road assets: Integrating LCA and LCCA</title><link>http://arxiv.org/abs/2112.12589v3</link><description>Road maintenance planning is an integral part of road asset management. Oneof the main challenges in Maintenance and Rehabilitation (M&amp;R) practices is todetermine maintenance type and timing. This research proposes a framework usingReinforcement Learning (RL) based on the Long Term Pavement Performance (LTPP)database to determine the type and timing of M&amp;R practices. A predictive DNNmodel is first developed in the proposed algorithm, which serves as theEnvironment for the RL algorithm. For the Policy estimation of the RL model,both DQN and PPO models are developed. However, PPO has been selected in theend due to better convergence and higher sample efficiency. Indicators used inthis study are International Roughness Index (IRI) and Rutting Depth (RD).Initially, we considered Cracking Metric (CM) as the third indicator, but itwas then excluded due to the much fewer data compared to other indicators,which resulted in lower accuracy of the results. Furthermore, incost-effectiveness calculation (reward), we considered both the economic andenvironmental impacts of M&amp;R treatments. Costs and environmental impacts havebeen evaluated with paLATE 2.0 software. Our method is tested on a hypotheticalcase study of a six-lane highway with 23 kilometers length located in Texas,which has a warm and wet climate. The results propose a 20-year M&amp;R plan inwhich road condition remains in an excellent condition range. Because the earlystate of the road is at a good level of service, there is no need for heavymaintenance practices in the first years. Later, after heavy M&amp;R actions, thereare several 1-2 years of no need for treatments. All of these show that theproposed plan has a logical result. Decision-makers and transportation agenciescan use this scheme to conduct better maintenance practices that can preventbudget waste and, at the same time, minimize the environmental impacts.</description><author>Moein Latifi, Fateme Golivand Darvishvand, Omid Khandel, Mobin Latifi Nowsoud</author><pubDate>Mon, 27 Nov 2023 18:29:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.12589v3</guid></item><item><title>DiffSLVA: Harnessing Diffusion Models for Sign Language Video Anonymization</title><link>http://arxiv.org/abs/2311.16060v1</link><description>Since American Sign Language (ASL) has no standard written form, Deaf signersfrequently share videos in order to communicate in their native language.However, since both hands and face convey critical linguistic information insigned languages, sign language videos cannot preserve signer privacy. Whilesigners have expressed interest, for a variety of applications, in signlanguage video anonymization that would effectively preserve linguisticcontent, attempts to develop such technology have had limited success, giventhe complexity of hand movements and facial expressions. Existing approachesrely predominantly on precise pose estimations of the signer in video footageand often require sign language video datasets for training. These requirementsprevent them from processing videos 'in the wild,' in part because of thelimited diversity present in current sign language video datasets. To addressthese limitations, our research introduces DiffSLVA, a novel methodology thatutilizes pre-trained large-scale diffusion models for zero-shot text-guidedsign language video anonymization. We incorporate ControlNet, which leverageslow-level image features such as HED (Holistically-Nested Edge Detection)edges, to circumvent the need for pose estimation. Additionally, we develop aspecialized module dedicated to capturing facial expressions, which arecritical for conveying essential linguistic information in signed languages. Wethen combine the above methods to achieve anonymization that better preservesthe essential linguistic content of the original signer. This innovativemethodology makes possible, for the first time, sign language videoanonymization that could be used for real-world applications, which would offersignificant benefits to the Deaf and Hard-of-Hearing communities. Wedemonstrate the effectiveness of our approach with a series of signeranonymization experiments.</description><author>Zhaoyang Xia, Carol Neidle, Dimitris N. Metaxas</author><pubDate>Mon, 27 Nov 2023 18:26:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16060v1</guid></item><item><title>Online Estimation and Optimization of Utility-Based Shortfall Risk</title><link>http://arxiv.org/abs/2111.08805v3</link><description>Utility-Based Shortfall Risk (UBSR) is a risk metric that is increasinglypopular in financial applications, owing to certain desirable properties thatit enjoys. We consider the problem of estimating UBSR in a recursive setting,where samples from the underlying loss distribution are availableone-at-a-time. We cast the UBSR estimation problem as a root finding problem,and propose stochastic approximation-based estimations schemes. We derivenon-asymptotic bounds on the estimation error in the number of samples. We alsoconsider the problem of UBSR optimization within a parameterized class ofrandom variables. We propose a stochastic gradient descent based algorithm forUBSR optimization, and derive non-asymptotic bounds on its convergence.</description><author>Vishwajit Hegde, Arvind S. Menon, L. A. Prashanth, Krishna Jagannathan</author><pubDate>Mon, 27 Nov 2023 18:24:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.08805v3</guid></item><item><title>Nova$^+$: Generative Language Models for Binaries</title><link>http://arxiv.org/abs/2311.13721v2</link><description>Generative large language models (LLMs) pre-trained on code have shownimpressive effectiveness in code generation, program repair, and documentanalysis. However, existing generative LLMs focus on source code and are notspecialized for binaries. There are three main challenges for LLMs to model andlearn binary code: hex-decimal values, complex global dependencies, andcompiler optimization levels. To bring the benefit of LLMs to the binarydomain, we develop Nova and Nova$^+$, which are LLMs pre-trained on binarycorpora. Nova is pre-trained with the standard language modeling task, showingsignificantly better capability on five benchmarks for three downstream tasks:binary code similarity detection (BCSD), binary code translation (BCT), andbinary code recovery (BCR), over GPT-3.5 and other existing techniques. Webuild Nova$^+$ to further boost Nova using two new pre-training tasks, i.e.,optimization generation and optimization level prediction, which are designedto learn binary optimization and align equivalent binaries. Nova$^+$ showsoverall the best performance for all three downstream tasks on five benchmarks,demonstrating the contributions of the new pre-training tasks.</description><author>Nan Jiang, Chengxiao Wang, Kevin Liu, Xiangzhe Xu, Lin Tan, Xiangyu Zhang</author><pubDate>Mon, 27 Nov 2023 18:22:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13721v2</guid></item><item><title>Metric Space Magnitude for Evaluating Unsupervised Representation Learning</title><link>http://arxiv.org/abs/2311.16054v1</link><description>The magnitude of a metric space was recently established as a novelinvariant, providing a measure of the `effective size' of a space acrossmultiple scales. By capturing both geometrical and topological properties ofdata, magnitude is poised to address challenges in unsupervised representationlearning tasks. We formalise a novel notion of dissimilarity between magnitudefunctions of finite metric spaces and use them to derive a quality measure fordimensionality reduction tasks. Our measure is provably stable underperturbations of the data, can be efficiently calculated, and enables arigorous multi-scale comparison of embeddings. We show the utility of ourmeasure in an experimental suite that comprises different domains and tasks,including the comparison of data visualisations.</description><author>Katharina Limbeck, Rayna Andreeva, Rik Sarkar, Bastian Rieck</author><pubDate>Mon, 27 Nov 2023 18:19:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16054v1</guid></item><item><title>Exploring Attribute Variations in Style-based GANs using Diffusion Models</title><link>http://arxiv.org/abs/2311.16052v1</link><description>Existing attribute editing methods treat semantic attributes as binary,resulting in a single edit per attribute. However, attributes such aseyeglasses, smiles, or hairstyles exhibit a vast range of diversity. In thiswork, we formulate the task of \textit{diverse attribute editing} by modelingthe multidimensional nature of attribute edits. This enables users to generatemultiple plausible edits per attribute. We capitalize on disentangled latentspaces of pretrained GANs and train a Denoising Diffusion Probabilistic Model(DDPM) to learn the latent distribution for diverse edits. Specifically, wetrain DDPM over a dataset of edit latent directions obtained by embedding imagepairs with a single attribute change. This leads to latent subspaces thatenable diverse attribute editing. Applying diffusion in the highly compressedlatent space allows us to model rich distributions of edits within limitedcomputational resources. Through extensive qualitative and quantitativeexperiments conducted across a range of datasets, we demonstrate theeffectiveness of our approach for diverse attribute editing. We also showcasethe results of our method applied for 3D editing of various face attributes.</description><author>Rishubh Parihar, Prasanna Balaji, Raghav Magazine, Sarthak Vora, Tejan Karmali, Varun Jampani, R. Venkatesh Babu</author><pubDate>Mon, 27 Nov 2023 18:14:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16052v1</guid></item><item><title>Neuradicon: operational representation learning of neuroimaging reports</title><link>http://arxiv.org/abs/2107.10021v2</link><description>Radiological reports typically summarize the content and interpretation ofimaging studies in unstructured form that precludes quantitative analysis. Thislimits the monitoring of radiological services to throughput undifferentiatedby content, impeding specific, targeted operational optimization. Here wepresent Neuradicon, a natural language processing (NLP) framework forquantitative analysis of neuroradiological reports. Our framework is a hybridof rule-based and artificial intelligence models to represent neurologicalreports in succinct, quantitative form optimally suited to operationalguidance. We demonstrate the application of Neuradicon to operationalphenotyping of a corpus of 336,569 reports, and report excellentgeneralizability across time and two independent healthcare institutions.</description><author>Henry Watkins, Robert Gray, Adam Julius, Yee-Haur Mah, Walter H. L. Pinaya, Paul Wright, Ashwani Jha, Holger Engleitner, Jorge Cardoso, Sebastien Ourselin, Geraint Rees, Rolf Jaeger, Parashkev Nachev</author><pubDate>Mon, 27 Nov 2023 18:09:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.10021v2</guid></item><item><title>Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF Decomposition and Ray Tracing</title><link>http://arxiv.org/abs/2311.16043v1</link><description>We present a novel differentiable point-based rendering framework formaterial and lighting decomposition from multi-view images, enabling editing,ray-tracing, and real-time relighting of the 3D point cloud. Specifically, a 3Dscene is represented as a set of relightable 3D Gaussian points, where eachpoint is additionally associated with a normal direction, BRDF parameters, andincident lights from different directions. To achieve robust lightingestimation, we further divide incident lights of each point into global andlocal components, as well as view-dependent visibilities. The 3D scene isoptimized through the 3D Gaussian Splatting technique while BRDF and lightingare decomposed by physically-based differentiable rendering. Moreover, weintroduce an innovative point-based ray-tracing approach based on the boundingvolume hierarchy for efficient visibility baking, enabling real-time renderingand relighting of 3D Gaussian points with accurate shadow effects. Extensiveexperiments demonstrate improved BRDF estimation and novel view renderingresults compared to state-of-the-art material estimation approaches. Ourframework showcases the potential to revolutionize the mesh-based graphicspipeline with a relightable, traceable, and editable rendering pipeline solelybased on point cloud. Projectpage:https://nju-3dv.github.io/projects/Relightable3DGaussian/.</description><author>Jian Gao, Chun Gu, Youtian Lin, Hao Zhu, Xun Cao, Li Zhang, Yao Yao</author><pubDate>Mon, 27 Nov 2023 18:07:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16043v1</guid></item><item><title>Weakly-Supervised 3D Reconstruction of Clothed Humans via Normal Maps</title><link>http://arxiv.org/abs/2311.16042v1</link><description>We present a novel deep learning-based approach to the 3D reconstruction ofclothed humans using weak supervision via 2D normal maps. Given a single RGBimage or multiview images, our network infers a signed distance function (SDF)discretized on a tetrahedral mesh surrounding the body in a rest pose.Subsequently, inferred pose and camera parameters are used to generate a normalmap from the SDF. A key aspect of our approach is the use of MarchingTetrahedra to (uniquely) compute a triangulated surface from the SDF on thetetrahedral mesh, facilitating straightforward differentiation (and thusbackpropagation). Thus, given only ground truth normal maps (with no volumetricinformation ground truth information), we can train the network to produce SDFvalues from corresponding RGB images. Optionally, an additional multiview lossleads to improved results. We demonstrate the efficacy of our approach for bothnetwork inference and 3D reconstruction.</description><author>Jane Wu, Diego Thomas, Ronald Fedkiw</author><pubDate>Mon, 27 Nov 2023 18:06:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16042v1</guid></item><item><title>OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving</title><link>http://arxiv.org/abs/2311.16038v1</link><description>Understanding how the 3D scene evolves is vital for making decisions inautonomous driving. Most existing methods achieve this by predicting themovements of object boxes, which cannot capture more fine-grained sceneinformation. In this paper, we explore a new framework of learning a worldmodel, OccWorld, in the 3D Occupancy space to simultaneously predict themovement of the ego car and the evolution of the surrounding scenes. We proposeto learn a world model based on 3D occupancy rather than 3D bounding boxes andsegmentation maps for three reasons: 1) expressiveness. 3D occupancy candescribe the more fine-grained 3D structure of the scene; 2) efficiency. 3Doccupancy is more economical to obtain (e.g., from sparse LiDAR points). 3)versatility. 3D occupancy can adapt to both vision and LiDAR. To facilitate themodeling of the world evolution, we learn a reconstruction-based scenetokenizer on the 3D occupancy to obtain discrete scene tokens to describe thesurrounding scenes. We then adopt a GPT-like spatial-temporal generativetransformer to generate subsequent scene and ego tokens to decode the futureoccupancy and ego trajectory. Extensive experiments on the widely used nuScenesbenchmark demonstrate the ability of OccWorld to effectively model theevolution of the driving scenes. OccWorld also produces competitive planningresults without using instance and map supervision. Code:https://github.com/wzzheng/OccWorld.</description><author>Wenzhao Zheng, Weiliang Chen, Yuanhui Huang, Borui Zhang, Yueqi Duan, Jiwen Lu</author><pubDate>Mon, 27 Nov 2023 17:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16038v1</guid></item><item><title>A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems</title><link>http://arxiv.org/abs/2311.04014v2</link><description>This paper introduces a novel operator, termed the Y operator, to elevatecontrol performance in Actor-Critic(AC) based reinforcement learning forsystems governed by stochastic differential equations(SDEs). The Y operatoringeniously integrates the stochasticity of a class of child-mother system intothe Critic network's loss function, yielding substantial advancements in thecontrol performance of RL algorithms.Additionally, the Y operator elegantlyreformulates the challenge of solving partial differential equations for thestate-value function into a parallel problem for the drift and diffusionfunctions within the system's SDEs.A rigorous mathematical proof confirms theoperator's validity.This transformation enables the Y Operator-basedReinforcement Learning(YORL) framework to efficiently tackle optimal controlproblems in both model-based and data-driven systems.The superiority of YORL isdemonstrated through linear and nonlinear numerical examples showing itsenhanced performance over existing methods post convergence.</description><author>Cheng Yin, Yi Chen</author><pubDate>Mon, 27 Nov 2023 17:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04014v2</guid></item><item><title>GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions</title><link>http://arxiv.org/abs/2311.16037v1</link><description>Recently, impressive results have been achieved in 3D scene editing with textinstructions based on a 2D diffusion model. However, current diffusion modelsprimarily generate images by predicting noise in the latent space, and theediting is usually applied to the whole image, which makes it challenging toperform delicate, especially localized, editing for 3D scenes. Inspired byrecent 3D Gaussian splatting, we propose a systematic framework, namedGaussianEditor, to edit 3D scenes delicately via 3D Gaussians with textinstructions. Benefiting from the explicit property of 3D Gaussians, we designa series of techniques to achieve delicate editing. Specifically, we firstextract the region of interest (RoI) corresponding to the text instruction,aligning it to 3D Gaussians. The Gaussian RoI is further used to control theediting process. Our framework can achieve more delicate and precise editing of3D scenes than previous methods while enjoying much faster training speed, i.e.within 20 minutes on a single V100 GPU, more than twice as fast asInstruct-NeRF2NeRF (45 minutes -- 2 hours).</description><author>Jiemin Fang, Junjie Wang, Xiaopeng Zhang, Lingxi Xie, Qi Tian</author><pubDate>Mon, 27 Nov 2023 17:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16037v1</guid></item><item><title>DeepTSF: Codeless machine learning operations for time series forecasting</title><link>http://arxiv.org/abs/2308.00709v2</link><description>This paper presents DeepTSF, a comprehensive machine learning operations(MLOps) framework aiming to innovate time series forecasting through workflowautomation and codeless modeling. DeepTSF automates key aspects of the MLlifecycle, making it an ideal tool for data scientists and MLops engineersengaged in machine learning (ML) and deep learning (DL)-based forecasting.DeepTSF empowers users with a robust and user-friendly solution, while it isdesigned to seamlessly integrate with existing data analysis workflows,providing enhanced productivity and compatibility. The framework offers afront-end user interface (UI) suitable for data scientists, as well as otherhigher-level stakeholders, enabling comprehensive understanding throughinsightful visualizations and evaluation metrics. DeepTSF also prioritizessecurity through identity management and access authorization mechanisms. Theapplication of DeepTSF in real-life use cases of the I-NERGY project hasalready proven DeepTSF's efficacy in DL-based load forecasting, showcasing itssignificant added value in the electrical power and energy systems domain.</description><author>Sotiris Pelekis, Evangelos Karakolis, Theodosios Pountridis, George Kormpakis, George Lampropoulos, Spiros Mouzakitis, Dimitris Askounis</author><pubDate>Mon, 27 Nov 2023 17:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00709v2</guid></item><item><title>RobustState: Boosting Fidelity of Quantum State Preparation via Noise-Aware Variational Training</title><link>http://arxiv.org/abs/2311.16035v1</link><description>Quantum state preparation, a crucial subroutine in quantum computing,involves generating a target quantum state from initialized qubits. Arbitrarystate preparation algorithms can be broadly categorized into arithmeticdecomposition (AD) and variational quantum state preparation (VQSP). AD employsa predefined procedure to decompose the target state into a series of gates,whereas VQSP iteratively tunes ansatz parameters to approximate target state.VQSP is particularly apt for Noisy-Intermediate Scale Quantum (NISQ) machinesdue to its shorter circuits. However, achieving noise-robust parameteroptimization still remains challenging. We present RobustState, a novel VQSP training methodology that combines highrobustness with high training efficiency. The core idea involves utilizingmeasurement outcomes from real machines to perform back-propagation throughclassical simulators, thus incorporating real quantum noise into gradientcalculations. RobustState serves as a versatile, plug-and-play techniqueapplicable for training parameters from scratch or fine-tuning existingparameters to enhance fidelity on target machines. It is adaptable to variousansatzes at both gate and pulse levels and can even benefit other variationalalgorithms, such as variational unitary synthesis. Comprehensive evaluation of RobustState on state preparation tasks for 4distinct quantum algorithms using 10 real quantum machines demonstrates acoherent error reduction of up to 7.1 $\times$ and state fidelity improvementof up to 96\% and 81\% for 4-Q and 5-Q states, respectively. On average,RobustState improves fidelity by 50\% and 72\% for 4-Q and 5-Q states comparedto baseline approaches.</description><author>Hanrui Wang, Yilian Liu, Pengyu Liu, Jiaqi Gu, Zirui Li, Zhiding Liang, Jinglei Cheng, Yongshan Ding, Xuehai Qian, Yiyu Shi, David Z. Pan, Frederic T. Chong, Song Han</author><pubDate>Mon, 27 Nov 2023 17:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16035v1</guid></item><item><title>Machine Learning-Enhanced Aircraft Landing Scheduling under Uncertainties</title><link>http://arxiv.org/abs/2311.16030v1</link><description>This paper addresses aircraft delays, emphasizing their impact on safety andfinancial losses. To mitigate these issues, an innovative machine learning(ML)-enhanced landing scheduling methodology is proposed, aiming to improveautomation and safety. Analyzing flight arrival delay scenarios reveals strongmultimodal distributions and clusters in arrival flight time durations. Amulti-stage conditional ML predictor enhances separation time prediction basedon flight events. ML predictions are then integrated as safety constraints in atime-constrained traveling salesman problem formulation, solved usingmixed-integer linear programming (MILP). Historical flight recordings and modelpredictions address uncertainties between successive flights, ensuringreliability. The proposed method is validated using real-world data from theAtlanta Air Route Traffic Control Center (ARTCC ZTL). Case studies demonstratean average 17.2% reduction in total landing time compared to theFirst-Come-First-Served (FCFS) rule. Unlike FCFS, the proposed methodologyconsiders uncertainties, instilling confidence in scheduling. The studyconcludes with remarks and outlines future research directions.</description><author>Yutian Pang, Peng Zhao, Jueming Hu, Yongming Liu</author><pubDate>Mon, 27 Nov 2023 17:50:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16030v1</guid></item><item><title>Evaluating the Robustness to Instructions of Large Language Models</title><link>http://arxiv.org/abs/2308.14306v3</link><description>Recently, Instruction fine-tuning has risen to prominence as a potentialmethod for enhancing the zero-shot capabilities of Large Language Models (LLMs)on novel tasks. This technique has shown an exceptional ability to boost theperformance of moderately sized LLMs, sometimes even reaching performancelevels comparable to those of much larger model variants. The focus is on therobustness of instruction-tuned LLMs to seen and unseen tasks. We conducted anexploration of six models including Alpaca, Vicuna, WizardLM, and TraditionalTask-oriented Models(Flan-T5-XL/XXL, T0++) using real-world relation extractiondatasets as case studies. We carried out a comprehensive evaluation of theseinstruction-following LLMs which have been tuned based on open-domaininstructions and task-oriented instructions. The main discussion is theirperformance and robustness towards instructions. We have observed that in mostcases, the model's performance in dealing with unfamiliar instructions tends toworsen significantly, and the robustness of the model for RE instructionsdeteriorates compared to QA. Further, we discovered that up until a certainparameter size threshold (3B), the performance of the FLAN-T5 model improves asthe parameter count increases. The robustness of different scales of FLAN-T5models to RE instruction is worse than the robustness to QA instruction.</description><author>Yuansheng Ni, Sichao Jiang, Xinyu wu, Hui Shen, Yuli Zhou</author><pubDate>Mon, 27 Nov 2023 17:43:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14306v3</guid></item><item><title>An HCAI Methodological Framework: Putting It Into Action to Enable Human-Centered AI</title><link>http://arxiv.org/abs/2311.16027v1</link><description>Human-centered AI (HCAI), as a design philosophy, advocates prioritizinghumans in designing, developing, and deploying intelligent systems, aiming tomaximize the benefits of AI technology to humans and avoid its potentialadverse effects. While HCAI has gained momentum, the lack of guidance onmethodology in its implementation makes its adoption challenging. Afterassessing the needs for a methodological framework for HCAI, this paper firstproposes a comprehensive and interdisciplinary HCAI methodological frameworkintegrated with seven components, including design goals, design principles,implementation approaches, design paradigms, interdisciplinary teams, methods,and processes. THe implications of the framework are also discussed. This paperalso presents a "three-layer" approach to facilitate the implementation of theframework. We believe the proposed framework is systematic and executable,which can overcome the weaknesses in current frameworks and the challengescurrently faced in implementing HCAI. Thus, the framework can help put it intoaction to develop, transfer, and implement HCAI in practice, eventuallyenabling the design, development, and deployment of HCAI-based intelligentsystems.</description><author>Wei Xu, Zaifeng Gao, Marvin Dainoff</author><pubDate>Mon, 27 Nov 2023 17:40:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16027v1</guid></item><item><title>A Neural Framework for Generalized Causal Sensitivity Analysis</title><link>http://arxiv.org/abs/2311.16026v1</link><description>Unobserved confounding is common in many applications, making causalinference from observational data challenging. As a remedy, causal sensitivityanalysis is an important tool to draw causal conclusions under unobservedconfounding with mathematical guarantees. In this paper, we propose NeuralCSA,a neural framework for generalized causal sensitivity analysis. Unlike previouswork, our framework is compatible with (i) a large class of sensitivity models,including the marginal sensitivity model, f-sensitivity models, and Rosenbaum'ssensitivity model; (ii) different treatment types (i.e., binary andcontinuous); and (iii) different causal queries, including (conditional)average treatment effects and simultaneous effects on multiple outcomes. Thegenerality of \frameworkname is achieved by learning a latent distributionshift that corresponds to a treatment intervention using two conditionalnormalizing flows. We provide theoretical guarantees that NeuralCSA is able toinfer valid bounds on the causal query of interest and also demonstrate thisempirically using both simulated and real-world data.</description><author>Dennis Frauen, Fergus Imrie, Alicia Curth, Valentyn Melnychuk, Stefan Feuerriegel, Mihaela van der Schaar</author><pubDate>Mon, 27 Nov 2023 17:40:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16026v1</guid></item><item><title>Generative AI and US Intellectual Property Law</title><link>http://arxiv.org/abs/2311.16023v1</link><description>The rapidity with which generative AI has been adopted and advanced hasraised legal and ethical questions related to the impact on artists rights,content production, data collection, privacy, accuracy of information, andintellectual property rights. Recent administrative and case law challengeshave shown that generative AI software systems do not have independentintellectual property rights in the content that they generate. It remains tobe seen whether human content creators can retain their intellectual propertyrights against generative AI software, its developers, operators, and ownersfor the misappropriation of the work of human creatives, given the metes andbounds of existing law. Early signs from various courts are mixed as to whetherand to what degree the results generated by AI models meet the legal standardsof infringement under existing law.</description><author>Cherie M Poland</author><pubDate>Mon, 27 Nov 2023 17:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16023v1</guid></item><item><title>ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting</title><link>http://arxiv.org/abs/2310.13258v2</link><description>Seamless human-robot manipulation in close proximity relies on accurateforecasts of human motion. While there has been significant progress inlearning forecast models at scale, when applied to manipulation tasks, thesemodels accrue high errors at critical transition points leading to degradationin downstream planning performance. Our key insight is that instead ofpredicting the most likely human motion, it is sufficient to produce forecaststhat capture how future human motion would affect the cost of a robot's plan.We present ManiCast, a novel framework that learns cost-aware human forecastsand feeds them to a model predictive control planner to execute collaborativemanipulation tasks. Our framework enables fluid, real-time interactions betweena human and a 7-DoF robot arm across a number of real-world tasks such asreactive stirring, object handovers, and collaborative table setting. Weevaluate both the motion forecasts and the end-to-end forecaster-planner systemagainst a range of learned and heuristic baselines while additionallycontributing new datasets. We release our code and datasets athttps://portal-cornell.github.io/manicast/.</description><author>Kushal Kedia, Prithwish Dan, Atiksh Bhardwaj, Sanjiban Choudhury</author><pubDate>Mon, 27 Nov 2023 17:36:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13258v2</guid></item><item><title>Scheduling and Communication Schemes for Decentralized Federated Learning</title><link>http://arxiv.org/abs/2311.16021v1</link><description>Federated learning (FL) is a distributed machine learning paradigm in which alarge number of clients coordinate with a central server to learn a modelwithout sharing their own training data. One central server is not enough, dueto problems of connectivity with clients. In this paper, a decentralizedfederated learning (DFL) model with the stochastic gradient descent (SGD)algorithm has been introduced, as a more scalable approach to improve thelearning performance in a network of agents with arbitrary topology. Threescheduling policies for DFL have been proposed for communications between theclients and the parallel servers, and the convergence, accuracy, and loss havebeen tested in a totally decentralized mplementation of SGD. The experimentalresults show that the proposed scheduling polices have an impact both on thespeed of convergence and in the final global model.</description><author>Bahaa-Eldin Ali Abdelghany, Ana Fernández-Vilas, Manuel Fernández-Veiga, Nashwa El-Bendary, Ammar M. Hassan, Walid M. Abdelmoez</author><pubDate>Mon, 27 Nov 2023 17:35:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16021v1</guid></item><item><title>RIDE: Real-time Intrusion Detection via Explainable Machine Learning Implemented in a Memristor Hardware Architecture</title><link>http://arxiv.org/abs/2311.16018v1</link><description>Deep Learning (DL) based methods have shown great promise in networkintrusion detection by identifying malicious network traffic behavior patternswith high accuracy, but their applications to real-time, packet-leveldetections in high-speed communication networks are challenging due to the highcomputation time and resource requirements of Deep Neural Networks (DNNs), aswell as lack of explainability. To this end, we propose a packet-level networkintrusion detection solution that makes novel use of Recurrent Autoencoders tointegrate an arbitrary-length sequence of packets into a more compact jointfeature embedding, which is fed into a DNN-based classifier. To enableexplainability and support real-time detections at micro-second speed, wefurther develop a Software-Hardware Co-Design approach to efficiently realizethe proposed solution by converting the learned detection policies intodecision trees and implementing them using an emerging architecture based onmemristor devices. By jointly optimizing associated software and hardwareconstraints, we show that our approach leads to an extremely efficient,real-time solution with high detection accuracy at the packet level. Evaluationresults on real-world datasets (e.g., UNSW and CIC-IDS datasets) demonstratenearly three-nines detection accuracy with a substantial speedup of nearly fourorders of magnitude.</description><author>Jingdi Chen, Lei Zhang, Joseph Riem, Gina Adam, Nathaniel D. Bastian, Tian Lan</author><pubDate>Mon, 27 Nov 2023 17:30:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16018v1</guid></item><item><title>Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models</title><link>http://arxiv.org/abs/2311.16017v1</link><description>Identifying and resolving logic errors can be one of the most frustratingchallenges for novices programmers. Unlike syntax errors, for which a compileror interpreter can issue a message, logic errors can be subtle. In certainconditions, buggy code may even exhibit correct behavior -- in other cases, theissue might be about how a problem statement has been interpreted. Such errorscan be hard to spot when reading the code, and they can also at times be missedby automated tests. There is great educational potential in automaticallydetecting logic errors, especially when paired with suitable feedback fornovices. Large language models (LLMs) have recently demonstrated surprisingperformance for a range of computing tasks, including generating and explainingcode. These capabilities are closely linked to code syntax, which aligns withthe next token prediction behavior of LLMs. On the other hand, logic errorsrelate to the runtime performance of code and thus may not be as well suited toanalysis by LLMs. To explore this, we investigate the performance of twopopular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendlyexplanation of logic errors. We compare LLM performance with a large cohort ofintroductory computing students $(n=964)$ solving the same error detectiontask. Through a mixed-methods analysis of student and model responses, weobserve significant improvement in logic error identification between theprevious and current generation of LLMs, and find that both LLM generationssignificantly outperform students. We outline how such models could beintegrated into computing education tools, and discuss their potential forsupporting students when learning programming.</description><author>Stephen MacNeil, Paul Denny, Andrew Tran, Juho Leinonen, Seth Bernstein, Arto Hellas, Sami Sarsa, Joanne Kim</author><pubDate>Mon, 27 Nov 2023 17:28:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16017v1</guid></item><item><title>Low-degree learning and the metric entropy of polynomials</title><link>http://arxiv.org/abs/2203.09659v3</link><description>Let $\mathscr{F}_{n,d}$ be the class of all functions $f:\{-1,1\}^n\to[-1,1]$on the $n$-dimensional discrete hypercube of degree at most $d$. In the firstpart of this paper, we prove that any (deterministic or randomized) algorithmwhich learns $\mathscr{F}_{n,d}$ with $L_2$-accuracy $\varepsilon$ requires atleast $\Omega((1-\sqrt{\varepsilon})2^d\log n)$ queries for large enough $n$,thus establishing the sharpness as $n\to\infty$ of a recent upper bound ofEskenazis and Ivanisvili (2021). To do this, we show that the $L_2$-packingnumbers $\mathsf{M}(\mathscr{F}_{n,d},\|\cdot\|_{L_2},\varepsilon)$ of theconcept class $\mathscr{F}_{n,d}$ satisfy the two-sided estimate$$c(1-\varepsilon)2^d\log n \leq \log\mathsf{M}(\mathscr{F}_{n,d},\|\cdot\|_{L_2},\varepsilon) \leq \frac{2^{Cd}\logn}{\varepsilon^4}$$ for large enough $n$, where $c, C&gt;0$ are universalconstants. In the second part of the paper, we present a logarithmic upperbound for the randomized query complexity of classes of bounded approximatepolynomials whose Fourier spectra are concentrated on few subsets. As anapplication, we prove new estimates for the number of random queries requiredto learn approximate juntas of a given degree, functions with rapidly decayingFourier tails and constant depth circuits of given size. Finally, we obtainbounds for the number of queries required to learn the polynomial class$\mathscr{F}_{n,d}$ without error in the query and random example models.</description><author>Alexandros Eskenazis, Paata Ivanisvili, Lauritz Streck</author><pubDate>Mon, 27 Nov 2023 17:23:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.09659v3</guid></item><item><title>Deep Calibration of Market Simulations using Neural Density Estimators and Embedding Networks</title><link>http://arxiv.org/abs/2311.11913v2</link><description>The ability to construct a realistic simulator of financial exchanges,including reproducing the dynamics of the limit order book, can give insightinto many counterfactual scenarios, such as a flash crash, a margin call, orchanges in macroeconomic outlook. In recent years, agent-based models have beendeveloped that reproduce many features of an exchange, as summarised by a setof stylised facts and statistics. However, the ability to calibrate simulatorsto a specific period of trading remains an open challenge. In this work, wedevelop a novel approach to the calibration of market simulators by leveragingrecent advances in deep learning, specifically using neural density estimatorsand embedding networks. We demonstrate that our approach is able to correctlyidentify high probability parameter sets, both when applied to synthetic andhistorical data, and without reliance on manually selected or weightedensembles of stylised facts.</description><author>Namid R. Stillman, Rory Baggott, Justin Lyon, Jianfei Zhang, Dingqiu Zhu, Tao Chen, Perukrishnen Vytelingum</author><pubDate>Mon, 27 Nov 2023 17:17:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11913v2</guid></item><item><title>Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and Besov Spaces</title><link>http://arxiv.org/abs/2211.14400v5</link><description>Let $\Omega = [0,1]^d$ be the unit cube in $\mathbb{R}^d$. We study theproblem of how efficiently, in terms of the number of parameters, deep neuralnetworks with the ReLU activation function can approximate functions in theSobolev spaces $W^s(L_q(\Omega))$ and Besov spaces $B^s_r(L_q(\Omega))$, witherror measured in the $L_p(\Omega)$ norm. This problem is important whenstudying the application of neural networks in a variety of fields, includingscientific computing and signal processing, and has previously been solved onlywhen $p=q=\infty$. Our contribution is to provide a complete solution for all$1\leq p,q\leq \infty$ and $s &gt; 0$ for which the corresponding Sobolev or Besovspace compactly embeds into $L_p$. The key technical tool is a novelbit-extraction technique which gives an optimal encoding of sparse vectors.This enables us to obtain sharp upper bounds in the non-linear regime where $p&gt; q$. We also provide a novel method for deriving $L_p$-approximation lowerbounds based upon VC-dimension when $p &lt; \infty$. Our results show that verydeep ReLU networks significantly outperform classical methods of approximationin terms of the number of parameters, but that this comes at the cost ofparameters which are not encodable.</description><author>Jonathan W. Siegel</author><pubDate>Mon, 27 Nov 2023 17:13:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.14400v5</guid></item><item><title>Using Decentralized Aggregation for Federated Learning with Differential Privacy</title><link>http://arxiv.org/abs/2311.16008v1</link><description>Nowadays, the ubiquitous usage of mobile devices and networks have raisedconcerns about the loss of control over personal data and research advancetowards the trade-off between privacy and utility in scenarios that combineexchange communications, big databases and distributed and collaborative (P2P)Machine Learning techniques. On the other hand, although Federated Learning(FL) provides some level of privacy by retaining the data at the local node,which executes a local training to enrich a global model, this scenario isstill susceptible to privacy breaches as membership inference attacks. Toprovide a stronger level of privacy, this research deploys an experimentalenvironment for FL with Differential Privacy (DP) using benchmark datasets. Theobtained results show that the election of parameters and techniques of DP iscentral in the aforementioned trade-off between privacy and utility by means ofa classification example.</description><author>Hadeel Abd El-Kareem, Abd El-Moaty Saleh, Ana Fernández-Vilas, Manuel Fernández-Veiga, asser El-Sonbaty</author><pubDate>Mon, 27 Nov 2023 17:02:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16008v1</guid></item><item><title>Car-Following Models: A Multidisciplinary Review</title><link>http://arxiv.org/abs/2304.07143v3</link><description>Car-following (CF) algorithms are crucial components of traffic simulationsand have been integrated into many production vehicles equipped with AdvancedDriving Assistance Systems (ADAS). Insights from the model of car-followingbehavior help us understand the causes of various macro phenomena that arisefrom interactions between pairs of vehicles. Car-following models encompassmultiple disciplines, including traffic engineering, physics, dynamic systemcontrol, cognitive science, machine learning, and reinforcement learning. Thispaper presents an extensive survey that highlights the differences,complementarities, and overlaps among microscopic traffic flow and controlmodels based on their underlying principles and design logic. It reviewsrepresentative algorithms, ranging from theory-based kinematic models,Psycho-Physical Models, and Adaptive cruise control models to data-drivenalgorithms like Reinforcement Learning and Imitation Learning (IL). Themanuscript discusses the strengths and limitations of these models and explorestheir applications in different contexts. This review synthesizes existingresearches across different domains to fill knowledge gaps and offer guidancefor future research by identifying the latest trends in car following modelsand their applications.</description><author>Tianya Zhang, Peter J. Jin, Alexandre Bayen, Ph. D., Benedetto Piccoli</author><pubDate>Mon, 27 Nov 2023 17:02:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07143v3</guid></item><item><title>What If the TV Was Off? Examining Counterfactual Reasoning Abilities of Multi-modal Language Models</title><link>http://arxiv.org/abs/2310.06627v2</link><description>Counterfactual reasoning, a fundamental aspect of human cognition, involvescontemplating alternatives to established facts or past events, significantlyenhancing our abilities in planning and decision-making. In light of theadvancements in current multi-modal large language models, we explore theireffectiveness in counterfactual reasoning. To facilitate this investigation, weintroduce a novel dataset, C-VQA, specifically designed to test thecounterfactual reasoning capabilities of modern multi-modal large languagemodels. This dataset is constructed by infusing original questions withcounterfactual presuppositions, spanning various types such as numerical andboolean queries. It encompasses a mix of real and synthetic data, representinga wide range of difficulty levels. Our thorough evaluations of contemporaryvision-language models using this dataset have revealed substantial performancedrops, with some models showing up to a 40\% decrease, highlighting asignificant gap between current models and human-like vision reasoningcapabilities. We hope our dataset will serve as a vital benchmark forevaluating the counterfactual reasoning capabilities of models. Code anddataset are publicly available at https://bzhao.me/C-VQA/.</description><author>Letian Zhang, Xiaotong Zhai, Zhongkai Zhao, Yongshuo Zong, Xin Wen, Bingchen Zhao</author><pubDate>Mon, 27 Nov 2023 16:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06627v2</guid></item><item><title>Average Token Delay: A Duration-aware Latency Metric for Simultaneous Translation</title><link>http://arxiv.org/abs/2311.14353v2</link><description>Simultaneous translation is a task in which the translation begins before theend of an input speech segment. Its evaluation should be conducted based onlatency in addition to quality, and for users, the smallest possible amount oflatency is preferable. Most existing metrics measure latency based on the starttimings of partial translations and ignore their duration. This means suchmetrics do not penalize the latency caused by long translation output, whichdelays the comprehension of users and subsequent translations. In this work, wepropose a novel latency evaluation metric for simultaneous translation called\emph{Average Token Delay} (ATD) that focuses on the duration of partialtranslations. We demonstrate its effectiveness through analyses simulatinguser-side latency based on Ear-Voice Span (EVS). In our experiment, ATD had thehighest correlation with EVS among baseline latency metrics under mostconditions.</description><author>Yasumasa Kano, Katsuhito Sudoh, Satoshi Nakamura</author><pubDate>Mon, 27 Nov 2023 16:55:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14353v2</guid></item><item><title>Improved Data Generation for Enhanced Asset Allocation: A Synthetic Dataset Approach for the Fixed Income Universe</title><link>http://arxiv.org/abs/2311.16004v1</link><description>We present a novel process for generating synthetic datasets tailored toassess asset allocation methods and construct portfolios within the fixedincome universe. Our approach begins by enhancing the CorrGAN model to generatesynthetic correlation matrices. Subsequently, we propose an Encoder-Decodermodel that samples additional data conditioned on a given correlation matrix.The resulting synthetic dataset facilitates in-depth analyses of assetallocation methods across diverse asset universes. Additionally, we provide acase study that exemplifies the use of the synthetic dataset to improveportfolios constructed within a simulation-based asset allocation process.</description><author>Szymon Kubiak, Tillman Weyde, Oleksandr Galkin, Dan Philps, Ram Gopal</author><pubDate>Mon, 27 Nov 2023 16:55:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16004v1</guid></item><item><title>Forecasting Auxiliary Energy Consumption for Electric Heavy-Duty Vehicles</title><link>http://arxiv.org/abs/2311.16003v1</link><description>Accurate energy consumption prediction is crucial for optimizing theoperation of electric commercial heavy-duty vehicles, e.g., route planning forcharging. Moreover, understanding why certain predictions are cast is paramountfor such a predictive model to gain user trust and be deployed in practice.Since commercial vehicles operate differently as transportation tasks, ambient,and drivers vary, a heterogeneous population is expected when building an AIsystem for forecasting energy consumption. The dependencies between the inputfeatures and the target values are expected to also differ acrosssub-populations. One well-known example of such a statistical phenomenon is theSimpson paradox. In this paper, we illustrate that such a setting poses achallenge for existing XAI methods that produce global feature statistics, e.g.LIME or SHAP, causing them to yield misleading results. We demonstrate apotential solution by training multiple regression models on subsets of data.It not only leads to superior regression performance but also more relevant andconsistent LIME explanations. Given that the employed groupings correspond torelevant sub-populations, the associations between the input features and thetarget values are consistent within each cluster but different across clusters.Experiments on both synthetic and real-world datasets show that such splittingof a complex problem into simpler ones yields better regression performance andinterpretability.</description><author>Yuantao Fan, Zhenkan Wang, Sepideh Pashami, Slawomir Nowaczyk, Henrik Ydreskog</author><pubDate>Mon, 27 Nov 2023 16:52:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16003v1</guid></item><item><title>UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs</title><link>http://arxiv.org/abs/2311.09257v3</link><description>Text-to-image diffusion models have demonstrated remarkable capabilities intransforming textual prompts into coherent images, yet the computational costof their inference remains a persistent challenge. To address this issue, wepresent UFOGen, a novel generative model designed for ultra-fast, one-steptext-to-image synthesis. In contrast to conventional approaches that focus onimproving samplers or employing distillation techniques for diffusion models,UFOGen adopts a hybrid methodology, integrating diffusion models with a GANobjective. Leveraging a newly introduced diffusion-GAN objective andinitialization with pre-trained diffusion models, UFOGen excels in efficientlygenerating high-quality images conditioned on textual descriptions in a singlestep. Beyond traditional text-to-image generation, UFOGen showcases versatilityin applications. Notably, UFOGen stands among the pioneering models enablingone-step text-to-image generation and diverse downstream tasks, presenting asignificant advancement in the landscape of efficient generative models.</description><author>Yanwu Xu, Yang Zhao, Zhisheng Xiao, Tingbo Hou</author><pubDate>Mon, 27 Nov 2023 16:51:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09257v3</guid></item><item><title>On the Effectiveness of Log Representation for Log-based Anomaly Detection</title><link>http://arxiv.org/abs/2308.08736v2</link><description>Logs are an essential source of information for people to understand therunning status of a software system. Due to the evolving modern softwarearchitecture and maintenance methods, more research efforts have been devotedto automated log analysis. In particular, machine learning (ML) has been widelyused in log analysis tasks. In ML-based log analysis tasks, converting textuallog data into numerical feature vectors is a critical and indispensable step.However, the impact of using different log representation techniques on theperformance of the downstream models is not clear, which limits researchers andpractitioners' opportunities of choosing the optimal log representationtechniques in their automated log analysis workflows. Therefore, this workinvestigates and compares the commonly adopted log representation techniquesfrom previous log analysis research. Particularly, we select six logrepresentation techniques and evaluate them with seven ML models and fourpublic log datasets (i.e., HDFS, BGL, Spirit and Thunderbird) in the context oflog-based anomaly detection. We also examine the impacts of the log parsingprocess and the different feature aggregation approaches when they are employedwith log representation techniques. From the experiments, we provide someheuristic guidelines for future researchers and developers to follow whendesigning an automated log analysis workflow. We believe our comprehensivecomparison of log representation techniques can help researchers andpractitioners better understand the characteristics of different logrepresentation techniques and provide them with guidance for selecting the mostsuitable ones for their ML-based log analysis workflow.</description><author>Xingfang Wu, Heng Li, Foutse Khomh</author><pubDate>Mon, 27 Nov 2023 16:49:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.08736v2</guid></item><item><title>Machine learning and Topological data analysis identify unique features of human papillae in 3D scans</title><link>http://arxiv.org/abs/2307.06255v2</link><description>The tongue surface houses a range of papillae that are integral to themechanics and chemistry of taste and textural sensation. Although gustatoryfunction of papillae is well investigated, the uniqueness of papillae withinand across individuals remains elusive. Here, we present the first machinelearning framework on 3D microscopic scans of human papillae (n = 2092),uncovering the uniqueness of geometric and topological features of papillae.The finer differences in shapes of papillae are investigated computationallybased on a number of features derived from discrete differential geometry andcomputational topology. Interpretable machine learning techniques show thatpersistent homology features of the papillae shape are the most effective inpredicting the biological variables. Models trained on these features withsmall volumes of data samples predict the type of papillae with an accuracy of85%. The papillae type classification models can map the spatial arrangement offiliform and fungiform papillae on a surface. Remarkably, the papillae arefound to be distinctive across individuals and an individual can be identifiedwith an accuracy of 48% among the 15 participants from a single papillae.Collectively, this is the first unprecedented evidence demonstrating thattongue papillae can serve as a unique identifier inspiring new researchdirection for food preferences and oral diagnostics.</description><author>Rayna Andreeva, Anwesha Sarkar, Rik Sarkar</author><pubDate>Mon, 27 Nov 2023 16:48:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06255v2</guid></item><item><title>Automated Measurement of Vascular Calcification in Femoral Endarterectomy Patients Using Deep Learning</title><link>http://arxiv.org/abs/2311.16001v1</link><description>Atherosclerosis, a chronic inflammatory disease affecting the large arteries,presents a global health risk. Accurate analysis of diagnostic images, likecomputed tomographic angiograms (CTAs), is essential for staging and monitoringthe progression of atherosclerosis-related conditions, including peripheralarterial disease (PAD). However, manual analysis of CTA images istime-consuming and tedious. To address this limitation, we employed a deeplearning model to segment the vascular system in CTA images of PAD patientsundergoing femoral endarterectomy surgery and to measure vascular calcificationfrom the left renal artery to the patella. Utilizing proprietary CTA images of27 patients undergoing femoral endarterectomy surgery provided by Prisma HealthMidlands, we developed a Deep Neural Network (DNN) model to first segment thearterial system, starting from the descending aorta to the patella, and second,to provide a metric of arterial calcification. Our designed DNN achieved 83.4%average Dice accuracy in segmenting arteries from aorta to patella, advancingthe state-of-the-art by 0.8%. Furthermore, our work is the first to present arobust statistical analysis of automated calcification measurement in the lowerextremities using deep learning, attaining a Mean Absolute Percentage Error(MAPE) of 9.5% and a correlation coefficient of 0.978 between automated andmanual calcification scores. These findings underscore the potential of deeplearning techniques as a rapid and accurate tool for medical professionals toassess calcification in the abdominal aorta and its branches above the patella.The developed DNN model and related documentation in this project are availableat GitHub page at https://github.com/pip-alireza/DeepCalcScoring.</description><author>Alireza Bagheri Rajeoni, Breanna Pederson, Daniel G. Clair, Susan M. Lessner, Homayoun Valafar</author><pubDate>Mon, 27 Nov 2023 16:47:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16001v1</guid></item><item><title>AST: Effective Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories</title><link>http://arxiv.org/abs/2310.10541v2</link><description>Training large AI models typically requires large-scale datasets in themachine learning process, making training and parameter-tuning process bothtime-consuming and costly. Some researchers address this problem by carefullysynthesizing a very small number of highly representative and informativesamples from real-world datasets. This approach, known as Dataset Distillation(DD), proposes a perspective for data-efficient learning. Despite recentprogress in this field, the performance of existing methods still cannot meetexpectations, and distilled datasets cannot effectively replace originaldatasets. In this paper, unlike previous methods that focus solely on improvingthe effectiveness of student distillation, we recognize and leverage theimportant mutual influence between expert and student models. We observed thatthe smoothness of expert trajectories has a significant impact on subsequentstudent parameter alignment. Based on this, we propose an effective DDframework named AST, standing for Alignment with Smooth and high-quality expertTrajectories. We devise the integration of clipping loss and gradient penaltyto regulate the rate of parameter changes in expert trajectory generation. Tofurther refine the student parameter alignment with expert trajectory, we putforward representative initialization for the synthetic dataset and balancedinner-loop loss in response to the sensitivity exhibited towards randomlyinitialized variables during distillation. We also propose two enhancementstrategies, namely intermediate matching loss and weight perturbation, tomitigate the potential occurrence of cumulative errors. We conduct extensiveexperiments on datasets of different scales, sizes, and resolutions. Theresults demonstrate that the proposed method significantly outperforms priormethods.</description><author>Jiyuan Shen, Wenzhuo Yang, Kwok-Yan Lam</author><pubDate>Mon, 27 Nov 2023 16:45:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10541v2</guid></item><item><title>Closing the ODE-SDE gap in score-based diffusion models through the Fokker-Planck equation</title><link>http://arxiv.org/abs/2311.15996v1</link><description>Score-based diffusion models have emerged as one of the most promisingframeworks for deep generative modelling, due to their state-of-the artperformance in many generation tasks while relying on mathematical foundationssuch as stochastic differential equations (SDEs) and ordinary differentialequations (ODEs). Empirically, it has been reported that ODE based samples areinferior to SDE based samples. In this paper we rigorously describe the rangeof dynamics and approximations that arise when training score-based diffusionmodels, including the true SDE dynamics, the neural approximations, the variousapproximate particle dynamics that result, as well as their associatedFokker--Planck equations and the neural network approximations of theseFokker--Planck equations. We systematically analyse the difference between theODE and SDE dynamics of score-based diffusion models, and link it to anassociated Fokker--Planck equation. We derive a theoretical upper bound on theWasserstein 2-distance between the ODE- and SDE-induced distributions in termsof a Fokker--Planck residual. We also show numerically that conventionalscore-based diffusion models can exhibit significant differences between ODE-and SDE-induced distributions which we demonstrate using explicit comparisons.Moreover, we show numerically that reducing the Fokker--Planck residual byadding it as an additional regularisation term leads to closing the gap betweenODE- and SDE-induced distributions. Our experiments suggest that thisregularisation can improve the distribution generated by the ODE, however thatthis can come at the cost of degraded SDE sample quality.</description><author>Teo Deveney, Jan Stanczuk, Lisa Maria Kreusser, Chris Budd, Carola-Bibiane Schönlieb</author><pubDate>Mon, 27 Nov 2023 16:44:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15996v1</guid></item><item><title>Sensitivity-Based Layer Insertion for Residual and Feedforward Neural Networks</title><link>http://arxiv.org/abs/2311.15995v1</link><description>The training of neural networks requires tedious and often manual tuning ofthe network architecture. We propose a systematic method to insert new layersduring the training process, which eliminates the need to choose a fixednetwork size before training. Our technique borrows techniques from constrainedoptimization and is based on first-order sensitivity information of theobjective with respect to the virtual parameters that additional layers, ifinserted, would offer. We consider fully connected feedforward networks withselected activation functions as well as residual neural networks. In numericalexperiments, the proposed sensitivity-based layer insertion technique exhibitsimproved training decay, compared to not inserting the layer. Furthermore, thecomputational effort is reduced in comparison to inserting the layer from thebeginning. The code is available at\url{https://github.com/LeonieKreis/layer_insertion_sensitivity_based}.</description><author>Evelyn Herberg, Roland Herzog, Frederik Köhne, Leonie Kreis, Anton Schiela</author><pubDate>Mon, 27 Nov 2023 16:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15995v1</guid></item><item><title>Adversaral Doodles: Interpretable and Human-drawable Attacks Provide Describable Insights</title><link>http://arxiv.org/abs/2311.15994v1</link><description>DNN-based image classification models are susceptible to adversarial attacks.Most previous adversarial attacks do not focus on the interpretability of thegenerated adversarial examples, and we cannot gain insights into the mechanismof the target classifier from the attacks. Therefore, we propose AdversarialDoodles, which have interpretable shapes. We optimize black b\'ezier curves tofool the target classifier by overlaying them onto the input image. Byintroducing random perspective transformation and regularizing the doodledarea, we obtain compact attacks that cause misclassification even when humansreplicate them by hand. Adversarial doodles provide describable and intriguinginsights into the relationship between our attacks and the classifier's output.We utilize adversarial doodles and discover the bias inherent in the targetclassifier, such as "We add two strokes on its head, a triangle onto its body,and two lines inside the triangle on a bird image. Then, the classifiermisclassifies the image as a butterfly."</description><author>Ryoya Nara, Yusuke Matsui</author><pubDate>Mon, 27 Nov 2023 16:43:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15994v1</guid></item><item><title>Unified Batch Normalization: Identifying and Alleviating the Feature Condensation in Batch Normalization and a Unified Framework</title><link>http://arxiv.org/abs/2311.15993v1</link><description>Batch Normalization (BN) has become an essential technique in contemporaryneural network design, enhancing training stability. Specifically, BN employscentering and scaling operations to standardize features along the batchdimension and uses an affine transformation to recover features. Althoughstandard BN has shown its capability to improve deep neural network trainingand convergence, it still exhibits inherent limitations in certain cases. Mostexisting techniques that enhance BN consider a single or a few aspects of BN.In this paper, we first identify problems with BN from a feature perspectiveand explore that feature condensation exists in the learning when employing BN,which negatively affects testing performance. To tackle this problem, wepropose a two-stage unified framework called Unified Batch Normalization (UBN).In the first stage, we utilize a simple feature condensation threshold toalleviate the feature condensation, which hinders inappropriate statisticupdates in normalization. In the second stage, we unify various normalizationvariants to boost each component of BN. Our experimental results reveal thatUBN significantly enhances performance across different visual backbones andnotably expedites network training convergence, particularly in early trainingstages. Notably, our method improved about 3% in top-1 accuracy on ImageNetclassification with large batch sizes, showing the effectiveness of ourapproach in real-world scenarios.</description><author>Shaobo Wang, Xiangdong Zhang, Junchi Yan</author><pubDate>Mon, 27 Nov 2023 16:41:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15993v1</guid></item><item><title>DiffAnt: Diffusion Models for Action Anticipation</title><link>http://arxiv.org/abs/2311.15991v1</link><description>Anticipating future actions is inherently uncertain. Given an observed videosegment containing ongoing actions, multiple subsequent actions can plausiblyfollow. This uncertainty becomes even larger when predicting far into thefuture. However, the majority of existing action anticipation models adhere toa deterministic approach, neglecting to account for future uncertainties. Inthis work, we rethink action anticipation from a generative view, employingdiffusion models to capture different possible future actions. In thisframework, future actions are iteratively generated from standard Gaussiannoise in the latent space, conditioned on the observed video, and subsequentlytransitioned into the action space. Extensive experiments on four benchmarkdatasets, i.e., Breakfast, 50Salads, EpicKitchens, and EGTEA Gaze+, areperformed and the proposed method achieves superior or comparable results tostate-of-the-art methods, showing the effectiveness of a generative approachfor action anticipation. Our code and trained models will be published onGitHub.</description><author>Zeyun Zhong, Chengzhi Wu, Manuel Martin, Michael Voit, Juergen Gall, Jürgen Beyerer</author><pubDate>Mon, 27 Nov 2023 16:40:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15991v1</guid></item><item><title>Should We Learn Most Likely Functions or Parameters?</title><link>http://arxiv.org/abs/2311.15990v1</link><description>Standard regularized training procedures correspond to maximizing a posteriordistribution over parameters, known as maximum a posteriori (MAP) estimation.However, model parameters are of interest only insomuch as they combine withthe functional form of a model to provide a function that can make goodpredictions. Moreover, the most likely parameters under the parameter posteriordo not generally correspond to the most likely function induced by theparameter posterior. In fact, we can re-parametrize a model such that anysetting of parameters can maximize the parameter posterior. As an alternative,we investigate the benefits and drawbacks of directly estimating the mostlikely function implied by the model and the data. We show that this procedureleads to pathological solutions when using neural networks and prove conditionsunder which the procedure is well-behaved, as well as a scalable approximation.Under these conditions, we find that function-space MAP estimation can lead toflatter minima, better generalization, and improved robustness to overfitting.</description><author>Shikai Qiu, Tim G. J. Rudner, Sanyam Kapoor, Andrew Gordon Wilson</author><pubDate>Mon, 27 Nov 2023 16:39:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15990v1</guid></item><item><title>Applications of Large Scale Foundation Models for Autonomous Driving</title><link>http://arxiv.org/abs/2311.12144v4</link><description>Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007,autonomous driving has been the most active field of AI applications. Recentlypowered by large language models (LLMs), chat systems, such as chatGPT andPaLM, emerge and rapidly become a promising direction to achieve artificialgeneral intelligence (AGI) in natural language processing (NLP). There comes anatural thinking that we could employ these abilities to reformulate autonomousdriving. By combining LLM with foundation models, it is possible to utilize thehuman knowledge, commonsense and reasoning to rebuild autonomous drivingsystems from the current long-tailed AI dilemma. In this paper, we investigatethe techniques of foundation models and LLMs applied for autonomous driving,categorized as simulation, world model, data annotation and planning or E2Esolutions etc.</description><author>Yu Huang, Yue Chen, Zhu Li</author><pubDate>Mon, 27 Nov 2023 16:38:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12144v4</guid></item><item><title>Understanding plasticity in neural networks</title><link>http://arxiv.org/abs/2303.01486v4</link><description>Plasticity, the ability of a neural network to quickly change its predictionsin response to new information, is essential for the adaptability androbustness of deep reinforcement learning systems. Deep neural networks areknown to lose plasticity over the course of training even in relatively simplelearning problems, but the mechanisms driving this phenomenon are still poorlyunderstood. This paper conducts a systematic empirical analysis into plasticityloss, with the goal of understanding the phenomenon mechanistically in order toguide the future development of targeted solutions. We find that loss ofplasticity is deeply connected to changes in the curvature of the losslandscape, but that it often occurs in the absence of saturated units. Based onthis insight, we identify a number of parameterization and optimization designchoices which enable networks to better preserve plasticity over the course oftraining. We validate the utility of these findings on larger-scale RLbenchmarks in the Arcade Learning Environment.</description><author>Clare Lyle, Zeyu Zheng, Evgenii Nikishin, Bernardo Avila Pires, Razvan Pascanu, Will Dabney</author><pubDate>Mon, 27 Nov 2023 16:36:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.01486v4</guid></item><item><title>Sparsify-then-Classify: From Internal Neurons of Large Language Models To Efficient Text Classifiers</title><link>http://arxiv.org/abs/2311.15983v1</link><description>Among the many tasks that Large Language Models (LLMs) have revolutionized istext classification. However, existing approaches for applying pretrained LLMsto text classification predominantly rely on using single token outputs fromonly the last layer of hidden states. As a result, they suffer from limitationsin efficiency, task-specificity, and interpretability. In our work, wecontribute an approach that uses all internal representations by employingmultiple pooling strategies on all activation and hidden states. Our novellightweight strategy, Sparsify-then-Classify (STC) first sparsifiestask-specific features layer-by-layer, then aggregates across layers for textclassification. STC can be applied as a seamless plug-and-play module on top ofexisting LLMs. Our experiments on a comprehensive set of models and datasetsdemonstrate that STC not only consistently improves the classificationperformance of pretrained and fine-tuned models, but is also more efficient forboth training and inference, and is more intrinsically interpretable.</description><author>Yilun Liu, Difan Jiao, Ashton Anderson</author><pubDate>Mon, 27 Nov 2023 16:28:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15983v1</guid></item><item><title>Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion</title><link>http://arxiv.org/abs/2311.15980v1</link><description>Recent advances in generative AI have unveiled significant potential for thecreation of 3D content. However, current methods either apply a pre-trained 2Ddiffusion model with the time-consuming score distillation sampling (SDS), or adirect 3D diffusion model trained on limited 3D data losing generationdiversity. In this work, we approach the problem by employing a multi-view 2.5Ddiffusion fine-tuned from a pre-trained 2D diffusion model. The multi-view 2.5Ddiffusion directly models the structural distribution of 3D data, while stillmaintaining the strong generalization ability of the original 2D diffusionmodel, filling the gap between 2D diffusion-based and direct 3D diffusion-basedmethods for 3D content generation. During inference, multi-view normal maps aregenerated using the 2.5D diffusion, and a novel differentiable rasterizationscheme is introduced to fuse the almost consistent multi-view normal maps intoa consistent 3D model. We further design a normal-conditioned multi-view imagegeneration module for fast appearance generation given the 3D geometry. Ourmethod is a one-pass diffusion process and does not require any SDSoptimization as post-processing. We demonstrate through extensive experimentsthat, our direct 2.5D generation with the specially-designed fusion scheme canachieve diverse, mode-seeking-free, and high-fidelity 3D content generation inonly 10 seconds. Project page: https://nju-3dv.github.io/projects/direct25.</description><author>Yuanxun Lu, Jingyang Zhang, Shiwei Li, Tian Fang, David McKinnon, Yanghai Tsin, Long Quan, Xun Cao, Yao Yao</author><pubDate>Mon, 27 Nov 2023 16:26:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15980v1</guid></item><item><title>Soil Organic Carbon Estimation from Climate-related Features with Graph Neural Network</title><link>http://arxiv.org/abs/2311.15979v1</link><description>Soil organic carbon (SOC) plays a pivotal role in the global carbon cycle,impacting climate dynamics and necessitating accurate estimation forsustainable land and agricultural management. While traditional methods of SOCestimation face resolution and accuracy challenges, recent technologicalsolutions harness remote sensing, machine learning, and high-resolutionsatellite mapping. Graph Neural Networks (GNNs), especially when integratedwith positional encoders, can capture complex relationships between soil andclimate. Using the LUCAS database, this study compared four GNN operators inthe positional encoder framework. Results revealed that the PESAGE andPETransformer models outperformed others in SOC estimation, indicating theirpotential in capturing the complex relationship between SOC and climatefeatures. Our findings confirm the feasibility of applications of GNNarchitectures in SOC prediction, establishing a framework for futureexplorations of this topic with more advanced GNN models.</description><author>Weiying Zhao, Natalia Efremova</author><pubDate>Mon, 27 Nov 2023 16:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15979v1</guid></item><item><title>From Isolated Islands to Pangea: Unifying Semantic Space for Human Action Understanding</title><link>http://arxiv.org/abs/2304.00553v3</link><description>As a vital step toward the intelligent agent, Action understanding mattersfor intelligent agents and has attracted long-term attention. It can be formedas the mapping from the action physical space to the semantic space. Typically,researchers built action datasets according to idiosyncratic choices to defineclasses and push the envelope of benchmarks respectively. Thus, datasets areincompatible with each other like "Isolated Islands" due to semantic gaps andvarious class granularities, e.g., do housework in dataset A and wash plate indataset B. We argue that a more principled semantic space is an urgent need toconcentrate the community efforts and enable us to use all datasets together topursue generalizable action learning. To this end, we design a structuredaction semantic space in view of verb taxonomy hierarchy and covering massiveactions. By aligning the classes of previous datasets to our semantic space, wegather (image/video/skeleton/MoCap) datasets into a unified database in aunified label system, i.e., bridging ``isolated islands'' into a "Pangea".Accordingly, we propose a novel model mapping from the physical space tosemantic space to fully use Pangea. In extensive experiments, our new systemshows significant superiority, especially in transfer learning. Code and datawill be made publicly available.</description><author>Yong-Lu Li, Xiaoqian Wu, Xinpeng Liu, Zehao Wang, Yiming Dou, Yikun Ji, Junyi Zhang, Yixing Li, Jingru Tan, Xudong Lu, Cewu Lu</author><pubDate>Mon, 27 Nov 2023 16:24:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00553v3</guid></item><item><title>Text2Loc: 3D Point Cloud Localization from Natural Language</title><link>http://arxiv.org/abs/2311.15977v1</link><description>We tackle the problem of 3D point cloud localization based on a few naturallinguistic descriptions and introduce a novel neural network, Text2Loc, thatfully interprets the semantic relationship between points and text. Text2Locfollows a coarse-to-fine localization pipeline: text-submap global placerecognition, followed by fine localization. In global place recognition,relational dynamics among each textual hint are captured in a hierarchicaltransformer with max-pooling (HTM), whereas a balance between positive andnegative pairs is maintained using text-submap contrastive learning. Moreover,we propose a novel matching-free fine localization method to further refine thelocation predictions, which completely removes the need for complicatedtext-instance matching and is lighter, faster, and more accurate than previousmethods. Extensive experiments show that Text2Loc improves the localizationaccuracy by up to $2\times$ over the state-of-the-art on the KITTI360Posedataset. We will make the code publicly available.</description><author>Yan Xia, Letian Shi, Zifeng Ding, João F. Henriques, Daniel Cremers</author><pubDate>Mon, 27 Nov 2023 16:23:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15977v1</guid></item><item><title>Bayesian Flow Networks</title><link>http://arxiv.org/abs/2308.07037v4</link><description>This paper introduces Bayesian Flow Networks (BFNs), a new class ofgenerative model in which the parameters of a set of independent distributionsare modified with Bayesian inference in the light of noisy data samples, thenpassed as input to a neural network that outputs a second, interdependentdistribution. Starting from a simple prior and iteratively updating the twodistributions yields a generative procedure similar to the reverse process ofdiffusion models; however it is conceptually simpler in that no forward processis required. Discrete and continuous-time loss functions are derived forcontinuous, discretised and discrete data, along with sample generationprocedures. Notably, the network inputs for discrete data lie on theprobability simplex, and are therefore natively differentiable, paving the wayfor gradient-based sample guidance and few-step generation in discrete domainssuch as language modelling. The loss function directly optimises datacompression and places no restrictions on the network architecture. In ourexperiments BFNs achieve competitive log-likelihoods for image modelling ondynamically binarized MNIST and CIFAR-10, and outperform all known discretediffusion models on the text8 character-level language modelling task.</description><author>Alex Graves, Rupesh Kumar Srivastava, Timothy Atkinson, Faustino Gomez</author><pubDate>Mon, 27 Nov 2023 16:15:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07037v4</guid></item><item><title>ENIGMA-51: Towards a Fine-Grained Understanding of Human-Object Interactions in Industrial Scenarios</title><link>http://arxiv.org/abs/2309.14809v2</link><description>ENIGMA-51 is a new egocentric dataset acquired in an industrial scenario by19 subjects who followed instructions to complete the repair of electricalboards using industrial tools (e.g., electric screwdriver) and equipments(e.g., oscilloscope). The 51 egocentric video sequences are densely annotatedwith a rich set of labels that enable the systematic study of human behavior inthe industrial domain. We provide benchmarks on four tasks related to humanbehavior: 1) untrimmed temporal detection of human-object interactions, 2)egocentric human-object interaction detection, 3) short-term object interactionanticipation and 4) natural language understanding of intents and entities.Baseline results show that the ENIGMA-51 dataset poses a challenging benchmarkto study human behavior in industrial scenarios. We publicly release thedataset at https://iplab.dmi.unict.it/ENIGMA-51.</description><author>Francesco Ragusa, Rosario Leonardi, Michele Mazzamuto, Claudia Bonanno, Rosario Scavo, Antonino Furnari, Giovanni Maria Farinella</author><pubDate>Mon, 27 Nov 2023 16:09:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14809v2</guid></item><item><title>Asymptotic Bounds for Smoothness Parameter Estimates in Gaussian Process Interpolation</title><link>http://arxiv.org/abs/2203.05400v5</link><description>It is common to model a deterministic response function, such as the outputof a computer experiment, as a Gaussian process with a Mat\'ern covariancekernel. The smoothness parameter of a Mat\'ern kernel determines many importantproperties of the model in the large data limit, including the rate ofconvergence of the conditional mean to the response function. We prove that themaximum likelihood estimate of the smoothness parameter cannot asymptoticallyundersmooth the truth when the data are obtained on a fixed bounded subset of$\mathbb{R}^d$. That is, if the data-generating response function has Sobolevsmoothness $\nu_0 &gt; d/2$, then the smoothness parameter estimate cannot beasymptotically less than $\nu_0$. The lower bound is sharp. Additionally, weshow that maximum likelihood estimation recovers the true smoothness for aclass of compactly supported self-similar functions. For cross-validation weprove an asymptotic lower bound $\nu_0 - d/2$, which however is unlikely to besharp. The results are based on approximation theory in Sobolev spaces and somegeneral theorems that restrict the set of values that the parameter estimatorscan take.</description><author>Toni Karvonen</author><pubDate>Mon, 27 Nov 2023 16:08:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.05400v5</guid></item><item><title>Towards Transfer Learning for Large-Scale Image Classification Using Annealing-based Quantum Boltzmann Machines</title><link>http://arxiv.org/abs/2311.15966v1</link><description>Quantum Transfer Learning (QTL) recently gained popularity as a hybridquantum-classical approach for image classification tasks by efficientlycombining the feature extraction capabilities of large Convolutional NeuralNetworks with the potential benefits of Quantum Machine Learning (QML).Existing approaches, however, only utilize gate-based Variational QuantumCircuits for the quantum part of these procedures. In this work we present anapproach to employ Quantum Annealing (QA) in QTL-based image classification.Specifically, we propose using annealing-based Quantum Boltzmann Machines aspart of a hybrid quantum-classical pipeline to learn the classification ofreal-world, large-scale data such as medical images through supervisedtraining. We demonstrate our approach by applying it to the three-classCOVID-CT-MD dataset, a collection of lung Computed Tomography (CT) scan slices.Using Simulated Annealing as a stand-in for actual QA, we compare our method toclassical transfer learning, using a neural network of the same order ofmagnitude, to display its improved classification performance. We find that ourapproach consistently outperforms its classical baseline in terms of testaccuracy and AUC-ROC-Score and needs less training epochs to do this.</description><author>Daniëlle Schuman, Leo Sünkel, Philipp Altmann, Jonas Stein, Christoph Roch, Thomas Gabor, Claudia Linnhoff-Popien</author><pubDate>Mon, 27 Nov 2023 16:07:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15966v1</guid></item><item><title>FALCON: Fairness Learning via Contrastive Attention Approach to Continual Semantic Scene Understanding in Open World</title><link>http://arxiv.org/abs/2311.15965v1</link><description>Continual Learning in semantic scene segmentation aims to continually learnnew unseen classes in dynamic environments while maintaining previously learnedknowledge. Prior studies focused on modeling the catastrophic forgetting andbackground shift challenges in continual learning. However, fairness, anothermajor challenge that causes unfair predictions leading to low performance amongmajor and minor classes, still needs to be well addressed. In addition, priormethods have yet to model the unknown classes well, thus resulting in producingnon-discriminative features among unknown classes. This paper presents a novelFairness Learning via Contrastive Attention Approach to continual learning insemantic scene understanding. In particular, we first introduce a new FairnessContrastive Clustering loss to address the problems of catastrophic forgettingand fairness. Then, we propose an attention-based visual grammar approach toeffectively model the background shift problem and unknown classes, producingbetter feature representations for different unknown classes. Through ourexperiments, our proposed approach achieves State-of-the-Art (SOTA) performanceon different continual learning settings of three standard benchmarks, i.e.,ADE20K, Cityscapes, and Pascal VOC. It promotes the fairness of the continualsemantic segmentation model.</description><author>Thanh-Dat Truong, Utsav Prabhu, Bhiksha Raj, Jackson Cothren, Khoa Luu</author><pubDate>Mon, 27 Nov 2023 16:07:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15965v1</guid></item><item><title>Efficient Pre-training for Localized Instruction Generation of Videos</title><link>http://arxiv.org/abs/2311.15964v1</link><description>Procedural videos show step-by-step demonstrations of tasks like recipepreparation. Understanding such videos is challenging, involving the preciselocalization of steps and the generation of textual instructions. Manuallyannotating steps and writing instructions is costly, which limits the size ofcurrent datasets and hinders effective learning. Leveraging large but noisyvideo-transcript datasets for pre-training can boost performance, but demandssignificant computational resources. Furthermore, transcripts containirrelevant content and exhibit style variation compared to instructions writtenby human annotators. To mitigate both issues, we propose a technique,Sieve-&amp;-Swap, to automatically curate a smaller dataset: (i) Sieve filtersirrelevant transcripts and (ii) Swap enhances the quality of the textinstruction by automatically replacing the transcripts with human-writteninstructions from a text-only recipe dataset. The curated dataset, three ordersof magnitude smaller than current web-scale datasets, enables efficienttraining of large-scale models with competitive performance. We complement ourSieve-\&amp;-Swap approach with a Procedure Transformer (ProcX) for end-to-end steplocalization and instruction generation for procedural videos. When this modelis pre-trained on our curated dataset, it achieves state-of-the-art performancein zero-shot and finetuning settings on YouCook2 and Tasty, while using afraction of the computational resources.</description><author>Anil Batra, Davide Moltisanti, Laura Sevilla-Lara, Marcus Rohrbach, Frank Keller</author><pubDate>Mon, 27 Nov 2023 16:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15964v1</guid></item><item><title>From Pixels to Titles: Video Game Identification by Screenshots using Convolutional Neural Networks</title><link>http://arxiv.org/abs/2311.15963v1</link><description>This paper investigates video game identification through single screenshots,utilizing five convolutional neural network (CNN) architectures (MobileNet,DenseNet, EfficientNetB0, EfficientNetB2, and EfficientNetB3) across 22 homeconsole systems, spanning from Atari 2600 to PlayStation 5. Confirming thehypothesis, CNNs autonomously extract image features, enabling theidentification of game titles from screenshots without additional features.Using ImageNet pre-trained weights, EfficientNetB3 achieves the highest averageaccuracy (74.51%), while DenseNet169 excels in 14 of the 22 systems. Employingalternative initial weights from another screenshots dataset boosts accuracyfor EfficientNetB2 and EfficientNetB3, with the latter reaching a peak accuracyof 76.36% and demonstrating reduced convergence epochs from 23.7 to 20.5 onaverage. Overall, the combination of optimal architecture and weights attains77.67% accuracy, primarily led by EfficientNetB3 in 19 systems. These findingsunderscore the efficacy of CNNs in video game identification throughscreenshots.</description><author>Fabricio Breve</author><pubDate>Mon, 27 Nov 2023 16:07:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15963v1</guid></item><item><title>Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift</title><link>http://arxiv.org/abs/2311.15961v1</link><description>A key challenge of modern machine learning systems is to achieveOut-of-Distribution (OOD) generalization -- generalizing to target data whosedistribution differs from that of source data. Despite its significantimportance, the fundamental question of ``what are the most effectivealgorithms for OOD generalization'' remains open even under the standardsetting of covariate shift. This paper addresses this fundamental question byproving that, surprisingly, classical Maximum Likelihood Estimation (MLE)purely using source data (without any modification) achieves the minimaxoptimality for covariate shift under the well-specified setting. That is, noalgorithm performs better than MLE in this setting (up to a constant factor),justifying MLE is all you need. Our result holds for a very rich class ofparametric models, and does not require any boundedness condition on thedensity ratio. We illustrate the wide applicability of our framework byinstantiating it to three concrete examples -- linear regression, logisticregression, and phase retrieval. This paper further complement the study byproving that, under the misspecified setting, MLE is no longer the optimalchoice, whereas Maximum Weighted Likelihood Estimator (MWLE) emerges as minimaxoptimal in certain scenarios.</description><author>Jiawei Ge, Shange Tang, Jianqing Fan, Cong Ma, Chi Jin</author><pubDate>Mon, 27 Nov 2023 16:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15961v1</guid></item><item><title>Addressing Long-Horizon Tasks by Integrating Program Synthesis and State Machines</title><link>http://arxiv.org/abs/2311.15960v1</link><description>Deep reinforcement learning excels in various domains but lacksgeneralizability and interoperability. Programmatic RL methods (Trivedi et al.,2021; Liu et al., 2023) reformulate solving RL tasks as synthesizinginterpretable programs that can be executed in the environments. Despiteencouraging results, these methods are limited to short-horizon tasks. On theother hand, representing RL policies using state machines (Inala et al., 2020)can inductively generalize to long-horizon tasks; however, it struggles toscale up to acquire diverse and complex behaviors. This work proposes ProgramMachine Policies (POMPs), which bridge the advantages of programmatic RL andstate machine policies, allowing for the representation of complex behaviorsand the address of long-term tasks. Specifically, we introduce a method thatcan retrieve a set of effective, diverse, compatible programs. Then, we usethese programs as modes of a state machine and learn a transition function totransition among mode programs, allowing for capturing long-horizon repetitivebehaviors. Our proposed framework outperforms programmatic RL and deep RLbaselines on various tasks and demonstrates the ability to generalize to evenlonger horizons without any fine-tuning inductively. Ablation studies justifythe effectiveness of our proposed search algorithm for retrieving a set ofprograms as modes.</description><author>Yu-An Lin, Chen-Tao Lee, Guan-Ting Liu, Pu-Jen Cheng, Shao-Hua Sun</author><pubDate>Mon, 27 Nov 2023 16:06:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15960v1</guid></item><item><title>CheapNET: Improving Light-weight speech enhancement network by projected loss function</title><link>http://arxiv.org/abs/2311.15959v1</link><description>Noise suppression and echo cancellation are critical in speech enhancementand essential for smart devices and real-time communication. Deployed in voiceprocessing front-ends and edge devices, these algorithms must ensure efficientreal-time inference with low computational demands. Traditional edge-basednoise suppression often uses MSE-based amplitude spectrum mask training, butthis approach has limitations. We introduce a novel projection loss function,diverging from MSE, to enhance noise suppression. This method uses projectiontechniques to isolate key audio components from noise, significantly improvingmodel performance. For echo cancellation, the function enables directpredictions on LAEC pre-processed outputs, substantially enhancing performance.Our noise suppression model achieves near state-of-the-art results with only3.1M parameters and 0.4GFlops/s computational load. Moreover, our echocancellation model outperforms replicated industry-leading models, introducinga new perspective in speech enhancement.</description><author>Kaijun Tan, Benzhe Dai, Jiakui Li, Wenyu Mao</author><pubDate>Mon, 27 Nov 2023 16:03:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15959v1</guid></item><item><title>Dimensionality Reduction and Wasserstein Stability for Kernel Regression</title><link>http://arxiv.org/abs/2203.09347v3</link><description>In a high-dimensional regression framework, we study consequences of thenaive two-step procedure where first the dimension of the input variables isreduced and second, the reduced input variables are used to predict the outputvariable with kernel regression. In order to analyze the resulting regressionerrors, a novel stability result for kernel regression with respect to theWasserstein distance is derived. This allows us to bound errors that occur whenperturbed input data is used to fit the regression function. We apply thegeneral stability result to principal component analysis (PCA). Exploitingknown estimates from the literature on both principal component analysis andkernel regression, we deduce convergence rates for the two-step procedure. Thelatter turns out to be particularly useful in a semi-supervised setting.</description><author>Stephan Eckstein, Armin Iske, Mathias Trabs</author><pubDate>Mon, 27 Nov 2023 15:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.09347v3</guid></item><item><title>The Chosen One: Consistent Characters in Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2311.10093v2</link><description>Recent advances in text-to-image generation models have unlocked vastpotential for visual creativity. However, these models struggle with generationof consistent characters, a crucial aspect for numerous real-world applicationssuch as story visualization, game development asset design, advertising, andmore. Current methods typically rely on multiple pre-existing images of thetarget character or involve labor-intensive manual processes. In this work, wepropose a fully automated solution for consistent character generation, withthe sole input being a text prompt. We introduce an iterative procedure that,at each stage, identifies a coherent set of images sharing a similar identityand extracts a more consistent identity from this set. Our quantitativeanalysis demonstrates that our method strikes a better balance between promptalignment and identity consistency compared to the baseline methods, and thesefindings are reinforced by a user study. To conclude, we showcase severalpractical applications of our approach. Project page is available athttps://omriavrahami.com/the-chosen-one</description><author>Omri Avrahami, Amir Hertz, Yael Vinker, Moab Arar, Shlomi Fruchter, Ohad Fried, Daniel Cohen-Or, Dani Lischinski</author><pubDate>Mon, 27 Nov 2023 15:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10093v2</guid></item><item><title>A Quantitative Approach to Understand Self-Supervised Models as Cross-lingual Feature Extractors</title><link>http://arxiv.org/abs/2311.15954v1</link><description>In this work, we study the features extracted by English self-supervisedlearning (SSL) models in cross-lingual contexts and propose a new metric topredict the quality of feature representations. Using automatic speechrecognition (ASR) as a downstream task, we analyze the effect of model size,training objectives, and model architecture on the models' performance as afeature extractor for a set of topologically diverse corpora. We develop anovel metric, the Phonetic-Syntax Ratio (PSR), to measure the phonetic andsynthetic information in the extracted representations using deep generalizedcanonical correlation analysis. Results show the contrastive loss in thewav2vec2.0 objective facilitates more effective cross-lingual featureextraction. There is a positive correlation between PSR scores and ASRperformance, suggesting that phonetic information extracted by monolingual SSLmodels can be used for downstream tasks in cross-lingual settings. The proposedmetric is an effective indicator of the quality of the representations and canbe useful for model selection.</description><author>Shuyue Stella Li, Beining Xu, Xiangyu Zhang, Hexin Liu, Wenhan Chao, Leibny Paola Garcia</author><pubDate>Mon, 27 Nov 2023 15:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15954v1</guid></item><item><title>Replay across Experiments: A Natural Extension of Off-Policy RL</title><link>http://arxiv.org/abs/2311.15951v1</link><description>Replaying data is a principal mechanism underlying the stability and dataefficiency of off-policy reinforcement learning (RL). We present an effectiveyet simple framework to extend the use of replays across multiple experiments,minimally adapting the RL workflow for sizeable improvements in controllerperformance and research iteration times. At its core, Replay AcrossExperiments (RaE) involves reusing experience from previous experiments toimprove exploration and bootstrap learning while reducing required changes to aminimum in comparison to prior work. We empirically show benefits across anumber of RL algorithms and challenging control domains spanning bothlocomotion and manipulation, including hard exploration tasks from egocentricvision. Through comprehensive ablations, we demonstrate robustness to thequality and amount of data available and various hyperparameter choices.Finally, we discuss how our approach can be applied more broadly acrossresearch life cycles and can increase resilience by reloading data acrossrandom seeds or hyperparameter variations.</description><author>Dhruva Tirumala, Thomas Lampe, Jose Enrique Chen, Tuomas Haarnoja, Sandy Huang, Guy Lever, Ben Moran, Tim Hertweck, Leonard Hasenclever, Martin Riedmiller, Nicolas Heess, Markus Wulfmeier</author><pubDate>Mon, 27 Nov 2023 15:57:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15951v1</guid></item><item><title>TorchRL: A data-driven decision-making library for PyTorch</title><link>http://arxiv.org/abs/2306.00577v2</link><description>PyTorch has ascended as a premier machine learning framework, yet it lacks anative and comprehensive library for decision and control tasks suitable forlarge development teams dealing with complex real-world data and environments.To address this issue, we propose TorchRL, a generalistic control library forPyTorch that provides well-integrated, yet standalone components. We introducea new and flexible PyTorch primitive, the TensorDict, which facilitatesstreamlined algorithm development across the many branches of ReinforcementLearning (RL) and control. We provide a detailed description of the buildingblocks and an extensive overview of the library across domains and tasks.Finally, we experimentally demonstrate its reliability and flexibility and showcomparative benchmarks to demonstrate its computational efficiency. TorchRLfosters long-term support and is publicly available on GitHub for greaterreproducibility and collaboration within the research community. The code isopen-sourced on GitHub.</description><author>Albert Bou, Matteo Bettini, Sebastian Dittert, Vikash Kumar, Shagun Sodhani, Xiaomeng Yang, Gianni De Fabritiis, Vincent Moens</author><pubDate>Mon, 27 Nov 2023 15:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00577v2</guid></item><item><title>Auto-CsiNet: Scenario-customized Automatic Neural Network Architecture Generation for Massive MIMO CSI Feedback</title><link>http://arxiv.org/abs/2311.15950v1</link><description>Deep learning has revolutionized the design of the channel state information(CSI) feedback module in wireless communications. However, designing theoptimal neural network (NN) architecture for CSI feedback can be a laboriousand time-consuming process. Manual design can be prohibitively expensive forcustomizing NNs to different scenarios. This paper proposes using neuralarchitecture search (NAS) to automate the generation of scenario-customized CSIfeedback NN architectures, thereby maximizing the potential of deep learning inexclusive environments. By employing automated machine learning andgradient-descent-based NAS, an efficient and cost-effective architecture designprocess is achieved. The proposed approach leverages implicit scene knowledge,integrating it into the scenario customization process in a data-driven manner,and fully exploits the potential of deep learning for each specific scenario.To address the issue of excessive search, early stopping and elastic selectionmechanisms are employed, enhancing the efficiency of the proposed scheme. Theexperimental results demonstrate that the automatically generated architecture,known as Auto-CsiNet, outperforms manually-designed models in bothreconstruction performance (achieving approximately a 14% improvement) andcomplexity (reducing it by approximately 50%). Furthermore, the paper analyzesthe impact of the scenario on the NN architecture and its capacity.</description><author>Xiangyi Li, Jiajia Guo, Chao-Kai Wen, Shi Jin</author><pubDate>Mon, 27 Nov 2023 15:56:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15950v1</guid></item><item><title>GloNets: Globally Connected Neural Networks</title><link>http://arxiv.org/abs/2311.15947v1</link><description>Deep learning architectures suffer from depth-related performancedegradation, limiting the effective depth of neural networks. Approaches likeResNet are able to mitigate this, but they do not completely eliminate theproblem. We introduce Globally Connected Neural Networks (GloNet), a novelarchitecture overcoming depth-related issues, designed to be superimposed onany model, enhancing its depth without increasing complexity or reducingperformance. With GloNet, the network's head uniformly receives informationfrom all parts of the network, regardless of their level of abstraction. Thisenables GloNet to self-regulate information flow during training, reducing theinfluence of less effective deeper layers, and allowing for stable trainingirrespective of network depth. This paper details GloNet's design, itstheoretical basis, and a comparison with existing similar architectures.Experiments show GloNet's self-regulation ability and resilience todepth-related learning challenges, like performance degradation. Our findingssuggest GloNet as a strong alternative to traditional architectures likeResNets.</description><author>Antonio Di Cecco, Carlo Metta, Marco Fantozzi, Francesco Morandin, Maurizio Parton</author><pubDate>Mon, 27 Nov 2023 15:54:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15947v1</guid></item><item><title>Leveraging deep active learning to identify low-resource mobility functioning information in public clinical notes</title><link>http://arxiv.org/abs/2311.15946v1</link><description>Function is increasingly recognized as an important indicator of whole-personhealth, although it receives little attention in clinical natural languageprocessing research. We introduce the first public annotated datasetspecifically on the Mobility domain of the International Classification ofFunctioning, Disability and Health (ICF), aiming to facilitate automaticextraction and analysis of functioning information from free-text clinicalnotes. We utilize the National NLP Clinical Challenges (n2c2) research datasetto construct a pool of candidate sentences using keyword expansion. Our activelearning approach, using query-by-committee sampling weighted by densityrepresentativeness, selects informative sentences for human annotation. Wetrain BERT and CRF models, and use predictions from these models to guide theselection of new sentences for subsequent annotation iterations. Our finaldataset consists of 4,265 sentences with a total of 11,784 entities, including5,511 Action entities, 5,328 Mobility entities, 306 Assistance entities, and639 Quantification entities. The inter-annotator agreement (IAA), averaged overall entity types, is 0.72 for exact matching and 0.91 for partial matching. Wealso train and evaluate common BERT models and state-of-the-art Nested NERmodels. The best F1 scores are 0.84 for Action, 0.7 for Mobility, 0.62 forAssistance, and 0.71 for Quantification. Empirical results demonstratepromising potential of NER models to accurately extract mobility functioninginformation from clinical text. The public availability of our annotateddataset will facilitate further research to comprehensively capture functioninginformation in electronic health records (EHRs).</description><author>Tuan-Dung Le, Zhuqi Miao, Samuel Alvarado, Brittany Smith, William Paiva, Thanh Thieu</author><pubDate>Mon, 27 Nov 2023 15:53:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15946v1</guid></item><item><title>Over-Squashing in Riemannian Graph Neural Networks</title><link>http://arxiv.org/abs/2311.15945v1</link><description>Most graph neural networks (GNNs) are prone to the phenomenon ofover-squashing in which node features become insensitive to information fromdistant nodes in the graph. Recent works have shown that the topology of thegraph has the greatest impact on over-squashing, suggesting graph rewiringapproaches as a suitable solution. In this work, we explore whetherover-squashing can be mitigated through the embedding space of the GNN. Inparticular, we consider the generalization of Hyperbolic GNNs (HGNNs) toRiemannian manifolds of variable curvature in which the geometry of theembedding space is faithful to the graph's topology. We derive bounds on thesensitivity of the node features in these Riemannian GNNs as the number oflayers increases, which yield promising theoretical and empirical results foralleviating over-squashing in graphs with negative curvature.</description><author>Julia Balla</author><pubDate>Mon, 27 Nov 2023 15:51:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15945v1</guid></item><item><title>Tell2Design: A Dataset for Language-Guided Floor Plan Generation</title><link>http://arxiv.org/abs/2311.15941v1</link><description>We consider the task of generating designs directly from natural languagedescriptions, and consider floor plan generation as the initial research area.Language conditional generative models have recently been very successful ingenerating high-quality artistic images. However, designs must satisfydifferent constraints that are not present in generating artistic images,particularly spatial and relational constraints. We make multiple contributionsto initiate research on this task. First, we introduce a novel dataset,\textit{Tell2Design} (T2D), which contains more than $80k$ floor plan designsassociated with natural language instructions. Second, we propose aSequence-to-Sequence model that can serve as a strong baseline for futureresearch. Third, we benchmark this task with several text-conditional imagegeneration models. We conclude by conducting human evaluations on the generatedsamples and providing an analysis of human performance. We hope ourcontributions will propel the research on language-guided design generationforward.</description><author>Sicong Leng, Yang Zhou, Mohammed Haroon Dupty, Wee Sun Lee, Sam Conrad Joyce, Wei Lu</author><pubDate>Mon, 27 Nov 2023 15:49:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15941v1</guid></item><item><title>Physics-informed neural networks for transformed geometries and manifolds</title><link>http://arxiv.org/abs/2311.15940v1</link><description>Physics-informed neural networks (PINNs) effectively embed physicalprinciples into machine learning, but often struggle with complex oralternating geometries. We propose a novel method for integrating geometrictransformations within PINNs to robustly accommodate geometric variations. Ourmethod incorporates a diffeomorphism as a mapping of a reference domain andadapts the derivative computation of the physics-informed loss function. Thisgeneralizes the applicability of PINNs not only to smoothly deformed domains,but also to lower-dimensional manifolds and allows for direct shapeoptimization while training the network. We demonstrate the effectivity of ourapproach on several problems: (i) Eikonal equation on Archimedean spiral, (ii)Poisson problem on surface manifold, (iii) Incompressible Stokes flow indeformed tube, and (iv) Shape optimization with Laplace operator. Through theseexamples, we demonstrate the enhanced flexibility over traditional PINNs,especially under geometric variations. The proposed framework presents anoutlook for training deep neural operators over parametrized geometries, pavingthe way for advanced modeling with PDEs on complex geometries in science andengineering.</description><author>Samuel Burbulla</author><pubDate>Mon, 27 Nov 2023 15:47:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15940v1</guid></item><item><title>Unleashing the Power of Prompt-driven Nucleus Instance Segmentation</title><link>http://arxiv.org/abs/2311.15939v1</link><description>Nuclear instance segmentation in histology images is crucial for a broadspectrum of clinical applications. Current prevailing nuclear instancesegmentation algorithms rely on regression of nuclei contours, distance maps,watershed markers or a proxy nuclear representation of star-convex polygons.Consequently, these methods necessitate sophisticated post-processingoperations to distinguish nuclei instances, which are commonly acknowledged tobe error-prone and parameter-sensitive. Recently, the segment anything model(SAM) has earned attracted huge attention within the domain of medical imagesegmentation due to its impressive generalization ability and promptableproperty. Nevertheless, its potential on nuclear instance segmentation remainslargely underexplored. In this paper, we present a novel prompt-drivenframework that consists of a point prompter and a SAM for automatic nucleiinstance segmentation. Specifically, the prompter learns to generate a uniquepoint prompt for each nucleus while the SAM is fine tuned to output thecorresponding mask of the cued nucleus. Furthermore, we propose to add adjacentnuclei as negative prompts to promote the model's ability to recognizeoverlapping nuclei. Without bells and whistles, our proposed method sets a newstate-of-the-art performance on three challenging benchmarks. Our code isavailable at\textcolor{magenta}{\url{https://github.com/windygoo/PromptNucSeg}} .</description><author>Zhongyi Shui, Yunlong Zhang, Kai Yao, Chenglu Zhu, Yuxuan Sun, Lin Yang</author><pubDate>Mon, 27 Nov 2023 15:46:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15939v1</guid></item><item><title>Optimal Transport Aggregation for Visual Place Recognition</title><link>http://arxiv.org/abs/2311.15937v1</link><description>The task of Visual Place Recognition (VPR) aims to match a query imageagainst references from an extensive database of images from different places,relying solely on visual cues. State-of-the-art pipelines focus on theaggregation of features extracted from a deep backbone, in order to form aglobal descriptor for each image. In this context, we introduce SALAD (SinkhornAlgorithm for Locally Aggregated Descriptors), which reformulates NetVLAD'ssoft-assignment of local features to clusters as an optimal transport problem.In SALAD, we consider both feature-to-cluster and cluster-to-feature relationsand we also introduce a 'dustbin' cluster, designed to selectively discardfeatures deemed non-informative, enhancing the overall descriptor quality.Additionally, we leverage and fine-tune DINOv2 as a backbone, which providesenhanced description power for the local features, and dramatically reduces therequired training time. As a result, our single-stage method not only surpassessingle-stage baselines in public VPR datasets, but also surpasses two-stagemethods that add a re-ranking with significantly higher cost. Code and modelsare available at https://github.com/serizba/salad.</description><author>Sergio Izquierdo, Javier Civera</author><pubDate>Mon, 27 Nov 2023 15:46:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15937v1</guid></item><item><title>Towards Responsible Governance of Biological Design Tools</title><link>http://arxiv.org/abs/2311.15936v1</link><description>Recent advancements in generative machine learning have enabled rapidprogress in biological design tools (BDTs) such as protein structure andsequence prediction models. The unprecedented predictive accuracy and noveldesign capabilities of BDTs present new and significant dual-use risks. Forexample, their predictive accuracy allows biological agents, whether vaccinesor pathogens, to be developed more quickly, while the design capabilities couldbe used to discover drugs or evade DNA screening techniques. Similar to otherdual-use AI systems, BDTs present a wicked problem: how can regulators upholdpublic safety without stifling innovation? We highlight how current regulatoryproposals that are primarily tailored toward large language models may be lesseffective for BDTs, which require fewer computational resources to train andare often developed in an open-source manner. We propose a range of measures tomitigate the risk that BDTs are misused, across the areas of responsibledevelopment, risk assessment, transparency, access management, cybersecurity,and investing in resilience. Implementing such measures will require closecoordination between developers and governments.</description><author>Richard Moulange, Max Langenkamp, Tessa Alexanian, Samuel Curtis, Morgan Livingston</author><pubDate>Mon, 27 Nov 2023 15:45:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15936v1</guid></item><item><title>A new fuzzy multi-attribute group decision-making method based on TOPSIS and optimization models</title><link>http://arxiv.org/abs/2311.15933v1</link><description>In this paper, a new method based on TOPSIS and optimization models isproposed for multi-attribute group decision-making in the environment ofinterval-valued intuitionistic fuzzy sets.Firstly, by minimizing the sum ofdifferences between individual evaluations and the overallconsistentevaluations of all experts, a new optimization model is established fordetermining expert weights. Secondly, based on TOPSIS method, the improvedcloseness index for evaluating each alternative is obtained. Finally, theattribute weight is determined by establishing an optimization model with thegoal of maximizing the closeness of each alternative, and it is brought intothe closeness index so that the alternatives can be ranked. Combining all thesetogether, the complete fuzzy multi-attribute group decision-making algorithm isformulated, which can give full play to the advantages of subjective andobjective weighting methods. In the end, the feasibility and effectiveness ofthe provided method are verified by a real case study.</description><author>Qixiao Hu, Shiquan Zhang, Chaolang Hu, Yuetong Liu</author><pubDate>Mon, 27 Nov 2023 15:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15933v1</guid></item><item><title>Energy Discrepancies: A Score-Independent Loss for Energy-Based Models</title><link>http://arxiv.org/abs/2307.06431v2</link><description>Energy-based models are a simple yet powerful class of probabilistic models,but their widespread adoption has been limited by the computational burden oftraining them. We propose a novel loss function called Energy Discrepancy (ED)which does not rely on the computation of scores or expensive Markov chainMonte Carlo. We show that ED approaches the explicit score matching andnegative log-likelihood loss under different limits, effectively interpolatingbetween both. Consequently, minimum ED estimation overcomes the problem ofnearsightedness encountered in score-based estimation methods, while alsoenjoying theoretical guarantees. Through numerical experiments, we demonstratethat ED learns low-dimensional data distributions faster and more accuratelythan explicit score matching or contrastive divergence. For high-dimensionalimage data, we describe how the manifold hypothesis puts limitations on ourapproach and demonstrate the effectiveness of energy discrepancy by trainingthe energy-based model as a prior of a variational decoder model.</description><author>Tobias Schröder, Zijing Ou, Jen Ning Lim, Yingzhen Li, Sebastian J. Vollmer, Andrew B. Duncan</author><pubDate>Mon, 27 Nov 2023 15:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06431v2</guid></item><item><title>WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large Language Models</title><link>http://arxiv.org/abs/2311.15930v1</link><description>We propose WorldSense, a benchmark designed to assess the extent to whichLLMs are consistently able to sustain tacit world models, by testing how theydraw simple inferences from descriptions of simple arrangements of entities.Worldsense is a synthetic benchmark with three problem types, each with theirown trivial control, which explicitly avoids bias by decorrelating the abstractstructure of problems from the vocabulary and expressions, and by decorrelatingall problem subparts with the correct response. We run our benchmark on threestate-of-the-art chat-LLMs (GPT3.5, GPT4 and Llama2-chat) and show that thesemodels make errors even with as few as three objects. Furthermore, they havequite heavy response biases, preferring certain responses irrespective of thequestion. Errors persist even with chain-of-thought prompting and in-contextlearning. Lastly, we show that while finetuning on similar problems does resultin substantial improvements -- within- and out-of-distribution -- the finetunedmodels do not generalise beyond a constraint problem space.</description><author>Youssef Benchekroun, Megi Dervishi, Mark Ibrahim, Jean-Baptiste Gaya, Xavier Martinet, Grégoire Mialon, Thomas Scialom, Emmanuel Dupoux, Dieuwke Hupkes, Pascal Vincent</author><pubDate>Mon, 27 Nov 2023 15:38:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15930v1</guid></item></channel></rss>