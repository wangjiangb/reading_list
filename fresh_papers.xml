<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 20 Nov 2023 06:00:29 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Machine learning phase transitions: Connections to the Fisher information</title><link>http://arxiv.org/abs/2311.10710v1</link><description>Despite the widespread use and success of machine-learning techniques fordetecting phase transitions from data, their working principle and fundamentallimits remain elusive. Here, we explain the inner workings and identifypotential failure modes of these techniques by rooting popular machine-learningindicators of phase transitions in information-theoretic concepts. Using toolsfrom information geometry, we prove that several machine-learning indicators ofphase transitions approximate the square root of the system's (quantum) Fisherinformation from below -- a quantity that is known to indicate phasetransitions but is often difficult to compute from data. We numericallydemonstrate the quality of these bounds for phase transitions in classical andquantum systems.</description><author>Julian Arnold, Niels Lörch, Flemming Holtorf, Frank Schäfer</author><pubDate>Fri, 17 Nov 2023 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10710v1</guid></item><item><title>Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning</title><link>http://arxiv.org/abs/2311.10709v1</link><description>We present Emu Video, a text-to-video generation model that factorizes thegeneration into two steps: first generating an image conditioned on the text,and then generating a video conditioned on the text and the generated image. Weidentify critical design decisions--adjusted noise schedules for diffusion, andmulti-stage training--that enable us to directly generate high quality and highresolution videos, without requiring a deep cascade of models as in prior work.In human evaluations, our generated videos are strongly preferred in qualitycompared to all prior work--81% vs. Google's Imagen Video, 90% vs. Nvidia'sPYOCO, and 96% vs. Meta's Make-A-Video. Our model outperforms commercialsolutions such as RunwayML's Gen2 and Pika Labs. Finally, our factorizingapproach naturally lends itself to animating images based on a user's textprompt, where our generations are preferred 96% over prior work.</description><author>Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, Samaneh Azadi, Sai Saketh Rambhatla, Akbar Shah, Xi Yin, Devi Parikh, Ishan Misra</author><pubDate>Fri, 17 Nov 2023 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10709v1</guid></item><item><title>SelfEval: Leveraging the discriminative nature of generative models for evaluation</title><link>http://arxiv.org/abs/2311.10708v1</link><description>In this work, we show that text-to-image generative models can be 'inverted'to assess their own text-image understanding capabilities in a completelyautomated manner. Our method, called SelfEval, uses the generative model to compute thelikelihood of real images given text prompts, making the generative modeldirectly applicable to discriminative tasks. Using SelfEval, we repurpose standard datasets created for evaluatingmultimodal text-image discriminative models to evaluate generative models in afine-grained manner: assessing their performance on attribute binding, colorrecognition, counting, shape recognition, spatial understanding. To the best of our knowledge SelfEval is the first automated metric to show ahigh degree of agreement for measuring text-faithfulness with the gold-standardhuman evaluations across multiple models and benchmarks. Moreover, SelfEval enables us to evaluate generative models on challengingtasks such as Winoground image-score where they demonstrate competitiveperformance to discriminative models. We also show severe drawbacks of standard automated metrics such asCLIP-score to measure text faithfulness on benchmarks such as DrawBench, andhow SelfEval sidesteps these issues. We hope SelfEval enables easy and reliable automated evaluation for diffusionmodels.</description><author>Sai Saketh Rambhatla, Ishan Misra</author><pubDate>Fri, 17 Nov 2023 18:58:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10708v1</guid></item><item><title>Multimodal Representation Learning by Alternating Unimodal Adaptation</title><link>http://arxiv.org/abs/2311.10707v1</link><description>Multimodal learning, which integrates data from diverse sensory modes, playsa pivotal role in artificial intelligence. However, existing multimodallearning methods often struggle with challenges where some modalities appearmore dominant than others during multimodal learning, resulting in suboptimalperformance. To address this challenge, we propose MLA (Multimodal Learningwith Alternating Unimodal Adaptation). MLA reframes the conventional jointmultimodal learning process by transforming it into an alternating unimodallearning process, thereby minimizing interference between modalities.Simultaneously, it captures cross-modal interactions through a shared head,which undergoes continuous optimization across different modalities. Thisoptimization process is controlled by a gradient modification mechanism toprevent the shared head from losing previously acquired information. During theinference phase, MLA utilizes a test-time uncertainty-based model fusionmechanism to integrate multimodal information. Extensive experiments areconducted on five diverse datasets, encompassing scenarios with completemodalities and scenarios with missing modalities. These experiments demonstratethe superiority of MLA over competing prior approaches.</description><author>Xiaohui Zhang, Jaehong Yoon, Mohit Bansal, Huaxiu Yao</author><pubDate>Fri, 17 Nov 2023 18:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10707v1</guid></item><item><title>JaxMARL: Multi-Agent RL Environments in JAX</title><link>http://arxiv.org/abs/2311.10090v2</link><description>Benchmarks play an important role in the development of machine learningalgorithms. For example, research in reinforcement learning (RL) has beenheavily influenced by available environments and benchmarks. However, RLenvironments are traditionally run on the CPU, limiting their scalability withtypical academic compute. Recent advancements in JAX have enabled the wider useof hardware acceleration to overcome these computational hurdles, enablingmassively parallel RL training pipelines and environments. This is particularlyuseful for multi-agent reinforcement learning (MARL) research. First of all,multiple agents must be considered at each environment step, addingcomputational burden, and secondly, the sample complexity is increased due tonon-stationarity, decentralised partial observability, or other MARLchallenges. In this paper, we present JaxMARL, the first open-source code basethat combines ease-of-use with GPU enabled efficiency, and supports a largenumber of commonly used MARL environments as well as popular baselinealgorithms. When considering wall clock time, our experiments show that per-runour JAX-based training pipeline is up to 12500x faster than existingapproaches. This enables efficient and thorough evaluations, with the potentialto alleviate the evaluation crisis of the field. We also introduce andbenchmark SMAX, a vectorised, simplified version of the popular StarCraftMulti-Agent Challenge, which removes the need to run the StarCraft II gameengine. This not only enables GPU acceleration, but also provides a moreflexible MARL environment, unlocking the potential for self-play,meta-learning, and other future applications in MARL. We provide code athttps://github.com/flairox/jaxmarl.</description><author>Alexander Rutherford, Benjamin Ellis, Matteo Gallici, Jonathan Cook, Andrei Lupu, Gardar Ingvarsson, Timon Willi, Akbir Khan, Christian Schroeder de Witt, Alexandra Souly, Saptarashmi Bandyopadhyay, Mikayel Samvelyan, Minqi Jiang, Robert Tjarko Lange, Shimon Whiteson, Bruno Lacerda, Nick Hawes, Tim Rocktaschel, Chris Lu, Jakob Nicolaus Foerster</author><pubDate>Fri, 17 Nov 2023 18:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10090v2</guid></item><item><title>SHAMSUL: Systematic Holistic Analysis to investigate Medical Significance Utilizing Local interpretability methods in deep learning for chest radiography pathology prediction</title><link>http://arxiv.org/abs/2307.08003v2</link><description>The interpretability of deep neural networks has become a subject of greatinterest within the medical and healthcare domain. This attention stems fromconcerns regarding transparency, legal and ethical considerations, and themedical significance of predictions generated by these deep neural networks inclinical decision support systems. To address this matter, our study delvesinto the application of four well-established interpretability methods: LocalInterpretable Model-agnostic Explanations (LIME), Shapley Additive exPlanations(SHAP), Gradient-weighted Class Activation Mapping (Grad-CAM), and Layer-wiseRelevance Propagation (LRP). Leveraging the approach of transfer learning witha multi-label-multi-class chest radiography dataset, we aim to interpretpredictions pertaining to specific pathology classes. Our analysis encompassesboth single-label and multi-label predictions, providing a comprehensive andunbiased assessment through quantitative and qualitative investigations, whichare compared against human expert annotation. Notably, Grad-CAM demonstratesthe most favorable performance in quantitative evaluation, while the LIMEheatmap score segmentation visualization exhibits the highest level of medicalsignificance. Our research underscores both the outcomes and the challengesfaced in the holistic approach adopted for assessing these interpretabilitymethods and suggests that a multimodal-based approach, incorporating diversesources of information beyond chest radiography images, could offer additionalinsights for enhancing interpretability in the medical domain.</description><author>Mahbub Ul Alam, Jaakko Hollmén, Jón Rúnar Baldvinsson, Rahim Rahmani</author><pubDate>Fri, 17 Nov 2023 18:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08003v2</guid></item><item><title>Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2</title><link>http://arxiv.org/abs/2311.10702v1</link><description>Since the release of T\"ULU [Wang et al., 2023b], open resources forinstruction tuning have developed quickly, from better base models to newfinetuning techniques. We test and incorporate a number of these advances intoT\"ULU, resulting in T\"ULU 2, a suite of improved T\"ULU models for advancingthe understanding and best practices of adapting pretrained language models todownstream tasks and user preferences. Concretely, we release: (1)T\"ULU-V2-mix, an improved collection of high-quality instruction datasets; (2)T\"ULU 2, LLAMA-2 models finetuned on the V2 mixture; (3) T\"ULU 2+DPO, T\"ULU2 models trained with direct preference optimization (DPO), including thelargest DPO-trained model to date (T\"ULU 2+DPO 70B); (4) CODE T\"ULU 2, CODELLAMA models finetuned on our V2 mix that outperform CODE LLAMA and itsinstruction-tuned variant, CODE LLAMA-Instruct. Our evaluation from multipleperspectives shows that the T\"ULU 2 suite achieves state-of-the-artperformance among open models and matches or exceeds the performance ofGPT-3.5-turbo-0301 on several benchmarks. We release all the checkpoints, data,training and evaluation code to facilitate future open efforts on adaptinglarge language models.</description><author>Hamish Ivison, Yizhong Wang, Valentina Pyatkin, Nathan Lambert, Matthew Peters, Pradeep Dasigi, Joel Jang, David Wadden, Noah A. Smith, Iz Beltagy, Hannaneh Hajishirzi</author><pubDate>Fri, 17 Nov 2023 18:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10702v1</guid></item><item><title>SpACNN-LDVAE: Spatial Attention Convolutional Latent Dirichlet Variational Autoencoder for Hyperspectral Pixel Unmixing</title><link>http://arxiv.org/abs/2311.10701v1</link><description>The Hyperspectral Unxming problem is to find the pure spectral signal of theunderlying materials (endmembers) and their proportions (abundances). Theproposed method builds upon the recently proposed method, Latent DirichletVariational Autoencoder (LDVAE). It assumes that abundances can be encoded asDirichlet Distributions while mixed pixels and endmembers are represented byMultivariate Normal Distributions. However, LDVAE does not leverage spatialinformation present in an HSI; we propose an Isotropic CNN encoder with spatialattention to solve the hyperspectral unmixing problem. We evaluated our modelon Samson, Hydice Urban, Cuprite, and OnTech-HSI-Syn-21 datasets. Our modelalso leverages the transfer learning paradigm for Cuprite Dataset, where wetrain the model on synthetic data and evaluate it on real-world data. We areable to observe the improvement in the results for the endmember extraction andabundance estimation by incorporating the spatial information. Code can befound at https://github.com/faisalqureshi/cnn-ldvae</description><author>Soham Chitnis, Kiran Mantripragada, Faisal Z. Qureshi</author><pubDate>Fri, 17 Nov 2023 18:45:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10701v1</guid></item><item><title>Using linear initialisation to improve speed of convergence and fully-trained error in Autoencoders</title><link>http://arxiv.org/abs/2311.10699v1</link><description>Good weight initialisation is an important step in successful training ofArtificial Neural Networks. Over time a number of improvements have beenproposed to this process. In this paper we introduce a novel weightinitialisation technique called the Straddled Matrix Initialiser. Thisinitialisation technique is motivated by our assumption that major,global-scale relationships in data are linear with only smaller effectsrequiring complex non-linearities. Combination of Straddled Matrix and ReLUactivation function initialises a Neural Network as a de facto linear model,which we postulate should be a better starting point for optimisation given ourassumptions. We test this by training autoencoders on three datasets usingStraddled Matrix and seven other state-of-the-art weight initialisationtechniques. In all our experiments the Straddeled Matrix Initialiser clearlyoutperforms all other methods.</description><author>Marcel Marais, Mate Hartstein, George Cevora</author><pubDate>Fri, 17 Nov 2023 18:43:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10699v1</guid></item><item><title>VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use</title><link>http://arxiv.org/abs/2308.06595v3</link><description>We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark forevaluation of instruction-following vision-language models for real-world use.Our starting point is curating 70 'instruction families' that we envisioninstruction tuned vision-language models should be able to address. Extendingbeyond evaluations like VQAv2 and COCO, tasks range from basic recognition togame playing and creative generation. Following curation, our dataset comprises592 test queries, each with a human-authored instruction-conditioned caption.These descriptions surface instruction-specific factors, e.g., for aninstruction asking about the accessibility of a storefront for wheelchairusers, the instruction-conditioned caption describes ramps/potential obstacles.These descriptions enable 1) collecting human-verified reference outputs foreach instance; and 2) automatic evaluation of candidate multimodal generationsusing a text-only LLM, aligning with human judgment. We quantify quality gapsbetween models and references using both human and automatic evaluations; e.g.,the top-performing instruction-following model wins against the GPT-4 referencein just 27% of the comparison. VisIT-Bench is dynamic to participate,practitioners simply submit their model's response on the project website;Data, code and leaderboard is available at visit-bench.github.io.</description><author>Yonatan Bitton, Hritik Bansal, Jack Hessel, Rulin Shao, Wanrong Zhu, Anas Awadalla, Josh Gardner, Rohan Taori, Ludwig Schmidt</author><pubDate>Fri, 17 Nov 2023 18:39:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06595v3</guid></item><item><title>PEFT-MedAware: Large Language Model for Medical Awareness</title><link>http://arxiv.org/abs/2311.10697v1</link><description>Chat models are capable of answering a wide range of questions, however, theaccuracy of their responses is highly uncertain. In this research, we propose aspecialized PEFT-MedAware model where we utilize parameter-efficientfine-tuning (PEFT) to enhance the Falcon-1b large language model on specializedMedQuAD data consisting of 16,407 medical QA pairs, leveraging only 0.44% ofits trainable parameters to enhance computational efficiency. The paper adoptsdata preprocessing and PEFT to optimize model performance, complemented by aBitsAndBytesConfig for efficient transformer training. The resulting model wascapable of outperforming other LLMs in medical question-answering tasks inspecific domains with greater accuracy utilizing limited computationalresources making it suitable for deployment in resource-constrainedenvironments. We propose further improvements through expanded datasets, largermodels, and feedback mechanisms for sustained medical relevancy. Our workhighlights the efficiency gains and specialized capabilities of PEFT in medicalAI, outpacing standard models in precision without extensive resource demands.The proposed model and data are released for research purposes only.</description><author>Keivalya Pandya</author><pubDate>Fri, 17 Nov 2023 18:32:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10697v1</guid></item><item><title>Versatile Medical Image Segmentation Learned from Multi-Source Datasets via Model Self-Disambiguation</title><link>http://arxiv.org/abs/2311.10696v1</link><description>A versatile medical image segmentation model applicable to imaging datacollected with diverse equipment and protocols can facilitate model deploymentand maintenance. However, building such a model typically requires a large,diverse, and fully annotated dataset, which is rarely available due to thelabor-intensive and costly data curation. In this study, we develop acost-efficient method by harnessing readily available data with partially oreven sparsely annotated segmentation labels. We devise strategies for modelself-disambiguation, prior knowledge incorporation, and imbalance mitigation toaddress challenges associated with inconsistently labeled data from varioussources, including label ambiguity and imbalances across modalities, datasets,and segmentation labels. Experimental results on a multi-modal dataset compiledfrom eight different sources for abdominal organ segmentation have demonstratedour method's effectiveness and superior performance over alternativestate-of-the-art methods, highlighting its potential for optimizing the use ofexisting annotated data and reducing the annotation efforts for new data tofurther enhance model capability.</description><author>Xiaoyang Chen, Hao Zheng, Yuemeng Li, Yuncong Ma, Liang Ma, Hongming Li, Yong Fan</author><pubDate>Fri, 17 Nov 2023 18:28:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10696v1</guid></item><item><title>Optimal Embedding Dimension for Sparse Subspace Embeddings</title><link>http://arxiv.org/abs/2311.10680v1</link><description>A random $m\times n$ matrix $S$ is an oblivious subspace embedding (OSE) withparameters $\epsilon&gt;0$, $\delta\in(0,1/3)$ and $d\leq m\leq n$, if for any$d$-dimensional subspace $W\subseteq R^n$, $P\big(\,\forall_{x\in W}\ (1+\epsilon)^{-1}\|x\|\leq\|Sx\|\leq(1+\epsilon)\|x\|\,\big)\geq 1-\delta.$ It is known that the embedding dimension of an OSE must satisfy $m\geq d$,and for any $\theta &gt; 0$, a Gaussian embedding matrix with $m\geq (1+\theta) d$is an OSE with $\epsilon = O_\theta(1)$. However, such optimal embeddingdimension is not known for other embeddings. Of particular interest are sparseOSEs, having $s\ll m$ non-zeros per column, with applications to problems suchas least squares regression and low-rank approximation. We show that, given any $\theta &gt; 0$, an $m\times n$ random matrix $S$ with$m\geq (1+\theta)d$ consisting of randomly sparsified $\pm1/\sqrt s$ entriesand having $s= O(\log^4(d))$ non-zeros per column, is an oblivious subspaceembedding with $\epsilon = O_{\theta}(1)$. Our result addresses the main openquestion posed by Nelson and Nguyen (FOCS 2013), who conjectured that sparseOSEs can achieve $m=O(d)$ embedding dimension, and it improves on$m=O(d\log(d))$ shown by Cohen (SODA 2016). We use this to construct the firstoblivious subspace embedding with $O(d)$ embedding dimension that can beapplied faster than current matrix multiplication time, and to obtain anoptimal single-pass algorithm for least squares regression. We further extendour results to construct even sparser non-oblivious embeddings, leading to thefirst subspace embedding with low distortion $\epsilon=o(1)$ and optimalembedding dimension $m=O(d/\epsilon^2)$ that can be applied in current matrixmultiplication time.</description><author>Shabarish Chenakkod, Michał Dereziński, Xiaoyu Dong, Mark Rudelson</author><pubDate>Fri, 17 Nov 2023 18:01:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10680v1</guid></item><item><title>Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections</title><link>http://arxiv.org/abs/2311.10678v1</link><description>Today's robot policies exhibit subpar performance when faced with thechallenge of generalizing to novel environments. Human corrective feedback is acrucial form of guidance to enable such generalization. However, adapting toand learning from online human corrections is a non-trivial endeavor: not onlydo robots need to remember human feedback over time to retrieve the rightinformation in new settings and reduce the intervention rate, but also theywould need to be able to respond to feedback that can be arbitrary correctionsabout high-level human preferences to low-level adjustments to skillparameters. In this work, we present Distillation and Retrieval of OnlineCorrections (DROC), a large language model (LLM)-based system that can respondto arbitrary forms of language feedback, distill generalizable knowledge fromcorrections, and retrieve relevant past experiences based on textual and visualsimilarity for improving performance in novel settings. DROC is able to respondto a sequence of online language corrections that address failures in bothhigh-level task plans and low-level skill primitives. We demonstrate that DROCeffectively distills the relevant information from the sequence of onlinecorrections in a knowledge base and retrieves that knowledge in settings withnew task or object instances. DROC outperforms other techniques that directlygenerate robot code via LLMs by using only half of the total number ofcorrections needed in the first round and requires little to no correctionsafter two iterations. We show further results, videos, prompts and code onhttps://sites.google.com/stanford.edu/droc .</description><author>Lihan Zha, Yuchen Cui, Li-Heng Lin, Minae Kwon, Montserrat Gonzalez Arenas, Andy Zeng, Fei Xia, Dorsa Sadigh</author><pubDate>Fri, 17 Nov 2023 18:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10678v1</guid></item><item><title>Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference</title><link>http://arxiv.org/abs/2311.10671v1</link><description>We present multimodal neural posterior estimation (MultiNPE), a method tointegrate heterogeneous data from different sources in simulation-basedinference with neural networks. Inspired by advances in attention-based deepfusion learning, it empowers researchers to analyze data from different domainsand infer the parameters of complex mathematical models with increasedaccuracy. We formulate different multimodal fusion approaches for MultiNPE(early, late, and hybrid) and evaluate their performance in three challengingnumerical experiments. MultiNPE not only outperforms na\"ive baselines on abenchmark model, but also achieves superior inference on representativescientific models from neuroscience and cardiology. In addition, wesystematically investigate the impact of partially missing data on thedifferent fusion strategies. Across our different experiments, late and hybridfusion techniques emerge as the methods of choice for practical applications ofmultimodal simulation-based inference.</description><author>Marvin Schmitt, Stefan T. Radev, Paul-Christian Bürkner</author><pubDate>Fri, 17 Nov 2023 17:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10671v1</guid></item><item><title>Online Calibration of Deep Learning Sub-Models for Hybrid Numerical Modeling Systems</title><link>http://arxiv.org/abs/2311.10665v1</link><description>Artificial intelligence and deep learning are currently reshaping numericalsimulation frameworks by introducing new modeling capabilities. Theseframeworks are extensively investigated in the context of model correction andparameterization where they demonstrate great potential and often outperformtraditional physical models. Most of these efforts in defining hybrid dynamicalsystems follow {offline} learning strategies in which the neuralparameterization (called here sub-model) is trained to output an idealcorrection. Yet, these hybrid models can face hard limitations when definingwhat should be a relevant sub-model response that would translate into a goodforecasting performance. End-to-end learning schemes, also referred to asonline learning, could address such a shortcoming by allowing the deep learningsub-models to train on historical data. However, defining end-to-end trainingschemes for the calibration of neural sub-models in hybrid systems requiresworking with an optimization problem that involves the solver of the physicalequations. Online learning methodologies thus require the numerical model to bedifferentiable, which is not the case for most modeling systems. To overcomethis difficulty and bypass the differentiability challenge of physical models,we present an efficient and practical online learning approach for hybridsystems. The method, called EGA for Euler Gradient Approximation, assumes anadditive neural correction to the physical model, and an explicit Eulerapproximation of the gradients. We demonstrate that the EGA converges to theexact gradients in the limit of infinitely small time steps. Numericalexperiments are performed on various case studies, including prototypicalocean-atmosphere dynamics. Results show significant improvements over offlinelearning, highlighting the potential of end-to-end online learning for hybridmodeling.</description><author>Said Ouala, Bertrand Chapron, Fabrice Collard, Lucile Gaultier, Ronan Fablet</author><pubDate>Fri, 17 Nov 2023 17:36:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10665v1</guid></item><item><title>InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration in Improving the Performance of Information Extraction</title><link>http://arxiv.org/abs/2305.14659v2</link><description>Learning template based information extraction from documents is a crucialyet difficult task. Prior template-based IE approaches assume foreknowledge ofthe domain templates; however, real-world IE do not have pre-defined schemasand it is a figure-out-as you go phenomena. To quickly bootstrap templates in areal-world setting, we need to induce template slots from documents with zeroor minimal supervision. Since the purpose of question answering intersect withthe goal of information extraction, we use automatic question generation toinduce template slots from the documents and investigate how a tiny amount of aproxy human-supervision on-the-fly (termed as InteractiveIE) can further boostthe performance. Extensive experiments on biomedical and legal documents, whereobtaining training data is expensive, reveal encouraging trends of performanceimprovement using InteractiveIE over AI-only baseline.</description><author>Ishani Mondal, Michelle Yuan, Anandhavelu N, Aparna Garimella, Francis Ferraro, Andrew Blair-Stanek, Benjamin Van Durme, Jordan Boyd-Graber</author><pubDate>Fri, 17 Nov 2023 17:31:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14659v2</guid></item><item><title>Learning Realistic Joint Space Boundaries for Range of Motion Analysis of Healthy and Impaired Human Arms</title><link>http://arxiv.org/abs/2311.10653v1</link><description>A realistic human kinematic model that satisfies anatomical constraints isessential for human-robot interaction, biomechanics and robot-assistedrehabilitation. Modeling realistic joint constraints, however, is challengingas human arm motion is constrained by joint limits, inter- and intra-jointdependencies, self-collisions, individual capabilities and muscular orneurological constraints which are difficult to represent. Hence, physiciansand researchers have relied on simple box-constraints, ignoring importantanatomical factors. In this paper, we propose a data-driven method to learnrealistic anatomically constrained upper-limb range of motion (RoM) boundariesfrom motion capture data. This is achieved by fitting a one-class supportvector machine to a dataset of upper-limb joint space exploration motions withan efficient hyper-parameter tuning scheme. Our approach outperforms similarworks focused on valid RoM learning. Further, we propose an impairment index(II) metric that offers a quantitative assessment of capability/impairment whencomparing healthy and impaired arms. We validate the metric on healthy subjectsphysically constrained to emulate hemiplegia and different disability levels asstroke patients.</description><author>Shafagh Keyvanian, Michelle J. Johnson, Nadia Figueroa</author><pubDate>Fri, 17 Nov 2023 17:14:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10653v1</guid></item><item><title>3D-TexSeg: Unsupervised Segmentation of 3D Texture using Mutual Transformer Learning</title><link>http://arxiv.org/abs/2311.10651v1</link><description>Analysis of the 3D Texture is indispensable for various tasks, such asretrieval, segmentation, classification, and inspection of sculptures, knittedfabrics, and biological tissues. A 3D texture is a locally repeated surfacevariation independent of the surface's overall shape and can be determinedusing the local neighborhood and its characteristics. Existing techniquestypically employ computer vision techniques that analyze a 3D mesh globally,derive features, and then utilize the obtained features for retrieval orclassification. Several traditional and learning-based methods exist in theliterature, however, only a few are on 3D texture, and nothing yet, to the bestof our knowledge, on the unsupervised schemes. This paper presents an originalframework for the unsupervised segmentation of the 3D texture on the meshmanifold. We approach this problem as binary surface segmentation, partitioningthe mesh surface into textured and non-textured regions without priorannotation. We devise a mutual transformer-based system comprising a labelgenerator and a cleaner. The two models take geometric image representations ofthe surface mesh facets and label them as texture or non-texture across aniterative mutual learning scheme. Extensive experiments on three publiclyavailable datasets with diverse texture patterns demonstrate that the proposedframework outperforms standard and SOTA unsupervised techniques and competesreasonably with supervised methods.</description><author>Iyyakutti Iyappan Ganapathi, Fayaz Ali, Sajid Javed, Syed Sadaf Ali, Naoufel Werghi</author><pubDate>Fri, 17 Nov 2023 17:13:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10651v1</guid></item><item><title>What User Behaviors Make the Differences During the Process of Visual Analytics?</title><link>http://arxiv.org/abs/2311.00690v2</link><description>The understanding of visual analytics process can benefit visualizationresearchers from multiple aspects, including improving visual designs anddeveloping advanced interaction functions. However, the log files of userbehaviors are still hard to analyze due to the complexity of sensemaking andour lack of knowledge on the related user behaviors. This work presents a studyon a comprehensive data collection of user behaviors, and our analysis approachwith time-series classification methods. We have chosen a classicalvisualization application, Covid-19 data analysis, with common analysis taskscovering geo-spatial, time-series and multi-attributes. Our user study collectsuser behaviors on a diverse set of visualization tasks with two comparablesystems, desktop and immersive visualizations. We summarize the classificationresults with three time-series machine learning algorithms at two scales, andexplore the influences of behavior features. Our results reveal that userbehaviors can be distinguished during the process of visual analytics and thereis a potentially strong association between the physical behaviors of users andthe visualization tasks they perform. We also demonstrate the usage of ourmodels by interpreting open sessions of visual analytics, which provides anautomatic way to study sensemaking without tedious manual annotations.</description><author>Shahin Doroudian, Zekun Wu, Aidong Lu</author><pubDate>Fri, 17 Nov 2023 17:09:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00690v2</guid></item><item><title>Self-trained Panoptic Segmentation</title><link>http://arxiv.org/abs/2311.10648v1</link><description>Panoptic segmentation is an important computer vision task which combinessemantic and instance segmentation. It plays a crucial role in domains ofmedical image analysis, self-driving vehicles, and robotics by providing acomprehensive understanding of visual environments. Traditionally, deeplearning panoptic segmentation models have relied on dense and accuratelyannotated training data, which is expensive and time consuming to obtain.Recent advancements in self-supervised learning approaches have shown greatpotential in leveraging synthetic and unlabelled data to generate pseudo-labelsusing self-training to improve the performance of instance and semanticsegmentation models. The three available methods for self-supervised panopticsegmentation use proposal-based transformer architectures which arecomputationally expensive, complicated and engineered for specific tasks. Theaim of this work is to develop a framework to perform embedding-basedself-supervised panoptic segmentation using self-training in asynthetic-to-real domain adaptation problem setting.</description><author>Shourya Verma</author><pubDate>Fri, 17 Nov 2023 17:06:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10648v1</guid></item><item><title>In search of dispersed memories: Generative diffusion models are associative memory networks</title><link>http://arxiv.org/abs/2309.17290v2</link><description>Uncovering the mechanisms behind long-term memory is one of the mostfascinating open problems in neuroscience and artificial intelligence.Artificial associative memory networks have been used to formalize importantaspects of biological memory. Generative diffusion models are a type ofgenerative machine learning techniques that have shown great performance inmany tasks. Like associative memory systems, these networks define a dynamicalsystem that converges to a set of target states. In this work we show thatgenerative diffusion models can be interpreted as energy-based models and that,when trained on discrete patterns, their energy function is (asymptotically)identical to that of modern Hopfield networks. This equivalence allows us tointerpret the supervised training of diffusion models as a synaptic learningprocess that encodes the associative dynamics of a modern Hopfield network inthe weight structure of a deep neural network. Leveraging this connection, weformulate a generalized framework for understanding the formation of long-termmemory, where creative generation and memory recall can be seen as parts of aunified continuum.</description><author>Luca Ambrogioni</author><pubDate>Fri, 17 Nov 2023 17:05:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17290v2</guid></item><item><title>Closed Drafting as a Case Study for First-Principle Interpretability, Memory, and Generalizability in Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2310.20654v3</link><description>Closed drafting or "pick and pass" is a popular game mechanic where eachround players select a card or other playable element from their hand and passthe rest to the next player. In this paper, we establish first-principlemethods for studying the interpretability, generalizability, and memory of DeepQ-Network (DQN) models playing closed drafting games. In particular, we use apopular family of closed drafting games called "Sushi Go Party", in which weachieve state-of-the-art performance. We fit decision rules to interpret thedecision-making strategy of trained DRL agents by comparing them to the rankingpreferences of different types of human players. As Sushi Go Party can beexpressed as a set of closely-related games based on the set of cards in play,we quantify the generalizability of DRL models trained on various sets ofcards, establishing a method to benchmark agent performance as a function ofenvironment unfamiliarity. Using the explicitly calculable memory of otherplayer's hands in closed drafting games, we create measures of the ability ofDRL models to learn memory.</description><author>Ryan Rezai, Jason Wang</author><pubDate>Fri, 17 Nov 2023 17:01:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20654v3</guid></item><item><title>Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as an Alternative to Attention Layers in Transformers</title><link>http://arxiv.org/abs/2311.10642v1</link><description>This work presents an analysis of the effectiveness of using standard shallowfeed-forward networks to mimic the behavior of the attention mechanism in theoriginal Transformer model, a state-of-the-art architecture forsequence-to-sequence tasks. We substitute key elements of the attentionmechanism in the Transformer with simple feed-forward networks, trained usingthe original components via knowledge distillation. Our experiments, conductedon the IWSLT2017 dataset, reveal the capacity of these "attentionlessTransformers" to rival the performance of the original architecture. Throughrigorous ablation studies, and experimenting with various replacement networktypes and sizes, we offer insights that support the viability of our approach.This not only sheds light on the adaptability of shallow feed-forward networksin emulating attention mechanisms but also underscores their potential tostreamline complex architectures for sequence-to-sequence tasks.</description><author>Vukasin Bozic, Danilo Dordervic, Daniele Coppola, Joseph Thommes</author><pubDate>Fri, 17 Nov 2023 16:58:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10642v1</guid></item><item><title>Multi-delay arterial spin-labeled perfusion estimation with biophysics simulation and deep learning</title><link>http://arxiv.org/abs/2311.10640v1</link><description>Purpose: To develop biophysics-based method for estimating perfusion Q fromarterial spin labeling (ASL) images using deep learning. Methods: A 3D U-Net(QTMnet) was trained to estimate perfusion from 4D tracer propagation images.The network was trained and tested on simulated 4D tracer concentration databased on artificial vasculature structure generated by constrained constructiveoptimization (CCO) method. The trained network was further tested in asynthetic brain ASL image based on vasculature network extracted from magneticresonance (MR) angiography. The estimations from both trained network and aconventional kinetic model were compared in ASL images acquired from eighthealthy volunteers. Results: QTMnet accurately reconstructed perfusion Q fromconcentration data. Relative error of the synthetic brain ASL image was 7.04%for perfusion Q, lower than the error using single-delay ASL model: 25.15% forQ, and multi-delay ASL model: 12.62% for perfusion Q. Conclusion: QTMnetprovides accurate estimation on perfusion parameters and is a promisingapproach as a clinical ASL MRI image processing pipeline.</description><author>Renjiu Hu, Qihao Zhang, Pascal Spincemaille, Thanh D. Nguyen, Yi Wang</author><pubDate>Fri, 17 Nov 2023 16:55:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10640v1</guid></item><item><title>Concept-free Causal Disentanglement with Variational Graph Auto-Encoder</title><link>http://arxiv.org/abs/2311.10638v1</link><description>In disentangled representation learning, the goal is to achieve a compactrepresentation that consists of all interpretable generative factors in theobservational data. Learning disentangled representations for graphs becomesincreasingly important as graph data rapidly grows. Existing approaches oftenrely on Variational Auto-Encoder (VAE) or its causal structure learning-basedrefinement, which suffer from sub-optimality in VAEs due to the independencefactor assumption and unavailability of concept labels, respectively. In thispaper, we propose an unsupervised solution, dubbed concept-free causaldisentanglement, built on a theoretically provable tight upper boundapproximating the optimal factor. This results in an SCM-like causal structuremodeling that directly learns concept structures from data. Based on this idea,we propose Concept-free Causal VGAE (CCVGAE) by incorporating a novel causaldisentanglement layer into Variational Graph Auto-Encoder. Furthermore, weprove concept consistency under our concept-free causal disentanglementframework, hence employing it to enhance the meta-learning framework, calledconcept-free causal Meta-Graph (CC-Meta-Graph). We conduct extensiveexperiments to demonstrate the superiority of the proposed models: CCVGAE andCC-Meta-Graph, reaching up to $29\%$ and $11\%$ absolute improvements overbaselines in terms of AUC, respectively.</description><author>Jingyun Feng, Lin Zhang, Lili Yang</author><pubDate>Fri, 17 Nov 2023 16:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10638v1</guid></item><item><title>A Privacy Preserving System for Movie Recommendations Using Federated Learning</title><link>http://arxiv.org/abs/2303.04689v2</link><description>Recommender systems have become ubiquitous in the past years. They solve thetyranny of choice problem faced by many users, and are utilized by many onlinebusinesses to drive engagement and sales. Besides other criticisms, likecreating filter bubbles within social networks, recommender systems are oftenreproved for collecting considerable amounts of personal data. However, topersonalize recommendations, personal information is fundamentally required. Arecent distributed learning scheme called federated learning has made itpossible to learn from personal user data without its central collection.Consequently, we present a recommender system for movie recommendations, whichprovides privacy and thus trustworthiness on multiple levels: First andforemost, it is trained using federated learning and thus, by its very nature,privacy-preserving, while still enabling users to benefit from global insights.Furthermore, a novel federated learning scheme, called FedQ, is employed, whichnot only addresses the problem of non-i.i.d.-ness and small local datasets, butalso prevents input data reconstruction attacks by aggregating client updatesearly. Finally, to reduce the communication overhead, compression is applied,which significantly compresses the exchanged neural network parametrizations toa fraction of their original size. We conjecture that this may also improvedata privacy through its lossy quantization stage.</description><author>David Neumann, Andreas Lutz, Karsten Müller, Wojciech Samek</author><pubDate>Fri, 17 Nov 2023 16:47:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04689v2</guid></item><item><title>Don't Say What You Don't Know: Improving the Consistency of Abstractive Summarization by Constraining Beam Search</title><link>http://arxiv.org/abs/2203.08436v2</link><description>Abstractive summarization systems today produce fluent and relevant output,but often "hallucinate" statements not supported by the source text. We analyzethe connection between hallucinations and training data, and find evidence thatmodels hallucinate because they train on target summaries that are unsupportedby the source. Based on our findings, we present PINOCCHIO, a new decodingmethod that improves the consistency of a transformer-based abstractivesummarizer by constraining beam search to avoid hallucinations. Given the modelstates and outputs at a given step, PINOCCHIO detects likely modelhallucinations based on various measures of attribution to the source text.PINOCCHIO backtracks to find more consistent output, and can opt to produce nosummary at all when no consistent generation can be found. In experiments, wefind that PINOCCHIO improves the consistency of generation (in terms of F1) byan average of~67% on two abstractive summarization datasets.</description><author>Daniel King, Zejiang Shen, Nishant Subramani, Daniel S. Weld, Iz Beltagy, Doug Downey</author><pubDate>Fri, 17 Nov 2023 16:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.08436v2</guid></item><item><title>Comparing Deep Reinforcement Learning Algorithms in Two-Echelon Supply Chains</title><link>http://arxiv.org/abs/2204.09603v3</link><description>In this study, we analyze and compare the performance of state-of-the-artdeep reinforcement learning algorithms for solving the supply chain inventorymanagement problem. This complex sequential decision-making problem consists ofdetermining the optimal quantity of products to be produced and shipped acrossdifferent warehouses over a given time horizon. In particular, we present amathematical formulation of a two-echelon supply chain environment withstochastic and seasonal demand, which allows managing an arbitrary number ofwarehouses and product types. Through a rich set of numerical experiments, wecompare the performance of different deep reinforcement learning algorithmsunder various supply chain structures, topologies, demands, capacities, andcosts. The results of the experimental plan indicate that deep reinforcementlearning algorithms outperform traditional inventory management strategies,such as the static (s, Q)-policy. Furthermore, this study provides detailedinsight into the design and development of an open-source software library thatprovides a customizable environment for solving the supply chain inventorymanagement problem using a wide range of data-driven approaches.</description><author>Francesco Stranieri, Fabio Stella</author><pubDate>Fri, 17 Nov 2023 16:42:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.09603v3</guid></item><item><title>Predicting the Probability of Collision of a Satellite with Space Debris: A Bayesian Machine Learning Approach</title><link>http://arxiv.org/abs/2311.10633v1</link><description>Space is becoming more crowded in Low Earth Orbit due to increased spaceactivity. Such a dense space environment increases the risk of collisionsbetween space objects endangering the whole space population. Therefore, theneed to consider collision avoidance as part of routine operations is evidentto satellite operators. Current procedures rely on the analysis of multiplecollision warnings by human analysts. However, with the continuous growth ofthe space population, this manual approach may become unfeasible, highlightingthe importance of automation in risk assessment. In 2019, ESA launched acompetition to study the feasibility of applying machine learning in collisionrisk estimation and released a dataset that contained sequences of ConjunctionData Messages (CDMs) in support of real close encounters. The competitionresults showed that the naive forecast and its variants are strong predictorsfor this problem, which suggests that the CDMs may follow the Markov property.The proposed work investigates this theory by benchmarking Hidden Markov Models(HMM) in predicting the risk of collision between two resident space objects byusing one feature of the entire dataset: the sequence of the probability in theCDMs. In addition, Bayesian statistics are used to infer a joint distributionfor the parameters of the models, which allows the development of robust andreliable probabilistic predictive models that can incorporate physical or priorknowledge about the problem within a rigorous theoretical framework andprovides prediction uncertainties that nicely reflect the accuracy of thepredicted risk. This work shows that the implemented HMM outperforms the naivesolution in some metrics, which further adds to the idea that the collisionwarnings may be Markovian and suggests that this is a powerful method to befurther explored.</description><author>João Simões Catulo, Cláudia Soares, Marta Guimarães</author><pubDate>Fri, 17 Nov 2023 16:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10633v1</guid></item><item><title>Inferential Moments of Uncertain Multivariable Systems</title><link>http://arxiv.org/abs/2305.01841v2</link><description>This article expands the framework of Bayesian inference and provides directprobabilistic methods for approaching inference tasks that are typicallyhandled with information theory. We treat Bayesian probability updating as arandom process and uncover intrinsic quantitative features of joint probabilitydistributions called inferential moments. Inferential moments quantify shapeinformation about how a prior distribution is expected to update in response toyet to be obtained information. Further, we quantify the unique probabilitydistribution whose statistical moments are the inferential moments in question.We find a power series expansion of the mutual information in terms ofinferential moments, which implies a connection between inferential theoreticlogic and elements of information theory. Of particular interest is theinferential deviation, which is the expected variation of the probability ofone variable in response to an inferential update of another. We explore twoapplications that analyze the inferential deviations of a Bayesian network toimprove decision-making. We implement simple greedy algorithms for exploringsensor tasking using inferential deviations that generally outperform similargreedy mutual information algorithms in terms of root mean squared errorbetween epistemic probability estimates and the ground truth probabilities theyare estimating.</description><author>Kevin Vanslette</author><pubDate>Fri, 17 Nov 2023 16:37:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.01841v2</guid></item><item><title>Conditional Optimal Transport on Function Spaces</title><link>http://arxiv.org/abs/2311.05672v2</link><description>We present a systematic study of conditional triangular transport maps infunction spaces from the perspective of optimal transportation and with a viewtowards amortized Bayesian inference. More specifically, we develop a theory ofconstrained optimal transport problems that describe block-triangular Mongemaps that characterize conditional measures along with their Kantorovichrelaxations. This generalizes the theory of optimal triangular transport toseparable infinite-dimensional function spaces with general cost functions. Wefurther tailor our results to the case of Bayesian inference problems andobtain regularity estimates on the conditioning maps from the prior to theposterior. Finally, we present numerical experiments that demonstrate thecomputational applicability of our theoretical results for amortized andlikelihood-free inference of functional parameters.</description><author>Bamdad Hosseini, Alexander W. Hsu, Amirhossein Taghvaei</author><pubDate>Fri, 17 Nov 2023 16:32:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05672v2</guid></item><item><title>Approximately Equivariant Graph Networks</title><link>http://arxiv.org/abs/2308.10436v3</link><description>Graph neural networks (GNNs) are commonly described as being permutationequivariant with respect to node relabeling in the graph. This symmetry of GNNsis often compared to the translation equivariance of Euclidean convolutionneural networks (CNNs). However, these two symmetries are fundamentallydifferent: The translation equivariance of CNNs corresponds to symmetries ofthe fixed domain acting on the image signals (sometimes known as activesymmetries), whereas in GNNs any permutation acts on both the graph signals andthe graph domain (sometimes described as passive symmetries). In this work, wefocus on the active symmetries of GNNs, by considering a learning setting wheresignals are supported on a fixed graph. In this case, the natural symmetries ofGNNs are the automorphisms of the graph. Since real-world graphs tend to beasymmetric, we relax the notion of symmetries by formalizing approximatesymmetries via graph coarsening. We present a bias-variance formula thatquantifies the tradeoff between the loss in expressivity and the gain in theregularity of the learned estimator, depending on the chosen symmetry group. Toillustrate our approach, we conduct extensive experiments on image inpainting,traffic flow prediction, and human pose estimation with different choices ofsymmetries. We show theoretically and empirically that the best generalizationperformance can be achieved by choosing a suitably larger group than the graphautomorphism, but smaller than the permutation group.</description><author>Ningyuan Huang, Ron Levie, Soledad Villar</author><pubDate>Fri, 17 Nov 2023 16:29:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10436v3</guid></item><item><title>Astronomical Images Quality Assessment with Automated Machine Learning</title><link>http://arxiv.org/abs/2311.10617v1</link><description>Electronically Assisted Astronomy consists in capturing deep sky images witha digital camera coupled to a telescope to display views of celestial objectsthat would have been invisible through direct observation. This practicegenerates a large quantity of data, which may then be enhanced with dedicatedimage editing software after observation sessions. In this study, we show howImage Quality Assessment can be useful for automatically rating astronomicalimages, and we also develop a dedicated model by using Automated MachineLearning.</description><author>Olivier Parisot, Pierrick Bruneau, Patrik Hitzelberger</author><pubDate>Fri, 17 Nov 2023 16:14:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10617v1</guid></item><item><title>A Self-enhancement Approach for Domain-specific Chatbot Training via Knowledge Mining and Digest</title><link>http://arxiv.org/abs/2311.10614v1</link><description>Large Language Models (LLMs), despite their great power in languagegeneration, often encounter challenges when dealing with intricate andknowledge-demanding queries in specific domains. This paper introduces a novelapproach to enhance LLMs by effectively extracting the relevant knowledge fromdomain-specific textual sources, and the adaptive training of a chatbot withdomain-specific inquiries. Our two-step approach starts from training aknowledge miner, namely LLMiner, which autonomously extracts Question-Answerpairs from relevant documents through a chain-of-thought reasoning process.Subsequently, we blend the mined QA pairs with a conversational dataset tofine-tune the LLM as a chatbot, thereby enriching its domain-specific expertiseand conversational capabilities. We also developed a new evaluation benchmarkwhich comprises four domain-specific text corpora and associated human-craftedQA pairs for testing. Our model shows remarkable performance improvement overgenerally aligned LLM and surpasses domain-adapted models directly fine-tunedon domain corpus. In particular, LLMiner achieves this with minimal humanintervention, requiring only 600 seed instances, thereby providing a pathwaytowards self-improvement of LLMs through model-synthesized training data.</description><author>Ruohong Zhang, Luyu Gao, Chen Zheng, Zhen Fan, Guokun Lai, Zheng Zhang, Fangzhou Ai, Yiming Yang, Hongxia Yang</author><pubDate>Fri, 17 Nov 2023 16:09:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10614v1</guid></item><item><title>Variational Quantum Eigensolver with Constraints (VQEC): Solving Constrained Optimization Problems via VQE</title><link>http://arxiv.org/abs/2311.08502v2</link><description>Variational quantum approaches have shown great promise in findingnear-optimal solutions to computationally challenging tasks. Nonetheless,enforcing constraints in a disciplined fashion has been largely unexplored. Toaddress this gap, this work proposes a hybrid quantum-classical algorithmicparadigm termed VQEC that extends the celebrated VQE to handle optimizationwith constraints. As with the standard VQE, the vector of optimizationvariables is captured by the state of a variational quantum circuit (VQC). Todeal with constraints, VQEC optimizes a Lagrangian function classically overboth the VQC parameters as well as the dual variables associated withconstraints. To comply with the quantum setup, variables are updated via aperturbed primal-dual method leveraging the parameter shift rule. Among a widegamut of potential applications, we showcase how VQEC can approximately solvequadratically-constrained binary optimization (QCBO) problems, find stochasticbinary policies satisfying quadratic constraints on the average and inprobability, and solve large-scale linear programs (LP) over the probabilitysimplex. Under an assumption on the error for the VQC to approximate anarbitrary probability mass function (PMF), we provide bounds on the optimalitygap attained by a VQC. Numerical tests on a quantum simulator investigate theeffect of various parameters and corroborate that VQEC can generatehigh-quality solutions.</description><author>Thinh Viet Le, Vassilis Kekatos</author><pubDate>Fri, 17 Nov 2023 16:08:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08502v2</guid></item><item><title>A Poincaré Inequality and Consistency Results for Signal Sampling on Large Graphs</title><link>http://arxiv.org/abs/2311.10610v1</link><description>Large-scale graph machine learning is challenging as the complexity oflearning models scales with the graph size. Subsampling the graph is a viablealternative, but sampling on graphs is nontrivial as graphs are non-Euclidean.Existing graph sampling techniques require not only computing the spectra oflarge matrices but also repeating these computations when the graph changes,e.g., grows. In this paper, we introduce a signal sampling theory for a type ofgraph limit -- the graphon. We prove a Poincar\'e inequality for graphonsignals and show that complements of node subsets satisfying this inequalityare unique sampling sets for Paley-Wiener spaces of graphon signals. Exploitingconnections with spectral clustering and Gaussian elimination, we prove thatsuch sampling sets are consistent in the sense that unique sampling sets on aconvergent graph sequence converge to unique sampling sets on the graphon. Wethen propose a related graphon signal sampling algorithm for large graphs, anddemonstrate its good empirical performance on graph machine learning tasks.</description><author>Thien Le, Luana Ruiz, Stefanie Jegelka</author><pubDate>Fri, 17 Nov 2023 16:04:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10610v1</guid></item><item><title>Scaling TabPFN: Sketching and Feature Selection for Tabular Prior-Data Fitted Networks</title><link>http://arxiv.org/abs/2311.10609v1</link><description>Tabular classification has traditionally relied on supervised algorithms,which estimate the parameters of a prediction model using its training data.Recently, Prior-Data Fitted Networks (PFNs) such as TabPFN have successfullylearned to classify tabular data in-context: the model parameters are designedto classify new samples based on labelled training samples given after themodel training. While such models show great promise, their applicability toreal-world data remains limited due to the computational scale needed. Here westudy the following question: given a pre-trained PFN for tabular data, what isthe best way to summarize the labelled training samples before feeding them tothe model? We conduct an initial investigation of sketching andfeature-selection methods for TabPFN, and note certain key differences betweenit and conventionally fitted tabular models.</description><author>Benjamin Feuer, Chinmay Hegde, Niv Cohen</author><pubDate>Fri, 17 Nov 2023 16:04:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10609v1</guid></item><item><title>Active Inference on the Edge: A Design Study</title><link>http://arxiv.org/abs/2311.10607v1</link><description>Machine Learning (ML) is a common tool to interpret and predict the behaviorof distributed computing systems, e.g., to optimize the task distributionbetween devices. As more and more data is created by Internet of Things (IoT)devices, data processing and ML training are carried out by edge devices inclose proximity. To ensure Quality of Service (QoS) throughout theseoperations, systems are supervised and dynamically adapted with the help of ML.However, as long as ML models are not retrained, they fail to capture gradualshifts in the variable distribution, leading to an inaccurate view of thesystem state. Moreover, as the prediction accuracy decreases, the reportingdevice should actively resolve uncertainties to improve the model's precision.Such a level of self-determination could be provided by Active Inference (ACI)-- a concept from neuroscience that describes how the brain constantly predictsand evaluates sensory information to decrease long-term surprise. Weencompassed these concepts in a single action-perception cycle, which weimplemented for distributed agents in a smart manufacturing use case. As aresult, we showed how our ACI agent was able to quickly and traceably solve anoptimization problem while fulfilling QoS requirements.</description><author>Boris Sedlak, Victor Casamayor Pujol, Praveen Kumar Donta, Schahram Dustdar</author><pubDate>Fri, 17 Nov 2023 16:03:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10607v1</guid></item><item><title>CA-Jaccard: Camera-aware Jaccard Distance for Person Re-identification</title><link>http://arxiv.org/abs/2311.10605v1</link><description>Person re-identification (re-ID) is a challenging task that aims to learndiscriminative features for person retrieval. In person re-ID, Jaccard distanceis a widely used distance metric, especially in re-ranking and clusteringscenarios. However, we discover that camera variation has a significantnegative impact on the reliability of Jaccard distance. In particular, Jaccarddistance calculates the distance based on the overlap of relevant neighbors.Due to camera variation, intra-camera samples dominate the relevant neighbors,which reduces the reliability of the neighbors by introducing intra-cameranegative samples and excluding inter-camera positive samples. To overcome thisproblem, we propose a novel camera-aware Jaccard (CA-Jaccard) distance thatleverages camera information to enhance the reliability of Jaccard distance.Specifically, we introduce camera-aware k-reciprocal nearest neighbors (CKRNNs)to find k-reciprocal nearest neighbors on the intra-camera and inter-cameraranking lists, which improves the reliability of relevant neighbors andguarantees the contribution of inter-camera samples in the overlap. Moreover,we propose a camera-aware local query expansion (CLQE) to exploit cameravariation as a strong constraint to mine reliable samples in relevant neighborsand assign these samples higher weights in overlap to further improve thereliability. Our CA-Jaccard distance is simple yet effective and can serve as ageneral distance metric for person re-ID methods with high reliability and lowcomputational cost. Extensive experiments demonstrate the effectiveness of ourmethod.</description><author>Yiyu Chen, Zheyi Fan, Zhaoru Chen, Yixuan Zhu</author><pubDate>Fri, 17 Nov 2023 16:01:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10605v1</guid></item><item><title>Multimodal Indoor Localization Using Crowdsourced Radio Maps</title><link>http://arxiv.org/abs/2311.10601v1</link><description>Indoor Positioning Systems (IPS) traditionally rely on odometry and buildinginfrastructures like WiFi, often supplemented by building floor plans forincreased accuracy. However, the limitation of floor plans in terms ofavailability and timeliness of updates challenges their wide applicability. Incontrast, the proliferation of smartphones and WiFi-enabled robots has madecrowdsourced radio maps - databases pairing locations with their correspondingReceived Signal Strengths (RSS) - increasingly accessible. These radio maps notonly provide WiFi fingerprint-location pairs but encode movement regularitiesakin to the constraints imposed by floor plans. This work investigates thepossibility of leveraging these radio maps as a substitute for floor plans inmultimodal IPS. We introduce a new framework to address the challenges of radiomap inaccuracies and sparse coverage. Our proposed system integrates anuncertainty-aware neural network model for WiFi localization and a bespokenBayesian fusion technique for optimal fusion. Extensive evaluations on multiplereal-world sites indicate a significant performance enhancement, with resultsshowing ~ 25% improvement over the best baseline</description><author>Zhaoguang Yi, Xiangyu Wen, Qiyue Xia, Peize Li, Francisco Zampella, Firas Alsehly, Chris Xiaoxuan Lu</author><pubDate>Fri, 17 Nov 2023 15:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10601v1</guid></item><item><title>Chatbots as social companions: How people perceive consciousness, human likeness, and social health benefits in machines</title><link>http://arxiv.org/abs/2311.10599v1</link><description>As artificial intelligence (AI) becomes more widespread, one question thatarises is how human-AI interaction might impact human-human interaction.Chatbots, for example, are increasingly used as social companions, but littleis known about how their use impacts human relationships. A common hypothesisis that these companion bots are detrimental to social health by harming orreplacing human interaction. To understand how companion bots impact socialhealth, we studied people who used companion bots and people who did not.Contrary to expectations, companion bot users indicated that theserelationships were beneficial to their social health, whereas nonusers viewedthem as harmful. Another common assumption is that people perceive conscious,humanlike AI as disturbing and threatening. Among both users and nonusers,however, we found the opposite: perceiving companion bots as more conscious andhumanlike correlated with more positive opinions and better social healthbenefits. Humanlike bots may aid social health by supplying reliable and safeinteractions, without necessarily harming human relationships.</description><author>Rose Guingrich, Michael S. A. Graziano</author><pubDate>Fri, 17 Nov 2023 15:53:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10599v1</guid></item><item><title>Deep Learning-based Compressed Domain Multimedia for Man and Machine: A Taxonomy and Application to Point Cloud Classification</title><link>http://arxiv.org/abs/2310.18849v2</link><description>In the current golden age of multimedia, human visualization is no longer thesingle main target, with the final consumer often being a machine whichperforms some processing or computer vision tasks. In both cases, deep learningplays a undamental role in extracting features from the multimediarepresentation data, usually producing a compressed representation referred toas latent representation. The increasing development and adoption of deeplearning-based solutions in a wide area of multimedia applications have openedan exciting new vision where a common compressed multimedia representation isused for both man and machine. The main benefits of this vision are two-fold:i) improved performance for the computer vision tasks, since the effects ofcoding artifacts are mitigated; and ii) reduced computational complexity, sinceprior decoding is not required. This paper proposes the first taxonomy fordesigning compressed domain computer vision solutions driven by thearchitecture and weights compatibility with an available spatio-temporalcomputer vision processor. The potential of the proposed taxonomy isdemonstrated for the specific case of point cloud classification by designingnovel compressed domain processors using the JPEG Pleno Point Cloud Codingstandard under development and adaptations of the PointGrid classifier.Experimental results show that the designed compressed domain point cloudclassification solutions can significantly outperform the spatial-temporaldomain classification benchmarks when applied to the decompressed data,containing coding artifacts, and even surpass their performance when applied tothe original uncompressed data.</description><author>Abdelrahman Seleem, André F. R. Guarda, Nuno M. M. Rodrigues, Fernando Pereira</author><pubDate>Fri, 17 Nov 2023 15:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18849v2</guid></item><item><title>Designing Reconfigurable Intelligent Systems with Markov Blankets</title><link>http://arxiv.org/abs/2311.10597v1</link><description>Compute Continuum (CC) systems comprise a vast number of devices distributedover computational tiers. Evaluating business requirements, i.e., Service LevelObjectives (SLOs), requires collecting data from all those devices; if SLOs areviolated, devices must be reconfigured to ensure correct operation. If donecentrally, this dramatically increases the number of devices and variables thatmust be considered, while creating an enormous communication overhead. Toaddress this, we (1) introduce a causality filter based on Markov blankets (MB)that limits the number of variables that each device must track, (2) evaluateSLOs decentralized on a device basis, and (3) infer optimal deviceconfiguration for fulfilling SLOs. We evaluated our methodology by analyzingvideo stream transformations and providing device configurations that ensurethe Quality of Service (QoS). The devices thus perceived their environment andacted accordingly -- a form of decentralized intelligence.</description><author>Boris Sedlak, Victor Casamayor Pujol, Praveen Kumar Donta, Schahram Dustdar</author><pubDate>Fri, 17 Nov 2023 15:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10597v1</guid></item><item><title>Hashing it Out: Predicting Unhealthy Conversations on Twitter</title><link>http://arxiv.org/abs/2311.10596v1</link><description>Personal attacks in the context of social media conversations often lead tofast-paced derailment, leading to even more harmful exchanges being made.State-of-the-art systems for the detection of such conversational derailmentoften make use of deep learning approaches for prediction purposes. In thispaper, we show that an Attention-based BERT architecture, pre-trained on alarge Twitter corpus and fine-tuned on our task, is efficient and effective inmaking such predictions. This model shows clear advantages in performance tothe existing LSTM model we use as a baseline. Additionally, we show that thisimpressive performance can be attained through fine-tuning on a relativelysmall, novel dataset, particularly after mitigating overfitting issues throughsynthetic oversampling techniques. By introducing the first transformer basedmodel for forecasting conversational events on Twitter, this work lays thefoundation for a practical tool to encourage better interactions on one of themost ubiquitous social media platforms.</description><author>Steven Leung, Filippos Papapolyzos</author><pubDate>Fri, 17 Nov 2023 15:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10596v1</guid></item><item><title>Targeted Image Data Augmentation Increases Basic Skills Captioning Robustness</title><link>http://arxiv.org/abs/2309.15991v2</link><description>Artificial neural networks typically struggle in generalizing toout-of-context examples. One reason for this limitation is caused by havingdatasets that incorporate only partial information regarding the potentialcorrelational structure of the world. In this work, we propose TIDA (TargetedImage-editing Data Augmentation), a targeted data augmentation method focusedon improving models' human-like abilities (e.g., gender recognition) by fillingthe correlational structure gap using a text-to-image generative model. Morespecifically, TIDA identifies specific skills in captions describing images(e.g., the presence of a specific gender in the image), changes the caption(e.g., "woman" to "man"), and then uses a text-to-image model to edit the imagein order to match the novel caption (e.g., uniquely changing a woman to a manwhile maintaining the context identical). Based on the Flickr30K benchmark, weshow that, compared with the original data set, a TIDA-enhanced dataset relatedto gender, color, and counting abilities induces better performance in severalimage captioning metrics. Furthermore, on top of relying on the classical BLEUmetric, we conduct a fine-grained analysis of the improvements of our modelsagainst the baseline in different ways. We compared text-to-image generativemodels and found different behaviors of the image captioning models in terms ofencoding visual encoding and textual decoding.</description><author>Valentin Barriere, Felipe del Rio, Andres Carvallo De Ferari, Carlos Aspillaga, Eugenio Herrera-Berg, Cristian Buc Calderon</author><pubDate>Fri, 17 Nov 2023 15:47:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15991v2</guid></item><item><title>Détection d'objets célestes dans des images astronomiques par IA explicable</title><link>http://arxiv.org/abs/2311.10592v1</link><description>Amateur and professional astronomers can easily capture a large number ofdeep sky images with recent smart telescopes. However, afterwards verificationis still required to check whether the celestial objects targeted are actuallyvisible in the images produced. Depending on the magnitude of the targets, theobservation conditions and the time during which the data is captured, it ispossible that only stars are present in the images. In this study, we proposean approach based on explainable Artificial Intelligence to automaticallydetect the presence and position of captured objects. -- -- Gr\^ace \`a l'apport des t\'elescopes automatis\'es grand public, lesastronomes amateurs et professionnels peuvent capturer facilement une grandequantit\'e d'images du ciel profond (comme par exemple les galaxies,n\'ebuleuses, ou amas globulaires). N\'eanmoins, une v\'erification resten\'ecessaire \`a post\'eriori pour v\'erifier si les objets c\'elestes vis\'essont effectivement visibles dans les images produites: cela d\'epend notammentde la magnitude des cibles, des conditions d'observation mais aussi de ladur\'ee pendant laquelle les donn\'ees sont captur\'ees. Dans cette \'etude,nous proposons une approche bas\'ee sur l'IA explicable pour d\'etecterautomatiquement la pr\'esence et la position des objets captur\'es.</description><author>Olivier Parisot, Mahmoud Jaziri</author><pubDate>Fri, 17 Nov 2023 15:46:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10592v1</guid></item><item><title>FOCAL: A Cost-Aware Video Dataset for Active Learning</title><link>http://arxiv.org/abs/2311.10591v1</link><description>In this paper, we introduce the FOCAL (Ford-OLIVES Collaboration on ActiveLearning) dataset which enables the study of the impact of annotation-costwithin a video active learning setting. Annotation-cost refers to the time ittakes an annotator to label and quality-assure a given video sequence. Apractical motivation for active learning research is to minimizeannotation-cost by selectively labeling informative samples that will maximizeperformance within a given budget constraint. However, previous work in videoactive learning lacks real-time annotation labels for accurately assessing costminimization and instead operates under the assumption that annotation-costscales linearly with the amount of data to annotate. This assumption does nottake into account a variety of real-world confounding factors that contributeto a nonlinear cost such as the effect of an assistive labeling tool and thevariety of interactions within a scene such as occluded objects, weather, andmotion of objects. FOCAL addresses this discrepancy by providing realannotation-cost labels for 126 video sequences across 69 unique city sceneswith a variety of weather, lighting, and seasonal conditions. We also introducea set of conformal active learning algorithms that take advantage of thesequential structure of video data in order to achieve a better trade-offbetween annotation-cost and performance while also reducing floating pointoperations (FLOPS) overhead by at least 77.67%. We show how these approachesbetter reflect how annotations on videos are done in practice through asequence selection framework. We further demonstrate the advantage of theseapproaches by introducing two performance-cost metrics and show that the bestconformal active learning method is cheaper than the best traditional activelearning method by 113 hours.</description><author>Kiran Kokilepersaud, Yash-Yee Logan, Ryan Benkert, Chen Zhou, Mohit Prabhushankar, Ghassan AlRegib, Enrique Corona, Kunjan Singh, Mostafa Parchami</author><pubDate>Fri, 17 Nov 2023 15:46:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10591v1</guid></item><item><title>EduGym: An Environment Suite for Reinforcement Learning Education</title><link>http://arxiv.org/abs/2311.10590v1</link><description>Due to the empirical success of reinforcement learning, an increasing numberof students study the subject. However, from our practical teaching experience,we see students entering the field (bachelor, master and early PhD) oftenstruggle. On the one hand, textbooks and (online) lectures provide thefundamentals, but students find it hard to translate between equations andcode. On the other hand, public codebases do provide practical examples, butthe implemented algorithms tend to be complex, and the underlying testenvironments contain multiple reinforcement learning challenges at once.Although this is realistic from a research perspective, it often hinderseducational conceptual understanding. To solve this issue we introduce EduGym,a set of educational reinforcement learning environments and associatedinteractive notebooks tailored for education. Each EduGym environment isspecifically designed to illustrate a certain aspect/challenge of reinforcementlearning (e.g., exploration, partial observability, stochasticity, etc.), whilethe associated interactive notebook explains the challenge and its possiblesolution approaches, connecting equations and code in a single document. Anevaluation among RL students and researchers shows 86% of them think EduGym isa useful tool for reinforcement learning education. All notebooks are availablefrom https://sites.google.com/view/edu-gym/home, while the full softwarepackage can be installed from https://github.com/RLG-Leiden/edugym.</description><author>Thomas M. Moerland, Matthias Müller-Brockhausen, Zhao Yang, Andrius Bernatavicius, Koen Ponse, Tom Kouwenhoven, Andreas Sauter, Michiel van der Meer, Bram Renting, Aske Plaat</author><pubDate>Fri, 17 Nov 2023 15:45:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10590v1</guid></item><item><title>Exploring and Interacting with the Set of Good Sparse Generalized Additive Models</title><link>http://arxiv.org/abs/2303.16047v3</link><description>In real applications, interaction between machine learning models and domainexperts is critical; however, the classical machine learning paradigm thatusually produces only a single model does not facilitate such interaction.Approximating and exploring the Rashomon set, i.e., the set of all near-optimalmodels, addresses this practical challenge by providing the user with asearchable space containing a diverse set of models from which domain expertscan choose. We present algorithms to efficiently and accurately approximate theRashomon set of sparse, generalized additive models with ellipsoids for fixedsupport sets and use these ellipsoids to approximate Rashomon sets for manydifferent support sets. The approximated Rashomon set serves as a cornerstoneto solve practical challenges such as (1) studying the variable importance forthe model class; (2) finding models under user-specified constraints(monotonicity, direct editing); and (3) investigating sudden changes in theshape functions. Experiments demonstrate the fidelity of the approximatedRashomon set and its effectiveness in solving practical challenges.</description><author>Chudi Zhong, Zhi Chen, Jiachang Liu, Margo Seltzer, Cynthia Rudin</author><pubDate>Fri, 17 Nov 2023 15:41:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.16047v3</guid></item><item><title>Countering Misinformation via Emotional Response Generation</title><link>http://arxiv.org/abs/2311.10587v1</link><description>The proliferation of misinformation on social media platforms (SMPs) poses asignificant danger to public health, social cohesion and ultimately democracy.Previous research has shown how social correction can be an effective way tocurb misinformation, by engaging directly in a constructive dialogue with userswho spread -- often in good faith -- misleading messages. Although professionalfact-checkers are crucial to debunking viral claims, they usually do not engagein conversations on social media. Thereby, significant effort has been made toautomate the use of fact-checker material in social correction; however, noprevious work has tried to integrate it with the style and pragmatics that arecommonly employed in social media communication. To fill this gap, we presentVerMouth, the first large-scale dataset comprising roughly 12 thousandclaim-response pairs (linked to debunking articles), accounting for bothSMP-style and basic emotions, two factors which have a significant role inmisinformation credibility and spreading. To collect this dataset we used atechnique based on an author-reviewer pipeline, which efficiently combines LLMsand human annotators to obtain high-quality data. We also provide comprehensiveexperiments showing how models trained on our proposed dataset have significantimprovements in terms of output quality and generalization capabilities.</description><author>Daniel Russo, Shane Peter Kaszefski-Yaschuk, Jacopo Staiano, Marco Guerini</author><pubDate>Fri, 17 Nov 2023 15:37:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10587v1</guid></item><item><title>Human motion trajectory prediction using the Social Force Model for real-time and low computational cost applications</title><link>http://arxiv.org/abs/2311.10582v1</link><description>Human motion trajectory prediction is a very important functionality forhuman-robot collaboration, specifically in accompanying, guiding, orapproaching tasks, but also in social robotics, self-driving vehicles, orsecurity systems. In this paper, a novel trajectory prediction model, SocialForce Generative Adversarial Network (SoFGAN), is proposed. SoFGAN uses aGenerative Adversarial Network (GAN) and Social Force Model (SFM) to generatedifferent plausible people trajectories reducing collisions in a scene.Furthermore, a Conditional Variational Autoencoder (CVAE) module is added toemphasize the destination learning. We show that our method is more accurate inmaking predictions in UCY or BIWI datasets than most of the currentstate-of-the-art models and also reduces collisions in comparison to otherapproaches. Through real-life experiments, we demonstrate that the model can beused in real-time without GPU's to perform good quality predictions with a lowcomputational cost.</description><author>Oscar Gil, Alberto Sanfeliu</author><pubDate>Fri, 17 Nov 2023 15:32:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10582v1</guid></item><item><title>Implicit Maximum a Posteriori Filtering via Adaptive Optimization</title><link>http://arxiv.org/abs/2311.10580v1</link><description>Bayesian filtering approximates the true underlying behavior of atime-varying system by inverting an explicit generative model to convert noisymeasurements into state estimates. This process typically requires eitherstorage, inversion, and multiplication of large matrices or Monte Carloestimation, neither of which are practical in high-dimensional state spacessuch as the weight spaces of artificial neural networks. Here, we frame thestandard Bayesian filtering problem as optimization over a time-varyingobjective. Instead of maintaining matrices for the filtering equations orsimulating particles, we specify an optimizer that defines the Bayesian filterimplicitly. In the linear-Gaussian setting, we show that every Kalman filterhas an equivalent formulation using K steps of gradient descent. In thenonlinear setting, our experiments demonstrate that our framework results infilters that are effective, robust, and scalable to high-dimensional systems,comparing well against the standard toolbox of Bayesian filtering solutions. Wesuggest that it is easier to fine-tune an optimizer than it is to specify thecorrect filtering equations, making our framework an attractive option forhigh-dimensional filtering problems.</description><author>Gianluca M. Bencomo, Jake C. Snell, Thomas L. Griffiths</author><pubDate>Fri, 17 Nov 2023 15:30:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10580v1</guid></item><item><title>Graph Neural Networks for Pressure Estimation in Water Distribution Systems</title><link>http://arxiv.org/abs/2311.10579v1</link><description>Pressure and flow estimation in Water Distribution Networks (WDN) allowswater management companies to optimize their control operations. For manyyears, mathematical simulation tools have been the most common approach toreconstructing an estimate of the WDN hydraulics. However, pure physics-basedsimulations involve several challenges, e.g. partially observable data, highuncertainty, and extensive manual configuration. Thus, data-driven approacheshave gained traction to overcome such limitations. In this work, we combinephysics-based modeling and Graph Neural Networks (GNN), a data-driven approach,to address the pressure estimation problem. First, we propose a new datageneration method using a mathematical simulation but not considering temporalpatterns and including some control parameters that remain untouched inprevious works; this contributes to a more diverse training data. Second, ourtraining strategy relies on random sensor placement making our GNN-basedestimation model robust to unexpected sensor location changes. Third, arealistic evaluation protocol considers real temporal patterns and additionallyinjects the uncertainties intrinsic to real-world scenarios. Finally, amulti-graph pre-training strategy allows the model to be reused for pressureestimation in unseen target WDNs. Our GNN-based model estimates the pressure ofa large-scale WDN in The Netherlands with a MAE of 1.94mH$_2$O and a MAPE of7%, surpassing the performance of previous studies. Likewise, it outperformedprevious approaches on other WDN benchmarks, showing a reduction of absoluteerror up to approximately 52% in the best cases.</description><author>Huy Truong, Andrés Tello, Alexander Lazovik, Victoria Degeler</author><pubDate>Fri, 17 Nov 2023 15:30:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10579v1</guid></item><item><title>A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking Systems</title><link>http://arxiv.org/abs/2305.14937v2</link><description>Existing evaluations of entity linking systems often say little about how thesystem is going to perform for a particular application. There are twofundamental reasons for this. One is that many evaluations only use aggregatemeasures (like precision, recall, and F1 score), without a detailed erroranalysis or a closer look at the results. The other is that all of the widelyused benchmarks have strong biases and artifacts, in particular: a strong focuson named entities, an unclear or missing specification of what else counts asan entity mention, poor handling of ambiguities, and an over- orunderrepresentation of certain kinds of entities. We provide a more meaningful and fair in-depth evaluation of a variety ofexisting end-to-end entity linkers. We characterize their strengths andweaknesses and also report on reproducibility aspects. The detailed results ofour evaluation can be inspected underhttps://elevant.cs.uni-freiburg.de/emnlp2023 . Our evaluation is based onseveral widely used benchmarks, which exhibit the problems mentioned above tovarious degrees, as well as on two new benchmarks, which address the problemsmentioned above. The new benchmarks can be found underhttps://github.com/ad-freiburg/fair-entity-linking-benchmarks .</description><author>Hannah Bast, Matthias Hertel, Natalie Prange</author><pubDate>Fri, 17 Nov 2023 15:28:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14937v2</guid></item><item><title>Uncovering Intermediate Variables in Transformers using Circuit Probing</title><link>http://arxiv.org/abs/2311.04354v2</link><description>Neural network models have achieved high performance on a wide variety ofcomplex tasks, but the algorithms that they implement are notoriously difficultto interpret. In order to understand these algorithms, it is often necessary tohypothesize intermediate variables involved in the network's computation. Forexample, does a language model depend on particular syntactic properties whengenerating a sentence? However, existing analysis tools make it difficult totest hypotheses of this type. We propose a new analysis technique -- circuitprobing -- that automatically uncovers low-level circuits that computehypothesized intermediate variables. This enables causal analysis throughtargeted ablation at the level of model parameters. We apply this method tomodels trained on simple arithmetic tasks, demonstrating its effectiveness at(1) deciphering the algorithms that models have learned, (2) revealing modularstructure within a model, and (3) tracking the development of circuits overtraining. We compare circuit probing to other methods across these threeexperiments, and find it on par or more effective than existing analysismethods. Finally, we demonstrate circuit probing on a real-world use case,uncovering circuits that are responsible for subject-verb agreement andreflexive anaphora in GPT2-Small and Medium.</description><author>Michael A. Lepori, Thomas Serre, Ellie Pavlick</author><pubDate>Fri, 17 Nov 2023 15:15:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04354v2</guid></item><item><title>GCondNet: A Novel Method for Improving Neural Networks on Small High-Dimensional Tabular Data</title><link>http://arxiv.org/abs/2211.06302v3</link><description>Neural network models often struggle with high-dimensional but smallsample-size tabular datasets. One reason is that current weight initialisationmethods assume independence between weights, which can be problematic whenthere are insufficient samples to estimate the model's parameters accurately.In such small data scenarios, leveraging additional structures can improve themodel's performance and training stability. To address this, we proposeGCondNet, a general approach to enhance neural networks by leveraging implicitstructures present in tabular data. We create a graph between samples for eachdata dimension, and utilise Graph Neural Networks (GNNs) for extracting thisimplicit structure, and for conditioning the parameters of the first layer ofan underlying predictor network. By creating many small graphs, GCondNetexploits the data's high-dimensionality, and thus improves the performance ofan underlying predictor network. We demonstrate the effectiveness of our methodon 9 real-world datasets, where GCondNet outperforms 15 standard andstate-of-the-art methods. The results show that GCondNet is a versatileframework for injecting graph-regularisation into various types of neuralnetworks, including MLPs and tabular Transformers.</description><author>Andrei Margeloiu, Nikola Simidjievski, Pietro Lio, Mateja Jamnik</author><pubDate>Fri, 17 Nov 2023 15:14:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.06302v3</guid></item><item><title>SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning</title><link>http://arxiv.org/abs/2311.10572v1</link><description>Semi-supervised learning (SSL) methods effectively leverage unlabeled data toimprove model generalization. However, SSL models often underperform inopen-set scenarios, where unlabeled data contain outliers from novel categoriesthat do not appear in the labeled set. In this paper, we study the challengingand realistic open-set SSL setting, where the goal is to both correctlyclassify inliers and to detect outliers. Intuitively, the inlier classifiershould be trained on inlier data only. However, we find that inlierclassification performance can be largely improved by incorporatinghigh-confidence pseudo-labeled data, regardless of whether they are inliers oroutliers. Also, we propose to utilize non-linear transformations to separatethe features used for inlier classification and outlier detection in themulti-task learning framework, preventing adverse effects between them.Additionally, we introduce pseudo-negative mining, which further boosts outlierdetection performance. The three ingredients lead to what we call Simple butStrong Baseline (SSB) for open-set SSL. In experiments, SSB greatly improvesboth inlier classification and outlier detection performance, outperformingexisting methods by a large margin. Our code will be released athttps://github.com/YUE-FAN/SSB.</description><author>Yue Fan, Anna Kukleva, Dengxin Dai, Bernt Schiele</author><pubDate>Fri, 17 Nov 2023 15:14:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10572v1</guid></item><item><title>Direct Amortized Likelihood Ratio Estimation</title><link>http://arxiv.org/abs/2311.10571v1</link><description>We introduce a new amortized likelihood ratio estimator for likelihood-freesimulation-based inference (SBI). Our estimator is simple to train andestimates the likelihood ratio using a single forward pass of the neuralestimator. Our approach directly computes the likelihood ratio between twocompeting parameter sets which is different from the previous approach ofcomparing two neural network output values. We refer to our model as the directneural ratio estimator (DNRE). As part of introducing the DNRE, we derive acorresponding Monte Carlo estimate of the posterior. We benchmark our new ratioestimator and compare to previous ratio estimators in the literature. We showthat our new ratio estimator often outperforms these previous approaches. As afurther contribution, we introduce a new derivative estimator for likelihoodratio estimators that enables us to compare likelihood-free Hamiltonian MonteCarlo (HMC) with random-walk Metropolis-Hastings (MH). We show that HMC isequally competitive, which has not been previously shown. Finally, we include anovel real-world application of SBI by using our neural ratio estimator todesign a quadcopter. Code is available at https://github.com/SRI-CSL/dnre.</description><author>Adam D. Cobb, Brian Matejek, Daniel Elenius, Anirban Roy, Susmit Jha</author><pubDate>Fri, 17 Nov 2023 15:10:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10571v1</guid></item><item><title>Phase Guided Light Field for Spatial-Depth High Resolution 3D Imaging</title><link>http://arxiv.org/abs/2311.10568v1</link><description>On 3D imaging, light field cameras typically are of single shot, and however,they heavily suffer from low spatial resolution and depth accuracy. In thispaper, by employing an optical projector to project a group of singlehigh-frequency phase-shifted sinusoid patterns, we propose a phase guided lightfield algorithm to significantly improve both the spatial and depth resolutionsfor off-the-shelf light field cameras. First, for correcting the axialaberrations caused by the main lens of our light field camera, we propose adeformed cone model to calibrate our structured light field system. Second,over wrapped phases computed from patterned images, we propose a stereomatching algorithm, i.e. phase guided sum of absolute difference, to robustlyobtain the correspondence for each pair of neighbored two lenslets. Finally, byintroducing a virtual camera according to the basic geometrical optics of lightfield imaging, we propose a reorganization strategy to reconstruct 3D pointclouds with spatial-depth high resolution. Experimental results show that,compared with the state-of-the-art active light field methods, the proposedreconstructs 3D point clouds with a spatial resolution of 1280$\times$720 withfactors 10$\times$ increased, while maintaining the same high depth resolutionand needing merely a single group of high-frequency patterns.</description><author>Geyou Zhang, Ce Zhu, Kai Liu, Yipeng Liu</author><pubDate>Fri, 17 Nov 2023 15:08:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10568v1</guid></item><item><title>Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning</title><link>http://arxiv.org/abs/2309.07383v4</link><description>This paper studies convergence rates for some value function approximationsthat arise in a collection of reproducing kernel Hilbert spaces (RKHS)$H(\Omega)$. By casting an optimal control problem in a specific class ofnative spaces, strong rates of convergence are derived for the operatorequation that enables offline approximations that appear in policy iteration.Explicit upper bounds on error in value function and controller approximationsare derived in terms of power function $\mathcal{P}_{H,N}$ for the space offinite dimensional approximants $H_N$ in the native space $H(\Omega)$. Thesebounds are geometric in nature and refine some well-known, now classicalresults concerning convergence of approximations of value functions.</description><author>Ali Bouland, Shengyuan Niu, Sai Tej Paruchuri, Andrew Kurdila, John Burns, Eugenio Schuster</author><pubDate>Fri, 17 Nov 2023 15:04:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.07383v4</guid></item><item><title>A finite sample analysis of the benign overfitting phenomenon for ridge function estimation</title><link>http://arxiv.org/abs/2007.12882v4</link><description>Recent extensive numerical experiments in high scale machine learning haveallowed to uncover a quite counterintuitive phase transition, as a function ofthe ratio between the sample size and the number of parameters in the model. Asthe number of parameters $p$ approaches the sample size $n$, the generalisationerror increases, but surprisingly, it starts decreasing again past thethreshold $p=n$. This phenomenon, brought to the theoretical communityattention in \cite{belkin2019reconciling}, has been thoroughly investigatedlately, more specifically for simpler models than deep neural networks, such asthe linear model when the parameter is taken to be the minimum norm solution tothe least-squares problem, firstly in the asymptotic regime when $p$ and $n$tend to infinity, see e.g. \cite{hastie2019surprises}, and recently in thefinite dimensional regime and more specifically for linear models\cite{bartlett2020benign}, \cite{tsigler2020benign},\cite{lecue2022geometrical}. In the present paper, we propose a finite sampleanalysis of non-linear models of \textit{ridge} type, where we investigate the\textit{overparametrised regime} of the double descent phenomenon for both the\textit{estimation problem} and the \textit{prediction} problem. Our resultsprovide a precise analysis of the distance of the best estimator from the trueparameter as well as a generalisation bound which complements recent works of\cite{bartlett2020benign} and \cite{chinot2020benign}. Our analysis is based ontools closely related to the continuous Newton method\cite{neuberger2007continuous} and a refined quantitative analysis of theperformance in prediction of the minimum $\ell_2$-norm solution.</description><author>Emmanuel Caron, Stephane Chretien</author><pubDate>Fri, 17 Nov 2023 14:44:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2007.12882v4</guid></item><item><title>RONAALP: Reduced-Order Nonlinear Approximation with Active Learning Procedure</title><link>http://arxiv.org/abs/2311.10550v1</link><description>Many engineering applications rely on the evaluation of expensive, non-linearhigh-dimensional functions. In this paper, we propose the RONAALP algorithm(Reduced Order Nonlinear Approximation with Active Learning Procedure) toincrementally learn a fast and accurate reduced-order surrogate model of atarget function on-the-fly as the application progresses. First, thecombination of nonlinear auto-encoder, community clustering and radial basisfunction networks allows to learn an efficient and compact surrogate model withlimited training data. Secondly, the active learning procedure overcome anyextrapolation issue when evaluating the surrogate model outside of its initialtraining range during the online stage. This results in generalizable, fast andaccurate reduced-order models of high-dimensional functions. The method isdemonstrated on three direct numerical simulations of hypersonic flows inchemical nonequilibrium. Accurate simulations of these flows rely on detailedthermochemical gas models that dramatically increase the cost of suchcalculations. Using RONAALP to learn a reduced-order thermodynamic modelsurrogate on-the-fly, the cost of such simulation was reduced by up to 75%while maintaining an error of less than 10% on relevant quantities of interest.</description><author>Clément Scherding, Georgios Rigas, Denis Sipp, Peter J Schmid, Taraneh Sayadi</author><pubDate>Fri, 17 Nov 2023 14:32:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10550v1</guid></item><item><title>Archtree: on-the-fly tree-structured exploration for latency-aware pruning of deep neural networks</title><link>http://arxiv.org/abs/2311.10549v1</link><description>Deep neural networks (DNNs) have become ubiquitous in addressing a number ofproblems, particularly in computer vision. However, DNN inference iscomputationally intensive, which can be prohibitive e.g. when considering edgedevices. To solve this problem, a popular solution is DNN pruning, and more sostructured pruning, where coherent computational blocks (e.g. channels forconvolutional networks) are removed: as an exhaustive search of the space ofpruned sub-models is intractable in practice, channels are typically removediteratively based on an importance estimation heuristic. Recently, promisinglatency-aware pruning methods were proposed, where channels are removed untilthe network reaches a target budget of wall-clock latency pre-emptivelyestimated on specific hardware. In this paper, we present Archtree, a novelmethod for latency-driven structured pruning of DNNs. Archtree exploresmultiple candidate pruned sub-models in parallel in a tree-like fashion,allowing for a better exploration of the search space. Furthermore, it involveson-the-fly latency estimation on the target hardware, accounting for closerlatencies as compared to the specified budget. Empirical results on several DNNarchitectures and target hardware show that Archtree better preserves theoriginal model accuracy while better fitting the latency budget as compared toexisting state-of-the-art methods.</description><author>Rémi Ouazan Reboul, Edouard Yvinec, Arnaud Dapogny, Kevin Bailly</author><pubDate>Fri, 17 Nov 2023 14:24:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10549v1</guid></item><item><title>Joint covariance property under geometric image transformations for spatio-temporal receptive fields according to generalized Gaussian model for receptive fields</title><link>http://arxiv.org/abs/2311.10543v1</link><description>The influence of natural image transformations on receptive field responsesis crucial for modelling visual operations in computer vision and biologicalvision. In this regard, covariance properties with respect to geometric imagetransformations in the earliest layers of the visual hierarchy are essentialfor expressing robust image operations and for formulating invariant visualoperations at higher levels. This paper defines and proves a joint covarianceproperty under compositions of spatial scaling transformations, spatial affinetransformations, Galilean transformations and temporal scaling transformations,which makes it possible to characterize how different types of imagetransformations interact with each other. Specifically, the derived relationsshow the receptive field parameters need to be transformed, in order to matchthe output from spatio-temporal receptive fields with the underlyingspatio-temporal image transformations.</description><author>Tony Lindeberg</author><pubDate>Fri, 17 Nov 2023 14:10:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10543v1</guid></item><item><title>Detection of Offensive and Threatening Online Content in a Low Resource Language</title><link>http://arxiv.org/abs/2311.10541v1</link><description>Hausa is a major Chadic language, spoken by over 100 million people inAfrica. However, from a computational linguistic perspective, it is considereda low-resource language, with limited resources to support Natural LanguageProcessing (NLP) tasks. Online platforms often facilitate social interactionsthat can lead to the use of offensive and threatening language, which can goundetected due to the lack of detection systems designed for Hausa. This studyaimed to address this issue by (1) conducting two user studies (n=308) toinvestigate cyberbullying-related issues, (2) collecting and annotating thefirst set of offensive and threatening datasets to support relevant downstreamtasks in Hausa, (3) developing a detection system to flag offensive andthreatening content, and (4) evaluating the detection system and the efficacyof the Google-based translation engine in detecting offensive and threateningterms in Hausa. We found that offensive and threatening content is quitecommon, particularly when discussing religion and politics. Our detectionsystem was able to detect more than 70% of offensive and threatening content,although many of these were mistranslated by Google's translation engine. Weattribute this to the subtle relationship between offensive and threateningcontent and idiomatic expressions in the Hausa language. We recommend thatdiverse stakeholders participate in understanding local conventions anddemographics in order to develop a more effective detection system. Theseinsights are essential for implementing targeted moderation strategies tocreate a safe and inclusive online environment.</description><author>Fatima Muhammad Adam, Abubakar Yakubu Zandam, Isa Inuwa-Dutse</author><pubDate>Fri, 17 Nov 2023 14:08:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10541v1</guid></item><item><title>Testing Language Model Agents Safely in the Wild</title><link>http://arxiv.org/abs/2311.10538v1</link><description>A prerequisite for safe autonomy-in-the-wild is safe testing-in-the-wild. Yetreal-world autonomous tests face several unique safety challenges, both due tothe possibility of causing harm during a test, as well as the risk ofencountering new unsafe agent behavior through interactions with real-world andpotentially malicious actors. We propose a framework for conducting safeautonomous agent tests on the open internet: agent actions are audited by acontext-sensitive monitor that enforces a stringent safety boundary to stop anunsafe test, with suspect behavior ranked and logged to be examined by humans.We a design a basic safety monitor that is flexible enough to monitor existingLLM agents, and, using an adversarial simulated agent, we measure its abilityto identify and stop unsafe situations. Then we apply the safety monitor on abattery of real-world tests of AutoGPT, and we identify several limitations andchallenges that will face the creation of safe in-the-wild tests as autonomousagents grow more capable.</description><author>Silen Naihin, David Atkinson, Marc Green, Merwane Hamadi, Craig Swift, Douglas Schonholtz, Adam Tauman Kalai, David Bau</author><pubDate>Fri, 17 Nov 2023 14:06:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10538v1</guid></item><item><title>RBPGAN: Recurrent Back-Projection GAN for Video Super Resolution</title><link>http://arxiv.org/abs/2311.09178v2</link><description>Recently, video super resolution (VSR) has become a very impactful task inthe area of Computer Vision due to its various applications. In this paper, wepropose Recurrent Back-Projection Generative Adversarial Network (RBPGAN) forVSR in an attempt to generate temporally coherent solutions while preservingspatial details. RBPGAN integrates two state-of-the-art models to get the bestin both worlds without compromising the accuracy of produced video. Thegenerator of the model is inspired by RBPN system, while the discriminator isinspired by TecoGAN. We also utilize Ping-Pong loss to increase temporalconsistency over time. Our contribution together results in a model thatoutperforms earlier work in terms of temporally consistent details, as we willdemonstrate qualitatively and quantitatively using different datasets.</description><author>Israa Fahmy, Marwah Sulaiman, Zahraa Shehabeldin, Mohammed Barakat, Dareen Hussein, Mohammed El-Naggar, Hesham Eraqi, Moustafa Youssef</author><pubDate>Fri, 17 Nov 2023 14:02:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09178v2</guid></item><item><title>Segment Anything Model with Uncertainty Rectification for Auto-Prompting Medical Image Segmentation</title><link>http://arxiv.org/abs/2311.10529v1</link><description>The introduction of the Segment Anything Model (SAM) has marked a significantadvancement in prompt-driven image segmentation. However, SAM's application tomedical image segmentation requires manual prompting of target structures toobtain acceptable performance, which is still labor-intensive. Despite attemptsof auto-prompting to turn SAM into a fully automatic manner, it still exhibitssubpar performance and lacks of reliability in the field of medical imaging. Inthis paper, we propose UR-SAM, an uncertainty rectified SAM framework toenhance the robustness and reliability for auto-prompting medical imagesegmentation. Our method incorporates a prompt augmentation module to estimatethe distribution of predictions and generate uncertainty maps, and anuncertainty-based rectification module to further enhance the performance ofSAM. Extensive experiments on two public 3D medical datasets covering thesegmentation of 35 organs demonstrate that without supplementary training orfine-tuning, our method further improves the segmentation performance with upto 10.7 % and 13.8 % in dice similarity coefficient, demonstrating efficiencyand broad capabilities for medical image segmentation without manual prompting.</description><author>Yichi Zhang, Shiyao Hu, Chen Jiang, Yuan Cheng, Yuan Qi</author><pubDate>Fri, 17 Nov 2023 13:49:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10529v1</guid></item><item><title>Utilizing VQ-VAE for End-to-End Health Indicator Generation in Predicting Rolling Bearing RUL</title><link>http://arxiv.org/abs/2311.10525v1</link><description>The prediction of the remaining useful life (RUL) of rolling bearings is apivotal issue in industrial production. A crucial approach to tackling thisissue involves transforming vibration signals into health indicators (HI) toaid model training. This paper presents an end-to-end HI construction method,vector quantised variational autoencoder (VQ-VAE), which addresses the need fordimensionality reduction of latent variables in traditional unsupervisedlearning methods such as autoencoder. Moreover, concerning the inadequacy oftraditional statistical metrics in reflecting curve fluctuations accurately,two novel statistical metrics, mean absolute distance (MAD) and mean variance(MV), are introduced. These metrics accurately depict the fluctuation patternsin the curves, thereby indicating the model's accuracy in discerning similarfeatures. On the PMH2012 dataset, methods employing VQ-VAE for labelconstruction achieved lower values for MAD and MV. Furthermore, the ASTCNprediction model trained with VQ-VAE labels demonstrated commendableperformance, attaining the lowest values for MAD and MV.</description><author>Junliang Wang, Qinghua Zhang, Guanhua Zhu, Guoxi Sun</author><pubDate>Fri, 17 Nov 2023 13:45:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10525v1</guid></item><item><title>Removing Adverse Volumetric Effects From Trained Neural Radiance Fields</title><link>http://arxiv.org/abs/2311.10523v1</link><description>While the use of neural radiance fields (NeRFs) in different challengingsettings has been explored, only very recently have there been anycontributions that focus on the use of NeRF in foggy environments. We arguethat the traditional NeRF models are able to replicate scenes filled with fogand propose a method to remove the fog when synthesizing novel views. Bycalculating the global contrast of a scene, we can estimate a density thresholdthat, when applied, removes all visible fog. This makes it possible to use NeRFas a way of rendering clear views of objects of interest located in fog-filledenvironments. Additionally, to benchmark performance on such scenes, weintroduce a new dataset that expands some of the original synthetic NeRF scenesthrough the addition of fog and natural environments. The code, dataset, andvideo results can be found on our project page: https://vegardskui.com/fognerf/</description><author>Andreas L. Teigen, Mauhing Yip, Victor P. Hamran, Vegard Skui, Annette Stahl, Rudolf Mester</author><pubDate>Fri, 17 Nov 2023 13:44:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10523v1</guid></item><item><title>Enhancing Object Coherence in Layout-to-Image Synthesis</title><link>http://arxiv.org/abs/2311.10522v1</link><description>Layout-to-image synthesis is an emerging technique in conditional imagegeneration. It aims to generate complex scenes, where users require finecontrol over the layout of the objects in a scene. However, it remainschallenging to control the object coherence, including semantic coherence(e.g., the cat looks at the flowers or not) and physical coherence (e.g., thehand and the racket should not be misaligned). In this paper, we propose anovel diffusion model with effective global semantic fusion (GSF) andself-similarity feature enhancement modules to guide the object coherence forthis task. For semantic coherence, we argue that the image caption containsrich information for defining the semantic relationship within the objects inthe images. Instead of simply employing cross-attention between captions andgenerated images, which addresses the highly relevant layout restriction andsemantic coherence separately and thus leads to unsatisfying results shown inour experiments, we develop GSF to fuse the supervision from the layoutrestriction and semantic coherence requirement and exploit it to guide theimage synthesis process. Moreover, to improve the physical coherence, wedevelop a Self-similarity Coherence Attention (SCA) module to explicitlyintegrate local contextual physical coherence into each pixel's generationprocess. Specifically, we adopt a self-similarity map to encode the coherencerestrictions and employ it to extract coherent features from text embedding.Through visualization of our self-similarity map, we explore the essence ofSCA, revealing that its effectiveness is not only in capturing reliablephysical coherence patterns but also in enhancing complex texture generation.Extensive experiments demonstrate the superiority of our proposed method inboth image generation quality and controllability.</description><author>Yibin Wang, Weizhong Zhang, Jianwei Zheng, Cheng Jin</author><pubDate>Fri, 17 Nov 2023 13:43:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10522v1</guid></item><item><title>Mind the map! Accounting for existing map information when estimating online HDMaps from sensor data</title><link>http://arxiv.org/abs/2311.10517v1</link><description>Online High Definition Map (HDMap) estimation from sensors offers a low-costalternative to manually acquired HDMaps. As such, it promises to lighten costsfor already HDMap-reliant Autonomous Driving systems, and potentially evenspread their use to new systems. In this paper, we propose to improve onlineHDMap estimation by accounting for already existing maps. We identify 3reasonable types of useful existing maps (minimalist, noisy, and outdated). Wealso introduce MapEX, a novel online HDMap estimation framework that accountsfor existing maps. MapEX achieves this by encoding map elements into querytokens and by refining the matching algorithm used to train classic query basedmap estimation models. We demonstrate that MapEX brings significantimprovements on the nuScenes dataset. For instance, MapEX - given noisy maps -improves by 38% over the MapTRv2 detector it is based on and by 16% over thecurrent SOTA.</description><author>Rémy Sun, Li Yang, Diane Lingrand, Frédéric Precioso</author><pubDate>Fri, 17 Nov 2023 13:40:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10517v1</guid></item><item><title>When a Language Question Is at Stake. A Revisited Approach to Label Sensitive Content</title><link>http://arxiv.org/abs/2311.10514v1</link><description>Many under-resourced languages require high-quality datasets for specifictasks such as offensive language detection, disinformation, or misinformationidentification. However, the intricacies of the content may have a detrimentaleffect on the annotators. The article aims to revisit an approach ofpseudo-labeling sensitive data on the example of Ukrainian tweets covering theRussian-Ukrainian war. Nowadays, this acute topic is in the spotlight ofvarious language manipulations that cause numerous disinformation and profanityon social media platforms. The conducted experiment highlights three mainstages of data annotation and underlines the main obstacles during machineannotation. Ultimately, we provide a fundamental statistical analysis of theobtained data, evaluation of models used for pseudo-labelling, and set furtherguidelines on how the scientists can leverage the corpus to execute moreadvanced research and extend the existing data samples without annotators'engagement.</description><author>Stetsenko Daria</author><pubDate>Fri, 17 Nov 2023 13:35:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10514v1</guid></item><item><title>A Framework of Landsat-8 Band Selection based on UMDA for Deforestation Detection</title><link>http://arxiv.org/abs/2311.10513v1</link><description>The conservation of tropical forests is a current subject of social andecological relevance due to their crucial role in the global ecosystem.Unfortunately, millions of hectares are deforested and degraded each year.Therefore, government or private initiatives are needed for monitoring tropicalforests. In this sense, this work proposes a novel framework, which uses ofdistribution estimation algorithm (UMDA) to select spectral bands fromLandsat-8 that yield a better representation of deforestation areas to guide asemantic segmentation architecture called DeepLabv3+. In performed experiments,it was possible to find several compositions that reach balanced accuracysuperior to 90% in segment classification tasks. Furthermore, the bestcomposition (651) found by UMDA algorithm fed the DeepLabv3+ architecture andsurpassed in efficiency and effectiveness all compositions compared in thiswork.</description><author>Eduardo B. Neto, Paulo R. C. Pedro, Alvaro Fazenda, Fabio A. Faria</author><pubDate>Fri, 17 Nov 2023 13:34:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10513v1</guid></item><item><title>Causal Fairness-Guided Dataset Reweighting using Neural Networks</title><link>http://arxiv.org/abs/2311.10512v1</link><description>The importance of achieving fairness in machine learning models cannot beoverstated. Recent research has pointed out that fairness should be examinedfrom a causal perspective, and several fairness notions based on the on Pearl'scausal framework have been proposed. In this paper, we construct a reweightingscheme of datasets to address causal fairness. Our approach aims at mitigatingbias by considering the causal relationships among variables and incorporatingthem into the reweighting process. The proposed method adopts two neuralnetworks, whose structures are intentionally used to reflect the structures ofa causal graph and of an interventional graph. The two neural networks canapproximate the causal model of the data, and the causal model ofinterventions. Furthermore, reweighting guided by a discriminator is applied toachieve various fairness notions. Experiments on real-world datasets show thatour method can achieve causal fairness on the data while remaining close to theoriginal data for downstream tasks.</description><author>Xuan Zhao, Klaus Broelemann, Salvatore Ruggieri, Gjergji Kasneci</author><pubDate>Fri, 17 Nov 2023 13:31:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10512v1</guid></item><item><title>Validating ChatGPT Facts through RDF Knowledge Graphs and Sentence Similarity</title><link>http://arxiv.org/abs/2311.04524v2</link><description>Since ChatGPT offers detailed responses without justifications, and erroneousfacts even for popular persons, events and places, in this paper we present anovel pipeline that retrieves the response of ChatGPT in RDF and tries tovalidate the ChatGPT facts using one or more RDF Knowledge Graphs (KGs). Tothis end we leverage DBpedia and LODsyndesis (an aggregated Knowledge Graphthat contains 2 billion triples from 400 RDF KGs of many domains) and shortsentence embeddings, and introduce an algorithm that returns the more relevanttriple(s) accompanied by their provenance and a confidence score. This enablesthe validation of ChatGPT responses and their enrichment with justificationsand provenance. To evaluate this service (such services in general), we createan evaluation benchmark that includes 2,000 ChatGPT facts; specifically 1,000facts for famous Greek Persons, 500 facts for popular Greek Places, and 500facts for Events related to Greece. The facts were manually labelled(approximately 73% of ChatGPT facts were correct and 27% of facts wereerroneous). The results are promising; indicatively for the whole benchmark, wemanaged to verify the 85.3% of the correct facts of ChatGPT and to find thecorrect answer for the 58% of the erroneous ChatGPT facts.</description><author>Michalis Mountantonakis, Yannis Tzitzikas</author><pubDate>Fri, 17 Nov 2023 13:24:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04524v2</guid></item><item><title>Tree Variational Autoencoders</title><link>http://arxiv.org/abs/2306.08984v3</link><description>We propose Tree Variational Autoencoder (TreeVAE), a new generativehierarchical clustering model that learns a flexible tree-based posteriordistribution over latent variables. TreeVAE hierarchically divides samplesaccording to their intrinsic characteristics, shedding light on hiddenstructures in the data. It adapts its architecture to discover the optimal treefor encoding dependencies between latent variables. The proposed tree-basedgenerative architecture enables lightweight conditional inference and improvesgenerative performance by utilizing specialized leaf decoders. We show thatTreeVAE uncovers underlying clusters in the data and finds meaningfulhierarchical relations between the different groups on a variety of datasets,including real-world imaging data. We present empirically that TreeVAE providesa more competitive log-likelihood lower bound than the sequential counterparts.Finally, due to its generative nature, TreeVAE is able to generate new samplesfrom the discovered clusters via conditional sampling.</description><author>Laura Manduchi, Moritz Vandenhirtz, Alain Ryser, Julia Vogt</author><pubDate>Fri, 17 Nov 2023 13:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08984v3</guid></item><item><title>CNL2ASP: converting controlled natural language sentences into ASP</title><link>http://arxiv.org/abs/2311.10505v1</link><description>Answer Set Programming (ASP) is a popular declarative programming languagefor solving hard combinatorial problems. Although ASP has gained widespreadacceptance in academic and industrial contexts, there are certain user groupswho may find it more advantageous to employ a higher-level language thatclosely resembles natural language when specifying ASP programs. In this paper,we propose a novel tool, called CNL2ASP, for translating English sentencesexpressed in a controlled natural language (CNL) form into ASP. In particular,we first provide a definition of the type of sentences allowed by our CNL andtheir translation as ASP rules, and then exemplify the usage of the CNL for thespecification of both synthetic and real-world combinatorial problems. Finally,we report the results of an experimental analysis conducted on the real-worldproblems to compare the performance of automatically generated encodings withthe ones written by ASP practitioners, showing that our tool can obtainsatisfactory performance on these benchmarks. Under consideration in Theory andPractice of Logic Programming (TPLP).</description><author>Simone Caruso, Carmine Dodaro, Marco Maratea, Marco Mochi, Francesco Riccio</author><pubDate>Fri, 17 Nov 2023 13:10:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10505v1</guid></item><item><title>Fast Estimations of Hitting Time of Elitist Evolutionary Algorithms from Fitness Levels</title><link>http://arxiv.org/abs/2311.10502v1</link><description>The fitness level method is an easy-to-use tool for estimating the hittingtime of elitist EAs. Recently, general linear lower and upper bounds fromfitness levels have been constructed. However, the construction of these boundsrequires recursive computation, which makes them difficult to use in practice.We address this shortcoming with a new directed graph (digraph) method thatdoes not require recursive computation and significantly simplifies thecalculation of coefficients in linear bounds. In this method, an EA is modeledas a Markov chain on a digraph. Lower and upper bounds are directly calculatedusing conditional transition probabilities on the digraph. This digraph methodprovides straightforward and explicit expressions of lower and upper time boundfor elitist EAs. In particular, it can be used to derive tight lower bound onboth fitness landscapes without and with shortcuts. This is demonstratedthrough four examples: the (1+1) EA on OneMax, FullyDeceptive, TwoMax1 andDeceptive. Our work extends the fitness level method from addressing simplefitness functions without shortcuts to more realistic functions with shortcuts.</description><author>Jun He, Siang Yew Chong, Xin Yao</author><pubDate>Fri, 17 Nov 2023 13:04:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10502v1</guid></item><item><title>From Principle to Practice: Vertical Data Minimization for Machine Learning</title><link>http://arxiv.org/abs/2311.10500v1</link><description>Aiming to train and deploy predictive models, organizations collect largeamounts of detailed client data, risking the exposure of private information inthe event of a breach. To mitigate this, policymakers increasingly demandcompliance with the data minimization (DM) principle, restricting datacollection to only that data which is relevant and necessary for the task.Despite regulatory pressure, the problem of deploying machine learning modelsthat obey DM has so far received little attention. In this work, we addressthis challenge in a comprehensive manner. We propose a novel vertical DM (vDM)workflow based on data generalization, which by design ensures that nofull-resolution client data is collected during training and deployment ofmodels, benefiting client privacy by reducing the attack surface in case of abreach. We formalize and study the corresponding problem of findinggeneralizations that both maximize data utility and minimize empirical privacyrisk, which we quantify by introducing a diverse set of policy-alignedadversarial scenarios. Finally, we propose a range of baseline vDM algorithms,as well as Privacy-aware Tree (PAT), an especially effective vDM algorithm thatoutperforms all baselines across several settings. We plan to release our codeas a publicly available library, helping advance the standardization of DM formachine learning. Overall, we believe our work can help lay the foundation forfurther exploration and adoption of DM principles in real-world applications.</description><author>Robin Staab, Nikola Jovanović, Mislav Balunović, Martin Vechev</author><pubDate>Fri, 17 Nov 2023 13:01:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10500v1</guid></item><item><title>The Dark Side of the Language: Pre-trained Transformers in the DarkNet</title><link>http://arxiv.org/abs/2201.05613v3</link><description>Pre-trained Transformers are challenging human performances in many NLPtasks. The massive datasets used for pre-training seem to be the key to theirsuccess on existing tasks. In this paper, we explore how a range of pre-trainedNatural Language Understanding models perform on definitely unseen sentencesprovided by classification tasks over a DarkNet corpus. Surprisingly, resultsshow that syntactic and lexical neural networks perform on par with pre-trainedTransformers even after fine-tuning. Only after what we call extreme domainadaptation, that is, retraining with the masked language model task on all thenovel corpus, pre-trained Transformers reach their standard high results. Thissuggests that huge pre-training corpora may give Transformers unexpected helpsince they are exposed to many of the possible sentences.</description><author>Leonardo Ranaldi, Aria Nourbakhsh, Arianna Patrizi, Elena Sofia Ruzzetti, Dario Onorati, Francesca Fallucchi, Fabio Massimo Zanzotto</author><pubDate>Fri, 17 Nov 2023 13:01:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.05613v3</guid></item><item><title>Bespoke: A Block-Level Neural Network Optimization Framework for Low-Cost Deployment</title><link>http://arxiv.org/abs/2303.01913v2</link><description>As deep learning models become popular, there is a lot of need for deployingthem to diverse device environments. Because it is costly to develop andoptimize a neural network for every single environment, there is a line ofresearch to search neural networks for multiple target environmentsefficiently. However, existing works for such a situation still suffer fromrequiring many GPUs and expensive costs. Motivated by this, we propose a novelneural network optimization framework named Bespoke for low-cost deployment.Our framework searches for a lightweight model by replacing parts of anoriginal model with randomly selected alternatives, each of which comes from apretrained neural network or the original model. In the practical sense,Bespoke has two significant merits. One is that it requires near zero cost fordesigning the search space of neural networks. The other merit is that itexploits the sub-networks of public pretrained neural networks, so the totalcost is minimal compared to the existing works. We conduct experimentsexploring Bespoke's the merits, and the results show that it finds efficientmodels for multiple targets with meager cost.</description><author>Jong-Ryul Lee, Yong-Hyuk Moon</author><pubDate>Fri, 17 Nov 2023 12:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.01913v2</guid></item><item><title>A Relay System for Semantic Image Transmission based on Shared Feature Extraction and Hyperprior Entropy Compression</title><link>http://arxiv.org/abs/2311.10492v1</link><description>Nowadays, the need for high-quality image reconstruction and restoration ismore and more urgent. However, most image transmission systems may suffer fromimage quality degradation or transmission interruption in the face ofinterference such as channel noise and link fading. To solve this problem, arelay communication network for semantic image transmission based on sharedfeature extraction and hyperprior entropy compression (HEC) is proposed, wherethe shared feature extraction technology based on Pearson correlation isproposed to eliminate partial shared feature of extracted semantic latentfeature. In addition, the HEC technology is used to resist the effect ofchannel noise and link fading and carried out respectively at the source nodeand the relay node. Experimental results demonstrate that compared with otherrecent research methods, the proposed system has lower transmission overheadand higher semantic image transmission performance. Particularly, under thesame conditions, the multi-scale structural similarity (MS-SSIM) of this systemis superior to the comparison method by approximately 0.2.</description><author>Wannian An, Zhicheng Bao, Haotai Liang, Chen Dong, Xiaodong</author><pubDate>Fri, 17 Nov 2023 12:45:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10492v1</guid></item><item><title>Edit-A-Video: Single Video Editing with Object-Aware Consistency</title><link>http://arxiv.org/abs/2303.07945v4</link><description>Despite the fact that text-to-video (TTV) model has recently achievedremarkable success, there have been few approaches on TTV for its extension tovideo editing. Motivated by approaches on TTV models adapting fromdiffusion-based text-to-image (TTI) models, we suggest the video editingframework given only a pretrained TTI model and a single &lt;text, video&gt; pair,which we term Edit-A-Video. The framework consists of two stages: (1) inflatingthe 2D model into the 3D model by appending temporal modules and tuning on thesource video (2) inverting the source video into the noise and editing withtarget text prompt and attention map injection. Each stage enables the temporalmodeling and preservation of semantic attributes of the source video. One ofthe key challenges for video editing include a background inconsistencyproblem, where the regions not included for the edit suffer from undesirableand inconsistent temporal alterations. To mitigate this issue, we alsointroduce a novel mask blending method, termed as sparse-causal blending (SCBlending). We improve previous mask blending methods to reflect the temporalconsistency so that the area where the editing is applied exhibits smoothtransition while also achieving spatio-temporal consistency of the uneditedregions. We present extensive experimental results over various types of textand videos, and demonstrate the superiority of the proposed method compared tobaselines in terms of background consistency, text alignment, and video editingquality.</description><author>Chaehun Shin, Heeseung Kim, Che Hyun Lee, Sang-gil Lee, Sungroh Yoon</author><pubDate>Fri, 17 Nov 2023 12:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07945v4</guid></item><item><title>Investigating and Mitigating the Side Effects of Noisy Views for Self-Supervised Clustering Algorithms in Practical Multi-View Scenarios</title><link>http://arxiv.org/abs/2303.17245v3</link><description>Multi-view clustering (MVC) aims at exploring category structures amongmulti-view data in self-supervised manners. Multiple views provide moreinformation than single views and thus existing MVC methods can achievesatisfactory performance. However, their performance might seriously degeneratewhen the views are noisy in practical multi-view scenarios. In this paper, wefirst formally investigate the drawback of noisy views and then propose atheoretically grounded deep MVC method (namely MVCAN) to address this issue.Specifically, we propose a novel MVC objective that enables un-sharedparameters and inconsistent clustering predictions across multiple views toreduce the side effects of noisy views. Furthermore, a two-level multi-viewiterative optimization is designed to generate robust learning targets forrefining individual views' representation learning. Theoretical analysisreveals that MVCAN works by achieving the multi-view consistency,complementarity, and noise robustness. Finally, experiments on extensive publicdatasets demonstrate that MVCAN outperforms state-of-the-art methods and isrobust against the existence of noisy views.</description><author>Jie Xu, Yazhou Ren, Xiaolong Wang, Lei Feng, Zheng Zhang, Gang Niu, Xiaofeng Zhu</author><pubDate>Fri, 17 Nov 2023 12:43:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17245v3</guid></item><item><title>Handling Overlapping Asymmetric Datasets -- A Twice Penalized P-Spline Approach</title><link>http://arxiv.org/abs/2311.10489v1</link><description>Overlapping asymmetric datasets are common in data science and pose questionsof how they can be incorporated together into a predictive analysis. Inhealthcare datasets there is often a small amount of information that isavailable for a larger number of patients such as an electronic health record,however a small number of patients may have had extensive further testing.Common solutions such as missing imputation can often be unwise if the smallercohort is significantly different in scale to the larger sample, therefore theaim of this research is to develop a new method which can model the smallercohort against a particular response, whilst considering the larger cohortalso. Motivated by non-parametric models, and specifically flexible smoothingtechniques via generalized additive models, we model a twice penalized P-Splineapproximation method to firstly prevent over/under-fitting of the smallercohort and secondly to consider the larger cohort. This second penalty iscreated through discrepancies in the marginal value of covariates that exist inboth the smaller and larger cohorts. Through data simulations, parametertunings and model adaptations to consider a continuous and binary response, wefind our twice penalized approach offers an enhanced fit over a linear B-Splineand once penalized P-Spline approximation. Applying to a real-life datasetrelating to a person's risk of developing Non-Alcoholic Steatohepatitis, we seean improved model fit performance of over 65%. Areas for future work withinthis space include adapting our method to not require dimensionality reductionand also consider parametric modelling methods. However, to our knowledge thisis the first work to propose additional marginal penalties in a flexibleregression of which we can report a vastly improved model fit that is able toconsider asymmetric datasets, without the need for missing data imputation.</description><author>Matthew McTeer, Robin Henderson, Quentin M Anstee, Paolo Missier</author><pubDate>Fri, 17 Nov 2023 12:41:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10489v1</guid></item><item><title>Trustworthy Recommender Systems</title><link>http://arxiv.org/abs/2208.06265v3</link><description>Recommender systems (RSs) aim to help users to effectively retrieve items oftheir interests from a large catalogue. For a quite long period of time,researchers and practitioners have been focusing on developing accurate RSs.Recent years have witnessed an increasing number of threats to RSs, coming fromattacks, system and user generated noise, system bias. As a result, it hasbecome clear that a strict focus on RS accuracy is limited and the researchmust consider other important factors, e.g., trustworthiness. For end users, atrustworthy RS (TRS) should not only be accurate, but also transparent,unbiased and fair as well as robust to noise or attacks. These observationsactually led to a paradigm shift of the research on RSs: from accuracy-orientedRSs to TRSs. However, researchers lack a systematic overview and discussion ofthe literature in this novel and fast developing field of TRSs. To this end, inthis paper, we provide an overview of TRSs, including a discussion of themotivation and basic concepts of TRSs, a presentation of the challenges inbuilding TRSs, and a perspective on the future directions in this area. We alsoprovide a novel conceptual framework to support the construction of TRSs.</description><author>Shoujin Wang, Xiuzhen Zhang, Yan Wang, Huan Liu, Francesco Ricci</author><pubDate>Fri, 17 Nov 2023 12:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.06265v3</guid></item><item><title>FRCSyn Challenge at WACV 2024:Face Recognition Challenge in the Era of Synthetic Data</title><link>http://arxiv.org/abs/2311.10476v1</link><description>Despite the widespread adoption of face recognition technology around theworld, and its remarkable performance on current benchmarks, there are stillseveral challenges that must be covered in more detail. This paper offers anoverview of the Face Recognition Challenge in the Era of Synthetic Data(FRCSyn) organized at WACV 2024. This is the first international challengeaiming to explore the use of synthetic data in face recognition to addressexisting limitations in the technology. Specifically, the FRCSyn Challengetargets concerns related to data privacy issues, demographic biases,generalization to unseen scenarios, and performance limitations in challengingscenarios, including significant age disparities between enrollment andtesting, pose variations, and occlusions. The results achieved in the FRCSynChallenge, together with the proposed benchmark, contribute significantly tothe application of synthetic data to improve face recognition technology.</description><author>Pietro Melzi, Ruben Tolosana, Ruben Vera-Rodriguez, Minchul Kim, Christian Rathgeb, Xiaoming Liu, Ivan DeAndres-Tame, Aythami Morales, Julian Fierrez, Javier Ortega-Garcia, Weisong Zhao, Xiangyu Zhu, Zheyu Yan, Xiao-Yu Zhang, Jinlin Wu, Zhen Lei, Suvidha Tripathi, Mahak Kothari, Md Haider Zama, Debayan Deb, Bernardo Biesseck, Pedro Vidal, Roger Granada, Guilherme Fickel, Gustavo Führ, David Menotti, Alexander Unnervik, Anjith George, Christophe Ecabert, Hatef Otroshi Shahreza, Parsa Rahimi, Sébastien Marcel, Ioannis Sarridis, Christos Koutlis, Georgia Baltsou, Symeon Papadopoulos, Christos Diou, Nicolò Di Domenico, Guido Borghi, Lorenzo Pellegrini, Enrique Mas-Candela, Ángela Sánchez-Pérez, Andrea Atzori, Fadi Boutros, Naser Damer, Gianni Fenu, Mirko Marras</author><pubDate>Fri, 17 Nov 2023 12:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10476v1</guid></item><item><title>End-to-end autoencoding architecture for the simultaneous generation of medical images and corresponding segmentation masks</title><link>http://arxiv.org/abs/2311.10472v1</link><description>Despite the increasing use of deep learning in medical image segmentation,acquiring sufficient training data remains a challenge in the medical field. Inresponse, data augmentation techniques have been proposed; however, thegeneration of diverse and realistic medical images and their correspondingmasks remains a difficult task, especially when working with insufficienttraining sets. To address these limitations, we present an end-to-endarchitecture based on the Hamiltonian Variational Autoencoder (HVAE). Thisapproach yields an improved posterior distribution approximation compared totraditional Variational Autoencoders (VAE), resulting in higher imagegeneration quality. Our method outperforms generative adversarial architecturesunder data-scarce conditions, showcasing enhancements in image quality andprecise tumor mask synthesis. We conduct experiments on two publicly availabledatasets, MICCAI's Brain Tumor Segmentation Challenge (BRATS), and Head andNeck Tumor Segmentation Challenge (HECKTOR), demonstrating the effectiveness ofour method on different medical imaging modalities.</description><author>Aghiles Kebaili, Jérôme Lapuyade-Lahorgue, Pierre Vera, Su Ruan</author><pubDate>Fri, 17 Nov 2023 11:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10472v1</guid></item><item><title>Regions are Who Walk Them: a Large Pre-trained Spatiotemporal Model Based on Human Mobility for Ubiquitous Urban Sensing</title><link>http://arxiv.org/abs/2311.10471v1</link><description>User profiling and region analysis are two tasks of significant commercialvalue. However, in practical applications, modeling different featurestypically involves four main steps: data preparation, data processing, modelestablishment, evaluation, and optimization. This process is time-consuming andlabor-intensive. Repeating this workflow for each feature results in abundantdevelopment time for tasks and a reduced overall volume of task development.Indeed, human mobility data contains a wealth of information. Severalsuccessful cases suggest that conducting in-depth analysis of populationmovement data could potentially yield meaningful profiles about users andareas. Nonetheless, most related works have not thoroughly utilized thesemantic information within human mobility data and trained on a fixed numberof the regions. To tap into the rich information within population movement,based on the perspective that Regions Are Who walk them, we propose a largespatiotemporal model based on trajectories (RAW). It possesses the followingcharacteristics: 1) Tailored for trajectory data, introducing a GPT-likestructure with a parameter count of up to 1B; 2) Introducing a spatiotemporalfine-tuning module, interpreting trajectories as collection of users to derivearbitrary region embedding. This framework allows rapid task development basedon the large spatiotemporal model. We conducted extensive experiments tovalidate the effectiveness of our proposed large spatiotemporal model. It'sevident that our proposed method, relying solely on human mobility data withoutadditional features, exhibits a certain level of relevance in user profilingand region analysis. Moreover, our model showcases promising predictivecapabilities in trajectory generation tasks based on the current state,offering the potential for further innovative work utilizing this largespatiotemporal model.</description><author>Ruixing Zhang, Liangzhe Han, Leilei Sun, Yunqi Liu, Jibin Wang, Weifeng Lv</author><pubDate>Fri, 17 Nov 2023 11:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10471v1</guid></item><item><title>Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes</title><link>http://arxiv.org/abs/2311.08149v2</link><description>In this paper, we propose a deep generative time series approach using latenttemporal processes for modeling and holistically analyzing complex diseasetrajectories. We aim to find meaningful temporal latent representations of anunderlying generative process that explain the observed disease trajectories inan interpretable and comprehensive way. To enhance the interpretability ofthese latent temporal processes, we develop a semi-supervised approach fordisentangling the latent space using established medical concepts. By combiningthe generative approach with medical knowledge, we leverage the ability todiscover novel aspects of the disease while integrating medical concepts intothe model. We show that the learned temporal latent processes can be utilizedfor further data analysis and clinical hypothesis testing, including findingsimilar patients and clustering the disease into new sub-types. Moreover, ourmethod enables personalized online monitoring and prediction of multivariatetime series including uncertainty quantification. We demonstrate theeffectiveness of our approach in modeling systemic sclerosis, showcasing thepotential of our machine learning model to capture complex disease trajectoriesand acquire new medical knowledge.</description><author>Cécile Trottet, Manuel Schürch, Ahmed Allam, Imon Barua, Liubov Petelytska, Oliver Distler, Anna-Maria Hoffmann-Vold, Michael Krauthammer, the EUSTAR collaborators</author><pubDate>Fri, 17 Nov 2023 11:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08149v2</guid></item><item><title>Using Cooperative Game Theory to Prune Neural Networks</title><link>http://arxiv.org/abs/2311.10468v1</link><description>We show how solution concepts from cooperative game theory can be used totackle the problem of pruning neural networks. The ever-growing size of deep neural networks (DNNs) increases theirperformance, but also their computational requirements. We introduce a methodcalled Game Theory Assisted Pruning (GTAP), which reduces the neural network'ssize while preserving its predictive accuracy. GTAP is based on eliminatingneurons in the network based on an estimation of their joint impact on theprediction quality through game theoretic solutions. Specifically, we use apower index akin to the Shapley value or Banzhaf index, tailored using aprocedure similar to Dropout (commonly used to tackle overfitting problems inmachine learning). Empirical evaluation of both feedforward networks and convolutional neuralnetworks shows that this method outperforms existing approaches in the achievedtradeoff between the number of parameters and model accuracy.</description><author>Mauricio Diaz-Ortiz Jr, Benjamin Kempinski, Daphne Cornelisse, Yoram Bachrach, Tal Kachman</author><pubDate>Fri, 17 Nov 2023 11:48:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10468v1</guid></item><item><title>Correlation-Distance Graph Learning for Treatment Response Prediction from rs-fMRI</title><link>http://arxiv.org/abs/2311.10463v1</link><description>Resting-state fMRI (rs-fMRI) functional connectivity (FC) analysis providesvaluable insights into the relationships between different brain regions andtheir potential implications for neurological or psychiatric disorders.However, specific design efforts to predict treatment response from rs-fMRIremain limited due to difficulties in understanding the current brain state andthe underlying mechanisms driving the observed patterns, which limited theclinical application of rs-fMRI. To overcome that, we propose a graph learningframework that captures comprehensive features by integrating both correlationand distance-based similarity measures under a contrastive loss. This approachresults in a more expressive framework that captures brain dynamic features atdifferent scales and enables more accurate prediction of treatment response.Our experiments on the chronic pain and depersonalization disorder datasetsdemonstrate that our proposed method outperforms current methods in differentscenarios. To the best of our knowledge, we are the first to explore theintegration of distance-based and correlation-based neural similarity intograph learning for treatment response prediction.</description><author>Xiatian Zhang, Sisi Zheng, Hubert P. H. Shum, Haozheng Zhang, Nan Song, Mingkang Song, Hongxiao Jia</author><pubDate>Fri, 17 Nov 2023 11:34:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10463v1</guid></item><item><title>Dual-Query Multiple Instance Learning for Dynamic Meta-Embedding based Tumor Classification</title><link>http://arxiv.org/abs/2307.07482v2</link><description>Whole slide image (WSI) assessment is a challenging and crucial step incancer diagnosis and treatment planning. WSIs require high magnifications tofacilitate sub-cellular analysis. Precise annotations for patch- or evenpixel-level classifications in the context of gigapixel WSIs are tedious toacquire and require domain experts. Coarse-grained labels, on the other hand,are easily accessible, which makes WSI classification an ideal use case formultiple instance learning (MIL). In our work, we propose a novelembedding-based Dual-Query MIL pipeline (DQ-MIL). We contribute to both theembedding and aggregation steps. Since all-purpose visual featurerepresentations are not yet available, embedding models are currently limitedin terms of generalizability. With our work, we explore the potential ofdynamic meta-embedding based on cutting-edge self-supervised pre-trained modelsin the context of MIL. Moreover, we propose a new MIL architecture capable ofcombining MIL-attention with correlated self-attention. The Dual-QueryPerceiver design of our approach allows us to leverage the concept ofself-distillation and to combine the advantages of a small model in the contextof a low data regime with the rich feature representation of a larger model. Wedemonstrate the superior performance of our approach on three histopathologicaldatasets, where we show improvement of up to 10% over state-of-the-artapproaches.</description><author>Simon Holdenried-Krafft, Peter Somers, Ivonne A. Montes-Majarro, Diana Silimon, Cristina Tarín, Falko Fend, Hendrik P. A. Lensch</author><pubDate>Fri, 17 Nov 2023 11:30:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07482v2</guid></item><item><title>Hybrid quantum physics-informed neural networks for simulating computational fluid dynamics in complex shapes</title><link>http://arxiv.org/abs/2304.11247v2</link><description>Finding the distribution of the velocities and pressures of a fluid (bysolving the Navier-Stokes equations) is a principal task in the chemical,energy, and pharmaceutical industries, as well as in mechanical engineering andthe design of pipeline systems. With existing solvers, such as OpenFOAM andAnsys, simulations of fluid dynamics in intricate geometries arecomputationally expensive and require re-simulation whenever the geometricparameters or the initial and boundary conditions are altered. Physics-informedneural networks are a promising tool for simulating fluid flows in complexgeometries, as they can adapt to changes in the geometry and mesh definitions,allowing for generalization across different shapes. We present a hybridquantum physics-informed neural network that simulates laminar fluid flows in3D Y-shaped mixers. Our approach combines the expressive power of a quantummodel with the flexibility of a physics-informed neural network, resulting in a21% higher accuracy compared to a purely classical neural network. Our findingshighlight the potential of machine learning approaches, and in particularhybrid quantum physics-informed neural network, for complex shape optimizationtasks in computational fluid dynamics. By improving the accuracy of fluidsimulations in complex geometries, our research using hybrid quantum modelscontributes to the development of more efficient and reliable fluid dynamicssolvers.</description><author>Alexandr Sedykh, Maninadh Podapaka, Asel Sagingalieva, Karan Pinto, Markus Pflitsch, Alexey Melnikov</author><pubDate>Fri, 17 Nov 2023 11:28:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11247v2</guid></item><item><title>Accurate and Fast Fischer-Tropsch Reaction Microkinetics using PINNs</title><link>http://arxiv.org/abs/2311.10456v1</link><description>Microkinetics allows detailed modelling of chemical transformations occurringin many industrially relevant reactions. Traditional way of solving themicrokinetics model for Fischer-Tropsch synthesis (FTS) becomes inefficientwhen it comes to more advanced real-time applications. In this work, we addressthese challenges by using physics-informed neural networks(PINNs) for modellingFTS microkinetics. We propose a computationally efficient and accurate method,enabling the ultra-fast solution of the existing microkinetics models inrealistic process conditions. The proposed PINN model computes the fraction ofvacant catalytic sites, a key quantity in FTS microkinetics, with medianrelative error (MRE) of 0.03%, and the FTS product formation rates with MRE of0.1%. Compared to conventional equation solvers, the model achieves up to 1E+06times speed-up when running on GPUs, thus being fast enough for multi-scale andmulti-physics reactor modelling and enabling its applications in real-timeprocess control and optimization.</description><author>Harshil Patel, Aniruddha Panda, Tymofii Nikolaienko, Stanislav Jaso, Alejandro Lopez, Kaushic Kalyanaraman</author><pubDate>Fri, 17 Nov 2023 11:21:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10456v1</guid></item><item><title>Model-Based Reinforcement Learning with Isolated Imaginations</title><link>http://arxiv.org/abs/2303.14889v2</link><description>World models learn the consequences of actions in vision-based interactivesystems. However, in practical scenarios like autonomous driving,noncontrollable dynamics that are independent or sparsely dependent on actionsignals often exist, making it challenging to learn effective world models. Toaddress this issue, we propose Iso-Dream++, a model-based reinforcementlearning approach that has two main contributions. First, we optimize theinverse dynamics to encourage the world model to isolate controllable statetransitions from the mixed spatiotemporal variations of the environment.Second, we perform policy optimization based on the decoupled latentimaginations, where we roll out noncontrollable states into the future andadaptively associate them with the current controllable state. This enableslong-horizon visuomotor control tasks to benefit from isolating mixed dynamicssources in the wild, such as self-driving cars that can anticipate the movementof other vehicles, thereby avoiding potential risks. On top of our previouswork, we further consider the sparse dependencies between controllable andnoncontrollable states, address the training collapse problem of statedecoupling, and validate our approach in transfer learning setups. Ourempirical study demonstrates that Iso-Dream++ outperforms existingreinforcement learning models significantly on CARLA and DeepMind Control.</description><author>Minting Pan, Xiangming Zhu, Yitao Zheng, Yunbo Wang, Xiaokang Yang</author><pubDate>Fri, 17 Nov 2023 11:18:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14889v2</guid></item><item><title>Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs</title><link>http://arxiv.org/abs/2311.01404v2</link><description>The term "Normalizing Flows" is related to the task of constructinginvertible transport maps between probability measures by means of deep neuralnetworks. In this paper, we consider the problem of recovering the$W_2$-optimal transport map $T$ between absolutely continuous measures$\mu,\nu\in\mathcal{P}(\mathbb{R}^n)$ as the flow of a linear-control neuralODE. We first show that, under suitable assumptions on $\mu,\nu$ and on thecontrolled vector fields, the optimal transport map is contained in the$C^0_c$-closure of the flows generated by the system. Assuming that discreteapproximations $\mu_N,\nu_N$ of the original measures $\mu,\nu$ are available,we use a discrete optimal coupling $\gamma_N$ to define an optimal controlproblem. With a $\Gamma$-convergence argument, we prove that its solutionscorrespond to flows that approximate the optimal transport map $T$. Finally,taking advantage of the Pontryagin Maximum Principle, we propose an iterativenumerical scheme for the resolution of the optimal control problem, resultingin an algorithm for the practical computation of the approximated optimaltransport map.</description><author>Alessandro Scagliotti, Sara Farinelli</author><pubDate>Fri, 17 Nov 2023 11:06:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01404v2</guid></item><item><title>DeepClean: Machine Unlearning on the Cheap by Resetting Privacy Sensitive Weights using the Fisher Diagonal</title><link>http://arxiv.org/abs/2311.10448v1</link><description>Machine learning models trained on sensitive or private data caninadvertently memorize and leak that information. Machine unlearning seeks toretroactively remove such details from model weights to protect privacy. Wecontribute a lightweight unlearning algorithm that leverages the FisherInformation Matrix (FIM) for selective forgetting. Prior work in this arearequires full retraining or large matrix inversions, which are computationallyexpensive. Our key insight is that the diagonal elements of the FIM, whichmeasure the sensitivity of log-likelihood to changes in weights, containsufficient information for effective forgetting. Specifically, we compute theFIM diagonal over two subsets -- the data to retain and forget -- for alltrainable weights. This diagonal representation approximates the complete FIMwhile dramatically reducing computation. We then use it to selectively updateweights to maximize forgetting of the sensitive subset while minimizing impacton the retained subset. Experiments show that our algorithm can successfullyforget any randomly selected subsets of training data across neural networkarchitectures. By leveraging the FIM diagonal, our approach provides aninterpretable, lightweight, and efficient solution for machine unlearning withpractical privacy benefits.</description><author>Jiaeli Shi, Najah Ghalyan, Kostis Gourgoulias, John Buford, Sean Moran</author><pubDate>Fri, 17 Nov 2023 11:03:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10448v1</guid></item></channel></rss>