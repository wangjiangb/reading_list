<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 13 Oct 2023 06:00:28 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Dynamic Subgoal-based Exploration via Bayesian Optimization</title><link>http://arxiv.org/abs/1910.09143v5</link><description>Reinforcement learning in sparse-reward navigation environments withexpensive and limited interactions is challenging and poses a need foreffective exploration. Motivated by complex navigation tasks that requirereal-world training (when cheap simulators are not available), we consider anagent that faces an unknown distribution of environments and must decide on anexploration strategy. It may leverage a series of training environments toimprove its policy before it is evaluated in a test environment drawn from thesame environment distribution. Most existing approaches focus on fixedexploration strategies, while the few that view exploration as ameta-optimization problem tend to ignore the need for cost-efficientexploration. We propose a cost-aware Bayesian optimization approach thatefficiently searches over a class of dynamic subgoal-based explorationstrategies. The algorithm adjusts a variety of levers -- the locations of thesubgoals, the length of each episode, and the number of replications per trial-- in order to overcome the challenges of sparse rewards, expensiveinteractions, and noise. An experimental evaluation demonstrates that the newapproach outperforms existing baselines across a number of problem domains. Wealso provide a theoretical foundation and prove that the method asymptoticallyidentifies a near-optimal subgoal design.</description><author>Yijia Wang, Matthias Poloczek, Daniel R. Jiang</author><pubDate>Thu, 12 Oct 2023 18:27:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1910.09143v5</guid></item><item><title>Multimodal Graph Learning for Generative Tasks</title><link>http://arxiv.org/abs/2310.07478v2</link><description>Multimodal learning combines multiple data modalities, broadening the typesand complexity of data our models can utilize: for example, from plain text toimage-caption pairs. Most multimodal learning algorithms focus on modelingsimple one-to-one pairs of data from two modalities, such as image-captionpairs, or audio-text pairs. However, in most real-world settings, entities ofdifferent modalities interact with each other in more complex and multifacetedways, going beyond one-to-one mappings. We propose to represent these complexrelationships as graphs, allowing us to capture data with any number ofmodalities, and with complex relationships between modalities that can flexiblyvary from one sample to another. Toward this goal, we propose Multimodal GraphLearning (MMGL), a general and systematic framework for capturing informationfrom multiple multimodal neighbors with relational structures among them. Inparticular, we focus on MMGL for generative tasks, building upon pretrainedLanguage Models (LMs), aiming to augment their text generation with multimodalneighbor contexts. We study three research questions raised by MMGL: (1) howcan we infuse multiple neighbor information into the pretrained LMs, whileavoiding scalability issues? (2) how can we infuse the graph structureinformation among multimodal neighbors into the LMs? and (3) how can wefinetune the pretrained LMs to learn from the neighbor context in aparameter-efficient manner? We conduct extensive experiments to answer thesethree questions on MMGL and analyze the empirical results to pave the way forfuture MMGL research.</description><author>Minji Yoon, Jing Yu Koh, Bryan Hooi, Ruslan Salakhutdinov</author><pubDate>Thu, 12 Oct 2023 18:07:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07478v2</guid></item><item><title>Axiomatic Aggregations of Abductive Explanations</title><link>http://arxiv.org/abs/2310.03131v3</link><description>The recent criticisms of the robustness of post hoc model approximationexplanation methods (like LIME and SHAP) have led to the rise of model-preciseabductive explanations. For each data point, abductive explanations provide aminimal subset of features that are sufficient to generate the outcome. Whiletheoretically sound and rigorous, abductive explanations suffer from a majorissue -- there can be several valid abductive explanations for the same datapoint. In such cases, providing a single abductive explanation can beinsufficient; on the other hand, providing all valid abductive explanations canbe incomprehensible due to their size. In this work, we solve this issue byaggregating the many possible abductive explanations into feature importancescores. We propose three aggregation methods: two based on power indices fromcooperative game theory and a third based on a well-known measure of causalstrength. We characterize these three methods axiomatically, showing that eachof them uniquely satisfies a set of desirable properties. We also evaluate themon multiple datasets and show that these explanations are robust to the attacksthat fool SHAP and LIME.</description><author>Gagan Biradar, Yacine Izza, Elita Lobo, Vignesh Viswanathan, Yair Zick</author><pubDate>Thu, 12 Oct 2023 18:02:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03131v3</guid></item><item><title>NECO: NEural Collapse Based Out-of-distribution detection</title><link>http://arxiv.org/abs/2310.06823v2</link><description>Detecting out-of-distribution (OOD) data is a critical challenge in machinelearning due to model overconfidence, often without awareness of theirepistemological limits. We hypothesize that ``neural collapse'', a phenomenonaffecting in-distribution data for models trained beyond loss convergence, alsoinfluences OOD data. To benefit from this interplay, we introduce NECO, a novelpost-hoc method for OOD detection, which leverages the geometric properties of``neural collapse'' and of principal component spaces to identify OOD data. Ourextensive experiments demonstrate that NECO achieves state-of-the-art resultson both small and large-scale OOD detection tasks while exhibiting stronggeneralization capabilities across different network architectures.Furthermore, we provide a theoretical explanation for the effectiveness of ourmethod in OOD detection. We plan to release the code after the anonymityperiod.</description><author>Mouïn Ben Ammar, Nacim Belkhir, Sebastian Popescu, Antoine Manzanera, Gianni Franchi</author><pubDate>Thu, 12 Oct 2023 17:42:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06823v2</guid></item><item><title>Flood and Echo: Algorithmic Alignment of GNNs with Distributed Computing</title><link>http://arxiv.org/abs/2310.06970v2</link><description>Graph Neural Networks are a natural fit for learning algorithms. They candirectly represent tasks through an abstract but versatile graph structure andhandle inputs of different sizes. This opens up the possibility for scaling andextrapolation to larger graphs, one of the most important advantages of analgorithm. However, this raises two core questions i) How can we enable nodesto gather the required information in a given graph ($\textit{informationexchange}$), even if is far away and ii) How can we design an executionframework which enables this information exchange for extrapolation to largergraph sizes ($\textit{algorithmic alignment for extrapolation}$). We propose anew execution framework that is inspired by the design principles ofdistributed algorithms: Flood and Echo Net. It propagates messages through theentire graph in a wave like activation pattern, which naturally generalizes tolarger instances. Through its sparse but parallel activations it is provablymore efficient in terms of message complexity. We study the proposed model andprovide both empirical evidence and theoretical insights in terms of itsexpressiveness, efficiency, information exchange and ability to extrapolate.</description><author>Joël Mathys, Florian Grötschla, Kalyan Varma Nadimpalli, Roger Wattenhofer</author><pubDate>Thu, 12 Oct 2023 15:21:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06970v2</guid></item><item><title>In-Context Unlearning: Language Models as Few Shot Unlearners</title><link>http://arxiv.org/abs/2310.07579v2</link><description>Machine unlearning, the study of efficiently removing the impact of specifictraining points on the trained model, has garnered increased attention of late,driven by the need to comply with privacy regulations like the Right to beForgotten. Although unlearning is particularly relevant for LLMs in light ofthe copyright issues they raise, achieving precise unlearning iscomputationally infeasible for very large models. To this end, recent work hasproposed several algorithms which approximate the removal of training datawithout retraining the model. These algorithms crucially rely on access to themodel parameters in order to update them, an assumption that may not hold inpractice due to computational constraints or when the LLM is accessed via API.In this work, we propose a new class of unlearning methods for LLMs we call''In-Context Unlearning'', providing inputs in context and without having toupdate model parameters. To unlearn a particular training instance, we providethe instance alongside a flipped label and additional correctly labelledinstances which are prepended as inputs to the LLM at inference time. Ourexperimental results demonstrate that these contexts effectively removespecific information from the training set while maintaining performance levelsthat are competitive with (or in some cases exceed) state-of-the-art unlearningmethods that require access to the LLM parameters.</description><author>Martin Pawelczyk, Seth Neel, Himabindu Lakkaraju</author><pubDate>Thu, 12 Oct 2023 15:15:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07579v2</guid></item><item><title>AirIMU: Learning Uncertainty Propagation for Inertial Odometry</title><link>http://arxiv.org/abs/2310.04874v3</link><description>Accurate uncertainty estimation for inertial odometry is the foundation toachieve optimal fusion in multi-sensor systems, such as visual or LiDARinertial odometry. Prior studies often simplify the assumptions regarding theuncertainty of inertial measurements, presuming fixed covariance parameters andempirical IMU sensor models. However, the inherent physical limitations andnon-linear characteristics of sensors are difficult to capture. Moreover,uncertainty may fluctuate based on sensor rates and motion modalities, leadingto variations across different IMUs. To address these challenges, we formulatea learning-based method that not only encapsulate the non-linearities inherentto IMUs but also ensure the accurate propagation of covariance in a data-drivenmanner. We extend the PyPose library to enable differentiable batched IMUintegration with covariance propagation on manifolds, leading to significantruntime speedup. To demonstrate our method's adaptability, we evaluate it onseveral benchmarks as well as a large-scale helicopter dataset spanning over262 kilometers. The drift rate of the inertial odometry on these datasets isreduced by a factor of between 2.2 and 4 times. Our method lays the groundworkfor advanced developments in inertial odometry.</description><author>Yuheng Qiu, Chen Wang, Xunfei Zhou, Youjie Xia, Sebastian Scherer</author><pubDate>Thu, 12 Oct 2023 13:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04874v3</guid></item><item><title>NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series Pretraining</title><link>http://arxiv.org/abs/2310.07402v2</link><description>Recent research on time-series self-supervised models shows great promise inlearning semantic representations. However, it has been limited to small-scaledatasets, e.g., thousands of temporal sequences. In this work, we make keytechnical contributions that are tailored to the numerical properties oftime-series data and allow the model to scale to large datasets, e.g., millionsof temporal sequences. We adopt the Transformer architecture by firstpartitioning the input into non-overlapping windows. Each window is thencharacterized by its normalized shape and two scalar values denoting the meanand standard deviation within each window. To embed scalar values that maypossess arbitrary numerical scales to high-dimensional vectors, we propose anumerically multi-scaled embedding module enumerating all possible scales forthe scalar values. The model undergoes pretraining using the proposednumerically multi-scaled embedding with a simple contrastive objective on alarge-scale dataset containing over a million sequences. We study its transferperformance on a number of univariate and multivariate classificationbenchmarks. Our method exhibits remarkable improvement against previousrepresentation learning approaches and establishes the new state of the art,even compared with domain-specific non-learning-based methods.</description><author>Chenguo Lin, Xumeng Wen, Wei Cao, Congrui Huang, Jiang Bian, Stephen Lin, Zhirong Wu</author><pubDate>Thu, 12 Oct 2023 11:30:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07402v2</guid></item><item><title>PoRF: Pose Residual Field for Accurate Neural Surface Reconstruction</title><link>http://arxiv.org/abs/2310.07449v2</link><description>Neural surface reconstruction is sensitive to the camera pose noise, even ifstate-of-the-art pose estimators like COLMAP or ARKit are used. Moreimportantly, existing Pose-NeRF joint optimisation methods have struggled toimprove pose accuracy in challenging real-world scenarios. To overcome thechallenges, we introduce the pose residual field (\textbf{PoRF}), a novelimplicit representation that uses an MLP for regressing pose updates. This ismore robust than the conventional pose parameter optimisation due to parametersharing that leverages global information over the entire sequence.Furthermore, we propose an epipolar geometry loss to enhance the supervisionthat leverages the correspondences exported from COLMAP results without theextra computational overhead. Our method yields promising results. On the DTUdataset, we reduce the rotation error by 78\% for COLMAP poses, leading to thedecreased reconstruction Chamfer distance from 3.48mm to 0.85mm. On theMobileBrick dataset that contains casually captured unbounded 360-degreevideos, our method refines ARKit poses and improves the reconstruction F1 scorefrom 69.18 to 75.67, outperforming that with the dataset provided ground-truthpose (75.14). These achievements demonstrate the efficacy of our approach inrefining camera poses and improving the accuracy of neural surfacereconstruction in real-world scenarios.</description><author>Jia-Wang Bian, Wenjing Bian, Victor Adrian Prisacariu, Philip Torr</author><pubDate>Thu, 12 Oct 2023 11:14:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07449v2</guid></item><item><title>S4C: Self-Supervised Semantic Scene Completion with Neural Fields</title><link>http://arxiv.org/abs/2310.07522v2</link><description>3D semantic scene understanding is a fundamental challenge in computervision. It enables mobile agents to autonomously plan and navigate arbitraryenvironments. SSC formalizes this challenge as jointly estimating densegeometry and semantic information from sparse observations of a scene. Currentmethods for SSC are generally trained on 3D ground truth based on aggregatedLiDAR scans. This process relies on special sensors and annotation by handwhich are costly and do not scale well. To overcome this issue, our workpresents the first self-supervised approach to SSC called S4C that does notrely on 3D ground truth data. Our proposed method can reconstruct a scene froma single image and only relies on videos and pseudo segmentation ground truthgenerated from off-the-shelf image segmentation network during training. Unlikeexisting methods, which use discrete voxel grids, we represent scenes asimplicit semantic fields. This formulation allows querying any point within thecamera frustum for occupancy and semantic class. Our architecture is trainedthrough rendering-based self-supervised losses. Nonetheless, our methodachieves performance close to fully supervised state-of-the-art methods.Additionally, our method demonstrates strong generalization capabilities andcan synthesize accurate segmentation maps for far away viewpoints.</description><author>Adrian Hayler, Felix Wimbauer, Dominik Muhle, Christian Rupprecht, Daniel Cremers</author><pubDate>Thu, 12 Oct 2023 09:02:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07522v2</guid></item><item><title>An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT</title><link>http://arxiv.org/abs/2310.07282v2</link><description>This paper conducts a comprehensive investigation into applying largelanguage models, particularly on BioBERT, in healthcare. It begins withthoroughly examining previous natural language processing (NLP) approaches inhealthcare, shedding light on the limitations and challenges these methodsface. Following that, this research explores the path that led to theincorporation of BioBERT into healthcare applications, highlighting itssuitability for addressing the specific requirements of tasks related tobiomedical text mining. The analysis outlines a systematic methodology forfine-tuning BioBERT to meet the unique needs of the healthcare domain. Thisapproach includes various components, including the gathering of data from awide range of healthcare sources, data annotation for tasks like identifyingmedical entities and categorizing them, and the application of specializedpreprocessing techniques tailored to handle the complexities found inbiomedical texts. Additionally, the paper covers aspects related to modelevaluation, with a focus on healthcare benchmarks and functions like processingof natural language in biomedical, question-answering, clinical documentclassification, and medical entity recognition. It explores techniques toimprove the model's interpretability and validates its performance compared toexisting healthcare-focused language models. The paper thoroughly examinesethical considerations, particularly patient privacy and data security. Ithighlights the benefits of incorporating BioBERT into healthcare contexts,including enhanced clinical decision support and more efficient informationretrieval. Nevertheless, it acknowledges the impediments and complexities ofthis integration, encompassing concerns regarding data privacy, transparency,resource-intensive requirements, and the necessity for model customization toalign with diverse healthcare domains.</description><author>Shyni Sharaf, V. S. Anoop</author><pubDate>Thu, 12 Oct 2023 08:53:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07282v2</guid></item><item><title>WiGenAI: The Symphony of Wireless and Generative AI via Diffusion Models</title><link>http://arxiv.org/abs/2310.07312v2</link><description>Innovative foundation models, such as GPT-3 and stable diffusion models, havemade a paradigm shift in the realm of artificial intelligence (AI) towardsgenerative AI-based systems. In unison, from data communication and networkingperspective, AI and machine learning (AI/ML) algorithms are envisioned to bepervasively incorporated into the future generations of wireless communicationssystems, highlighting the need for novel AI-native solutions for the emergentcommunication scenarios. In this article, we outline the applications ofgenerative AI in wireless communication systems to lay the foundations forresearch in this field. Diffusion-based generative models, as the newstate-of-the-art paradigm of generative models, are introduced, and theirapplications in wireless communication systems are discussed. Two case studiesare also presented to showcase how diffusion models can be exploited for thedevelopment of resilient AI-native communication systems. Specifically, wepropose denoising diffusion probabilistic models (DDPM) for a wirelesscommunication scheme with non-ideal transceivers, where 30% improvement isachieved in terms of bit error rate. As the second application, DDPMs areemployed at the transmitter to shape the constellation symbols, highlighting arobust out-of-distribution performance. Finally, future directions and openissues for the development of generative AI-based wireless systems arediscussed to promote future research endeavors towards wireless generative AI(WiGenAI).</description><author>Mehdi Letafati, Samad Ali, Matti Latva-aho</author><pubDate>Thu, 12 Oct 2023 07:57:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07312v2</guid></item><item><title>GraphControl: Adding Conditional Control to Universal Graph Pre-trained Models for Graph Domain Transfer Learning</title><link>http://arxiv.org/abs/2310.07365v2</link><description>Graph-structured data is ubiquitous in the world which models complexrelationships between objects, enabling various Web applications. Dailyinfluxes of unlabeled graph data on the Web offer immense potential for theseapplications. Graph self-supervised algorithms have achieved significantsuccess in acquiring generic knowledge from abundant unlabeled graph data.These pre-trained models can be applied to various downstream Web applications,saving training time and improving downstream (target) performance. However,different graphs, even across seemingly similar domains, can differsignificantly in terms of attribute semantics, posing difficulties, if notinfeasibility, for transferring the pre-trained models to downstream tasks.Concretely speaking, for example, the additional task-specific node informationin downstream tasks (specificity) is usually deliberately omitted so that thepre-trained representation (transferability) can be leveraged. The trade-off assuch is termed as "transferability-specificity dilemma" in this work. Toaddress this challenge, we introduce an innovative deployment module coined asGraphControl, motivated by ControlNet, to realize better graph domain transferlearning. Specifically, by leveraging universal structural pre-trained modelsand GraphControl, we align the input space across various graphs andincorporate unique characteristics of target data as conditional inputs. Theseconditions will be progressively integrated into the model during fine-tuningor prompt tuning through ControlNet, facilitating personalized deployment.Extensive experiments show that our method significantly enhances theadaptability of pre-trained models on target attributed datasets, achieving1.4-3x performance gain. Furthermore, it outperforms training-from-scratchmethods on target data with a comparable margin and exhibits fasterconvergence.</description><author>Yun Zhu, Yaoke Wang, Haizhou Shi, Zhenshuo Zhang, Siliang Tang</author><pubDate>Thu, 12 Oct 2023 07:00:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07365v2</guid></item><item><title>Score Regularized Policy Optimization through Diffusion Behavior</title><link>http://arxiv.org/abs/2310.07297v2</link><description>Recent developments in offline reinforcement learning have uncovered theimmense potential of diffusion modeling, which excels at representingheterogeneous behavior policies. However, sampling from diffusion policies isconsiderably slow because it necessitates tens to hundreds of iterativeinference steps for one action. To address this issue, we propose to extract anefficient deterministic inference policy from critic models and pretraineddiffusion behavior models, leveraging the latter to directly regularize thepolicy gradient with the behavior distribution's score function duringoptimization. Our method enjoys powerful generative capabilities of diffusionmodeling while completely circumventing the computationally intensive andtime-consuming diffusion sampling scheme, both during training and evaluation.Extensive results on D4RL tasks show that our method boosts action samplingspeed by more than 25 times compared with various leading diffusion-basedmethods in locomotion tasks, while still maintaining state-of-the-artperformance.</description><author>Huayu Chen, Cheng Lu, Zhengyi Wang, Hang Su, Jun Zhu</author><pubDate>Thu, 12 Oct 2023 06:15:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07297v2</guid></item><item><title>Automated Argument Generation from Legal Facts</title><link>http://arxiv.org/abs/2310.05680v3</link><description>The count of pending cases has shown an exponential rise across nations(e.g., with more than 10 million pending cases in India alone). The main issuelies in the fact that the number of cases submitted to the law system is fargreater than the available number of legal professionals present in a country.Given this worldwide context, the utilization of AI technology has gainedparamount importance to enhance the efficiency and speed of legal procedures.In this study we partcularly focus on helping legal professionals in theprocess of analyzing a legal case. Our specific investigation delves intoharnessing the generative capabilities of open-sourced large language models tocreate arguments derived from the facts present in legal cases. Experimentalresults show that the generated arguments from the best performing method haveon average 63% overlap with the benchmark set gold standard annotations.</description><author>Oscar Tuvey, Procheta Sen</author><pubDate>Thu, 12 Oct 2023 05:47:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05680v3</guid></item><item><title>Elastic Decision Transformer</title><link>http://arxiv.org/abs/2307.02484v5</link><description>This paper introduces Elastic Decision Transformer (EDT), a significantadvancement over the existing Decision Transformer (DT) and its variants.Although DT purports to generate an optimal trajectory, empirical evidencesuggests it struggles with trajectory stitching, a process involving thegeneration of an optimal or near-optimal trajectory from the best parts of aset of sub-optimal trajectories. The proposed EDT differentiates itself byfacilitating trajectory stitching during action inference at test time,achieved by adjusting the history length maintained in DT. Further, the EDToptimizes the trajectory by retaining a longer history when the previoustrajectory is optimal and a shorter one when it is sub-optimal, enabling it to"stitch" with a more optimal trajectory. Extensive experimentation demonstratesEDT's ability to bridge the performance gap between DT-based and QLearning-based approaches. In particular, the EDT outperforms Q Learning-basedmethods in a multi-task regime on the D4RL locomotion benchmark and Atarigames. Videos are available at: https://kristery.github.io/edt/</description><author>Yueh-Hua Wu, Xiaolong Wang, Masashi Hamaya</author><pubDate>Thu, 12 Oct 2023 05:06:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02484v5</guid></item><item><title>Rethinking the BERT-like Pretraining for DNA Sequences</title><link>http://arxiv.org/abs/2310.07644v2</link><description>With the success of large-scale pretraining in NLP, there is an increasingtrend of applying it to the domain of life sciences. In particular, pretrainingmethods based on DNA sequences have garnered growing attention due to theirpotential to capture generic information about genes. However, existingpretraining methods for DNA sequences largely rely on direct adoptions of BERTpretraining from NLP, lacking a comprehensive understanding and a specificallytailored approach. To address this research gap, we first conducted a series ofexploratory experiments and gained several insightful observations: 1) In thefine-tuning phase of downstream tasks, when using K-mer overlappingtokenization instead of K-mer non-overlapping tokenization, both overlappingand non-overlapping pretraining weights show consistent performanceimprovement.2) During the pre-training process, using K-mer overlappingtokenization quickly produces clear K-mer embeddings and reduces the loss to avery low level, while using K-mer non-overlapping tokenization results in lessdistinct embeddings and continuously decreases the loss. 3) Using overlappingtokenization causes the self-attention in the intermediate layers ofpre-trained models to tend to overly focus on certain tokens, reflecting thatthese layers are not adequately optimized. In summary, overlapping tokenizationcan benefit the fine-tuning of downstream tasks but leads to inadequatepretraining with fast convergence. To unleash the pretraining potential, weintroduce a novel approach called RandomMask, which gradually increases thetask difficulty of BERT-like pretraining by continuously expanding its maskboundary, forcing the model to learn more knowledge. RandomMask is simple buteffective, achieving top-tier performance across 26 datasets of 28 datasetsspanning 7 downstream tasks.</description><author>Chaoqi Liang, Weiqiang Bai, Lifeng Qiao, Yuchen Ren, Jianle Sun, Peng Ye, Hongliang Yan, Xinzhu Ma, Wangmeng Zuo, Wanli Ouyang</author><pubDate>Thu, 12 Oct 2023 04:32:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07644v2</guid></item><item><title>FABind: Fast and Accurate Protein-Ligand Binding</title><link>http://arxiv.org/abs/2310.06763v2</link><description>Modeling the interaction between proteins and ligands and accuratelypredicting their binding structures is a critical yet challenging task in drugdiscovery. Recent advancements in deep learning have shown promise inaddressing this challenge, with sampling-based and regression-based methodsemerging as two prominent approaches. However, these methods have notablelimitations. Sampling-based methods often suffer from low efficiency due to theneed for generating multiple candidate structures for selection. On the otherhand, regression-based methods offer fast predictions but may experiencedecreased accuracy. Additionally, the variation in protein sizes often requiresexternal modules for selecting suitable binding pockets, further impactingefficiency. In this work, we propose $\mathbf{FABind}$, an end-to-end modelthat combines pocket prediction and docking to achieve accurate and fastprotein-ligand binding. $\mathbf{FABind}$ incorporates a unique ligand-informedpocket prediction module, which is also leveraged for docking pose estimation.The model further enhances the docking process by incrementally integrating thepredicted pocket to optimize protein-ligand binding, reducing discrepanciesbetween training and inference. Through extensive experiments on benchmarkdatasets, our proposed $\mathbf{FABind}$ demonstrates strong advantages interms of effectiveness and efficiency compared to existing methods. Our code isavailable at $\href{https://github.com/QizhiPei/FABind}{Github}$.</description><author>Qizhi Pei, Kaiyuan Gao, Lijun Wu, Jinhua Zhu, Yingce Xia, Shufang Xie, Tao Qin, Kun He, Tie-Yan Liu, Rui Yan</author><pubDate>Thu, 12 Oct 2023 04:24:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06763v2</guid></item><item><title>Imitation Learning from Observation with Automatic Discount Scheduling</title><link>http://arxiv.org/abs/2310.07433v2</link><description>Humans often acquire new skills through observation and imitation. Forrobotic agents, learning from the plethora of unlabeled video demonstrationdata available on the Internet necessitates imitating the expert without accessto its action, presenting a challenge known as Imitation Learning fromObservations (ILfO). A common approach to tackle ILfO problems is to convertthem into inverse reinforcement learning problems, utilizing a proxy rewardcomputed from the agent's and the expert's observations. Nonetheless, weidentify that tasks characterized by a progress dependency property posesignificant challenges for such approaches; in these tasks, the agent needs toinitially learn the expert's preceding behaviors before mastering thesubsequent ones. Our investigation reveals that the main cause is that thereward signals assigned to later steps hinder the learning of initialbehaviors. To address this challenge, we present a novel ILfO framework thatenables the agent to master earlier behaviors before advancing to later ones.We introduce an Automatic Discount Scheduling (ADS) mechanism that adaptivelyalters the discount factor in reinforcement learning during the training phase,prioritizing earlier rewards initially and gradually engaging later rewardsonly when the earlier behaviors have been mastered. Our experiments, conductedon nine Meta-World tasks, demonstrate that our method significantly outperformsstate-of-the-art methods across all tasks, including those that are unsolvableby them.</description><author>Yuyang Liu, Weijun Dong, Yingdong Hu, Chuan Wen, Zhao-Heng Yin, Chongjie Zhang, Yang Gao</author><pubDate>Thu, 12 Oct 2023 04:04:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07433v2</guid></item><item><title>Federated Generalization via Information-Theoretic Distribution Diversification</title><link>http://arxiv.org/abs/2310.07171v2</link><description>Federated Learning (FL) has surged in prominence due to its capability ofcollaborative model training without direct data sharing. However, the vastdisparity in local data distributions among clients, often termed thenon-Independent Identically Distributed (non-IID) challenge, poses asignificant hurdle to FL's generalization efficacy. The scenario becomes evenmore complex when not all clients participate in the training process, a commonoccurrence due to unstable network connections or limited computationalcapacities. This can greatly complicate the assessment of the trained models'generalization abilities. While a plethora of recent studies has centered onthe generalization gap pertaining to unseen data from participating clientswith diverse distributions, the divergence between the training distributionsof participating clients and the testing distributions of non-participatingones has been largely overlooked. In response, our paper unveils aninformation-theoretic generalization framework for FL. Specifically, itquantifies generalization errors by evaluating the information entropy of localdistributions and discerning discrepancies across these distributions. Inspiredby our deduced generalization bounds, we introduce a weighted aggregationapproach and a duo of client selection strategies. These innovations aim tobolster FL's generalization prowess by encompassing a more varied set of clientdata distributions. Our extensive empirical evaluations reaffirm the potency ofour proposed methods, aligning seamlessly with our theoretical construct.</description><author>Zheshun Wu, Zenglin Xu, Dun Zeng, Qifan Wang</author><pubDate>Thu, 12 Oct 2023 03:27:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07171v2</guid></item><item><title>Quantum-Enhanced Forecasting: Leveraging Quantum Gramian Angular Field and CNNs for Stock Return Predictions</title><link>http://arxiv.org/abs/2310.07427v2</link><description>We propose a time series forecasting method named Quantum Gramian AngularField (QGAF). This approach merges the advantages of quantum computingtechnology with deep learning, aiming to enhance the precision of time seriesclassification and forecasting. We successfully transformed stock return timeseries data into two-dimensional images suitable for Convolutional NeuralNetwork (CNN) training by designing specific quantum circuits. Distinct fromthe classical Gramian Angular Field (GAF) approach, QGAF's uniqueness lies ineliminating the need for data normalization and inverse cosine calculations,simplifying the transformation process from time series data to two-dimensionalimages. To validate the effectiveness of this method, we conducted experimentson datasets from three major stock markets: the China A-share market, the HongKong stock market, and the US stock market. Experimental results revealed thatcompared to the classical GAF method, the QGAF approach significantly improvedtime series prediction accuracy, reducing prediction errors by an average of25% for Mean Absolute Error (MAE) and 48% for Mean Squared Error (MSE). Thisresearch confirms the potential and promising prospects of integrating quantumcomputing with deep learning techniques in financial time series forecasting.</description><author>Zhengmeng Xu, Hai Lin</author><pubDate>Thu, 12 Oct 2023 03:04:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07427v2</guid></item><item><title>OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2310.07637v2</link><description>Large language models (LLMs) have exhibited remarkable capabilities inNLP-related tasks such as translation, summarizing, and generation. Theapplication of LLMs in specific areas, notably AIOps (Artificial Intelligencefor IT Operations), holds great potential due to their advanced abilities ininformation summarizing, report analyzing, and ability of API calling.Nevertheless, the performance of current LLMs in AIOps tasks is yet to bedetermined. Furthermore, a comprehensive benchmark is required to steer theoptimization of LLMs tailored for AIOps. Compared with existing benchmarks thatfocus on evaluating specific fields like network configuration, in this paper,we present \textbf{OpsEval}, a comprehensive task-oriented AIOps benchmarkdesigned for LLMs. For the first time, OpsEval assesses LLMs' proficiency inthree crucial scenarios (Wired Network Operation, 5G Communication Operation,and Database Operation) at various ability levels (knowledge recall, analyticalthinking, and practical application). The benchmark includes 7,200 questions inboth multiple-choice and question-answer (QA) formats, available in English andChinese. With quantitative and qualitative results, we show how various LLMtricks can affect the performance of AIOps, including zero-shot,chain-of-thought, and few-shot in-context learning. We find that GPT4-score ismore consistent with experts than widely used Bleu and Rouge, which can be usedto replace automatic metrics for large-scale qualitative evaluations.</description><author>Yuhe Liu, Changhua Pei, Longlong Xu, Bohan Chen, Mingze Sun, Zhirui Zhang, Yongqian Sun, Shenglin Zhang, Kun Wang, Haiming Zhang, Jianhui Li, Gaogang Xie, Xidao Wen, Xiaohui Nie, Dan Pei</author><pubDate>Thu, 12 Oct 2023 02:53:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07637v2</guid></item><item><title>Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction</title><link>http://arxiv.org/abs/2310.07284v2</link><description>Humans possess an extraordinary ability to selectively focus on the soundsource of interest amidst complex acoustic environments, commonly referred toas cocktail party scenarios. In an attempt to replicate this remarkableauditory attention capability in machines, target speaker extraction (TSE)models have been developed. These models leverage the pre-registered cues ofthe target speaker to extract the sound source of interest. However, theeffectiveness of these models is hindered in real-world scenarios due to theunreliable or even absence of pre-registered cues. To address this limitation,this study investigates the integration of natural language description toenhance the feasibility, controllability, and performance of existing TSEmodels. Specifically, we propose a model named LLM-TSE, wherein a largelanguage model (LLM) to extract useful semantic cues from the user's typed textinput. These cues can serve as independent extraction cues, task selectors tocontrol the TSE process, or complement the pre-registered cues. Ourexperimental results demonstrate competitive performance when only text-basedcues are presented, the effectiveness of using input text as a task selector,and a new state-of-the-art when combining text-based cues with pre-registeredcues. To our knowledge, this is the first study to successfully incorporateLLMs to guide target speaker extraction, which can be a cornerstone forcocktail party problem research.</description><author>Xiang Hao, Jibin Wu, Jianwei Yu, Chenglin Xu, Kay Chen Tan</author><pubDate>Thu, 12 Oct 2023 02:40:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07284v2</guid></item><item><title>Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue</title><link>http://arxiv.org/abs/2310.07659v2</link><description>Accurate knowledge selection is critical in knowledge-grounded dialoguesystems. Towards a closer look at it, we offer a novel perspective to organizeexisting literature, i.e., knowledge selection coupled with, after, and beforegeneration. We focus on the third under-explored category of study, which cannot only select knowledge accurately in advance, but has the advantage toreduce the learning, adjustment, and interpretation burden of subsequentresponse generation models, especially LLMs. We propose GATE, agenerator-agnostic knowledge selection method, to prepare knowledge forsubsequent response generation models by selecting context-related knowledgeamong different knowledge structures and variable knowledge requirements.Experimental results demonstrate the superiority of GATE, and indicate thatknowledge selection before generation is a lightweight yet effective way tofacilitate LLMs (e.g., ChatGPT) to generate more informative responses.</description><author>Lang Qin, Yao Zhang, Hongru Liang, Jun Wang, Zhenglu Yang</author><pubDate>Thu, 12 Oct 2023 02:08:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07659v2</guid></item><item><title>Multi-SpacePhish: Extending the Evasion-space of Adversarial Attacks against Phishing Website Detectors using Machine Learning</title><link>http://arxiv.org/abs/2210.13660v3</link><description>Existing literature on adversarial Machine Learning (ML) focuses either onshowing attacks that break every ML model, or defenses that withstand mostattacks. Unfortunately, little consideration is given to the actual feasibilityof the attack or the defense. Moreover, adversarial samples are often craftedin the "feature-space", making the corresponding evaluations of questionablevalue. Simply put, the current situation does not allow to estimate the actualthreat posed by adversarial attacks, leading to a lack of secure ML systems. We aim to clarify such confusion in this paper. By considering theapplication of ML for Phishing Website Detection (PWD), we formalize the"evasion-space" in which an adversarial perturbation can be introduced to foola ML-PWD -- demonstrating that even perturbations in the "feature-space" areuseful. Then, we propose a realistic threat model describing evasion attacksagainst ML-PWD that are cheap to stage, and hence intrinsically more attractivefor real phishers. After that, we perform the first statistically validatedassessment of state-of-the-art ML-PWD against 12 evasion attacks. Ourevaluation shows (i) the true efficacy of evasion attempts that are more likelyto occur; and (ii) the impact of perturbations crafted in differentevasion-spaces. Our realistic evasion attempts induce a statisticallysignificant degradation (3-10% at p&lt;0.05), and their cheap cost makes them asubtle threat. Notably, however, some ML-PWD are immune to our most realisticattacks (p=0.22). Finally, as an additional contribution of this journal publication, we arethe first to consider the intriguing case wherein an attacker introducesperturbations in multiple evasion-spaces at the same time. These new resultsshow that simultaneously applying perturbations in the problem- andfeature-space can cause a drop in the detection rate from 0.95 to 0.</description><author>Ying Yuan, Giovanni Apruzzese, Mauro Conti</author><pubDate>Thu, 12 Oct 2023 01:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.13660v3</guid></item><item><title>PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection</title><link>http://arxiv.org/abs/2310.07716v1</link><description>Object anomaly detection is an important problem in the field of machinevision and has seen remarkable progress recently. However, two significantchallenges hinder its research and application. First, existing datasets lackcomprehensive visual information from various pose angles. They usually have anunrealistic assumption that the anomaly-free training dataset is pose-aligned,and the testing samples have the same pose as the training data. However, inpractice, anomaly may exist in any regions on a object, the training and querysamples may have different poses, calling for the study on pose-agnosticanomaly detection. Second, the absence of a consensus on experimental protocolsfor pose-agnostic anomaly detection leads to unfair comparisons of differentmethods, hindering the research on pose-agnostic anomaly detection. To addressthese issues, we develop Multi-pose Anomaly Detection (MAD) dataset andPose-agnostic Anomaly Detection (PAD) benchmark, which takes the first step toaddress the pose-agnostic anomaly detection problem. Specifically, we build MADusing 20 complex-shaped LEGO toys including 4K views with various poses, andhigh-quality and diverse 3D anomalies in both simulated and real environments.Additionally, we propose a novel method OmniposeAD, trained using MAD,specifically designed for pose-agnostic anomaly detection. Throughcomprehensive evaluations, we demonstrate the relevance of our dataset andmethod. Furthermore, we provide an open-source benchmark library, includingdataset and baseline methods that cover 8 anomaly detection paradigms, tofacilitate future research and application in this domain. Code, data, andmodels are publicly available at https://github.com/EricLee0224/PAD.</description><author>Qiang Zhou, Weize Li, Lihan Jiang, Guoliang Wang, Guyue Zhou, Shanghang Zhang, Hao Zhao</author><pubDate>Wed, 11 Oct 2023 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07716v1</guid></item><item><title>TidyBot: Personalized Robot Assistance with Large Language Models</title><link>http://arxiv.org/abs/2305.05658v2</link><description>For a robot to personalize physical assistance effectively, it must learnuser preferences that can be generally reapplied to future scenarios. In thiswork, we investigate personalization of household cleanup with robots that cantidy up rooms by picking up objects and putting them away. A key challenge isdetermining the proper place to put each object, as people's preferences canvary greatly depending on personal taste or cultural background. For instance,one person may prefer storing shirts in the drawer, while another may preferthem on the shelf. We aim to build systems that can learn such preferences fromjust a handful of examples via prior interactions with a particular person. Weshow that robots can combine language-based planning and perception with thefew-shot summarization capabilities of large language models (LLMs) to infergeneralized user preferences that are broadly applicable to futureinteractions. This approach enables fast adaptation and achieves 91.2% accuracyon unseen objects in our benchmark dataset. We also demonstrate our approach ona real-world mobile manipulator called TidyBot, which successfully puts away85.0% of objects in real-world test scenarios.</description><author>Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, Thomas Funkhouser</author><pubDate>Wed, 11 Oct 2023 18:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05658v2</guid></item><item><title>To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing</title><link>http://arxiv.org/abs/2310.07715v1</link><description>NLP is in a period of disruptive change that is impacting our methodologies,funding sources, and public perception. In this work, we seek to understand howto shape our future by better understanding our past. We study factors thatshape NLP as a field, including culture, incentives, and infrastructure byconducting long-form interviews with 26 NLP researchers of varying seniority,research area, institution, and social identity. Our interviewees identifycyclical patterns in the field, as well as new shifts without historicalparallel, including changes in benchmark culture and software infrastructure.We complement this discussion with quantitative analysis of citation,authorship, and language use in the ACL Anthology over time. We conclude bydiscussing shared visions, concerns, and hopes for the future of NLP. We hopethat this study of our field's past and present can prompt informed discussionof our community's implicit norms and more deliberate action to consciouslyshape the future.</description><author>Sireesh Gururaja, Amanda Bertsch, Clara Na, David Gray Widder, Emma Strubell</author><pubDate>Wed, 11 Oct 2023 18:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07715v1</guid></item><item><title>InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining</title><link>http://arxiv.org/abs/2310.07713v1</link><description>Pretraining auto-regressive large language models (LLMs) with retrievaldemonstrates better perplexity and factual accuracy by leveraging externaldatabases. However, the size of existing pretrained retrieval-augmented LLM isstill limited (e.g., Retro has 7.5B parameters), which limits the effectivenessof instruction tuning and zero-shot generalization. In this work, we introduceRetro 48B, the largest LLM pretrained with retrieval before instruction tuning.Specifically, we continue to pretrain the 43B GPT model on additional 100billion tokens using the Retro augmentation method by retrieving from 1.2trillion tokens. The obtained foundation model, Retro 48B, largely outperformsthe original 43B GPT in terms of perplexity. After instruction tuning on Retro,InstructRetro demonstrates significant improvement over the instruction tunedGPT on zero-shot question answering (QA) tasks. Specifically, the averageimprovement of InstructRetro is 7% over its GPT counterpart across 8 short-formQA tasks, and 10% over GPT across 4 challenging long-form QA tasks.Surprisingly, we find that one can ablate the encoder from InstructRetroarchitecture and directly use its decoder backbone, while achieving comparableresults. We hypothesize that pretraining with retrieval makes its decoder goodat incorporating context for QA. Our results highlights the promising directionto obtain a better GPT decoder for QA through continued pretraining withretrieval before instruction tuning.</description><author>Boxin Wang, Wei Ping, Lawrence McAfee, Peng Xu, Bo Li, Mohammad Shoeybi, Bryan Catanzaro</author><pubDate>Wed, 11 Oct 2023 18:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07713v1</guid></item><item><title>Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models</title><link>http://arxiv.org/abs/2310.07712v1</link><description>Large language models (LLMs) exhibit positional bias in how they use context,which especially complicates listwise ranking. To address this, we proposepermutation self-consistency, a form of self-consistency over ranking listoutputs of black-box LLMs. Our key idea is to marginalize out different listorders in the prompt to produce an order-independent ranking with lesspositional bias. First, given some input prompt, we repeatedly shuffle the listin the prompt and pass it through the LLM while holding the instructions thesame. Next, we aggregate the resulting sample of rankings by computing thecentral ranking closest in distance to all of them, marginalizing out promptorder biases in the process. Theoretically, we prove the robustness of ourmethod, showing convergence to the true ranking in the presence of randomperturbations. Empirically, on five list-ranking datasets in sorting andpassage reranking, our approach improves scores from conventional inference byup to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previousstate of the art in passage reranking. Our code is athttps://github.com/castorini/perm-sc.</description><author>Raphael Tang, Xinyu Zhang, Xueguang Ma, Jimmy Lin, Ferhan Ture</author><pubDate>Wed, 11 Oct 2023 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07712v1</guid></item><item><title>Growing Brains: Co-emergence of Anatomical and Functional Modularity in Recurrent Neural Networks</title><link>http://arxiv.org/abs/2310.07711v1</link><description>Recurrent neural networks (RNNs) trained on compositional tasks can exhibitfunctional modularity, in which neurons can be clustered by activity similarityand participation in shared computational subtasks. Unlike brains, these RNNsdo not exhibit anatomical modularity, in which functional clustering iscorrelated with strong recurrent coupling and spatial localization offunctional clusters. Contrasting with functional modularity, which can beephemerally dependent on the input, anatomically modular networks form a robustsubstrate for solving the same subtasks in the future. To examine whether it ispossible to grow brain-like anatomical modularity, we apply a recent machinelearning method, brain-inspired modular training (BIMT), to a network beingtrained to solve a set of compositional cognitive tasks. We find thatfunctional and anatomical clustering emerge together, such that functionallysimilar neurons also become spatially localized and interconnected. Moreover,compared to standard $L_1$ or no regularization settings, the model exhibitssuperior performance by optimally balancing task performance and networksparsity. In addition to achieving brain-like organization in RNNs, ourfindings also suggest that BIMT holds promise for applications in neuromorphiccomputing and enhancing the interpretability of neural network architectures.</description><author>Ziming Liu, Mikail Khona, Ila R. Fiete, Max Tegmark</author><pubDate>Wed, 11 Oct 2023 18:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07711v1</guid></item><item><title>DiPmark: A Stealthy, Efficient and Resilient Watermark for Large Language Models</title><link>http://arxiv.org/abs/2310.07710v1</link><description>Watermarking techniques offer a promising way to secure data via embeddingcovert information into the data. A paramount challenge in the domain lies inpreserving the distribution of original data during watermarking. Our researchextends and refines existing watermarking framework, placing emphasis on theimportance of a distribution-preserving (DiP) watermark. Contrary to thecurrent strategies, our proposed DiPmark preserves the original tokendistribution during watermarking (stealthy), is detectable without access tothe language model API or weights (efficient), and is robust to moderatechanges of tokens (resilient). This is achieved by incorporating a novelreweight strategy, combined with a hash function that assigns unique\textit{i.i.d.} ciphers based on the context. The empirical benchmarks of ourapproach underscore its stealthiness, efficiency, and resilience, making it arobust solution for watermarking tasks that demand impeccable qualitypreservation.</description><author>Yihan Wu, Zhengmian Hu, Hongyang Zhang, Heng Huang</author><pubDate>Wed, 11 Oct 2023 18:57:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07710v1</guid></item><item><title>MatFormer: Nested Transformer for Elastic Inference</title><link>http://arxiv.org/abs/2310.07707v1</link><description>Transformer models are deployed in a wide range of settings, frommulti-accelerator clusters to standalone mobile phones. The diverse inferenceconstraints in these scenarios necessitate practitioners to train foundationmodels such as PaLM 2, Llama, &amp; ViTs as a series of models of varying sizes.Due to significant training costs, only a select few model sizes are trainedand supported, limiting more fine-grained control over relevant tradeoffs,including latency, cost, and accuracy. This work introduces MatFormer, a nestedTransformer architecture designed to offer elasticity in a variety ofdeployment constraints. Each Feed Forward Network (FFN) block of a MatFormermodel is jointly optimized with a few nested smaller FFN blocks. This trainingprocedure allows for the Mix'n'Match of model granularities across layers --i.e., a trained universal MatFormer model enables extraction of hundreds ofaccurate smaller models, which were never explicitly optimized. We empiricallydemonstrate MatFormer's effectiveness across different model classes (decoders&amp; encoders), modalities (language &amp; vision), and scales (up to 2.6Bparameters). We find that a 2.6B decoder-only MatFormer language model (MatLM)allows us to extract smaller models spanning from 1.5B to 2.6B, each exhibitingcomparable validation loss and one-shot downstream evaluations to theirindependently trained counterparts. Furthermore, we observe that smallerencoders extracted from a universal MatFormer-based ViT (MatViT) encoderpreserve the metric-space structure for adaptive large-scale retrieval.Finally, we showcase that speculative decoding with the accurate and consistentsubmodels extracted from MatFormer can further reduce inference latency.</description><author>Devvrit, Sneha Kudugunta, Aditya Kusupati, Tim Dettmers, Kaifeng Chen, Inderjit Dhillon, Yulia Tsvetkov, Hannaneh Hajishirzi, Sham Kakade, Ali Farhadi, Prateek Jain</author><pubDate>Wed, 11 Oct 2023 18:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07707v1</guid></item><item><title>Pixel State Value Network for Combined Prediction and Planning in Interactive Environments</title><link>http://arxiv.org/abs/2310.07706v1</link><description>Automated vehicles operating in urban environments have to reliably interactwith other traffic participants. Planning algorithms often utilize separateprediction modules forecasting probabilistic, multi-modal, and interactivebehaviors of objects. Designing prediction and planning as two separate modulesintroduces significant challenges, particularly due to the interdependence ofthese modules. This work proposes a deep learning methodology to combineprediction and planning. A conditional GAN with the U-Net architecture istrained to predict two high-resolution image sequences. The sequences representexplicit motion predictions, mainly used to train context understanding, andpixel state values suitable for planning encoding kinematic reachability,object dynamics, safety, and driving comfort. The model can be trained offlineon target images rendered by a sampling-based model-predictive planner,leveraging real-world driving data. Our results demonstrate intuitive behaviorin complex situations, such as lane changes amidst conflicting objectives.</description><author>Sascha Rosbach, Stefan M. Leupold, Simon Großjohann, Stefan Roth</author><pubDate>Wed, 11 Oct 2023 18:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07706v1</guid></item><item><title>Ferret: Refer and Ground Anything Anywhere at Any Granularity</title><link>http://arxiv.org/abs/2310.07704v1</link><description>We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable ofunderstanding spatial referring of any shape or granularity within an image andaccurately grounding open-vocabulary descriptions. To unify referring andgrounding in the LLM paradigm, Ferret employs a novel and powerful hybridregion representation that integrates discrete coordinates and continuousfeatures jointly to represent a region in the image. To extract the continuousfeatures of versatile regions, we propose a spatial-aware visual sampler, adeptat handling varying sparsity across different shapes. Consequently, Ferret canaccept diverse region inputs, such as points, bounding boxes, and free-formshapes. To bolster the desired capability of Ferret, we curate GRIT, acomprehensive refer-and-ground instruction tuning dataset including 1.1Msamples that contain rich hierarchical spatial knowledge, with 95K hardnegative data to promote model robustness. The resulting model not onlyachieves superior performance in classical referring and grounding tasks, butalso greatly outperforms existing MLLMs in region-based andlocalization-demanded multimodal chatting. Our evaluations also reveal asignificantly improved capability of describing image details and a remarkablealleviation in object hallucination. Code and data will be available athttps://github.com/apple/ml-ferret</description><author>Haoxuan You, Haotian Zhang, Zhe Gan, Xianzhi Du, Bowen Zhang, Zirui Wang, Liangliang Cao, Shih-Fu Chang, Yinfei Yang</author><pubDate>Wed, 11 Oct 2023 18:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07704v1</guid></item><item><title>ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models</title><link>http://arxiv.org/abs/2310.07702v1</link><description>In this work, we investigate the capability of generating images frompre-trained diffusion models at much higher resolutions than the training imagesizes. In addition, the generated images should have arbitrary image aspectratios. When generating images directly at a higher resolution, 1024 x 1024,with the pre-trained Stable Diffusion using training images of resolution 512 x512, we observe persistent problems of object repetition and unreasonableobject structures. Existing works for higher-resolution generation, such asattention-based and joint-diffusion approaches, cannot well address theseissues. As a new perspective, we examine the structural components of the U-Netin diffusion models and identify the crucial cause as the limited perceptionfield of convolutional kernels. Based on this key observation, we propose asimple yet effective re-dilation that can dynamically adjust the convolutionalperception field during inference. We further propose the dispersed convolutionand noise-damped classifier-free guidance, which can enableultra-high-resolution image generation (e.g., 4096 x 4096). Notably, ourapproach does not require any training or optimization. Extensive experimentsdemonstrate that our approach can address the repetition issue well and achievestate-of-the-art performance on higher-resolution image synthesis, especiallyin texture details. Our work also suggests that a pre-trained diffusion modeltrained on low-resolution images can be directly used for high-resolutionvisual generation without further tuning, which may provide insights for futureresearch on ultra-high-resolution image and video synthesis.</description><author>Yingqing He, Shaoshu Yang, Haoxin Chen, Xiaodong Cun, Menghan Xia, Yong Zhang, Xintao Wang, Ran He, Qifeng Chen, Ying Shan</author><pubDate>Wed, 11 Oct 2023 18:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07702v1</guid></item><item><title>Knowledge-enhanced Memory Model for Emotional Support Conversation</title><link>http://arxiv.org/abs/2310.07700v1</link><description>The prevalence of mental disorders has become a significant issue, leading tothe increased focus on Emotional Support Conversation as an effectivesupplement for mental health support. Existing methods have achieved compellingresults, however, they still face three challenges: 1) variability of emotions,2) practicality of the response, and 3) intricate strategy modeling. To addressthese challenges, we propose a novel knowledge-enhanced Memory mODEl foremotional suppoRt coNversation (MODERN). Specifically, we first devise aknowledge-enriched dialogue context encoding to perceive the dynamic emotionchange of different periods of the conversation for coherent user statemodeling and select context-related concepts from ConceptNet for practicalresponse generation. Thereafter, we implement a novel memory-enhanced strategymodeling module to model the semantic patterns behind the strategy categories.Extensive experiments on a widely used large-scale dataset verify thesuperiority of our model over cutting-edge baselines.</description><author>Mengzhao Jia, Qianglong Chen, Liqiang Jing, Dawei Fu, Renyu Li</author><pubDate>Wed, 11 Oct 2023 18:51:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07700v1</guid></item><item><title>From Scarcity to Efficiency: Improving CLIP Training via Visual-enriched Captions</title><link>http://arxiv.org/abs/2310.07699v1</link><description>Web-crawled datasets are pivotal to the success of pre-trainingvision-language models, exemplified by CLIP. However, web-crawled AltTexts canbe noisy and potentially irrelevant to images, thereby undermining the crucialimage-text alignment. Existing methods for rewriting captions using largelanguage models (LLMs) have shown promise on small, curated datasets like CC3Mand CC12M. Nevertheless, their efficacy on massive web-captured captions isconstrained by the inherent noise and randomness in such data. In this study,we address this limitation by focusing on two key aspects: data quality anddata variety. Unlike recent LLM rewriting techniques, we emphasize exploitingvisual concepts and their integration into the captions to improve dataquality. For data variety, we propose a novel mixed training scheme thatoptimally leverages AltTexts alongside newly generated Visual-enriched Captions(VeC). We use CLIP as one example and adapt the method for CLIP training onlarge-scale web-crawled datasets, named VeCLIP. We conduct a comprehensiveevaluation of VeCLIP across small, medium, and large scales of raw data. Ourresults show significant advantages in image-text alignment and overall modelperformance, underscoring the effectiveness of VeCLIP in improving CLIPtraining. For example, VeCLIP achieves a remarkable over 20% improvement inCOCO and Flickr30k retrieval tasks under the 12M setting. For data efficiency,we also achieve a notable over 3% improvement while using only 14% of the dataemployed in the vanilla CLIP and 11% in ALIGN.</description><author>Zhengfeng Lai, Haotian Zhang, Wentao Wu, Haoping Bai, Aleksei Timofeev, Xianzhi Du, Zhe Gan, Jiulong Shan, Chen-Nee Chuah, Yinfei Yang, Meng Cao</author><pubDate>Wed, 11 Oct 2023 18:49:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07699v1</guid></item><item><title>SurroCBM: Concept Bottleneck Surrogate Models for Generative Post-hoc Explanation</title><link>http://arxiv.org/abs/2310.07698v1</link><description>Explainable AI seeks to bring light to the decision-making processes ofblack-box models. Traditional saliency-based methods, while highlightinginfluential data segments, often lack semantic understanding. Recentadvancements, such as Concept Activation Vectors (CAVs) and Concept BottleneckModels (CBMs), offer concept-based explanations but necessitate human-definedconcepts. However, human-annotated concepts are expensive to attain. This paperintroduces the Concept Bottleneck Surrogate Models (SurroCBM), a novelframework that aims to explain the black-box models with automaticallydiscovered concepts. SurroCBM identifies shared and unique concepts acrossvarious black-box models and employs an explainable surrogate model forpost-hoc explanations. An effective training strategy using self-generated datais proposed to enhance explanation quality continuously. Through extensiveexperiments, we demonstrate the efficacy of SurroCBM in concept discovery andexplanation, underscoring its potential in advancing the field of explainableAI.</description><author>Bo Pan, Zhenke Liu, Yifei Zhang, Liang Zhao</author><pubDate>Wed, 11 Oct 2023 18:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07698v1</guid></item><item><title>ConditionVideo: Training-Free Condition-Guided Text-to-Video Generation</title><link>http://arxiv.org/abs/2310.07697v1</link><description>Recent works have successfully extended large-scale text-to-image models tothe video domain, producing promising results but at a high computational costand requiring a large amount of video data. In this work, we introduceConditionVideo, a training-free approach to text-to-video generation based onthe provided condition, video, and input text, by leveraging the power ofoff-the-shelf text-to-image generation methods (e.g., Stable Diffusion).ConditionVideo generates realistic dynamic videos from random noise or givenscene videos. Our method explicitly disentangles the motion representation intocondition-guided and scenery motion components. To this end, the ConditionVideomodel is designed with a UNet branch and a control branch. To improve temporalcoherence, we introduce sparse bi-directional spatial-temporal attention(sBiST-Attn). The 3D control network extends the conventional 2D controlnetmodel, aiming to strengthen conditional generation accuracy by additionallyleveraging the bi-directional frames in the temporal domain. Our methodexhibits superior performance in terms of frame consistency, clip score, andconditional accuracy, outperforming other compared methods.</description><author>Bo Peng, Xinyuan Chen, Yaohui Wang, Chaochao Lu, Yu Qiao</author><pubDate>Wed, 11 Oct 2023 18:46:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07697v1</guid></item><item><title>FateZero: Fusing Attentions for Zero-shot Text-based Video Editing</title><link>http://arxiv.org/abs/2303.09535v3</link><description>The diffusion-based generative models have achieved remarkable success intext-based image generation. However, since it contains enormous randomness ingeneration progress, it is still challenging to apply such models forreal-world visual content editing, especially in videos. In this paper, wepropose FateZero, a zero-shot text-based editing method on real-world videoswithout per-prompt training or use-specific mask. To edit videos consistently,we propose several techniques based on the pre-trained models. Firstly, incontrast to the straightforward DDIM inversion technique, our approach capturesintermediate attention maps during inversion, which effectively retain bothstructural and motion information. These maps are directly fused in the editingprocess rather than generated during denoising. To further minimize semanticleakage of the source video, we then fuse self-attentions with a blending maskobtained by cross-attention features from the source prompt. Furthermore, wehave implemented a reform of the self-attention mechanism in denoising UNet byintroducing spatial-temporal attention to ensure frame consistency. Yetsuccinct, our method is the first one to show the ability of zero-shottext-driven video style and local attribute editing from the trainedtext-to-image model. We also have a better zero-shot shape-aware editingability based on the text-to-video model. Extensive experiments demonstrate oursuperior temporal consistency and editing capability than previous works.</description><author>Chenyang Qi, Xiaodong Cun, Yong Zhang, Chenyang Lei, Xintao Wang, Ying Shan, Qifeng Chen</author><pubDate>Wed, 11 Oct 2023 18:46:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09535v3</guid></item><item><title>Efficient Transformer-based 3D Object Detection with Dynamic Token Halting</title><link>http://arxiv.org/abs/2303.05078v2</link><description>Balancing efficiency and accuracy is a long-standing problem for deployingdeep learning models. The trade-off is even more important for real-timesafety-critical systems like autonomous vehicles. In this paper, we propose aneffective approach for accelerating transformer-based 3D object detectors bydynamically halting tokens at different layers depending on their contributionto the detection task. Although halting a token is a non-differentiableoperation, our method allows for differentiable end-to-end learning byleveraging an equivalent differentiable forward-pass. Furthermore, ourframework allows halted tokens to be reused to inform the model's predictionsthrough a straightforward token recycling mechanism. Our method significantlyimproves the Pareto frontier of efficiency versus accuracy when compared withthe existing approaches. By halting tokens and increasing model capacity, weare able to improve the baseline model's performance without increasing themodel's latency on the Waymo Open Dataset.</description><author>Mao Ye, Gregory P. Meyer, Yuning Chai, Qiang Liu</author><pubDate>Wed, 11 Oct 2023 18:46:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05078v2</guid></item><item><title>SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models</title><link>http://arxiv.org/abs/2303.08896v3</link><description>Generative Large Language Models (LLMs) such as GPT-3 are capable ofgenerating highly fluent responses to a wide variety of user prompts. However,LLMs are known to hallucinate facts and make non-factual statements which canundermine trust in their output. Existing fact-checking approaches eitherrequire access to the output probability distribution (which may not beavailable for systems such as ChatGPT) or external databases that areinterfaced via separate, often complex, modules. In this work, we propose"SelfCheckGPT", a simple sampling-based approach that can be used to fact-checkthe responses of black-box models in a zero-resource fashion, i.e. without anexternal database. SelfCheckGPT leverages the simple idea that if an LLM hasknowledge of a given concept, sampled responses are likely to be similar andcontain consistent facts. However, for hallucinated facts, stochasticallysampled responses are likely to diverge and contradict one another. Weinvestigate this approach by using GPT-3 to generate passages about individualsfrom the WikiBio dataset, and manually annotate the factuality of the generatedpassages. We demonstrate that SelfCheckGPT can: i) detect non-factual andfactual sentences; and ii) rank passages in terms of factuality. We compare ourapproach to several baselines and show that our approach has considerablyhigher AUC-PR scores in sentence-level hallucination detection and highercorrelation scores in passage-level factuality assessment compared to grey-boxmethods.</description><author>Potsawee Manakul, Adian Liusie, Mark J. F. Gales</author><pubDate>Wed, 11 Oct 2023 18:43:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.08896v3</guid></item><item><title>Performance of Deep Learning models with transfer learning for multiple-step-ahead forecasts in monthly time series</title><link>http://arxiv.org/abs/2203.11196v2</link><description>Deep Learning and transfer learning models are being used to generate timeseries forecasts; however, there is scarce evidence about their performanceprediction that it is more evident for monthly time series. The purpose of thispaper is to compare Deep Learning models with transfer learning and withouttransfer learning and other traditional methods used for monthly forecasts toanswer three questions about the suitability of Deep Learning and TransferLearning to generate predictions of time series. Time series of M4 and M3competitions were used for the experiments. The results suggest that deeplearning models based on TCN, LSTM, and CNN with transfer learning tend tosurpass the performance prediction of other traditional methods. On the otherhand, TCN and LSTM, trained directly on the target time series, got similar orbetter performance than traditional methods for some forecast horizons.</description><author>Martín Solís, Luis-Alexander Calvo-Valverde</author><pubDate>Wed, 11 Oct 2023 18:38:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.11196v2</guid></item><item><title>Orbital Polarimetric Tomography of a Flare Near the Sagittarius A* Supermassive Black Hole</title><link>http://arxiv.org/abs/2310.07687v1</link><description>The interaction between the supermassive black hole at the center of theMilky Way, Sagittarius A$^*$, and its accretion disk, occasionally produceshigh energy flares seen in X-ray, infrared and radio. One mechanism forobserved flares is the formation of compact bright regions that appear withinthe accretion disk and close to the event horizon. Understanding these flarescan provide a window into black hole accretion processes. Althoughsophisticated simulations predict the formation of these flares, theirstructure has yet to be recovered by observations. Here we show the firstthree-dimensional (3D) reconstruction of an emission flare in orbit recoveredfrom ALMA light curves observed on April 11, 2017. Our recovery results showcompact bright regions at a distance of roughly 6 times the event horizon.Moreover, our recovery suggests a clockwise rotation in a low-inclinationorbital plane, a result consistent with prior studies by EHT and GRAVITYcollaborations. To recover this emission structure we solve a highly ill-posedtomography problem by integrating a neural 3D representation (an emergentartificial intelligence approach for 3D reconstruction) with a gravitationalmodel for black holes. Although the recovered 3D structure is subject, andsometimes sensitive, to the model assumptions, under physically motivatedchoices we find that our results are stable and our approach is successful onsimulated data. We anticipate that in the future, this approach could be usedto analyze a richer collection of time-series data that could shed light on themechanisms governing black hole and plasma dynamics.</description><author>Aviad Levis, Andrew A. Chael, Katherine L. Bouman, Maciek Wielgus, Pratul P. Srinivasan</author><pubDate>Wed, 11 Oct 2023 18:36:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07687v1</guid></item><item><title>Hermes: Unlocking Security Analysis of Cellular Network Protocols by Synthesizing Finite State Machines from Natural Language Specifications</title><link>http://arxiv.org/abs/2310.04381v2</link><description>In this paper, we present Hermes, an end-to-end framework to automaticallygenerate formal representations from natural language cellular specifications.We first develop a neural constituency parser, NEUTREX, to processtransition-relevant texts and extract transition components (i.e., states,conditions, and actions). We also design a domain-specific language totranslate these transition components to logical formulas by leveragingdependency parse trees. Finally, we compile these logical formulas to generatetransitions and create the formal model as finite state machines. Todemonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and5G RRC specifications and obtain an overall accuracy of 81-87%, which is asubstantial improvement over the state-of-the-art. Our security analysis of theextracted models uncovers 3 new vulnerabilities and identifies 19 previousattacks in 4G and 5G specifications, and 7 deviations in commercial 4Gbasebands.</description><author>Abdullah Al Ishtiaq, Sarkar Snigdha Sarathi Das, Syed Md Mukit Rashid, Ali Ranjbar, Kai Tu, Tianwei Wu, Zhezheng Song, Weixuan Wang, Mujtahid Akon, Rui Zhang, Syed Rafiul Hussain</author><pubDate>Wed, 11 Oct 2023 18:36:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04381v2</guid></item><item><title>Hypergraph Neural Networks through the Lens of Message Passing: A Common Perspective to Homophily and Architecture Design</title><link>http://arxiv.org/abs/2310.07684v1</link><description>Most of the current hypergraph learning methodologies and benchmarkingdatasets in the hypergraph realm are obtained by lifting procedures from theirgraph analogs, simultaneously leading to overshadowing hypergraph networkfoundations. This paper attempts to confront some pending questions in thatregard: Can the concept of homophily play a crucial role in Hypergraph NeuralNetworks (HGNNs), similar to its significance in graph-based research? Is thereroom for improving current hypergraph architectures and methodologies? (e.g. bycarefully addressing the specific characteristics of higher-order networks) Doexisting datasets provide a meaningful benchmark for HGNNs? Diving into thedetails, this paper proposes a novel conceptualization of homophily inhigher-order networks based on a message passing scheme; this approachharmonizes the analytical frameworks of datasets and architectures, offering aunified perspective for exploring and interpreting complex, higher-ordernetwork structures and dynamics. Further, we propose MultiSet, a novel messagepassing framework that redefines HGNNs by allowing hyperedge-dependent noderepresentations, as well as introduce a novel architecture MultiSetMixer thatleverages a new hyperedge sampling strategy. Finally, we provide an extensiveset of experiments that contextualize our proposals and lead to valuableinsights in hypergraph representation learning.</description><author>Lev Telyatnikov, Maria Sofia Bucarelli, Guillermo Bernardez, Olga Zaghen, Simone Scardapane, Pietro Lio</author><pubDate>Wed, 11 Oct 2023 18:35:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07684v1</guid></item><item><title>Controllable Data Generation Via Iterative Data-Property Mutual Mappings</title><link>http://arxiv.org/abs/2310.07683v1</link><description>Deep generative models have been widely used for their ability to generaterealistic data samples in various areas, such as images, molecules, text, andspeech. One major goal of data generation is controllability, namely togenerate new data with desired properties. Despite growing interest in the areaof controllable generation, significant challenges still remain, including 1)disentangling desired properties with unrelated latent variables, 2)out-of-distribution property control, and 3) objective optimization forout-of-distribution property control. To address these challenges, in thispaper, we propose a general framework to enhance VAE-based data generators withproperty controllability and ensure disentanglement. Our proposed objective canbe optimized on both data seen and unseen in the training set. We propose atraining procedure to train the objective in a semi-supervised manner byiteratively conducting mutual mappings between the data and properties. Theproposed framework is implemented on four VAE-based controllable generators toevaluate its performance on property error, disentanglement, generationquality, and training time. The results indicate that our proposed frameworkenables more precise control over the properties of generated samples in ashort training time, ensuring the disentanglement and keeping the validity ofthe generated samples.</description><author>Bo Pan, Muran Qin, Shiyu Wang, Yifei Zhang, Liang Zhao</author><pubDate>Wed, 11 Oct 2023 18:34:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07683v1</guid></item><item><title>VisoGender: A dataset for benchmarking gender bias in image-text pronoun resolution</title><link>http://arxiv.org/abs/2306.12424v2</link><description>We introduce VisoGender, a novel dataset for benchmarking gender bias invision-language models. We focus on occupation-related biases within ahegemonic system of binary gender, inspired by Winograd and Winogender schemas,where each image is associated with a caption containing a pronoun relationshipof subjects and objects in the scene. VisoGender is balanced by genderrepresentation in professional roles, supporting bias evaluation in two ways:i) resolution bias, where we evaluate the difference between pronoun resolutionaccuracies for image subjects with gender presentations perceived as masculineversus feminine by human annotators and ii) retrieval bias, where we compareratios of professionals perceived to have masculine and feminine genderpresentations retrieved for a gender-neutral search query. We benchmark severalstate-of-the-art vision-language models and find that they demonstrate bias inresolving binary gender in complex scenes. While the direction and magnitude ofgender bias depends on the task and the model being evaluated, captioningmodels are generally less biased than Vision-Language Encoders. Dataset andcode are available at https://github.com/oxai/visogender</description><author>Siobhan Mackenzie Hall, Fernanda Gonçalves Abrantes, Hanwen Zhu, Grace Sodunke, Aleksandar Shtedritski, Hannah Rose Kirk</author><pubDate>Wed, 11 Oct 2023 18:34:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12424v2</guid></item><item><title>Prediction of MET Overexpression in Non-Small Cell Lung Adenocarcinomas from Hematoxylin and Eosin Images</title><link>http://arxiv.org/abs/2310.07682v1</link><description>MET protein overexpression is a targetable event in non-small cell lungcancer (NSCLC) and is the subject of active drug development. Challenges inidentifying patients for these therapies include lack of access to validatedtesting, such as standardized immunohistochemistry (IHC) assessment, andconsumption of valuable tissue for a single gene/protein assay. Development ofpre-screening algorithms using routinely available digitized hematoxylin andeosin (H&amp;E)-stained slides to predict MET overexpression could promote testingfor those who will benefit most. While assessment of MET expression using IHCis currently not routinely performed in NSCLC, next-generation sequencing iscommon and in some cases includes RNA expression panel testing. In this work,we leveraged a large database of matched H&amp;E slides and RNA expression data totrain a weakly supervised model to predict MET RNA overexpression directly fromH&amp;E images. This model was evaluated on an independent holdout test set of 300over-expressed and 289 normal patients, demonstrating an ROC-AUC of 0.70 (95thpercentile interval: 0.66 - 0.74) with stable performance characteristicsacross different patient clinical variables and robust to synthetic noise onthe test set. These results suggest that H&amp;E-based predictive models could beuseful to prioritize patients for confirmatory testing of MET protein or METgene expression status.</description><author>Kshitij Ingale, Sun Hae Hong, Josh S. K. Bell, Abbas Rizvi, Amy Welch, Lingdao Sha, Irvin Ho, Kunal Nagpal, Aicha BenTaieb, Rohan P Joshi, Martin C Stumpe</author><pubDate>Wed, 11 Oct 2023 18:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07682v1</guid></item><item><title>Explainable Image Similarity: Integrating Siamese Networks and Grad-CAM</title><link>http://arxiv.org/abs/2310.07678v1</link><description>With the proliferation of image-based applications in various domains, theneed for accurate and interpretable image similarity measures has becomeincreasingly critical. Existing image similarity models often lacktransparency, making it challenging to understand the reasons why two imagesare considered similar. In this paper, we propose the concept of explainableimage similarity, where the goal is the development of an approach, which iscapable of providing similarity scores along with visual factual andcounterfactual explanations. Along this line, we present a new framework, whichintegrates Siamese Networks and Grad-CAM for providing explainable imagesimilarity and discuss the potential benefits and challenges of adopting thisapproach. In addition, we provide a comprehensive discussion about factual andcounterfactual explanations provided by the proposed framework for assistingdecision making. The proposed approach has the potential to enhance theinterpretability, trustworthiness and user acceptance of image-based systems inreal-world image similarity applications. The implementation code can be foundin https://github.com/ioannislivieris/Grad_CAM_Siamese.git.</description><author>Ioannis E. Livieris, Emmanuel Pintelas, Niki Kiriakidou, Panagiotis Pintelas</author><pubDate>Wed, 11 Oct 2023 18:21:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07678v1</guid></item><item><title>Composite Backdoor Attacks Against Large Language Models</title><link>http://arxiv.org/abs/2310.07676v1</link><description>Large language models (LLMs) have demonstrated superior performance comparedto previous methods on various tasks, and often serve as the foundation modelsfor many researches and services. However, the untrustworthy third-party LLMsmay covertly introduce vulnerabilities for downstream tasks. In this paper, weexplore the vulnerability of LLMs through the lens of backdoor attacks.Different from existing backdoor attacks against LLMs, ours scatters multipletrigger keys in different prompt components. Such a Composite Backdoor Attack(CBA) is shown to be stealthier than implanting the same multiple trigger keysin only a single component. CBA ensures that the backdoor is activated onlywhen all trigger keys appear. Our experiments demonstrate that CBA is effectivein both natural language processing (NLP) and multimodal tasks. For instance,with $3\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset,our attack achieves a $100\%$ Attack Success Rate (ASR) with a False TriggeredRate (FTR) below $2.06\%$ and negligible model accuracy degradation. The uniquecharacteristics of our CBA can be tailored for various practical scenarios,e.g., targeting specific user groups. Our work highlights the necessity ofincreased security research on the trustworthiness of foundation LLMs.</description><author>Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang</author><pubDate>Wed, 11 Oct 2023 18:21:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07676v1</guid></item><item><title>Stabilizing Estimates of Shapley Values with Control Variates</title><link>http://arxiv.org/abs/2310.07672v1</link><description>Shapley values are among the most popular tools for explaining predictions ofblackbox machine learning models. However, their high computational costmotivates the use of sampling approximations, inducing a considerable degree ofuncertainty. To stabilize these model explanations, we propose ControlSHAP, anapproach based on the Monte Carlo technique of control variates. Ourmethodology is applicable to any machine learning model and requires virtuallyno extra computation or modeling effort. On several high-dimensional datasets,we find it can produce dramatic reductions in the Monte Carlo variability ofShapley estimates.</description><author>Jeremy Goldwasser, Giles Hooker</author><pubDate>Wed, 11 Oct 2023 18:18:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07672v1</guid></item><item><title>HaarNet: Large-scale Linear-Morphological Hybrid Network for RGB-D Semantic Segmentation</title><link>http://arxiv.org/abs/2310.07669v1</link><description>Signals from different modalities each have their own combination algebrawhich affects their sampling processing. RGB is mostly linear; depth is ageometric signal following the operations of mathematical morphology. If anetwork obtaining RGB-D input has both kinds of operators available in itslayers, it should be able to give effective output with fewer parameters. Inthis paper, morphological elements in conjunction with more familiar linearmodules are used to construct a mixed linear-morphological network calledHaarNet. This is the first large-scale linear-morphological hybrid, evaluatedon a set of sizeable real-world datasets. In the network, morphological Haarsampling is applied to both feature channels in several layers, which splitsextreme values and high-frequency information such that both can be processedto improve both modalities. Moreover, morphologically parameterised ReLU isused, and morphologically-sound up-sampling is applied to obtain afull-resolution output. Experiments show that HaarNet is competitive with astate-of-the-art CNN, implying that morphological networks are a promisingresearch direction for geometry-based learning tasks.</description><author>Rick Groenendijk, Leo Dorst, Theo Gevers</author><pubDate>Wed, 11 Oct 2023 18:18:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07669v1</guid></item><item><title>GRaMuFeN: Graph-based Multi-modal Fake News Detection in Social Media</title><link>http://arxiv.org/abs/2310.07668v1</link><description>The proliferation of social media platforms such as Twitter, Instagram, andWeibo has significantly enhanced the dissemination of false information. Thisphenomenon grants both individuals and governmental entities the ability toshape public opinions, highlighting the need for deploying effective detectionmethods. In this paper, we propose GraMuFeN, a model designed to detect fakecontent by analyzing both the textual and image content of news. GraMuFeNcomprises two primary components: a text encoder and an image encoder. Fortextual analysis, GraMuFeN treats each text as a graph and employs a GraphConvolutional Neural Network (GCN) as the text encoder. Additionally, thepre-trained ResNet-152, as a Convolutional Neural Network (CNN), has beenutilized as the image encoder. By integrating the outputs from these twoencoders and implementing a contrastive similarity loss function, GraMuFeNachieves remarkable results. Extensive evaluations conducted on two publiclyavailable benchmark datasets for social media news indicate a 10 % increase inmicro F1-Score, signifying improvement over existing state-of-the-art models.These findings underscore the effectiveness of combining GCN and CNN models fordetecting fake news in multi-modal data, all while minimizing the additionalcomputational burden imposed by model parameters.</description><author>Makan Kananian, Fatima Badiei, S. AmirAli Gh. Ghahramani</author><pubDate>Wed, 11 Oct 2023 18:17:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07668v1</guid></item><item><title>Global Minima, Recoverability Thresholds, and Higher-Order Structure in GNNS</title><link>http://arxiv.org/abs/2310.07667v1</link><description>We analyze the performance of graph neural network (GNN) architectures fromthe perspective of random graph theory. Our approach promises to complementexisting lenses on GNN analysis, such as combinatorial expressive power andworst-case adversarial analysis, by connecting the performance of GNNs totypical-case properties of the training data. First, we theoreticallycharacterize the nodewise accuracy of one- and two-layer GCNs relative to thecontextual stochastic block model (cSBM) and related models. We additionallyprove that GCNs cannot beat linear models under certain circumstances. Second,we numerically map the recoverability thresholds, in terms of accuracy, of fourdiverse GNN architectures (GCN, GAT, SAGE, and Graph Transformer) under avariety of assumptions about the data. Sample results of this second analysisinclude: heavy-tailed degree distributions enhance GNN performance, GNNs canwork well on strongly heterophilous graphs, and SAGE and Graph Transformer canperform well on arbitrarily noisy edge data, but no architecture handledsufficiently noisy feature data well. Finally, we show how both specifichigher-order structures in synthetic data and the mix of empirical structuresin real data have dramatic effects (usually negative) on GNN performance.</description><author>Drake Brown, Trevor Garrity, Kaden Parker, Jason Oliphant, Stone Carson, Cole Hanson, Zachary Boyd</author><pubDate>Wed, 11 Oct 2023 18:16:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07667v1</guid></item><item><title>High-dimensional and universally consistent k-sample tests</title><link>http://arxiv.org/abs/1910.08883v4</link><description>The k-sample testing problem involves determining whether $k$ groups of datapoints are each drawn from the same distribution. The standard method fork-sample testing in biomedicine is Multivariate analysis of variance (MANOVA),despite that it depends on strong, and often unsuitable, parametricassumptions. Moreover, independence testing and k-sample testing are closelyrelated, and several universally consistent high-dimensional independence testssuch as distance correlation (Dcorr) and Hilbert-Schmidt-Independence-Criterion(Hsic) enjoy solid theoretical and empirical properties. In this paper, weprove that independence tests achieve universally consistent k-sample testingand that k-sample statistics such as Energy and Maximum Mean Discrepancy (MMD)are precisely equivalent to Dcorr. An empirical evaluation of nonparametricindependence tests showed that they generally perform better than the popularMANOVA test, even in Gaussian distributed scenarios. The evaluation includedseveral popular independence statistics and covered a comprehensive set ofsimulations. Additionally, the testing approach was extended to performmultiway and multilevel tests, which were demonstrated in a simulated study aswell as a real-world fMRI brain scans with a set of attributes.</description><author>Sambit Panda, Cencheng Shen, Ronan Perry, Jelle Zorn, Antoine Lutz, Carey E. Priebe, Joshua T. Vogelstein</author><pubDate>Wed, 11 Oct 2023 18:14:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1910.08883v4</guid></item><item><title>Deep Backtracking Counterfactuals for Causally Compliant Explanations</title><link>http://arxiv.org/abs/2310.07665v1</link><description>Counterfactuals can offer valuable insights by answering what would have beenobserved under altered circumstances, conditional on a factual observation.Whereas the classical interventional interpretation of counterfactuals has beenstudied extensively, backtracking constitutes a less studied alternative thebacktracking principle has emerged as an alternative philosophy where allcausal laws are kept intact. In the present work, we introduce a practicalmethod for computing backtracking counterfactuals in structural causal modelsthat consist of deep generative components. To this end, we impose conditionson the structural assignments that enable the generation of counterfactuals bysolving a tractable constrained optimization problem in the structured latentspace of a causal model. Our formulation also facilitates a comparison withmethods in the field of counterfactual explanations. Compared to these, ourmethod represents a versatile, modular and causally compliant alternative. Wedemonstrate these properties experimentally on a modified version of MNIST andCelebA.</description><author>Klaus-Rudolf Kladny, Julius von Kügelgen, Bernhard Schölkopf, Michael Muehlebach</author><pubDate>Wed, 11 Oct 2023 18:11:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07665v1</guid></item><item><title>Learning from Very Little Data: On the Value of Landscape Analysis for Predicting Software Project Health</title><link>http://arxiv.org/abs/2301.06577v2</link><description>When data is scarce, software analytics can make many mistakes. For example,consider learning predictors for open source project health (e.g. the number ofclosed pull requests in twelve months time). The training data for this taskmay be very small (e.g. five years of data, collected every month means just 60rows of training data). The models generated from such tiny data sets can makemany prediction errors. Those errors can be tamed by a {\em landscape analysis} that selects betterlearner control parameters. Our niSNEAK tool (a)~clusters the data to find thegeneral landscape of the hyperparameters; then (b)~explores a fewrepresentatives from each part of that landscape. niSNEAK is both faster andmore effective than prior state-of-the-art hyperparameter optimizationalgorithms (e.g. FLASH, HYPEROPT, OPTUNA). The configurations found by niSNEAK have far less error than other methods.For example, for project health indicators such as $C$= number of commits;$I$=number of closed issues, and $R$=number of closed pull requests, niSNEAK's12 month prediction errors are \{I=0\%, R=33\%\,C=47\%\} Based on the above, we recommend landscape analytics (e.g. niSNEAK)especially when learning from very small data sets. This paper only exploresthe application of niSNEAK to project health. That said, we see nothing inprinciple that prevents the application of this technique to a wider range ofproblems. To assist other researchers in repeating, improving, or even refuting ourresults, all our scripts and data are available on GitHub athttps://github.com/zxcv123456qwe/niSneak</description><author>Andre Lustosa, Tim Menzies</author><pubDate>Wed, 11 Oct 2023 18:10:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06577v2</guid></item><item><title>Accelerating Vision Transformers Based on Heterogeneous Attention Patterns</title><link>http://arxiv.org/abs/2310.07664v1</link><description>Recently, Vision Transformers (ViTs) have attracted a lot of attention in thefield of computer vision. Generally, the powerful representative capacity ofViTs mainly benefits from the self-attention mechanism, which has a highcomputation complexity. To accelerate ViTs, we propose an integratedcompression pipeline based on observed heterogeneous attention patterns acrosslayers. On one hand, different images share more similar attention patterns inearly layers than later layers, indicating that the dynamic query-by-keyself-attention matrix may be replaced with a static self-attention matrix inearly layers. Then, we propose a dynamic-guided static self-attention (DGSSA)method where the matrix inherits self-attention information from the replaceddynamic self-attention to effectively improve the feature representationability of ViTs. On the other hand, the attention maps have more low-rankpatterns, which reflect token redundancy, in later layers than early layers. Ina view of linear dimension reduction, we further propose a method of globalaggregation pyramid (GLAD) to reduce the number of tokens in later layers ofViTs, such as Deit. Experimentally, the integrated compression pipeline ofDGSSA and GLAD can accelerate up to 121% run-time throughput compared withDeiT, which surpasses all SOTA approaches.</description><author>Deli Yu, Teng Xi, Jianwei Li, Baopu Li, Gang Zhang, Haocheng Feng, Junyu Han, Jingtuo Liu, Errui Ding, Jingdong Wang</author><pubDate>Wed, 11 Oct 2023 18:09:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07664v1</guid></item><item><title>Deep Video Inpainting Guided by Audio-Visual Self-Supervision</title><link>http://arxiv.org/abs/2310.07663v1</link><description>Humans can easily imagine a scene from auditory information based on theirprior knowledge of audio-visual events. In this paper, we mimic this innatehuman ability in deep learning models to improve the quality of videoinpainting. To implement the prior knowledge, we first train the audio-visualnetwork, which learns the correspondence between auditory and visualinformation. Then, the audio-visual network is employed as a guider thatconveys the prior knowledge of audio-visual correspondence to the videoinpainting network. This prior knowledge is transferred through our proposedtwo novel losses: audio-visual attention loss and audio-visual pseudo-classconsistency loss. These two losses further improve the performance of the videoinpainting by encouraging the inpainting result to have a high correspondenceto its synchronized audio. Experimental results demonstrate that our proposedmethod can restore a wider domain of video scenes and is particularly effectivewhen the sounding object in the scene is partially blinded.</description><author>Kyuyeon Kim, Junsik Jung, Woo Jae Kim, Sung-Eui Yoon</author><pubDate>Wed, 11 Oct 2023 18:03:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07663v1</guid></item><item><title>Schema-adaptable Knowledge Graph Construction</title><link>http://arxiv.org/abs/2305.08703v3</link><description>Conventional Knowledge Graph Construction (KGC) approaches typically followthe static information extraction paradigm with a closed set of pre-definedschema. As a result, such approaches fall short when applied to dynamicscenarios or domains, whereas a new type of knowledge emerges. Thisnecessitates a system that can handle evolving schema automatically to extractinformation for KGC. To address this need, we propose a new task calledschema-adaptable KGC, which aims to continually extract entity, relation, andevent based on a dynamically changing schema graph without re-training. Wefirst split and convert existing datasets based on three principles to build abenchmark, i.e., horizontal schema expansion, vertical schema expansion, andhybrid schema expansion; then investigate the schema-adaptable performance ofseveral well-known approaches such as Text2Event, TANL, UIE and GPT-3.5. Wefurther propose a simple yet effective baseline dubbed \textsc{AdaKGC}, whichcontains schema-enriched prefix instructor and schema-conditioned dynamicdecoding to better handle evolving schema. Comprehensive experimental resultsillustrate that AdaKGC can outperform baselines but still have room forimprovement. We hope the proposed work can deliver benefits to the community.Code and datasets available at https://github.com/zjunlp/AdaKGC.</description><author>Hongbin Ye, Honghao Gui, Xin Xu, Huajun Chen, Ningyu Zhang</author><pubDate>Wed, 11 Oct 2023 18:00:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08703v3</guid></item><item><title>Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue</title><link>http://arxiv.org/abs/2310.07659v1</link><description>Accurate knowledge selection is critical in knowledge-grounded dialoguesystems. Towards a closer look at it, we offer a novel perspective to organizeexisting literature, i.e., knowledge selection coupled with, after, and beforegeneration. We focus on the third under-explored category of study, which cannot only select knowledge accurately in advance, but has the advantage toreduce the learning, adjustment, and interpretation burden of subsequentresponse generation models, especially LLMs. We propose GATE, agenerator-agnostic knowledge selection method, to prepare knowledge forsubsequent response generation models by selecting context-related knowledgeamong different knowledge structures and variable knowledge requirements.Experimental results demonstrate the superiority of GATE, and indicate thatknowledge selection before generation is a lightweight yet effective way tofacilitate LLMs (e.g., ChatGPT) to generate more informative responses.</description><author>Qin Lang, Zhang Yao, Liang Hongru, Wang jun, Yang Zhenglu</author><pubDate>Wed, 11 Oct 2023 18:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07659v1</guid></item><item><title>The First Pathloss Radio Map Prediction Challenge</title><link>http://arxiv.org/abs/2310.07658v1</link><description>To foster research and facilitate fair comparisons among recently proposedpathloss radio map prediction methods, we have launched the ICASSP 2023 FirstPathloss Radio Map Prediction Challenge. In this short overview paper, webriefly describe the pathloss prediction problem, the provided datasets, thechallenge task and the challenge evaluation methodology. Finally, we presentthe results of the challenge.</description><author>Çağkan Yapar, Fabian Jaensch, Ron Levie, Gitta Kutyniok, Giuseppe Caire</author><pubDate>Wed, 11 Oct 2023 18:00:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07658v1</guid></item><item><title>Audio-Visual Neural Syntax Acquisition</title><link>http://arxiv.org/abs/2310.07654v1</link><description>We study phrase structure induction from visually-grounded speech. The coreidea is to first segment the speech waveform into sequences of word segments,and subsequently induce phrase structure using the inferred segment-levelcontinuous representations. We present the Audio-Visual Neural Syntax Learner(AV-NSL) that learns phrase structure by listening to audio and looking atimages, without ever being exposed to text. By training on paired images andspoken captions, AV-NSL exhibits the capability to infer meaningful phrasestructures that are comparable to those derived by naturally-supervised textparsers, for both English and German. Our findings extend prior work inunsupervised language acquisition from speech and grounded grammar induction,and present one approach to bridge the gap between the two topics.</description><author>Cheng-I Jeff Lai, Freda Shi, Puyuan Peng, Yoon Kim, Kevin Gimpel, Shiyu Chang, Yung-Sung Chuang, Saurabhchand Bhati, David Cox, David Harwath, Yang Zhang, Karen Livescu, James Glass</author><pubDate>Wed, 11 Oct 2023 17:54:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07654v1</guid></item><item><title>Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models</title><link>http://arxiv.org/abs/2310.07653v1</link><description>The revolution of artificial intelligence content generation has been rapidlyaccelerated with the booming text-to-image (T2I) diffusion models. Within justtwo years of development, it was unprecedentedly of high-quality, diversity,and creativity that the state-of-the-art models could generate. However, aprevalent limitation persists in the effective communication with these popularT2I models, such as Stable Diffusion, using natural language descriptions. Thistypically makes an engaging image hard to obtain without expertise in promptengineering with complex word compositions, magic tags, and annotations.Inspired by the recently released DALLE3 - a T2I model directly built-inChatGPT that talks human language, we revisit the existing T2I systemsendeavoring to align human intent and introduce a new task - interactive textto image (iT2I), where people can interact with LLM for interleavedhigh-quality image generation/edit/refinement and question answering withstronger images and text correspondences using natural language. In addressingthe iT2I problem, we present a simple approach that augments LLMs for iT2I withprompting techniques and off-the-shelf T2I models. We evaluate our approach foriT2I in a variety of common-used scenarios under different LLMs, e.g., ChatGPT,LLAMA, Baichuan, and InternLM. We demonstrate that our approach could be aconvenient and low-cost way to introduce the iT2I ability for any existing LLMsand any text-to-image models without any training while bringing littledegradation on LLMs' inherent capabilities in, e.g., question answering andcode generation. We hope this work could draw broader attention and provideinspiration for boosting user experience in human-machine interactionsalongside the image quality of the next-generation T2I systems.</description><author>Lai Zeqiang, Zhu Xizhou, Dai Jifeng, Qiao Yu, Wang Wenhai</author><pubDate>Wed, 11 Oct 2023 17:53:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07653v1</guid></item><item><title>Editing Large Language Models: Problems, Methods, and Opportunities</title><link>http://arxiv.org/abs/2305.13172v2</link><description>Despite the ability to train capable LLMs, the methodology for maintainingtheir relevancy and rectifying errors remains elusive. To this end, the pastfew years have witnessed a surge in techniques for editing LLMs, the objectiveof which is to efficiently alter the behavior of LLMs within a specific domainwithout negatively impacting performance across other inputs. This paperembarks on a deep exploration of the problems, methods, and opportunitiesrelated to model editing for LLMs. In particular, we provide an exhaustiveoverview of the task definition and challenges associated with model editing,along with an in-depth empirical analysis of the most progressive methodscurrently at our disposal. We also build a new benchmark dataset to facilitatea more robust evaluation and pinpoint enduring issues intrinsic to existingtechniques. Our objective is to provide valuable insights into theeffectiveness and feasibility of each editing technique, thereby assisting thecommunity in making informed decisions on the selection of the most appropriatemethod for a specific task or context. Code and datasets are available athttps://github.com/zjunlp/EasyEdit.</description><author>Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, Ningyu Zhang</author><pubDate>Wed, 11 Oct 2023 17:51:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13172v2</guid></item><item><title>LLM4Vis: Explainable Visualization Recommendation using ChatGPT</title><link>http://arxiv.org/abs/2310.07652v1</link><description>Data visualization is a powerful tool for exploring and communicatinginsights in various domains. To automate visualization choice for datasets, atask known as visualization recommendation has been proposed. Variousmachine-learning-based approaches have been developed for this purpose, butthey often require a large corpus of dataset-visualization pairs for trainingand lack natural explanations for their results. To address this research gap,we propose LLM4Vis, a novel ChatGPT-based prompting approach to performvisualization recommendation and return human-like explanations using very fewdemonstration examples. Our approach involves feature description,demonstration example selection, explanation generation, demonstration exampleconstruction, and inference steps. To obtain demonstration examples withhigh-quality explanations, we propose a new explanation generationbootstrapping to iteratively refine generated explanations by considering theprevious generation and template-based hint. Evaluations on the VizML datasetshow that LLM4Vis outperforms or performs similarly to supervised learningmodels like Random Forest, Decision Tree, and MLP in both few-shot andzero-shot settings. The qualitative evaluation also shows the effectiveness ofexplanations generated by LLM4Vis. We make our code publicly available at\href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}.</description><author>Lei Wang, Songheng Zhang, Yun Wang, Ee-Peng Lim, Yong Wang</author><pubDate>Wed, 11 Oct 2023 17:51:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07652v1</guid></item><item><title>CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools</title><link>http://arxiv.org/abs/2307.15770v2</link><description>In the face of climate change, are companies really taking substantial stepstoward more sustainable operations? A comprehensive answer lies in the dense,information-rich landscape of corporate sustainability reports. However, thesheer volume and complexity of these reports make human analysis very costly.Therefore, only a few entities worldwide have the resources to analyze thesereports at scale, which leads to a lack of transparency in sustainabilityreporting. Empowering stakeholders with LLM-based automatic analysis tools canbe a promising way to democratize sustainability report analysis. However,developing such tools is challenging due to (1) the hallucination of LLMs and(2) the inefficiency of bringing domain experts into the AI development loop.In this paper, we ChatReport, a novel LLM-based system to automate the analysisof corporate sustainability reports, addressing existing challenges by (1)making the answers traceable to reduce the harm of hallucination and (2)actively involving domain experts in the development loop. We make ourmethodology, annotated datasets, and generated analyses of 1015 reportspublicly available.</description><author>Jingwei Ni, Julia Bingler, Chiara Colesanti-Senni, Mathias Kraus, Glen Gostlow, Tobias Schimanski, Dominik Stammbach, Saeid Ashraf Vaghefi, Qian Wang, Nicolas Webersinke, Tobias Wekhof, Tingyu Yu, Markus Leippold</author><pubDate>Wed, 11 Oct 2023 17:49:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15770v2</guid></item><item><title>Hypercomplex Multimodal Emotion Recognition from EEG and Peripheral Physiological Signals</title><link>http://arxiv.org/abs/2310.07648v1</link><description>Multimodal emotion recognition from physiological signals is receiving anincreasing amount of attention due to the impossibility to control them at willunlike behavioral reactions, thus providing more reliable information. Existingdeep learning-based methods still rely on extracted handcrafted features, nottaking full advantage of the learning ability of neural networks, and oftenadopt a single-modality approach, while human emotions are inherently expressedin a multimodal way. In this paper, we propose a hypercomplex multimodalnetwork equipped with a novel fusion module comprising parameterizedhypercomplex multiplications. Indeed, by operating in a hypercomplex domain theoperations follow algebraic rules which allow to model latent relations amonglearned feature dimensions for a more effective fusion step. We performclassification of valence and arousal from electroencephalogram (EEG) andperipheral physiological signals, employing the publicly available databaseMAHNOB-HCI surpassing a multimodal state-of-the-art network. The code of ourwork is freely available at https://github.com/ispamm/MHyEEG.</description><author>Eleonora Lopez, Eleonora Chiarantano, Eleonora Grassucci, Danilo Comminiello</author><pubDate>Wed, 11 Oct 2023 17:45:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07648v1</guid></item><item><title>Rethinking the BERT-like Pretraining for DNA Sequences</title><link>http://arxiv.org/abs/2310.07644v1</link><description>With the success of large-scale pretraining in NLP, there is an increasingtrend of applying it to the domain of life sciences. In particular, pretrainingmethods based on DNA sequences have garnered growing attention due to theirpotential to capture generic information about genes. However, existingpretraining methods for DNA sequences largely rely on direct adoptions of BERTpretraining from NLP, lacking a comprehensive understanding and a specificallytailored approach. To address this research gap, we first conducted a series ofexploratory experiments and gained several insightful observations: 1) In thefine-tuning phase of downstream tasks, when using K-mer overlappingtokenization instead of K-mer non-overlapping tokenization, both overlappingand non-overlapping pretraining weights show consistent performanceimprovement.2) During the pre-training process, using K-mer overlappingtokenization quickly produces clear K-mer embeddings and reduces the loss to avery low level, while using K-mer non-overlapping tokenization results in lessdistinct embeddings and continuously decreases the loss. 3) Using overlappingtokenization causes the self-attention in the intermediate layers ofpre-trained models to tend to overly focus on certain tokens, reflecting thatthese layers are not adequately optimized. In summary, overlapping tokenizationcan benefit the fine-tuning of downstream tasks but leads to inadequatepretraining with fast convergence. To unleash the pretraining potential, weintroduce a novel approach called RandomMask, which gradually increases thetask difficulty of BERT-like pretraining by continuously expanding its maskboundary, forcing the model to learn more knowledge. RandomMask is simple buteffective, achieving top-tier performance across 26 datasets of 28 datasetsspanning 7 downstream tasks.</description><author>Chaoqi Liang, Weiqiang Bai, Lifeng Qiao, Yuchen Ren, Jianle Sun, Peng Ye, Hongliang Yan, Xinzhu Ma, Wangmeng Zuo, Wanli Ouyang</author><pubDate>Wed, 11 Oct 2023 17:40:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07644v1</guid></item><item><title>Evaluating Large Language Models at Evaluating Instruction Following</title><link>http://arxiv.org/abs/2310.07641v1</link><description>As research in large language models (LLMs) continues to accelerate,LLM-based evaluation has emerged as a scalable and cost-effective alternativeto human evaluations for comparing the ever increasing list of models. Thispaper investigates the efficacy of these "LLM evaluators", particularly inusing them to assess instruction following, a metric that gauges how closelygenerated text adheres to the given instruction. We introduce a challengingmeta-evaluation benchmark, LLMBar, designed to test the ability of an LLMevaluator in discerning instruction-following outputs. The authors manuallycurated 419 pairs of outputs, one adhering to instructions while the otherdiverging, yet may possess deceptive qualities that mislead an LLM evaluator,e.g., a more engaging tone. Contrary to existing meta-evaluation, we discoverthat different evaluators (i.e., combinations of LLMs and prompts) exhibitdistinct performance on LLMBar and even the highest-scoring ones havesubstantial room for improvement. We also present a novel suite of promptingstrategies that further close the gap between LLM and human evaluators. WithLLMBar, we hope to offer more insight into LLM evaluators and foster futureresearch in developing better instruction-following models.</description><author>Zhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya Goyal, Danqi Chen</author><pubDate>Wed, 11 Oct 2023 17:38:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07641v1</guid></item><item><title>Analysis of the Cambridge Multiple-Choice Questions Reading Dataset with a Focus on Candidate Response Distribution</title><link>http://arxiv.org/abs/2306.13047v3</link><description>Multiple choice exams are widely used to assess candidates across a diverserange of domains and tasks. To moderate question quality, newly proposedquestions often pass through pre-test evaluation stages before being deployedinto real-world exams. Currently, this evaluation process is manuallyintensive, which can lead to time lags in the question development cycle.Streamlining this process via automation can significantly enhance efficiency,however, there's a current lack of datasets with adequate pre-test analysisinformation. In this paper we analyse the Cambridge Multiple-Choice QuestionsReading Dataset; a multiple-choice comprehension dataset of questions atdifferent target levels, with corresponding candidate selection distributions.We introduce the task of candidate distribution matching, propose severalevaluation metrics for the task, and demonstrate that automatic systems trainedon RACE++ can be leveraged as baselines for our task. We further demonstratethat these automatic systems can be used for practical pre-test evaluationtasks such as detecting underperforming distractors, where our detectionsystems can automatically identify poor distractors that few candidates select.</description><author>Adian Liusie, Vatsal Raina, Andrew Mullooly, Kate Knill, Mark J. F. Gales</author><pubDate>Wed, 11 Oct 2023 17:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13047v3</guid></item><item><title>Context-Enhanced Detector For Building Detection From Remote Sensing Images</title><link>http://arxiv.org/abs/2310.07638v1</link><description>The field of building detection from remote sensing images has madesignificant progress, but faces challenges in achieving high-accuracy detectiondue to the diversity in building appearances and the complexity of vast scenes.To address these challenges, we propose a novel approach calledContext-Enhanced Detector (CEDet). Our approach utilizes a three-stage cascadestructure to enhance the extraction of contextual information and improvebuilding detection accuracy. Specifically, we introduce two modules: theSemantic Guided Contextual Mining (SGCM) module, which aggregates multi-scalecontexts and incorporates an attention mechanism to capture long-rangeinteractions, and the Instance Context Mining Module (ICMM), which capturesinstance-level relationship context by constructing a spatial relationshipgraph and aggregating instance features. Additionally, we introduce a semanticsegmentation loss based on pseudo-masks to guide contextual informationextraction. Our method achieves state-of-the-art performance on three buildingdetection benchmarks, including CNBuilding-9P, CNBuilding-23P, and SpaceNet.</description><author>Ziyue Huang, Mingming Zhang, Qingjie Liu, Wei Wang, Zhe Dong, Yunhong Wang</author><pubDate>Wed, 11 Oct 2023 17:33:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07638v1</guid></item><item><title>OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2310.07637v1</link><description>Large language models (LLMs) have exhibited remarkable capabilities inNLP-related tasks such as translation, summarizing, and generation. Theapplication of LLMs in specific areas, notably AIOps (Artificial Intelligencefor IT Operations), holds great potential due to their advanced abilities ininformation summarizing, report analyzing, and ability of API calling.Nevertheless, the performance of current LLMs in AIOps tasks is yet to bedetermined. Furthermore, a comprehensive benchmark is required to steer theoptimization of LLMs tailored for AIOps. Compared with existing benchmarks thatfocus on evaluating specific fields like network configuration, in this paper,we present \textbf{OpsEval}, a comprehensive task-oriented AIOps benchmarkdesigned for LLMs. For the first time, OpsEval assesses LLMs' proficiency inthree crucial scenarios (Wired Network Operation, 5G Communication Operation,and Database Operation) at various ability levels (knowledge recall, analyticalthinking, and practical application). The benchmark includes 7,200 questions inboth multiple-choice and question-answer (QA) formats, available in English andChinese. With quantitative and qualitative results, we show how various LLMtricks can affect the performance of AIOps, including zero-shot,chain-of-thought, and few-shot in-context learning. We find that GPT4-score ismore consistent with experts than widely used Bleu and Rouge, which can be usedto replace automatic metrics for large-scale qualitative evaluations.</description><author>Yuhe Liu, Changhua Pei, Longlong Xu, Bohan Chen, Mingze Sun, Zhirui Zhang, Yongqian Sun, Shenglin Zhang, Kun Wang, Haiming Zhang, Jianhui Li, Gaogang Xie, Xidaoo Wen, Xiaohui Nie, Dan Pei</author><pubDate>Wed, 11 Oct 2023 17:33:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07637v1</guid></item><item><title>DataPerf: Benchmarks for Data-Centric AI Development</title><link>http://arxiv.org/abs/2207.10062v3</link><description>Machine learning research has long focused on models rather than datasets,and prominent datasets are used for common ML tasks without regard to thebreadth, difficulty, and faithfulness of the underlying problems. Neglectingthe fundamental importance of data has given rise to inaccuracy, bias, andfragility in real-world applications, and research is hindered by saturationacross existing dataset benchmarks. In response, we present DataPerf, acommunity-led benchmark suite for evaluating ML datasets and data-centricalgorithms. We aim to foster innovation in data-centric AI through competition,comparability, and reproducibility. We enable the ML community to iterate ondatasets, instead of just architectures, and we provide an open, onlineplatform with multiple rounds of challenges to support this iterativedevelopment. The first iteration of DataPerf contains five benchmarks coveringa wide spectrum of data-centric techniques, tasks, and modalities in vision,speech, acquisition, debugging, and diffusion prompting, and we support hostingnew contributed benchmarks from the community. The benchmarks, onlineevaluation platform, and baseline implementations are open source, and theMLCommons Association will maintain DataPerf to ensure long-term benefits toacademia and industry.</description><author>Mark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan Karlaš, William Gaviria Rojas, Sudnya Diamos, Greg Diamos, Lynn He, Alicia Parrish, Hannah Rose Kirk, Jessica Quaye, Charvi Rastogi, Douwe Kiela, David Jurado, David Kanter, Rafael Mosquera, Juan Ciro, Lora Aroyo, Bilge Acun, Lingjiao Chen, Mehul Smriti Raje, Max Bartolo, Sabri Eyuboglu, Amirata Ghorbani, Emmett Goodman, Oana Inel, Tariq Kane, Christine R. Kirkpatrick, Tzu-Sheng Kuo, Jonas Mueller, Tristan Thrush, Joaquin Vanschoren, Margaret Warren, Adina Williams, Serena Yeung, Newsha Ardalani, Praveen Paritosh, Lilith Bath-Leah, Ce Zhang, James Zou, Carole-Jean Wu, Cody Coleman, Andrew Ng, Peter Mattson, Vijay Janapa Reddi</author><pubDate>Wed, 11 Oct 2023 17:32:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.10062v3</guid></item><item><title>Attention-Map Augmentation for Hypercomplex Breast Cancer Classification</title><link>http://arxiv.org/abs/2310.07633v1</link><description>Breast cancer is the most widespread neoplasm among women and early detectionof this disease is critical. Deep learning techniques have become of greatinterest to improve diagnostic performance. Nonetheless, discriminating betweenmalignant and benign masses from whole mammograms remains challenging due tothem being almost identical to an untrained eye and the region of interest(ROI) occupying a minuscule portion of the entire image. In this paper, wepropose a framework, parameterized hypercomplex attention maps (PHAM), toovercome these problems. Specifically, we deploy an augmentation step based oncomputing attention maps. Then, the attention maps are used to condition theclassification step by constructing a multi-dimensional input comprised of theoriginal breast cancer image and the corresponding attention map. In this step,a parameterized hypercomplex neural network (PHNN) is employed to performbreast cancer classification. The framework offers two main advantages. First,attention maps provide critical information regarding the ROI and allow theneural model to concentrate on it. Second, the hypercomplex architecture hasthe ability to model local relations between input dimensions thanks tohypercomplex algebra rules, thus properly exploiting the information providedby the attention map. We demonstrate the efficacy of the proposed framework onboth mammography images as well as histopathological ones, surpassingattention-based state-of-the-art networks and the real-valued counterpart ofour method. The code of our work is available athttps://github.com/elelo22/AttentionBCS.</description><author>Eleonora Lopez, Filippo Betello, Federico Carmignani, Eleonora Grassucci, Danilo Comminiello</author><pubDate>Wed, 11 Oct 2023 17:28:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07633v1</guid></item><item><title>Prompt Backdoors in Visual Prompt Learning</title><link>http://arxiv.org/abs/2310.07632v1</link><description>Fine-tuning large pre-trained computer vision models is infeasible forresource-limited users. Visual prompt learning (VPL) has thus emerged toprovide an efficient and flexible alternative to model fine-tuning throughVisual Prompt as a Service (VPPTaaS). Specifically, the VPPTaaS provideroptimizes a visual prompt given downstream data, and downstream users can usethis prompt together with the large pre-trained model for prediction. However,this new learning paradigm may also pose security risks when the VPPTaaSprovider instead provides a malicious visual prompt. In this paper, we take thefirst step to explore such risks through the lens of backdoor attacks.Specifically, we propose BadVisualPrompt, a simple yet effective backdoorattack against VPL. For example, poisoning $5\%$ CIFAR10 training data leads toabove $99\%$ attack success rates with only negligible model accuracy drop by$1.5\%$. In particular, we identify and then address a new technical challengerelated to interactions between the backdoor trigger and visual prompt, whichdoes not exist in conventional, model-level backdoors. Moreover, we providein-depth analyses of seven backdoor defenses from model, prompt, and inputlevels. Overall, all these defenses are either ineffective or impractical tomitigate our BadVisualPrompt, implying the critical vulnerability of VPL.</description><author>Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang</author><pubDate>Wed, 11 Oct 2023 17:25:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07632v1</guid></item><item><title>Graph Transformer Network for Flood Forecasting with Heterogeneous Covariates</title><link>http://arxiv.org/abs/2310.07631v1</link><description>Floods can be very destructive causing heavy damage to life, property, andlivelihoods. Global climate change and the consequent sea-level rise haveincreased the occurrence of extreme weather events, resulting in elevated andfrequent flood risk. Therefore, accurate and timely flood forecasting incoastal river systems is critical to facilitate good flood management. However,the computational tools currently used are either slow or inaccurate. In thispaper, we propose a Flood prediction tool using Graph Transformer Network(FloodGTN) for river systems. More specifically, FloodGTN learns thespatio-temporal dependencies of water levels at different monitoring stationsusing Graph Neural Networks (GNNs) and an LSTM. It is currently implemented toconsider external covariates such as rainfall, tide, and the settings ofhydraulic structures (e.g., outflows of dams, gates, pumps, etc.) along theriver. We use a Transformer to learn the attention given to external covariatesin computing water levels. We apply the FloodGTN tool to data from the SouthFlorida Water Management District, which manages a coastal area prone tofrequent storms and hurricanes. Experimental results show that FloodGTNoutperforms the physics-based model (HEC-RAS) by achieving higher accuracy with70% improvement while speeding up run times by at least 500x.</description><author>Jimeng Shi, Vitalii Stebliankin, Zhaonan Wang, Shaowen Wang, Giri Narasimhan</author><pubDate>Wed, 11 Oct 2023 17:24:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07631v1</guid></item><item><title>Differentiable Euler Characteristic Transforms for Shape Classification</title><link>http://arxiv.org/abs/2310.07630v1</link><description>The Euler Characteristic Transform (ECT) has proven to be a powerfulrepresentation, combining geometrical and topological characteristics of shapesand graphs. However, the ECT was hitherto unable to learn task-specificrepresentations. We overcome this issue and develop a novel computational layerthat enables learning the ECT in an end-to-end fashion. Our method DECT is fastand computationally efficient, while exhibiting performance on a par with morecomplex models in both graph and point cloud classification tasks. Moreover, weshow that this seemingly unexpressive statistic still provides the sametopological expressivity as more complex topological deep learning layersprovide.</description><author>Ernst Roell, Bastian Rieck</author><pubDate>Wed, 11 Oct 2023 17:23:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07630v1</guid></item><item><title>The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values</title><link>http://arxiv.org/abs/2310.07629v1</link><description>Human feedback is increasingly used to steer the behaviours of Large LanguageModels (LLMs). However, it is unclear how to collect and incorporate feedbackin a way that is efficient, effective and unbiased, especially for highlysubjective human preferences and values. In this paper, we survey existingapproaches for learning from human feedback, drawing on 95 papers primarilyfrom the ACL and arXiv repositories.First, we summarise the past, pre-LLMtrends for integrating human feedback into language models. Second, we give anoverview of present techniques and practices, as well as the motivations forusing feedback; conceptual frameworks for defining values and preferences; andhow feedback is collected and from whom. Finally, we encourage a better futureof feedback learning in LLMs by raising five unresolved conceptual andpractical challenges.</description><author>Hannah Rose Kirk, Andrew M. Bean, Bertie Vidgen, Paul Röttger, Scott A. Hale</author><pubDate>Wed, 11 Oct 2023 17:18:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07629v1</guid></item><item><title>Chat with the Environment: Interactive Multimodal Perception Using Large Language Models</title><link>http://arxiv.org/abs/2303.08268v3</link><description>Programming robot behavior in a complex world faces challenges on multiplelevels, from dextrous low-level skills to high-level planning and reasoning.Recent pre-trained Large Language Models (LLMs) have shown remarkable reasoningability in few-shot robotic planning. However, it remains challenging to groundLLMs in multimodal sensory input and continuous action output, while enabling arobot to interact with its environment and acquire novel information as itspolicies unfold. We develop a robot interaction scenario with a partiallyobservable state, which necessitates a robot to decide on a range of epistemicactions in order to sample sensory information among multiple modalities,before being able to execute the task correctly. Matcha (Multimodal environmentchatting) agent, an interactive perception framework, is therefore proposedwith an LLM as its backbone, whose ability is exploited to instruct epistemicactions and to reason over the resulting multimodal sensations (vision, sound,haptics, proprioception), as well as to plan an entire task execution based onthe interactively acquired information. Our study demonstrates that LLMs canprovide high-level planning and reasoning skills and control interactive robotbehavior in a multimodal environment, while multimodal modules with the contextof the environmental state help ground the LLMs and extend their processingability. The project website can be found at https://matcha-agent.github.io.</description><author>Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, Stefan Wermter</author><pubDate>Wed, 11 Oct 2023 17:17:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.08268v3</guid></item><item><title>Clifford Group Equivariant Neural Networks</title><link>http://arxiv.org/abs/2305.11141v3</link><description>We introduce Clifford Group Equivariant Neural Networks: a novel approach forconstructing $\mathrm{O}(n)$- and $\mathrm{E}(n)$-equivariant models. Weidentify and study the $\textit{Clifford group}$, a subgroup inside theClifford algebra whose definition we adjust to achieve several favorableproperties. Primarily, the group's action forms an orthogonal automorphism thatextends beyond the typical vector space to the entire Clifford algebra whilerespecting the multivector grading. This leads to several non-equivalentsubrepresentations corresponding to the multivector decomposition. Furthermore,we prove that the action respects not just the vector space structure of theClifford algebra but also its multiplicative structure, i.e., the geometricproduct. These findings imply that every polynomial in multivectors, Anadvantage worth mentioning is that we obtain expressive layers that canelegantly generalize to inner-product spaces of any dimension. We demonstrate,notably from a single core implementation, state-of-the-art performance onseveral distinct tasks, including a three-dimensional $n$-body experiment, afour-dimensional Lorentz-equivariant high-energy physics experiment, and afive-dimensional convex hull experiment.</description><author>David Ruhe, Johannes Brandstetter, Patrick Forré</author><pubDate>Wed, 11 Oct 2023 17:16:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11141v3</guid></item><item><title>Unsupervised Learning of Sea Surface Height Interpolation from Multi-variate Simulated Satellite Observations</title><link>http://arxiv.org/abs/2310.07626v1</link><description>Satellite-based remote sensing missions have revolutionized our understandingof the Ocean state and dynamics. Among them, spaceborne altimetry providesvaluable measurements of Sea Surface Height (SSH), which is used to estimatesurface geostrophic currents. However, due to the sensor technology employed,important gaps occur in SSH observations. Complete SSH maps are produced by thealtimetry community using linear Optimal Interpolations (OI) such as thewidely-used Data Unification and Altimeter Combination System (DUACS). However,OI is known for producing overly smooth fields and thus misses somemesostructures and eddies. On the other hand, Sea Surface Temperature (SST)products have much higher data coverage and SST is physically linked togeostrophic currents through advection. We design a realistic twin experimentto emulate the satellite observations of SSH and SST to evaluate interpolationmethods. We introduce a deep learning network able to use SST information, anda trainable in two settings: one where we have no access to ground truth duringtraining and one where it is accessible. Our investigation involves acomparative analysis of the aforementioned network when trained using eithersupervised or unsupervised loss functions. We assess the quality of SSHreconstructions and further evaluate the network's performance in terms of eddydetection and physical properties. We find that it is possible, even in anunsupervised setting to use SST to improve reconstruction performance comparedto SST-agnostic interpolations. We compare our reconstructions to DUACS's andreport a decrease of 41\% in terms of root mean squared error.</description><author>Theo Archambault, Arthur Filoche, Anastase Charantonis, Dominique Bereziat, Sylvie Thiria</author><pubDate>Wed, 11 Oct 2023 17:09:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07626v1</guid></item><item><title>Dual Quaternion Rotational and Translational Equivariance in 3D Rigid Motion Modelling</title><link>http://arxiv.org/abs/2310.07623v1</link><description>Objects' rigid motions in 3D space are described by rotations andtranslations of a highly-correlated set of points, each with associated $x,y,z$coordinates that real-valued networks consider as separate entities, losinginformation. Previous works exploit quaternion algebra and their ability tomodel rotations in 3D space. However, these algebras do not properly encodetranslations, leading to sub-optimal performance in 3D learning tasks. Toovercome these limitations, we employ a dual quaternion representation of rigidmotions in the 3D space that jointly describes rotations and translations ofpoint sets, processing each of the points as a single entity. Our approach istranslation and rotation equivariant, so it does not suffer from shifts in thedata and better learns object trajectories, as we validate in the experimentalevaluations. Models endowed with this formulation outperform previousapproaches in a human pose forecasting application, attesting to theeffectiveness of the proposed dual quaternion formulation for rigid motions in3D space.</description><author>Guilherme Vieira, Eleonora Grassucci, Marcos Eduardo Valle, Danilo Comminiello</author><pubDate>Wed, 11 Oct 2023 17:06:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07623v1</guid></item><item><title>BertRLFuzzer: A BERT and Reinforcement Learning based Fuzzer</title><link>http://arxiv.org/abs/2305.12534v2</link><description>We present a novel tool BertRLFuzzer, a BERT and Reinforcement Learning (RL)based fuzzer aimed at finding security vulnerabilities for Web applications.BertRLFuzzer works as follows: given a set of seed inputs, the fuzzer performsgrammar-adhering and attack-provoking mutation operations on them to generatecandidate attack vectors. The key insight of BertRLFuzzer is the use of RL witha BERT model as an agent to guide the fuzzer to efficiently learngrammar-adhering and attack-provoking mutation operators. In order to establishthe efficacy of BertRLFuzzer we compare it against a total of 13 black box andwhite box fuzzers over a benchmark of 9 victim websites with over 16K LOC. Weobserved a significant improvement, relative to the nearest competing tool, interms of time to first attack (54% less), new vulnerabilities found (17 newvulnerabilities), and attack rate (4.4% more attack vectors generated).</description><author>Piyush Jha, Joseph Scott, Jaya Sriram Ganeshna, Mudit Singh, Vijay Ganesh</author><pubDate>Wed, 11 Oct 2023 17:05:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12534v2</guid></item><item><title>Reinforcement Learning-based Knowledge Graph Reasoning for Explainable Fact-checking</title><link>http://arxiv.org/abs/2310.07613v1</link><description>Fact-checking is a crucial task as it ensures the prevention ofmisinformation. However, manual fact-checking cannot keep up with the rate atwhich false information is generated and disseminated online. Automatedfact-checking by machines is significantly quicker than by humans. But forbetter trust and transparency of these automated systems, explainability in thefact-checking process is necessary. Fact-checking often entails contrasting afactual assertion with a body of knowledge for such explanations. An effectiveway of representing knowledge is the Knowledge Graph (KG). There have beensufficient works proposed related to fact-checking with the usage of KG but notmuch focus is given to the application of reinforcement learning (RL) in suchcases. To mitigate this gap, we propose an RL-based KG reasoning approach forexplainable fact-checking. Extensive experiments on FB15K-277 and NELL-995datasets reveal that reasoning over a KG is an effective way of producinghuman-readable explanations in the form of paths and classifications for factclaims. The RL reasoning agent computes a path that either proves or disprovesa factual claim, but does not provide a verdict itself. A verdict is reached bya voting mechanism that utilizes paths produced by the agent. These paths canbe presented to human readers so that they themselves can decide whether or notthe provided evidence is convincing or not. This work will encourage works inthis direction for incorporating RL for explainable fact-checking as itincreases trustworthiness by providing a human-in-the-loop approach.</description><author>Gustav Nikopensius, Mohit Mayank, Orchid Chetia Phukan, Rajesh Sharma</author><pubDate>Wed, 11 Oct 2023 16:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07613v1</guid></item><item><title>PHYDI: Initializing Parameterized Hypercomplex Neural Networks as Identity Functions</title><link>http://arxiv.org/abs/2310.07612v1</link><description>Neural models based on hypercomplex algebra systems are growing andprolificating for a plethora of applications, ranging from computer vision tonatural language processing. Hand in hand with their adoption, parameterizedhypercomplex neural networks (PHNNs) are growing in size and no techniques havebeen adopted so far to control their convergence at a large scale. In thispaper, we study PHNNs convergence and propose parameterized hypercomplexidentity initialization (PHYDI), a method to improve their convergence atdifferent scales, leading to more robust performance when the number of layersscales up, while also reaching the same performance with fewer iterations. Weshow the effectiveness of this approach in different benchmarks and with commonPHNNs with ResNets- and Transformer-based architecture. The code is availableat https://github.com/ispamm/PHYDI.</description><author>Matteo Mancanelli, Eleonora Grassucci, Aurelio Uncini, Danilo Comminiello</author><pubDate>Wed, 11 Oct 2023 16:56:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07612v1</guid></item><item><title>Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models</title><link>http://arxiv.org/abs/2310.07611v1</link><description>The dominance of proprietary LLMs has led to restricted access and raisedinformation privacy concerns. High-performing open-source alternatives arecrucial for information-sensitive and high-volume applications but often lagbehind in performance. To address this gap, we propose (1) A untargeted variantof iterative self-critique and self-refinement devoid of external influence.(2) A novel ranking metric - Performance, Refinement, and Inference Cost Score(PeRFICS) - to find the optimal model for a given task considering refinedperformance and cost. Our experiments show that SoTA open source models ofvarying sizes from 7B - 65B, on average, improve 8.2% from their baselineperformance. Strikingly, even models with extremely small memory footprints,such as Vicuna-7B, show a 11.74% improvement overall and up to a 25.39%improvement in high-creativity, open ended tasks on the Vicuna benchmark.Vicuna-13B takes it a step further and outperforms ChatGPT post-refinement.This work has profound implications for resource-constrained andinformation-sensitive environments seeking to leverage LLMs without incurringprohibitive costs, compromising on performance and privacy. The domain-agnosticself-refinement process coupled with our novel ranking metric facilitatesinformed decision-making in model selection, thereby reducing costs anddemocratizing access to high-performing language models, as evidenced by casestudies.</description><author>Sumuk Shashidhar, Abhinav Chinta, Vaibhav Sahai, Zhenhailong Wang, Heng Ji</author><pubDate>Wed, 11 Oct 2023 16:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07611v1</guid></item><item><title>QACHECK: A Demonstration System for Question-Guided Multi-Hop Fact-Checking</title><link>http://arxiv.org/abs/2310.07609v1</link><description>Fact-checking real-world claims often requires complex, multi-step reasoningdue to the absence of direct evidence to support or refute them. However,existing fact-checking systems often lack transparency in theirdecision-making, making it challenging for users to comprehend their reasoningprocess. To address this, we propose the Question-guided Multi-hopFact-Checking (QACHECK) system, which guides the model's reasoning process byasking a series of questions critical for verifying a claim. QACHECK has fivekey modules: a claim verifier, a question generator, a question-answeringmodule, a QA validator, and a reasoner. Users can input a claim into QACHECK,which then predicts its veracity and provides a comprehensive report detailingits reasoning process, guided by a sequence of (question, answer) pairs.QACHECK also provides the source of evidence supporting each question,fostering a transparent, explainable, and user-friendly fact-checking process.A recorded video of QACHECK is at https://www.youtube.com/watch?v=ju8kxSldM64</description><author>Liangming Pan, Xinyuan Lu, Min-Yen Kan, Preslav Nakov</author><pubDate>Wed, 11 Oct 2023 16:51:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07609v1</guid></item><item><title>Probabilistically Robust Recourse: Navigating the Trade-offs between Costs and Robustness in Algorithmic Recourse</title><link>http://arxiv.org/abs/2203.06768v4</link><description>As machine learning models are increasingly being employed to makeconsequential decisions in real-world settings, it becomes critical to ensurethat individuals who are adversely impacted (e.g., loan denied) by thepredictions of these models are provided with a means for recourse. Whileseveral approaches have been proposed to construct recourses for affectedindividuals, the recourses output by these methods either achieve low costs(i.e., ease-of-implementation) or robustness to small perturbations (i.e.,noisy implementations of recourses), but not both due to the inherenttrade-offs between the recourse costs and robustness. Furthermore, priorapproaches do not provide end users with any agency over navigating theaforementioned trade-offs. In this work, we address the above challenges byproposing the first algorithmic framework which enables users to effectivelymanage the recourse cost vs. robustness trade-offs. More specifically, ourframework Probabilistically ROBust rEcourse (\texttt{PROBE}) lets users choosethe probability with which a recourse could get invalidated (recourseinvalidation rate) if small changes are made to the recourse i.e., the recourseis implemented somewhat noisily. To this end, we propose a novel objectivefunction which simultaneously minimizes the gap between the achieved(resulting) and desired recourse invalidation rates, minimizes recourse costs,and also ensures that the resulting recourse achieves a positive modelprediction. We develop novel theoretical results to characterize the recourseinvalidation rates corresponding to any given instance w.r.t. different classesof underlying models (e.g., linear models, tree based models etc.), andleverage these results to efficiently optimize the proposed objective.Experimental evaluation with multiple real world datasets demonstrates theefficacy of the proposed framework.</description><author>Martin Pawelczyk, Teresa Datta, Johannes van-den-Heuvel, Gjergji Kasneci, Himabindu Lakkaraju</author><pubDate>Wed, 11 Oct 2023 16:46:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.06768v4</guid></item><item><title>Dual Radar: A Multi-modal Dataset with Dual 4D Radar for Autononous Driving</title><link>http://arxiv.org/abs/2310.07602v1</link><description>Radar has stronger adaptability in adverse scenarios for autonomous drivingenvironmental perception compared to widely adopted cameras and LiDARs.Compared with commonly used 3D radars, latest 4D radars have precise verticalresolution and higher point cloud density, making it a highly promising sensorfor autonomous driving in complex environmental perception. However, due to themuch higher noise than LiDAR, manufacturers choose different filteringstrategies, resulting in an inverse ratio between noise level and point clouddensity. There is still a lack of comparative analysis on which method isbeneficial for deep learning-based perception algorithms in autonomous driving.One of the main reasons is that current datasets only adopt one type of 4Dradar, making it difficult to compare different 4D radars in the same scene.Therefore, in this paper, we introduce a novel large-scale multi-modal datasetfeaturing, for the first time, two types of 4D radars captured simultaneously.This dataset enables further research into effective 4D radar perceptionalgorithms.Our dataset consists of 151 consecutive series, most of which last20 seconds and contain 10,007 meticulously synchronized and annotated frames.Moreover, our dataset captures a variety of challenging driving scenarios,including many road conditions, weather conditions, nighttime and daytime withdifferent lighting intensities and periods. Our dataset annotates consecutiveframes, which can be applied to 3D object detection and tracking, and alsosupports the study of multi-modal tasks. We experimentally validate ourdataset, providing valuable results for studying different types of 4D radars.This dataset is released on https://github.com/adept-thu/Dual-Radar.</description><author>Xinyu Zhang, Li Wang, Jian Chen, Cheng Fang, Lei Yang, Ziying Song, Guangqi Yang, Yichen Wang, Xiaofei Zhang, Jun Li</author><pubDate>Wed, 11 Oct 2023 16:41:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07602v1</guid></item><item><title>Survey on Imbalanced Data, Representation Learning and SEP Forecasting</title><link>http://arxiv.org/abs/2310.07598v1</link><description>Deep Learning methods have significantly advanced various data-driven taskssuch as regression, classification, and forecasting. However, much of thisprogress has been predicated on the strong but often unrealistic assumptionthat training datasets are balanced with respect to the targets they contain.This misalignment with real-world conditions, where data is frequentlyimbalanced, hampers the effectiveness of such models in practical applications.Methods that reconsider that assumption and tackle real-world imbalances havebegun to emerge and explore avenues to address this challenge. One suchpromising avenue is representation learning, which enables models to capturecomplex data characteristics and generalize better to minority classes. Byfocusing on a richer representation of the feature space, these techniques holdthe potential to mitigate the impact of data imbalance. In this survey, wepresent deep learning works that step away from the balanced-data assumption,employing strategies like representation learning to better approximatereal-world imbalances. We also highlight a critical application in SEPforecasting where addressing data imbalance is paramount for success.</description><author>Josias Moukpe</author><pubDate>Wed, 11 Oct 2023 16:38:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07598v1</guid></item><item><title>Prospective Side Information for Latent MDPs</title><link>http://arxiv.org/abs/2310.07596v1</link><description>In many interactive decision-making settings, there is latent and unobservedinformation that remains fixed. Consider, for example, a dialogue system, wherecomplete information about a user, such as the user's preferences, is notgiven. In such an environment, the latent information remains fixed throughouteach episode, since the identity of the user does not change during aninteraction. This type of environment can be modeled as a Latent MarkovDecision Process (LMDP), a special instance of Partially Observed MarkovDecision Processes (POMDPs). Previous work established exponential lower boundsin the number of latent contexts for the LMDP class. This puts forward aquestion: under which natural assumptions a near-optimal policy of an LMDP canbe efficiently learned? In this work, we study the class of LMDPs with {\emprospective side information}, when an agent receives additional, weaklyrevealing, information on the latent context at the beginning of each episode.We show that, surprisingly, this problem is not captured by contemporarysettings and algorithms designed for partially observed environments. We thenestablish that any sample efficient algorithm must suffer at least$\Omega(K^{2/3})$-regret, as opposed to standard $\Omega(\sqrt{K})$ lowerbounds, and design an algorithm with a matching upper bound.</description><author>Jeongyeol Kwon, Yonathan Efroni, Shie Mannor, Constantine Caramanis</author><pubDate>Wed, 11 Oct 2023 16:37:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07596v1</guid></item><item><title>Transformers for Green Semantic Communication: Less Energy, More Semantics</title><link>http://arxiv.org/abs/2310.07592v1</link><description>Semantic communication aims to transmit meaningful and effective informationrather than focusing on individual symbols or bits, resulting in benefits likereduced latency, bandwidth usage, and higher throughput compared to traditionalcommunication. However, semantic communication poses significant challenges dueto the need for universal metrics for benchmarking the joint effects ofsemantic information loss and practical energy consumption. This researchpresents a novel multi-objective loss function named "Energy-Optimized SemanticLoss" (EOSL), addressing the challenge of balancing semantic information lossand energy consumption. Through comprehensive experiments on transformermodels, including CPU and GPU energy usage, it is demonstrated that EOSL-basedencoder model selection can save up to 90\% of energy while achieving a 44\%improvement in semantic similarity performance during inference in thisexperiment. This work paves the way for energy-efficient neural networkselection and the development of greener semantic communication architectures.</description><author>Shubhabrata Mukherjee, Cory Beard, Sejun Song</author><pubDate>Wed, 11 Oct 2023 16:35:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07592v1</guid></item><item><title>On the Trade-Off between Actionable Explanations and the Right to be Forgotten</title><link>http://arxiv.org/abs/2208.14137v3</link><description>As machine learning (ML) models are increasingly being deployed inhigh-stakes applications, policymakers have suggested tighter data protectionregulations (e.g., GDPR, CCPA). One key principle is the "right to beforgotten" which gives users the right to have their data deleted. Another keyprinciple is the right to an actionable explanation, also known as algorithmicrecourse, allowing users to reverse unfavorable decisions. To date, it isunknown whether these two principles can be operationalized simultaneously.Therefore, we introduce and study the problem of recourse invalidation in thecontext of data deletion requests. More specifically, we theoretically andempirically analyze the behavior of popular state-of-the-art algorithms anddemonstrate that the recourses generated by these algorithms are likely to beinvalidated if a small number of data deletion requests (e.g., 1 or 2) warrantupdates of the predictive model. For the setting of differentiable models, wesuggest a framework to identify a minimal subset of critical training pointswhich, when removed, maximize the fraction of invalidated recourses. Using ourframework, we empirically show that the removal of as little as 2 datainstances from the training set can invalidate up to 95 percent of allrecourses output by popular state-of-the-art algorithms. Thus, our work raisesfundamental questions about the compatibility of "the right to an actionableexplanation" in the context of the "right to be forgotten", while alsoproviding constructive insights on the determining factors of recourserobustness.</description><author>Martin Pawelczyk, Tobias Leemann, Asia Biega, Gjergji Kasneci</author><pubDate>Wed, 11 Oct 2023 16:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.14137v3</guid></item><item><title>PeP: a Point enhanced Painting method for unified point cloud tasks</title><link>http://arxiv.org/abs/2310.07591v1</link><description>Point encoder is of vital importance for point cloud recognition. As the verybeginning step of whole model pipeline, adding features from diverse sourcesand providing stronger feature encoding mechanism would provide better inputfor downstream modules. In our work, we proposed a novel PeP module to tackleabove issue. PeP contains two main parts, a refined point painting method and aLM-based point encoder. Experiments results on the nuScenes and KITTI datasetsvalidate the superior performance of our PeP. The advantages leads to strongperformance on both semantic segmentation and object detection, in both lidarand multi-modal settings. Notably, our PeP module is model agnostic andplug-and-play. Our code will be publicly available soon.</description><author>Zichao Dong, Hang Ji, Xufeng Huang, Weikun Zhang, Xin Zhan, Junbo Chen</author><pubDate>Wed, 11 Oct 2023 16:33:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07591v1</guid></item><item><title>Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models</title><link>http://arxiv.org/abs/2310.07589v1</link><description>Considerable effort has been dedicated to mitigating toxicity, but existingmethods often require drastic modifications to model parameters or the use ofcomputationally intensive auxiliary models. Furthermore, previous approacheshave often neglected the crucial factor of language's evolving nature overtime. In this work, we present a comprehensive perspective on toxicitymitigation that takes into account its changing nature. We introduceGoodtriever, a flexible methodology that matches the current state-of-the-arttoxicity mitigation while achieving 43% relative latency reduction duringinference and being more computationally efficient. By incorporating aretrieval-based approach at decoding time, Goodtriever enablestoxicity-controlled text generation. Our research advocates for an increasedfocus on adaptable mitigation techniques, which better reflect the data driftmodels face when deployed in the wild. Code and data are available athttps://github.com/for-ai/goodtriever.</description><author>Luiza Pozzobon, Beyza Ermis, Patrick Lewis, Sara Hooker</author><pubDate>Wed, 11 Oct 2023 16:30:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07589v1</guid></item><item><title>Accurate Use of Label Dependency in Multi-Label Text Classification Through the Lens of Causality</title><link>http://arxiv.org/abs/2310.07588v1</link><description>Multi-Label Text Classification (MLTC) aims to assign the most relevantlabels to each given text. Existing methods demonstrate that label dependencycan help to improve the model's performance. However, the introduction of labeldependency may cause the model to suffer from unwanted prediction bias. In thisstudy, we attribute the bias to the model's misuse of label dependency, i.e.,the model tends to utilize the correlation shortcut in label dependency ratherthan fusing text information and label dependency for prediction. Motivated bycausal inference, we propose a CounterFactual Text Classifier (CFTC) toeliminate the correlation bias, and make causality-based predictions.Specifically, our CFTC first adopts the predict-then-modify backbone to extractprecise label information embedded in label dependency, then blocks thecorrelation shortcut through the counterfactual de-bias technique with the helpof the human causal graph. Experimental results on three datasets demonstratethat our CFTC significantly outperforms the baselines and effectivelyeliminates the correlation bias in datasets.</description><author>Caoyun Fan, Wenqing Chen, Jidong Tian, Yitian Li, Hao He, Yaohui Jin</author><pubDate>Wed, 11 Oct 2023 16:28:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07588v1</guid></item><item><title>Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer</title><link>http://arxiv.org/abs/2310.07587v1</link><description>Data privacy and long-tailed distribution are the norms rather than theexception in many real-world tasks. This paper investigates a federatedlong-tailed learning (Fed-LT) task in which each client holds a locallyheterogeneous dataset; if the datasets can be globally aggregated, they jointlyexhibit a long-tailed distribution. Under such a setting, existing federatedoptimization and/or centralized long-tailed learning methods hardly apply dueto challenges in (a) characterizing the global long-tailed distribution underprivacy constraints and (b) adjusting the local learning strategy to cope withthe head-tail imbalance. In response, we propose a method termed$\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB)module that re-weights clients' gradients in a closed-loop manner, based on thefeedback of global long-tailed distribution evaluated by a Direct PriorAnalyzer (DPA) module. Using $\texttt{Fed-GraB}$, clients can effectivelyalleviate the distribution drift caused by data heterogeneity during the modeltraining process and obtain a global model with better performance on theminority classes while maintaining the performance of the majority classes.Extensive experiments demonstrate that $\texttt{Fed-GraB}$ achievesstate-of-the-art performance on representative datasets such as CIFAR-10-LT,CIFAR-100-LT, ImageNet-LT, and iNaturalist.</description><author>Zikai Xiao, Zihan Chen, Songshang Liu, Hualiang Wang, Yang Feng, Jin Hao, Joey Tianyi Zhou, Jian Wu, Howard Hao Yang, Zuozhu Liu</author><pubDate>Wed, 11 Oct 2023 16:28:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07587v1</guid></item></channel></rss>