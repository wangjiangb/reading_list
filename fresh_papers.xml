<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 23 Jun 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective</title><link>http://arxiv.org/abs/2306.13092v1</link><description>We present a new dataset condensation framework termed Squeeze, Recover andRelabel (SRe$^2$L) that decouples the bilevel optimization of model andsynthetic data during training, to handle varying scales of datasets, modelarchitectures and image resolutions for effective dataset condensation. Theproposed method demonstrates flexibility across diverse dataset scales andexhibits multiple advantages in terms of arbitrary resolutions of synthesizedimages, low training cost and memory consumption with high-resolution training,and the ability to scale up to arbitrary evaluation network architectures.Extensive experiments are conducted on Tiny-ImageNet and full ImageNet-1Kdatasets. Under 50 IPC, our approach achieves the highest 42.5% and 60.8%validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming allprevious state-of-the-art methods by margins of 14.5% and 32.9%, respectively.Our approach also outperforms MTT by approximately 52$\times$ (ConvNet-4) and16$\times$ (ResNet-18) faster in speed with less memory consumption of11.6$\times$ and 6.4$\times$ during data synthesis. Our code and condenseddatasets of 50, 200 IPC with 4K recovery budget are available athttps://zeyuanyin.github.io/projects/SRe2L/.</description><author>Zeyuan Yin, Eric Xing, Zhiqiang Shen</author><pubDate>Thu, 22 Jun 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13092v1</guid></item><item><title>Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces</title><link>http://arxiv.org/abs/2306.13091v1</link><description>The ability of generative models to produce highly realistic synthetic faceimages has raised security and ethical concerns. As a first line of defenseagainst such fake faces, deep learning based forensic classifiers have beendeveloped. While these forensic models can detect whether a face image issynthetic or real with high accuracy, they are also vulnerable to adversarialattacks. Although such attacks can be highly successful in evading detection byforensic classifiers, they introduce visible noise patterns that are detectablethrough careful human scrutiny. Additionally, these attacks assume access tothe target model(s) which may not always be true. Attempts have been made todirectly perturb the latent space of GANs to produce adversarial fake facesthat can circumvent forensic classifiers. In this work, we go one step furtherand show that it is possible to successfully generate adversarial fake faceswith a specified set of attributes (e.g., hair color, eye size, race, gender,etc.). To achieve this goal, we leverage the state-of-the-art generative modelStyleGAN with disentangled representations, which enables a range ofmodifications without leaving the manifold of natural images. We propose aframework to search for adversarial latent codes within the feature space ofStyleGAN, where the search can be guided either by a text prompt or a referenceimage. We also propose a meta-learning based optimization strategy to achievetransferable performance on unknown target models. Extensive experimentsdemonstrate that the proposed approach can produce semantically manipulatedadversarial fake faces, which are true to the specified attribute set and cansuccessfully fool forensic face classifiers, while remaining undetectable byhumans. Code: https://github.com/koushiksrivats/face_attribute_attack.</description><author>Fahad Shamshad, Koushik Srivatsan, Karthik Nandakumar</author><pubDate>Thu, 22 Jun 2023 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13091v1</guid></item><item><title>PromptIR: Prompting for All-in-One Blind Image Restoration</title><link>http://arxiv.org/abs/2306.13090v1</link><description>Image restoration involves recovering a high-quality clean image from itsdegraded version. Deep learning-based methods have significantly improved imagerestoration performance, however, they have limited generalization ability todifferent degradation types and levels. This restricts their real-worldapplication since it requires training individual models for each specificdegradation and knowing the input degradation type to apply the relevant model.We present a prompt-based learning approach, PromptIR, for All-In-One imagerestoration that can effectively restore images from various types and levelsof degradation. In particular, our method uses prompts to encodedegradation-specific information, which is then used to dynamically guide therestoration network. This allows our method to generalize to differentdegradation types and levels, while still achieving state-of-the-art results onimage denoising, deraining, and dehazing. Overall, PromptIR offers a genericand efficient plugin module with few lightweight prompts that can be used torestore images of various types and levels of degradation with no priorinformation on the corruptions present in the image. Our code and pretrainedmodels are available here: https://github.com/va1shn9v/PromptIR</description><author>Vaishnav Potlapalli, Syed Waqas Zamir, Salman Khan, Fahad Shahbaz Khan</author><pubDate>Thu, 22 Jun 2023 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13090v1</guid></item><item><title>Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting</title><link>http://arxiv.org/abs/2306.13085v1</link><description>Most offline reinforcement learning (RL) algorithms return a target policymaximizing a trade-off between (1) the expected performance gain over thebehavior policy that collected the dataset, and (2) the risk stemming from theout-of-distribution-ness of the induced state-action occupancy. It follows thatthe performance of the target policy is strongly related to the performance ofthe behavior policy and, thus, the trajectory return distribution of thedataset. We show that in mixed datasets consisting of mostly low-returntrajectories and minor high-return trajectories, state-of-the-art offline RLalgorithms are overly restrained by low-return trajectories and fail to exploithigh-performing trajectories to the fullest. To overcome this issue, we showthat, in deterministic MDPs with stochastic initial states, the datasetsampling can be re-weighted to induce an artificial dataset whose behaviorpolicy has a higher return. This re-weighted sampling strategy may be combinedwith any offline RL algorithm. We further analyze that the opportunity forperformance improvement over the behavior policy correlates with thepositive-sided variance of the returns of the trajectories in the dataset. Weempirically show that while CQL, IQL, and TD3+BC achieve only a part of thispotential policy improvement, these same algorithms combined with ourreweighted sampling strategy fully exploit the dataset. Furthermore, weempirically demonstrate that, despite its theoretical limitation, the approachmay still be efficient in stochastic environments. The code is available athttps://github.com/Improbable-AI/harness-offline-rl.</description><author>Zhang-Wei Hong, Pulkit Agrawal, RÃ©mi Tachet des Combes, Romain Laroche</author><pubDate>Thu, 22 Jun 2023 18:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13085v1</guid></item><item><title>Demystifying GPT Self-Repair for Code Generation</title><link>http://arxiv.org/abs/2306.09896v3</link><description>Large Language Models (LLMs) have shown remarkable aptitude in codegeneration but still struggle on challenging programming tasks. Self-repair --in which the model debugs and fixes mistakes in its own code -- has recentlybecome a popular way to boost performance in these settings. However, only verylimited studies on how and when self-repair works effectively exist in theliterature, and one might wonder to what extent a model is really capable ofproviding accurate feedback on why the code is wrong when that code wasgenerated by the same model. In this paper, we analyze GPT-3.5 and GPT-4'sability to perform self-repair on APPS, a challenging dataset consisting ofdiverse coding challenges. To do so, we first establish a new evaluationstrategy dubbed pass@t that measures the pass rate of the tasks against thetotal number of tokens sampled from the model, enabling a fair comparison topurely sampling-based approaches. With this evaluation strategy, we find thatthe effectiveness of self-repair is only seen in GPT-4. We also observe thatself-repair is bottlenecked by the feedback stage; using GPT-4 to give feedbackon the programs generated by GPT-3.5 and using expert human programmers to givefeedback on the programs generated by GPT-4, we unlock significant performancegains.</description><author>Theo X. Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, Armando Solar-Lezama</author><pubDate>Thu, 22 Jun 2023 18:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09896v3</guid></item><item><title>Continuous Layout Editing of Single Images with Diffusion Models</title><link>http://arxiv.org/abs/2306.13078v1</link><description>Recent advancements in large-scale text-to-image diffusion models haveenabled many applications in image editing. However, none of these methods havebeen able to edit the layout of single existing images. To address this gap, wepropose the first framework for layout editing of a single image whilepreserving its visual properties, thus allowing for continuous editing on asingle image. Our approach is achieved through two key modules. First, topreserve the characteristics of multiple objects within an image, wedisentangle the concepts of different objects and embed them into separatetextual tokens using a novel method called masked textual inversion. Next, wepropose a training-free optimization method to perform layout control for apre-trained diffusion model, which allows us to regenerate images with learnedconcepts and align them with user-specified layouts. As the first framework toedit the layout of existing images, we demonstrate that our method is effectiveand outperforms other baselines that were modified to support this task. Ourcode will be freely available for public use upon acceptance.</description><author>Zhiyuan Zhang, Zhitong Huang, Jing Liao</author><pubDate>Thu, 22 Jun 2023 18:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13078v1</guid></item><item><title>A Comparison of Time-based Models for Multimodal Emotion Recognition</title><link>http://arxiv.org/abs/2306.13076v1</link><description>Emotion recognition has become an important research topic in the field ofhuman-computer interaction. Studies on sound and videos to understand emotionsfocused mainly on analyzing facial expressions and classified 6 basic emotions.In this study, the performance of different sequence models in multi-modalemotion recognition was compared. The sound and images were first processed bymulti-layered CNN models, and the outputs of these models were fed into varioussequence models. The sequence model is GRU, Transformer, LSTM and Max Pooling.Accuracy, precision, and F1 Score values of all models were calculated. Themulti-modal CREMA-D dataset was used in the experiments. As a result of thecomparison of the CREMA-D dataset, GRU-based architecture with 0.640 showed thebest result in F1 score, LSTM-based architecture with 0.699 in precisionmetric, while sensitivity showed the best results over time with MaxPooling-based architecture with 0.620. As a result, it has been observed thatthe sequence models compare performances close to each other.</description><author>Ege Kesim, Selahattin Serdar Helli, Sena Nur Cavsak</author><pubDate>Thu, 22 Jun 2023 18:48:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13076v1</guid></item><item><title>Semi-automated extraction of research topics and trends from NCI funding in radiological sciences from 2000-2020</title><link>http://arxiv.org/abs/2306.13075v1</link><description>Investigators, funders, and the public desire knowledge on topics and trendsin publicly funded research but current efforts in manual categorization arelimited in scale and understanding. We developed a semi-automated approach toextract and name research topics, and applied this to \$1.9B of NCI fundingover 21 years in the radiological sciences to determine micro- and macro-scaleresearch topics and funding trends. Our method relies on sequential clusteringof existing biomedical-based word embeddings, naming using subject matterexperts, and visualization to discover trends at a macroscopic scale aboveindividual topics. We present results using 15 and 60 cluster topics, where wefound that 2D projection of grant embeddings reveals two dominant axes:physics-biology and therapeutic-diagnostic. For our dataset, we found thatfunding for therapeutics- and physics-based research have outpaced diagnostics-and biology-based research, respectively. We hope these results may (1) giveinsight to funders on the appropriateness of their funding allocation, (2)assist investigators in contextualizing their work and explore neighboringresearch domains, and (3) allow the public to review where their tax dollarsare being allocated.</description><author>Mark Nguyen, Peter Beidler, Joseph Tsai, August Anderson, Daniel Chen, Paul Kinahan, John Kang</author><pubDate>Thu, 22 Jun 2023 18:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13075v1</guid></item><item><title>Iterative Scale-Up ExpansionIoU and Deep Features Association for Multi-Object Tracking in Sports</title><link>http://arxiv.org/abs/2306.13074v1</link><description>Multi-object tracking algorithms have made significant advancements due tothe recent developments in object detection. However, most existing methodsprimarily focus on tracking pedestrians or vehicles, which exhibit relativelysimple and regular motion patterns. Consequently, there is a scarcity ofalgorithms that address the tracking of targets with irregular or non-linearmotion, such as multi-athlete tracking. Furthermore, popular trackingalgorithms often rely on the Kalman filter for object motion modeling, whichfails to track objects when their motion contradicts the linear motionassumption of the Kalman filter. Due to this reason, we proposed a novel onlineand robust multi-object tracking approach, named Iterative Scale-UpExpansionIoU and Deep Features for multi-object tracking. Unlike conventionalmethods, we abandon the use of the Kalman filter and propose utilizing theiterative scale-up expansion IoU. This approach achieves superior trackingperformance without requiring additional training data or adopting a morerobust detector, all while maintaining a lower computational cost compared toother appearance-based methods. Our proposed method demonstrates remarkableeffectiveness in tracking irregular motion objects, achieving a score of 75.3%in HOTA. It outperforms all state-of-the-art online tracking algorithms on theSportsMOT dataset, covering various kinds of sport scenarios.</description><author>Hsiang-Wei Huang, Cheng-Yen Yang, Jenq-Neng Hwang, Chung-I Huang</author><pubDate>Thu, 22 Jun 2023 18:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13074v1</guid></item><item><title>visClust: A visual clustering algorithm based on orthogonal projections</title><link>http://arxiv.org/abs/2211.03894v2</link><description>We present a novel clustering algorithm, visClust, that is based on lowerdimensional data representations and visual interpretation. Thereto, we designa transformation that allows the data to be represented by a binary integerarray enabling the further use of image processing methods to select apartition. Qualitative and quantitative analyses show that the algorithmobtains high accuracy (measured with an adjusted one-sided Rand-Index) andrequires low runtime and RAM. We compare the results to 6 state-of-the-artalgorithms, confirming the quality of visClust by outperforming in mostexperiments. Moreover, the algorithm asks for just one obligatory inputparameter while allowing optimization via optional parameters. The code is madeavailable on GitHub.</description><author>Anna Breger, Clemens Karner, Martin Ehler</author><pubDate>Thu, 22 Jun 2023 18:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.03894v2</guid></item><item><title>Auditing Predictive Models for Intersectional Biases</title><link>http://arxiv.org/abs/2306.13064v1</link><description>Predictive models that satisfy group fairness criteria in aggregate formembers of a protected class, but do not guarantee subgroup fairness, couldproduce biased predictions for individuals at the intersection of two or moreprotected classes. To address this risk, we propose Conditional Bias Scan(CBS), a flexible auditing framework for detecting intersectional biases inclassification models. CBS identifies the subgroup for which there is the mostsignificant bias against the protected class, as compared to the equivalentsubgroup in the non-protected class, and can incorporate multiple commonly usedfairness definitions for both probabilistic and binarized predictions. We showthat this methodology can detect previously unidentified intersectional andcontextual biases in the COMPAS pre-trial risk assessment tool and has higherbias detection power compared to similar methods that audit for subgroupfairness.</description><author>Kate S. Boxer, Edward McFowland III, Daniel B. Neill</author><pubDate>Thu, 22 Jun 2023 18:32:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13064v1</guid></item><item><title>Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs</title><link>http://arxiv.org/abs/2306.13063v1</link><description>The task of empowering large language models (LLMs) to accurately expresstheir confidence, referred to as confidence elicitation, is essential inensuring reliable and trustworthy decision-making processes. Previous methods,which primarily rely on model logits, have become less suitable for LLMs andeven infeasible with the rise of closed-source LLMs (e.g., commercialized LLMAPIs). This leads to a growing need to explore the untapped area of\emph{non-logit-based} approaches to estimate the uncertainty of LLMs. Hence,in this study, we investigate approaches for confidence elicitation that do notrequire model fine-tuning or access to proprietary information. We introducethree categories of methods: verbalize-based, consistency-based, and theirhybrid methods for benchmarking, and evaluate their performance across fivetypes of datasets and four widely-used LLMs. Our analysis of these methodsuncovers several key insights: 1) LLMs often exhibit a high degree ofoverconfidence when verbalizing their confidence; 2) Prompting strategies suchas CoT, Top-K and Multi-step confidences improve calibration of verbalizedconfidence; 3) Consistency-based methods outperform the verbalized confidencesin most cases, with particularly notable improvements on the arithmeticreasoning task; 4) Hybrid methods consistently deliver the best performanceover their baselines, thereby emerging as a promising state-of-the-artapproach; 5) Despite these advancements, all investigated methods continue tostruggle with challenging tasks, such as those requiring professionalknowledge, leaving significant scope for improvement of confidence elicitation.</description><author>Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, Bryan Hooi</author><pubDate>Thu, 22 Jun 2023 18:31:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13063v1</guid></item><item><title>Named entity recognition in resumes</title><link>http://arxiv.org/abs/2306.13062v1</link><description>Named entity recognition (NER) is used to extract information from variousdocuments and texts such as names and dates. It is important to extracteducation and work experience information from resumes in order to filter them.Considering the fact that all information in a resume has to be entered to thecompanys system manually, automatizing this process will save time of thecompanies. In this study, a deep learning-based semi-automatic named entityrecognition system has been implemented with a focus on resumes in the field ofIT. Firstly, resumes of employees from five different IT related fields hasbeen annotated. Six transformer based pre-trained models have been adapted tonamed entity recognition problem using the annotated data. These models havebeen selected among popular models in the natural language processing field.The obtained system can recognize eight different entity types which are city,date, degree, diploma major, job title, language, country and skill. Modelsused in the experiments are compared using micro, macro and weighted F1 scoresand the performance of the methods was evaluated. Taking these scores intoaccount for test set the best micro and weighted F1 score is obtained byRoBERTa and the best macro F1 score is obtained by Electra model.</description><author>Ege Kesim, Aysu Deliahmetoglu</author><pubDate>Thu, 22 Jun 2023 18:30:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13062v1</guid></item><item><title>Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms</title><link>http://arxiv.org/abs/2306.12383v2</link><description>In stochastic zeroth-order optimization, a problem of practical relevance isunderstanding how to fully exploit the local geometry of the underlyingobjective function. We consider a fundamental setting in which the objectivefunction is quadratic, and provide the first tight characterization of theoptimal Hessian-dependent sample complexity. Our contribution is twofold.First, from an information-theoretic point of view, we prove tight lower boundson Hessian-dependent complexities by introducing a concept called energyallocation, which captures the interaction between the searching algorithm andthe geometry of objective functions. A matching upper bound is obtained bysolving the optimal energy spectrum. Then, algorithmically, we show theexistence of a Hessian-independent algorithm that universally achieves theasymptotic optimal sample complexities for all Hessian instances. The optimalsample complexities achieved by our algorithm remain valid for heavy-tailednoise distributions, which are enabled by a truncation method.</description><author>Qian Yu, Yining Wang, Baihe Huang, Qi Lei, Jason D. Lee</author><pubDate>Thu, 22 Jun 2023 18:30:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12383v2</guid></item><item><title>SQ Lower Bounds for Learning Bounded Covariance GMMs</title><link>http://arxiv.org/abs/2306.13057v1</link><description>We study the complexity of learning mixtures of separated Gaussians withcommon unknown bounded covariance matrix. Specifically, we focus on learningGaussian mixture models (GMMs) on $\mathbb{R}^d$ of the form $P= \sum_{i=1}^kw_i \mathcal{N}(\boldsymbol \mu_i,\mathbf \Sigma_i)$, where $\mathbf \Sigma_i =\mathbf \Sigma \preceq \mathbf I$ and $\min_{i \neq j} \| \boldsymbol \mu_i -\boldsymbol \mu_j\|_2 \geq k^\epsilon$ for some $\epsilon&gt;0$. Known learningalgorithms for this family of GMMs have complexity $(dk)^{O(1/\epsilon)}$. Inthis work, we prove that any Statistical Query (SQ) algorithm for this problemrequires complexity at least $d^{\Omega(1/\epsilon)}$. In the special casewhere the separation is on the order of $k^{1/2}$, we additionally obtainfine-grained SQ lower bounds with the correct exponent. Our SQ lower boundsimply similar lower bounds for low-degree polynomial tests. Conceptually, ourresults provide evidence that known algorithms for this problem are nearly bestpossible.</description><author>Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis</author><pubDate>Thu, 22 Jun 2023 18:23:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13057v1</guid></item><item><title>Deep Metric Learning with Soft Orthogonal Proxies</title><link>http://arxiv.org/abs/2306.13055v1</link><description>Deep Metric Learning (DML) models rely on strong representations andsimilarity-based measures with specific loss functions. Proxy-based losses haveshown great performance compared to pair-based losses in terms of convergencespeed. However, proxies that are assigned to different classes may end up beingclosely located in the embedding space and hence having a hard time todistinguish between positive and negative items. Alternatively, they may becomehighly correlated and hence provide redundant information with the model. Toaddress these issues, we propose a novel approach that introduces SoftOrthogonality (SO) constraint on proxies. The constraint ensures the proxies tobe as orthogonal as possible and hence control their positions in the embeddingspace. Our approach leverages Data-Efficient Image Transformer (DeiT) as anencoder to extract contextual features from images along with a DML objective.The objective is made of the Proxy Anchor loss along with the SOregularization. We evaluate our method on four public benchmarks forcategory-level image retrieval and demonstrate its effectiveness withcomprehensive experimental results and ablation studies. Our evaluationsdemonstrate the superiority of our proposed approach over state-of-the-artmethods by a significant margin.</description><author>Farshad Saberi-Movahed, Mohammad K. Ebrahimpour, Farid Saberi-Movahed, Monireh Moshavash, Dorsa Rahmatian, Mahvash Mohazzebi, Mahdi Shariatzadeh, Mahdi Eftekhari</author><pubDate>Thu, 22 Jun 2023 18:22:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13055v1</guid></item><item><title>Quantum Pufferfish Privacy: A Flexible Privacy Framework for Quantum Systems</title><link>http://arxiv.org/abs/2306.13054v1</link><description>We propose a versatile privacy framework for quantum systems, termed quantumpufferfish privacy (QPP). Inspired by classical pufferfish privacy, ourformulation generalizes and addresses limitations of quantum differentialprivacy by offering flexibility in specifying private information, feasiblemeasurements, and domain knowledge. We show that QPP can be equivalentlyformulated in terms of the Datta-Leditzky information spectrum divergence, thusproviding the first operational interpretation thereof. We reformulate thisdivergence as a semi-definite program and derive several properties of it,which are then used to prove convexity, composability, and post-processing ofQPP mechanisms. Parameters that guarantee QPP of the depolarization mechanismare also derived. We analyze the privacy-utility tradeoff of general QPPmechanisms and, again, study the depolarization mechanism as an explicitinstance. The QPP framework is then applied to privacy auditing for identifyingprivacy violations via a hypothesis testing pipeline that leverages quantumalgorithms. Connections to quantum fairness and other quantum divergences arealso explored and several variants of QPP are examined.</description><author>Theshani Nuradha, Ziv Goldfeld, Mark M. Wilde</author><pubDate>Thu, 22 Jun 2023 18:21:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13054v1</guid></item><item><title>Context-lumpable stochastic bandits</title><link>http://arxiv.org/abs/2306.13053v1</link><description>We consider a contextual bandit problem with $S $ contexts and $A $ actions.In each round $t=1,2,\dots$ the learner observes a random context and choosesan action based on its past experience. The learner then observes a randomreward whose mean is a function of the context and the action for the round.Under the assumption that the contexts can be lumped into $r\le \min\{S ,A \}$groups such that the mean reward for the various actions is the same for anytwo contexts that are in the same group, we give an algorithm that outputs an$\epsilon$-optimal policy after using at most $\widetilde O(r (S +A)/\epsilon^2)$ samples with high probability and provide a matching$\widetilde\Omega(r (S +A )/\epsilon^2)$ lower bound. In the regretminimization setting, we give an algorithm whose cumulative regret up to time$T$ is bounded by $\widetilde O(\sqrt{r^3(S +A )T})$. To the best of ourknowledge, we are the first to show the near-optimal sample complexity in thePAC setting and $\widetilde O(\sqrt{{poly}(r)(S+K)T})$ minimax regret in theonline setting for this problem. We also show our algorithms can be applied tomore general low-rank bandits and get improved regret bounds in some scenarios.</description><author>Chung-Wei Lee, Qinghua Liu, Yasin Abbasi-Yadkori, Chi Jin, Tor Lattimore, Csaba SzepesvÃ¡ri</author><pubDate>Thu, 22 Jun 2023 18:20:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13053v1</guid></item><item><title>Data augmentation for recommender system: A semi-supervised approach using maximum margin matrix factorization</title><link>http://arxiv.org/abs/2306.13050v1</link><description>Collaborative filtering (CF) has become a popular method for developingrecommender systems (RS) where ratings of a user for new items is predictedbased on her past preferences and available preference information of otherusers. Despite the popularity of CF-based methods, their performance is oftengreatly limited by the sparsity of observed entries. In this study, we explorethe data augmentation and refinement aspects of Maximum Margin MatrixFactorization (MMMF), a widely accepted CF technique for the ratingpredictions, which have not been investigated before. We exploit the inherentcharacteristics of CF algorithms to assess the confidence level of individualratings and propose a semi-supervised approach for rating augmentation based onself-training. We hypothesize that any CF algorithm's predictions with lowconfidence are due to some deficiency in the training data and hence, theperformance of the algorithm can be improved by adopting a systematic dataaugmentation strategy. We iteratively use some of the ratings predicted withhigh confidence to augment the training data and remove low-confidence entriesthrough a refinement process. By repeating this process, the system learns toimprove prediction accuracy. Our method is experimentally evaluated on severalstate-of-the-art CF algorithms and leads to informative rating augmentation,improving the performance of the baseline approaches.</description><author>Shamal Shaikh, Venkateswara Rao Kagita, Vikas Kumar, Arun K Pujari</author><pubDate>Thu, 22 Jun 2023 18:17:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13050v1</guid></item><item><title>CamChoice: A Corpus of Multiple Choice Questions and Candidate Response Distributions</title><link>http://arxiv.org/abs/2306.13047v1</link><description>Multiple Choice examinations are a ubiquitous form of assessment that is usedto measure the ability of candidates across various domains and tasks.Maintaining the quality of proposed questions is of great importance to testdesigners, and therefore newly proposed questions go through several pre-testevaluation stages before they can be deployed into real-world exams. Thisprocess is currently quite manual, which can lead to time lags in the questiondevelopment cycle. Automating this process would lead to a large improvement inefficiency, however, current datasets do not contain sufficient pre-testanalysis information. In this paper, we introduce CamChoice; a multiple-choicecomprehension dataset with questions at different target levels, wherequestions have the true candidate selected options distributions. We introducethe task of candidate distribution matching, propose several evaluation metricsfor the task, and demonstrate that automatic systems trained on RACE++ can beleveraged as baselines for our task. We further demonstrate that theseautomatic systems can be used for practical pre-test evaluation tasks such asdetecting underperforming distractors, where our detection systems canautomatically identify poor distractors that few candidates select. We releasethe data publicly for future research.</description><author>Adian Liusie, Vatsal Raina, Andrew Mullooly, Kate Knill, Mark J. F. Gales</author><pubDate>Thu, 22 Jun 2023 18:13:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13047v1</guid></item><item><title>A One-Sample Decentralized Proximal Algorithm for Non-Convex Stochastic Composite Optimization</title><link>http://arxiv.org/abs/2302.09766v2</link><description>We focus on decentralized stochastic non-convex optimization, where $n$agents work together to optimize a composite objective function which is a sumof a smooth term and a non-smooth convex term. To solve this problem, wepropose two single-time scale algorithms: Prox-DASA and Prox-DASA-GT. Thesealgorithms can find $\epsilon$-stationary points in$\mathcal{O}(n^{-1}\epsilon^{-2})$ iterations using constant batch sizes (i.e.,$\mathcal{O}(1)$). Unlike prior work, our algorithms achieve comparablecomplexity without requiring large batch sizes, more complex per-iterationoperations (such as double loops), or stronger assumptions. Our theoreticalfindings are supported by extensive numerical experiments, which demonstratethe superiority of our algorithms over previous approaches. Our code isavailable at https://github.com/xuxingc/ProxDASA.</description><author>Tesi Xiao, Xuxing Chen, Krishnakumar Balasubramanian, Saeed Ghadimi</author><pubDate>Thu, 22 Jun 2023 18:12:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09766v2</guid></item><item><title>Multi-Task Learning with Loop Specific Attention for CDR Structure Prediction</title><link>http://arxiv.org/abs/2306.13045v1</link><description>The Complementarity Determining Region (CDR) structure prediction of loops inantibody engineering has gained a lot of attraction by researchers. Whendesigning antibodies, a main challenge is to predict the CDR structure of theH3 loop. Compared with the other CDR loops, that is the H1 and H2 loops, theCDR structure of the H3 loop is more challenging due to its varying length andflexible structure. In this paper, we propose a Multi-task learning model withLoop Specific Attention, namely MLSA. In particular, to the best of ourknowledge we are the first to jointly learn the three CDR loops, via a novelmulti-task learning strategy. In addition, to account for the structural andfunctional similarities and differences of the three CDR loops, we propose aloop specific attention mechanism to control the influence of each CDR loop onthe training of MLSA. Our experimental evaluation on widely used benchmark datashows that the proposed MLSA method significantly reduces the prediction errorof the CDR structure of the H3 loop, by at least 19%, when compared with otherbaseline strategies. Finally, for reproduction purposes we make theimplementation of MLSA publicly available athttps://anonymous.4open.science/r/MLSA-2442/.</description><author>Eleni Giovanoudi, Dimitrios Rafailidis</author><pubDate>Thu, 22 Jun 2023 18:11:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13045v1</guid></item><item><title>Towards Explainable Evaluation Metrics for Machine Translation</title><link>http://arxiv.org/abs/2306.13041v1</link><description>Unlike classical lexical overlap metrics such as BLEU, most currentevaluation metrics for machine translation (for example, COMET or BERTScore)are based on black-box large language models. They often achieve strongcorrelations with human judgments, but recent research indicates that thelower-quality classical metrics remain dominant, one of the potential reasonsbeing that their decision processes are more transparent. To foster morewidespread acceptance of novel high-quality metrics, explainability thusbecomes crucial. In this concept paper, we identify key properties as well askey goals of explainable machine translation metrics and provide acomprehensive synthesis of recent techniques, relating them to our establishedgoals and properties. In this context, we also discuss the lateststate-of-the-art approaches to explainable metrics based on generative modelssuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generationapproaches, including natural language explanations. We hope that our work canhelp catalyze and guide future research on explainable evaluation metrics and,mediately, also contribute to better and more transparent machine translationsystems.</description><author>Christoph Leiter, Piyawat Lertvittayakumjorn, Marina Fomicheva, Wei Zhao, Yang Gao, Steffen Eger</author><pubDate>Thu, 22 Jun 2023 18:07:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13041v1</guid></item><item><title>VL-CheckList: Evaluating Pre-trained Vision-Language Models with Objects, Attributes and Relations</title><link>http://arxiv.org/abs/2207.00221v2</link><description>Vision-Language Pretraining (VLP) models have recently successfullyfacilitated many cross-modal downstream tasks. Most existing works evaluatedtheir systems by comparing the fine-tuned downstream task performance. However,only average downstream task accuracy provides little information about thepros and cons of each VLP method, let alone provides insights on how thecommunity can improve the systems in the future. Inspired by the CheckList fortesting natural language processing, we exploit VL-CheckList, a novel frameworkto understand the capabilities of VLP models. The proposed method divides theimage-texting ability of a VLP model into three categories: objects,attributes, and relations, and uses a novel taxonomy to further break downthese three aspects. We conduct comprehensive studies to analyze seven recentlypopular VLP models via the proposed framework. Results confirm theeffectiveness of the proposed method by revealing fine-grained differencesamong the compared models that were not visible from downstream task-onlyevaluation. Further results show promising research direction in buildingbetter VLP models. Our data and code are available at:https://github.com/om-ai-lab/VL-CheckList.</description><author>Tiancheng Zhao, Tianqi Zhang, Mingwei Zhu, Haozhan Shen, Kyusong Lee, Xiaopeng Lu, Jianwei Yin</author><pubDate>Thu, 22 Jun 2023 17:55:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.00221v2</guid></item><item><title>PyKoopman: A Python Package for Data-Driven Approximation of the Koopman Operator</title><link>http://arxiv.org/abs/2306.12962v1</link><description>PyKoopman is a Python package for the data-driven approximation of theKoopman operator associated with a dynamical system. The Koopman operator is aprincipled linear embedding of nonlinear dynamics and facilitates theprediction, estimation, and control of strongly nonlinear dynamics using linearsystems theory. In particular, PyKoopman provides tools for data-driven systemidentification for unforced and actuated systems that build on theequation-free dynamic mode decomposition (DMD) and its variants. In this work,we provide a brief description of the mathematical underpinnings of the Koopmanoperator, an overview and demonstration of the features implemented inPyKoopman (with code examples), practical advice for users, and a list ofpotential extensions to PyKoopman. Software is available athttp://github.com/dynamicslab/pykoopman</description><author>Shaowu Pan, Eurika Kaiser, Brian M. de Silva, J. Nathan Kutz, Steven L. Brunton</author><pubDate>Thu, 22 Jun 2023 17:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12962v1</guid></item><item><title>Impacts and Risk of Generative AI Technology on Cyber Defense</title><link>http://arxiv.org/abs/2306.13033v1</link><description>Generative Artificial Intelligence (GenAI) has emerged as a powerfultechnology capable of autonomously producing highly realistic content invarious domains, such as text, images, audio, and videos. With its potentialfor positive applications in creative arts, content generation, virtualassistants, and data synthesis, GenAI has garnered significant attention andadoption. However, the increasing adoption of GenAI raises concerns about itspotential misuse for crafting convincing phishing emails, generatingdisinformation through deepfake videos, and spreading misinformation viaauthentic-looking social media posts, posing a new set of challenges and risksin the realm of cybersecurity. To combat the threats posed by GenAI, we proposeleveraging the Cyber Kill Chain (CKC) to understand the lifecycle ofcyberattacks, as a foundational model for cyber defense. This paper aims toprovide a comprehensive analysis of the risk areas introduced by the offensiveuse of GenAI techniques in each phase of the CKC framework. We also analyze thestrategies employed by threat actors and examine their utilization throughoutdifferent phases of the CKC, highlighting the implications for cyber defense.Additionally, we propose GenAI-enabled defense strategies that are bothattack-aware and adaptive. These strategies encompass various techniques suchas detection, deception, and adversarial training, among others, aiming toeffectively mitigate the risks posed by GenAI-induced cyber threats.</description><author>Subash Neupane, Ivan A. Fernandez, Sudip Mittal, Shahram Rahimi</author><pubDate>Thu, 22 Jun 2023 17:51:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13033v1</guid></item><item><title>Online Self-Supervised Learning in Machine Learning Intrusion Detection for the Internet of Things</title><link>http://arxiv.org/abs/2306.13030v1</link><description>This paper proposes a novel Self-Supervised Intrusion Detection (SSID)framework, which enables a fully online Machine Learning (ML) based IntrusionDetection System (IDS) that requires no human intervention or prior off-linelearning. The proposed framework analyzes and labels incoming traffic packetsbased only on the decisions of the IDS itself using an Auto-Associative DeepRandom Neural Network, and on an online estimate of its statistically measuredtrustworthiness. The SSID framework enables IDS to adapt rapidly totime-varying characteristics of the network traffic, and eliminates the needfor offline data collection. This approach avoids human errors in datalabeling, and human labor and computational costs of model training and datacollection. The approach is experimentally evaluated on public datasets andcompared with well-known ML models, showing that this SSID framework is veryuseful and advantageous as an accurate and online learning ML-based IDS for IoTsystems.</description><author>Mert NakÄ±p, Erol Gelenbe</author><pubDate>Thu, 22 Jun 2023 17:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13030v1</guid></item><item><title>Decentralized Online Federated G-Network Learning for Lightweight Intrusion Detection</title><link>http://arxiv.org/abs/2306.13029v1</link><description>Cyberattacks are increasingly threatening networked systems, often with theemergence of new types of unknown (zero-day) attacks and the rise of vulnerabledevices. While Machine Learning (ML)-based Intrusion Detection Systems (IDSs)have been shown to be extremely promising in detecting these attacks, the needto learn large amounts of labelled data often limits the applicability ofML-based IDSs to cybersystems that only have access to private local data. Toaddress this issue, this paper proposes a novel Decentralized and OnlineFederated Learning Intrusion Detection (DOF-ID) architecture. DOF-ID is acollaborative learning system that allows each IDS used for a cybersystem tolearn from experience gained in other cybersystems in addition to its own localdata without violating the data privacy of other systems. As the performanceevaluation results using public Kitsune and Bot-IoT datasets show, DOF-IDsignificantly improves the intrusion detection performance in all collaboratingnodes simultaneously with acceptable computation time for online learning.</description><author>Mert NakÄ±p, Baran Can GÃ¼l, Erol Gelenbe</author><pubDate>Thu, 22 Jun 2023 17:46:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13029v1</guid></item><item><title>Transferable Curricula through Difficulty Conditioned Generators</title><link>http://arxiv.org/abs/2306.13028v1</link><description>Advancements in reinforcement learning (RL) have demonstrated superhumanperformance in complex tasks such as Starcraft, Go, Chess etc. However,knowledge transfer from Artificial "Experts" to humans remain a significantchallenge. A promising avenue for such transfer would be the use of curricula.Recent methods in curricula generation focuses on training RL agentsefficiently, yet such methods rely on surrogate measures to track studentprogress, and are not suited for training robots in the real world (or moreambitiously humans). In this paper, we introduce a method named ParameterizedEnvironment Response Model (PERM) that shows promising results in training RLagents in parameterized environments. Inspired by Item Response Theory, PERMseeks to model difficulty of environments and ability of RL agents directly.Given that RL agents and humans are trained more efficiently under the "zone ofproximal development", our method generates a curriculum by matching thedifficulty of an environment to the current ability of the student. Inaddition, PERM can be trained offline and does not employ non-stationarymeasures of student ability, making it suitable for transfer between students.We demonstrate PERM's ability to represent the environment parameter space, andtraining with RL agents with PERM produces a strong performance indeterministic environments. Lastly, we show that our method is transferablebetween students, without any sacrifice in training quality.</description><author>Sidney Tio, Pradeep Varakantham</author><pubDate>Thu, 22 Jun 2023 17:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13028v1</guid></item><item><title>Active Inference in Hebbian Learning Networks</title><link>http://arxiv.org/abs/2306.05053v2</link><description>This work studies how brain-inspired neural ensembles equipped with localHebbian plasticity can perform active inference (AIF) in order to controldynamical agents. A generative model capturing the environment dynamics islearned by a network composed of two distinct Hebbian ensembles: a posteriornetwork, which infers latent states given the observations, and a statetransition network, which predicts the next expected latent state given currentstate-action pairs. Experimental studies are conducted using the Mountain Carenvironment from the OpenAI gym suite, to study the effect of the variousHebbian network parameters on the task performance. It is shown that theproposed Hebbian AIF approach outperforms the use of Q-learning, while notrequiring any replay buffer, as in typical reinforcement learning systems.These results motivate further investigations of Hebbian learning for thedesign of AIF networks that can learn environment dynamics without the need forrevisiting past buffered experiences.</description><author>Ali Safa, Tim Verbelen, Lars Keuninckx, Ilja Ocket, AndrÃ© Bourdoux, Francky Catthoor, Georges Gielen, Gert Cauwenberghs</author><pubDate>Thu, 22 Jun 2023 17:34:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05053v2</guid></item><item><title>Efficient Learning of Locomotion Skills through the Discovery of Diverse Environmental Trajectory Generator Priors</title><link>http://arxiv.org/abs/2210.04819v2</link><description>Data-driven learning based methods have recently been particularly successfulat learning robust locomotion controllers for a variety of unstructuredterrains. Prior work has shown that incorporating good locomotion priors in theform of trajectory generators (TGs) is effective at efficiently learningcomplex locomotion skills. However, defining a good, single TG astasks/environments become increasingly more complex remains a challengingproblem as it requires extensive tuning and risks reducing the effectiveness ofthe prior. In this paper, we present Evolved Environmental TrajectoryGenerators (EETG), a method that learns a diverse set of specialised locomotionpriors using Quality-Diversity algorithms while maintaining a single policywithin the Policies Modulating TG (PMTG) architecture. The results demonstratethat EETG enables a quadruped robot to successfully traverse a wide range ofenvironments, such as slopes, stairs, rough terrain, and balance beams. Ourexperiments show that learning a diverse set of specialized TG priors issignificantly (5 times) more efficient than using a single, fixed prior whendealing with a wide range of environments.</description><author>Shikha Surana, Bryan Lim, Antoine Cully</author><pubDate>Thu, 22 Jun 2023 17:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04819v2</guid></item><item><title>AugDMC: Data Augmentation Guided Deep Multiple Clustering</title><link>http://arxiv.org/abs/2306.13023v1</link><description>Clustering aims to group similar objects together while separating dissimilarones apart. Thereafter, structures hidden in data can be identified to helpunderstand data in an unsupervised manner. Traditional clustering methods suchas k-means provide only a single clustering for one data set. Deep clusteringmethods such as auto-encoder based clustering methods have shown a betterperformance, but still provide a single clustering. However, a given datasetmight have multiple clustering structures and each represents a uniqueperspective of the data. Therefore, some multiple clustering methods have beendeveloped to discover multiple independent structures hidden in data. Althoughdeep multiple clustering methods provide better performance, how to efficientlycapture the alternative perspectives in data is still a problem. In this paper,we propose AugDMC, a novel data Augmentation guided Deep Multiple Clusteringmethod, to tackle the challenge. Specifically, AugDMC leverages dataaugmentations to automatically extract features related to a certain aspect ofthe data using a self-supervised prototype-based representation learning, wheredifferent aspects of the data can be preserved under different dataaugmentations. Moreover, a stable optimization strategy is proposed toalleviate the unstable problem from different augmentations. Thereafter,multiple clusterings based on different aspects of the data can be obtained.Experimental results on three real-world datasets compared withstate-of-the-art methods validate the effectiveness of the proposed method.</description><author>Jiawei Yao, Enbei Liu, Maham Rashid, Juhua Hu</author><pubDate>Thu, 22 Jun 2023 17:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13023v1</guid></item><item><title>Toward Automated Detection of Microbleeds with Anatomical Scale Localization: A Complete Clinical Diagnosis Support Using Deep Learning</title><link>http://arxiv.org/abs/2306.13020v1</link><description>Cerebral Microbleeds (CMBs) are chronic deposits of small blood products inthe brain tissues, which have explicit relation to various cerebrovasculardiseases depending on their anatomical location, including cognitive decline,intracerebral hemorrhage, and cerebral infarction. However, manual detection ofCMBs is a time-consuming and error-prone process because of their sparse andtiny structural properties. The detection of CMBs is commonly affected by thepresence of many CMB mimics that cause a high false-positive rate (FPR), suchas calcification and pial vessels. This paper proposes a novel 3D deep learningframework that does not only detect CMBs but also inform their anatomicallocation in the brain (i.e., lobar, deep, and infratentorial regions). For theCMB detection task, we propose a single end-to-end model by leveraging theU-Net as a backbone with Region Proposal Network (RPN). To significantly reducethe FPs within the same single model, we develop a new scheme, containingFeature Fusion Module (FFM) that detects small candidates utilizing contextualinformation and Hard Sample Prototype Learning (HSPL) that mines CMB mimics andgenerates additional loss term called concentration loss using ConvolutionalPrototype Learning (CPL). The anatomical localization task does not only tellto which region the CMBs belong but also eliminate some FPs from the detectiontask by utilizing anatomical information. The results show that the proposedRPN that utilizes the FFM and HSPL outperforms the vanilla RPN and achieves asensitivity of 94.66% vs. 93.33% and an average number of false positives persubject (FPavg) of 0.86 vs. 14.73. Also, the anatomical localization taskfurther improves the detection performance by reducing the FPavg to 0.56 whilemaintaining the sensitivity of 94.66%.</description><author>Jun-Ho Kim, Young Noh, Haejoon Lee, Seul Lee, Woo-Ram Kim, Koung Mi Kang, Eung Yeop Kim, Mohammed A. Al-masni, Dong-Hyun Kim</author><pubDate>Thu, 22 Jun 2023 17:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13020v1</guid></item><item><title>Sharp analysis of EM for learning mixtures of pairwise differences</title><link>http://arxiv.org/abs/2302.10066v2</link><description>We consider a symmetric mixture of linear regressions with random samplesfrom the pairwise comparison design, which can be seen as a noisy version of atype of Euclidean distance geometry problem. We analyze theexpectation-maximization (EM) algorithm locally around the ground truth andestablish that the sequence converges linearly, providing an $\ell_\infty$-normguarantee on the estimation error of the iterates. Furthermore, we show thatthe limit of the EM sequence achieves the sharp rate of estimation in the$\ell_2$-norm, matching the information-theoretically optimal constant. We alsoargue through simulation that convergence from a random initialization is muchmore delicate in this setting, and does not appear to occur in general. Ourresults show that the EM algorithm can exhibit several unique behaviors whenthe covariate distribution is suitably structured.</description><author>Abhishek Dhawan, Cheng Mao, Ashwin Pananjady</author><pubDate>Thu, 22 Jun 2023 17:22:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10066v2</guid></item><item><title>Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories</title><link>http://arxiv.org/abs/2210.06518v3</link><description>Natural agents can effectively learn from multiple data sources that differin size, quality, and types of measurements. We study this heterogeneity in thecontext of offline reinforcement learning (RL) by introducing a new,practically motivated semi-supervised setting. Here, an agent has access to twosets of trajectories: labelled trajectories containing state, action and rewardtriplets at every timestep, along with unlabelled trajectories that containonly state and reward information. For this setting, we develop and study asimple meta-algorithmic pipeline that learns an inverse dynamics model on thelabelled data to obtain proxy-labels for the unlabelled data, followed by theuse of any offline RL algorithm on the true and proxy-labelled trajectories.Empirically, we find this simple pipeline to be highly successful -- on severalD4RL benchmarks~\cite{fu2020d4rl}, certain offline RL algorithms can match theperformance of variants trained on a fully labelled dataset even when we labelonly 10\% of trajectories which are highly suboptimal. To strengthen ourunderstanding, we perform a large-scale controlled empirical studyinvestigating the interplay of data-centric properties of the labelled andunlabelled datasets, with algorithmic design choices (e.g., choice of inversedynamics, offline RL algorithm) to identify general trends and best practicesfor training RL agents on semi-supervised offline datasets.</description><author>Qinqing Zheng, Mikael Henaff, Brandon Amos, Aditya Grover</author><pubDate>Thu, 22 Jun 2023 17:12:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06518v3</guid></item><item><title>Can Differentiable Decision Trees Learn Interpretable Reward Functions?</title><link>http://arxiv.org/abs/2306.13004v1</link><description>There is an increasing interest in learning reward functions that model humanintent and human preferences. However, many frameworks use blackbox learningmethods that, while expressive, are difficult to interpret. We propose andevaluate a novel approach for learning expressive and interpretable rewardfunctions from preferences using Differentiable Decision Trees (DDTs) for bothlow- and high-dimensional state inputs. We explore and discuss the viability oflearning interpretable reward functions using DDTs by evaluating our algorithmon Cartpole, Visual Gridworld environments, and Atari games. We provideevidence that that the tree structure of our learned reward function is usefulin determining the extent to which a reward function is aligned with humanpreferences. We visualize the learned reward DDTs and find that they arecapable of learning interpretable reward functions but that the discrete natureof the trees hurts the performance of reinforcement learning at test time.However, we also show evidence that using soft outputs (averaged over all leafnodes) results in competitive performance when compared with larger capacitydeep neural network reward functions.</description><author>Akansha Kalra, Daniel S. Brown</author><pubDate>Thu, 22 Jun 2023 17:04:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13004v1</guid></item><item><title>RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows</title><link>http://arxiv.org/abs/2306.06034v2</link><description>Physics-informed neural networks (PINNs) provide a framework to buildsurrogate models for dynamical systems governed by differential equations.During the learning process, PINNs incorporate a physics-based regularizationterm within the loss function to enhance generalization performance. Sincesimulating dynamics controlled by partial differential equations (PDEs) can becomputationally expensive, PINNs have gained popularity in learning parametricsurrogates for fluid flow problems governed by Navier-Stokes equations. In thiswork, we introduce RANS-PINN, a modified PINN framework, to predict flow fields(i.e., velocity and pressure) in high Reynolds number turbulent flow regime. Toaccount for the additional complexity introduced by turbulence, RANS-PINNemploys a 2-equation eddy viscosity model based on a Reynolds-averagedNavier-Stokes (RANS) formulation. Furthermore, we adopt a novel trainingapproach that ensures effective initialization and balance among the variouscomponents of the loss function. The effectiveness of RANS-PINN framework isthen demonstrated using a parametric PINN.</description><author>Shinjan Ghosh, Amit Chakraborty, Georgia Olympia Brikis, Biswadip Dey</author><pubDate>Thu, 22 Jun 2023 17:03:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06034v2</guid></item><item><title>Apolitical Intelligence? Auditing Delphi's responses on controversial political issues in the US</title><link>http://arxiv.org/abs/2306.13000v1</link><description>As generative language models are deployed in ever-wider contexts, concernsabout their political values have come to the forefront with critique from allparts of the political spectrum that the models are biased and lack neutrality.However, the question of what neutrality is and whether it is desirable remainsunderexplored. In this paper, I examine neutrality through an audit of Delphi[arXiv:2110.07574], a large language model designed for crowdsourced ethics. Ianalyse how Delphi responds to politically controversial questions compared todifferent US political subgroups. I find that Delphi is poorly calibrated withrespect to confidence and exhibits a significant political skew. Based on theseresults, I examine the question of neutrality from a data-feminist lens, interms of how notions of neutrality shift power and further marginalise unheardvoices. These findings can hopefully contribute to a more reflexive debateabout the normative questions of alignment and what role we want generativemodels to play in society.</description><author>Jonathan H. RystrÃ¸m</author><pubDate>Thu, 22 Jun 2023 16:56:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13000v1</guid></item><item><title>Affine Correspondences between Multi-Camera Systems for Relative Pose Estimation</title><link>http://arxiv.org/abs/2306.12996v1</link><description>We present a novel method to compute the relative pose of multi-camerasystems using two affine correspondences (ACs). Existing solutions to themulti-camera relative pose estimation are either restricted to special cases ofmotion, have too high computational complexity, or require too many pointcorrespondences (PCs). Thus, these solvers impede an efficient or accuraterelative pose estimation when applying RANSAC as a robust estimator. This papershows that the 6DOF relative pose estimation problem using ACs permits afeasible minimal solution, when exploiting the geometric constraints betweenACs and multi-camera systems using a special parameterization. We present aproblem formulation based on two ACs that encompass two common types of ACsacross two views, i.e., inter-camera and intra-camera. Moreover, the frameworkfor generating the minimal solvers can be extended to solve various relativepose estimation problems, e.g., 5DOF relative pose estimation with knownrotation angle prior. Experiments on both virtual and real multi-camera systemsprove that the proposed solvers are more efficient than the state-of-the-artalgorithms, while resulting in a better relative pose accuracy. Source code isavailable at https://github.com/jizhaox/relpose-mcs-depth.</description><author>Banglei Guan, Ji Zhao</author><pubDate>Thu, 22 Jun 2023 16:52:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12996v1</guid></item><item><title>AI Security for Geoscience and Remote Sensing: Challenges and Future Trends</title><link>http://arxiv.org/abs/2212.09360v2</link><description>Recent advances in artificial intelligence (AI) have significantlyintensified research in the geoscience and remote sensing (RS) field. AIalgorithms, especially deep learning-based ones, have been developed andapplied widely to RS data analysis. The successful application of AI coversalmost all aspects of Earth observation (EO) missions, from low-level visiontasks like super-resolution, denoising and inpainting, to high-level visiontasks like scene classification, object detection and semantic segmentation.While AI techniques enable researchers to observe and understand the Earth moreaccurately, the vulnerability and uncertainty of AI models deserve furtherattention, considering that many geoscience and RS tasks are highlysafety-critical. This paper reviews the current development of AI security inthe geoscience and RS field, covering the following five important aspects:adversarial attack, backdoor attack, federated learning, uncertainty andexplainability. Moreover, the potential opportunities and trends are discussedto provide insights for future research. To the best of the authors' knowledge,this paper is the first attempt to provide a systematic review of AIsecurity-related research in the geoscience and RS community. Available codeand datasets are also listed in the paper to move this vibrant field ofresearch forward.</description><author>Yonghao Xu, Tao Bai, Weikang Yu, Shizhen Chang, Peter M. Atkinson, Pedram Ghamisi</author><pubDate>Thu, 22 Jun 2023 16:51:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09360v2</guid></item><item><title>Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers</title><link>http://arxiv.org/abs/2306.12992v1</link><description>High-quality panoramic images with a Field of View (FoV) of 360-degree areessential for contemporary panoramic computer vision tasks. However,conventional imaging systems come with sophisticated lens designs and heavyoptical components. This disqualifies their usage in many mobile and wearableapplications where thin and portable, minimalist imaging systems are desired.In this paper, we propose a Panoramic Computational Imaging Engine (PCIE) toaddress minimalist and high-quality panoramic imaging. With less than threespherical lenses, a Minimalist Panoramic Imaging Prototype (MPIP) isconstructed based on the design of the Panoramic Annular Lens (PAL), but withlow-quality imaging results due to aberrations and small image plane size. Wepropose two pipelines, i.e. Aberration Correction (AC) and Super-Resolution andAberration Correction (SR&amp;AC), to solve the image quality problems of MPIP,with imaging sensors of small and large pixel size, respectively. To provide auniversal network for the two pipelines, we leverage the information from thePoint Spread Function (PSF) of the optical system and design a PSF-awareAberration-image Recovery Transformer (PART), in which the self-attentioncalculation and feature extraction are guided via PSF-aware mechanisms. Wetrain PART on synthetic image pairs from simulation and put forward the PALHQdataset to fill the gap of real-world high-quality PAL images for low-levelvision. A comprehensive variety of experiments on synthetic and real-worldbenchmarks demonstrates the impressive imaging results of PCIE and theeffectiveness of plug-and-play PSF-aware mechanisms. We further deliverheuristic experimental findings for minimalist and high-quality panoramicimaging. Our dataset and code will be available athttps://github.com/zju-jiangqi/PCIE-PART.</description><author>Qi Jiang, Shaohua Gao, Yao Gao, Kailun Yang, Zhonghua Yi, Hao Shi, Lei Sun, Kaiwei Wang</author><pubDate>Thu, 22 Jun 2023 16:47:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12992v1</guid></item><item><title>Speech Emotion Diarization: Which Emotion Appears When?</title><link>http://arxiv.org/abs/2306.12991v1</link><description>Speech Emotion Recognition (SER) typically relies on utterance-levelsolutions. However, emotions conveyed through speech should be considered asdiscrete speech events with definite temporal boundaries, rather thanattributes of the entire utterance. To reflect the fine-grained nature ofspeech emotions, we propose a new task: Speech Emotion Diarization (SED). Justas Speaker Diarization answers the question of "Who speaks when?", SpeechEmotion Diarization answers the question of "Which emotion appears when?". Tofacilitate the evaluation of the performance and establish a common benchmarkfor researchers, we introduce the Zaion Emotion Dataset (ZED), an openlyaccessible speech emotion dataset that includes non-acted emotions recorded inreal-life conditions, along with manually-annotated boundaries of emotionsegments within the utterance. We provide competitive baselines and open-sourcethe code and the pre-trained models.</description><author>Yingzhi Wang, Mirco Ravanelli, Alaa Nfissi, Alya Yacoubi</author><pubDate>Thu, 22 Jun 2023 16:47:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12991v1</guid></item><item><title>Can a single image processing algorithm work equally well across all phases of DCE-MRI?</title><link>http://arxiv.org/abs/2306.12988v1</link><description>Image segmentation and registration are said to be challenging when appliedto dynamic contrast enhanced MRI sequences (DCE-MRI). The contrast agent causesrapid changes in intensity in the region of interest and elsewhere, which canlead to false positive predictions for segmentation tasks and confound theimage registration similarity metric. While it is widely assumed that contrastchanges increase the difficulty of these tasks, to our knowledge no work hasquantified these effects. In this paper we examine the effect of training withdifferent ratios of contrast enhanced (CE) data on two popular tasks:segmentation with nnU-Net and Mask R-CNN and registration using VoxelMorph andVTN. We experimented further by strategically using the available datasetsthrough pretraining and fine tuning with different splits of data. We foundthat to create a generalisable model, pretraining with CE data and fine tuningwith non-CE data gave the best result. This interesting find could be expandedto other deep learning based image processing tasks with DCE-MRI and providesignificant improvements to the models performance.</description><author>Adam G. Tattersall, Keith A. Goatman, Lucy E. Kershaw, Scott I. K. Semple, Sonia Dahdouh</author><pubDate>Thu, 22 Jun 2023 16:44:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12988v1</guid></item><item><title>Mixed-TD: Efficient Neural Network Accelerator with Layer-Specific Tensor Decomposition</title><link>http://arxiv.org/abs/2306.05021v2</link><description>Neural Network designs are quite diverse, from VGG-style to ResNet-style, andfrom Convolutional Neural Networks to Transformers. Towards the design ofefficient accelerators, many works have adopted a dataflow-based, inter-layerpipelined architecture, with a customised hardware towards each layer,achieving ultra high throughput and low latency. The deployment of neuralnetworks to such dataflow architecture accelerators is usually hindered by theavailable on-chip memory as it is desirable to preload the weights of neuralnetworks on-chip to maximise the system performance. To address this, networksare usually compressed before the deployment through methods such as pruning,quantization and tensor decomposition. In this paper, a framework for mappingCNNs onto FPGAs based on a novel tensor decomposition method called Mixed-TD isproposed. The proposed method applies layer-specific Singular ValueDecomposition (SVD) and Canonical Polyadic Decomposition (CPD) in a mixedmanner, achieving 1.73x to 10.29x throughput per DSP to state-of-the-art CNNs.Our work is open-sourced: https://github.com/Yu-Zhewen/Mixed-TD</description><author>Zhewen Yu, Christos-Savvas Bouganis</author><pubDate>Thu, 22 Jun 2023 16:44:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05021v2</guid></item><item><title>Backdoor Attacks for Remote Sensing Data with Wavelet Transform</title><link>http://arxiv.org/abs/2211.08044v2</link><description>Recent years have witnessed the great success of deep learning algorithms inthe geoscience and remote sensing realm. Nevertheless, the security androbustness of deep learning models deserve special attention when addressingsafety-critical remote sensing tasks. In this paper, we provide a systematicanalysis of backdoor attacks for remote sensing data, where both sceneclassification and semantic segmentation tasks are considered. While most ofthe existing backdoor attack algorithms rely on visible triggers like squaredpatches with well-designed patterns, we propose a novel wavelet transform-basedattack (WABA) method, which can achieve invisible attacks by injecting thetrigger image into the poisoned image in the low-frequency domain. In this way,the high-frequency information in the trigger image can be filtered out in theattack, resulting in stealthy data poisoning. Despite its simplicity, theproposed method can significantly cheat the current state-of-the-art deeplearning models with a high attack success rate. We further analyze howdifferent trigger images and the hyper-parameters in the wavelet transformwould influence the performance of the proposed method. Extensive experimentson four benchmark remote sensing datasets demonstrate the effectiveness of theproposed method for both scene classification and semantic segmentation tasksand thus highlight the importance of designing advanced backdoor defensealgorithms to address this threat in remote sensing scenarios. The code will beavailable online at \url{https://github.com/ndraeger/waba}.</description><author>Nikolaus DrÃ¤ger, Yonghao Xu, Pedram Ghamisi</author><pubDate>Thu, 22 Jun 2023 16:43:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.08044v2</guid></item><item><title>Inferring the finest pattern of mutual independence from data</title><link>http://arxiv.org/abs/2306.12984v1</link><description>For a random variable $X$, we are interested in the blind extraction of itsfinest mutual independence pattern $\mu ( X )$. We introduce a specific kind ofindependence that we call dichotomic. If $\Delta ( X )$ stands for the set ofall patterns of dichotomic independence that hold for $X$, we show that $\mu (X )$ can be obtained as the intersection of all elements of $\Delta ( X )$. Wethen propose a method to estimate $\Delta ( X )$ when the data are independentand identically (i.i.d.) realizations of a multivariate normal distribution. If$\hat{\Delta} ( X )$ is the estimated set of valid patterns of dichotomicindependence, we estimate $\mu ( X )$ as the intersection of all patterns of$\hat{\Delta} ( X )$. The method is tested on simulated data, showing itsadvantages and limits. We also consider an application to a toy example as wellas to experimental data.</description><author>G. Marrelec, A. Giron</author><pubDate>Thu, 22 Jun 2023 16:41:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12984v1</guid></item><item><title>Towards More Realistic Membership Inference Attacks on Large Diffusion Models</title><link>http://arxiv.org/abs/2306.12983v1</link><description>Generative diffusion models, including Stable Diffusion and Midjourney, cangenerate visually appealing, diverse, and high-resolution images for variousapplications. These models are trained on billions of internet-sourced images,raising significant concerns about the potential unauthorized use ofcopyright-protected images. In this paper, we examine whether it is possible todetermine if a specific image was used in the training set, a problem known inthe cybersecurity community and referred to as a membership inference attack.Our focus is on Stable Diffusion, and we address the challenge of designing afair evaluation framework to answer this membership question. We propose amethodology to establish a fair evaluation setup and apply it to StableDiffusion, enabling potential extensions to other generative models. Utilizingthis evaluation setup, we execute membership attacks (both known and newlyintroduced). Our research reveals that previously proposed evaluation setups donot provide a full understanding of the effectiveness of membership inferenceattacks. We conclude that the membership inference attack remains a significantchallenge for large diffusion models (often deployed as black-box systems),indicating that related privacy and copyright issues will persist in theforeseeable future.</description><author>Jan DubiÅski, Antoni Kowalczuk, StanisÅaw Pawlak, PrzemysÅaw Rokita, Tomasz TrzciÅski, PaweÅ Morawiecki</author><pubDate>Thu, 22 Jun 2023 16:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12983v1</guid></item><item><title>Conversation Derailment Forecasting with Graph Convolutional Networks</title><link>http://arxiv.org/abs/2306.12982v1</link><description>Online conversations are particularly susceptible to derailment, which canmanifest itself in the form of toxic communication patterns like disrespectfulcomments or verbal abuse. Forecasting conversation derailment predicts signs ofderailment in advance enabling proactive moderation of conversations. Currentstate-of-the-art approaches to address this problem rely on sequence modelsthat treat dialogues as text streams. We propose a novel model based on a graphconvolutional neural network that considers dialogue user dynamics and theinfluence of public perception on conversation utterances. Through empiricalevaluation, we show that our model effectively captures conversation dynamicsand outperforms the state-of-the-art models on the CGA and CMV benchmarkdatasets by 1.5\% and 1.7\%, respectively.</description><author>Enas Altarawneh, Ammeta Agrawal, Michael Jenkin, Manos Papagelis</author><pubDate>Thu, 22 Jun 2023 16:40:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12982v1</guid></item><item><title>Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping</title><link>http://arxiv.org/abs/2306.12981v1</link><description>Reinforcement learning often needs to deal with the exponential growth ofstates and actions when exploring optimal control in high-dimensional spaces(often known as the curse of dimensionality). In this work, we address thisissue by learning the inherent structure of action-wise similar MDP toappropriately balance the performance degradation versus sample/computationalcomplexity. In particular, we partition the action spaces into multiple groupsbased on the similarity in transition distribution and reward function, andbuild a linear decomposition model to capture the difference between theintra-group transition kernel and the intra-group rewards. Both our theoreticalanalysis and experiments reveal a \emph{surprising and counter-intuitiveresult}: while a more refined grouping strategy can reduce the approximationerror caused by treating actions in the same group as identical, it also leadsto increased estimation error when the size of samples or the computationresources is limited. This finding highlights the grouping strategy as a newdegree of freedom that can be optimized to minimize the overall performanceloss. To address this issue, we formulate a general optimization problem fordetermining the optimal grouping strategy, which strikes a balance betweenperformance loss and sample/computational complexity. We further propose acomputationally efficient method for selecting a nearly-optimal groupingstrategy, which maintains its computational complexity independent of the sizeof the action space.</description><author>Yining Li, Peizhong Ju, Ness Shroff</author><pubDate>Thu, 22 Jun 2023 16:40:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12981v1</guid></item><item><title>Sum-Rate Maximization of RSMA-based Aerial Communications with Energy Harvesting: A Reinforcement Learning Approach</title><link>http://arxiv.org/abs/2306.12977v1</link><description>In this letter, we investigate a joint power and beamforming design problemfor rate-splitting multiple access (RSMA)-based aerial communications withenergy harvesting, where a self-sustainable aerial base station serves multipleusers by utilizing the harvested energy. Considering maximizing the sum-ratefrom the long-term perspective, we utilize a deep reinforcement learning (DRL)approach, namely the soft actor-critic algorithm, to restrict the maximumtransmission power at each time based on the stochastic property of the channelenvironment, harvested energy, and battery power information. Moreover, fordesigning precoders and power allocation among all the private/common streamsof the RSMA, we employ sequential least squares programming (SLSQP) using theHan-Powell quasi-Newton method to maximize the sum-rate for the giventransmission power via DRL. Numerical results show the superiority of theproposed scheme over several baseline methods in terms of the average sum-rateperformance.</description><author>Jaehyup Seong, Mesut Toka, Wonjae Shin</author><pubDate>Thu, 22 Jun 2023 16:38:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12977v1</guid></item><item><title>Adaptive Bernstein Change Detector for High-Dimensional Data Streams</title><link>http://arxiv.org/abs/2306.12974v1</link><description>Change detection is of fundamental importance when analyzing data streams.Detecting changes both quickly and accurately enables monitoring and predictionsystems to react, e.g., by issuing an alarm or by updating a learningalgorithm. However, detecting changes is challenging when observations arehigh-dimensional. In high-dimensional data, change detectors should not only beable to identify when changes happen, but also in which subspace they occur.Ideally, one should also quantify how severe they are. Our approach, ABCD, hasthese properties. ABCD learns an encoder-decoder model and monitors itsaccuracy over a window of adaptive size. ABCD derives a change score based onBernstein's inequality to detect deviations in terms of accuracy, whichindicate changes. Our experiments demonstrate that ABCD outperforms its bestcompetitor by at least 8% and up to 23% in F1-score on average. It can alsoaccurately estimate changes' subspace, together with a severity measure thatcorrelates with the ground truth.</description><author>Marco Heyden, Edouard FouchÃ©, Vadim Arzamasov, Tanja Fenn, Florian Kalinke, Klemens BÃ¶hm</author><pubDate>Thu, 22 Jun 2023 16:35:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12974v1</guid></item><item><title>Siamese SIREN: Audio Compression with Implicit Neural Representations</title><link>http://arxiv.org/abs/2306.12957v1</link><description>Implicit Neural Representations (INRs) have emerged as a promising method forrepresenting diverse data modalities, including 3D shapes, images, and audio.While recent research has demonstrated successful applications of INRs in imageand 3D shape compression, their potential for audio compression remains largelyunexplored. Motivated by this, we present a preliminary investigation into theuse of INRs for audio compression. Our study introduces Siamese SIREN, a novelapproach based on the popular SIREN architecture. Our experimental resultsindicate that Siamese SIREN achieves superior audio reconstruction fidelitywhile utilizing fewer network parameters compared to previous INRarchitectures.</description><author>Luca A. LanzendÃ¶rfer, Roger Wattenhofer</author><pubDate>Thu, 22 Jun 2023 16:16:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12957v1</guid></item><item><title>Triggering Dark Showers with Conditional Dual Auto-Encoders</title><link>http://arxiv.org/abs/2306.12955v1</link><description>Auto-encoders (AEs) have the potential to be effective and generic tools fornew physics searches at colliders, requiring little to no model-dependentassumptions. New hypothetical physics signals can be considered anomalies thatdeviate from the well-known background processes generally expected to describethe whole dataset. We present a search formulated as an anomaly detection (AD)problem, using an AE to define a criterion to decide about the physics natureof an event. In this work, we perform an AD search for manifestations of a darkversion of strong force using raw detector images, which are large and verysparse, without leveraging any physics-based pre-processing or assumption onthe signals. We propose a dual-encoder design which can learn a compact latentspace through conditioning. In the context of multiple AD metrics, we present aclear improvement over competitive baselines and prior approaches. It is thefirst time that an AE is shown to exhibit excellent discrimination againstmultiple dark shower models, illustrating the suitability of this method as aperformant, model-independent algorithm to deploy, e.g., in the trigger stageof LHC experiments such as ATLAS and CMS.</description><author>Luca Anzalone, Simranjit Singh Chhibra, Benedikt Maier, Nadezda Chernyavskaya, Maurizio Pierini</author><pubDate>Thu, 22 Jun 2023 16:13:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12955v1</guid></item><item><title>Tracking public attitudes toward ChatGPT on Twitter using sentiment analysis and topic modeling</title><link>http://arxiv.org/abs/2306.12951v1</link><description>ChatGPT sets a new record with the fastest-growing user base, as a chatbotpowered by a large language model (LLM). While it demonstrates state-of-the-artcapabilities in a variety of language-generating tasks, it also raiseswidespread public concerns regarding its societal impact. In this paper, weutilize natural language processing approaches to investigate the publicattitudes towards ChatGPT by applying sentiment analysis and topic modelingtechniques to Twitter data. Our result shows that the overall sentiment islargely neutral to positive, which also holds true across different occupationgroups. Among a wide range of topics mentioned in tweets, the most populartopics are Artificial Intelligence, Search Engines, Education, Writing, andQuestion Answering.</description><author>Ratanond Koonchanok, Yanling Pan, Hyeju Jang</author><pubDate>Thu, 22 Jun 2023 16:10:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12951v1</guid></item><item><title>On the use of the Gram matrix for multivariate functional principal components analysis</title><link>http://arxiv.org/abs/2306.12949v1</link><description>Dimension reduction is crucial in functional data analysis (FDA). The keytool to reduce the dimension of the data is functional principal componentanalysis. Existing approaches for functional principal component analysisusually involve the diagonalization of the covariance operator. With theincreasing size and complexity of functional datasets, estimating thecovariance operator has become more challenging. Therefore, there is a growingneed for efficient methodologies to estimate the eigencomponents. Using theduality of the space of observations and the space of functional features, wepropose to use the inner-product between the curves to estimate theeigenelements of multivariate and multidimensional functional datasets. Therelationship between the eigenelements of the covariance operator and those ofthe inner-product matrix is established. We explore the application of thesemethodologies in several FDA settings and provide general guidance on theirusability.</description><author>Steven Golovkine, Edward Gunning, Andrew J. Simpkin, Norma Bargary</author><pubDate>Thu, 22 Jun 2023 16:09:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12949v1</guid></item><item><title>Exploring Human-Like Translation Strategy with Large Language Models</title><link>http://arxiv.org/abs/2305.04118v2</link><description>Large language models (LLMs) have demonstrated impressive capabilities ingeneral scenarios, exhibiting a level of aptitude that approaches, in someaspects even surpasses, human-level intelligence. Among their numerous skills,the translation abilities of LLMs have received considerable attention. Incontrast to traditional machine translation that focuses solely onsource-target mapping, LLM-based translation can potentially mimic the humantranslation process that takes many preparatory steps to ensure high-qualitytranslation. This work aims to explore this possibility by proposing the MAPSframework, which stands for Multi-Aspect Prompting and Selection. Specifically,we enable LLMs to first analyze the given source text and extract three aspectsof translation-related knowledge: keywords, topics and relevant demonstrationsto guide the translation process. To filter out the noisy and unhelpfulknowledge, we employ a selection mechanism based on quality estimation.Experiments suggest that MAPS brings significant and consistent improvementsover text-davinci-003 and Alpaca on eight translation directions from thelatest WMT22 test sets. Our further analysis shows that the extracted knowledgeis critical in resolving up to 59% of hallucination mistakes in translation.Code is available at https://github.com/zwhe99/MAPS-mt.</description><author>Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, Xing Wang</author><pubDate>Thu, 22 Jun 2023 16:05:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04118v2</guid></item><item><title>Graph Pooling for Graph Neural Networks: Progress, Challenges, and Opportunities</title><link>http://arxiv.org/abs/2204.07321v2</link><description>Graph neural networks have emerged as a leading architecture for manygraph-level tasks, such as graph classification and graph generation. As anessential component of the architecture, graph pooling is indispensable forobtaining a holistic graph-level representation of the whole graph. Although agreat variety of methods have been proposed in this promising andfast-developing research field, to the best of our knowledge, little effort hasbeen made to systematically summarize these works. To set the stage for thedevelopment of future works, in this paper, we attempt to fill this gap byproviding a broad review of recent methods for graph pooling. Specifically, 1)we first propose a taxonomy of existing graph pooling methods with amathematical summary for each category; 2) then, we provide an overview of thelibraries related to graph pooling, including the commonly used datasets, modelarchitectures for downstream tasks, and open-source implementations; 3) next,we further outline the applications that incorporate the idea of graph poolingin a variety of domains; 4) finally, we discuss certain critical challengesfacing current studies and share our insights on future potential directionsfor research on the improvement of graph pooling.</description><author>Chuang Liu, Yibing Zhan, Jia Wu, Chang Li, Bo Du, Wenbin Hu, Tongliang Liu, Dacheng Tao</author><pubDate>Thu, 22 Jun 2023 16:00:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.07321v2</guid></item><item><title>Scrutinizing XAI using linear ground-truth data with suppressor variables</title><link>http://arxiv.org/abs/2111.07473v2</link><description>Machine learning (ML) is increasingly often used to inform high-stakesdecisions. As complex ML models (e.g., deep neural networks) are oftenconsidered black boxes, a wealth of procedures has been developed to shed lighton their inner workings and the ways in which their predictions come about,defining the field of 'explainable AI' (XAI). Saliency methods rank inputfeatures according to some measure of 'importance'. Such methods are difficultto validate since a formal definition of feature importance is, thus far,lacking. It has been demonstrated that some saliency methods can highlightfeatures that have no statistical association with the prediction target(suppressor variables). To avoid misinterpretations due to such behavior, wepropose the actual presence of such an association as a necessary condition andobjective preliminary definition for feature importance. We carefully crafted aground-truth dataset in which all statistical dependencies are well-defined andlinear, serving as a benchmark to study the problem of suppressor variables. Weevaluate common explanation methods including LRP, DTD, PatternNet,PatternAttribution, LIME, Anchors, SHAP, and permutation-based methods withrespect to our objective definition. We show that most of these methods areunable to distinguish important features from suppressors in this setting.</description><author>Rick Wilming, CÃ©line Budding, Klaus-Robert MÃ¼ller, Stefan Haufe</author><pubDate>Thu, 22 Jun 2023 15:58:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.07473v2</guid></item><item><title>Evolving Computation Graphs</title><link>http://arxiv.org/abs/2306.12943v1</link><description>Graph neural networks (GNNs) have demonstrated success in modeling relationaldata, especially for data that exhibits homophily: when a connection betweennodes tends to imply that they belong to the same class. However, while thisassumption is true in many relevant situations, there are important real-worldscenarios that violate this assumption, and this has spurred research intoimproving GNNs for these cases. In this work, we propose Evolving ComputationGraphs (ECGs), a novel method for enhancing GNNs on heterophilic datasets. Ourapproach builds on prior theoretical insights linking node degree, highhomophily, and inter vs intra-class embedding similarity by rewiring the GNNs'computation graph towards adding edges that connect nodes that are likely to bein the same class. We utilise weaker classifiers to identify these edges,ultimately improving GNN performance on non-homophilic data as a result. Weevaluate ECGs on a diverse set of recently-proposed heterophilous datasets anddemonstrate improvements over the relevant baselines. ECG presents a simple,intuitive and elegant approach for improving GNN performance on heterophilicdatasets without requiring prior domain knowledge.</description><author>Andreea Deac, Jian Tang</author><pubDate>Thu, 22 Jun 2023 15:58:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12943v1</guid></item><item><title>TSMixer: An all-MLP Architecture for Time Series Forecasting</title><link>http://arxiv.org/abs/2303.06053v3</link><description>Real-world time-series datasets are often multivariate with complex dynamics.To capture this complexity, high capacity architectures like recurrent- orattention-based sequential deep learning models have become popular. However,recent work demonstrates that simple univariate linear models can outperformsuch deep learning models on several commonly used academic benchmarks.Extending them, in this paper, we investigate the capabilities of linear modelsfor time-series forecasting and present Time-Series Mixer (TSMixer), a novelarchitecture designed by stacking multi-layer perceptrons (MLPs). TSMixer isbased on mixing operations along both the time and feature dimensions toextract information efficiently. On popular academic benchmarks, thesimple-to-implement TSMixer is comparable to specialized state-of-the-artmodels that leverage the inductive biases of specific benchmarks. On thechallenging and large scale M5 benchmark, a real-world retail dataset, TSMixerdemonstrates superior performance compared to the state-of-the-artalternatives. Our results underline the importance of efficiently utilizingcross-variate and auxiliary information for improving the performance of timeseries forecasting. We present various analyses to shed light into thecapabilities of TSMixer. The design paradigms utilized in TSMixer are expectedto open new horizons for deep learning-based time series forecasting. Theimplementation is available athttps://github.com/google-research/google-research/tree/master/tsmixer</description><author>Si-An Chen, Chun-Liang Li, Nate Yoder, Sercan O. Arik, Tomas Pfister</author><pubDate>Thu, 22 Jun 2023 15:56:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06053v3</guid></item><item><title>Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models</title><link>http://arxiv.org/abs/2306.12941v1</link><description>While a large amount of work has focused on designing adversarial attacksagainst image classifiers, only a few methods exist to attack semanticsegmentation models. We show that attacking segmentation models presentstask-specific challenges, for which we propose novel solutions. Our finalevaluation protocol outperforms existing methods, and shows that those canoverestimate the robustness of the models. Additionally, so far adversarialtraining, the most successful way for obtaining robust image classifiers, couldnot be successfully applied to semantic segmentation. We argue that this isbecause the task to be learned is more challenging, and requires significantlyhigher computational effort than for image classification. As a remedy, we showthat by taking advantage of recent advances in robust ImageNet classifiers, onecan train adversarially robust segmentation models at limited computationalcost by fine-tuning robust backbones.</description><author>Francesco Croce, Naman D Singh, Matthias Hein</author><pubDate>Thu, 22 Jun 2023 15:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12941v1</guid></item><item><title>Feature Mixing for Writer Retrieval and Identification on Papyri Fragments</title><link>http://arxiv.org/abs/2306.12939v1</link><description>This paper proposes a deep-learning-based approach to writer retrieval andidentification for papyri, with a focus on identifying fragments associatedwith a specific writer and those corresponding to the same image. We present anovel neural network architecture that combines a residual backbone with afeature mixing stage to improve retrieval performance, and the final descriptoris derived from a projection layer. The methodology is evaluated on twobenchmarks: PapyRow, where we achieve a mAP of 26.6 % and 24.9 % on writer andpage retrieval, and HisFragIR20, showing state-of-the-art performance (44.0 %and 29.3 % mAP). Furthermore, our network has an accuracy of 28.7 % for writeridentification. Additionally, we conduct experiments on the influence of twobinarization techniques on fragments and show that binarizing does not enhanceperformance. Our code and models are available to the community.</description><author>Marco Peer, Robert Sablatnig</author><pubDate>Thu, 22 Jun 2023 15:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12939v1</guid></item><item><title>HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile Mapping System with Tilted LiDAR and Panoramic Visual Camera</title><link>http://arxiv.org/abs/2301.11823v3</link><description>This paper proposes a novel visual simultaneous localization and mapping(SLAM) system called Hybrid Depth-augmented Panoramic Visual SLAM (HDPV-SLAM),that employs a panoramic camera and a tilted multi-beam LiDAR scanner togenerate accurate and metrically-scaled trajectories. RGB-D SLAM was the designbasis for HDPV-SLAM, which added depth information to visual features. It aimsto solve the two major issues hindering the performance of similar SLAMsystems. The first obstacle is the sparseness of LiDAR depth, which makes itdifficult to correlate it with the extracted visual features of the RGB image.A deep learning-based depth estimation module for iteratively densifying sparseLiDAR depth was suggested to address this issue. The second issue pertains tothe difficulties in depth association caused by a lack of horizontal overlapbetween the panoramic camera and the tilted LiDAR sensor. To surmount thisdifficulty, we present a hybrid depth association module that optimallycombines depth information estimated by two independent procedures,feature-based triangulation and depth estimation. During a phase of featuretracking, this hybrid depth association module aims to maximize the use of moreaccurate depth information between the triangulated depth with visual featurestracked and the deep learning-based corrected depth. We evaluated the efficacyof HDPV-SLAM using the 18.95 km-long York University and Teledyne Optech (YUTO)MMS dataset. The experimental results demonstrate that the two proposed modulescontribute substantially to the performance of HDPV-SLAM, which surpasses thatof the state-of-the-art (SOTA) SLAM systems.</description><author>Mostafa Ahmadi, Amin Alizadeh Naeini, Mohammad Moein Sheikholeslami, Zahra Arjmandi, Yujia Zhang, Gunho Sohn</author><pubDate>Thu, 22 Jun 2023 15:49:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11823v3</guid></item><item><title>Streaming algorithms for evaluating noisy judges on unlabeled data -- binary classification</title><link>http://arxiv.org/abs/2306.01726v2</link><description>The evaluation of noisy binary classifiers on unlabeled data is treated as astreaming task: given a data sketch of the decisions by an ensemble, estimatethe true prevalence of the labels as well as each classifier's accuracy onthem. Two fully algebraic evaluators are constructed to do this. Both are basedon the assumption that the classifiers make independent errors. The first isbased on majority voting. The second, the main contribution of the paper, isguaranteed to be correct. But how do we know the classifiers are independent onany given test? This principal/agent monitoring paradox is ameliorated byexploiting the failures of the independent evaluator to return sensibleestimates. A search for nearly error independent trios is empirically carriedout on the \texttt{adult}, \texttt{mushroom}, and \texttt{two-norm} datasets byusing the algebraic failure modes to reject evaluation ensembles as toocorrelated. The searches are refined by constructing a surface in evaluationspace that contains the true value point. The algebra of arbitrarily correlatedclassifiers permits the selection of a polynomial subset free of anycorrelation variables. Candidate evaluation ensembles are rejected if theirdata sketches produce independent estimates too far from the constructedsurface. The results produced by the surviving ensembles can sometimes be asgood as 1\%. But handling even small amounts of correlation remains achallenge. A Taylor expansion of the estimates produced when independence isassumed but the classifiers are, in fact, slightly correlated helps clarify howthe independent evaluator has algebraic `blind spots'.</description><author>AndrÃ©s Corrada-Emmanuel</author><pubDate>Thu, 22 Jun 2023 15:46:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01726v2</guid></item><item><title>Robust Unsupervised StyleGAN Image Restoration</title><link>http://arxiv.org/abs/2302.06733v2</link><description>GAN-based image restoration inverts the generative process to repair imagescorrupted by known degradations. Existing unsupervised methods must becarefully tuned for each task and degradation level. In this work, we makeStyleGAN image restoration robust: a single set of hyperparameters works acrossa wide range of degradation levels. This makes it possible to handlecombinations of several degradations, without the need to retune. Our proposedapproach relies on a 3-phase progressive latent space extension and aconservative optimizer, which avoids the need for any additional regularizationterms. Extensive experiments demonstrate robustness on inpainting, upsampling,denoising, and deartifacting at varying degradations levels, outperformingother StyleGAN-based inversion techniques. Our approach also favorably comparesto diffusion-based restoration by yielding much more realistic inversionresults. Code is available at https://lvsn.github.io/RobustUnsupervised/.</description><author>Yohan Poirier-Ginter, Jean-FranÃ§ois Lalonde</author><pubDate>Thu, 22 Jun 2023 15:44:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06733v2</guid></item><item><title>Prior Density Learning in Variational Bayesian Phylogenetic Parameters Inference</title><link>http://arxiv.org/abs/2302.02522v2</link><description>The advances in variational inference are providing promising paths inBayesian estimation problems. These advances make variational phylogeneticinference an alternative approach to Markov Chain Monte Carlo methods forapproximating the phylogenetic posterior. However, one of the main drawbacks ofsuch approaches is the modelling of the prior through fixed distributions,which could bias the posterior approximation if they are distant from thecurrent data distribution. In this paper, we propose an approach and animplementation framework to relax the rigidity of the prior densities bylearning their parameters using a gradient-based method and a neuralnetwork-based parameterization. We applied this approach for branch lengths andevolutionary parameters estimation under several Markov chain substitutionmodels. The results of performed simulations show that the approach is powerfulin estimating branch lengths and evolutionary model parameters. They also showthat a flexible prior model could provide better results than a predefinedprior model. Finally, the results highlight that using neural networks improvesthe initialization of the optimization of the prior density parameters.</description><author>Amine M. Remita, Golrokh Kiani Vitae, Abdoulaye BanirÃ© Diallo</author><pubDate>Thu, 22 Jun 2023 15:44:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02522v2</guid></item><item><title>Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing</title><link>http://arxiv.org/abs/2306.12929v1</link><description>Transformer models have been widely adopted in various domains over the lastyears, and especially large language models have advanced the field of AIsignificantly. Due to their size, the capability of these networks hasincreased tremendously, but this has come at the cost of a significant increasein necessary compute. Quantization is one of the most effective ways to reducethe computational time and memory consumption of neural networks. Many studieshave shown, however, that modern transformer models tend to learn strongoutliers in their activations, making them difficult to quantize. To retainacceptable performance, the existence of these outliers requires activations tobe in higher bitwidth or the use of different numeric formats, extrafine-tuning, or other workarounds. We show that strong outliers are related tovery specific behavior of attention heads that try to learn a "no-op" or just apartial update of the residual. To achieve the exact zeros needed in theattention matrix for a no-update, the input to the softmax is pushed to belarger and larger during training, causing outliers in other parts of thenetwork. Based on these observations, we propose two simple (independent)modifications to the attention mechanism - clipped softmax and gated attention.We empirically show that models pre-trained using our methods learnsignificantly smaller outliers while maintaining and sometimes even improvingthe floating-point task performance. This enables us to quantize transformersto full INT8 quantization of the activations without any additional effort. Wedemonstrate the effectiveness of our methods on both language models (BERT,OPT) and vision transformers.</description><author>Yelysei Bondarenko, Markus Nagel, Tijmen Blankevoort</author><pubDate>Thu, 22 Jun 2023 15:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12929v1</guid></item><item><title>Decentralized Multi-Agent Reinforcement Learning with Global State Prediction</title><link>http://arxiv.org/abs/2306.12926v1</link><description>Deep reinforcement learning (DRL) has seen remarkable success in the controlof single robots. However, applying DRL to robot swarms presents significantchallenges. A critical challenge is non-stationarity, which occurs when two ormore robots update individual or shared policies concurrently, thereby engagingin an interdependent training process with no guarantees of convergence.Circumventing non-stationarity typically involves training the robots withglobal information about other agents' states and/or actions. In contrast, inthis paper we explore how to remove the need for global information. We poseour problem as a Partially Observable Markov Decision Process, due to theabsence of global knowledge on other agents. Using collective transport as atestbed scenario, we study two approaches to multi-agent training. In thefirst, the robots exchange no messages, and are trained to rely on implicitcommunication through push-and-pull on the object to transport. In the secondapproach, we introduce Global State Prediction (GSP), a network trained toforma a belief over the swarm as a whole and predict its future states. Weprovide a comprehensive study over four well-known deep reinforcement learningalgorithms in environments with obstacles, measuring performance as thesuccessful transport of the object to the goal within a desired time-frame.Through an ablation study, we show that including GSP boosts performance andincreases robustness when compared with methods that use global knowledge.</description><author>Joshua Bloom, Pranjal Paliwal, Apratim Mukherjee, Carlo Pinciroli</author><pubDate>Thu, 22 Jun 2023 15:38:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12926v1</guid></item><item><title>AudioPaLM: A Large Language Model That Can Speak and Listen</title><link>http://arxiv.org/abs/2306.12925v1</link><description>We introduce AudioPaLM, a large language model for speech understanding andgeneration. AudioPaLM fuses text-based and speech-based language models, PaLM-2[Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unifiedmultimodal architecture that can process and generate text and speech withapplications including speech recognition and speech-to-speech translation.AudioPaLM inherits the capability to preserve paralinguistic information suchas speaker identity and intonation from AudioLM and the linguistic knowledgepresent only in text large language models such as PaLM-2. We demonstrate thatinitializing AudioPaLM with the weights of a text-only large language modelimproves speech processing, successfully leveraging the larger quantity of texttraining data used in pretraining to assist with the speech tasks. Theresulting model significantly outperforms existing systems for speechtranslation tasks and has the ability to perform zero-shot speech-to-texttranslation for many languages for which input/target language combinationswere not seen in training. AudioPaLM also demonstrates features of audiolanguage models, such as transferring a voice across languages based on a shortspoken prompt. We release examples of our method athttps://google-research.github.io/seanet/audiopalm/examples</description><author>Paul K. Rubenstein, Chulayuth Asawaroengchai, Duc Dung Nguyen, Ankur Bapna, ZalÃ¡n Borsos, FÃ©lix de Chaumont Quitry, Peter Chen, Dalia El Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, Dirk Padfield, James Qin, Danny Rozenberg, Tara Sainath, Johan Schalkwyk, Matt Sharifi, Michelle Tadmor, Ramanovich, Marco Tagliasacchi, Alexandru Tudor, Mihajlo VelimiroviÄ, Damien Vincent, Jiahui Yu, Yongqiang Wang, Vicky Zayats, Neil Zeghidour, Yu Zhang, Zhishuai Zhang, Lukas Zilka, Christian Frank</author><pubDate>Thu, 22 Jun 2023 15:37:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12925v1</guid></item><item><title>An Interactive Interface for Novel Class Discovery in Tabular Data</title><link>http://arxiv.org/abs/2306.12919v1</link><description>Novel Class Discovery (NCD) is the problem of trying to discover novelclasses in an unlabeled set, given a labeled set of different but relatedclasses. The majority of NCD methods proposed so far only deal with image data,despite tabular data being among the most widely used type of data in practicalapplications. To interpret the results of clustering or NCD algorithms, datascientists need to understand the domain- and application-specific attributesof tabular data. This task is difficult and can often only be performed by adomain expert. Therefore, this interface allows a domain expert to easily runstate-of-the-art algorithms for NCD in tabular data. With minimal knowledge indata science, interpretable results can be generated.</description><author>Colin Troisemaine, Joachim Flocon-Cholet, StÃ©phane Gosselin, Alexandre Reiffers-Masson, Sandrine Vaton, Vincent Lemaire</author><pubDate>Thu, 22 Jun 2023 15:32:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12919v1</guid></item><item><title>Cross-lingual Cross-temporal Summarization: Dataset, Models, Evaluation</title><link>http://arxiv.org/abs/2306.12916v1</link><description>While summarization has been extensively researched in natural languageprocessing (NLP), cross-lingual cross-temporal summarization (CLCTS) is alargely unexplored area that has the potential to improve cross-culturalaccessibility, information sharing, and understanding. This papercomprehensively addresses the CLCTS task, including dataset creation, modeling,and evaluation. We build the first CLCTS corpus, leveraging historical fictivetexts and Wikipedia summaries in English and German, and examine theeffectiveness of popular transformer end-to-end models with differentintermediate task finetuning tasks. Additionally, we explore the potential ofChatGPT for CLCTS as a summarizer and an evaluator. Overall, we reportevaluations from humans, ChatGPT, and several recent automatic evaluationmetrics where we find our intermediate task finetuned end-to-end modelsgenerate bad to moderate quality summaries; ChatGPT as a summarizer (withoutany finetuning) provides moderate to good quality outputs and as an evaluatorcorrelates moderately with human evaluations though it is prone to giving lowerscores. ChatGPT also seems to be very adept at normalizing historical text. Wefinally test ChatGPT in a scenario with adversarially attacked and unseensource documents and find that ChatGPT is better at omission and entity swapthan negating against its prior knowledge.</description><author>Ran Zhang, Jihed Ouni, Steffen Eger</author><pubDate>Thu, 22 Jun 2023 15:31:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12916v1</guid></item><item><title>Multi-Objective Hull Form Optimization with CAD Engine-based Deep Learning Physics for 3D Flow Prediction</title><link>http://arxiv.org/abs/2306.12915v1</link><description>In this work, we propose a built-in Deep Learning Physics Optimization (DLPO)framework to set up a shape optimization study of the Duisburg Test Case (DTC)container vessel. We present two different applications: (1) sensitivityanalysis to detect the most promising generic basis hull shapes, and (2)multi-objective optimization to quantify the trade-off between optimal hullforms. DLPO framework allows for the evaluation of design iterationsautomatically in an end-to-end manner. We achieved these results by couplingExtrality's Deep Learning Physics (DLP) model to a CAD engine and an optimizer.Our proposed DLP model is trained on full 3D volume data coming from RANSsimulations, and it can provide accurate and high-quality 3D flow predictionsin real-time, which makes it a good evaluator to perform optimization of newcontainer vessel designs w.r.t the hydrodynamic efficiency. In particular, itis able to recover the forces acting on the vessel by integration on the hullsurface with a mean relative error of 3.84\% \pm 2.179\% on the totalresistance. Each iteration takes only 20 seconds, thus leading to a drasticsaving of time and engineering efforts, while delivering valuable insight intothe performance of the vessel, including RANS-like detailed flow information.We conclude that DLPO framework is a promising tool to accelerate the shipdesign process and lead to more efficient ships with better hydrodynamicperformance.</description><author>Jocelyn Ahmed Mazari, Antoine Reverberi, Pierre Yser, Sebastian Sigmund</author><pubDate>Thu, 22 Jun 2023 15:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12915v1</guid></item><item><title>Implicit spoken language diarization</title><link>http://arxiv.org/abs/2306.12913v1</link><description>Spoken language diarization (LD) and related tasks are mostly explored usingthe phonotactic approach. Phonotactic approaches mostly use explicit way oflanguage modeling, hence requiring intermediate phoneme modeling andtranscribed data. Alternatively, the ability of deep learning approaches tomodel temporal dynamics may help for the implicit modeling of languageinformation through deep embedding vectors. Hence this work initially exploresthe available speaker diarization frameworks that capture speaker informationimplicitly to perform LD tasks. The performance of the LD system on syntheticcode-switch data using the end-to-end x-vector approach is 6.78% and 7.06%, andfor practical data is 22.50% and 60.38%, in terms of diarization error rate andJaccard error rate (JER), respectively. The performance degradation is due tothe data imbalance and resolved to some extent by using pre-trained wave2vecembeddings that provide a relative improvement of 30.74% in terms of JER.</description><author>Jagabandhu Mishra, Amartya Chowdhury, S. R. Mahadeva Prasanna</author><pubDate>Thu, 22 Jun 2023 15:29:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12913v1</guid></item><item><title>CosmoPower-JAX: high-dimensional Bayesian inference with differentiable cosmological emulators</title><link>http://arxiv.org/abs/2305.06347v2</link><description>We present CosmoPower-JAX, a JAX-based implementation of the CosmoPowerframework, which accelerates cosmological inference by building neuralemulators of cosmological power spectra. We show how, using the automaticdifferentiation, batch evaluation and just-in-time compilation features of JAX,and running the inference pipeline on graphics processing units (GPUs),parameter estimation can be accelerated by orders of magnitude with advancedgradient-based sampling techniques. These can be used to efficiently explorehigh-dimensional parameter spaces, such as those needed for the analysis ofnext-generation cosmological surveys. We showcase the accuracy andcomputational efficiency of CosmoPower-JAX on two simulated Stage IVconfigurations. We first consider a single survey performing a cosmic shearanalysis totalling 37 model parameters. We validate the contours derived withCosmoPower-JAX and a Hamiltonian Monte Carlo sampler against those derived witha nested sampler and without emulators, obtaining a speed-up factor of$\mathcal{O}(10^3)$. We then consider a combination of three Stage IV surveys,each performing a joint cosmic shear and galaxy clustering (3x2pt) analysis,for a total of 157 model parameters. Even with such a high-dimensionalparameter space, CosmoPower-JAX provides converged posterior contours in 3days, as opposed to the estimated 6 years required by standard methods.CosmoPower-JAX is fully written in Python, and we make it publicly available tohelp the cosmological community meet the accuracy requirements set bynext-generation surveys.</description><author>D. Piras, A. Spurio Mancini</author><pubDate>Thu, 22 Jun 2023 15:29:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06347v2</guid></item><item><title>Mitigating Discrimination in Insurance with Wasserstein Barycenters</title><link>http://arxiv.org/abs/2306.12912v1</link><description>The insurance industry is heavily reliant on predictions of risks based oncharacteristics of potential customers. Although the use of said models iscommon, researchers have long pointed out that such practices perpetuatediscrimination based on sensitive features such as gender or race. Given thatsuch discrimination can often be attributed to historical data biases, anelimination or at least mitigation is desirable. With the shift from moretraditional models to machine-learning based predictions, calls for greatermitigation have grown anew, as simply excluding sensitive variables in thepricing process can be shown to be ineffective. In this article, we firstinvestigate why predictions are a necessity within the industry and whycorrecting biases is not as straightforward as simply identifying a sensitivevariable. We then propose to ease the biases through the use of Wassersteinbarycenters instead of simple scaling. To demonstrate the effects andeffectiveness of the approach we employ it on real data and discuss itsimplications.</description><author>Arthur Charpentier, FranÃ§ois Hu, Philipp Ratz</author><pubDate>Thu, 22 Jun 2023 15:27:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12912v1</guid></item><item><title>The Impact of Partial Occlusion on Pedestrian Detectability</title><link>http://arxiv.org/abs/2205.04812v5</link><description>Robust detection of vulnerable road users is a safety critical requirementfor the deployment of autonomous vehicles in heterogeneous traffic. One of themost complex outstanding challenges is that of partial occlusion where a targetobject is only partially available to the sensor due to obstruction by anotherforeground object. A number of leading pedestrian detection benchmarks provideannotation for partial occlusion, however each benchmark varies greatly intheir definition of the occurrence and severity of occlusion. Recent researchdemonstrates that a high degree of subjectivity is used to classify occlusionlevel in these cases and occlusion is typically categorized into 2 to 3 broadcategories such as partially and heavily occluded. This can lead to inaccurateor inconsistent reporting of pedestrian detection model performance dependingon which benchmark is used. This research introduces a novel, objectivebenchmark for partially occluded pedestrian detection to facilitate theobjective characterization of pedestrian detection models. Characterization iscarried out on seven popular pedestrian detection models for a range ofocclusion levels from 0-99%, in order to demonstrate the efficacy and increasedanalysis capabilities of the proposed characterization method. Resultsdemonstrate that pedestrian detection performance degrades, and the number offalse negative detections increase as pedestrian occlusion level increases. Ofthe seven popular pedestrian detection routines characterized, CenterNet hasthe greatest overall performance, followed by SSDlite. RetinaNet has the lowestoverall detection performance across the range of occlusion levels.</description><author>Shane Gilroy, Darragh Mullins, Edward Jones, Ashkan Parsi, Martin Glavin</author><pubDate>Thu, 22 Jun 2023 15:21:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.04812v5</guid></item><item><title>xSIM++: An Improved Proxy to Bitext Mining Performance for Low-Resource Languages</title><link>http://arxiv.org/abs/2306.12907v1</link><description>We introduce a new proxy score for evaluating bitext mining based onsimilarity in a multilingual embedding space: xSIM++. In comparison to xSIM,this improved proxy leverages rule-based approaches to extend English sentencesin any evaluation set with synthetic, hard-to-distinguish examples which moreclosely mirror the scenarios we encounter during large-scale mining. Wevalidate this proxy by running a significant number of bitext miningexperiments for a set of low-resource languages, and subsequently train NMTsystems on the mined data. In comparison to xSIM, we show that xSIM++ is bettercorrelated with the downstream BLEU scores of translation systems trained onmined bitexts, providing a reliable proxy of bitext mining performance withoutneeding to run expensive bitext mining pipelines. xSIM++ also reportsperformance for different error types, offering more fine-grained feedback formodel development.</description><author>Mingda Chen, Kevin Heffernan, Onur Ãelebi, Alex Mourachko, Holger Schwenk</author><pubDate>Thu, 22 Jun 2023 15:20:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12907v1</guid></item><item><title>Taming Multi-Agent Reinforcement Learning with Estimator Variance Reduction</title><link>http://arxiv.org/abs/2209.01054v2</link><description>Centralised training with decentralised execution (CT-DE) serves as thefoundation of many leading multi-agent reinforcement learning (MARL)algorithms. Despite its popularity, it suffers from a critical drawback due toits reliance on learning from a single sample of the joint-action at a givenstate. As agents explore and update their policies during training, thesesingle samples may poorly represent the actual joint-policy of the system ofagents leading to high variance gradient estimates that hinder learning. Toaddress this problem, we propose an enhancement tool that accommodates anyactor-critic MARL method. Our framework, Performance Enhancing ReinforcementLearning Apparatus (PERLA), introduces a sampling technique of the agents'joint-policy into the critics while the agents train. This leads to TD updatesthat closely approximate the true expected value under the current joint-policyrather than estimates from a single sample of the joint-action at a givenstate. This produces low variance and precise estimates of expected returns,minimising the variance in the critic estimators which typically hinderslearning. Moreover, as we demonstrate, by eliminating much of the criticvariance from the single sampling of the joint policy, PERLA enables CT-DEmethods to scale more efficiently with the number of agents. Theoretically, weprove that PERLA reduces variance in value estimates similar to that ofdecentralised training while maintaining the benefits of centralised training.Empirically, we demonstrate PERLA's superior performance and ability to reduceestimator variance in a range of benchmarks including Multi-agent Mujoco, andStarCraft II Multi-agent Challenge.</description><author>Taher Jafferjee, Juliusz Ziomek, Tianpei Yang, Zipeng Dai, Jianhong Wang, Matthew Taylor, Kun Shao, Jun Wang, David Mguni</author><pubDate>Thu, 22 Jun 2023 15:19:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.01054v2</guid></item><item><title>Using ChatGPT for Entity Matching</title><link>http://arxiv.org/abs/2305.03423v2</link><description>Entity Matching is the task of deciding if two entity descriptions refer tothe same real-world entity. State-of-the-art entity matching methods often relyon fine-tuning Transformer models such as BERT or RoBERTa. Two major drawbacksof using these models for entity matching are that (i) the models requiresignificant amounts of fine-tuning data for reaching a good performance and(ii) the fine-tuned models are not robust concerning out-of-distributionentities. In this paper, we investigate using ChatGPT for entity matching as amore robust, training data-efficient alternative to traditional Transformermodels. We perform experiments along three dimensions: (i) general promptdesign, (ii) in-context learning, and (iii) provision of higher-level matchingknowledge. We show that ChatGPT is competitive with a fine-tuned RoBERTa model,reaching a zero-shot performance of 82.35% F1 on a challenging matching task onwhich RoBERTa requires 2000 training examples for reaching a similarperformance. Adding in-context demonstrations to the prompts further improvesthe F1 by up to 7.85% when using similarity-based example selection. Alwaysusing the same set of 10 handpicked demonstrations leads to an improvement of4.92% over the zero-shot performance. Finally, we show that ChatGPT can also beguided by adding higher-level matching knowledge in the form of rules to theprompts. Providing matching rules leads to similar performance gains asproviding in-context demonstrations.</description><author>Ralph Peeters, Christian Bizer</author><pubDate>Thu, 22 Jun 2023 15:09:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03423v2</guid></item><item><title>In Situ Framework for Coupling Simulation and Machine Learning with Application to CFD</title><link>http://arxiv.org/abs/2306.12900v1</link><description>Recent years have seen many successful applications of machine learning (ML)to facilitate fluid dynamic computations. As simulations grow, generating newtraining datasets for traditional offline learning creates I/O and storagebottlenecks. Additionally, performing inference at runtime requires non-trivialcoupling of ML framework libraries with simulation codes. This work offers asolution to both limitations by simplifying this coupling and enabling in situtraining and inference workflows on heterogeneous clusters. LeveragingSmartSim, the presented framework deploys a database to store data and MLmodels in memory, thus circumventing the file system. On the Polarissupercomputer, we demonstrate perfect scaling efficiency to the full machinesize of the data transfer and inference costs thanks to a novel co-locateddeployment of the database. Moreover, we train an autoencoder in situ from aturbulent flow simulation, showing that the framework overhead is negligiblerelative to a solver time step and training epoch.</description><author>Riccardo Balin, Filippo Simini, Cooper Simpson, Andrew Shao, Alessandro Rigazzi, Matthew Ellis, Stephen Becker, Alireza Doostan, John A. Evans, Kenneth E. Jansen</author><pubDate>Thu, 22 Jun 2023 15:07:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12900v1</guid></item><item><title>Machine-Learning-Assisted and Real-Time-Feedback-Controlled Growth of InAs/GaAs Quantum Dots</title><link>http://arxiv.org/abs/2306.12898v1</link><description>Self-assembled InAs/GaAs quantum dots (QDs) have properties highly valuablefor developing various optoelectronic devices such as QD lasers and singlephoton sources. The applications strongly rely on the density and quality ofthese dots, which has motivated studies of the growth process control torealize high-quality epi-wafers and devices. Establishing the processparameters in molecular beam epitaxy (MBE) for a specific density of QDs is amultidimensional optimization challenge, usually addressed throughtime-consuming and iterative trial-and-error. Meanwhile, reflective high-energyelectron diffraction (RHEED) has been widely used to capture a wealth of growthinformation in situ. However, it still faces the challenges of extractinginformation from noisy and overlapping images. Here, based on 3D ResNet, wedeveloped a machine learning (ML) model specially designed for training RHEEDvideos instead of static images and providing real-time feedback on surfacemorphologies for process control. We demonstrated that ML from previous growthcould predict the post-growth density of QDs, by successfully tuning the QDdensities in near-real time from 1.5E10 cm-2 down to 3.8E8 cm-2 or up to 1.4E11 cm-2. Compared to traditional methods, our approach, with in-situ tuningcapabilities and excellent reliability, can dramatically expedite the materialoptimization process and improve the reproducibility of MBE growth,constituting significant progress for thin film growth techniques. The conceptsand methodologies proved feasible in this work are promising to be applied to avariety of material growth processes, which will revolutionize semiconductormanufacturing for microelectronic and optoelectronic industries.</description><author>Chao Shen, Wenkang Zhan, Kaiyao Xin, Manyang Li, Zhenyu Sun, Jian Tang, Zhaofeng Wu, Bo Xu, Zhongming Wei, Chao Zhao, Zhanguo Wang</author><pubDate>Thu, 22 Jun 2023 15:07:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12898v1</guid></item><item><title>Unveiling Global Narratives: A Multilingual Twitter Dataset of News Media on the Russo-Ukrainian Conflict</title><link>http://arxiv.org/abs/2306.12886v1</link><description>The ongoing Russo-Ukrainian conflict has been a subject of intense mediacoverage worldwide. Understanding the global narrative surrounding this topicis crucial for researchers that aim to gain insights into its multifaceteddimensions. In this paper, we present a novel dataset that focuses on thistopic by collecting and processing tweets posted by news or media companies onsocial media across the globe. We collected tweets from February 2022 to May2023 to acquire approximately 1.5 million tweets in 60 different languages.Each tweet in the dataset is accompanied by processed tags, allowing for theidentification of entities, stances, concepts, and sentiments expressed. Theavailability of the dataset serves as a valuable resource for researchersaiming to investigate the global narrative surrounding the ongoing conflictfrom various aspects such as who are the prominent entities involved, whatstances are taken, where do these stances originate, and how are the differentconcepts related to the event portrayed.</description><author>Sherzod Hakimov, Gullal S. Cheema</author><pubDate>Thu, 22 Jun 2023 14:52:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12886v1</guid></item><item><title>Data-Free Backbone Fine-Tuning for Pruned Neural Networks</title><link>http://arxiv.org/abs/2306.12881v1</link><description>Model compression techniques reduce the computational load and memoryconsumption of deep neural networks. After the compression operation, e.g.parameter pruning, the model is normally fine-tuned on the original trainingdataset to recover from the performance drop caused by compression. However,the training data is not always available due to privacy issues or otherfactors. In this work, we present a data-free fine-tuning approach for pruningthe backbone of deep neural networks. In particular, the pruned networkbackbone is trained with synthetically generated images, and our proposedintermediate supervision to mimic the unpruned backbone's output feature map.Afterwards, the pruned backbone can be combined with the original network headto make predictions. We generate synthetic images by back-propagating gradientsto noise images while relying on L1-pruning for the backbone pruning. In ourexperiments, we show that our approach is task-independent due to pruning onlythe backbone. By evaluating our approach on 2D human pose estimation, objectdetection, and image classification, we demonstrate promising performancecompared to the unpruned model. Our code is available athttps://github.com/holzbock/dfbf.</description><author>Adrian Holzbock, Achyut Hegde, Klaus Dietmayer, Vasileios Belagiannis</author><pubDate>Thu, 22 Jun 2023 14:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12881v1</guid></item><item><title>FuXi: A cascade machine learning forecasting system for 15-day global weather forecast</title><link>http://arxiv.org/abs/2306.12873v1</link><description>Over the past few years, due to the rapid development of machine learning(ML) models for weather forecasting, state-of-the-art ML models have shownsuperior performance compared to the European Centre for Medium-Range WeatherForecasts (ECMWF)'s high-resolution forecast (HRES) in 10-day forecasts at aspatial resolution of 0.25 degree. However, the challenge remains to performcomparably to the ECMWF ensemble mean (EM) in 15-day forecasts. Previousstudies have demonstrated the importance of mitigating the accumulation offorecast errors for effective long-term forecasts. Despite numerous efforts toreduce accumulation errors, including autoregressive multi-time step loss,using a single model is found to be insufficient to achieve optimal performancein both short and long lead times. Therefore, we present FuXi, a cascaded MLweather forecasting system that provides 15-day global forecasts with atemporal resolution of 6 hours and a spatial resolution of 0.25 degree. FuXi isdeveloped using 39 years of the ECMWF ERA5 reanalysis dataset. The performanceevaluation, based on latitude-weighted root mean square error (RMSE) andanomaly correlation coefficient (ACC), demonstrates that FuXi has comparableforecast performance to ECMWF EM in 15-day forecasts, making FuXi the firstML-based weather forecasting system to accomplish this achievement.</description><author>Lei Chen, Xiaohui Zhong, Feng Zhang, Yuan Cheng, Yinghui Xu, Yuan Qi, Hao Li</author><pubDate>Thu, 22 Jun 2023 14:34:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12873v1</guid></item><item><title>Wind Noise Reduction with a Diffusion-based Stochastic Regeneration Model</title><link>http://arxiv.org/abs/2306.12867v1</link><description>In this paper we present a method for single-channel wind noise reductionusing our previously proposed diffusion-based stochastic regeneration modelcombining predictive and generative modelling. We introduce a non-additivespeech in noise model to account for the non-linear deformation of the membranecaused by the wind flow and possible clipping. We show that our stochasticregeneration model outperforms other neural-network-based wind noise reductionmethods as well as purely predictive and generative models, on a dataset usingsimulated and real-recorded wind noise. We further show that the proposedmethod generalizes well by testing on an unseen dataset with real-recorded windnoise. Audio samples, data generation scripts and code for the proposed methodscan be found online (https://uhh.de/inf-sp-storm-wind).</description><author>Jean-Marie Lemercier, Joachim Thiemann, Raphael Koning, Timo Gerkmann</author><pubDate>Thu, 22 Jun 2023 14:25:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12867v1</guid></item><item><title>Learning from Visual Observation via Offline Pretrained State-to-Go Transformer</title><link>http://arxiv.org/abs/2306.12860v1</link><description>Learning from visual observation (LfVO), aiming at recovering policies fromonly visual observation data, is promising yet a challenging problem. ExistingLfVO approaches either only adopt inefficient online learning schemes orrequire additional task-specific information like goal states, making them notsuited for open-ended tasks. To address these issues, we propose a two-stageframework for learning from visual observation. In the first stage, weintroduce and pretrain State-to-Go (STG) Transformer offline to predict anddifferentiate latent transitions of demonstrations. Subsequently, in the secondstage, the STG Transformer provides intrinsic rewards for downstreamreinforcement learning tasks where an agent learns merely from intrinsicrewards. Empirical results on Atari and Minecraft show that our proposed methodoutperforms baselines and in some tasks even achieves performance comparable tothe policy learned from environmental rewards. These results shed light on thepotential of utilizing video-only data to solve difficult visual reinforcementlearning tasks rather than relying on complete offline datasets containingstates, actions, and rewards. The project's website and code can be found athttps://sites.google.com/view/stgtransformer.</description><author>Bohan Zhou, Ke Li, Jiechuan Jiang, Zongqing Lu</author><pubDate>Thu, 22 Jun 2023 14:14:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12860v1</guid></item><item><title>Reinforcement Federated Learning Method Based on Adaptive OPTICS Clustering</title><link>http://arxiv.org/abs/2306.12859v1</link><description>Federated learning is a distributed machine learning technology, whichrealizes the balance between data privacy protection and data sharingcomputing. To protect data privacy, feder-ated learning learns shared models bylocally executing distributed training on participating devices and aggregatinglocal models into global models. There is a problem in federated learning, thatis, the negative impact caused by the non-independent and identicaldistribu-tion of data across different user terminals. In order to alleviatethis problem, this paper pro-poses a strengthened federation aggregation methodbased on adaptive OPTICS clustering. Specifically, this method perceives theclustering environment as a Markov decision process, and models the adjustmentprocess of parameter search direction, so as to find the best clus-teringparameters to achieve the best federated aggregation method. The corecontribution of this paper is to propose an adaptive OPTICS clusteringalgorithm for federated learning. The algorithm combines OPTICS clustering andadaptive learning technology, and can effective-ly deal with the problem ofnon-independent and identically distributed data across different userterminals. By perceiving the clustering environment as a Markov decisionprocess, the goal is to find the best parameters of the OPTICS cluster withoutartificial assistance, so as to obtain the best federated aggregation methodand achieve better performance. The reliability and practicability of thismethod have been verified on the experimental data, and its effec-tiveness andsuperiority have been proved.</description><author>Tianyu Zhao, Junping Du, Yingxia Shao, Zeli Guan</author><pubDate>Thu, 22 Jun 2023 14:11:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12859v1</guid></item><item><title>Efficient Partitioning Method of Large-Scale Public Safety Spatio-Temporal Data based on Information Loss Constraints</title><link>http://arxiv.org/abs/2306.12857v1</link><description>The storage, management, and application of massive spatio-temporal data arewidely applied in various practical scenarios, including public safety.However, due to the unique spatio-temporal distribution characteristics ofre-al-world data, most existing methods have limitations in terms of thespatio-temporal proximity of data and load balancing in distributed storage.There-fore, this paper proposes an efficient partitioning method of large-scalepublic safety spatio-temporal data based on information loss constraints(IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporalpoint da-ta by combining the spatio-temporal partitioning module (STPM) withthe graph partitioning module (GPM). This approach can significantly reduce thescale of data while maintaining the model's accuracy, in order to improve thepartitioning efficiency. It can also ensure the load balancing of distributedstorage while maintaining spatio-temporal proximity of the data partitioningresults. This method provides a new solution for distributed storage ofmas-sive spatio-temporal data. The experimental results on multiple real-worldda-tasets demonstrate the effectiveness and superiority of IFL-LSTP.</description><author>Jie Gao, Yawen Li, Zhe Xue, Zeli Guan</author><pubDate>Thu, 22 Jun 2023 14:08:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12857v1</guid></item><item><title>Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation</title><link>http://arxiv.org/abs/2205.12593v2</link><description>Recent research has revealed that deep neural networks often take datasetbiases as a shortcut to make decisions rather than understand tasks, leading tofailures in real-world applications. In this study, we focus on the spuriouscorrelation between word features and labels that models learn from the biaseddata distribution of training data. In particular, we define the word highlyco-occurring with a specific label as biased word, and the example containingbiased word as biased example. Our analysis shows that biased examples areeasier for models to learn, while at the time of prediction, biased words makea significantly higher contribution to the models' predictions, and models tendto assign predicted labels over-relying on the spurious correlation betweenwords and labels. To mitigate models' over-reliance on the shortcut (i.e.spurious correlation), we propose a training strategy Less-Learn-Shortcut(LLS): our strategy quantifies the biased degree of the biased examples anddown-weights them accordingly. Experimental results on Question Matching,Natural Language Inference and Sentiment Analysis tasks show that LLS is atask-agnostic strategy and can improve the model performance on adversarialdata while maintaining good performance on in-domain data.</description><author>Yanrui Du, Jing Yan, Yan Chen, Jing Liu, Sendong Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Bing Qin</author><pubDate>Thu, 22 Jun 2023 14:05:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.12593v2</guid></item><item><title>SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish</title><link>http://arxiv.org/abs/2304.13994v3</link><description>We present SweCTRL-Mini, a large Swedish language model that can be used forinference and fine-tuning on a single consumer-grade GPU. The model is based onthe CTRL architecture by Keskar, McCann, Varshney, Xiong, and Socher (2019),which means that users of the SweCTRL-Mini model can control the genre of thegenerated text by inserting special tokens in the generation prompts.SweCTRL-Mini is trained on a subset of the Swedish part of the mC4 corpus and aset of Swedish novels. In this article, we provide (1) a detailed account ofthe utilized training data and text pre-processing steps, to the extent that itis possible to check whether a specific phrase/source was a part of thetraining data, and (2) an evaluation of the model on both discriminative tasks,using automatic evaluation methods, and generative tasks, using human referees.We also compare the generative capabilities of the model with those of GPT-3.SweCTRL-Mini is fully open and available for download.</description><author>Dmytro Kalpakchi, Johan Boye</author><pubDate>Thu, 22 Jun 2023 14:02:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13994v3</guid></item><item><title>Enhancing Deformable Convolution based Video Frame Interpolation with Coarse-to-fine 3D CNN</title><link>http://arxiv.org/abs/2202.07731v2</link><description>This paper presents a new deformable convolution-based video frameinterpolation (VFI) method, using a coarse to fine 3D CNN to enhance themulti-flow prediction. This model first extracts spatio-temporal features atmultiple scales using a 3D CNN, and estimates multi-flows using these featuresin a coarse-to-fine manner. The estimated multi-flows are then used to warp theoriginal input frames as well as context maps, and the warped results are fusedby a synthesis network to produce the final output. This VFI approach has beenfully evaluated against 12 state-of-the-art VFI methods on three commonly usedtest databases. The results evidently show the effectiveness of the proposedmethod, which offers superior interpolation performance over other state of theart algorithms, with PSNR gains up to 0.19dB.</description><author>Duolikun Danier, Fan Zhang, David Bull</author><pubDate>Thu, 22 Jun 2023 13:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.07731v2</guid></item><item><title>A Subjective Quality Study for Video Frame Interpolation</title><link>http://arxiv.org/abs/2202.07727v2</link><description>Video frame interpolation (VFI) is one of the fundamental research areas invideo processing and there has been extensive research on novel and enhancedinterpolation algorithms. The same is not true for quality assessment of theinterpolated content. In this paper, we describe a subjective quality study forVFI based on a newly developed video database, BVI-VFI. BVI-VFI contains 36reference sequences at three different frame rates and 180 distorted videosgenerated using five conventional and learning based VFI algorithms. Subjectiveopinion scores have been collected from 60 human participants, and thenemployed to evaluate eight popular quality metrics, including PSNR, SSIM andLPIPS which are all commonly used for assessing VFI methods. The resultsindicate that none of these metrics provide acceptable correlation with theperceived quality on interpolated content, with the best-performing metric,LPIPS, offering a SROCC value below 0.6. Our findings show that there is anurgent need to develop a bespoke perceptual quality metric for VFI. The BVI-VFIdataset is publicly available and can be accessed athttps://danier97.github.io/BVI-VFI/.</description><author>Duolikun Danier, Fan Zhang, David Bull</author><pubDate>Thu, 22 Jun 2023 13:56:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.07727v2</guid></item><item><title>On-line reinforcement learning for optimization of real-life energy trading strategy</title><link>http://arxiv.org/abs/2303.16266v2</link><description>An increasing share of energy is produced from renewable sources by manysmall producers. The efficiency of those sources is volatile and, to someextent, random, exacerbating the problem of energy market balancing. In manycountries, this balancing is done on the day-ahead (DA) energy markets. Thispaper considers automated trading on the DA energy market by a medium sizeprosumer. We model this activity as a Markov Decision Process and formalize aframework in which an applicable in real-life strategy can be optimized withoff-line data. We design a trading strategy that is fed with the availableenvironmental information that can impact future prices, including weatherforecasts. We use state-of-the-art reinforcement learning (RL) algorithms tooptimize this strategy. For comparison, we also synthesize a simple parametrictrading strategy and optimize it with an evolutionary algorithm. Results showthat our RL-based strategy generates the highest market profits.</description><author>Åukasz Lepak, PaweÅ WawrzyÅski</author><pubDate>Thu, 22 Jun 2023 13:53:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.16266v2</guid></item><item><title>FloLPIPS: A Bespoke Video Quality Metric for Frame Interpoation</title><link>http://arxiv.org/abs/2207.08119v2</link><description>Video frame interpolation (VFI) serves as a useful tool for many videoprocessing applications. Recently, it has also been applied in the videocompression domain for enhancing both conventional video codecs andlearning-based compression architectures. While there has been an increasedfocus on the development of enhanced frame interpolation algorithms in recentyears, the perceptual quality assessment of interpolated content remains anopen field of research. In this paper, we present a bespoke full referencevideo quality metric for VFI, FloLPIPS, that builds on the popular perceptualimage quality metric, LPIPS, which captures the perceptual degradation inextracted image feature space. In order to enhance the performance of LPIPS forevaluating interpolated content, we re-designed its spatial feature aggregationstep by using the temporal distortion (through comparing optical flows) toweight the feature difference maps. Evaluated on the BVI-VFI database, whichcontains 180 test sequences with various frame interpolation artefacts,FloLPIPS shows superior correlation performance (with statistical significance)with subjective ground truth over 12 popular quality assessors. To facilitatefurther research in VFI quality assessment, our code is publicly available athttps://danier97.github.io/FloLPIPS.</description><author>Duolikun Danier, Fan Zhang, David Bull</author><pubDate>Thu, 22 Jun 2023 13:51:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.08119v2</guid></item><item><title>Don't Treat the Symptom, Find the Cause! Efficient Artificial-Intelligence Methods for (Interactive) Debugging</title><link>http://arxiv.org/abs/2306.12850v1</link><description>In the modern world, we are permanently using, leveraging, interacting with,and relying upon systems of ever higher sophistication, ranging from our cars,recommender systems in e-commerce, and networks when we go online, tointegrated circuits when using our PCs and smartphones, the power grid toensure our energy supply, security-critical software when accessing our bankaccounts, and spreadsheets for financial planning and decision making. Thecomplexity of these systems coupled with our high dependency on them impliesboth a non-negligible likelihood of system failures, and a high potential thatsuch failures have significant negative effects on our everyday life. For thatreason, it is a vital requirement to keep the harm of emerging failures to aminimum, which means minimizing the system downtime as well as the cost ofsystem repair. This is where model-based diagnosis comes into play. Model-based diagnosis is a principled, domain-independent approach that canbe generally applied to troubleshoot systems of a wide variety of types,including all the ones mentioned above, and many more. It exploits andorchestrates i.a. techniques for knowledge representation, automated reasoning,heuristic problem solving, intelligent search, optimization, stochastics,statistics, decision making under uncertainty, machine learning, as well ascalculus, combinatorics and set theory to detect, localize, and fix faults inabnormally behaving systems. In this thesis, we will give an introduction to the topic of model-baseddiagnosis, point out the major challenges in the field, and discuss a selectionof approaches from our research addressing these issues.</description><author>Patrick Rodler</author><pubDate>Thu, 22 Jun 2023 13:44:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12850v1</guid></item><item><title>Cryptocurrency Valuation: An Explainable AI Approach</title><link>http://arxiv.org/abs/2201.12893v7</link><description>Currently, there are no convincing proxies for the fundamentals ofcryptocurrency assets. We propose a new market-to-fundamental ratio, theprice-to-utility (PU) ratio, utilizing unique blockchain accounting methods. Wethen proxy various existing fundamental-to-market ratios by Bitcoin historicaldata and find they have little predictive power for short-term bitcoin returns.However, PU ratio effectively predicts long-term bitcoin returns thanalternative methods. Furthermore, we verify the explainability of PU ratiousing machine learning. Finally, we present an automated trading strategyadvised by the PU ratio that outperforms the conventional buy-and-hold andmarket-timing strategies. Our research contributes to explainable AI in financefrom three facets: First, our market-to-fundamental ratio is based on classicmonetary theory and the unique UTXO model of Bitcoin accounting rather than adhoc; Second, the empirical evidence testifies the buy-low and sell-highimplications of the ratio; Finally, we distribute the trading algorithms asopen-source software via Python Package Index for future research, which isexceptional in finance research.</description><author>Yulin Liu, Luyao Zhang</author><pubDate>Thu, 22 Jun 2023 13:35:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.12893v7</guid></item><item><title>On the explainable properties of 1-Lipschitz Neural Networks: An Optimal Transport Perspective</title><link>http://arxiv.org/abs/2206.06854v2</link><description>Input gradients have a pivotal role in a variety of applications, includingadversarial attack algorithms for evaluating model robustness, explainable AItechniques for generating Saliency Maps, and counterfactual explanations.However, Saliency Maps generated by traditional neural networks are often noisyand provide limited insights. In this paper, we demonstrate that, on thecontrary, the Saliency Maps of 1-Lipschitz neural networks, learnt with thedual loss of an optimal transportation problem, exhibit desirable XAIproperties: They are highly concentrated on the essential parts of the imagewith low noise, significantly outperforming state-of-the-art explanationapproaches across various models and metrics. We also prove that these mapsalign unprecedentedly well with human explanations on ImageNet. To explain theparticularly beneficial properties of the Saliency Map for such models, weprove this gradient encodes both the direction of the transportation plan andthe direction towards the nearest adversarial attack. Following the gradientdown to the decision boundary is no longer considered an adversarial attack,but rather a counterfactual explanation that explicitly transports the inputfrom one class to another. Thus, Learning with such a loss jointly optimizesthe classification objective and the alignment of the gradient , i.e. theSaliency Map, to the transportation plan direction. These networks werepreviously known to be certifiably robust by design, and we demonstrate thatthey scale well for large problems and models, and are tailored forexplainability using a fast and straightforward method.</description><author>Mathieu Serrurier, Franck Mamalet, Thomas Fel, Louis BÃ©thune, Thibaut Boissin</author><pubDate>Thu, 22 Jun 2023 13:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.06854v2</guid></item><item><title>Text-Driven Foley Sound Generation With Latent Diffusion Model</title><link>http://arxiv.org/abs/2306.10359v2</link><description>Foley sound generation aims to synthesise the background sound for multimediacontent. Previous models usually employ a large development set with labels asinput (e.g., single numbers or one-hot vector). In this work, we propose adiffusion model based system for Foley sound generation with text conditions.To alleviate the data scarcity issue, our model is initially pre-trained withlarge-scale datasets and fine-tuned to this task via transfer learning usingthe contrastive language-audio pertaining (CLAP) technique. We have observedthat the feature embedding extracted by the text encoder can significantlyaffect the performance of the generation model. Hence, we introduce a trainablelayer after the encoder to improve the text embedding produced by the encoder.In addition, we further refine the generated waveform by generating multiplecandidate audio clips simultaneously and selecting the best one, which isdetermined in terms of the similarity score between the embedding of thecandidate clips and the embedding of the target text label. Using the proposedmethod, our system ranks ${1}^{st}$ among the systems submitted to DCASEChallenge 2023 Task 7. The results of the ablation studies illustrate that theproposed techniques significantly improve sound generation performance. Thecodes for implementing the proposed system are available online.</description><author>Yi Yuan, Haohe Liu, Xubo Liu, Xiyuan Kang, Peipei Wu, Mark D. Plumbley, Wenwu Wang</author><pubDate>Thu, 22 Jun 2023 13:19:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10359v2</guid></item><item><title>Natural Language Processing in Electronic Health Records in Relation to Healthcare Decision-making: A Systematic Review</title><link>http://arxiv.org/abs/2306.12834v1</link><description>Background: Natural Language Processing (NLP) is widely used to extractclinical insights from Electronic Health Records (EHRs). However, the lack ofannotated data, automated tools, and other challenges hinder the fullutilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL)and NLP techniques are studied and compared to understand the limitations andopportunities in this space comprehensively. Methodology: After screening 261 articles from 11 databases, we included 127papers for full-text review covering seven categories of articles: 1) medicalnote classification, 2) clinical entity recognition, 3) text summarisation, 4)deep learning (DL) and transfer learning architecture, 5) informationextraction, 6) Medical language translation and 7) other NLP applications. Thisstudy follows the Preferred Reporting Items for Systematic Reviews andMeta-Analyses (PRISMA) guidelines. Result and Discussion: EHR was the most commonly used data type among theselected articles, and the datasets were primarily unstructured. Various ML andDL methods were used, with prediction or classification being the most commonapplication of ML or DL. The most common use cases were: the InternationalClassification of Diseases, Ninth Revision (ICD-9) classification, clinicalnote analysis, and named entity recognition (NER) for clinical descriptions andresearch on psychiatric disorders. Conclusion: We find that the adopted ML models were not adequately assessed.In addition, the data imbalance problem is quite important, yet we must findtechniques to address this underlining problem. Future studies should addresskey limitations in studies, primarily identifying Lupus Nephritis, SuicideAttempts, perinatal self-harmed and ICD-9 classification.</description><author>Elias Hossain, Rajib Rana, Niall Higgins, Jeffrey Soar, Prabal Datta Barua, Anthony R. Pisani, Ph. D, Kathryn Turner}</author><pubDate>Thu, 22 Jun 2023 13:10:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12834v1</guid></item><item><title>MultiTASC: A Multi-Tenancy-Aware Scheduler for Cascaded DNN Inference at the Consumer Edge</title><link>http://arxiv.org/abs/2306.12830v1</link><description>Cascade systems comprise a two-model sequence, with a lightweight modelprocessing all samples and a heavier, higher-accuracy model conditionallyrefining harder samples to improve accuracy. By placing the light model on thedevice side and the heavy model on a server, model cascades constitute a widelyused distributed inference approach. With the rapid expansion of intelligentindoor environments, such as smart homes, the new setting of Multi-DeviceCascade is emerging where multiple and diverse devices are to simultaneouslyuse a shared heavy model on the same server, typically located within or closeto the consumer environment. This work presents MultiTASC, amulti-tenancy-aware scheduler that adaptively controls the forwarding decisionfunctions of the devices in order to maximize the system throughput, whilesustaining high accuracy and low latency. By explicitly considering deviceheterogeneity, our scheduler improves the latency service-level objective (SLO)satisfaction rate by 20-25 percentage points (pp) over state-of-the-art cascademethods in highly heterogeneous setups, while serving over 40 devices,showcasing its scalability.</description><author>Sokratis Nikolaidis, Stylianos I. Venieris, Iakovos S. Venieris</author><pubDate>Thu, 22 Jun 2023 13:04:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12830v1</guid></item></channel></rss>